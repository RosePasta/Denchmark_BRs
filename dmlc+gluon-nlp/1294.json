{"BR": {"BR_id": "1294", "BR_author": "davisliang", "BRopenT": "2020-08-10T23:11:14Z", "BRcloseT": "2020-08-13T01:20:04Z", "BR_text": {"BRsummary": "GluonNLP 0.8 BERT output is different from GluonNLP 0.9", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n Using the same BERT model parameters, GluonNLP0.8 and GluonNLP0.9 output drastically different encoder representations. Tested on both MxNet1.5, MxNet1.6.\n <denchmark-h:h3>Error Message</denchmark-h>\n \n GluonNLP 0.8 output:\n [[[-0.14241228  0.13353696 -0.12907042 ... -0.3596797  -0.05622234\n 0.36050126]\n [-0.3506479   0.10419717  0.62444484 ... -0.17610289  0.48340234\n 0.06443496]\n [-0.24513118 -0.15731761  0.69451797 ... -0.5654461  -0.08939961\n -0.18564416]\n [-0.824786   -0.9119225  -0.65607095 ...  0.50742507 -0.19388743\n -0.1658766 ]\n [ 0.87665254  0.03524816 -0.12331399 ...  0.2720159  -0.63690007\n -0.15850069]]]\n <NDArray 1x5x768 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n GluonNLP 0.9 output:\n [[[-0.8164635  -0.18977094 -0.44616854 ... -0.9124998   0.02381709\n 0.5544555 ]\n [-1.0949776  -0.41612968  0.5249134  ... -0.706112    0.14636786\n -0.38614586]\n [-0.8410385  -0.45054507  0.3945069  ... -0.9239115  -0.3351414\n 0.05241004]\n [-0.8435936  -1.2706859  -0.5667961  ... -0.40249282 -0.1447221\n -0.12529008]\n [ 0.75693136 -1.1236286  -0.2741627  ...  0.08363507 -0.71608377\n 0.29923674]]]\n <NDArray 1x5x768 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n First, install the packages:\n !pip install mxnet-cu102\n !pip install gluonnlp==0.9.1\n !pip install gluonnlp==0.8\n <denchmark-code>import gluonnlp as nlp; import mxnet as mx;\n model, vocab = nlp.model.get_model('bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased', use_classifier=False, use_decoder=False);\n tokenizer = nlp.data.BERTTokenizer(vocab, lower=True);\n transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=512, pair=False, pad=False);\n sample = transform(['Hello world!']);\n words, valid_len, segments = mx.nd.array([sample[0]]), mx.nd.array([sample[1]]), mx.nd.array([sample[2]]);\n seq_encoding, cls_encoding = model(words, segments, valid_len);\n \n print(seq_encoding)\n </denchmark-code>\n \n <denchmark-h:h3>Steps to reproduce</denchmark-h>\n \n (Paste the commands you ran that produced the error.)\n \n Install the package (either GluonNLP 0.8 or 0.9, as detailed in To Reproduce)\n Run the example code snippet, taken from the GluonNLP BERT tutorial\n \n <denchmark-h:h2>What have you tried to solve it?</denchmark-h>\n \n \n I hypothesized there might be something different in the handing of parameters but it doesn't seem like it.\n I hypothesized there might be something different with tokenization and transformations but it doesn't seem like that's the issue either.\n \n <denchmark-h:h2>Environment</denchmark-h>\n \n Any EC2\n We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\n <denchmark-code>curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\n \n # paste outputs here\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "davisliang", "commentT": "2020-08-10T23:12:26Z", "comment_text": "\n \t\tI did a git bisect on the 0.9.x branch with start commit <denchmark-link:https://github.com/dmlc/gluon-nlp/commit/76fdafbebbbb8f4a09fb82a032b2bdd17ef86287>76fdafb</denchmark-link>\n  and got the following result: <denchmark-link:https://github.com/dmlc/gluon-nlp/commit/75c29a3518ee42b98cc651b6922cbae85d2e961e>75c29a3</denchmark-link>\n \n <denchmark-code>75c29a3518ee42b98cc651b6922cbae85d2e961e is the first bad commit\n commit 75c29a3518ee42b98cc651b6922cbae85d2e961e\n Author: Haibin Lin <linhaibin.eric@gmail.com>\n Date:   Fri Feb 7 13:51:21 2020 -0800\n \n     [API] use softmax with length, and interleaved matmul for BERT (#1136)\n </denchmark-code>\n \n cc <denchmark-link:https://github.com/eric-haibin-lin>@eric-haibin-lin</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "davisliang", "commentT": "2020-08-13T01:09:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/davisliang>@davisliang</denchmark-link>\n  Is it solved by <denchmark-link:https://github.com/dmlc/gluon-nlp/pull/1296>#1296</denchmark-link>\n ?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "davisliang", "commentT": "2020-08-13T01:20:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/sxjscience>@sxjscience</denchmark-link>\n  yes, looks like it solves the issue. Thanks for the quick turnaround!\n \t\t"}}}, "commit": {"commit_id": "d75185ec7eb1eb082ee92992be8677666aaf7ec7", "commit_author": "Haibin Lin", "commitT": "2020-08-12 14:36:22-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\gluonnlp\\model\\bert.py", "file_new_name": "src\\gluonnlp\\model\\bert.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "137,138,139,140,141", "deleted_lines": "137"}}}}}}