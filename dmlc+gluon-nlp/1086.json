{"BR": {"BR_id": "1086", "BR_author": "liuzh91", "BRopenT": "2020-01-03T08:23:43Z", "BRcloseT": "2020-01-10T02:46:27Z", "BR_text": {"BRsummary": "Conflict between weight tied and weight sharing", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n This bug is the same as <denchmark-link:https://github.com/apache/incubator-mxnet/issues/17184>apache/incubator-mxnet#17184</denchmark-link>\n  It is an error introduced in gluonnlp models instead of mxnet side, so I move the issue here.\n We experience some weight initialization error when we use weight sharing and weight tied simultaneously. We share weights between model and model_eval. The code is shown below:\n model = nlp.model.train.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\n                                args.tied, args.dropout, args.weight_dropout,\n                                args.dropout_h, args.dropout_i, args.dropout_e)\n model_eval = nlp.model.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,\n                               args.tied, args.dropout, args.weight_dropout,\n                               args.dropout_h, args.dropout_i, args.dropout_e,\n                               params=model.collect_params())\n \n model.initialize(mx.init.Xavier(), ctx=context)\n \n model.hybridize(static_alloc=True)\n \n print(model)\n \n def check_initialized(net):\n     params = net.collect_params()\n     for param in params:\n         try:\n             params[param].list_ctx()\n         except RuntimeError:\n             return False\n     return True\n \n print(check_initialized(model))\n print(check_initialized(model_eval))\n <denchmark-h:h3>Log Message</denchmark-h>\n \n If args.tied is set True, we get the following log message:\n True\n False\n If we turn off args.tied, the initialization works correctly.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n (If you developed your own code, please provide a short script that reproduces the error. For existing examples, please provide link.)\n The file can be found in (<denchmark-link:https://github.com/dmlc/gluon-nlp/blob/v0.8.x/scripts/language_model/word_language_model.py>https://github.com/dmlc/gluon-nlp/blob/v0.8.x/scripts/language_model/word_language_model.py</denchmark-link>\n ). To reproduce the above message, you may need to replace line 153 onward  with the above code snippet. Run the following command:\n <denchmark-code>python -m pdb word_language_model.py --tied --dropout_e=0\n </denchmark-code>\n \n You will encounter the above error.\n <denchmark-h:h2>What have you tried to solve it?</denchmark-h>\n \n The parameter that not initialized properly is the parameter awdrnn0_hybridsequential0_embedding0_bias. It is the weight used in the decoder of AWDRNN.  After some investigation, we found it is the tied weights introducing this error:\n     if self._tie_weights:\n          output.add(nn.Dense(self._vocab_size, flatten=False,\n                              params=self.embedding[0].params))\n I print some debug information which may be helpful here:\n <denchmark-code>(Pdb) model_eval.decoder[0]._params['awdrnn0_hybridsequential0_embedding0_bias'].list_ctx()\n *** RuntimeError: Parameter 'awdrnn0_hybridsequential0_embedding0_bias' has not been initialized\n </denchmark-code>\n \n <denchmark-h:h2>Environment</denchmark-h>\n \n We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\n <denchmark-code>curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\n \n # paste outputs here\n </denchmark-code>\n \n \t"}, "comments": {}}, "commit": {"commit_id": "0f29a403068a10ce33faca4c9a4c25879113f5cb", "commit_author": "liuzh91", "commitT": "2020-01-09 12:41:23+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\gluonnlp\\model\\train\\language_model.py", "file_new_name": "src\\gluonnlp\\model\\train\\language_model.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "109,110,111,112,113,114,115,116,117,118,119,120,121", "deleted_lines": "106,107", "method_info": {"method_name": "_get_decoder", "method_params": "self", "method_startline": "105", "method_endline": "124"}}}}}}}