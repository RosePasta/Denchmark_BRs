{"BR": {"BR_id": "4770", "BR_author": "EdwardJB", "BRopenT": "2019-12-05T14:27:12Z", "BRcloseT": "2019-12-06T13:07:40Z", "BR_text": {"BRsummary": "Text classification results (Document.cat) missing when multiprocessing enabled", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n On a model that contains some text classifiers, run this code with n_process=1. It works as expected; classifications are present:\n text='my test text'\n docs = self.model.pipe([text],n_process=1)\n response = []\n for i, (text, doc) in enumerate(zip(texts, docs), start=1):\n     print(doc.to_json())\n {'text': 'my test text', 'sents': [{'start': 0, 'end': 12}], 'cats': {...all of my cats are here..}, 'tokens': [{'id': 0, 'start': 0, 'end': 2}, {'id': 1, 'start': 3, 'end': 7}, {'id': 2, 'start': 8, 'end': 12}]}\n Now run the same with n_process=-1, and they are missing:\n text='my test text'\n docs = self.model.pipe([text],n_process=-1)\n response = []\n for i, (text, doc) in enumerate(zip(texts, docs), start=1):\n     print(doc.to_json())\n     print(doc.cats)\n {'text': 'my test text', 'sents': [{'start': 0, 'end': 12}], 'tokens': [{'id': 0, 'start': 0, 'end': 2}, {'id': 1, 'start': 3, 'end': 7}, {'id': 2, 'start': 8, 'end': 12}]}\n {}\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n <denchmark-h:h2>Info about spaCy</denchmark-h>\n \n \n spaCy version: 2.2.3\n Platform: Linux-4.4.0-18362-Microsoft-x86_64-with-glibc2.2.5\n Python version: 3.8.0\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "EdwardJB", "commentT": "2019-12-05T19:28:23Z", "comment_text": "\n \t\tThanks for the report! I can replicate this and it looks like the cats are going missing when the Doc is serialized. I'm surprised this bug wasn't noticed a lot earlier...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "EdwardJB", "commentT": "2020-01-05T14:19:24Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "676e75838f852246ac045837cd852b854b06d77e", "commit_author": "adrianeboyd", "commitT": "2019-12-06 14:07:39+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "spacy\\tests\\serialize\\test_serialize_doc.py", "file_new_name": "spacy\\tests\\serialize\\test_serialize_doc.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "70,73,80,81,82,83", "deleted_lines": "77", "method_info": {"method_name": "test_serialize_doc_bin", "method_params": "", "method_startline": "67", "method_endline": "83"}}, "hunk_1": {"Ismethod": 1, "added_lines": "27", "deleted_lines": null, "method_info": {"method_name": "test_serialize_doc_roundtrip_bytes", "method_params": "en_vocab", "method_startline": "25", "method_endline": "30"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "spacy\\tokens\\_serialize.py", "file_new_name": "spacy\\tokens\\_serialize.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "127", "deleted_lines": null, "method_info": {"method_name": "merge", "method_params": "self,other", "method_startline": "113", "method_endline": "129"}}, "hunk_1": {"Ismethod": 1, "added_lines": "107", "deleted_lines": null, "method_info": {"method_name": "get_docs", "method_params": "self,vocab", "method_startline": "90", "method_endline": "111"}}, "hunk_2": {"Ismethod": 1, "added_lines": "147", "deleted_lines": null, "method_info": {"method_name": "to_bytes", "method_params": "self", "method_startline": "131", "method_endline": "151"}}, "hunk_3": {"Ismethod": 1, "added_lines": "61", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,attrs,store_user_data", "method_startline": "45", "method_endline": "64"}}, "hunk_4": {"Ismethod": 1, "added_lines": "172", "deleted_lines": null, "method_info": {"method_name": "from_bytes", "method_params": "self,bytes_data", "method_startline": "153", "method_endline": "177"}}, "hunk_5": {"Ismethod": 1, "added_lines": "86", "deleted_lines": null, "method_info": {"method_name": "add", "method_params": "self,doc", "method_startline": "70", "method_endline": "88"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\doc.pyx", "file_new_name": "spacy\\tokens\\doc.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "890,920,942,943", "deleted_lines": null}}}}}}