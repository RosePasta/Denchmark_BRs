{"BR": {"BR_id": "1427", "BR_author": "benhachey", "BRopenT": "2017-10-17T03:08:21Z", "BRcloseT": "2017-10-20T11:09:35Z", "BR_text": {"BRsummary": "Cannot deserialise LAW entities", "BRdescription": "\n I can't get LAW entities to deserialise, e.g.:\n import spacy\n from spacy.tokens import Span\n \n text = u'Netflix is hiring a new VP of global policy according to Section 1 of the corporate charter.'\n \n nlp = spacy.load('en_core_web_sm')\n doc = nlp(text)\n \n from spacy.tokens import Doc\n from spacy.vocab import Vocab\n \n bin_doc = doc.to_bytes()\n doc2 = Doc(Vocab()).from_bytes(bin_doc)\n \n print([(e.label_, e.text) for e in doc.ents])\n print([(e.label_, e.text) for e in doc2.ents])\n Raises:\n <denchmark-code>[('ORG', 'VP'), ('LAW', 'Section 1')]\n ---------------------------------------------------------------------------\n AssertionError                            Traceback (most recent call last)\n <ipython-input-28-35776b8a45af> in <module>()\n       1 print([(e.label_, e.text) for e in doc.ents])\n ----> 2 print([(e.label_, e.text) for e in doc2.ents])\n \n doc.pyx in spacy.tokens.doc.Doc.ents.__get__()\n \n span.pyx in spacy.tokens.span.Span.__cinit__()\n \n AssertionError: 4035656307355538346\n </denchmark-code>\n \n Breaking at:\n \n \n \n spaCy/spacy/tokens/span.pyx\n \n \n          Line 60\n       in\n       485c4f6\n \n \n \n \n \n \n  assert label in doc.vocab.strings, label \n \n \n \n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "benhachey", "commentT": "2017-10-17T09:18:57Z", "comment_text": "\n \t\tBugger, thanks.\n To keep you working: nlp.vocab.strings.add('LAW')\n Strings are hashed into uint64, which is obviously one-way. So if we try to look up a string that's missing it will cause an error.\n I'm sort of worried about the implications of this though. Does this mean there were zero LAW entities in the data? Also I thought all the entity labels would be in spacy.symbols...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "benhachey", "commentT": "2017-10-18T22:39:52Z", "comment_text": "\n \t\t\n I'm sort of worried about the implications of this though. Does this mean there were zero LAW entities in the data?\n \n I just checked and even though it's present in the OntoNotes 5 corpus, spaCy currently doesn't have a LAW symbol \ud83d\ude31 It's also not part of our documented NER scheme... which I guess was based on spacy.symbols, so we never noticed? It's very mysterious.\n The good news is, the issue that made it very difficult to add new symbols in v1.x is not a problem in v2.0 anymore. So we can simply add it to spacy.symbols now.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "benhachey", "commentT": "2017-10-20T11:09:35Z", "comment_text": "\n \t\tFixed and will be included in v2.0!\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "benhachey", "commentT": "2018-05-08T13:28:01Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "4acab77a8a36c6f54cacf5e26b32860a30d09657", "commit_author": "ines", "commitT": "2017-10-20 13:07:57+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\symbols.pxd", "file_new_name": "spacy\\symbols.pxd", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "470", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\symbols.pyx", "file_new_name": "spacy\\symbols.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "461", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "website\\api\\_annotation\\_named-entities.jade", "file_new_name": "website\\api\\_annotation\\_named-entities.jade", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "40,41,42,43", "deleted_lines": null}}}}}}