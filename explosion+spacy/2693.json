{"BR": {"BR_id": "2693", "BR_author": "j-rausch", "BRopenT": "2018-08-21T22:41:57Z", "BRcloseT": "2018-11-30T20:22:49Z", "BR_text": {"BRsummary": "Unexpected behavior of nlp.has_pipe(\"sentencizer\")", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n Basically following the tutorial in <denchmark-link:https://spacy.io/usage/linguistic-features#sbd-component>https://spacy.io/usage/linguistic-features#sbd-component</denchmark-link>\n  with the addition of calling has_pipe() in a loop:\n <denchmark-code>import spacy\n from spacy.lang.en import English\n \n nlp = English()  # just the language with no model\n for i in range(2):\n     if not nlp.has_pipe('sentencizer'):\n         sbd = nlp.create_pipe('sentencizer')   # or: nlp.create_pipe('sbd')\n         nlp.add_pipe(sbd)\n     doc = nlp(u\"This is a sentence. This is another sentence.\")\n     for sent in doc.sents:\n         print(sent.text)\n \n </denchmark-code>\n \n Leads to following error:\n  ValueError: [E007] 'sbd' already exists in pipeline. Existing names: ['sbd']\n I noticed that, while it is possible to create a pipeline with the \"sentencizer\" string, calling has_pipe(\"sentencizer\") will not return True for the pipeline afterwards.\n Replacing \"sentencizer\" with \"sbd\" in the code resolves the error.\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n python 3.6, spacy 2.0.12\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "j-rausch", "commentT": "2018-10-01T15:32:10Z", "comment_text": "\n \t\tI was able to recreate the issue on my computer. It looks like pipe_create is the only pipe method for which the alias 'sentencizer' works, effectively just substituting the input 'sentencizer' for the input 'sbd' and expecting all future method calls to use 'sbd'. Until the issue is fixed, it probably makes the most sense just to stick with 'sbd' in your code.\n It's feasible though non-trivial to make small code changes to most of the pipeline methods (pipe_names, has_pipe, replace_pipe, rename_pipe, remove_pipe, etc.) to accommodate arbitrary aliases for pipes.\n To contributors more familiar, is having multiple possible names for each pipe necessary or worth the effort and loss of code elegance? Or should the code just accept 'sbd' and reject 'sentencizer'?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "j-rausch", "commentT": "2018-10-01T22:28:02Z", "comment_text": "\n \t\tThanks for the detailed analysis \u2013\u00a0I'm pretty sure that's correct!\n \n To contributors more familiar, is having multiple possible names for each pipe necessary or worth the effort and loss of code elegance? Or should the code just accept 'sbd' and reject 'sentencizer'?\n \n To be honest, I think we should have just gone with sbd or at least standardised on one name. The original idea behind sentencizer was to make it more explicit and immediately obvious what the component does from looking at the pipe names (sbd is kinda cryptic if you don't know that it means \"sentence boundary detection\"). sbd seemed more convenient, though, so we added that as well... and now we're stuck with both \ud83d\ude1d\n We can still change this, possibly already for 2.1.0 (standardise on one name, output a warning if the other is used?). Also open to naming suggestions!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "j-rausch", "commentT": "2018-10-01T22:58:32Z", "comment_text": "\n \t\thow about sents? Otherwise, sentencizer seems fine. sbd seems cryptic to me.\n I can make changes in the code/docs in favor of one name if you think it's a good idea.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "j-rausch", "commentT": "2018-10-09T02:16:05Z", "comment_text": "\n \t\tI can just follow through with sentencizer if that makes things simple going forward. I suppose I'll have to look for docs referring to sbd as well.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "j-rausch", "commentT": "2018-11-21T05:18:54Z", "comment_text": "\n \t\tbump\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "j-rausch", "commentT": "2018-11-26T13:26:23Z", "comment_text": "\n \t\tSorry, totally missed your comments! Thanks for offering to take care of this \ud83d\udc4d\n Let's go for sentencizer then \u2013\u00a0but we should probably only implement this on develop, since it's a breaking change. We don't need to worry much about existing models that include the sbd component, since users will have to retrain their models with v2.1.x anyways. However, spaCy should probably raise a more specific error on nlp.create_pipe('sbd') informing the user that this component name has been deprecated and to use 'sentencizer' instead.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "j-rausch", "commentT": "2018-11-27T23:07:30Z", "comment_text": "\n \t\tSo there seem to be a lot of references to sbd internally (e.g. names of tests like in test_sbd.py) as well as references for the website (e.g. sbd-parser, sbd-manual, sbd-component, etc.) in addition to documentation. Would you want me to try and change both, or just the website, or stick to the source code? I'm happy to try, but I am new to spacy contribution.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "j-rausch", "commentT": "2018-11-28T14:09:48Z", "comment_text": "\n \t\t\n Would you want me to try and change both, or just the website, or stick to the source code?\n \n I'd say sbd is totally fine internally, because it is the common abbreviation for \"sentence boundary detection\" (whereas \"sentencizer\" is really something we made up because it's a cool component name \ud83d\ude03).\n So you'd only have to focus on changing string name of the built-in component (and references to it).\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "j-rausch", "commentT": "2018-11-29T03:59:00Z", "comment_text": "\n \t\tI'm getting ready to submit my first PR, but even before my changes the currently existing tests seem to fail a lot. In particular, I'm getting \"spacy/tests/lang/tr/test_lemmatization.py Killed\" when I run py.test spacy. Is there something wrong with my developer environment?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "j-rausch", "commentT": "2018-11-29T11:40:32Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/gavrieltal>@gavrieltal</denchmark-link>\n  First, are you on the  branch? (The tests on there should be better and faster, and we want the changes on the  branch anyways.)\n And did you check that everything compiled correctly? Here's how I usually set up my development environment (macOS / Linux) and run tests:\n python -m venv .env                  # create virtual environment\n source .env/bin/activate             # activate virtual environment\n pip install -r requirements.txt      # install requirements (including dev dependencies)\n python setup.py build_ext --inplace  # compile spaCy\n python -m pytest spacy               # run tests\n Also, is there a traceback or do you see more info when the tests die?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "j-rausch", "commentT": "2018-11-29T19:16:14Z", "comment_text": "\n \t\tI switched to the develop branch (I was on master). I followed your instructions precisely, except the first line was python3 -m venv .env. (I ran pip install.. and pip3 install.., as well as python3 -m pytest spacy and python -m pytest spacy, and also I tried using python2's virtualenv just in case). I have the same problem. The compilation stage featured a number of warnings about deprecation and flags working for C/ObjC but not C++. Regarding errors, my test suite performance is the same as previously:\n <denchmark-code>(.env) gavriel@stockholm:~/Desktop/python/spaCy$ python3 -m pytest spacy\n ================================================================== test session starts ==================================================================\n platform linux -- Python 3.6.7, pytest-4.0.1, py-1.7.0, pluggy-0.8.0\n rootdir: /home/gavriel/Desktop/python/spaCy, inifile:\n plugins: timeout-1.3.3\n collected 1633 items                                                                                                                                    \n \n spacy/tests/test_align.py ............                                                                                                            [  0%]\n spacy/tests/test_cli.py .                                                                                                                         [  0%]\n spacy/tests/test_gold.py ......                                                                                                                   [  1%]\n spacy/tests/test_misc.py ...........                                                                                                              [  1%]\n spacy/tests/test_pickles.py ..                                                                                                                    [  1%]\n spacy/tests/doc/test_add_entities.py ..                                                                                                           [  2%]\n spacy/tests/doc/test_array.py .....                                                                                                               [  2%]\n spacy/tests/doc/test_creation.py ...                                                                                                              [  2%]\n spacy/tests/doc/test_doc_api.py ..........x.......                                                                                                [  3%]\n spacy/tests/doc/test_pickle_doc.py .....                                                                                                          [  3%]\n spacy/tests/doc/test_span.py ..............                                                                                                       [  4%]\n spacy/tests/doc/test_span_merge.py ........                                                                                                       [  5%]\n spacy/tests/doc/test_token_api.py ...........                                                                                                     [  6%]\n spacy/tests/doc/test_underscore.py .....................                                                                                          [  7%]\n spacy/tests/lang/test_attrs.py ...................................                                                                                [  9%]\n spacy/tests/lang/ar/test_exceptions.py ......                                                                                                     [  9%]\n spacy/tests/lang/ar/test_text.py .                                                                                                                [  9%]\n spacy/tests/lang/bn/test_tokenizer.py ..........                                                                                                  [ 10%]\n spacy/tests/lang/ca/test_exception.py ....                                                                                                        [ 10%]\n spacy/tests/lang/ca/test_text.py .................                                                                                                [ 11%]\n spacy/tests/lang/da/test_exceptions.py .................                                                                                          [ 12%]\n spacy/tests/lang/da/test_lemma.py ....                                                                                                            [ 13%]\n spacy/tests/lang/da/test_prefix_suffix_infix.py ................................                                                                  [ 15%]\n spacy/tests/lang/da/test_text.py ..............                                                                                                   [ 15%]\n spacy/tests/lang/de/test_exceptions.py .............                                                                                              [ 16%]\n spacy/tests/lang/de/test_lemma.py ......                                                                                                          [ 17%]\n spacy/tests/lang/de/test_parser.py ..                                                                                                             [ 17%]\n spacy/tests/lang/de/test_prefix_suffix_infix.py ........................                                                                          [ 18%]\n spacy/tests/lang/de/test_text.py .......                                                                                                          [ 19%]\n spacy/tests/lang/el/test_exception.py .....                                                                                                       [ 19%]\n spacy/tests/lang/el/test_text.py ......                                                                                                           [ 19%]\n spacy/tests/lang/en/test_customized_tokenizer.py .                                                                                                [ 19%]\n spacy/tests/lang/en/test_exceptions.py ....................................................                                                       [ 22%]\n spacy/tests/lang/en/test_indices.py ..                                                                                                            [ 23%]\n spacy/tests/lang/en/test_noun_chunks.py .                                                                                                         [ 23%]\n spacy/tests/lang/en/test_parser.py .....                                                                                                          [ 23%]\n spacy/tests/lang/en/test_prefix_suffix_infix.py .......................xx                                                                         [ 24%]\n spacy/tests/lang/en/test_punct.py .......................................                                                                         [ 27%]\n spacy/tests/lang/en/test_sbd.py ....x                                                                                                             [ 27%]\n spacy/tests/lang/en/test_tagger.py .                                                                                                              [ 27%]\n spacy/tests/lang/en/test_text.py .......x............                                                                                             [ 28%]\n spacy/tests/lang/es/test_exception.py .....                                                                                                       [ 29%]\n spacy/tests/lang/es/test_text.py ......                                                                                                           [ 29%]\n spacy/tests/lang/fi/test_tokenizer.py ..                                                                                                          [ 29%]\n spacy/tests/lang/fr/test_exceptions.py ............x.                                                                                             [ 30%]\n spacy/tests/lang/fr/test_lemmatization.py ..x.                                                                                                    [ 30%]\n spacy/tests/lang/fr/test_prefix_suffix_infix.py ..                                                                                                [ 30%]\n spacy/tests/lang/fr/test_text.py ...                                                                                                              [ 31%]\n spacy/tests/lang/ga/test_tokenizer.py ..                                                                                                          [ 31%]\n spacy/tests/lang/he/test_tokenizer.py ......                                                                                                      [ 31%]\n spacy/tests/lang/hu/test_tokenizer.py .x...x............x...x.................................................................................... [ 38%]\n ........................................................................................................................................          [ 46%] \n spacy/tests/lang/id/test_prefix_suffix_infix.py .........................                                                                         [ 48%]\n spacy/tests/lang/id/test_text.py .                                                                                                                [ 48%]\n spacy/tests/lang/ja/test_lemmatization.py sssss                                                                                                   [ 48%]\n spacy/tests/lang/ja/test_tokenizer.py sssssssssssssss                                                                                             [ 49%]\n spacy/tests/lang/nb/test_tokenizer.py ..                                                                                                          [ 49%]\n spacy/tests/lang/nl/test_text.py ..                                                                                                               [ 49%]\n spacy/tests/lang/pt/test_text.py ..                                                                                                               [ 49%]\n spacy/tests/lang/ro/test_lemmatizer.py ....                                                                                                       [ 49%]\n spacy/tests/lang/ro/test_tokenizer.py ......                                                                                                      [ 50%]\n spacy/tests/lang/ru/test_exceptions.py sss                                                                                                        [ 50%]\n spacy/tests/lang/ru/test_lemmatizer.py sssssssssssssssssssss                                                                                      [ 51%]\n spacy/tests/lang/ru/test_text.py .                                                                                                                [ 51%]\n spacy/tests/lang/ru/test_tokenizer.py sssssssssssssssssssssssssssssssssssssss                                                                     [ 54%]\n spacy/tests/lang/sv/test_tokenizer.py .......                                                                                                     [ 54%]\n spacy/tests/lang/th/test_tokenizer.py s                                                                                                           [ 54%]\n spacy/tests/lang/tr/test_lemmatization.py Killed\n (.env) gavriel@stockholm:~/Desktop/python/spaCy$```\n </denchmark-code>\n \n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "j-rausch", "commentT": "2018-11-29T19:24:14Z", "comment_text": "\n \t\tPerfect, the steps all sound correct and the output during compilation is normal \ud83d\udc4d\n How much memory does your machine have? Maybe you're running out of memory!\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "j-rausch", "commentT": "2018-11-29T19:55:12Z", "comment_text": "\n \t\twow, the one test is actually blowing my 3.5 GB of memory. I hit like 200% RAM usage in htop before the test was killed. My old-school hard-drive access light turns on. I'm not changing anything related to Turkish; maybe I'll just submit the request and depend on Travis.\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "j-rausch", "commentT": "2018-12-30T20:48:02Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "919729d38cb6f1149d431761a8bdad038e59566b", "commit_author": "Gavriel Loria", "commitT": "2018-11-30 21:22:40+01:00", "changed_files": {"file_0": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": ".github\\contributors\\gavrieltal.md"}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\errors.py", "file_new_name": "spacy\\errors.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "287,288,289", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\language.py", "file_new_name": "spacy\\language.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "245,246,247,248", "deleted_lines": "246", "method_info": {"method_name": "create_pipe", "method_params": "self,name,config", "method_startline": "237", "method_endline": "250"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\pipeline.pyx", "file_new_name": "spacy\\pipeline.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "52", "deleted_lines": "52"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "website\\usage\\_linguistic-features\\_sentence-segmentation.jade", "file_new_name": "website\\usage\\_linguistic-features\\_sentence-segmentation.jade", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "91,92,125,126", "deleted_lines": "91,92,125,126"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "website\\usage\\_processing-pipelines\\_extensions.jade", "file_new_name": "website\\usage\\_processing-pipelines\\_extensions.jade", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "147,155", "deleted_lines": "147,155"}}}}}}