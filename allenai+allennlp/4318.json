{"BR": {"BR_id": "4318", "BR_author": "epwalsh", "BRopenT": "2020-06-03T20:43:11Z", "BRcloseT": "2020-06-04T22:50:03Z", "BR_text": {"BRsummary": "Peak CPU memory not reported correctly in distributed training", "BRdescription": "\n I noticed this bug while benchmarking some distributed experiments on beaker. I think allennlp.common.util.peak_memory_mb() is only called from the master process, and it only reports the memory usage for the master process. This should really report the combined memory used across all workers.\n \t"}, "comments": {}}, "commit": {"commit_id": "7d66b3e720cb3e1ffdd7a56e1b17ca23d91d03fd", "commit_author": "Evan Pete Walsh", "commitT": "2020-06-04 15:50:02-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "39,40", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "allennlp\\common\\util.py", "file_new_name": "allennlp\\common\\util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "354,356,360,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,387,389,390,391,392,393,395,397", "deleted_lines": "354,356,357,361,364,366,367,368,369,371,372,373,376,377", "method_info": {"method_name": "peak_memory_mb", "method_params": "", "method_startline": "354", "method_endline": "397"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "allennlp\\training\\tensorboard_writer.py", "file_new_name": "allennlp\\training\\tensorboard_writer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "102,103,104,105,106", "deleted_lines": "102,103,104,105", "method_info": {"method_name": "log_memory_usage", "method_params": "self", "method_startline": "102", "method_endline": "106"}}, "hunk_1": {"Ismethod": 1, "added_lines": "101,102", "deleted_lines": "102", "method_info": {"method_name": "log_memory_usage", "method_params": "self,int,int", "method_startline": "101", "method_endline": "102"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "allennlp\\training\\trainer.py", "file_new_name": "allennlp\\training\\trainer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "489,490,491,492,493,495,661,662,663", "deleted_lines": "484,485,487,653,654", "method_info": {"method_name": "_train_epoch", "method_params": "self,int", "method_startline": "484", "method_endline": "665"}}, "hunk_1": {"Ismethod": 1, "added_lines": "800,801,802", "deleted_lines": "790,791,792,793,795", "method_info": {"method_name": "train", "method_params": "self", "method_startline": "763", "method_endline": "904"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tests\\training\\trainer_test.py", "file_new_name": "tests\\training\\trainer_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "135,136,137", "deleted_lines": "135,136,137", "method_info": {"method_name": "test_trainer_can_run_cuda", "method_params": "self", "method_startline": "129", "method_endline": "139"}}, "hunk_1": {"Ismethod": 1, "added_lines": "112,113,114", "deleted_lines": "112,113,114", "method_info": {"method_name": "test_trainer_can_run", "method_params": "self", "method_startline": "76", "method_endline": "114"}}}}}}}