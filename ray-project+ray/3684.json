{"BR": {"BR_id": "3684", "BR_author": "marlonjan", "BRopenT": "2019-01-03T13:50:45Z", "BRcloseT": "2019-01-07T03:37:36Z", "BR_text": {"BRsummary": "[RLlib] PGAgent learns with lr=0.0", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra\n Ray installed from (source or binary): installed with pip\n Ray version: 0.6.0\n Python version: 3.6.7\n Exact command to reproduce: See below\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n PGAgent successfully trains with learning rate 0.0, while all model weights should remain constant.\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n <denchmark-code>import ray\n import ray.tune as tune\n from ray.rllib.agents.pg import PGAgent\n from ray.tune import Experiment\n \n if __name__ == \"__main__\":\n     ray.init()\n     tune.run_experiments(\n         Experiment(\n             name=\"zero_lr_cart_pole\",\n             run=PGAgent,\n             stop={\"episode_reward_mean\": 400.0},\n             config={\n                 \"env\": \"CartPole-v0\", \n                 \"num_gpus\": 0, \n                 \"num_workers\": 1, \n                 \"lr\": 0.0  # <---------- zero\n             },\n         )\n     )\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "marlonjan", "commentT": "2019-01-03T15:57:56Z", "comment_text": "\n \t\tMy impression is that the learning rate parameter gets ignored also for non-zero values. This is CartPole-v0 for radically different learning rates:\n <denchmark-link:https://user-images.githubusercontent.com/9771046/50647354-a4fc4880-0f78-11e9-8b5d-c2ece330d386.png></denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "marlonjan", "commentT": "2019-01-06T07:24:21Z", "comment_text": "\n \t\tThanks for reporting -- should be fixed in <denchmark-link:https://github.com/ray-project/ray/pull/3697>#3697</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "e78562b2e8d2affc8b0f7fabde37aa192b4385fc", "commit_author": "Eric Liang", "commitT": "2019-01-06 19:37:35-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "doc\\source\\rllib-training.rst", "file_new_name": "doc\\source\\rllib-training.rst", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "182,186,187,190,193,196", "deleted_lines": "182,186,187,190,193,194,197,198"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "python\\ray\\rllib\\agents\\agent.py", "file_new_name": "python\\ray\\rllib\\agents\\agent.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "344,345,346,347,348,349,350,353,354,355,363,364,365", "deleted_lines": "344,364,365,366,367,368,369", "method_info": {"method_name": "compute_action", "method_params": "self,observation,state,policy_id", "method_startline": "344", "method_endline": "369"}}, "hunk_1": {"Ismethod": 1, "added_lines": "399,400,401,402,403,404,405,406", "deleted_lines": null, "method_info": {"method_name": "get_policy", "method_params": "self,policy_id", "method_startline": "399", "method_endline": "406"}}, "hunk_2": {"Ismethod": 1, "added_lines": "344,345,346,347,348,349,350", "deleted_lines": "344", "method_info": {"method_name": "compute_action", "method_params": "self,observation,state,prev_action,prev_reward,info,policy_id", "method_startline": "344", "method_endline": "350"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\ddpg\\apex.py", "file_new_name": "python\\ray\\rllib\\agents\\ddpg\\apex.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "51,52", "deleted_lines": "51", "method_info": {"method_name": "update_target_if_needed", "method_params": "self", "method_startline": "47", "method_endline": "54"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\dqn\\apex.py", "file_new_name": "python\\ray\\rllib\\agents\\dqn\\apex.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "54,55", "deleted_lines": "54", "method_info": {"method_name": "update_target_if_needed", "method_params": "self", "method_startline": "50", "method_endline": "57"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\pg\\pg_policy_graph.py", "file_new_name": "python\\ray\\rllib\\agents\\pg\\pg_policy_graph.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "94,95", "deleted_lines": null, "method_info": {"method_name": "optimizer", "method_params": "self", "method_startline": "94", "method_endline": "95"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\qmix\\apex.py", "file_new_name": "python\\ray\\rllib\\agents\\qmix\\apex.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "53,54", "deleted_lines": "53", "method_info": {"method_name": "update_target_if_needed", "method_params": "self", "method_startline": "49", "method_endline": "56"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\evaluation\\policy_evaluator.py", "file_new_name": "python\\ray\\rllib\\evaluation\\policy_evaluator.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "492,493,494,495,496,497,498,499", "deleted_lines": null, "method_info": {"method_name": "get_policy", "method_params": "self,policy_id", "method_startline": "492", "method_endline": "499"}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\rllib\\evaluation\\policy_graph.py", "file_new_name": "python\\ray\\rllib\\evaluation\\policy_graph.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "74,75,76", "deleted_lines": "74,75,76", "method_info": {"method_name": "compute_single_action", "method_params": "self,obs,state,prev_action,prev_reward,info,episode,kwargs", "method_startline": "71", "method_endline": "78"}}, "hunk_1": {"Ismethod": 1, "added_lines": "74,75,76", "deleted_lines": "74,75,76", "method_info": {"method_name": "compute_single_action", "method_params": "self,obs,state,prev_action_batch,prev_reward_batch,info_batch,episode,kwargs", "method_startline": "71", "method_endline": "78"}}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\rllib\\evaluation\\tf_policy_graph.py", "file_new_name": "python\\ray\\rllib\\evaluation\\tf_policy_graph.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "304,305", "deleted_lines": "304,305", "method_info": {"method_name": "_build_signature_def", "method_params": "self", "method_startline": "269", "method_endline": "307"}}, "hunk_1": {"Ismethod": 1, "added_lines": "344,345,346,347", "deleted_lines": null, "method_info": {"method_name": "_build_apply_gradients", "method_params": "self,builder,gradients", "method_startline": "343", "method_endline": "353"}}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\rllib\\optimizers\\async_samples_optimizer.py", "file_new_name": "python\\ray\\rllib\\optimizers\\async_samples_optimizer.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "295,296,297", "deleted_lines": null}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\optimizers\\multi_gpu_impl.py", "file_new_name": "python\\ray\\rllib\\optimizers\\multi_gpu_impl.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "164,165,166,167", "deleted_lines": "164,165", "method_info": {"method_name": "load_data", "method_params": "self,sess,inputs,state_inputs", "method_startline": "117", "method_endline": "194"}}}}, "file_11": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\rllib\\test\\test_supported_spaces.py", "file_new_name": "python\\ray\\rllib\\test\\test_supported_spaces.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189", "deleted_lines": null, "method_info": {"method_name": "testMultiAgent", "method_params": "self", "method_startline": "171", "method_endline": "207"}}, "hunk_1": {"Ismethod": 1, "added_lines": "95", "deleted_lines": "95", "method_info": {"method_name": "check_support_multiagent", "method_params": "alg,config", "method_startline": "92", "method_endline": "102"}}}}}}}