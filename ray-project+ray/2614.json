{"BR": {"BR_id": "2614", "BR_author": "hfurkanbozkurt", "BRopenT": "2018-08-09T12:46:13Z", "BRcloseT": "2018-08-11T13:01:03Z", "BR_text": {"BRsummary": "[tune/rllib] Tuple space range problem", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.13.5\n Ray installed from (source or binary): Binary\n Ray version: 0.5.0\n Python version: 3.6.6\n Exact command to reproduce: not applicable\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n In my environment, action space is the following:\n <denchmark-code>Tuple([Discrete(20), Discrete(6)])\n </denchmark-code>\n \n When I run a PopulationBasedTraining scheduler to train a PPO agent with that environment, ray does something strange.\n Instead of selecting actions in ranges [0:20) and [0:6), it selects in ranges of [0:13) and [0:13). It would be great if you could help me to solve this problem.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "hfurkanbozkurt", "commentT": "2018-08-09T17:20:17Z", "comment_text": "\n \t\tHey thanks for posting this issue.\n Does the problem still exist when you turn off the PopulationBasedTraining scheduler?\n If the problem is still there, can you post a small example script so that I can reproduce the bug?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "hfurkanbozkurt", "commentT": "2018-08-10T15:05:27Z", "comment_text": "\n \t\tHey, thank you for your answer.\n The problem still exists without the PopulationBasedTraining scheduler.\n Here is a little script to regenerate the problem:\n import gym\n from gym.spaces import Tuple, Discrete, Box\n \n import ray\n from ray.tune import run_experiments\n from ray.tune.registry import register_env\n \n class RayEnv(gym.Env):\n     def __init__(self):\n         self.action_space = Tuple([Discrete(20), Discrete(6)])\n         self.observation_space = Box(0, 1, (1,))\n \n     def step(self, action):\n         print(\"Action: {}, {}\".format(*action))\n         assert action[0] < 20 and action[1] < 6\n         return self.observation_space.sample(), 0, False, {}\n \n     def reset(self):\n         return self.observation_space.sample()\n \n def env_creator(env_config):\n     return RayEnv()\n \n def run():\n     register_env(\"ray-env\", env_creator)\n     ray.init()\n     run_experiments({\n         \"test\": {\n             \"run\": \"PPO\",\n             \"env\": \"ray-env\",\n         }})\n \n if __name__ == \"__main__\":\n     run()\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "hfurkanbozkurt", "commentT": "2018-08-11T00:48:04Z", "comment_text": "\n \t\tThanks for reporting this <denchmark-link:https://github.com/hfurkanbozkurt>@hfurkanbozkurt</denchmark-link>\n  , this should fix the issue: <denchmark-link:https://github.com/ray-project/ray/pull/2637/files>https://github.com/ray-project/ray/pull/2637/files</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "hfurkanbozkurt", "commentT": "2018-08-11T13:01:03Z", "comment_text": "\n \t\tYes, it fixes the issue. Thank you for taking time to solve this problem <denchmark-link:https://github.com/ericl>@ericl</denchmark-link>\n  and <denchmark-link:https://github.com/richardliaw>@richardliaw</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "9559873d135de78734a835d9725f2c0dabe4ace7", "commit_author": "Eric Liang", "commitT": "2018-08-11 10:57:40-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "python\\ray\\rllib\\models\\action_dist.py", "file_new_name": "python\\ray\\rllib\\models\\action_dist.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "185,186", "deleted_lines": "185,186,187,188", "method_info": {"method_name": "__init__", "method_params": "self,inputs,action_space,child_distributions", "method_startline": "185", "method_endline": "192"}}, "hunk_1": {"Ismethod": 1, "added_lines": "194", "deleted_lines": "196", "method_info": {"method_name": "logp", "method_params": "self,x", "method_startline": "192", "method_endline": "203"}}, "hunk_2": {"Ismethod": 1, "added_lines": "183,184,185,186", "deleted_lines": "185,186,187,188", "method_info": {"method_name": "__init__", "method_params": "self,inputs,action_space,child_distributions,input_lens", "method_startline": "183", "method_endline": "190"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\models\\catalog.py", "file_new_name": "python\\ray\\rllib\\models\\catalog.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "91,95,99,100", "deleted_lines": "90,95,99", "method_info": {"method_name": "get_action_dist", "method_params": "action_space,config,dist_type", "method_startline": "61", "method_endline": "103"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\rllib\\models\\multiagentfcnet.py", "file_new_name": "python\\ray\\rllib\\models\\multiagentfcnet.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}}}}