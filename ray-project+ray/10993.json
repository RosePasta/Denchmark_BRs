{"BR": {"BR_id": "10993", "BR_author": "architkulkarni", "BRopenT": "2020-09-24T04:16:53Z", "BRcloseT": "2020-09-29T01:10:44Z", "BR_text": {"BRsummary": "[Serve] create_backend() hangs on adding too many replicas", "BRdescription": "\n <denchmark-h:h3>What is the problem?</denchmark-h>\n \n When adding certain numbers of replicas using create_backend(), it doesn't realize there aren't enough resources available, so create_backend() hangs forever waiting for another CPU to become available.  The repro script below makes it seem like it's an off-by-one error, but I'm not sure that's the case; I ran into this issue frequently on a multi-node cluster (5 nodes, 2 CPUs each) when adding several backends with ~4 replicas each.  Maybe the HTTPproxyactor isn't being counted or something?\n Ray version and other system information (Python version, TensorFlow version, OS):\n Ray 1.0.0rc2, Python 3.8, Mac OS\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):\n import ray\n from ray import serve\n ray.init(address=\"auto\") # 1 node, 16 cores\n client = serve.start() \n \n def f(_):\n     return \"hi\"\n \n # As expected: \"RayServeException: Cannot scale backend hi to 20 replicas. \n # Ray Serve tried to add 20 replicas but the resources only allows 16 to be added.\"\n client.create_backend(\"hi\", f, config=serve.BackendConfig(num_replicas=20))\n \n # hangs forever: \"WARNING worker.py:1073 -- The actor or task with ID \n # ffffffffffffffff591ac74701000000 is pending and cannot currently be \n # scheduled. It requires {CPU: 1.000000} ...\"\n client.create_backend(\"hi\", f, config=serve.BackendConfig(num_replicas=16))\n \n # With num_replicas=15 it would have succeeded.\n If we cannot run your script, we cannot fix your issue.\n \n  I have verified my script runs in a clean environment and reproduces the issue.\n  I have verified the issue also occurs with the latest wheels.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "architkulkarni", "commentT": "2020-09-24T19:06:12Z", "comment_text": "\n \t\t\ud83e\udd26 ok i found the bug. we were checking total resource but we should check available resource\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "architkulkarni", "commentT": "2020-09-24T19:34:54Z", "comment_text": "\n \t\tWe can fix it in Serve once <denchmark-link:https://github.com/ray-project/ray/pull/11014>#11014</denchmark-link>\n  is merged\n \t\t"}}}, "commit": {"commit_id": "6cfc1a16a0a97bb935fa0737a970e83c05a4d040", "commit_author": "Simon Mo", "commitT": "2020-09-28 18:10:43-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\serve\\controller.py", "file_new_name": "python\\ray\\serve\\controller.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "539,540,541,542,543", "deleted_lines": "539,540,541,542,543,544", "method_info": {"method_name": "_scale_replicas", "method_params": "self,str,int", "method_startline": "517", "method_endline": "573"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\serve\\tests\\test_util.py", "file_new_name": "python\\ray\\serve\\tests\\test_util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "72,73,76,77,80", "deleted_lines": "72,73,74,75,78,79,80,81,82,85", "method_info": {"method_name": "test_mock_scheduler", "method_params": "", "method_startline": "71", "method_endline": "109"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\serve\\utils.py", "file_new_name": "python\\ray\\serve\\utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "240", "deleted_lines": "240", "method_info": {"method_name": "try_schedule_resources_on_nodes", "method_params": "List", "method_startline": "238", "method_endline": "240"}}, "hunk_1": {"Ismethod": 1, "added_lines": "240", "deleted_lines": "240", "method_info": {"method_name": "try_schedule_resources_on_nodes", "method_params": "str,None", "method_startline": "238", "method_endline": "240"}}}}}}}