{"BR": {"BR_id": "10810", "BR_author": "jrtcppv", "BRopenT": "2020-09-15T19:55:05Z", "BRcloseT": "2020-10-12T20:49:12Z", "BR_text": {"BRsummary": "[rllib] How to train beyond 2^31 timesteps?", "BRdescription": "\n I am using ray 0.8.5. I would like to continue training beyond 2 billion timesteps but am hitting an error related to the timesteps variable being of type np.int32. Is there a way to force the model to use np.int64 without forking ray? Specifically I am using a RecurrentTFModelV2 with APPO.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jrtcppv", "commentT": "2020-09-17T06:42:56Z", "comment_text": "\n \t\tHmm I think this is a bug we'd have to fix. Probably the tensor is defined as int32 somewhere? cc <denchmark-link:https://github.com/sven1977>@sven1977</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jrtcppv", "commentT": "2020-09-17T18:01:32Z", "comment_text": "\n \t\tYeah, could be one of the timestep tensors used mainly for exploration that overflows. Taking a look. ...\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jrtcppv", "commentT": "2020-10-09T07:53:57Z", "comment_text": "\n \t\tThis PR fixes the problem:\n <denchmark-link:https://github.com/ray-project/ray/pull/11301>#11301</denchmark-link>\n \n There is also a test case now confirming good ts counting behavior by the different policies (ray/rllib/tests/test_timesteps.py).\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jrtcppv", "commentT": "2020-10-09T07:56:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jrtcppv>@jrtcppv</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jrtcppv", "commentT": "2020-10-09T07:56:35Z", "comment_text": "\n \t\tThanks for filing this issue! :)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jrtcppv", "commentT": "2020-10-09T12:20:52Z", "comment_text": "\n \t\tNo problem, thank you for taking care of it and for all the work you do on this excellent library!\n \t\t"}}}, "commit": {"commit_id": "8ea1bc5ff9faa2cdea2074a1f84f3830f2c5a082", "commit_author": "Sven Mika", "commitT": "2020-10-12 13:49:11-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\BUILD", "file_new_name": "rllib\\BUILD", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1434,1435,1436,1437,1438,1439,1440", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\examples\\env\\random_env.py", "file_new_name": "rllib\\examples\\env\\random_env.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "49,55", "deleted_lines": "54", "method_info": {"method_name": "step", "method_params": "self,action", "method_startline": "39", "method_endline": "61"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\policy\\dynamic_tf_policy.py", "file_new_name": "rllib\\policy\\dynamic_tf_policy.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "170", "deleted_lines": "170"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "rllib\\policy\\eager_tf_policy.py", "file_new_name": "rllib\\policy\\eager_tf_policy.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "23,31,33", "deleted_lines": "23,32", "method_info": {"method_name": "_convert_to_tf", "method_params": "x,dtype", "method_startline": "23", "method_endline": "34"}}, "hunk_1": {"Ismethod": 1, "added_lines": "23,31,33", "deleted_lines": "23,32", "method_info": {"method_name": "_convert_to_tf", "method_params": "x", "method_startline": "23", "method_endline": "33"}}, "hunk_2": {"Ismethod": 1, "added_lines": "56,58,59", "deleted_lines": "55,57", "method_info": {"method_name": "convert_eager_inputs", "method_params": "func", "method_startline": "51", "method_endline": "65"}}, "hunk_3": {"Ismethod": 1, "added_lines": "56,58,59", "deleted_lines": "55,57", "method_info": {"method_name": "convert_eager_inputs._func", "method_params": "args,kwargs", "method_startline": "53", "method_endline": "63"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\policy\\tf_policy.py", "file_new_name": "rllib\\policy\\tf_policy.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "180", "deleted_lines": "180"}}}, "file_5": {"file_change_type": "ADD", "file_Nmethod": 0, "file_old_name": "None", "file_new_name": "rllib\\tests\\test_timesteps.py"}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\utils\\exploration\\epsilon_greedy.py", "file_new_name": "rllib\\utils\\exploration\\epsilon_greedy.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "1,58,59,60,61", "deleted_lines": "57"}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\utils\\exploration\\gaussian_noise.py", "file_new_name": "rllib\\utils\\exploration\\gaussian_noise.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2,78,79,80,81", "deleted_lines": "77"}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\utils\\exploration\\stochastic_sampling.py", "file_new_name": "rllib\\utils\\exploration\\stochastic_sampling.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2,57,58,59,60", "deleted_lines": "56"}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\utils\\framework.py", "file_new_name": "rllib\\utils\\framework.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2,189,212,214,216,217,218", "deleted_lines": "210,212"}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "rllib\\utils\\schedules\\piecewise_schedule.py", "file_new_name": "rllib\\utils\\schedules\\piecewise_schedule.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "82", "deleted_lines": null, "method_info": {"method_name": "_tf_value_op._cond", "method_params": "i,x", "method_startline": "81", "method_endline": "86"}}, "hunk_1": {"Ismethod": 1, "added_lines": "68,82,92", "deleted_lines": "68,91", "method_info": {"method_name": "_tf_value_op", "method_params": "self,t", "method_startline": "62", "method_endline": "93"}}}}}}}