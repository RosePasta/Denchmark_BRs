{"BR": {"BR_id": "4397", "BR_author": "nikola-j", "BRopenT": "2019-03-18T12:31:55Z", "BRcloseT": "2019-03-29T20:19:43Z", "BR_text": {"BRsummary": "[rllib] Remote worker envs cause memory leak", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04\n Ray installed from (source or binary): source\n Ray version: newest master\n Python version: 3.6.7\n Exact command to reproduce:\n \n import ray\n import ray.tune as tune\n \n ray.init()\n tune.run_experiments({\n     \"my_experiment\": {\n         \"run\": \"PPO\",\n         \"env\": \"CartPole-v0\",\n         'stop': {\n             'training_iteration': 3,\n         },\n         'num_samples': 10,\n         \"config\": {\n             \"num_gpus\": 1,\n             \"num_workers\": 4,\n             \"num_envs_per_worker\": 8,\n             \"remote_worker_envs\": True,\n             \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n         },\n     },\n })\n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n When running rllib with remote worker envs and multiple tune trials the number of workers grows constantly between each trial until rllib crashes because of OOM.\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n <denchmark-code>2019-03-18 12:27:07,252\tERROR worker.py:1752 -- WARNING: X workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n </denchmark-code>\n \n Where X increases by 48 for each new trial until I run out of memory.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "nikola-j", "commentT": "2019-03-21T04:06:11Z", "comment_text": "\n \t\tIt looks like this is since the remote env actors aren't cleaned up. They probably could be killed with an atexit  hook or something? agent._stop() could also send remote calls to all the policy evaluators to clean up remote envs.\n \t\t"}}}, "commit": {"commit_id": "77005d1814b7264a0511dbe3d4fb7e73958daa90", "commit_author": "bjg2", "commitT": "2019-03-29 13:19:42-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\jenkins_tests\\run_rllib_tests.sh", "file_new_name": "ci\\jenkins_tests\\run_rllib_tests.sh", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "63,70", "deleted_lines": "63,70"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "ci\\long_running_tests\\workloads\\impala.py", "file_new_name": "ci\\long_running_tests\\workloads\\impala.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "46", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "doc\\source\\rllib-env.rst", "file_new_name": "doc\\source\\rllib-env.rst", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "122,123,124", "deleted_lines": "122"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\rllib\\agents\\agent.py", "file_new_name": "python\\ray\\rllib\\agents\\agent.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "384,385,386,387,388,389,390,395", "deleted_lines": null, "method_info": {"method_name": "_stop", "method_params": "self", "method_startline": "383", "method_endline": "397"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "python\\ray\\rllib\\env\\base_env.py", "file_new_name": "python\\ray\\rllib\\env\\base_env.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "187,188,189", "deleted_lines": null, "method_info": {"method_name": "stop", "method_params": "self", "method_startline": "187", "method_endline": "189"}}, "hunk_1": {"Ismethod": 1, "added_lines": "83", "deleted_lines": "81", "method_info": {"method_name": "to_base_env", "method_params": "env,make_env,num_envs,remote_envs,remote_env_batch_wait_ms", "method_startline": "79", "method_endline": "83"}}, "hunk_2": {"Ismethod": 1, "added_lines": null, "deleted_lines": "81", "method_info": {"method_name": "to_base_env", "method_params": "env,make_env,num_envs,remote_envs,async_remote_envs", "method_startline": "77", "method_endline": "81"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 7, "file_old_name": "python\\ray\\rllib\\env\\remote_vector_env.py", "file_new_name": "python\\ray\\rllib\\env\\remote_vector_env.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "34,35,36,37,38,39", "deleted_lines": "34,35", "method_info": {"method_name": "poll.make_remote_env", "method_params": "i", "method_startline": "34", "method_endline": "39"}}, "hunk_1": {"Ismethod": 1, "added_lines": "32,33,34,35,36,37,38,39,40,41,42,55", "deleted_lines": "31,32,33,34,35,51", "method_info": {"method_name": "poll", "method_params": "self", "method_startline": "31", "method_endline": "70"}}, "hunk_2": {"Ismethod": 1, "added_lines": "79,80,81,82", "deleted_lines": null, "method_info": {"method_name": "try_reset", "method_params": "self,env_id", "method_startline": "78", "method_endline": "82"}}, "hunk_3": {"Ismethod": 1, "added_lines": "21,22", "deleted_lines": "21", "method_info": {"method_name": "__init__", "method_params": "self,make_env,num_envs,multiagent,remote_env_batch_wait_ms", "method_startline": "21", "method_endline": "22"}}, "hunk_4": {"Ismethod": 1, "added_lines": "21,22,24,25,26,27,28,32,33,34,35,36", "deleted_lines": "21,23,24,25,26,27,28,29,30,31,32,33,34,35", "method_info": {"method_name": "__init__", "method_params": "self,make_env,num_envs,multiagent,sync", "method_startline": "21", "method_endline": "36"}}, "hunk_5": {"Ismethod": 1, "added_lines": "84,85,86,87", "deleted_lines": null, "method_info": {"method_name": "stop", "method_params": "self", "method_startline": "84", "method_endline": "87"}}, "hunk_6": {"Ismethod": 1, "added_lines": "28,32,33", "deleted_lines": "28,29,30,31,32,33", "method_info": {"method_name": "__init__.make_remote_env", "method_params": "i", "method_startline": "28", "method_endline": "33"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\rllib\\evaluation\\policy_evaluator.py", "file_new_name": "python\\ray\\rllib\\evaluation\\policy_evaluator.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "128", "deleted_lines": "128", "method_info": {"method_name": "__init__", "method_params": "self,env_creator,policy_graph,policy_mapping_fn,policies_to_train,tf_session_creator,batch_steps,batch_mode,episode_horizon,preprocessor_pref,sample_async,compress_observations,num_envs,observation_filter,clip_rewards,clip_actions,env_config,model_config,policy_config,worker_index,monitor_path,log_dir,log_level,callbacks,input_creator", "method_startline": "100", "method_endline": "128"}}, "hunk_1": {"Ismethod": 1, "added_lines": "675,676", "deleted_lines": null, "method_info": {"method_name": "stop", "method_params": "self", "method_startline": "675", "method_endline": "676"}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "python\\ray\\rllib\\evaluation\\sampler.py", "file_new_name": "python\\ray\\rllib\\evaluation\\sampler.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17,493,494,495", "deleted_lines": "17,493,494"}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "python\\ray\\rllib\\tests\\test_multi_agent_env.py", "file_new_name": "python\\ray\\rllib\\tests\\test_multi_agent_env.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "374", "deleted_lines": "365", "method_info": {"method_name": "testMultiAgentSampleAsyncRemote", "method_params": "self", "method_startline": "362", "method_endline": "376"}}, "hunk_1": {"Ismethod": 1, "added_lines": "285,286,287,288,289,290,291,292,293,294", "deleted_lines": "285,286", "method_info": {"method_name": "testVectorizeBasic", "method_params": "self", "method_startline": "231", "method_endline": "313"}}, "hunk_2": {"Ismethod": 1, "added_lines": "611,612,613,617,618", "deleted_lines": "602,603,604,608,609,610", "method_info": {"method_name": "_testWithOptimizer", "method_params": "self,optimizer_cls", "method_startline": "571", "method_endline": "625"}}, "hunk_3": {"Ismethod": 1, "added_lines": "357,358", "deleted_lines": "349", "method_info": {"method_name": "testMultiAgentSampleSyncRemote", "method_params": "self", "method_startline": "345", "method_endline": "360"}}}}}}}