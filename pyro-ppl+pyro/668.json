{"BR": {"BR_id": "668", "BR_author": "1Reinier", "BRopenT": "2018-01-08T16:28:21Z", "BRcloseT": "2018-01-12T23:58:25Z", "BR_text": {"BRsummary": "`enum_discrete` Tensor location bug", "BRdescription": "\n Hi,\n When using enum_discrete = True to reduce variance in my SVI, Pyro complains that some internal tensors are not in the same location (GPU/CPU), whereas turning it off makes it work fine:\n ---------------------------------------------------------------------------\n RuntimeError                              Traceback (most recent call last)\n <ipython-input-31-93fd337a0d5c> in <module>()\n ----> 1 train()\n \n <ipython-input-30-98110a9a9720> in train()\n      33 \n      34             # Train and score\n ---> 35             train_loss += svi.step(input_batch, target_batch)\n      36 \n      37         # Store history\n \n /home/reinier/anaconda2/lib/python2.7/site-packages/pyro/infer/svi.pyc in step(self, *args, **kwargs)\n      96         \"\"\"\n      97         # get loss and compute gradients\n ---> 98         loss = self.loss_and_grads(self.model, self.guide, *args, **kwargs)\n      99 \n     100         # get active params\n \n /home/reinier/anaconda2/lib/python2.7/site-packages/pyro/infer/elbo.pyc in loss_and_grads(self, model, guide, *args, **kwargs)\n      63         :rtype: float\n      64         \"\"\"\n ---> 65         return self.which_elbo.loss_and_grads(model, guide, *args, **kwargs)\n \n /home/reinier/anaconda2/lib/python2.7/site-packages/pyro/infer/trace_elbo.pyc in loss_and_grads(self, model, guide, *args, **kwargs)\n     149                         guide_site = guide_trace.nodes[name]\n     150                         lp_lq = model_site[log_pdf] - guide_site[log_pdf]\n --> 151                         elbo_particle += lp_lq\n     152                         if guide_site[\"fn\"].reparameterized:\n     153                             surrogate_elbo_particle += lp_lq\n \n RuntimeError: Expected object of type Variable[torch.FloatTensor] but found type Variable[torch.cuda.FloatTensor] for argument #1 'other'\n I suspect this is a bug. Any tips?\n -Reinier\n PS The bug arises here:\n         for inputs, targets in train_loader:\n \n             # Put batch on GPU\n             input_batch = Variable(inputs.cuda(device=CUDA_ID, async=use_async))  # Pinned memory with async transfer\n             target_batch = Variable(targets.cuda(device=CUDA_ID, async=use_async))\n \n             # Train and score\n             train_loss += svi.step(input_batch, target_batch)\n \n         # Store history\n         train_losses += [train_loss / n_train_samples]\n Where CUDA_ID is some device id and async is currently False.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "1Reinier", "commentT": "2018-01-08T16:36:17Z", "comment_text": "\n \t\tThanks for pinpointing this. I think we have a ton of these placement bugs. I'll take a look.\n \t\t"}}}, "commit": {"commit_id": "5eedf2997d1fc0e7cd1d09ef75c0ac20dee89d67", "commit_author": "Fritz Obermeyer", "commitT": "2018-01-12 15:58:24-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pyro\\distributions\\util.py", "file_new_name": "pyro\\distributions\\util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "154", "deleted_lines": "154", "method_info": {"method_name": "torch_multinomial", "method_params": "input,num_samples,replacement", "method_startline": "148", "method_endline": "156"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pyro\\infer\\enum.py", "file_new_name": "pyro\\infer\\enum.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "48,49,50,51", "deleted_lines": "47,48,49,50,51", "method_info": {"method_name": "iter_discrete_traces", "method_params": "graph_type,fn,args,kwargs", "method_startline": "18", "method_endline": "52"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pyro\\infer\\trace_elbo.py", "file_new_name": "pyro\\infer\\trace_elbo.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "104,105,106,107", "deleted_lines": "103", "method_info": {"method_name": "loss", "method_params": "self,model,guide,args,kwargs", "method_startline": "93", "method_endline": "128"}}, "hunk_1": {"Ismethod": 1, "added_lines": "144,145,146,147", "deleted_lines": "140", "method_info": {"method_name": "loss_and_grads", "method_params": "self,model,guide,args,kwargs", "method_startline": "130", "method_endline": "191"}}}}}}}