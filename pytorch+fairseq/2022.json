{"BR": {"BR_id": "2022", "BR_author": "villmow", "BRopenT": "2020-04-17T21:26:00Z", "BRcloseT": "2020-05-10T13:13:17Z", "BR_text": {"BRsummary": "Recent SequenceGenerator update makes it unusable with sub-classes that have a different `net_input`", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n This is not a real bug, I rather want to discuss a recent change in master.\n Situation: My (transformer) encoder sub-class needs additional input during the forward path. Currently I'm feeding this to my encoder by adding it to the net_input dictionary. During validation/generation I need the additional input as well. This worked out of the box for generation, because the generator only used to forward the net_input to the encoder:\n \n \n \n fairseq/fairseq/sequence_generator.py\n \n \n          Line 133\n       in\n       630701e\n \n \n \n \n \n \n  encoder_outs = model.forward_encoder(encoder_input) \n \n \n \n \n \n With a recent change of the SequenceGenerator this is not possible anymore. The generator now only feeds src_tokens and src_lengths to the encoder (probably for torchscript):\n \n \n \n fairseq/fairseq/sequence_generator.py\n \n \n         Lines 197 to 200\n       in\n       57526c6\n \n \n \n \n \n \n  encoder_outs = self.model.forward_encoder( \n \n \n \n  src_tokens=encoder_input[\"src_tokens\"], \n \n \n \n  src_lengths=encoder_input[\"src_lengths\"], \n \n \n \n  ) \n \n \n \n \n \n This change requires me to sub-class the generator and add the input there as well.\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n I should be able to add additional input to my encoder, without having to sub-class the generator.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n fairseq Version (e.g., 1.0 or master): master\n \n \t"}, "comments": {}}, "commit": {"commit_id": "11345a7608a6b73feb53046f6c0eef3dc4d3fc08", "commit_author": "Marco Gaido", "commitT": "2020-05-10 06:13:06-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "fairseq\\models\\fairseq_encoder.py", "file_new_name": "fairseq\\models\\fairseq_encoder.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "56,57,58,59,60,61,62", "deleted_lines": null, "method_info": {"method_name": "forward_non_torchscript", "method_params": "self,str", "method_startline": "56", "method_endline": "62"}}, "hunk_1": {"Ismethod": 1, "added_lines": "41,42,43,44,45,46,47,48,49,50,51,52,53", "deleted_lines": null, "method_info": {"method_name": "forward_torchscript", "method_params": "self,str", "method_startline": "41", "method_endline": "53"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "fairseq\\sequence_generator.py", "file_new_name": "fairseq\\sequence_generator.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "703,707", "deleted_lines": null, "method_info": {"method_name": "forward_encoder", "method_params": "self,str", "method_startline": "703", "method_endline": "709"}}, "hunk_1": {"Ismethod": 1, "added_lines": null, "deleted_lines": "710,714", "method_info": {"method_name": "forward_encoder", "method_params": "self,src_tokens,src_lengths", "method_startline": "710", "method_endline": "716"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\test_sequence_generator.py", "file_new_name": "tests\\test_sequence_generator.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "305,306,307,308,309,310,311,312,313,314,315,316", "deleted_lines": null, "method_info": {"method_name": "test_generation_with_additional_input", "method_params": "self", "method_startline": "305", "method_endline": "316"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 6, "file_old_name": "tests\\utils.py", "file_new_name": "tests\\utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "314,315,316,317,318,319,320,321,322", "deleted_lines": null, "method_info": {"method_name": "reorder_encoder_out", "method_params": "self,encoder_out,new_order", "method_startline": "314", "method_endline": "322"}}, "hunk_1": {"Ismethod": 1, "added_lines": "335,336,337,338,339,340", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,src_tokens,src_lengths,prev_output_tokens,kwargs", "method_startline": "335", "method_endline": "340"}}, "hunk_2": {"Ismethod": 1, "added_lines": "298,299,300", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,args,dictionary", "method_startline": "298", "method_endline": "300"}}, "hunk_3": {"Ismethod": 1, "added_lines": "330,331,332,333", "deleted_lines": null, "method_info": {"method_name": "build_model", "method_params": "cls,args,task", "method_startline": "330", "method_endline": "333"}}, "hunk_4": {"Ismethod": 1, "added_lines": "326,327", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,encoder,decoder", "method_startline": "326", "method_endline": "327"}}, "hunk_5": {"Ismethod": 1, "added_lines": "302,303,304,305,306,307,308,309,310,311,312", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,src_tokens,src_lengths,kwargs", "method_startline": "302", "method_endline": "312"}}}}}}}