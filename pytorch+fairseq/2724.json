{"BR": {"BR_id": "2724", "BR_author": "psorianom", "BRopenT": "2020-10-12T17:42:49Z", "BRcloseT": "2020-10-22T13:27:38Z", "BR_text": {"BRsummary": "Cache loading fails when there is no internet connection", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n When getting resources from cache (with  in <denchmark-link:https://github.com/pytorch/fairseq/blob/60442af216d551e4afc9d4fab1c056c1051725cc/fairseq/file_utils.py#L243>file_utils.py</denchmark-link>\n ), and not having an internet connection, the launched process fails (after several retrials in <denchmark-link:https://github.com/pytorch/fairseq/blob/60442af216d551e4afc9d4fab1c056c1051725cc/fairseq/file_utils.py#L216>request_wrap_timeout</denchmark-link>\n ) with a  that is not handled in the caller function (<denchmark-link:https://github.com/pytorch/fairseq/blob/60442af216d551e4afc9d4fab1c056c1051725cc/fairseq/file_utils.py#L267>get_from_cache</denchmark-link>\n ). Instead, an  exception is handled and thus the exception ends the process, .\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n from fairseq.file_utils import get_from_cache\n url = \"https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\"\n \n path = get_from_cache(url)\n print(f\"This is the path I got: {path}\")\n File \"/home/user/fairseq/fairseq/file_utils.py\", line 225, in request_wrap_timeout\n     raise RuntimeError(f\"Unable to fetch file {url}\")\n RuntimeError: Unable to fetch file https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n The process should not end if the file is already cached. When catching the exception, the value of etag should be set to None and finally the cached file path should be found.\n This is the path I got: /home/user/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.\n 0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n \n \n fairseq Version : master\n \n \n PyTorch Version : 1.6.0\n \n \n OS (e.g., Linux): Linux\n \n \n How you installed fairseq (pip, source): git clone + pip install -e .\n \n \n Python version: 3.7.9\n \n \n CPU\n \n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n A proper solution would entail not needing an internet connection to check if we have the file cached in disk. I guess this has been already pondered and the current solution must be the best.\n A simple way to address the returned exception, , would be to handle it  of the handled , as it stands. This is proposed in a <denchmark-link:https://github.com/pytorch/fairseq/compare/master...psorianom:request_wrap_exception>branch of mine</denchmark-link>\n .\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "psorianom", "commentT": "2020-10-17T16:33:46Z", "comment_text": "\n \t\tYour fix looks good to me! Can you please submit a PR?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "psorianom", "commentT": "2020-10-21T10:28:22Z", "comment_text": "\n \t\tyes ! I will do that!\n \t\t"}}}, "commit": {"commit_id": "751bcbfcb939b777e61af251d1fce5d4a4dc1f12", "commit_author": "Pavel Soriano", "commitT": "2020-10-22 06:31:07-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "fairseq\\file_utils.py", "file_new_name": "fairseq\\file_utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "289", "deleted_lines": "289", "method_info": {"method_name": "get_from_cache", "method_params": "url,cache_dir", "method_startline": "262", "method_endline": "335"}}}}}}}