{"BR": {"BR_id": "17239", "BR_author": "apeforest", "BRopenT": "2020-01-07T19:18:59Z", "BRcloseT": "2020-01-22T17:07:11Z", "BR_text": {"BRsummary": "Cmake with NCCL flag does not work.", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n If I build mxnet with NCCL using cmake, it failed with \"Could not find NCCL libraries\" even though my NCCL is installed at /usr/local/cuda/include\n <denchmark-h:h2>Reproduce</denchmark-h>\n \n <denchmark-code>cmake -GNinja -DUSE_CUDA=ON -DCMAKE_CUDA_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_BUILD_TYPE=Release -DUSE_CUDNN=ON -DUSE_NCCL=ON ..\n \n CMake Warning at CMakeLists.txt:299 (message):\n   Could not find NCCL libraries\n </denchmark-code>\n \n <denchmark-h:h2>Environment</denchmark-h>\n \n We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:\n <denchmark-code>curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python\n \n ----------Python Info----------\n Version      : 3.6.6\n Compiler     : GCC 7.2.0\n Build        : ('default', 'Jun 28 2018 17:14:51')\n Arch         : ('64bit', '')\n ------------Pip Info-----------\n Version      : 19.3.1\n Directory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip\n ----------MXNet Info-----------\n No MXNet installed.\n ----------System Info----------\n Platform     : Linux-4.4.0-1096-aws-x86_64-with-debian-stretch-sid\n system       : Linux\n node         : ip-172-31-20-50\n release      : 4.4.0-1096-aws\n version      : #107-Ubuntu SMP Thu Oct 3 01:51:58 UTC 2019\n ----------Hardware Info----------\n machine      : x86_64\n processor    : x86_64\n Architecture:          x86_64\n CPU op-mode(s):        32-bit, 64-bit\n Byte Order:            Little Endian\n CPU(s):                64\n On-line CPU(s) list:   0-63\n Thread(s) per core:    2\n Core(s) per socket:    16\n Socket(s):             2\n NUMA node(s):          2\n Vendor ID:             GenuineIntel\n CPU family:            6\n Model:                 79\n Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n Stepping:              1\n CPU MHz:               2699.984\n CPU max MHz:           3000.0000\n CPU min MHz:           1200.0000\n BogoMIPS:              4600.11\n Hypervisor vendor:     Xen\n Virtualization type:   full\n L1d cache:             32K\n L1i cache:             32K\n L2 cache:              256K\n L3 cache:              46080K\n NUMA node0 CPU(s):     0-15,32-47\n NUMA node1 CPU(s):     16-31,48-63\n Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq monitor est ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt ida\n ----------Network Test----------\n Setting timeout: 10\n Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0060 sec, LOAD: 0.5026 sec.\n Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0011 sec, LOAD: 0.5116 sec.\n Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1051 sec, LOAD: 0.3917 sec.\n Timing for D2L: http://d2l.ai, DNS: 0.0108 sec, LOAD: 0.2085 sec.\n Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.1761 sec, LOAD: 0.1178 sec.\n Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.1306 sec, LOAD: 0.1471 sec.\n Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0123 sec, LOAD: 0.4014 sec.\n Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0120 sec, LOAD: 0.0739 sec.\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "apeforest", "commentT": "2020-01-07T19:23:49Z", "comment_text": "\n \t\tWe may refactor <denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindNCCL.cmake>https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindNCCL.cmake</denchmark-link>\n  to improve autodetection. In the meantime see the variables used for searching. If you set one of them to your nccl base directory, it should find nccl successfully?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "apeforest", "commentT": "2020-01-08T12:59:39Z", "comment_text": "\n \t\tI experienced this too ... try using -DUSE_NCCL=1 -DUSE_NCCL_PATH=/usr/local/cuda/include (or as <denchmark-link:https://github.com/leezu>@leezu</denchmark-link>\n  your NCCL path)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "apeforest", "commentT": "2020-01-12T07:40:11Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mjsML>@mjsML</denchmark-link>\n  Thanks, using that flag worked for me. <denchmark-link:https://github.com/guanxinq>@guanxinq</denchmark-link>\n  or <denchmark-link:https://github.com/ChaiBapchya>@ChaiBapchya</denchmark-link>\n  interested in fixing FindNCCL.cmake as suggested? :)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "apeforest", "commentT": "2020-01-13T03:38:25Z", "comment_text": "\n \t\tI took a look at this auto-detection issue.\n To solve this particular case, I added a check for symlink (if UNIX) - <denchmark-link:https://github.com/ChaiBapchya/incubator-mxnet/blob/nccl_autodetect/cmake/Modules/FindNCCL.cmake>https://github.com/ChaiBapchya/incubator-mxnet/blob/nccl_autodetect/cmake/Modules/FindNCCL.cmake</denchmark-link>\n \n If this is enough, I can submit a PR.\n However, I'm not sure if it is complete. Coz I took a look at <denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindCUDAToolkit.cmake>https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindCUDAToolkit.cmake</denchmark-link>\n \n It has a fairly long drawn way of finding the Cuda Toolkit\n \n Language / user provided path\n If cuda_root cmake/env not specified, check\n \n \n check symlink\n check platform default\n \n Is this what's needed? <denchmark-link:https://github.com/leezu>@leezu</denchmark-link>\n  <denchmark-link:https://github.com/apeforest>@apeforest</denchmark-link>\n \n In that case it makes sense to \"factor\" out this check as it will be used at 2 places (findCudatoolkit and findNCCL)\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "apeforest", "commentT": "2020-01-13T11:37:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/apeforest>@apeforest</denchmark-link>\n  could you provide some background if NCCL is installed at  by default?\n <denchmark-link:https://github.com/ChaiBapchya>@ChaiBapchya</denchmark-link>\n  your change seems to rely on , but this variable is not among the variables exported by . In fact, you can see it's explicitly unset:\n <denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindCUDAToolkit.cmake#L708>https://github.com/apache/incubator-mxnet/blob/master/cmake/Modules/FindCUDAToolkit.cmake#L708</denchmark-link>\n \n Instead, let's use the result variables\n \n \n \n incubator-mxnet/cmake/Modules/FindCUDAToolkit.cmake\n \n \n         Lines 427 to 464\n       in\n       28e053e\n \n \n \n \n \n \n  Result variables \n \n \n \n  ^^^^^^^^^^^^^^^^ \n \n \n \n  \n \n \n \n  ``CUDAToolkit_FOUND`` \n \n \n \n      A boolean specifying whether or not the CUDA Toolkit was found. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_VERSION`` \n \n \n \n      The exact version of the CUDA Toolkit found (as reported by \n \n \n \n      ``nvcc --version``). \n \n \n \n  \n \n \n \n  ``CUDAToolkit_VERSION_MAJOR`` \n \n \n \n      The major version of the CUDA Toolkit. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_VERSION_MAJOR`` \n \n \n \n      The minor version of the CUDA Toolkit. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_VERSION_PATCH`` \n \n \n \n      The patch version of the CUDA Toolkit. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_BIN_DIR`` \n \n \n \n      The path to the CUDA Toolkit library directory that contains the CUDA \n \n \n \n      executable ``nvcc``. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_INCLUDE_DIRS`` \n \n \n \n      The path to the CUDA Toolkit ``include`` folder containing the header files \n \n \n \n      required to compile a project linking against CUDA. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_LIBRARY_DIR`` \n \n \n \n      The path to the CUDA Toolkit library directory that contains the CUDA \n \n \n \n      Runtime library ``cudart``. \n \n \n \n  \n \n \n \n  ``CUDAToolkit_NVCC_EXECUTABLE`` \n \n \n \n      The path to the NVIDIA CUDA compiler ``nvcc``.  Note that this path may \n \n \n \n      **not** be the same as \n \n \n \n      :variable:`CMAKE_CUDA_COMPILER <CMAKE_<LANG>_COMPILER>`.  ``nvcc`` must be \n \n \n \n      found to determine the CUDA Toolkit version as well as determining other \n \n \n \n      features of the Toolkit.  This variable is set for the convenience of \n \n \n \n      modules that depend on this one. \n \n \n \n \n \n Specifically CUDAToolkit_INCLUDE_DIRS and CUDAToolkit_LIBRARY_DIR? Or would the nccl library not be at the CUDAToolkit_LIBRARY_DIR?\n Besides using the  variables as additional defaults to find nccl, the  variable needs to be examined as per <denchmark-link:https://cmake.org/cmake/help/latest/policy/CMP0074.html>https://cmake.org/cmake/help/latest/policy/CMP0074.html</denchmark-link>\n \n (which is done correctly currently I think)\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "apeforest", "commentT": "2020-01-13T19:43:44Z", "comment_text": "\n \t\tIn DLAMI, nccl is installed by default in the cuda directory: /usr/local/cuda/include/nccl.h\n However, if user installed nccl manually by themselves, sudo apt install libnccl2 libnccl-dev, you may use the  to find where it is.\n <denchmark-link:https://askubuntu.com/questions/1134732/where-is-nccl-h>https://askubuntu.com/questions/1134732/where-is-nccl-h</denchmark-link>\n \n I would suggest <denchmark-link:https://github.com/ChaiBapchya>@ChaiBapchya</denchmark-link>\n  to first search . If not found, try  instead. Would that work?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "apeforest", "commentT": "2020-01-13T19:44:59Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/ChaiBapchya>@ChaiBapchya</denchmark-link>\n  for volunteering to work on this!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "apeforest", "commentT": "2020-01-13T20:44:01Z", "comment_text": "\n \t\t\n If not found, try sudo dpkg-query -L libnccl-dev instead.\n \n That's would only work on Debian based platforms and only for one particular way of installing nccl on these systems. I think it's safe to require users to set NCCL_ROOT if they manually installed nccl to a different path.\n To improve the user experience, we may fall-back to building nccl ourselves if nccl is required and not found. Pytorch does that for example.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "apeforest", "commentT": "2020-01-13T21:18:08Z", "comment_text": "\n \t\tYa. Even when I looked at different autodetection files for cmake used in various other open-source frameworks\n \n Xgboost - https://github.com/dmlc/xgboost/blob/master/cmake/modules/FindNccl.cmake\n Flashlight - https://github.com/facebookresearch/flashlight/blob/master/cmake/FindNCCL.cmake\n Pytorch - https://github.com/pytorch/pytorch/blob/master/cmake/Modules/FindNCCL.cmake\n Caffe - https://github.com/BVLC/caffe/blob/master/cmake/Modules/FindNCCL.cmake\n Thunder - https://github.com/thuem/THUNDER/blob/master/cmake/FindNCCL.cmake\n \n They have similar approach. Either look for default path, env var (NCCL_ROOT) or /usr/local/cuda\n Agree with <denchmark-link:https://github.com/leezu>@leezu</denchmark-link>\n  I haven't seen \"dpkg-query\" or equivalent \"find\" commands used in cmake. They are more of command line searches. In cmake, there's find_path, find_library which does similar job.\n Thanks <denchmark-link:https://github.com/apeforest>@apeforest</denchmark-link>\n  <denchmark-link:https://github.com/leezu>@leezu</denchmark-link>\n  for chiming in!\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "apeforest", "commentT": "2020-01-14T14:55:12Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ChaiBapchya>@ChaiBapchya</denchmark-link>\n  BTW, unfortunately a lot of CMake usage out in the wild does not meet the modern CMake bar but is leftover from the early days of CMake. While not covering all use-cases of MXNet, sometimes we can refer to <denchmark-link:https://cliutils.gitlab.io/modern-cmake/>https://cliutils.gitlab.io/modern-cmake/</denchmark-link>\n  for best practices\n \t\t"}}}, "commit": {"commit_id": "3de5cae76075cc0e154abae6f04435d4592660d1", "commit_author": "Chaitanya Prakash Bapat", "commitT": "2020-01-22 09:07:10-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "cmake\\Modules\\FindNCCL.cmake", "file_new_name": "cmake\\Modules\\FindNCCL.cmake", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "34,35,36,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76", "deleted_lines": "34"}}}}}}