{"BR": {"BR_id": "2116", "BR_author": "helloworldlxb", "BRopenT": "2016-05-12T03:57:15Z", "BRcloseT": "2018-09-25T05:42:34Z", "BR_text": {"BRsummary": "Shape of labels does not match shape of predictions", "BRdescription": "\n I'm using the official LSTM model with my own iterator(<denchmark-link:https://github.com/apache/incubator-mxnet/issues/2105>#2105</denchmark-link>\n ).\n However, it reports \"Shape of labels does not match shape of predictions\" even though I reshaped the variable label in the model.\n The codes for the model:\n <denchmark-code>def lstm_unroll(batch_size, num_lstm_layer, seq_len, \n                 num_hidden, num_label, dropout=0.):\n \n     # embed_weight = mx.sym.Variable(\"embed_weight\")\n     cls_weight = mx.sym.Variable(\"cls_weight\")\n     cls_bias = mx.sym.Variable(\"cls_bias\")\n     param_cells = []\n     last_states = []\n     for i in range(num_lstm_layer):\n         param_cells.append(LSTMParam(i2h_weight=mx.sym.Variable(\"l%d_i2h_weight\" % i),\n                                      i2h_bias=mx.sym.Variable(\"l%d_i2h_bias\" % i),\n                                      h2h_weight=mx.sym.Variable(\"l%d_h2h_weight\" % i),\n                                      h2h_bias=mx.sym.Variable(\"l%d_h2h_bias\" % i)))\n         state = LSTMState(c=mx.sym.Variable(\"l%d_init_c\" % i),\n                           h=mx.sym.Variable(\"l%d_init_h\" % i))\n         last_states.append(state)\n     assert(len(last_states) == num_lstm_layer)\n \n     # convolution layers\n     data = mx.sym.Variable('data')\n     label = mx.sym.Variable('softmax_label')\n     conv1_weight = mx.sym.Variable('conv1_weight')\n     conv1_bias = mx.sym.Variable('conv1_bias')\n     conv2_weight = mx.sym.Variable('conv2_weight')\n     conv2_bias = mx.sym.Variable('conv2_bias')\n     # pool2 = [[]] * seq_len\n     # for i in range(seq_len):\n     # print data.infer_shape()\n     pool = []\n     data = mx.sym.SliceChannel(data=data, num_outputs=batch_size, axis=0, squeeze_axis=True)\n     for i in range(batch_size):\n         conv1 = mx.sym.Convolution(data=data[i], kernel=(3,3), num_filter=100, weight=conv1_weight, bias=conv1_bias)\n         # print conv1.infer_shape()\n         conv1 = mx.sym.Activation(data=conv1, act_type='relu')\n         pool1 = mx.sym.Pooling(data=conv1, kernel=(3,3), stride=(2,2), pool_type='max')\n         conv2 = mx.sym.Convolution(data=pool1, kernel=(3,3), num_filter=100, weight=conv2_weight, bias=conv2_bias)\n         conv2 = mx.sym.Activation(data=conv2, act_type='relu')\n         pool2 = mx.sym.Pooling(data=conv2, kernel=(3,3), stride=(2,2), pool_type='max')\n         # shape = pool2.infer_shape(**{'data':(batch_size, seq_len, 1, 120, 160)})[-2][0]\n         pool2 = mx.sym.Reshape(data=pool2, target_shape=(1, 500, 100, 28, 38))\n         pool.append(pool2)\n     # embed = mx.sym.Embedding(data=data, input_dim=input_size,\n     #                          weight=embed_weight, output_dim=num_embed, name='embed')\n     # wordvec = mx.sym.SliceChannel(data=embed, num_outputs=seq_len, squeeze_axis=1)\n     pool = mx.sym.Concat(*pool, dim=0)\n     # pool = mx.sym.SliceChannel(data=pool, num_outputs=batch_size, axis=0)\n     data_seq = mx.sym.SliceChannel(data=pool, num_outputs=seq_len, axis=1, squeeze_axis=True)\n     hidden_all = []\n     for seqidx in range(seq_len):\n         hidden = data_seq[seqidx]\n         # stack LSTM\n         for i in range(num_lstm_layer):\n             if i == 0:\n                 dp_ratio = 0.\n             else:\n                 dp_ratio = dropout\n             next_state = lstm(num_hidden, indata=hidden,\n                               prev_state=last_states[i],\n                               param=param_cells[i],\n                               seqidx=seqidx, layeridx=i, dropout=dp_ratio)\n             hidden = next_state.h\n             last_states[i] = next_state\n         # decoder\n         if dropout > 0.:\n             hidden = mx.sym.Dropout(data=hidden, p=dropout)\n         hidden_all.append(hidden)\n \n     hidden_concat = mx.sym.Concat(*hidden_all, dim=0)\n \n     pred = mx.sym.FullyConnected(data=hidden_concat, num_hidden=num_label,\n                                  weight=cls_weight, bias=cls_bias, name='pred')\n \n     ################################################################################\n     # Make label the same shape as our produced data path\n     # I did not observe big speed difference between the following two ways\n \n     label = mx.sym.transpose(data=label)\n     label = mx.sym.Reshape(data=label, target_shape=(batch_size * seq_len,))\n \n     #label_slice = mx.sym.SliceChannel(data=label, num_outputs=seq_len)\n     #label = [label_slice[t] for t in range(seq_len)]\n     #label = mx.sym.Concat(*label, dim=0)\n     #label = mx.sym.Reshape(data=label, target_shape=(0,))\n     ################################################################################\n     # return label\n     sm = mx.sym.SoftmaxOutput(data=pred, label=label, name='softmax')\n \n     return sm\n </denchmark-code>\n \n Thank you in advance!\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "helloworldlxb", "commentT": "2016-05-12T07:26:00Z", "comment_text": "\n \t\tDo you get this error in metric?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "helloworldlxb", "commentT": "2016-05-12T07:31:22Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Godricly>@Godricly</denchmark-link>\n  Yes. The full traceback:\n <denchmark-code>Traceback (most recent call last):\n   File \"video_lstm_2.py\", line 277, in <module>\n     model = mx.model.FeedForward.create(m, X=iter, eval_data=val_iter, num_epoch\n  = 200, learning_rate=0.01, epoch_end_callback=a_epoch, batch_end_callback=mx.ca\n llback.Speedometer(batch_size))\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n model.py\", line 900, in create\n     eval_batch_end_callback=eval_batch_end_callback)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n model.py\", line 783, in fit\n     sym_gen=self.sym_gen)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n model.py\", line 245, in _train_multi_device\n     executor_manager.update_metric(eval_metric, data_batch.label)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n executor_manager.py\", line 406, in update_metric\n     self.curr_execgrp.update_metric(metric, labels)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n executor_manager.py\", line 262, in update_metric\n     metric.update(labels_slice, texec.outputs)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n metric.py\", line 141, in update\n     check_label_shapes(label, pred_label)\n   File \"F:\\PublicToolbox\\Anaconda\\lib\\site-packages\\mxnet-0.5.0-py2.7.egg\\mxnet\\\n metric.py\", line 20, in check_label_shapes\n     \"predictions {}\".format(label_shape, pred_shape))\n ValueError: Shape of labels 1 does not match shape of predictions 500\n </denchmark-code>\n \n And I tried to print the labels, it should have been an NDArray shaped like (500,), however it actually shaped like (1,500,)\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "helloworldlxb", "commentT": "2016-05-12T08:07:14Z", "comment_text": "\n \t\tA stupid way I used is to write another metric to bypass this check and handle your data label urself. I think mxnet is giving you the shape of your raw label(before reshape). I can't remember the exact reason as my coworker get into this problem before, It probably because the metric is using data_batch.label in its update in the model.py. <denchmark-link:https://github.com/piiswrong>@piiswrong</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "helloworldlxb", "commentT": "2016-07-18T09:50:12Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/helloworldlxb>@helloworldlxb</denchmark-link>\n  Hi! Have you fixed your problem? I am having exactly the same issue here. Any wisdom please? Many thanks!\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "helloworldlxb", "commentT": "2016-10-23T17:36:43Z", "comment_text": "\n \t\tFor everyone's information, hereby I would like to share my solution to this problem. Although the structure of my customized networks is different, I also encountered the same error, i.e. \"Shape of labels does not match shape of predictions\".\n I agree with <denchmark-link:https://github.com/Godricly>@Godricly</denchmark-link>\n   that this is kind of a bug of the metric. Even we have reshaped the label to 1D vector, the metric will use the shape provided by the data batch, i.e. (1, 500,) in your case. Hence, to address this issue, the straight way is to modify your customized DataIter code to make sure the labels provided are a 1D vector.\n However, if you have labels for each time step, the solution above doesn't work. Here is another ugly trick for both cases. Just modify the codes in the metric.py (of course, you need root/sudo permission) to squeeze the labels. The squeeze function will remove the single dimension. If I remember correctly, there is one line like \"label = labels[i].asnumpy().astype(\"int32\")\". Below it, you could add a new line \"label = label.squeeze()\". I know this sounds crazy, but it works anyway.\n Hope my reply would help you guys.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "helloworldlxb", "commentT": "2017-09-28T06:59:34Z", "comment_text": "\n \t\tThis issue is closed due to lack of activity in the last 90 days. Feel free to reopen if this is still an active issue. Thanks!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "helloworldlxb", "commentT": "2018-01-28T09:17:29Z", "comment_text": "\n \t\tSo mxnet just ignore this bug and leave it alone???\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "helloworldlxb", "commentT": "2018-01-28T16:52:34Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Matafight>@Matafight</denchmark-link>\n  are you still running into this issue on certain metric?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "helloworldlxb", "commentT": "2018-01-29T04:46:30Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  yes, at first, I thought there may be sth wrong with my own iterator, just now I tried with mx.io.NDArrayIter, the same error occured\u3002\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "helloworldlxb", "commentT": "2018-01-29T04:52:31Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  the error  is:\n \n And the simplified codes that can reproduce the above issue is as follows:\n #_*_coding:utf-8_*_\n import mxnet as mx\n import mxnet.ndarray as nd\n \n #setup parameters\n def get_parameters():\n     batch_size = 128\n     embed_dim = 200\n     num_steps = 90\n     num_hidden = 100\n     return batch_size,embed_dim,num_steps,num_hidden\n \n def try_gpu():\n     try:\n         ctx=mx.gpu()\n         _ = nd.array([0],ctx=ctx)\n     except:\n         ctx=mx.cpu()\n     return ctx\n \n #setup context\n context = try_gpu()\n \n #load data\n def test_mx_io_dataiter(batch_size,num_steps):\n     corpus_vec = nd.ones(shape = (1024,num_steps),ctx=context)\n     dataiter = mx.io.NDArrayIter(data = corpus_vec,label=corpus_vec,batch_size=batch_size,data_name='data',label_name='softmax_label')\n     return dataiter\n \n def poem_rnn(batch_size,vocab_size,embed_dim,num_hidden,num_steps):\n     seq_input = mx.symbol.Variable('data')\n     label = mx.sym.Variable('softmax_label')\n     embedded_seq = mx.symbol.Embedding(data=seq_input, \n                                        input_dim=vocab_size, \n                                        output_dim=embed_dim)\n     lstm_cell = mx.rnn.LSTMCell(num_hidden=num_hidden)\n     #NTC : batch_size *num_steps*input_embed_dim\n     outputs, _ = lstm_cell.unroll(length=num_steps, \n                                        inputs=embedded_seq, \n                                        layout='NTC', \n                                        merge_outputs=True)\n \n     pred = mx.sym.Reshape(outputs,shape=(-1,num_hidden))\n     pred = mx.sym.FullyConnected(data = pred,num_hidden=vocab_size,name='pred')\n     label = mx.sym.Reshape(label,shape=(-1,))\n     pred = mx.sym.SoftmaxOutput(data = pred,label=label,name='softmax')\n     return pred\n \n \n batch_size,embed_dim,num_steps,num_hidden = get_parameters()\n vocab_size  = 1500\n \n data_iter = test_mx_io_dataiter(batch_size,num_steps)\n output = poem_rnn(batch_size,vocab_size,embed_dim,num_hidden,num_steps)\n mod = mx.mod.Module(output,data_names=[\"data\"],label_names=[\"softmax_label\"])\n model_prefix = 'poem_rnn'\n save_period = 1\n checkpoint = mx.callback.do_checkpoint(model_prefix,period = save_period)\n mod.fit(data_iter,num_epoch=5,epoch_end_callback=checkpoint)\n I'am not sure  if it is actually the same bug or there is some other bugs in my codes\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "helloworldlxb", "commentT": "2018-01-29T06:42:33Z", "comment_text": "\n \t\tmod.fit(data_iter,num_epoch=5,epoch_end_callback=checkpoint)\n The default evel_metric above is 'acc'.\n However, when I choose to use other metrics,the error disappear\n mod.fit(data_iter, eval_metric='ce',  num_epoch=5, epoch_end_callback=checkpoint)\n or\n mod.fit(data_iter, eval_metric=mx.metric.Perplexity(ignore_label=-1),  num_epoch=5, epoch_end_callback=checkpoint)\n I think we can avoid this issue by specifying a specific evel_metric.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "helloworldlxb", "commentT": "2018-04-06T21:55:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/helloworldlxb>@helloworldlxb</denchmark-link>\n  <denchmark-link:https://github.com/Matafight>@Matafight</denchmark-link>\n  this issue should be fix by PR <denchmark-link:https://github.com/apache/incubator-mxnet/pull/10446>#10446</denchmark-link>\n \n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "helloworldlxb", "commentT": "2018-09-25T04:21:28Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/sandeep-krishnamurthy>@sandeep-krishnamurthy</denchmark-link>\n  Please close this issue as it has been fixed with the PR.\n <denchmark-link:https://github.com/helloworldlxb>@helloworldlxb</denchmark-link>\n  <denchmark-link:https://github.com/Matafight>@Matafight</denchmark-link>\n  Please feel free to reopen this issue if you encounter it again.\n \t\t"}}}, "commit": {"commit_id": "e42f7e08bb5d8277bd87f81babf42cb5121ec160", "commit_author": "Lai Wei", "commitT": "2018-04-10 17:27:36-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\mxnet\\metric.py", "file_new_name": "python\\mxnet\\metric.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "420,421,422,426,427", "deleted_lines": "423,424", "method_info": {"method_name": "update", "method_params": "self,labels,preds", "method_startline": "401", "method_endline": "427"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\python\\unittest\\test_metric.py", "file_new_name": "tests\\python\\unittest\\test_metric.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "57,58,59,60,61,62,63,64,65,66", "deleted_lines": null, "method_info": {"method_name": "test_acc_2d_label", "method_params": "", "method_startline": "57", "method_endline": "66"}}}}}}}