{"BR": {"BR_id": "15268", "BR_author": "Ishitori", "BRopenT": "2019-06-18T18:31:26Z", "BRcloseT": "2019-06-21T01:41:01Z", "BR_text": {"BRsummary": "Backward doesn't work on LSTM with sequence_length", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n LSTM with out-of-the-box variable length was introduced in <denchmark-link:https://github.com/apache/incubator-mxnet/pull/14208/>this PR</denchmark-link>\n . I tried to use it, and while the forward pass works well, the backward pass fails.\n I provide minimum reproducible example. To my best knowledge, the backward pass is not covered with a unit test.\n <denchmark-h:h2>Environment info (Required)</denchmark-h>\n \n The latest version with --pre\n Package used (Python/R/Scala/Julia):\n Python\n <denchmark-h:h2>Error Message:</denchmark-h>\n \n <denchmark-code>MXNetError: [17:18:04] src/operator/./rnn-inl.h:1006: Check failed: in_data.size() == num_inputs (4 vs. 5) : \n Stack trace:\n   [bt] (0) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x4a157b) [0x7fdedb45957b]\n   [bt] (1) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x507b9ad) [0x7fdee00339ad]\n   [bt] (2) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x50b5cac) [0x7fdee006dcac]\n   [bt] (3) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(mxnet::imperative::PushOperator(mxnet::OpStatePtr const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode)::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)#3}::operator()(mxnet::RunContext, mxnet::engine::CallbackOnComplete) const+0x396) [0x7fdedd6b3d36]\n   [bt] (4) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushOperator(mxnet::OpStatePtr const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, mxnet::DispatchMode)::{lambda(mxnet::RunContext)#4}>::_M_invoke(std::_Any_data const&, mxnet::RunContext)+0x5d) [0x7fdedd6b43cd]\n   [bt] (5) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x264c4f9) [0x7fdedd6044f9]\n   [bt] (6) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2658961) [0x7fdedd610961]\n   [bt] (7) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x265be70) [0x7fdedd613e70]\n   [bt] (8) /home/ubuntu/anaconda3/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x265c106) [0x7fdedd614106]\n \n </denchmark-code>\n \n <denchmark-h:h2>Minimum reproducible example</denchmark-h>\n \n You have to use GPU to run it, as this feature is GPU only.\n The devil is in the fact that the backward fails silently and mx.nd.waitall() is necessary at the end\n import mxnet as mx\n import numpy as np\n from mxnet.gluon import nn\n from mxnet.gluon.rnn import LSTM\n \n ctx = mx.gpu(0)\n \n label = mx.nd.array([1, 2, 3, 4, 5, 6, 7], ctx=ctx)\n # random numbers, but with ones at the end as a padding symbol\n x = mx.nd.array([[5434, 3232, 776, 323, 1, 1, 1], [4353, 545, 37, 23, 23, 545, 1]], ctx=ctx)\n \n embedding = nn.Embedding(input_dim=6000,\n                           output_dim=100,\n                           weight_initializer=mx.initializer.Uniform(0.001))\n \n lstm = LSTM(hidden_size=100,\n             num_layers=1, dropout=0.2, bidirectional=True,\n             use_sequence_length=True)\n \n dense = nn.Dense(1)\n l1 = mx.gluon.loss.L1Loss()\n \n embedding.initialize(ctx=ctx)\n lstm.initialize(ctx=ctx)\n dense.initialize(ctx=ctx)\n \n \n with mx.autograd.record():\n     x_mask = x != 1\n     x_len = mx.nd.sum(x_mask, axis=1).astype(np.int32)    \n     state = lstm.begin_state(batch_size=x.shape[0], ctx=x.context)\n     x_emb = embedding(x)\n     x_emb = x_emb.transpose((1, 0, 2))\n     a, _ = lstm(x_emb, states=state, sequence_length=x_len)\n     out = dense(a)\n     loss = l1(out, label)\n     # this prints the loss, showing that forward pass works fine\n     print(loss)\n \n # this one will fail\n loss.backward()\n mx.nd.waitall()\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Ishitori", "commentT": "2019-06-18T18:31:32Z", "comment_text": "\n \t\tHey, this is the MXNet Label Bot.\n Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it.\n Here are my recommended labels: Bug\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Ishitori", "commentT": "2019-06-18T18:34:12Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/stephenrawls>@stephenrawls</denchmark-link>\n , any help with that?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Ishitori", "commentT": "2019-06-18T20:39:58Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/mxnet-label-bot>@mxnet-label-bot</denchmark-link>\n  add [Bug, Gluon]\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Ishitori", "commentT": "2019-06-18T22:12:50Z", "comment_text": "\n \t\tI could reproduce this issue. Here is a full callstack.\n ubuntu@ip-172-31-31-181:~$ python lstm_test.py\n [1.0000387 2.0000887 3.000114  4.000115  5.000068  6.0000405 7.       ]\n <NDArray 7 <denchmark-link:https://github.com/gpu>@gpu</denchmark-link>\n (0)>\n Traceback (most recent call last):\n File \"lstm_test.py\", line 42, in \n mx.nd.waitall()\n File \"/home/ubuntu/incubator-mxnet/python/mxnet/ndarray/ndarray.py\", line 166, in waitall\n check_call(_LIB.MXNDArrayWaitAll())\n File \"/home/ubuntu/incubator-mxnet/python/mxnet/base.py\", line 253, in check_call\n raise MXNetError(py_str(_LIB.MXGetLastError()))\n mxnet.base.MXNetError: [22:04:02] src/operator/./rnn-inl.h:1006: Check failed: in_data.size() == num_inputs (4 vs. 5) :\n Stack trace:\n [bt] (0) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7ffa222a1082]\n [bt] (1) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::op::RNNOp<mshadow::gpu, float, float>::Backward(mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&, std::vector<mxnet::OpReqType, std::allocatormxnet::OpReqType > const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&)+0x1dc) [0x7ffa26c335bc]\n [bt] (2) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::op::RNNStatefulGradComputemshadow::gpu(mxnet::OpStatePtr const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&, std::vector<mxnet::OpReqType, std::allocatormxnet::OpReqType > const&, std::vector<mxnet::TBlob, std::allocatormxnet::TBlob > const&)+0x21b6) [0x7ffa26c68186]\n [bt] (3) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::imperative::PushOperator(mxnet::OpStatePtr const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocatormxnet::engine::Var* > const&, std::vector<mxnet::engine::Var*, std::allocatormxnet::engine::Var* > const&, std::vector<mxnet::Resource, std::allocatormxnet::Resource > const&, std::vector<mxnet::NDArray*, std::allocatormxnet::NDArray* > const&, std::vector<mxnet::NDArray*, std::allocatormxnet::NDArray* > const&, std::vector<unsigned int, std::allocator > const&, std::vector<mxnet::OpReqType, std::allocatormxnet::OpReqType > const&, mxnet::DispatchMode)::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)<denchmark-link:https://github.com/apache/incubator-mxnet/pull/3>#3</denchmark-link>\n }::operator()(mxnet::RunContext, mxnet::engine::CallbackOnComplete) const+0x1333) [0x7ffa24680473]\n [bt] (4) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushOperator(mxnet::OpStatePtr const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocatormxnet::engine::Var* > const&, std::vector<mxnet::engine::Var*, std::allocatormxnet::engine::Var* > const&, std::vector<mxnet::Resource, std::allocatormxnet::Resource > const&, std::vector<mxnet::NDArray*, std::allocatormxnet::NDArray* > const&, std::vector<mxnet::NDArray*, std::allocatormxnet::NDArray* > const&, std::vector<unsigned int, std::allocator > const&, std::vector<mxnet::OpReqType, std::allocatormxnet::OpReqType > const&, mxnet::DispatchMode)::{lambda(mxnet::RunContext)<denchmark-link:https://github.com/apache/incubator-mxnet/pull/4>#4</denchmark-link>\n }>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&)+0x1d) [0x7ffa2468173d]\n [bt] (5) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler<void (mxnet::RunContext, mxnet::engine::CallbackOnComplete), mxnet::engine::ThreadedEngine::BulkFlush()::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)<denchmark-link:https://github.com/apache/incubator-mxnet/pull/1>#1</denchmark-link>\n }>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&, mxnet::engine::CallbackOnComplete&&)+0x1ec) [0x7ffa24e3f3dc]\n [bt] (6) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x945) [0x7ffa24e42c35]\n [bt] (7) /home/ubuntu/incubator-mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>, bool)::{lambda()<denchmark-link:https://github.com/apache/incubator-mxnet/pull/4>#4</denchmark-link>\n }::operator()() const::{lambda(std::shared_ptrdmlc::ManualEvent)<denchmark-link:https://github.com/apache/incubator-mxnet/pull/1>#1</denchmark-link>\n }>::_M_invoke(std::_Any_data const&, std::shared_ptrdmlc::ManualEvent&&)+0x4e) [0x7ffa24e5a8fe]\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Ishitori", "commentT": "2019-06-18T22:49:43Z", "comment_text": "\n \t\tLooking at this now.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Ishitori", "commentT": "2019-06-19T05:49:29Z", "comment_text": "\n \t\tI think I have a solution, at least I have tested locally and it appears to work.\n Just need to update unit tests and then I will file a PR.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Ishitori", "commentT": "2019-06-19T06:00:06Z", "comment_text": "\n \t\tThanks <denchmark-link:https://github.com/Ishitori>@Ishitori</denchmark-link>\n   for the catch!\n Hi <denchmark-link:https://github.com/stephenrawls>@stephenrawls</denchmark-link>\n , could you tag <denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  and me in your PR? We would like to include your fix in MXNet 1.5.0 release. This feature is already included in <denchmark-link:https://github.com/apache/incubator-mxnet/releases/tag/1.5.0.rc1>1.5.0.rc1</denchmark-link>\n \n Thanks!\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Ishitori", "commentT": "2019-06-20T20:06:52Z", "comment_text": "\n \t\tI verified that the issue is fixed in the latest code.\n <denchmark-link:https://github.com/lanking520>@lanking520</denchmark-link>\n   I would recommend closing this issue.\n \t\t"}}}, "commit": {"commit_id": "4d9667121ae6fb643f2a02ab15e25231ed756cde", "commit_author": "stephenrawls", "commitT": "2019-06-19 20:55:33-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "src\\operator\\rnn-inl.h", "file_new_name": "src\\operator\\rnn-inl.h", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1586,1587,1588,1589,1590", "deleted_lines": "1586,1587", "method_info": {"method_name": "mxnet::op::CreateRNNState", "method_params": "attrs,ctx,in_shapes,in_types", "method_startline": "1577", "method_endline": "1603"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1655,1675,1676,1677,1678,1679,1680,1681,1682,1683", "deleted_lines": "1652", "method_info": {"method_name": "mxnet::op::RNNStatefulGradCompute", "method_params": "state,ctx,inputs,req,outputs", "method_startline": "1640", "method_endline": "1687"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\python\\gpu\\test_gluon_gpu.py", "file_new_name": "tests\\python\\gpu\\test_gluon_gpu.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "231,232,233,234,235", "method_info": {"method_name": "check_layer_bidirectional_varseqlen.__init__", "method_params": "self,size,kwargs", "method_startline": "231", "method_endline": "235"}}, "hunk_1": {"Ismethod": 1, "added_lines": "238,245,250,252,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289", "deleted_lines": "230,231,232,233,234,235,236,237,238,239,240,241,242,251,258,259,265,266,267,268,269,275", "method_info": {"method_name": "check_layer_bidirectional_varseqlen", "method_params": "size,in_size", "method_startline": "229", "method_endline": "289"}}, "hunk_2": {"Ismethod": 1, "added_lines": "238", "deleted_lines": "237,238,239,240,241,242", "method_info": {"method_name": "check_layer_bidirectional_varseqlen.forward", "method_params": "self,inpt,sequence_length", "method_startline": "237", "method_endline": "242"}}}}}}}