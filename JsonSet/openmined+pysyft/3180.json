{"BR": {"BR_id": "3180", "BR_author": "avinath1998", "BRopenT": "2020-03-11T15:34:39Z", "BRcloseT": "2020-03-16T12:32:12Z", "BR_text": {"BRsummary": "Runtime Error asking all parameters to have requires_grad=True", "BRdescription": "\n Describe the bug\n I'm trying to finetune a alexnet model and i've set the parameters except for the final layer of the model to requires_grad=False and have created a new classification layer with the desired outputs i want. However the .send() function keeps throwing a runtime error `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n <denchmark-code>import syft\n import torch\n from torchvision import models\n import torch.nn as nn\n \n hook = syft.TorchHook(torch)\n worker = syft.VirtualWorker(hook, id=\"worker\")\n \n model = models.alexnet(pretrained=True)\n for param in model.parameters():\n     param.requires_grad=False\n model.classifier[6] = nn.Linear(model.classifier[6].in_features, 3)\n model.send(worker)\n ---------------------------------------------------------------------------\n RuntimeError                              Traceback (most recent call last)\n <ipython-input-15-a250859d9a13> in <module>\n ----> 1 model.send(worker)\n \n ~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in module_send_(nn_self, force_send, *dest, **kwargs)\n     608 \n     609             if module_is_missing_grad(nn_self):\n --> 610                 create_grad_objects(nn_self)\n     611 \n     612             for p in nn_self.parameters():\n \n ~/implementation/PyGrid/gateway/src/syft/syft/frameworks/torch/hook/hook.py in create_grad_objects(model)\n     600             for p in model.parameters():\n     601                 o = p.sum()\n --> 602                 o.backward()\n     603                 if p.grad is not None:\n     604                     p.grad -= p.grad\n \n ~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/trace.py in trace_wrapper(*args, **kwargs)\n      81                 syft.hook.trace.logs.append((command, response))\n      82             else:\n ---> 83                 response = func(*args, **kwargs)\n      84 \n      85             return response\n \n ~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)\n     436                 except BaseException as e:\n     437                     # we can make some errors more descriptive with this method\n --> 438                     raise route_method_exception(e, self, args, kwargs)\n     439 \n     440             else:  # means that there is a wrapper to remove\n \n ~/implementation/PyGrid/gateway/src/syft/syft/generic/frameworks/hook/hook.py in overloaded_native_method(self, *args, **kwargs)\n     432 \n     433                 try:\n --> 434                     response = method(*args, **kwargs)\n     435 \n     436                 except BaseException as e:\n \n ~/anaconda3/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)\n     193                 products. Defaults to ``False``.\n     194         \"\"\"\n --> 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)\n     196 \n     197     def register_hook(self, hook):\n \n ~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\n      97     Variable._execution_engine.run_backward(\n      98         tensors, grad_tensors, retain_graph, create_graph,\n ---> 99         allow_unreachable=True)  # allow_unreachable flag\n     100 \n     101 \n \n RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n  \n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "avinath1998", "commentT": "2020-03-11T21:22:59Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/avinath1998>@avinath1998</denchmark-link>\n  If you are trying to change the whole  block, then your input dimension (which you put 2) is wrong. The input dimension of  should be 256x6x6.\n refer: <denchmark-link:https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py>https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py</denchmark-link>\n \n <denchmark-code>self.classifier = nn.Sequential(\n             nn.Dropout(),\n             nn.Linear(256 * 6 * 6, 4096),\n             nn.ReLU(inplace=True),\n             nn.Dropout(),\n             nn.Linear(4096, 4096),\n             nn.ReLU(inplace=True),\n             nn.Linear(4096, num_classes),\n         )\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "avinath1998", "commentT": "2020-03-11T21:40:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/imraniac>@imraniac</denchmark-link>\n  Oh shoot, i only added this as an example and didnt see that. Regardless, the error still comes up, ive updated the issue accordingly\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "avinath1998", "commentT": "2020-03-11T22:08:25Z", "comment_text": "\n \t\tHave you still updated the issue with an example? Because it should be 256 * 6 * 6 and not 224\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "avinath1998", "commentT": "2020-03-12T10:33:22Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/imraniac>@imraniac</denchmark-link>\n  updated accordingly, still doesn't work, the error occurs\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "avinath1998", "commentT": "2020-03-12T18:51:54Z", "comment_text": "\n \t\tI will check this.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "avinath1998", "commentT": "2020-03-12T19:18:26Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/tudorcebere>@tudorcebere</denchmark-link>\n , assigned you\n \t\t"}}}, "commit": {"commit_id": "eabe8f60243e7fc3b88cc89d5ce0531cdb462a3d", "commit_author": "Karl Higley", "commitT": "2020-03-16 14:32:10+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "syft\\frameworks\\torch\\hook\\hook.py", "file_new_name": "syft\\frameworks\\torch\\hook\\hook.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "592,593,594,595,596", "deleted_lines": "592,593,594,595", "method_info": {"method_name": "_hook_module.create_grad_objects", "method_params": "model", "method_startline": "589", "method_endline": "596"}}, "hunk_1": {"Ismethod": 1, "added_lines": "592,593,594,595,596", "deleted_lines": "592,593,594,595", "method_info": {"method_name": "_hook_module", "method_params": "self", "method_startline": "575", "method_endline": "730"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "test\\torch\\hook\\test_hook.py", "file_new_name": "test\\torch\\hook\\test_hook.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "63,64,65,66,67,68,69,70,71,72,73,74,75,76", "deleted_lines": null, "method_info": {"method_name": "test_send_frozen", "method_params": "", "method_startline": "63", "method_endline": "76"}}, "hunk_1": {"Ismethod": 1, "added_lines": "79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98", "deleted_lines": null, "method_info": {"method_name": "test_send_partially_frozen", "method_params": "", "method_startline": "79", "method_endline": "98"}}}}}}}