{"BR": {"BR_id": "8411", "BR_author": "jsuarez5341", "BRopenT": "2020-05-12T06:27:19Z", "BRcloseT": "2020-05-20T20:29:08Z", "BR_text": {"BRsummary": "[rllib] Apparently broken compute_actio function for multiagent environments", "BRdescription": "\n Problem: Internal error thrown when calling compute_action in a multiagent policy\n Details: Python 3.7 with the latest Ray on Ubuntu using a PyTorch policy\n Solution: Remove the cast to list (e.g. [action] -> action) on line 161 of ray-project/ray/blob/master/rllib/policy/policy.py\n I assume the cast is required for single agent policies, so possibly just return action and cast to a list if the result is not iterable.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jsuarez5341", "commentT": "2020-05-12T08:12:17Z", "comment_text": "\n \t\tHey <denchmark-link:https://github.com/jsuarez5341>@jsuarez5341</denchmark-link>\n  not sure I understand the issue.\n Which method call actually fails?\n \n trainer.compute_action\n policy.compute_single_action\n policy.compute_actions\n Could you post a small repro script?\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jsuarez5341", "commentT": "2020-05-12T08:24:56Z", "comment_text": "\n \t\tWe can't remove the [] around the action return, because it would break returning a single action (when passing in a batch-of-1 to the policy.compute_actions call).\n I think the reason is somewhere else. Maybe the new nested action space support broke something.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jsuarez5341", "commentT": "2020-05-12T23:00:02Z", "comment_text": "\n \t\tHmm is it that we can't desugar an array into a list? So we should be calling return_value[0] instead?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jsuarez5341", "commentT": "2020-05-20T09:58:05Z", "comment_text": "\n \t\tGot it. Policy.compute_single_action() Has to be:\n <denchmark-code>        batched_action, state_out, info = self.compute_actions(\n             [obs],\n             state_batch,\n             prev_action_batch=prev_action_batch,\n             prev_reward_batch=prev_reward_batch,\n             info_batch=info_batch,\n             episodes=episodes,\n             explore=explore,\n             timestep=timestep)\n \n         single_action = unbatch_actions(batched_action)\n         assert len(single_action) == 1\n         single_action = single_action[0]\n \n         if clip_actions:\n             single_action = clip_action(\n                 single_action, self.action_space_struct)\n \n         # Return action, internal state(s), infos.\n         return single_action, [s[0] for s in state_out], \\\n             {k: v[0] for k, v in info.items()}\n </denchmark-code>\n \n In case of a complex nested action, the action comes back as batched (nested struct of different batches) and hence has to be converted into a single nested action.\n Will PR now. ...\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jsuarez5341", "commentT": "2020-05-20T10:31:14Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jsuarez5341>@jsuarez5341</denchmark-link>\n  Could you check this PR and let me know, whether this fixes the issue?\n <denchmark-link:https://github.com/ray-project/ray/pull/8514>#8514</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "d76578700dc57016fa01bd35dfea36afa9dda3c8", "commit_author": "Sven Mika", "commitT": "2020-05-20 22:29:08+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\agents\\ars\\ars_tf_policy.py", "file_new_name": "rllib\\agents\\ars\\ars_tf_policy.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "62", "deleted_lines": "62", "method_info": {"method_name": "compute_actions", "method_params": "self,observation,add_noise,update", "method_startline": "57", "method_endline": "65"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\agents\\es\\es_tf_policy.py", "file_new_name": "rllib\\agents\\es\\es_tf_policy.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "113", "deleted_lines": "114", "method_info": {"method_name": "compute_actions", "method_params": "self,observation,add_noise,update", "method_startline": "102", "method_endline": "114"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "rllib\\agents\\es\\es_torch_policy.py", "file_new_name": "rllib\\agents\\es\\es_torch_policy.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "64", "deleted_lines": "64", "method_info": {"method_name": "before_init._compute_actions", "method_params": "policy,obs_batch,add_noise,update", "method_startline": "53", "method_endline": "67"}}, "hunk_1": {"Ismethod": 1, "added_lines": "64", "deleted_lines": "64", "method_info": {"method_name": "before_init", "method_params": "policy,observation_space,action_space,config", "method_startline": "19", "method_endline": "69"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\evaluation\\sampler.py", "file_new_name": "rllib\\evaluation\\sampler.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763", "method_info": {"method_name": "unbatch_actions", "method_params": "action_batches", "method_startline": "729", "method_endline": "763"}}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "rllib\\policy\\policy.py", "file_new_name": "rllib\\policy\\policy.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10,11,162,172,173,174,175,177,178,181", "deleted_lines": "10,161,172,175"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "rllib\\utils\\space_utils.py", "file_new_name": "rllib\\utils\\space_utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130", "deleted_lines": null, "method_info": {"method_name": "unbatch", "method_params": "batches_struct", "method_startline": "97", "method_endline": "130"}}}}}}}