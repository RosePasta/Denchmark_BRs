{"BR": {"BR_id": "1409", "BR_author": "richardliaw", "BRopenT": "2018-01-10T02:13:06Z", "BRcloseT": "2018-02-08T08:57:28Z", "BR_text": {"BRsummary": "[rllib] Occasional Thread Error from RLlib", "BRdescription": "\n <denchmark-h:h3>System information</denchmark-h>\n \n \n Linux Ubuntu 16.04\n Ray installed via Binary\n Python 3.6.3\n on branch https://github.com/richardliaw/ray/tree/shard_autoscale\n git checkout 6b993974265 && cd [rllib_dir] && python train.py -f shard/pong-shard.yaml\n \n <denchmark-h:h3>Describe the problem</denchmark-h>\n \n I get this error occasionally when running a custom agent.\n <denchmark-h:h3>Source code / logs</denchmark-h>\n \n <denchmark-code>Traceback (most recent call last):\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 1625, in fetch_and_execute_function_to_run\n     function = pickle.loads(serialized_function)\n   File \"/home/ubuntu/ray/python/ray/tune/__init__.py\", line 6, in <module>\n     from ray.tune.tune import run_experiments\n   File \"/home/ubuntu/ray/python/ray/tune/tune.py\", line 88, in <module>\n     from ray.rllib.shard.shardedagent import ShardedAgent\n   File \"/home/ubuntu/ray/python/ray/rllib/__init__.py\", line 18, in <module>\n     _register_all()\n   File \"/home/ubuntu/ray/python/ray/rllib/__init__.py\", line 13, in _register_all\n     register_trainable(key, get_agent_class(key))\n   File \"/home/ubuntu/ray/python/ray/rllib/agent.py\", line 368, in get_agent_class\n     from ray.rllib import es\n   File \"/home/ubuntu/ray/python/ray/rllib/es/__init__.py\", line 1, in <module>\n     from ray.rllib.es.es import (ESAgent, DEFAULT_CONFIG)\n   File \"/home/ubuntu/ray/python/ray/rllib/es/es.py\", line 43, in <module>\n     @ray.remote\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2579, in remote\n     max_calls, checkpoint_interval)(args[0])\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2482, in remote_decorator\n     function_properties)\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2541, in remote_function_decorator\n     func_invoker, function_properties)\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2380, in export_remote_function\n     check_main_thread()\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 959, in check_main_thread\n     .format(threading.current_thread().getName()))\n Exception: The Ray methods are not thread safe and must be called from the main thread. This method was called from thread Thread-4.\n \n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "richardliaw", "commentT": "2018-01-13T03:46:40Z", "comment_text": "\n \t\tI've also seen this before at high scales, it seems a module import may happen off the main thread. The workaround was just to remove that check. Cc <denchmark-link:https://github.com/pcmoritz>@pcmoritz</denchmark-link>\n  if you know if this is safe in the general case\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "richardliaw", "commentT": "2018-01-22T00:12:59Z", "comment_text": "\n \t\tI've been looking into this more, and I think there may be a couple of ways that this issue can arise.\n \n \n If there are two jobs sharing the same cluster, an export from one job gets imported by the driver for the second job and causes this exception in the driver for the second job. The solution here is to have separate export queues for different jobs.\n \n \n If a worker defines a custom serializer (or some other export), which somehow closes over a module that defines a remote function, such that when the custom serializer is unpickled by the driver, the driver imports the module and attempts to export the remote function. This is probably the issue that's happening above. I'll come up with some simpler ways of reproducing this problem and propose a fix.\n \n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "richardliaw", "commentT": "2018-01-22T00:34:06Z", "comment_text": "\n \t\tAnother approach would be to just get rid of the import thread entirely (see <denchmark-link:https://github.com/ray-project/ray/issues/951>#951</denchmark-link>\n ). I may give this a try.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "richardliaw", "commentT": "2018-02-07T00:55:01Z", "comment_text": "\n \t\tFlow lab is seeing this in their multiagent runs:\n <denchmark-code>Traceback (most recent call last):\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 1624, in fetch_and_execute_function_to_run\n     function = pickle.loads(serialized_function)\n   File \"/home/ubuntu/ray/python/ray/rllib/__init__.py\", line 20, in <module>\n     _register_all()\n   File \"/home/ubuntu/ray/python/ray/rllib/__init__.py\", line 15, in _register_all\n     register_trainable(key, get_agent_class(key))\n   File \"/home/ubuntu/ray/python/ray/rllib/agent.py\", line 219, in get_agent_class\n     from ray.rllib import es\n   File \"/home/ubuntu/ray/python/ray/rllib/es/__init__.py\", line 1, in <module>\n     from ray.rllib.es.es import (ESAgent, DEFAULT_CONFIG)\n   File \"/home/ubuntu/ray/python/ray/rllib/es/es.py\", line 45, in <module>\n     @ray.remote\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2576, in remote\n     max_calls, checkpoint_interval)(args[0])\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2479, in remote_decorator\n     function_properties)\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2538, in remote_function_decorator\n     func_invoker, function_properties)\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 2377, in export_remote_function\n     check_main_thread()\n   File \"/home/ubuntu/ray/python/ray/worker.py\", line 955, in check_main_thread\n     .format(threading.current_thread().getName()))\n Exception: The Ray methods are not thread safe and must be called from the main thread. This method was called from thread Thread-4.\n </denchmark-code>\n \n Should we just merge the workaround? This actually seems a pretty common issue.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "richardliaw", "commentT": "2018-02-08T09:19:35Z", "comment_text": "\n \t\tOh, was this fixed by <denchmark-link:https://github.com/ray-project/ray/pull/1441>#1441</denchmark-link>\n ? That's good, though there are likely some remaining ways this error could occur.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "richardliaw", "commentT": "2018-06-13T00:32:28Z", "comment_text": "\n \t\tEncounter the error with actor today,  the call is invoked from a thread instead of the main thread. Do we want to remove this check?\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "richardliaw", "commentT": "2018-06-13T04:08:02Z", "comment_text": "\n \t\tWe do want to remove the check, but it will need to be accompanied by making the Ray API thread safe, e.g., something like <denchmark-link:https://github.com/ray-project/ray/pull/2034>#2034</denchmark-link>\n , however that implementation is buggy and I haven't had a chance to fix it up yet.\n \t\t"}}}, "commit": {"commit_id": "4ec51a4660a28399461c56ed9f1f5b0bae5f2191", "commit_author": "Eric Liang", "commitT": "2018-02-06 20:30:11-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\worker.py", "file_new_name": "python\\ray\\worker.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1638,1639,1640,1641,1642,1643,1644", "deleted_lines": null, "method_info": {"method_name": "fetch_and_execute_function_to_run", "method_params": "key,worker", "method_startline": "1634", "method_endline": "1661"}}}}}}}