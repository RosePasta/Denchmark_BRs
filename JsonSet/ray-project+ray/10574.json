{"BR": {"BR_id": "10574", "BR_author": "raoul-khour-ts", "BRopenT": "2020-09-04T15:02:14Z", "BRcloseT": "2020-09-23T17:19:56Z", "BR_text": {"BRsummary": "[Ray] Manual Cluster Setup (not bringing CPUs into available resources).", "BRdescription": "\n [RAY CORE]\n When following <denchmark-link:https://docs.ray.io/en/latest/cluster/index.html#manual-ray-cluster-setup>https://docs.ray.io/en/latest/cluster/index.html#manual-ray-cluster-setup</denchmark-link>\n \n on 0.8.7 Once I have connected the remote worker nodes I see the number of available CPUs go up. However on the current 0.9.0.dev CPUs stay at 0\n Ray version and other system information (Python version, TensorFlow version, OS):\n 0.9.0.dev seems to currently prevent manual clusters\n <denchmark-h:h3>Reproduction (REQUIRED)</denchmark-h>\n \n install 0.9.0.dev latest\n on main machine run: ray start --head --num-cpus=0\n on worker machine run: ray start --address=xxx --redis-password=xxx --num-cpus=24\n back on main machine run: 'python3 -c \"import ray; ray.init(address='auto');print(ray.available_resources())\"\n see no cpus in available resources\n in 0.8.7 and 0.8.6\n after following above I see 24cpus\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "raoul-khour-ts", "commentT": "2020-09-04T17:51:59Z", "comment_text": "\n \t\tI will investigate and mark as P0 once I can reproduce it\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "raoul-khour-ts", "commentT": "2020-09-05T05:38:53Z", "comment_text": "\n \t\tWas unable to reproduce this. What I tried:\n \n \n In EC2 spin up 2 nodes and ensure they're in the same VPC, subnet, security group, etc.\n \n \n Installed the latest nightly wheel on each machine.\n \n \n Ran\n \n \n <denchmark-code>ubuntu@ip~$ /home/ubuntu/.local/bin/ray start --head --num-cpus=0\n Local node IP: 172.31.37.161\n Available RAM\n   Workers: 18.26 GiB\n   Objects: 9.15 GiB\n   \n   To adjust these values, use\n     ray.init(memory=<bytes>, object_store_memory=<bytes>)\n Dashboard URL: http://localhost:8265\n \n --------------------\n Ray runtime started.\n --------------------\n \n Next steps\n   To connect to this Ray runtime from another node, run\n     ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000'\n   \n   Alternatively, use the following Python code:\n     import ray\n     ray.init(address='auto', redis_password='5241590000000000')\n   \n   If connection fails, check your firewall settings other network configuration.\n   \n   To terminate the Ray runtime, run\n     ray stop\n </denchmark-code>\n \n \n On the other node:\n \n <denchmark-code>ubuntu@ip:~$ .local/bin/ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000'Local node IP: 172.31.42.67\n Available RAM\n   Workers: 21.34 GiB\n   Objects: 9.15 GiB\n   \n   To adjust these values, use\n     ray.init(memory=<bytes>, object_store_memory=<bytes>)\n \n --------------------\n Ray runtime started.\n --------------------\n \n To terminate the Ray runtime, run\n   ray stop\n </denchmark-code>\n \n \n Check the resources from the head node:\n \n <denchmark-code>ubuntu@ip:~$ python3\n Python 3.6.9 (default, Jul 17 2020, 12:50:27) \n [GCC 8.4.0] on linux\n Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n >>> import ray\n >>> ray.init(address=\"auto\")\n 2020-09-05 05:25:03,902\tINFO worker.py:633 -- Connecting to existing Ray cluster at address: xxx.xxx.xxx.xxx:6379\n {'node_ip_address': 'xxx.xxx.xxx.xxx', 'raylet_ip_address': 'xxx.xxx.xxx.xxx', 'redis_address': 'xxx.xxx.xxx.xxx:6379', 'object_store_address': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923/sockets/raylet', 'webui_url': 'localhost:8265', 'session_dir': '/tmp/ray/session_2020-09-05_05-24-24_528207_10923', 'metrics_export_port': 62757}\n >>> ray.available_resources()\n {'memory': 811.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'object_store_memory': 258.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'CPU': 8.0}\n >>> ray.cluster_resources()\n {'CPU': 8.0, 'node:xxx.xxx.xxx.xxx': 1.0, 'memory': 811.0, 'object_store_memory': 258.0, 'node:xxx.xxx.xxx.xxx': 1.0} \n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "raoul-khour-ts", "commentT": "2020-09-05T22:35:00Z", "comment_text": "\n \t\t\n back on main machine run: 'python3 -c \"import ray; print(ray.available_resources())\"\n \n <denchmark-link:https://github.com/raoul-khour-ts>@raoul-khour-ts</denchmark-link>\n  Is that actually enough to reproduce the issue? Don't you need to call ? Note that if you call  then it won't attach to the cluster, so you'll just see one machine's resources.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:07:40Z", "comment_text": "\n \t\tNote that once I do call ray.init(address=\"auto\") I keep getting this in my logs:\n (pid=raylet, ip=xx) service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 127.0.0.1:46515\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:23:44Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/raoul-khour-ts>@raoul-khour-ts</denchmark-link>\n  can you try the steps I used and verify that works?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:30:26Z", "comment_text": "\n \t\tI did exactly that but in our environment (not EC2 but a local farm of machines)\n on 0.8.7 I can recreate your steps all fine and no logs.\n on 0.9.0.dev no cpu's show up in the cluster and the above error message keeps getting logged.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:35:43Z", "comment_text": "\n \t\tThe remote machine (and local) shows up on my ray dashboard... I just for some reason don't have access to its cpus...\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:46:23Z", "comment_text": "\n \t\tCould you do a fresh run of this, then share /tmp/ray/session_latest/logs? Also what's your OS, and python version?\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:53:51Z", "comment_text": "\n \t\tUnfortunately I can not share all my logs. Is there a particular one of the files you are interested in?\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:54:48Z", "comment_text": "\n \t\tOne notable one is the gcs_server.err and out giving these lines:\n network_util.cc:62] Failed to find other valid local IP. Using 127.0.0.1, not possible to go distributed!\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:55:39Z", "comment_text": "\n \t\tIs there a change between how this occurs between 0.8.7 and 9.0.0.dev?\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T01:56:26Z", "comment_text": "\n \t\tI am running python 3.6.10 on a linux machine.\n \t\t"}, "comments_12": {"comment_id": 13, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T02:15:40Z", "comment_text": "\n \t\tJust checked that downgrading to 0.8.7 again does not show that gcs_server.err.\n Interestingly I did notice that when I start python and run ray.init(address='auto') on 0.8.7 I get:\n \n \n \n import ray\n ray.init(address='auto')\n WARNING: Logging before InitGoogleLogging() is written to STDERR\n global_state_accessor.cc:25] Redis server address = xx:6379, is test flag = 0\n redis_client.cc:146] RedisClient connected.\n redis_gcs_client.cc:89] RedisGcsClient Connected.\n service_based_gcs_client.cc:193] Reconnected to GCS server: xx:43483\n service_based_accessor.cc:92] Reestablishing subscription for job info.\n ...\n Reestablishing subscription for worker failures.\n ServiceBasedGcsClient Connected.\n ray.cluster_resources()\n {'object_store_memory': 1786.0, 'memory': 5849.0, 'node:xxx': 1.0, 'node:xx': 1.0, 'CPU': 24.0}\n \n \n \n I dont seem to have that in 0.9.0.dev\n \t\t"}, "comments_13": {"comment_id": 14, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T02:40:15Z", "comment_text": "\n \t\t\n \n back on main machine run: 'python3 -c \"import ray; print(ray.available_resources())\"\n \n @raoul-khour-ts Is that actually enough to reproduce the issue? Don't you need to call ray.init(address=...)? Note that if you call ray.init() then it won't attach to the cluster, so you'll just see one machine's resources.\n \n Hey <denchmark-link:https://github.com/robertnishihara>@robertnishihara</denchmark-link>\n , yeah sorry I forgot to add that to my reproduce guide (but yes I did call ray.init(address='auto')). Updated reproduce guide now.\n \t\t"}, "comments_14": {"comment_id": 15, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T02:45:40Z", "comment_text": "\n \t\tanother observance:\n if I run the ray start --address='xxx.xxx.xxx.xxx:6379' --redis-password='5241590000000000' --num-cpus=20 on the head then I see 20 cpus in the cluster...\n \t\t"}, "comments_15": {"comment_id": 16, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T16:22:09Z", "comment_text": "\n \t\tAre there any errors/stack traces in raylet.err or and of the worker logs?\n \t\t"}, "comments_16": {"comment_id": 17, "comment_author": "raoul-khour-ts", "commentT": "2020-09-07T21:03:10Z", "comment_text": "\n \t\traylet.err is empty\n raylet.out looks normal\n Not sure where the worker logs are. are those the python-core-driver-xxx.log?\n if so then nothing different from the 0.8.7 runs.\n \t\t"}, "comments_17": {"comment_id": 18, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T02:20:24Z", "comment_text": "\n \t\tThere were some changes in finding IP addresses from 0.8.7 => 0.9.0.dev0\n network_util.cc:62] Failed to find other valid local IP. Using 127.0.0.1, not possible to go distributed!\n I believe this log is something we added lately. What OS are you currently using?\n \t\t"}, "comments_18": {"comment_id": 19, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T02:23:40Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ray-project/ray/pull/10004>#10004</denchmark-link>\n \n One of possibilities is that your machines are not using any of network interface listed in the PR description. Can you elaborate more about your cluster environment?\n \t\t"}, "comments_19": {"comment_id": 20, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T02:27:03Z", "comment_text": "\n \t\tThe workaround is to manually set the Redis key so that raylets can find the IP address of GCS. look at this link <denchmark-link:https://github.com/ray-project/ray/issues/8648#issuecomment-664233815>#8648 (comment)</denchmark-link>\n \n \t\t"}, "comments_20": {"comment_id": 21, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T02:43:42Z", "comment_text": "\n \t\tI'm using Debian 9 and python 3.6.10\n \n The workaround is to manually set the Redis key so that raylets can find the IP address of GCS. look at this link #8648 (comment)\n \n I would be happy to test if this would fix my issue but. I actually have no idea how to set the GcsServerAddress to 10.251.231.121:40531 in redis manually,\n Thank you <denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  in advance!\n \t\t"}, "comments_21": {"comment_id": 22, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T03:02:24Z", "comment_text": "\n \t\tIn this case the gcs server address will be  [your head node private ip address]:[gcs_server port], and you can set this by connecting to the Redis in a head node.\n \t\t"}, "comments_22": {"comment_id": 23, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T03:17:15Z", "comment_text": "\n \t\tso running python3 -c \"import redis; r = redis.Redis(host=xxx, port=yyy, db=0); r.set('GcsServerAddress', 'xxx:zzz')\"\n Ill try this tomorrow. Thank you <denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  Ill let you know how that goes.\n \t\t"}, "comments_23": {"comment_id": 24, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T03:26:29Z", "comment_text": "\n \t\tYeah I think that should work. Don\u2019t forget to specify gcs-server port with \u201cray start \u2014head \u2014gcs-port=\u201c so that you don\u2019t need to worry about finding where gcs server has been bound to.\n \t\t"}, "comments_24": {"comment_id": 25, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T03:27:29Z", "comment_text": "\n \t\tBtw, it is interesting the new version has some addresses it resolve while 0.8.7 could. We should probably find a solution for this.\n \t\t"}, "comments_25": {"comment_id": 26, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T20:00:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n \n Sorry about the delay here but it worked!!!:\n ray start --head --gcs-server-port=ddd --cpus=0\n import redis\n r = redis.Redis(host=xxx, port=yyy, password=zzz, db=0)\n r.get('GcsServerAddress')\n >>> 127.0.0.1:ddd\n r.set('GcsServerAddress', xxx:ddd)\n ssh to other_machine\n ray start --address=xxx --redis-password=zzz --num-cpus=24\n back on main machine:\n 'python3 -c \"import ray; ray.init(address='auto');print(ray.available_resources())\"\n \n \n \n {..., cpus:24}\n \n \n \n Now the question is how do we make this work without having to do all this...\n \t\t"}, "comments_26": {"comment_id": 27, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T21:07:09Z", "comment_text": "\n \t\tThe issue here is your manual cluster\u2019s network interface is probably not typical, and we have trouble resolving addresses. I think I can create a patch that allows you to specify GCS address. What do you think about this solution?\n \t\t"}, "comments_27": {"comment_id": 28, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T21:09:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  honestly the gcs address is always going to be the --head ip_address for me at least. Shouldn't that be easy to resolve?\n The port seems to be resolving fine...\n \t\t"}, "comments_28": {"comment_id": 29, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T21:12:35Z", "comment_text": "\n \t\tAh, I see. So, the issue is gcs server address is not matching head ip address you specified right?\n \t\t"}, "comments_29": {"comment_id": 30, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T21:33:41Z", "comment_text": "\n \t\tWell the gcs server address seems to for some reason fail to connect to head_ip_address then fall back to localhost. However that prevents remote machines from connecting.\n \t\t"}, "comments_30": {"comment_id": 31, "comment_author": "raoul-khour-ts", "commentT": "2020-09-09T21:35:33Z", "comment_text": "\n \t\tbut If i go back into redis and manually set it to head_ip_address everything is fine...\n \t\t"}, "comments_31": {"comment_id": 32, "comment_author": "raoul-khour-ts", "commentT": "2020-09-17T13:23:07Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  and I have isolated the issue to being an issue with private networks. My machine can not ping out to 8.8.8.8 which makes the GCS configuration fail.\n \t\t"}, "comments_32": {"comment_id": 33, "comment_author": "raoul-khour-ts", "commentT": "2020-09-19T08:54:27Z", "comment_text": "\n \t\tNote: I will make a PR to use Python code to resolve addresses of GCS servers\n \t\t"}, "comments_33": {"comment_id": 34, "comment_author": "raoul-khour-ts", "commentT": "2020-09-23T17:19:56Z", "comment_text": "\n \t\tWas able to confirm that <denchmark-link:https://github.com/ray-project/ray/pull/10946>#10946</denchmark-link>\n  fixed the issue.\n Thank you <denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n . This should make it out to the 1.1.0 release hopefully sometime in November?\n \t\t"}, "comments_34": {"comment_id": 35, "comment_author": "raoul-khour-ts", "commentT": "2020-09-23T17:37:52Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/raoul-khour-ts>@raoul-khour-ts</denchmark-link>\n  Yes! We have a monthly release cycle, and the 1.0 target date is the end of September, so the next version will be released around Nov! There's a possibility to have a shorter release cycle (though I cannot guarantee). The next version might not be 1.1, but it will be 1.0.1. We might have a new second digit release every quarter.\n \t\t"}, "comments_35": {"comment_id": 36, "comment_author": "raoul-khour-ts", "commentT": "2020-12-14T19:12:01Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/rkooo567>@rkooo567</denchmark-link>\n  I am starting to see issues like this again on 1.1.0.dev. Its a little stranger though that it seems like things end up dieing but with similar errors.\n Have y'all moved 1.1.0.dev to distributed or spawning gcs or something? (could be a separate issue)\n \t\t"}, "comments_36": {"comment_id": 37, "comment_author": "raoul-khour-ts", "commentT": "2020-12-14T19:12:31Z", "comment_text": "\n \t\teither way it seems like the gcs location is being lost... and this is only happening in clusters.\n \t\t"}, "comments_37": {"comment_id": 38, "comment_author": "raoul-khour-ts", "commentT": "2020-12-14T19:17:19Z", "comment_text": "\n \t\tAre there logs in gcs_server.err?  (/tmp/ray/session_latest/logs)\n \t\t"}}}, "commit": {"commit_id": "390107b6cbe1550defdcd86d4dbf945cadd43372", "commit_author": "SangBin Cho", "commitT": "2020-09-23 01:52:26-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "python\\ray\\node.py", "file_new_name": "python\\ray\\node.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "683,684", "deleted_lines": "683", "method_info": {"method_name": "start_gcs_server", "method_params": "self", "method_startline": "670", "method_endline": "689"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "python\\ray\\services.py", "file_new_name": "python\\ray\\services.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1100", "deleted_lines": "1100", "method_info": {"method_name": "start_gcs_server", "method_params": "redis_address,stdout_file,stderr_file,redis_password,config,fate_share,gcs_server_port,metrics_agent_port", "method_startline": "1093", "method_endline": "1100"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1100,1101", "deleted_lines": "1100", "method_info": {"method_name": "start_gcs_server", "method_params": "redis_address,stdout_file,stderr_file,redis_password,config,fate_share,gcs_server_port,metrics_agent_port,node_ip_address", "method_startline": "1093", "method_endline": "1101"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\ray\\gcs\\gcs_server\\gcs_server.cc", "file_new_name": "src\\ray\\gcs\\gcs_server\\gcs_server.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "255,256,257,258,259,260,261", "deleted_lines": "255,256,257,258,259", "method_info": {"method_name": "ray::gcs::GcsServer::StoreGcsServerAddressInRedis", "method_params": "", "method_startline": "254", "method_endline": "267"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "src\\ray\\gcs\\gcs_server\\gcs_server.h", "file_new_name": "src\\ray\\gcs\\gcs_server\\gcs_server.h", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "37", "deleted_lines": null}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "src\\ray\\gcs\\gcs_server\\gcs_server_main.cc", "file_new_name": "src\\ray\\gcs\\gcs_server\\gcs_server_main.cc", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "46,80", "deleted_lines": null, "method_info": {"method_name": "main", "method_params": "argc", "method_startline": "32", "method_endline": "104"}}}}}}}