{"BR": {"BR_id": "2958", "BR_author": "HeekangPark", "BRopenT": "2020-10-14T09:40:04Z", "BRcloseT": "2020-10-30T08:41:25Z", "BR_text": {"BRsummary": "SPOS Example Fails to Run", "BRdescription": "\n Environment:\n \n NNI version: 1.8\n NNI mode (local|remote|pai): local\n Client OS: Ubuntu 18.04\n Server OS (for remote mode only):\n Python version: v3.7\n PyTorch/TensorFlow version: Pytorch v1.6.0\n Is conda/virtualenv/venv used?: conda used\n Is running in Docker?: no\n \n Log message:\n \n nnimanager.log:\n dispatcher.log:\n nnictl stdout and stderr:\n \n What issue meet, what's expected?:\n Currently, in examples/nas/spos/supernet.py, line 55, the argument of flops_func is set as model.module.get_candidate_flops.\n However, when I run python supernet.py, it fails to run due to that line.\n I think the argument of flops_func should be model.get_candidate_flops, not model.module.get_candidate_flops.\n How to reproduce it?:\n Clone the repo, and just run python supernet.py in examples/nas/spos/.\n Additional information:\n I'm new to this field, so the issue I found might be due to my ignorance. Thank you in advance.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "HeekangPark", "commentT": "2020-10-14T10:31:27Z", "comment_text": "\n \t\tI find out the problem.\n supernet.py runs in parallel only when the number of available gpu is bigger than 1.\n I used only 1 gpu to run the code, so nn.DataParallel() was not executed, which makes model.module.get_candidate_flops as wrong code.\n Well, of course it is not a wise idea to run NAS with only 1 gpu, , but for those who run code with 1 gpu like me, I suggest to add a line of code right below line 47(model = ShuffleNetV2OneShot()) like this.\n <denchmark-code>model = ShuffleNetV2OneShot()  # line 47\n flops_func = model.get_candidate_flops\n if args.load_checkpoint:\n     if not args.spos_preprocessing:\n         logger.warning(\"You might want to use SPOS preprocessing if you are loading their checkpoints.\")\n     model.load_state_dict(load_and_parse_state_dict())\n model.cuda()\n if torch.cuda.device_count() > 1:  # exclude last gpu, saving for data preprocessing on gpu\n     model = nn.DataParallel(model, device_ids=list(range(0, torch.cuda.device_count() - 1)))\n </denchmark-code>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "HeekangPark", "commentT": "2020-10-15T01:41:23Z", "comment_text": "\n \t\tHi. Seems that you've identified the problem and would you kindly submit a pull request? We would be happy to have you as one of our contributor. :)\n \t\t"}}}, "commit": {"commit_id": "cd23bc414a108b9d27b6b3a1596b00d3f1a17930", "commit_author": "HeekangPark", "commitT": "2020-10-19 10:22:33+08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "examples\\nas\\spos\\supernet.py", "file_new_name": "examples\\nas\\spos\\supernet.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "48,56", "deleted_lines": "55"}}}}}}