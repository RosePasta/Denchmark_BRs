{"BR": {"BR_id": "11961", "BR_author": "piyushghai", "BRopenT": "2018-08-01T04:21:43Z", "BRcloseT": "2018-08-06T16:11:58Z", "BR_text": {"BRsummary": "Model inference outputs not matching across MXNet versions using save_params and load_params", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n Model inference outputs not matching when model is saved on MXNet v1.0.0 and the same model is loaded on MXNet v1.3.0 (built from latest master branch).\n The error was observed in the CI run for Model Backwards Compatibility Check and is available here  : <denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/restricted-backwards-compatibility-checker/detail/restricted-backwards-compatibility-checker/1/pipeline/>http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/restricted-backwards-compatibility-checker/detail/restricted-backwards-compatibility-checker/1/pipeline/</denchmark-link>\n \n <denchmark-h:h2>Error Message:</denchmark-h>\n \n Items are not equal:\n <denchmark-code>  File \"model_backwards_compat_inference.py\", line 135, in <module>\n     test_lenet_gluon_load_params_api()\n   File \"model_backwards_compat_inference.py\", line 72, in test_lenet_gluon_load_params_api\n     assert_almost_equal(old_inference_results.asnumpy(), output.asnumpy())\n   File \"/work/mxnet/python/mxnet/test_utils.py\", line 493, in assert_almost_equal\n     raise AssertionError(msg)\n AssertionError: \n Items are not equal:\n Error 1.969787 exceeds tolerance rtol=0.000010, atol=0.000000.  Location of maximum error:(5, 0), a=0.003014, b=0.003014\n  a: array([[ 0.01743407, -0.30903903],\n        [ 0.08352755, -0.365019  ],\n        [ 0.06324662, -0.4323489 ],...\n  b: array([[ 0.01743408, -0.3090391 ],\n        [ 0.08352771, -0.365019  ],\n        [ 0.06324662, -0.4323488 ],...\n </denchmark-code>\n \n <denchmark-h:h2>Minimum reproducible example</denchmark-h>\n \n Perform the training and save the model on MXNet 1.0.0.\n Model Definition:\n <denchmark-code>class Net(gluon.Block):\n     def __init__(self, **kwargs):\n         super(Net, self).__init__(**kwargs)\n         with self.name_scope():\n             # layers created in name_scope will inherit name space\n             # from parent layer.\n             self.conv1 = nn.Conv2D(20, kernel_size=(5, 5))\n             self.pool1 = nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2))\n             self.conv2 = nn.Conv2D(50, kernel_size=(5, 5))\n             self.pool2 = nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2))\n             self.fc1 = nn.Dense(500)\n             self.fc2 = nn.Dense(2)\n \n     def forward(self, x):\n         x = self.pool1(F.tanh(self.conv1(x)))\n         x = self.pool2(F.tanh(self.conv2(x)))\n         # 0 means copy over size from corresponding dimension.\n         # -1 means infer size from the rest of dimensions.\n         x = x.reshape((0, -1))\n         x = F.tanh(self.fc1(x))\n         x = F.tanh(self.fc2(x))\n         return x\n \n </denchmark-code>\n \n Training code snippet :\n <denchmark-code>def train_lenet_gluon_save_params_api():\n     model_name = 'lenet_gluon_save_params_api'\n     create_model_folder(model_name)\n     logging.info('Saving files for model %s' % model_name)\n     net = Net()\n     weights = mx.initializer.Xavier(magnitude=2.57)\n     net.initialize(weights, ctx=[mx.cpu(0)])\n     # Prepare data\n \n     test_data = mx.nd.array(np.random.uniform(-1, 1, size=(20, 1, 30, 30)))\n     output = net(test_data)\n     # print (y)\n \n     mx.nd.save(os.path.join(get_model_path(model_name), ''.join([model_name, '-data'])), {'data': test_data})\n     save_inference_results(output, model_name)\n     net.save_params(os.path.join(get_model_path(model_name), ''.join([model_name, '-params'])))\n </denchmark-code>\n \n Model Inference to be performed on MXNet built from source from the latest <denchmark-link:https://github.com/apache/incubator-mxnet>master</denchmark-link>\n \n Inference snippet :\n <denchmark-code>def test_lenet_gluon_load_params_api():\n     from mxnet.test_utils import assert_almost_equal\n     model_name = 'lenet_gluon_save_params_api'\n     logging.info('Performing inference for model/API %s' % model_name)\n \n     data = mx.nd.load(''.join([model_name, '-data']))\n     test_data = data['data']\n     # Load the model and perform inference\n     loaded_model = Net()\n     loaded_model.load_params(model_name + '-params')\n     output = loaded_model(test_data)\n     old_inference_results = mx.nd.load(model_name + '-inference')['inference']\n     assert_almost_equal(old_inference_results.asnumpy(), output.asnumpy())\n     logging.info('=================================')\n     logging.info('Assertion passed for model : %s' % model_name)\n \n </denchmark-code>\n \n <denchmark-h:h2>Steps to reproduce</denchmark-h>\n \n \n Run the training on MXNet 1.0.0 ( Installed via pip install mxnet==1.0.0)\n Run the inference on MXNet 1.3.0 ( Built from source using latest master branch)\n \n This regression is not seen on models trained on v1.1.0 and v1.2.0 with inference performed on v1.3.0\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "piyushghai", "commentT": "2018-08-01T07:46:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Roshrini>@Roshrini</denchmark-link>\n  please take a look. This may be another blocker we want to fix for 1.3 release.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "piyushghai", "commentT": "2018-08-01T09:06:07Z", "comment_text": "\n \t\tReproducible using\n <denchmark-code>ci/build.py --platform ubuntu_nightly_cpu /work/runtime_functions.sh nightly_model_backwards_compat_test\n </denchmark-code>\n \n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "piyushghai", "commentT": "2018-08-01T18:38:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/piyushghai>@piyushghai</denchmark-link>\n  Thanks for reporting this issue.\n Looking into it.\n <denchmark-link:https://github.com/sandeep-krishnamurthy>@sandeep-krishnamurthy</denchmark-link>\n  Can you please add label: Bug\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "piyushghai", "commentT": "2018-08-01T22:57:55Z", "comment_text": "\n \t\tI was able to reproduce this issue. Need to debug more to see why its happening.\n <denchmark-link:https://github.com/szha>@szha</denchmark-link>\n  Have you observed this before or have any idea about why it may be happening?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "piyushghai", "commentT": "2018-08-02T18:10:12Z", "comment_text": "\n \t\tSeems like the tolerance level is not set in the mentioned test.. The difference seen in the values is after 7th decimal point which is acceptable.\n Output I got:\n old_inference_results:\n [[-0.22245485 -0.60762584]\n [-0.18619929 -0.4941083 ]\n [-0.2614998  -0.4940931 ]\n [-0.23192915 -0.4607012 ]\n [-0.22917394 -0.4702541 ]\n [-0.03644256 -0.5791895 ]\n [-0.06653443 -0.5936823 ]\n [-0.27859935 -0.55876964]\n [-0.11784768 -0.5614954 ]\n [-0.19131322 -0.65991235]\n [-0.14616844 -0.49545118]\n [-0.19445111 -0.4866081 ]\n [-0.12782529 -0.5715893 ]\n [-0.12283947 -0.59274095]\n [-0.20627439 -0.4948909 ]\n [-0.25454554 -0.5265834 ]\n [-0.16980055 -0.4900279 ]\n [-0.25898194 -0.5047521 ]\n [-0.10910024 -0.60400814]\n [-0.08615021 -0.55358285]]\n <NDArray 20x2 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n new inference result:\n [[-0.22245483 -0.6076257 ]\n [-0.18619926 -0.49410838]\n [-0.26149982 -0.49409294]\n [-0.2319293  -0.46070114]\n [-0.2291741  -0.47025427]\n [-0.03644253 -0.5791895 ]\n [-0.06653453 -0.59368235]\n [-0.2785993  -0.5587696 ]\n [-0.11784772 -0.5614954 ]\n [-0.19131319 -0.65991235]\n [-0.14616835 -0.4954512 ]\n [-0.19445102 -0.4866083 ]\n [-0.12782538 -0.5715892 ]\n [-0.12283948 -0.5927409 ]\n [-0.20627451 -0.494891  ]\n [-0.25454548 -0.52658343]\n [-0.1698006  -0.49002784]\n [-0.25898185 -0.50475204]\n [-0.10910021 -0.60400814]\n [-0.08615006 -0.553583  ]]\n <NDArray 20x2 <denchmark-link:https://github.com/cpu>@cpu</denchmark-link>\n (0)>\n <denchmark-link:https://github.com/piyushghai>@piyushghai</denchmark-link>\n  will be working on fixing the test with proper tolerance level.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "piyushghai", "commentT": "2018-08-02T18:29:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Roshrini>@Roshrini</denchmark-link>\n  Created the PR : <denchmark-link:https://github.com/apache/incubator-mxnet/pull/12006>#12006</denchmark-link>\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "piyushghai", "commentT": "2018-08-03T16:42:25Z", "comment_text": "\n \t\tLooks like the build has passed now after the PR Merge.\n <denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/restricted-backwards-compatibility-checker/detail/restricted-backwards-compatibility-checker/5/pipeline>http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/restricted-backwards-compatibility-checker/detail/restricted-backwards-compatibility-checker/5/pipeline</denchmark-link>\n \n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "piyushghai", "commentT": "2018-08-06T16:12:15Z", "comment_text": "\n \t\tClosing, since the issue is no longer seen after merging <denchmark-link:https://github.com/apache/incubator-mxnet/pull/12006>#12006</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "25341648365598a9a123f033bf92ce7fb51c0a39", "commit_author": "Piyush Ghai", "commitT": "2018-08-03 12:08:05+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\nightly\\model_backwards_compatibility_check\\common.py", "file_new_name": "tests\\nightly\\model_backwards_compatibility_check\\common.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "44,45", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\nightly\\model_backwards_compatibility_check\\model_backwards_compat_inference.py", "file_new_name": "tests\\nightly\\model_backwards_compatibility_check\\model_backwards_compat_inference.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "72", "deleted_lines": "72", "method_info": {"method_name": "test_lenet_gluon_load_params_api", "method_params": "", "method_startline": "54", "method_endline": "75"}}, "hunk_1": {"Ismethod": 1, "added_lines": "127", "deleted_lines": "127", "method_info": {"method_name": "test_lstm_gluon_load_parameters_api", "method_params": "", "method_startline": "101", "method_endline": "130"}}, "hunk_2": {"Ismethod": 1, "added_lines": "95", "deleted_lines": "95", "method_info": {"method_name": "test_lenet_gluon_hybrid_imports_api", "method_params": "", "method_startline": "78", "method_endline": "98"}}, "hunk_3": {"Ismethod": 1, "added_lines": "47", "deleted_lines": "47", "method_info": {"method_name": "test_module_checkpoint_api", "method_params": "", "method_startline": "23", "method_endline": "51"}}}}}}}