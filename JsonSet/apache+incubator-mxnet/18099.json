{"BR": {"BR_id": "18099", "BR_author": "szha", "BRopenT": "2020-04-19T01:36:02Z", "BRcloseT": "2020-05-14T06:48:41Z", "BR_text": {"BRsummary": "Error in test_contrib_amp.py::test_amp_coverage", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n As part of <denchmark-link:https://github.com/apache/incubator-mxnet/pull/18025>#18025</denchmark-link>\n  I added a waitall() in between tests in amp. This revealed the following error in unix-gpu pipeline which seems to be related to pointwise fusion.\n <denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-18025/34/pipeline/417>http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-18025/34/pipeline/417</denchmark-link>\n \n <denchmark-code>==================================== ERRORS ====================================\n ____________________ ERROR at teardown of test_amp_coverage ____________________\n \n     def teardown():\n >       mx.nd.waitall()\n \n tests/python/gpu/test_contrib_amp.py:42: \n _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n python/mxnet/ndarray/ndarray.py:211: in waitall\n     check_call(_LIB.MXNDArrayWaitAll())\n _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n \n ret = -1\n \n     def check_call(ret):\n         \"\"\"Check the return value of C API call.\n     \n         This function will raise an exception when an error occurs.\n         Wrap every API call with this function.\n     \n         Parameters\n         ----------\n         ret : int\n             return value from API calls.\n         \"\"\"\n         if ret != 0:\n >           raise get_last_ffi_error()\n E           mxnet.base.MXNetError: Traceback (most recent call last):\n E             [bt] (9) /work/mxnet/python/mxnet/../../build/libmxnet.so(std::thread::_State_impl<std::thread::_Invoker<std::tuple<std::function<void (std::shared_ptr<dmlc::ManualEvent>)>, std::shared_ptr<dmlc::ManualEvent> > > >::_M_run()+0x4a) [0x7fb2e5fce4da]\n E             [bt] (8) /work/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler<void (std::shared_ptr<dmlc::ManualEvent>), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr<dmlc::ManualEvent>)#1}>::_M_invoke(std::_Any_data const&, std::shared_ptr<dmlc::ManualEvent>&&)+0x4e) [0x7fb2e5fd27fe]\n E             [bt] (7) /work/mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker<(dmlc::ConcurrentQueueType)0>(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock<(dmlc::ConcurrentQueueType)0>*, std::shared_ptr<dmlc::ManualEvent> const&)+0x11d) [0x7fb2e5fd251d]\n E             [bt] (6) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x121) [0x7fb2e5fcf491]\n E             [bt] (5) /work/mxnet/python/mxnet/../../build/libmxnet.so(+0x20828ee) [0x7fb2e5fc48ee]\n E             [bt] (4) /work/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&)+0x17) [0x7fb2e609b027]\n E             [bt] (3) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x934) [0x7fb2e609abd4]\n E             [bt] (2) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::op::TVMBinaryBroadcastScalarCompute::operator()(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x5b8) [0x7fb2e721ee28]\n E             [bt] (1) /work/mxnet/python/mxnet/../../build/libmxnet.so(tvm::runtime::TVMOpModule::CallEx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, tvm::runtime::TVMArgs) const+0xb1) [0x7fb2e8fce2d1]\n E             [bt] (0) /work/build/3rdparty/tvm/libtvm_runtime.so(+0x4ac09) [0x7fb3641c5c09]\n E             [bt] (9) /work/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler<void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}>::_M_invoke(std::_Any_data const&, mxnet::RunContext&&)+0x17) [0x7fb2e609b027]\n E             [bt] (8) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::imperative::PushFCompute(std::function<void (nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)> const&, nnvm::Op const*, nnvm::NodeAttrs const&, mxnet::Context const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::engine::Var*, std::allocator<mxnet::engine::Var*> > const&, std::vector<mxnet::Resource, std::allocator<mxnet::Resource> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<mxnet::NDArray*, std::allocator<mxnet::NDArray*> > const&, std::vector<unsigned int, std::allocator<unsigned int> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x934) [0x7fb2e609abd4]\n E             [bt] (7) /work/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::op::TVMBinaryBroadcastScalarCompute::operator()(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, std::vector<mxnet::OpReqType, std::allocator<mxnet::OpReqType> > const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&)+0x5b8) [0x7fb2e721ee28]\n E             [bt] (6) /work/mxnet/python/mxnet/../../build/libmxnet.so(tvm::runtime::TVMOpModule::CallEx(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, mxnet::OpContext const&, std::vector<mxnet::TBlob, std::allocator<mxnet::TBlob> > const&, tvm::runtime::TVMArgs) const+0xb1) [0x7fb2e8fce2d1]\n E             [bt] (5) /work/build/3rdparty/tvm/libtvm_runtime.so(+0x4a09f) [0x7fb3641c509f]\n E             [bt] (4) /work/mxnet/python/mxnet/../../build/libtvmop.so(greater_scalar_gpufloat32_2bool_2+0x210) [0x7fb1ea39d900]\n E             [bt] (3) /work/mxnet/python/mxnet/../../build/libtvmop.so(+0xb0b1f) [0x7fb1ea39db1f]\n E             [bt] (2) /work/build/3rdparty/tvm/libtvm_runtime.so(TVMBackendGetFuncFromEnv+0x61) [0x7fb3641ab831]\n E             [bt] (1) /work/build/3rdparty/tvm/libtvm_runtime.so(tvm::runtime::ModuleNode::GetFuncFromEnv(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)+0x3d8) [0x7fb3641ce498]\n E             [bt] (0) /work/mxnet/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x7f) [0x7fb2e5dc10cf]\n E             File \"/work/mxnet/3rdparty/tvm/src/runtime/module.cc\", line 123\n E             File \"/work/mxnet/3rdparty/tvm/src/runtime/library_module.cc\", line 91\n E           TVMError: Check failed: ret == 0 (-1 vs. 0) : Check failed: f != nullptr: Cannot find function greater_scalar_gpufloat32_2bool_2_kernel0 in the imported modules or global registry\n \n python/mxnet/base.py:246: MXNetError\n =============================== warnings summary ===============================\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "szha", "commentT": "2020-04-20T03:33:09Z", "comment_text": "\n \t\tNote that the original error was wrong due to confusing log on teardown of module which attributes errors to the last test (i.e. ). This happens even though it was disabled which helped me catch this problem. This bug is tracked in <denchmark-link:https://github.com/pytest-dev/pytest/issues/7101>pytest-dev/pytest#7101</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "szha", "commentT": "2020-04-20T03:40:36Z", "comment_text": "\n \t\tcc <denchmark-link:https://github.com/yzhliu>@yzhliu</denchmark-link>\n  as we discussed about a (supposedly) related problem with  before.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "szha", "commentT": "2020-04-20T07:41:22Z", "comment_text": "\n \t\tsame problem with  <denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-18025/35/pipeline/417>http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-18025/35/pipeline/417</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "szha", "commentT": "2020-04-20T16:31:18Z", "comment_text": "\n \t\tSeems to have the same problem for the rest of the tests so this indicates a problem to the amp module itself. I've disabled all amp tests at the moment\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "szha", "commentT": "2020-05-12T19:53:02Z", "comment_text": "\n \t\tThe error comes from TVM actually, not pointwise fusion.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "szha", "commentT": "2020-05-12T22:00:36Z", "comment_text": "\n \t\tLet's reenable the test as TVMOP is now disabled on GPU builds\n \t\t"}}}, "commit": {"commit_id": "446ce14ef43e19c07e90c70bde99c37274a3cee1", "commit_author": "Leonard Lausen", "commitT": "2020-05-13 23:48:40-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "tests\\python\\gpu\\test_contrib_amp.py", "file_new_name": "tests\\python\\gpu\\test_contrib_amp.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "107"}}}}}}