{"BR": {"BR_id": "12528", "BR_author": "luobao-intel", "BRopenT": "2018-09-12T04:20:26Z", "BRcloseT": "2018-10-16T01:07:39Z", "BR_text": {"BRsummary": "Those cases with some problems in dir : example", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n In the directory example,  there are some cases that can't be run normally due to code bugs and  lost  dependency files or  links.\n <denchmark-h:h2>covered cases</denchmark-h>\n \n \n  mxnet_adversarial_vae\n  restricted-boltzmann-machine\n  sparse\\linear_classification\n  speech_recognition\n \n <denchmark-h:h2>Environment info (Required)</denchmark-h>\n \n All the cases were tested on the master branch, commit id :  <denchmark-link:https://github.com/apache/incubator-mxnet/commit/abbe283ef8b1d78b002cb492651f002ae27ba544>abbe283</denchmark-link>\n \n <denchmark-h:h3>mxnet_adversarial_vae</denchmark-h>\n \n \n command : python vaegan_mxnet.py --train\n Error Message:\n terminate called after throwing an instance of 'dmlc::Error'\n what():  [10:07:17] src/engine/./threaded_engine.h:379: std::exception\n A fatal error occurred in asynchronous engine operation. If you do not know what caused this error, you can try set environment variable MXNET_ENGINE_TYPE to NaiveEngine and run with debugger (i.e. gdb). This will force all operations to be synchronous and backtrace will give you the series of calls that lead to this error. Remember to set MXNET_ENGINE_TYPE back to empty after debugging.\n \n <denchmark-h:h3>named_entity_recognition</denchmark-h>\n \n \n command : python preprocess.py\n error description: the data.csv file can't be normally read.\n Error Message:\n Traceback (most recent call last):\n File \"preprocess.py\", line 27, in \n df = pd.read_csv(\"../data/ner_dataset.csv\")\n File \"/home/luobaozo/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/io/parsers.py\", line 678, in parser_f\n return _read(filepath_or_buffer, kwds)\n File \"/home/luobaozo/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/io/parsers.py\", line 446, in _read\n data = parser.read(nrows)\n File \"/home/luobaozo/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/io/parsers.py\", line 1036, in read\n ret = self._engine.read(nrows)\n File \"/home/luobaozo/anaconda3/envs/py27/lib/python2.7/site-packages/pandas/io/parsers.py\", line 1848, in read\n data = self._reader.read(nrows)\n File \"pandas/_libs/parsers.pyx\", line 876, in pandas._libs.parsers.TextReader.read\n File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._read_low_memory\n File \"pandas/_libs/parsers.pyx\", line 945, in pandas._libs.parsers.TextReader._read_rows\n File \"pandas/_libs/parsers.pyx\", line 932, in pandas._libs.parsers.TextReader._tokenize_rows\n File \"pandas/_libs/parsers.pyx\", line 2112, in pandas._libs.parsers.raise_parser_error\n pandas.errors.ParserError: Error tokenizing data. C error: Expected 1 fields in line 6, saw 2\n \n <denchmark-h:h3>restricted-boltzmann-machine</denchmark-h>\n \n \n command: python binary_rbm_gluon.py --no-cuda\n Error Message:\n File \"binary_rbm_gluon.py\", line 56, in \n mx.random.seed(pyrnd.getrandbits(32))\n File \"/home/luobaozo/intel_mxnet_2-subgraph_dev/python/mxnet/random.py\", line 94, in seed\n raise ValueError('seed_state must be int')\n ValueError: seed_state must be int\n \n <denchmark-h:h3>sparse\\linear_classification</denchmark-h>\n \n \n command: python train.py\n error description:\n Error Message:\n Dataset avazu-app not present. Downloading now ...\n bzip2: avazu-app.bz2 is not a bzip2 file.\n Dataset avazu-app is now present.\n Dataset avazu-app.t not present. Downloading now ...\n bzip2: avazu-app.t.bz2 is not a bzip2 file.\n Dataset avazu-app.t is now present.\n Traceback (most recent call last):\n File \"train.py\", line 85, in \n part_index=rank)\n File \"/home/luobaozo/intel_mxnet_2-subgraph_dev/python/mxnet/io.py\", line 936, in creator\n ctypes.byref(iter_handle)))\n File \"/home/luobaozo/intel_mxnet_2-subgraph_dev/python/mxnet/base.py\", line 255, in check_call\n raise MXNetError(py_str(LIB.MXGetLastError()))\n mxnet.base.MXNetError: [12:08:19] src/io/input_split_base.cc:173: Check failed: files.size() != 0U (0 vs. 0) Cannot find any files that matches the URI pattern /home/luobaozo/incubator-mxnet/example/sparse/linear_classification/data/avazu-app\n \n <denchmark-h:h3>speech_recognition</denchmark-h>\n \n \n lost link:  The instruction of Baidu's Warp CTC installation\n \n <denchmark-link:https://github.com/pengzhao-intel>@pengzhao-intel</denchmark-link>\n  <denchmark-link:https://github.com/juliusshufan>@juliusshufan</denchmark-link>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "luobao-intel", "commentT": "2018-09-12T19:49:53Z", "comment_text": "\n \t\tThanks for submitting the issue <denchmark-link:https://github.com/luobao-intel>@luobao-intel</denchmark-link>\n \n <denchmark-link:https://github.com/mxnet-label-bot>@mxnet-label-bot</denchmark-link>\n [Bug, Example]\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "luobao-intel", "commentT": "2018-09-13T23:55:55Z", "comment_text": "\n \t\tI was able to run the sparse/linear_classification example successfully on Mac OS Sierra using MXNet- v1.3 installed from PIP on python2.\n Could you try running that example again <denchmark-link:https://github.com/luobao-intel>@luobao-intel</denchmark-link>\n  ?\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "luobao-intel", "commentT": "2018-09-14T01:33:29Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/kalyc>@kalyc</denchmark-link>\n  Thanks,  could you try other cases (also in Linux) and see if the issue is still there?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "luobao-intel", "commentT": "2018-09-19T12:06:14Z", "comment_text": "\n \t\tI cannot reproduce the error in the restricted Boltzmann machine example. The stack trace you gave essentially says that  returns , but it should return  simply because  returns an  (<denchmark-link:https://docs.python.org/3/library/random.html#random.getrandbits>python doc</denchmark-link>\n ). Would you try once more?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "luobao-intel", "commentT": "2018-10-09T23:37:59Z", "comment_text": "\n \t\tHaving a look into it. Will update my findings here.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "luobao-intel", "commentT": "2018-10-10T00:33:06Z", "comment_text": "\n \t\tHere are my findings :\n I compiled MXNet from source using the instructions here : <denchmark-link:https://mxnet.incubator.apache.org/install/index.html?platform=Linux&language=Python&processor=CPU>https://mxnet.incubator.apache.org/install/index.html?platform=Linux&language=Python&processor=CPU</denchmark-link>\n  . MXNet was compiled from the master branch using the commit hash : <denchmark-link:https://github.com/apache/incubator-mxnet/commit/c98b19e2d108a3861d89b475927e8a21a913e540>c98b19e</denchmark-link>\n \n I used a machine with Ubuntu 16.04 as pointed by <denchmark-link:https://github.com/pengzhao-intel>@pengzhao-intel</denchmark-link>\n  to try to reproduce the error.\n \n Following the instructions from here : <denchmark-link:https://github.com/apache/incubator-mxnet/tree/master/example/mxnet_adversarial_vae>https://github.com/apache/incubator-mxnet/tree/master/example/mxnet_adversarial_vae</denchmark-link>\n \n I ran the following two commands :\n <denchmark-code>python convert_data.py\n python vaegan_mxnet.py --train\n </denchmark-code>\n \n The following output was observed :\n <denchmark-code>python vaegan_mxnet.py --train\n Training...\n [00:16:56] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:16:56] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n epoch: 0 iter: 10 metric: ('facc', 0.9161458333333333) ('fentropy', 4.697351173559825) ('fentropy', 0.1544979902760436) ('kldivergence', 30.890868949890137) [36.404568] [4215.3438]\n epoch: 0 iter: 20 metric: ('facc', 0.8911458333333333) ('fentropy', 4.428191826927165) ('fentropy', 0.42831218464331566) ('kldivergence', 45.59204025268555) [54.703785] [4094.2957]\n ....\n </denchmark-code>\n \n \n There is one step which is misleading in the instructions given here : <denchmark-link:https://github.com/apache/incubator-mxnet/tree/master/example/named_entity_recognition>https://github.com/apache/incubator-mxnet/tree/master/example/named_entity_recognition</denchmark-link>\n .\n The download and unzip step in the readme needs to be rephrased.  yields a html as a result instead of csv file.\n To fetch the correct dataset, click <denchmark-link:https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/downloads/ner_dataset.csv>https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/downloads/ner_dataset.csv</denchmark-link>\n  and then download the dataset from Kaggle's website.\n After that, follow the rest of the instructions from the README.\n I ran these two commands :\n <denchmark-code> cd src && python preprocess.py\n cd src && python ner.py\n </denchmark-code>\n \n This yielded the following output :\n <denchmark-code>Buckets  created:  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n Warning, 610 sentences sliced to largest bucket size.\n \n Buckets  created:  [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n Warning, 162 sentences sliced to largest bucket size.\n [00:21:41] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n /home/ubuntu/incubator-mxnet/example/named_entity_recognition/src/metrics.py:61: RuntimeWarning: invalid value encountered in double_scalars\n   f1 = 2 * precision * recall / (precision + recall)\n /home/ubuntu/incubator-mxnet/example/named_entity_recognition/src/metrics.py:53: RuntimeWarning: invalid value encountered in long_scalars\n   precision = correct_entitites/entity_preds\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:21:53] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n [00:22:12] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:109: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n INFO:root:Epoch[0] Train-accuracy=0.903614\n INFO:root:Epoch[0] Train-entity precision=nan\n INFO:root:Epoch[0] Train-entity recall=0.398506\n INFO:root:Epoch[0] Train-entity f1 score=nan\n INFO:root:Epoch[0] Time cost=43.281\n INFO:root:Epoch[0] Validation-accuracy=0.960105\n INFO:root:Epoch[0] Validation-entity precision=0.834820\n INFO:root:Epoch[0] Validation-entity recall=0.766734\n INFO:root:Epoch[0] Validation-entity f1 score=0.798455\n ...\n </denchmark-code>\n \n \n I followed the README from here : <denchmark-link:https://github.com/apache/incubator-mxnet/tree/master/example/restricted-boltzmann-machine>https://github.com/apache/incubator-mxnet/tree/master/example/restricted-boltzmann-machine</denchmark-link>\n  and ran\n <denchmark-code>python binary_rbm_gluon.py --no-cuda --num-epoch=5\n </denchmark-code>\n \n The following output was observed :\n <denchmark-code>Epoch 0 completed with test log-likelihood -193.894379 and train log-likelihood -196.995422\n Epoch 1 completed with test log-likelihood -178.264587 and train log-likelihood -181.239731\n ...\n </denchmark-code>\n \n \n Again following the README from <denchmark-link:https://github.com/apache/incubator-mxnet/tree/master/example/sparse/linear_classification>https://github.com/apache/incubator-mxnet/tree/master/example/sparse/linear_classification</denchmark-link>\n , I ran :\n <denchmark-code>python2 train.py\n </denchmark-code>\n \n and got this output :\n <denchmark-code>2018-10-10 00:02:09,340 Namespace(batch_size=8192, kvstore=None, num_epoch=5, optimizer='sgd')\n Dataset avazu-app not present. Downloading now ...\n Dataset avazu-app is now present.\n Dataset avazu-app.t not present. Downloading now ...\n Dataset avazu-app.t is now present.\n 2018-10-10 00:04:17,542 Training started ...\n /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/module/module.py:854: UserWarning: Parameters are not updated in the KVStore. No need to call sparse_row_id_fn.\n   warnings.warn(UserWarning(\"Parameters are not updated in the KVStore. \"\n 2018-10-10 00:04:18,666 Epoch[0] Batch [100]\tSpeed: 768263.29 samples/sec\tnll-loss=0.636536\n 2018-10-10 00:04:19,727 Epoch[0] Batch [200]\tSpeed: 771779.48 samples/sec\tnll-loss=0.589219\n ...\n </denchmark-code>\n \n Note : This example does not work with python3 due to an incompatible urllib library issue. module 'urllib' has no attribute 'urlretrieve'  . But this works in Python 2.\n \n I fixed the broken link issue in this PR : <denchmark-link:https://github.com/apache/incubator-mxnet/pull/12774>#12774</denchmark-link>\n \n The rest of the README works fine. Though, running the CTC example is really slow!\n Please try at your end as well on the latest version of MXNet and let me know if you still experience some issues running these examples.\n Thanks!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "luobao-intel", "commentT": "2018-10-10T16:33:41Z", "comment_text": "\n \t\tThanks for taking a look at the other examples <denchmark-link:https://github.com/piyushghai>@piyushghai</denchmark-link>\n \n <denchmark-link:https://github.com/luobao-intel>@luobao-intel</denchmark-link>\n  could you please close the issue if your query has been resolved?\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "luobao-intel", "commentT": "2018-10-15T18:24:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/luobao-intel>@luobao-intel</denchmark-link>\n  could you please close the issue or comment on what is still not working as expected? Thanks!\n \t\t"}}}, "commit": {"commit_id": "c0cd583cf92a3e47dd3b6c4bd67e64a3c12bf057", "commit_author": "Piyush Ghai", "commitT": "2018-10-10 09:29:31-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "example\\speech_recognition\\README.md", "file_new_name": "example\\speech_recognition\\README.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "31", "deleted_lines": "31"}}}}}}