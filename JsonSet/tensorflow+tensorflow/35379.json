{"BR": {"BR_id": "35379", "BR_author": "bearsroom", "BRopenT": "2019-12-24T06:21:18Z", "BRcloseT": "2019-12-27T01:59:40Z", "BR_text": {"BRsummary": "Cannot export keras model to SavedModel if mixed-precision policy is enabled", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9\n TensorFlow installed from (source or binary): binary\n TensorFlow version (use command below): starting from 2.0, nightly version tested\n Python version: 3.5\n \n Describe the current behavior\n When keras mixed-precision policy \"mixed_float16\" is in use, we can't save the keras model in SavedModel format with method keras.models.Model.save without a specific signatures. It seems like a mismatch between input signature inferred by the model itself and the auto-casted inputs:\n <denchmark-code>ValueError: Python inputs incompatible with input_signature: inputs ((<tf.Tensor 'conv1_pad/Cast:0' shape=(None, 224, 224, 3) dtype=float16>,)), input_signature ((TensorSpec(shape=(None, None, None, None), dtype=tf.float32, name=None),))\n </denchmark-code>\n \n Although we can use graph_rewrite as mixed-precision training method to bypass this autocasting issue, but graph_rewrite is not working in some cases (e.g. train a subclassed model with tf.GradientTape) thus it is not recommended by tensorflow official guide. For flexibility we do hope to use mixed-precision policy in mixed-precision training, and directly exporting mixed-precision trained model to SavedModel for deployment is straightforward in production pipeline.\n Code to reproduce the issue\n We can reproduce this bug by using the official image classification training example from <denchmark-link:https://github.com/tensorflow/models/tree/master/official/vision/image_classification>https://github.com/tensorflow/models/tree/master/official/vision/image_classification</denchmark-link>\n \n <denchmark-code>\"\"\"\n Test mixed-precision policy model saving\n \"\"\"\n import logging\n import os\n \n from absl import app as absl_app\n import tensorflow as tf\n \n from official.vision.image_classification.resnet_model import resnet50\n \n \n def main(argv):\n   tf.compat.v1.enable_eager_execution()\n   \n   # setup mixed-precision policy\n   # the policy enables the autocasting behavior in keras layers\n   policy = tf.keras.mixed_precision.experimental.Policy(\n         'mixed_float16', loss_scale=128)\n   tf.keras.mixed_precision.experimental.set_policy(policy)\n \n   model = resnet50(1000)\n   model_dir = 'temp/saved_model_test'\n \n   if not os.path.isdir(model_dir):\n     os.makedirs(model_dir)\n   model.save(model_dir,\n              save_format='tf')\n   logging.info('Exported trained model to directory {}'.format(\n       model_dir))\n \n \n if __name__ == '__main__':\n   absl_app.run(main)\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "bearsroom", "commentT": "2019-12-24T06:24:41Z", "comment_text": "\n \t\tGently ping <denchmark-link:https://github.com/reedwm>@reedwm</denchmark-link>\n ; does this look familiar to you?\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "bearsroom", "commentT": "2019-12-26T06:33:51Z", "comment_text": "\n \t\tWhen tried replicating the issue, I got the error as per the colab <denchmark-link:https://colab.sandbox.google.com/gist/oanush/1cc1d54c6411da3cdc2d5009b59775b1/35379.ipynb>gist</denchmark-link>\n .Thanks!\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "bearsroom", "commentT": "2019-12-27T00:23:03Z", "comment_text": "\n \t\tThank you for filing this and the short example to reproduce. I will have a fix soon. In the future, I plan on testing the official models with SavedModel to ensure issues like this do not occur in the future.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "bearsroom", "commentT": "2019-12-27T01:59:42Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35379>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35379>No</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "bearsroom", "commentT": "2019-12-27T05:05:51Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/reedwm>@reedwm</denchmark-link>\n  thanks for the prompt fix!\n <denchmark-link:https://github.com/goldiegadde>@goldiegadde</denchmark-link>\n  shall we apply the fix above to r2.1? Mixed precision along with XLA improves training performance dramatically and we\u2019d really like to use it with our e2e training/inference pipeline.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "bearsroom", "commentT": "2020-01-22T19:42:15Z", "comment_text": "\n \t\tIs this working for anyone? I updated to 2.1 and I no longer get this same error but now I get\n TypeError: Input 'filter' of 'Conv2D' Op has type float16 that does not match type float32 of argument 'input'.\n I tried this first on my models and then ran the given snippet and got the same deal.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "bearsroom", "commentT": "2020-01-22T21:48:56Z", "comment_text": "\n \t\tUnfortunately the fix did not make it into 2.1 :(. It will be in 2.2 however, and the fix is already in tf-nightly\n I'm not sure why the error message is different. Note that Model.save_weights still works, just not Model.save.\n As a workaround, you can call , rebuild the model in fp32, call  on the fp32 model then call . But understandably, this is very irritating, and it doesn't save a mixed precision model. Using the old <denchmark-link:https://www.tensorflow.org/api_docs/python/tf/train/experimental/enable_mixed_precision_graph_rewrite>tf.train.experimental.enable_mixed_precision_graph_rewrite</denchmark-link>\n  API also works but note we plan on deprecating then removing it (it will remain in  for a long time though).\n \t\t"}}}, "commit": {"commit_id": "cd6184047e9e497955c473b88387b54818ff23a0", "commit_author": "Reed Wanderman-Milne", "commitT": "2019-12-26 17:58:07-08:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\keras\\mixed_precision\\experimental\\keras_test.py", "file_new_name": "tensorflow\\python\\keras\\mixed_precision\\experimental\\keras_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "498", "deleted_lines": null, "method_info": {"method_name": "test_model", "method_params": "self,strategy_fn,use_operator,use_regularizer,policy_name,get_config,save_format,use_input_spec,experimental_run_tf_function", "method_startline": "491", "method_endline": "499"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tensorflow\\python\\keras\\mixed_precision\\experimental\\test_util.py", "file_new_name": "tensorflow\\python\\keras\\mixed_precision\\experimental\\test_util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "127", "deleted_lines": "127", "method_info": {"method_name": "assert_input_types", "method_params": "self,inputs", "method_startline": "120", "method_endline": "127"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py", "file_new_name": "tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "368", "deleted_lines": "368", "method_info": {"method_name": "_generate_input_signature.to_tensor_spec_or_none", "method_params": "x", "method_startline": "367", "method_endline": "375"}}, "hunk_1": {"Ismethod": 1, "added_lines": "368", "deleted_lines": "368", "method_info": {"method_name": "_generate_input_signature", "method_params": "self,layer", "method_startline": "349", "method_endline": "381"}}}}}}}