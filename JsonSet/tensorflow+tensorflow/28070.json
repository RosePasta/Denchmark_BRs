{"BR": {"BR_id": "28070", "BR_author": "jiarenyf", "BRopenT": "2019-04-23T09:48:26Z", "BRcloseT": "2019-04-27T00:29:23Z", "BR_text": {"BRsummary": "tf2.0a0 tf.nn.ctc_loss with AttributeError: Tensor.op is meaningless when eager execution is enabled.", "BRdescription": "\n System information\n \n Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\n OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04/16.04\n Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\n TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.0.0-alpha\n TensorFlow version (use command below): 2.0.0-alpha0 / v1.12.0-9492-g2c319fb\n Python version: 3.7.0\n Bazel version (if compiling from source):\n GCC/Compiler version (if compiling from source):\n CUDA/cuDNN version: 10.0/fogotten\n GPU model and memory:\n \n Code to reproduce the issue\n Provide a reproducible test case that is the bare minimum necessary to generate the problem.\n When running: python loss.py, error raised, see the error.txt for details. Maybe there is some internal implementation error on the function namely tf.nn.ctc_loss...\n 1. helper.py\n <denchmark-code># Author: Jiarenyf ...\n # pylint: disable=invalid-name\n # pylint: disable=too-many-locals\n # pylint: disable=missing-docstring\n # pylint: disable=redefined-outer-name\n \n import tensorflow as tf\n \n #########################################\n \n \n def dense_to_sparse(tensor, eos_token):\n     eos_token = tf.constant(eos_token, tensor.dtype)\n     indices = tf.where(tf.not_equal(tensor, eos_token))\n \n     values = tf.gather_nd(tensor, indices)\n     shape = tf.shape(tensor, out_type=tf.int64)\n     return tf.SparseTensor(indices, values, shape)\n \n </denchmark-code>\n \n 2. loss.py\n <denchmark-code># Author: Jiarenyf ...\n # pylint: disable=invalid-name\n # pylint: disable=too-many-locals\n # pylint: disable=missing-docstring\n # pylint: disable=redefined-outer-name\n \n import tensorflow as tf\n from helper import dense_to_sparse\n \n #########################################\n \n \n def ctc_loss(label, logit, label_len, logit_len, classes):\n     prediction_sparse = tf.cast(tf.nn.ctc_greedy_decoder(\n         logit, logit_len, merge_repeated=True)[0][0], tf.int32)\n     prediction = tf.sparse.to_dense(prediction_sparse, classes)\n \n     label_sparse = dense_to_sparse(label, classes)\n     accuracy = 1.0 - tf.edit_distance(\n         prediction_sparse, label_sparse, normalize=True)\n     loss = tf.nn.ctc_loss(\n         label, logit, label_len, logit_len, blank_index=classes)\n \n     return loss, accuracy, prediction\n \n \n #########################################\n \n \n LOSS_DICT = {\n     'ctc': ctc_loss,\n }\n \n \n #########################################\n \n if __name__ == '__main__':\n     frames = 8\n     classes = 20\n     batch_size = 16\n     label_len = tf.ones(batch_size, tf.int32)\n     label = tf.ones((batch_size, 5), tf.int32)\n     logit_len = tf.zeros(batch_size, tf.int32)\n     logit = tf.zeros((frames, batch_size, classes+1))\n     print(ctc_loss(label, logit, label_len, logit_len, classes+1))\n \n </denchmark-code>\n \n 3. error.txt\n <denchmark-code>Traceback (most recent call last):\n   File \"loss.py\", line 45, in <module>\n     print(ctc_loss(label, logit, label_len, logit_len, classes+1))\n   File \"loss.py\", line 22, in ctc_loss\n     label, logit, label_len, logit_len, blank_index=classes)\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/ops/ctc_ops.py\", line 672, in ctc_loss_v2\n     name=name)\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/ops/ctc_ops.py\", line 784, in ctc_loss_dense\n     return compute_ctc_loss(*args)[0]\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/framework/function.py\", line 520, in __call__\n     ret, op = _call(self._signature, *args, **kwargs)\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/framework/function.py\", line 1022, in _call\n     compute_shapes=False)\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n     return func(*args, **kwargs)\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3466, in create_op\n     input_ops = set([t.op for t in inputs])\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3466, in <listcomp>\n     input_ops = set([t.op for t in inputs])\n   File \"/home/jiarenyf/miniconda3/envs/tensorflow_2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 934, in op\n     \"Tensor.op is meaningless when eager execution is enabled.\")\n AttributeError: Tensor.op is meaningless when eager execution is enabled.\n \n </denchmark-code>\n \n Other info / logs\n Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jiarenyf", "commentT": "2019-04-23T09:52:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/shashvatshahi1998>@shashvatshahi1998</denchmark-link>\n  <denchmark-link:https://github.com/gadagashwini>@gadagashwini</denchmark-link>\n  <denchmark-link:https://github.com/ebrevdo>@ebrevdo</denchmark-link>\n \n Could you please help me, thank you.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jiarenyf", "commentT": "2019-04-23T10:32:38Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jiarenyf>@jiarenyf</denchmark-link>\n  refer to this issue <denchmark-link:https://github.com/tensorflow/tensorflow/issues/27739>#27739</denchmark-link>\n  for further updates as your code is showing same Attribute error.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jiarenyf", "commentT": "2019-04-24T04:03:42Z", "comment_text": "\n \t\tI found that changing the tf.nn.ctc_loss to tf.compat.v1.nn.ctc_loss is ok, but when would the error in 2.0.0-alpha being fixed...\n <denchmark-code># Author: Jiarenyf ...\n # pylint: disable=invalid-name\n # pylint: disable=too-many-locals\n # pylint: disable=missing-docstring\n # pylint: disable=redefined-outer-name\n \n import tensorflow as tf\n from helper import dense_to_sparse\n \n #########################################\n \n \n def ctc_loss(label, logit, label_len, logit_len, classes):\n     prediction_sparse = tf.cast(tf.nn.ctc_greedy_decoder(\n         logit, logit_len, merge_repeated=True)[0][0], tf.int32)\n     prediction = tf.sparse.to_dense(prediction_sparse, classes)\n \n     label_sparse = dense_to_sparse(label, classes)\n     accuracy = 1.0 - tf.edit_distance(\n         prediction_sparse, label_sparse, normalize=True)\n     loss = tf.compat.v1.nn.ctc_loss(label_sparse, logit, logit_len)\n     # loss = tf.nn.ctc_loss(\n     # label, logit, label_len, logit_len, blank_index=classes)\n \n     return loss, accuracy, prediction\n \n \n #########################################\n \n \n LOSS_DICT = {\n     'ctc': ctc_loss,\n }\n \n \n #########################################\n \n if __name__ == '__main__':\n     num = 5\n     frames = 9\n     classes = 20\n     batch_size = 16\n     label = tf.zeros((batch_size, num), tf.int32)\n     label_len = tf.ones(batch_size, tf.int32) * num\n     logit = tf.concat([\n         tf.ones((frames//num, batch_size, 1)),\n         tf.zeros((frames//num, batch_size, classes)),\n     ], axis=-1)\n     for i in range(num-1):\n         tmp1 = tf.concat([\n             tf.zeros((frames//num, batch_size, classes)),\n             tf.ones((frames//num, batch_size, 1)),\n         ], axis=-1)\n         tmp2 = tf.concat([\n             tf.ones((frames//num, batch_size, 1)),\n             tf.zeros((frames//num, batch_size, classes)),\n         ], axis=-1)\n         logit = tf.concat([logit, tmp1, tmp2], axis=0)\n \n     logit_len = tf.ones(batch_size, tf.int32) * frames\n     loss, accuracy, prediction = map(\n         lambda r: r.numpy(),\n         ctc_loss(label, logit, label_len, logit_len, classes+1))\n     for l, a, p in zip(loss, accuracy, prediction):\n         print(f\"Loss: {'%.3f'%l}; Accuracy: {a*100}%; Prediction: {p}\")\n \n </denchmark-code>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jiarenyf", "commentT": "2019-04-27T00:29:24Z", "comment_text": "\n \t\tAre you satisfied with the resolution of your issue?\n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28070>Yes</denchmark-link>\n \n <denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28070>No</denchmark-link>\n \n \t\t"}}}, "commit": {"commit_id": "778ca5c0bcf87c9e2df73fe9b8074bae5b8c3e58", "commit_author": "Alexandre Passos", "commitT": "2019-04-26 17:19:34-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\kernel_tests\\ctc_loss_op_test.py", "file_new_name": "tensorflow\\python\\kernel_tests\\ctc_loss_op_test.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "343,344,345", "deleted_lines": null, "method_info": {"method_name": "testCtcLossV2.assert_same_loss_and_grads", "method_params": "loss", "method_startline": "342", "method_endline": "349"}}, "hunk_1": {"Ismethod": 1, "added_lines": "331,332,333,334,335,336,337,338,343,344,345", "deleted_lines": "329,330,331,332,333,334,339", "method_info": {"method_name": "testCtcLossV2", "method_params": "self", "method_startline": "311", "method_endline": "357"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "tensorflow\\python\\ops\\ctc_ops.py", "file_new_name": "tensorflow\\python\\ops\\ctc_ops.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "805,806,807,808", "deleted_lines": "805,807", "method_info": {"method_name": "grad", "method_params": "grad_loss", "method_startline": "805", "method_endline": "808"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1163,1164,1165,1166,1167,1168,1169,1170,1171", "deleted_lines": "1111,1118,1160,1161", "method_info": {"method_name": "_scan", "method_params": "fn,elems,initial,reverse,inclusive,final_only", "method_startline": "1063", "method_endline": "1173"}}}}}}}