{"BR": {"BR_id": "1791", "BR_author": "mgaido91", "BRopenT": "2020-03-06T16:27:03Z", "BRcloseT": "2020-03-10T18:51:18Z", "BR_text": {"BRsummary": "Sequence generation fails if the encoder outputs a sequence with lenght different from input", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n The problem is present when there is a model in which the encoder outputs a sequence having a length different from the input one. This is very common in speech processing models which contain convolutions reducing the size of the input.\n With such a model, the following command fails:\n <denchmark-code>python generate.py  $DATA_DIR \\\n     --gen-subset test \\\n     --path $MY_MODEL_PATH \\\n     --max-source-positions 2000 --max-target-positions 1000 \\\n     --task speech_recognition --user-dir examples/speech_recognition \\\n     --skip-invalid-size-inputs-valid-test\n </denchmark-code>\n \n with the following stacktrace:\n <denchmark-code>  File \".../fairseq/tasks/fairseq_task.py\", line 317, in inference_step\n     return generator.generate(models, sample, prefix_tokens=prefix_tokens)\n   File \".../python3.7/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n     return func(*args, **kwargs)\n   File \".../fairseq/sequence_generator.py\", line 92, in generate\n     return self._generate(model, sample, **kwargs)\n   File \".../python3.7/site-packages/torch/autograd/grad_mode.py\", line 49, in decorate_no_grad\n     return func(*args, **kwargs)\n   File .../fairseq/sequence_generator.py\", line 335, in _generate\n     attn[:, :, step + 1].copy_(avg_attn_scores)\n RuntimeError: The size of tensor a (1069) must match the size of tensor b (268) at non-singleton dimension 1\n </denchmark-code>\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n A very simple reproducer is provided as unit test in the PR related to this issue.\n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n The expected behavior is that the generation works fine without failures.\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n fairseq Version (e.g., 1.0 or master): master\n PyTorch Version (e.g., 1.0): 1.4\n OS (e.g., Linux): Linux\n How you installed fairseq (pip, source): source\n Build command you used (if compiling from source): pip install -e .\n Python version: 3.7\n CUDA/cuDNN version: 10.0\n GPU models and configuration: K80\n Any other relevant information:\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n In the failure described in the command above I am using an implementation of <denchmark-link:https://www.aclweb.org/anthology/W19-6603.pdf>https://www.aclweb.org/anthology/W19-6603.pdf</denchmark-link>\n .\n \t"}, "comments": {}}, "commit": {"commit_id": "431d604f696a15c06fceab56b4ace271bb85e74b", "commit_author": "Marco Gaido", "commitT": "2020-03-10 11:51:08-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "fairseq\\sequence_generator.py", "file_new_name": "fairseq\\sequence_generator.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "334", "deleted_lines": "334"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\test_sequence_generator.py", "file_new_name": "tests\\test_sequence_generator.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "141,142,143,144,145,146,147,148,149", "deleted_lines": null, "method_info": {"method_name": "test_encoder_with_different_output_len", "method_params": "self", "method_startline": "141", "method_endline": "149"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "tests\\utils.py", "file_new_name": "tests\\utils.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "252,253", "deleted_lines": null, "method_info": {"method_name": "reorder_encoder_out", "method_params": "self,encoder_out,new_order", "method_startline": "252", "method_endline": "253"}}, "hunk_1": {"Ismethod": 1, "added_lines": "239,240,241", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,args,dictionary", "method_startline": "239", "method_endline": "241"}}, "hunk_2": {"Ismethod": 1, "added_lines": "261,262,263,264", "deleted_lines": null, "method_info": {"method_name": "build_model", "method_params": "cls,args,task", "method_startline": "261", "method_endline": "264"}}, "hunk_3": {"Ismethod": 1, "added_lines": "257,258", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,encoder,decoder", "method_startline": "257", "method_endline": "258"}}, "hunk_4": {"Ismethod": 1, "added_lines": "243,244,245,246,247,248,249,250", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,src_tokens,src_lengths,kwargs", "method_startline": "243", "method_endline": "250"}}}}}}}