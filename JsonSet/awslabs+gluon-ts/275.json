{"BR": {"BR_id": "275", "BR_author": "rshyamsundar", "BRopenT": "2019-08-30T21:47:25Z", "BRcloseT": "2019-09-02T13:47:39Z", "BR_text": {"BRsummary": "Bug in loading quarterly and yearly time series data", "BRdescription": "\n <denchmark-h:h2>Description</denchmark-h>\n \n It looks like recent changes (<denchmark-link:https://github.com/awslabs/gluon-ts/pull/253>#253</denchmark-link>\n ) introduced a bug in loading yearly, quarterly data. The loaded train and test datasets have monthly frequency instead of yearly (\"12M\") or quarterly (\"3M\") frequency.\n This seems to be the culprit: <denchmark-link:https://github.com/awslabs/gluon-ts/blob/master/src/gluonts/dataset/common.py#L330>https://github.com/awslabs/gluon-ts/blob/master/src/gluonts/dataset/common.py#L330</denchmark-link>\n \n I actually came across this while doing evaluations for yearly data. Model trained with DeepAREstimator failed during evaluation with the following error. It shows the frequency here correctly in the error message since the estimator gets it from the metadata but the actual train and test datasets have wrong frequency.\n <denchmark-code>AssertionError: Cannot extract prediction target since the index of forecast is outside the index of target\n Index of forecast: DatetimeIndex(['1752-07-31', '1753-07-31', '1754-07-31', '1755-07-31',\n                '1756-07-31', '1757-07-31'],\n               dtype='datetime64[ns]', freq='12M')\n  Index of target: DatetimeIndex(['1749-12-31', '1750-12-31', '1751-12-31', '1752-12-31',\n                '1753-12-31', '1754-12-31', '1755-12-31', '1756-12-31',\n                '1757-12-31', '1758-12-31', '1759-12-31', '1760-12-31',\n                '1761-12-31', '1762-12-31', '1763-12-31', '1764-12-31',\n                '1765-12-31', '1766-12-31', '1767-12-31', '1768-12-31',\n                '1769-12-31', '1770-12-31', '1771-12-31', '1772-12-31',\n                '1773-12-31', '1774-12-31', '1775-12-31', '1776-12-31',\n                '1777-12-31', '1778-12-31', '1779-12-31', '1780-12-31',\n                '1781-12-31', '1782-12-31', '1783-12-31', '1784-12-31',\n                '1785-12-31'],\n               dtype='datetime64[ns]', freq='12M')\n </denchmark-code>\n \n <denchmark-h:h2>To Reproduce</denchmark-h>\n \n <denchmark-code>In [1]: import gluonts                                                                                                                                                                                              \n \n In [2]: from gluonts.dataset.repository.datasets import get_dataset                                                                                                                                                 \n \n In [3]: dataset = get_dataset(\"m4_yearly\", regenerate=False)                                                                                                                                                        \n \n In [4]: next(iter(dataset.test))['start']                                                                                                                                                                           \n Out[4]: Timestamp('1749-12-31 00:00:00', freq='M')\n \n In [5]: dataset.metadata.freq\n Out[5]: '12M'\n \n In [6]: dataset = get_dataset(\"m4_quarterly\", regenerate=False)                                                                                                                                                     \n \n In [7]: next(iter(dataset.test))['start']                                                                                                                                                                           \n Out[7]: Timestamp('1749-12-31 00:00:00', freq='M')\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "rshyamsundar", "commentT": "2019-08-30T22:31:09Z", "comment_text": "\n \t\tSince  field had wrong frequency <denchmark-link:https://github.com/awslabs/gluon-ts/blob/master/src/gluonts/transform.py#L1081>Forecast start date was wrongly set here</denchmark-link>\n  by shifting 31 months instead of  instead of 31 years in case of m4_yearly data. This explains why the forecast index started at 1752-07-31 as shown in the error message instead of 1780-12-31.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "rshyamsundar", "commentT": "2019-08-31T04:28:35Z", "comment_text": "\n \t\tIt's not clear why ProcessStartField.process needs to have all that logic: we could use some documentation explaining why simply doing\n return pd.Timestamp(string, freq=freq)\n is not sufficient\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "rshyamsundar", "commentT": "2019-08-31T11:10:07Z", "comment_text": "\n \t\tAFAIK, we do this processing, to align all timestamps within the same period.\n E.g. all timestamps in August 2019 should to 2019-08-31:\n In [32]: to_offset(\"M\").rollback(pd.Timestamp.now())\n Out[32]: Timestamp('2019-08-31 12:57:48.139117')\n As we can see, rollback doesn't affect the time information, that's why we call replace on it to reset these values:\n In [34]: _32.replace(hour=0, minute=0, second=0, microsecond=0, nanosecond=0)\n Out[34]: Timestamp('2019-08-31 00:00:00')\n <denchmark-h:hr></denchmark-h>\n \n That being said, I think 12M still only aligns the data on a monthly bases and not a yearly one:\n In [48]: to_offset(\"12M\").rollback(pd.Timestamp.now())\n Out[48]: Timestamp('2019-08-31 13:09:39.763214')\n vs\n In [49]: to_offset(\"Y\").rollback(pd.Timestamp.now())\n Out[49]: Timestamp('2018-12-31 13:09:59.602807')\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "rshyamsundar", "commentT": "2019-08-31T11:48:08Z", "comment_text": "\n \t\t\n It's not clear why ProcessStartField.process needs to have all that logic: we could use some documentation explaining why simply doing\n return pd.Timestamp(string, freq=freq)\n is not sufficient\n \n I've tried running the tests with your suggestion and the only tests failing are the ones, which explicitly test for the alignment. Maybe <denchmark-link:https://github.com/vafl>@vafl</denchmark-link>\n  can tell us more, why we need to align the timestamps?\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "rshyamsundar", "commentT": "2019-08-31T13:56:51Z", "comment_text": "\n \t\tThe main reason for aligning the time stamps are the time dependent features. These are quite expensive to compute and so we cache the feature values for all time points in a feature matrix:\n \n \n \n gluon-ts/src/gluonts/transform.py\n \n \n          Line 840\n       in\n       4d044a2\n \n \n \n \n \n \n  def _update_cache(self, start: pd.Timestamp, length: int) -> None: \n \n \n \n \n \n When we add time features in the transformation, we do a lookup of the start time point and then just index into the feature matrix to return the corresponding part. This cache would not work if time points are not aligned with a regular grid.\n Maybe we can improve the alignment logic taking into account the multiple?\n \t\t"}}}, "commit": {"commit_id": "fb041e45038013cfc74fd2885e59cc82537e30be", "commit_author": "Jasper Schulz", "commitT": "2019-09-02 15:47:38+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "src\\gluonts\\dataset\\common.py", "file_new_name": "src\\gluonts\\dataset\\common.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "335,336,337,338,339,340", "deleted_lines": null, "method_info": {"method_name": "rollback", "method_params": "timestamp", "method_startline": "335", "method_endline": "340"}}, "hunk_1": {"Ismethod": 1, "added_lines": "314,315,318,319,320,322,324,325,326,327,328,331,332", "deleted_lines": "313,314,315,316,317,318,319,320,323,324,325,326,327,328,329,331", "method_info": {"method_name": "process", "method_params": "str,str", "method_startline": "313", "method_endline": "332"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "test\\dataset\\test_common.py", "file_new_name": "test\\dataset\\test_common.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "34", "deleted_lines": "33", "method_info": {"method_name": "test_process_start_field", "method_params": "freq,expected", "method_startline": "30", "method_endline": "34"}}}}}}}