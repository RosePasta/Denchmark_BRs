{"BR": {"BR_id": "1272", "BR_author": "laomaup", "BRopenT": "2020-11-03T09:48:02Z", "BRcloseT": "2020-11-20T10:23:37Z", "BR_text": {"BRsummary": "RuntimeError: No such operator torchvision::nms", "BRdescription": "\n Before submitting a bug report, please be aware that your issue must be reproducible with all of the following, otherwise it is non-actionable, and we can not help you:\n \n Current repo: run git fetch && git status -uno to check and git pull to update repo\n Common dataset: coco.yaml or coco128.yaml\n Common environment: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov5#environments\n \n If this is a custom dataset/training question you must include your train*.jpg, test*.jpg and results.png figures, or we can not help you. You can generate these with utils.plot_results().\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n A clear and concise description of what the bug is.\n Starting training for 30 epochs...\n <denchmark-code> Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n   0/29    0.799G   0.07891   0.03296   0.06775    0.1796         2       640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 218/218 [00:51<00:00,  4.22it/s]\n            Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0%|                   | 0/19 [00:00<?, ?it/s]\n </denchmark-code>\n \n Traceback (most recent call last):\n File \"train.py\", line 482, in \n train(hyp, opt, device, tb_writer, wandb)\n File \"train.py\", line 318, in train\n results, maps, times = test.test(opt.data,\n File \"/workspace/yolov5/test.py\", line 125, in test\n output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n File \"/workspace/yolov5/utils/general.py\", line 661, in non_max_suppression\n i = torch.ops.torchvision.nms(boxes, scores, iou_thres)\n File \"/root/anaconda3/envs/yolo5/lib/python3.8/site-packages/torch/_ops.py\", line 61, in getattr\n op = torch._C._jit_get_operation(qualified_op_name)\n RuntimeError: No such operator torchvision::nms\n <denchmark-h:h2>To Reproduce (REQUIRED)</denchmark-h>\n \n Input:\n <denchmark-code>python train.py --img 640 --batch 8 --epochs 30 --data ./data/handpose.yaml --cfg ./models/yolov5s.yaml --weights '' --device 0,1\n Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11177MB)\n            device1 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11178MB)\n \n Namespace(adam=False, batch_size=8, bucket='', cache_images=False, cfg='./models/yolov5s.yaml', data='./data/handpose.yaml', device='0,1', epochs=30, evolve=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_imgs=10, logdir='runs/', multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, sync_bn=False, total_batch_size=8, weights='', workers=8, world_size=1)\n Start Tensorboard with \"tensorboard --logdir runs/\", view at http://localhost:6006/\n Install Weights & Biases for experiment logging via 'pip install wandb' (recommended)\n Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n Overriding model.yaml nc=80 with nc=13\n \n                  from  n    params  module                                  arguments                     \n   0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n   1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n   2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n   3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n   4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n   5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n   6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n   7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n   8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n   9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n  10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n  11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n  12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n  13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n  14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n  15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n  16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n  17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n  18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n  19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n  20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n  21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n  22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n  23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n  24      [17, 20, 23]  1     48546  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n Model Summary: 191 layers, 7.28746e+06 parameters, 7.28746e+06 gradients\n \n Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n Scanning images:   0%|                                                                                              | 0/1738 [00:00<?, ?it/s]WARNING: Ignoring corrupted image and/or label /workspace/yolov5/data/images/chen_7.jpg: setting an array element with a sequence.\n Scanning images: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1738/1738 [00:00<00:00, 6555.56it/s]\n Scanning labels /workspace/yolov5/data/labels.cache (1071 found, 0 missing, 0 empty, 0 duplicate, for 1737 images): 1071it [00:00, 10703.55itScanning labels /workspace/yolov5/data/labels.cache (1737 found, 0 missing, 0 empty, 0 duplicate, for 1737 images): 1737it [00:00, 10807.05it/s]\n Scanning images: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 145/145 [00:00<00:00, 5554.81it/s]\n Scanning labels /workspace/yolov5/data/labels.cache (145 found, 0 missing, 0 empty, 0 duplicate, for 145 images): 145it [00:00, 8856.99it/s]\n \n Analyzing anchors... anchors/target = 5.27, Best Possible Recall (BPR) = 1.0000\n Image sizes 640 train, 640 test\n Using 8 dataloader workers\n \n </denchmark-code>\n \n Output:\n Starting training for 30 epochs...\n <denchmark-code> Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n   0/29    0.799G   0.07891   0.03296   0.06775    0.1796         2       640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 218/218 [00:51<00:00,  4.22it/s]\n            Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0%|                   | 0/19 [00:00<?, ?it/s]\n </denchmark-code>\n \n Traceback (most recent call last):\n File \"train.py\", line 482, in \n train(hyp, opt, device, tb_writer, wandb)\n File \"train.py\", line 318, in train\n results, maps, times = test.test(opt.data,\n File \"/workspace/yolov5/test.py\", line 125, in test\n output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)\n File \"/workspace/yolov5/utils/general.py\", line 661, in non_max_suppression\n i = torch.ops.torchvision.nms(boxes, scores, iou_thres)\n File \"/root/anaconda3/envs/yolo5/lib/python3.8/site-packages/torch/_ops.py\", line 61, in getattr\n op = torch._C._jit_get_operation(qualified_op_name)\n RuntimeError: No such operator torchvision::nms\n <denchmark-h:h2>Expected behavior</denchmark-h>\n \n A clear and concise description of what you expected to happen.\n <denchmark-h:h2>Environment</denchmark-h>\n \n If applicable, add screenshots to help explain your problem.\n \n OS: [e.g. Ubuntu18.04]\n GPU [e.g. 1080 Ti]\n CUDA [e.g. 10.1]\n python[e.g 3.8]\n \n <denchmark-h:h2>Additional context</denchmark-h>\n \n my conda Environment\n _libgcc_mutex             0.1                        main    defaults\n absl-py                   0.11.0                    \n ca-certificates           2020.10.14                    0    defaults\n cachetools                4.1.1                     \n certifi                   2020.6.20          pyhd3eb1b0_3    defaults\n chardet                   3.0.4                     \n cycler                    0.10.0                    \n Cython                    0.29.21                   \n dataclasses               0.6                       \n future                    0.18.2                    \n google-auth               1.23.0                    \n google-auth-oauthlib      0.4.2                     \n grpcio                    1.33.2                    \n idna                      2.10                      \n kiwisolver                1.3.1                     \n ld_impl_linux-64          2.33.1               h53a641e_7    defaults\n libedit                   3.1.20191231         h14c3975_1    defaults\n libffi                    3.3                  he6710b0_2    defaults\n libgcc-ng                 9.1.0                hdf63c60_0    defaults\n libstdcxx-ng              9.1.0                hdf63c60_0    defaults\n Markdown                  3.3.3                     \n matplotlib                3.3.2                     \n ncurses                   6.2                  he6710b0_1    defaults\n numpy                     1.19.4                    \n oauthlib                  3.1.0                     \n opencv-python             4.4.0.46                  \n openssl                   1.1.1h               h7b6447c_0    defaults\n Pillow                    8.0.1                     \n pip                       20.2.4                   py38_0    defaults\n protobuf                  3.13.0                    \n pyasn1                    0.4.8                     \n pyasn1-modules            0.2.8                     \n pyparsing                 2.4.7                     \n python                    3.8.5                h7579374_1    defaults\n python-dateutil           2.8.1                     \n PyYAML                    5.3.1                     \n readline                  8.0                  h7b6447c_0    defaults\n requests                  2.24.0                    \n requests-oauthlib         1.3.0                     \n rsa                       4.6                       \n scipy                     1.5.3                     \n setuptools                50.3.0           py38hb0f4dca_1    defaults\n six                       1.15.0                    \n sqlite                    3.33.0               h62c20be_0    defaults\n tensorboard               2.3.0                     \n tensorboard-plugin-wit    1.7.0                     \n tk                        8.6.10               hbc83047_0    defaults\n torch                     1.7.0+cu101               \n torchvision               0.8.1                     \n tqdm                      4.51.0                    \n typing-extensions         3.7.4.3                   \n urllib3                   1.25.11                   \n Werkzeug                  1.0.1                     \n wheel                     0.35.1                     py_0    defaults\n xz                        5.2.5                h7b6447c_0    defaults\n zlib                      1.2.11               h7b6447c_3    defaults\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "laomaup", "commentT": "2020-11-03T09:48:48Z", "comment_text": "\n \t\tHello <denchmark-link:https://github.com/laomaup>@laomaup</denchmark-link>\n , thank you for your interest in our work! Please visit our <denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data>Custom Training Tutorial</denchmark-link>\n  to get started, and see our <denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb>Jupyter Notebook</denchmark-link>\n  <denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb></denchmark-link>\n , <denchmark-link:https://hub.docker.com/r/ultralytics/yolov5>Docker Image</denchmark-link>\n , and <denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart>Google Cloud Quickstart Guide</denchmark-link>\n  for example environments.\n If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.\n If this is a custom model or data training question, please note Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:\n \n Cloud-based AI systems operating on hundreds of HD video streams in realtime.\n Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.\n Custom data training, hyperparameter evolution, and model exportation to any destination.\n \n For more information please visit <denchmark-link:https://www.ultralytics.com>https://www.ultralytics.com</denchmark-link>\n .\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "laomaup", "commentT": "2020-11-03T11:49:37Z", "comment_text": "\n \t\tIt appears you may have environment problems. Please ensure you meet all dependency requirements if you are attempting to run YOLOv5 locally.  If in doubt, create a new virtual Python 3.8 environment, clone the latest repo (code changes daily), and pip install -r requirements.txt again. We also highly recommend using one of our verified environments below.\n <denchmark-h:h2>Requirements</denchmark-h>\n \n  or later with all <denchmark-link:https://github.com/ultralytics/yolov5/blob/master/requirements.txt>requirements.txt</denchmark-link>\n  dependencies installed, including . To install run:\n $ pip install -r requirements.txt\n <denchmark-h:h2>Environments</denchmark-h>\n \n YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including <denchmark-link:https://developer.nvidia.com/cuda>CUDA</denchmark-link>\n /<denchmark-link:https://developer.nvidia.com/cudnn>CUDNN</denchmark-link>\n , <denchmark-link:https://www.python.org/>Python</denchmark-link>\n  and <denchmark-link:https://pytorch.org/>PyTorch</denchmark-link>\n  preinstalled):\n \n Google Colab Notebook with free GPU: \n Kaggle Notebook with free GPU: https://www.kaggle.com/ultralytics/yolov5\n Google Cloud Deep Learning VM. See GCP Quickstart Guide\n Docker Image https://hub.docker.com/r/ultralytics/yolov5. See Docker Quickstart Guide \n \n <denchmark-h:h2>Status</denchmark-h>\n \n <denchmark-link:https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg></denchmark-link>\n \n If this badge is green, all <denchmark-link:https://github.com/ultralytics/yolov5/actions>YOLOv5 GitHub Actions</denchmark-link>\n  Continuous Integration (CI) tests are passing. These tests evaluate proper operation of basic YOLOv5 functionality, including training (<denchmark-link:https://github.com/ultralytics/yolov5/blob/master/train.py>train.py</denchmark-link>\n ), testing (<denchmark-link:https://github.com/ultralytics/yolov5/blob/master/test.py>test.py</denchmark-link>\n ), inference (<denchmark-link:https://github.com/ultralytics/yolov5/blob/master/detect.py>detect.py</denchmark-link>\n ) and export (<denchmark-link:https://github.com/ultralytics/yolov5/blob/master/models/export.py>export.py</denchmark-link>\n ) on MacOS, Windows, and Ubuntu.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "laomaup", "commentT": "2020-11-03T11:54:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/laomaup>@laomaup</denchmark-link>\n  all seems fine according to your pip list, not sure what the problem may be. Perhaps start from a clean venv and try again. You might also try the Docker image failing that.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "laomaup", "commentT": "2020-11-04T01:25:21Z", "comment_text": "\n \t\tok, i will try,think you.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "laomaup", "commentT": "2020-11-20T09:41:24Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  I just came across this issue from <denchmark-link:https://github.com/pytorch/vision/issues/1405#issuecomment-731056137>pytorch/vision#1405 (comment)</denchmark-link>\n \n I would strongly recommend replacing \n \n \n yolov5/utils/general.py\n \n \n          Line 326\n       in\n       199c9c7\n \n \n \n \n \n \n  i = torch.ops.torchvision.nms(boxes, scores, iou_thres) \n \n \n \n \n  with\n torchvision.ops.nms, as in order for torch.ops.torchvision to be available, one first need to import torchvision to register NMS.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "laomaup", "commentT": "2020-11-20T09:52:02Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/fmassa>@fmassa</denchmark-link>\n  ah I see. Thanks for the advice, I will create a PR for this!\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "laomaup", "commentT": "2020-11-20T10:25:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/laomaup>@laomaup</denchmark-link>\n  I've pushed a PR per <denchmark-link:https://github.com/fmassa>@fmassa</denchmark-link>\n  recommendations. Please  and see if the problem is fixed.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "laomaup", "commentT": "2020-11-24T10:14:08Z", "comment_text": "\n \t\tit is work now\uff0cthink you.\n \n \n \n At 2020-11-20 17:41:40, \"Francisco Massa\" <notifications@github.com> wrote:\n \n <denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  I just came across this issue from <denchmark-link:https://github.com/pytorch/vision/issues/1405>pytorch/vision#1405</denchmark-link>\n  (comment)\n \n I would strongly recommend replacing <denchmark-link:https://github.com/ultralytics/yolov5/blob/199c9c787427ece5723d5309e1c7c524a99bc59d/utils/general.py#L326>https://github.com/ultralytics/yolov5/blob/199c9c787427ece5723d5309e1c7c524a99bc59d/utils/general.py#L326</denchmark-link>\n  with\n torchvision.ops.nms, as in order for torch.ops.torchvision to be available, one first need to import torchvision to register NMS.\n \n \u2014\n You are receiving this because you were mentioned.\n Reply to this email directly, view it on GitHub, or unsubscribe.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "laomaup", "commentT": "2020-11-24T10:24:27Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/laomaup>@laomaup</denchmark-link>\n  great, glad to hear its working!\n \t\t"}}}, "commit": {"commit_id": "394131c2aa66637177890a41654f75ceae61a0c8", "commit_author": "Glenn Jocher", "commitT": "2020-11-20 11:23:36+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "utils\\general.py", "file_new_name": "utils\\general.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "327", "deleted_lines": "326", "method_info": {"method_name": "non_max_suppression", "method_params": "prediction,conf_thres,iou_thres,merge,classes,agnostic", "method_startline": "266", "method_endline": "342"}}}}}}}