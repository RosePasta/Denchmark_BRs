{"BR": {"BR_id": "2205", "BR_author": "xiadingZ", "BRopenT": "2020-06-16T02:29:09Z", "BRcloseT": "2020-09-16T18:31:56Z", "BR_text": {"BRsummary": "[metrics] Accuracy Metric: Tensors must be CUDA and dense", "BRdescription": "\n I try the new Accuracy Metric, but it throws error:\n <denchmark-code>Traceback (most recent call last):\n   File \"main.py\", line 139, in <module>\n     main(hparams)\n   File \"main.py\", line 69, in main\n     trainer.fit(model)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 820, in fit\n     self.ddp_train(task, model)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py\", line 502, in ddp_train\n     self.run_pretrain_routine(model)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in run_pretrain_routine\n     False)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 278, in _evaluate\n     output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 418, in evaluation_forward\n     output = model(*args)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 558, in __call__\n     result = self.forward(*input, **kwargs)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\", line 96, in forward\n     output = self.module.validation_step(*inputs[0], **kwargs[0])\n   File \"/mnt/lustre/maxiao1/PVM/models/baseline.py\", line 374, in validation_step\n     acc = self.accuracy(labels_hat, labels)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/metric.py\", line 147, in __call__\n     return apply_to_collection(self._orig_call(*args, **kwargs), torch.Tensor,\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py\", line 59, in new_func\n     return func_to_apply(result, *dec_args, **dec_kwargs)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py\", line 26, in apply_to_collection\n     return function(data, *args, **kwargs)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py\", line 244, in _sync_ddp_if_available\n     async_op=False)\n   File \"/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py\", line 898, in all_reduce\n     work = _default_pg.allreduce([tensor], opts)\n RuntimeError: Tensors must be CUDA and dense\n </denchmark-code>\n \n This is my code:\n <denchmark-code>            pred = pred.view(-1, pred.shape[-1])\n             labels = labels.view(-1)\n             valid_index = torch.where(labels != -1)\n             # select valid part to calculate\n             pred = pred[valid_index].contiguous()\n             labels = labels[valid_index].contiguous()\n             loss = self.loss_fn(pred, labels)\n             labels_hat = torch.argmax(pred, dim=1).type_as(labels)\n             acc = self.accuracy(labels_hat, labels)\n </denchmark-code>\n \n Also have a question, TensorMetric's default reduce_op is SUM, does it automatically calculate average acc?\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:37:36Z", "comment_text": "\n \t\t1.) What are your devices for labels_hat and labels? Are you running in a DDP environment?\n 2.) No it doesn't. It does what it says (calculates the sum) unfortunately there is no DDP reduction  op that calculates the average. For averaging, you still need to divide by the size of your process group\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:47:34Z", "comment_text": "\n \t\tThis is my code:\n <denchmark-code>            imgs = batch['imgs']\n             labels = batch['labels']\n             result = self(imgs)\n \n             pred = result['total']\n             pred = pred.view(-1, pred.shape[-1])\n             labels = labels.view(-1)\n             valid_index = torch.where(labels != -1)\n             # select valid part to calculate\n             pred = pred[valid_index]\n             labels = labels[valid_index]\n             loss = self.loss_fn(pred, labels)\n             labels_hat = torch.argmax(pred, dim=1).type_as(labels)\n             acc = self.accuracy(labels_hat, labels)\n </denchmark-code>\n \n I'm running in DDP environment, I think labels be automatically transfered to one gpu device, and I use type_as to ensure labels_hat on same device as labels\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:51:39Z", "comment_text": "\n \t\tcan you try to call .contiguous() on the tensors before?\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:53:22Z", "comment_text": "\n \t\tI tried on labels and labels_hat, but it doesn't work\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:53:53Z", "comment_text": "\n \t\tdo you use sparse tensors?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:54:42Z", "comment_text": "\n \t\tNo\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "xiadingZ", "commentT": "2020-06-16T11:59:43Z", "comment_text": "\n \t\tAnd I think 2) should add some example in docs. Now code example  in docs is\n <denchmark-code># PyTorch Lightning\n class MyModule(LightningModule):\n     def __init__(self):\n         super().__init__()\n         self.metric = Accuracy()\n \n     def training_step(self, batch, batch_idx):\n         x, y = batch\n         y_hat = ...\n         acc = self.metric(y_hat, y)\n </denchmark-code>\n \n and it says can run in ddp mode, but it doesn't say we should divide by the size of process group by hand if using ddp\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "xiadingZ", "commentT": "2020-06-16T12:00:53Z", "comment_text": "\n \t\tBut it also does not state, that it calculates the mean. I will have a look how much work it is, to integrate this.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "xiadingZ", "commentT": "2020-09-01T18:02:47Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/xiadingZ>@xiadingZ</denchmark-link>\n  are you still facing the  error?\n Your second point, about dividing by result by process group can be achieved by setting the  argument to either  or  (solved by PR <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2568>#2568</denchmark-link>\n )\n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "xiadingZ", "commentT": "2020-09-16T18:31:56Z", "comment_text": "\n \t\tclosing this. please comment if this needs to be reopened.\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "xiadingZ", "commentT": "2020-10-03T21:23:33Z", "comment_text": "\n \t\t\n @xiadingZ are you still facing the RuntimeError: Tensors must be CUDA and dense error?\n \n I am running into this issue, using R2Score metric. Same traceback.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "xiadingZ", "commentT": "2020-10-05T13:11:47Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/wconnell>@wconnell</denchmark-link>\n  is am not able to reproduce on master using . Do you have an code example that can reproduce the error?\n \t\t"}}}, "commit": {"commit_id": "17d87731062691f4510c75f12f2ce63b5dde0a43", "commit_author": "Nicki Skafte", "commitT": "2020-08-26 13:01:29+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "12", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\core\\step_result.py", "file_new_name": "pytorch_lightning\\core\\step_result.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "23,127", "deleted_lines": "23,127"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 12, "file_old_name": "pytorch_lightning\\metrics\\converters.py", "file_new_name": "pytorch_lightning\\metrics\\converters.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "112", "deleted_lines": "110", "method_info": {"method_name": "_convert_to_numpy", "method_params": "Tensor,ndarray", "method_startline": "110", "method_endline": "126"}}, "hunk_1": {"Ismethod": 1, "added_lines": "89,95,96,102,105,107", "deleted_lines": "89,100,103,105", "method_info": {"method_name": "convert_to_tensor", "method_params": "Any,dtype,device", "method_startline": "89", "method_endline": "109"}}, "hunk_2": {"Ismethod": 1, "added_lines": "89,95,96,102,105,107", "deleted_lines": "89,100,103,105", "method_info": {"method_name": "_convert_to_tensor", "method_params": "Any", "method_startline": "89", "method_endline": "107"}}, "hunk_3": {"Ismethod": 1, "added_lines": "112", "deleted_lines": null, "method_info": {"method_name": "convert_to_numpy", "method_params": "Tensor,ndarray", "method_startline": "112", "method_endline": "128"}}, "hunk_4": {"Ismethod": 1, "added_lines": "331", "deleted_lines": null, "method_info": {"method_name": "decorator_fn", "method_params": "func_to_decorate", "method_startline": "329", "method_endline": "332"}}, "hunk_5": {"Ismethod": 1, "added_lines": "243,244,245,246", "deleted_lines": "243,244", "method_info": {"method_name": "sync_ddp_if_available", "method_params": "None,None", "method_startline": "243", "method_endline": "246"}}, "hunk_6": {"Ismethod": 1, "added_lines": "283,284", "deleted_lines": null, "method_info": {"method_name": "gather_all_tensors_if_available", "method_params": "None", "method_startline": "283", "method_endline": "284"}}, "hunk_7": {"Ismethod": 1, "added_lines": "155", "deleted_lines": "153", "method_info": {"method_name": "_tensor_metric_output_conversion", "method_params": "Callable", "method_startline": "145", "method_endline": "155"}}, "hunk_8": {"Ismethod": 1, "added_lines": "203", "deleted_lines": "201", "method_info": {"method_name": "_tensor_collection_metric_output_conversion", "method_params": "Callable", "method_startline": "192", "method_endline": "203"}}, "hunk_9": {"Ismethod": 1, "added_lines": "142", "deleted_lines": "140", "method_info": {"method_name": "_numpy_metric_input_conversion", "method_params": "Callable", "method_startline": "131", "method_endline": "142"}}, "hunk_10": {"Ismethod": 1, "added_lines": "243,244", "deleted_lines": "241,242,243,244", "method_info": {"method_name": "_sync_ddp_if_available", "method_params": "None,None", "method_startline": "241", "method_endline": "244"}}, "hunk_11": {"Ismethod": 1, "added_lines": "189", "deleted_lines": "187", "method_info": {"method_name": "_tensor_metric_input_conversion", "method_params": "Callable", "method_startline": "178", "method_endline": "189"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "pytorch_lightning\\metrics\\functional\\classification.py", "file_new_name": "pytorch_lightning\\metrics\\functional\\classification.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "307", "deleted_lines": "307"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 9, "file_old_name": "pytorch_lightning\\metrics\\metric.py", "file_new_name": "pytorch_lightning\\metrics\\metric.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "140,141,142,143,144,145,146,147,148,149,150,151,152", "deleted_lines": "150,151,152", "method_info": {"method_name": "compute", "method_params": "self,Any,Any", "method_startline": "140", "method_endline": "152"}}, "hunk_1": {"Ismethod": 1, "added_lines": "72,73,74,75,76,77,78,79,80,81,82", "deleted_lines": "77,78,80,81,82", "method_info": {"method_name": "input_convert", "method_params": "self,Any", "method_startline": "72", "method_endline": "82"}}, "hunk_2": {"Ismethod": 1, "added_lines": "61,62,63,64,65,66,67,68,69", "deleted_lines": null, "method_info": {"method_name": "__init__", "method_params": "self,str", "method_startline": "53", "method_endline": "69"}}, "hunk_3": {"Ismethod": 1, "added_lines": "110,111,112,113,114,115,116,117,118,119,120,121,122", "deleted_lines": "118,119,121,122", "method_info": {"method_name": "ddp_sync", "method_params": "self,Any,Any", "method_startline": "110", "method_endline": "122"}}, "hunk_4": {"Ismethod": 1, "added_lines": "85,90", "deleted_lines": "85", "method_info": {"method_name": "forward", "method_params": "self,args,kwargs", "method_startline": "85", "method_endline": "93"}}, "hunk_5": {"Ismethod": 1, "added_lines": "96,97,98,99,100,101,102,103,104,105,106,107", "deleted_lines": null, "method_info": {"method_name": "output_convert", "method_params": "self,Any,Any", "method_startline": "96", "method_endline": "107"}}, "hunk_6": {"Ismethod": 1, "added_lines": "81,82", "deleted_lines": "81,82", "method_info": {"method_name": "__call__._to_device_dtype", "method_params": "Tensor", "method_startline": "81", "method_endline": "82"}}, "hunk_7": {"Ismethod": 1, "added_lines": "80,81,82,85", "deleted_lines": "80,81,82,84,85", "method_info": {"method_name": "__call__", "method_params": "self,args,kwargs", "method_startline": "80", "method_endline": "85"}}, "hunk_8": {"Ismethod": 1, "added_lines": "125,126,127,128,129,130,131,132,133,134,135,136,137", "deleted_lines": "125,126", "method_info": {"method_name": "aggregate", "method_params": "self,Any,Any", "method_startline": "125", "method_endline": "137"}}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\base\\model_train_steps.py", "file_new_name": "tests\\base\\model_train_steps.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194", "deleted_lines": null, "method_info": {"method_name": "training_step__using_metrics", "method_params": "self,batch,batch_idx,optimizer_idx", "method_startline": "179", "method_endline": "194"}}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\metrics\\test_classification.py", "file_new_name": "tests\\metrics\\test_classification.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": null, "deleted_lines": "48", "method_info": {"method_name": "test_confusion_matrix", "method_params": "normalize", "method_startline": "42", "method_endline": "50"}}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 4, "file_old_name": "tests\\metrics\\test_converters.py", "file_new_name": "tests\\metrics\\test_converters.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "66", "deleted_lines": "66", "method_info": {"method_name": "test_convert_to_tensor", "method_params": "", "method_startline": "64", "method_endline": "68"}}, "hunk_1": {"Ismethod": 1, "added_lines": "126,131", "deleted_lines": "126,131", "method_info": {"method_name": "_ddp_test_fn", "method_params": "rank,worldsize,bool,reduction_mean", "method_startline": "119", "method_endline": "134"}}, "hunk_2": {"Ismethod": 1, "added_lines": "73", "deleted_lines": "73", "method_info": {"method_name": "test_convert_to_numpy", "method_params": "", "method_startline": "71", "method_endline": "75"}}, "hunk_3": {"Ismethod": 1, "added_lines": "161", "deleted_lines": "161", "method_info": {"method_name": "test_sync_reduce_simple", "method_params": "", "method_startline": "157", "method_endline": "164"}}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\metrics\\test_metrics.py", "file_new_name": "tests\\metrics\\test_metrics.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "174,175,176,177,178,179,180,181,182,183,184,185,186,187,188", "deleted_lines": null, "method_info": {"method_name": "test_saving_pickable", "method_params": "tmpdir,Metric", "method_startline": "174", "method_endline": "188"}}, "hunk_1": {"Ismethod": 1, "added_lines": "150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170", "deleted_lines": null, "method_info": {"method_name": "test_model_pickable", "method_params": "tmpdir,Metric", "method_startline": "150", "method_endline": "170"}}, "hunk_2": {"Ismethod": 1, "added_lines": "19", "deleted_lines": null, "method_info": {"method_name": "forward", "method_params": "self,input1,input2", "method_startline": "16", "method_endline": "19"}}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\metrics\\test_sklearn.py", "file_new_name": "tests\\metrics\\test_sklearn.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "166,173,176", "deleted_lines": "166,173,176", "method_info": {"method_name": "test_sklearn_metric", "method_params": "metric_class,sklearn_func,inputs", "method_startline": "165", "method_endline": "179"}}}}}}}