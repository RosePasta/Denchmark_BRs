{"BR": {"BR_id": "3424", "BR_author": "GimmickNG", "BRopenT": "2020-09-09T16:18:23Z", "BRcloseT": "2020-10-01T08:33:13Z", "BR_text": {"BRsummary": "DataModule with lr_find not supported", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Create a Trainer (trainer), a LightningModule (model) and a DataModule (data_module)\n Call trainer.lr_find(model, datamodule=data_module)\n Error: TypeError: lr_find() got an unexpected keyword argument 'datamodule'\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n <denchmark-code>import torch\n import torch.nn as nn\n import pytorch_lightning as pl\n from torch.utils.data import DataLoader\n class DataModule(pl.LightningDataModule):\n     def __init__(self):\n         super().__init__()\n     def gen_set(self, start, end):\n         vals = torch.tensor([float(i) for i in range(0, 800)])\n         return torch.stack([torch.sin(vals), torch.cos(vals)], 1)\n     def train_dataloader(self):\n         return DataLoader(dataset=self.gen_set(0, 800))\n     def val_dataloader(self):\n         return DataLoader(dataset=self.gen_set(800, 900))\n     def test_dataloader(self):\n         return DataLoader(dataset=self.gen_set(900, 1000))\n \n class LitModel(pl.LightningModule):\n     def __init__(self, in_features):\n         super().__init__()\n         self.in_layer = nn.Linear(in_features, in_features//2)\n         self.out_layer = nn.Linear(in_features//2, in_features)\n         self.criterion = nn.MSELoss()\n         self.lr = 0.001\n     def forward(self, inp):\n         inp = torch.tanh(self.in_layer(inp))\n         return self.out_layer(inp)\n     def training_step(self, batch, batch_idx):\n         x = batch\n         y_hat = self(x)\n         loss = self.criterion(y_hat, x.float())\n         return pl.TrainResult(minimize=loss)\n     def configure_optimizers(self):\n         return torch.optim.Adam(self.parameters(), lr=(self.lr or self.learning_rate))\n     \n data_module = DataModule()\n trainer = pl.Trainer()\n model = LitModel(in_features=2)\n lr_finder = trainer.lr_find(model, datamodule=data_module)   #error\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n The lr_find() function should work as if it were passed a train_loader and test_loader when invoking it, just like fit()\n <denchmark-h:h3>Environment</denchmark-h>\n \n \n Packages:\n \n numpy:             1.18.5\n pyTorch_debug:     False\n pyTorch_version:   1.5.1\n pytorch-lightning: 0.9.0\n tensorboard:       2.2.0\n tqdm:              4.45.0\n \n \n System:\n \n OS:                Linux\n architecture:\n \n 64bit\n \n \n processor:         x86_64\n python:            3.7.6\n \n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "GimmickNG", "commentT": "2020-09-09T16:19:18Z", "comment_text": "\n \t\tHi! thanks for your contribution!, great first issue!\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "GimmickNG", "commentT": "2020-09-10T17:13:45Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/nateraw>@nateraw</denchmark-link>\n  take a look?\n \t\t"}}}, "commit": {"commit_id": "e4e60e9b82adc48482db4721ce3e1fdc3ab6d6fe", "commit_author": "GimmickNG", "commitT": "2020-10-01 10:33:12+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "30,31", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\tuner\\lr_finder.py", "file_new_name": "pytorch_lightning\\tuner\\lr_finder.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "76", "deleted_lines": null, "method_info": {"method_name": "lr_find", "method_params": "trainer,LightningModule,None,DataLoader,None,float,float,int,str,float,None", "method_startline": "66", "method_endline": "76"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\tuner\\tuning.py", "file_new_name": "pytorch_lightning\\tuner\\tuning.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "54", "deleted_lines": null, "method_info": {"method_name": "lr_find", "method_params": "self,LightningModule,None,DataLoader,None,float,float,int,str,float,None", "method_startline": "44", "method_endline": "54"}}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "tests\\trainer\\test_lr_finder.py", "file_new_name": "tests\\trainer\\test_lr_finder.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177", "deleted_lines": null, "method_info": {"method_name": "test_datamodule_parameter", "method_params": "tmpdir", "method_startline": "156", "method_endline": "177"}}}}}}}