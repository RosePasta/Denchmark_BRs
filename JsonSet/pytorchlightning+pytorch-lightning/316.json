{"BR": {"BR_id": "316", "BR_author": "ceyzaguirre4", "BRopenT": "2019-10-06T03:39:34Z", "BRcloseT": "2019-10-08T21:33:34Z", "BR_text": {"BRsummary": "Custom logger (LightningLoggerBase) doesn't call log_hyperparams and log_metrics receives empty metrics dict", "BRdescription": "\n Describe the bug\n Custom logger (LightningLoggerBase) doesn't call log_hyperparams and log_metrics receives empty metrics dict.\n To Reproduce\n from pytorch_lightning.logging import LightningLoggerBase, rank_zero_only\n \n class CustomLogger(LightningLoggerBase):\n     def __init__(self, *args, **kwargs):\n         super(CustomLogger, self).__init__()\n         print(\"--\"*30)\n         print(\"it does at least initialize\")\n \n     @rank_zero_only\n     def log_hyperparams(self, params):\n         print(\"--\"*30)\n         print(\"this will never be printed\")\n \n     @rank_zero_only\n     def log_metrics(self, metrics, step_num):\n         print(\"--\"*30)\n         print(\"the following will be an empty dict {}\")\n         print(metrics)\n \n custom_logger = CustomLogger()\n trainer = Trainer(\n         logger=custom_logger,\n         max_nb_epochs=10\n     )\n \n trainer.fit(model)\n Desktop (please complete the following information):\n \n OS: MacOS 10.13.6\n pytorch-lightning version 0.5.1\n \n I should add that model is defined correctly\n     \n def validation_step(self, batch, batch_nb):\n     \"\"\"some processing\"\"\"\n     return {\n         'val_corrects': corrects(y, y_pred).item(),\n         'val_ponder_costs': torch.mean(ponder_cost).item(),\n         'val_steps': torch.mean(steps).item(),\n     }\n \n def validation_end(self, outputs):\n     n = 0\n     all_corrects = 0\n     ponder_costs = 0\n     acc_steps = 0\n \n     for output in outputs:\n         all_corrects += output['val_corrects']\n         ponder_costs += output['val_ponder_costs']\n         acc_steps += output['val_steps']\n \n     avgs = (elem / len(outputs) for elem in (all_corrects, ponder_costs, acc_steps))\n     \n     return {\n             'val_corrects': all_corrects / len(outputs),\n             'val_ponder_costs': ponder_costs / len(outputs),\n             'val_steps': acc_steps / len(outputs),\n         }\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "ceyzaguirre4", "commentT": "2019-10-06T16:21:15Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/neggert>@neggert</denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "ceyzaguirre4", "commentT": "2019-10-07T00:30:49Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ceyzaguirre4>@ceyzaguirre4</denchmark-link>\n  install the latest version and try again? i pushed a fix\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "ceyzaguirre4", "commentT": "2019-10-08T02:30:19Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/williamFalcon>@williamFalcon</denchmark-link>\n  The last update fixed the arguments passed to , however, the loggers and  methods are still never called.\n (on 0.5.13)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "ceyzaguirre4", "commentT": "2019-10-08T11:43:06Z", "comment_text": "\n \t\tGot it, <denchmark-link:https://github.com/neggert>@neggert</denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "ceyzaguirre4", "commentT": "2019-10-08T17:22:35Z", "comment_text": "\n \t\tTaking a look\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "ceyzaguirre4", "commentT": "2019-10-08T17:43:37Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/ceyzaguirre4>@ceyzaguirre4</denchmark-link>\n  I can reproduce  not being called, but  seems fine.\n Are your hyperparameters stored as an  in ?\n Here's the test I wrote. It makes it through up to the assert on logger.finalized.\n def test_custom_logger():\n \n     class CustomLogger(LightningLoggerBase):\n         def __init__(self):\n             super().__init__()\n             self.hparams_logged = None\n             self.metrics_logged = None\n             self.finalized = False\n \n         @rank_zero_only\n         def log_hyperparams(self, params):\n             self.hparams_logged = params\n \n         @rank_zero_only\n         def log_metrics(self, metrics, step_num):\n             self.metrics_logged = metrics\n         \n         @rank_zero_only\n         def finalize(self):\n             self.finalized = True\n \n     hparams = get_hparams()\n     model = LightningTestModel(hparams)\n \n     logger = CustomLogger()\n \n     trainer_options = dict(\n         max_nb_epochs=1,\n         train_percent_check=0.01,\n         logger=logger\n     )\n \n     trainer = Trainer(**trainer_options)\n     result = trainer.fit(model)\n     assert result == 1, \"Training failed\"\n     assert logger.hparams_logged == hparams\n     assert logger.metrics_logged != {}\n     assert logger.finalized\n \t\t"}}}, "commit": {"commit_id": "8088052825276b72b650b67fd169b8f92b91401f", "commit_author": "Nic Eggert", "commitT": "2019-10-08 17:33:33-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\logging\\mlflow_logger.py", "file_new_name": "pytorch_lightning\\logging\\mlflow_logger.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "56,57", "deleted_lines": null, "method_info": {"method_name": "finalize", "method_params": "self,status", "method_startline": "55", "method_endline": "58"}}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pytorch_lightning\\trainer\\trainer.py", "file_new_name": "pytorch_lightning\\trainer\\trainer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "1075,1076", "deleted_lines": null, "method_info": {"method_name": "__train", "method_params": "self", "method_startline": "1032", "method_endline": "1076"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 5, "file_old_name": "tests\\test_logging.py", "file_new_name": "tests\\test_logging.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "141,142,143,144,145", "deleted_lines": null, "method_info": {"method_name": "test_custom_logger.__init__", "method_params": "self", "method_startline": "141", "method_endline": "145"}}, "hunk_1": {"Ismethod": 1, "added_lines": "138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175", "deleted_lines": null, "method_info": {"method_name": "test_custom_logger", "method_params": "", "method_startline": "138", "method_endline": "175"}}, "hunk_2": {"Ismethod": 1, "added_lines": "156,157", "deleted_lines": null, "method_info": {"method_name": "test_custom_logger.finalize", "method_params": "self,status", "method_startline": "156", "method_endline": "157"}}, "hunk_3": {"Ismethod": 1, "added_lines": "152,153", "deleted_lines": null, "method_info": {"method_name": "test_custom_logger.log_metrics", "method_params": "self,metrics,step_num", "method_startline": "152", "method_endline": "153"}}, "hunk_4": {"Ismethod": 1, "added_lines": "148,149", "deleted_lines": null, "method_info": {"method_name": "test_custom_logger.log_hyperparams", "method_params": "self,params", "method_startline": "148", "method_endline": "149"}}}}}}}