{"BR": {"BR_id": "2429", "BR_author": "Uroc327", "BRopenT": "2020-06-30T13:58:35Z", "BRcloseT": "2020-07-01T11:53:20Z", "BR_text": {"BRsummary": "Batched iterative dataloading disables validation", "BRdescription": "\n <denchmark-h:h2>\ud83d\udc1b Bug</denchmark-h>\n \n Setting the batch_size parameter for torch.utils.data.DataLoader to a number greater than 1, prevents validation_step and validation_epoch_end from being called.\n <denchmark-h:h3>To Reproduce</denchmark-h>\n \n Steps to reproduce the behavior:\n \n Run python main.py with bs = 1\n Observe exception raised in validation_step\n Run python main.py after changing to bs = 2\n Observe the model train successfully\n \n <denchmark-h:h4>Code sample</denchmark-h>\n \n import pytorch_lightning as pl\n import torch\n import torch.nn as nn\n import torch.nn.functional as F\n from torch.utils.data import DataLoader, IterableDataset\n \n class Dataset(IterableDataset):\n     def __init__(self):\n         super().__init__()\n \n     def __iter__(self):\n         for _ in range(1024):\n             yield torch.randn(20)\n \n     def __len__(self):\n         return 1024\n \n class Model(pl.LightningModule):\n     def __init__(self):\n         super().__init__()\n         self.fst = nn.Linear(20, 1)\n         self.snd = nn.Linear(1, 20)\n \n     def forward(self, x):\n         x = self.fst(x)\n         x = F.relu(x)\n         x = self.snd(x)\n         return x\n \n     def training_step(self, batch, batchIdx):\n         x = self.forward(batch)\n         return {'loss': F.mse_loss(x, batch)}\n \n     def validation_step(self, batch, batchIdx):\n         raise NotImplementedError()\n         x = self.forward(batch)\n         return {'val_loss': F.mse_loss(x, batch)}\n \n     def validation_epoch_end(self, outputs):\n         return {'val_loss': torch.mean(torch.stack([x['val_loss'] for x in outputs]))}\n \n     def configure_optimizers(self):\n         return torch.optim.AdamW(self.parameters())\n \n if __name__ == '__main__':\n     trainer = pl.Trainer(num_sanity_val_steps=0)\n     net = Model()\n     dataset = Dataset()\n \n     bs = 2\n     trainer.fit(net, train_dataloader=DataLoader(dataset, batch_size=bs), val_dataloaders=DataLoader(dataset, batch_size=bs))\n <denchmark-code>> python main.py # with bs=2, should fail\n GPU available: True, used: False\n TPU available: False, using: 0 TPU cores\n \n   | Name | Type   | Params\n --------------------------------\n 0 | fst  | Linear | 21    \n 1 | snd  | Linear | 40    \n /home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n   warnings.warn(*args, **kwargs)\n /home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n   warnings.warn(*args, **kwargs)\n Epoch 1000:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                                                                                                                                     | 512/2048 [00:00<00:01, 1396.66it/s, loss=0.890, v_num=20]\n </denchmark-code>\n \n <denchmark-h:h3>Expected behavior</denchmark-h>\n \n <denchmark-code>> python main.py # with bs=1\n GPU available: True, used: False\n TPU available: False, using: 0 TPU cores\n \n   | Name | Type   | Params\n --------------------------------\n 0 | fst  | Linear | 21    \n 1 | snd  | Linear | 40    \n /home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n   warnings.warn(*args, **kwargs)\n /home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n   warnings.warn(*args, **kwargs)\n Epoch 1:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588Traceback (most recent call last):\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                                                                          | 1024/2048 [00:00<00:00, 1337.66it/s, loss=1.032, v_num=19]\n   File \"main.py\", line 57, in <module>\n     trainer.fit(net, train_dataloader=DataLoader(dataset, batch_size=bs), val_dataloaders=DataLoader(dataset, batch_size=bs))\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 954, in fit\n     self.run_pretrain_routine(model)\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1093, in run_pretrain_routine\n     self.train()\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 375, in train\n     self.run_training_epoch()\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\", line 490, in run_training_epoch\n     self.run_evaluation(test_mode=self.testing)\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 379, in run_evaluation\n     eval_results = self._evaluate(self.model, dataloaders, max_batches, test_mode)\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 281, in _evaluate\n     output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 452, in evaluation_forward\n     output = model.validation_step(*args)\n   File \"main.py\", line 39, in validation_step\n     raise NotImplementedError()\n NotImplementedError\n Exception ignored in: <object repr() failed>\n Traceback (most recent call last):\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/tqdm/std.py\", line 1086, in __del__\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/tqdm/std.py\", line 1293, in close\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/tqdm/std.py\", line 1471, in display\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/tqdm/std.py\", line 1089, in __repr__\n   File \"/home/constantin/.virtualenvs/tensor/lib64/python3.6/site-packages/tqdm/std.py\", line 1433, in format_dict\n TypeError: 'NoneType' object is not iterable\n </denchmark-code>\n \n <denchmark-h:h3>Environment</denchmark-h>\n \n <denchmark-code>Collecting environment information...\n PyTorch version: 1.5.1+cu101\n Is debug build: No\n CUDA used to build PyTorch: 10.1\n \n OS: Gentoo Base System release 2.7\n GCC version: (Gentoo 9.3.0 p1) 9.3.0\n CMake version: version 3.17.3\n \n Python version: 3.6\n Is CUDA available: Yes\n CUDA runtime version: 10.1.243\n GPU models and configuration: GPU 0: GeForce GT 730\n Nvidia driver version: 440.82\n cuDNN version: /opt/cuda/targets/x86_64-linux/lib/libcudnn.so.7.6.5\n \n Versions of relevant libraries:\n [pip3] numpy==1.19.0\n [pip3] pytorch-lightning==0.8.1\n [pip3] torch==1.5.1+cu101\n [pip3] torchvision==0.6.1+cu101\n [conda] Could not collect\n </denchmark-code>\n \n <denchmark-h:h3>Additional context</denchmark-h>\n \n Basically a reopen of <denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2351>#2351</denchmark-link>\n , as this issue is not fixed by changing batch size and dataset size.\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Uroc327", "commentT": "2020-06-30T14:06:39Z", "comment_text": "\n \t\tSame behavior with pytorch-lightning==0.8.3.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Uroc327", "commentT": "2020-06-30T22:18:57Z", "comment_text": "\n \t\tI can reproduce. It is caused by pl.Trainer(num_sanity_val_steps=0)\n For num_sanity_val_steps>0 it works fine\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "Uroc327", "commentT": "2020-06-30T22:49:11Z", "comment_text": "\n \t\ttrying to fix his right now. another observation: only happens with iterable dataset.\n EDIT: iterable dataset that has also length defined (see comment below)\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "Uroc327", "commentT": "2020-07-01T00:42:43Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/awaelchli>@awaelchli</denchmark-link>\n   thanks for looking into this! If I remember correctly, then for  it only raised the exception during sanity checks on my machine. When I try to raise the exception only in actual training (for example by raising the exception on the fourth time  is called), then this completes sucessfully (i.e. does not call validation) as well.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "Uroc327", "commentT": "2020-07-01T01:09:28Z", "comment_text": "\n \t\tI think the issue is that your dataset is of type Iterable but has  defined. PL interprets that wrongly. In fact, there is a weird issue with dataloaders from iterable datasets that have len defined, check out this colab that I made:\n <denchmark-link:https://colab.research.google.com/drive/1RQyNLGORe4vOL_RS6khcFNObcxyFxtEm?usp=sharing>https://colab.research.google.com/drive/1RQyNLGORe4vOL_RS6khcFNObcxyFxtEm?usp=sharing</denchmark-link>\n \n isn't it strange?\n if I remove the len from the dataset definition, your code sample works.\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "Uroc327", "commentT": "2020-07-01T13:00:04Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Uroc327>@Uroc327</denchmark-link>\n  fyi, it turned out there is no bug, but rather a technical thing with iterable datasets. We deciced to add a warning message when IterableDataset defines also length.\n In your case you have the following options:\n \n remove __len__ from your IterableDataset (this is the preferred option you want 99.9%)\n convert it to a regular torch.utils.data.Dataset\n keep the batch size 1 (not great)\n write a custom BatchSampler (I guess, I have not tried it)\n \n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "Uroc327", "commentT": "2020-07-01T20:50:21Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/awaelchli>@awaelchli</denchmark-link>\n  Ok, thanks! I'll remove the  implementation.\n Btw, the pytorch docs for <denchmark-link:https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>DataLoader</denchmark-link>\n  explicitly allow an  with a .\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "Uroc327", "commentT": "2020-07-01T20:59:26Z", "comment_text": "\n \t\tYep! However as the docs say in the note at the bottom of your link the user has to to their own batching to avoid duplicate data. That's why I added the warning to PL.\n Note that for example in your case, leaving it as is len(dataloader) would always return 1024 as the length, regardless of the batch size. That would be incorrect for batch size > 1.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "Uroc327", "commentT": "2020-07-01T21:02:16Z", "comment_text": "\n \t\tMakes sense, thank you \ud83d\ude04\n \t\t"}}}, "commit": {"commit_id": "927f305f7e556828b5cdd45e3977c67f3c54b8fc", "commit_author": "Adrian W\u00e4lchli", "commitT": "2020-07-01 07:53:19-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "CHANGELOG.md", "file_new_name": "CHANGELOG.md", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "13,14", "deleted_lines": null}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "pytorch_lightning\\trainer\\data_loading.py", "file_new_name": "pytorch_lightning\\trainer\\data_loading.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "148,149", "deleted_lines": null, "method_info": {"method_name": "auto_add_sampler", "method_params": "self,DataLoader,bool", "method_startline": "144", "method_endline": "167"}}, "hunk_1": {"Ismethod": 1, "added_lines": "46,47,48", "deleted_lines": "46", "method_info": {"method_name": "_has_iterable_dataset", "method_params": "DataLoader", "method_startline": "46", "method_endline": "48"}}, "hunk_2": {"Ismethod": 1, "added_lines": "53,54,60,62,64,65,66,67,68,69,70,71,72", "deleted_lines": "52,54,56", "method_info": {"method_name": "_has_len", "method_params": "DataLoader", "method_startline": "51", "method_endline": "72"}}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "requirements\\base.txt", "file_new_name": "requirements\\base.txt", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 3, "file_old_name": "tests\\trainer\\test_dataloaders.py", "file_new_name": "tests\\trainer\\test_dataloaders.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "506,507", "deleted_lines": null, "method_info": {"method_name": "test_warning_with_iterable_dataset_and_len.__len__", "method_params": "self", "method_startline": "506", "method_endline": "507"}}, "hunk_1": {"Ismethod": 1, "added_lines": "503,504", "deleted_lines": null, "method_info": {"method_name": "test_warning_with_iterable_dataset_and_len.__iter__", "method_params": "self", "method_startline": "503", "method_endline": "504"}}, "hunk_2": {"Ismethod": 1, "added_lines": "496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519", "deleted_lines": null, "method_info": {"method_name": "test_warning_with_iterable_dataset_and_len", "method_params": "tmpdir", "method_startline": "496", "method_endline": "519"}}}}}}}