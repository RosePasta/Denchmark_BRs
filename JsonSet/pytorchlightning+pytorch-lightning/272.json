{"BR": {"BR_id": "272", "BR_author": "kvhooreb", "BRopenT": "2019-10-01T08:19:47Z", "BRcloseT": "2019-10-02T15:11:09Z", "BR_text": {"BRsummary": "Trainer track_grad_norm always results in 0", "BRdescription": "\n Describe the bug\n The Trainer has a flag track_grad_norm which allows us to log the gradient norms to Tensorboard. This flag is checked in the run_tng_epoch function after the training step and validation step. However, the training step (__run_tng_batch) calls model.optimizer_step(), which, in the default implementation, calls optimizer.zero_grad(). This results in the tracked gradient norms to be always zero.\n Moreover, there is an optional __run_evaluation call in the validatin_step. This results in a call to model.zero_grad(), which I assume will also result in zero gradient norms.\n To Reproduce\n Steps to reproduce the behavior:\n \n Train a model with the track_grad_norm flag set to True and Tensorboard logging enabled\n Go to Tensorboard\n Check the gradient_norms\n \n Expected behavior\n The gradient norms should not always be zero.\n Desktop (please complete the following information):\n \n OS: Windows\n Version 0.4.9\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "kvhooreb", "commentT": "2019-10-01T08:29:55Z", "comment_text": "\n \t\tI temporarily worked around this by overwriting the  function of my LightningModule to not set the gradients to zero, and moved that to the  hook. However, it's clear that the validation runs also cause the gradients to be zero. See the image attached, where there is one validation batch every 5 training batches. The gradient clearly periodically drops to zero.\n <denchmark-link:https://user-images.githubusercontent.com/7951058/65946306-29132c00-e436-11e9-8c91-2522c4df7212.png></denchmark-link>\n \n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "kvhooreb", "commentT": "2019-10-01T10:14:16Z", "comment_text": "\n \t\tgood catch!\n \n evaluation does not calculate gradients, so the norms should be zero. the real solution is not to track grad norm during evaluation.\n  these lines, should be moved right before optimizer_step (this line).\n \n Would love a PR to fix if you have some time!\n \t\t"}}}, "commit": {"commit_id": "41236c7bbbe2a22714c19b625bdf557854d747e8", "commit_author": "kvhooreb", "commitT": "2019-10-02 11:11:08-04:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 2, "file_old_name": "pytorch_lightning\\trainer\\trainer.py", "file_new_name": "pytorch_lightning\\trainer\\trainer.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "995,1026", "deleted_lines": "995,1026,1027,1028,1029", "method_info": {"method_name": "run_training_epoch", "method_params": "self", "method_startline": "971", "method_endline": "1045"}}, "hunk_1": {"Ismethod": 1, "added_lines": "1178,1179,1180,1182,1190,1229,1230,1231,1232,1233,1234,1235,1260", "deleted_lines": "1182,1190,1253", "method_info": {"method_name": "__run_training_batch", "method_params": "self,batch,batch_nb", "method_startline": "1177", "method_endline": "1260"}}}}}}}