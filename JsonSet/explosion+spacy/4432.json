{"BR": {"BR_id": "4432", "BR_author": "DDouteaux", "BRopenT": "2019-10-11T12:29:04Z", "BRcloseT": "2019-12-10T12:23:28Z", "BR_text": {"BRsummary": "Memory leak with beam_parse method", "BRdescription": "\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n We are currently trying to obtain a confidence score for entities found with NER. In order to do so, we implement the solution that was suggested in these places :\n \n https://support.prodi.gy/t/displaying-a-confidence-score-next-to-a-user-defined-entity/403/7\n #881\n \n The code is performing well for the functionality, but unfortunately implies a memory leak, as suggested by <denchmark-link:https://github.com/usamec>@usamec</denchmark-link>\n  in the thread <denchmark-link:https://github.com/explosion/spaCy/issues/881>#881</denchmark-link>\n  . The first code was produced for SpaCy 2.0 and we first thought that it might have been corrected in newest releases, so we perform tests with version 2.2 but with same results.\n Here is the code used to highlight the memory leak :\n # Imports for SpaCy\n import spacy\n from spacy.tokens import Doc\n from spacy.pipeline import EntityRecognizer\n \n # Imports for debug\n import psutil\n import os\n import time\n \n # Imports for drawing\n import matplotlib.pyplot as plt\n \n # Miscellaneous\n from collections import defaultdict\n \n nlp = spacy.load(\"fr_core_news_md\")\n \n # Process a \"long\" text\n texts = [\"De deux choses l'une, ou le puits \u00e9tait vraiment bien profond, ou elle tombait bien doucement ; car elle eut tout le loisir, dans sa chute, de regarder autour d'elle et de se demander avec \u00e9tonnement ce qu'elle allait devenir. D'abord elle regarda dans le fond du trou pour savoir o\u00f9 elle allait ; mais il y faisait bien trop sombre pour y rien voir. Ensuite elle porta les yeux sur les parois du puits, et s'aper\u00e7ut qu'elles \u00e9taient garnies d'armoires et d'\u00e9tag\u00e8res ; \u00e7\u00e0 et l\u00e0, elle vit pendues \u00e0 des clous des cartes g\u00e9ographiques et des images. En passant elle prit sur un rayon un pot de confiture portant cette \u00e9tiquette, \u00ab MARMELADE D'ORANGES. \u00bb Mais, \u00e0 son grand regret, le pot \u00e9tait vide : elle n'osait le laisser tomber dans la crainte de tuer quelqu'un ; aussi s'arrangea-t-elle de mani\u00e8re \u00e0 le d\u00e9poser en passant dans une des armoires. \u00ab Certes, \u00bb dit Alice, \u00ab apr\u00e8s une chute pareille je ne me moquerai pas mal de d\u00e9gringoler l'escalier ! Comme ils vont me trouver brave chez nous ! Je tomberais du haut des toits que je ne ferais pas entendre une plainte. \u00bb (Ce qui \u00e9tait bien probable.) Tombe, tombe, tombe ! \u00ab Cette chute n'en finira donc pas ! Je suis curieuse de savoir combien de milles j'ai d\u00e9j\u00e0 faits, \u00bb dit-elle tout haut. \u00ab Je dois \u00eatre bien pr\u00e8s du centre de la terre. Voyons donc, cela serait \u00e0 quatre mille milles de profondeur, il me semble. \u00bb (Comme vous voyez, Alice avait appris pas mal de choses dans ses le\u00e7ons ; et bien que ce ne f\u00fbt pas l\u00e0 une tr\u00e8s-bonne occasion de faire parade de son savoir, vu qu'il n'y avait point d'auditeur, cependant c'\u00e9tait un bon exercice que de r\u00e9p\u00e9ter sa le\u00e7on.) \u00ab Oui, c'est bien \u00e0 peu pr\u00e8s cela ; mais alors \u00e0 quel degr\u00e9 de latitude ou de longitude est-ce que je me trouve ? \u00bb (Alice n'avait pas la moindre id\u00e9e de ce que voulait dire latitude ou longitude, mais ces grands mots lui paraissaient beaux et sonores.) Bient\u00f4t elle reprit : \u00ab Si j'allais traverser compl\u00e9tement la terre ? Comme \u00e7a serait dr\u00f4le de se trouver au milieu de gens qui marchent la t\u00eate en bas. Aux Antipathies, je crois. \u00bb (Elle n'\u00e9tait pas f\u00e2ch\u00e9e cette fois qu'il n'y e\u00fbt personne l\u00e0 pour l'entendre, car ce mot ne lui faisait pas l'effet d'\u00eatre bien juste.) \u00ab Eh mais, j'aurai \u00e0 leur demander le nom du pays. \u2014 Pardon, Madame, est-ce ici la Nouvelle-Zemble ou l'Australie ? \u00bb \u2014 En m\u00eame temps elle essaya de faire la r\u00e9v\u00e9rence. (Quelle id\u00e9e ! Faire la r\u00e9v\u00e9rence en l'air ! Dites-moi un peu, comment vous y prendriez-vous ?) \u00ab Quelle petite ignorante ! pensera la dame quand je lui ferai cette question. Non, il ne faut pas demander cela ; peut-\u00eatre le verrai-je \u00e9crit quelque part. \u00bb Tombe, tombe, tombe ! \u2014 Donc Alice, faute d'avoir rien de mieux \u00e0 faire, se remit \u00e0 se parler : \u00ab Dinah remarquera mon absence ce soir, bien s\u00fbr. \u00bb (Dinah c'\u00e9tait son chat.) \u00ab Pourvu qu'on n'oublie pas de lui donner sa jatte de lait \u00e0 l'heure du th\u00e9. Dinah, ma minette, que n'es-tu ici avec moi ? Il n'y a pas de souris dans les airs, j'en ai bien peur ; mais tu pourrais attraper une chauve-souris, et cela ressemble beaucoup \u00e0 une souris, tu sais. Mais les chats mangent-ils les chauves-souris ? \u00bb Ici le sommeil commen\u00e7a \u00e0 gagner Alice. Elle r\u00e9p\u00e9tait, \u00e0 moiti\u00e9 endormie : \u00ab Les chats mangent-ils les chauves-souris ? Les chats mangent-ils les chauves-souris ? \u00bb Et quelquefois : \u00ab Les chauves-souris mangent-elles les chats ? \u00bb Car vous comprenez bien que, puisqu'elle ne pouvait r\u00e9pondre ni \u00e0 l'une ni \u00e0 l'autre de ces questions, peu importait la mani\u00e8re de les poser. Elle s'assoupissait et commen\u00e7ait \u00e0 r\u00eaver qu'elle se promenait tenant Dinah par la main, lui disant tr\u00e8s-s\u00e9rieusement : \u00ab Voyons, Dinah, dis-moi la v\u00e9rit\u00e9, as-tu jamais mang\u00e9 des chauves-souris ? \u00bb Quand tout \u00e0 coup, pouf ! la voil\u00e0 \u00e9tendue sur un tas de fagots et de feuilles s\u00e8ches, \u2014 et elle a fini de tomber. Alice ne s'\u00e9tait pas fait le moindre mal. Vite elle se remet sur ses pieds et regarde en l'air ; mais tout est noir l\u00e0-haut. Elle voit devant elle un long passage et le Lapin Blanc qui court \u00e0 toutes jambes. Il n'y a pas un instant \u00e0 perdre ; Alice part comme le vent et arrive tout juste \u00e0 temps pour entendre le Lapin dire, tandis qu'il tourne le coin : \u00ab Par ma moustache et mes oreilles, comme il se fait tard ! \u00bb Elle n'en \u00e9tait plus qu'\u00e0 deux pas : mais le coin tourn\u00e9, le Lapin avait disparu. Elle se trouva alors dans une salle longue et basse, \u00e9clair\u00e9e par une rang\u00e9e de lampes pendues au plafond. Il y avait des portes tout autour de la salle : ces portes \u00e9taient toutes ferm\u00e9es, et, apr\u00e8s avoir vainement tent\u00e9 d'ouvrir celles du c\u00f4t\u00e9 droit, puis celles du c\u00f4t\u00e9 gauche, Alice se promena tristement au beau milieu de cette salle, se demandant comment elle en sortirait. Tout \u00e0 coup elle rencontra sur son passage une petite table \u00e0 trois pieds, en verre massif, et rien dessus qu'une toute petite clef d'or. Alice pensa aussit\u00f4t que ce pouvait \u00eatre celle d'une des portes ; mais h\u00e9las ! soit que les serrures fussent trop grandes, soit que la clef f\u00fbt trop petite, elle ne put toujours en ouvrir aucune. Cependant, ayant fait un second tour, elle aper\u00e7ut un rideau plac\u00e9 tr\u00e8s-bas et qu'elle n'avait pas vu d'abord ; par derri\u00e8re se trouvait encore une petite porte \u00e0 peu pr\u00e8s quinze pouces de haut ; elle essaya la petite clef d'or \u00e0 la serrure, et, \u00e0 sa grande joie, il se trouva qu'elle y allait \u00e0 merveille. Alice ouvrit la porte, et vit qu'elle conduisait dans un \u00e9troit passage \u00e0 peine plus large qu'un trou \u00e0 rat. Elle s'agenouilla, et, jetant les yeux le long du passage, d\u00e9couvrit le plus ravissant jardin du monde. Oh ! Qu'il lui tardait de sortir de cette salle t\u00e9n\u00e9breuse et d'errer au milieu de ces carr\u00e9s de fleurs brillantes, de ces fra\u00eeches fontaines ! Mais sa t\u00eate ne pouvait m\u00eame pas passer par la porte. \u00ab Et quand m\u00eame ma t\u00eate y passerait, \u00bb pensait Alice, \u00ab \u00e0 quoi cela servirait-il sans mes \u00e9paules ? Oh ! que je voudrais donc avoir la facult\u00e9 de me fermer comme un t\u00e9lescope ! \u00c7a se pourrait peut-\u00eatre, si je savais comment m'y prendre. \u00bb Il lui \u00e9tait d\u00e9j\u00e0 arriv\u00e9 tant de choses extraordinaires, qu'Alice commen\u00e7ait \u00e0 croire qu'il n'y en avait gu\u00e8re d'impossibles. Comme cela n'avan\u00e7ait \u00e0 rien de passer son temps \u00e0 attendre \u00e0 la petite porte, elle retourna vers la table, esp\u00e9rant presque y trouver une autre clef, ou tout au moins quelque grimoire donnant les r\u00e8gles \u00e0 suivre pour se fermer comme un t\u00e9lescope. Cette fois elle trouva sur la table une petite bouteille (qui certes n'\u00e9tait pas l\u00e0 tout \u00e0 l'heure). Au cou de cette petite bouteille \u00e9tait attach\u00e9e une \u00e9tiquette en papier, avec ces mots \u00ab BUVEZ-MOI \u00bb admirablement imprim\u00e9s en grosses lettres.\"]\n \n # Beam configuration\n beam_width = 16\n beam_density = 0.0001\n \n # For plots\n x = []\n y = []\n \n # Treat the document multiple times\n for i in range(0, 30):\n     x.append(i)\n     process = psutil.Process(os.getpid())\n     y.append(process.memory_info().rss / 1000000)\n \n     with nlp.disable_pipes('ner'):\n         docs = list(nlp.pipe(texts))\n     beams = nlp.entity.beam_parse(docs, beam_width=beam_width, beam_density=beam_density)\n \n     for doc, beam in zip(docs, beams):\n         entity_scores = defaultdict(float)\n         for score, ents in nlp.entity.moves.get_beam_parses(beam):\n             for start, end, label in ents:\n                 entity_scores[(start, end, label)] += score\n \n # Give time for gc to do its work if needed\n time.sleep(30)\n x.append(x[-1]+1)\n process = psutil.Process(os.getpid())\n y.append(process.memory_info().rss / 1000000)\n \n # Display memory usage evolution\n plt.plot(x, y)\n plt.show()\n The result is a linear curve with a 250 Mb increase of memory usage that is never released (see attachment). Tested with thousands of documents, we eventually crashed our server.\n <denchmark-link:https://user-images.githubusercontent.com/11420230/66651465-55e3f200-ec33-11e9-8e35-f6234683433b.PNG></denchmark-link>\n \n Another question comes with this bug :\n \n Is there another way of obtaining confidence score for NER entities ?\n \n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n Operating System:  Windows-10-10.0.17134-SP0 and CentOS 7 (when packaged)\n Python Version Used: 3.6.5\n spaCy Version Used: 2.2.1 and 2.0.18\n Environment Information: Windows environment is a dev environment. CentOS env is for deployment after we packaged the project. The first crash was produced on CentOS, and was reproduced on dev env after. The curve given above comes from a Windows environment.\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "DDouteaux", "commentT": "2019-10-11T13:02:46Z", "comment_text": "\n \t\tThanks for the report and test case! Have you also seen the discussion in <denchmark-link:https://github.com/explosion/spaCy/issues/3618>#3618</denchmark-link>\n ? I suspect this is the same bug.\n The current (obviously not very satisfactory) work-around is to periodically reload nlp(). See a few of the relevant comments:\n \n #3618 (comment)\n #3618 (comment)\n \n Hopefully we'll be able to track this down soon...\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "DDouteaux", "commentT": "2019-10-11T13:13:53Z", "comment_text": "\n \t\tThanks for your quick answer !\n I have already seen most of these posts, unfortunately :\n \n I can not work without NER, so disabling it could not be done.\n We already thought of reloading SpaCy model periodically. Hence, we restart our process every 10000 documents via an option of our webservice based on Gunicorn. Maybe we can lower this value, but then we fear to lose too many time waiting for models to be reloaded.\n Using a pool can be done but then remains the fact that we will have to reload the model too much time.\n \n For information, our current patch is to disable NER confidence computation, and we will re-wire it whenever a bug fix is released.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "DDouteaux", "commentT": "2019-10-20T07:14:56Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/honnibal>@honnibal</denchmark-link>\n : It might not be the whole story, but I think this is one spot with an obvious memory leak related to beam_parse:\n \n \n \n spaCy/spacy/syntax/transition_system.pyx\n \n \n         Lines 28 to 30\n       in\n       7772d5d\n \n \n \n \n \n \n  cdef void* _init_state(Pool mem, int length, void* tokens) except NULL: \n \n \n \n      cdef StateC* st = new StateC(<const TokenC*>tokens, length) \n \n \n \n  return <void*>st \n \n \n \n \n \n valgrind reports ~8MB lost per new StateC(), which is consistent with the 250MB / 30 iterations above.\n It's called here and never deleted:\n <denchmark-link:https://github.com/explosion/thinc/blob/732b7c0366fd349e8131b6786130b74ffe063ab1/thinc/extra/search.pyx#L83-L86>https://github.com/explosion/thinc/blob/732b7c0366fd349e8131b6786130b74ffe063ab1/thinc/extra/search.pyx#L83-L86</denchmark-link>\n \n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "DDouteaux", "commentT": "2019-10-21T06:16:57Z", "comment_text": "\n \t\tOkay, so this is a separate issue from <denchmark-link:https://github.com/explosion/spaCy/issues/3618>#3618</denchmark-link>\n  just related to  where the beam states aren't being freed correctly. As far as I can tell, a fix will require changes to both thinc and spacy, which makes this a little more complicated, but I hope we'll have something ready soon. A quick preview of the updated memory usage:\n <denchmark-link:https://user-images.githubusercontent.com/5794899/67180590-58381000-f3da-11e9-9948-737dcc1b3b34.png></denchmark-link>\n \n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "DDouteaux", "commentT": "2020-01-07T15:19:52Z", "comment_text": "\n \t\tHey, is this fix going to be relfected in the release of v2.2.4 or is it already in v2.2.3?\n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "DDouteaux", "commentT": "2020-01-23T13:13:50Z", "comment_text": "\n \t\tHi, this isn't in v2.2.3, sorry. It should be fixed in an upcoming release, but there isn't a concrete version number or release date set yet. If you need this in the meanwhile, you can compile the master branches from spacy and thinc from source, being sure to update the requirements first.\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "DDouteaux", "commentT": "2020-02-22T14:33:11Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "38e1bc19f4a1c28e27938f46bb3805df4919fedc", "commit_author": "adrianeboyd", "commitT": "2019-12-10 13:23:27+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\syntax\\_beam_utils.pyx", "file_new_name": "spacy\\syntax\\_beam_utils.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "72,73", "deleted_lines": "72"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\syntax\\arc_eager.pyx", "file_new_name": "spacy\\syntax\\arc_eager.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "327,328,329,330,331,336", "deleted_lines": null}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\syntax\\transition_system.pxd", "file_new_name": "spacy\\syntax\\transition_system.pxd", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "36,37,47", "deleted_lines": null}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\syntax\\transition_system.pyx", "file_new_name": "spacy\\syntax\\transition_system.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "33,34,35,36,37,52,81,82", "deleted_lines": "75"}}}}}}