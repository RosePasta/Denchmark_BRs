{"BR": {"BR_id": "2772", "BR_author": "christian-storm", "BRopenT": "2018-09-19T00:04:19Z", "BRcloseT": "2018-09-19T12:53:26Z", "BR_text": {"BRsummary": "parser not obeying is_sent_start == False (regression)", "BRdescription": "\n Not only is spacy nightly not obeying is_sent_start it also is producing a bad sentence segmentation.\n <denchmark-h:h2>How to reproduce the behaviour</denchmark-h>\n \n import spacy\n \n text = 'When we write or communicate virtually, we can hide our through feelings and many not become ourselves since we do not want the other party to judge us.'\n \n \n def sbd_component(doc):\n     doc[0].is_sent_start = True\n     for i, token in enumerate(doc[1:]):\n         # define sentence start after space token\n         if doc[i-1].is_space:\n             doc[i].is_sent_start = True\n         else:\n             doc[i].is_sent_start = False\n     return doc\n \n # Bad builtin sbd\n nlp = spacy.load('en_core_web_sm')\n doc = nlp(text)\n for i, sent in enumerate(doc.sents):\n     print(i, sent.text)\n \n # Spacy isn't honoring is_sent_start and producing the same poor sbd\n nlp.add_pipe(sbd_component, before='parser')  # insert before the parser\n doc = nlp(text)\n for i, sent in enumerate(doc.sents):\n     print(i, sent.text)\n I expected\n 1 When we write or communicate virtually, we can hide our through feelings and many not become ourselves since we do not want the other party to judge us.\n 1 When we write or communicate virtually, we can hide our through feelings and many not become ourselves since we do not want the other party to judge us.\n But get this instead\n 1 When\n 2 we write or communicate virtually, we can hide our through feelings and many not become ourselves since we do not want the other party to judge us\n 1 When\n 2 we write or communicate virtually, we can hide our through feelings and many not become ourselves since we do not want the other party to judge us\n When I run this on the binder (<denchmark-link:https://spacy.io/usage/processing-pipelines#component-example1>https://spacy.io/usage/processing-pipelines#component-example1</denchmark-link>\n ) it works as expected.\n <denchmark-h:h2>Your Environment</denchmark-h>\n \n \n spaCy version: 2.1.0a1\n Platform: Darwin-17.7.0-x86_64-i386-64bit\n Python version: 3.7.0\n Models: en_core_web_md, es_core_news_md, en_core_web_lg, en_core_web_sm\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "christian-storm", "commentT": "2018-09-19T11:20:36Z", "comment_text": "\n \t\tThanks, I've been chasing this bug for a while on develop. I think it's occurring in set_heads_from_children. The parse and sentence boundaries actually disagree here.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "christian-storm", "commentT": "2018-09-19T11:44:16Z", "comment_text": "\n \t\tThe issue arises when we have non-projective dependencies (aka crossing brackets). The parser is constrained to produce only projective trees, but there's a pre- and post- processing trick to make the parser predict non-projective analyses. After deprojectivisation, we run the set_children_from_heads routine, which was written with the assumption that the parse is projective --- but this assumption is no longer true, causing the error.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "christian-storm", "commentT": "2018-09-19T12:53:23Z", "comment_text": "\n \t\tThanks again for the test case. Fixed now! This had held up the experiments on the universal dependencies corpus, as there are many more non-projective parses there.\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "christian-storm", "commentT": "2018-10-19T13:09:51Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "1759abf1e5703cb568e0f2de56ed1beb0388a6f6", "commit_author": "Matthew Honnibal", "commitT": "2018-09-19 14:50:06+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tests\\regression\\test_issue2772.py", "file_new_name": "spacy\\tests\\regression\\test_issue2772.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": null, "deleted_lines": "5"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\tokens\\doc.pyx", "file_new_name": "spacy\\tokens\\doc.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017", "deleted_lines": "996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014"}}}}}}