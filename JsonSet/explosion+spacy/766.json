{"BR": {"BR_id": "766", "BR_author": "savkov", "BRopenT": "2017-01-22T13:34:09Z", "BRcloseT": "2017-02-24T13:33:05Z", "BR_text": {"BRsummary": "Possible index off by one in matches by the ZERO_PLUS operator", "BRdescription": "\n Hi,\n <denchmark-link:https://github.com/mbatchkarov>@mbatchkarov</denchmark-link>\n  and I found a bug in the matcher when using a  operator. There is also a possible inconsistency in the matches, which may or may not be true. Take a look at the following code example:\n from spacy.en import English\n from spacy.matcher import Matcher\n from spacy.attrs import ORTH\n \n nlp = English()\n \n matcher = Matcher(nlp.vocab)\n matcher.add_pattern('KleenePhilippe', [{ORTH: 'Philippe', 'OP': '+'}])\n \n doc = nlp('Philippe Philippe of Philippe.')\n \n m = matcher(doc)\n \n def print_matcher_output(m):\n     for ent_id, label, start, end in m:\n         print(str(doc[start:end]))\n \n print_matcher_output(m)\n Output:\n <denchmark-code>>>> Philippe Philippe of\n >>> Philippe of\n >>> Philippe.\n </denchmark-code>\n \n The obvious bug is related to the index that is passed to the list of matches. We are not sure if this is due to a faulty index passed by the matcher or by a faulty match. The fact that it matches any token after what is the match means it is probably a bad index.\n Apart from the index, it is not quite clear what the behaviour of the ZERO_PLUS operator should be. In the case above we see two interpretations:\n \n ['Philippe Philippe', 'Philippe'] to match a greedy matching behaviour (like re.findall('(P+)', 'PP of P')),\n ['Philippe', 'Philippe Philippe', 'Philippe', 'Philippe'] to produce all possible matches consistent with how matches from different rules behave.\n \n It is not clear what the logic of the current output is, so maybe it's just the manifestation of another bug.\n Here is another test case that doesn't work at all:\n matcher = Matcher(nlp.vocab)\n matcher.add_pattern('KleenePhilippe', [{ORTH: 'Philippe', 'OP':'+'}], label=321)\n \n doc = nlp('Philippe Philippe')\n \n m = matcher(doc)\n \n print(m)\n Output:\n <denchmark-code>[]\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "savkov", "commentT": "2017-02-24T13:32:52Z", "comment_text": "\n \t\tHi,\n Sorry for the delay getting to this. Two issues here:\n \n \n There was a bug in the matcher that meant that patterns ending with \"optional\" items that could be filled at the end of the string failed to match. I've fixed this (although the fix is a little under-tested, which makes me nervous)\n \n \n The '+' is implemented as a sequence of operators: ONE, ZERO_PLUS. The ZERO_PLUS operator isn't greedy, so you'd get a length-2 match. I agree this isn't great. I've exposed the ONE operator with the op string '1', to give better control of these things. It'd be nice to have a more satisfying system here.\n \n \n Matt\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "savkov", "commentT": "2018-05-09T02:38:55Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "8f94897d078122fecc2ba76f59a868cf4d979a9d", "commit_author": "Matthew Honnibal", "commitT": "2017-02-24 14:27:02+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "spacy\\matcher.pyx", "file_new_name": "spacy\\matcher.pyx", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "141,153,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436", "deleted_lines": "141,153"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "spacy\\tests\\matcher\\test_matcher.py", "file_new_name": "spacy\\tests\\matcher\\test_matcher.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "109,110,111,112,113,114,115,116,117,118,119,120,121,122,123", "deleted_lines": null, "method_info": {"method_name": "test_matcher_match_one_plus", "method_params": "matcher", "method_startline": "109", "method_endline": "123"}}}}}}}