{"BR": {"BR_id": "1182", "BR_author": "jingweirobot", "BRopenT": "2020-05-15T12:01:04Z", "BRcloseT": "2020-05-16T03:51:42Z", "BR_text": {"BRsummary": "test.py\", line 211, in test  : initialize COCO ground truth api IndexError: list index out of range", "BRdescription": "\n (base) jingwei@jingwei:~/yolov3$ python3 train.py  --batch-size 8\n Apex recommended for faster mixed precision training: <denchmark-link:https://github.com/NVIDIA/apex>https://github.com/NVIDIA/apex</denchmark-link>\n \n Namespace(adam=False, batch_size=8, bucket='', cache_images=False, cfg='cfg/yolov3-spp.cfg', data='data/coco2017.data', device='', epochs=1, evolve=False, img_size=[320, 640], multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/yolov3-spp-ultralytics.pt')\n Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2080 Ti', total_memory=11016MB)\n Start Tensorboard with \"tensorboard --logdir=runs\", view at <denchmark-link:http://localhost:6006/>http://localhost:6006/</denchmark-link>\n \n Model Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients\n Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n Caching labels (117266 found, 1021 missing, 0 empty, 0 duplicate, for 118287 ima\n Caching labels (4952 found, 48 missing, 0 empty, 0 duplicate, for 5000 images):\n Image sizes 320 - 640 train, 640 test\n Using 8 dataloader workers\n Starting training for 1 epochs...\n <denchmark-code> Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n    0/0     9.99G      2.45      2.72     0.928       6.1        72       384\n            Class    Images   Targets         P         R   mAP@0.5        F1\n              all     5e+03  3.63e+04     0.373     0.672     0.566     0.474\n </denchmark-code>\n \n Speed: 13.9/1.4/15.2 ms inference/NMS/total per 640x640 image at batch-size 8\n COCO mAP with pycocotools...\n Traceback (most recent call last):\n File \"train.py\", line 411, in \n train(hyp)  # train normally\n File \"train.py\", line 317, in train\n dataloader=testloader)\n File \"/home/jingwei/yolov3/test.py\", line 211, in test\n cocoGt = COCO(glob.glob('/home/jingwei/yolov3/data/annotations/instances_val*.json')[0])  # initialize COCO ground truth api\n IndexError: list index out of range\n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jingweirobot", "commentT": "2020-05-15T12:02:29Z", "comment_text": "\n \t\tDear Author\n When I train this model, I got the issue above. Could you help me fix this? Thanks a lot.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jingweirobot", "commentT": "2020-05-15T17:15:54Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jingweirobot>@jingweirobot</denchmark-link>\n  your model trained correctly. This error happens when trying to use pycocotools on your results.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jingweirobot", "commentT": "2020-05-16T03:02:36Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  do you know how to fix this issue? Thanks a lot\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "jingweirobot", "commentT": "2020-05-16T03:34:24Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jingweirobot>@jingweirobot</denchmark-link>\n  if you are training coco, then you do want pycocotools to run, which means you need to install numpy == 1.17, otherwise this error will occur.\n if you are training a custom dataset, then you do not want pycocotools to run, and you can either ignore this error, or rename your *.data file to remove the word coco from it.\n \t\t"}, "comments_4": {"comment_id": 5, "comment_author": "jingweirobot", "commentT": "2020-05-16T03:45:35Z", "comment_text": "\n \t\tSee <denchmark-link:https://github.com/cocodataset/cocoapi/issues/356>cocodataset/cocoapi#356</denchmark-link>\n \n \t\t"}, "comments_5": {"comment_id": 6, "comment_author": "jingweirobot", "commentT": "2020-05-16T06:58:33Z", "comment_text": "\n \t\t(base) jingwei@jingwei:~/yolov3$ python3 train.py  --batch-size 8\n Apex recommended for faster mixed precision training: <denchmark-link:https://github.com/NVIDIA/apex>https://github.com/NVIDIA/apex</denchmark-link>\n \n Your branch is behind 'origin/master' by 4 commits, and can be fast-forwarded.\n (use \"git pull\" to update your local branch)\n Namespace(adam=False, batch_size=8, bucket='', cache_images=False, cfg='cfg/yolov3-spp.cfg', data='data/coco2017.data', device='', epochs=1, evolve=False, img_size=[320, 640], multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/yolov3-spp-ultralytics.pt')\n Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2080 Ti', total_memory=11016MB)\n Start Tensorboard with \"tensorboard --logdir=runs\", view at <denchmark-link:http://localhost:6006/>http://localhost:6006/</denchmark-link>\n \n Model Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients\n Optimizer groups: 76 .bias, 76 Conv2d.weight, 73 other\n Caching labels (117266 found, 1021 missing, 0 empty, 0 duplicate, for 118287 ima\n Caching labels (4952 found, 48 missing, 0 empty, 0 duplicate, for 5000 images):\n Image sizes 320 - 640 train, 640 test\n Using 8 dataloader workers\n Starting training for 1 epochs...\n <denchmark-code> Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n    0/0     9.99G      2.46      2.75     0.967      6.18        72       384\n            Class    Images   Targets         P         R   mAP@0.5        F1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [01:55<00:00,  5.41it/s]\n              all     5e+03  3.63e+04     0.378     0.666     0.556      0.47\n </denchmark-code>\n \n Speed: 13.7/1.4/15.1 ms inference/NMS/total per 640x640 image at batch-size 8\n COCO mAP with pycocotools...\n Traceback (most recent call last):\n File \"train.py\", line 411, in \n train(hyp)  # train normally\n File \"train.py\", line 317, in train\n dataloader=testloader)\n File \"/home/jingwei/yolov3/test.py\", line 211, in test\n cocoGt = COCO(glob.glob('/home/jingwei/yolov3/data/annotations/instances_val*.json')[0])  # initialize COCO ground truth api\n IndexError: list index out of range\n (base) jingwei@jingwei:/yolov3$ python -c \"import numpy; print(numpy.version)\"\n 1.17.5\n (base) jingwei@jingwei:/yolov3$\n \t\t"}, "comments_6": {"comment_id": 7, "comment_author": "jingweirobot", "commentT": "2020-05-16T06:59:16Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n \n numpy =1.17.5\n I still met the same issue.\n \t\t"}, "comments_7": {"comment_id": 8, "comment_author": "jingweirobot", "commentT": "2020-05-16T15:39:50Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  solved this issue. That is not Numpy version issue.\n Using\n cocoRoot = \"/home/jingwei/yolov3/data/coco/\"\n dataType = \"val2017\"\n <denchmark-code>        File = os.path.join(cocoRoot, f'annotations/instances_{dataType}.json')\n \n         cocoGt=COCO(File)\n    to replace \n          cocoGt = COCO(glob.glob('/home/jingwei/yolov3/data/coco/annotations/instances_val*.json')[0])  \n </denchmark-code>\n \n Thanks a lot. If anyone meets this problem, please mention and try this.\n \t\t"}, "comments_8": {"comment_id": 9, "comment_author": "jingweirobot", "commentT": "2020-05-16T16:46:57Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/jingweirobot>@jingweirobot</denchmark-link>\n  ah I see, thanks for the update! Yes the current implementation is designed for coco and yolov3 folders next to each other:\n <denchmark-code>/dir\n     /coco\n     /yolov3\n </denchmark-code>\n \n \t\t"}, "comments_9": {"comment_id": 10, "comment_author": "jingweirobot", "commentT": "2020-08-19T15:12:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  I have trained yolov3 on my custom dataset. Now I want to generate AP scores for different scales (AP scores across scales) that are available in pycocotools.\n I tried to run test.py but getting this error:\n <denchmark-code>COCO mAP with pycocotools...\n Traceback (most recent call last):\n   File \"test.py\", line 261, in <module>\n     opt.augment)\n   File \"test.py\", line 214, in test\n     cocoGt = COCO(glob.glob('../coco/annotations/instances_val*.json')[0])  # initialize COCO ground truth api\n IndexError: list index out of range\n </denchmark-code>\n \n any idea on how to get these scores for custom datasets?\n \t\t"}, "comments_10": {"comment_id": 11, "comment_author": "jingweirobot", "commentT": "2020-08-19T18:43:23Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/Rajat-Mehta>@Rajat-Mehta</denchmark-link>\n  recommend yolov5. mAP by size is not available outside of pycocotools.\n \t\t"}, "comments_11": {"comment_id": 12, "comment_author": "jingweirobot", "commentT": "2020-08-19T18:50:00Z", "comment_text": "\n \t\t<denchmark-link:https://github.com/glenn-jocher>@glenn-jocher</denchmark-link>\n  is it available in yolov5?\n \t\t"}}}, "commit": {"commit_id": "3f27ef1253bf83429350cbaeb8e1d01aff9de7ae", "commit_author": "Glenn Jocher", "commitT": "2020-05-15 20:50:58-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "requirements.txt", "file_new_name": "requirements.txt", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "2,3", "deleted_lines": "2"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "test.py", "file_new_name": "test.py", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "207,208,209,210,211,212,213,214,215,216,217,219,220", "deleted_lines": "208,209,210,211,212,213,214,215,216,217,218,219"}}}}}}