{"BR": {"BR_id": "2607", "BR_author": "jmugan", "BRopenT": "2020-08-20T02:28:37Z", "BRcloseT": "2020-08-31T18:49:19Z", "BR_text": {"BRsummary": "Sampling Categorical Quits After Two Samples [bug, but probably user error]", "BRdescription": "\n <denchmark-h:h3>Issue Description</denchmark-h>\n \n The sampler works with a Gaussian but not with categorical. Similar as <denchmark-link:https://github.com/pyro-ppl/pyro/issues/2159>#2159</denchmark-link>\n  but it was suggested that I open a new issue.\n <denchmark-h:h3>Environment</denchmark-h>\n \n Python 3.7 with Pyro 1.4.0\n <denchmark-h:h3>Code Snippet</denchmark-h>\n \n If I set use_gaussian to True it works as expected.\n <denchmark-code>import torch\n import pyro\n import pyro.distributions as dist\n import pyro.poutine as poutine\n from pyro.infer import MCMC, NUTS\n #pyro.set_rng_seed(101)\n \n # This works if I set it to True\n use_gaussian = False\n \n def model(prior_elves):\n     print('prior:', prior_elves)\n     if use_gaussian:\n         num_elves = pyro.sample(\"num_elves\",\n                                    dist.Normal(prior_elves, torch.tensor(2.0)))\n     else:\n         num_elves = pyro.sample(\"num_elves\",\n                                pyro.distributions.Categorical(probs=prior_elves))\n     print(\"Num elves: \", num_elves)\n \n     num_rocks = num_elves * 4\n     num_logs = num_elves * 6\n \n     print(f\"Rocks: {num_rocks}, Logs: {num_logs}\")\n \n     # begin https://pyro.ai/examples/intro_part_ii.html\n \n     rocks_observed = pyro.sample(\"rocks_observed\",\n                                    dist.Normal(num_rocks, torch.tensor(3.0)))\n \n     logs_observed = pyro.sample(\"logs_observed\",\n                                    dist.Normal(num_logs, torch.tensor(3.0)))\n \n     print(f\"Rocks obs: {rocks_observed}, Logs obs: {logs_observed}\")\n \n     return num_elves\n \n def conditioned_model(model, data, prior_elves):\n     return poutine.condition(model, data=data)(prior_elves)\n \n data = {\"rocks_observed\": torch.tensor(4),\n     \"logs_observed\": torch.tensor(6),\n     }\n \n if use_gaussian:\n     prior_elves = torch.tensor(2.0)\n else:\n     prior_elves = torch.tensor([.2,.2,.2,.2,.2])\n \n nuts_kernel = NUTS(conditioned_model, jit_compile=False)\n mcmc = MCMC(nuts_kernel,\n                 num_samples=10,\n                 warmup_steps=5,\n                 num_chains=1)\n mcmc.run(model, data, prior_elves)\n \n mcmc.summary(prob=.5)\n </denchmark-code>\n \n Gives the output\n <denchmark-code>Sample: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 15/15 [00:00, 1853.70it/s, step size=1.00e+00, acc. prob=1.000]\n prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n Num elves:  tensor(4)\n Rocks: 16, Logs: 24\n Rocks obs: 4, Logs obs: 6\n prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n Num elves:  tensor([0, 1, 2, 3, 4])\n Rocks: tensor([ 0,  4,  8, 12, 16]), Logs: tensor([ 0,  6, 12, 18, 24])\n Rocks obs: 4, Logs obs: 6\n prior: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000])\n Num elves:  tensor([0, 1, 2, 3, 4])\n Rocks: tensor([ 0,  4,  8, 12, 16]), Logs: tensor([ 0,  6, 12, 18, 24])\n Rocks obs: 4, Logs obs: 6\n \n Traceback (most recent call last):\n   File \"/Users/jmugan/Dropbox/code/python_examples/jwm_pyro/elves.py\", line 75, in <module>\n     mcmc.summary(prob=.5)\n   File \"/Users/jmugan/anaconda3/lib/python3.7/site-packages/pyro/infer/mcmc/api.py\", line 485, in summary\n     print_summary(self._samples, prob=prob)\n   File \"/Users/jmugan/anaconda3/lib/python3.7/site-packages/pyro/infer/mcmc/util.py\", line 522, in print_summary\n     max_len = max(max(map(lambda x: len(x), row_names.values())), 10)\n ValueError: max() arg is an empty sequence\n \n Process finished with exit code 1\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "jmugan", "commentT": "2020-08-20T04:35:54Z", "comment_text": "\n \t\tBecause your conditioned_model does not have any continuous latent variable, MCMC will collect nothing for you. The ValueError is indeed a bug: we should print an empty summary, rather than triggering an error.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "jmugan", "commentT": "2020-08-20T04:49:43Z", "comment_text": "\n \t\tThanks. I'll have to think about how all this works. I'll leave it open due to the ValueError. Thanks again.\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "jmugan", "commentT": "2020-08-20T05:17:24Z", "comment_text": "\n \t\tIn Pyro MCMC, we marginalize the discrete latent variable num_elves. After that, there is no latent variable (two variables rocks_observed and logs_observed are observed after you conditioned on the data). If you only condition on rocks_observed\n (i.e. data = {\"rocks_observed\": torch.tensor(4)}), then MCMC will collect logs_observed samples. I think your model is a nice example to illustrate the difference between using discrete vs continuous latent variables in Pyro. :)\n \t\t"}}}, "commit": {"commit_id": "927001fdf85d085c669d6a18a6f76e0e6d27845a", "commit_author": "Du Phan", "commitT": "2020-08-20 12:52:18-07:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "pyro\\infer\\mcmc\\util.py", "file_new_name": "pyro\\infer\\mcmc\\util.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "518,519", "deleted_lines": null, "method_info": {"method_name": "print_summary", "method_params": "samples,prob,group_by_chain", "method_startline": "504", "method_endline": "541"}}}}}}}