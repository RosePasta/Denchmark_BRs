{"BR": {"BR_id": "1970", "BR_author": "lissyx", "BRopenT": "2019-03-20T22:23:07Z", "BRcloseT": "2019-04-03T18:49:54Z", "BR_text": {"BRsummary": "Can't upload deepspeech-gpu-0.5.0a4.tgz to npm", "BRdescription": "\n  triggers some code that tries to  the  file, and it hits limitations in the NodeJS buffer: <denchmark-link:https://github.com/npm/npm-registry-client/blob/14efa6848ca1e7278de0eb12a1430cdb85bddf02/lib/publish.js#L103>https://github.com/npm/npm-registry-client/blob/14efa6848ca1e7278de0eb12a1430cdb85bddf02/lib/publish.js#L103</denchmark-link>\n \n <denchmark-link:https://tools.taskcluster.net/groups/brZLYYp-QwC2djoDw_a1Gg/tasks/VCU-kUTOQt-1Rd4LZsg5Ag/runs/2/logs/public%2Flogs%2Flive_backing.log#L113>https://tools.taskcluster.net/groups/brZLYYp-QwC2djoDw_a1Gg/tasks/VCU-kUTOQt-1Rd4LZsg5Ag/runs/2/logs/public%2Flogs%2Flive_backing.log#L113</denchmark-link>\n \n <denchmark-code>npm verb stack Error: toString failed\n npm verb stack     at Buffer.toString (buffer.js:456:11)\n npm verb stack     at CachingRegistryClient.putFirst (/app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/lib/publish.js:97:23)\n npm verb stack     at /app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/lib/publish.js:54:14\n npm verb stack     at ConcatStream.<anonymous> (/app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/node_modules/concat-stream/index.js:36:43)\n npm verb stack     at emitNone (events.js:72:20)\n npm verb stack     at ConcatStream.emit (events.js:166:7)\n npm verb stack     at finishMaybe (/app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js:475:14)\n npm verb stack     at endWritable (/app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js:485:3)\n npm verb stack     at ConcatStream.Writable.end (/app/.heroku/node/lib/node_modules/npm/node_modules/npm-registry-client/node_modules/concat-stream/node_modules/readable-stream/lib/_stream_writable.js:455:41)\n npm verb stack     at ReadStream.onend (_stream_readable.js:498:10)\n npm verb cwd /app\n npm ERR! Linux 4.4.0-1038-aws\n npm ERR! argv \"/app/.heroku/node/bin/node\" \"/app/.heroku/node/bin/npm\" \"publish\" \"--verbose\" \"/tmp/work/PWAf_XusTySO-13W6Ev_-Q/deepspeech-gpu-0.5.0-alpha.4.tgz\" \"--tag\" \"prerelease\"\n npm ERR! node v4.8.7\n npm ERR! npm  v2.15.12\n \n npm ERR! toString failed\n npm ERR! \n npm ERR! If you need help, you may report this error at:\n npm ERR!     <https://github.com/npm/npm/issues>\n npm verb exit [ 1, true ]\n </denchmark-code>\n \n Currently, the deepspeech-gpu-0.5.0a4.tgz is 316MB.\n We might:\n \n split deepspeech-gpu into several subpackages: linux, windows\n try to use upx (need some patching, this might be dangerous), we can get the tgz to 217MB\n hand-upload, looking how it is done:\n \n https://stackoverflow.com/questions/43543459/publishing-large-npm-packages\n https://github.com/npm/npm-registry-client/blob/14efa6848ca1e7278de0eb12a1430cdb85bddf02/lib/publish.js#L60-L137\n \n \n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "lissyx", "commentT": "2019-03-21T22:55:17Z", "comment_text": "\n \t\tWe could also reduce the number of CUDA compute compatibilities we provide. I could measure that going from a 508MB libdeepspeech.so with the current list to 192MB by limiting to compute 3.5. Then, we can also use selective registration in tensorflow. With CUDA deps and runtime builtin (I need to get proper registration of the kernels), I'm around 138MB libdeepspeech.so for a compute 3.5 coverage.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "lissyx", "commentT": "2019-04-02T12:53:55Z", "comment_text": "\n \t\tFor now we will just stick to CUDA compute compatibility 3.5, all the testing I could perform reveal it works with no noticeable perf regression\n \t\t"}, "comments_2": {"comment_id": 3, "comment_author": "lissyx", "commentT": "2019-04-03T09:44:01Z", "comment_text": "\n \t\tSo, resulting deepspeech-gpu-0.5.0-alpha.4.tgz is 75MB, will give us some more room\n \t\t"}, "comments_3": {"comment_id": 4, "comment_author": "lissyx", "commentT": "2019-05-03T19:19:20Z", "comment_text": "\n \t\tThis thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n \t\t"}}}, "commit": {"commit_id": "3aa286f6157ff24d0254bdaef9f0f837fc5d468a", "commit_author": "Alexandre Lissy", "commitT": "2019-04-03 14:31:57+02:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\.build.yml", "file_new_name": "taskcluster\\.build.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "26", "deleted_lines": "26"}}}, "file_1": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\android-arm64-cpu-opt.yml", "file_new_name": "taskcluster\\android-arm64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}, "file_2": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\android-armv7-cpu-opt.yml", "file_new_name": "taskcluster\\android-armv7-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}, "file_3": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\android-java-opt.yml", "file_new_name": "taskcluster\\android-java-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "16", "deleted_lines": "16"}}}, "file_4": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\android-x86_64-cpu-opt.yml", "file_new_name": "taskcluster\\android-x86_64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}, "file_5": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\darwin-amd64-cpu-opt.yml", "file_new_name": "taskcluster\\darwin-amd64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}, "file_6": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\darwin-amd64-ctc-opt.yml", "file_new_name": "taskcluster\\darwin-amd64-ctc-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}, "file_7": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\linux-amd64-cpu-opt.yml", "file_new_name": "taskcluster\\linux-amd64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17", "deleted_lines": "17"}}}, "file_8": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\linux-amd64-ctc-opt.yml", "file_new_name": "taskcluster\\linux-amd64-ctc-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17", "deleted_lines": "17"}}}, "file_9": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\linux-amd64-gpu-opt.yml", "file_new_name": "taskcluster\\linux-amd64-gpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "15", "deleted_lines": "15"}}}, "file_10": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\linux-arm64-cpu-opt.yml", "file_new_name": "taskcluster\\linux-arm64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "7", "deleted_lines": "7"}}}, "file_11": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\linux-rpi3-cpu-opt.yml", "file_new_name": "taskcluster\\linux-rpi3-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "7", "deleted_lines": "7"}}}, "file_12": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\node-package-cpu.yml", "file_new_name": "taskcluster\\node-package-cpu.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "20", "deleted_lines": "20"}}}, "file_13": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\node-package-gpu.yml", "file_new_name": "taskcluster\\node-package-gpu.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "17", "deleted_lines": "17"}}}, "file_14": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\test-lite_benchmark_model-linux-amd64-opt.yml", "file_new_name": "taskcluster\\test-lite_benchmark_model-linux-amd64-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "7", "deleted_lines": "7"}}}, "file_15": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\test-training_upstream-linux-amd64-py27mu-opt.yml", "file_new_name": "taskcluster\\test-training_upstream-linux-amd64-py27mu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "10", "deleted_lines": "10"}}}, "file_16": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\win-amd64-cpu-opt.yml", "file_new_name": "taskcluster\\win-amd64-cpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}, "file_17": {"file_change_type": "MODIFY", "file_Nmethod": 0, "file_old_name": "taskcluster\\win-amd64-gpu-opt.yml", "file_new_name": "taskcluster\\win-amd64-gpu-opt.yml", "hunks": {"hunk_0": {"Ismethod": 0, "added_lines": "9", "deleted_lines": "9"}}}}}}