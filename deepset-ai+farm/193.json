{"BR": {"BR_id": "193", "BR_author": "Hahny", "BRopenT": "2020-01-16T11:29:21Z", "BRcloseT": "2020-01-19T19:08:01Z", "BR_text": {"BRsummary": "Error during dev set evaluation in lm_finetuning.py when adding a custom vocab via  tokenizer.add_tokens", "BRdescription": "\n Hello and thanks again for your work and help!\n When i add custom tokens during an LM finetuning an index out of range error is thrown during the evaluation of the dev set. The error does not appear if you run the training without an dev set (setting dev_filename=False in the  BertStyleLMProcessor).\n If no dev and test set is specified, the model can later be used for a downstream task with the new custom vocab. Error seems only to appear when a dev and test set is specified like in the example. I am using the latest master branch.\n The reason i want a dev set in the LM finetuning is to save some \"checkpoints\" via early stopping during the LM fine tuning and test them on a downstream task.\n Here is the error and after that the whole script:\n <denchmark-code>Train epoch 1/1 (Cur. train loss: 0.6664):  18%|\u2588\u258a        | 30/170 [00:48<03:43,  1.60s/it]\n Evaluating:   0%|          | 0/319 [00:00<?, ?it/s]\n ---------------------------------------------------------------------------\n IndexError                                Traceback (most recent call last)\n <ipython-input-3-f9d4de447982> in <module>()\n       1 # 7. Let it grow! Watch the tracked metrics live on the public mlflow server: https://public-mlflow.deepset.ai\n ----> 2 model = trainer.train(model)\n \n ~/bertclassifier/FARM/farm/train.py in train(self, model)\n     224                     ):\n     225                         evalnr += 1\n --> 226                         result = self.evaluator_dev.eval(model)\n     227                         self.evaluator_dev.log_results(result, \"Dev\", self.global_step)\n     228                         if self.early_stopping:\n \n ~/bertclassifier/FARM/farm/eval.py in eval(self, model, return_preds_and_labels)\n      71                 losses_per_head = model.logits_to_loss_per_head(logits=logits, **batch)\n      72                 preds = model.logits_to_preds(logits=logits, **batch)\n ---> 73                 labels = model.prepare_labels(**batch)\n      74 \n      75             # stack results of all batches per prediction head\n \n ~/bertclassifier/FARM/farm/modeling/adaptive_model.py in prepare_labels(self, **kwargs)\n     170         #     all_labels.append(labels)\n     171         for head in self.prediction_heads:\n --> 172             labels = head.prepare_labels(**kwargs)\n     173             all_labels.append(labels)\n     174         return all_labels\n \n ~/bertclassifier/FARM/farm/modeling/prediction_head.py in prepare_labels(self, **kwargs)\n     662         # we have a batch of sequences here. we need to convert for each token in each sequence.\n     663         for ids_for_sequence in label_ids:\n --> 664             labels.append([self.label_list[int(x)] for x in ids_for_sequence if int(x) != -1])\n     665         return labels\n     666 \n \n ~/bertclassifier/FARM/farm/modeling/prediction_head.py in <listcomp>(.0)\n     662         # we have a batch of sequences here. we need to convert for each token in each sequence.\n     663         for ids_for_sequence in label_ids:\n --> 664             labels.append([self.label_list[int(x)] for x in ids_for_sequence if int(x) != -1])\n     665         return labels\n     666 \n \n IndexError: list index out of range\n </denchmark-code>\n \n Script:\n <denchmark-code>import logging\n \n import torch\n \n from farm.data_handler.data_silo import DataSilo\n from farm.data_handler.processor import BertStyleLMProcessor\n from farm.modeling.adaptive_model import AdaptiveModel\n from farm.modeling.language_model import LanguageModel\n from farm.modeling.prediction_head import BertLMHead, NextSentenceHead\n from farm.modeling.tokenization import Tokenizer\n from farm.train import Trainer\n from farm.modeling.optimization import initialize_optimizer\n \n from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings\n \n logging.basicConfig(\n     format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n     datefmt=\"%m/%d/%Y %H:%M:%S\",\n     level=logging.INFO,\n )\n \n set_all_seeds(seed=42)\n ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n ml_logger.init_experiment(\n     experiment_name=\"Public_FARM\", run_name=\"Run_minimal_example_lm\"\n )\n \n device, n_gpu = \"cuda\",1\n n_epochs = 1\n batch_size = 32\n evaluate_every = 30\n lang_model = \"bert-base-cased\"\n \n \n # 1.Create a tokenizer\n tokenizer = Tokenizer.load(\n     pretrained_model_name_or_path=lang_model, do_lower_case=False\n )\n \n special_tokens = ['regression', 'logistic']\n tokenizer.add_tokens(list(special_tokens))\n \n # 2. Create a DataProcessor that handles all the conversion from raw text into a pytorch Dataset\n processor = BertStyleLMProcessor(\n     data_dir=\"../data/lm_finetune_nips\", tokenizer=tokenizer, max_seq_len=128, max_docs=30\n )\n # 3. Create a DataSilo that loads several datasets (train/dev/test), provides DataLoaders for them and calculates a few descriptive statistics of our datasets\n data_silo = DataSilo(processor=processor, batch_size=batch_size, max_multiprocessing_chunksize=20)\n \n language_model = LanguageModel.load(lang_model,n_added_tokens=len(tokenizer.added_tokens_decoder))\n lm_prediction_head = BertLMHead.load(lang_model,n_added_tokens=len(tokenizer.added_tokens_decoder))\n next_sentence_head = NextSentenceHead.load(lang_model)\n \n model = AdaptiveModel(\n     language_model=language_model,\n     prediction_heads=[lm_prediction_head, next_sentence_head],\n     embeds_dropout_prob=0.1,\n     lm_output_types=[\"per_token\", \"per_sequence\"],\n     device=device,\n )\n \n # 5. Create an optimizer\n model, optimizer, lr_schedule = initialize_optimizer(\n     model=model,\n     learning_rate=2e-5,\n     device=device,\n     n_batches=len(data_silo.loaders[\"train\"]),\n     n_epochs=n_epochs,\n )\n \n # 6. Feed everything to the Trainer, which keeps care of growing our model into powerful plant and evaluates it from time to time\n trainer = Trainer(\n     optimizer=optimizer,\n     data_silo=data_silo,\n     epochs=n_epochs,\n     n_gpu=n_gpu,\n     lr_schedule=lr_schedule,\n     evaluate_every=evaluate_every,\n     device=device,\n )\n \n # 7. Let it grow! Watch the tracked metrics live on the public mlflow server: https://public-mlflow.deepset.ai\n model = trainer.train(model)\n </denchmark-code>\n \n \t"}, "comments": {"comments_0": {"comment_id": 1, "comment_author": "Hahny", "commentT": "2020-01-17T14:03:53Z", "comment_text": "\n \t\tHey thanks for a well documented issue. I was able to replicate it. I believe the issue has to do with the initialization of the BertStyleLMProcessor (processor.py). The vocab list there is not updated with the added tokens. I have opened  <denchmark-link:https://github.com/deepset-ai/FARM/pull/197>#197</denchmark-link>\n  to deal with this. Let me know if this solves it.\n \t\t"}, "comments_1": {"comment_id": 2, "comment_author": "Hahny", "commentT": "2020-01-19T19:08:01Z", "comment_text": "\n \t\tThanks, i had written my own checking points according to my needs, Therefore, i did not test your update.\n \t\t"}}}, "commit": {"commit_id": "1f6e08260670ddb5b2af5d5a783ec2f9a9ebf91b", "commit_author": "Branden Chan", "commitT": "2020-01-17 18:15:06+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\data_handler\\processor.py", "file_new_name": "farm\\data_handler\\processor.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "730,731,732,733", "deleted_lines": null, "method_info": {"method_name": "get_added_tokens", "method_params": "self", "method_startline": "730", "method_endline": "733"}}}}}}}