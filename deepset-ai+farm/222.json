{"BR": {"BR_id": "222", "BR_author": "tholor", "BRopenT": "2020-01-29T10:15:29Z", "BRcloseT": "2020-01-30T09:40:11Z", "BR_text": {"BRsummary": "Loading cached DataSilo even if max_seq_len has changed", "BRdescription": "\n Describe the bug\n We introduced caching of the DataSilo to speed up preprocessing. However, the checksum of the cache is currently only based on the filename of the training data. This is not enough, since users might change preprocessing params in their script (e.g. max_seq_len) and end up with loading an \"outdated\" cache\n Expected behavior\n Don't load the old cache if preprocessing params have changed\n \n Add the params to the checksum here:\n <denchmark-link:https://github.com/deepset-ai/FARM/blob/master/farm/data_handler/data_silo.py#L221>https://github.com/deepset-ai/FARM/blob/master/farm/data_handler/data_silo.py#L221</denchmark-link>\n \n It must include: ,  and  (from tokenizer)\n It should include: all serializable attributes from the processor ( , , , ,  ....)\n \t"}, "comments": {}}, "commit": {"commit_id": "12d416ecc79376770403bc17adf8e17c241393a8", "commit_author": "Tanay Soni", "commitT": "2020-01-30 10:40:10+01:00", "changed_files": {"file_0": {"file_change_type": "MODIFY", "file_Nmethod": 1, "file_old_name": "farm\\data_handler\\data_silo.py", "file_new_name": "farm\\data_handler\\data_silo.py", "hunks": {"hunk_0": {"Ismethod": 1, "added_lines": "265,266,267,268,269", "deleted_lines": "265", "method_info": {"method_name": "_get_checksum", "method_params": "self", "method_startline": "259", "method_endline": "272"}}}}}}}