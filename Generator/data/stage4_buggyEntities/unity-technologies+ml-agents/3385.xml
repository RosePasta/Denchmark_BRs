<commit id='2b8630f5cb76fc6dd0cfd07e5828be43c87eb43a' author='Ervin T' date='2020-03-09 12:57:55-07:00'>
	<dmm_unit complexity='1.0' interfacing='0.9285714285714286' size='0.07142857142857142'></dmm_unit>
	<modification change_type='MODIFY' old_name='com.unity.ml-agents\CHANGELOG.md' new_name='com.unity.ml-agents\CHANGELOG.md'>
		<file_info nloc='None' complexity='None' token_count='None'></file_info>
		<modified_lines>
			<added_lines>46</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\__init__.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\__init__.py'>
		<file_info nloc='64' complexity='4' token_count='330'></file_info>
		<method name='evaluate_batch' parameters='self,str'>
				<method_info nloc='13' complexity='1' token_count='69' nesting_level='1' start_line='42' end_line='54'></method_info>
			<added_lines>43</added_lines>
			<deleted_lines>42</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='56' end_line='57'></method_info>
			<added_lines></added_lines>
			<deleted_lines>57</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='57' end_line='58'></method_info>
			<added_lines>58</added_lines>
			<deleted_lines>57</deleted_lines>
		</method>
		<method name='evaluate_batch' parameters='self,AgentBuffer'>
				<method_info nloc='13' complexity='1' token_count='62' nesting_level='1' start_line='43' end_line='55'></method_info>
			<added_lines>43</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>11</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\curiosity\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\curiosity\signal.py'>
		<file_info nloc='94' complexity='8' token_count='648'></file_info>
		<method name='evaluate_batch' parameters='self,str'>
				<method_info nloc='25' complexity='5' token_count='241' nesting_level='1' start_line='44' end_line='69'></method_info>
			<added_lines>45</added_lines>
			<deleted_lines>44</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='82' end_line='83'></method_info>
			<added_lines></added_lines>
			<deleted_lines>83</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='83' end_line='84'></method_info>
			<added_lines>84</added_lines>
			<deleted_lines>83</deleted_lines>
		</method>
		<method name='evaluate_batch' parameters='self,AgentBuffer'>
				<method_info nloc='25' complexity='5' token_count='234' nesting_level='1' start_line='45' end_line='70'></method_info>
			<added_lines>45</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>8</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\extrinsic\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\extrinsic\signal.py'>
		<file_info nloc='18' complexity='2' token_count='124'></file_info>
		<method name='evaluate_batch' parameters='self,str'>
				<method_info nloc='3' complexity='1' token_count='46' nesting_level='1' start_line='19' end_line='21'></method_info>
			<added_lines>20</added_lines>
			<deleted_lines>19</deleted_lines>
		</method>
		<method name='evaluate_batch' parameters='self,AgentBuffer'>
				<method_info nloc='3' complexity='1' token_count='39' nesting_level='1' start_line='20' end_line='22'></method_info>
			<added_lines>20</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>5</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\components\reward_signals\gail\signal.py' new_name='ml-agents\mlagents\trainers\components\reward_signals\gail\signal.py'>
		<file_info nloc='113' complexity='9' token_count='823'></file_info>
		<method name='evaluate_batch' parameters='self,str'>
				<method_info nloc='25' complexity='6' token_count='239' nesting_level='1' start_line='64' end_line='90'></method_info>
			<added_lines>65</added_lines>
			<deleted_lines>64</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,str,int'>
				<method_info nloc='2' complexity='1' token_count='22' nesting_level='1' start_line='103' end_line='104'></method_info>
			<added_lines></added_lines>
			<deleted_lines>104</deleted_lines>
		</method>
		<method name='prepare_update' parameters='self,TFPolicy,AgentBuffer,int'>
				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='104' end_line='105'></method_info>
			<added_lines>105</added_lines>
			<deleted_lines>104</deleted_lines>
		</method>
		<method name='evaluate_batch' parameters='self,AgentBuffer'>
				<method_info nloc='25' complexity='6' token_count='232' nesting_level='1' start_line='65' end_line='91'></method_info>
			<added_lines>65</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>9,113,115</added_lines>
			<deleted_lines>112,113,114,115,116,117,118,119,121</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\sac\optimizer.py' new_name='ml-agents\mlagents\trainers\sac\optimizer.py'>
		<file_info nloc='546' complexity='23' token_count='3412'></file_info>
		<method name='add_reward_signal_dicts' parameters='self,Tensor,str,str,str,int'>
				<method_info nloc='7' complexity='1' token_count='48' nesting_level='1' start_line='565' end_line='571'></method_info>
			<added_lines>570</added_lines>
			<deleted_lines>570</deleted_lines>
		</method>
		<method name='update_reward_signals' parameters='self,str,int'>
				<method_info nloc='2' complexity='1' token_count='16' nesting_level='1' start_line='539' end_line='540'></method_info>
			<added_lines>540</added_lines>
			<deleted_lines>540</deleted_lines>
		</method>
		<method name='update_reward_signals' parameters='self,str,int'>
				<method_info nloc='2' complexity='1' token_count='16' nesting_level='1' start_line='539' end_line='540'></method_info>
			<added_lines>540</added_lines>
			<deleted_lines>540</deleted_lines>
		</method>
		<method name='add_reward_signal_dicts' parameters='self,Tensor,str,str,str,int'>
				<method_info nloc='7' complexity='1' token_count='48' nesting_level='1' start_line='565' end_line='571'></method_info>
			<added_lines>570</added_lines>
			<deleted_lines>570</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='ml-agents\mlagents\trainers\tests\test_ppo.py' new_name='ml-agents\mlagents\trainers\tests\test_ppo.py'>
		<file_info nloc='318' complexity='22' token_count='2018'></file_info>
		<method name='test_ppo_optimizer_update_gail' parameters='gail_dummy_config,dummy_config'>
				<method_info nloc='26' complexity='1' token_count='183' nesting_level='0' start_line='157' end_line='188'></method_info>
			<added_lines>157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_ppo_optimizer_update_curiosity' parameters='curiosity_dummy_config,dummy_config,rnn,visual,discrete'>
				<method_info nloc='2' complexity='1' token_count='11' nesting_level='0' start_line='133' end_line='134'></method_info>
			<added_lines>133,134</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17,18,19,20,129,130,131,132,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,189,190</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
</commit>
