<commit id='b9a91646bd97942609b545794e889b16ba8e05a5' author='dependabot-preview[bot]' date='2020-07-09 11:50:12-07:00'>
	<dmm_unit complexity='1.0' interfacing='1.0' size='0.0'></dmm_unit>
	<modification change_type='MODIFY' old_name='CHANGELOG.md' new_name='CHANGELOG.md'>
		<file_info nloc='None' complexity='None' token_count='None'></file_info>
		<modified_lines>
			<added_lines>27,47</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py' new_name='allennlp\data\tokenizers\pretrained_transformer_tokenizer.py'>
		<file_info nloc='382' complexity='17' token_count='1837'></file_info>
		<modified_lines>
			<added_lines>131,133</added_lines>
			<deleted_lines>131,133,188</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='setup.py' new_name='setup.py'>
		<file_info nloc='59' complexity='0' token_count='187'></file_info>
		<modified_lines>
			<added_lines>67</added_lines>
			<deleted_lines>67</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\data\token_indexers\pretrained_transformer_indexer_test.py' new_name='tests\data\token_indexers\pretrained_transformer_indexer_test.py'>
		<file_info nloc='169' complexity='16' token_count='1193'></file_info>
		<method name='test_as_array_produces_token_sequence_roberta' parameters='self'>
				<method_info nloc='12' complexity='1' token_count='79' nesting_level='1' start_line='54' end_line='66'></method_info>
			<added_lines>58</added_lines>
			<deleted_lines>58</deleted_lines>
		</method>
		<method name='test_as_array_produces_token_sequence_roberta_sentence_pair' parameters='self'>
				<method_info nloc='16' complexity='1' token_count='96' nesting_level='1' start_line='68' end_line='83'></method_info>
			<added_lines>74,83</added_lines>
			<deleted_lines>74,83</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\data\tokenizers\pretrained_transformer_tokenizer_test.py' new_name='tests\data\tokenizers\pretrained_transformer_tokenizer_test.py'>
		<file_info nloc='283' complexity='32' token_count='1432'></file_info>
		<method name='test_token_idx_bert_cased' parameters='self'>
				<method_info nloc='24' complexity='3' token_count='111' nesting_level='1' start_line='117' end_line='140'></method_info>
			<added_lines>123,124,125,134</added_lines>
			<deleted_lines>123,132</deleted_lines>
		</method>
		<method name='test_splits_roberta' parameters='self'>
				<method_info nloc='17' complexity='2' token_count='58' nesting_level='1' start_line='10' end_line='27'></method_info>
			<added_lines>16</added_lines>
			<deleted_lines>16</deleted_lines>
		</method>
		<method name='test_token_idx_roberta' parameters='self'>
				<method_info nloc='22' complexity='3' token_count='103' nesting_level='1' start_line='142' end_line='163'></method_info>
			<added_lines>146</added_lines>
			<deleted_lines>144</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
</commit>
