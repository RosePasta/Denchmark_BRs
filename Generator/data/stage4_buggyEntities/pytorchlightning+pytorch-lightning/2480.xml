<commit id='992a7e2a414d052754f3579e173620baf740308a' author='Hayden Housen' date='2020-07-09 07:11:07-04:00'>
	<dmm_unit complexity='1.0' interfacing='0.0' size='1.0'></dmm_unit>
	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_tricks.py' new_name='pytorch_lightning\trainer\training_tricks.py'>
		<file_info nloc='235' complexity='41' token_count='1406'></file_info>
		<method name='configure_accumulated_gradients' parameters='self,accumulate_grad_batches'>
				<method_info nloc='8' complexity='3' token_count='53' nesting_level='1' start_line='98' end_line='105'></method_info>
			<added_lines>102</added_lines>
			<deleted_lines>102</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\test_lr_finder.py' new_name='tests\trainer\test_lr_finder.py'>
		<file_info nloc='126' complexity='13' token_count='707'></file_info>
		<method name='test_accumulation_and_early_stopping' parameters='tmpdir'>
				<method_info nloc='16' complexity='1' token_count='93' nesting_level='0' start_line='136' end_line='158'></method_info>
			<added_lines>157</added_lines>
			<deleted_lines>157</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\test_trainer.py' new_name='tests\trainer\test_trainer.py'>
		<file_info nloc='658' complexity='73' token_count='5391'></file_info>
		<method name='test_gradient_accumulation_scheduling._optimizer_step' parameters='epoch,batch_idx,optimizer,optimizer_idx,second_order_closure,on_tpu,using_native_amp,using_lbfgs'>
				<method_info nloc='3' complexity='1' token_count='27' nesting_level='1' start_line='143' end_line='145'></method_info>
			<added_lines>143,144,145</added_lines>
			<deleted_lines>144,145</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling' parameters='tmpdir'>
				<method_info nloc='45' complexity='7' token_count='324' nesting_level='0' start_line='106' end_line='181'></method_info>
			<added_lines>106,107,108,109,110,111,112,113,114,134,135,136,137,138,139,140,141,143,144,145,150,151,154,156,157,161,162,165,167,168,171,172,175,177,178</added_lines>
			<deleted_lines>106,127,128,133,134,137,139,140,144,145,148,150,151,154,155,158,160,161,168,169,170,171,172,173,174,175,176,178</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling._optimizer_step' parameters='self,epoch,batch_idx,optimizer,optimizer_idx,second_order_closure'>
				<method_info nloc='2' complexity='1' token_count='17' nesting_level='1' start_line='127' end_line='128'></method_info>
			<added_lines></added_lines>
			<deleted_lines>127,128</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling' parameters='tmpdir,schedule,expected'>
				<method_info nloc='44' complexity='7' token_count='359' nesting_level='0' start_line='114' end_line='189'></method_info>
			<added_lines>114,134,135,136,137,138,139,140,141,143,144,145,150,151,154,156,157,161,162,165,167,168,171,172,175,177,178,186</added_lines>
			<deleted_lines>127,128,133,134,137,139,140,144,145,148,150,151,154,155,158,160,161,168,169,170,171,172,173,174,175,176,178</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
</commit>
