<commit id='0ec410769744843726a140b7efabbeeb1c4e2929' author='Justus Schock' date='2020-10-21 19:34:29+01:00'>
	<dmm_unit complexity='1.0' interfacing='0.59375' size='1.0'></dmm_unit>
	<modification change_type='MODIFY' old_name='pytorch_lightning\accelerators\accelerator.py' new_name='pytorch_lightning\accelerators\accelerator.py'>
		<file_info nloc='167' complexity='41' token_count='1181'></file_info>
		<method name='backward' parameters='self,closure_loss,optimizer,opt_idx,args,kwargs'>
				<method_info nloc='10' complexity='2' token_count='86' nesting_level='1' start_line='87' end_line='99'></method_info>
			<added_lines>94,95</added_lines>
			<deleted_lines>94,95,96,97,98</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='pytorch_lightning\core\lightning.py' new_name='pytorch_lightning\core\lightning.py'>
		<file_info nloc='1235' complexity='109' token_count='2815'></file_info>
		<method name='backward' parameters='self,Tensor,Optimizer,int,args,kwargs'>
				<method_info nloc='21' complexity='1' token_count='48' nesting_level='1' start_line='1084' end_line='1104'></method_info>
			<added_lines>1084,1103,1104</added_lines>
			<deleted_lines>1084,1085,1086,1087</deleted_lines>
		</method>
		<method name='optimizer_step' parameters='self,int,int,Optimizer,int,None,bool,bool,bool'>
				<method_info nloc='10' complexity='1' token_count='47' nesting_level='1' start_line='1128' end_line='1137'></method_info>
			<added_lines>1132</added_lines>
			<deleted_lines>1134</deleted_lines>
		</method>
		<method name='backward' parameters='self,Tensor,Optimizer,int'>
				<method_info nloc='20' complexity='1' token_count='25' nesting_level='1' start_line='1087' end_line='1106'></method_info>
			<added_lines>1103,1104</added_lines>
			<deleted_lines>1087,1106</deleted_lines>
		</method>
		<method name='manual_backward' parameters='self,Tensor,Optimizer,args,kwargs'>
				<method_info nloc='20' complexity='1' token_count='59' nesting_level='1' start_line='1061' end_line='1085'></method_info>
			<added_lines>1084</added_lines>
			<deleted_lines>1084,1085</deleted_lines>
		</method>
		<method name='optimizer_step' parameters='self,int,int,Optimizer,int,None,bool,bool,bool'>
				<method_info nloc='10' complexity='1' token_count='47' nesting_level='1' start_line='1126' end_line='1135'></method_info>
			<added_lines>1132</added_lines>
			<deleted_lines>1134</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>1148,1158,1163,1187,1204,1206,1207,1208,1211</added_lines>
			<deleted_lines>1150,1160,1165,1189,1206,1209,1210,1212</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\training_loop.py' new_name='pytorch_lightning\trainer\training_loop.py'>
		<file_info nloc='524' complexity='152' token_count='4040'></file_info>
		<method name='on_train_end' parameters='self'>
				<method_info nloc='17' complexity='5' token_count='125' nesting_level='1' start_line='172' end_line='202'></method_info>
			<added_lines>185</added_lines>
			<deleted_lines>182</deleted_lines>
		</method>
		<method name='on_trainer_init' parameters='self,max_epochs,min_epochs,max_steps,min_steps,num_sanity_val_steps,automatic_optimization'>
				<method_info nloc='2' complexity='1' token_count='15' nesting_level='1' start_line='50' end_line='51'></method_info>
			<added_lines>50,51</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='_process_result' parameters='self,training_step_output,split_batch'>
				<method_info nloc='24' complexity='2' token_count='52' nesting_level='1' start_line='420' end_line='447'></method_info>
			<added_lines>440,441,442</added_lines>
			<deleted_lines>440,441</deleted_lines>
		</method>
		<method name='optimizer_step' parameters='self,optimizer,opt_idx,batch_idx,train_step_and_backward_closure'>
				<method_info nloc='5' complexity='1' token_count='41' nesting_level='1' start_line='449' end_line='454'></method_info>
			<added_lines>450,452,453,454</added_lines>
			<deleted_lines>449,451,452</deleted_lines>
		</method>
		<method name='update_train_loop_lr_schedulers' parameters='self,monitor_metrics'>
				<method_info nloc='5' complexity='3' token_count='66' nesting_level='1' start_line='824' end_line='830'></method_info>
			<added_lines>830</added_lines>
			<deleted_lines>827</deleted_lines>
		</method>
		<method name='track_and_norm_grad' parameters='self,optimizer'>
				<method_info nloc='4' complexity='1' token_count='29' nesting_level='1' start_line='463' end_line='469'></method_info>
			<added_lines>463,469</added_lines>
			<deleted_lines>467</deleted_lines>
		</method>
		<method name='save_loggers_on_train_batch_end' parameters='self'>
				<method_info nloc='7' complexity='6' token_count='64' nesting_level='1' start_line='875' end_line='882'></method_info>
			<added_lines>878,879</added_lines>
			<deleted_lines>878</deleted_lines>
		</method>
		<method name='run_training_batch' parameters='self,batch,batch_idx,dataloader_idx'>
				<method_info nloc='69' complexity='20' token_count='535' nesting_level='1' start_line='620' end_line='756'></method_info>
			<added_lines>641,646,650,651,652,653,673,674,675,676,677,678,679,680,681,682,683,684,685,687,688,689,690,692,694,696,697,698,699,700,701,702,703,704,706,707,709,710,712,713,714,716,717,718,719,720,721,723,724,732,733,734,735,736,754</added_lines>
			<deleted_lines>642,647,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,686,687,689,690,692,693,694,696,697,698,700,701,703,704,706,707,708,709,710,711,712,713,714,716,717,718,719,721,722,730,731,732,733,751</deleted_lines>
		</method>
		<method name='_process_training_step_output_1_0' parameters='self,training_step_output,split_batch'>
				<method_info nloc='18' complexity='3' token_count='117' nesting_level='1' start_line='387' end_line='418'></method_info>
			<added_lines>395,396,397,402</added_lines>
			<deleted_lines>395,396,397,402</deleted_lines>
		</method>
		<method name='_process_closure_result' parameters='self,list,list,list,int'>
				<method_info nloc='2' complexity='1' token_count='19' nesting_level='1' start_line='758' end_line='759'></method_info>
			<added_lines>758,759</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='setup_fit' parameters='self,model,train_dataloader,val_dataloaders,datamodule'>
				<method_info nloc='6' complexity='2' token_count='65' nesting_level='1' start_line='91' end_line='103'></method_info>
			<added_lines>96</added_lines>
			<deleted_lines>93</deleted_lines>
		</method>
		<method name='backward' parameters='self,result,optimizer,opt_idx,args,kwargs'>
				<method_info nloc='8' complexity='2' token_count='85' nesting_level='1' start_line='813' end_line='822'></method_info>
			<added_lines>814,821</added_lines>
			<deleted_lines>817</deleted_lines>
		</method>
		<method name='training_step' parameters='self,split_batch,batch_idx,opt_idx,hiddens'>
				<method_info nloc='31' complexity='4' token_count='190' nesting_level='1' start_line='297' end_line='341'></method_info>
			<added_lines>301,303,306,309</added_lines>
			<deleted_lines>300,302,305,308,309</deleted_lines>
		</method>
		<method name='on_train_batch_end' parameters='self,epoch_output,epoch_end_outputs,batch,batch_idx,dataloader_idx'>
				<method_info nloc='4' complexity='1' token_count='47' nesting_level='1' start_line='244' end_line='250'></method_info>
			<added_lines>249,250</added_lines>
			<deleted_lines>248,249</deleted_lines>
		</method>
		<method name='check_checkpoint_callback' parameters='self,should_save,is_last'>
				<method_info nloc='7' complexity='8' token_count='77' nesting_level='1' start_line='204' end_line='211'></method_info>
			<added_lines>209</added_lines>
			<deleted_lines>206</deleted_lines>
		</method>
		<method name='run_training_epoch' parameters='self'>
				<method_info nloc='41' complexity='10' token_count='317' nesting_level='1' start_line='522' end_line='618'></method_info>
			<added_lines>554,604,611</added_lines>
			<deleted_lines>552,602,603,604,605,612</deleted_lines>
		</method>
		<method name='on_train_start' parameters='self'>
				<method_info nloc='5' complexity='3' token_count='47' nesting_level='1' start_line='80' end_line='89'></method_info>
			<added_lines>85,89</added_lines>
			<deleted_lines>82,86</deleted_lines>
		</method>
		<method name='should_check_val_fx' parameters='self,batch_idx,is_last_batch'>
				<method_info nloc='8' complexity='6' token_count='86' nesting_level='1' start_line='844' end_line='853'></method_info>
			<added_lines>850</added_lines>
			<deleted_lines>845,846</deleted_lines>
		</method>
		<method name='on_trainer_init' parameters='self,max_epochs,min_epochs,max_steps,min_steps,num_sanity_val_steps,automatic_optimization'>
				<method_info nloc='19' complexity='2' token_count='140' nesting_level='1' start_line='49' end_line='70'></method_info>
			<added_lines>50,51,52</added_lines>
			<deleted_lines>49,68</deleted_lines>
		</method>
		<method name='training_step_and_backward' parameters='self,split_batch,batch_idx,opt_idx,optimizer,hiddens'>
				<method_info nloc='13' complexity='4' token_count='114' nesting_level='1' start_line='787' end_line='811'></method_info>
			<added_lines>793,796,801,807,808,809,810</added_lines>
			<deleted_lines>787,788,797,800,801</deleted_lines>
		</method>
		<method name='_process_training_step_output' parameters='self,training_step_output,split_batch'>
				<method_info nloc='24' complexity='7' token_count='163' nesting_level='1' start_line='343' end_line='385'></method_info>
			<added_lines>363</added_lines>
			<deleted_lines>363</deleted_lines>
		</method>
		<method name='tbptt_split_batch' parameters='self,batch'>
				<method_info nloc='7' complexity='2' token_count='59' nesting_level='1' start_line='514' end_line='520'></method_info>
			<added_lines>518</added_lines>
			<deleted_lines>516</deleted_lines>
		</method>
		<method name='process_train_step_outputs' parameters='self,all_train_step_outputs,early_stopping_accumulator,checkpoint_accumulator'>
				<method_info nloc='14' complexity='10' token_count='117' nesting_level='1' start_line='884' end_line='914'></method_info>
			<added_lines>901,902,904,905,911</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='build_train_args' parameters='self,batch,batch_idx,opt_idx,hiddens'>
				<method_info nloc='14' complexity='4' token_count='88' nesting_level='1' start_line='855' end_line='873'></method_info>
			<added_lines>860,865</added_lines>
			<deleted_lines>868,869,871,872</deleted_lines>
		</method>
		<method name='on_before_backward' parameters='self,batch_idx,optimizer'>
				<method_info nloc='4' complexity='1' token_count='28' nesting_level='1' start_line='461' end_line='467'></method_info>
			<added_lines>463</added_lines>
			<deleted_lines>461,467</deleted_lines>
		</method>
		<method name='__init__' parameters='self,trainer'>
				<method_info nloc='11' complexity='1' token_count='64' nesting_level='1' start_line='38' end_line='48'></method_info>
			<added_lines>47,48</added_lines>
			<deleted_lines>38</deleted_lines>
		</method>
		<method name='on_after_backward' parameters='self,training_step_output,batch_idx,untouched_loss'>
				<method_info nloc='8' complexity='2' token_count='64' nesting_level='1' start_line='283' end_line='295'></method_info>
			<added_lines>292</added_lines>
			<deleted_lines>291</deleted_lines>
		</method>
		<method name='run_training_batch.train_step_and_backward_closure' parameters=''>
				<method_info nloc='9' complexity='2' token_count='34' nesting_level='6' start_line='696' end_line='704'></method_info>
			<added_lines>696,697,698,699,700,701,702,703,704</added_lines>
			<deleted_lines>696,697,698,700,701,703,704</deleted_lines>
		</method>
		<method name='run_on_epoch_end_hook' parameters='self,epoch_output'>
				<method_info nloc='3' complexity='1' token_count='25' nesting_level='1' start_line='832' end_line='834'></method_info>
			<added_lines>833,834</added_lines>
			<deleted_lines>832</deleted_lines>
		</method>
		<method name='setup_training' parameters='self,LightningModule'>
				<method_info nloc='29' complexity='12' token_count='296' nesting_level='1' start_line='105' end_line='170'></method_info>
			<added_lines>140,150,169</added_lines>
			<deleted_lines>137,147,166</deleted_lines>
		</method>
		<method name='on_train_epoch_start' parameters='self,epoch'>
				<method_info nloc='15' complexity='3' token_count='120' nesting_level='1' start_line='213' end_line='242'></method_info>
			<added_lines>234,241,242</added_lines>
			<deleted_lines>231,232,233,240,241</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>71,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786</added_lines>
			<deleted_lines>763,768,777,784,785,786</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\base\deterministic_model.py' new_name='tests\base\deterministic_model.py'>
		<file_info nloc='334' complexity='60' token_count='3387'></file_info>
		<method name='backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='7' complexity='3' token_count='51' nesting_level='1' start_line='488' end_line='495'></method_info>
			<added_lines>495</added_lines>
			<deleted_lines>495</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\data_flow\test_eval_loop_flow_1_0.py' new_name='tests\trainer\data_flow\test_eval_loop_flow_1_0.py'>
		<file_info nloc='165' complexity='28' token_count='957'></file_info>
		<method name='test__eval_step__flow' parameters='tmpdir'>
				<method_info nloc='21' complexity='1' token_count='90' nesting_level='0' start_line='25' end_line='66'></method_info>
			<added_lines>47</added_lines>
			<deleted_lines>46</deleted_lines>
		</method>
		<method name='test__eval_step__eval_step_end__flow.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='96' end_line='97'></method_info>
			<added_lines>97</added_lines>
			<deleted_lines>96</deleted_lines>
		</method>
		<method name='test__eval_step__epoch_end__flow.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='153' end_line='154'></method_info>
			<added_lines>154</added_lines>
			<deleted_lines>153</deleted_lines>
		</method>
		<method name='test__eval_step__epoch_end__flow' parameters='tmpdir'>
				<method_info nloc='22' complexity='1' token_count='99' nesting_level='0' start_line='118' end_line='174'></method_info>
			<added_lines>154</added_lines>
			<deleted_lines>153</deleted_lines>
		</method>
		<method name='test__validation_step__step_end__epoch_end__flow' parameters='tmpdir'>
				<method_info nloc='22' complexity='1' token_count='95' nesting_level='0' start_line='177' end_line='238'></method_info>
			<added_lines>219</added_lines>
			<deleted_lines>218</deleted_lines>
		</method>
		<method name='test__validation_step__step_end__epoch_end__flow.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='218' end_line='219'></method_info>
			<added_lines>219</added_lines>
			<deleted_lines>218</deleted_lines>
		</method>
		<method name='test__eval_step__flow.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='46' end_line='47'></method_info>
			<added_lines>47</added_lines>
			<deleted_lines>46</deleted_lines>
		</method>
		<method name='test__eval_step__eval_step_end__flow' parameters='tmpdir'>
				<method_info nloc='21' complexity='1' token_count='86' nesting_level='0' start_line='69' end_line='115'></method_info>
			<added_lines>97</added_lines>
			<deleted_lines>96</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\data_flow\test_train_loop_flow_dict_1_0.py' new_name='tests\trainer\data_flow\test_train_loop_flow_dict_1_0.py'>
		<file_info nloc='131' complexity='18' token_count='834'></file_info>
		<method name='test__training_step__step_end__epoch_end__flow_dict' parameters='tmpdir'>
				<method_info nloc='21' complexity='1' token_count='85' nesting_level='0' start_line='149' end_line='200'></method_info>
			<added_lines>182</added_lines>
			<deleted_lines>181</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__flow_dict.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='127' end_line='128'></method_info>
			<added_lines>128</added_lines>
			<deleted_lines>127</deleted_lines>
		</method>
		<method name='test__training_step__flow_dict.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='37' end_line='38'></method_info>
			<added_lines>38</added_lines>
			<deleted_lines>37</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__flow_dict' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='84' nesting_level='0' start_line='101' end_line='146'></method_info>
			<added_lines>128</added_lines>
			<deleted_lines>127</deleted_lines>
		</method>
		<method name='test__training_step__step_end__epoch_end__flow_dict.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='181' end_line='182'></method_info>
			<added_lines>182</added_lines>
			<deleted_lines>181</deleted_lines>
		</method>
		<method name='test__training_step__flow_dict' parameters='tmpdir'>
				<method_info nloc='19' complexity='1' token_count='83' nesting_level='0' start_line='24' end_line='56'></method_info>
			<added_lines>38</added_lines>
			<deleted_lines>37</deleted_lines>
		</method>
		<method name='test__training_step__tr_step_end__flow_dict' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='84' nesting_level='0' start_line='59' end_line='98'></method_info>
			<added_lines>80</added_lines>
			<deleted_lines>79</deleted_lines>
		</method>
		<method name='test__training_step__tr_step_end__flow_dict.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='79' end_line='80'></method_info>
			<added_lines>80</added_lines>
			<deleted_lines>79</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\data_flow\test_train_loop_flow_scalar_1_0.py' new_name='tests\trainer\data_flow\test_train_loop_flow_scalar_1_0.py'>
		<file_info nloc='151' complexity='21' token_count='871'></file_info>
		<method name='test__training_step__flow_scalar.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='39' end_line='40'></method_info>
			<added_lines>40</added_lines>
			<deleted_lines>39</deleted_lines>
		</method>
		<method name='test__training_step__flow_scalar' parameters='tmpdir'>
				<method_info nloc='19' complexity='1' token_count='83' nesting_level='0' start_line='26' end_line='58'></method_info>
			<added_lines>40</added_lines>
			<deleted_lines>39</deleted_lines>
		</method>
		<method name='test__training_step__step_end__epoch_end__flow_scalar.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='183' end_line='184'></method_info>
			<added_lines>184</added_lines>
			<deleted_lines>183</deleted_lines>
		</method>
		<method name='test__training_step__tr_step_end__flow_scalar' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='84' nesting_level='0' start_line='61' end_line='100'></method_info>
			<added_lines>82</added_lines>
			<deleted_lines>81</deleted_lines>
		</method>
		<method name='test__training_step__step_end__epoch_end__flow_scalar' parameters='tmpdir'>
				<method_info nloc='21' complexity='1' token_count='85' nesting_level='0' start_line='151' end_line='202'></method_info>
			<added_lines>184</added_lines>
			<deleted_lines>183</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__flow_scalar.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='129' end_line='130'></method_info>
			<added_lines>130</added_lines>
			<deleted_lines>129</deleted_lines>
		</method>
		<method name='test__training_step__tr_step_end__flow_scalar.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='81' end_line='82'></method_info>
			<added_lines>82</added_lines>
			<deleted_lines>81</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__flow_scalar' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='84' nesting_level='0' start_line='103' end_line='148'></method_info>
			<added_lines>130</added_lines>
			<deleted_lines>129</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\legacy_deprecate_flow_log_tests\test_eval_loop_dict_return.py' new_name='tests\trainer\legacy_deprecate_flow_log_tests\test_eval_loop_dict_return.py'>
		<file_info nloc='204' complexity='14' token_count='1243'></file_info>
		<method name='test_validation_step_no_return' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='106' nesting_level='0' start_line='22' end_line='52'></method_info>
			<added_lines>26,27,28,29,30</added_lines>
			<deleted_lines>25</deleted_lines>
		</method>
		<method name='test_validation_step_no_return.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='28' end_line='29'></method_info>
			<added_lines>28,29</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\logging\test_eval_loop_logging_1_0.py' new_name='tests\trainer\logging\test_eval_loop_logging_1_0.py'>
		<file_info nloc='249' complexity='25' token_count='1657'></file_info>
		<method name='test__validation_step__step_end__epoch_end__log.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='120' end_line='121'></method_info>
			<added_lines>121</added_lines>
			<deleted_lines>120</deleted_lines>
		</method>
		<method name='test__validation_step__log' parameters='tmpdir'>
				<method_info nloc='33' complexity='1' token_count='147' nesting_level='0' start_line='27' end_line='84'></method_info>
			<added_lines>50</added_lines>
			<deleted_lines>49</deleted_lines>
		</method>
		<method name='test__validation_step__log.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='49' end_line='50'></method_info>
			<added_lines>50</added_lines>
			<deleted_lines>49</deleted_lines>
		</method>
		<method name='test__validation_step__step_end__epoch_end__log' parameters='tmpdir'>
				<method_info nloc='42' complexity='1' token_count='184' nesting_level='0' start_line='87' end_line='162'></method_info>
			<added_lines>121</added_lines>
			<deleted_lines>120</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\logging\test_train_loop_logging_1_0.py' new_name='tests\trainer\logging\test_train_loop_logging_1_0.py'>
		<file_info nloc='346' complexity='38' token_count='2579'></file_info>
		<method name='test__training_step__log' parameters='tmpdir'>
				<method_info nloc='46' complexity='1' token_count='212' nesting_level='0' start_line='28' end_line='121'></method_info>
			<added_lines>72</added_lines>
			<deleted_lines>71</deleted_lines>
		</method>
		<method name='test__training_step__log.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='71' end_line='72'></method_info>
			<added_lines>72</added_lines>
			<deleted_lines>71</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__log' parameters='tmpdir'>
				<method_info nloc='36' complexity='1' token_count='194' nesting_level='0' start_line='124' end_line='183'></method_info>
			<added_lines>145</added_lines>
			<deleted_lines>144</deleted_lines>
		</method>
		<method name='test__training_step__epoch_end__log.backward' parameters='self,loss,optimizer,optimizer_idx'>
				<method_info nloc='2' complexity='1' token_count='24' nesting_level='2' start_line='144' end_line='145'></method_info>
			<added_lines>145</added_lines>
			<deleted_lines>144</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>17</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='ADD' old_name='None' new_name='tests\trainer\optimization\test_backward_calls.py'>
		<file_info nloc='32' complexity='3' token_count='218'></file_info>
	</modification>
	<modification change_type='MODIFY' old_name='tests\trainer\test_trainer.py' new_name='tests\trainer\test_trainer.py'>
		<file_info nloc='1008' complexity='99' token_count='6776'></file_info>
		<method name='test_trainer_subclassing.__init__' parameters='self,custom_arg,args,custom_kwarg,kwargs'>
				<method_info nloc='4' complexity='1' token_count='39' nesting_level='2' start_line='1114' end_line='1117'></method_info>
			<added_lines>1114,1115,1116,1117</added_lines>
			<deleted_lines>1114</deleted_lines>
		</method>
		<method name='test_disabled_validation' parameters='tmpdir'>
				<method_info nloc='30' complexity='1' token_count='164' nesting_level='0' start_line='729' end_line='775'></method_info>
			<added_lines>761,763,764,772,774,775</added_lines>
			<deleted_lines>740,742,743,744,745,753,755,756,757,758,762,770</deleted_lines>
		</method>
		<method name='test_gradient_clipping' parameters='tmpdir'>
				<method_info nloc='13' complexity='1' token_count='65' nesting_level='0' start_line='872' end_line='904'></method_info>
			<added_lines>886,887,888,889,890,891,892,893,894,895,896,897,898,899,900</added_lines>
			<deleted_lines>878,893,894,895,896,897,898</deleted_lines>
		</method>
		<method name='test_loading_yaml' parameters='tmpdir'>
				<method_info nloc='11' complexity='2' token_count='101' nesting_level='0' start_line='361' end_line='377'></method_info>
			<added_lines>368,374,377</added_lines>
			<deleted_lines>366,369</deleted_lines>
		</method>
		<method name='test_gradient_clipping_fp16' parameters='tmpdir'>
				<method_info nloc='15' complexity='1' token_count='73' nesting_level='0' start_line='909' end_line='942'></method_info>
			<added_lines>925,926,927,928,929,930,931,932,933,934,935,936,937,938,939</added_lines>
			<deleted_lines>909,926,930,931,932,933,934,935,936,937,938,939,940,941,942</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling' parameters='tmpdir,schedule,expected'>
				<method_info nloc='57' complexity='12' token_count='493' nesting_level='0' start_line='190' end_line='282'></method_info>
			<added_lines>193,194,212,226,227,229,230,231,232,233,234,235,236,237,238</added_lines>
			<deleted_lines>206,221,222,223,273,274,275,276,277,278,279,280,281,282</deleted_lines>
		</method>
		<method name='test_resume_from_checkpoint_epoch_restored' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
				<method_info nloc='32' complexity='4' token_count='233' nesting_level='0' start_line='503' end_line='571'></method_info>
			<added_lines>506,540,542,556,560,567,570</added_lines>
			<deleted_lines>525,527,541,545,552,555</deleted_lines>
		</method>
		<method name='test_gradient_clipping_fp16._optimizer_step' parameters='args,kwargs'>
				<method_info nloc='4' complexity='2' token_count='75' nesting_level='1' start_line='894' end_line='897'></method_info>
			<added_lines>894,895,896,897</added_lines>
			<deleted_lines>894,895,896,897</deleted_lines>
		</method>
		<method name='test_nan_loss_detection.training_step' parameters='self,batch,batch_idx,optimizer_idx'>
				<method_info nloc='8' complexity='3' token_count='64' nesting_level='2' start_line='782' end_line='789'></method_info>
			<added_lines>786</added_lines>
			<deleted_lines>784</deleted_lines>
		</method>
		<method name='test_num_sanity_val_steps' parameters='tmpdir,limit_val_batches'>
				<method_info nloc='20' complexity='2' token_count='116' nesting_level='0' start_line='995' end_line='1020'></method_info>
			<added_lines>1013</added_lines>
			<deleted_lines>1007,1010,1018,1019,1020</deleted_lines>
		</method>
		<method name='test_dp_output_reduce' parameters=''>
				<method_info nloc='9' complexity='1' token_count='102' nesting_level='0' start_line='380' end_line='394'></method_info>
			<added_lines>391,393,394</added_lines>
			<deleted_lines>383,384,385,386,387,388,390,391,392,393,394</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling._optimizer_step' parameters='epoch,batch_idx,optimizer,optimizer_idx,second_order_closure,on_tpu,using_native_amp,using_lbfgs'>
				<method_info nloc='9' complexity='1' token_count='26' nesting_level='1' start_line='229' end_line='237'></method_info>
			<added_lines>229,230,231,232,233,234,235,236,237</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_trainer_subclassing.__init__' parameters='self,kwargs'>
				<method_info nloc='4' complexity='1' token_count='41' nesting_level='2' start_line='1306' end_line='1309'></method_info>
			<added_lines>1307,1308</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_no_val_module' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
				<method_info nloc='28' complexity='2' token_count='166' nesting_level='0' start_line='43' end_line='84'></method_info>
			<added_lines>46,62,65,70,74,75,76,77,78,79</added_lines>
			<deleted_lines>43,47,63,66,71,75,76,84</deleted_lines>
		</method>
		<method name='test_trainer_subclassing' parameters=''>
				<method_info nloc='19' complexity='1' token_count='120' nesting_level='0' start_line='1286' end_line='1319'></method_info>
			<added_lines>1291,1296,1300,1307,1308,1311,1314,1319</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_num_sanity_val_steps_neg_one' parameters='tmpdir,limit_val_batches'>
				<method_info nloc='17' complexity='1' token_count='108' nesting_level='0' start_line='1032' end_line='1054'></method_info>
			<added_lines>1046,1049</added_lines>
			<deleted_lines>1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054</deleted_lines>
		</method>
		<method name='test_trainer_subclassing.__init__' parameters='self,custom_arg,args,custom_kwarg,kwargs'>
				<method_info nloc='4' complexity='1' token_count='39' nesting_level='2' start_line='1291' end_line='1294'></method_info>
			<added_lines>1291</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_nan_loss_detection' parameters='tmpdir'>
				<method_info nloc='15' complexity='2' token_count='91' nesting_level='0' start_line='778' end_line='805'></method_info>
			<added_lines>786,800</added_lines>
			<deleted_lines>784,793</deleted_lines>
		</method>
		<method name='test_trainer_setup_call' parameters='tmpdir'>
				<method_info nloc='13' complexity='1' token_count='89' nesting_level='0' start_line='1343' end_line='1365'></method_info>
			<added_lines>1357,1360,1361,1364,1365</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='test_gpu_choice' parameters='tmpdir'>
				<method_info nloc='10' complexity='2' token_count='75' nesting_level='0' start_line='945' end_line='957'></method_info>
			<added_lines>956</added_lines>
			<deleted_lines>945,952,953,954,955,956,957</deleted_lines>
		</method>
		<method name='test_no_val_end_module' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
				<method_info nloc='26' complexity='2' token_count='143' nesting_level='0' start_line='88' end_line='126'></method_info>
			<added_lines>91,108,111,116,117,118,119,120,121</added_lines>
			<deleted_lines>88,105,108,113,114,122,126</deleted_lines>
		</method>
		<method name='test_model_checkpoint_only_weights' parameters='tmpdir'>
				<method_info nloc='21' complexity='1' token_count='165' nesting_level='0' start_line='455' end_line='491'></method_info>
			<added_lines>457,458,464,469,475,476,482,486,487,490</added_lines>
			<deleted_lines>460,461,467,471,472,475,487,491</deleted_lines>
		</method>
		<method name='test_gradient_clipping.training_step_and_backward' parameters='split_batch,batch_idx,opt_idx,optimizer,hiddens'>
				<method_info nloc='6' complexity='2' token_count='100' nesting_level='1' start_line='888' end_line='898'></method_info>
			<added_lines>888,889,890,891,892,893,894,895,896,897,898</added_lines>
			<deleted_lines>893,894,895,896,897,898</deleted_lines>
		</method>
		<method name='test_model_checkpoint_options.mock_save_function' parameters='filepath,args'>
				<method_info nloc='2' complexity='1' token_count='18' nesting_level='1' start_line='425' end_line='426'></method_info>
			<added_lines>426</added_lines>
			<deleted_lines>426</deleted_lines>
		</method>
		<method name='test_trainer_max_steps_and_epochs' parameters='tmpdir'>
				<method_info nloc='20' complexity='1' token_count='128' nesting_level='0' start_line='589' end_line='621'></method_info>
			<added_lines>611</added_lines>
			<deleted_lines>596,616</deleted_lines>
		</method>
		<method name='test_trainer_min_steps_and_epochs' parameters='tmpdir'>
				<method_info nloc='23' complexity='3' token_count='164' nesting_level='0' start_line='624' end_line='661'></method_info>
			<added_lines>631,638,646,647,648,651,659,660,661</added_lines>
			<deleted_lines>631,632,635,643,644</deleted_lines>
		</method>
		<method name='test_strict_model_load' parameters='monkeypatch,tmpdir,tmpdir_server,url_ckpt'>
				<method_info nloc='42' complexity='4' token_count='202' nesting_level='0' start_line='130' end_line='189'></method_info>
			<added_lines>133,155,160,161,162,163,164,165</added_lines>
			<deleted_lines>148,153,154,155,183,184,185,186,187,188</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling_last_batch.on_train_batch_end' parameters='self,outputs,batch,batch_idx,dataloader_idx'>
				<method_info nloc='6' complexity='5' token_count='81' nesting_level='2' start_line='314' end_line='321'></method_info>
			<added_lines>315</added_lines>
			<deleted_lines>321</deleted_lines>
		</method>
		<method name='test_nan_params_detection' parameters='tmpdir'>
				<method_info nloc='15' complexity='2' token_count='107' nesting_level='0' start_line='808' end_line='830'></method_info>
			<added_lines>824</added_lines>
			<deleted_lines>809</deleted_lines>
		</method>
		<method name='test_gradient_clipping._optimizer_step' parameters='args,kwargs'>
				<method_info nloc='4' complexity='2' token_count='75' nesting_level='1' start_line='865' end_line='868'></method_info>
			<added_lines></added_lines>
			<deleted_lines>865,866,867,868</deleted_lines>
		</method>
		<method name='test_test_checkpoint_path' parameters='tmpdir,ckpt_path,save_top_k'>
				<method_info nloc='32' complexity='5' token_count='195' nesting_level='0' start_line='690' end_line='726'></method_info>
			<added_lines>698,701,704,718,720,721,722,723,724</added_lines>
			<deleted_lines>701,703</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling_last_batch' parameters='tmpdir,accumulate_grad_batches,limit_train_batches'>
				<method_info nloc='13' complexity='1' token_count='54' nesting_level='0' start_line='304' end_line='332'></method_info>
			<added_lines>315,329</added_lines>
			<deleted_lines>307,321</deleted_lines>
		</method>
		<method name='test_model_checkpoint_options' parameters='tmpdir,save_top_k,save_last,file_prefix,expected_files'>
				<method_info nloc='19' complexity='3' token_count='150' nesting_level='0' start_line='422' end_line='452'></method_info>
			<added_lines>426,431,432,433,441,446,447,448</added_lines>
			<deleted_lines>426,431,432,433,442,443,449</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling._optimizer_step' parameters='epoch,batch_idx,optimizer,optimizer_idx,second_order_closure,on_tpu,using_native_amp,using_lbfgs'>
				<method_info nloc='3' complexity='1' token_count='27' nesting_level='1' start_line='221' end_line='223'></method_info>
			<added_lines></added_lines>
			<deleted_lines>221,222,223</deleted_lines>
		</method>
		<method name='test_gradient_clipping_fp16.training_step_and_backward' parameters='split_batch,batch_idx,opt_idx,optimizer,hiddens'>
				<method_info nloc='6' complexity='2' token_count='100' nesting_level='1' start_line='927' end_line='937'></method_info>
			<added_lines>927,928,929,930,931,932,933,934,935,936,937</added_lines>
			<deleted_lines>930,931,932,933,934,935,936,937</deleted_lines>
		</method>
		<method name='test_gradient_accumulation_scheduling' parameters='tmpdir,schedule,expected'>
				<method_info nloc='57' complexity='12' token_count='497' nesting_level='0' start_line='196' end_line='290'></method_info>
			<added_lines>212,226,227,229,230,231,232,233,234,235,236,237,238,288,289,290</added_lines>
			<deleted_lines>206,221,222,223,273,274,275,276,277,278,279,280,281,282,286</deleted_lines>
		</method>
		<method name='test_tpu_choice' parameters='tmpdir,tpu_cores,expected_tpu_id,error_expected'>
				<method_info nloc='7' complexity='2' token_count='65' nesting_level='0' start_line='976' end_line='982'></method_info>
			<added_lines>978</added_lines>
			<deleted_lines>977</deleted_lines>
		</method>
		<method name='test_loading_meta_tags' parameters='tmpdir'>
				<method_info nloc='14' complexity='1' token_count='118' nesting_level='0' start_line='335' end_line='358'></method_info>
			<added_lines>343,353</added_lines>
			<deleted_lines>335,345</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>33,42,87,129,294,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,502,688,689,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,985,986,987,988,989,990,991,992,993,994,1023,1024,1025,1026,1027,1028,1029,1030,1031,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1322,1323,1324,1325,1326,1327,1328,1368,1369,1370,1371,1372,1373,1374,1375</added_lines>
			<deleted_lines>33,34,360,395,396,397,398,399,400,401,402,403,404,405,406,407,412,417,418,454,623,671,672,681,684,687,864,869,908,958,987,988,989,990,991,992,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1113,1119,1123,1129,1131,1132,1135,1138,1143,1146,1147,1148,1149,1168,1173,1180,1181,1182,1183,1184,1187,1188,1191,1192,1195,1196,1197,1198,1199</deleted_lines>
		</modified_lines>
	</modification>
</commit>
