<commit id='6780214b27e6ebace9cf38b6f5701224204e28ad' author='Ananya Harsh Jha' date='2020-07-24 08:26:05+00:00'>
	<dmm_unit complexity='0.0' interfacing='1.0' size='0.0'></dmm_unit>
	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\distrib_data_parallel.py' new_name='pytorch_lightning\trainer\distrib_data_parallel.py'>
		<file_info nloc='473' complexity='113' token_count='2328'></file_info>
		<method name='set_distributed_mode' parameters='self,distributed_backend'>
				<method_info nloc='58' complexity='28' token_count='336' nesting_level='1' start_line='247' end_line='314'></method_info>
			<added_lines>313,314</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>315</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='pytorch_lightning\trainer\trainer.py' new_name='pytorch_lightning\trainer\trainer.py'>
		<file_info nloc='1143' complexity='137' token_count='4848'></file_info>
		<modified_lines>
			<added_lines>533,534</added_lines>
			<deleted_lines>466,467</deleted_lines>
		</modified_lines>
	</modification>
</commit>
