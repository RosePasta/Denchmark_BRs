<commit id='b810d10386fad58bded6b39b233f5009406f6da3' author='Leonard Lausen' date='2019-09-11 13:52:50-07:00'>
	<dmm_unit complexity='1.0' interfacing='1.0' size='0.5'></dmm_unit>
	<modification change_type='MODIFY' old_name='scripts\tests\test_scripts.py' new_name='scripts\tests\test_scripts.py'>
		<file_info nloc='360' complexity='31' token_count='2471'></file_info>
		<method name='test_embedding_evaluate_pretrained' parameters='fasttextloadngrams'>
				<method_info nloc='12' complexity='2' token_count='61' nesting_level='0' start_line='72' end_line='84'></method_info>
			<added_lines>72,73,83,84</added_lines>
			<deleted_lines>72</deleted_lines>
		</method>
		<method name='test_embedding_evaluate_from_path' parameters='evaluateanalogies,maxvocabsize'>
				<method_info nloc='17' complexity='3' token_count='117' nesting_level='0' start_line='96' end_line='112'></method_info>
			<added_lines>104,108</added_lines>
			<deleted_lines>101,105</deleted_lines>
		</method>
		<method name='test_embedding_evaluate_pretrained' parameters='fasttextloadngrams,maxvocabsize'>
				<method_info nloc='14' complexity='3' token_count='76' nesting_level='0' start_line='73' end_line='87'></method_info>
			<added_lines>73,83,84</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='scripts\word_embeddings\evaluate_pretrained.py' new_name='scripts\word_embeddings\evaluate_pretrained.py'>
		<file_info nloc='177' complexity='18' token_count='1142'></file_info>
		<method name='load_embedding_from_path' parameters='args'>
				<method_info nloc='22' complexity='4' token_count='170' nesting_level='0' start_line='134' end_line='165'></method_info>
			<added_lines>148,149,150,151,152,153,154,157,158,159,160,161</added_lines>
			<deleted_lines>143,144,145,151,152,153,154,155,156,159</deleted_lines>
		</method>
		<method name='enforce_max_size' parameters='token_embedding,size'>
				<method_info nloc='11' complexity='4' token_count='86' nesting_level='0' start_line='180' end_line='190'></method_info>
			<added_lines>185,186,187,188,189,190</added_lines>
			<deleted_lines>183,184,185,186,187,188</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>210,211,212,213,219,220,221,235,236,237</added_lines>
			<deleted_lines>208,214,228</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='src\gluonnlp\vocab\vocab.py' new_name='src\gluonnlp\vocab\vocab.py'>
		<file_info nloc='381' complexity='58' token_count='1720'></file_info>
		<method name='set_embedding' parameters='self,embeddings'>
				<method_info nloc='31' complexity='11' token_count='235' nesting_level='1' start_line='373' end_line='421'></method_info>
			<added_lines>403,404</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
</commit>
