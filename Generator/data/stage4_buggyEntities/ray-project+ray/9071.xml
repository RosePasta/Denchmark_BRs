<commit id='2e3655e8a9b1e37fa6e29f11db02a6b53cfb5928' author='Sven Mika' date='2021-01-19 14:22:36+01:00'>
	<dmm_unit complexity='None' interfacing='None' size='None'></dmm_unit>
	<modification change_type='MODIFY' old_name='rllib\agents\a3c\a3c_tf_policy.py' new_name='rllib\agents\a3c\a3c_tf_policy.py'>
		<file_info nloc='87' complexity='9' token_count='645'></file_info>
		<method name='setup_mixins' parameters='policy,obs_space,action_space,config'>
				<method_info nloc='3' complexity='1' token_count='39' nesting_level='0' start_line='98' end_line='100'></method_info>
			<added_lines>99</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='postprocess_advantages' parameters='policy,sample_batch,other_agent_batches,episode'>
				<method_info nloc='4' complexity='1' token_count='15' nesting_level='0' start_line='17' end_line='20'></method_info>
			<added_lines>17,18,19,20</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='__init__.value' parameters='ob,prev_action,prev_reward,state'>
				<method_info nloc='9' complexity='2' token_count='106' nesting_level='2' start_line='75' end_line='83'></method_info>
			<added_lines></added_lines>
			<deleted_lines>75,76,77,78,79,80,81,82,83</deleted_lines>
		</method>
		<method name='__init__' parameters='self'>
				<method_info nloc='4' complexity='1' token_count='21' nesting_level='1' start_line='73' end_line='85'></method_info>
			<added_lines></added_lines>
			<deleted_lines>73,74,75,76,77,78,79,80,81,82,83,84,85</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>4,6,10,12,21,22,23,24,25,26,27,28,29,30,31,110</added_lines>
			<deleted_lines>5,10,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,72,86,87,118,129</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\a3c\a3c_torch_policy.py' new_name='rllib\agents\a3c\a3c_torch_policy.py'>
		<file_info nloc='77' complexity='6' token_count='503'></file_info>
		<method name='_value' parameters='self,obs'>
				<method_info nloc='3' complexity='1' token_count='51' nesting_level='1' start_line='82' end_line='84'></method_info>
			<added_lines></added_lines>
			<deleted_lines>82,83,84</deleted_lines>
		</method>
		<method name='add_advantages' parameters='policy,sample_batch,other_agent_batches,episode'>
				<method_info nloc='4' complexity='1' token_count='15' nesting_level='0' start_line='18' end_line='21'></method_info>
			<added_lines>18,19,20,21</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='setup_mixins' parameters='Policy,Space,Space,TrainerConfigDict'>
				<method_info nloc='3' complexity='1' token_count='29' nesting_level='0' start_line='70' end_line='72'></method_info>
			<added_lines>70,71,72</added_lines>
			<deleted_lines>70,71,72</deleted_lines>
		</method>
		<method name='apply_grad_clipping' parameters='policy,optimizer,loss'>
				<method_info nloc='13' complexity='5' token_count='99' nesting_level='0' start_line='60' end_line='74'></method_info>
			<added_lines>70,71,72,73,74</added_lines>
			<deleted_lines>60,61,62,63,64,65,66,67,68,69,70,71,72,73,74</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>1,2,4,5,7,10,12,13,22,23,24,25,26,27,28,29,30,31,32,75,76,77,78,79,80,81,90,94</added_lines>
			<deleted_lines>2,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,75,76,81,93</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\cql\cql_torch_policy.py' new_name='rllib\agents\cql\cql_torch_policy.py'>
		<file_info nloc='242' complexity='8' token_count='1960'></file_info>
		<modified_lines>
			<added_lines>24,25</added_lines>
			<deleted_lines>11,25</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ddpg\ddpg_torch_policy.py' new_name='rllib\agents\ddpg\ddpg_torch_policy.py'>
		<file_info nloc='194' complexity='29' token_count='1489'></file_info>
		<modified_lines>
			<added_lines>12</added_lines>
			<deleted_lines>4,13</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\dqn\dqn_tf_policy.py' new_name='rllib\agents\dqn\dqn_tf_policy.py'>
		<file_info nloc='347' complexity='21' token_count='2470'></file_info>
		<modified_lines>
			<added_lines>304,305,306,307,308</added_lines>
			<deleted_lines>304,305,306,307,308,309,310,311,312,313,314</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\dqn\dqn_torch_policy.py' new_name='rllib\agents\dqn\dqn_torch_policy.py'>
		<file_info nloc='320' complexity='13' token_count='2180'></file_info>
		<modified_lines>
			<added_lines>22,23</added_lines>
			<deleted_lines>7,23,24,25</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\dreamer\dreamer_torch_policy.py' new_name='rllib\agents\dreamer\dreamer_torch_policy.py'>
		<file_info nloc='174' complexity='14' token_count='1553'></file_info>
		<modified_lines>
			<added_lines>8</added_lines>
			<deleted_lines>4</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\impala\impala.py' new_name='rllib\agents\impala\impala.py'>
		<file_info nloc='191' complexity='24' token_count='1219'></file_info>
		<method name='get_policy_class' parameters='config'>
				<method_info nloc='16' complexity='4' token_count='77' nesting_level='0' start_line='148' end_line='163'></method_info>
			<added_lines>162</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines>4</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\impala\vtrace_torch_policy.py' new_name='rllib\agents\impala\vtrace_torch_policy.py'>
		<file_info nloc='183' complexity='18' token_count='1354'></file_info>
		<modified_lines>
			<added_lines>13,14</added_lines>
			<deleted_lines>6,14,15</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\maml\maml_tf_policy.py' new_name='rllib\agents\maml\maml_tf_policy.py'>
		<file_info nloc='365' complexity='36' token_count='2487'></file_info>
		<modified_lines>
			<added_lines>4,5,6,7,425</added_lines>
			<deleted_lines>4,5,6,7,425</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\maml\maml_torch_policy.py' new_name='rllib\agents\maml\maml_torch_policy.py'>
		<file_info nloc='306' complexity='23' token_count='2081'></file_info>
		<modified_lines>
			<added_lines>4,5,8,12,358</added_lines>
			<deleted_lines>4,7,8,11,358</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\mbmpo\mbmpo_torch_policy.py' new_name='rllib\agents\mbmpo\mbmpo_torch_policy.py'>
		<file_info nloc='75' complexity='1' token_count='412'></file_info>
		<modified_lines>
			<added_lines>8,10,17,88</added_lines>
			<deleted_lines>6,9,10,88</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ppo\appo_tf_policy.py' new_name='rllib\agents\ppo\appo_tf_policy.py'>
		<file_info nloc='344' complexity='16' token_count='2014'></file_info>
		<modified_lines>
			<added_lines>17,18,341,342</added_lines>
			<deleted_lines>16,18,341,342</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ppo\appo_torch_policy.py' new_name='rllib\agents\ppo\appo_torch_policy.py'>
		<file_info nloc='244' complexity='12' token_count='1724'></file_info>
		<modified_lines>
			<added_lines>29,30</added_lines>
			<deleted_lines>13,30,31</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ppo\ppo_tf_policy.py' new_name='rllib\agents\ppo\ppo_tf_policy.py'>
		<file_info nloc='277' complexity='19' token_count='1520'></file_info>
		<method name='postprocess_ppo_gae' parameters='Policy,SampleBatch,AgentID,None,None'>
				<method_info nloc='5' complexity='1' token_count='36' nesting_level='0' start_line='330' end_line='334'></method_info>
			<added_lines>330,331,332,333,334</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>11,335,336,337,338,339,340,341,342,343,344,345,352</added_lines>
			<deleted_lines>11,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,401</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ppo\ppo_torch_policy.py' new_name='rllib\agents\ppo\ppo_torch_policy.py'>
		<file_info nloc='232' complexity='16' token_count='1226'></file_info>
		<modified_lines>
			<added_lines>10,11,12,21,22,281</added_lines>
			<deleted_lines>10,11,12,13,22,23,282</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\ppo\tests\test_ppo.py' new_name='rllib\agents\ppo\tests\test_ppo.py'>
		<file_info nloc='322' complexity='53' token_count='2634'></file_info>
		<method name='test_ppo_loss_function' parameters='self'>
				<method_info nloc='81' complexity='18' token_count='587' nesting_level='1' start_line='226' end_line='321'></method_info>
			<added_lines>256,257,258</added_lines>
			<deleted_lines>258,259,260,261,262</deleted_lines>
		</method>
		<method name='test_ppo_free_log_std' parameters='self'>
				<method_info nloc='33' complexity='8' token_count='234' nesting_level='1' start_line='177' end_line='224'></method_info>
			<added_lines>216,217</added_lines>
			<deleted_lines>215,216,217,218,219</deleted_lines>
		</method>
		<modified_lines>
			<added_lines>8,9,10,11,12,13</added_lines>
			<deleted_lines>8,9,10,11,12</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\sac\sac.py' new_name='rllib\agents\sac\sac.py'>
		<file_info nloc='105' complexity='6' token_count='417'></file_info>
		<modified_lines>
			<added_lines>76,106</added_lines>
			<deleted_lines>76,77,107,108,109</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\agents\sac\sac_torch_policy.py' new_name='rllib\agents\sac\sac_torch_policy.py'>
		<file_info nloc='400' complexity='15' token_count='2191'></file_info>
		<modified_lines>
			<added_lines>25</added_lines>
			<deleted_lines>12,26</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\contrib\maddpg\maddpg_policy.py' new_name='rllib\contrib\maddpg\maddpg_policy.py'>
		<file_info nloc='303' complexity='36' token_count='2170'></file_info>
		<method name='gradients' parameters='self,optimizer,loss'>
				<method_info nloc='7' complexity='2' token_count='68' nesting_level='1' start_line='267' end_line='273'></method_info>
			<added_lines>268,269,270,271,272</added_lines>
			<deleted_lines>268,269,270,271,272,273</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines>274,275,276,277,278</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\evaluation\postprocessing.py' new_name='rllib\evaluation\postprocessing.py'>
		<file_info nloc='116' complexity='3' token_count='623'></file_info>
		<method name='compute_gae_for_sample_batch' parameters='Policy,SampleBatch,AgentID,None,None'>
				<method_info nloc='5' complexity='1' token_count='36' nesting_level='0' start_line='84' end_line='88'></method_info>
			<added_lines>84,85,86,87,88</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<method name='discount_cumsum' parameters='ndarray,float'>
				<method_info nloc='13' complexity='1' token_count='53' nesting_level='0' start_line='149' end_line='161'></method_info>
			<added_lines>149,150,151,152,153,154,155,156,157,158,159,160,161</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>3,4,5,6,9,82,83,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148</added_lines>
			<deleted_lines>5,6,7,8,9,10,11,12,13,14,15,16,17,18,19</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\tuned_examples\sac\mspacman-sac.yaml' new_name='rllib\tuned_examples\sac\mspacman-sac.yaml'>
		<file_info nloc='None' complexity='None' token_count='None'></file_info>
		<modified_lines>
			<added_lines>17,18,20,21</added_lines>
			<deleted_lines>17,18,20,21</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\utils\tf_ops.py' new_name='rllib\utils\tf_ops.py'>
		<file_info nloc='129' complexity='42' token_count='1058'></file_info>
		<method name='minimize_and_clip' parameters='optimizer,objective,var_list,clip_val'>
				<method_info nloc='11' complexity='6' token_count='110' nesting_level='0' start_line='89' end_line='106'></method_info>
			<added_lines>95,105,106</added_lines>
			<deleted_lines>95,105,106</deleted_lines>
		</method>
		<modified_lines>
			<added_lines></added_lines>
			<deleted_lines>107,108</deleted_lines>
		</modified_lines>
	</modification>
	<modification change_type='MODIFY' old_name='rllib\utils\torch_ops.py' new_name='rllib\utils\torch_ops.py'>
		<file_info nloc='109' complexity='42' token_count='1052'></file_info>
		<method name='apply_grad_clipping' parameters='policy,optimizer,loss'>
				<method_info nloc='13' complexity='5' token_count='100' nesting_level='0' start_line='17' end_line='38'></method_info>
			<added_lines>17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38</added_lines>
			<deleted_lines></deleted_lines>
		</method>
		<modified_lines>
			<added_lines>39,40</added_lines>
			<deleted_lines></deleted_lines>
		</modified_lines>
	</modification>
</commit>
