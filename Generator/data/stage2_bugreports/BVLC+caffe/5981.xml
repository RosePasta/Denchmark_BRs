<bug id='5981' author='vlomonaco' open_date='2017-10-15T22:16:18Z' closed_time='2018-01-29T19:31:15Z'>
	<summary>New Accuracy Layer on GPU interferes with training</summary>
	<description>
&lt;denchmark-h:h3&gt;Issue summary&lt;/denchmark-h&gt;

Using the "Accuracy" layer in the "Training net" on GPU breaks the training. The layer somehow interferes with the gradient. Loss explodes quickly and Train/Test Accuracies stall to 1.
&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;


Download the the latest version of Caffe (commit 691febc)
Compile it with this Makefile.config
Run a network with Accuracy layer in the TRAIN phase.

&lt;denchmark-h:h3&gt;My system configuration&lt;/denchmark-h&gt;

Operating system: Ubuntu 14.04.5 LTS
CUDA version (if applicable): 7.0
CUDNN version (if applicable): 4.7
BLAS: libblas.so.3
Python version: 3.5
&lt;denchmark-h:h3&gt;How to fix it&lt;/denchmark-h&gt;

All these three solutions can fix it:

Remove the Accuracy Layer from the "Training net", not problems with the phase: TEST.
Change back-end to CPU.
Rollback before commit 62e0c85 (which I suspect caused the issue).

	</description>
	<comments>
		<comment id='1' author='vlomonaco' date='2017-10-16T09:41:48Z'>
		I can reproduce this behavior for the GPU implementation. CPU does not seem to be affected. I'll be looking into this today; in the meantime, could you take a look too, &lt;denchmark-link:https://github.com/shaibagon&gt;@shaibagon&lt;/denchmark-link&gt;
?
EDIT: My suspicion after half an hour of tinkering with this: could it be that &lt;denchmark-link:https://github.com/BVLC/caffe/blob/62e0c8559045cb2b5a12e0d6c41acd25d4122630/src/caffe/layers/accuracy_layer.cu#L74-L77&gt;this&lt;/denchmark-link&gt;
 memory actually  used for something? That is, we use it as a temporary memory but Caffe actually does propagate back from here?
		</comment>
		<comment id='2' author='vlomonaco' date='2017-10-16T10:44:42Z'>
		&lt;denchmark-link:https://github.com/Noiredd&gt;@Noiredd&lt;/denchmark-link&gt;
 Is it possible &lt;denchmark-link:https://github.com/BVLC/caffe/blob/62e0c8559045cb2b5a12e0d6c41acd25d4122630/src/caffe/layers/accuracy_layer.cu#L143&gt;this&lt;/denchmark-link&gt;
 causes the issue? I will look into it.
		</comment>
		<comment id='3' author='vlomonaco' date='2017-10-16T11:13:45Z'>
		Removing the if and replacing with an unconditional NOT_IMPLEMENTED; did not change anything.
However, forcing:
caffe_gpu_set(bottom[0]-&gt;count(), Dtype(0), acc_data);
caffe_gpu_set(bottom[0]-&gt;count(), Dtype(0), counts);
at the end of Forward_gpu() fixes the problem, supporting my guess that Caffe indeed propagates from there.
This is not counter-intuitive. Think of intermediate classifiers - if we have a prediction blob A that is a bottom to one Accuracy layer but it's also a bottom to, let's say, InnerProduct, we want the IP to propagate. By reusing the blob's gradient memory, we effectively overrode the other gradients.
		</comment>
		<comment id='4' author='vlomonaco' date='2017-10-16T11:36:15Z'>
		&lt;denchmark-link:https://github.com/Noiredd&gt;@Noiredd&lt;/denchmark-link&gt;
 if you set  and  to zero - you are setting the gradients to zero. Thus, if caffe does propagate from there - you just killed the gradients.
I suppose it would require allocation of an internal  to be used as a buffer.
		</comment>
		<comment id='5' author='vlomonaco' date='2017-10-16T12:57:09Z'>
		&lt;denchmark-link:https://github.com/shaibagon&gt;@shaibagon&lt;/denchmark-link&gt;
 Of course, this was just to prove that the problem is indeed there. I can come up with a fix in a while - unless you want to take it from here? Since you fathered this PR ;)
		</comment>
		<comment id='6' author='vlomonaco' date='2017-10-16T12:59:18Z'>
		&lt;denchmark-link:https://github.com/Noiredd&gt;@Noiredd&lt;/denchmark-link&gt;
 if it is okay with you, I'd appreciate if you can take it from here. I am not as available as I used to be for caffe :(
		</comment>
		<comment id='7' author='vlomonaco' date='2017-10-16T14:41:00Z'>
		&lt;denchmark-link:https://github.com/vlomonaco&gt;@vlomonaco&lt;/denchmark-link&gt;
 Check PR &lt;denchmark-link:https://github.com/BVLC/caffe/pull/5987&gt;#5987&lt;/denchmark-link&gt;
 - does it solve the issue for you?
		</comment>
		<comment id='8' author='vlomonaco' date='2017-10-16T16:30:39Z'>
		Hi &lt;denchmark-link:https://github.com/Noiredd&gt;@Noiredd&lt;/denchmark-link&gt;
 thank you for the fix in less than 24hrs! It works!
		</comment>
		<comment id='9' author='vlomonaco' date='2018-01-12T15:42:53Z'>
		Hi, I have the exact same problem, somehow &lt;denchmark-link:https://github.com/Noiredd&gt;@Noiredd&lt;/denchmark-link&gt;
 's fix didn't work for me. Besides, I have my Accuracy layer only for the Test phase. I don't know why I am having this problem. My batchsize is not small and I have enough space, which rules out other reasons I have come across.
		</comment>
	</comments>
</bug>