<bug id='4157' author='wertig0n' open_date='2016-05-16T20:45:58Z' closed_time='2016-05-19T07:26:37Z'>
	<summary>[Caffe-OpenCL] Training CaffeNet freezes computer</summary>
	<description>
Hi!
I have a small little project with about 200 images I wish to train on. I know this is not nearly enough data to get a good result, but right now I want a proof-of-concept, not a full working solution.
I have set it up so I can train, based on the CaffeNet model. However when I run train_caffenet.sh it runs, but then it stops after the first step and just... Freeze up. It takes 100% CPU and it's not even possible to kill it without a reboot.
Any ideas what I could be doing wrong here?
	</description>
	<comments>
		<comment id='1' author='wertig0n' date='2016-05-16T22:18:54Z'>
		&lt;denchmark-link:https://github.com/wertig0n&gt;@wertig0n&lt;/denchmark-link&gt;

Please provide a bit more information:

Hardware information (devices, memory, output of "clinfo", is there optirun/optimus or primus or similar present, is it desktop or notebook/laptop/mobile).
Size of the images, network configuration used.
Operating system

		</comment>
		<comment id='2' author='wertig0n' date='2016-05-17T07:54:39Z'>
		Ok, of course.
I run an aging desktop with the following specs:
CPU: Core 2 Duo E7500 @ 2.93 GHz
GPU: AMD Radeon R9 270X GPU with 4GB of memory
Main Memory: 4GB
OS: Ubuntu 14.04.04
Caffe: latest git source of caffe-opencl branch
Other: latest git source of viennacl-dev
I run the opencl branch because I do not have the budget to buy a proper nVidia card at the moment, and yes I know it is an experimental branch.
The network configuration used is the same as CaffeNet with a simple modification, all I've changed is the number of outputs in the fc8 layer to 9 instead of 1000 outputs (because I only wish to classify 9 different classes). I have resized the images to 256x256.
I am attaching  the clinfo output as a text file. Hope that information helps!
&lt;denchmark-link:https://github.com/BVLC/caffe/files/267616/clinfo.txt&gt;clinfo.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='wertig0n' date='2016-05-17T15:53:41Z'>
		Ok that all looks good so far.

Run make runtest to see if all layers work correctly
The next steps to diagnose would be if all kernels compile correctly (is usually already included in make runtest), with:
./build/test/test_all.testbin --gtest_filter=*OpenCLKernelCompileTest* 0
Then test if the AlexNet network runs well in multiple forward/backward steps:
./build/tools/caffe time -model models/bvlc_alexnet/deploy.prototxt -gpu=0

		</comment>
		<comment id='4' author='wertig0n' date='2016-05-17T17:13:12Z'>
		running the tests gives one failed.
&lt;denchmark-code&gt;[----------] 1 test from NetTest/0, where TypeParam = caffe::CPUDevice&lt;float&gt;
[ RUN      ] NetTest/0.TestSharedWeightsUpdate
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 8.2940083
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 8.2939987
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 10.278276
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 10.278267
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 10.855959
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 10.855949
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 9.1899281
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 9.1899185
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 12.916765
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 12.916756
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 7.1070118
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 7.1070023
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 13.106203
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 13.106194
src/caffe/test/test_net.cpp:1213: Failure
Value of: shared_params.cpu_diff()[i]
  Actual: 9.9245319
Expected: ip1_weights-&gt;cpu_diff()[i] + ip2_weights-&gt;cpu_diff()[i]
Which is: 9.9245224
[  FAILED  ] NetTest/0.TestSharedWeightsUpdate, where TypeParam = caffe::CPUDevice&lt;float&gt; (4 ms)


[----------] Global test environment tear-down
[==========] 2002 tests from 268 test cases ran. (1030450 ms total)
[  PASSED  ] 2001 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] NetTest/0.TestSharedWeightsUpdate, where TypeParam = caffe::CPUDevice&lt;float&gt;

 1 FAILED TEST
make: *** [runtest] Error 1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='wertig0n' date='2016-05-17T18:59:17Z'>
		That's ok, it's not actually a fail, the epsilon-distance between "is" and "should" is just a bit bigger than the test setting appreciates.
What about ./build/tools/caffe time -model models/bvlc_alexnet/deploy.prototxt -gpu=0 though?
		</comment>
		<comment id='6' author='wertig0n' date='2016-05-17T19:11:40Z'>
		That yields a bit worse results, it core dumps. Might've found the problem, the solution eludes me a bit though. :)
&lt;denchmark-code&gt;I0517 21:07:49.670588  9497 caffe.cpp:347] Use GPU with device ID 0
I0517 21:07:53.913576  9497 net.cpp:53] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 10
      dim: 3
      dim: 227
      dim: 227
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I0517 21:07:53.914641  9497 layer_factory.hpp:78] Creating layer data
I0517 21:07:53.914670  9497 net.cpp:101] Creating Layer data
I0517 21:07:53.914685  9497 net.cpp:431] data -&gt; data
I0517 21:07:53.914742  9497 net.cpp:152] Setting up data
I0517 21:07:53.914764  9497 net.cpp:160] Top shape: 10 3 227 227 (1545870)
I0517 21:07:53.914782  9497 layer_factory.hpp:78] Creating layer conv1
I0517 21:07:53.914834  9497 net.cpp:101] Creating Layer conv1
I0517 21:07:53.914849  9497 net.cpp:462] conv1 &lt;- data
I0517 21:07:53.914865  9497 net.cpp:431] conv1 -&gt; conv1
I0517 21:07:53.914988  9497 net.cpp:152] Setting up conv1
I0517 21:07:53.915004  9497 net.cpp:160] Top shape: 10 96 55 55 (2904000)
I0517 21:07:53.915030  9497 layer_factory.hpp:78] Creating layer relu1
I0517 21:07:53.915045  9497 net.cpp:101] Creating Layer relu1
I0517 21:07:53.915056  9497 net.cpp:462] relu1 &lt;- conv1
I0517 21:07:53.915071  9497 net.cpp:418] relu1 -&gt; conv1 (in-place)
I0517 21:07:53.915086  9497 net.cpp:152] Setting up relu1
I0517 21:07:53.915099  9497 net.cpp:160] Top shape: 10 96 55 55 (2904000)
I0517 21:07:53.915113  9497 layer_factory.hpp:78] Creating layer norm1
I0517 21:07:53.915127  9497 net.cpp:101] Creating Layer norm1
I0517 21:07:53.915139  9497 net.cpp:462] norm1 &lt;- conv1
I0517 21:07:53.915153  9497 net.cpp:431] norm1 -&gt; norm1
I0517 21:07:53.915177  9497 net.cpp:152] Setting up norm1
I0517 21:07:53.915192  9497 net.cpp:160] Top shape: 10 96 55 55 (2904000)
I0517 21:07:53.915206  9497 layer_factory.hpp:78] Creating layer pool1
I0517 21:07:53.915222  9497 net.cpp:101] Creating Layer pool1
I0517 21:07:53.915235  9497 net.cpp:462] pool1 &lt;- norm1
I0517 21:07:53.915248  9497 net.cpp:431] pool1 -&gt; pool1
I0517 21:07:53.915297  9497 net.cpp:152] Setting up pool1
I0517 21:07:53.915312  9497 net.cpp:160] Top shape: 10 96 27 27 (699840)
I0517 21:07:53.915326  9497 layer_factory.hpp:78] Creating layer conv2
I0517 21:07:53.915343  9497 net.cpp:101] Creating Layer conv2
I0517 21:07:53.915355  9497 net.cpp:462] conv2 &lt;- pool1
I0517 21:07:53.915370  9497 net.cpp:431] conv2 -&gt; conv2
I0517 21:07:53.915968  9497 net.cpp:152] Setting up conv2
I0517 21:07:53.915992  9497 net.cpp:160] Top shape: 10 256 27 27 (1866240)
I0517 21:07:53.916014  9497 layer_factory.hpp:78] Creating layer relu2
I0517 21:07:53.916029  9497 net.cpp:101] Creating Layer relu2
I0517 21:07:53.916041  9497 net.cpp:462] relu2 &lt;- conv2
I0517 21:07:53.916055  9497 net.cpp:418] relu2 -&gt; conv2 (in-place)
I0517 21:07:53.916070  9497 net.cpp:152] Setting up relu2
I0517 21:07:53.916084  9497 net.cpp:160] Top shape: 10 256 27 27 (1866240)
I0517 21:07:53.916097  9497 layer_factory.hpp:78] Creating layer norm2
I0517 21:07:53.916112  9497 net.cpp:101] Creating Layer norm2
I0517 21:07:53.916123  9497 net.cpp:462] norm2 &lt;- conv2
I0517 21:07:53.916137  9497 net.cpp:431] norm2 -&gt; norm2
I0517 21:07:53.916157  9497 net.cpp:152] Setting up norm2
I0517 21:07:53.916170  9497 net.cpp:160] Top shape: 10 256 27 27 (1866240)
I0517 21:07:53.916187  9497 layer_factory.hpp:78] Creating layer pool2
I0517 21:07:53.916203  9497 net.cpp:101] Creating Layer pool2
I0517 21:07:53.916214  9497 net.cpp:462] pool2 &lt;- norm2
I0517 21:07:53.916229  9497 net.cpp:431] pool2 -&gt; pool2
I0517 21:07:53.916261  9497 net.cpp:152] Setting up pool2
I0517 21:07:53.916276  9497 net.cpp:160] Top shape: 10 256 13 13 (432640)
I0517 21:07:53.916291  9497 layer_factory.hpp:78] Creating layer conv3
I0517 21:07:53.916308  9497 net.cpp:101] Creating Layer conv3
I0517 21:07:53.916321  9497 net.cpp:462] conv3 &lt;- pool2
I0517 21:07:53.916335  9497 net.cpp:431] conv3 -&gt; conv3
I0517 21:07:53.918740  9497 net.cpp:152] Setting up conv3
I0517 21:07:53.918820  9497 net.cpp:160] Top shape: 10 384 13 13 (648960)
I0517 21:07:53.918856  9497 layer_factory.hpp:78] Creating layer relu3
I0517 21:07:53.918875  9497 net.cpp:101] Creating Layer relu3
I0517 21:07:53.918889  9497 net.cpp:462] relu3 &lt;- conv3
I0517 21:07:53.918905  9497 net.cpp:418] relu3 -&gt; conv3 (in-place)
I0517 21:07:53.918922  9497 net.cpp:152] Setting up relu3
I0517 21:07:53.918936  9497 net.cpp:160] Top shape: 10 384 13 13 (648960)
I0517 21:07:53.918953  9497 layer_factory.hpp:78] Creating layer conv4
I0517 21:07:53.918974  9497 net.cpp:101] Creating Layer conv4
I0517 21:07:53.918985  9497 net.cpp:462] conv4 &lt;- conv3
I0517 21:07:53.919001  9497 net.cpp:431] conv4 -&gt; conv4
I0517 21:07:53.921025  9497 net.cpp:152] Setting up conv4
I0517 21:07:53.921082  9497 net.cpp:160] Top shape: 10 384 13 13 (648960)
I0517 21:07:53.921156  9497 layer_factory.hpp:78] Creating layer relu4
I0517 21:07:53.921175  9497 net.cpp:101] Creating Layer relu4
I0517 21:07:53.921186  9497 net.cpp:462] relu4 &lt;- conv4
I0517 21:07:53.921202  9497 net.cpp:418] relu4 -&gt; conv4 (in-place)
I0517 21:07:53.921221  9497 net.cpp:152] Setting up relu4
I0517 21:07:53.921233  9497 net.cpp:160] Top shape: 10 384 13 13 (648960)
I0517 21:07:53.921250  9497 layer_factory.hpp:78] Creating layer conv5
I0517 21:07:53.921270  9497 net.cpp:101] Creating Layer conv5
I0517 21:07:53.921283  9497 net.cpp:462] conv5 &lt;- conv4
I0517 21:07:53.921298  9497 net.cpp:431] conv5 -&gt; conv5
I0517 21:07:53.922582  9497 net.cpp:152] Setting up conv5
I0517 21:07:53.922615  9497 net.cpp:160] Top shape: 10 256 13 13 (432640)
I0517 21:07:53.922639  9497 layer_factory.hpp:78] Creating layer relu5
I0517 21:07:53.922655  9497 net.cpp:101] Creating Layer relu5
I0517 21:07:53.922667  9497 net.cpp:462] relu5 &lt;- conv5
I0517 21:07:53.922680  9497 net.cpp:418] relu5 -&gt; conv5 (in-place)
I0517 21:07:53.922695  9497 net.cpp:152] Setting up relu5
I0517 21:07:53.922708  9497 net.cpp:160] Top shape: 10 256 13 13 (432640)
I0517 21:07:53.922724  9497 layer_factory.hpp:78] Creating layer pool5
I0517 21:07:53.922739  9497 net.cpp:101] Creating Layer pool5
I0517 21:07:53.922751  9497 net.cpp:462] pool5 &lt;- conv5
I0517 21:07:53.922766  9497 net.cpp:431] pool5 -&gt; pool5
I0517 21:07:53.922803  9497 net.cpp:152] Setting up pool5
I0517 21:07:53.922817  9497 net.cpp:160] Top shape: 10 256 6 6 (92160)
I0517 21:07:53.922832  9497 layer_factory.hpp:78] Creating layer fc6
I0517 21:07:53.922854  9497 net.cpp:101] Creating Layer fc6
I0517 21:07:53.922866  9497 net.cpp:462] fc6 &lt;- pool5
I0517 21:07:53.922880  9497 net.cpp:431] fc6 -&gt; fc6
I0517 21:07:54.066718  9497 net.cpp:152] Setting up fc6
I0517 21:07:54.066815  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.066866  9497 layer_factory.hpp:78] Creating layer relu6
I0517 21:07:54.066887  9497 net.cpp:101] Creating Layer relu6
I0517 21:07:54.066912  9497 net.cpp:462] relu6 &lt;- fc6
I0517 21:07:54.066927  9497 net.cpp:418] relu6 -&gt; fc6 (in-place)
I0517 21:07:54.066947  9497 net.cpp:152] Setting up relu6
I0517 21:07:54.066964  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.066980  9497 layer_factory.hpp:78] Creating layer drop6
I0517 21:07:54.067009  9497 net.cpp:101] Creating Layer drop6
I0517 21:07:54.067023  9497 net.cpp:462] drop6 &lt;- fc6
I0517 21:07:54.067036  9497 net.cpp:418] drop6 -&gt; fc6 (in-place)
I0517 21:07:54.067064  9497 net.cpp:152] Setting up drop6
I0517 21:07:54.067078  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.067095  9497 layer_factory.hpp:78] Creating layer fc7
I0517 21:07:54.067111  9497 net.cpp:101] Creating Layer fc7
I0517 21:07:54.067121  9497 net.cpp:462] fc7 &lt;- fc6
I0517 21:07:54.067136  9497 net.cpp:431] fc7 -&gt; fc7
I0517 21:07:54.136657  9497 net.cpp:152] Setting up fc7
I0517 21:07:54.136742  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.136790  9497 layer_factory.hpp:78] Creating layer relu7
I0517 21:07:54.136811  9497 net.cpp:101] Creating Layer relu7
I0517 21:07:54.136826  9497 net.cpp:462] relu7 &lt;- fc7
I0517 21:07:54.136842  9497 net.cpp:418] relu7 -&gt; fc7 (in-place)
I0517 21:07:54.136860  9497 net.cpp:152] Setting up relu7
I0517 21:07:54.136873  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.136888  9497 layer_factory.hpp:78] Creating layer drop7
I0517 21:07:54.136904  9497 net.cpp:101] Creating Layer drop7
I0517 21:07:54.136916  9497 net.cpp:462] drop7 &lt;- fc7
I0517 21:07:54.136930  9497 net.cpp:418] drop7 -&gt; fc7 (in-place)
I0517 21:07:54.136957  9497 net.cpp:152] Setting up drop7
I0517 21:07:54.136971  9497 net.cpp:160] Top shape: 10 4096 (40960)
I0517 21:07:54.136988  9497 layer_factory.hpp:78] Creating layer fc8
I0517 21:07:54.137003  9497 net.cpp:101] Creating Layer fc8
I0517 21:07:54.137015  9497 net.cpp:462] fc8 &lt;- fc7
I0517 21:07:54.137029  9497 net.cpp:431] fc8 -&gt; fc8
I0517 21:07:54.149531  9497 net.cpp:152] Setting up fc8
I0517 21:07:54.149677  9497 net.cpp:160] Top shape: 10 1000 (10000)
I0517 21:07:54.149727  9497 layer_factory.hpp:78] Creating layer prob
I0517 21:07:54.149750  9497 net.cpp:101] Creating Layer prob
I0517 21:07:54.149763  9497 net.cpp:462] prob &lt;- fc8
I0517 21:07:54.149780  9497 net.cpp:431] prob -&gt; prob
I0517 21:07:54.149811  9497 net.cpp:152] Setting up prob
I0517 21:07:54.149827  9497 net.cpp:160] Top shape: 10 1000 (10000)
I0517 21:07:54.149840  9497 net.cpp:241] prob does not need backward computation.
I0517 21:07:54.149855  9497 net.cpp:241] fc8 does not need backward computation.
I0517 21:07:54.149868  9497 net.cpp:241] drop7 does not need backward computation.
I0517 21:07:54.149883  9497 net.cpp:241] relu7 does not need backward computation.
I0517 21:07:54.149894  9497 net.cpp:241] fc7 does not need backward computation.
I0517 21:07:54.149906  9497 net.cpp:241] drop6 does not need backward computation.
I0517 21:07:54.149917  9497 net.cpp:241] relu6 does not need backward computation.
I0517 21:07:54.149930  9497 net.cpp:241] fc6 does not need backward computation.
I0517 21:07:54.149941  9497 net.cpp:241] pool5 does not need backward computation.
I0517 21:07:54.149955  9497 net.cpp:241] relu5 does not need backward computation.
I0517 21:07:54.149966  9497 net.cpp:241] conv5 does not need backward computation.
I0517 21:07:54.149981  9497 net.cpp:241] relu4 does not need backward computation.
I0517 21:07:54.149992  9497 net.cpp:241] conv4 does not need backward computation.
I0517 21:07:54.150004  9497 net.cpp:241] relu3 does not need backward computation.
I0517 21:07:54.150017  9497 net.cpp:241] conv3 does not need backward computation.
I0517 21:07:54.150029  9497 net.cpp:241] pool2 does not need backward computation.
I0517 21:07:54.150043  9497 net.cpp:241] norm2 does not need backward computation.
I0517 21:07:54.150055  9497 net.cpp:241] relu2 does not need backward computation.
I0517 21:07:54.150070  9497 net.cpp:241] conv2 does not need backward computation.
I0517 21:07:54.150082  9497 net.cpp:241] pool1 does not need backward computation.
I0517 21:07:54.150096  9497 net.cpp:241] norm1 does not need backward computation.
I0517 21:07:54.150109  9497 net.cpp:241] relu1 does not need backward computation.
I0517 21:07:54.150121  9497 net.cpp:241] conv1 does not need backward computation.
I0517 21:07:54.150133  9497 net.cpp:241] data does not need backward computation.
I0517 21:07:54.150146  9497 net.cpp:284] This network produces output prob
I0517 21:07:54.150177  9497 net.cpp:298] Network initialization done.
I0517 21:07:54.150189  9497 net.cpp:299] Memory required for data: 83232440
I0517 21:07:54.150353  9497 caffe.cpp:361] Performing Forward
I0517 21:07:55.137918  9497 caffe.cpp:366] Initial loss: 0
I0517 21:07:55.138103  9497 caffe.cpp:367] Performing Backward
I0517 21:07:55.138175  9497 caffe.cpp:375] *** Benchmark begins ***
I0517 21:07:55.138242  9497 caffe.cpp:376] Testing for 50 iterations.
*** Aborted at 1463512075 (unix time) try "date -d @1463512075" if you are using GNU date ***
PC: @     0x7f9c9e306990 caffe::device::device()
*** SIGSEGV (@0x28) received by PID 9497 (TID 0x7f9c9e83cac0) from PID 40; stack trace: ***
    @     0x7f9c9ce98d40 (unknown)
    @     0x7f9c9e306990 caffe::device::device()
    @           0x41266e caffe::Layer&lt;&gt;::Forward()
    @           0x40fcf8 time()
    @           0x40cd6c main
    @     0x7f9c9ce83ec5 (unknown)
    @           0x40d52e (unknown)
    @                0x0 (unknown)
Segmentation fault (core dumped)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='wertig0n' date='2016-05-17T19:37:06Z'>
		It seems like the device "dies" after the first forward/backward pass of CaffeNet/AlexNet, which is strange...
Since you have two OpenCL devices (CPU and GPU), does the same happen when you run:
./build/tools/caffe time -model models/bvlc_alexnet/deploy.prototxt -gpu=1
Might be slow, given it's a Core2Duo generation CPU, but definitely worth a try to rule out the issue (which could be driver related...)
		</comment>
		<comment id='8' author='wertig0n' date='2016-05-17T20:01:38Z'>
		Speed-wise it's actually faster - it core dumps almost instantly.
See attached file.
&lt;denchmark-link:https://github.com/BVLC/caffe/files/269049/results.txt&gt;results.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='wertig0n' date='2016-05-17T20:10:46Z'>
		Could it be that I'm missing something from my Makefile.config? See attachment.
&lt;denchmark-link:https://github.com/BVLC/caffe/files/269058/Makefile.config.txt&gt;Makefile.config.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='wertig0n' date='2016-05-18T08:48:17Z'>
		You could try if it helps to comment out USE_CUDA := 0, instead of setting to 0
But the configuration otherwise seems fine.
I was able to reproduce the error on my machine though and commited some changes. Could you try if the error persists in the latest code version? Just make sure to do a "make clean" before "make all".
		</comment>
		<comment id='11' author='wertig0n' date='2016-05-18T14:28:59Z'>
		Ok, tested it.
It works with gpu=0 but gpu=1 I get a complaint from viennacl about a kernel missing. I decided to go ahead and try to resume training with a small step size, I should know pretty soon if it's working or not.
Thanks a ton for the help! :)
		</comment>
		<comment id='12' author='wertig0n' date='2016-05-18T14:34:59Z'>
		&lt;denchmark-link:https://github.com/wertig0n&gt;@wertig0n&lt;/denchmark-link&gt;

Then I consider this bug closed. If you experience training issues or have doubts about performance, just open up another one. It could be that C2D, C2Q are not fully supported by AMDs OpenCL...
		</comment>
		<comment id='13' author='wertig0n' date='2016-05-18T14:46:00Z'>
		Hmm, nope... If I have a step size of 1000 it trains for the first 1000 iterations and completes the step, and then... Nothing.
Going to try to increase the step size to 10 000 now.
		</comment>
		<comment id='14' author='wertig0n' date='2016-05-18T15:15:08Z'>
		&lt;denchmark-link:https://github.com/wertig0n&gt;@wertig0n&lt;/denchmark-link&gt;

That's interesting, I don't think anything special other than changing the learning rate happens at the step size boundary.
What about a small step size such as 100? Does it crash after 100 then?
		</comment>
		<comment id='15' author='wertig0n' date='2016-05-18T18:46:09Z'>
		Yes, it seems that way - nothing I do changes it. It completes Test net 0 and 1, and then it hangs.
Could it be that my dataset is really small and that's what sets it off? Since I have a batch-size of 256 but only around 150 images to train on, it might affect stuff, but I'm not sure. I'm like a total newbie on this stuff so... :)
I've provided the output up until when it "crashes" (more like, it goes idle and then I cannot do anything with the console window, trying to kill Caffe results in a zombie process).
Since it's multithreaded I'd suspect a deadlock condition, but I have no idea if it is caffe or if it's me doing something I shouldn't. I have a CPU-version of caffe around as well, I will try that to see if it's working and get back to you later.
&lt;denchmark-link:https://github.com/BVLC/caffe/files/271162/results.txt&gt;output.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='wertig0n' date='2016-05-18T18:52:57Z'>
		What you can try to see if something with your example or the OpenCL Caffe might be wrong, is running an example that I know is working (or supposed to be):
&lt;denchmark-code&gt;./data/mnist/get_mnist.sh
./examples/mnist/create_mnist.sh
./examples/mnist/train_lenet.sh
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='wertig0n' date='2016-05-18T19:16:50Z'>
		I tried with CPU training - Caffe regular have no problem with this network. It must be something specific to Caffe-opencl.
I'll try with lenet next.
		</comment>
		<comment id='18' author='wertig0n' date='2016-05-18T21:15:16Z'>
		Ok, Lenet works as it should, moving very rapidly through the iterations.
So, this has something to do with caffenet then - is there any other network I can use for image classification tasks? Or could this perhaps have something to do with how I created the caffenet clone... Hmmm. Getting closer I feel like.
		</comment>
		<comment id='19' author='wertig0n' date='2016-05-18T21:25:35Z'>
		&lt;denchmark-link:https://github.com/wertig0n&gt;@wertig0n&lt;/denchmark-link&gt;

It's very hard to tell for me why it doesn't work on your card.
LeNet is considerably smaller than CaffeNet, so maybe a memory issue (?).
You can try to play around with parameters, such as:

batch_size from 256 to 128 or 64, and adjusting the base learning rate accordingly (increase it by a factor of (sqrt(256-128) or sqrt(256-64)) to get the same "learning speed".
batch_size is in train_val.prototxt
base_lr is in solver.prototxt

What's strange though is that you don't get an error message about a kernel that failed or memory allocation errors (as it should give in that situation). And how high does the main memory get when you train CaffeNet on the CPU? Although there you can probably go way beyond the 4 GB due to the swap file/partition.
		</comment>
		<comment id='20' author='wertig0n' date='2016-05-18T21:30:09Z'>
		Yes, maybe a memory issue but the behavior makes me suspect some sort of deadlock condition arise, because the behavior is typical for deadlocks (the application is idling). I'll check further on it tomorrow, now I'm going to let both the computer and myself get some well-needed rest :)
		</comment>
		<comment id='21' author='wertig0n' date='2016-05-18T21:34:45Z'>
		There are no deadlocks possible in the code. CPU is single threaded and GPU kernels are scheduled on one queue only. Only the data loader may use multiple threads, but that is likewise possible on both CPU and GPU training.
With AMD cards, the driver can have a crash situation in which the application isn't doing anything anymore (waiting for a kernel to complete) while the OpenCL kernel is dead. This is far more likely and could arise due to the card trying to allocate more resources when there aren't any left.
		</comment>
		<comment id='22' author='wertig0n' date='2016-05-19T07:26:11Z'>
		Yes, you were right, it was my card crashing. It trains now with a batch size of 128 and a learning rate of 0.11.
And yes, not technicly a deadlock but same result (one thread "crashed" and the other waited for that thread to release resources - which never happened since the thread crashed). Thank you very much for your help and time! :)
		</comment>
	</comments>
</bug>