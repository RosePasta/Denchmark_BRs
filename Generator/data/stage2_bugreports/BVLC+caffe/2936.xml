<bug id='2936' author='ronghanghu' open_date='2015-08-16T07:29:04Z' closed_time='2017-01-17T20:50:03Z'>
	<summary>Reconcile PythonLayer with Multi-GPU</summary>
	<description>
Right now PythonLayer cannot be parallelized in MultiGPU, which is a bug. Python Global Interpreter Lock (GIL) only allows one thread at a time to run in the python interpreter. This issue is reported in &lt;denchmark-link:https://github.com/BVLC/caffe/issues/2923&gt;#2923&lt;/denchmark-link&gt;
.
We should find a solution to to this bug, or only allow shared PythonLayer and serializing PythonLayer forward (currently via ) it in MultiGPU (then we need a backward lock, too? but it is more complicated than that &lt;denchmark-link:https://github.com/BVLC/caffe/issues/2923#issuecomment-131504078&gt;#2923 (comment)&lt;/denchmark-link&gt;
) Perhaps we may use &lt;denchmark-link:https://docs.python.org/2/library/multiprocessing.html&gt;multiprocessing&lt;/denchmark-link&gt;
 module to fix this bug? But on second thought it doesn't seem like a good idea either.
	</description>
	<comments>
		<comment id='1' author='ronghanghu' date='2015-08-16T07:37:24Z'>
		This is not going to work that cleanly. Multi-process means multiple gpu
contexts and a different multi-gpu design leading to some perf loss.
Moreover, data exchange in general becomes much more complex.
Still amazes me that python doesn't support threading in a reasonable way.
On Aug 16, 2015 12:29 AM, "Ronghang Hu" &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;
 wrote:

Right now PythonLayer cannot be parallelized, which is a bug. Python
Global Interpreter Lock (GIL) only allows one thread at a time to run in
the python interpreter. This issue is reported in #2923
#2923.
We may use multiprocessing
https://docs.python.org/2/library/multiprocessing.html module to fix
this bug.
â€”
Reply to this email directly or view it on GitHub
#2936.

		</comment>
		<comment id='2' author='ronghanghu' date='2015-08-16T07:51:58Z'>
		
This is not going to work that cleanly. Multi-process means multiple gpu
contexts and a different multi-gpu design leading to some perf loss.
Moreover, data exchange in general becomes much more complex.

Yes, I totally agree with you. On second thought maybe Python's multiprocessing module is not suitable here.
		</comment>
		<comment id='3' author='ronghanghu' date='2015-08-16T10:04:23Z'>
		Joblib allows you to use a threading backend when used in conjunction with Cython and releasing the GIL. Maybe that work be appropriate here?
		</comment>
		<comment id='4' author='ronghanghu' date='2015-08-16T10:14:07Z'>
		A manual little example to workaround GIL &lt;denchmark-link:http://pieceofpy.com/2010/02/26/boost-python-threads-and-releasing-the-gil/&gt;http://pieceofpy.com/2010/02/26/boost-python-threads-and-releasing-the-gil/&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ronghanghu' date='2015-08-16T18:34:10Z'>
		The straightforward (and perhaps naive) workaround seems to be to serialize all calls to any Python code, i.e. only allow having one PythonLayer execution at a time to behave like before. This can be done via a global python lock, perhaps as a static member variable in PythonLayer class.
From my perspective, I think serializing python execution is reasonable for CPU Bound PythonLayer since Python interpretation is always serialized in GIL and never actually run in parallel. One may argue for the case of IO Bound PythonLayer (such as using PythonLayer as a data layer), but then I would not even expect to run into this case since people should set share_in_parallel: true to share it among workers to load data sequentially (avoiding loading all the same data for each solver). And after all, even for IO Bound PythonLayer with set share_in_parallel: false, serialized execution is still better than a crash.
Any comment?
		</comment>
		<comment id='6' author='ronghanghu' date='2015-08-16T18:37:05Z'>
		In the short term until this gets sorted out, perhaps setting share_in_parallel to false on the PythonLayer should print a fatal message explaining that the unshared case is not implemented yet.
		</comment>
		<comment id='7' author='ronghanghu' date='2015-08-16T18:42:04Z'>
		But even for the shared case, backward is not working correctly &lt;denchmark-link:https://github.com/BVLC/caffe/issues/2923#issuecomment-131504078&gt;#2923 (comment)&lt;/denchmark-link&gt;
, as in &lt;denchmark-link:https://github.com/BVLC/caffe/pull/2903&gt;#2903&lt;/denchmark-link&gt;
 I only expected a PythonLayer to be shared when used as a data layer and performs no backward.
		</comment>
		<comment id='8' author='ronghanghu' date='2015-08-16T18:50:12Z'>
		You could also give a fatal message for that case too.
I agree that this is tricky and don't have a solution, but failing cleanly is a reasonable placeholder.
		</comment>
		<comment id='9' author='ronghanghu' date='2015-08-20T12:16:11Z'>
		This is probably a stupid idea, but would it be possible to start several python process, each with their own GIL? My bad.
		</comment>
		<comment id='10' author='ronghanghu' date='2015-08-20T12:21:25Z'>
		&lt;denchmark-link:https://github.com/BlGene&gt;@BlGene&lt;/denchmark-link&gt;
 see &lt;denchmark-link:https://github.com/thatguymike&gt;@thatguymike&lt;/denchmark-link&gt;
 and  &lt;denchmark-link:https://github.com/ronghanghu&gt;@ronghanghu&lt;/denchmark-link&gt;
 comments on python multiprocess
		</comment>
		<comment id='11' author='ronghanghu' date='2015-08-20T17:44:25Z'>
		I'm leaving this issue open for further discussion. &lt;denchmark-link:https://github.com/BVLC/caffe/pull/2939&gt;#2939&lt;/denchmark-link&gt;
 provides a workaround for the crash but it is indeed not very satisfactory, and I don't like &lt;denchmark-link:https://github.com/BVLC/caffe/pull/2939&gt;#2939&lt;/denchmark-link&gt;
 either. On the other hand, multi-process is a hacky way to go. Everyone are welcome to share if they have good ideas/solutions to this issue.
		</comment>
		<comment id='12' author='ronghanghu' date='2016-06-23T13:35:02Z'>
		What about to implement a method pyforward and pybackward in Net class C++ definition, such that it just releases GIL by means of a ScopedGILRelease and immediately after calls the forward (or backward) methods. Then, simply expose pyforward and pybackward functions to boost interface.
Otherwise, a PyNet C++ class that inherit from Net, and override forward and backward doing simply GIL realease and call super.forward() (or super.backward()).
At least for the most used time consuming/commonly used methods is important to release GIL, otherwise making caffe not suited to production multi-threaded python applications.
		</comment>
		<comment id='13' author='ronghanghu' date='2016-06-23T13:50:05Z'>
		&lt;denchmark-link:https://github.com/ronghanghu&gt;@ronghanghu&lt;/denchmark-link&gt;

I do release the GIL for the forward/backward passes in the OpenCL branch and it seems to work fine so far, also with using multiple GPUs on multiple threads (although for data parallel computation and not multi-GPU training).
For the python layer, the GIL gets re-acquired and it passes the python runtests like that.
		</comment>
		<comment id='14' author='ronghanghu' date='2016-06-24T09:24:02Z'>
		I have done a pull request for fix it &lt;denchmark-link:https://github.com/BVLC/caffe/pull/4360&gt;#4360&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='ronghanghu' date='2017-01-17T20:50:02Z'>
		Each net can run in it's own fork now, there is an example in /python/train.py. &lt;denchmark-link:https://github.com/BVLC/caffe/pull/4563&gt;#4563&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='ronghanghu' date='2017-07-25T14:06:49Z'>
		I can't understand why this was closed? &lt;denchmark-link:https://github.com/BVLC/caffe/pull/4563&gt;#4563&lt;/denchmark-link&gt;
 doesn't release GIL. It only implements multiple GPU training. I wan't to have multiple workers with shared memory and single GPU thread to stream forward passes only, but everything gets blocked during forward pass. What's wrong with &lt;denchmark-link:https://github.com/BVLC/caffe/pull/4360&gt;#4360&lt;/denchmark-link&gt;
, except code style?
		</comment>
		<comment id='17' author='ronghanghu' date='2018-07-05T20:39:41Z'>
		Sorry, so is there any way to create a custom data layer with multiple GPU?
		</comment>
	</comments>
</bug>