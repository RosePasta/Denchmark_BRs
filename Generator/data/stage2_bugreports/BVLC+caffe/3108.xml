<bug id='3108' author='beniz' open_date='2015-09-22T13:01:03Z' closed_time='2017-04-14T04:12:04Z'>
	<summary>Data source identification breaks the loading of multiple instances of the same net</summary>
	<description>
Source identification at &lt;denchmark-link:https://github.com/BVLC/caffe/blob/master/include/caffe/data_reader.hpp#L68&gt;https://github.com/BVLC/caffe/blob/master/include/caffe/data_reader.hpp#L68&lt;/denchmark-link&gt;
 was introduced by &lt;denchmark-link:https://github.com/BVLC/caffe/commit/bcc8f50a95ecad954d1887f3fb273eaa298e2274&gt;bcc8f50&lt;/denchmark-link&gt;
 and leads to raising a fatal check at  &lt;denchmark-link:https://github.com/BVLC/caffe/blob/master/src/caffe/data_reader.cpp#L98&gt;https://github.com/BVLC/caffe/blob/master/src/caffe/data_reader.cpp#L98&lt;/denchmark-link&gt;
 whenever two nearly identical nets train concurrently (e.g. on a single GPU).
The problem occurs if two nets are trained concurrently and share:

layer names
data source

This typically occurs when training several nets with different layer parameters but identical source and layer names.
My current solution to this problem is to enrich the source identification routine with a hash of the running thread, but my understanding is that it might break the original detection of identical sources from within the same net. For this reason, I am not sharing a PR in order to gather more thoughts on this issue.
	</description>
	<comments>
		<comment id='1' author='beniz' date='2015-09-22T14:02:38Z'>
		Different symptom but same underlying issue reported here: &lt;denchmark-link:https://github.com/BVLC/caffe/issues/3037&gt;#3037&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='beniz' date='2015-11-05T09:41:24Z'>
		I can confirm that this is a bug in need of attention.

This breaks multiple nets using the same source (even, e.g., reloading a net from an interactive Python session).
The encoding of sources in strings is bogus and not necessary; e.g., ":" is a valid character in both layer names and file names, so spurious collisions are possible.

		</comment>
		<comment id='3' author='beniz' date='2015-11-05T10:55:34Z'>
		Then for the sake of discussion,  here is my fix from last month: &lt;denchmark-link:https://github.com/jolibrain/caffe/commit/70fd4f7ee2f378e8302e387c97fb8d0fdad9c355&gt;jolibrain@70fd4f7&lt;/denchmark-link&gt;

One of the many reasons you may not want this in vanilla Caffe is that it requires a C++11 compiler.
		</comment>
		<comment id='4' author='beniz' date='2016-07-23T00:23:08Z'>
		So I have the same issue...is there a fix yet?
		</comment>
		<comment id='5' author='beniz' date='2016-07-23T08:21:21Z'>
		&lt;denchmark-link:https://github.com/tarunsharma1&gt;@tarunsharma1&lt;/denchmark-link&gt;
 if you use the fork I maintain at &lt;denchmark-link:https://github.com/beniz/caffe&gt;https://github.com/beniz/caffe&lt;/denchmark-link&gt;
 it should work fine. This fork remains up to date with master with a short delay. You'd need a C++11 compiler however.
		</comment>
		<comment id='6' author='beniz' date='2016-07-23T15:30:27Z'>
		This is for other/new users who have the same issue and want a quick easy hack around it. This is not a permanent solution  -&gt;
Turns out that the issue is with opening the same lmdb twice irrespective of whether you use CPU or GPU. A quick fix is to make a copy of your lmdb and give it a different name and use these two different lmdb names in your two networks respectively.
Does not work
Net1 -&gt; train_lmdb
Net2 -&gt; train_lmdb
Works
Net1 -&gt; train_lmdb
Net2 -&gt; train_lmdb_copy
		</comment>
		<comment id='7' author='beniz' date='2016-07-26T21:13:41Z'>
		So FTR, I've tested my branch against &lt;denchmark-link:https://github.com/BVLC/caffe/issues/3037&gt;#3037&lt;/denchmark-link&gt;
 and it doesn't fix the problem there. I believe this is because my fix uses the thread id, which fixes the issue when training multiple models from the same data source using multiple threads, not from the same inner model.
		</comment>
		<comment id='8' author='beniz' date='2017-04-14T04:12:04Z'>
		Fixed by the parallelism reformation in &lt;denchmark-link:https://github.com/BVLC/caffe/pull/4563&gt;#4563&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>