<bug id='69' author='rwightman' open_date='2020-08-01T20:17:52Z' closed_time='2020-08-28T06:11:03Z'>
	<summary>PyTorch 1.6 breaks with apex SyncBn</summary>
	<description>
PyTorch 1.6 using the SyncBatchnorm in apex is throwing an exception. No such issues with PyTorch 1.4 or 1.5.x.
Hacking up the current code to force Torch native DDP + SyncBN (w/ Apex amp for mixed prec) works fine but there is a throughput drop of 5-6%.
I likely won't fix this until I have a moment to properly support native amp autocast. Then Apex primitives will only be used pre 1.6 and &gt;= 1.6 will use all torch native mixed prec + distributed training helpers.
Call stack for anyone that runs into it:
&lt;denchmark-code&gt;  File "envs/pytorch-16/lib/python3.8/site-packages/apex/parallel/optimized_sync_batchnorm.py", line 85, in forward
    return SyncBatchnormFunction.apply(input, z, self.weight, self.bias, self.running_mean, self.running_var, self.eps, self.training or not self.track_running_stats, exponential_average_factor, self.process_group, channel_last, self.fuse_relu)
  File "envs/pytorch-16/lib/python3.8/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py", line 36, in forward
    torch.distributed.all_gather(mean_l, mean, process_group)
  File "envs/pytorch-16/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1185, in all_gather
    work = _default_pg.allgather([tensor_list], [tensor])
RuntimeError: All tensor operands to scatter/gather must have the same size
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rwightman' date='2020-08-02T21:52:56Z'>
		Related: &lt;denchmark-link:https://github.com/pytorch/pytorch/pull/40573&gt;pytorch/pytorch#40573&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='rwightman' date='2020-08-28T06:11:03Z'>
		Fixed by &lt;denchmark-link:https://github.com/NVIDIA/apex/pull/942&gt;NVIDIA/apex#942&lt;/denchmark-link&gt;
 ... pull apex and rebuild.
		</comment>
	</comments>
</bug>