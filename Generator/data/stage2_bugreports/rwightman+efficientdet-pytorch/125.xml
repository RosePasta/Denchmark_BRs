<bug id='125' author='MichaelMonashev' open_date='2020-11-13T08:48:54Z' closed_time='2020-11-13T16:05:57Z'>
	<summary>[QUESTION] How to predict bounding boxed on big images with model trained on small images?</summary>
	<description>
I have efficientdet-d1 trained on images 640x640. And trying to predict bboxes on image 2048x2048.
I loaded model from snapshot and tried to change image_size for model.config to recreate anchors. But got error "omegaconf.errors.ReadonlyConfigError: Cannot change read-only config container" .
I look to the reset_head() , but it do not change anchors.
Think that I am going wrong way.
How to predict bounding boxed on big images with model trained on small images?
	</description>
	<comments>
		<comment id='1' author='MichaelMonashev' date='2020-11-13T11:50:41Z'>
		I found solution:
&lt;denchmark-code&gt;        config = get_efficientdet_config(model_name)
        config.image_size=(2048, 2048)

        self.model = create_model_from_config(config,
            bench_task='predict',
            num_classes=num_classes,
            pretrained=False,
            pretrained_backbone=False,
            checkpoint_path = '/snapshots/efficientdet-d1.pth',
        )
&lt;/denchmark-code&gt;

Is it correct?
		</comment>
		<comment id='2' author='MichaelMonashev' date='2020-11-17T19:16:02Z'>
		Correct me if I am wrong!
So the Efficientdet-D0 model requires (512, 512) as the input image size.
My dataset consists images of size (600, 800)(H*W) input image size.
So 1) I resize the original image(600*800 ) to (512, 512) and scale the groundtruth bounding box accordingly.
While observing the bbox prediction output I see the bbox coordinates are higher than 512.
For eg, consider the bbox as [x1,y1,x2,y2] format I observe the output bbox as [0,0,700,600]
This means the output bbox is according to the original image and not the resized (512, 512) image.
I see out of 100 boxes 80 are in the wat discussed above. The shocking part is these boxes have higher classification scores like above 0.77 and all.
Am I understanding the concept correctly?
Any help appreciated!

I found solution:
        config = get_efficientdet_config(model_name)
        config.image_size=(2048, 2048)

        self.model = create_model_from_config(config,
            bench_task='predict',
            num_classes=num_classes,
            pretrained=False,
            pretrained_backbone=False,
            checkpoint_path = '/snapshots/efficientdet-d1.pth',
        )

Is it correct?

		</comment>
		<comment id='3' author='MichaelMonashev' date='2020-11-17T19:34:28Z'>
		
I found solution:
        config = get_efficientdet_config(model_name)
        config.image_size=(2048, 2048)

        self.model = create_model_from_config(config,
            bench_task='predict',
            num_classes=num_classes,
            pretrained=False,
            pretrained_backbone=False,
            checkpoint_path = '/snapshots/efficientdet-d1.pth',
        )

Is it correct?

I have one more question, when you input the (2048, 2048) image in the loader while predicting the create_loader takes you to transforms ResizePad function where the image resizes to (640, 640) because the efficientdet-d1 requires 640*640 image to operate, and then calculate the predictions correspondingly right?
So I don't think the larger image would arise problem.
		</comment>
		<comment id='4' author='MichaelMonashev' date='2020-11-18T10:59:09Z'>
		&lt;denchmark-link:https://github.com/Ekta246&gt;@Ekta246&lt;/denchmark-link&gt;
 , I am using &lt;denchmark-link:https://albumentations.ai/&gt;https://albumentations.ai/&lt;/denchmark-link&gt;
 for data augmentation. It can crop and resize image and bboxes together.

While observing the bbox prediction output I see the bbox coordinates are higher than 512.

I am clipping bbox.
		</comment>
	</comments>
</bug>