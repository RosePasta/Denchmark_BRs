<bug id='3617' author='jerrylam' open_date='2019-07-08T13:42:38Z' closed_time='2019-07-14T18:34:27Z'>
	<summary>EKS GPU Support Issue (nvidia-device-plugin-daemonset crashes)</summary>
	<description>
I'm using kubeflow v0.5-branch and k8s version 1.12
I followed the instruction on updating the cluster_config.yaml to include this:
&lt;denchmark-code&gt;  - name: Tesla-V100
    instanceType: p2.xlarge
    desiredCapacity: 1
    minSize: 0
    maxSize: 2
    volumeSize: 50
    ssh:
      allow: true
      publicKeyPath: '~/.ssh/id_rsa.pub'
&lt;/denchmark-code&gt;

After the nodegroup starts and apply k8s, I noticed that nvidia-device-plugin-daemonset pod crashed.
Looking at the error, this is what I got:
&lt;denchmark-code&gt;  Warning  Failed     8m2s                   kubelet, ip-x.ap-south-1.compute.internal  Error: failed to start 
container "nvidia-device-plugin-ctr": Error response from daemon: OCI runtime create failed: 
container_linux.go:348: starting container process caused "process_linux.go:402: container init caused 
\"process_linux.go:385: running prestart hook 0 caused \\\"error running hook: exit status 1, stdout: , 
stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --
ldconfig=@/sbin/ldconfig --device=all --utility --pid=28909 
/var/lib/docker/overlay2/d2a5b4a4bad7f9f3b6c9c2c10137e76958c225b9a056475f0129a3f84b13dd8
f/merged]\\\\nnvidia-container-cli: initialization error: cuda error: no cuda-capable device is 
detected\\\\n\\\"\"": unknown
&lt;/denchmark-code&gt;

There is only one nodegroup that is the p2.xlarge above.
Anyone knows what I'm missing?
Thanks!
	</description>
	<comments>
		<comment id='1' author='jerrylam' date='2019-07-08T13:42:41Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.77. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='jerrylam' date='2019-07-14T18:34:27Z'>
		I found out the reason. It is because the default AMI for GPU is out-dated. It needs to be specified in the cluster_config.yaml to get it to work.
		</comment>
		<comment id='3' author='jerrylam' date='2019-09-11T13:23:36Z'>
		I had the same problem recently. Minimal supported version of eksctl is 0.1.31 according to  the installation instructions. However, 0.1.31 uses an old AMI id. Upgrading eksctl to version 0.5.2 solves the problem for me since it specifies the correct, new AMI.
		</comment>
	</comments>
</bug>