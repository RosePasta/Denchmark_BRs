<bug id='4965' author='lalithvaka' open_date='2020-04-17T18:01:40Z' closed_time='2020-04-24T01:46:50Z'>
	<summary>Profile creation through central dashboard vs kubectl YAML does not have the same behavior</summary>
	<description>
/kind bug

Kubeflow 1.0.2 enabled with OIDC integration. Have one of the user(&lt;denchmark-link:mailto:a264297@xx.com&gt;a264297@xx.com&lt;/denchmark-link&gt;
) login through the central dashboard and self service profile got created. Also, created a manual profile through kubectl using &lt;denchmark-link:https://www.kubeflow.org/docs/components/multi-tenancy/getting-started/#manual-profile-creation&gt;https://www.kubeflow.org/docs/components/multi-tenancy/getting-started/#manual-profile-creation&lt;/denchmark-link&gt;
 yaml file
apiVersion: kubeflow.org/v1beta1
kind: Profile
metadata:
name: poc1   # replace with the name of profile you want
spec:
owner:
kind: User
name: &lt;denchmark-link:mailto:xxxx@xx.com&gt;xxxx@xx.com&lt;/denchmark-link&gt;
   # replace with the email of the user
‚ûú kubectl get-all -n poc1
No resources found.
(base)
~/Installs/profiles via üÖí base at ‚ò∏Ô∏è kubernetes-admin@kubernetes took 8s
‚ûú kubectl get-all -n a264297
NAME                                                  NAMESPACE  AGE
secret/default-editor-token-tfqr7                     a264297    34h
secret/default-token-xn9xh                            a264297    34h
secret/default-viewer-token-lggrz                     a264297    34h
secret/istio.default                                  a264297    34h
secret/istio.default-editor                           a264297    34h
secret/istio.default-viewer                           a264297    34h
serviceaccount/default                                a264297    34h
serviceaccount/default-editor                         a264297    34h
serviceaccount/default-viewer                         a264297    34h
rolebinding.rbac.authorization.k8s.io/default-editor  a264297    34h
rolebinding.rbac.authorization.k8s.io/default-viewer  a264297    34h
rolebinding.rbac.authorization.k8s.io/namespaceAdmin  a264297    34h
servicerolebinding.rbac.istio.io/owner-binding-istio  a264297    34h
servicerole.rbac.istio.io/ns-access-istio             a264297    34h

&lt;denchmark-link:mailto:xxxx@xx.com&gt;xxxx@xx.com&lt;/denchmark-link&gt;
 is not able to login to the central dashboard as the UI is still asking to create a new profile even though &lt;denchmark-link:mailto:xxxx@xx.com&gt;xxxx@xx.com&lt;/denchmark-link&gt;
 is the owner of the profile.
Also the expected both methods to have same resources created in their respective namespaces
Anything else you would like to add:
[Miscellaneous information that will assist in solving the issue.]
Environment:

Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard): 1.0.2
kfctl version: (use kfctl version):
Kubernetes platform: (e.g. minikube)
Kubernetes version: (use kubectl version):
OS (e.g. from /etc/os-release):

	</description>
	<comments>
		<comment id='1' author='lalithvaka' date='2020-04-17T18:01:53Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




kind/bug
0.98



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='lalithvaka' date='2020-04-17T20:39:56Z'>
		/area centraldashboard
/priority p1
		</comment>
		<comment id='3' author='lalithvaka' date='2020-04-22T00:59:28Z'>
		/cc &lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='lalithvaka' date='2020-04-22T01:15:40Z'>
		What's your platform? For AWS users using ALB with either Cognito or OIDC, user can change to other claims beside email. It takes some efforts and needs some customizations. This is something we have not tried yet, we use email by default and required IDP to verify user emails (Otherwise, a valid IDP user don't necessarily have email)
		</comment>
		<comment id='5' author='lalithvaka' date='2020-04-22T03:11:56Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 here are the YAML extracts as below
a264297 profile is created using central dashboard self service method by doing a SSO
poc1 profile is created using the YAML example from kubeflow.org
‚ûú kubectl get profile a264297 -o yaml
apiVersion: kubeflow.org/v1
kind: Profile
metadata:
creationTimestamp: "2020-04-16T04:06:58Z"
finalizers:

profile-finalizer
generation: 2
name: a264297
resourceVersion: "155374"
selfLink: /apis/kubeflow.org/v1/profiles/a264297
uid: 0637a739-f929-4d42-800d-383930cc249b
spec:
owner:
kind: User
name: A264297@zq.msds.kp.org
resourceQuotaSpec: {}

‚ûú kubectl get profile poc1 -o yaml
apiVersion: kubeflow.org/v1
kind: Profile
metadata:
creationTimestamp: "2020-04-20T22:34:39Z"
generation: 1
name: poc1
resourceVersion: "3491829"
selfLink: /apis/kubeflow.org/v1/profiles/poc1
uid: 8c8f2eba-416c-469e-ba9e-cfa7683b789d
spec:
owner:
kind: User
name: &lt;denchmark-link:mailto:I397401@zq.msds.kp.org&gt;I397401@zq.msds.kp.org&lt;/denchmark-link&gt;

resourceQuotaSpec: {}
		</comment>
		<comment id='6' author='lalithvaka' date='2020-04-22T03:19:38Z'>
		
What's your platform? For AWS users using ALB with either Cognito or OIDC, user can change to other claims beside email. It takes some efforts and needs some customizations. This is something we have not tried yet, we use email by default and required IDP to verify user emails (Otherwise, a valid IDP user don't necessarily have email)

We are doing this onPrem on base K8S. By default the Profile creation through Self Serv method of the central dashboard uses EmailID to create RoleBindings and Owners. I was wondering if there is a configuration that I could change that would enable using EnterpriseID (JWT Subject) as the default string instead of Email. This is not a must, we could use EmailIDs, but exploring if there is a configuration option. Coz, if my Kuberenetes RBAC uses EnterpriseID instead of Email, I want Kubeflow to use the Enterprise ID as well to be consistent with Istio rback permissions as well as K8S RBac.
		</comment>
		<comment id='7' author='lalithvaka' date='2020-04-22T20:58:37Z'>
		&lt;denchmark-link:https://github.com/lalithvaka&gt;@lalithvaka&lt;/denchmark-link&gt;
 Can you provide the logs from the profile controller?
In the YAML you pasted its unclear whether indentation issues are just copy-paste issues or whether they are indicating an error in the spec.
Could you do
&lt;denchmark-code&gt;kubectl get profile ${NAME} -o yaml &gt; /tmp/${NAME}.txt
&lt;/denchmark-code&gt;

And then attach those to the GitHub issues? This should preserve formatting and we can sure the specs don't have indentation issues.
		</comment>
		<comment id='8' author='lalithvaka' date='2020-04-23T00:11:58Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 Our profile controller seems to be stuck in this indefinite loop with log msgs as following. Tried killing the pods but they come back up with these msgs non stop.. Also attaching the profile extracts
E0422 23:51:59.073724       1 reflector.go:126] pkg/mod/k8s.io/client-go@v11.0.1-0.20190409021438-1a26190bd76a+incompatible/tools/cache/reflector.go:94: Failed to list [-+]?[0-9])$', error found in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/10&gt;#10&lt;/denchmark-link&gt;
 byte of ...|ry":"20gi","memory":|..., bigger context ...|itsCpu":"4","limitsCpu1":"4","limitsMemory":"20gi","memory":"20Gi","pods":"20","requests.nvidia.com/|...
E0422 23:52:01.080516       1 reflector.go:126] pkg/mod/k8s.io/client-go@v11.0.1-0.20190409021438-1a26190bd76a+incompatible/tools/cache/reflector.go:94: Failed to list [-+]?[0-9])$', error found in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/10&gt;#10&lt;/denchmark-link&gt;
 byte of ...|ry":"20gi","memory":|..., bigger context ...|itsCpu":"4","limitsCpu1":"4","limitsMemory":"20gi","memory":"20Gi","pods":"20","requests.nvidia.com/|...
E0422 23:52:03.087673       1 reflector.go:126] pkg/mod/k8s.io/client-go@v11.0.1-0.20190409021438-1a26190bd76a+incompatible/tools/cache/reflector.go:94: Failed to list [-+]?[0-9])$', error found in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/10&gt;#10&lt;/denchmark-link&gt;
 byte of ...|ry":"20gi","memory":|..., bigger context ...|itsCpu":"4","limitsCpu1":"4","limitsMemory":"20gi","memory":"20Gi","pods":"20","requests.nvidia.com/|...
E0422 23:52:05.093619       1 reflector.go:126] pkg/mod/k8s.io/client-go@v11.0.1-0.20190409021438-1a26190bd76a+incompatible/tools/cache/reflector.go:94: Failed to list [-+]?[0-9])$', error found in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/10&gt;#10&lt;/denchmark-link&gt;
 byte of ...|ry":"20gi","memory":|..., bigger context ...|itsCpu":"4","limitsCpu1":"4","limitsMemory":"20gi","memory":"20Gi","pods":"20","requests.nvidia.com/|...
E0422 23:52:07.103127       1 reflector.go:126] pkg/mod/k8s.io/client-go@v11.0.1-0.20190409021438-1a26190bd76a+incompatible/tools/cache/reflector.go:94: Failed to list [-+]?[0-9])$', error found in &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/10&gt;#10&lt;/denchmark-link&gt;
 byte of ...|ry":"20gi","memory":|..., bigger context ...|itsCpu":"4","limitsCpu1":"4","limitsMemory":"20gi","memory":"20Gi","pods":"20","requests.nvidia.com/|...
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4519511/poc1.txt&gt;poc1.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4519514/a264297.txt&gt;a264297.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4519516/poc2.txt&gt;poc2.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='lalithvaka' date='2020-04-23T19:56:27Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 It appears that my "resourceQuotaSpec" in my poc1.txt yaml file might have caused all these issues. If I remove the following section my profile creation via YAML and self service appears to be same good.
resourceQuotaSpec:
hard:
requestsGpu: "1"
requestsCpu: "2"
requestsMemory: 20Gi
limitsCpu: "4"
limitsCpu1: "4"
limitsMemory: 20gi
cpu: "10"
memory: 20Gi
pods: "20"
requests.nvidia.com/gpu: "1"
With the help of &lt;denchmark-link:https://github.com/jtfogarty&gt;@jtfogarty&lt;/denchmark-link&gt;
 I was able to come out of the infinite parsing error in my profile-controller log which might have triggered either during the poc1 profile creation (using the YAML) or profile deletion.
The behavior if I remember right,
Step1 - created a profile thru self service
Step2 - created an yaml file with resourceQuotaSpec and ran via kubectl. Didnt complain anything on the kubectl. I did not check the logs at this point.
Step3 - Noticed the resources created under the above steps does not appear same.
Step4 - Tried deleting the profile using kubectl delete profile  .. never gracefully completed.
Step5 - new self service profile creation started failing.
Step6 - deleted the profile-controller pods and still did not work
Step7 - updated the profile poc1 using kubectl edit and removed the resourceQuotaSpec per &lt;denchmark-link:https://github.com/jtfogarty&gt;@jtfogarty&lt;/denchmark-link&gt;
 's recommendation. Profile-Controller manager log came out of the infinite parsing loop.
Step8 - Everything started working back to normal.
Not sure if you want me to close this issue or leave it open to have some fix applied in profile controller as everything is blocked after a trial and error that I did with resourceQuotaSpec ??
		</comment>
		<comment id='10' author='lalithvaka' date='2020-04-24T01:46:50Z'>
		&lt;denchmark-link:https://github.com/lalithvaka&gt;@lalithvaka&lt;/denchmark-link&gt;
 it looks like the profile controller is choking on invalid specs. This is a common failure mode for operators. It could be fixed with a validating admission hook.
Here are some related issues:
&lt;denchmark-link:https://github.com/kubeflow/tf-operator/issues/1016&gt;kubeflow/tf-operator#1016&lt;/denchmark-link&gt;
 - Create common CRD validation.
		</comment>
		<comment id='11' author='lalithvaka' date='2020-07-21T18:59:16Z'>
		Hi I want to use resourcesQuotaspec when i am adding GPU in yaml then i am trying to create Notebook server its showing me error, Can you guys help me out how to add gpu/cpu  in profile resources allocation for a namespace? below are the link i am following
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/blob/960587ac9025b6a4ba7facaabc8aa1769fb01dc8/components/profile-controller/config/samples/profile_v1beta1_profile.yaml&gt;KubeflowProfileContoller&lt;/denchmark-link&gt;

&lt;denchmark-link:https://kubernetes.io/docs/concepts/policy/resource-quotas/&gt;KubernatesResourceQuota&lt;/denchmark-link&gt;

I am using DEX Configuration , below is my yaml file
apiVersion: kubeflow.org/v1beta1
kind: Profile
metadata:
name: aniruddha-choudhury
spec:
owner:
kind: User
name: &lt;denchmark-link:mailto:aniruddha.choudhury@gmail.com&gt;aniruddha.choudhury@gmail.com&lt;/denchmark-link&gt;

plugins:

kind: WorkloadIdentity
spec:
gcpServiceAccount: kubeflow2@project-id.iam.gserviceaccount.com
resourceQuotaSpec:
hard:
cpu: "10"
memory: 20Gi
pods: "20"
requests.nvidia.com/gpu: "1"

&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
  Please see if the above yaml file will work or not as when i give GPU as a attribute it is creating problem.
		</comment>
	</comments>
</bug>