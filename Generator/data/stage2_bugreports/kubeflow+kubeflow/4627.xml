<bug id='4627' author='tanguycdls' open_date='2020-01-07T17:42:50Z' closed_time='2020-04-08T11:04:21Z'>
	<summary>Pytorch Distributed on Jupyter notebooks on Kubeflow disconnect the notebook and freezes</summary>
	<description>
/kind bug
What steps did you take and what happened:
Hi i'm trying to run a toy example of Pytorch distributed with a Gloo backend that runs in my local computer on a jupyter notebook hosted on Kubeflow and I cannot make it run. The script freezes on p.join() and never stops.
The script uses tcp to synchronize between the processes I tried modifying the port number with no success.
When I call the script:

I loose the connection to the notebook right away.
I then have to go back to the kubeflow notebook ui and click connect again
When I connect to the notebook again the script is hanging.

The script creates the 4 processes but never ends, if I do a ctrl + c i can see its waiting on p.join(). All the other processes are suspended. I tried modifying the port to a lower number and the ip to localhost but nothing changes. I also tried using a file instead to share data but the problem is the same.
Sometimes I get that error instead:
&lt;denchmark-code&gt;RuntimeError: [/opt/conda/conda-bld/pytorch_1573049304260/work/third_party/gloo/gloo/transport/tcp/pair.cc:563] Read error [***********]:17795: Connection reset by peer
&lt;/denchmark-code&gt;

**the same docker and code but running in my personal machine using ``docker run -p 8888:8888 -it  works. **
I'm running the following code:
&lt;denchmark-code&gt;import os
import tempfile
import torch
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp
import datetime
from torch.multiprocessing import Process

from torch.nn.parallel import DistributedDataParallel as DDP
def run(rank, size):
    a=torch.tensor([rank])
    b=a**2

    tensor_list1 = [torch.zeros_like(b) for _ in range(size)]

    if rank==0:
        dist.gather(tensor=b,dst=0, gather_list=tensor_list1)
    else:
        dist.gather(tensor=b, dst=0)

    print('Rank ', rank, 'b: ', tensor_list1)

def init_processes(rank, size, fn, backend='gloo'):
    """ Initialize the distributed environment. """
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '9999'
    dist.init_process_group(backend, rank=rank, world_size=size)
    fn(rank, size)


if __name__ == "__main__":
    size = 4
    processes = []
    for rank in range(size):
        p = Process(target=init_processes, args=(rank, size, run))
        p.start()
        processes.append(p)

    for p in processes:
        p.join()
&lt;/denchmark-code&gt;

What did you expect to happen:
It should do the calculation on 4 processes and stop.
Anything else you would like to add:
Environment:

Kubeflow version: 0.7 on an AWS cluster using authentification
OS (e.g. from /etc/os-release): Dockerfile :
Minimal Dockerfile

&lt;denchmark-code&gt;FROM jupyter/base-notebook
RUN pip install torch
ENV NB_PREFIX /
# Set the default cmd to run jupyter notebook with the appropriate params for kubeflow
# cf. https://www.kubeflow.org/docs/notebooks/custom-notebook/
CMD ["sh", "-c", "jupyter lab --notebook-dir=/home/jovyan --ip=0.0.0.0 --no-browser --allow-root --port=8888 --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_origin='*' --NotebookApp.base_url=${NB_PREFIX}"]
&lt;/denchmark-code&gt;

I checked the Pytorch Job operator and it seems to use the same two variables but it does not set the master addr neither the master port. I think the problem comes from there.
Did anyone succeeded into using Pytorch distributed into Kubeflow Jupyter?
I also tested creating a socket and talking between the two processes using that socket. It works and i dont see any deconnection. Simple Http Server works as well.
Let me know if its not the good place to put the issue,
Thanks
	</description>
	<comments>
		<comment id='1' author='tanguycdls' date='2020-01-08T13:44:19Z'>
		I checked with nmap using nmap -sT -O localhostand the port 9999 is correctly opened with service name abyss.
I also tried to open a simple http server on a port to test if opening a port was the problem and it works.
		</comment>
		<comment id='2' author='tanguycdls' date='2020-04-07T18:03:28Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>