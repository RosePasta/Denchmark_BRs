<bug id='4767' author='jlewi' open_date='2020-02-14T14:57:26Z' closed_time='2020-02-18T14:57:16Z'>
	<summary>Central Dasbhoard Reports Unable to Contact Profile Controller</summary>
	<description>
/kind bug
&lt;denchmark-link:https://kf-v1-0212-8db.endpoints.kubeflow-ci-deployment.cloud.goog/&gt;https://kf-v1-0212-8db.endpoints.kubeflow-ci-deployment.cloud.goog/&lt;/denchmark-link&gt;

Deployed from
&lt;denchmark-link:https://github.com/kubeflow/manifests/tree/096f312&gt;https://github.com/kubeflow/manifests/tree/096f312&lt;/denchmark-link&gt;

Using kfctl_gcp_iap.yaml
Cluster had been up for 1 day when it started reporting "unable to contact profile controller" in the central dashboard.
	</description>
	<comments>
		<comment id='1' author='jlewi' date='2020-02-14T14:57:35Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




kind/bug
0.99



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='jlewi' date='2020-02-14T15:01:33Z'>
		The profiles controller deployment  appears to be missing.
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4204969/deploy.txt&gt;deploy.txt&lt;/denchmark-link&gt;

So it looks like something might have gone wrong during deployment.
		</comment>
		<comment id='3' author='jlewi' date='2020-02-14T15:07:32Z'>
		Here are the logs from the deployment.
It looks like it was deployed successfully
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4204986/auto-deploy-v1-bvkvk-v9fgd.logs.txt&gt;auto-deploy-v1-bvkvk-v9fgd.logs.txt&lt;/denchmark-link&gt;

We also see profile created namespaces
&lt;denchmark-code&gt;kubectl get namespace
NAME                     STATUS   AGE
cert-manager             Active   39h
default                  Active   39h
istio-system             Active   39h
jlewi                    Active   36h
knative-serving          Active   39h
kube-node-lease          Active   39h
kube-public              Active   39h
kube-system              Active   39h
kubeflow                 Active   39h
kubeflow-kf-ci-v1-user   Active   39h
&lt;/denchmark-code&gt;

This is a cluster I successfully ran mnist on yesterday.
I'm going to assume that at some point someone or something deleted the profiles controller but that everything is working as intended.
So I'm going to close this for now.
		</comment>
		<comment id='4' author='jlewi' date='2020-02-14T21:35:02Z'>
		I'm running into same on an upgraded cluster
		</comment>
		<comment id='5' author='jlewi' date='2020-02-14T22:19:24Z'>
		&lt;denchmark-link:https://github.com/yantriks-edi-bice&gt;@yantriks-edi-bice&lt;/denchmark-link&gt;
 can you list out your deployments? Is the profile-controller missing?
		</comment>
		<comment id='6' author='jlewi' date='2020-02-16T20:02:57Z'>
		I deployed a new cluster.
From:
&lt;denchmark-link:https://github.com/kubeflow/manifests/commit/6753c78b2501891e3bb395b1ce8c753d32a3d139&gt;kubeflow/manifests@6753c78&lt;/denchmark-link&gt;

Here are the event pod logs for the profile deployment
/home/jlewi/tmp/profiles-deployment-6d6bbd6487-4hmhc.v1-0214.logs.txt
The logs show that it ran for 24 hours and then was stopped.
Here are the event logs for the profiels-deployment
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210832/profiles-deployment.v1-0214.logs.txt&gt;profiles-deployment.v1-0214.logs.txt&lt;/denchmark-link&gt;

There are no indications it was deleted.
		</comment>
		<comment id='7' author='jlewi' date='2020-02-16T20:19:34Z'>
		Here are the audit logs for the deployment
The logs show the deployment is deleted by
system:serviceaccount:kube-system:generic-garbage-collector
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210855/audited_resource__logs__2020-02-15T03-15.csv.txt&gt;audited_resource__logs__2020-02-15T03-15.csv.txt&lt;/denchmark-link&gt;

Here are the audit logs for the pod.
The audit logs show the pod is being deleted by the K8s garbage collector service account.
Here's the search query.
&lt;denchmark-code&gt;logName="projects/jlewi-dev/logs/cloudaudit.googleapis.com%2Factivity"
profiles-deployment-6d6bbd6487-4hmhc
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210852/audited_resource__logs__2020-02-15T03-15.json.txt&gt;audited_resource__logs__2020-02-15T03-15.json.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='jlewi' date='2020-02-16T20:31:11Z'>
		I took a look at the application controller logs. I didn't see any events indicating a deletion of the deployment.
The profiles application is still there.
&lt;denchmark-code&gt;kubectl -n kubeflow get applications -o yaml profiles
apiVersion: app.k8s.io/v1beta1
kind: Application
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"app.k8s.io/v1beta1","kind":"Application","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"profiles","app.kubernetes.io/instance":"profiles-v1.0.0","app.kubernetes.io/managed-by":"kfctl","app.kubernetes.io/name":"profiles","app.kubernetes.io/part-of":"kubeflow","app.kubernetes.io/version":"v1.0.0"},"name":"profiles","namespace":"kubeflow"},"spec":{"addOwnerRef":true,"componentKinds":[{"group":"rbac.authorization.k8s.io","kind":"ClusterRole"},{"group":"rbac.authorization.k8s.io","kind":"ClusterRoleBinding"},{"group":"apps","kind":"Deployment"},{"group":"core","kind":"ServiceAccount"},{"group":"core","kind":"Service"},{"group":"kubeflow.org","kind":"Profile"}],"descriptor":{"description":"","keywords":["profiles","kubeflow"],"links":[{"description":"profiles","url":"https://github.com/kubeflow/kubeflow/tree/master/components/profile-controller"},{"description":"kfam","url":"https://github.com/kubeflow/kubeflow/tree/master/components/access-management"}],"maintainers":[{"email":"kunming@google.com","name":"Kunming Qu"}],"owners":[{"email":"kunming@google.com","name":"Kunming Qu"}],"type":"profiles","version":"v1"},"selector":{"matchLabels":{"app.kubernetes.io/component":"profiles","app.kubernetes.io/instance":"profiles-v1.0.0","app.kubernetes.io/managed-by":"kfctl","app.kubernetes.io/name":"profiles","app.kubernetes.io/part-of":"kubeflow","app.kubernetes.io/version":"v1.0.0"}}}}
  creationTimestamp: "2020-02-14T23:34:18Z"
  generation: 730
  labels:
    app.kubernetes.io/component: profiles
    app.kubernetes.io/instance: profiles-v1.0.0
    app.kubernetes.io/managed-by: kfctl
    app.kubernetes.io/name: profiles
    app.kubernetes.io/part-of: kubeflow
    app.kubernetes.io/version: v1.0.0
  name: profiles
  namespace: kubeflow
  resourceVersion: "741851"
  selfLink: /apis/app.k8s.io/v1beta1/namespaces/kubeflow/applications/profiles
  uid: 8516bafd-4f82-11ea-ba29-42010a8e01aa
spec:
  addOwnerRef: true
  componentKinds:
  - group: rbac.authorization.k8s.io
    kind: ClusterRole
  - group: rbac.authorization.k8s.io
    kind: ClusterRoleBinding
  - group: apps
    kind: Deployment
  - group: core
    kind: ServiceAccount
  - group: core
    kind: Service
  - group: kubeflow.org
    kind: Profile
  descriptor:
    keywords:
    - profiles
    - kubeflow
    links:
    - description: profiles
      url: https://github.com/kubeflow/kubeflow/tree/master/components/profile-controller
    - description: kfam
      url: https://github.com/kubeflow/kubeflow/tree/master/components/access-management
    maintainers:
    - email: kunming@google.com
      name: Kunming Qu
    owners:
    - email: kunming@google.com
      name: Kunming Qu
    type: profiles
    version: v1
  selector:
    matchLabels:
      app.kubernetes.io/component: profiles
      app.kubernetes.io/instance: profiles-v1.0.0
      app.kubernetes.io/managed-by: kfctl
      app.kubernetes.io/name: profiles
      app.kubernetes.io/part-of: kubeflow
      app.kubernetes.io/version: v1.0.0
status:
  conditions:
  - lastTransitionTime: "2020-02-14T23:38:13Z"
    lastUpdateTime: "2020-02-14T23:38:13Z"
    message: all components ready
    reason: ComponentsReady
    status: "True"
    type: Ready
  - lastTransitionTime: "2020-02-14T23:34:25Z"
    lastUpdateTime: "2020-02-14T23:34:25Z"
    message: No error seen
    reason: NoError
    status: "False"
    type: Error
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='jlewi' date='2020-02-16T20:36:44Z'>
		I reran
&lt;denchmark-code&gt;kfctl apply -V info -f kfctl_gcp_iap.v1.0.0.yaml
&lt;/denchmark-code&gt;

To recreate the profile controller.  Need to kick the iap-enabler pod
&lt;denchmark-code&gt;kubectl -n istio-system delete pods iap-enabler-99d54c4c6-tw9np
&lt;/denchmark-code&gt;

Now its working again.
		</comment>
		<comment id='10' author='jlewi' date='2020-02-16T20:41:14Z'>
		Here's the profiles deployment yaml and profiles application yaml
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210885/profiles_deployment.yaml.txt&gt;profiles_deployment.yaml.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210887/profiles.app.yaml.txt&gt;profiles.app.yaml.txt&lt;/denchmark-link&gt;

The owner reference of the profiles deployment is set to the application.
		</comment>
		<comment id='11' author='jlewi' date='2020-02-16T20:55:59Z'>
		I don't see any recent changes to the profile controller manifest
&lt;denchmark-link:https://github.com/kubeflow/manifests/commits/v1.0-branch/profiles&gt;https://github.com/kubeflow/manifests/commits/v1.0-branch/profiles&lt;/denchmark-link&gt;

But we did unpin GKE. The cluster exhibiting the problem is
1.14.10-gke.22
Where as I have a cluster at 1.14.8-gke.33 that has been up for 6 days with no problem.
		</comment>
		<comment id='12' author='jlewi' date='2020-02-16T21:05:32Z'>
		It looks like our application is claiming and setting owner references on cluster scoped resources like
the role bindings.
Per &lt;denchmark-link:https://github.com/kubeflow/manifests/issues/540&gt;kubeflow/manifests#540&lt;/denchmark-link&gt;
 this is a violation of GC garbage collection policy and can lead to unexpected behavior. In the past, this could to other (non-cluster scoped resources) being GC'd because the GC would cache the id of the owner as not being found because of the cross namespace issue.
Its unclear why we weren't hitting this with 1.14.8. A quick fix should be to update the application selector to not parent any cluster scoped resources.
		</comment>
		<comment id='13' author='jlewi' date='2020-02-16T21:05:39Z'>
		/cc &lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='jlewi' date='2020-02-16T21:11:42Z'>
		I checked all our other applications
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210923/applications.yaml.txt&gt;applications.yaml.txt&lt;/denchmark-link&gt;

I found one other reference in the webhook to a cluster scoped resource.
		</comment>
		<comment id='15' author='jlewi' date='2020-02-16T21:19:38Z'>
		Looking at the auto-deployed clusters we have 2 clusters both about 1 day and 17 hours old
The cluster from master deployed at
&lt;denchmark-link:https://github.com/kubeflow/manifests/tree/9eab2b4&gt;https://github.com/kubeflow/manifests/tree/9eab2b4&lt;/denchmark-link&gt;

1.14.10-gke.22
Doesn't have this problem but
The cluster from v1 does
&lt;denchmark-link:https://github.com/kubeflow/manifests/tree/07c58a0&gt;https://github.com/kubeflow/manifests/tree/07c58a0&lt;/denchmark-link&gt;

1.14.10-gke.22
		</comment>
		<comment id='16' author='jlewi' date='2020-02-16T21:25:37Z'>
		I'm puzzled why the v1 and vmaster clusters are illustrating different behavior.
They both appear to be using the same application controller image.
&lt;denchmark-code&gt;image: gcr.io/kubeflow-images-public/kubernetes-sigs/application:1.0-beta
    imageID: docker-pullable://gcr.io/kubeflow-images-public/kubernetes-sigs/application@sha256:5725ee7effdc948ec9f6480aca65baec2509e01c9fe27fe40044a448202b3c6e
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='jlewi' date='2020-02-16T21:29:36Z'>
		Here are the YAML specs for the profiles application and profiles-deployment on master
The application's selector doesn't match the labels of the deployment. Application is using version v1.0.0 and the deployment has label v0.7.0 for the version.
As a result the owner reference on the deployment isn't set.
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210942/master_profiles-deployment.yaml.txt&gt;master_profiles-deployment.yaml.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4210943/master_application.yaml.txt&gt;master_application.yaml.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='jlewi' date='2020-02-16T23:37:02Z'>
		&lt;denchmark-link:https://github.com/kubeflow/manifests/pull/921&gt;kubeflow/manifests#921&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/kubeflow/manifests/pull/922&gt;kubeflow/manifests#922&lt;/denchmark-link&gt;
 have been merged.
I deployed a cluster from
&lt;denchmark-link:https://github.com/jlewi/manifests/tree/automated-cherry-pick-of-%23921-upstream-v1.0-branch&gt;https://github.com/jlewi/manifests/tree/automated-cherry-pick-of-%23921-upstream-v1.0-branch&lt;/denchmark-link&gt;

Here's the application resource
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4211241/profiles_application.yaml.txt&gt;profiles_application.yaml.txt&lt;/denchmark-link&gt;

It is not claiming any cluster resources.
Lets wait 24 hours to verify the cluster is still healthy.
		</comment>
		<comment id='19' author='jlewi' date='2020-02-16T23:38:37Z'>
		We also have the auto-deployed cluster from commit
&lt;denchmark-link:https://github.com/kubeflow/manifests/tree/1913078&gt;https://github.com/kubeflow/manifests/tree/1913078&lt;/denchmark-link&gt;

cluster: kf-v1-0216-20f
		</comment>
		<comment id='20' author='jlewi' date='2020-02-17T19:46:57Z'>
		
@yantriks-edi-bice can you list out your deployments? Is the profile-controller missing?

kubectl get deployments
NAME                                                         READY   UP-TO-DATE   AVAILABLE   AGE
admission-webhook-deployment                                 1/1     1            1           2d22h
argo-ui                                                      1/1     1            1           41d
centraldashboard                                             1/1     1            1           2d22h
ghsumm-d0622191-e289-40b2-9535-0c30fab96efe                  1/1     1            1           30d
ghsumm-d0622191-e289-40b2-9535-0c30fab96efe-webapp           1/1     1            1           30d
jupyter-web-app-deployment                                   1/1     1            1           2d22h
metadata-db                                                  1/1     1            1           2d22h
metadata-deployment                                          1/1     1            1           2d22h
metadata-envoy-deployment                                    1/1     1            1           2d22h
metadata-grpc-deployment                                     1/1     1            1           2d22h
metadata-ui                                                  1/1     1            1           2d22h
minio                                                        1/1     1            1           40d
ml-pipeline                                                  1/1     1            1           40d
ml-pipeline-ml-pipeline-visualizationserver                  1/1     1            1           41d
ml-pipeline-persistenceagent                                 1/1     1            1           40d
ml-pipeline-scheduledworkflow                                1/1     1            1           41d
ml-pipeline-ui                                               1/1     1            1           41d
ml-pipeline-viewer-controller-deployment                     1/1     1            1           41d
mysql                                                        1/1     1            1           40d
nasnet-mobile-v1                                             1/1     1            1           5d22h
notebook-controller-deployment                               1/1     1            1           2d22h
pytorch-operator                                             1/1     1            1           2d22h
spark-operatorsparkoperator                                  1/1     1            1           2d22h
tensorboard                                                  1/1     1            1           41d
viewer-11fdd59c1ce974be69512e0b723da3d3011af590-deployment   1/1     1            1           30d
viewer-86f51bef648affc92caad8147c9579b5eb478c35-deployment   1/1     1            1           21d
workflow-controller                                          1/1     1            1           41d
		</comment>
		<comment id='21' author='jlewi' date='2020-02-18T04:00:53Z'>
		Everything is looking good with cluster kf-v1-0216-20f which has been up for 29 hours.
Here's a list of deployments showing the profiles deployment.
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4217240/deploy.yaml.txt&gt;deploy.yaml.txt&lt;/denchmark-link&gt;

Here's the latest application
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/4217245/profiles_application.yaml.txt&gt;profiles_application.yaml.txt&lt;/denchmark-link&gt;

So its not claiming any cluster level resources.
So this looks to be fixed on the v1.0-branch by &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/922&gt;#922&lt;/denchmark-link&gt;
.
&lt;denchmark-link:https://github.com/yantriks-edi-bice&gt;@yantriks-edi-bice&lt;/denchmark-link&gt;
 can you please try the latest manifests from the v1.0-branch and see if that resolves the issue for you.
		</comment>
		<comment id='22' author='jlewi' date='2020-02-18T14:57:16Z'>
		Closing this as fixed.
		</comment>
		<comment id='23' author='jlewi' date='2020-02-18T20:26:06Z'>
		I gave up trying to upgrade the 0.7 (kf-poc) cluster to 1.0 and launched a fresh 1.0 one (kf-tst). So far so good, though trying to upgrade the 0.7 now that you asked ran into the following:
Error: couldn't apply KfUpgrade:  (kubeflow.error): Code 500 with message: kfApp Apply failed for kustomize:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when applying patch:
{"metadata":{"annotations":{"kubectl.kubernetes.io/last-applied-configuration":"{"apiVersion":"v1","kind":"PersistentVolume","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"minio","app.kubernetes.io/instance":"minio-0.2.0","app.kubernetes.io/managed-by":"kfctl","app.kubernetes.io/name":"minio","app.kubernetes.io/part-of":"kubeflow","app.kubernetes.io/version":"0.2.0"},"name":"minio-pv"},"spec":{"accessModes":["ReadWriteOnce"],"capacity":{"storage":"20Gi"},"gcePersistentDisk":{"fsType":"ext4","pdName":"kf-poc-storage-artifact-store"}}}\n"}},"spec":{"gcePersistentDisk":{"pdName":"kf-poc-storage-artifact-store"}}}
to:
Resource: "/v1, Resource=persistentvolumes", GroupVersionKind: "/v1, Kind=PersistentVolume"
Name: "minio-pv", Namespace: ""
Object: &amp;{map["apiVersion":"v1" "kind":"PersistentVolume" "metadata":map["annotations":map["kubectl.kubernetes.io/last-applied-configuration":"{"apiVersion":"v1","kind":"PersistentVolume","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"minio","app.kubernetes.io/instance":"minio-0.2.0","app.kubernetes.io/managed-by":"kfctl","app.kubernetes.io/name":"minio","app.kubernetes.io/part-of":"kubeflow","app.kubernetes.io/version":"0.2.0"},"name":"minio-pv"},"spec":{"accessModes":["ReadWriteOnce"],"capacity":{"storage":"20Gi"},"gcePersistentDisk":{"fsType":"ext4","pdName":"kf-tst-storage-artifact-store"}}}\n" "pv.kubernetes.io/bound-by-controller":"yes"] "creationTimestamp":"2020-02-17T20:58:09Z" "finalizers":["kubernetes.io/pv-protection"] "labels":map["app.kubernetes.io/component":"minio" "app.kubernetes.io/instance":"minio-0.2.0" "app.kubernetes.io/managed-by":"kfctl" "app.kubernetes.io/name":"minio" "app.kubernetes.io/part-of":"kubeflow" "app.kubernetes.io/version":"0.2.0" "failure-domain.beta.kubernetes.io/region":"us-central1" "failure-domain.beta.kubernetes.io/zone":"us-central1-a"] "name":"minio-pv" "resourceVersion":"4052" "selfLink":"/api/v1/persistentvolumes/minio-pv" "uid":"33f40606-51c8-11ea-ae4a-42010a80008f"] "spec":map["accessModes":["ReadWriteOnce"] "capacity":map["storage":"20Gi"] "claimRef":map["apiVersion":"v1" "kind":"PersistentVolumeClaim" "name":"minio-pv-claim" "namespace":"kubeflow" "resourceVersion":"4050" "uid":"340b3b4c-51c8-11ea-ae4a-42010a80008f"] "gcePersistentDisk":map["fsType":"ext4" "pdName":"kf-tst-storage-artifact-store"] "nodeAffinity":map["required":map["nodeSelectorTerms":[map["matchExpressions":[map["key":"failure-domain.beta.kubernetes.io/zone" "operator":"In" "values":["us-central1-a"]] map["key":"failure-domain.beta.kubernetes.io/region" "operator":"In" "values":["us-central1"]]]]]]] "persistentVolumeReclaimPolicy":"Retain" "volumeMode":"Filesystem"] "status":map["phase":"Bound"]]}
for: "/tmp/kout586539023": PersistentVolume "minio-pv" is invalid: spec.persistentvolumesource: Forbidden: is immutable after creation
		</comment>
	</comments>
</bug>