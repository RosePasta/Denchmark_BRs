<bug id='3810' author='holdenk' open_date='2019-08-01T21:28:25Z' closed_time='2019-09-03T21:06:59Z'>
	<summary>Running kfctl apply k8s fails on 2nd application</summary>
	<description>
/kind bug
What steps did you take and what happened:
I ran kfctl apply k8s a 2nd time and it failed saying istio had already bound the port.
output:

time="2019-08-01T14:24:56-07:00" level=info msg="creating Service/istio-galley\n" filename="kustomize/kustomize.go:440"
time="2019-08-01T14:24:56-07:00" level=info msg="creating Service/istio-ingressgateway\n" filename="kustomize/kustomize.go:440"
Error: couldn't apply KfApp:  (kubeflow.error): Code 500 with message: kfApp Apply failed for kustomize:  (kubeflow.error): Code 500 with message: couldn't create resources from istio-install Error: Service "istio-ingressgateway" is invalid: spec.ports[1].nodePort: Invalid value: 31380: provided port is already allocated
Usage:
kfctl apply [all(=default)|k8s|platform] [flags]
Flags:
-h, --help      help for apply
-V, --verbose   verbose output default is false
couldn't apply KfApp:  (kubeflow.error): Code 500 with message: kfApp Apply failed for kustomize:  (kubeflow.error): Code 500 with message: couldn't create resources from istio-install Error: Service "istio-ingressgateway" is invalid: spec.ports[1].nodePort: Invalid value: 31380: provided port is already allocated

What did you expect to happen:
Since the docs &lt;denchmark-link:https://www.kubeflow.org/docs/gke/customizing-gke/&gt;https://www.kubeflow.org/docs/gke/customizing-gke/&lt;/denchmark-link&gt;
 suggest that I can reapply, I expected this to silently skip istio or otherwise not fail.
Anything else you would like to add:
Short term solution could be a doc change, longer term I think we do want to support kfctl apply k8s multiple times.
Environment:

Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard): master (df2b68d)
kfctl version: (use kfctl version): v20181207-4e7f4ed-198-gaeea303e-dirty-03e65e
Kubernetes platform: (e.g. minikube) gke
Kubernetes version: (use kubectl version): Client Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.0", GitCommit:"e8462b5b5dc2584fdcd18e6bcfe9f1e4d970a529", GitTreeState:"clean", BuildDate:"2019-06-19T16:40:16Z", GoVersion:"go1.12.5", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"12+", GitVersion:"v1.12.9-gke.7", GitCommit:"b6001a5d99c235723fc19342d347eee4394f2005", GitTreeState:"clean", BuildDate:"2019-06-18T12:12:30Z", GoVersion:"go1.10.8b4", Compiler:"gc", Platform:"linux/amd64"}
OS (e.g. from /etc/os-release):
NAME="Ubuntu"
VERSION="18.04.2 LTS (Bionic Beaver)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 18.04.2 LTS"
VERSION_ID="18.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic

	</description>
	<comments>
		<comment id='1' author='holdenk' date='2019-08-01T21:28:27Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.99. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='holdenk' date='2019-08-02T18:26:33Z'>
		/priority p1
		</comment>
		<comment id='3' author='holdenk' date='2019-08-02T18:27:11Z'>
		/cc &lt;denchmark-link:https://github.com/lluunn&gt;@lluunn&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='holdenk' date='2019-08-02T18:29:55Z'>
		&lt;denchmark-link:https://github.com/lluunn&gt;@lluunn&lt;/denchmark-link&gt;
  is there a simple way that we can avoid this?  when trying to apply ISTIO resources, it ignores the fact that ingress was already created and tries to allocate the same port.
		</comment>
		<comment id='5' author='holdenk' date='2019-08-02T18:38:41Z'>
		Should be dup of &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3686&gt;#3686&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/abhi-g&gt;@abhi-g&lt;/denchmark-link&gt;
 also ran into this recently I think.
It's a istio issue: &lt;denchmark-link:https://github.com/istio/istio/issues/10795&gt;istio/istio#10795&lt;/denchmark-link&gt;
.
The workaround as pointed out in that issue is to edit the manifest (istio-install) and comment out the specified port number.
We should find a way in kfctl to get around this.
		</comment>
		<comment id='6' author='holdenk' date='2019-08-02T19:01:58Z'>
		I believe that in 0.5 ksonnet knew how to do what it called an "upsert", but with kustomize on 0.6, the equivalent of a  is always done: &lt;denchmark-link:https://github.com/kubeflow/kubeflow/blob/v0.6.1/bootstrap/v2/pkg/kfapp/kustomize/kustomize.go#L446&gt;https://github.com/kubeflow/kubeflow/blob/v0.6.1/bootstrap/v2/pkg/kfapp/kustomize/kustomize.go#L446&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='holdenk' date='2019-08-02T19:39:14Z'>
		&lt;denchmark-link:https://github.com/mattnworb&gt;@mattnworb&lt;/denchmark-link&gt;
 yes that's right.
&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kunming&gt;@kunming&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yanniszark&gt;@yanniszark&lt;/denchmark-link&gt;
  should we change this behavior - effectively an apply instead of create?
		</comment>
		<comment id='8' author='holdenk' date='2019-08-05T01:47:40Z'>
		&lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
 Yes I think we should change the behavior. as &lt;denchmark-link:https://github.com/holdenk&gt;@holdenk&lt;/denchmark-link&gt;
 run  should be idempotent if everything is already deployed correctly.
		</comment>
		<comment id='9' author='holdenk' date='2019-08-05T01:48:36Z'>
		We should consider running kfctl apply twice in our E2E tests as a way to verify that it works as expected.
		</comment>
		<comment id='10' author='holdenk' date='2019-08-07T17:28:34Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
  once server-side apply becomes available we should use that.
Until then, any ideas about what is the best practice available to have a behaviour close to kubectl apply?
		</comment>
		<comment id='11' author='holdenk' date='2019-08-09T17:42:13Z'>
		/assign &lt;denchmark-link:https://github.com/gabrielwen&gt;@gabrielwen&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='holdenk' date='2019-08-09T18:41:30Z'>
		&lt;denchmark-link:https://github.com/yanniszark&gt;@yanniszark&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gabrielwen&gt;@gabrielwen&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ashahba&gt;@ashahba&lt;/denchmark-link&gt;

I've been going through the kubectl &lt;denchmark-link:https://git.k8s.io/kubectl/pkg/cmd/apply&gt;Apply&lt;/denchmark-link&gt;
 code and it's none trivial using various flags like --prune, --force, --include-uninitialized.
Unless we're willing to use JsonPatch or StrategicPatch, the simplest approach
would be to just do new objects. More complicated use cases of Patch could be done
using Kustomize for individual targets and possible some tooling.
		</comment>
		<comment id='13' author='holdenk' date='2019-08-09T19:22:11Z'>
		&lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
 instead of complex apply functionality, would a simple update work for us?
It replaces the whole old object with the new one.
Is that what you mean by  ?
Maybe we can use the controller-runtime library and define common helper functions in pkg/utils/k8sutils.go ?
		</comment>
		<comment id='14' author='holdenk' date='2019-08-09T19:55:50Z'>
		
@kkasravi instead of complex apply functionality, would a simple update work for us?
It replaces the whole old object with the new one.
Is that what you mean by just do new objects ?

replacing some objects would definitely be destructive (namespace, deployment, replicas, application) especially if they have cascaded deletes and some would have weird side effects like webhooks. I was thinking that new objects would be safest and probably address the use case of kfctl apply aborting halfway through. One think we're seeing is that istio CRDs aren't being created quick enough for subsequent CR's. This might be fixed by setting an option on the client-go post related to synchronous behavior.

Maybe we can use the controller-runtime library and define common helper functions in pkg/utils/k8sutils.go ?

i think that's worth pursuing.
		</comment>
		<comment id='15' author='holdenk' date='2019-08-09T20:54:59Z'>
		Has it ever been considered to shell out to kubectl apply ... rather than have client-go code in kfctl that talks to the k8s api-server directly?
		</comment>
		<comment id='16' author='holdenk' date='2019-08-09T21:00:39Z'>
		+1 to that. I think coloring the did to apply is getting hairy and will end
up replicating kubectl.
&lt;denchmark-link:#&gt;‚Ä¶&lt;/denchmark-link&gt;


On Fri, Aug 9, 2019 at 1:55 PM Matt Brown ***@***.***&gt; wrote:
 Has it ever been considered to shell out to kubectl apply ... rather than
 have client-go code in kfctl that talks to the k8s api-server directly?

 ‚Äî
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#3810?email_source=notifications&amp;email_token=ACZ2UZV3P54E2BGOFY5JJH3QDXKTBA5CNFSM4IIWGOU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD37X4AQ#issuecomment-520060418&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ACZ2UZT2SHABD63T6D25QYDQDXKTBANCNFSM4IIWGOUQ&gt;
 .



		</comment>
		<comment id='17' author='holdenk' date='2019-08-09T21:29:34Z'>
		there has been some prototyping related to kustomize plugins where most of kfctl can be embedded within kustomize. Given the fact that kustomize is part of kubectl (&lt;denchmark-link:https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/&gt;https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/&lt;/denchmark-link&gt;
) there is a pathway where kfctl could mostly if not entirely disappear - with parts being integrated into kubectl via kustomize plugins. At this point we wouldn't need to shell out since we're already 'in' :)
		</comment>
		<comment id='18' author='holdenk' date='2019-08-09T21:34:30Z'>
		Followup on above.
kubectl apply -k kustomization.yaml is the syntax since k8-v1.14
		</comment>
		<comment id='19' author='holdenk' date='2019-08-19T19:44:30Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 yes - sometime today - may be in the evening
		</comment>
		<comment id='20' author='holdenk' date='2019-08-26T01:56:51Z'>
		My suggestion would be even if &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/3957&gt;#3957&lt;/denchmark-link&gt;
 gets committed in time; which is unlikely that we don't try to include in the 0.6.2 release of kfctl.
I think we are just about ready to finalize 0.6.2 of kfctl; I think &lt;denchmark-link:https://github.com/kubeflow/kubeflow/pull/3957&gt;#3957&lt;/denchmark-link&gt;
 is a big enough change that we should plan on another minor release for it just so that we don't block the fixes already in 0.6.2.
		</comment>
		<comment id='21' author='holdenk' date='2019-09-04T00:13:37Z'>
		&lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
 suggested using the following work around until the fix is released in kfctl 0.7.
Create an apply.sh with the following contents
&lt;denchmark-code&gt;#!/usr/bin/env bash

for i in $(cat app.yaml | grep '^        path: ' | awk -F: '{print $2}');do
  childdir=${i#*/}
  if [[ -d kustomize/$childdir &amp;&amp; -f kustomize/$childdir/kustomization.yaml ]]; then
    kustomize build kustomize/$childdir | kubectl apply -f -
    sleep 3
  fi
done
&lt;/denchmark-code&gt;

Then

chmod +x apply.sh
move the script to where  you called kfctl generate.
Run the script from that location

		</comment>
		<comment id='22' author='holdenk' date='2019-09-17T05:55:52Z'>
		Much appreciate your sharing this workaround script
i had to install kustomize in a different directory from KFAPP
(since KFAPP has directory named kustomize)
using instructions in &lt;denchmark-link:https://github.com/kubernetes-sigs/kustomize/blob/master/docs/INSTALL.md&gt;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/INSTALL.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='holdenk' date='2019-09-17T14:21:10Z'>
		hi
kustomize's API is called by kfctl. The workaround calls the kustomize command
So you'll need to install &lt;denchmark-link:https://github.com/kubernetes-sigs/kustomize/releases/tag/v2.0.3&gt;kustomize-v2.0.3&lt;/denchmark-link&gt;

		</comment>
		<comment id='24' author='holdenk' date='2019-09-19T22:53:57Z'>
		&lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
  Hi, I have tried this workaround and I have ran into the following issues through out the log
Multiple of these --"Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply"
Multiple of these -- "for: "STDIN": Timeout: request did not complete within requested timeout 30s
Error from server (Timeout): error when applying patch:"
Multiple of these -- "Error from server (Timeout): error when creating "STDIN": Timeout: request did not complete within requested timeout 30s"
Attaching the log for your reference,
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/3633475/Apply_sh_workaround_log.log&gt;Apply_sh_workaround_log.log&lt;/denchmark-link&gt;

		</comment>
		<comment id='25' author='holdenk' date='2019-09-25T00:13:23Z'>
		&lt;denchmark-link:https://github.com/kkasravi&gt;@kkasravi&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 , the workaround mentioned about seems to be not working.
I am attaching both the logs for your reference. Appreciate any help before the 0.7 release.

kfctl_Apply_Failure.log -- kfctl apply all -V failure log
Apply_sh_workaround_log.log --&gt; workaround success / failure log
After the work around completion, if I check the kubeflow install, am getting the following limited set.
‚ûú kubectl -n kubeflow get po
NAME                                          READY   STATUS              RESTARTS   AGE
admission-webhook-bootstrap-stateful-set-0    1/1     Running             0          3m8s
application-controller-stateful-set-0         1/1     Running             0          3m43s
jupyter-web-app-deployment-7b5f9c8b77-2rwst   1/1     Running             0          2m53s
katib-controller-6dbf6db58d-fz2db             1/1     Running             0          2m34s
profiles-deployment-7b79cd776c-9gxsw          0/2     ContainerCreating   0          13s
seldon-operator-controller-manager-0          0/1     ContainerCreating   0          6s
(base)
~/Installs/kf-poc via üÖí base at ‚ò∏Ô∏è kubernetes-admin@kubernetes

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/3649964/kfctl_Apply_Failure.log&gt;kfctl_Apply_Failure.log&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kubeflow/kubeflow/files/3649965/Apply_sh_workaround_log.log&gt;Apply_sh_workaround_log.log&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='holdenk' date='2019-09-30T05:08:38Z'>
		I commented the port number 31380, 31390 and 31400 in file ../kustomize/istio-install/base/istio-noauth.yaml
&lt;denchmark-code&gt;.......
spec:
  type: NodePort
  selector:
    release: istio
    app: istio-ingressgateway
    istio: ingressgateway
  ports:
    -
      name: status-port
      port: 15020
      targetPort: 15020
    -
      name: http2
      #nodePort: 31380
      port: 80
      targetPort: 80
    -
      name: https
      #nodePort: 31390
      port: 443
    -
      name: tcp
      #nodePort: 31400
      port: 31400
    -
      name: https-kiali
      port: 15029
      targetPort: 15029
    -
      name: https-prometheus
      port: 15030
      targetPort: 15030
    -
      name: https-grafana
      port: 15031
      targetPort: 15031
......
&lt;/denchmark-code&gt;

But this just solves this particular problem, while led to another issue.
From the kubflow dashboard, if I upload the any pipeline yaml file i came up with this erroe:
&lt;denchmark-code&gt;Failed to upload pipeline
Error occured while trying to proxy to: localhost:8080/apis/v1beta1/pipelines/upload?name=taxi
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>