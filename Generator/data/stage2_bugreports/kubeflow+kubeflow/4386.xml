<bug id='4386' author='buildlackey' open_date='2019-10-24T01:10:10Z' closed_time='2020-12-04T21:22:14Z'>
	<summary>error during apply filename="kustomize/kustomize.go", leads to Code 500 with message: kfApp Apply failed for kustomize</summary>
	<description>
/kind bug

attempted to install kubeflow per these instructions -&gt;
&lt;denchmark-link:https://www.kubeflow.org/docs/started/k8s/kfctl-k8s-istio/&gt;https://www.kubeflow.org/docs/started/k8s/kfctl-k8s-istio/&lt;/denchmark-link&gt;

I am trying to install v0.7.0-rc.5 because I ran in to this bug:
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4199&gt;#4199&lt;/denchmark-link&gt;

and the fix for that only seems to be available in  v0.7.0 release candidates.
After I run
&lt;denchmark-code&gt;kfctl apply -V -f ${CONFIG_URI}
&lt;/denchmark-code&gt;

I see continued errors and attempts to retry, as shown in the section ERROR AND RETRY.
After about 10 retry attempts the installation finally fails with this message:
(kubeflow.error): Code 500 with message: kfApp Apply failed for kustomize --- Error unable to recognize "/tmp/kout500167443": no matches for kind "Deployment" in version "apps/v1beta2"
Any guidance most gratefully appreciated.
ERROR AND RETRY
WARN[0339] Encountered error during apply:          filename="kustomize/kustomize.go:183"
WARN[0339] Will retry in 21 seconds.                     filename="kustomize/kustomize.go:184"
serviceaccount/metadata-ui unchanged
role.rbac.authorization.k8s.io/metadata-ui unchanged
rolebinding.rbac.authorization.k8s.io/metadata-ui unchanged
configmap/metadata-ui-parameters-b6c8ghff7c unchanged
secret/metadata-db-secrets unchanged
service/metadata-db unchanged
service/metadata-envoy-service unchanged
service/metadata-grpc-service unchanged
service/metadata-service unchanged
service/metadata-ui unchanged
deployment.apps/metadata-db unchanged
deployment.apps/metadata-deployment unchanged
deployment.apps/metadata-grpc-deployment unchanged
deployment.apps/metadata-ui unchanged
virtualservice.networking.istio.io/metadata-grpc unchanged
virtualservice.networking.istio.io/metadata-ui unchanged
persistentvolumeclaim/metadata-mysql unchanged
WARN[0366] Encountered error during apply:          filename="kustomize/kustomize.go:183"
WARN[0366] Will retry in 41 seconds.                     filename="kustomize/kustomize.go:184"
What did you expect to happen:
was hoping for a clean install...   didn't succeed ;^(
Anything else you would like to add:
[Miscellaneous information that will assist in solving the issue.]
Environment:


Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard):   v0.7.0-rc.5


kfctl version: (use kfctl version):
kfctl v0.7.0-rc.5-0-g18fba77a


Kubernetes platform: (e.g. minikube)
minikube version: v1.4.0
commit: 7969c25a98a018b94ea87d949350f3271e9d64b6


Kubernetes version: (use kubectl version):
Client Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.2", GitCommit:"c97fe5036ef3df2967d086711e6c0c405941e14b", GitTreeState:"clean", BuildDate:"2019-10-15T19:18:23Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.0", GitCommit:"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77", GitTreeState:"clean", BuildDate:"2019-09-18T14:27:17Z", GoVersion:"go1.12.9", Compiler:"gc", Platform:"linux/amd64"}


OS (e.g. from /etc/os-release):
MacOS mojave 10.14.5


	</description>
	<comments>
		<comment id='1' author='buildlackey' date='2019-10-24T01:10:13Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.99. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='buildlackey' date='2019-10-24T05:06:36Z'>
		apps/v1beta2 is deprecated api in kubernetes 1.16
see &lt;denchmark-link:https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/&gt;kubernetes blog&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='buildlackey' date='2019-10-24T14:04:21Z'>
		We are only testing on Kubernetes 1.14 right now.
		</comment>
		<comment id='4' author='buildlackey' date='2019-10-26T06:24:03Z'>
		I downgraded to kubectl version 1.14.8 but I am getting similar errors. If this problem is arising from another issue or error on my behalf please let me know.
&lt;denchmark-code&gt;serviceaccount/controller unchanged
clusterrole.rbac.authorization.k8s.io/custom-metrics-server-resources unchanged
clusterrole.rbac.authorization.k8s.io/knative-serving-admin configured
clusterrole.rbac.authorization.k8s.io/knative-serving-core unchanged
clusterrole.rbac.authorization.k8s.io/knative-serving-istio unchanged
clusterrole.rbac.authorization.k8s.io/knative-serving-namespaced-admin unchanged
rolebinding.rbac.authorization.k8s.io/custom-metrics-auth-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/custom-metrics:system:auth-delegator unchanged
clusterrolebinding.rbac.authorization.k8s.io/hpa-controller-custom-metrics unchanged
clusterrolebinding.rbac.authorization.k8s.io/knative-serving-controller-admin unchanged
configmap/config-autoscaler unchanged
configmap/config-defaults unchanged
configmap/config-deployment unchanged
configmap/config-domain unchanged
configmap/config-gc unchanged
configmap/config-istio unchanged
configmap/config-logging unchanged
configmap/config-network unchanged
configmap/config-observability unchanged
configmap/config-tracing unchanged
service/activator-service unchanged
service/autoscaler unchanged
service/controller unchanged
service/webhook unchanged
deployment.apps/activator configured
deployment.apps/autoscaler unchanged
deployment.apps/autoscaler-hpa configured
deployment.apps/controller configured
deployment.apps/networking-istio configured
deployment.apps/webhook unchanged
apiservice.apiregistration.k8s.io/v1beta1.custom.metrics.k8s.io unchanged
application.app.k8s.io/knative-serving-install configured
horizontalpodautoscaler.autoscaling/activator unchanged
gateway.networking.istio.io/cluster-local-gateway unchanged
gateway.networking.istio.io/knative-ingress-gateway unchanged
servicerole.rbac.istio.io/istio-service-role unchanged
servicerolebinding.rbac.istio.io/istio-service-role-binding unchanged
WARN[0755] Encountered error during apply: &lt;nil&gt;         filename="kustomize/kustomize.go:183"
WARN[0755] Will retry in 12 seconds.                     filename="kustomize/kustomize.go:184"
&lt;/denchmark-code&gt;



kfctl version:
kfctl v0.7.0-rc.5-7-gc66ebff3


kubectl version:
Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.8", GitCommit:"211047e9a1922595eaa3a1127ed365e9299a6c23", GitTreeState:"clean", BuildDate:"2019-10-15T12:11:03Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"14+", GitVersion:"v1.14.7-gke.10", GitCommit:"8cea5f8ae165065f0d35e5de5dfa2f73617f02d1", GitTreeState:"clean", BuildDate:"2019-10-05T00:08:10Z", GoVersion:"go1.12.9b4", Compiler:"gc", Platform:"linux/amd64"}


OS:
macOS Mojave 10.14.6


		</comment>
		<comment id='5' author='buildlackey' date='2019-10-28T12:35:20Z'>
		&lt;denchmark-link:https://github.com/AGKhalil&gt;@AGKhalil&lt;/denchmark-link&gt;
 in your latest output I don't see an error; I see a warning that it couldn't apply one of the manifests and it will retry
Did the retry succeed?
Did you just downgrade kubectl or did you downgrade your cluster too? I don't think just downgrading kubectl is sufficient. You need to downgrade your cluster as well.
		</comment>
		<comment id='6' author='buildlackey' date='2019-10-30T19:43:39Z'>
		The retry never succeeds.
I did only downgrade kubectl, and nothing to do with my cluster since I'm not deploying to an existing one.
I'm just using the config file mentioned in the Deploy using CLI  &lt;denchmark-link:https://www.kubeflow.org/docs/gke/deploy/deploy-cli/&gt;https://www.kubeflow.org/docs/gke/deploy/deploy-cli/&lt;/denchmark-link&gt;
 and that creates a new cluster for me. So shouldn't it be compatible with my versions of  and ? Or do I need to do something else?
This is the config file I am using: "https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.0.yaml"
I'm a novice to Kubeflow/K8s so I may be doing something wrong without realising it, but really I'm only following the instructions in the Kubeflow docs and it has never worked thus far. Any guidance would be much appreciated.
		</comment>
		<comment id='7' author='buildlackey' date='2020-01-08T23:15:54Z'>
		/area kustomize
/priority p2
		</comment>
		<comment id='8' author='buildlackey' date='2020-01-22T14:19:27Z'>
		Same here on

kubeflow 0.7.1.
microk8s: 1.14.10
manifest: v0.7.1

INFO[0000] Deleting cachedir /opt/kubeflow/kubeflow-poc/.cache/manifests because Status.ReposCache is out of date  filename="kfconfig/types.go:464" INFO[0000] Fetching https://github.com/kubeflow/manifests/archive/v0.7-branch.tar.gz to /opt/kubeflow/kubeflow-poc/.cache/manifests  filename="kfconfig/types.go:485" Error: failed to build kfApp from URI /opt/kubeflow/kubeflow-poc/kfctl_existing_arrikto.yaml: couldn't generate KfApp:  (kubeflow.error): Code 500 with message: could not sync cache. Error:  (kubeflow.error): Code 400 with message: couldn't download URI https://github.com/kubeflow/manifests/archive/v0.7-branch.tar.gz Error Error opening a gzip reader for /tmp/getter084554824/archive: EOF
I have no Idea about Kubernetes and kubeflow either. I just followed the install instructions for 0.7.1. But I found a workaround, so it will deploy on my machine.

cd ${KF_DIR}
edit vi kfctl_existing_arrikto.yaml --&gt; replace https://github.com/kubeflow/manifests/archive/v0.7-branch.tar.gz with a local directory /tmp/manifests-0.7-branch
cd /tmp
wget https://github.com/kubeflow/manifests/archive/v0.7-branch.tar.gz
tar -xvf v0.7-branch.tar.gz
cd ${KF_DIR}
kfctl apply -V -f ${CONFIG_FILE}

that's just a workaround, but works for me.
		</comment>
		<comment id='9' author='buildlackey' date='2020-01-23T16:10:18Z'>
		similar error and got solved by above comment
&lt;denchmark-code&gt;$kfctl version
kfctl v0.7.1-2-g55f9b2a
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;couldn't generate KfApp:  (kubeflow.error): Code 500 with message: coordinator Generate failed for gcp:  (kubeflow.error): Code 400 with message: couldn't download URI https://github.com/kubeflow/kubeflow/archive/xxxxxxxxxxxxxxx.tar.gz Error Error opening a gzip reader for /var/folders/1_/xxxxxxxxxxx/T/getterxxxxxxxx/archive: EOF
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='buildlackey' date='2020-01-24T17:59:06Z'>
		Same error as above^ but the work around did not help. I am simply trying to follow the same instructions as the original post with microk8s
The error I am getting is
&lt;denchmark-code&gt;failed to build kfApp from URI kfctl_gcp_iap.0.7.0.yaml: couldn't generate KfApp:  (kubeflow.error): Code 500 with message: coordinator Generate failed for gcp: Could not configure IAP auth; environment variable CLIENT_ID not set
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='buildlackey' date='2020-04-27T11:00:54Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='12' author='buildlackey' date='2020-04-27T13:11:10Z'>
		This error should be solved in kubeflow v1.0.1. I was able to install kubeflow 1.0.1 without this error on microk8s v1.15.
		</comment>
		<comment id='13' author='buildlackey' date='2020-06-10T19:20:52Z'>
		not resolved in kfctl v1.0.2 using it with Kubeadm
		</comment>
		<comment id='14' author='buildlackey' date='2020-06-12T20:27:06Z'>
		Still no fix apparently! I just gave it a try with the latest versions:

kubeflow: v1.0.2
k8s: Client v.1.18.3 and Server v.1.16.8

		</comment>
		<comment id='15' author='buildlackey' date='2020-07-13T13:35:12Z'>
		Is it a version issue? I face the same issue on EKS where there are warnings and retries ending up in the failure of kubeflow deployment:
&lt;denchmark-code&gt;denied the request: unrecognized type logentry, error when creating "/tmp/kout078882086": admission webhook "validation.istio.io" denied the request: unrecognized type metric]  filename="kustomize/kustomize.go:202"
WARN[0246] Will retry in 7 seconds.                      filename="kustomize/kustomize.go:203"
&lt;/denchmark-code&gt;


Kubeflow version: 1.0.2
Kubernetes version: Client v.1.18.2 and Server v.1.15

Is there any way to solve this?
		</comment>
		<comment id='16' author='buildlackey' date='2020-08-09T12:01:41Z'>
		This issue still persists for me. Is there a fix for this?
Kubeflow version: 1.0.2
Kubernetes version: 1.14.8
kfctl version: v1.0.2
		</comment>
		<comment id='17' author='buildlackey' date='2020-08-09T12:01:48Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




area/kfctl
0.91



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://label-bot-prod.mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='18' author='buildlackey' date='2020-08-27T14:38:46Z'>
		I'm experiencing the same issue when running the following commands:
&lt;denchmark-code&gt;echo Install kubectl on Linux
curl -LO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
kubectl version --client
echo Install Minikube
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \
  &amp;&amp; chmod +x minikube
sudo mkdir -p /usr/local/bin/
sudo install minikube /usr/local/bin/
minikube start
minikube status
echo Run container to be deployed onto the cluster
kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.10
kubectl expose deployment hello-minikube --type=NodePort --port=8080
kubectl get pod
echo Enable dashboard using Minikube
minikube addons enable dashboard
echo Install kustomize
export opsys=linux
curl -s https://api.github.com/repos/kubernetes-sigs/kustomize/releases |\
grep browser_download |\
grep download/kustomize |\
grep -m 1 $opsys |\
cut -d '"' -f 4 |\
xargs curl -O -L
tar xzf ./kustomize_v*_${opsys}_amd64.tar.gz
mkdir -p ${HOME}/bin
mv kustomize ${HOME}/bin/kustomize
chmod u+x ${HOME}/bin/kustomize
export PATH=$PATH:${HOME}/bin
echo Install Kubeflow on Minikube
curl -LO "https://github.com/kubeflow/kfctl/releases/download/v1.1.0/kfctl_v1.1.0-0-g9a3621e_linux.tar.gz"
tar -xvf kfctl_v1.1.0-0-g9a3621e_linux.tar.gz
# The following command is optional, to make kfctl binary easier to use.
export PATH=$PATH:${HOME}/dev/tf-template

# Set KF_NAME to the name of your Kubeflow deployment. This also becomes the
# name of the directory containing your configuration.
# For example, your deployment name can be 'my-kubeflow' or 'kf-test'.
export KF_NAME=kubeflow-deployment

# Set the path to the base directory where you want to store one or more 
# Kubeflow deployments. For example, /opt/.
# Then set the Kubeflow application directory for this deployment.
export BASE_DIR=${HOME}/dev/tf-template
export KF_DIR=${BASE_DIR}/${KF_NAME}

# Set the configuration file to use for installation of Kubeflow on existing Kubernetes cluster
export CONFIG_URI="https://raw.githubusercontent.com/kubeflow/manifests/v1.1-branch/kfdef/kfctl_k8s_istio.v1.1.0.yaml"

# Generate and deploy Kubeflow:
mkdir -p ${KF_DIR}
cd ${KF_DIR}
kfctl build -V -f ${CONFIG_URI}
# You can now customize your local Kubeflow configuration before running the next lines
export CONFIG_FILE=${KF_DIR}/kfctl_k8s_istio.v1.1.0.yaml #remove istio and spark from .yaml
kfctl apply -V -f ${CONFIG_FILE}
&lt;/denchmark-code&gt;

After complaints about the path to spark-operator, spartakus and tensorboard not existing, I removed these from the .yaml file. Now, I'm first getting the warning:
&lt;denchmark-code&gt;Encountered error applying application kubeflow-apps:  (kubeflow.error): Code 500 with message: Apply.Run : error when creating "/tmp/kout317589436": CustomResourceDefinition.apiextensions.k8s.io "seldondeployments.machinelearning.seldon.io" is invalid: [spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[componentSpecs].items.properties[spec].properties[containers].items.properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property, spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[componentSpecs].items.properties[spec].properties[initContainers].items.properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property, spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[explainer].properties[containerSpec].properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property]  filename="kustomize/kustomize.go:266"
&lt;/denchmark-code&gt;

And after many retries it terminates with the error:
&lt;denchmark-code&gt;kfctl exited with error: failed to apply:  (kubeflow.error): Code 500 with message: kfApp Apply failed for kustomize:  (kubeflow.error): Code 500 with message: Apply.Run : error when creating "/tmp/kout734428631": CustomResourceDefinition.apiextensions.k8s.io "seldondeployments.machinelearning.seldon.io" is invalid: [spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[componentSpecs].items.properties[spec].properties[initContainers].items.properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property, spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[componentSpecs].items.properties[spec].properties[containers].items.properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property, spec.validation.openAPIV3Schema.properties[spec].properties[predictors].items.properties[explainer].properties[containerSpec].properties[ports].items.properties[protocol].default: Required value: this property is in x-kubernetes-list-map-keys, so it must have a default or be a required property]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='19' author='buildlackey' date='2020-11-26T22:04:01Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>