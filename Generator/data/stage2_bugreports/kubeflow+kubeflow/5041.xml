<bug id='5041' author='TomVanWemmel' open_date='2020-05-26T16:24:58Z' closed_time='2020-06-02T12:16:25Z'>
	<summary>Encountered error applying application argo: VirtualService has timeout</summary>
	<description>
/kind bug

I'm trying to install Kubeflow on an existing AWS EKS cluster. I've followed the steps described in the documentation &lt;denchmark-link:https://www.kubeflow.org/docs/aws/deploy/install-kubeflow/&gt;here&lt;/denchmark-link&gt;
.
When I use  the execution seems stuck at "applying application argo"
&lt;denchmark-code&gt;INFO[0017] Successfully applied application metacontroller  filename="kustomize/kustomize.go:209"
INFO[0017] Deploying application argo                    filename="kustomize/kustomize.go:172"
customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io unchanged
serviceaccount/argo unchanged
serviceaccount/argo-ui unchanged
clusterrole.rbac.authorization.k8s.io/argo unchanged
clusterrole.rbac.authorization.k8s.io/argo-ui unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo-ui unchanged
configmap/workflow-controller-configmap unchanged
configmap/workflow-controller-parameters unchanged
service/argo-ui unchanged
deployment.apps/argo-ui unchanged
deployment.apps/workflow-controller unchanged
application.app.k8s.io/argo configured
WARN[0048] Encountered error applying application argo:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when creating "/tmp/kout138708174": Timeout: request did not complete within requested timeout 30s  filename="kustomize/kustomize.go:202"
WARN[0048] Will retry in 2 seconds.                      filename="kustomize/kustomize.go:203"
customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io unchanged
serviceaccount/argo unchanged
serviceaccount/argo-ui unchanged
clusterrole.rbac.authorization.k8s.io/argo unchanged
clusterrole.rbac.authorization.k8s.io/argo-ui unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo-ui unchanged
configmap/workflow-controller-configmap unchanged
configmap/workflow-controller-parameters unchanged
service/argo-ui unchanged
deployment.apps/argo-ui unchanged
deployment.apps/workflow-controller unchanged
application.app.k8s.io/argo configured
WARN[0080] Encountered error applying application argo:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when creating "/tmp/kout452794063": Timeout: request did not complete within requested timeout 30s  filename="kustomize/kustomize.go:202"
WARN[0080] Will retry in 4 seconds.                      filename="kustomize/kustomize.go:203"
customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io unchanged
serviceaccount/argo unchanged
serviceaccount/argo-ui unchanged
clusterrole.rbac.authorization.k8s.io/argo unchanged
clusterrole.rbac.authorization.k8s.io/argo-ui unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo-ui unchanged
configmap/workflow-controller-configmap unchanged
configmap/workflow-controller-parameters unchanged
service/argo-ui unchanged
deployment.apps/argo-ui unchanged
deployment.apps/workflow-controller unchanged
application.app.k8s.io/argo configured
WARN[0114] Encountered error applying application argo:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when creating "/tmp/kout271681380": Timeout: request did not complete within requested timeout 30s  filename="kustomize/kustomize.go:202"
WARN[0114] Will retry in 7 seconds.                      filename="kustomize/kustomize.go:203"
customresourcedefinition.apiextensions.k8s.io/workflows.argoproj.io unchanged
serviceaccount/argo unchanged
serviceaccount/argo-ui unchanged
clusterrole.rbac.authorization.k8s.io/argo unchanged
clusterrole.rbac.authorization.k8s.io/argo-ui unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo unchanged
clusterrolebinding.rbac.authorization.k8s.io/argo-ui unchanged
configmap/workflow-controller-configmap unchanged
configmap/workflow-controller-parameters unchanged
service/argo-ui unchanged
deployment.apps/argo-ui unchanged
deployment.apps/workflow-controller unchanged
application.app.k8s.io/argo configured
WARN[0152] Encountered error applying application argo:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when creating "/tmp/kout711025181": Timeout: request did not complete within requested timeout 30s  filename="kustomize/kustomize.go:202"
WARN[0152] Will retry in 13 seconds.                     filename="kustomize/kustomize.go:203"
&lt;/denchmark-code&gt;

This goes on until it gives up completely.
What did you expect to happen:
That Kubeflow is installed on my cluster.
Anything else you would like to add:
I've looked at the temporary files that are mentioned in the logs and put the last element in a separate file:
&lt;denchmark-code&gt;apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  labels:
    app.kubernetes.io/component: argo
    app.kubernetes.io/instance: argo-v2.3.0
    app.kubernetes.io/managed-by: kfctl
    app.kubernetes.io/name: argo
    app.kubernetes.io/part-of: kubeflow
    app.kubernetes.io/version: v2.3.0
  name: argo-ui
  namespace: kubeflow
spec:
  gateways:
  - kubeflow-gateway
  hosts:
  - '*'
  http:
  - match:
    - uri:
        prefix: /argo/
    rewrite:
      uri: /
    route:
    - destination:
        host: argo-ui.kubeflow.svc.cluster.local
        port:
          number: 80
&lt;/denchmark-code&gt;

Then I've used kubectl apply with a larger timeout and get a more specific error:
&lt;denchmark-code&gt;$ kubectl apply -f /tmp/koutlastpart --request-timeout=1m 
Error from server (InternalError): error when creating "/tmp/koutlastpart": Internal error occurred: failed calling webhook "pilot.validation.istio.io": Post https://istio-galley.istio-system.svc:443/admitpilot?timeout=30s: context deadline exceeded (Client.Timeout exceeded while awaiting headers)
&lt;/denchmark-code&gt;

Galley seems to be running fine
&lt;denchmark-code&gt;$kubectl get -n istio-system po   
NAME                                      READY   STATUS      RESTARTS   AGE
cluster-local-gateway-7bf56777fb-5n45n    1/1     Running     0          97m
grafana-86f89dbd84-646pn                  1/1     Running     0          97m
istio-citadel-74966f47d6-zmg2c            1/1     Running     0          97m
istio-cleanup-secrets-1.1.6-vg28b         0/1     Completed   0          97m
istio-egressgateway-5c64d575bc-ghrc7      1/1     Running     0          97m
istio-galley-784b9f6d75-nb6wk             1/1     Running     0          97m
istio-grafana-post-install-1.1.6-h28kd    0/1     Completed   0          97m
istio-ingressgateway-589ff776dd-mmk8k     1/1     Running     0          97m
istio-pilot-677df6b6d4-cmwkm              2/2     Running     0          97m
istio-policy-6f74d9d95d-9ff9w             2/2     Running     3          97m
istio-security-post-install-1.1.6-gk477   0/1     Completed   0          97m
istio-sidecar-injector-866f4b98c7-9qc7f   1/1     Running     0          97m
istio-telemetry-549c8f9dcb-2m7pf          2/2     Running     3          97m
istio-tracing-555cf644d-wrt7n             1/1     Running     0          97m
kiali-7db44d6dfb-fmkc7                    1/1     Running     0          97m
prometheus-d44645598-x4nld                1/1     Running     0          97m

&lt;/denchmark-code&gt;

Environment:

Kubeflow version: 1.0.0
kfctl version: kfctl v1.0.2-0-ga476281
Kubernetes platform: AWS EKS
Kubernetes version: Client Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.5", GitCommit:"20c265fef0741dd71a66480e35bd69f18351daea", GitTreeState:"clean", BuildDate:"2019-10-15T19:16:51Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"15+", GitVersion:"v1.15.11-eks-af3caf", GitCommit:"af3caf6136cd355f467083651cc1010a499f59b1", GitTreeState:"clean", BuildDate:"2020-03-27T21:51:36Z", GoVersion:"go1.12.17", Compiler:"gc", Platform:"linux/amd64"}
OS:sw_vers
ProductName:	Mac OS X
ProductVersion:	10.15.4
BuildVersion:	19E287

	</description>
	<comments>
		<comment id='1' author='TomVanWemmel' date='2020-05-26T16:25:05Z'>
		Issue Label Bot is not confident enough to auto-label this issue.
See &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='2' author='TomVanWemmel' date='2020-05-31T18:07:11Z'>
		/cc &lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='TomVanWemmel' date='2020-05-31T18:29:41Z'>
		We have managed to solve this issue.
From &lt;denchmark-link:https://github.com/istio/istio/issues/7449#issuecomment-524725058&gt;istio/istio#7449 (comment)&lt;/denchmark-link&gt;


For those running into this with EKS (side car injection) and are using Terraform to provision the cluster, I found that the issue for me, was that you needed to allow the kubernetes master access to the worker node on 443. Basically, you create another security group rule allowing this, and it resolved the issue for me. Hopefully this is helpful to someone.

		</comment>
		<comment id='4' author='TomVanWemmel' date='2020-06-02T12:16:25Z'>
		Thanks glad you were able to resolve it.
		</comment>
	</comments>
</bug>