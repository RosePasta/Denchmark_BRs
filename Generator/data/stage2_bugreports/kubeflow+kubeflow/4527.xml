<bug id='4527' author='tiopramayudi' open_date='2019-11-26T04:34:30Z' closed_time='2020-01-21T14:05:14Z'>
	<summary>Kubeflow 0.7.0 Deployment IAP Failed Create Endpoints with private GKE</summary>
	<description>
/kind bug
What steps did you take and what happened:
I faced problem when deploying kubeflow 0.7.0 in private cluster using gke 1.14 and this https://raw.githubusercontent.com/kubeflow/manifests/v0.7-branch/kfdef/kfctl_gcp_iap.0.7.0.yaml and used modified network for cluster dm. There is no error logs while doing deployment, but I can't access https://${{FQDN}}, got error DNS_PROBE_FINISHED_NXDOMAIN. I did troubleshoot by running this
  kubectl describe -n istio-system managedcertificate gke-certificate

  Status:
  Certificate Name:    mcrt-853cec7a-8a3b-4c34-989e-8818e9c104b4
  Certificate Status:  Provisioning
  Domain Status:
    Domain:  {{KF_NAME}}.endpoints.{{PROJECT}}.cloud.goog
    Status:  FailedNotVisible
I also noticed that endpoint is not created. This is log on cloud-endpoints-controller
[ERROR][{{KF_NAME}}] Failed to get existing endpoint service: Get https://servicemanagement.googleapis.com/v1/services/{{KF_NAME}}.endpoints.{{PROJECT}}.cloud.goog?alt=json: status code 500 trying to fetch http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token
What did you expect to happen:
I can access https://${{FQDN}}
Anything else you would like to add:
Some troubleshooting steps from jeremy,
gcloud --project=${PROJECT} iam service-accounts  get-iam-policy ${KFNAME}-admin@${PROJECT}.iam.gserviceaccount.com 

bindings:
- members:
  - serviceAccount:${PROJECT}.svc.id.goog[istio-system/kf-admin]
  - serviceAccount:${PROJECT}.svc.id.goog[kubeflow/kf-admin]
  - serviceAccount:${PROJECT}.id.goog[kubeflow/profiles-controller-service-account]
  role: roles/iam.workloadIdentityUser
etag: BwWYLZVxpU4=
version: 1
kubectl -n istio-system describe cloudendpoints ${KF_NAME}
Name:         {{KF_NAME}}
Namespace:    istio-system
Labels:       app.kubernetes.io/component=iap-ingress
              app.kubernetes.io/instance=iap-ingress-v0.7.0
              app.kubernetes.io/managed-by=kfctl
              app.kubernetes.io/name=iap-ingress
              app.kubernetes.io/part-of=kubeflow
              app.kubernetes.io/version=v0.7.0
              kustomize.component=iap-ingress
Annotations:  kubectl.kubernetes.io/last-applied-configuration:
                {"apiVersion":"ctl.isla.solutions/v1","kind":"CloudEndpoint","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"iap-ing...
API Version:  ctl.isla.solutions/v1
Kind:         CloudEndpoint
Metadata:
  Creation Timestamp:  2019-11-21T15:37:22Z
  Generation:          1
  Resource Version:    3382
  Self Link:           /apis/ctl.isla.solutions/v1/namespaces/istio-system/cloudendpoints/{{KF_NAME}}
  UID:                 cfa7fcdd-0c74-11ea-85b1-4201ac100013
Spec:
  Project:  {{PROJECT}}
  Target Ingress:
    Name:       envoy-ingress
    Namespace:  istio-system
Events:         &lt;none&gt;
Checking if there are problems with the node-metadata server in the case where I modified the network
kubectl run --rm -it \
  --generator=run-pod/v1 \
  --image google/cloud-sdk:slim \
  --serviceaccount kf-admin \
  --namespace kubeflow \
  workload-identity-test

gcloud auth list
ACTIVE  ACCOUNT
*       {{KF_NAME}}-admin@{{PROJECT}}.iam.gserviceaccount.com

gcloud config list
[component_manager]
disable_update_check = true
[core]
account = {{KF_NAME}}-admin@{{PROJECT}}.iam.gserviceaccount.com
disable_usage_reporting = true
project = {{PROJECT}}
[metrics]
environment = github_docker_image
Also deployment status for activator, autoscaler, autoscaler-hpa, controller is  Internal error occurred: failed calling webhook "sidecar-injector.istio.io": Post https://istio-sidecar-injector.istio-system.svc:443/inject?timeout=30s: no endpoints available for service "istio-sidecar-injector". Also there is discussion here https://groups.google.com/forum/#!topic/kubeflow-discuss/1V4w7OHoML0 related issue that I faced
Environment:

kfctl version: (use kfctl version): 0.7.0
Kubernetes platform: GKE
Kubernetes version: (use kubectl version): 1.14.8-gke.17

	</description>
	<comments>
		<comment id='1' author='tiopramayudi' date='2019-11-26T04:34:47Z'>
		Issue Label Bot is not confident enough to auto-label this issue.
See &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='2' author='tiopramayudi' date='2019-11-26T08:24:55Z'>
		/assign &lt;denchmark-link:https://github.com/lluunn&gt;@lluunn&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='tiopramayudi' date='2019-12-03T21:03:56Z'>
		I tried the &lt;denchmark-link:https://www.kubeflow.org/docs/gke/private-clusters/#deploy-kubeflow-with-private-gke&gt;instructions&lt;/denchmark-link&gt;
 before step 11 (updated image to gcr). So some images cannot be pulled, but cloudendpoint should be fine.
But got different error:

when visiting FQDN, I got ERR_NAME_NOT_RESOLVED, server IP address could not be found. I think this means cloud endpoint is not functioning.
I can see a cloudendpoint resource, but the cloudendpoint pod logs seems not doing anything:
2019/12/03 19:53:47 [INFO] Fetching Project ID from Compute metadata API...
2019/12/03 19:53:47 [INFO] Fetching Numeric Project ID from Compute metadata API...
2019/12/03 19:53:47 [INFO] Instantiating GCE client...
2019/12/03 19:53:47 [INFO] Instantiating Google Cloud Service Management Client...
2019/12/03 19:53:47 [INFO] Initialized controller on port 80



Also, many istio images cannot be pulled, I think we need a different manifests:
&lt;denchmark-code&gt;NAME                                      READY   STATUS              RESTARTS   AGE
backend-updater-0                         1/1     Running             0          72m
grafana-67c69bb567-kpd28                  0/1     ImagePullBackOff    0          73m
iap-enabler-7f87598576-vwzdm              1/1     Running             0          72m
istio-citadel-67697b6697-4ckxn            0/1     ImagePullBackOff    0          73m
istio-cleanup-secrets-1.1.6-b68kf         0/1     ImagePullBackOff    0          73m
istio-egressgateway-7dbbb87698-k8xt5      0/1     ImagePullBackOff    0          73m
istio-galley-7bffd57ff4-lndht             0/1     ContainerCreating   0          73m
istio-grafana-post-install-1.1.6-cfzr7    0/1     ImagePullBackOff    0          73m
istio-ingressgateway-565b894b5f-dsqn7     0/1     ImagePullBackOff    0          73m
istio-pilot-6dd5b8f74c-5bspb              0/2     ImagePullBackOff    0          73m
istio-policy-7f8bb87857-xj7xw             0/2     ImagePullBackOff    0          73m
istio-security-post-install-1.1.6-2b42f   0/1     ImagePullBackOff    0          73m
istio-sidecar-injector-fd5875568-xlth7    0/1     ContainerCreating   0          73m
istio-telemetry-8759dc6b7-5tvzh           0/2     ImagePullBackOff    0          73m
istio-tracing-5d8f57c8ff-hd4z6            0/1     ImagePullBackOff    0          73m
kiali-d4d886dd7-t7wzw                     0/1     ImagePullBackOff    0          73m
prometheus-d8d46c5b5-842n7                0/1     ContainerCreating   0          73m
whoami-app-cbdf7bf6f-chdqx                1/1     Running             0          72m
&lt;/denchmark-code&gt;

UPDATE: I need to update the metacontroller image from dockerhub to gcr because cloud endpoint controller relies on that.
		</comment>
		<comment id='4' author='tiopramayudi' date='2019-12-04T01:27:06Z'>
		Since the istio-ingressgateway cannot be pulled, I tried using GKE's istio add-on.
This can be added after cluster created: &lt;denchmark-link:https://cloud.google.com/istio/docs/istio-on-gke/installing#adding_istio_on_gke_to_an_existing_cluster&gt;https://cloud.google.com/istio/docs/istio-on-gke/installing#adding_istio_on_gke_to_an_existing_cluster&lt;/denchmark-link&gt;

After this, I think the certificate works. Now my error when visiting FQDN is: Origin authentication failed.
I think the problem is iap-enabler, logs:
&lt;denchmark-code&gt;node port is 31462
BACKEND_ID=871584170915856936
+ NODE_PORT=31462
+ echo 'node port is 31462'
+ [[ -z k8s-be-31380--45316dca55a0f388 ]]
+ [[ -z 871584170915856936 ]]
+ echo BACKEND_ID=871584170915856936
+ JWT_AUDIENCE=/projects/711890160434/global/backendServices/871584170915856936
patch JWT audience: /projects/711890160434/global/backendServices/87158417091585693
&lt;/denchmark-code&gt;

It gets that the node port should be 31462 (not the default one 31380 that we always pick), but it seems to get the id of a wrong backendservice.
I think we need to cp &lt;denchmark-link:https://github.com/kubeflow/manifests/pull/573&gt;kubeflow/manifests#573&lt;/denchmark-link&gt;
 to 0.7
Or workaround: delete the iap-enabler pod, then it will pickup the new backend
However, with the workaround, I still got Origin authentication failed, investigating...
		</comment>
		<comment id='5' author='tiopramayudi' date='2019-12-04T02:04:16Z'>
		For some reason my IAP was turned off. I enabled it again via console &lt;denchmark-link:https://console.cloud.google.com/security/iap?_ga=2.216801814.-1643724808.1565303314&gt;https://console.cloud.google.com/security/iap?_ga=2.216801814.-1643724808.1565303314&lt;/denchmark-link&gt;
, and now I can see the kubeflow dashboard
		</comment>
		<comment id='6' author='tiopramayudi' date='2019-12-16T13:58:07Z'>
		Thanks &lt;denchmark-link:https://github.com/lluunn&gt;@lluunn&lt;/denchmark-link&gt;
 should we update the instructions
&lt;denchmark-link:https://www.kubeflow.org/docs/gke/private-clusters/&gt;https://www.kubeflow.org/docs/gke/private-clusters/&lt;/denchmark-link&gt;

Can we add a banner to the page similar to the one on the upgrade page indicating that upgrades are
alpha support?
&lt;denchmark-link:https://github.com/kubeflow/website/blob/master/content/docs/upgrading/upgrade.md&gt;https://github.com/kubeflow/website/blob/master/content/docs/upgrading/upgrade.md&lt;/denchmark-link&gt;

Related: &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3082&gt;#3082&lt;/denchmark-link&gt;
 - Document use of shared VPC
		</comment>
		<comment id='7' author='tiopramayudi' date='2020-01-21T14:05:14Z'>
		Closing this as a duplicate of  &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3650&gt;#3650&lt;/denchmark-link&gt;
 which is tracking installing Kubeflow on private GKE.
Duplicate of &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3650&gt;#3650&lt;/denchmark-link&gt;

Filed &lt;denchmark-link:https://github.com/kubeflow/website/issues/1542&gt;kubeflow/website#1542&lt;/denchmark-link&gt;
 to update the docs with a banner indicating Alpha support.
		</comment>
	</comments>
</bug>