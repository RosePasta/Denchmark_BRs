<bug id='4540' author='y4roslav' open_date='2019-11-30T18:07:05Z' closed_time='2019-12-14T20:11:00Z'>
	<summary>Centraldashboard 403 error</summary>
	<description>
/kind bug
We are using 0.7 kubeflow with LDAP/Dax integration. In one day our dashboard start rejecting our request with error 403.
What did you expect to happen:
Central Dashboard with Dax page
Anything else you would like to add:
Only errors I can see is from central dashboard pod
&lt;denchmark-code&gt;&gt; node dist/server.js
Initializing Kubernetes configuration
Unable to fetch Nodes { kind: 'Status',
  apiVersion: 'v1',
  metadata: {},
  status: 'Failure',
  message:
   'nodes is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "nodes" in API g
roup "" at the cluster scope',
  reason: 'Forbidden',
  details: { kind: 'nodes' },
  code: 403 }
Unable to fetch Application information: { kind: 'Status',
  apiVersion: 'v1',
  metadata: {},
  status: 'Failure',
  message:
   'applications.app.k8s.io is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resourc
e "applications" in API group "app.k8s.io" in the namespace "kubeflow"',
  reason: 'Forbidden',
  details: { group: 'app.k8s.io', kind: 'applications' },
  code: 403 }
Unable to fetch Nodes { kind: 'Status',
  apiVersion: 'v1',
  metadata: {},
  status: 'Failure',
  message:
   'nodes is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "nodes" in API g
roup "" at the cluster scope',
  reason: 'Forbidden',
  details: { kind: 'nodes' },
  code: 403 }
&lt;/denchmark-code&gt;

Environment:

Kubeflow version: 0.7
kfctl version: 0.7
Kubernetes platform: CaaS (SUSE, CRI-O)
Kubernetes version: v1.15.2
OS: SLES 15

	</description>
	<comments>
		<comment id='1' author='y4roslav' date='2019-11-30T18:07:15Z'>
		Issue Label Bot is not confident enough to auto-label this issue.
See &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='2' author='y4roslav' date='2019-12-11T11:26:06Z'>
		My dashboard also started all of a sudden to return 403.
Standard setup following the instructions in &lt;denchmark-link:https://www.kubeflow.org/docs/started/k8s/kfctl-existing-arrikto/#before-you-start&gt;https://www.kubeflow.org/docs/started/k8s/kfctl-existing-arrikto/#before-you-start&lt;/denchmark-link&gt;
 in a Google Kubernetes cluster:
&lt;denchmark-code&gt;$ gcloud container clusters create NAME \
   --zone ZONE \
   --num-nodes=1 \
   --disk-size=50GB \
   --machine-type=n1-standard-4 #Has 15 GB memory
&lt;/denchmark-code&gt;

I access for example https://mydomain.com/test1 and after ~20 seconds I get this 403:
&lt;denchmark-code&gt;$ kubectl logs   -n istio-system  pod/istio-ingressgateway-57f7cfdfdd-fxjdm
[...]
[2019-12-11T10:49:58.959Z] "GET /test1 HTTP/1.1" 403 UAEX "-" 0 0 10001 - "85.195.222.99,10.44.0.17" "... browser details ..." "dfbbaff5-ed4a-9183-a902-4b26af8464c9" "mydomain.com" "-" - - 127.0.0.1:80 127.0.0.1:42440 -
&lt;/denchmark-code&gt;

No cookies seem to be associated with the domain in the browser.
I see this but I don't think it's related, as nothing new appears when the 403 is returned:
&lt;denchmark-code&gt;$ kubectl logs   -n kubeflow pod/centraldashboard-64c4cb4c6-xl8rq
[...]
Unable to fetch Events for myuser: { kind: 'Status',
  apiVersion: 'v1',
  metadata: {},
  status: 'Failure',
  message:
   'events is forbidden: User "system:serviceaccount:kubeflow:centraldashboard" cannot list resource "events" in API group "" in the namespace "myuser"',
  reason: 'Forbidden',
  details: { kind: 'events' },
  code: 403 }
&lt;/denchmark-code&gt;

Any idea how to get more info about what's causing this?
		</comment>
		<comment id='3' author='y4roslav' date='2019-12-12T12:34:41Z'>
		Hi all.
I believe you are hitting this issue: &lt;denchmark-link:https://github.com/arrikto/oidc-authservice/issues/2&gt;arrikto/oidc-authservice#2&lt;/denchmark-link&gt;

This has been fixed in a later version, which is now being merged into v0.7.
&lt;denchmark-link:https://github.com/kubeflow/manifests/pull/639&gt;kubeflow/manifests#639&lt;/denchmark-link&gt;

The temporary solution is to delete the authservice pod, which will unblock it.
The permanent solution is to update the authservice image.
		</comment>
		<comment id='4' author='y4roslav' date='2019-12-13T10:31:55Z'>
		I deleted the pod, but I still get 403:
&lt;denchmark-code&gt;$ kubectl get pods --all-namespaces | grep authservice                                             
istio-system   authservice-55d474b894-plv25                                  1/1     Running     0          3m10s

$ kubectl delete -n istio-system pod/authservice-55d474b894-plv25   
pod "authservice-55d474b894-plv25" deleted
&lt;/denchmark-code&gt;

I also tried to delete the gateway, but still the same:
&lt;denchmark-code&gt;$ kubectl delete  -n istio-system  pod/istio-ingressgateway-57f7cfdfdd-fxjdm 
pod "istio-ingressgateway-57f7cfdfdd-fxjdm" deleted
&lt;/denchmark-code&gt;

Is there an option to set a more verbose log level on this gateway?
		</comment>
		<comment id='5' author='y4roslav' date='2019-12-13T10:34:18Z'>
		If I recreate the cluster will that include the latest 0.7 including the &lt;denchmark-link:https://github.com/kubeflow/manifests/pull/639&gt;kubeflow/manifests#639&lt;/denchmark-link&gt;
 fix?
		</comment>
		<comment id='6' author='y4roslav' date='2019-12-13T10:39:14Z'>
		&lt;denchmark-link:https://github.com/aleb&gt;@aleb&lt;/denchmark-link&gt;
 I applied fix recommended by &lt;denchmark-link:https://github.com/yanniszark&gt;@yanniszark&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/arrikto/oidc-authservice/issues/2&gt;arrikto/oidc-authservice#2&lt;/denchmark-link&gt;
 and looks like it works. To check that your build would work without issue please check you kustromize files. Both should contain this lines:

istio/oidc-authservice/base/deployment.yaml

&lt;denchmark-code&gt;readinessProbe:
             httpGet:
               path: /
               port: 8081
&lt;/denchmark-code&gt;


Main one istio/oidc-authservice/base/kustomization.yaml should have tag newTag: 28c59ef instead  6ac9400

It works for my installation.
PS If it will keep working next few days and you would be able to fix it I will close this issue.
		</comment>
		<comment id='7' author='y4roslav' date='2019-12-13T13:47:37Z'>
		Until &lt;denchmark-link:https://www.kubeflow.org/docs/started/k8s/kfctl-existing-arrikto&gt;https://www.kubeflow.org/docs/started/k8s/kfctl-existing-arrikto&lt;/denchmark-link&gt;
 is updated to point to an updated yaml, I'll use the workaround. It was not enough to delete the pod, I had to do it like this:
&lt;denchmark-code&gt;$ kubectl delete -n istio-system deployment.apps/authservice
$ ~/Downloads/kfctl-darwin apply -V -f kfctl_existing_arrikto.yaml 
$ kubectl describe -n istio-system pod/authservice-6bcdbbd76d-crl5q | grep Readiness
    Readiness:      http-get http://:8081/ delay=0s timeout=1s period=10s #success=1 #failure=3
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>