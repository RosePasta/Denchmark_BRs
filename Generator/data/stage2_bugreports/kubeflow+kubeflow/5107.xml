<bug id='5107' author='iamvarol' open_date='2020-07-06T09:44:37Z' closed_time='2020-07-08T19:13:55Z'>
	<summary>Minikf on GCP installation is not proceeding maybe for 2 hours. It is stuck on 33/35 and 34/35 pods are ready. Progress bar moves one step back and moves forward one step so and so forth. But couldn't finished in 2 hours</summary>
	<description>
/kind bug

Minikf on GCP installation is not proceeding maybe for 2 hours. It is stuck on 32/35 (92%), 33/35 (94%), and 34/35 (97%) pods are ready. The progress bar moves one step back and moves forward one step so and so forth. But couldn't finish in 2 hours.
&lt;denchmark-link:https://user-images.githubusercontent.com/55491416/86579739-61780580-bf86-11ea-8496-200568035379.png&gt;&lt;/denchmark-link&gt;

What did you expect to happen:
Finish the installation in minutes.
Environment:

Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard): Current version on GCP (Minkube + Kubeflow + Rok = Minikf)
kfctl version: (use kfctl version):
Kubernetes platform: (e.g. minikube)
Kubernetes version: (use kubectl version):
OS (e.g. from /etc/os-release):

	</description>
	<comments>
		<comment id='1' author='iamvarol' date='2020-07-06T09:44:44Z'>
		Issue Label Bot is not confident enough to auto-label this issue.
See &lt;denchmark-link:https://label-bot-prod.mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='2' author='iamvarol' date='2020-07-06T09:44:51Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




platform/gcp
0.72



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://label-bot-prod.mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='3' author='iamvarol' date='2020-07-07T07:41:15Z'>
		I am facing a similar issue for "MiniKF on your laptop"installation as well. It is stuck at 33/35 pods for the whole night.
I am doing this installation on Windows 10.
		</comment>
		<comment id='4' author='iamvarol' date='2020-07-07T07:48:59Z'>
		
I am facing a similar issue for "MiniKF on your laptop"installation as well. It is stuck at 33/35 pods for the whole night.
I am doing this installation on Windows 10.

Fixed this issue, by deleting the local state files. In case of windows it was by using this command.
[Windows] del minikf-user-data.vdi
		</comment>
		<comment id='5' author='iamvarol' date='2020-07-07T18:46:23Z'>
		&lt;denchmark-link:https://github.com/cspavlou&gt;@cspavlou&lt;/denchmark-link&gt;
 Hey Chris, can you please look at this issue?
		</comment>
		<comment id='6' author='iamvarol' date='2020-07-08T17:06:50Z'>
		Hi &lt;denchmark-link:https://github.com/iamvarol&gt;@iamvarol&lt;/denchmark-link&gt;
 , what are the VM specs?
edit: note that according to the &lt;denchmark-link:https://www.kubeflow.org/docs/started/workstation/minikf-gcp/&gt;official doc&lt;/denchmark-link&gt;
:

If you are using the GCP Free Tier or the 12-month trial period with $300 credit, note that you canâ€™t run the default GCP installation of MiniKF, because the free tier does not offer enough resources. You need to upgrade to a paid account.

		</comment>
		<comment id='7' author='iamvarol' date='2020-07-08T19:13:50Z'>
		Ahaa, I got the point, it is a free tier!
		</comment>
		<comment id='8' author='iamvarol' date='2020-10-03T09:09:50Z'>
		I am on GCP, started with free tier but have upgraded to paid. I have transferred 10usd as a test (at 310usd credit now) . But I still get the abovementioned issue. Have tried redeploying from market place multiple times but no luck.
"stuck on 33/35 and 34/35 pods are ready"
My credit card is linked so I do not understand what is happening.
Do I need to delete the "minikf-user-data.vdi" files as someaone mentioned ?
Thanks.
		</comment>
		<comment id='9' author='iamvarol' date='2020-10-12T21:18:04Z'>
		I am getting the same issue on Ubuntu 20.04.
I have plenty of free resources. I listed the pods in kubectl and this is what I see:
admission-webhook-deployment-79b7c7744d-zrrl9                  1/1     Running            0          12m
application-controller-stateful-set-0                          1/1     Running            0          12m
argo-ui-778676df64-hbwtx                                       1/1     Running            0          12m
centraldashboard-6f7dc48894-xmg64                              1/1     Running            0          12m
jupyter-web-app-deployment-9584df4f9-kmrpb                     1/1     Running            0          12m
katib-controller-6b789b6cb5-jwk2q                              1/1     Running            1          11m
katib-db-manager-64f548b47c-v6fwr                              1/1     Running            1          11m
katib-mysql-57884cb488-48lqr                                   1/1     Running            0          11m
katib-ui-5c5cc6bd77-j85x7                                      1/1     Running            0          11m
kfserving-controller-manager-0                                 2/2     Running            1          11m
kubeflow-reception-5974d59596-s2b6t                            1/1     Running            0          12m
metadata-db-76c9f78f77-rkhdp                                   1/1     Running            0          12m
metadata-deployment-674fdd976b-c7xnm                           1/1     Running            0          12m
metadata-envoy-deployment-5688989bd6-4x5zv                     1/1     Running            0          12m
metadata-grpc-deployment-5579bdc87b-5tcvr                      1/1     Running            2          12m
metadata-ui-9b8cd699d-7xxgs                                    1/1     Running            0          12m
minio-755ff748b-d9sc4                                          1/1     Running            0          11m
ml-pipeline-79b4f85cbc-bjwbw                                   1/1     Running            0          11m
ml-pipeline-ml-pipeline-visualizationserver-5fdffdc5bf-ndtnl   1/1     Running            0          10m
ml-pipeline-persistenceagent-645cb66874-g7phb                  1/1     Running            0          11m
ml-pipeline-scheduledworkflow-6c978b6b85-7g746                 1/1     Running            0          11m
ml-pipeline-ui-74d7fc4d6-zxfqr                                 1/1     Running            0          11m
ml-pipeline-viewer-controller-deployment-8554dc7b9f-x6bbm      1/1     Running            0          11m
mysql-598bc897dc-bh8kl                                         1/1     Running            0          11m
notebook-controller-deployment-64549ff58b-w8gbr                1/1     Running            0          12m
profiles-deployment-785868bcd7-p5cq9                           2/2     Running            0          10m
pvcviewer-controller-controller-manager-dfdd686d4-w5wbd        2/2     Running            0          10m
pytorch-operator-5fd5f94bdd-96qbj                              1/1     Running            0          12m
seldon-controller-manager-679fc777cd-mxwhw                     1/1     Running            0          10m
spark-operatorcrd-cleanup-h4f7b                                0/2     Completed          0          12m
spark-operatorsparkoperator-c7b64b87f-4s259                    1/1     Running            0          12m
spartakus-volunteer-6b767c8d6-x2vv7                            1/1     Running            0          11m
tensorboard-6544748d94-4vm5h                                   0/1     CrashLoopBackOff   6          11m
tf-job-operator-7d7c8fb8bb-pcwts                               1/1     Running            0          11m
volumes-web-app-df9cf6fb7-267pv                                1/1     Running            0          10m
workflow-controller-945c84565-bgqh6                            1/1     Running            0          12m
This same deployment has previously worked, but it looks like the tensorboard pod is failing?
I can't log into the deployment in it's current condition.
What I've tried:

vagrant halt
vagrant destroy
vagrant up

No change.
Any advice/ideas much appreciated.
Any ideas?
		</comment>
		<comment id='10' author='iamvarol' date='2020-10-12T21:18:12Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




area/kfctl
0.96



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://label-bot-prod.mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
	</comments>
</bug>