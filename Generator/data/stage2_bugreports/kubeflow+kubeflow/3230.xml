<bug id='3230' author='jsnowacki' open_date='2019-05-09T10:46:42Z' closed_time='2020-01-07T21:08:31Z'>
	<summary>[GCP] CLI deployment (kfctl) fails to create cloud endpoint correctly</summary>
	<description>
I performed (multiple times) the deployment using the description given at &lt;denchmark-link:https://www.kubeflow.org/docs/gke/deploy/deploy-cli/&gt;https://www.kubeflow.org/docs/gke/deploy/deploy-cli/&lt;/denchmark-link&gt;
. Everything seems to run fine but when I try to reach the endpoint .endpoints..cloud.goog I get in the browser DNS_PROBE_FINISHED_NXDOMAIN. Indeed, looking into endpoints in the cloud console or CLI nothing is there.
I checked the pod logs for cloud-endpoints-controller-... and get the following log lines repeating every second or so:
&lt;denchmark-code&gt;2019/05/09 09:44:49 [DEBUG][&lt;kfapp&gt;] Changed because parent sig different
2019/05/09 09:44:49 [DEBUG][&lt;kfapp&gt;] Changed because ingress target IP changed
2019/05/09 09:44:50 [INFO][&lt;kfapp&gt;] Service does not yet exist, creating: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog
2019/05/09 09:44:51 [ERROR] Could not sync state: [ERROR] Failed to creat Cloud Endpoints service: serviceName: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, err: googleapi: Error 400: Service &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog has been deleted and will be purged after 30 days. To reuse this service, please undelete the service following https://cloud.google.com/service-management/create-delete., failedPrecondition
&lt;/denchmark-code&gt;

I removed kfapp and project names on purpose for potential security reasons; they are given in a correct form; nothing complains at least.
I don't see any issues before, access denied etc. There are no errors during the kfctl run as well. I also tried specifying version -v v0.5.0 and -v v0.5.1, but both give the same result.
Before I tried the web UI deployment and it worker, but I wanted to customize deployment and test different machine pools settings.
Not sure if it's relevant, but I run it on Windows 10 WSL Ubuntu, thus, at least theoretically from the application perspective, Linux.
	</description>
	<comments>
		<comment id='1' author='jsnowacki' date='2019-05-09T10:46:45Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.79. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='jsnowacki' date='2019-05-10T13:30:10Z'>
		The logs say your ingress IP keeps changing is that accurate?
Do you use the same kfapp name on each run?
Can you use stackdriver to look at the logs for cloud endpoints to see what's going on with the service?
		</comment>
		<comment id='3' author='jsnowacki' date='2019-05-13T09:52:37Z'>
		The above keeps repeating in the logs, thus, it seems the IP keeps changing, though, I myself are not causing it. Also the cluster is dedicated to Kubeflow, hence, nothing else should intervene.
Yes, I repeat deployment with the same KFAPP name. Thought, it is different than the one used on web UI deployment.
I have some logs and the cloud endpoint pods and replica set are being created. The only error(ish)  log I found so far is:
&lt;denchmark-code&gt; {
 insertId: "9f1ffa0d-62fb-4f17-8e69-038d27463f29"  
 
labels: {
  authorization.k8s.io/decision: "allow"   
  authorization.k8s.io/reason: "RBAC: allowed by ClusterRoleBinding "default-admin" of ClusterRole "cluster-admin" to User "&lt;mail&gt;""   
 }
 logName: "projects/sotrender-rd/logs/cloudaudit.googleapis.com%2Factivity"  
 
operation: {
  first: true   
  id: "9f1ffa0d-62fb-4f17-8e69-038d27463f29"   
  last: true   
  producer: "k8s.io"   
 }
 
protoPayload: {
  @type: "type.googleapis.com/google.cloud.audit.AuditLog"   
  
authenticationInfo: {
   principalEmail: "&lt;mail&gt;"    
  }
  
authorizationInfo: [
   
0: {
    granted: true     
    permission: "io.k8s.metacontroller.v1alpha1.compositecontrollers.patch"     
    resource: "metacontroller.k8s.io/v1alpha1/compositecontrollers/cloud-endpoints-controller"     
    
resourceAttributes: {
    }
   }
  ]
  methodName: "io.k8s.metacontroller.v1alpha1.compositecontrollers.patch"   
  
requestMetadata: {
   callerIp: "83.144.96.18"    
   
destinationAttributes: {
   }
   
requestAttributes: {
   }
  }
  resourceName: "metacontroller.k8s.io/v1alpha1/compositecontrollers/cloud-endpoints-controller"   
  serviceName: "k8s.io"   
  
status: {
   code: 5    
   message: "NOT_FOUND"    
  }
 }
 receiveTimestamp: "2019-05-13T09:22:38.491432979Z"  
 
resource: {
  
labels: {
   cluster_name: "&lt;kfapp&gt;"    
   location: "europe-west1-b"    
   project_id: "&lt;projecy&gt;"    
  }
  type: "k8s_cluster"   
 }
 timestamp: "2019-05-13T09:22:26.923533Z"  
}
&lt;/denchmark-code&gt;

If you need some other logs from stack driver just let me know.
		</comment>
		<comment id='4' author='jsnowacki' date='2019-05-13T12:34:04Z'>
		Can you check your ingress;
&lt;denchmark-code&gt;kubectl get ingress -o yaml
&lt;/denchmark-code&gt;

What is the ip address in the status? Does it keep changing?
Can you run
&lt;denchmark-code&gt;gcloud --project=${PROJECT}  endpoints services list
gcloud --project=${PROJECT}  endpoints services describe ${SERVICE NAME}
&lt;/denchmark-code&gt;

Then try running
&lt;denchmark-code&gt;gcloud --project=${PROJECT}  endpoints services undelete ${SERVICE NAME}
&lt;/denchmark-code&gt;

I think the CloudEndpoints controller needs to explicitly check if the service is in the process of being deleted and then undelete it before trying to apply the config.
/cc &lt;denchmark-link:https://github.com/danisla&gt;@danisla&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='jsnowacki' date='2019-05-13T13:12:34Z'>
		The ingress command
&lt;denchmark-code&gt;$ kubectl get ingress -o yaml
&lt;/denchmark-code&gt;

gives:
apiVersion: v1
items:
- apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    annotations:
      certmanager.k8s.io/issuer: letsencrypt-prod
      ingress.kubernetes.io/backends: '{"k8s-be-30338--dd52cf248c76c70c":"HEALTHY","k8s-be-30573--dd52cf248c76c70c":"HEALTHY","k8s-be-31298--dd52cf248c76c70c":"HEALTHY"}'
      ingress.kubernetes.io/forwarding-rule: k8s-fw-kubeflow-envoy-ingress--dd52cf248c76c70c
      ingress.kubernetes.io/ssl-redirect: "true"
      ingress.kubernetes.io/target-proxy: k8s-tp-kubeflow-envoy-ingress--dd52cf248c76c70c
      ingress.kubernetes.io/url-map: k8s-um-kubeflow-envoy-ingress--dd52cf248c76c70c
      ksonnet.io/managed: '{"pristine":"H4sIAAAAAAAA/2SRO47cMAyG+xyDZWB5druBbpAmSJUmSEFLjEewTAokPcnC8N0DeXbzwAIqJOp/fIJ2wFa+kloRhgj0y4n73i7354kcn2GApXCGCJ94VjKDAVZyzOgIcQdkFkfvln5MpL4i40w6Llcbi1yK2UYKESq5ESd9aR6aSoYByiNzXLaJlMnpdJjVoJSLUnKI4LpRx/hP8+acq0xYg3WGFEoLjCtBBM3hR5WfobR3Vq8WMJ2qM/oYoOJE9XzAYsJM3nVJ1iZM3BkKtvBa2fWvJcR3efkzf4ytYep3vbMTdLk1Sj1ct0oG8dsONzH/SzkS5yaF3UYTV+JMGjSPqcqWx1lkhgFu7q2HNPTbI2TCtFD/mx2M9F4Sff6HC4a36RdRh3h9uj4dw2mHCJePcHw/+vrwGwAA//8BAAD//2+gwpMEAgAA"}'
      kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
      kubernetes.io/ingress.global-static-ip-name: &lt;kfapp&gt;-ip
      kubernetes.io/tls-acme: "true"
    creationTimestamp: "2019-05-13T12:53:11Z"
    generation: 2
    labels:
      app.kubernetes.io/deploy-manager: ksonnet
      ksonnet.io/component: iap-ingress
    name: envoy-ingress
    namespace: kubeflow
    resourceVersion: "3875"
    selfLink: /apis/extensions/v1beta1/namespaces/kubeflow/ingresses/envoy-ingress
    uid: 107796bb-757e-11e9-8b93-42010a840264
  spec:
    rules:
    - host: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog
      http:
        paths:
        - backend:
            serviceName: envoy
            servicePort: 8080
          path: /*
        - backend:
            serviceName: cm-acme-http-solver-5pbmq
            servicePort: 8089
          path: /.well-known/acme-challenge/_q0EAcw6v4PjBupTLh6M_gaHdeo8s1gDtlKjVHN0mYg
  status:
    loadBalancer:
      ingress:
      - ip: &lt;ip&gt;
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
The gcloud commands give:
&lt;denchmark-code&gt;$ gcloud --project=${PROJECT}  endpoints services list
Listed 0 items.

$ gcloud --project=${PROJECT}  endpoints services describe ${KFAPP}
ERROR: (gcloud.endpoints.services.describe) User [&lt;mail&gt;] does not have permission to access service [&lt;kfapp&gt;] (or it may not exist): Service &lt;kfapp&gt; not found or permission denied.

gcloud --project=${PROJECT}  endpoints services undelete ${KFAPP}
ERROR: (gcloud.endpoints.services.undelete) User [&lt;mail&gt;] does not have permission to access service [&lt;kfapp&gt;] (or it may not exist): Service &lt;kfapp&gt; not found or permission denied.
&lt;/denchmark-code&gt;

I assume the latter errors are caused by the lack of service rather than permission denied.
BTW during the command run kfctl apply all -V I got the following error once:
&lt;denchmark-code&gt;ERRO[0354] (Will retry) Component cloud-endpoints apply failed; Error: handle object: patching object from cluster: merging object with existing state: unable to recognize "/tmp/ksonnet-mergepatch210932744": no matches for kind "CompositeController" in version "metacontroller.k8s.io/v1alpha1"  filename="ksonnet/ksonnet.go:174"
&lt;/denchmark-code&gt;

But at the end I get all OK result:
&lt;denchmark-code&gt;INFO[0880] All components apply succeeded                filename="ksonnet/ksonnet.go:192"
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='jsnowacki' date='2019-05-13T15:09:34Z'>
		OK, I've tried with the newer kfctl app build 0.5.1 for linux and changed name slightly 2 and the endpoint gets created this time:
&lt;denchmark-code&gt;$ gcloud --project=${PROJECT}  endpoints services list
NAME                                        TITLE
&lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog

$ gcloud --project=${PROJECT}  endpoints services describe &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
producerProjectId: &lt;project&gt;
serviceConfig:
  documentation: {}
  legacy:
    apiV1Name: &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
    devconsole:
      consoleApi: NEW
  migration: {}
  usage: {}
serviceName: &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
&lt;/denchmark-code&gt;

Now I get new log from cloud-endpoints-controller-...
&lt;denchmark-code&gt;2019/05/13 14:59:46 [INFO][rd-flow2] Create pending
2019/05/13 14:59:46 [INFO][rd-flow2] waiting for loadbalancer status from Ingress envoy-ingress
&lt;/denchmark-code&gt;

All envoys are dead:
&lt;denchmark-code&gt;envoy-69bf97959c-2bbm9                                      1/2     CrashLoopBackOff   9          22m
envoy-69bf97959c-bnhvm                                      1/2     CrashLoopBackOff   9          22m
envoy-69bf97959c-j4hkg                                      1/2     CrashLoopBackOff   9          22m
&lt;/denchmark-code&gt;

Log from envoy:
&lt;denchmark-code&gt;[2019-05-13 15:01:12.548][1][info][main] external/envoy/source/server/server.cc:184] initializing epoch 0 (hot restart version=9.200.16384.127.options=capacity=16384, num_slots=8209 hash=228984379728933363)
[2019-05-13 15:01:12.548][1][critical][main] external/envoy/source/server/server.cc:71] error initializing configuration '/etc/envoy/envoy-config.json': unable to read file: /etc/envoy/envoy-config.json
&lt;/denchmark-code&gt;

And envoy iap has a lot of:
&lt;denchmark-code&gt;Waiting for backend id PROJECT=&lt;project&gt; NAMESPACE=kubeflow SERVICE=envoy filter=name~k8s-be-30035-...
&lt;/denchmark-code&gt;

Not sure if changing the name or kfctl version moved it forward but the endpoint is still unresponsive, despite it has been created.
		</comment>
		<comment id='7' author='jsnowacki' date='2019-05-15T01:22:23Z'>
		Can you try following the troubleshooting guide.
&lt;denchmark-link:https://www.kubeflow.org/docs/gke/deploy/monitor-iap-setup/&gt;https://www.kubeflow.org/docs/gke/deploy/monitor-iap-setup/&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='jsnowacki' date='2019-05-15T08:44:38Z'>
		While I was checking the causes, keys etc. I noticed that the endpoint with new  name has not been listed in the Authorized redirect URIs, so I corrected and deployed again but still no luck.
Below are the dumps you've requested.
&lt;denchmark-code&gt;$  kubectl -n kubeflow describe ingress
Name:             envoy-ingress
Namespace:        kubeflow
Address:
Default backend:  default-http-backend:80 (10.28.0.10:8080)
Rules:
  Host                                        Path  Backends
  ----                                        ----  --------
  &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
                                              /*
envoy:8080 ()
                                              /.well-known/acme-challenge/bDXsSVPftU5SSWzP3si7-LAkJW4DnIgrnF33aOkJYxI
cm-acme-http-solver-mknjh:8089 (10.28.0.13:8089)
Annotations:
  certmanager.k8s.io/issuer:                    letsencrypt-prod
  ingress.kubernetes.io/ssl-redirect:           true
  ksonnet.io/managed:                           {"pristine":"H4sIAAAAAAAA/2SRzY7UMAzH7zyGj6jp7HIa5Q24IE5cEAc3MZ2oqR3Z7sCq6rujdHbRIqQcEuf/8YuyA7byjdSKMESg307c93a5P0/k+AwDLIUzRPjMs5IZDLCSY0ZHiDsgszh6t/RjIvUVGWfScbnaWORSzDZSiFDJjTjpS/PQVDIMUB6Z47JNpExOp8OsBqVclJJDBNeNOsY/mjfnXGXCGqwzpFBaYFwJImgOP6v8+hRK+8/r1QKmU3ZmHwNUnKieL1hMmMm7LsnahIk7RMEWXju7/rWF+C4vf+ePsTVM/a53doQut0aph+tWySB+3+Em5u8wR+LcpLDbaOJKnEmD5jFV2fI4i8wwwM299ZSGfnukTJgW6r+zg5HeS6Iv78BgeJt+FXWI16fr0zGcdohw+QjHj6OvD38AAAD//wEAAP//kBBYBgYCAAA="}
  kubecfg.ksonnet.io/garbage-collect-tag:       gc-tag
  kubernetes.io/ingress.global-static-ip-name:  &lt;kfapp&gt;2-ip
  kubernetes.io/tls-acme:                       true
Events:
  Type     Reason     Age                 From                     Message
  ----     ------     ----                ----                     -------
  Normal   ADD        15m                 loadbalancer-controller  kubeflow/envoy-ingress
  Warning  Translate  15m (x11 over 15m)  loadbalancer-controller  error while evaluating the ingress spec: could not find service "kubeflow/envoy"
  Warning  Translate  14m (x2 over 15m)   loadbalancer-controller  error while evaluating the ingress spec: error getting BackendConfig for port "8080" on service "kubeflow/envoy", err: no BackendConfig for service port exists.
  Warning  Sync       3s (x7 over 14m)    loadbalancer-controller  Error during sync: Error running backend syncing routine: googleapi: Error 403: Quota 'BACKEND_SERVICES' exceeded. Limit: 9.0 globally., quotaExceeded
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ kubectl -n kubeflow get certificate envoy-ingress-tls  -o yaml
apiVersion: certmanager.k8s.io/v1alpha1
kind: Certificate
metadata:
  annotations:
    ksonnet.io/managed: '{"pristine":"H4sIAAAAAAAA/5yRMW/jMAyF9/sZb7Z9l5sOXm/qkqFDlyCDItGOYJkURDpFYPi/F0qaDgU6tJugh0d++LjC5fhCRaMwengqNjt2I5Vu+qddlN+XnUv57HZoMEUO6PGfisUhemeEBjOZC84c+hXJnShpfU0qzGR1gJc5CxMbekSX28hjIVVsDdjNhB7EF7k+/ltLinuk2fmaT8uJhiSvtaKZfF3gfK2u8MJDHNEfVgSZXWRFf0AJbS387YhDlsimnYoV4kClLaHzSZbQjSIjjg3OZvnPrk57sH1iwrYdtwZe5ll4f4f+xooGgbXWfsAWVRcqzzTcrL4fIC1qVJ5uET40JjIl9uWarc1Fwk0X+UK2/8rztv16AwAA//8BAAD///bFoUQCAgAA"}'
    kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
  creationTimestamp: "2019-05-15T08:10:13Z"
  generation: 1
  labels:
    app.kubernetes.io/deploy-manager: ksonnet
    ksonnet.io/component: iap-ingress
  name: envoy-ingress-tls
  namespace: kubeflow
  resourceVersion: "10215"
  selfLink: /apis/certmanager.k8s.io/v1alpha1/namespaces/kubeflow/certificates/envoy-ingress-tls
  uid: dda1eef0-76e8-11e9-8cd7-42010a840ff1
spec:
  acme:
    config:
    - domains:
      - &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
      http01:
        ingress: envoy-ingress
  commonName: &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
  dnsNames:
  - &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
  issuerRef:
    kind: ClusterIssuer
    name: letsencrypt-prod
  secretName: envoy-ingress-tls
status:
  acme:
    order:
      challenges:
      - authzURL: https://acme-v02.api.letsencrypt.org/acme/authz/SoB0onhqucJfYCclToCpvWEZUurq0z-FWwHqA7rs_IY
        domain: &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog
        http01:
          ingress: envoy-ingress
        key: ...
        token: ...
        type: http-01
        url: https://acme-v02.api.letsencrypt.org/acme/challenge/SoB0onhqucJfYCclToCpvWEZUurq0z-FWwHqA7rs_IY/15885107504
        wildcard: false
      url: https://acme-v02.api.letsencrypt.org/acme/order/57112821/451671679
  conditions:
  - lastTransitionTime: "2019-05-15T08:36:00Z"
    message: http-01 self check failed for domain "&lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog"
    reason: ValidateError
    status: "False"
    type: Ready
&lt;/denchmark-code&gt;

Envoy is still down:
&lt;denchmark-code&gt;$ kubectl -n kubeflow get pods -l service=envoy
NAME                     READY   STATUS             RESTARTS   AGE
envoy-69bf97959c-5f7cp   1/2     CrashLoopBackOff   10         28m
envoy-69bf97959c-bkqhx   1/2     CrashLoopBackOff   10         28m
envoy-69bf97959c-bm88v   1/2     CrashLoopBackOff   10         28m
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ kubectl logs envoy-69bf97959c-5f7cp envoy
[2019-05-15 08:38:23.119][1][info][main] external/envoy/source/server/server.cc:184] initializing epoch 0 (hot restart version=9.200.16384.127.options=capacity=16384, num_slots=8209 hash=228984379728933363)
[2019-05-15 08:38:23.119][1][critical][main] external/envoy/source/server/server.cc:71] error initializing configuration '/etc/envoy/envoy-config.json': unable to read file: /etc/envoy/envoy-config.json
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ kubectl -n kubeflow get ingress
NAME            HOSTS                                        ADDRESS   PORTS   AGE
envoy-ingress   &lt;kfapp&gt;2.endpoints.&lt;project&gt;.cloud.goog             80      30m
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt; BACKEND_NAME=$(gcloud compute --project=${PROJECT} backend-services list --filter=name~k8s-be-${NODE_PORT}- --format='value(name)')
&lt;/denchmark-code&gt;

BACKEND_NAME is empty hence there is no backend-service it seems. Though, this might be due to the dead envoy.
		</comment>
		<comment id='9' author='jsnowacki' date='2019-05-16T14:28:08Z'>
		It seems that it also doesn't work now form the Web UI (&lt;denchmark-link:https://deploy.kubeflow.cloud&gt;https://deploy.kubeflow.cloud&lt;/denchmark-link&gt;
) for me. I did the same setup as above and I have the exact error.  The web log just keeps waiting with:
&lt;denchmark-code&gt;2019-04-16 16:26:08.420: Waiting for the IAP setup to get ready...
&lt;/denchmark-code&gt;

And envoy is also dead.
		</comment>
		<comment id='10' author='jsnowacki' date='2019-05-23T13:26:03Z'>
		OK I've managed to find the core of the problem by looking into &lt;denchmark-link:https://www.kubeflow.org/docs/gke/troubleshooting-gke/#envoy-pods-crash-looping-root-cause-is-backend-quota-exceeded&gt;https://www.kubeflow.org/docs/gke/troubleshooting-gke/#envoy-pods-crash-looping-root-cause-is-backend-quota-exceeded&lt;/denchmark-link&gt;
. The ingress command, indeed, shows the issue with quota, though I've never considered it before as this GCP project was created mostly for this task so I didn't look into the quota at first.
When I checked the quota the limit was reached. The backend-services list is given below; the list was taken when no k8s or kf or, in fact, any other instances were running on the project.
&lt;denchmark-code&gt;$ gcloud compute backend-services list
NAME                            BACKENDS                                                PROTOCOL
k8s-be-30338--dd52cf248c76c70c  europe-west1-b/instanceGroups/k8s-ig--dd52cf248c76c70c  HTTP
k8s-be-30573--dd52cf248c76c70c  europe-west1-b/instanceGroups/k8s-ig--dd52cf248c76c70c  HTTP
k8s-be-31294--91068d808fb8b281  europe-west1-b/instanceGroups/k8s-ig--91068d808fb8b281  HTTP
k8s-be-31439--c4d6eda44bf0eff2  europe-west1-b/instanceGroups/k8s-ig--c4d6eda44bf0eff2  HTTP
k8s-be-31806--91068d808fb8b281  europe-west1-b/instanceGroups/k8s-ig--91068d808fb8b281  HTTP
k8s-be-32088--c4d6eda44bf0eff2  europe-west1-b/instanceGroups/k8s-ig--c4d6eda44bf0eff2  HTTP
k8s-be-32560--206514658bb6cd8a  europe-west1-b/instanceGroups/k8s-ig--206514658bb6cd8a  HTTP
k8s-be-32610--206514658bb6cd8a  europe-west1-b/instanceGroups/k8s-ig--206514658bb6cd8a  HTTP
&lt;/denchmark-code&gt;

Before I was recreating the deployment a few times using mostly (golang) CLI, hence, it seems that the delete command leaves things behind as I didn't get any errors regarding the backend-services.
After the next deployment with the quota fixed (i.e. quota increased and dangling backend removed) the envoy lives happily but the endpoint is not being created:
&lt;denchmark-code&gt;$ kubectl get cloudendpoints &lt;kfapp&gt; -o yaml
apiVersion: ctl.isla.solutions/v1
kind: CloudEndpoint
metadata:
  annotations:
    ksonnet.io/managed: '{"pristine":"H4sIAAAAAAAA/3TNPW7sMAzE8f4dY2rZi9eqDVLkAum5ErNgLJOCSG8QGL574Hx16Qb/4jc7qMszDxdTZJRos3ij2a1tIaZ+uf9HwiJakfHQbKuPWruJBhJWDqoUhLyj0ZWbn2txU+WYxS7F1m7KGsgQ6pPobbA7jgSllZEx6vTS7A1fwTuVsy7blT/zkeCdy8n2Ya9cTsktBmvlMY2KhKBx43j6pvP+Q7Pe7f338q+D4/j3AQAA//8BAAD//7x2nuMFAQAA"}'
    kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
  creationTimestamp: "2019-05-23T13:06:58Z"
  generation: 1
  labels:
    app.kubernetes.io/deploy-manager: ksonnet
    ksonnet.io/component: iap-ingress
  name: &lt;kfapp&gt;
  namespace: kubeflow
  resourceVersion: "1693"
  selfLink: /apis/ctl.isla.solutions/v1/namespaces/kubeflow/cloudendpoints/&lt;kfapp&gt;
  uid: a5e049b2-7d5b-11e9-94c2-42010a84010c
spec:
  project: &lt;project&gt;
  targetIngress:
    name: envoy-ingress
    namespace: kubeflow
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ kubectl describe cloudendpoints &lt;kfapp&gt;
Name:         &lt;kfapp&gt;
Namespace:    kubeflow
Labels:       app.kubernetes.io/deploy-manager=ksonnet
              ksonnet.io/component=iap-ingress
Annotations:  ksonnet.io/managed:
                {"pristine":"H4sIAAAAAAAA/3TNPW7sMAzE8f4dY2rZi9eqDVLkAum5ErNgLJOCSG8QGL574Hx16Qb/4jc7qMszDxdTZJRos3ij2a1tIaZ+uf9HwiJakfHQbKuPWruJBhJWDqoUh...
              kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
API Version:  ctl.isla.solutions/v1
Kind:         CloudEndpoint
Metadata:
  Creation Timestamp:  2019-05-23T13:06:58Z
  Generation:          1
  Resource Version:    1693
  Self Link:           /apis/ctl.isla.solutions/v1/namespaces/kubeflow/cloudendpoints/&lt;kfapp&gt;
  UID:                 a5e049b2-7d5b-11e9-94c2-42010a84010c
Spec:
  Project:  &lt;project&gt;
  Target Ingress:
    Name:       envoy-ingress
    Namespace:  kubeflow
Events:         &lt;none&gt;
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ gcloud --project=${PROJECT} endpoints operations list
ERROR: (gcloud.endpoints.operations.list) PERMISSION_DENIED: Service 'None' not found or permission denied.
&lt;/denchmark-code&gt;

The last one is most likely due to the fact that there is no endpoint created in the project.
I'll give it a go again with different name and check if it comes up, but the endpoint creation proces seems to flaky as sometimes its just not there despite no errors given during the deployment.
BTW also the delete command leaves kubeflow-created context for kubectl; I'm not sure is it a bug or a feature, but it makes a little bit of a mess.
		</comment>
		<comment id='11' author='jsnowacki' date='2019-05-29T13:49:50Z'>
		The finding so far, aside the issue quota which is not occuring at the moment, is that if one creates a deployment with one kfapp name, let say kubeflow, than first deployment works fine and endpoint gets created, but if we do:
&lt;denchmark-code&gt;kfctl delete all -V
# .... do something or nothing here, doesn't matter really...
kfctl apply all -V
&lt;/denchmark-code&gt;

Than the second deployment goes through fine, but the endpoint doesn't get created, hence, it's quite unusable, at least easily.
Further inspections shows that iap-enabler keeps crashing:
&lt;denchmark-code&gt;$ kubectl get pods
NAME                                                        READY   STATUS             RESTARTS   AGE
...
gcp-cred-webhook-6fbfc849c8-dnffj                           1/1     Running            0          55m
iap-enabler-99779c66d-m9wjk                                 0/1     CrashLoopBackOff   15         55m
ingress-bootstrap-52xg4                                     1/1     Running            0          55m
...
&lt;/denchmark-code&gt;

The endpoint-controller logs, despite working, look as follows:
&lt;denchmark-code&gt;$ kubectl logs --tail 10 cloud-endpoints-controller-5888c755cb-pv9pq
2019/05/29 12:08:13 [INFO][kubeflow] Service does not yet exist, creating: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog
2019/05/29 12:08:14 [ERROR] Could not sync state: [ERROR] Failed to creat Cloud Endpoints service: serviceName: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, err: googleapi: Error 400: Service &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog has been deleted and will be purged after 30 days. To reuse this service, please undelete the service following https://cloud.google.com/service-management/create-delete., failedPrecondition
2019/05/29 12:08:15 [DEBUG][kubeflow] Changed because parent sig different
2019/05/29 12:08:15 [DEBUG][kubeflow] Changed because ingress target IP changed
&lt;/denchmark-code&gt;

The list of endpoint services is empty, but I tried undeleting the service, with the below command, which returns an error:
&lt;denchmark-code&gt;$ gcloud endpoints services undelete &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog
Waiting for async operation operations/services.&lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog-3 to complete...
ERROR: (gcloud.endpoints.services.undelete) The operation with ID s&lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog-3 resulted in a failure.
&lt;/denchmark-code&gt;

After the above operation the endpoint-controller logs show:
&lt;denchmark-code&gt;$ kubectl logs --tail 10 cloud-endpoints-controller-5888c755cb-pv9pq -f
2019/05/29 13:34:21 [INFO][kubeflow] Endpoint service already exists, skipping create.
2019/05/29 13:34:21 [INFO][kubeflow] Current state: ENDPOINT_CREATE_PENDING
2019/05/29 13:34:23 [INFO][kubeflow] Create pending
2019/05/29 13:34:23 [INFO][kubeflow] Endpoint created: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, submitting endpoint config.
2019/05/29 13:34:24 [INFO][kubeflow] Current state: ENDPOINT_SUBMIT_PENDING
2019/05/29 13:34:25 [INFO][kubeflow] Service config submit complete for endpoint &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, config: 2019-05-29r1
2019/05/29 13:34:26 [INFO][kubeflow] Creating endpoint service config rollout for: endpoint: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, config: 2019-05-29r1
2019/05/29 13:34:27 [INFO][kubeflow] Current state: ENDPOINT_ROLLOUT_PENDING
2019/05/29 13:34:45 [INFO][kubeflow] Service config rollout complete for: endpoint: &lt;kfapp&gt;.endpoints.&lt;project&gt;.cloud.goog, config: 2019-05-29r1
2019/05/29 13:34:45 [INFO][kubeflow] Current state: IDLE
&lt;/denchmark-code&gt;

And after undeleting and waiting for a while the endpoint is again working.
Hence there should be either a deployment or endpoint-controller command to create or undelete the endpoint, as the creating recently deleted endpoint doesn't seem to work now.
		</comment>
		<comment id='12' author='jsnowacki' date='2019-06-20T03:43:35Z'>
		Thanks for debugging that.
		</comment>
		<comment id='13' author='jsnowacki' date='2019-09-09T23:17:15Z'>
		&lt;denchmark-link:https://github.com/jlewi&gt;@jlewi&lt;/denchmark-link&gt;
 is it still an issue in 0.6?
		</comment>
		<comment id='14' author='jsnowacki' date='2019-09-15T03:52:52Z'>
		The correct fix is for the cloud-endpoints controller to handle the case where the endpoint is being deleted and then undeletes it.
The cloud-endpoints controller we are using i s set here
&lt;denchmark-link:https://github.com/kubeflow/manifests/blob/ffede944f18343271f526bd217cde2edbe6e0e38/gcp/cloud-endpoints/base/deployment.yaml#L13&gt;https://github.com/kubeflow/manifests/blob/ffede944f18343271f526bd217cde2edbe6e0e38/gcp/cloud-endpoints/base/deployment.yaml#L13&lt;/denchmark-link&gt;

gcr.io/cloud-solutions-group/cloud-endpoints-controller:0.2.1
Source is here:
&lt;denchmark-link:https://github.com/danisla/cloud-endpoints-controller&gt;https://github.com/danisla/cloud-endpoints-controller&lt;/denchmark-link&gt;

I don't see any logic in the controller to deal with this use case
&lt;denchmark-link:https://github.com/danisla/cloud-endpoints-controller/blob/master/cmd/cloud-endpoints-controller/main.go&gt;https://github.com/danisla/cloud-endpoints-controller/blob/master/cmd/cloud-endpoints-controller/main.go&lt;/denchmark-link&gt;

So it looks like we still need to fix the controller to work with this.
A longer term solution might be for Kubernetes Cloud Connector
&lt;denchmark-link:https://github.com/GoogleCloudPlatform/k8s-config-connector&gt;https://github.com/GoogleCloudPlatform/k8s-config-connector&lt;/denchmark-link&gt;

To support Cloud Endpoints
		</comment>
		<comment id='15' author='jsnowacki' date='2019-09-15T04:00:17Z'>
		&lt;denchmark-link:https://github.com/danisla&gt;@danisla&lt;/denchmark-link&gt;
 any interest in updating your controller to handle the case where the service is being deleted and then undelete it?
		</comment>
		<comment id='16' author='jsnowacki' date='2019-12-31T20:59:21Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>