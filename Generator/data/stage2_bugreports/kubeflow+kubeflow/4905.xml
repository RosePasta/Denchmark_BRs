<bug id='4905' author='plaffitte' open_date='2020-04-01T13:56:41Z' closed_time='2020-04-06T12:28:58Z'>
	<summary>model training fails because EKS cluster can't connect to s3 endpoint sometimes</summary>
	<description>
/kind bug
What steps did you take and what happened:
I am trying to run several ML model training in a python script using tensorflow 2. To do this I dockerize my script and setup a tfjob on Kubeflow. For some models the training goes to completion but for others the training fails and I get the following error when tensorflow tries to save the checkpoint:
cannot connect to endpoint
What did you expect to happen:
I expect the s3 connection errors to be handled by tensorflow so that it doesn't error out when it can't connect to the endpoint during checkpoint saving.
Anything else you would like to add:
[Miscellaneous information that will assist in solving the issue.]
Environment:

Kubeflow version: 1.0.0
kfctl version: 0.7.0
Kubernetes platform: EKS
Kubernetes version: 1.14.0
OS (e.g. from /etc/os-release):

	</description>
	<comments>
		<comment id='1' author='plaffitte' date='2020-04-01T13:56:51Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




kind/bug
0.99



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='plaffitte' date='2020-04-01T21:54:41Z'>
		/assign
		</comment>
		<comment id='3' author='plaffitte' date='2020-04-01T21:56:23Z'>
		&lt;denchmark-link:https://github.com/plaffitte&gt;@plaffitte&lt;/denchmark-link&gt;

All your checkpoint persistence call failed? Have you ever successfully talk to S3 in your environment? Could you share trainer pod env setting for S3?
		</comment>
		<comment id='4' author='plaffitte' date='2020-04-02T12:07:51Z'>
		Thanks for your answer &lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;
 , I don't know if they all fail, but when I set the env variable  to  I get a bunch of those  from  during the training process:
2020-04-02 12:48:32.828933: E tensorflow/core/platform/s3/aws_logging.cc:60] HTTP response code: 404 Exception name: Error message: No response body. 6 response headers: content-type : application/xml date : Thu, 02 Apr 2020 12:48:32 GMT server : AmazonS3
However this does not seem to hinder training since it continues, and I'm not even sure that those errors are a big problem. So it seems like it is able to communicate to S3 (In fact at the very beginning of the script I download a dataset from S3 and that works like a charm).
But I guess at some point it becomes critical, such as when the evaluation is looking for a new checkpoint and it hasn't been saved because it could not find the endpoint. The error I get in that case is just a
Unable to connect to endpoint [[node save/SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:334) ]]
Here are my pod settings:
`apiVersion: kubeflow.org/v1
kind: TFJob
metadata:
name: $(trainingName)
namespace: kubeflow
spec:
tfReplicaSpecs:
Chief:
replicas: 1
template:
metadata:
annotations:
sidecar.istio.io/inject: "false"
spec:
serviceAccount: default-editor
containers:
- name: tensorflow
image: training-image
command:
- /usr/bin/python
- /opt/model.py
- --tf-data-dir=$(dataDir)
- --tf-model-dir=$(modelDir)
- --tf-train-steps=$(trainSteps)
- --tf-batch-size=$(batchSize)
- --tf-learning-rate=$(learningRate)
- --tf-training-mode=$(mode)
env:
- name: modelDir
value: $(modelDir)
- name: dataDir
value: $(dataDir)
- name: trainSteps
value: $(trainSteps)
- name: batchSize
value: $(batchSize)
- name: learningRate
value: $(learningRate)
- name: mode
value: $(mode)
volumeMounts:
- name: training-data
mountPath: "/data"
workingDir: /opt
restartPolicy: OnFailure
volumes:
- name: training-data
emptyDir: {}
		</comment>
		<comment id='5' author='plaffitte' date='2020-04-02T17:40:59Z'>
		I don't see you have AWS environment variables in the container for TF to talk to s3
		</comment>
		<comment id='6' author='plaffitte' date='2020-04-02T17:50:53Z'>
		&lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;
 Yeah I'm sorry all the AWS env variables are in a different config file with a config map definition. Here's a snippet:
`configMapGenerator:

literals:

trainSteps=50
batchSize=16
learningRate=0.01
name=test-with-mnist-config
awsAccessKeyIDName=awsAccessKeyID
awsSecretAccessKeyName=awsSecretAccessKey
S3_ENDPOINT=s3.us-east-1.amazonaws.com
AWS_ENDPOINT_URL=http://s3.us-east-1.amazonaws.com
AWS_REGION=us-east-1
BUCKET_NAME=some-bucket
S3_USE_HTTPS=1
S3_VERIFY_SSL=1
dataDir=s3://some-bucket/some-folder
modelDir=/opt/model/
mode=train
name: mnist-map-training`



		</comment>
		<comment id='7' author='plaffitte' date='2020-04-02T18:06:08Z'>
		Can you try to change http://s3.us-east-1.amazonaws.com to s3.us-east-1.amazonaws.com?
		</comment>
		<comment id='8' author='plaffitte' date='2020-04-03T08:58:58Z'>
		Thanks for the suggestion, I'm trying that right now. In the meantime I just wanted to share with you the print of the error I'm getting:
`I0330 16:10:45.925055 140196133001024 basic_session_run_hooks.py:613] Saving checkpoints for 2765 into s3://some-bucket/model/model.ckpt.
Error during training on feature
: Unable to connect to endpoint
[[node save/SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:334) ]]
Errors may have originated from an input operation.
Input Source operations connected to node save/SaveV2_1:
Const (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:333) ()`
		</comment>
		<comment id='9' author='plaffitte' date='2020-04-03T14:21:00Z'>
		I made the change you suggested but I still have issues. Now it seems like I get a different error every time... Those are 4 errors I've got from running my script so far:
Read less bytes than requested [[node save/RestoreV2 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:334) ]] ()
XAmzContentSHA256Mismatch: Unable to parse ExceptionName: XAmzContentSHA256Mismatch Message: The provided 'x-amz-content-sha256' header does not match what was computed. [[node SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:403) ]] ()
There was no new checkpoint after the training. Eval status: no new checkpoint ('There was no new checkpoint after the training. Eval status: no new checkpoint',)
XAmzContentSHA256Mismatch: Unable to parse ExceptionName: XAmzContentSHA256Mismatch Message: The provided 'x-amz-content-sha256' header does not match what was computed. [[node SaveV2_1 (defined at usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/keras.py:403) ]] ()
		</comment>
		<comment id='10' author='plaffitte' date='2020-04-03T17:20:49Z'>
		&lt;denchmark-link:https://github.com/plaffitte&gt;@plaffitte&lt;/denchmark-link&gt;
 Have you tested in a container, we are trying to solve kubeflow problems here. If there's something wrong on the SDK side. I would suggest you to submit issue to aws/sdk. For example, &lt;denchmark-link:https://github.com/aws/aws-sdk-go/issues/148&gt;aws/aws-sdk-go#148&lt;/denchmark-link&gt;
 it has similar issue but in golang
		</comment>
		<comment id='11' author='plaffitte' date='2020-04-06T08:47:21Z'>
		&lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;
 Thanks for the tip, I'll put my issue there. And thanks for your help
		</comment>
	</comments>
</bug>