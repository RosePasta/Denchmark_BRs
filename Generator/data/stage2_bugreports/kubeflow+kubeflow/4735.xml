<bug id='4735' author='chrisstockton' open_date='2020-02-05T08:25:24Z' closed_time='2020-06-11T23:48:12Z'>
	<summary>Tensorboard Viewer pod not mounting service account credentials properly</summary>
	<description>
/kind bug

I ran the mnist pipeline from the &lt;denchmark-link:https://github.com/kubeflow/examples/blob/master/pipelines/mnist-pipelines/mnist_pipeline.py&gt;examples&lt;/denchmark-link&gt;
, but updated &lt;denchmark-link:https://github.com/kubeflow/examples/blob/master/mnist/model.py&gt;model.py&lt;/denchmark-link&gt;
 file to include a tensorboard output field:
&lt;denchmark-code&gt;  if is_chief:
    print("Export saved model")
    classifier.export_savedmodel(args.tf_export_dir, serving_input_receiver_fn=serving_fn)
    print("Done exporting the model")
    # output tensorboard
    metadata = {
        'outputs' : [{
        'type': 'tensorboard',
            'source': args.tf_export_dir
        }]
    }
    with open('/mlpipeline-ui-metadata.json', 'w') as f:
        json.dump(metadata, f)
&lt;/denchmark-code&gt;

I then started a tensorboard for the output, but when I clicked the "Open Tensorboard" button
&lt;denchmark-link:https://user-images.githubusercontent.com/8291994/73822806-4455d400-483a-11ea-859a-1c43cb6cf908.png&gt;&lt;/denchmark-link&gt;

A new tab opened with the following error message:
&lt;denchmark-code&gt;Error occured while trying to proxy to: kubeflow.endpoints.&lt;project_id&gt;.cloud.googviewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-service.kubeflow.svc.cluster.local:80/tensorboard/viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83/
&lt;/denchmark-code&gt;

I checked the logs of the newly created viewer pod viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-deploymentm6hgk and saw the following error in the logs:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/usr/lib/python2.7/threading.py", line 801, in __bootstrap_inner
    self.run()
  File "/usr/lib/python2.7/threading.py", line 754, in run
    self.__target(*self.__args, **self.__kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorboard/backend/application.py", line 586, in _reload
    multiplexer.AddRunsFromDirectory(path, name)
  File "/usr/local/lib/python2.7/dist-packages/tensorboard/backend/event_processing/plugin_event_multiplexer.py", line 189, in AddRunsFromDirectory
    for subdir in io_wrapper.GetLogdirSubdirectories(path):
  File "/usr/local/lib/python2.7/dist-packages/tensorboard/backend/event_processing/io_wrapper.py", line 178, in GetLogdirSubdirectories
    if not tf.io.gfile.exists(path):
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/lib/io/file_io.py", line 280, in file_exists_v2
    pywrap_tensorflow.FileExists(compat.as_bytes(path))
PermissionDeniedError: Error executing an HTTP request: HTTP response code 403 with body '{
  "error": {
    "code": 403,
    "message": "Primary: /namespaces/&lt;project_id&gt;.svc.id.goog with additional claims does not have storage.objects.get access to &lt;project_id&gt;-kubeflow-bucket/export.",
    "errors": [
      {
        "message": "Primary: /namespaces/&lt;project_id&gt;.svc.id.goog with additional claims does not have storage.objects.get access to &lt;project_id&gt;-kubeflow-bucket/export.",
        "domain": "global",
        "reason": "forbidden"
  '
	 when reading metadata of gs://&lt;bucket&gt;/export
&lt;/denchmark-code&gt;

The service account (kubeflow-user@&lt;project_id&gt;.iam.gserviceaccount.com) is a Storage Admin and should be able to read from GCS, however the deployment shows that the secret is mounted incorrectly and GOOGLE_APPLICATION_CREDENTIALS is pointing to a directory.
&lt;denchmark-code&gt;$ kubectl describe deployment viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-deployment
Name:                   viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-deployment
Namespace:              kubeflow
CreationTimestamp:      Wed, 05 Feb 2020 15:51:17 +0900
Labels:                 &lt;none&gt;
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=viewer,deployment=viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-deployment,viewer=viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83
Replicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=viewer
           deployment=viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-deployment
           viewer=viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83
  Containers:
   viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83-pod:
    Image:      tensorflow/tensorflow
    Port:       6006/TCP
    Host Port:  0/TCP
    Args:
      tensorboard
      --logdir=gs://mercari-data-infra-test-kubeflow-bucket/export
      --path_prefix=/tensorboard/viewer-c6c1759a2bebee7a8538948f4f3838ef77637a83/
    Environment:
      GOOGLE_APPLICATION_CREDENTIALS:  /secret/gcp-credentials/user-gcp-sa.json
    Mounts:
      /secret/gcp-credentials/user-gcp-sa.json from gcp-credentials (ro)
  Volumes:
   gcp-credentials:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  &lt;unset&gt;
&lt;/denchmark-code&gt;

The Mount should be /secret/gcp-credentials instead of /secret/gcp-credentials/user-gcp-sa.json.
What did you expect to happen:
The tensorboard viewer-deployment yaml should mount the secret as /secret/gcp-credentials and open without error.
Anything else you would like to add:
[Miscellaneous information that will assist in solving the issue.]
Environment:

Kubeflow version: 0.7.0
kfctl version: kfctl v1.0-rc.1-0-g963c787
Kubernetes platform: GCP
Kubernetes version: Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.7", GitCommit:"8fca2ec50a6133511b771a11559e24191b1aa2b4", GitTreeState:"clean", BuildDate:"2019-09-18T14:47:22Z", GoVersion:"go1.12.9", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"14+", GitVersion:"v1.14.10-gke.0", GitCommit:"a988db14950de3628f9e21773f3de0bf52485534", GitTreeState:"clean", BuildDate:"2019-12-11T22:37:55Z", GoVersion:"go1.12.12b4", Compiler:"gc", Platform:"linux/amd64"}
OS (e.g. from /etc/os-release):

	</description>
	<comments>
		<comment id='1' author='chrisstockton' date='2020-02-05T08:25:48Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




kind/bug
1.00



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='chrisstockton' date='2020-02-05T13:41:25Z'>
		cc &lt;denchmark-link:https://github.com/jessiezcc&gt;@jessiezcc&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='chrisstockton' date='2020-02-06T02:02:11Z'>
		exactly same problem here!
		</comment>
		<comment id='4' author='chrisstockton' date='2020-02-06T02:22:34Z'>
		just so you know, I'll attach a part of my viewer-deployments's yaml file.
&lt;denchmark-code&gt;      containers:
      - args:
        - tensorboard
        - --logdir=gs://MY-BUCKET/output/logs
        - --path_prefix=/tensorboard/viewer-3e75f8012f366e91ec84b49e6ed193e10a3690f5/
        env:
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: /secret/gcp-credentials/user-gcp-sa.json
        image: tensorflow/tensorflow
        imagePullPolicy: Always
        name: viewer-3e75f8012f366e91ec84b49e6ed193e10a3690f5-pod
        ports:
        - containerPort: 6006
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /secret/gcp-credentials/user-gcp-sa.json
          name: gcp-credentials
          readOnly: true
&lt;/denchmark-code&gt;

whereas my compiled pipeline yaml file is using different path
&lt;denchmark-code&gt;      "volumeMounts":
      - "mountPath": |-
          /secret/gcp-credentials
        "name": |-
          gcp-credentials-user-gcp-sa
&lt;/denchmark-code&gt;

I'm using latest kubeflow. I re-installed whole cluster yesterday.
		</comment>
		<comment id='5' author='chrisstockton' date='2020-02-07T07:56:28Z'>
		I think the issue below is caused by the same reason.
&lt;denchmark-link:https://github.com/kubeflow/pipelines/issues/2883&gt;kubeflow/pipelines#2883&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='chrisstockton' date='2020-02-07T08:52:05Z'>
		
I think the issue below is caused by the same reason.
kubeflow/pipelines#2883

That does look like the same error.  I believe the bucket is inaccessible in both cases because of the error in mounting the secret as a volume causing the GOOGLE_APPLICATION_CREDENTIALS to point to a directory instead of an application credentials file.
I looked through some of the code and found where (I think) the viewer pod was being launched, but I couldn't determine where the volume mount was created.
		</comment>
		<comment id='7' author='chrisstockton' date='2020-02-14T07:32:03Z'>
		On kubeflow v1.0.0 that I created today, still getting same error
&lt;denchmark-code&gt;"message": "Primary: /namespaces/PROJECT_ID.svc.id.goog with additional claims does not have storage.objects.get access to BUCKET_NAME/PATH_TO_LOG.",
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='chrisstockton' date='2020-02-28T09:56:56Z'>
		I am also encountering this issue. Has anyone figured out a workaround?
		</comment>
		<comment id='9' author='chrisstockton' date='2020-03-06T17:21:35Z'>
		Same problem here
		</comment>
		<comment id='10' author='chrisstockton' date='2020-06-04T23:28:16Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>