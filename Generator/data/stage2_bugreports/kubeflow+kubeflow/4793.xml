<bug id='4793' author='marcindulak' open_date='2020-02-22T10:11:31Z' closed_time='2020-10-22T04:26:21Z'>
	<summary>istio-policy CrashLoopBackOff: Start-Setup of the dashboard fails</summary>
	<description>
/kind bug
What steps did you take and what happened:
On a fresh install using &lt;denchmark-link:https://github.com/kubeflow/manifests/commit/2a9816f9b482be927f7d8a772cc66095cb571aa8&gt;kubeflow/manifests@2a9816f&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;wget https://raw.githubusercontent.com/kubeflow/manifests/2a9816f9b482be927f7d8a772cc66095cb571aa8/kfdef/kfctl_k8s_istio.v1.0.0.yaml
sed -i 's/v1.0.0.tar.gz/2a9816f9b482be927f7d8a772cc66095cb571aa8.tar.gz/' kfctl_k8s_istio.v1.0.0.yaml
kfctl apply -V -f kfctl_k8s_istio.v1.0.0.yaml
&lt;/denchmark-code&gt;

4 istio-policy pods are in CrashLoopBackOff
&lt;denchmark-code&gt; kubectl -n istio-system get pod -lapp=policy
NAME                            READY   STATUS             RESTARTS   AGE
istio-policy-6f74d9d95d-2m2js   1/2     CrashLoopBackOff   15         34m
istio-policy-6f74d9d95d-9x97j   2/2     Running            5          7h36m
istio-policy-6f74d9d95d-qm5qt   1/2     CrashLoopBackOff   29         73m
istio-policy-6f74d9d95d-whcc7   1/2     CrashLoopBackOff   29         73m
istio-policy-6f74d9d95d-xzrh2   1/2     CrashLoopBackOff   61         159m
&lt;/denchmark-code&gt;

The log of the running pod say
&lt;denchmark-code&gt;kubectl -n istio-system logs istio-policy-6f74d9d95d-9x97j mixer  | tail -3
2020-02-22T09:58:03.138389Z	error	mcp	Failed to create a new MCP sink stream: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 10.102.214.102:9901: connect: connection timed out"
2020-02-22T09:58:03.986348Z	info	pickfirstBalancer: HandleSubConnStateChange: 0xc4200ec320, CONNECTING
2020-02-22T09:58:04.138645Z	info	mcp	(re)trying to establish new MCP sink stream
&lt;/denchmark-code&gt;

and
&lt;denchmark-code&gt;kubectl -n istio-system logs istio-policy-6f74d9d95d-9x97j istio-proxy
...
2020-02-22T01:53:06.357526Z	warn	watching /etc/certs/cert-chain.pem encounters an error no such file or directory
2020-02-22T01:53:06.357645Z	info	Envoy command: [-c /etc/istio/proxy/envoy.yaml --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster istio-policy --service-node sidecar~192.168.49.79~istio-policy-6f74d9d95d-9x97j.istio-system~istio-system.svc.cluster.local --max-obj-name-len 189 --allow-unknown-fields -l warning]
[2020-02-22 01:53:06.404][19][warning][misc] [external/envoy/source/common/protobuf/utility.cc:174] Using deprecated option 'envoy.api.v2.Cluster.hosts' from file cds.proto. This configuration will be removed from Envoy soon. Please see https://www.envoyproxy.io/docs/envoy/latest/intro/deprecated for details.
[2020-02-22 01:53:06.405][19][warning][misc] [external/envoy/source/common/protobuf/utility.cc:174] Using deprecated option 'envoy.api.v2.Cluster.hosts' from file cds.proto. This configuration will be removed from Envoy soon. Please see https://www.envoyproxy.io/docs/envoy/latest/intro/deprecated for details.
[2020-02-22 01:53:06.405][19][warning][misc] [external/envoy/source/common/protobuf/utility.cc:174] Using deprecated option 'envoy.api.v2.Cluster.hosts' from file cds.proto. This configuration will be removed from Envoy soon. Please see https://www.envoyproxy.io/docs/envoy/latest/intro/deprecated for details.
[2020-02-22 02:48:31.281][29][warning][filter] [src/istio/mixerclient/report_batch.cc:106] Mixer Report failed with: UNAVAILABLE:Server is currently overloaded. Please try again.
&lt;/denchmark-code&gt;

The crashed pods logs say
&lt;denchmark-code&gt;kubectl -n istio-system logs istio-policy-6f74d9d95d-2m2js mixer 
gc 1 @0.246s 0%: 0.007+95+0.27 ms clock, 0.046+0.092/1.3/2.1+1.6 ms cpu, 4-&gt;4-&gt;2 MB, 5 MB goal, 6 P
gc 2 @0.447s 5%: 0.029+195+0.20 ms clock, 0.17+0.17/197/382+1.2 ms cpu, 4-&gt;4-&gt;3 MB, 5 MB goal, 6 P
Mixer started with
MaxMessageSize:  1048576
MaxConcurrentStreams:  1024
APIWorkerPoolSize:  1024
AdapterWorkerPoolSize:  1024
APIPort:  9091
APIAddress:  unix:///sock/mixer.socket
MonitoringPort:  15014
EnableProfiling:  true
SingleThreaded:  false
NumCheckCacheEntries:  1500000
ConfigStoreURL:  mcp://istio-galley.istio-system.svc:9901
CertificateFile:  /etc/certs/cert-chain.pem
KeyFile:  /etc/certs/key.pem
CACertificateFile:  /etc/certs/root-cert.pem
ConfigDefaultNamespace:  istio-system
LoggingOptions: log.Options{OutputPaths:[]string{"stdout"}, ErrorOutputPaths:[]string{"stderr"}, RotateOutputPath:"", RotationMaxSize:104857600, RotationMaxAge:30, RotationMaxBackups:1000, JSONEncoding:false, LogGrpc:true, outputLevels:"default:info", logCallers:"", stackTraceLevels:"default:none", testonlyExit:(func())(nil)}
TracingOptions: tracing.Options{ZipkinURL:"http://zipkin:9411/api/v1/spans", JaegerURL:"", LogTraceSpans:false, SamplingRate:0}
IntrospectionOptions: ctrlz.Options{Port:0x2694, Address:"127.0.0.1"}
LoadSheddingOptions: loadshedding.Options{Mode:0, AverageLatencyThreshold:0, SamplesPerSecond:1.7976931348623157e+308, SampleHalfLife:1000000000, MaxRequestsPerSecond:0, BurstSize:0}

2020-02-22T09:58:14.071037Z	info	mcp	Requesting following collections:
2020-02-22T09:58:14.071068Z	info	mcp	  [0] istio/config/v1alpha2/legacy/apikeys
2020-02-22T09:58:14.071073Z	info	mcp	  [1] istio/policy/v1beta1/instances
2020-02-22T09:58:14.071075Z	info	mcp	  [2] istio/config/v1alpha2/legacy/kuberneteses
2020-02-22T09:58:14.071078Z	info	mcp	  [3] istio/config/v1alpha2/legacy/logentries
2020-02-22T09:58:14.071081Z	info	mcp	  [4] istio/config/v1alpha2/legacy/authorizations
2020-02-22T09:58:14.071084Z	info	mcp	  [5] istio/config/v1alpha2/legacy/metrics
2020-02-22T09:58:14.071087Z	info	mcp	  [6] istio/config/v1alpha2/legacy/prometheuses
2020-02-22T09:58:14.071090Z	info	mcp	  [7] istio/config/v1alpha2/templates
2020-02-22T09:58:14.071093Z	info	mcp	  [8] istio/config/v1alpha2/adapters
2020-02-22T09:58:14.071096Z	info	mcp	  [9] istio/config/v1alpha2/legacy/bypasses
2020-02-22T09:58:14.071099Z	info	mcp	  [10] istio/config/v1alpha2/legacy/dogstatsds
2020-02-22T09:58:14.071102Z	info	mcp	  [11] istio/config/v1alpha2/legacy/quotas
2020-02-22T09:58:14.071104Z	info	mcp	  [12] istio/config/v1alpha2/legacy/signalfxs
2020-02-22T09:58:14.071107Z	info	mcp	  [13] istio/config/v1alpha2/legacy/deniers
2020-02-22T09:58:14.071110Z	info	mcp	  [14] istio/policy/v1beta1/handlers
2020-02-22T09:58:14.071113Z	info	mcp	  [15] istio/config/v1alpha2/legacy/rbacs
2020-02-22T09:58:14.071118Z	info	mcp	  [16] istio/config/v1alpha2/legacy/stdios
2020-02-22T09:58:14.071122Z	info	mcp	  [17] istio/config/v1alpha2/legacy/tracespans
2020-02-22T09:58:14.071126Z	info	mcp	  [18] istio/policy/v1beta1/attributemanifests
2020-02-22T09:58:14.071131Z	info	mcp	  [19] istio/config/v1alpha2/legacy/statsds
2020-02-22T09:58:14.071135Z	info	mcp	  [20] istio/config/v1alpha2/legacy/zipkins
2020-02-22T09:58:14.071138Z	info	mcp	  [21] istio/config/v1alpha2/legacy/checknothings
2020-02-22T09:58:14.071141Z	info	mcp	  [22] istio/config/v1alpha2/legacy/edges
2020-02-22T09:58:14.071144Z	info	mcp	  [23] istio/config/v1alpha2/legacy/listcheckers
2020-02-22T09:58:14.071151Z	info	mcp	  [24] istio/config/v1alpha2/legacy/memquotas
2020-02-22T09:58:14.071154Z	info	mcp	  [25] istio/config/v1alpha2/legacy/opas
2020-02-22T09:58:14.071157Z	info	mcp	  [26] istio/config/v1alpha2/legacy/redisquotas
2020-02-22T09:58:14.071160Z	info	mcp	  [27] istio/config/v1alpha2/legacy/solarwindses
2020-02-22T09:58:14.071163Z	info	mcp	  [28] istio/config/v1alpha2/legacy/stackdrivers
2020-02-22T09:58:14.071166Z	info	mcp	  [29] istio/config/v1alpha2/legacy/circonuses
2020-02-22T09:58:14.071169Z	info	mcp	  [30] istio/config/v1alpha2/legacy/fluentds
2020-02-22T09:58:14.071172Z	info	mcp	  [31] istio/config/v1alpha2/legacy/kubernetesenvs
2020-02-22T09:58:14.071175Z	info	mcp	  [32] istio/config/v1alpha2/legacy/noops
2020-02-22T09:58:14.071178Z	info	mcp	  [33] istio/config/v1alpha2/legacy/reportnothings
2020-02-22T09:58:14.071181Z	info	mcp	  [34] istio/policy/v1beta1/rules
2020-02-22T09:58:14.071184Z	info	mcp	  [35] istio/config/v1alpha2/legacy/cloudwatches
2020-02-22T09:58:14.071187Z	info	mcp	  [36] istio/config/v1alpha2/legacy/listentries
2020-02-22T09:58:14.071199Z	info	parsed scheme: ""
2020-02-22T09:58:14.071209Z	info	scheme "" not registered, fallback to default scheme
2020-02-22T09:58:14.071313Z	info	Using new MCP client sink stack
2020-02-22T09:58:14.071348Z	info	Awaiting for config store sync...
2020-02-22T09:58:14.071522Z	info	ccResolverWrapper: sending new addresses to cc: [{istio-galley.istio-system.svc:9901 0  &lt;nil&gt;}]
2020-02-22T09:58:14.071536Z	info	ClientConn switching balancer to "pick_first"
2020-02-22T09:58:14.071773Z	info	pickfirstBalancer: HandleSubConnStateChange: 0xc420a6e810, CONNECTING
2020-02-22T09:58:14.163853Z	info	mcp	(re)trying to establish new MCP sink stream
&lt;/denchmark-code&gt;

The istio-galley pod is missing
&lt;denchmark-code&gt;kubectl -n istio-system get deployment 
NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
cluster-local-gateway    5/5     5            5           8h
grafana                  1/1     1            1           8h
istio-citadel            1/1     1            1           8h
istio-egressgateway      5/5     5            5           8h
istio-galley             0/1     0            0           8h
istio-ingressgateway     5/5     5            5           8h
istio-pilot              5/5     5            5           8h
istio-policy             1/5     5            1           8h
istio-sidecar-injector   1/1     1            1           8h
istio-telemetry          1/1     1            1           8h
istio-tracing            1/1     1            1           8h
kiali                    1/1     1            1           8h
prometheus               1/1     1            1           8h
&lt;/denchmark-code&gt;

The notebook-controller-deployment pod reports errors due to istio-policy
&lt;denchmark-code&gt;kubectl -n kubeflow logs notebook-controller-deployment-5c55f5845b-h5npd
...
2020-02-22T09:54:57.861Z	DEBUG	controller-runtime.controller	Successfully Reconciled	{"controller": "notebook", "request": "istio-system/istio-policy-6f74d9d95d-2m2js.15f5ad7e79315178"}
2020-02-22T10:05:02.804Z	ERROR	controllers.Notebook	unable to fetch Notebook	{"notebook": "istio-system/", "error": "Notebook.kubeflow.org \"\" not found"}
github.com/go-logr/zapr.(*zapLogger).Error
	/go/pkg/mod/github.com/go-logr/zapr@v0.1.0/zapr.go:128
github.com/kubeflow/kubeflow/components/notebook-controller/controllers.(*NotebookReconciler).Reconcile
	/workspace/notebook-controller/controllers/notebook_controller.go:111
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.2.0/pkg/internal/controller/controller.go:216
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.2.0/pkg/internal/controller/controller.go:192
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker
	/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.2.0/pkg/internal/controller/controller.go:171
k8s.io/apimachinery/pkg/util/wait.JitterUntil.func1
	/go/pkg/mod/k8s.io/apimachinery@v0.0.0-20190404173353-6a84e37a896d/pkg/util/wait/wait.go:152
k8s.io/apimachinery/pkg/util/wait.JitterUntil
	/go/pkg/mod/k8s.io/apimachinery@v0.0.0-20190404173353-6a84e37a896d/pkg/util/wait/wait.go:153
k8s.io/apimachinery/pkg/util/wait.Until
	/go/pkg/mod/k8s.io/apimachinery@v0.0.0-20190404173353-6a84e37a896d/pkg/util/wait/wait.go:88
2020-02-22T10:05:02.804Z	DEBUG	controller-runtime.controller	Successfully Reconciled	{"controller": "notebook", "request": "istio-system/"}
&lt;/denchmark-code&gt;

What did you expect to happen:
Start-Setup of the dashboard.
Anything else you would like to add:
I was waiting for &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4731&gt;#4731&lt;/denchmark-link&gt;
 and see discussions of various istio versions there, but I see
&lt;denchmark-code&gt;kubectl -n istio-system get deployment -lrelease=istio -oyaml | grep image:
          image: grafana/grafana:6.0.2
          image: docker.io/istio/citadel:1.1.6
          image: docker.io/istio/proxyv2:1.1.6
          image: docker.io/istio/galley:1.1.6
          image: docker.io/istio/proxyv2:1.1.6
          image: docker.io/istio/pilot:1.1.6
          image: docker.io/istio/proxyv2:1.1.6
          image: docker.io/istio/mixer:1.1.6
          image: docker.io/istio/proxyv2:1.1.6
          image: docker.io/istio/sidecar_injector:1.1.6
          image: docker.io/istio/mixer:1.1.6
          image: docker.io/istio/proxyv2:1.1.6
          image: docker.io/jaegertracing/all-in-one:1.9
          image: docker.io/kiali/kiali:v0.16
          image: docker.io/prom/prometheus:v2.3.1
&lt;/denchmark-code&gt;

Environment:

Kubeflow version: Start-Setup of the dashboard fails, intermittent errors: sometimes it hangs at clicking "Finish" and creates the anonymous profile, then after kubectl delete profile anonymous sometimes it does not create the profile when repeating Start-Setup.
kfctl version:

&lt;denchmark-code&gt;kfctl version
kfctl v1.0-rc.3-1-g24b60e8
&lt;/denchmark-code&gt;


Kubernetes platform: kind https://hub.docker.com/layers/kindest/node/v1.15.7/images/sha256-e2df133f80ef633c53c0200114fce2ed5e1f6947477dbc83261a6a921169488d?context=explore
Kubernetes version:

&lt;denchmark-code&gt;kubectl version
Client Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.7", GitCommit:"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4", GitTreeState:"clean", BuildDate:"2019-12-11T12:42:56Z", GoVersion:"go1.12.12", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"15", GitVersion:"v1.15.7", GitCommit:"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4", GitTreeState:"clean", BuildDate:"2020-01-14T00:28:37Z", GoVersion:"go1.12.12", Compiler:"gc", Platform:"linux/amd64"}
&lt;/denchmark-code&gt;


OS:

&lt;denchmark-code&gt;cat /etc/*release | grep PRETTY
PRETTY_NAME="Ubuntu 19.10"
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='marcindulak' date='2020-02-22T10:12:11Z'>
		Issue-Label Bot is automatically applying the labels:



Label
Probability




kind/bug
1.00



Please mark this comment with  or  to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/marketplace/issue-label-botdata/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='marcindulak' date='2020-02-22T11:11:40Z'>
		After kubectl -n istio-system delete rs -lapp=galley istio-galley starts, but istio-policy are still in CrashLoopBackOff for 5 minutes, then kubectl -n istio-system delete pod -lapp=policy makes istio-policy Running, and Start-Setup of the dashboard succeeds.
		</comment>
		<comment id='3' author='marcindulak' date='2020-02-26T13:43:47Z'>
		/cc &lt;denchmark-link:https://github.com/krishnadurai&gt;@krishnadurai&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yanniszark&gt;@yanniszark&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/johnugeorge&gt;@johnugeorge&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='marcindulak' date='2020-02-26T14:45:15Z'>
		I'm seeing this as well.
		</comment>
		<comment id='5' author='marcindulak' date='2020-02-27T10:45:21Z'>
		Hello &lt;denchmark-link:https://github.com/marcindulak&gt;@marcindulak&lt;/denchmark-link&gt;
,
I deployed a cluster using the same configuration as stated above on KinD and was not able to reproduce this issue.
I found a similar issue in Istio's github repo, can you check if setting this filter in your node helps?
&lt;denchmark-link:https://github.com/istio/istio/issues/14261#issuecomment-495121279&gt;istio/istio#14261 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='marcindulak' date='2020-02-27T20:58:32Z'>
		
Hello @marcindulak,
I deployed a cluster using the same configuration as stated above on KinD and was not able to reproduce this issue.
I found a similar issue in Istio's github repo, can you check if setting this filter in your node helps?
istio/istio#14261 (comment)

Those seem to be loaded/set
&lt;denchmark-code&gt;docker exec -it kubeflow-control-plane bash -c "lsmod | grep br_netfilter"
br_netfilter           24576  0
bridge                155648  1 br_netfilter
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;docker exec -it kubeflow-control-plane bash -c "sysctl net.bridge.bridge-nf-call-iptables"
net.bridge.bridge-nf-call-iptables = 1
&lt;/denchmark-code&gt;

Without any changes, I've performed another kubeflow installation from scratch, as described in the original post, this time with no CrashLoopBackOff.
		</comment>
		<comment id='7' author='marcindulak' date='2020-05-20T05:45:41Z'>
		I'm experiencing the same issue.
Anyone can help in resolving this without installing from scratch?
		</comment>
		<comment id='8' author='marcindulak' date='2020-07-16T09:19:49Z'>
		I experienced the same issue. It happened just suddenly, my cluster was already running for some time (e.g. days). I followed the instruction by &lt;denchmark-link:https://github.com/marcindulak&gt;@marcindulak&lt;/denchmark-link&gt;
 :
&lt;denchmark-code&gt;kubectl -n istio-system delete rs -lapp=galley
kubectl -n istio-system delete pod -lapp=policy
&lt;/denchmark-code&gt;

And then the istio-routing is revived and the dashboard-ui works again.
		</comment>
		<comment id='9' author='marcindulak' date='2020-10-15T04:17:31Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>