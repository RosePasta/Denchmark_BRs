<bug id='4538' author='AGKhalil' open_date='2019-11-28T11:39:10Z' closed_time='2020-08-08T02:24:53Z'>
	<summary>Jupyter notebook not spawning</summary>
	<description>
/kind bug
Been trying to create a notebook server without success. Here's the content of my kubeflow namespace:
&lt;denchmark-code&gt;kubectl get all -n kubeflow
NAME                                                               READY   STATUS             RESTARTS   AGE
pod/admission-webhook-bootstrap-stateful-set-0                     0/1     CrashLoopBackOff   29         125m
pod/admission-webhook-deployment-78d899bf68-dsn5n                  1/1     Running            0          105s
pod/application-controller-stateful-set-0                          1/1     Running            0          125m
pod/argo-ui-55b859f7d7-gwh76                                       1/1     Running            0          124m
pod/centraldashboard-75474d6f94-k96ln                              1/1     Running            0          125m
pod/jupyter-web-app-deployment-6c8f4c8997-h5mrt                    1/1     Running            0          125m
pod/katib-controller-85995d4f5f-d42bg                              1/1     Running            1          125m
pod/katib-db-6558656ffc-5cjtf                                      1/1     Running            0          125m
pod/katib-manager-79f78fc794-968nb                                 1/1     Running            3          125m
pod/katib-ui-fcdb8f8c5-6wf5j                                       1/1     Running            0          125m
pod/kfserving-controller-manager-0                                 2/2     Running            1          125m
pod/metacontroller-0                                               1/1     Running            0          125m
pod/metadata-db-75958d988b-dtfmr                                   0/1     CrashLoopBackOff   28         125m
pod/metadata-deployment-67658fd6cd-b9sjh                           0/1     Running            6          125m
pod/metadata-envoy-deployment-7ccf5c4f74-zwrxh                     1/1     Running            0          125m
pod/metadata-grpc-deployment-57966444dc-nt9n9                      0/1     CrashLoopBackOff   26         125m
pod/metadata-ui-78f5b59b56-fwrsj                                   1/1     Running            0          125m
pod/minio-6f48db9cc4-dwf78                                         1/1     Running            0          125m
pod/ml-pipeline-844645fd-zqfpg                                     1/1     Running            0          125m
pod/ml-pipeline-ml-pipeline-visualizationserver-865894f5f7-kq7bx   1/1     Running            0          125m
pod/ml-pipeline-persistenceagent-66f89b56d9-9skrv                  1/1     Running            1          125m
pod/ml-pipeline-scheduledworkflow-57445ddf88-w49gn                 1/1     Running            0          125m
pod/ml-pipeline-ui-5c64b6c666-qmn2q                                1/1     Running            0          125m
pod/ml-pipeline-viewer-controller-deployment-7cc8d77468-d29kt      1/1     Running            0          125m
pod/mysql-749f87bff5-fnpdm                                         1/1     Running            0          125m
pod/notebook-controller-deployment-6c887454f7-tvdc4                1/1     Running            0          125m
pod/profiles-deployment-bd576fd8f-q5fgf                            2/2     Running            0          125m
pod/pytorch-operator-84c58df794-287sb                              1/1     Running            0          125m
pod/seldon-operator-controller-manager-0                           1/1     Running            1          125m
pod/spartakus-volunteer-9768df654-g4v78                            1/1     Running            0          125m
pod/tensorboard-6544748d94-qfzzf                                   1/1     Running            0          125m
pod/tf-job-operator-db676465c-vbrzs                                1/1     Running            0          125m
pod/workflow-controller-676484d796-7tbc6                           1/1     Running            0          124m

NAME                                                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/admission-webhook-service                      ClusterIP   10.99.197.101    &lt;none&gt;        443/TCP             126m
service/application-controller-service                 ClusterIP   10.101.250.124   &lt;none&gt;        443/TCP             126m
service/argo-ui                                        NodePort    10.109.42.199    &lt;none&gt;        80:32341/TCP        126m
service/centraldashboard                               ClusterIP   10.109.84.171    &lt;none&gt;        80/TCP              126m
service/jupyter-web-app-service                        ClusterIP   10.111.188.122   &lt;none&gt;        80/TCP              126m
service/katib-controller                               ClusterIP   10.98.169.46     &lt;none&gt;        443/TCP             126m
service/katib-db                                       ClusterIP   10.96.219.3      &lt;none&gt;        3306/TCP            126m
service/katib-manager                                  ClusterIP   10.107.53.146    &lt;none&gt;        6789/TCP            126m
service/katib-ui                                       ClusterIP   10.100.223.191   &lt;none&gt;        80/TCP              126m
service/kfserving-controller-manager-metrics-service   ClusterIP   10.107.131.203   &lt;none&gt;        8443/TCP            126m
service/kfserving-controller-manager-service           ClusterIP   10.101.40.24     &lt;none&gt;        443/TCP             126m
service/kfserving-webhook-server-service               ClusterIP   10.110.21.134    &lt;none&gt;        443/TCP             125m
service/metadata-db                                    ClusterIP   10.104.116.32    &lt;none&gt;        3306/TCP            126m
service/metadata-envoy-service                         ClusterIP   10.107.182.8     &lt;none&gt;        9090/TCP            126m
service/metadata-grpc-service                          ClusterIP   10.110.141.186   &lt;none&gt;        8080/TCP            126m
service/metadata-service                               ClusterIP   10.108.113.170   &lt;none&gt;        8080/TCP            126m
service/metadata-ui                                    ClusterIP   10.106.145.136   &lt;none&gt;        80/TCP              126m
service/minio-service                                  ClusterIP   10.110.25.186    &lt;none&gt;        9000/TCP            126m
service/ml-pipeline                                    ClusterIP   10.108.150.107   &lt;none&gt;        8888/TCP,8887/TCP   126m
service/ml-pipeline-ml-pipeline-visualizationserver    ClusterIP   10.106.9.83      &lt;none&gt;        8888/TCP            126m
service/ml-pipeline-tensorboard-ui                     ClusterIP   10.97.152.72     &lt;none&gt;        80/TCP              126m
service/ml-pipeline-ui                                 ClusterIP   10.97.148.233    &lt;none&gt;        80/TCP              126m
service/mysql                                          ClusterIP   10.107.128.108   &lt;none&gt;        3306/TCP            126m
service/notebook-controller-service                    ClusterIP   10.105.32.90     &lt;none&gt;        443/TCP             126m
service/profiles-kfam                                  ClusterIP   10.102.250.43    &lt;none&gt;        8081/TCP            126m
service/pytorch-operator                               ClusterIP   10.102.26.142    &lt;none&gt;        8443/TCP            126m
service/seldon-operator-controller-manager-service     ClusterIP   10.111.189.113   &lt;none&gt;        443/TCP             126m
service/tensorboard                                    ClusterIP   10.101.41.114    &lt;none&gt;        9000/TCP            126m
service/tf-job-operator                                ClusterIP   10.99.192.147    &lt;none&gt;        8443/TCP            126m
service/webhook-server-service                         ClusterIP   10.99.68.9       &lt;none&gt;        443/TCP             126m

NAME                                                          READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/admission-webhook-deployment                  1/1     1            1           126m
deployment.apps/argo-ui                                       1/1     1            1           126m
deployment.apps/centraldashboard                              1/1     1            1           126m
deployment.apps/jupyter-web-app-deployment                    1/1     1            1           126m
deployment.apps/katib-controller                              1/1     1            1           126m
deployment.apps/katib-db                                      1/1     1            1           126m
deployment.apps/katib-manager                                 1/1     1            1           126m
deployment.apps/katib-ui                                      1/1     1            1           126m
deployment.apps/metadata-db                                   0/1     1            0           126m
deployment.apps/metadata-deployment                           0/1     1            0           126m
deployment.apps/metadata-envoy-deployment                     1/1     1            1           126m
deployment.apps/metadata-grpc-deployment                      0/1     1            0           126m
deployment.apps/metadata-ui                                   1/1     1            1           126m
deployment.apps/minio                                         1/1     1            1           126m
deployment.apps/ml-pipeline                                   1/1     1            1           126m
deployment.apps/ml-pipeline-ml-pipeline-visualizationserver   1/1     1            1           126m
deployment.apps/ml-pipeline-persistenceagent                  1/1     1            1           126m
deployment.apps/ml-pipeline-scheduledworkflow                 1/1     1            1           126m
deployment.apps/ml-pipeline-ui                                1/1     1            1           126m
deployment.apps/ml-pipeline-viewer-controller-deployment      1/1     1            1           126m
deployment.apps/mysql                                         1/1     1            1           126m
deployment.apps/notebook-controller-deployment                1/1     1            1           126m
deployment.apps/profiles-deployment                           1/1     1            1           126m
deployment.apps/pytorch-operator                              1/1     1            1           126m
deployment.apps/spartakus-volunteer                           1/1     1            1           126m
deployment.apps/tensorboard                                   1/1     1            1           126m
deployment.apps/tf-job-operator                               1/1     1            1           126m
deployment.apps/workflow-controller                           1/1     1            1           126m

NAME                                                                     DESIRED   CURRENT   READY   AGE
replicaset.apps/admission-webhook-deployment-78d899bf68                  1         1         1       126m
replicaset.apps/argo-ui-55b859f7d7                                       1         1         1       126m
replicaset.apps/centraldashboard-75474d6f94                              1         1         1       126m
replicaset.apps/jupyter-web-app-deployment-6c8f4c8997                    1         1         1       126m
replicaset.apps/katib-controller-85995d4f5f                              1         1         1       126m
replicaset.apps/katib-db-6558656ffc                                      1         1         1       126m
replicaset.apps/katib-manager-79f78fc794                                 1         1         1       126m
replicaset.apps/katib-ui-fcdb8f8c5                                       1         1         1       126m
replicaset.apps/metadata-db-75958d988b                                   1         1         0       126m
replicaset.apps/metadata-deployment-67658fd6cd                           1         1         0       126m
replicaset.apps/metadata-envoy-deployment-7ccf5c4f74                     1         1         1       126m
replicaset.apps/metadata-grpc-deployment-57966444dc                      1         1         0       126m
replicaset.apps/metadata-ui-78f5b59b56                                   1         1         1       126m
replicaset.apps/minio-6f48db9cc4                                         1         1         1       126m
replicaset.apps/ml-pipeline-844645fd                                     1         1         1       126m
replicaset.apps/ml-pipeline-ml-pipeline-visualizationserver-865894f5f7   1         1         1       126m
replicaset.apps/ml-pipeline-persistenceagent-66f89b56d9                  1         1         1       126m
replicaset.apps/ml-pipeline-scheduledworkflow-57445ddf88                 1         1         1       126m
replicaset.apps/ml-pipeline-ui-5c64b6c666                                1         1         1       126m
replicaset.apps/ml-pipeline-viewer-controller-deployment-7cc8d77468      1         1         1       126m
replicaset.apps/mysql-749f87bff5                                         1         1         1       126m
replicaset.apps/notebook-controller-deployment-6c887454f7                1         1         1       126m
replicaset.apps/profiles-deployment-bd576fd8f                            1         1         1       126m
replicaset.apps/pytorch-operator-84c58df794                              1         1         1       126m
replicaset.apps/spartakus-volunteer-9768df654                            1         1         1       126m
replicaset.apps/tensorboard-6544748d94                                   1         1         1       126m
replicaset.apps/tf-job-operator-db676465c                                1         1         1       126m
replicaset.apps/workflow-controller-676484d796                           1         1         1       126m

NAME                                                        READY   AGE
statefulset.apps/admission-webhook-bootstrap-stateful-set   0/1     126m
statefulset.apps/application-controller-stateful-set        1/1     126m
statefulset.apps/kfserving-controller-manager               1/1     126m
statefulset.apps/metacontroller                             1/1     126m
statefulset.apps/seldon-operator-controller-manager         1/1     126m
&lt;/denchmark-code&gt;

Here's the content of the namespace used for the notebook:
&lt;denchmark-code&gt;kubectl get all -n ahmed
NAME        READY   STATUS             RESTARTS   AGE
pod/pls-0   0/1     CrashLoopBackOff   5          5m33s

NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/pls   ClusterIP   10.109.92.100   &lt;none&gt;        80/TCP    5m33s

NAME                   READY   AGE
statefulset.apps/pls   0/1     5m33s
&lt;/denchmark-code&gt;

The pod created for the notebook:
&lt;denchmark-code&gt;kubectl describe pod/pls-0 -n ahmed
Name:               pls-0
Namespace:          ahmed
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               zeta/10.70.26.96
Start Time:         Thu, 28 Nov 2019 10:53:03 +0000
Labels:             app=pls
                    controller-revision-hash=pls-56bbdd4c4f
                    notebook-name=pls
                    statefulset=pls
                    statefulset.kubernetes.io/pod-name=pls-0
Annotations:        &lt;none&gt;
Status:             Running
IP:                 10.36.0.52
Controlled By:      StatefulSet/pls
Containers:
  pls:
    Container ID:   docker://9321eb68d8918c989562f33ab1406f6cb54e6adebad7632decaa0fd6ef699971
    Image:          gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-cpu:v0.7.0
    Image ID:       docker-pullable://gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-cpu@sha256:e45be757280cd44c468892305fd10dd76098f01ad4706f0a8be1387051d9baca
    Port:           8888/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Thu, 28 Nov 2019 11:14:06 +0000
      Finished:     Thu, 28 Nov 2019 11:14:06 +0000
    Ready:          False
    Restart Count:  9
    Requests:
      cpu:     500m
      memory:  1Gi
    Environment:
      NB_PREFIX:  /notebook/ahmed/pls
    Mounts:
      /dev/shm from dshm (rw)
      /home/jovyan from workspace-pls (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-editor-token-hjc7s (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  workspace-pls:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  workspace-pls
    ReadOnly:   false
  dshm:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  &lt;unset&gt;
  default-editor-token-hjc7s:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-editor-token-hjc7s
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason     Age                 From               Message
  ----     ------     ----                ----               -------
  Normal   Scheduled  21m                 default-scheduler  Successfully assigned ahmed/pls-0 to zeta
  Normal   Pulled     19m (x5 over 21m)   kubelet, zeta      Container image "gcr.io/kubeflow-images-public/tensorflow-2.0.0a0-notebook-cpu:v0.7.0" already present on machine
  Normal   Created    19m (x5 over 21m)   kubelet, zeta      Created container pls
  Normal   Started    19m (x5 over 21m)   kubelet, zeta      Started container pls
  Warning  BackOff    79s (x95 over 21m)  kubelet, zeta      Back-off restarting failed container
&lt;/denchmark-code&gt;

The workspace is bound to pv-volume3
&lt;denchmark-code&gt;kubectl get pvc -n ahmed
NAME            STATUS   VOLUME       CAPACITY   ACCESS MODES   STORAGECLASS    AGE
workspace-pls   Bound    pv-volume3   10Gi       RWX            local-storage   7m36s
&lt;/denchmark-code&gt;

When I try to get the pod logs, I get:
&lt;denchmark-code&gt;kubectl logs -f pod/pls-0 -n ahmed
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 528, in get
    value = obj._trait_values[self.name]
KeyError: 'runtime_dir'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/bin/jupyter-notebook", line 10, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 267, in launch_instance
    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 657, in launch_instance
    app.initialize(argv)
  File "&lt;/usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-7&gt;", line 2, in initialize
  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 87, in catch_config_error
    return method(app, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/notebook/notebookapp.py", line 1676, in initialize
    self.init_configurables()
  File "/usr/local/lib/python3.6/dist-packages/notebook/notebookapp.py", line 1349, in init_configurables
    connection_dir=self.runtime_dir,
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 556, in __get__
    return self.get(obj, cls)
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 535, in get
    value = self._validate(obj, dynamic_default())
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 99, in _runtime_dir_default
    ensure_dir_exists(rd, mode=0o700)
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/utils/__init__.py", line 13, in ensure_dir_exists
    os.makedirs(path, mode=mode)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/jovyan/.local'
&lt;/denchmark-code&gt;

I found two issues that are similar to what I'm having: &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3487&gt;#3487&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/1241&gt;#1241&lt;/denchmark-link&gt;
. Both point to not having the correct permission for directory used for my partition . So I changed it to have 777 permission:
&lt;denchmark-code&gt;stat -c "%a %n" /mnt/pv3/
777 /mnt/pv3/
&lt;/denchmark-code&gt;

But still nothing. My server does not spawn. Any insight on this would be really appreciated.
Environment:

Kubeflow version: (version number can be found at the bottom left corner of the Kubeflow dashboard): build version 0.7.0
kfctl version: (use kfctl version): v0.7.0
Kubernetes platform: kubeadm
Kubernetes version: (use kubectl version): Client Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.8", GitCommit:"211047e9a1922595eaa3a1127ed365e9299a6c23", GitTreeState:"clean", BuildDate:"2019-10-15T12:11:03Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"14", GitVersion:"v1.14.9", GitCommit:"500f5aba80d71253cc01ac6a8622b8377f4a7ef9", GitTreeState:"clean", BuildDate:"2019-11-13T11:13:04Z", GoVersion:"go1.12.12", Compiler:"gc", Platform:"linux/amd64"}
OS (e.g. from /etc/os-release):  18.04.3 LTS (Bionic Beaver)

	</description>
	<comments>
		<comment id='1' author='AGKhalil' date='2019-11-28T11:39:47Z'>
		Issue Label Bot is not confident enough to auto-label this issue.
See &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='2' author='AGKhalil' date='2019-12-03T13:53:07Z'>
		Anyone?
		</comment>
		<comment id='3' author='AGKhalil' date='2020-01-12T15:06:52Z'>
		Happy new year guys. Now please look at this issue ðŸ˜„
		</comment>
		<comment id='4' author='AGKhalil' date='2020-01-15T11:19:55Z'>
		i have no problem with that. what docker images that you used for the Jupyter Notebook?
		</comment>
		<comment id='5' author='AGKhalil' date='2020-01-15T11:23:01Z'>
		Thanks a bunch! I believe I tried all of the TF ones, but mainly 1.14 CPU and 2.0 CPU.
		</comment>
		<comment id='6' author='AGKhalil' date='2020-01-15T11:26:02Z'>
		Are you sure your deployment is clear? Have you tried to re-deploy and try it again?
Can you share how did you deploy your Kubeflow?
		</comment>
		<comment id='7' author='AGKhalil' date='2020-01-15T11:32:26Z'>
		I did try redeploying multiple times but that was a while ago and I know this repo changes very often. I tried to delete Kubeflow a couple days ago but couldn't due to &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4642&gt;#4642&lt;/denchmark-link&gt;
 but I can try again soon (since it just got fixed).
As for how I deployed, I followed &lt;denchmark-link:https://www.kubeflow.org/docs/started/k8s/kfctl-k8s-istio/&gt;https://www.kubeflow.org/docs/started/k8s/kfctl-k8s-istio/&lt;/denchmark-link&gt;

I manually created a StorageClass and the necessary PVs to get things working. The PV for my notebook server binds as far as I can tell.
		</comment>
		<comment id='8' author='AGKhalil' date='2020-01-29T19:59:54Z'>
		&lt;denchmark-link:https://github.com/AGKhalil&gt;@AGKhalil&lt;/denchmark-link&gt;

I've ran into several issues as well with Kubeflow, seems fickle at best...but I'm running into similar issues that you are.
The things I've noticed in your logs.
pod/metadata-db-75958d988b-dtfmr                                   0/1     CrashLoopBackOff   28         125m
pod/metadata-grpc-deployment-57966444dc-nt9n9                      0/1     CrashLoopBackOff   26         125m
These were not started for me either (i'm not sure if they are impacting you or not, I have a very similar issue as you and my metadata-db and metadata-grpc-deployment is "running" for me, but I did have to fix them in my original deployment).
To fix these make sure your pvc are allocated correctly, those two in particular need a PV of at least &gt;20GB.
You can check to the request sizes doing
kubectl -n &lt;namespace&gt; get pvc &lt;PVC_NAME&gt; -o yaml
It will be under the "requests" section. Once you create the larger PVs those containers should grab and make the PVCs.
As for &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4642&gt;#4642&lt;/denchmark-link&gt;
 it seems to be fixed in a later version of kfctl in this link.
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4642#issuecomment-573873499&gt;#4642 (comment)&lt;/denchmark-link&gt;

Now...as for your current problem, are you trying to request a notebook with the option?

Don't use Persistent Storage for User's home

If so I have the same exact issue.  If so there are several other problems I found related to this issue. &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/3487&gt;#3487&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/1241&gt;#1241&lt;/denchmark-link&gt;

If I don't select the option

Don't use Persistent Storage for User's home

and I create another PV that can be grabbed by this newly created container that hosts the jupyter notebook it gets past this error message but generates new error messages.
&lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4519&gt;#4519&lt;/denchmark-link&gt;

I've also seen the another related error message &lt;denchmark-link:https://github.com/kubeflow/kubeflow/issues/4284&gt;#4284&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='9' author='AGKhalil' date='2020-04-14T22:48:17Z'>
		&lt;denchmark-link:https://github.com/vaskokj&gt;@vaskokj&lt;/denchmark-link&gt;
, did you ever figure this out?
I just deployed v1.0.1 &lt;denchmark-link:https://github.com/kubeflow/kfctl/releases/download/v1.0.1/kfctl_v1.0.1-0-gf3edb9b_linux.tar.gz&gt;kfctl &lt;/denchmark-link&gt;
with the v1.0.1 for istio on-prem.
I am running on K8S v1.15.3 deployed via Kubespray.
I am deploying my containers with no data volumes and no workspace volumes.
If I use my own &lt;denchmark-link:https://github.com/NVIDIA/deepops/blob/master/containers/ngc/tensorflow/Dockerfile&gt;container &lt;/denchmark-link&gt;
everything works fine.
If I use any of the supplied GCR containers I run into:
&lt;denchmark-code&gt;user@ubuntu1:~/$ kubectl logs  -n anonymous test-0 test
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 528, in get
    value = obj._trait_values[self.name]
KeyError: 'runtime_dir'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/bin/jupyter-notebook", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 268, in launch_instance
    return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 663, in launch_instance
    app.initialize(argv)
  File "&lt;/usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-7&gt;", line 2, in initialize
  File "/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py", line 87, in catch_config_error
    return method(app, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/notebook/notebookapp.py", line 1766, in initialize
    self.init_configurables()
  File "/usr/local/lib/python3.6/dist-packages/notebook/notebookapp.py", line 1380, in init_configurables
    connection_dir=self.runtime_dir,
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 556, in __get__
    return self.get(obj, cls)
  File "/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py", line 535, in get
    value = self._validate(obj, dynamic_default())
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/application.py", line 99, in _runtime_dir_default
    ensure_dir_exists(rd, mode=0o700)
  File "/usr/local/lib/python3.6/dist-packages/jupyter_core/utils/__init__.py", line 13, in ensure_dir_exists
    os.makedirs(path, mode=mode)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 210, in makedirs
    makedirs(head, mode, exist_ok)
  File "/usr/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
PermissionError: [Errno 13] Permission denied: '/home/jovyan/.local'

&lt;/denchmark-code&gt;

And these kubeflow pods are having issues:
&lt;denchmark-code&gt;NAME                                                           READY   STATUS             RESTARTS   AGE
katib-mysql-dcf7dcbd5-ffgk5                                    0/1     Pending            0          168m
metadata-db-65fb5b695d-vbql5                                   0/1     Pending            0          168m
metadata-grpc-deployment-75f9888cbf-h9p8b                      0/1     CrashLoopBackOff   37         168m
minio-69b4676bb7-mq5mx                                         0/1     Pending            0          167m
ml-pipeline-persistenceagent-6ff9fb86dc-9z4p8                  0/1     CrashLoopBackOff   25         167m
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='AGKhalil' date='2020-04-15T16:00:02Z'>
		&lt;denchmark-link:https://github.com/supertetelman&gt;@supertetelman&lt;/denchmark-link&gt;

The only way I was able to get around this was with associating a data volume with it for the permission issue.
I feel they have an issue with permissions in the container. They chown the directory to the the wrong user on this line (I believe it is incorrectly assigned to root:root if I remember correctly) when I was playing with creating my own docker container. Which is why you don't see the problem with your own container.



kubeflow/components/tensorflow-notebook-image/Dockerfile


         Line 120
      in
      eca9680






 RUN docker-credential-gcr configure-docker &amp;&amp; chown ${NB_USER}:users $HOME/.docker/config.json 





As for your other problem, you probably have an issue with those docker containers not starting up due to no PVC/PV bindings. Check it with
kubectl get pv,pvc -A
You will probably see PENDING creation. If you do you will need to manually create the container volumes (probably have to delete kubeflow and redeploy it). OR create automatic provisioning of PV/PVCs. Unfortunately all of this stuff is pretty fickle in the setup process.
		</comment>
		<comment id='11' author='AGKhalil' date='2020-04-15T19:23:53Z'>
		&lt;denchmark-link:https://github.com/vaskokj&gt;@vaskokj&lt;/denchmark-link&gt;

Looks like you are correct.
The bug I am hitting is that the default GCR containers have bad permissions that block them from working if no workspace volume is mounted.
It seems like this is the root cause for most of the people in this thread.
		</comment>
		<comment id='12' author='AGKhalil' date='2020-05-02T12:59:42Z'>
		Is there a resolution to this problem?   I see the same permission errors as stated above.
		</comment>
		<comment id='13' author='AGKhalil' date='2020-07-31T17:04:05Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>