<bug id='3844' author='SheharyarTkxel' open_date='2019-08-08T07:51:30Z' closed_time='2019-08-12T18:02:01Z'>
	<summary>Cluster Autoscaling Not Working</summary>
	<description>
Problem Statement:
I want to deploy 2 Node Groups (1st with 3 CPUs in Master, 2nd with 0 GPUs in Worker) and then scale up/down the GPU based Worker nodes as the load goes up/down.
:
Followed the &lt;denchmark-link:https://www.kubeflow.org/docs/aws/deploy/install-kubeflow/&gt;official tutorial&lt;/denchmark-link&gt;
 to setup Kubeflow on AWS with this yaml file configuration (don't mind the formatting):
`apiVersion: eksctl.io/v1alpha5
availabilityZones:

us-east-2a
us-east-2b
us-east-2c
kind: ClusterConfig
metadata:
name: kubeflow-gpu-aws
region: us-east-2
version: "1.12"
nodeGroups:
desiredCapacity: 3
instanceType: t3.large
maxSize: 3
minSize: 1
name: cpu-nodegroup
volumeSize: 150
availabilityZones:

us-east-2a
desiredCapacity: 0
iam:
withAddonPolicies:
autoScaler: true
instanceType: p2.xlarge
labels:
k8s.amazonaws.com/accelerator: nvidia-tesla-k80
maxSize: 3
minSize: 0
name: Scale-GPU
volumeSize: 100`



After this I followed this &lt;denchmark-link:https://eksworkshop.com/scaling/deploy_ca/#create-iam-policy-for-asg-1&gt;tutorial&lt;/denchmark-link&gt;
 to setup the Cluster Autoscaler. But it doesn't scale up the GPU nodes and instead gives out this message in the  command "".

&lt;denchmark-link:https://user-images.githubusercontent.com/51945960/62692044-5a005300-b9e9-11e9-9961-a2dde29d5e96.png&gt;&lt;/denchmark-link&gt;

Environment:

Kubeflow version: v0.5-branch
Kubernetes version: (Client=GitVersion: v1.15.0  ||  Server= v1.12.10-eks-2e569f)
OS: CentOS VM

	</description>
	<comments>
		<comment id='1' author='SheharyarTkxel' date='2019-08-08T07:51:32Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.55. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='SheharyarTkxel' date='2019-08-09T22:10:02Z'>
		/assign &lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='SheharyarTkxel' date='2019-08-09T22:11:06Z'>
		More like a cluster autoscaler issue. Better to submit issue there. I am also maintainer of CA. What's the CA version?
		</comment>
		<comment id='4' author='SheharyarTkxel' date='2019-08-09T23:02:03Z'>
		Let's track this issue here &lt;denchmark-link:https://github.com/kubernetes/autoscaler/issues/2161&gt;kubernetes/autoscaler#2161&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='SheharyarTkxel' date='2019-08-12T08:28:06Z'>
		I'm following this &lt;denchmark-link:https://eksworkshop.com/scaling/deploy_ca/#create-iam-policy-for-asg-1&gt;tutorial&lt;/denchmark-link&gt;
, and the cluster autoscaler yaml file in it specifies this which I assume is the version:
&lt;denchmark-link:https://user-images.githubusercontent.com/51945960/62853165-ecb03300-bd04-11e9-94c4-6dac308f44ab.png&gt;&lt;/denchmark-link&gt;

Let me know if I am wrong and how it check the version of CA from a command.
		</comment>
		<comment id='6' author='SheharyarTkxel' date='2019-08-12T08:31:01Z'>
		&lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;
 I'd appreciate if you comment on the feasibility of my scenario, if it is even possible:
Scenario
I want to deploy 2 Node Groups (1st with 3 CPUs in Master, 2nd with 0 GPUs in Worker) and then scale up/down the GPU based Worker nodes as the load goes up/down.
		</comment>
		<comment id='7' author='SheharyarTkxel' date='2019-08-12T18:01:53Z'>
		&lt;denchmark-link:https://github.com/SheharyarTkxel&gt;@SheharyarTkxel&lt;/denchmark-link&gt;
 Sure, that's possible and lots of user use this way. You need to create two node groups and follow CA instruction to scale from 0 for GPU nodes. you workloads should also have node affinity to choose GPU nodes.
I will close this issue and please submit an issue to corresponding repo. If the guidance you think has a problem, submit to eksworkshop.com github. If you think there's an issue in cluster autoscaler, we can discuss the issue there &lt;denchmark-link:https://github.com/kubernetes/autoscaler/issues&gt;https://github.com/kubernetes/autoscaler/issues&lt;/denchmark-link&gt;

We only talk about Kubeflow related issue here.
		</comment>
		<comment id='8' author='SheharyarTkxel' date='2019-08-12T18:02:00Z'>
		/close
		</comment>
		<comment id='9' author='SheharyarTkxel' date='2019-08-12T18:02:02Z'>
		&lt;denchmark-link:https://github.com/Jeffwan&gt;@Jeffwan&lt;/denchmark-link&gt;
: Closing this issue.

In response to this:

/close

Instructions for interacting with me using PR comments are available here.  If you have questions or suggestions related to my behavior, please file an issue against the kubernetes/test-infra repository.

		</comment>
	</comments>
</bug>