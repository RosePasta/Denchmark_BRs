<bug id='3481' author='asispatra' open_date='2019-06-17T18:03:38Z' closed_time='2019-09-10T17:23:25Z'>
	<summary>minio-pvc and mysql-pv-claim Pods stuck in Pending state although I have created 3 persistent volume</summary>
	<description>
I was following &lt;denchmark-link:https://www.kubeflow.org/docs/other-guides/troubleshooting/&gt;Kubeflow Troubleshooting&lt;/denchmark-link&gt;
 document section "Pods stuck in Pending state". One pvc become "Bound" state. but rest two are still pending although I have created three persistent volume.
&lt;denchmark-code&gt;$ kubectl -n kubeflow get pvc
NAME             STATUS    VOLUME       CAPACITY   ACCESS MODES   STORAGECLASS   AGE
katib-mysql      Bound     pv-volume3   10Gi       RWO                           70m
minio-pvc        Pending                                                         69m
mysql-pv-claim   Pending                                                         69m

$ kubectl -n kubeflow describe pvc minio-pvc
Name:          minio-pvc
Namespace:     kubeflow
StorageClass:
Status:        Pending
Volume:
Labels:        app.kubernetes.io/deploy-manager=ksonnet
               ksonnet.io/component=pipeline
Annotations:   ksonnet.io/managed:
                 {"pristine":"H4sIAAAAAAAA/ySOPU/EMBBEe37G1OGzTEtBhUAUR4Eo9pwBrWLvGq9zFKf8d+Sje3oaPc0ZUvXAFuqGGad7TFjVFsx4HTY6rR88b4WPWbRgQmGXRbpgPiPLkTkGr...
               kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:
Access Modes:
VolumeMode:    Filesystem
Events:
  Type       Reason         Age                  From                         Message
  ----       ------         ----                 ----                         -------
  Normal     FailedBinding  21s (x303 over 75m)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set
Mounted By:  minio-5f6b9b5b7-ms5kb

$ kubectl -n kubeflow describe pvc mysql-pv-claim
Name:          mysql-pv-claim
Namespace:     kubeflow
StorageClass:
Status:        Pending
Volume:
Labels:        app.kubernetes.io/deploy-manager=ksonnet
               ksonnet.io/component=pipeline
Annotations:   ksonnet.io/managed:
                 {"pristine":"H4sIAAAAAAAA/yyOPU8DMRBEe37G1Be+SrcUVAhEEQpEsfENyDp71/H6glB0/x05Svf0dvU0Z0hNezZPpgg4PWDCknRGwNuw3ql9b3ktfMqSCiYUdpmlC8IZWQ7MP...
               kubecfg.ksonnet.io/garbage-collect-tag: gc-tag
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:
Access Modes:
VolumeMode:    Filesystem
Events:
  Type       Reason         Age                  From                         Message
  ----       ------         ----                 ----                         -------
  Normal     FailedBinding  38s (x303 over 75m)  persistentvolume-controller  no persistent volumes available for this claim and no storage class is set
Mounted By:  mysql-657f87857d-dfxb7
&lt;/denchmark-code&gt;

Environment details:
OS: Ubuntu 18.04
Platform: x86
Thanks.
	</description>
	<comments>
		<comment id='1' author='asispatra' date='2019-06-17T18:03:40Z'>
		Issue-Label Bot is automatically applying the label kind/bug to this issue, with a confidence of 0.94. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/kubeflow/kubeflow&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='asispatra' date='2019-07-01T23:01:35Z'>
		This is because the docs are wrong üòÑ the 2 pending PVCs are requesting 20Gi:
&lt;denchmark-code&gt;$ kubectl get pvc -o custom-columns='name:{.metadata.name},storage:{.spec.resources.requests.storage}'
name             storage
katib-mysql      10Gi
minio-pvc        20Gi
mysql-pv-claim   20Gi
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='asispatra' date='2019-07-01T23:15:33Z'>
		Here's a PR suggesting the change: &lt;denchmark-link:https://github.com/kubeflow/website/pull/854&gt;kubeflow/website#854&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='asispatra' date='2019-11-22T16:51:41Z'>
		I'm having trouble with this too. I get the following when I look at the pvc requests.
&lt;denchmark-code&gt;$ kubectl get pvc -o custom-columns='name:{.metadata.name},storage:{.spec.resources.requests.storage}' -n kubeflow
name                storage
katib-mysql         10Gi
metadata-mysql      10Gi
minio-pv-claim      20Gi
mysql-pv-claim      20Gi
&lt;/denchmark-code&gt;

And when I look at the pv I created, I get:
&lt;denchmark-code&gt;$ kubectl get pv -n kubeflow
NAME         CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                              STORAGECLASS    REASON   AGE
pv-volume2   10Gi       RWO            Retain           Bound    kubeflow/metadata-mysql            local-storage            65s
pv-volume3   10Gi       RWO            Retain           Bound    kubeflow/katib-mysql               local-storage            65s
pv-volume4   20Gi       RWO            Retain           Bound    ahmed/workspace-myfirst-notebook   local-storage            65s
pv-volume5   20Gi       RWO            Retain           Bound    ahmed/workspace-first-notebook     local-storage            65s
&lt;/denchmark-code&gt;

Nevertheless, looking at my pvcs I still get pending statuses.
&lt;denchmark-code&gt;kubectl get pvc -n kubeflow
NAME             STATUS    VOLUME       CAPACITY   ACCESS MODES   STORAGECLASS    AGE
katib-mysql      Bound     pv-volume3   10Gi       RWO            local-storage   8s
metadata-mysql   Bound     pv-volume2   10Gi       RWO            local-storage   10s
minio-pv-claim   Pending                                          local-storage   8s
mysql-pv-claim   Pending                                          local-storage   8s
&lt;/denchmark-code&gt;

As a reference, here's my pv.yaml:
&lt;denchmark-code&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-volume2
  labels:
    type: local
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/pv2"
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-volume3
  labels:
    type: local
spec:
  storageClassName: local-storage
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/pv3"
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-volume4
  labels:
    type: local
spec:
  storageClassName: local-storage
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/pv4"
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-volume5
  labels:
    type: local
spec:
  storageClassName: local-storage
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/pv5"
---
&lt;/denchmark-code&gt;

Any insight on this would be appreciated.
		</comment>
		<comment id='5' author='asispatra' date='2019-11-22T16:57:16Z'>
		Check why they're pending with describe:
&lt;denchmark-code&gt;kubectl describe pvc -n kubeflow minio-pv-claim
&lt;/denchmark-code&gt;

My guess is that the available PVs don't have enough capacity.
		</comment>
		<comment id='6' author='asispatra' date='2019-11-25T11:06:49Z'>
		Would you mind explaining what you mean by not enough capacity? Should I create larger partitions, then? Also below is the output of the describe command for mini-pv-claim. Thanks for looking into this.
&lt;denchmark-code&gt;kubectl describe pvc -n kubeflow minio-pv-claim
Name:          minio-pv-claim
Namespace:     kubeflow
StorageClass:  local-storage
Status:        Pending
Volume:        
Labels:        app=minio
               app.kubernetes.io/component=minio
               app.kubernetes.io/instance=minio-0.1.31
               app.kubernetes.io/managed-by=kfctl
               app.kubernetes.io/name=minio
               app.kubernetes.io/part-of=kubeflow
               app.kubernetes.io/version=0.1.31
Annotations:   kubectl.kubernetes.io/last-applied-configuration:
                 {"apiVersion":"v1","kind":"PersistentVolumeClaim","metadata":{"annotations":{},"labels":{"app":"minio","app.kubernetes.io/component":"mini...
Finalizers:    [kubernetes.io/pvc-protection]
Capacity:      
Access Modes:  
VolumeMode:    Filesystem
Events:
  Type       Reason              Age                  From                         Message
  ----       ------              ----                 ----                         -------
  Warning    ProvisioningFailed  18s (x8 over 2m36s)  persistentvolume-controller  no volume plugin matched
Mounted By:  &lt;none&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='asispatra' date='2019-11-25T11:16:58Z'>
		I sense that this may have something to do with my default storage class so I'm posting that here as well.
&lt;denchmark-code&gt;kubectl describe sc
Name:                  local-storage
IsDefaultClass:        Yes
Annotations:           storageclass.kubernetes.io/is-default-class=true
Provisioner:           kubernetes.io/no-provisioner
Parameters:            &lt;none&gt;
AllowVolumeExpansion:  &lt;unset&gt;
MountOptions:          &lt;none&gt;
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                &lt;none&gt;
&lt;/denchmark-code&gt;

And here's the yaml file for it:
&lt;denchmark-code&gt;apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: Immediate
&lt;/denchmark-code&gt;

Thanks in advance!
		</comment>
		<comment id='8' author='asispatra' date='2019-11-25T23:49:33Z'>
		But volume-4 and volume-5 both have a capacity of 20Gi. Why is that not enough then?
		</comment>
		<comment id='9' author='asispatra' date='2019-11-25T23:51:12Z'>
		Sorry -- I hit enter to add a newline and it submitted my comment with half-formed thoughts; one moment.
		</comment>
		<comment id='10' author='asispatra' date='2019-11-25T23:53:24Z'>
		Btw I think I see something:
&lt;denchmark-code&gt;$ kubectl get pv -n kubeflow
NAME         CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                              STORAGECLASS    REASON   AGE
pv-volume2   10Gi       RWO            Retain           Bound    kubeflow/metadata-mysql            local-storage            65s
pv-volume3   10Gi       RWO            Retain           Bound    kubeflow/katib-mysql               local-storage            65s
pv-volume4   20Gi       RWO            Retain           Bound    ahmed/workspace-myfirst-notebook   local-storage            65s
pv-volume5   20Gi       RWO            Retain           Bound    ahmed/workspace-first-notebook     local-storage            65s
&lt;/denchmark-code&gt;

The claim on my last 2 pvs are to a notebook I created before. I've been testing with the same app directory. It's possible that I just need to delete everything and create the kubeflow app from scratch. At which point there will be no trace of my notebook servers.
		</comment>
		<comment id='11' author='asispatra' date='2019-11-25T23:55:39Z'>
		By "not enough capacity" I mean the spec.capacity.storage in your PVC is too large for any available PV.
Yep -- I just saw that myself! Those PVs are already bound ü§¶‚Äç‚ôÇÔ∏è
You can also delete just those PVCs and it will free up your PVs to be reclaimed (but any data will remain).
		</comment>
		<comment id='12' author='asispatra' date='2019-11-25T23:59:34Z'>
		I'm not at my PC right now to check this out. I'll do it first thing tomorrow!
Thanks a ton for your help hall!
		</comment>
		<comment id='13' author='asispatra' date='2020-02-18T03:14:44Z'>
		hi   , i have   " kubectl get pv -n kubeflow" showing the bound but the below process is still showing "CrashLoopBackOff". if you are saying docs are wrong then, can we please get a refernce to the right document

katib-mysql-dcf7dcbd5-6nc6v
metadata-db-65fb5b695d-k2tqb
ml-pipeline-5cddb75848-r79bv
4)ml-pipeline-persistenceagent-6ff9fb86dc-bl9k4
5)mysql-6bcbfbb6b8-n8r4m

NAME             CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   REASON   AGE
katib-mysql      10Gi       RWO            Retain           Bound    kubeflow/metadata-mysql                           5h17m
metadata-mysql   10Gi       RWO            Retain           Bound    kubeflow/katib-mysql                              4h49m
minio-pv-claim   20Gi       RWO            Retain           Bound    kubeflow/minio-pv-claim                           4h46m
mysql-pv-claim   20Gi       RWO            Retain           Bound    kubeflow/mysql-pv-claim                           4h44m
		</comment>
	</comments>
</bug>