<bug id='2593' author='kparichay' open_date='2020-07-29T08:16:52Z' closed_time='2020-09-09T11:08:28Z'>
	<summary>Tensor filter memory destroy bug</summary>
	<description>
Memory allocated by the tensor filters inside them (which support allocate_in_invoke)
is not freed appropriately. When using the single API, this memory is wrapped with ml_tensors_data
and freed wtih ml_tensors_data_destroy. However, these memories allocated by the tensor filter itself
must be destroyed with destroyer of the tensor filter extension.
	</description>
	<comments>
		<comment id='1' author='kparichay' date='2020-07-29T08:16:54Z'>
		 : Thank you for posting issue &lt;denchmark-link:https://github.com/nnstreamer/nnstreamer/issues/2593&gt;#2593&lt;/denchmark-link&gt;
. The person in charge will reply soon.
		</comment>
		<comment id='2' author='kparichay' date='2020-07-29T08:25:13Z'>
		This issue also exists in the pipeline C-API as well.
		</comment>
		<comment id='3' author='kparichay' date='2020-08-21T07:37:14Z'>
		Isn't this resolved?
		</comment>
		<comment id='4' author='kparichay' date='2020-08-24T00:08:20Z'>
		The memory allocated by custom filters internally is NOT YET tracked by single/pipeline API to be able to call the filter handle later (if open) as of now.
		</comment>
	</comments>
</bug>