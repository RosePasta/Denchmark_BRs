<bug id='30' author='apchenstu' open_date='2017-05-14T04:35:33Z' closed_time='2017-05-17T11:58:34Z'>
	<summary>resume error</summary>
	<description>
hi, when i using resume to load parameters, it is crash saying ''unexpected key "module.features.0.weight" in state_dict''.  I don't know what wrong with this, Thanks a lot!
	</description>
	<comments>
		<comment id='1' author='apchenstu' date='2017-05-14T04:37:42Z'>
		model.load_state_dict(checkpoint['model_state_dict']), interrupted in this code
		</comment>
		<comment id='2' author='apchenstu' date='2017-05-14T04:46:27Z'>
		You should check the key of checkpoint['model_state_dict'] by checkpoint['model_state_dict'] and maybe you need to overwrite the dictionary keys.
(this problem sometimes happens depends on the version of pytorch, maybe.)
		</comment>
		<comment id='3' author='apchenstu' date='2017-05-14T04:54:50Z'>
		well, and which version of pytorch could fix this problem?
		</comment>
		<comment id='4' author='apchenstu' date='2017-05-14T05:02:33Z'>
		Not sure, but I'm currently using 0.1.11, so please try it. if possible.
		</comment>
		<comment id='5' author='apchenstu' date='2017-05-14T05:30:40Z'>
		oh, i install 0.1.11 just now, it was crash when i didn't use resume, when load parameter from VGG16 "vgg16.load_state_dict(torch.load(pth_file))" is that mean i should use a new VGG  parrameter file? Thanks.
		</comment>
		<comment id='6' author='apchenstu' date='2017-05-14T05:43:09Z'>
		Maybe you can specify version of torchvision written in requirements.txt.
		</comment>
		<comment id='7' author='apchenstu' date='2017-05-14T05:50:24Z'>
		yes, i believe it is because the torchvision's version, by the way, would you like to tell me what is you torchvision 's version?
		</comment>
		<comment id='8' author='apchenstu' date='2017-05-14T05:54:21Z'>
		&lt;denchmark-link:https://github.com/wkentaro/pytorch-fcn/blob/master/requirements.txt#L5&gt;https://github.com/wkentaro/pytorch-fcn/blob/master/requirements.txt#L5&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='apchenstu' date='2017-05-14T07:42:12Z'>
		Oh, i found that is because i change the "model" type into Parallel(model) after init, e.t. i use model=torch.nn.DataParallel(model) , in torchfcn.Trainer() class init. then i shift this parallel model define before init parameters from resume, it works.
		</comment>
		<comment id='10' author='apchenstu' date='2017-09-13T16:46:11Z'>
		&lt;denchmark-link:https://github.com/apchenstu&gt;@apchenstu&lt;/denchmark-link&gt;
 I am facing the same issue and your solution is'nt very clear. Can you please explain in more detail  ?
		</comment>
	</comments>
</bug>