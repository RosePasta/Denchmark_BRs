<bug id='485' author='vince62s' open_date='2017-12-22T09:42:08Z' closed_time='2018-02-09T01:22:14Z'>
	<summary>Seed / reproducibility</summary>
	<description>
even though this &lt;denchmark-link:https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/bin/t2t-trainer#L173&gt;https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/bin/t2t-trainer#L173&lt;/denchmark-link&gt;

was added in 1.4.0, two runs in ar ow of the same config does not produce the sames results.
Just checked loss and evals afetr 2000 steps, different.
	</description>
	<comments>
		<comment id='1' author='vince62s' date='2017-12-22T14:11:32Z'>
		Note that t2t-datagen uses more sophisticated approach than t2t-trainer: 

Perhaps the same approach (setting all three random seeds and keep the seed as a parameter, possibly with 0 meaning, no fixing) should be done in t2t-trainer and t2t-decoder.
&lt;denchmark-link:https://github.com/vince62s&gt;@vince62s&lt;/denchmark-link&gt;
: can you try it and report if it helps?
		</comment>
		<comment id='2' author='vince62s' date='2017-12-22T14:26:22Z'>
		In the previous version, when the line of code was not there, I had tried these lines in t2t-trainer
did not help (as reported in gitter).
		</comment>
		<comment id='3' author='vince62s' date='2017-12-22T16:46:20Z'>
		Adding the fuller seed setting to the trainer. Seems like a good idea, even if it isn't the whole solution.
		</comment>
		<comment id='4' author='vince62s' date='2017-12-23T04:45:30Z'>
		You can set add 'tf_random_seed=1' in Runconfig,the code as follows:
estimator = tf.contrib.learn.Estimator(
model_fn=model_builder(model_name, hparams=hparams),
model_dir=output_dir,
config=tf.contrib.learn.RunConfig(
master=FLAGS.master,
model_dir=output_dir,
gpu_memory_fraction=FLAGS.worker_gpu_memory_fraction,
session_config=session_config(),
keep_checkpoint_max=FLAGS.keep_checkpoint_max,tf_random_seed=1))
now, it works when initialize the tensor!
i set all dropout=0.0 and close shuffle when training,but when i rerun this model, the loss and evals are different
		</comment>
		<comment id='5' author='vince62s' date='2017-12-23T04:56:49Z'>
		&lt;denchmark-link:https://github.com/vince62s&gt;@vince62s&lt;/denchmark-link&gt;
  the other solution,you can add 'set_random_seed()'  to  'def run()'  of  'trainer_util.py'
but,i don't know why it not works when I had tried these lines in 't2t-trainer'
		</comment>
		<comment id='6' author='vince62s' date='2018-01-02T16:06:57Z'>
		Thanks &lt;denchmark-link:https://github.com/jiangbojian&gt;@jiangbojian&lt;/denchmark-link&gt;
! Yes, I think the issue is that we're not setting it in the . Will have that out in the next release.
		</comment>
		<comment id='7' author='vince62s' date='2018-01-18T18:11:02Z'>
		This is now set in the RunConfig. Try your commands again and let me know how it goes.
		</comment>
	</comments>
</bug>