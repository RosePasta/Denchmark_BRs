<bug id='314' author='PicarusW' open_date='2018-11-21T05:42:54Z' closed_time='2019-05-21T05:58:11Z'>
	<summary>Training step for Criteo_tft example does not work on google cloud</summary>
	<description>

I am running the Criteo example, documented&lt;denchmark-link:https://cloud.google.com/blog/products/gcp/using-google-cloud-machine-learning-to-predict-clicks-at-scale&gt; here&lt;/denchmark-link&gt;
. I can run the preprocess step fine but when trying to run the training step (linear model fails) running on Google Cloud I get the following errors:

Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-install-guzRvj/fastavro/
Command '['pip', 'install', '--user', u'trainer-1.0.tar.gz']' returned non-zero exit status 1

the error message in Google ML engine is:
load raise ImportError("%r has no %r attribute" % (entry, attr)) ImportError: &lt;module 'setuptools.dist' from '/usr/lib/python2.7/dist-packages/setuptools/dist.pyc'&gt; has no 'check_specifier' attribute
What sample is this bug related to?
I cloned this repo a couple of days ago.
Source code / logs
See above
To Reproduce
Location is us-east1 (if that is relevant)
JOB_ID="largeclicks_linear_${USER}$(date +%Y%m%d%H%M%S)"
cd ~/cloudml-samples/criteo_tft/
gcloud beta ml-engine jobs submit  training "$JOB_ID" 
--module-name trainer.task 
--package-path trainer 
--staging-bucket "$BUCKET" 
--region "$LOCATION" 
--config config-small.yaml 
-- 
--dataset small 
--model_type linear 
--ignore_crosses 
--l2_regularization 1000 
--output_path "${GCS_PATH}/output/${JOB_ID}" 
--metadata_path "${GCS_PATH}/preproc/metadata.json" 
--eval_data_paths "${GCS_PATH}/preproc/features_eval*" 
--train_data_paths "${GCS_PATH}/preproc/features_train*"
Expected behavior
the job to start execution
System Information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Cloud Shell
Framework and version (Tensorflow, scikit-learn, XGBoost):
Python version: 2.7 (both on Cloud Shell and remotely, no version specified in gcloud call) as it seems that Tensorflow-transform does not support 3.x
Exact command to reproduce: See above
Tensorflow Transform environment (if applicable, see below): I have tried to specify many different versions in the requirements.txt, requires.txt and setup.py but does not seem to be relevant. Default values on the mentioned files do not work.
Setuptools is version 40.6.2


You can find a reduced version of  the data &lt;denchmark-link:https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz&gt;here&lt;/denchmark-link&gt;
. From the train dataset, you can generate a train and eval dataset. It is 10Gb so much less than the original 1Tb.
	</description>
	<comments>
		<comment id='1' author='PicarusW' date='2018-11-26T01:37:41Z'>
		Hi &lt;denchmark-link:https://github.com/PicarusW&gt;@PicarusW&lt;/denchmark-link&gt;
 Thank you for reporting the issue.  This seems to be a dependency issue on Cloud ML Engine.  Could you try to run the same training job specifying the most recent runtime version by adding the  flag.
		</comment>
		<comment id='2' author='PicarusW' date='2018-11-26T02:37:42Z'>
		&lt;denchmark-link:https://github.com/dizcology&gt;@dizcology&lt;/denchmark-link&gt;
 I have run the test you request. I had  already tried that with different runtime versions.
Based on a bit of research it seems  it could be related to tensorflow_transform version incompatibilities. Have you tried to run it successfully?
		</comment>
		<comment id='3' author='PicarusW' date='2018-11-26T07:00:43Z'>
		&lt;denchmark-link:https://github.com/PicarusW&gt;@PicarusW&lt;/denchmark-link&gt;
 I saw your PR, were you able to make it work after adding the import statement? Please let me know otherwise I will try to validate it tomorrow in office.
		</comment>
		<comment id='4' author='PicarusW' date='2018-11-26T22:14:45Z'>
		&lt;denchmark-link:https://github.com/gogasca&gt;@gogasca&lt;/denchmark-link&gt;
 , the PR is for the preprocessing step. Unrelated to this issue as it happens in a previous execution step.
I think  a good refresh of the code would be benefitial. the code is using very old versions of TF and TFT, making it difficult to run in GCP.  Also a lot of methods are deprecated.
		</comment>
		<comment id='5' author='PicarusW' date='2018-11-27T22:27:33Z'>
		&lt;denchmark-link:https://github.com/PicarusW&gt;@PicarusW&lt;/denchmark-link&gt;
 ok, thanks for responding, agree with the code refresh. I will make sure the current version is usable. Our team is working in updating most of the samples. We also welcome contributions from the community.
		</comment>
		<comment id='6' author='PicarusW' date='2018-11-27T22:34:48Z'>
		&lt;denchmark-link:https://github.com/dizcology&gt;@dizcology&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/gogasca&gt;@gogasca&lt;/denchmark-link&gt;
 , any hints on how to solve or workaround the problem while the refresh happens? have you been able to execute it?
		</comment>
		<comment id='7' author='PicarusW' date='2018-11-27T22:44:58Z'>
		&lt;denchmark-link:https://github.com/PicarusW&gt;@PicarusW&lt;/denchmark-link&gt;
 I assume you are using a virtualenv, I have seen that error related to old setup tools version, but looks like you are running latest 40.6.2, what pip version are you using? In this case error seems to be unrelated to ML code but more on the environment, I will give it a try in lab and update you.
		</comment>
		<comment id='8' author='PicarusW' date='2018-11-28T03:09:27Z'>
		I am using pip 18.1 with python 2.7 (as transform does not support python 3) But if I understand correctly the command is not executed locally but in the ML Engine instance. Is that correct?
		</comment>
		<comment id='9' author='PicarusW' date='2018-11-28T07:33:35Z'>
		&lt;denchmark-link:https://github.com/picarus&gt;@picarus&lt;/denchmark-link&gt;
 that is correct, the package setup happens in Cloud ML Engine.
I took a look at the README.md again:
Our  specifies TF 1.3 which is quite outdated.
When running in Cloud I use:  as 1.3 is not supported.
&lt;denchmark-link:https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list#1.4&gt;https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list#1.4&lt;/denchmark-link&gt;

When we don't pass  parameter by default we use TF 1.0
Next steps:

Google team to update documentation
Google team to update sample to a more recent TF version (TF 1.10+)

This command is working for me:
&lt;denchmark-code&gt;JOB_ID="smallclicks_linear_$(date +%Y%m%d_%H%M%S)"
gcloud ml-engine jobs submit training "$JOB_ID" \
  --module-name trainer.task \
  --package-path trainer \
  --staging-bucket "$BUCKET" \
  --region us-central1 \
  --config config-small.yaml \
  --async \
  --runtime-version=1.4 \
  -- \
  --dataset kaggle \
  --model_type linear \
  --l2_regularization 100 \
  --output_path "${GCS_PATH_SMALL}/model/${JOB_ID}" \
  --raw_metadata_path "${PREPROCESS_OUTPUT_SMALL}/raw_metadata" \
  --transformed_metadata_path "${PREPROCESS_OUTPUT_SMALL}/transformed_metadata" \
  --transform_savedmodel "${PREPROCESS_OUTPUT_SMALL}/transform_fn" \
  --eval_data_paths "${PREPROCESS_OUTPUT_SMALL}/features_eval*" \
  --train_data_paths "${PREPROCESS_OUTPUT_SMALL}/features_train*"
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='PicarusW' date='2018-11-28T23:37:11Z'>
		Well, now the job completes successfully.
It was a matter of
Using runtime-version=1.4 as parameter,
changing the requirements.txt to use tf 1.4 (not sure if that is redundant), I am a bit confused with the local and cloud execution.
And then some parameters had to be added (compared to the blog post), your sample code was enough.
It took just 10 mins to execute with the small configuration.
While a workaround has been provided I would like to keep the issue open until the example is updated to a newer version  (if you are ok with that).
About versions, may I suggest to use tf 1.10, or any other that is compatible with tf/Adanet (tf 1.12 seems not to be).
		</comment>
		<comment id='11' author='PicarusW' date='2018-11-29T00:01:30Z'>
		&lt;denchmark-link:https://github.com/PicarusW&gt;@PicarusW&lt;/denchmark-link&gt;
 we describe 2 modes in this configuration, local and CMLE:
Local (python -m trainer.task or gcloud ml-engine local train) will use the requirements.txt and the information in setup.py to build the package and execute the training job locally (Your Laptop/VM where code is executing).
In CMLE mode (gcloud ml-engine jobs submit training) we build the infrastructure required to run your job.
More information here:
&lt;denchmark-link:https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer&gt;https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer&lt;/denchmark-link&gt;

I created a new Feature Request to update sample for consistency. &lt;denchmark-link:https://github.com/GoogleCloudPlatform/cloudml-samples/issues/319&gt;#319&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='PicarusW' date='2018-11-29T02:21:40Z'>
		&lt;denchmark-link:https://github.com/gogasca&gt;@gogasca&lt;/denchmark-link&gt;
 That makes sense, confirms my intuition.
Can you give a try to the deep model?
I am trying to use Adanet, so this is the one I want to take as baseline for my work.
For me it is failing with this logs in Logs View:
Invalid argument: Nan in summary histogram for: dnn/dnn/hiddenlayer_0_activation
And these error messages on ML engine:
&lt;denchmark-code&gt;The replica worker 5 exited with a non-zero status of 1. Termination reason: 
Error. Traceback (most recent call last): [...] File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py", line 46, in _execute_schedule return task() File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 367, in train hooks=self._train_monitors + extra_hooks) File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 812, in _call_train monitors=hooks) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py", line 316, in new_func return func(*args, **kwargs) File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 480, in fit loss = self._train_model(input_fn=input_fn, hooks=hooks) File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 1040, in _train_model _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss]) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 521, in run run_metadata=run_metadata) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 892, in run run_metadata=run_metadata) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 967, in run raise six.reraise(*original_exc_info) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 952, in run return self._sess.run(*args, **kwargs) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py", line 1032, in run run_metadata=run_metadata)) File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py", line 579, in after_run raise NanLossDuringTrainingError NanLossDuringTrainingError: NaN loss during training.

&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='PicarusW' date='2018-11-30T08:08:03Z'>
		I saw the same error, when reproducing in a different sample, (TF 1.4) will take a look and get back to you. Seems to be a problem in running configuration.
		</comment>
		<comment id='14' author='PicarusW' date='2019-05-21T05:58:11Z'>
		We have decided to deprecate this sample. Closing this PR
		</comment>
	</comments>
</bug>