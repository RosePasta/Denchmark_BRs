<bug id='2965' author='we1pingyu' open_date='2020-06-09T14:38:49Z' closed_time='2020-09-30T15:50:25Z'>
	<summary>Custom dataset question - classes specification</summary>
	<description>
Checklist

I have searched related issues but cannot get the expected help.
The bug has not been fixed in the latest version.

Describe the bug
Cannot modify classes in config.py. Have to modify hard code. And if you modify the config, the training will start with a evaluation. Only happens in mmdet v2.0.
Reproduction

What command or script did you run?

&lt;denchmark-code&gt;./tools/dist_train.sh configs/cascade_rcnn/cascade_rcnn_x101_64x4d_fpn.py  2  --work-dir /data/cascade_rcnn_x101_64x4d_fpn
&lt;/denchmark-code&gt;


Did you make any modifications on the code or config? Did you understand what you have modified?

&lt;denchmark-code&gt;_base_ = './cascade_rcnn_r50_fpn_1x_coco.py'
model = dict(
    type='CascadeRCNN',
    pretrained='open-mmlab://resnext101_64x4d',
    backbone=dict(
        type='ResNeXt',
        depth=101,
        groups=64,
        base_width=4,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        style='pytorch'),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[4],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[.0, .0, .0, .0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),

    roi_head=dict(
        type='CascadeRoIHead',
        num_stages=3,
        stage_loss_weights=[1, 0.5, 0.25],
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', out_size=7, sample_num=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.05, 0.05, 0.1, 0.1]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,
                               loss_weight=1.0)),
            dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=10,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0., 0., 0., 0.],
                    target_stds=[0.033, 0.033, 0.067, 0.067]),
                reg_class_agnostic=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=1.0),
                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))
        ]))
# dataset settings
dataset_type = 'CocoDataset'
classes = ('pedestrian', 'people', 'bicycle', 'car', 'van', 'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor')
data_root = '/data/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='MinIoURandomCrop',
         min_ious=(0.1, 0.3, 0.5, 0.7, 0.9),
         min_crop_size=0.3),
    dict(type='Resize', img_scale=(1520, 1002), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Normalize', **img_norm_cfg),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1520, 1002),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(type='Normalize', **img_norm_cfg),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img']),
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'xxx/train.json',
        img_prefix=data_root + 'xxx/images/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'xxx/val.json',
        img_prefix=data_root + 'xxx/images/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        classes=classes,
        ann_file=data_root + 'xxx/val.json',
        img_prefix=data_root + 'xxx/images/',
        pipeline=test_pipeline))
evaluation = dict(interval=1, metric='bbox')
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=1.0 / 3,
    step=[12, 18, 26])
total_epochs = 30

&lt;/denchmark-code&gt;


What dataset did you use?

Environment
&lt;denchmark-code&gt;sys.platform: linux
Python: 3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
CUDA available: True
CUDA_HOME: /usr/local/cuda-10.1
NVCC: Cuda compilation tools, release 10.1, V10.1.243
GPU 0,1: GeForce GTX 1080 Ti
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.3.1
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.20.5 (Git Hash 0125f28c61c1f822fd48570b4c1066f96fcb9b2e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.1
  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=True, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.4.2
OpenCV: 4.2.0
MMCV: 0.5.9
MMDetection: 2.0.0+204f751
MMDetection Compiler: GCC 7.5
MMDetection CUDA Compiler: 10.1
&lt;/denchmark-code&gt;

Error traceback
If applicable, paste the error trackback here.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "./tools/train.py", line 161, in &lt;module&gt;
    main()
  File "./tools/train.py", line 157, in main
    meta=meta)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/apis/train.py", line 179, in train_detector
    runner.run(data_loaders, cfg.workflow, cfg.total_epochs)
  File "/home/omnisky/anaconda3/envs/mmdet2/lib/python3.6/site-packages/mmcv/runner/runner.py", line 384, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/omnisky/anaconda3/envs/mmdet2/lib/python3.6/site-packages/mmcv/runner/runner.py", line 293, in train
    self.call_hook('after_train_epoch')
  File "/home/omnisky/anaconda3/envs/mmdet2/lib/python3.6/site-packages/mmcv/runner/runner.py", line 245, in call_hook
    getattr(hook, fn_name)(self)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/core/evaluation/eval_hooks.py", line 74, in after_train_epoch
    self.evaluate(runner, results)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/core/evaluation/eval_hooks.py", line 32, in evaluate
    results, logger=runner.logger, **self.eval_kwargs)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/datasets/coco.py", line 343, in evaluate
    result_files, tmp_dir = self.format_results(results, jsonfile_prefix)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/datasets/coco.py", line 306, in format_results
    result_files = self.results2json(results, jsonfile_prefix)
  File "/home/omnisky/yuweiping/mmdetection/mmdet/datasets/coco.py", line 240, in results2json
    if isinstance(results[0], list):
IndexError: list index out of range

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='we1pingyu' date='2020-06-10T04:37:51Z'>
		I meet the same error. After taking a lot of time to debug, I found that I have to commend these 2 lines (file: datasets/custom.py, line number: 73-74). I still don't know is that a bug?
# if self.custom_classes:
#     self.data_infos = self.get_subset_by_classes()
		</comment>
		<comment id='2' author='we1pingyu' date='2020-06-10T12:39:15Z'>
		Same error here. I think that the change of pycocotools broke some things. I've been using this repository with no problems for the past months, but with that change I'm facing a few bugs. ðŸ˜¢
		</comment>
		<comment id='3' author='we1pingyu' date='2020-06-12T06:51:30Z'>
		I could reproduce &lt;denchmark-link:https://github.com/VoThanhDanh95&gt;@VoThanhDanh95&lt;/denchmark-link&gt;
 's bug and solution, so this should be a bug in . I am still checking the problem.
		</comment>
		<comment id='4' author='we1pingyu' date='2020-06-19T09:24:00Z'>
		Just wanted to quickly check, has there been any updates on the above?
		</comment>
		<comment id='5' author='we1pingyu' date='2020-06-24T02:04:53Z'>
		Same problem, any update?
		</comment>
		<comment id='6' author='we1pingyu' date='2020-06-24T02:11:28Z'>
		The background no longer counts as a class, so for COCO rather than num_classes=81, it is now num_classes=80
		</comment>
		<comment id='7' author='we1pingyu' date='2020-07-03T13:56:48Z'>
		Same problem, any update?
mmdet: v2.2 &lt;denchmark-link:https://github.com/ZwwWayne&gt;@ZwwWayne&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='we1pingyu' date='2020-07-03T16:33:20Z'>
		A quick workaround is to comment these two lines. We will try to solve this bug ASAP.
		</comment>
	</comments>
</bug>