<bug id='1649' author='thomashossler' open_date='2019-11-08T21:37:49Z' closed_time='2019-11-25T09:23:56Z'>
	<summary>Shuffle=True in build data loader</summary>
	<description>
Describe the bug


When setting shuffle=True inb the non distributed training case, the build_dataloader function crashes. Because of sampler = GroupSampler(dataset, imgs_per_gpu) if shuffle else None, when shuffle=True the sampler is defined and pytorch dataloader cannot have both.


more importantly, because of that logic, in non distributed training, the sampler is None and there is no shuffling which means that the training data is fed to the network in a deterministic fashion (which is really bad if the classes are not uniformly distributed in your dataset for example).


Reproduction

What command or script did you run?

&lt;denchmark-code&gt;python train.py ../configs/faster_rcnn_r50_fpn_1x.py
&lt;/denchmark-code&gt;


Did you make any modifications on the code or config? Did you understand what you have modified?
In mmdet/apis/train.py, line 203" in the _non_dist_train function:

&lt;denchmark-code&gt;    data_loaders = [
        build_dataloader(
            ds,
            cfg.data.imgs_per_gpu,
            cfg.data.workers_per_gpu,
            cfg.gpus,
            dist=False,
            shuffle=True) for ds in dataset
    ]
&lt;/denchmark-code&gt;


What dataset did you use?
coco2017

Environment

provided docker image

Error traceback
If applicable, paste the error trackback here.
&lt;denchmark-code&gt;ValueError: sampler option is mutually exclusive with shuffle
&lt;/denchmark-code&gt;

Bug fix
I can write the PR asap.
	</description>
	<comments>
		<comment id='1' author='thomashossler' date='2019-11-19T16:54:13Z'>
		any update on that &lt;denchmark-link:https://github.com/ZwwWayne&gt;@ZwwWayne&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='2' author='thomashossler' date='2019-11-20T01:47:11Z'>
		&lt;denchmark-link:https://github.com/thomashossler&gt;@thomashossler&lt;/denchmark-link&gt;
 Thanks for your advice, this is indeed a bug.
Could you write a PR to fix that?
		</comment>
		<comment id='3' author='thomashossler' date='2019-11-20T08:49:02Z'>
		sure,  I'll submit it tomorrow
		</comment>
		<comment id='4' author='thomashossler' date='2019-11-20T12:39:03Z'>
		Thanks a lot.
		</comment>
		<comment id='5' author='thomashossler' date='2019-11-20T19:21:25Z'>
		cool you have the PR reference above. This is my first PR in this repo, I followed the guidelines but lemme know if something is wrong. I think this was the easiest / cleanest way to solve the bug.
		</comment>
		<comment id='6' author='thomashossler' date='2019-11-25T09:23:56Z'>
		Thanks for the PR.
This issue is closed, feel free to reopen it if you have further questions.
		</comment>
	</comments>
</bug>