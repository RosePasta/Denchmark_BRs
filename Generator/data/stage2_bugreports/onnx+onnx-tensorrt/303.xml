<bug id='303' author='sunskyhsh' open_date='2019-10-26T09:00:31Z' closed_time='2020-11-10T22:08:00Z'>
	<summary>onnx parsing issue due to Gather[axis=0] in onnx model converted from pytorch model</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Onnx can't parse the onnx model converted from pytorch '.pth' model, and reports following issue:
&lt;denchmark-code&gt;(py3.6_env) ‚ûú  HRNet-Semantic-Segmentation git:(fd276ac) ‚úó onnx2trt model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.onnx -o model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.trt
----------------------------------------------------------------
Input filename:   model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.onnx
ONNX IR version:  0.0.4
Opset version:    9
Producer name:    pytorch
Producer version: 1.3
Domain:           
Model version:    0
Doc string:       
----------------------------------------------------------------
Parsing model
WARNING: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
Successfully casted down to INT32.
While parsing node number 54 [Gather -&gt; "490"]:
ERROR: /home/sunsky/repo/onnx-tensorrt/onnx2trt_utils.hpp:399 In function convert_axis:
[8] Assertion failed: axis &gt;= 0 &amp;&amp; axis &lt; nbDims
&lt;/denchmark-code&gt;

This is how I convert pytorch model to onnx model.
&lt;denchmark-code&gt;def saveONNX(model, filepath):
    '''
    dummy_input = torch.randn(1, 3, 720, 1280, device='cuda')
    torch.onnx.export(model, dummy_input, filepath, verbose=True)
&lt;/denchmark-code&gt;

In the output log of above conversion  I find the Gather[axis=0] operations:
&lt;denchmark-code&gt;  %488 : Long() = onnx::Constant[value={3}](), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %489 : Tensor = onnx::Shape(%473), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %490 : Long() = onnx::Gather[axis=0](%489, %488), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0] # /home/sunsky/repo/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet.py:239:0
  %491 : Long() = onnx::Constant[value={2}](), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %492 : Tensor = onnx::Shape(%473), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %493 : Long() = onnx::Gather[axis=0](%492, %491), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0] # /home/sunsky/repo/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet.py:240:0
&lt;/denchmark-code&gt;

And the Gather[axis=0] operations come from the 239th and 240th line in seg_hrnet.py:
&lt;denchmark-code&gt;    def forward(self, x):
        if self.num_branches == 1:
            return [self.branches[0](x[0])]

        for i in range(self.num_branches):
            x[i] = self.branches[i](x[i])

        x_fuse = []
        for i in range(len(self.fuse_layers)):
            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])
            for j in range(1, self.num_branches):
                if i == j:
                    y = y + x[j]
                elif j &gt; i:
                    width_output = x[i].shape[-1] # &lt;==== THE 239th LINE
                    height_output = x[i].shape[-2] # &lt;==== THE 240th LINE
                    y = y + F.interpolate(
                        self.fuse_layers[i][j](x[j]),
                        size=[height_output, width_output],
                        mode='bilinear')
                else:
                    y = y + self.fuse_layers[i][j](x[j])
            x_fuse.append(self.relu(y))

        return x_fuse
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Git clone https://github.com/HRNet/HRNet-Semantic-Segmentation.git
Download a pretrained model from https://github.com/HRNet/HRNet-Semantic-Segmentation, HRNetV2-W18-Small-v1 for example.
Use torch.onnx.export to convert the pretrained model to onnx model.
Use onnx-tensorrt or TensorRT 5.1.5 to parse the onnx model.

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

PyTorch version: 1.3.0
Is debug build: No
CUDA used to build PyTorch: 10.1.243
OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.14.4
Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: GPU 0: GeForce RTX 2070
Nvidia driver version: 418.56
cuDNN version: 7.5.0.56
Versions of relevant libraries:
[pip3] numpy==1.16.4
[pip3] ros-numpy==0.0.2
[pip3] torch==1.3.0
[pip3] torchvision==0.4.1
[conda] torch                     1.3.0                     
[conda] torchvision               0.4.1                     
	</description>
	<comments>
		<comment id='1' author='sunskyhsh' date='2019-11-07T01:55:12Z'>
		I have the same problem. The default version of onnx opset which is used  in pytorch 1.3 is 9.
And the official released that  "The ONNX Parser shipped with TensorRT 5.1.x supports ONNX IR (Intermediate Representation) version 0.0.3, opset version 9."
Refer to &lt;denchmark-link:https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#api&gt;https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#api&lt;/denchmark-link&gt;

It's wired that this problem happens. Can I guess that TensorRT 5.1.x cannot support the opset version 9 fully ?
		</comment>
		<comment id='2' author='sunskyhsh' date='2019-12-20T01:22:21Z'>
		
Bug
Onnx can't parse the onnx model converted from pytorch '.pth' model, and reports following issue:
(py3.6_env) ‚ûú  HRNet-Semantic-Segmentation git:(fd276ac) ‚úó onnx2trt model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.onnx -o model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.trt
----------------------------------------------------------------
Input filename:   model/hrnet_w18_small_v1_cityscapes_cls19_1024x2048_trainset.onnx
ONNX IR version:  0.0.4
Opset version:    9
Producer name:    pytorch
Producer version: 1.3
Domain:           
Model version:    0
Doc string:       
----------------------------------------------------------------
Parsing model
WARNING: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
Successfully casted down to INT32.
While parsing node number 54 [Gather -&gt; "490"]:
ERROR: /home/sunsky/repo/onnx-tensorrt/onnx2trt_utils.hpp:399 In function convert_axis:
[8] Assertion failed: axis &gt;= 0 &amp;&amp; axis &lt; nbDims

This is how I convert pytorch model to onnx model.
def saveONNX(model, filepath):
    '''
    dummy_input = torch.randn(1, 3, 720, 1280, device='cuda')
    torch.onnx.export(model, dummy_input, filepath, verbose=True)

In the output log of above conversion I find the Gather[axis=0] operations:
  %488 : Long() = onnx::Constant[value={3}](), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %489 : Tensor = onnx::Shape(%473), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %490 : Long() = onnx::Gather[axis=0](%489, %488), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0] # /home/sunsky/repo/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet.py:239:0
  %491 : Long() = onnx::Constant[value={2}](), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %492 : Tensor = onnx::Shape(%473), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0]
  %493 : Long() = onnx::Gather[axis=0](%492, %491), scope: HighResolutionNet/Sequential[stage2]/HighResolutionModule[0] # /home/sunsky/repo/HRNet-Semantic-Segmentation/tools/../lib/models/seg_hrnet.py:240:0

And the Gather[axis=0] operations come from the 239th and 240th line in seg_hrnet.py:
    def forward(self, x):
        if self.num_branches == 1:
            return [self.branches[0](x[0])]

        for i in range(self.num_branches):
            x[i] = self.branches[i](x[i])

        x_fuse = []
        for i in range(len(self.fuse_layers)):
            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])
            for j in range(1, self.num_branches):
                if i == j:
                    y = y + x[j]
                elif j &gt; i:
                    width_output = x[i].shape[-1] # &lt;==== THE 239th LINE
                    height_output = x[i].shape[-2] # &lt;==== THE 240th LINE
                    y = y + F.interpolate(
                        self.fuse_layers[i][j](x[j]),
                        size=[height_output, width_output],
                        mode='bilinear')
                else:
                    y = y + self.fuse_layers[i][j](x[j])
            x_fuse.append(self.relu(y))

        return x_fuse

To Reproduce
Steps to reproduce the behavior:

Git clone https://github.com/HRNet/HRNet-Semantic-Segmentation.git
Download a pretrained model from https://github.com/HRNet/HRNet-Semantic-Segmentation, HRNetV2-W18-Small-v1 for example.
Use torch.onnx.export to convert the pretrained model to onnx model.
Use onnx-tensorrt or TensorRT 5.1.5 to parse the onnx model.

Environment
PyTorch version: 1.3.0
Is debug build: No
CUDA used to build PyTorch: 10.1.243
OS: Ubuntu 16.04.6 LTS
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
CMake version: version 3.14.4
Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: GPU 0: GeForce RTX 2070
Nvidia driver version: 418.56
cuDNN version: 7.5.0.56
Versions of relevant libraries:
[pip3] numpy==1.16.4
[pip3] ros-numpy==0.0.2
[pip3] torch==1.3.0
[pip3] torchvision==0.4.1
[conda] torch 1.3.0
[conda] torchvision 0.4.1

Hi &lt;denchmark-link:https://github.com/sunskyhsh&gt;@sunskyhsh&lt;/denchmark-link&gt;
 ,
Did you figure out how to solve this problem?
I have the same problem. The two inputs of the problematic "Gather" op are outputs of one "Constant" op and one "Shape" op.
How come the ".shape" function in Pytorch becomes these two ops?
		</comment>
		<comment id='3' author='sunskyhsh' date='2019-12-23T03:45:36Z'>
		&lt;denchmark-link:https://github.com/zheng-xing&gt;@zheng-xing&lt;/denchmark-link&gt;
 Nope, upgrading TensorRT version might help but I haven't tried.
		</comment>
		<comment id='4' author='sunskyhsh' date='2020-02-13T20:38:42Z'>
		Hi &lt;denchmark-link:https://github.com/sunskyhsh&gt;@sunskyhsh&lt;/denchmark-link&gt;
 ,
Not sure whether you have solved this problem or not. But I tried TensorRT v7 yesterday and this problem disappeared.
		</comment>
		<comment id='5' author='sunskyhsh' date='2020-11-10T22:08:00Z'>
		Previous versions of TensorRT (&lt;6.0) did not support operations across the batch dimension - i.e. axis 0. Later versions of TensorRT have added this feature, and your model should be able to parse in later TRT versions.
Closing this issue, if you are still seeing failures with the new TRT version feel free to open a new issue.
		</comment>
		<comment id='6' author='sunskyhsh' date='2021-01-07T07:50:29Z'>
		can tensorRT 6.0 support this featureÔºü
		</comment>
		<comment id='7' author='sunskyhsh' date='2021-01-07T16:28:01Z'>
		In TensorRT 6.0 we've added support for explicit batch network definitions and dynamic shapes, so it may work there. See the 6.0-full-dims branch for more information.
However we've made a lot more updates and bug fixes for dynamic shapes over the past few releases, so if you are able to use the latest version of TensorRT I would recommend that.
		</comment>
	</comments>
</bug>