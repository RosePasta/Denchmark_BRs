<bug id='198' author='ypw-rich' open_date='2019-06-21T06:54:42Z' closed_time='2020-10-29T18:58:04Z'>
	<summary>I want to deploy the model using pytorch-&amp;gt;onnx-&amp;gt;tensorrt, but I have a problem with LSTM.</summary>
	<description>
I am using the following code to export the onnx file:
    dummy_input = torch.zeros((1, 3, 32, 1024))
    torch.onnx.export(model, dummy_input, 'crnn.onnx')
Then I use onnx-tensorrt to load the model:
import onnx
import onnx_tensorrt.backend as backend
import numpy as np

model = onnx.load('/data3/crnn/crnn.onnx')

engine = backend.prepare(model, device='CUDA:0')
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-3-0620a8bd333e&gt; in &lt;module&gt;
----&gt; 1 engine = backend.prepare(model, device='CUDA:0')

~/onnx-tensorrt/onnx_tensorrt/backend.py in prepare(cls, model, device, **kwargs)
    216         """
    217         super(TensorRTBackend, cls).prepare(model, device, **kwargs)
--&gt; 218         return TensorRTBackendRep(model, device, **kwargs)
    219     @classmethod
    220     def run_model(cls, model, inputs, device='CUDA:0', **kwargs):

~/onnx-tensorrt/onnx_tensorrt/backend.py in __init__(self, model, device, max_batch_size, max_workspace_size, serialize_engine, **kwargs)
     92                     (error.file(), error.line(), error.func(),
     93                      error.code(), error.desc()))
---&gt; 94             raise RuntimeError(msg)
     95         if max_workspace_size is None:
     96             max_workspace_size = 1 &lt;&lt; 28

RuntimeError: While parsing node number 26:
builtin_op_importers.cpp:1928 In function importTranspose:
[8] Assertion failed: perm.order[BATCH_DIM] == BATCH_DIM
&lt;/denchmark-code&gt;

The input shape of LSTM in pytorch is (seq_len, batch, input_size).
&lt;denchmark-link:https://pytorch.org/docs/master/nn.html#lstm&gt;https://pytorch.org/docs/master/nn.html#lstm&lt;/denchmark-link&gt;

Then I tried setting batch_first=True, but the error is as follows:
&lt;denchmark-code&gt;anaconda3/lib/python3.7/site-packages/torch/onnx/symbolic.py:173: UserWarning: ONNX export failed on RNN/GRU/LSTM because batch_first not supported
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ypw-rich' date='2019-06-27T10:55:00Z'>
		&lt;denchmark-link:https://github.com/kevinch-nv&gt;@kevinch-nv&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ypw-rich' date='2019-08-01T07:52:28Z'>
		Same error
		</comment>
		<comment id='3' author='ypw-rich' date='2019-11-22T05:50:44Z'>
		onnxsim will solve the problem.
		</comment>
		<comment id='4' author='ypw-rich' date='2020-03-31T07:28:56Z'>
		same, do u solve this problem?
		</comment>
		<comment id='5' author='ypw-rich' date='2020-08-11T11:32:38Z'>
		tensorrt parse output of onnx is [-1,-1,-1]  ,it's wrong, anyone solved this problem?
		</comment>
		<comment id='6' author='ypw-rich' date='2020-10-13T05:36:33Z'>
		There were some limitations in previous TensorRT versions that caused issues with importing LSTMs. Have you tried using the latest  TensorRT 7.1 libraries to parse your model?
		</comment>
		<comment id='7' author='ypw-rich' date='2020-10-29T18:58:03Z'>
		Closing due to inactivity - if you are still having issues feel free to reopen.
		</comment>
	</comments>
</bug>