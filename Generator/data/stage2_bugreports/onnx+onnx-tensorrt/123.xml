<bug id='123' author='YaraAlnaggar' open_date='2019-02-27T18:26:32Z' closed_time='2020-11-03T22:10:30Z'>
	<summary>pytorch upsample layer not loading in tesnorrt4</summary>
	<description>
I've created a dummy pytorch network and exported it to .onnx file, which will be parsed to trt file using onnx2trt. When deserializing the generated .trt file using tesnorrt4, I get segmentation fault.
&lt;denchmark-code&gt;This is the code for producing the onnx file
import torch.nn as nn        
import torch
import onnx
import torch.nn.functional as F

rand_net = nn.Sequential(nn.Conv2d(3, 10, 5),
                         nn.BatchNorm2d(10),
                         nn.Upsample(scale_factor=2))

def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.uniform_(m.weight)


rand_net.apply(init_normal)
dummy_input = torch.randn(1, 3, 300, 300)
out1= rand_net.forward(dummy_input)

torch.onnx.export(rand_net, dummy_input,  "test_upsample_seq.onnx", verbose=True, output_names=['scores'])
&lt;/denchmark-code&gt;

and this is the parser result
&lt;denchmark-code&gt;Input filename:   test_upsample_seq.onnx
ONNX IR version:  0.0.3
Opset version:    9
Producer name:    pytorch
Producer version: 0.4
Domain:           
Model version:    0
Doc string:       
----------------------------------------------------------------
Parsing model
Building TensorRT engine, FP16 available:1
    Max batch size:     32
    Max workspace size: 1024 MiB
Writing TensorRT engine to torch_upsample_seq.trt
All done
----------------------------------------------------------------
Input filename:   test_upsample_seq.onnx
ONNX IR version:  0.0.3
Opset version:    9
Producer name:    pytorch
Producer version: 0.4
Domain:           
Model version:    0
Doc string:       
----------------------------------------------------------------
Parsing model
Building TensorRT engine, FP16 available:1
    Max batch size:     32
    Max workspace size: 1024 MiB
Writing TensorRT engine to torch_upsample_seq.trt
All done
&lt;/denchmark-code&gt;

used packages versions are
&lt;denchmark-code&gt;&gt;&gt;&gt; import onnx 
&gt;&gt;&gt; import torch
&gt;&gt;&gt; torch.__version__
'1.0.1.post2'
&gt;&gt;&gt; onnx.__version__
'1.4.1'

&lt;/denchmark-code&gt;

Any idea why tensorrt4 can't deserialize a model with upsample layer? please note that I have tried replacing upsample with interpolate, but I get the same error
	</description>
	<comments>
		<comment id='1' author='YaraAlnaggar' date='2019-04-01T08:31:14Z'>
		I get the same error when doing Semantic Segmentation task.
		</comment>
		<comment id='2' author='YaraAlnaggar' date='2019-07-19T06:23:22Z'>
		
I get the same error when doing Semantic Segmentation task.

hey, did you solve your problem, actually I run into the same problem as yours.
		</comment>
		<comment id='3' author='YaraAlnaggar' date='2019-07-26T16:24:59Z'>
		&lt;denchmark-link:https://github.com/ASONG0506&gt;@ASONG0506&lt;/denchmark-link&gt;
  Unfortunately no. I shifted to Keras where it works.
		</comment>
		<comment id='4' author='YaraAlnaggar' date='2019-09-19T07:01:19Z'>
		this is because pytorch default channel order is not same with TensorRT while keras should be same as it is.
		</comment>
		<comment id='5' author='YaraAlnaggar' date='2020-11-03T22:10:30Z'>
		Closing this issue as TensorRT 4 is no longer supported.
Please consider upgrading to the latest TensorRT version for your application. In addition, we recommend using the shipped trtexec binary that comes with TensorRT to produce serialized engines over onnx2trt, as we plan on deprecating the latter in the future.
		</comment>
	</comments>
</bug>