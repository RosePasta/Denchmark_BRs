<bug id='247' author='ashu122' open_date='2018-07-18T12:02:06Z' closed_time='2019-09-28T15:57:26Z'>
	<summary>Wrong FS when loading NerCrfModel</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Saving a trained NerCrf model to s3 and loading it back throws a java.lang.IllegalArgumentException exception with the message "Wrong FS, ... expected: file://...."
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

A saved model (either standalone or as part of a spark PipelineModel) should be loadable from s3
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

While the model can be saved at the moment, reading it back throws an exception. A sample stacktrace looks like this:
Py4JJavaError: An error occurred while calling o872.load. : java.lang.IllegalArgumentException: Wrong FS: s3n://myntelligence-classifier-stage/stage/model/stages/4_NER_be413400d8f4/embeddings, expected: file:/// at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:649) at org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:82) at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:606) at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824) at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601) at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337) at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289) at org.apache.hadoop.fs.LocalFileSystem.copyToLocalFile(LocalFileSystem.java:88) at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:1979) at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.indexEmbeddings(SparkWordEmbeddings.scala:69) at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.apply(SparkWordEmbeddings.scala:108) at com.johnsnowlabs.nlp.HasWordEmbeddings$class.deserializeEmbeddings(HasWordEmbeddings.scala:61) at com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfModel.deserializeEmbeddings(NerCrfModel.scala:19) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$class.readEmbeddings(EmbeddingsReadable.scala:8) at com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfModel$.readEmbeddings(NerCrfModel.scala:84) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead$1.apply(ParamsAndFeaturesReadable.scala:31) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead$1.apply(ParamsAndFeaturesReadable.scala:30) at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$class.com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead(ParamsAndFeaturesReadable.scala:30) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$read$1.apply(ParamsAndFeaturesReadable.scala:41) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$read$1.apply(ParamsAndFeaturesReadable.scala:41) at com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:19) at com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:8) at org.apache.spark.ml.util.DefaultParamsReader$.loadParamsInstance(ReadWrite.scala:438) at org.apache.spark.ml.Pipeline$SharedReadWrite$$anonfun$4.apply(Pipeline.scala:273) at org.apache.spark.ml.Pipeline$SharedReadWrite$$anonfun$4.apply(Pipeline.scala:271) at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234) at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234) at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33) at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186) at scala.collection.TraversableLike$class.map(TraversableLike.scala:234) at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186) at org.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:271) at org.apache.spark.ml.PipelineModel$PipelineModelReader.load(Pipeline.scala:347) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244) at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357) at py4j.Gateway.invoke(Gateway.java:280) at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132) at py4j.commands.CallCommand.execute(CallCommand.java:79) at py4j.GatewayConnection.run(GatewayConnection.java:214) at java.lang.Thread.run(Thread.java:748) 
pm = PipelineModel.read().load("s3n://path")
This is the line that is throwing the above error
&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;







&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Version used: 1.5.4
Browser Name and version:
Operating System and version (desktop or mobile):
Link to your project:

Please let me know if you need more information. Thanks
	</description>
	<comments>
		<comment id='1' author='ashu122' date='2018-08-09T21:26:56Z'>
		Hi, this should have been fixed in 1.6.0. If not, 1.6.1 should. Which version did you use?
Thanks
		</comment>
		<comment id='2' author='ashu122' date='2018-08-22T13:57:21Z'>
		Hi, can you confirm this still happens in current version and by following these instructions?
&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp#s3-cluster-with-no-hadoop-configuration&gt;https://github.com/JohnSnowLabs/spark-nlp#s3-cluster-with-no-hadoop-configuration&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ashu122' date='2019-09-28T15:57:26Z'>
		closing for inactivity.
		</comment>
	</comments>
</bug>