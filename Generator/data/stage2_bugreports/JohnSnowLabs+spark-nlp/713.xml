<bug id='713' author='dkincaid' open_date='2019-12-10T03:51:47Z' closed_time='2019-12-24T16:34:56Z'>
	<summary>Sentence detector error on documents containing single quotes, double quotes and $ symbol</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When using the SentenceDetector in a pipeline certain combinations of single quotes, double quotes and dollar signs cause an error. The stack trace is attached here: &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/files/3942922/exception-for-jsl.txt&gt;exception-for-jsl.txt&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;

If you run the "bad" text below through a sentence detector you will get the error. The "good" text simply replaces the single quote before the dollar sign with a double quote and this processes with no error.
The "bad" text below that causes the error is a modified version of a real document in our database
&lt;denchmark-h:h2&gt;Code example&lt;/denchmark-h&gt;

A Jupyter notebook that demonstrating the error is here:
&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/files/3942926/Example.sentence.detector.error.zip&gt;Example sentence detector error.zip&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;# Bad
badtext = "The 'man' in the back said '$everyone attack\" and it turned into a ballroom blitz."

# Good
goodtext = "The 'man' in the back said \"$everyone attack\" and it turned into a ballroom blitz."
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

We are unable to process our documents because this error kills the Spark job
	</description>
	<comments>
		<comment id='1' author='dkincaid' date='2019-12-12T20:23:36Z'>
		Fixed in &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/718&gt;#718&lt;/denchmark-link&gt;

Thank you for reporting this &lt;denchmark-link:https://github.com/dkincaid&gt;@dkincaid&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='dkincaid' date='2019-12-24T16:34:56Z'>
		I'll close this issue as the fix was released in 2.3.5. Please feel free to reopen it if the issue still exists.
		</comment>
		<comment id='3' author='dkincaid' date='2019-12-24T16:41:03Z'>
		Thanks for jumping on this one so fast. Had 2.3.5 been officially released now?
		</comment>
		<comment id='4' author='dkincaid' date='2019-12-24T16:58:08Z'>
		Yes, it’s released every where. We are just waiting for Spark Packages to also push it through their cache or whatever it is they are slow but you can use the Maven coordinates instead for —packages
		</comment>
	</comments>
</bug>