<bug id='298' author='EnricoMi' open_date='2018-11-02T13:26:55Z' closed_time='2019-07-11T07:42:57Z'>
	<summary>Loading NER Model on Windows fails with RocksDBException</summary>
	<description>
Loading a pre-trained Crf or DL NER Model on Windows fails with an org.rocksdb.RocksDBException: Snappy not supported or corrupted Snappy compressed block contents.
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When loading a pre-trained Crf (ner_fast_en_1.7.0_2_1539896043754) or DL (ner_precise_en_1.7.0_2_1539623388047) NER model on Windows, I get this exception:
&lt;denchmark-code&gt;Caused by: org.rocksdb.RocksDBException: Snappy not supported or corrupted Snappy compressed block contents
at org.rocksdb.RocksDB.get(Native Method)
at org.rocksdb.RocksDB.get(RocksDB.java:788)
at com.johnsnowlabs.nlp.embeddings.WordEmbeddingsRetriever.result$lzycompute$1(WordEmbeddingsRetriever.scala:21)
...
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The models should load without an exception.
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

An exception is thrown.
&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

The model might be written to disk with Linux and this is not binary compatible to Windows.
&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import spark.implicits._

import com.johnsnowlabs.nlp.annotator.{NerCrfModel, NerDLModel, SentenceDetector}
import org.apache.spark.ml.{Pipeline, PipelineModel}

val data = Seq("Here is some text.").toDF("text")

val basicPipeline = PipelineModel.read.load("/home/user/cache_pretrained/pipeline_basic_en_1.6.1_2_1533856444797")
val sentence = new SentenceDetector().setOutputCol("sentence")
val ner = NerCrfModel.read.load("/home/user/cache_pretrained/ner_fast_en_1.7.0_2_1539896043754")
//val ner = NerDLModel.read.load("/home/user/cache_pretrained/ner_precise_en_1.7.0_2_1539623388047")
val pipeline = new Pipeline().setStages(Array(basicPipeline, sentence, ner))
pipeline.fit(Seq.empty[String].toDF("text")).transform(data).show(false)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

I simply want to load any pre-trained NER model on Windows and use it for NER tagging.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Spark: 2.3.0
Spark-NLP: 1.7.2
NER Model: Crf (ner_fast_en_1.7.0_2_1539896043754) or DL (ner_precise_en_1.7.0_2_1539623388047)
OS: Windows 10

	</description>
	<comments>
		<comment id='1' author='EnricoMi' date='2018-11-05T13:28:24Z'>
		Hi &lt;denchmark-link:https://github.com/EnricoMi&gt;@EnricoMi&lt;/denchmark-link&gt;

Thanks for reporting this out, I was aware of this issue sometime ago and got sidetracked. This happens when a model is trained on Linux OS which defaults to snappy compression and windows counterpart doesn't provide native libraries for such.
Any solutions or workarounds welcome. We could re-train models without snappy as a workaround.
		</comment>
		<comment id='2' author='EnricoMi' date='2018-11-05T17:04:21Z'>
		The very same Spark code on Windows is able to write parquet files with Snappy compression, so some Snappy implementation seems to be available.
However, providing models trained on Windows would be an easy fix to this.
		</comment>
		<comment id='3' author='EnricoMi' date='2019-07-11T03:27:22Z'>
		Is it fixed, can I download models trained on windows now? If yes, please share some references for the same.
		</comment>
		<comment id='4' author='EnricoMi' date='2019-07-11T07:42:57Z'>
		Yes, this happens automatically in latest versions (2.0.9). But in case for offline downloading:
&lt;denchmark-link:https://nlp.johnsnowlabs.com/docs/en/models&gt;https://nlp.johnsnowlabs.com/docs/en/models&lt;/denchmark-link&gt;

The ones with _contrib are for unix-based OS only.
		</comment>
	</comments>
</bug>