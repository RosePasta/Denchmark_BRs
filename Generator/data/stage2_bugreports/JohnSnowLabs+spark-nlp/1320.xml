<bug id='1320' author='Thijsvandepoll' open_date='2020-12-15T14:44:58Z' closed_time='2020-12-15T17:26:01Z'>
	<summary>Loading EmbeddingsFinisher in Pipeline not working in python.</summary>
	<description>
When saving and loading a pipeline including EmbeddingsFinisher in python, the following exception is thrown:
&lt;denchmark-code&gt;AttributeError: module 'sparknlp' has no attribute 'EmbeddingsFinisher'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

It should be possible to save the pipeline to disk and reload the entire Pipeline into memory. This is now not possible when using EmbeddingsFinisher. Would be great if this is fixed such that no workaround is necessary.
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

Loading an entire pipeline including the transformer EmbeddingsFinisher should be available.
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

The line
&lt;denchmark-code&gt;PipelineModel.load("./path/to/saved/pipeline")
&lt;/denchmark-code&gt;

results in
&lt;denchmark-code&gt;AttributeError: module 'sparknlp' has no attribute 'EmbeddingsFinisher'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

Import of sparknlp.base is missing.
&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
# Start spark session
spark = sparknlp.start()

# Create sample dataframe
data = spark.createDataFrame([
    (1, "This is the first example sentence."),
    (2, "This is another example sentence.")
], schema=["id", "text"])

# Create document assembler
document_assembler = DocumentAssembler(). \
    setInputCol("text"). \
    setOutputCol("document")

# Create universal sentence decoder
use = UniversalSentenceEncoder.pretrained(). \
    setInputCols("document"). \
    setOutputCol("embedding")

# Create embedding finisher
finisher = EmbeddingsFinisher(). \
    setInputCols(["embedding"]). \
    setOutputCols("finished"). \
    setOutputAsVector(True). \
    setCleanAnnotations(True)

# Create pipeline
pipe = Pipeline(stages=[
    document_assembler,
    use,
    finisher
])

# Create pipeline model
model = pipe.fit(data)

# Save model
model.write().overwrite().save("./test_model")

# Load model
loaded_model = PipelineModel.load("./test_model")
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

Now I have to use a workaround, i.e. create a PySpark ML custom transformer.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Spark NLP version: 2.6.4
Java version (java -version): 1.8.0_202
Setup and installation (Pypi, Conda, Maven, etc.): pip install pyspark==2.4.4 sparknlp==2.6.4
Operating System and version: macOS Catalina 10.15.7

	</description>
	<comments>
		<comment id='1' author='Thijsvandepoll' date='2020-12-15T17:33:17Z'>
		AttributeError: module 'sparknlp' has no attribute 'EmbeddingsFinisher is fixed in 2.6.5 release. Please re-open if there is still an issue.
		</comment>
	</comments>
</bug>