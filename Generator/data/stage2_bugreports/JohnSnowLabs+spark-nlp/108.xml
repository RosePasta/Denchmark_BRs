<bug id='108' author='lorenz-nlp' open_date='2018-02-20T17:15:45Z' closed_time='2018-08-22T17:14:04Z'>
	<summary>SentenceDetector replaces "ö" with "?"</summary>
	<description>
The SentenceDetector is applied on German texts. If an "ö" occurs, it is replaced by "?".  However, if other German special characters (such as ä,ü,ß) occur, the SentenceDetector performs as it should, and does not replace them by a question mark.
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The SentenceDetector should not change the text within its annotation.
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

The SentenceDetector replaces "ö" by "?".
&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;



Run the test-case:
sentenceDetector.txt


Show the transformed dataframe:
output.txt
The token of question is the second one within the second row.


&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

Subsequent annotators perform worse, for example a lemma cannot be found if the token was changed.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Version used: 1.4.0

	</description>
	<comments>
		<comment id='1' author='lorenz-nlp' date='2018-04-15T22:01:15Z'>
		I believe this was fixed in 1.4.0 after tokenizer became language agnostic. This is implicitly solved. Added test in PR to make sure this is so: &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/165&gt;#165&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='lorenz-nlp' date='2018-06-12T14:28:36Z'>
		Reopening issue. I just found by chance the mysterious reason for this issue, which implicitly caused other issues in some scenarios. Will be fixing in 1.5.5
		</comment>
		<comment id='3' author='lorenz-nlp' date='2018-06-12T14:44:46Z'>
		Fixed in &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/221&gt;#221&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>