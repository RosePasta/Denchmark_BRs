<bug id='277' author='apiltamang' open_date='2018-10-10T15:26:01Z' closed_time='2019-09-28T15:58:27Z'>
	<summary>Cannot call NerDLModel.pretrained() on a Windows Instance</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Downloaded the stock spark ver 2.3.1 with precompiled hadoop-7 in a Windows Server 2016. Started the spark-shell with dependency on spark-nlp 1.6.2. Then attempted to load the pretrained NerDL Model in the shell.
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The pretrained model should load just fine.
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

The load fails with the following stacktrace:
&lt;denchmark-code&gt;scala&gt; import com.johnsnowlabs.nlp.annotator._
import com.johnsnowlabs.nlp.annotator._

scala&gt; var ner = NerDLModel.pretrained().setInputCols("token","sentence").setOutputCol("pos")
2018-10-10 15:14:13 WARN  SparkSession$Builder:66 - Using an existing SparkSession; some configuration may not take effect.
java.net.URISyntaxException: Illegal character in opaque part at index 2: C:\Users\ADMINI~1\AppData\Local\Temp\2\d11ea9104f4f_idx6658578913357900011
  at java.net.URI$Parser.fail(Unknown Source)
  at java.net.URI$Parser.checkChars(Unknown Source)
  at java.net.URI$Parser.parse(Unknown Source)
  at java.net.URI.&lt;init&gt;(Unknown Source)
  at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.copyIndexToCluster(SparkWordEmbeddings.scala:78)
  at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.apply(SparkWordEmbeddings.scala:118)
  at com.johnsnowlabs.nlp.HasWordEmbeddings$class.deserializeEmbeddings(HasWordEmbeddings.scala:61)
  at com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel.deserializeEmbeddings(NerDLModel.scala:19)
  at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$class.readEmbeddings(EmbeddingsReadable.scala:8)
  at com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel$.readEmbeddings(NerDLModel.scala:122)
  at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11)
  at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11)
  at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead$1.apply(ParamsAndFeaturesReadable.scala:31)
  at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead$1.apply(ParamsAndFeaturesReadable.scala:30)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$class.com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead(ParamsAndFeaturesReadable.scala:30)
  at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$read$1.apply(ParamsAndFeaturesReadable.scala:41)
  at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$read$1.apply(ParamsAndFeaturesReadable.scala:41)
  at com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:19)
  at com.johnsnowlabs.nlp.FeaturesReader.load(ParamsAndFeaturesReadable.scala:8)
  at com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:108)
  at com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:102)
  at com.johnsnowlabs.nlp.annotators.ner.dl.PretrainedNerDL$class.pretrained(NerDLModel.scala:118)
  at com.johnsnowlabs.nlp.annotator$NerDLModel$.pretrained(annotator.scala:95)
  ... 51 elided
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

Someone else at my team suggested a potential fix:
&lt;denchmark-code&gt;   private def copyIndexToCluster(localFile: String, clusterFilePath: String, spark: SparkContext): String = {
-    val uri = new java.net.URI(localFile)
+    logger.info(s"Reading from path ${localFile}")
+    val uri = new File(localFile).toURI
     val fs = FileSystem.get(uri, spark.hadoopConfiguration)
&lt;/denchmark-code&gt;

but that resulted in an error at a deeper level in the stack. Specifically RocksDB now err out with the following error (Note that the paths are different because the stacktrace below is an attempt to run from the above patch on a different runtime instance):
&lt;denchmark-code&gt; Failed to open NewSequentialFilefile:/C:/Users/Administrator/Downloads/fusion.tar/fusion/4.2.0-SNAPSHOT/var/api/spark/spark-workDir-1539114041719/spark-5acd6d60-ef80-433c-902a-b668d71ab891/userFiles-e7dc48b0-1844-4ea3-b2da-ed8da9cdc91c/embeddingsdbfbf3296071_idx6439565287253175663_work//CURRENT: The system cannot find the path specified. at org.rocksdb.RocksDB.openROnly(Native Method) at 
org.rocksdb.RocksDB.openReadOnly(RocksDB.java:366) at
 org.rocksdb.RocksDB.openReadOnly(RocksDB.java:315) at 
com.johnsnowlabs.nlp.embeddings.WordEmbeddings.&lt;init&gt;(WordEmbeddings.scala:14) at 
com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings.wordEmbeddings(SparkWordEmbeddings.scala:36) at 
com.johnsnowlabs.nlp.HasWordEmbeddings$$anonfun$embeddings$1.apply(HasWordEmbeddings.scala:39) at 
com.johnsnowlabs.nlp.HasWordEmbeddings$$anonfun$embeddings$1.apply(HasWordEmbeddings.scala:35) at scala.Option.map(Option.scala:146) at 
com.johnsnowlabs.nlp.HasWordEmbeddings$class.embeddings(HasWordEmbeddings.scala:35) at 
com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel.embeddings(NerDLModel.scala:19) at 
com.johnsnowlabs.nlp.AnnotatorModel.transform(AnnotatorModel.scala:57) at 
org.apache.spark.ml.PipelineModel$$anonfun$transform$1.apply(Pipeline.scala:306) at 
org.apache.spark.ml.PipelineModel$$anonfun$transform$1.apply(Pipeline.scala:306) at 
scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:57) at 
scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:66) at 
scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:186) at 
org.apache.spark.ml.PipelineModel.transform(Pipeline.scala:306) at transform(&lt;console&gt;:82) at 
$anonfun$1.apply(&lt;console&gt;:64) at $anonfun$1.apply(&lt;console&gt;:64) at 
com.lucidworks.spark.job.sql.SparkSQLLoader$.runLoadSave(SparkSQLLoader.scala:176) at 
com.lucidworks.spark.job.sql.SparkSQLLoader$.runLoaderJob(SparkSQLLoader.scala:150) ... 86 
elided &lt;console&gt;:55: error: not found: value output println(SparkSQLLoader.debug)

&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;


Download and install stock spark 2.3.1 w/ hadoop-7
Start spark-shell with dependency to spark-nlp 1.6..2
Attempt to load the NerDLPretrained model
Note it fails.

&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

We depend on spark-nlp to do some internal text processing application. The existence of the above bug is quite critical as it precludes us from potentially releasing a new version of our product.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Version used: Spark-NLP 1.6.2/1.6.3
Browser Name and version:
Operating System and version (desktop or mobile): Windows 2016 Server
Link to your project:

	</description>
	<comments>
		<comment id='1' author='apiltamang' date='2018-10-18T18:47:32Z'>
		1.7.0 included the uri fix, can you confirm it now works?
		</comment>
		<comment id='2' author='apiltamang' date='2019-09-28T15:58:27Z'>
		closing for inactivity.
		</comment>
	</comments>
</bug>