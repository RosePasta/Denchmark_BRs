<bug id='245' author='ashu122' open_date='2018-07-18T07:56:34Z' closed_time='2019-07-10T07:26:15Z'>
	<summary>Error while loading model files</summary>
	<description>
I am unable to load model files from local and from s3 in my spark application which i trained using NerCrfModel.
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

While trying to load the model files from local directory and from s3 this is what I am getting.
Exception in thread "main" org.apache.spark.SparkException: addFile does not support local directories when not running local mode. at org.apache.spark.SparkContext.addFile(SparkContext.scala:1537) at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.copyIndexToCluster(SparkWordEmbeddings.scala:86) at com.johnsnowlabs.nlp.embeddings.SparkWordEmbeddings$.apply(SparkWordEmbeddings.scala:111) at com.johnsnowlabs.nlp.HasWordEmbeddings$class.deserializeEmbeddings(HasWordEmbeddings.scala:57) at com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfModel.deserializeEmbeddings(NerCrfModel.scala:19) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$class.readEmbeddings(EmbeddingsReadable.scala:8) at com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfModel$.readEmbeddings(NerCrfModel.scala:84) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11) at com.johnsnowlabs.nlp.embeddings.EmbeddingsReadable$$anonfun$1.apply(EmbeddingsReadable.scala:11) at com.johnsnowlabs.nlp.ParamsAndFeaturesReadable$$anonfun$com$johnsnowlabs$nlp$ParamsAndFeaturesReadable$$onRead$1.apply(ParamsAndFeaturesReadable.scala:31) 
This is how i load the models  -
val model = PipelineModel.read.load("/opt/model/")
I have checked that the model files are present at this path on all the worker nodes. So it looks like the library is trying to call spark's addFile method which doesn't support local file directories in cluster or client mode.
Please let me know if you need more information.
Thanks.
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;







&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Version used:
Browser Name and version:
Operating System and version (desktop or mobile):
Link to your project:

	</description>
	<comments>
		<comment id='1' author='ashu122' date='2018-07-25T18:16:04Z'>
		Facing the same issue (on a 5-node cluster) with External, Validation and Test dataset in NerDLApproach. The path from pyspark.SparkFiles.get('train.txt') is already available on all workers, however, I get the error addFile does not support local directories when not running local mode.
		</comment>
		<comment id='2' author='ashu122' date='2018-08-09T18:22:53Z'>
		duplicate of &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/issues/247&gt;#247&lt;/denchmark-link&gt;

S3 is not providing configuration defaultFS which is needed by Spark-NLP in order to identify some place to put cluster folder
		</comment>
		<comment id='3' author='ashu122' date='2018-08-09T19:25:04Z'>
		It is probable we include in next release, an override setting for shared path for internal embeddings in an S3 framework. We'll include instructions on the website and github
		</comment>
		<comment id='4' author='ashu122' date='2018-08-09T21:25:47Z'>
		&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/257&gt;#257&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ashu122' date='2018-08-22T17:11:07Z'>
		Hi, please try this solution on the new releases
&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp#s3-cluster-with-no-hadoop-configuration&gt;https://github.com/JohnSnowLabs/spark-nlp#s3-cluster-with-no-hadoop-configuration&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>