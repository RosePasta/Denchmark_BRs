<bug id='85' author='sofianeh' open_date='2018-01-19T06:33:34Z' closed_time='2018-03-28T13:15:45Z'>
	<summary>Could not initialize class com.johnsnowlabs.nlp.util.io.ResourceHelper$ error with EntityExtractor().setEntitiesPath</summary>
	<description>
I receive this error when I try to use EntityExtractor() in a transformer in Python:
&lt;denchmark-code&gt;java.lang.NoClassDefFoundError: Could not initialize class com.johnsnowlabs.nlp.util.io.ResourceHelper$
	at com.johnsnowlabs.nlp.annotators.EntityExtractor$.retrieveEntityExtractorPhrases(EntityExtractor.scala:148)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor.loadEntities(EntityExtractor.scala:80)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor.getSearchTrie(EntityExtractor.scala:67)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor.com$johnsnowlabs$nlp$annotators$EntityExtractor$$search(EntityExtractor.scala:106)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor$$anonfun$annotate$1.apply(EntityExtractor.scala:133)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor$$anonfun$annotate$1.apply(EntityExtractor.scala:133)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at com.johnsnowlabs.nlp.annotators.EntityExtractor.annotate(EntityExtractor.scala:133)
	at com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:42)
	at com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:41)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:423)
	at org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:49)
	at org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:126)
	at org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:125)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:110)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:349)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;

I tested with v1.2.6
	</description>
	<comments>
		<comment id='1' author='sofianeh' date='2018-02-03T03:47:14Z'>
		The issue happens on multi-nodes spark clusters. It seems that python api cannot find dependencies within worker nodes.
		</comment>
		<comment id='2' author='sofianeh' date='2018-02-13T14:32:23Z'>
		&lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
 May I ask you:

Sample of code that reproduces that error?
What spark-nlp library version do you use? Do you use spark+yarn?

		</comment>
		<comment id='3' author='sofianeh' date='2018-02-13T14:45:09Z'>
		It is the same &lt;denchmark-link:https://github.com/sofianeh/databricks-examples/blob/master/python/SparkNLP-entityExtractor-example.py&gt;code example&lt;/denchmark-link&gt;
 I've mentionned in &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/issues/57&gt;Issue 57&lt;/denchmark-link&gt;
. The error occurs when I use a Databricks multi-node spark cluster. I've already contacted them and it looks like the spark-nlp library is trying to create another spark context within the &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/blob/2b3f340e6e14b70e8e71fdd9a9387ef8ea134591/src/main/scala/com/johnsnowlabs/nlp/util/io/ResourceHelper.scala#L31&gt;ResourceHelper.scala&lt;/denchmark-link&gt;
 code
		</comment>
		<comment id='4' author='sofianeh' date='2018-02-13T14:50:19Z'>
		@saifjsl Is it solved by 1.4? Can you help with it?
		</comment>
		<comment id='5' author='sofianeh' date='2018-02-15T14:43:15Z'>
		Hi &lt;denchmark-link:https://github.com/aleksei-ai&gt;@aleksei-ai&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
,
I was able to reproduce this problem too. It seems that as &lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
 mentioned, a spark context is being created in one of the executors, and as a result the class that contains the context cannot be instantiated.
I can fix this with a reorg of the code, as the code we need to run on the executors doesn't actually need the initialized spark context.
I can have a PR for today with this, but you will need to re-build in order to get the fix.
Alberto.
		</comment>
		<comment id='6' author='sofianeh' date='2018-02-15T16:46:15Z'>
		&lt;denchmark-link:https://github.com/albertoandreottiATgmail&gt;@albertoandreottiATgmail&lt;/denchmark-link&gt;
 Hi Alberto,

I can have a PR for today with this, but you will need to re-build in order to get the fix.
Yes, it will be great.

		</comment>
		<comment id='7' author='sofianeh' date='2018-02-15T19:51:23Z'>
		Hi guys,
after reviewing the new code and testing, I can confirm that this is no longer a bug in the current code base. So no PR from my side, although &lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
  you will need to change the way you instantiate the EntityExtractor, like this,
extractor = EntityExtractor()
.setEntities("/dbfs/myentities.txt")
.setInputCols(["normal", "sentence"])
.setOutputCol("entities")
Only thing you will need is a fresh .jar. I compiled one updated to the latest code,
&lt;denchmark-link:https://drive.google.com/file/d/1zlSP4aVn5Uj1dB_ub37QuMlnaxcY9ucw/view?usp=sharing&gt;https://drive.google.com/file/d/1zlSP4aVn5Uj1dB_ub37QuMlnaxcY9ucw/view?usp=sharing&lt;/denchmark-link&gt;

Let me know how it goes.
Alberto.
		</comment>
		<comment id='8' author='sofianeh' date='2018-02-20T19:30:24Z'>
		&lt;denchmark-link:https://github.com/albertoandreottiATgmail&gt;@albertoandreottiATgmail&lt;/denchmark-link&gt;
 I loaded your JAR and I now receive the following error:

Prefixing the filename with file:/// made it work though.
Also, when I try to use setEntitiesFormat('TXTDS') instead, I receive this error:
AttributeError: 'EntityExtractor' object has no attribute 'setEntitiesFormat'
Is the documentation off?
		</comment>
		<comment id='9' author='sofianeh' date='2018-02-20T20:24:46Z'>
		hi &lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
, the API has changed a bit, the setEntitiesFormat() method is gone, now you specify the format as a parameter to setEntities() method, example,
setEntities(self, path, read_as="LINE_BY_LINE", options={"format": "text"})
documentation is indeed outdated, and there's already a PR for it that should be merged in the following days.
		</comment>
		<comment id='10' author='sofianeh' date='2018-02-26T02:02:54Z'>
		&lt;denchmark-link:https://github.com/albertoandreottiATgmail&gt;@albertoandreottiATgmail&lt;/denchmark-link&gt;
 Are the changes in your JAR (from google drive) now included in the master branch?
		</comment>
		<comment id='11' author='sofianeh' date='2018-02-26T14:33:34Z'>
		HI &lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
, yes, it should work now with the jar coming from the new release. Please take a look and let me know if anything does not work as expected.
		</comment>
		<comment id='12' author='sofianeh' date='2018-03-28T13:15:45Z'>
		&lt;denchmark-link:https://github.com/sofianeh&gt;@sofianeh&lt;/denchmark-link&gt;
 I'm closing this issue. Please reopen if there is still a problem here.
		</comment>
	</comments>
</bug>