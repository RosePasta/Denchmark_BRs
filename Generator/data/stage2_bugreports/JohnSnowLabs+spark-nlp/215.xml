<bug id='215' author='ShixAJ' open_date='2018-05-22T15:56:35Z' closed_time='2018-11-23T11:39:59Z'>
	<summary>RecursivePipeline Error</summary>
	<description>
I was trying to train using RecursivePipeline and I got this error while doing fit:
Py4JJavaError                             Traceback (most recent call last)
~/Desktop/charles/workspace/spark2.30/python/pyspark/sql/utils.py in deco(*a, **kw)
62         try:
---&gt; 63             return f(*a, **kw)
64         except py4j.protocol.Py4JJavaError as e:
~/Desktop/charles/workspace/spark2.30/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
319                     "An error occurred while calling {0}{1}{2}.\n".
--&gt; 320                     format(target_id, ".", name), value)
321             else:
Py4JJavaError: An error occurred while calling o61.transform.
: org.apache.spark.sql.AnalysisException: Cannot resolve column name "ner" among (text, document, sentence, token, pos);
at org.apache.spark.sql.Dataset$$anonfun$resolve$1.apply(Dataset.scala:222)
at org.apache.spark.sql.Dataset$$anonfun$resolve$1.apply(Dataset.scala:222)
at scala.Option.getOrElse(Option.scala:121)
at org.apache.spark.sql.Dataset.resolve(Dataset.scala:221)
at org.apache.spark.sql.Dataset.col(Dataset.scala:1241)
at com.johnsnowlabs.nlp.Finisher$$anonfun$transform$2.apply(Finisher.scala:99)
at com.johnsnowlabs.nlp.Finisher$$anonfun$transform$2.apply(Finisher.scala:90)
at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
at com.johnsnowlabs.nlp.Finisher.transform(Finisher.scala:90)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.GatewayConnection.run(GatewayConnection.java:214)
at java.lang.Thread.run(Thread.java:748)
During handling of the above exception, another exception occurred:
AnalysisException                         Traceback (most recent call last)
 in ()
2 print("Start fitting")
3 # model = pipeline.fit(data)
----&gt; 4 pipeline.fit(spark.createDataFrame([['']]).toDF("text"))
5 print("Fitting is ended")
6 print (time.time() - start)
~/Desktop/charles/workspace/spark2.30/python/pyspark/ml/base.py in fit(self, dataset, params)
130                 return self.copy(params)._fit(dataset)
131             else:
--&gt; 132                 return self._fit(dataset)
133         else:
134             raise ValueError("Params must be either a param map or a list/tuple of param maps, "
/tmp/spark-c0b09f09-dbb0-4ae5-ae7c-0d59514961c7/userFiles-58adcfbe-c750-48cb-b85a-17d600b21b6e/JohnSnowLabs_spark-nlp-1.5.3.jar/sparknlp/base.py in _fit(self, dataset)
145             if isinstance(stage, Transformer):
146                 transformers.append(stage)
--&gt; 147                 dataset = stage.transform(dataset)
148             elif isinstance(stage, JavaRecursiveEstimator):
149                 model = stage.fit(dataset, pipeline=PipelineModel(transformers))
~/Desktop/charles/workspace/spark2.30/python/pyspark/ml/base.py in transform(self, dataset, params)
171                 return self.copy(params)._transform(dataset)
172             else:
--&gt; 173                 return self._transform(dataset)
174         else:
175             raise ValueError("Params must be a param map but got %s." % type(params))
~/Desktop/charles/workspace/spark2.30/python/pyspark/ml/wrapper.py in _transform(self, dataset)
303     def _transform(self, dataset):
304         self._transfer_params_to_java()
--&gt; 305         return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)
306
307
~/Desktop/charles/workspace/spark2.30/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py in call(self, *args)
1158         answer = self.gateway_client.send_command(command)
1159         return_value = get_return_value(
-&gt; 1160             answer, self.gateway_client, self.target_id, self.name)
1161
1162         for temp_arg in temp_args:
~/Desktop/charles/workspace/spark2.30/python/pyspark/sql/utils.py in deco(*a, **kw)
67                                              e.java_exception.getStackTrace()))
68             if s.startswith('org.apache.spark.sql.AnalysisException: '):
---&gt; 69                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)
70             if s.startswith('org.apache.spark.sql.catalyst.analysis'):
71                 raise AnalysisException(s.split(': ', 1)[1], stackTrace)
AnalysisException: 'Cannot resolve column name "ner" among (text, document, sentence, token, pos);'
The Pipeline code I am using is:
documentAssembler = DocumentAssembler()
.setInputCol("text")
.setOutputCol("document")
sentenceDetector = SentenceDetector()
.setInputCols(["document"])
.setOutputCol("sentence")
tokenizer = Tokenizer()
.setInputCols(["document"])
.setOutputCol("token")
posTagger = PerceptronApproach()
.setIterations(1)
.setInputCols(["token", "document"])
.setOutputCol("pos")
.setCorpus("file:///" + os.getcwd() + "/anc-pos-corpus-small/", "|")
nerTagger = NerCrfApproach()
.setInputCols(["sentence", "token", "pos"])
.setLabelColumn("label")
.setOutputCol("ner")
.setMinEpochs(1)
.setMaxEpochs(1)
.setLossEps(1e-3)
.setEmbeddingsSource("glove.6B.100d.txt", 100, 2)
.setExternalFeatures("file:///" + os.getcwd() + "/ner-corpus/dict.txt", ",")
.setExternalDataset("file:///" + os.getcwd() + "/ner2.train")
.setL2(1)
.setC0(1250000)
.setRandomSeed(0)
.setVerbose(2)
finisher = Finisher() 
.setInputCols(["ner"]) 
.setIncludeKeys(True)
pipeline = RecursivePipeline(
stages = [
documentAssembler,
sentenceDetector,
tokenizer,
posTagger,
nerTagger,
finisher
])
	</description>
	<comments>
		<comment id='1' author='ShixAJ' date='2018-05-28T11:44:51Z'>
		Thank you, will look into this asap.
		</comment>
		<comment id='2' author='ShixAJ' date='2018-08-22T17:13:26Z'>
		Hi, please confirm on 1.6.2
		</comment>
		<comment id='3' author='ShixAJ' date='2018-11-23T11:39:58Z'>
		Since there are 6 months without an answer and I replicated the code without issues in my environment.
		</comment>
		<comment id='4' author='ShixAJ' date='2019-11-20T17:51:26Z'>
		I was trying to use the Featurized Hasher function and received this error.
Py4JJavaError: An error occurred while calling o451.transform.
: org.apache.spark.sql.AnalysisException: cannot resolve
		</comment>
		<comment id='5' author='ShixAJ' date='2019-11-20T22:20:54Z'>
		It’s been a long time and many releases, could you please create a new issue with all the versions, code, and full error stack so we can reproduce it? Thank you
		</comment>
		<comment id='6' author='ShixAJ' date='2019-11-26T05:40:59Z'>
		The columns to be hashed cant have special characters (back ticks, colons, equal signs, etc) otherwise it causes this error. Seems like a strange error.


Anyways, I wrote a SPARK UDF with re.sub('\W+','', string ) and  it seemed to work.

Peace,
Eric

Sent from Mail&lt;&lt;denchmark-link:https://go.microsoft.com/fwlink/?LinkId=550986&gt;https://go.microsoft.com/fwlink/?LinkId=550986&lt;/denchmark-link&gt;
&gt; for Windows 10
		</comment>
		<comment id='7' author='ShixAJ' date='2019-11-27T03:08:04Z'>
		Correction. I think it is just the ‘.’ In the name that caused the error.

Sent from Mail&lt;&lt;denchmark-link:https://go.microsoft.com/fwlink/?LinkId=550986&gt;https://go.microsoft.com/fwlink/?LinkId=550986&lt;/denchmark-link&gt;
&gt; for Windows 10
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


________________________________
From: Maziyar Panahi &lt;notifications@github.com&gt;
Sent: Wednesday, November 20, 2019 3:20:54 PM
To: JohnSnowLabs/spark-nlp &lt;spark-nlp@noreply.github.com&gt;
Cc: Eric Wittry &lt;ewittry@hotmail.com&gt;; Comment &lt;comment@noreply.github.com&gt;
Subject: Re: [JohnSnowLabs/spark-nlp] RecursivePipeline Error (#215)


It’s been a long time and many releases, could you please create a new issue with all the versions, code, and full error stack so we can reproduce it? Thank you

—
You are receiving this because you commented.
Reply to this email directly, view it on GitHub&lt;https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FJohnSnowLabs%2Fspark-nlp%2Fissues%2F215%3Femail_source%3Dnotifications%26email_token%3DACUJA42MD5V2YU7EA4MW6JTQUWZ4NA5CNFSM4FBDXWR2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEEVS4GQ%23issuecomment-556477978&amp;data=02%7C01%7C%7C404fee7845bf47b507c608d76e07e96e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637098852563168919&amp;sdata=tK%2BcxeSER5PUfWaQ9WhqUtbadC3adWjlP4mJ9oJKN0A%3D&amp;reserved=0&gt;, or unsubscribe&lt;https://eur02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FACUJA457OSYG42O77RN7W5LQUWZ4NANCNFSM4FBDXWRQ&amp;data=02%7C01%7C%7C404fee7845bf47b507c608d76e07e96e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637098852563178930&amp;sdata=M%2FEIg29M9unjy06B7%2FgoYpRHytZH%2FucJ1LUxWxmV7Pc%3D&amp;reserved=0&gt;.

		</comment>
	</comments>
</bug>