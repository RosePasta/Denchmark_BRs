<bug id='807' author='maziyarpanahi' open_date='2020-03-03T15:05:40Z' closed_time='2020-03-17T13:07:13Z'>
	<summary>TokenAssembler results are not the same as Tokenized tokens</summary>
	<description>
The output of the TokenAssembler is expected to be the same sentence/tokens coming from Tokenizer if there are no other annotators involved such as normalizer, lemmatizer, stopWordsCleaner, etc.
val c = Seq((1, "I won 4 days ago. I think I should stop playing with you guys.")).toDF("Id", "Utterrance")
val documentAssembler = new DocumentAssembler()
  .setInputCol("Utterrance")
  
val vanillaTokenizer = new Tokenizer()
      .setInputCols("document")
      .setOutputCol("token")
      
val tokenAssembler = new TokenAssembler()
      .setInputCols(Array("token"))
      .setOutputCol("transformed_doc")

val sink = new Pipeline()
         .setStages(Array(documentAssembler, vanillaTokenizer, tokenAssembler))
         .fit(c)
         .transform(c)
         
sink.select("token.result").show(false)
sink.select("transformed_doc.result").show(false)   

+---------------------------------------------------------------------------------+
|result                                                                           |
+---------------------------------------------------------------------------------+
|[I, won, 4, days, ago, ., I, think, I, should, stop, playing, with, you, guys, .]|
+---------------------------------------------------------------------------------+

+------------------------------------------------------------------------------+
|result                                                                        |
+------------------------------------------------------------------------------+
|[guys, 4, . ., stop, I I I, you, think, ago, should, with, playing, won, days]|
+------------------------------------------------------------------------------+


Spark NLP 2.4.1
Spark 2.4.4
Scala 2.11.12
Mac OS Catalina 10.15.3

	</description>
	<comments>
		<comment id='1' author='maziyarpanahi' date='2020-03-17T13:07:13Z'>
		This been fixed in 2.4.4 release
		</comment>
	</comments>
</bug>