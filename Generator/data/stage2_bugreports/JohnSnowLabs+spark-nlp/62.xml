<bug id='62' author='zhangjinge588' open_date='2017-12-14T00:11:19Z' closed_time='2017-12-18T05:24:56Z'>
	<summary>wordCount from ResourceHelper doesn't return any value from Map[String, Int]</summary>
	<description>
When reading the corpus as "TXTDS" configured from the SpellChecker, the variable result has 0 Values (e.g. result.toSeq.length == 0). Please offer suggestion on how to retrieve this.
The code snippet is below: (starting at ResourceHelper.Scala:273)
&lt;denchmark-code&gt;case TXTDS =&gt;
        import spark.implicits._
        val dataset = spark.read.textFile(source)
        val wordCount = spark.sparkContext.broadcast(MMap.empty[String, Int].withDefaultValue(0))
        val documentAssembler = new DocumentAssembler()
          .setInputCol("value")
        val tokenizer = new RegexTokenizer()
          .setInputCols("document")
          .setOutputCol("token")
        val normalizer = new Normalizer()
          .setInputCols("token")
          .setOutputCol("normal")
        val finisher = new Finisher()
          .setInputCols("normal")
          .setOutputCols("finished")
          .setAnnotationSplitSymbol("--")
        new Pipeline()
          .setStages(Array(documentAssembler, tokenizer, normalizer, finisher))
          .fit(dataset)
          .transform(dataset)
          .select("finished").as[String]
          .foreach(text =&gt; text.split("--").foreach(t =&gt; {
            wordCount.value(t) += 1
          }))
        val result = wordCount.value
        wordCount.destroy()
        result
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='zhangjinge588' date='2017-12-15T12:44:39Z'>
		&lt;denchmark-link:https://github.com/zhangjinge588&gt;@zhangjinge588&lt;/denchmark-link&gt;


Do you use method .setCorpusPath(path)?
If "Yes", Do you read from local file, or spark-nlp jar resource file?

		</comment>
		<comment id='2' author='zhangjinge588' date='2017-12-18T05:24:56Z'>
		Hello &lt;denchmark-link:https://github.com/zhangjinge588&gt;@zhangjinge588&lt;/denchmark-link&gt;
, thank you for testing the library.
To confirm this works properly, I have added a unittest here: &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/67&gt;#67&lt;/denchmark-link&gt;

This shows TXTDS works normally. So perhaps there is an unclear instruction on how it works:
TXTDS tells the spellchecker to read training corpus using a Spark Dataset. This is useful when the training corpus may be large and distributed (and/or hosted in Hadoop).
A code example snippet would be the following, which as Aleksei pointed out, it is required to provide a path to the text file location:
&lt;denchmark-code&gt;    val spellChecker = new NorvigSweetingApproach()
      .setInputCols(Array("tokenized"))
      .setOutputCol("spell")
      **.setCorpusPath("./src/test/resources/spell/sherlockholmes.txt")**
      **.setCorpusFormat("TXTDS")**
    spellChecker.fit(dataset)
&lt;/denchmark-code&gt;

Make sure you provide as corpus path a file which contains english text useful for the spell checker to learn from. You can also take a look at unit tests or python notebooks for more examples.
If this does not help, please reopen the issue with further more specific instructions on the issue you are having and how to reproduce it. Also, try reading such text file with normal "TXT" mode first and verify it works. Result should be the same if using the same textfile.
Best
		</comment>
	</comments>
</bug>