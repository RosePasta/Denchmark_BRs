<bug id='210' author='VincentRoma' open_date='2018-05-17T09:55:39Z' closed_time='2018-07-20T18:45:33Z'>
	<summary>Pretrained Model not working due to missing Amazon dependencies</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When running a pretrained model such as shown in the documentation, an error occurs due to com.amazonaws.services.s3 dependencies missing.
I've been trying to use this lib in a Spark Streaming job, but after trying to debug the dependency issue, I try running the simple exemple from the documention, and I'm getting this error using spark 1.6 or spark 2.2
&lt;denchmark-code&gt;scala&gt; import spark.implicits._
import spark.implicits._

scala&gt; import com.johnsnowlabs.nlp.pretrained.pipelines.en.BasicPipeline
import com.johnsnowlabs.nlp.pretrained.pipelines.en.BasicPipeline

scala&gt; val data = Seq("hello, this is an example sentence").toDF("mainColumn")
data: org.apache.spark.sql.DataFrame = [mainColumn: string]

scala&gt; BasicPipeline().annotate(data, "mainColumn").show()
java.lang.NoSuchMethodError: com.amazonaws.services.s3.S3ClientOptions.builder()Lcom/amazonaws/services/s3/S3ClientOptions$Builder;
  at com.amazonaws.services.s3.AmazonS3Builder.resolveS3ClientOptions(AmazonS3Builder.java:404)
  at com.amazonaws.services.s3.AmazonS3ClientBuilder.build(AmazonS3ClientBuilder.java:64)
  at com.amazonaws.services.s3.AmazonS3ClientBuilder.build(AmazonS3ClientBuilder.java:28)
  at com.amazonaws.client.builder.AwsSyncClientBuilder.build(AwsSyncClientBuilder.java:46)
  at com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.client$lzycompute(S3ResourceDownloader.scala:47)
  at com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.client(S3ResourceDownloader.scala:35)
  at com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.downloadMetadataIfNeed(S3ResourceDownloader.scala:62)
  at com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.resolveLink(S3ResourceDownloader.scala:73)
  at com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader.download(S3ResourceDownloader.scala:85)
  at com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadResource(ResourceDownloader.scala:91)
  at com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadPipeline(ResourceDownloader.scala:123)
  at com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadPipeline(ResourceDownloader.scala:118)
  at com.johnsnowlabs.nlp.pretrained.pipelines.PretrainedPipeline.modelCache$lzycompute(PretrainedPipeline.scala:11)
  at com.johnsnowlabs.nlp.pretrained.pipelines.PretrainedPipeline.modelCache(PretrainedPipeline.scala:10)
  at com.johnsnowlabs.nlp.pretrained.pipelines.PretrainedPipeline.annotate(PretrainedPipeline.scala:14)
  ... 50 elided
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;


run a spark-shell
spark-shell --packages JohnSnowLabs:spark-nlp:1.5.3
run documentation exemple:

&lt;denchmark-code&gt;import spark.implicits._
import com.johnsnowlabs.nlp.pretrained.pipelines.en.BasicPipeline
val data = Seq("hello, this is an example sentence").toDF("mainColumn")
BasicPipeline().annotate(data, "mainColumn").show()
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

Running on a CDH Cluster (EDH 5.11, Cloudera Certified) with Spark 1.6.1 &amp; Spark 2.2.0
	</description>
	<comments>
		<comment id='1' author='VincentRoma' date='2018-05-17T13:22:32Z'>
		&lt;denchmark-link:https://github.com/VincentRoma&gt;@VincentRoma&lt;/denchmark-link&gt;
 , we will look into this and let you know. Thanks for reporting.
		</comment>
		<comment id='2' author='VincentRoma' date='2018-05-31T17:21:56Z'>
		I'm  having the same issue.
		</comment>
		<comment id='3' author='VincentRoma' date='2018-05-31T17:26:28Z'>
		&lt;denchmark-link:https://github.com/haimco10&gt;@haimco10&lt;/denchmark-link&gt;
 thanks for reporting your situation. Are you also on CDH?
		</comment>
		<comment id='4' author='VincentRoma' date='2018-05-31T18:34:26Z'>
		Same issue.
Spark Standalone on OVH.
		</comment>
		<comment id='5' author='VincentRoma' date='2018-05-31T22:51:15Z'>
		Hi all, I will try to reproduce the issue and will let you know my findings
		</comment>
		<comment id='6' author='VincentRoma' date='2018-06-01T06:07:01Z'>
		I have reached out Cloudera to work together into solving this issue with CDH/CDSW.
&lt;denchmark-link:https://github.com/GreGGus&gt;@GreGGus&lt;/denchmark-link&gt;
 Can you point us to OVH website? I am not sure I heard of it.
		</comment>
		<comment id='7' author='VincentRoma' date='2018-06-01T07:25:59Z'>
		Hi @saifjsl, thanks for looking this up.
OVH is an european IAAS provider (&lt;denchmark-link:http://www.ovh.com&gt;www.ovh.com&lt;/denchmark-link&gt;
) that why &lt;denchmark-link:https://github.com/GreGGus&gt;@GreGGus&lt;/denchmark-link&gt;
 having the same issue would demonstrate that's it's not linked to Cloudera maybe...
		</comment>
		<comment id='8' author='VincentRoma' date='2018-06-03T12:57:24Z'>
		&lt;denchmark-link:https://github.com/albertoandreottiATgmail&gt;@albertoandreottiATgmail&lt;/denchmark-link&gt;
 . Yes, I'm also on CDH.
		</comment>
		<comment id='9' author='VincentRoma' date='2018-06-07T22:22:33Z'>
		@saifjsl, I made some test using a Spark standalone 2.2.0 on the same cluster and it's working. I now assume something is wrong with the spark2.2.0.cloudera1 version, I'm opening a ticket to Cloudera Support. I'll let you know
		</comment>
		<comment id='10' author='VincentRoma' date='2018-06-13T15:04:27Z'>
		Hi all, if anyone can build this PR and test it on Cloudera to confirm it's resolved
&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/222&gt;#222&lt;/denchmark-link&gt;

It's a proposal fix by rolling back AWS dependencies by &lt;denchmark-link:https://github.com/apiltamang&gt;@apiltamang&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='VincentRoma' date='2018-06-26T19:00:08Z'>
		BTW, pretrained model example from docs also required internet connection (to download model probably). This is not obvious. Is it possible to download models for offline work?
		</comment>
		<comment id='12' author='VincentRoma' date='2018-07-20T18:45:33Z'>
		Released.
&lt;denchmark-link:https://github.com/sshikov&gt;@sshikov&lt;/denchmark-link&gt;
 there is no way to do that now. But once you download them once through the API, you may have access to cache folder and may be able to read the models offline directly pointing to the path.
Cache folder by default is located in $HOME/cache_pretrained
		</comment>
		<comment id='13' author='VincentRoma' date='2018-07-20T19:51:04Z'>
		Thanks. What if I download it myself and manually put into cache_pretrained?
		</comment>
		<comment id='14' author='VincentRoma' date='2018-07-23T07:13:35Z'>
		@saifjsl Thank you, I want to download POS models all trained text files folder (for example, small pos trained tags &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/resources/anc-pos-corpus-small&gt;https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/resources/anc-pos-corpus-small&lt;/denchmark-link&gt;
) As per my knowledge which you have uploaded in amazon s3 server I don't know how to access it and also about the privilege it is private or public So how can I access it?
		</comment>
		<comment id='15' author='VincentRoma' date='2018-07-23T18:18:18Z'>
		It is public. I may have access to give you some links to download them offline. Lets continue on Slack to do so.
		</comment>
	</comments>
</bug>