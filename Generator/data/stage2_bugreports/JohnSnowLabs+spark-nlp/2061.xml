<bug id='2061' author='dlopes78' open_date='2021-01-05T00:30:11Z' closed_time='2021-01-08T23:00:19Z'>
	<summary>can't save classifierDL in spark-nlp 2.7 on Databricks runtime 6.5ML</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Saving pipeline for classifierDL was working in spark-nlp 2.6.5 but not in spark-nlp 2.7.0
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

regression issue, was working in 2.6.5
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

org.tensorflow.TensorFlowException: not an sstable (bad magic number)
&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;

val documentAssembler = new DocumentAssembler()
.setInputCol("text")
.setOutputCol("document")
val token = new Tokenizer()
.setInputCols("document")
.setOutputCol("token")
val embeddings = WordEmbeddingsModel.pretrained()
.setInputCols("document", "token")
.setOutputCol("embeddings")
val sentence_embeddings = new SentenceEmbeddings()
.setInputCols("document", "embeddings")
.setOutputCol("sentence_embeddings")
.setPoolingStrategy("AVERAGE")
val docClassifier = new ClassifierDLApproach()
.setInputCols("sentence_embeddings")
.setOutputCol("class")
.setLabelColumn("label")
.setMaxEpochs(30)
.setLr(5e-3f)
.setDropout(0.5f)
val pipeline = new Pipeline()
.setStages(
Array(
documentAssembler,
token,
embeddings,
sentence_embeddings,
docClassifier
)
)
val pipelineModel = pipeline.fit(trainDataset)
pipelineModel.write.overwrite().save("....file_path...")
&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

2.6.5 had an existing issue where classifierDL model saved and the loaded back was giving issues, &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/issues/973&gt;#973&lt;/denchmark-link&gt;
. Was testing if it got fixed in 2.7.0 but now can't save the model in the first place.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

Databricks runtime 6.5ML
	</description>
	<comments>
		<comment id='1' author='dlopes78' date='2021-01-05T07:30:38Z'>
		Hi,
could you please paste the full error when you are trying to save? Also, what is the exact path? (dbfs or FileStore)
		</comment>
		<comment id='2' author='dlopes78' date='2021-01-05T09:29:05Z'>
		I can confirm this issue. The release fixed the issue of training classifiers in the clusters and immediately using them without any drop in their accuracy, but introduced an issue with saving them on Databricks local storage file.
I'll add this to be fixed in the next hot-fix release.
		</comment>
		<comment id='3' author='dlopes78' date='2021-01-05T15:57:09Z'>
		&lt;denchmark-link:https://github.com/dlopes78&gt;@dlopes78&lt;/denchmark-link&gt;
 I have a Fat JAR which can be installed easily on Databricks (drag and drop) to test a fix for this issue. Please let me know if you are interested in participating.

The PyPI package will be the same
Uninstall the Maven package of Spark NLP
restart the cluster to be sure it is removed
upload the JAR via the UI in libraries
restart again
and just test it

The tests passed on both Databricks AWS and Azure, but it's hard to pin point it down. It would be great if you can test it on your cluster as well. (the 6.5 was deprecated so I had to test on 6.4)
		</comment>
		<comment id='4' author='dlopes78' date='2021-01-05T16:45:26Z'>
		&lt;denchmark-link:https://github.com/maziyarpanahi&gt;@maziyarpanahi&lt;/denchmark-link&gt;
 I'm happy to test, let me know how I can help.
		</comment>
		<comment id='5' author='dlopes78' date='2021-01-05T16:47:52Z'>
		&lt;denchmark-link:https://github.com/maziyarpanahi&gt;@maziyarpanahi&lt;/denchmark-link&gt;
  I also noticed that I can't run inference on the model just trained (so without saving it) - while it was working in 2.6.5:
val testDataset = spark.createDataFrame(Seq(
(0, "some text")
)).toDF("id", "text")
val prediction = pipelineModel.transform(testDataset)
display(prediction)
SparkException: Failed to execute user defined function($anonfun$dfAnnotate$1: (array&lt;array&lt;struct&lt;annotatorType:string,begin:int,end:int,result:string,metadata:map&lt;string,string&gt;,embeddings:array&gt;&gt;&gt;) =&gt; array&lt;struct&lt;annotatorType:string,begin:int,end:int,result:string,metadata:map&lt;string,string&gt;,embeddings:array&gt;&gt;)
.....
Caused by: org.tensorflow.TensorFlowException: not an sstable (bad magic number)
[[{{node save/RestoreV2}}]]
at org.tensorflow.Session.run(Native Method)
		</comment>
		<comment id='6' author='dlopes78' date='2021-01-05T16:54:28Z'>
		Yes, that is the issue in 2.7.0:
Here is the Fat JAR, you can follow those steps and making sure the Fat JAR is being used and not the Maven package:
&lt;denchmark-link:https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-tf-fix20.jar&gt;https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/spark-nlp-tf-fix20.jar&lt;/denchmark-link&gt;

Keep in mind, with this you cannot use the models trained in previous versions, what should work is as follow:

train a new ClassifierDL
use it right after without any accuracy drop
being able to save the ClassifierDL
load it back in a pipeline agin

		</comment>
		<comment id='7' author='dlopes78' date='2021-01-05T18:09:46Z'>
		&lt;denchmark-link:https://github.com/maziyarpanahi&gt;@maziyarpanahi&lt;/denchmark-link&gt;
 I tested the Jar and the issue seems to be solved:
--train a model
-- test model and accuracy is correct
-- save and reload the model
--  use reloaded model
Thanks for the quick reply!
		</comment>
		<comment id='8' author='dlopes78' date='2021-01-05T19:11:54Z'>
		That's great, since the JAR you have is actually a 2.7.0 release with this fix please go ahead and use it, please. I would like to be sure it doesn't come back since Databricks behave differently on local storage from time to time.
		</comment>
		<comment id='9' author='dlopes78' date='2021-01-08T23:00:19Z'>
		This should be resolved in the 2.7.1 release &lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.1&gt;https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.1&lt;/denchmark-link&gt;

Please re-open if the issue persists.
		</comment>
	</comments>
</bug>