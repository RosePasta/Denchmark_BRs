<bug id='299' author='EnricoMi' open_date='2018-11-02T14:00:18Z' closed_time='2018-11-15T21:11:37Z'>
	<summary>Using a NER model throws NoSuchElementException / SparkException</summary>
	<description>
Using a pre-trained Crf or DL NER Model with a DataFrame having multiple partitions fails with a NoSuchElementException and SparkException: Failed to get broadcast_6_piece0 of broadcast_6.
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When tagging a DataFrame using a pre-trained Crf (ner_fast_en_1.7.0_2_1539896043754) or DL (ner_precise_en_1.7.0_2_1539623388047) NER model in cluster mode, I get this exception:
&lt;denchmark-code&gt;java.util.NoSuchElementException: 60
...
Caused By: `org.apache.spark.SparkException: Failed to get broadcast_6_piece0 of broadcast_6
...
&lt;/denchmark-code&gt;

This works perfectly fine in local mode or in cluster mode with a DataFrame having a single partition.
&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The DataFrame should be tagged without an exception.
&lt;denchmark-h:h2&gt;Current Behavior&lt;/denchmark-h&gt;

An exception is thrown.
&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Steps to Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import spark.implicits._

import com.johnsnowlabs.nlp.annotator.{NerCrfModel, NerDLModel, SentenceDetector}
import org.apache.spark.ml.{Pipeline, PipelineModel}

val data = Seq("Here is some text.").toDF("text")

val basicPipeline = PipelineModel.read.load("/home/user/cache_pretrained/pipeline_basic_en_1.6.1_2_1533856444797")
val sentence = new SentenceDetector().setOutputCol("sentence")
val ner = NerCrfModel.read.load("/home/user/cache_pretrained/ner_fast_en_1.7.0_2_1539896043754")
//val ner = NerDLModel.read.load("/home/user/cache_pretrained/ner_precise_en_1.7.0_2_1539623388047")
val pipeline = new Pipeline().setStages(Array(basicPipeline, sentence, ner))
pipeline.fit(Seq.empty[String].toDF("text")).transform(data).show(false)  // this works just fine, even in cluster mode
pipeline.fit(Seq.empty[String].toDF("text")).transform(data.repartition(100)).show(false)  // this fails in cluster mode
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Context&lt;/denchmark-h&gt;

I simply want to use any pre-trained NER model for NER tagging.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Spark: 2.3.0
Spark-NLP: 1.7.2
NER Model: Crf (ner_fast_en_1.7.0_2_1539896043754) or DL (ner_precise_en_1.7.0_2_1539623388047)

	</description>
	<comments>
		<comment id='1' author='EnricoMi' date='2018-11-05T13:29:53Z'>
		Thank you, I am investigating the issue. Sounds to be introduced in 1.7.x.
		</comment>
		<comment id='2' author='EnricoMi' date='2018-11-11T22:17:36Z'>
		&lt;denchmark-link:https://github.com/JohnSnowLabs/spark-nlp/pull/303&gt;#303&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='EnricoMi' date='2018-11-15T21:06:08Z'>
		I can confirm that this is fixed for me. Great work, thanks!
		</comment>
	</comments>
</bug>