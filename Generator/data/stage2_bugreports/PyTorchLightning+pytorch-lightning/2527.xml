<bug id='2527' author='pableeto' open_date='2020-07-06T10:34:59Z' closed_time='2020-07-27T16:53:12Z'>
	<summary>checkpoint save dir is not correctly set when _save_dir is given by wandb logger</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When using ModelCheckpoint with default parameter and Wandb Logger with save_dir set to some dir,
The checkpoint is still dumped to os.getcwd()
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

........
logger = WandbLogger(save_dir='/path/to/experiment')
trainer = Trainer.from_argparse_args(other_args, logger = logger)
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The checkpoint should be saved under /path/to/experiment defined by Wandb logger's save_dir argument.
&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

The pl version i am use is by pip install, i.e. 0.8.4
I think the problem is related to the logic in on_train_start() function in model_checkpoint.py,
&lt;denchmark-code&gt;        if trainer.logger is not None:
            # weights_save_path overrides anything
            if getattr(trainer, 'weights_save_path', None) is not None:
                save_dir = trainer.weights_save_path
            else:
                save_dir = (getattr(trainer.logger, 'save_dir', None)
                            or getattr(trainer.logger, '_save_dir', None)
                            or trainer.default_root_dir)

&lt;/denchmark-code&gt;

Unfortunately, the default of "weights_save_path" is not None; it is set to default_root_dir which is os.getcwd() (See pytorch_lightning/trainer/callback_config.py, line 57):
&lt;denchmark-code&gt;        # if weights_save_path is still none here, set to current working dir
        if self.weights_save_path is None:
            self.weights_save_path = self.default_root_dir
&lt;/denchmark-code&gt;

Thus, the ckpt_path is always set to weights_save_path instead of save_dir from logger.
&lt;denchmark-h:h3&gt;Fix&lt;/denchmark-h&gt;

A quick patch for this might be as follows:
&lt;denchmark-code&gt;        if trainer.logger is not None:
            # weights_save_path overrides anything
            # unless if it is os.getcwd() and we have a logger set its save_dir to other folder
            weights_save_path = getattr(trainer, 'weights_save_path', None)
            loggers_save_path = (getattr(trainer.logger, 'save_dir', None)
                            or getattr(trainer.logger, '_save_dir', None)
                            or trainer.default_root_dir)
            avoid_weights_save_path = (weight_save_path == trainer.default_root_dir and loggers_save_path != trainer.default_root_dir)

            if (weights_save_path is not None and not avoid_weights_save_path):
                save_dir = weights_save_path
            else:
                save_dir = loggers_save_path

&lt;/denchmark-code&gt;

I would be happy to fork the code and submit a PR, btw.
	</description>
	<comments>
		<comment id='1' author='pableeto' date='2020-07-06T13:44:16Z'>
		&lt;denchmark-link:https://github.com/pableeto&gt;@pableeto&lt;/denchmark-link&gt;
 I don't think we want to make this part of the code even more complicated.
Wouldn't the real fix be to remove this if block here:


I think it is a left-over from a recent refactor.
		</comment>
		<comment id='2' author='pableeto' date='2020-07-06T14:45:21Z'>
		Well, I guess that would be fine :)
Not sure if remove that block will cause other issues, though.
		</comment>
		<comment id='3' author='pableeto' date='2020-07-06T15:20:22Z'>
		
@pableeto I don't think we want to make this part of the code even more complicated.
Wouldn't the real fix be to remove this if block here:



pytorch-lightning/pytorch_lightning/trainer/callback_config.py


         Line 57
      in
      25ee51b






 if self.weights_save_path is None: 





I think it is a left-over from a recent refactor.

I just found if we remove this block, then it will made the pipeline crush at line 391 of pytorch_lightning/trainer/training_io.py:
&lt;denchmark-code&gt;        folderpath = self.weights_save_path              # This will become None, next line will crush
        if os.path.exists(folderpath):
            files = os.listdir(folderpath)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='pableeto' date='2020-07-10T00:45:36Z'>
		&lt;denchmark-link:https://github.com/pableeto&gt;@pableeto&lt;/denchmark-link&gt;
 try:
&lt;denchmark-code&gt;pip install pytorch-lightning==0.8.5rc1
&lt;/denchmark-code&gt;

We can re-open if it is not fixed
		</comment>
		<comment id='5' author='pableeto' date='2020-07-15T07:59:11Z'>
		
@pableeto try:
pip install pytorch-lightning==0.8.5rc1

We can re-open if it is not fixed

&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 Just tried 0.8.5rc1, problem still exists.
		</comment>
		<comment id='6' author='pableeto' date='2020-07-26T17:56:44Z'>
		Fixed here &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2681&gt;#2681&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>