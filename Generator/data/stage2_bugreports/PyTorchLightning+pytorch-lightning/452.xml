<bug id='452' author='dreamgonfly' open_date='2019-11-03T13:54:04Z' closed_time='2019-11-05T13:55:45Z'>
	<summary>min_max log_gpu_memory option bug</summary>
	<description>
Describe the bug
Setting log_gpu_memory='min_max' in Trainer leads to the following bug.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 347, in fit
    self.single_gpu_train(model)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/dp_mixin.py", line 79, in single_gpu_train
    self.run_pretrain_routine(model)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 467, in run_pretrain_routine
    self.train()
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/train_loop_mixin.py", line 60, in train
    self.run_training_epoch()
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/train_loop_mixin.py", line 126, in run_training_epoch
    self.log_metrics(batch_step_metrics, grad_norm_dic)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/logging_mixin.py", line 20, in log_metrics
    mem_map = memory.get_memory_profile(self.log_gpu_memory)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/root_module/memory.py", line 205, in get_memory_profile
    for k, v in memory_map:
ValueError: too many values to unpack (expected 2)
&lt;/denchmark-code&gt;

To Reproduce
On current master, execute the following.
&lt;denchmark-code&gt;    trainer = Trainer(
        ...
        log_gpu_memory='min_max',
        ...
    )
    trainer.fit(model)
&lt;/denchmark-code&gt;

Expected behavior
Log the min/max utilization of gpu memory, as min_max option is documented.
Desktop (please complete the following information):

OS: Ubuntu 18.04
Version: Current master

I am working on this issue. Will submit a PR soon.
	</description>
	<comments>
	</comments>
</bug>