<bug id='4853' author='apacha' open_date='2020-11-25T15:56:20Z' closed_time='2020-12-07T15:11:08Z'>
	<summary>Reduce missing in DDP's training/validation_step_end</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

TLDR: validation_step_end does not aggregate the results when using DDP backend for evaluating on the entire dataset, instead of the individual splits.
The full description can be found in this SO question: &lt;denchmark-link:https://stackoverflow.com/q/64499294/448357&gt;https://stackoverflow.com/q/64499294/448357&lt;/denchmark-link&gt;

It seems that the respective code might have been forgotten, as it can be found both in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/404af43cde6696d04bb1899da2bb7e334e49716d/pytorch_lightning/accelerators/dp_accelerator.py#L140&gt;DP accelerator&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/404af43cde6696d04bb1899da2bb7e334e49716d/pytorch_lightning/accelerators/ddp2_accelerator.py#L90&gt;DDP2 accelerator&lt;/denchmark-link&gt;
, but not in the &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_accelerator.py#L47&gt;DDP accelerator&lt;/denchmark-link&gt;
.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Run training with DDP backend
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

One call after each epoch with the aggregated results in validation_step_end.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version (e.g., 1.0): 1.0.8
OS (e.g., Linux): Ubuntu
How you installed PyTorch (conda, pip, source): pip
Python version: 3.8
GPU models and configuration: 2xNvidia 1080Ti

	</description>
	<comments>
		<comment id='1' author='apacha' date='2020-11-25T15:57:08Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='apacha' date='2020-12-04T16:48:13Z'>
		Dear &lt;denchmark-link:https://github.com/apacha&gt;@apacha&lt;/denchmark-link&gt;
,
Thanks for using Lightning. Reduction is supported only on training_step, validation_step, test_step.
The right way to use it.
&lt;denchmark-code&gt;def training_step(...):
  .....

  return something

def training_step_end(all_something_across_ddp):
  ....
&lt;/denchmark-code&gt;

Should be adapted for test and validation. I hope it helps.
Best regards,
Thomas Chaton.
		</comment>
		<comment id='3' author='apacha' date='2020-12-06T22:10:42Z'>
		Am I missing something? I've stated that I am indeed using training_step_end and validation_step_end as you indicated, but I am NOT getting all_something_across_ddp but instead just the share that was assigned to a single GPU. This happens only when I'm using DDP accelerator, but works as expected with DDP2 and DP backends. Is this really how it was intended to work? And if so, why?
		</comment>
		<comment id='4' author='apacha' date='2020-12-07T13:30:18Z'>
		Hey &lt;denchmark-link:https://github.com/apacha&gt;@apacha&lt;/denchmark-link&gt;
,
Let me try it out on my side as it should work.
Best regards,
Thomas Chaton.
		</comment>
		<comment id='5' author='apacha' date='2020-12-07T15:11:08Z'>
		validation_step_end is ONLY for DP and DDP2...
It's meant to aggregate parts of the batch. In DDP there are no parts of the batch because each process runs on its own GPU.
# dp
num_gpus = 4
batch_parts = split_batch(batch, num_gpus)
model_copies = copy(model, num_gpus)

all_batch_outs = []
for batch in data:
    # run 1 batch
    batch_outs = []
    for model, batch_part in zip(model_copies, batch_parts):
        subbatch_out = model.validation_step(batch_part)
        batch_outs.append(subbatch_out)

    reduced = validation_step_end(batch_outs)
    all_batch_outs.append(reduced)

validation_epoch_end(all_batch_outs)
The documentation has videos that explain all this
		</comment>
		<comment id='6' author='apacha' date='2020-12-07T17:37:05Z'>
		May I ask what you would recommend me to do? I have to use DDP because the other backends are creating issues in my (hardware) environment. My problem is that validation only ever sees 1/4th of my validation set when training on four GPUs. But I would like to evaluate on the complete validation set. At least I thought that validation_step_end's intention was exactly that, but maybe I'm wrong.
I'll summarize: I want to run validation on all results from all GPUs to obtain aggregated statistics. How would I do that with the DDP backend?
I read through the &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/stable/multi_gpu.html&gt;documentation&lt;/denchmark-link&gt;
 and watched your video again, but I could not find any answer to that question. That's why I also posted it on Stackoverflow, where I also got the feedback, that I should used .
		</comment>
		<comment id='7' author='apacha' date='2020-12-10T12:49:53Z'>
		Hey &lt;denchmark-link:https://github.com/apacha&gt;@apacha&lt;/denchmark-link&gt;
,
There is 2 options.

You could create a metric using our Metric API which will take care of the reduction across DDP (recommended).
In 1.1.0, we introduced a self.gather function in the LightningModule to enable this use case.
Here is the function: 


pytorch-lightning/pytorch_lightning/core/lightning.py


         Line 368
      in
      4ebce38






 def all_gather(self, tensor: Union[torch.Tensor], group: Optional[Any] = None, sync_grads: bool = False): 






Best regards,
T.C
		</comment>
		<comment id='8' author='apacha' date='2020-12-11T12:11:42Z'>
		Hi! May I ask how to use the second option with self.all_gather? I wish to gather all validation results after an epoch and average across them, and to do this I have naively tried
&lt;denchmark-code&gt;    def validation_epoch_end(self, validation_step_outputs):
        self.all_gather(validation_step_outputs)
        self.log('val_metric', sum(validation_step_outputs)/ len(validation_step_outputs),  prog_bar = True)
&lt;/denchmark-code&gt;

But this does not work. I wonder how to properly use self.all_gather in this case?

Hey @apacha,
There is 2 options.
1. You could create a metric using our Metric API which will take care of the reduction across DDP (recommended).

2. In 1.1.0, we introduced a self.gather function in the LightningModule to enable this use case.
   Here is the function: https://github.com/PyTorchLightning/pytorch-lightning/blob/4ebce38478f28c70edc2c7236c514665df105217/pytorch_lightning/core/lightning.py#L368

Best regards,
T.C

		</comment>
		<comment id='9' author='apacha' date='2020-12-11T14:33:01Z'>
		&lt;denchmark-link:https://github.com/apacha&gt;@apacha&lt;/denchmark-link&gt;
 May I ask if you have solved this problem in the end? I met the exactly same problem for ddp.
		</comment>
		<comment id='10' author='apacha' date='2020-12-11T16:42:00Z'>
		No, I haven't solved it yet. That's why I created this ticket. Once I have time, I will try the Metric API approach
		</comment>
		<comment id='11' author='apacha' date='2020-12-24T09:34:24Z'>
		&lt;denchmark-link:https://github.com/apacha&gt;@apacha&lt;/denchmark-link&gt;

Execute me.
May I ask if it have solved this problem in the end? I met the same problem for ddp, too.
Have other solution or ideas?
		</comment>
	</comments>
</bug>