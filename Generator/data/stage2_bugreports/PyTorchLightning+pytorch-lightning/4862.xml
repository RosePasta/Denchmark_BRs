<bug id='4862' author='fire717' open_date='2020-11-26T02:11:42Z' closed_time='2020-11-26T03:27:10Z'>
	<summary>Training loss not convergence</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Running the example code below,  at my pc , the loss not change:
Epoch 29:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 800/1875 [00:04&lt;00:05, 189.48it/s, loss=1.483, v_num=87]
as u see, even at epoch29, the loss is around 1.5.
code:
`import os
import torch
from torch.nn import functional as F
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
from torchvision import transforms
import pytorch_lightning as pl
class MNISTModel(pl.LightningModule):
&lt;denchmark-code&gt;def __init__(self):
    super(MNISTModel, self).__init__()
    self.l1 = torch.nn.Linear(28 * 28, 10)

def forward(self, x):
    return torch.relu(self.l1(x.view(x.size(0), -1)))

def training_step(self, batch, batch_nb):
    x, y = batch
    loss = F.cross_entropy(self(x), y)
    tensorboard_logs = {'train_loss': loss}
    return {'loss': loss, 'log': tensorboard_logs}

def configure_optimizers(self):
    return torch.optim.Adam(self.parameters(), lr=0.02)
&lt;/denchmark-code&gt;

train_loader = DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)
mnist_model = MNISTModel()
trainer = pl.Trainer(gpus=1, progress_bar_refresh_rate=20)
trainer.fit(mnist_model, train_loader)  `
&lt;denchmark-h:h2&gt;Please reproduce using [the BoringModel and post here]&lt;/denchmark-h&gt;

Here comes the strange thing, with , I running at the colab,
(&lt;denchmark-link:https://colab.research.google.com/drive/1rPmzscbE4tCo7k8pj7FQJxck3JcM-Zx8?usp=sharing&gt;https://colab.research.google.com/drive/1rPmzscbE4tCo7k8pj7FQJxck3JcM-Zx8?usp=sharing&lt;/denchmark-link&gt;
)
Got this
Epoch 1: 77% 1440/1875 [00:06&lt;00:01, 230.34it/s, loss=0.669, v_num=0]
Even at epoch 1, I got loss = 0.669!
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Colab:&lt;denchmark-link:https://colab.research.google.com/drive/1rPmzscbE4tCo7k8pj7FQJxck3JcM-Zx8?usp=sharing&gt;https://colab.research.google.com/drive/1rPmzscbE4tCo7k8pj7FQJxck3JcM-Zx8?usp=sharing&lt;/denchmark-link&gt;

my local pc maybe you cannot Reach
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Colab and my pc get Same behavior , in other words,  my pc loss should convergence.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version (e.g., 1.0): 1.6.0
OS (e.g., Linux): Linux
How you installed PyTorch (conda, pip, source):   pip
Python version: 3.7.4
CUDA/cuDNN version: 10.1
GPU models and configuration:   Gforce1060 (1080ti also get loss around 1.5 all the time.)
Any other relevant information:

	</description>
	<comments>
		<comment id='1' author='fire717' date='2020-11-26T03:27:10Z'>
		change to pytoch-lightning 1.0.0  there is no problem. (use 1.0.8 before)
		</comment>
	</comments>
</bug>