<bug id='1037' author='erinkim1' open_date='2020-03-03T21:48:24Z' closed_time='2020-03-05T14:31:24Z'>
	<summary>ReduceLROnPlateau does not work with multiple schedulers</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

PL seems to only pull one ReduceLROnPlateau to call it the reduce_lr_on_plateau_scheduler
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

One example would be adding two ReduceLROnPlateau schedulers to the GAN example.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

All ReduceLROnPlateau should be recognized as such.
A natural solution might be to check if a scheduler is an instance of ReduceLROnPlateau for each scheduler in the loop that runs lr_scheduler.step(), instead of having a separate self.reduce_lr_on_plateau_scheduler
	</description>
	<comments>
		<comment id='1' author='erinkim1' date='2020-03-03T21:54:51Z'>
		Good catch!
mind submitting a PR?
		</comment>
		<comment id='2' author='erinkim1' date='2020-03-04T09:04:17Z'>
		If PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/941&gt;#941&lt;/denchmark-link&gt;
 is merged, it will also solve this problem
		</comment>
		<comment id='3' author='erinkim1' date='2020-03-04T09:50:58Z'>
		@darwinkim &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 pls coordinate your effort &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/941&gt;#941&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1039&gt;#1039&lt;/denchmark-link&gt;
 so none of your work gets wasted... ;] maybe make &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1039&gt;#1039&lt;/denchmark-link&gt;
 as followup of &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/941&gt;#941&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='4' author='erinkim1' date='2020-03-04T16:01:28Z'>
		&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/941&gt;#941&lt;/denchmark-link&gt;
 seems to solve it, and adds many related features
		</comment>
		<comment id='5' author='erinkim1' date='2020-03-05T14:01:32Z'>
		With &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/941&gt;#941&lt;/denchmark-link&gt;
 being merged now, this can be closed
		</comment>
		<comment id='6' author='erinkim1' date='2020-06-27T16:29:14Z'>
		I'm not sure if this is solved. I just tried 2 schedulers with 1 optimizer and it didn't work.
When I remove my linear scheduler, ReduceLROnPlateau starts to work again.
		</comment>
		<comment id='7' author='erinkim1' date='2020-06-27T18:49:00Z'>
		&lt;denchmark-link:https://github.com/Laksh1997&gt;@Laksh1997&lt;/denchmark-link&gt;
 could you provide more info:which version of lightning are you using, what does your configure optimizer looks like?
		</comment>
		<comment id='8' author='erinkim1' date='2020-06-27T18:57:50Z'>
		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;

Latest stable (0.8.1)
Using ReduceLROnPlateau at the epoch level and a linear warmup on the step level:
&lt;denchmark-code&gt;import torch


class LinearWarmupScheduler(torch.optim.lr_scheduler.LambdaLR):
    def __init__(
        self, optimizer: torch.optim.Optimizer, num_warmup_steps: int = 1000,
    ):
        assert num_warmup_steps &gt; 0
        super().__init__(optimizer, lambda step: min(step / num_warmup_steps, 1.0))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='erinkim1' date='2020-06-27T19:35:57Z'>
		Okay, but what does configure_optimizers method of your model look like?
		</comment>
		<comment id='10' author='erinkim1' date='2020-06-27T20:22:43Z'>
		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;

It returns the following:
&lt;denchmark-code&gt;[torch.optim.Adam(self.parameters(), lr=0.01)], [{"scheduler": ReduceLROnPlateau(...), "interval": "epoch"}, {"scheduler": LinearWarmupScheduler(...), "interval": "step"}]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='erinkim1' date='2020-06-27T20:29:35Z'>
		Here is my code more specifically:
def build_scheduler_params(scheduler_name, param_set, optimizer: Optimizer):
    """Parses scheduler params"""
    pl_scheduler_params = {
        "monitor": param_set.pop("monitor", "val_loss"),
        "interval": param_set.pop("interval", "epoch"),
        "frequency": param_set.pop("frequency", 1),
    }
    if hasattr(torch.optim.lr_scheduler, scheduler_name):
        scheduler_class = getattr(torch.optim.lr_scheduler, scheduler_name)
        scheduler = scheduler_class(optimizer, **param_set)
    elif hasattr(lr_schedulers, scheduler_name):
        scheduler_class = getattr(lr_schedulers, scheduler_name)
        scheduler = scheduler_class(optimizer, **param_set)
    else:
        raise ValueError(
            f"Scheduler: {scheduler_name} not available. "
            f"Schedulers available are: {get_available_schedulers()}"
        )
    pl_scheduler_params["scheduler"] = scheduler
    return pl_scheduler_params


def build_optimizer(model: nn.Module, config) -&gt; Optimizer:
    """Makes optimizer from model and config"""
    optim_kwargs = copy.deepcopy(config.optimizer_kwargs)
    optim_class = get_optim_class(config.optimizer)
    optim_param_groups = build_optim_param_groups(model, optim_kwargs)
    check_valid_param_groups(optim_param_groups, model)
    if isinstance(optim_kwargs, list):
        optim_kwargs = optim_kwargs[0]
    optimizer = optim_class(optim_param_groups, **optim_kwargs)
    return optimizer


def build_schedulers(optimizer: Optimizer, config):
    """Makes schedulers from optimizer and config"""
    schedulers = []
    schedulers_names = config.schedulers
    schedulers_kwargs = config.schedulers_kwargs

    assert len(schedulers_names) == len(schedulers_kwargs), (
        f"Need to have as many schedulers as scheduler param sets! "
        f"Got {len(schedulers_names)} of schedulers and "
        f"{len(schedulers_kwargs)} of scheduler param sets!"
    )
    if schedulers_names is not None:
        for scheduler_name, param_set in zip(schedulers_names, schedulers_kwargs):
            pl_scheduler_params = build_scheduler_params(
                scheduler_name, param_set, optimizer
            )
            schedulers.append(pl_scheduler_params)
    return schedulers


def configure_optimizers(model: nn.Module, config) -&gt; PL_EXPECTED_OUTPUT:
    """Configures PL optimizers and schedulers"""
    optimizer = build_optimizer(model, config)
    schedulers = build_schedulers(optimizer, config)
    return [optimizer], schedulers
		</comment>
		<comment id='12' author='erinkim1' date='2020-06-29T12:58:42Z'>
		&lt;denchmark-link:https://github.com/Laksh1997&gt;@Laksh1997&lt;/denchmark-link&gt;
 I do not really see a problem in your code. After experimenting around with  scheduler in combination with other schedulers, I don't think the there is a problem in lightning either as I can get multiple schedulers to work at the same time.
My best guess is that this is specific to your model/data. When you have two optimizers, and one is changing the learning rate every step it is very possible that you do not reach a plateau, such that the ReduceLROnPlateau scheduler never kicks in.
		</comment>
	</comments>
</bug>