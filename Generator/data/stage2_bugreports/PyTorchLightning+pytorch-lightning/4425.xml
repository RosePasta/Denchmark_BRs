<bug id='4425' author='jonas-ricker' open_date='2020-10-29T11:07:40Z' closed_time='2020-11-17T12:27:06Z'>
	<summary>Initializing Trainer fails if default_root_dir is SFTP address</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I'm using MLFlow as a logger and an SFTP Server as artifact store. However, with Trainer(default_root_dir="sftp://something") the following error occurs:
/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py in __init__(self, logger, checkpoint_callback, early_stop_callback, callbacks, default_root_dir, gradient_clip_val, process_position, num_nodes, num_processes, gpus, auto_select_gpus, tpu_cores, log_gpu_memory, progress_bar_refresh_rate, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, limit_train_batches, limit_val_batches, limit_test_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, distributed_backend, sync_batchnorm, precision, weights_summary, weights_save_path, num_sanity_val_steps, truncated_bptt_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, terminate_on_nan, auto_scale_batch_size, prepare_data_per_node, cluster_environment, amp_backend, amp_level, overfit_pct, log_save_interval, row_log_interval)
    375 
    376         # init logger flags
--&gt; 377         self.logger_connector.on_trainer_init(logger, flush_logs_every_n_steps, log_every_n_steps)
    378 
    379         # init debugging flags

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector.py in on_trainer_init(self, logger, flush_logs_every_n_steps, log_every_n_steps)
     37     def on_trainer_init(self, logger, flush_logs_every_n_steps, log_every_n_steps):
     38         # logging
---&gt; 39         self.configure_logger(logger)
     40         # todo: IDE is complaining, these shall be initialized in the Trainer init at leas as placeholders
     41         #  and assign here the desired value

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/logger_connector.py in configure_logger(self, logger)
     49             # default logger
     50             self.trainer.logger = TensorBoardLogger(
---&gt; 51                 save_dir=self.trainer.default_root_dir,
     52                 version=version,
     53                 name='lightning_logs'

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/properties.py in default_root_dir(self)
    156         It is used as a fallback if logger or checkpoint callback do not define specific save paths.
    157         """
--&gt; 158         if get_filesystem(self._default_root_dir).protocol == "file":
    159             return os.path.normpath(self._default_root_dir)
    160         return self._default_root_dir

/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/cloud_io.py in get_filesystem(path)
     37     if "://" in path:
     38         # use the fileystem from the protocol specified
---&gt; 39         return fsspec.filesystem(path.split(":", 1)[0])
     40     else:
     41         # use local filesystem

/usr/local/lib/python3.6/dist-packages/fsspec/registry.py in filesystem(protocol, **storage_options)
    233     """
    234     cls = get_filesystem_class(protocol)
--&gt; 235     return cls(**storage_options)

/usr/local/lib/python3.6/dist-packages/fsspec/spec.py in __call__(cls, *args, **kwargs)
     56             return cls._cache[token]
     57         else:
---&gt; 58             obj = super().__call__(*args, **kwargs)
     59             # Setting _fs_token here causes some static linters to complain.
     60             obj._fs_token_ = token

TypeError: __init__() missing 1 required positional argument: 'host'
&lt;denchmark-h:h2&gt;Please reproduce using the BoringModel and post here&lt;/denchmark-h&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1otdJrf2INa7277tH8iimInS6WWcC2M26?usp=sharing&gt;https://colab.research.google.com/drive/1otdJrf2INa7277tH8iimInS6WWcC2M26?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Checkpoints being sent to the SFTP Server and being available in the MLFlow UI.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:

Tesla T4


available:         True
version:           10.1


Packages:

numpy:             1.18.5
pyTorch_debug:     False
pyTorch_version:   1.6.0+cu101
pytorch-lightning: 0.10.0
tqdm:              4.41.1


System:

OS:                Linux
architecture:

64bit



processor:         x86_64
python:            3.6.9
version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

I assume that this could by fixed by extending  in cloud_io.py to parse the host and pass it to  s.t. it can be understood by &lt;denchmark-link:https://filesystem-spec.readthedocs.io/en/latest/_modules/fsspec/implementations/sftp.html&gt;SFTPFileSystem&lt;/denchmark-link&gt;

EDIT: After thinking it through, I'm afraid fixing this won't make the checkpoint saving to MLFlow perfect, as the checkpoints would be located in artifacts/&lt;experiment_id&gt;/&lt;run_id&gt;/checkpoints ... or am I missing something?
	</description>
	<comments>
		<comment id='1' author='jonas-ricker' date='2020-10-29T11:08:24Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
	</comments>
</bug>