<bug id='1901' author='xing1999' open_date='2020-05-20T11:49:11Z' closed_time='2020-05-20T13:33:55Z'>
	<summary>Bug in Early stopping and `check_val_every_n_epoch`</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Install PyTorch and PyTorch-Lightning
Cloning master branch
Edit the example by removing these lines
In the same place, add

early_stop = pl.callbacks.EarlyStopping(monitor="val_loss", patience=3, mode="min")
trainer = pl.Trainer(
     max_epochs=hparams.epochs,
     gpus=hparams.gpus,
     distributed_backend=hparams.distributed_backend,
     precision=16 if hparams.use_16bit else 32,
     check_val_every_n_epoch=2,
     early_stop_callback=early_stop,
)

Re-run the example with  python gpu_template.py --gpus 1

Error message:
&lt;denchmark-code&gt;RuntimeError: Early stopping conditioned on metric `val_loss` which is not available. Either add `val_loss` to the return of  validation_epoch end or modify your EarlyStopping callback to use any of the following: `loss`, `train_loss`
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

No error ü§£  .  Or at least the error still appears when removing the early_stop_callback parameters ü§£
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Please copy and paste the output from our
&lt;denchmark-link:https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py&gt;environment collection script&lt;/denchmark-link&gt;

(or fill out the checklist below manually).
You can get the script and run it with:
&lt;denchmark-code&gt;wget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py
# For security purposes, please check the contents of collect_env.py before running it.
python collect_env.py
&lt;/denchmark-code&gt;


PyTorch Version (e.g., 1.0): 1.4.0
OS (e.g., Linux): Linux
How you installed PyTorch (conda, pip, source): conda
Build command you used (if compiling from source):
Python version: 3.6
CUDA/cuDNN version: 9.2
PyTorch-Lightning Version: 0.7.6

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

I have also try to set check_val_every_n_epoch to 1, no error appears.
	</description>
	<comments>
		<comment id='1' author='xing1999' date='2020-05-20T11:49:49Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
	</comments>
</bug>