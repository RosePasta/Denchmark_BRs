<bug id='3006' author='pchandra90' open_date='2020-08-16T16:18:50Z' closed_time='2020-10-01T11:00:43Z'>
	<summary>Accuracy metrics: In the case of all class indices of a target tensor is 0, throwing error.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;version: 0.9.0rc12&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

from pytorch_lightning.metrics.functional import accuracy

pred = torch.tensor([0, 1, 2, 3])
target = torch.tensor([0, 0, 0, 0])

# calculates accuracy across all GPUs and all Nodes used in training
accuracy(pred, target)
&lt;denchmark-h:h3&gt;RuntimeError&lt;/denchmark-h&gt;

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-16-5d9063513e76&gt; in &lt;module&gt;
      5 
      6 # calculates accuracy across all GPUs and all Nodes used in training
----&gt; 7 accuracy(pred, target)

~/anaconda3/envs/pl/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py in accuracy(pred, target, num_classes, reduction)
    268     """
    269     if not (target &gt; 0).any() and num_classes is None:
--&gt; 270         raise RuntimeError("cannot infer num_classes when target is all zero")
    271 
    272     tps, fps, tns, fns, sups = stat_scores_multiple_classes(

RuntimeError: cannot infer num_classes when target is all zero
&lt;denchmark-h:h3&gt;Expected output&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;tensor(0.2500)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='pchandra90' date='2020-08-16T16:19:29Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='pchandra90' date='2020-08-16T17:22:57Z'>
		&lt;denchmark-link:https://github.com/justusschock&gt;@justusschock&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 This is a recurring confusion, we got asked about this several times now. Do we need to change the behavior here, or add a note/warning to the docs?
In sklearn for example, there is no such error and it returns 0.25
		</comment>
		<comment id='3' author='pchandra90' date='2020-08-16T17:25:42Z'>
		We can think about that. I just thought that for just one class, most metrics either aren't well defined or aren't descriptive.
Thoughts &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='4' author='pchandra90' date='2020-08-16T17:31:06Z'>
		another option would be to convert it to a warning instead of error.
		</comment>
		<comment id='5' author='pchandra90' date='2020-08-16T17:36:07Z'>
		We should probably change it. With so many people being confused about, I think it is a strong indicator that we are not doing what people expect, and we risk that people will not use the metrics if they are counter-intuitive.
		</comment>
		<comment id='6' author='pchandra90' date='2020-08-16T17:59:59Z'>
		In one batch, a single class scenario is common in the case of validation dataset without shuffling.
Even after passing the number of classes argument, it's throwing a warning.
		</comment>
		<comment id='7' author='pchandra90' date='2020-09-15T17:39:27Z'>
		&lt;denchmark-link:https://github.com/pchandra90&gt;@pchandra90&lt;/denchmark-link&gt;
 is this still an actual issue, mind test master? 
		</comment>
		<comment id='8' author='pchandra90' date='2020-09-15T18:51:22Z'>
		still raises an error, should be changed to a simple warning. &lt;denchmark-link:https://github.com/pchandra90&gt;@pchandra90&lt;/denchmark-link&gt;
 interested in sending a PR?
		</comment>
		<comment id='9' author='pchandra90' date='2020-09-16T05:15:50Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
, Tested the master, there is no change in the issue status. 
import pytorch_lightning as pl
import torch

from pytorch_lightning.metrics.functional import accuracy

print('PyTorch Lightning Version: {}'.format(pl.__version__))

pred = torch.tensor([0, 1, 2, 3])
target = torch.tensor([0, 0, 0, 0])

print('Is the num_classes argument specified: No')
accuracy(pred, target)
RuntimeError:
PyTorch Lightning Version: 0.9.1rc3
Is the num_classes argument specified: No
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-1-2c64fef4d70c&gt; in &lt;module&gt;
     10 
     11 print('Is the num_classes argument specified: No')
---&gt; 12 accuracy(pred, target)

~/anaconda3/envs/pl_dev/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py in accuracy(pred, target, num_classes, class_reduction)
    268     """
    269     if not (target &gt; 0).any() and num_classes is None:
--&gt; 270         raise RuntimeError("cannot infer num_classes when target is all zero")
    271 
    272     tps, fps, tns, fns, sups = stat_scores_multiple_classes(

RuntimeError: cannot infer num_classes when target is all zero
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

import pytorch_lightning as pl
import torch

from pytorch_lightning.metrics.functional import accuracy

print('PyTorch Lightning Version: {}'.format(pl.__version__))

pred = torch.tensor([0, 1, 2, 3])
target = torch.tensor([0, 0, 0, 0])

print('Is the num_classes argument specified: Yes')
accuracy(pred, target, num_classes=10)
Output with the warning:
PyTorch Lightning Version: 0.9.1rc3
Is the num_classes argument specified: Yes
/home/prakash/anaconda3/envs/pl_dev/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning: You have set 10 number of classes if different from predicted (4) and target (1) number of classes
  warnings.warn(*args, **kwargs)
tensor(0.2500)
&lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
 , Yes, I can send PR to fix the issue. However, can not do it before the weekend.
		</comment>
	</comments>
</bug>