<bug id='2670' author='BeHappyForMe' open_date='2020-07-22T09:40:31Z' closed_time='2020-08-03T22:29:52Z'>
	<summary>bug in pytorch_lightning.metrics.functional.auroc</summary>
	<description>
the code:
&lt;denchmark-code&gt;def validation_epoch_end(self, outputs):
        .........
        print(total_y_hat.device)
        print(total_y_true.device)
        print(total_y_hat)
        print(total_y_true)
        print(total_y_hat.shape)
        print(total_y_true.shape)
        auc_score = auroc(total_y_hat, total_y_true)
&lt;/denchmark-code&gt;

the output is:
&lt;denchmark-code&gt;Get data done!
Validation sanity check:  50%|█████     | 1/2 [00:00&lt;00:00,  1.06it/s]

cuda:0
cuda:0
tensor([0.5084, 0.5084, 0.5084,  ..., 0.5084, 0.5084, 0.5084], device='cuda:0')
tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
torch.Size([16384])
torch.Size([16384])
Traceback (most recent call last):
  File "lighting_sales.py", line 443, in &lt;module&gt;
    main(hparams)
  File "lighting_sales.py", line 392, in main
    trainer.fit(model)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in fit
    self.single_gpu_train(model)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py", line 176, in single_gpu_train
    self.run_pretrain_routine(model)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1076, in run_pretrain_routine
    False)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 330, in _evaluate
    eval_results = model.validation_epoch_end(outputs)
  File "lighting_sales.py", line 252, in validation_epoch_end
    auc_score = auroc(total_y_hat, total_y_true)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py", line 817, in auroc
    return _auroc(pred=pred, target=target, sample_weight=sample_weight, pos_label=pos_label)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py", line 766, in new_func
    x, y = func_to_decorate(*args, **kwargs)[:2]
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py", line 815, in _auroc
    return roc(pred, target, sample_weight, pos_label)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py", line 553, in roc
    pos_label=pos_label)
  File "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/metrics/functional/classification.py", line 504, in _binary_clf_curve
    torch.tensor([target.size(0) - 1])])
RuntimeError: All input tensors must be on the same device. Received cuda:0 and cpu
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='BeHappyForMe' date='2020-07-22T09:41:24Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='BeHappyForMe' date='2020-07-22T11:19:04Z'>
		That bug is fixed on master. See &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2657&gt;#2657&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='BeHappyForMe' date='2020-07-22T11:27:49Z'>
		thank u very much
		</comment>
		<comment id='4' author='BeHappyForMe' date='2020-07-22T20:31:02Z'>
		Does it work with master branch? If not, do you use the functional or module interface for the metric?
		</comment>
		<comment id='5' author='BeHappyForMe' date='2020-08-03T22:29:51Z'>
		&lt;denchmark-link:https://github.com/BeHappyForMe&gt;@BeHappyForMe&lt;/denchmark-link&gt;
 I'm closing this but please open if still experiencing this with master.
		</comment>
	</comments>
</bug>