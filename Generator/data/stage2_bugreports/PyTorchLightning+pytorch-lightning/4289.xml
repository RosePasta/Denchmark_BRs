<bug id='4289' author='PiotrJander' open_date='2020-10-21T15:49:34Z' closed_time='2020-10-22T09:36:01Z'>
	<summary>Dataloader crashes if num_worker&amp;gt;0 on MacOS with Python 3.8</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When using a DataLoader with num_workers &gt; 0, the process crashes with a stack trace which contains
&lt;denchmark-code&gt;...
RuntimeError:
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.
...
RuntimeError: DataLoader worker (pid 88201) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
...
&lt;/denchmark-code&gt;

The full stack trace is here: &lt;denchmark-link:https://gist.github.com/PiotrJander/e82ca1d94ae85e746f33a18d7ca2d492&gt;https://gist.github.com/PiotrJander/e82ca1d94ae85e746f33a18d7ca2d492&lt;/denchmark-link&gt;

The error does not occur when num_workers is set to 0.
The error only occurs on MacOS (specifically tested on 10.15.7) with Python 3.8 (specifically tested with Python 3.8.5). I could not reproduce it on Linux, or on MacOS with Python 3.6 or 3.7.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
Run the following script which is taken verbatim from the &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html&gt;official&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3&gt;documentation&lt;/denchmark-link&gt;
: &lt;denchmark-link:https://gist.github.com/PiotrJander/be093261db295b2571e3dde952a61ff4&gt;https://gist.github.com/PiotrJander/be093261db295b2571e3dde952a61ff4&lt;/denchmark-link&gt;

on MacOS with Python 3.8 in an environment containing
&lt;denchmark-code&gt;pytorch-lightning==1.0.0
torch==1.6.0
torchvision==0.7.0
&lt;/denchmark-code&gt;

The full stack trace is here: &lt;denchmark-link:https://gist.github.com/PiotrJander/e82ca1d94ae85e746f33a18d7ca2d492&gt;https://gist.github.com/PiotrJander/e82ca1d94ae85e746f33a18d7ca2d492&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;PyTorch version: 1.6.0
Is debug build: No
CUDA used to build PyTorch: None

OS: Mac OSX 10.15.7
GCC version: Could not collect
CMake version: version 3.16.2

Python version: 3.8
Is CUDA available: No
CUDA runtime version: No CUDA
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA

Versions of relevant libraries:
[pip3] numpy==1.18.5
[pip3] pytorch-lightning==1.0.0
[pip3] torch==1.6.0
[pip3] torchvision==0.7.0
[conda] Could not collect
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Additional notes&lt;/denchmark-h&gt;

This seems to be related to &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/5301&gt;pytorch/pytorch#5301&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/25302&gt;pytorch/pytorch#25302&lt;/denchmark-link&gt;
 but those issues were closed without providing a solution.
This issue was also reported as &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/46648&gt;a PyTorch issue&lt;/denchmark-link&gt;
 but maintainers suggested it should be cross-posted here as well.
	</description>
	<comments>
		<comment id='1' author='PiotrJander' date='2020-10-21T15:50:15Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='PiotrJander' date='2020-10-21T21:08:33Z'>
		Isn't this just a limitation of ?
Please check
&lt;denchmark-link:https://discuss.pytorch.org/t/multiprocessing-not-working-on-pytorch-on-macbook/80663/2&gt;https://discuss.pytorch.org/t/multiprocessing-not-working-on-pytorch-on-macbook/80663/2&lt;/denchmark-link&gt;

There is little evidence here that it is Lightning related.
		</comment>
		<comment id='3' author='PiotrJander' date='2020-10-21T21:22:15Z'>
		Hi &lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
 , thanks for the hint, adding  helped.
But:
(1) The thread you linked to explains why if __name__ == '__main__' is needed on Windows (no forking semantics). Do we know why this is also a problem on MacOS with Python 3.8, but not with other Python versions, and not on Ubuntu?
(2) Since the problem occurs in a very basic example in the intro to Lighting in the official docs, then perhaps those docs should be updated with a relevant note?
		</comment>
		<comment id='4' author='PiotrJander' date='2020-10-22T03:55:47Z'>
		&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/36515#issuecomment-613150083&gt;pytorch/pytorch#36515 (comment)&lt;/denchmark-link&gt;

Here this person is saying that in python 3.8 the multiprocessing default changed from fork to spawn on mac.
The issue itself is not related directly, but this is one difference I can identify so far which could answer your first question.
		</comment>
		<comment id='5' author='PiotrJander' date='2020-10-22T09:36:01Z'>
		That makes sense, thanks! Looks like it's a Pytorch issue, so closing the issue here.
		</comment>
	</comments>
</bug>