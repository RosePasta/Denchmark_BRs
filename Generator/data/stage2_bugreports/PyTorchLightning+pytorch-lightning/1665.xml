<bug id='1665' author='tshrjn' open_date='2020-04-29T15:59:49Z' closed_time='2020-05-12T12:53:27Z'>
	<summary>Trainer add args doesn't add default root dir</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;


When using parser = Trainer.add_argparse_args(parser), it's supposed to put all Trainer's arguments in the argparse with default values. Though currently it doesn't add default_root_dir and you get the error:

&lt;denchmark-code&gt;'Namespace' object has no attribute 'default_root_dir'
&lt;/denchmark-code&gt;

It does add default_save_path which is deprecated.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;Code Sample&lt;/denchmark-h&gt;

import argparse
from pytorch_lightning import Trainer

parser = argparse.ArgumentParser(description='demo')
parser = Trainer.add_argparse_args(parser)
args = parser.parse_args()

print(args.default_root_dir)
A similar unit test could also be made, if not there already.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
        - GPU:
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
        - available:         True
        - version:           10.1
* Packages:
        - numpy:             1.18.1
        - pyTorch_debug:     False
        - pyTorch_version:   1.4.0
        - pytorch-lightning: 0.7.3
        - tensorboard:       2.2.0
        - tqdm:              4.45.0
* System:
        - OS:                Linux
        - architecture:
                - 64bit
                -
        - processor:         x86_64
        - python:            3.6.7
        - version:           #75-Ubuntu SMP Tue Oct 1 05:24:09 UTC 2019
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='tshrjn' date='2020-04-30T11:46:49Z'>
		Did you tried to update to 0.7.5. Maybe it is already solved.
		</comment>
		<comment id='2' author='tshrjn' date='2020-05-04T07:15:14Z'>
		Hi &lt;denchmark-link:https://github.com/olineumann&gt;@olineumann&lt;/denchmark-link&gt;
, yes updating did resolve this. However, the  arg is now broken. The same demo code above with  gives the same error .
		</comment>
		<comment id='3' author='tshrjn' date='2020-05-04T08:57:26Z'>
		What do you mean 'with profiler'? Do you mean Trainer(..., profiler=True)? But you don't initialize a Trainer.
Running your code or this below didn't crash with any error on my machine.
import argparse
from pytorch_lightning import Trainer

parser = argparse.ArgumentParser(description='demo')
trainer = Trainer(profiler=True)
parser = trainer.add_argparse_args(parser)
args = parser.parse_args()

print(args.default_root_dir)
Maybe you could post the complete error message from the python interpreter.
		</comment>
		<comment id='4' author='tshrjn' date='2020-05-06T22:12:44Z'>
		add_argparse_args  is supposed to add the args from trainer to parser. But it doesn't do that for a few args. In this case profiler, previously the issue was for default_root_dir.
Try the following code by running:
python demo.py --profiler True or  other possibly accepted way python demo.py --profiler  with the following code:
import argparse
from pytorch_lightning import Trainer

trainer = Trainer()
parser = argparse.ArgumentParser(description='demo')
parser = trainer.add_argparse_args(parser)
args = parser.parse_args()

print(args.profiler)
		</comment>
		<comment id='5' author='tshrjn' date='2020-05-12T03:12:23Z'>
		Any update?
		</comment>
		<comment id='6' author='tshrjn' date='2020-05-12T10:43:03Z'>
		I just created a PR. After looking at the code I found out that add_argparse_args is checking the argument types and is only adding attributes of type str, float, int or bool. The profiler attribute could be of type bool so it should be a bug.
I saw that get_init_arguments_and_types() is returning profiler as argument but only of type BaseProfiler. After updating typing annotation of profiler argument it worked. Should be available in the next version.
See PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1794&gt;#1794&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='tshrjn' date='2020-05-12T21:06:28Z'>
		A similar issue is with the pickling of the profiler when it's a Profile object &amp; the trainer tries to save the hparams.
TypeError: can't pickle Profile objects
Example code:
import argparse
from pytorch_lightning import Trainer
from pytorch_lightning import profiler
from pl_bolts.models.gans import BasicGAN

trainer = Trainer()
parser = argparse.ArgumentParser(description='demo')
parser = trainer.add_argparse_args(parser)
args = parser.parse_args()
model = BasicGAN()

trainer = Trainer.from_argparse_args(
        args, profiler=profiler.AdvancedProfiler())
trainer.fit(model)
		</comment>
		<comment id='8' author='tshrjn' date='2020-05-13T08:02:45Z'>
		Can't reproduce your issue with pl version 0.7.6rc1. On my machine your code runs and saves checkpoints without crashing. Also this wouldn't belong to the topic of this issue imo. This would be a bug in the saving routine.
		</comment>
	</comments>
</bug>