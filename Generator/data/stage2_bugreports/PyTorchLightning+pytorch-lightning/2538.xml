<bug id='2538' author='djbyrne' open_date='2020-07-07T10:51:10Z' closed_time='2020-07-07T13:17:24Z'>
	<summary>tensor_metric decorator does not let you return Tuple or List ouputs</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When creating a metric function that returns multiple outputs in the form of a Tuple or List the metric class complains that it can't convert a Tuple or List to a tensor, even though the contents of the Tuple/List are tensors.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

An example of this would be a function  to return the topk accuracy
&lt;denchmark-code&gt;
    @tensor_metric()
    def accuracy(output, target, topk=(1,)):
        """Computes the precision@k for the specified values of k"""

        maxk = max(topk)
        batch_size = target.size(0)
    
        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))
    
        res = []
        for k in topk:
            correct_k = correct[:k].view(-1).float().sum(0)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        acc = self.accuracy(y_hat, y, topk=(1, 5))

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Error Output&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;
Epoch 1:   0%|          | 0/1876 [00:00&lt;?, ?it/s] Traceback (most recent call last):
  File "/home/local/CORP/dbyrne/Documents/Projects/RL/pytorch-lightning-bolts/pl_bolts/models/mnist_module.py", line 138, in &lt;module&gt;
    trainer.fit(model)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 912, in fit
    self.dp_train(model)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py", line 258, in dp_train
    self.run_pretrain_routine(model)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1093, in run_pretrain_routine
    self.train()
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 375, in train
    self.run_training_epoch()
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 458, in run_training_epoch
    _outputs = self.run_training_batch(batch, batch_idx)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 634, in run_training_batch
    loss, batch_output = optimizer_closure()
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 598, in optimizer_closure
    output_dict = self.training_forward(split_batch, batch_idx, opt_idx, self.hiddens)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 754, in training_forward
    output = self.model(*args)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 65, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 69, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 209, in parallel_apply
    raise output
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 166, in _worker
    output = module.training_step(*input, **kwargs)
  File "/home/local/CORP/dbyrne/Documents/Projects/RL/pytorch-lightning-bolts/pl_bolts/models/mnist_module.py", line 52, in training_step
    acc = self.accuracy(y_hat, y, topk=(1, 5))
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py", line 58, in new_func
    result = function_to_decorate(*args, **kwargs)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py", line 59, in new_func
    return func_to_apply(result, *dec_args, **dec_kwargs)
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py", line 84, in _convert_to_tensor
    raise TypeError(f"The given type ('{type(data).__name__}') cannot be converted to a tensor!")
TypeError: The given type ('list') cannot be converted to a tensor!
Exception ignored in: &lt;function tqdm.__del__ at 0x7f8c82724ae8&gt;
Traceback (most recent call last):
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/tqdm/std.py", line 1086, in __del__
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/tqdm/std.py", line 1293, in close
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/tqdm/std.py", line 1471, in display
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/tqdm/std.py", line 1089, in __repr__
  File "/home/local/CORP/dbyrne/anaconda3/envs/core_rl/lib/python3.7/site-packages/tqdm/std.py", line 1433, in format_dict
TypeError: cannot unpack non-iterable NoneType object

Process finished with exit code 1

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version: 1.4
OS: Linux
How you installed PyTorch: Conda
Python version: 3.7.7
CUDA/cuDNN version: 10.1
GPU models and configuration: RTX 2080

	</description>
	<comments>
		<comment id='1' author='djbyrne' date='2020-07-07T12:54:59Z'>
		Could you try to use the decorator tensor_collection_metric? The intention with tensor_metric is that should decorate metric functions that returns a single tensor, whereas tensor_collection_metric is meant to be used on a collection of metrics.
Otherwise you could just stack your res list into a tensor: res=torch.cat(res).
		</comment>
		<comment id='2' author='djbyrne' date='2020-07-07T13:17:24Z'>
		Hey &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
, yes that works perfectly thank you! Apologies, I do remember reading that tensor_collection_metric is needed for multiple outputs a few days ago and completely forgot. I will close the Issue
		</comment>
	</comments>
</bug>