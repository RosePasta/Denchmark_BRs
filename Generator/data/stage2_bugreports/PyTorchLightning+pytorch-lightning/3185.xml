<bug id='3185' author='VirajBagal' open_date='2020-08-26T05:19:53Z' closed_time='2020-09-01T13:17:53Z'>
	<summary>Value out of range (expected to be in range of [-1, 0], but got 1)</summary>
	<description>
&lt;denchmark-h:h2&gt;Value out of range (expected to be in range of [-1, 0], but got 1)&lt;/denchmark-h&gt;

Exception in device=TPU:5: torch_xla/csrc/helpers.cpp:97 : Check failed: min_shape_dim &lt;= dim &amp;&amp; dim &lt;= max_shape_dim
Following is the stack trace when I am using all 8 TPU cores on Kaggle. The exact same code with

sync_dist=False

works completely fine on Kaggle GPU.

Value out of range (expected to be in range of [-1, 0], but got 1)Exception in device=TPU:5: torch_xla/csrc/helpers.cpp:97 : Check failed: min_shape_dim &lt;= dim &amp;&amp; dim &lt;= max_shape_dim
*** Begin stack trace ***
tensorflow::CurrentStackTrace()
torch_xla::XlaHelpers::GetCanonicalDimensionIndex(long long, long long)
torch_xla::XlaHelpers::MakeTransposePermutation(long long, long long, long long)
torch_xla::XLATensor::transpose(torch_xla::XLATensor const&amp;, long long, long long)
torch_xla::AtenXlaType::t(at::Tensor const&amp;)
c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor ()(at::Tensor const&amp;), at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor (at::Tensor const&amp;)&gt;::call(c10::OperatorKernel, at::Tensor const&amp;)
at::t(at::Tensor const&amp;)
at::Tensor::t() const
_PyMethodDef_RawFastCallKeywords
_PyMethodDescr_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallDict
_PyObject_Call_Prepend
PyObject_Call
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallDict
_PyEval_EvalFrameDefault
_PyFunction_FastCallDict
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallDict
_PyObject_Call_Prepend
_PyObject_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallDict
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
PyEval_EvalCodeEx
PyEval_EvalCode
_PyMethodDef_RawFastCallKeywords
_PyCFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyGen_Send
_PyEval_EvalFrameDefault
_PyGen_Send
_PyEval_EvalFrameDefault
_PyGen_Send
_PyMethodDef_RawFastCallKeywords
_PyMethodDescr_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallDict
_PyObject_Call_Prepend
PyObject_Call
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyMethodDef_RawFastCallKeywords
_PyCFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyMethodDef_RawFastCallKeywords
_PyCFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyMethodDef_RawFastCallKeywords
_PyCFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyEval_EvalCodeWithName
_PyFunction_FastCallDict
_PyObject_Call_Prepend
PyObject_Call
_PyEval_EvalFrameDefault
_PyGen_Send
_PyMethodDef_RawFastCallKeywords
_PyMethodDescr_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallKeywords
_PyEval_EvalFrameDefault
_PyFunction_FastCallDict
*** End stack trace ***

Here is the code for my LightningModule
class GraphAEStage1(pl.LightningModule):
  def __init__(self, config):
    super(GraphAEStage1, self).__init__()
    max_deg = config['poc_max_degree']
    input_dim = config['input_dim']
    hidden_feat = config['hidden_feat_dim']
    layerid = config['layerid']
    self.lr = config['lr']
  
    self.encoder = GraphEncoderStage1(max_deg, input_dim, hidden_feat[layerid])
    self.decoder = GraphDecoderStage1(max_deg, input_dim, hidden_feat[layerid])
    
    self.encoder.apply(self.init_weights)
    
    self.crit = torch.nn.L1Loss()
    self.node_mae = MAE()
    self.adj_mae = MAE()
    
    self.decoder.self_linear.weight = nn.Parameter(self.encoder.self_linear.weight.permute(1,0))
    for d in range(config['poc_max_degree']):
        self.decoder.neigh_linear[d].weight = nn.Parameter(self.encoder.neigh_linear[d].weight.permute(1,0))

  def training_step(self, batch, batch_idx):
    loss, tf_node, _, _, _ = self.shared_step(batch)
    result = pl.TrainResult(minimize=loss)
    result.log('train_loss', loss, prog_bar = True, logger = True, on_step = False, on_epoch = True, sync_dist = True)
    return result

  def validation_step(self, batch, batch_idx):
    loss, tf_node, recon_node, val_node_mae, val_adj_mae = self.shared_step(batch)
    
    logs = {'val_loss': loss, 'node_mae': val_node_mae, 'adj_mae': val_adj_mae}
    result = pl.EvalResult(checkpoint_on = loss)
    result.log_dict(logs, prog_bar = True, logger = True, on_step = False, on_epoch = True, sync_dist = True)
    
    return result               

  def shared_step(self, batch):
    node, adj, deg, mask = batch
    tf_node, avg_adj = self.encoder(node, adj, deg, mask)
    recon_node, recon_adj = self.decoder(tf_node, deg)

    
    node_loss = self.criterion(recon_node, node)
    adj_loss = self.criterion(recon_adj, avg_adj)
    loss = node_loss + adj_loss
    
    node_mae = self.node_mae(node, recon_node)
    adj_mae = self.adj_mae(recon_adj, avg_adj)
    
    return loss, tf_node, recon_node, node_mae, adj_mae

  def configure_optimizers(self):
    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
    return optimizer

  def criterion(self, output, target):
    return self.crit(output, target)

  def init_weights(self, m):
    if type(m) == nn.Linear:
        torch.nn.init.xavier_uniform(m.weight)
        m.bias.data.fill_(0.00)  
There are similar issues reported on PyTorch XLA repo, but many of them were using CrossEntropyLoss. I am not using CrossEntropyLoss here.
	</description>
	<comments>
		<comment id='1' author='VirajBagal' date='2020-08-26T15:24:23Z'>
		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 mind taking a look at this?
		</comment>
		<comment id='2' author='VirajBagal' date='2020-08-26T15:41:59Z'>
		&lt;denchmark-link:https://github.com/VirajBagal&gt;@VirajBagal&lt;/denchmark-link&gt;
 could you share the notebook?
		</comment>
		<comment id='3' author='VirajBagal' date='2020-08-26T16:32:46Z'>
		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
 Due to some privacy issues, I can't share it publicly here. I have shared it with you on Kaggle. Please check the "Shared With You" tab on Kaggle.
		</comment>
		<comment id='4' author='VirajBagal' date='2020-08-26T16:46:24Z'>
		Sure.. Will do üòäüëç
		</comment>
		<comment id='5' author='VirajBagal' date='2020-08-28T17:42:29Z'>
		It seems xla does not support the  operation on 1-dimensional tensors. &lt;denchmark-link:https://github.com/zcain117&gt;@zcain117&lt;/denchmark-link&gt;
 could you help us out?  seems to be throwing the error mentioned when called. PyTorch usually returns 1d tensors as is.
		</comment>
	</comments>
</bug>