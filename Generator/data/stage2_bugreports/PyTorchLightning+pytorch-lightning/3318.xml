<bug id='3318' author='curehabit' open_date='2020-09-02T04:21:35Z' closed_time='2020-09-02T11:13:46Z'>
	<summary>Value out of range (expected to be in range of [-1, 0], but got 1)</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When I try to run mnist tutorial (&lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/stable/new-project.html&gt;https://pytorch-lightning.readthedocs.io/en/stable/new-project.html&lt;/denchmark-link&gt;
), I got an error:
Value out of range (expected to be in range of [-1, 0], but got 1)
2020-09-02 12:07:23.605391: E tensorflow/compiler/xla/xla_client/tf_logging.cc:11] Check failed: min_shape_dim &lt;= dim &amp;&amp; dim&lt;= max_shape_dim
My device is torch_xla, and I set Trainer( tpu_cores=1).
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
Just run as the tutorial.
&lt;denchmark-code&gt;pytorch_lightning/core/step_result.py(844)weighted_mean()
-&gt; weights = weights.to(result.device)
(Pdb) l
839             for k, v in predictions_dict.items():
840                 self.write(k, v, filename)
841
842
843     def weighted_mean(result, weights):
844 B-&gt;     weights = weights.to(result.device)
845         numerator = torch.dot(result.float(), weights.t().float()) ### Broken there
846         result = numerator / weights.sum().float()
847         return result

Value out of range (expected to be in range of [-1, 0], but got 1)
2020-09-02 12:07:23.605391: E tensorflow/compiler/xla/xla_client/tf_logging.cc:11] Check failed: min_shape_dim &lt;= dim &amp;&amp; dim&lt;= max_shape_dim
*** Begin stack trace ***
        tensorflow::CurrentStackTrace()
        torch_xla::XlaHelpers::GetCanonicalDimensionIndex(long long, long long)
        torch_xla::XlaHelpers::MakeTransposePermutation(long long, long long, long long)
        torch_xla::XLATensor::transpose(torch_xla::XLATensor const&amp;, long long, long long)
        torch_xla::AtenXlaType::t(at::Tensor const&amp;)
        c10::impl::wrap_kernel_functor_unboxed_&lt;c10::impl::detail::WrapFunctionIntoRuntimeFunctor_&lt;at::Tensor (*)(at::Tensorconst&amp;), at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;&gt; &gt;, at::Tensor (at::Tensor const&amp;)&gt;::call(c10::OperatorKernel*, at::Tensor const&amp;)
        at::Tensor c10::Dispatcher::call&lt;at::Tensor, at::Tensor const&amp;&gt;(c10::TypedOperatorHandle&lt;at::Tensor (at::Tensor const&amp;)&gt; const&amp;, at::Tensor const&amp;) const
        at::t(at::Tensor const&amp;)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:
- GPU:
- available:         False
- version:           None
Packages:
- numpy:             1.19.0
- pyTorch_debug:     False
- pyTorch_version:   1.6.0.dev20200622
- pytorch-lightning: 0.9.0
- tensorboard:       2.2.0
- tqdm:              4.48.2
System:
- OS:                Linux
- architecture:
- 64bit
-
- processor:
- python:            3.7.7
- version:           #1 SMP Debian 4.14.81.bm.15 Sun Sep 8 05:02:31 UTC 2019


PyTorch Version (e.g., 1.0): 1.6
OS (e.g., Linux): Linux
How you installed PyTorch (conda, pip, source): pip
Build command you used (if compiling from source):
Python version: 3.7.8
CUDA/cuDNN version: None
GPU models and configuration: None
Any other relevant information: torch_xla:1.6.0

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

I try to use pdb to debug it, and I found weights.t() caused this error.
&lt;denchmark-code&gt;def weighted_mean(result, weights):
844 B-&gt;     weights = weights.to(result.device)
845         numerator = torch.dot(result.float(), weights.t().float()) ### Broken there
846         result = numerator / weights.sum().float()
847         return result
(Pdb) weights.shape
torch.Size([1])
(Pdb) result.shape
torch.Size([1])
(Pdb) weights.t
&lt;built-in method t of Tensor object at 0x7fd0142f6be0&gt;
(Pdb) weights.t()
2020-09-02 12:07:23.605391: E tensorflow/compiler/xla/xla_client/tf_logging.cc:11] Check failed: min_shape_dim &lt;= dim &amp;&amp; dim&lt;= max_shape_dim
&lt;/denchmark-code&gt;

if I set weights = weights.t() before weights.to(result.device), it can run normally.
&lt;denchmark-code&gt;def weighted_mean(result, weights):
    weights = weights.t().to(result.device) # weights = weights.to(result.device)
    numerator = torch.dot(result.float(), weights.float()) 
    result = numerator / weights.sum().float()
    return result
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='curehabit' date='2020-09-02T04:22:16Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='curehabit' date='2020-09-02T09:27:49Z'>
		Also had this issue when using TPU +1
		</comment>
		<comment id='3' author='curehabit' date='2020-09-02T11:13:46Z'>
		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
 was working on this one, it shall be fixed &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3252&gt;#3252&lt;/denchmark-link&gt;
, mind trying master
		</comment>
	</comments>
</bug>