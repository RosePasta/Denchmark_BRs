<bug id='1332' author='toshiks' open_date='2020-04-01T21:22:18Z' closed_time='2020-04-16T23:17:24Z'>
	<summary>MultiGPU Training. Logging problem</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When we try logging to the tensorboard loss during last step of epoch with GPU number more than one, we can get exception.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Start training any model on any dataset with gpu amount over than one, but last batch should contains objects only for the part of GPUs.
I have next error:
ValueError: only one element tensors can be converted to Python scalars
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Success logging to tensorboard.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

OS: Ubuntu
pytorch-lightning==0.7.1
&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

I suppose problem in the method (trainer/logging.py):
def reduce_distributed_output(self, output, num_gpus)
# reduce only metrics that have the same number of gpus
elif output[k].size(0) == num_gpus:
    reduced = torch.mean(output[k])
    output[k] = reduced
If we have a last not full batch, we should get mean, isn't it?
	</description>
	<comments>
		<comment id='1' author='toshiks' date='2020-04-01T21:23:01Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='toshiks' date='2020-04-16T23:17:24Z'>
		seems to be the same as &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/1218&gt;#1218&lt;/denchmark-link&gt;
 so I am closing this one in its favour...
&lt;denchmark-link:https://github.com/toshiks&gt;@toshiks&lt;/denchmark-link&gt;
 may you give a minimal example to reproduce?
		</comment>
	</comments>
</bug>