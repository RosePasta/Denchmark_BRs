<bug id='4503' author='jaimergp' open_date='2020-11-03T21:51:32Z' closed_time='2020-11-04T08:34:03Z'>
	<summary>_log_on_evaluation_epoch_end_metrics() still expects a Results object instead of a dict</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Please reproduce using the BoringModel and post here&lt;/denchmark-h&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1Z1hOL_r67zcPnvgCkkjq3LZ4E58tFp7l?usp=sharing&gt;https://colab.research.google.com/drive/1Z1hOL_r67zcPnvgCkkjq3LZ4E58tFp7l?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

On testing, using multiple datasets should not raise an error. It looks like it's still expecting one of the now deprecated *Results objects, but the loop only passes dicts around.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
	- GPU:
		- Tesla T4
	- available:         True
	- version:           10.1
* Packages:
	- numpy:             1.18.5
	- pyTorch_debug:     False
	- pyTorch_version:   1.6.0+cu101
	- pytorch-lightning: 1.0.4
	- tqdm:              4.41.1
* System:
	- OS:                Linux
	- architecture:
		- 64bit
		- 
	- processor:         x86_64
	- python:            3.6.9
	- version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jaimergp' date='2020-11-03T21:52:15Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='jaimergp' date='2020-11-03T21:54:10Z'>
		Ah, wait, I see this is being handled in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/4136&gt;#4136&lt;/denchmark-link&gt;
 
		</comment>
	</comments>
</bug>