<bug id='3626' author='carmocca' open_date='2020-09-23T13:34:01Z' closed_time='2020-09-25T01:53:49Z'>
	<summary>#3598 does not allow monitoring tensors logged via `TrainResult`</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Code sample&lt;/denchmark-h&gt;

@pytest.mark.parametrize("monitor", ["tr_foo", "tr_bar", "va_foo", "va_bar"])
def test(tmpdir, monitor):
    model = DeterministicModel()

    def training_step(batch, batch_idx):
        acc = model.step(batch, batch_idx)
        result = TrainResult(minimize=acc)
        result.log("tr_foo", torch.randn(1), on_step=False, on_epoch=True)
        result.log("tr_bar", torch.randn(1), on_step=False, on_epoch=True)
        return result

    def validation_step(*args, **kwargs):
        result = EvalResult()
        result.log("va_foo", torch.randn(1), on_step=False, on_epoch=True)
        result.log("va_bar", torch.randn(1), on_step=False, on_epoch=True)
        return result

    model.training_step = training_step
    model.validation_step = validation_step
    model.validation_step_end = None
    model.validation_epoch_end = None

    trainer = Trainer(
        default_root_dir=tmpdir,
        early_stop_callback=EarlyStopping(monitor=monitor),
        checkpoint_callback=ModelCheckpoint(monitor=monitor),
        limit_train_batches=3,
        limit_val_batches=3,
        max_epochs=2,
        weights_summary=None,
    )
    trainer.fit(model)
tr_foo and tr_bar fail. va_foo and va_bar work.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

No failure and callbacks correctly monitor their monitor
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Current master
&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='carmocca' date='2020-09-23T13:37:43Z'>
		amazing. thanks for finding. can you submit a PR with the tests? i‚Äôll make the fixes on that PR
		</comment>
		<comment id='2' author='carmocca' date='2020-09-23T14:13:59Z'>
		Done
		</comment>
		<comment id='3' author='carmocca' date='2020-09-25T01:55:09Z'>
		please see the comments in the PR... this is not a valid use.
If you notice, you don't log anything until the end of the epoch... but yet you ask to monitor a value WITHIN a training epoch. This is of course a contradiction.
If you want to monitor something within an epoch, then log that value within the epoch. Otherwise monitor epoch metrics
		</comment>
		<comment id='4' author='carmocca' date='2020-09-25T02:25:28Z'>
		So, if I understood it correctly, is it because training has this structure?
for epoch in epochs
    for train_batch in train_dataloader():
        ...
        set_train_step_metrics()

        if should_check_val:
            for val_batch in val_dataloader():
                ...
                set_val_step_metrics()

            # validation is over
            set_val_epoch_metrics()
      
            # training epoch metrics are set
            # later so they cannot be monitored yet
            modelcheckpoints.save()

    # training is over
    # they get set here
    # but checkpoints have already been saved
    set_train_epoch_metrics()
		</comment>
	</comments>
</bug>