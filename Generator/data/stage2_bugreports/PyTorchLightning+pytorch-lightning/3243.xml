<bug id='3243' author='AxlAlm' open_date='2020-08-28T14:21:58Z' closed_time='2020-09-22T22:00:25Z'>
	<summary>Monitor metric not found for Learning Schedulers when using Result()</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

If you are using Result() (TrainResult() and EvalResult()) you cannot use a Learning Scheduler that monitors a metric as it will not find the metrics logged/stored by the Result() class. The available metrics for me that are listed below in the error are not the ones that exist in my TrainResult() and EvalResult().
either the update_learning_rates() function in training_loop.py is not looking in the right place for metrics or the Results() metric aggregation/updating is not updating in the correct places.
Am i right or am i doing something wrong?
ERROR:
&lt;denchmark-code&gt;....
~/opt/anaconda3/envs/axlnlp/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py in run_pretrain_routine(self, model)
   1237 
   1238         # CORE TRAINING LOOP
-&gt; 1239         self.train()
   1240 
   1241     def _run_sanity_check(self, ref_model, model):

~/opt/anaconda3/envs/axlnlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in train(self)
    399 
    400                 # update LR schedulers
--&gt; 401                 self.update_learning_rates(interval='epoch')
    402 
    403                 # early stopping

~/opt/anaconda3/envs/axlnlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py in update_learning_rates(self, interval, monitor_metrics)
   1279                         avail_metrics = ','.join(list(self.callback_metrics.keys()))
   1280                         raise MisconfigurationException(
-&gt; 1281                             f'ReduceLROnPlateau conditioned on metric {monitor_key}'
   1282                             f' which is not available. Available metrics are: {avail_metrics}.'
   1283                             ' Condition can be set using `monitor` key in lr scheduler dict'

MisconfigurationException: ReduceLROnPlateau conditioned on metric val-seg-f1 which is not available. Available metrics are: val_early_stop_on,val_checkpoint_on,checkpoint_on. Condition can be set using `monitor` key in lr scheduler dict
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AxlAlm' date='2020-08-28T14:22:42Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='AxlAlm' date='2020-08-28T14:37:26Z'>
		This is using pl version 0.9.0
		</comment>
		<comment id='3' author='AxlAlm' date='2020-08-30T10:42:58Z'>
		I have the same issue
		</comment>
		<comment id='4' author='AxlAlm' date='2020-08-31T10:56:25Z'>
		 &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2976&gt;#2976&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>