<bug id='3713' author='xiadingZ' open_date='2020-09-29T01:39:03Z' closed_time='2020-10-07T13:46:31Z'>
	<summary>AccuracyMetric automatically do ReduceOp.SUM in test_epoch_end</summary>
	<description>
my code:
&lt;denchmark-code&gt;    def test_step(self, batch, batch_idx):
         ...
        # self.accuracy_video = Accuracy()
        vid_acc = self.accuracy_video(video_labels_hat, video_labels)
        print("test_step, ", vid_acc)

        return {'test_loss': loss, "test_pacc": part_acc, "test_vacc": vid_acc}


    def test_epoch_end(self, outputs):
        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()
        avg_acc = torch.stack([x['test_vacc'] for x in outputs]).mean()
        print("avg_acc_1:", avg_acc)
        dist.all_reduce(avg_loss, op=dist.ReduceOp.SUM)
        dist.all_reduce(avg_acc, op=dist.ReduceOp.SUM)
        print("avg_acc_2:", avg_acc)
        avg_acc = avg_acc / self.trainer.world_size
        return {'test_loss': avg_loss, 'test_acc': avg_acc,}
&lt;/denchmark-code&gt;

my test_step vid_acc is 0.6~0.7, normal, but in test_epoch_end, avg_acc_1=22.3333, avg_acc_2=714.6666. Does test_vacc  is already synced by dist.ReduceOp.SUM by default?  then I only need to do avg_acc = avg_acc / self.trainer.world_size?
	</description>
	<comments>
		<comment id='1' author='xiadingZ' date='2020-09-29T13:22:33Z'>
		Yes, class metrics automatically sync between devices, with the default operation being dist.ReduceOp.SUM.
Depending on what version of lightning you are running, you should also be able to set the argument reduce_op to 'mean' when construction the metric.
		</comment>
		<comment id='2' author='xiadingZ' date='2020-09-30T01:45:30Z'>
		I know it, the problem is I construct Accuracy with reduce_op='avg':
&lt;denchmark-code&gt;self.accuracy_video = Accuracy(reduce_op='avg')
&lt;/denchmark-code&gt;

In my val step, it can normally do mean operation, value about 0.7. But in test_epoch_end, it doesn't, value about 22. Only difference is I store it in EvalResult in  val step, but return it directly in test step. EvalResult will automatically do sync_dist_op='mean', so I add
&lt;denchmark-code&gt;        dist.all_reduce(avg_acc, op=dist.ReduceOp.SUM)
        avg_acc = avg_acc / self.trainer.world_size
&lt;/denchmark-code&gt;

in test_epoch_end to do this operation. But It seems  dist.all_reduce(avg_acc, op=dist.ReduceOp.SUM) has been done automatically, I only need to do avg_acc = avg_acc / self.trainer.world_size
I'm using 0.9.1 rc3
&lt;denchmark-code&gt;    def validation_step(self, batch, batch_idx):

        vid_acc = self.accuracy_video(video_labels_hat, video_labels)

        monitor = 0-vid_acc
        result = pl.EvalResult(checkpoint_on=monitor)
        result.log('val_loss', loss, sync_dist=True)
        result.log('val_vacc', vid_acc, sync_dist=True,prog_bar=True)
        result.log('monitor', monitor, sync_dist=True)

        return result


    def test_step(self, batch, batch_idx):
        vid_acc = torch.sum(video_labels == video_labels_hat).type_as(imgs) / video_labels.shape[0]

        return {'test_loss': loss, "test_pacc": part_acc, "test_vacc": vid_acc, "cm":cm}


    def test_epoch_end(self, outputs):
        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()
        avg_acc = torch.stack([x['test_vacc'] for x in outputs]).mean()
        cm = torch.stack([x['test_vacc'] for x in outputs]).sum(dim=0)
        """
        dist.all_reduce(avg_loss, op=dist.ReduceOp.SUM)
        dist.all_reduce(avg_acc, op=dist.ReduceOp.SUM)
        dist.all_reduce(cm, op=dist.ReduceOp.SUM)
        """
        avg_loss = avg_loss / self.trainer.world_size
        avg_acc = avg_acc / self.trainer.world_size
        cm = cm / self.trainer.world_size

        print("avg_acc:", avg_acc)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='xiadingZ' date='2020-10-01T12:54:34Z'>
		
Yes, class metrics automatically sync between devices, with the default operation being dist.ReduceOp.SUM.
Depending on what version of lightning you are running, you should also be able to set the argument reduce_op to 'mean' when construction the metric.

Is this mentioned in the doc? I couldn't find it there.
		</comment>
		<comment id='4' author='xiadingZ' date='2020-10-01T13:04:59Z'>
		&lt;denchmark-link:https://github.com/Evpok&gt;@Evpok&lt;/denchmark-link&gt;
 do you refer to the auto sync or the argument?
Auto sync is mentioned a couple of times in the documentation:
&lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/metrics.html&gt;https://pytorch-lightning.readthedocs.io/en/latest/metrics.html&lt;/denchmark-link&gt;

The reduce_op argument is present on master, but not sure if it is mentioned in the documentation.
Please note that we are in the process of doing major changes to the metrics package before v1.0, so some of the problems mentioned here will probably be solved/made more clear after those updates.
		</comment>
		<comment id='5' author='xiadingZ' date='2020-10-01T13:07:41Z'>
		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
  I meant the  argument :-) glad to see that v1.0 should clarify it! Do you have an ETA for it?
		</comment>
		<comment id='6' author='xiadingZ' date='2020-10-01T13:18:11Z'>
		&lt;denchmark-link:https://github.com/Evpok&gt;@Evpok&lt;/denchmark-link&gt;
 soon, cannot give exact date 
		</comment>
		<comment id='7' author='xiadingZ' date='2020-10-07T13:46:39Z'>
		fixed with new metrics interface
		</comment>
	</comments>
</bug>