<bug id='4367' author='ThomasWollmann' open_date='2020-10-26T12:56:52Z' closed_time='2020-12-07T15:06:10Z'>
	<summary>Bug when running example in README.md</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When running the example in the README.md, the script crashes (Error: AttributeError: 'TypeError' object has no attribute 'message') when calling "trainer.fit(...)".
Appeared with 1.0.3, 1.0.2, 1.0.1, 1.0.0. The script works in 0.9.0 if you remove the line "self.log('train_loss', loss)".
Stacktrace:
&lt;denchmark-code&gt;GPU available: False, used: False
TPU available: False, using: 0 TPU cores
/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping validation loop
  warnings.warn(*args, **kwargs)
Traceback (most recent call last):
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 188, in log_metrics
    self.experiment.add_scalar(k, v, step)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py", line 450, in experiment
    return get_experiment() or DummyExperiment()
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/base.py", line 449, in get_experiment
    return fn(self)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 144, in experiment
    self._experiment = SummaryWriter(log_dir=self.log_dir, **self._kwargs)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 118, in log_dir
    version = self.version if isinstance(self.version, str) else f"version_{self.version}"
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 234, in version
    self._version = self._get_next_version()
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 246, in _get_next_version
    d = listing["name"]
TypeError: string indices must be integers
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/thomas/mx/tmp/main.py", line 41, in &lt;module&gt;
    trainer.fit(autoencoder, DataLoader(train), DataLoader(val))
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 440, in fit
    results = self.accelerator_backend.train()
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/accelerators/cpu_accelerator.py", line 45, in train
    self.trainer.train_loop.setup_training(model)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 132, in setup_training
    self.trainer.logger.log_hyperparams(ref_model.hparams)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 169, in log_hyperparams
    self.log_metrics(metrics, 0)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py", line 35, in wrapped_fn
    return fn(*args, **kwargs)
  File "/home/thomas/anaconda3/lib/python3.7/site-packages/pytorch_lightning/loggers/tensorboard.py", line 191, in log_metrics
    type(e)(e.message + m)
AttributeError: 'TypeError' object has no attribute 'message'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import os
import torch
from torch import nn
import torch.nn.functional as F
from torchvision.datasets import MNIST
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import pytorch_lightning as pl

class LitAutoEncoder(pl.LightningModule):

    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))
        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))
    
    def forward(self, x):
        # in lightning, forward defines the prediction/inference actions
        embedding = self.encoder(x)
        return embedding

    def training_step(self, batch, batch_idx):
        # training_step defined the train loop. It is independent of forward
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = F.mse_loss(x_hat, x)
        self.log('train_loss', loss)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return optimizer

dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
train, val = random_split(dataset, [55000, 5000])

autoencoder = LitAutoEncoder()
trainer = pl.Trainer()
trainer.fit(autoencoder, DataLoader(train), DataLoader(val))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Training should start.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:
available:         False
version:           10.2


Packages:

numpy:             1.17.2
pyTorch_debug:     False
pyTorch_version:   1.6.0
pytorch-lightning: 1.0.3
tqdm:              4.36.1


System:

OS:                Linux
architecture:

64bit


processor:         x86_64
python:            3.7.4
version:           #57-Ubuntu SMP Thu Oct 15 10:57:00 UTC 2020



	</description>
	<comments>
		<comment id='1' author='ThomasWollmann' date='2020-10-27T17:11:52Z'>
		Tried the code on colab. Not getting any error.
		</comment>
		<comment id='2' author='ThomasWollmann' date='2020-10-27T21:32:38Z'>
		I am getting the same error
		</comment>
		<comment id='3' author='ThomasWollmann' date='2020-10-28T03:56:49Z'>
		Can you guys reproduce this error with a colab notebook??
		</comment>
		<comment id='4' author='ThomasWollmann' date='2020-10-28T07:23:15Z'>
		
Tried the code on colab. Not getting any error.

Same here, the code works fine on Google Colab.
		</comment>
		<comment id='5' author='ThomasWollmann' date='2020-10-31T16:11:55Z'>
		Fine for me in Colab. Still not working locally.
		</comment>
		<comment id='6' author='ThomasWollmann' date='2020-11-04T15:55:05Z'>
		I solved this problem by installing pytorch-lightning v.1.0.5
pip uninstall pytorch-lightning
pip install pytorch-lighting==1.0.5
In Google Colab, pytorch-lightning version is 1.0.5 while my local version was 0.9
At the first place, I installed pytorch-lightning with conda install pytorch-lightning -c conda-forge  but it gave me v 0.9
&lt;denchmark-code&gt;OS: Windows 10
arch: x86_64
conda: 4.8.5
python: 3.8.2
pytorch: 1.6.0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='ThomasWollmann' date='2020-11-12T11:59:09Z'>
		I did the same. Also installed pytorch via conda. Still the same error.
		</comment>
		<comment id='8' author='ThomasWollmann' date='2020-11-17T19:45:33Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 any idea?
		</comment>
		<comment id='9' author='ThomasWollmann' date='2020-12-03T09:34:46Z'>
		&lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
 can we add running doctest (via Sphinx) also on all MarkDown files, what do you think? :]
		</comment>
		<comment id='10' author='ThomasWollmann' date='2020-12-03T22:36:21Z'>
		that's probably a bit overkill :)
		</comment>
		<comment id='11' author='ThomasWollmann' date='2020-12-04T07:36:00Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 having the samples as regular unit tests would be already nice. Do not thing there is not an urgent need for doctest.
		</comment>
		<comment id='12' author='ThomasWollmann' date='2020-12-04T08:56:22Z'>
		
@Borda having the samples as regular unit tests would be already nice. Do not thing there is not an urgent need for doctest.

well, how would utilize unit-tests as samples? the point with doctsring is that are examples and also tested so one code serves twice, compare to unit-tests which are usually in another folder (out of the package distribution) and then you just hope that if you a change in tests you update example accordingly...
		</comment>
		<comment id='13' author='ThomasWollmann' date='2020-12-07T15:03:53Z'>
		

@Borda having the samples as regular unit tests would be already nice. Do not thing there is not an urgent need for doctest.

well, how would utilize unit-tests as samples? the point with doctsring is that are examples and also tested so one code serves twice, compare to unit-tests which are usually in another folder (out of the package distribution) and then you just hope that if you a change in tests you update example accordingly...

That's true. It's a bit hacky to simulate an out of package sample within a unit test.
		</comment>
		<comment id='14' author='ThomasWollmann' date='2020-12-07T15:06:10Z'>
		I reinstalled my OS and couldn't reproduce the error anymore. Will close the issue for now.
		</comment>
		<comment id='15' author='ThomasWollmann' date='2020-12-19T02:00:09Z'>
		&lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
  I got the same problem. I fixed it by reinstalling a higher version TensorFlow (1.14+).
I think this is because Pytorch-lighting requires TensorBoard &gt;=2.2Ôºå but that means also requires a higher version TensorFlow to support the TensorBoard.
I found the TensorFlow version was only 1.12 in my environment. So I upgraded TensorFlow to 1.14, and the errors were missing.
&lt;denchmark-link:https://github.com/tensorflow/tensorboard#can-i-run-tensorboard-without-a-tensorflow-installation&gt;https://github.com/tensorflow/tensorboard#can-i-run-tensorboard-without-a-tensorflow-installation&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>