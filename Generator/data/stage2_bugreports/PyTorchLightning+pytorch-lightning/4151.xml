<bug id='4151' author='aeryen' open_date='2020-10-14T17:33:29Z' closed_time='2020-11-02T16:36:49Z'>
	<summary>on_after_backward is called before gradient is unscale_ when using mixed precision</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

From my understanding, one of the main purpose of callback on_after_backward, is to check and log gradients. However, when AMP is being enabled, the gradients you are accessing are not unscaled. I.E. all the numbers and norms you look at will be super large and not really useful.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Use following code snippet to log some layer's l2 norm.
&lt;denchmark-code&gt;    def on_after_backward(self):
            with torch.no_grad():
                if (self.model.*****.weight.grad is not None):
                    norm_value = self.model.*****.weight.grad.detach().norm(2).item()
                    self.log("norm2", norm_value)
&lt;/denchmark-code&gt;

The value registered will be wildly different when using 32bit precision vs. when you enable Native AMP using:
&lt;denchmark-code&gt;                     amp_backend='native',
                     precision=16,
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The weights accessible inside the on_after_backward callback should ideally be consistent, with or without AMP.
More specifically, lightning should consider calling the self.trainer.scaler.unscale_ before on_after_backward. Or maybe provide the option to do so.
Edit: Sorry I just realized this might not be possible since unscale_ should be called after gradient accumulation but on_after_backward is called for every step. This lead to another issue: when conducting gradient accumulation i sometimes need to manually check if current step is The Step to do weight update (the last step of accumulation). One possible solution for both of these issues is perhaps another separate callback that will be called every N accumulation steps. Right after _unscale but right before gradient clipping and updating? Although this will definitely make things a bit complicated.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:

TITAN RTX
GeForce RTX 2080 SUPER


available:         True
version:           10.2


Packages:

numpy:             1.19.1
pyTorch_debug:     False
pyTorch_version:   1.6.0
pytorch-lightning: 1.0.1
tqdm:              4.49.0


System:

OS:                Linux
architecture:

64bit



processor:         x86_64
python:            3.7.9
version:           #52-Ubuntu SMP Thu Sep 10 10:58:49 UTC 2020



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

Currently Lightning calls self.trainer.scaler.unscale_(optimizer) if gradient_clip_val is enabled. Hence if i want to use norm clipping currently i can't manually do un-scale inside the callback.
	</description>
	<comments>
		<comment id='1' author='aeryen' date='2020-10-22T16:18:23Z'>
		prob related &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4148&gt;#4148&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='aeryen' date='2020-10-23T16:48:00Z'>
		Hey &lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
,
I have been looking in Pytorch Doc and the PL Code.
In the Trainer, you have the option:
track_grad_norm which will do it for you automatically and using this one log_every_n_steps to control when to do so.
Under the hood, we are calling unscale_ while doing grad_clipping.
Here is the doc: &lt;denchmark-link:https://pytorch.org/docs/master/amp.html#torch.cuda.amp.GradScaler.unscale&gt;https://pytorch.org/docs/master/amp.html#torch.cuda.amp.GradScaler.unscale&lt;/denchmark-link&gt;
_
I have a good idea on how to solve both this one and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4148&gt;#4148&lt;/denchmark-link&gt;
 at once. I will work on those next week.
Best,
T.C
		</comment>
		<comment id='3' author='aeryen' date='2020-10-29T19:49:48Z'>
		prob also &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4427&gt;#4427&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>