<bug id='3099' author='abrahambotros' open_date='2020-08-22T00:17:16Z' closed_time='2020-10-19T22:34:44Z'>
	<summary>Result class discards checkpoint metrics with value 0</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When a Result class instance (i.e., TrainResult, EvalResult) is given a checkpoint metric with value 0, the metric evaluates falsy in the Result's init, and is discarded. This can cause issues downstream:

No checkpoints created if the metric is always 0 across all steps/epochs.
Fatal exception if this occurs on only one step in an epoch, since that step will have a different number of metric keys than the other steps when aggregating them together. (This may only occur when using a distributed_backend; exception is defined at 


pytorch-lightning/pytorch_lightning/overrides/data_parallel.py


         Line 129
      in
      7cca385






 raise ValueError('All dicts must have the same number of keys') 




).

This happens because a checkpoint metric tensor of just a single 0 value will evaluate to False/falsy, and therefore fails the check at 


pytorch-lightning/pytorch_lightning/core/step_result.py


         Line 42
      in
      7cca385






 if checkpoint_on is not None and checkpoint_on: 




 . The fix might be as simple as deleting the and checkpoint_on condition there... However, I'm not certain if that was intentionally put there for a reason and should not be deleted? I'd be happy to submit a simple PR and add some tests if that seems a reasonable fix though.
&lt;denchmark-h:h3&gt;To Reproduce / Code sample&lt;/denchmark-h&gt;

import torch
from pytorch_lightning import EvalResult

result = EvalResult(checkpoint_on=torch.tensor(0.))
result # {}
result.checkpoint_on # Does not exist

result = EvalResult(checkpoint_on=torch.tensor(1.))
result # {'checkpoint_on': tensor(1.)}
result.checkpoint_on # tensor(1.)
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

result.checkpoint_on (or result['checkpoint_on']) should be defined and usable even when the checkpoint metric value given is 0.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
	- GPU:
		- GeForce RTX 2070 with Max-Q Design
	- available:         True
	- version:           10.2
* Packages:
	- numpy:             1.19.1
	- pyTorch_debug:     False
	- pyTorch_version:   1.5.1
	- pytorch-lightning: 0.9.0rc18
	- tensorboard:       2.2.0
	- tqdm:              4.48.0
* System:
	- OS:                Linux
	- architecture:
		- 64bit
		- 
	- processor:         x86_64
	- python:            3.7.8
	- version:           #38~1596560323~20.04~7719dbd-Ubuntu SMP Tue Aug 4 19:12:34 UTC 2
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='abrahambotros' date='2020-08-25T08:28:57Z'>
		&lt;denchmark-link:https://github.com/abrahambotros&gt;@abrahambotros&lt;/denchmark-link&gt;
 sounds good, mind sending a PR so we see the exact change... 
		</comment>
		<comment id='2' author='abrahambotros' date='2020-08-25T18:29:56Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 sure thing, PR here: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3170&gt;#3170&lt;/denchmark-link&gt;
 .
I hadn't submitted a PR before since I wasn't sure if there was some reason for the truthy checkpoint_on check. However, when making the PR and looking around more, I saw that the typing specified checkpoint_on: Union[Tensor, bool, None], and that there was a single test that passed checkpoint_on=False. This makes sense if we do indeed want to accept bools, my apologies for not catching that before.
However, accepting booleans is not documented elsewhere, and in my opinion bool seems redundant and maybe even less clear than just passing None, which is also already the default. The PR I linked above removes the bool option from the typing, and instead just makes it an Optional[Tensor]. This also allows us to trivially remove the and checkpoint_on truthy check that I mentioned in the issue description above.
Let me know what you think.
		</comment>
		<comment id='3' author='abrahambotros' date='2020-10-19T22:34:43Z'>
		Please upgrade to 1.0.2. We deprecated Results for a much simpler API for checkpointing. Feel free to reopen if issue persists!
		</comment>
	</comments>
</bug>