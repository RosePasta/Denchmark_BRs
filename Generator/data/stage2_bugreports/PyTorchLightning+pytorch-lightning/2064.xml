<bug id='2064' author='lucadiliello' open_date='2020-06-03T22:58:06Z' closed_time='2020-06-26T13:41:55Z'>
	<summary>Logging not working correctly with optimizer frequency.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Using multiple optimizers with different frequencies, the last (with the higher optimizer_idx) log dict that is returned by the training_step is not considered in tensorboard.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

With a configure_step like
    res_1 = {
        "optimizer": opt_1,
        "scheduler": scheduler_2,
        "frequency": 2
    }

    res_2 = {
        "optimizer": opt_2,
        "scheduler": scheduler_2,
        "frequency": 4
    }

    return res_1, res_2
and a training_step like:
def training_step(self, batch, batches_idx, optimizer_idx):
    """ Simple training step. """
    inputs, labels = batch

    if optimizer_idx == 0:
        loss_1 = self.forward(inputs, labels)
        if self.trainer.use_dp or self.trainer.use_ddp2:
           loss_1 = loss_1.unsqueeze(0)
          
        loss = loss_1
        tqdm_dict = {
            'loss_1': loss_1
        }

    if optimizer_idx == 1:
        loss_2 = self.forward(inputs, labels)
        if self.trainer.use_dp or self.trainer.use_ddp2:
            loss_2 = loss_2.unsqueeze(0)
        loss = loss_2
        tqdm_dict = {
            'loss_2': loss_2
        }

    return {
        'loss': loss,
        'progress_bar': tqdm_dict,
        'log': tqdm_dict
    }
loss_2 is not reported in tensorboard.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

loss_2 to be present in tensorboard.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:

GeForce GTX 1080 Ti
GeForce GTX 1080 Ti


available:         True
version:           10.2


Packages:

numpy:             1.18.4
pyTorch_debug:     False
pyTorch_version:   1.5.0
pytorch-lightning: 0.7.6
tensorboard:       2.2.1
tqdm:              4.46.0


System:

OS:                Linux
architecture:

64bit



processor:         x86_64
python:            3.7.0
version:           #102-Ubuntu SMP Mon May 11 10:07:26 UTC 2020



	</description>
	<comments>
		<comment id='1' author='lucadiliello' date='2020-06-08T23:04:07Z'>
		Update
Using the option --row_log_interval=1 solves the issue.
The problem is in the rows 461 - 465 of training_loop.py
&lt;denchmark-code&gt;# when metrics should be logged
should_log_metrics = batch_idx % self.row_log_interval == 0 or early_stop_epoch
if should_log_metrics or self.fast_dev_run:
    # logs user requested information to logger
    self.log_metrics(batch_step_metrics, grad_norm_dic)
&lt;/denchmark-code&gt;

The problem is that the should_log_metrics boolean variable is computed without taking
into account that, with GANs for example, some steps are done on one optimizer (and with some specific metrics) and some steps are done on one other optim.
Suppose, for example, that you do 4 steps on optim_1 and 1 step on optim_2, with row_log_interval = 10:



Steps
1
1
1
1
2
1
1
1
1
2
1
1
1
1
2
...




Is logged
Y
N
N
N
N
N
N
N
N
N
Y
N
N
N
N
...



As you can see, the step that will print metrics will always be the one of the first optimizer.
		</comment>
	</comments>
</bug>