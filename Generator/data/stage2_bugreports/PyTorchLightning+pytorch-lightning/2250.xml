<bug id='2250' author='s-rog' open_date='2020-06-19T01:14:12Z' closed_time='2020-06-19T03:08:26Z'>
	<summary>dataframes passed outside hparams causing issues</summary>
	<description>
üêõ Bug
In 0.8.0 (updating from 0.7.5), using hyperparameters parsed by test-tube causes an exception.
In 0.8.0 (updating from 0.7.5), dataframes passed outside hparams errors out
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import argparse
import pandas as pd
import pytorch_lightning as pl

parser = argparse.ArgumentParser()
parser.add_argument('--hparam1', default=8, type=int)
parser.add_argument('--hparam2', default="test", type=str)
parser.add_argument('--hparam3', default=True, type=bool)
hparams = parser.parse_args()

some_data = pd.DataFrame([1, 2, 3])

class module(pl.LightningModule):
    def __init__(self, hparams, some_data):
        super(module, self).__init__()
        self.hparams = hparams
        self.data = some_data

    def train_dataloader(self):
        return

    def val_dataloader(self):
        return

    def configure_optimizers(self):
        return
    
    def forward(self, x):
        return x
    
    def training_step(self, batch, batch_idx):
        return batch

    def validation_step(self, batch, batch_idx):
        return batch

model = module(hparams, some_data)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):
  File "train_test.py", line 37, in &lt;module&gt;
    model = module(hparams, some_data)
  File "train_test.py", line 16, in __init__
    self.hparams = hparams
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 638, in __setattr__
    object.__setattr__(self, name, value)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py", line 1695, in hparams
    self.save_hyperparameters(hp, frame=inspect.currentframe().f_back.f_back)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py", line 1662, in save_hyperparameters
    cand_names = [k for k, v in init_args.items() if v == hp]
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py", line 1662, in &lt;listcomp&gt;
    cand_names = [k for k, v in init_args.items() if v == hp]
  File "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py", line 1479, in __nonzero__
    f"The truth value of a {type(self).__name__} is ambiguous. "
ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

hparams is saved correctly as previous versions, disregarding the dataframes
	</description>
	<comments>
		<comment id='1' author='s-rog' date='2020-06-19T01:20:16Z'>
		ummm wait... TTNamespace is a Namespace... this is weird.
can you post minimal code to reproduce?
		</comment>
		<comment id='2' author='s-rog' date='2020-06-19T01:24:42Z'>
		Yeah, I swapped over to pure argparse to test  and my hparams is &lt;class 'argparse.Namespace'&gt; but it doesn't seem to evaluate correctly... let me compile it
		</comment>
		<comment id='3' author='s-rog' date='2020-06-19T01:30:41Z'>
		argparse is 100% supported. we have explicit tests for this
		</comment>
		<comment id='4' author='s-rog' date='2020-06-19T01:32:17Z'>
		&lt;denchmark-code&gt;import argparse
import pandas as pd
import pytorch_lightning as pl

parser = argparse.ArgumentParser()
parser.add_argument('--hparam1', default=8, type=int)
parser.add_argument('--hparam2', default="test", type=str)
parser.add_argument('--hparam3', default=True, type=bool)
hparams = parser.parse_args()

some_data = pd.DataFrame([1, 2, 3])

class module(pl.LightningModule):
    def __init__(self, hparams, some_data):
        super(module, self).__init__()
        self.hparams = hparams
        self.data = some_data

    def train_dataloader(self):
        return

    def val_dataloader(self):
        return

    def configure_optimizers(self):
        return
    
    def forward(self, x):
        return x
    
    def training_step(self, batch, batch_idx):
        return batch

    def validation_step(self, batch, batch_idx):
        return batch

model = module(hparams, some_data)
&lt;/denchmark-code&gt;

ok I just tested it, it's caused by dataframes passed outside hparams
Edit: updated the original post to reflect the true source of the bug
		</comment>
		<comment id='5' author='s-rog' date='2020-06-19T01:40:20Z'>
		got it.
Found the bug!
&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;         self.save_hyperparameters(hp, frame=inspect.currentframe().f_back.f_back)
&lt;/denchmark-code&gt;

we shouldn't be doing frame inspection here...
		</comment>
		<comment id='6' author='s-rog' date='2020-06-19T01:47:29Z'>
		thanks for the quick response, I'll pull from the fork and give it a shot
		</comment>
		<comment id='7' author='s-rog' date='2020-06-19T01:50:38Z'>
		fixed!
&lt;denchmark-link:https://user-images.githubusercontent.com/3640001/85088280-bdccde00-b1ad-11ea-98b7-8aa3bca71956.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1jO8iyCyfC1BiJbjAdqcQxc7Qclil5hok#scrollTo=kppSZVsHRPtJ&gt;https://colab.research.google.com/drive/1jO8iyCyfC1BiJbjAdqcQxc7Qclil5hok#scrollTo=kppSZVsHRPtJ&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>