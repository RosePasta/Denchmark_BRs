<bug id='2891' author='manipopopo' open_date='2020-08-09T04:52:31Z' closed_time='2020-10-04T12:32:19Z'>
	<summary>The total number of batches shows by the progress bar of the sanity check is wrong</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

The total of the sanity check progress bar is set by



pytorch-lightning/pytorch_lightning/callbacks/progress.py


         Line 296
      in
      4d0406e






 self.val_progress_bar.total = convert_inf(trainer.num_sanity_val_steps * len(trainer.val_dataloaders)) 





The progress bar will always show trainer.num_sanity_val_steps even if  the length of the validation DataLoader is less than trainer.num_sanity_val_steps.
Maybe the total could be computed by
from pytorch_lightning.trainer import data_loading

num_full_val_dataloader_batches = [
    len(dataloader) if data_loading._has_len(dataloader) else float('inf')
    for dataloader in trainer.val_dataloaders
]
self.val_progress_bar.total = convert_inf(
    sum(min(num_batches, trainer.num_sanity_val_steps)
            for num_batches in num_full_val_dataloader_batches))
We use the private function data_loading._has_len to check if dataloader has __len__, maybe we could make data_loading._has_len public.
Or we could make num_full_val_dataloader_batches (and num_full_train_dataloader_batches) a member variable of Trainer and update the value in pytorch_lightning.trainer.data_loading.TrainerDataLoadingMixin.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

The progress bar of the sanity check in the following code (num_sanity_val_steps == 999 and len(val_data_loader) == 10) shows
&lt;denchmark-code&gt;Validation sanity check:   1%|          | 9/999 [00:09&lt;16:31,  1.00s/it]`
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

import time

import pytorch_lightning as pl
from torch.utils import data


class Dataset(data.Dataset):

  def __init__(self, length):
    self._elements = list(range(length))

  def __getitem__(self, item):
    return self._elements[item]

  def __len__(self):
    return len(self._elements)


class Model(pl.LightningModule):

  def forward(self, *args, **kwargs):
    pass

  def training_step(self, *args, **kwargs):
    pass

  def train_dataloader(self):
    pass

  def configure_optimizers(self):
    pass

  def validation_step(self, *args, **kwargs):
    time.sleep(1)
    return pl.EvalResult()


if __name__ == '__main__':
  model = Model()

  val_dataset_length = 10
  val_dataset = Dataset(val_dataset_length)
  val_data_loader = data.DataLoader(val_dataset)

  trainer = pl.Trainer(num_sanity_val_steps=999, limit_val_batches=999,
                       max_epochs=0)
  trainer.fit(model, val_dataloaders=val_data_loader)
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The program above should be
&lt;denchmark-code&gt;Validation sanity check: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:10&lt;00:00,  1.00s/it]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:
available:
version:


Packages:

numpy:             1.18.5
pyTorch_debug:     False
pyTorch_version:   1.6.0+cpu
pytorch-lightning: 0.9.0rc11
tensorboard:       1.15.0
tqdm:              4.48.2


System:

OS:                Windows
architecture:

64bit
WindowsPE


processor:
python:            3.7.3
version:           10.0.18362



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='manipopopo' date='2020-08-09T07:33:03Z'>
		&lt;denchmark-link:https://github.com/manipopopo&gt;@manipopopo&lt;/denchmark-link&gt;
 I guess the first solution gets things done without changing anything else. Mind submitting a PR?
		</comment>
		<comment id='2' author='manipopopo' date='2020-08-09T09:30:11Z'>
		I think once &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882&gt;#2882&lt;/denchmark-link&gt;
 gets resolved this issue will be resolved automatically.
		</comment>
		<comment id='3' author='manipopopo' date='2020-08-09T10:58:00Z'>
		It seems that resolve &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882&gt;#2882&lt;/denchmark-link&gt;
 will make the sanity check of  run exactly  steps (or  ) if the validation  has at least 5 batches.
Resolve this issue will make the total of the progress bar for the sanity check be the size of the validation DataLoader if it is less than num_sanity_val_steps (except num_sanity_val_steps == -1).
		</comment>
		<comment id='4' author='manipopopo' date='2020-08-09T12:02:11Z'>
		then I would suggest fixing &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2882&gt;#2882&lt;/denchmark-link&gt;
 first in which we can make self.num_sanity_val_steps to be a list of correct num_steps for each val_dataloader and then we can just do  here to assign it to progress_bar.
		</comment>
		<comment id='5' author='manipopopo' date='2020-08-09T13:53:40Z'>
		It seems that we have several ways to tackle the problem.


Make self.num_sanity_val_steps a list of correct numbers of steps as @rohitgr7 suggests. ProgressBar can update self.val_progress_bar.total using self.num_sanity_val_steps. Accessing the member num_sanity_val_steps may get values different from the one passed into Trainer.__init__.


Add a new member to save a list of correct numbers of steps or save a list of the sizes of validation DataLoaders. ProgressBar can update self.val_progress_bar.total using the new member.  Users of Trainer can still get num_sanity_val_steps passed into Trainer.__init__ by accessing the member num_sanity_val_steps. (Supposing #2882 is resolved and the member num_sanity_val_steps is independent of limit_val_batches )


Compute the correct number of steps in the ProgressBar with the help of pytorch_lightning.trainer.data_loading._has_len


It seems that the values of the public member Trainer.num_sanity_val_steps in stable 0.8.5 and master are different.


In 0.8.5, Trainer.num_sanity_val_steps is num_sanity_val_steps passed in __init__.





pytorch-lightning/pytorch_lightning/trainer/trainer.py


         Line 491
      in
      1e68968






 self.num_sanity_val_steps = float("inf") if num_sanity_val_steps == -1 else num_sanity_val_steps 





sets Trainer.num_sanity_val_steps to float('inf') when the one passed in __init__ is -1.





pytorch-lightning/pytorch_lightning/trainer/trainer.py


         Line 461
      in
      a59e140






 self.num_sanity_val_steps = min(num_sanity_val_steps, limit_val_batches) 





decides Trainer.num_sanity_val_steps according to limit_val_batches  and num_sanity_val_steps passed in __init__.


		</comment>
		<comment id='6' author='manipopopo' date='2020-08-22T04:07:27Z'>
		Fixed by &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2917&gt;#2917&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='manipopopo' date='2020-08-27T21:53:34Z'>
		It's broken again due to refactors, opening this so that we don't forget to fix this. If required, let's fix this after a week once refactors are done.



pytorch-lightning/pytorch_lightning/trainer/trainer.py


         Line 1256
      in
      85cd558






 _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches) 








pytorch-lightning/pytorch_lightning/trainer/evaluation_loop.py


         Line 246
      in
      85cd558






 self.evaluation_loop.on_evaluation_start() 








pytorch-lightning/pytorch_lightning/trainer/evaluate_loop.py


        Lines 53 to 57
      in
      85cd558






 def on_evaluation_start(self, *args, **kwargs): 



 if self.testing: 



 self.trainer.call_hook('on_test_start', *args, **kwargs) 



 else: 



 self.trainer.call_hook('on_validation_start', *args, **kwargs) 








pytorch-lightning/pytorch_lightning/callbacks/progress.py


        Lines 341 to 344
      in
      85cd558






 def on_validation_start(self, trainer, pl_module): 



 super().on_validation_start(trainer, pl_module) 



 self.val_progress_bar = self.init_validation_tqdm() 



 self.val_progress_bar.total = convert_inf(self.total_val_batches) 





		</comment>
		<comment id='8' author='manipopopo' date='2020-09-30T18:26:14Z'>
		this issue is annoying. will fix this.
		</comment>
	</comments>
</bug>