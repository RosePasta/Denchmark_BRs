<bug id='3572' author='diane-wagner' open_date='2020-09-20T18:35:55Z' closed_time='2020-09-22T20:23:54Z'>
	<summary>Metrics compute per batch and not per sample</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Some metrics (e.g. f1-score) compute per batch and not per sample (e.g. per image). What most people expect is that the metric is computed for each sample and then aggregated. The current behavior is not well documented,  which can lead to potential errors in evaluation.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&gt;&gt;&gt; import torch
&gt;&gt;&gt; from pytorch_lightning.metrics.functional import f1_score
&gt;&gt;&gt; pred = torch.tensor([[0, 1], [0, 1]])
&gt;&gt;&gt; target = torch.tensor([[0, 1], [0, 0]])
&gt;&gt;&gt; f1_per_batch = f1_score(pred=pred, target=target, num_classes=2, class_reduction="none")

&gt;&gt;&gt; f1_sample_0 = f1_score(pred=pred[0], target=target[0], num_classes=2, class_reduction="none")
&gt;&gt;&gt; f1_sample_1 = f1_score(pred=pred[1], target=target[1], num_classes=2, class_reduction="none")
&gt;&gt;&gt; f1_mean_across_samples = (f1_sample_0 + f1_sample_1) / 2

&gt;&gt;&gt; f1_per_batch
tensor([0.8000, 0.6667])

&gt;&gt;&gt; f1_mean_across_samples
tensor([0.8333, 0.5000])
However, f1_per_batch != f1_mean_across_samples.
	</description>
	<comments>
		<comment id='1' author='diane-wagner' date='2020-09-20T18:36:37Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='diane-wagner' date='2020-09-22T20:23:54Z'>
		thank you! We are looking into to this is other issues.
		</comment>
	</comments>
</bug>