<bug id='527' author='potrepka' open_date='2019-11-20T06:49:42Z' closed_time='2019-11-27T01:06:08Z'>
	<summary>Checkpoint saving period=10 off by one error</summary>
	<description>
Describe the bug
Checkpoint saving period=10 sometimes is off by one:
./checkpoints/_ckpt_epoch_10.ckpt
./checkpoints/_ckpt_epoch_20.ckpt
./checkpoints/_ckpt_epoch_30.ckpt
./checkpoints/_ckpt_epoch_40.ckpt
./checkpoints/_ckpt_epoch_50.ckpt
./checkpoints/_ckpt_epoch_60.ckpt
./checkpoints/_ckpt_epoch_70.ckpt
./checkpoints/_ckpt_epoch_80.ckpt
./checkpoints/_ckpt_epoch_90.ckpt
./checkpoints/_ckpt_epoch_100.ckpt
./checkpoints/_ckpt_epoch_110.ckpt
./checkpoints/_ckpt_epoch_120.ckpt
./checkpoints/_ckpt_epoch_130.ckpt
./checkpoints/_ckpt_epoch_140.ckpt
./checkpoints/_ckpt_epoch_150.ckpt
./checkpoints/_ckpt_epoch_160.ckpt
./checkpoints/_ckpt_epoch_170.ckpt
./checkpoints/_ckpt_epoch_180.ckpt
./checkpoints/_ckpt_epoch_191.ckpt
Another time, it incremented at 61 and then again at 192.
To Reproduce
No idea why this is happening. It's very random!
Expected behavior
The expected behavior is that it saves every 10 epochs exactly.
Screenshots
None.
Desktop (please complete the following information):

OS: Ubuntu 18.04.3 LTS

Additional context
Saving a checkpoint every 10 epochs.
&lt;denchmark-code&gt;    checkpoint = ModelCheckpoint(
        filepath=os.path.join(os.getcwd(), 'checkpoints'),
        verbose=True,
        save_best_only=False,
        save_weights_only=False,
        period=10
    )
    if setup.cuda_is_available():
        trainer = Trainer(
            distributed_backend='dp',
            gpus=setup.cuda_device_count(),
            checkpoint_callback=checkpoint,
            early_stop_callback=None,
            max_nb_epochs=params.epochs
        )
    else:
        trainer = Trainer(
            checkpoint_callback=checkpoint,
            early_stop_callback=None,
            max_nb_epochs=params.epochs
        )
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='potrepka' date='2019-11-20T13:32:46Z'>
		&lt;denchmark-link:https://github.com/Ir1d&gt;@Ir1d&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jeffling&gt;@jeffling&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='potrepka' date='2019-11-20T14:13:23Z'>
		is the ./checkpoints/_ckpt_epoch_191.ckpt the last one... and if it off does it hold the offset?
@nspotrepka do you have another example from your output? :)
		</comment>
		<comment id='3' author='potrepka' date='2019-11-20T14:52:19Z'>
		Did you use the latest master or the previous release?
		</comment>
		<comment id='4' author='potrepka' date='2019-11-20T21:06:16Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 yes it holds the offset
Another example from my own memory, since I deleted the files:
./checkpoints/_ckpt_epoch_10.ckpt
./checkpoints/_ckpt_epoch_20.ckpt
./checkpoints/_ckpt_epoch_30.ckpt
./checkpoints/_ckpt_epoch_40.ckpt
./checkpoints/_ckpt_epoch_50.ckpt
./checkpoints/_ckpt_epoch_61.ckpt
./checkpoints/_ckpt_epoch_71.ckpt
./checkpoints/_ckpt_epoch_81.ckpt
./checkpoints/_ckpt_epoch_91.ckpt
./checkpoints/_ckpt_epoch_101.ckpt
./checkpoints/_ckpt_epoch_111.ckpt
./checkpoints/_ckpt_epoch_121.ckpt
./checkpoints/_ckpt_epoch_131.ckpt
./checkpoints/_ckpt_epoch_141.ckpt
./checkpoints/_ckpt_epoch_151.ckpt
./checkpoints/_ckpt_epoch_161.ckpt
./checkpoints/_ckpt_epoch_171.ckpt
./checkpoints/_ckpt_epoch_181.ckpt
./checkpoints/_ckpt_epoch_192.ckpt
I don't mind the error, except that I don't get a checkpoint for epoch 200. How do I save the model at the end of training?
		</comment>
		<comment id='5' author='potrepka' date='2019-11-20T21:17:41Z'>
		&lt;denchmark-link:https://github.com/Ir1d&gt;@Ir1d&lt;/denchmark-link&gt;
 yes, 0.5.3.2
		</comment>
		<comment id='6' author='potrepka' date='2019-11-20T22:01:43Z'>
		@nspotrepka to reaction on &lt;denchmark-link:https://github.com/Ir1d&gt;@Ir1d&lt;/denchmark-link&gt;
 pls install from lat master
btw, do you have a sample code we can run to replicate your issue?
		</comment>
		<comment id='7' author='potrepka' date='2019-11-21T04:44:07Z'>
		the modelchecking strategy changed a bit in latest master, you might want to try it out.
Please note that epoch number starts from 0 now.
		</comment>
		<comment id='8' author='potrepka' date='2019-11-22T21:01:36Z'>
		Do you have any overrides related to checkpoints, like state_dict? or anything setting should_checkpoint?
Noticed you have DP settings as well, does the error happen without DP?
		</comment>
		<comment id='9' author='potrepka' date='2019-11-25T11:36:48Z'>
		@nspotrepka how did it go with the suggested fixes?
		</comment>
		<comment id='10' author='potrepka' date='2019-11-27T01:06:08Z'>
		I'm now saving the best model only, so I'm no longer looking at this issue.
		</comment>
	</comments>
</bug>