<bug id='2862' author='sykrn' open_date='2020-08-07T12:37:41Z' closed_time='2020-08-08T10:01:39Z'>
	<summary>Metrics error due to inplace operation, "computation has been modified by an inplace operation".</summary>
	<description>
Hey, &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
, I got a new error since I upgraded the library today.
I used the accuracy metric, but got an error.
&lt;denchmark-h:h3&gt;Code sample:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;# in lightning module
def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        acc = accuracy(y_hat, y)      # from the functional metric classification
        tensorboard_logs = {'train_loss': loss}
        return {'loss': loss, 'log': tensorboard_logs}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Error msg:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.LongTensor [32]] is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Can be solved using .clone() method.&lt;/denchmark-h&gt;

However, when I clone the y before feeding to the accuracy function, no error was shown.
&lt;denchmark-code&gt;acc = accuracy(y_hat, y.clone())
&lt;/denchmark-code&gt;

But, it's inconvenience if user has to do it manually, isn't it?
Actually, I can use the code above without clone before I upgrade to the latest. So, it might due to the latest update/rebase causing this error.

The same error shown for f1_score metric.

	</description>
	<comments>
		<comment id='1' author='sykrn' date='2020-08-07T12:38:21Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='sykrn' date='2020-08-07T13:36:30Z'>
		cc &lt;denchmark-link:https://github.com/justusschock&gt;@justusschock&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='sykrn' date='2020-08-07T14:39:27Z'>
		cc &lt;denchmark-link:https://github.com/Diuven&gt;@Diuven&lt;/denchmark-link&gt;
 , I think you introduced in-place ops for speed-up, right?
Does the speedup only come from inplace methods or can we simply replace them by out-of-place methods ?
		</comment>
		<comment id='4' author='sykrn' date='2020-08-08T03:23:02Z'>
		
cc @Diuven , I think you introduced in-place ops for speed-up, right?
Does the speedup only come from inplace methods or can we simply replace them by out-of-place methods ?

Yeah, you're right. I think this is because of the  I used in . &lt;denchmark-link:https://github.com/Diuven/pytorch-lightning/blob/7195b1dff618eb23d8341eb83fe84fb9167c93b9/pytorch_lightning/metrics/functional/classification.py#L184&gt;This&lt;/denchmark-link&gt;
 is the part.
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2878&gt;This&lt;/denchmark-link&gt;
 is a quick PR fixing this issue. If you may, please check the code still gives the issue.
Sorry for the inconvenience!
		</comment>
		<comment id='5' author='sykrn' date='2020-08-08T10:42:52Z'>
		Great, It runs without any error, now. Thanks for the hotfix. üëç
		</comment>
	</comments>
</bug>