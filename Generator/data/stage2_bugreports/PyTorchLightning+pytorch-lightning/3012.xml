<bug id='3012' author='xiadingZ' open_date='2020-08-17T09:01:13Z' closed_time='2020-08-18T20:04:30Z'>
	<summary>TrainResult doesn't log to tensorboard by default</summary>
	<description>
This is my code:
&lt;denchmark-code&gt;        result = pl.TrainResult(minimize=loss)
        result.log('train_loss', loss, prog_bar=True)
&lt;/denchmark-code&gt;

tensorboard logger doesn't show train_loss.
EvalResult is normal, it can log to tensorboard by default.
	</description>
	<comments>
		<comment id='1' author='xiadingZ' date='2020-08-17T18:02:30Z'>
		cc &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='xiadingZ' date='2020-08-17T19:56:26Z'>
		Hey &lt;denchmark-link:https://github.com/xiadingZ&gt;@xiadingZ&lt;/denchmark-link&gt;
, which version of  are you using? I ran into some issues if I wasn't using the PyPI version of .
Also, which version of PTL are you using?
		</comment>
		<comment id='3' author='xiadingZ' date='2020-08-18T01:52:53Z'>
		2.2.0.  But I tried 2.3.0 and it have same issue, no TrainResult's log
		</comment>
		<comment id='4' author='xiadingZ' date='2020-08-18T10:42:59Z'>
		can you post a colab that replicates this?
i suspect you might be doing something weird for config since we test that things are actually logged when expected...
		</comment>
		<comment id='5' author='xiadingZ' date='2020-08-18T19:54:17Z'>
		I have manually verified this works, see this colab: &lt;denchmark-link:https://colab.research.google.com/drive/1aD1sEYNBLHISvnsUhRzyyOLZtMkk-LWs?usp=sharing&gt;https://colab.research.google.com/drive/1aD1sEYNBLHISvnsUhRzyyOLZtMkk-LWs?usp=sharing&lt;/denchmark-link&gt;
.
Please send a colab or code so we can see what the issue is.  Closing for now.
		</comment>
		<comment id='6' author='xiadingZ' date='2020-09-04T15:13:47Z'>
		I have the same issue: &lt;denchmark-link:https://colab.research.google.com/drive/1s0kUXwXzO9t9Z1MXETohG7pu4dFJ6nej?usp=sharing&gt;https://colab.research.google.com/drive/1s0kUXwXzO9t9Z1MXETohG7pu4dFJ6nej?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='xiadingZ' date='2020-09-16T00:33:54Z'>
		I have the same issue with tensorboard==2.2.0, pytorch-lightning==0.9.0.
Edit: OK, found the reason. Trainer's row_log_interval argument is set to 50 by default. If the number of batches is less than row_log_interval, train metrics are never logged.
		</comment>
	</comments>
</bug>