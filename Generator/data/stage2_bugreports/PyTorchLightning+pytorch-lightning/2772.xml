<bug id='2772' author='JanRuettinger' open_date='2020-07-31T08:34:32Z' closed_time='2020-09-16T18:32:42Z'>
	<summary>Model alone makes different predictions compared to trainer + model</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I have trained a model and stored it in a checkpoint file. When I load the model from the checkpoint file and make predictions for my test set I get different results when I use the raw model compared to when I use the trainer class + model.
&lt;denchmark-h:h3&gt;Problematic code snippets&lt;/denchmark-h&gt;

Using the trainer class
&lt;denchmark-code&gt;trainer = Trainer(gpus=1)
ckpt_path='/content/gdrive/My Drive/colab_projects/colab_demo/checkpoints/model.ckpt'
model = TransferLearningModel.load_from_checkpoint(str(ckpt_path), **config)
trainer.test(model)
&lt;/denchmark-code&gt;

Not using the trainer class
&lt;denchmark-code&gt;model = TransferLearningModel.load_from_checkpoint(str(ckpt_path), **config)
model.freeze()
model.cuda()
with torch.no_grad():
  for x,y in dataloader:
    x = x.cuda()
    output = model(x)
    ....

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

I have setup a colab notebook which reproduces the bug.
&lt;denchmark-link:https://drive.google.com/file/d/16Vjcx_-NZ-pBA2mZJRSfytGTmDC8P9xY/view?usp=sharing&gt;https://drive.google.com/file/d/16Vjcx_-NZ-pBA2mZJRSfytGTmDC8P9xY/view?usp=sharing&lt;/denchmark-link&gt;

Happy to add more information when needed.
	</description>
	<comments>
		<comment id='1' author='JanRuettinger' date='2020-07-31T14:15:22Z'>
		it is interesting, that shall not happen, are you using the same data without shuffle?
&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 mind have a look at it? :]
		</comment>
		<comment id='2' author='JanRuettinger' date='2020-07-31T23:10:21Z'>
		By results, if you are referring to the DataFrames you printed in the notebook, then I think the results looks the same to me.
		</comment>
		<comment id='3' author='JanRuettinger' date='2020-08-03T03:30:46Z'>
		Could it be not running model = model.eval() when not using trainer class.
eval() does more than freeze, it uses overall mean and std for batchnorm instead of running mean and std. Also it will turn off the dropout.
		</comment>
		<comment id='4' author='JanRuettinger' date='2020-08-03T04:49:06Z'>
		&lt;denchmark-link:https://github.com/raynardj&gt;@raynardj&lt;/denchmark-link&gt;
  does that automatically I think.
		</comment>
		<comment id='5' author='JanRuettinger' date='2020-08-03T05:10:04Z'>
		
@raynardj model.freeze() does that automatically I think.

u r right, eval() is there.
I also took a close look at the comparison of 2 dataframe and they r the same
		</comment>
		<comment id='6' author='JanRuettinger' date='2020-08-04T10:41:46Z'>
		&lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/raynardj&gt;@raynardj&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 Any update on this issue?
I am facing a similar behavior in my prediction.
		</comment>
		<comment id='7' author='JanRuettinger' date='2020-08-04T10:44:40Z'>
		&lt;denchmark-link:https://github.com/agemagician&gt;@agemagician&lt;/denchmark-link&gt;
 Can you share code sample we can look at?
		</comment>
		<comment id='8' author='JanRuettinger' date='2020-08-04T10:48:02Z'>
		&lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
  Sure, I will write a Colab notebook for my code and share it, but did you figure out the problem from the above-shared notebook?
		</comment>
		<comment id='9' author='JanRuettinger' date='2020-08-04T10:52:47Z'>
		Not yet. We still don't find the results that are referred in the notebook by author. If the results are the dataframes then both are same. There is no difference in final prediction.
		</comment>
		<comment id='10' author='JanRuettinger' date='2020-08-04T10:55:50Z'>
		
@agemagician Can you share code sample we can look at?

this is the notebook above - &lt;denchmark-link:https://colab.research.google.com/drive/16Vjcx_-NZ-pBA2mZJRSfytGTmDC8P9xY&gt;https://colab.research.google.com/drive/16Vjcx_-NZ-pBA2mZJRSfytGTmDC8P9xY&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='JanRuettinger' date='2020-08-05T10:53:05Z'>
		After implementing the code again in Colab, I figured out the problem.
In my case, the input pipeline for test and prediction was different and that's why I didn't get the same results.
		</comment>
		<comment id='12' author='JanRuettinger' date='2020-08-06T17:44:37Z'>
		&lt;denchmark-link:https://github.com/raynardj&gt;@raynardj&lt;/denchmark-link&gt;
 the results I get are not the same as you can see in the two pictures below. They are similar but not the same. Do you have any pointers where to look for errors?
&lt;denchmark-link:https://user-images.githubusercontent.com/8582703/89564120-d015e080-d81c-11ea-8ebf-01d9b07ced09.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/8582703/89564128-d441fe00-d81c-11ea-8b81-9143f32564e0.png&gt;&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>