<bug id='4849' author='pableeto' open_date='2020-11-25T09:15:46Z' closed_time='2020-11-26T19:19:52Z'>
	<summary>Failed to get correct device id inside on_fit_start() or setup()</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

In DDP training mode, calling self.device in on_fit_start() or setup() function will return "cuda", while calling self.device in training_step will return "cuda:id" where id corrspondes to the correct device id.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;BoringModel(pl.LightningModule):
    def on_fit_start(self):
        print(self.device)      # will always return "cuda" regardless which device it on
    def setup(self, stage):
        print(self.device)      # will always return "cuda" regardless which device it on
    def training_step(self, **kwargs):
        print(self.device)      # will return device ids, e.g. "cuda:0"
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

on_fit_start() and/or setup() should be able to get correct device ids as same in training_step().
	</description>
	<comments>
		<comment id='1' author='pableeto' date='2020-11-25T13:37:17Z'>
		Actually I think this is kind of the correct behaviour. self.device only reflects changes of device types from model parameters.
If you call model.cuda() on your model, self.device only returns cuda (which means, the device should be the torch default gpu) and when you call model.cuda(1) your device will explicitly be the first gpu.
&lt;denchmark-code&gt;&gt;&gt;&gt; model.device
device(type='cpu')
&gt;&gt;&gt; model.cuda()
BoringModel()
&gt;&gt;&gt; model.device
device(type='cuda')
&gt;&gt;&gt; model.cuda(1)
BoringModel()
&gt;&gt;&gt; model.device
device(type='cuda', index=1)
&lt;/denchmark-code&gt;

However, I opened a PR (&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/4851&gt;#4851&lt;/denchmark-link&gt;
) to always include a device index there.
		</comment>
	</comments>
</bug>