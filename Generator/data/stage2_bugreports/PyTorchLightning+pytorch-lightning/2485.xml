<bug id='2485' author='frankier' open_date='2020-07-03T12:18:48Z' closed_time='2020-08-03T19:50:08Z'>
	<summary>Initialising model in setup not compatible with auto_scale_batch_size / auto_lr_find</summary>
	<description>
üêõ Bug
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;


Define your model in setup() as per the introduction guide's recommendation for when the model depends on the dataset https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html#models-defined-by-data
Try to use either auto_scale_batch_size / auto_lr_find

&lt;denchmark-code&gt;  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "train.py", line 76, in train
    trainer.fit(model)
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 879, in fit
    self._run_lr_finder_internally(model)
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/lr_finder.py", line 50, in _run_lr_finder_internally
    lr_finder = self.lr_find(model)
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/lr_finder.py", line 175, in lr_find
    optimizers, _, _ = self.init_optimizers(model)
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/pytorch_lightning/trainer/optimizers.py", line 18, in init_optimizers
    optim_conf = model.configure_optimizers()
  File "litmod.py", line 184, in configure_optimizers
    return torch.optim.SGD(
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/torch/optim/sgd.py", line 68, in __init__
    super(SGD, self).__init__(params, defaults)
  File "/home/frankier/.cache/pypoetry/virtualenvs/skelshop-NSMg5dGi-py3.8/lib/python3.8/site-packages/torch/optim/optimizer.py", line 46, in __init__
    raise ValueError("optimizer got an empty parameter list")
ValueError: optimizer got an empty parameter list
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

auto_scale_batch_size / auto_lr_find rely on the model being initailsed, but if it's initialised in setup(), it won't be ready yet.
I'm not sure whether this is a documentation bug or a behaviour bug.
	</description>
	<comments>
		<comment id='1' author='frankier' date='2020-07-03T12:19:42Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='frankier' date='2020-07-04T11:32:38Z'>
		Duplicate: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2101&gt;#2101&lt;/denchmark-link&gt;

PR fixing this issue: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1998&gt;#1998&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>