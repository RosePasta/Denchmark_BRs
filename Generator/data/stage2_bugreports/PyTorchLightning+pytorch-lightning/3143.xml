<bug id='3143' author='24hours' open_date='2020-08-25T03:25:50Z' closed_time='2020-09-10T21:01:21Z'>
	<summary>Trainer crashed when optimizer frequency is defined.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
Run the following code:
&lt;denchmark-link:https://gist.github.com/24hours/ec67de5384bb05e28544d580ae424639&gt;https://gist.github.com/24hours/ec67de5384bb05e28544d580ae424639&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):
  File "pl_bug.py", line 40, in &lt;module&gt;
    trainer.fit(mnist_model, train_loader) 
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/states.py", line 48, in wrapped_fn
    result = fn(self, *args, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 1073, in fit
    results = self.accelerator_backend.train(model)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/accelerators/gpu_backend.py", line 51, in train
    results = self.trainer.run_pretrain_routine(model)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py", line 1239, in run_pretrain_routine
    self.train()
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 394, in train
    self.run_training_epoch()
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 491, in run_training_epoch
    batch_output = self.run_training_batch(batch, batch_idx)
  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py", line 883, in run_training_batch
    batch_outputs[opt_idx].append(opt_closure_result.training_step_output_for_epoch_end)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

    def configure_optimizers(self):
        optimizer_G = torch.optim.Adam(self.parameters(), lr=0.1, weight_decay=1e-5)
        optimizer_D = torch.optim.Adam(self.parameters(), lr=0.1, weight_decay=1e-5)

        return [
                {'optimizer': optimizer_D, 'frequency': 5},
                {'optimizer': optimizer_G, 'frequency': 1}
            ]
the culprit is 'frequency' : 5, removing the line will allow trainer to run smoothly.
&lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/lightning-module.html?highlight=optimizers#configure-optimizers&gt;https://pytorch-lightning.readthedocs.io/en/latest/lightning-module.html?highlight=optimizers#configure-optimizers&lt;/denchmark-link&gt;

The definition is correct according to this documentation.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Model should train without crash.
The code work in 0.8.5 environment.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:

GeForce GTX TITAN X


available:         True
version:           11.0


Packages:

numpy:             1.18.5
pyTorch_debug:     False
pyTorch_version:   1.6.0a0+9907a3e
pytorch-lightning: 0.9.0
tensorboard:       2.2.0
tqdm:              4.48.2


System:

OS:                Linux
architecture:

64bit



processor:         x86_64
python:            3.6.10
version:           #110-Ubuntu SMP Tue Jun 23 02:39:32 UTC 2020



	</description>
	<comments>
		<comment id='1' author='24hours' date='2020-08-25T03:26:32Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='24hours' date='2020-08-25T07:08:55Z'>
		this is the case with multiple optimizers, you need to spec them.. so you would prefer having default 1 if freq is not specified?
		</comment>
		<comment id='3' author='24hours' date='2020-08-25T10:24:40Z'>
		the exception occur because trainer_loop.py incorrect count number of optimizer if frequency is defined. Since this configuration work in version 0.8.5, this look like regression error.
Unless of course if the configuration is unsupported in version 0.9.0
		</comment>
		<comment id='4' author='24hours' date='2020-08-25T22:23:14Z'>
		
so you would prefer having default 1 if freq is not specified?

That is a totally different case I think. If the frequency is not specified we run train_step for both optimizers but if it is specified to 1 for both then in such case it will run 1st batch for opt_1, 2nd for opt_2, 3rd for opt_1, 4th for opt_2...
A simple fix here can be:



pytorch-lightning/pytorch_lightning/trainer/training_loop.py


         Line 872
      in
      a7705c8






 batch_outputs[opt_idx].append(opt_closure_result.training_step_output_for_epoch_end) 





if len(batch_outputs) == 1:  # when frequencies are defined
    batch_outputs[0].append(opt_closure_result.training_step_output_for_epoch_end)
else:  # no frequencies
    batch_outputs[opt_idx].append(opt_closure_result.training_step_output_for_epoch_end)
		</comment>
		<comment id='5' author='24hours' date='2020-08-27T14:12:39Z'>
		ok, can someone write a test and submit a PR for this? show the test failing on master first.
&lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
  or &lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
 ?
		</comment>
	</comments>
</bug>