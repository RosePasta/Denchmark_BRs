<bug id='698' author='matthew-z' open_date='2020-01-17T05:04:44Z' closed_time='2020-02-26T21:55:19Z'>
	<summary>Error with Iterable Dataset</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Currently, the num_training_batches is set to inf when the dataset is in iterable-style, which may lead to this error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "scripts/msmacro.py", line 119, in &lt;module&gt;
    main()
  File "scripts/msmacro.py", line 115, in main
    trainer.fit(model)
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 417, in fit
    self.run_pretrain_routine(model)
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 481, in run_pretrain_routine
    self.get_dataloaders(ref_model)
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py", line 199, in get_dataloaders
    self.init_train_dataloader(model)
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py", line 78, in init_train_dataloader
    self.val_check_batch = int(self.num_training_batches * self.val_check_interval)
OverflowError: cannot convert float infinity to integer
&lt;/denchmark-code&gt;

workaround: set val_check_interval to an integer.
However, if the validation dataset is also in iterable style, then the following error will be raised, as there is no dataset type check in loading validation dataset
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "scripts/msmacro.py", line 119, in &lt;module&gt;
    main()
  File "scripts/msmacro.py", line 115, in main
    trainer.fit(model)
  File "/home/zhaohao/Documents/pytorch-lightning/pytorch_lightning/trainer/trainer.py", line 417, in fit
    self.run_pretrain_routine(model)
  File "/home/zhaohao/Documents/pytorch-lightning/pytorch_lightning/trainer/trainer.py", line 481, in run_pretrain_routine
    self.get_dataloaders(ref_model)
  File "/home/zhaohao/Documents/pytorch-lightning/pytorch_lightning/trainer/data_loading.py", line 201, in get_dataloaders
    self.init_val_dataloader(model)
  File "/home/zhaohao/Documents/pytorch-lightning/pytorch_lightning/trainer/data_loading.py", line 117, in init_val_dataloader
    self.num_val_batches = sum(len(dataloader) for dataloader in self.get_val_dataloaders())
  File "/home/zhaohao/Documents/pytorch-lightning/pytorch_lightning/trainer/data_loading.py", line 117, in &lt;genexpr&gt;
    self.num_val_batches = sum(len(dataloader) for dataloader in self.get_val_dataloaders())
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 297, in __len__
    return len(self._index_sampler)  # with iterable-style dataset, this will error
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/sampler.py", line 212, in __len__
    return (len(self.sampler) + self.batch_size - 1) // self.batch_size
  File "/home/zhaohao/.anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 57, in __len__
    raise TypeError('Cannot determine the DataLoader length of a IterableDataset')
TypeError: Cannot determine the DataLoader length of a IterableDataset
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='matthew-z' date='2020-01-21T12:24:49Z'>
		&lt;denchmark-link:https://github.com/matthew-z&gt;@matthew-z&lt;/denchmark-link&gt;
 want to submit a PR?
		</comment>
	</comments>
</bug>