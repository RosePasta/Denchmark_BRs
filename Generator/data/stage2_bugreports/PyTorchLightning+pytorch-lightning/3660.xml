<bug id='3660' author='ktrapeznikov' open_date='2020-09-25T20:04:03Z' closed_time='2020-12-02T13:05:13Z'>
	<summary>Colab TPU training stuck at end of epoch if checkpoint_callback=True</summary>
	<description>
I am seeing training stuck at the last step of the 1st epoch when checkpoint_callback=True is enabled. I am passing tpu_cores=8 to the trainer.
If it's False training is still slow for the first few steps and then it speeds up (I guess that this is expected since it takes a few steps for xla to compile stuff).
Here is a &lt;denchmark-link:https://colab.research.google.com/drive/1QCI_Nuz0iswNkVcdkJOFBtR8War1Xr7h?usp=sharing&gt;link&lt;/denchmark-link&gt;
 to the colab notebook example.
### Setup Model
class GPT2Tuned(pl.LightningModule):
    def __init__(self, hparams: argparse.Namespace):
        super().__init__()
        self.hparams = hparams
        self.model = AutoModelForCausalLM.from_pretrained(self.hparams.model_name_or_path)

    def forward(self, **inputs):
        return self.model(**inputs)
        
    def _step(self,batch):
        inputs = {"input_ids": batch[0]}
        inputs["labels"] = batch[0]
        outputs = self(**inputs)
        loss = outputs[0]
        return dict(loss=loss)

    def training_step(self, batch, batch_idx):
        out_dict = self._step(batch)
        return dict(loss=out_dict["loss"], log=out_dict)

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)

    def train_dataloader(self):
      # fake data
        dataset = TensorDataset(torch.randint(10000,(10000,128)).long()) 
        return  DataLoader(
            dataset,
            batch_size=self.hparams.batch_size,
            shuffle=True
        )

    @staticmethod
    def add_model_specific_args(parser):
        parser.add_argument("--model_name_or_path",type=str)
        parser.add_argument("--batch_size", default=4, type=int)
        parser.add_argument("--learning_rate", default=5e-5, type=float)
        return parser

#### Training 
parser = argparse.ArgumentParser()
parser = GPT2Tuned.add_model_specific_args(parser)
parser = pl.Trainer.add_argparse_args(parser)
args = parser.parse_args(["--gpus","0"])

args.__dict__.update(dict(model_name_or_path  = "gpt2-medium",
                          batch_size = 3,
                          precision=16,
                          tpu_cores=8))

model = GPT2Tuned(args)
trainer = pl.Trainer.from_argparse_args(args, checkpoint_callback=True)  
trainer.fit(model)
	</description>
	<comments>
		<comment id='1' author='ktrapeznikov' date='2020-09-25T20:04:41Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='ktrapeznikov' date='2020-09-25T22:16:39Z'>
		Thanks for the reproduction script.
Could be related &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2700&gt;#2700&lt;/denchmark-link&gt;

There is a PR for fixing checkpointing on TPU: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2726&gt;#2726&lt;/denchmark-link&gt;
 (need check if this applies)
		</comment>
		<comment id='3' author='ktrapeznikov' date='2020-09-25T22:54:26Z'>
		Thanks. Seems related. Is there another mechanism to save checkpoints as a temporary fix?
		</comment>
		<comment id='4' author='ktrapeznikov' date='2020-10-01T14:50:58Z'>
		&lt;denchmark-link:https://github.com/ktrapeznikov&gt;@ktrapeznikov&lt;/denchmark-link&gt;
  mind checking it now as Google Colab had an internal issue with TPUs in past days...
		</comment>
		<comment id='5' author='ktrapeznikov' date='2020-10-13T22:18:21Z'>
		Last time I tried... same issue
		</comment>
		<comment id='6' author='ktrapeznikov' date='2020-10-14T20:04:24Z'>
		This would be a nice feature to have since I would rarely do inference on TPU, just training.
		</comment>
		<comment id='7' author='ktrapeznikov' date='2020-10-22T16:06:22Z'>
		&lt;denchmark-link:https://github.com/lezwon&gt;@lezwon&lt;/denchmark-link&gt;
 maybe you can help revive the tpu + checkpoint fix?
		</comment>
		<comment id='8' author='ktrapeznikov' date='2020-10-22T16:25:27Z'>
		Been working on it. Finding it a bit tricky. I'll raise a PR with the current work I've done.
		</comment>
		<comment id='9' author='ktrapeznikov' date='2020-10-30T15:25:25Z'>
		hi, i am experiencing being stuck on 0% at first epoch when using TPU with pytorch-lightning. any possible reasons why?
		</comment>
		<comment id='10' author='ktrapeznikov' date='2020-11-01T18:51:37Z'>
		&lt;denchmark-link:https://github.com/sarmientoj24&gt;@sarmientoj24&lt;/denchmark-link&gt;
 mind share the notebook?
		</comment>
	</comments>
</bug>