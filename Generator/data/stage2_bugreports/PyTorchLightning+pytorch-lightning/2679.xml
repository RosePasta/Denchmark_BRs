<bug id='2679' author='drStacky' open_date='2020-07-23T17:53:41Z' closed_time='2020-08-11T14:11:44Z'>
	<summary>Default checkpoint location problematic when using docker</summary>
	<description>
The default behavior of ModelCheckpoint is to use os.getcwd(). Outside my docker container, this ended up being the same directory where my tensorboard logs were saved (e.g. /my/dir/tb_logs/default/version_0/checkpoints/).  But inside the docker container, it saved to the internal working directory (e.g. /home/default/version_0/checkpoints/). Since this location disappeared along with the container, the checkpoint was gone, and there was no warning raised to explain why.
Requiring a checkpoint directory isn't desirable, but I'd like to help others avoid this grief in the future. Is there a better way to infer a default location than os.getcwd()? Something as simple as a print statement with the checkpoint location would have saved me a lot of time troubleshooting.
	</description>
	<comments>
		<comment id='1' author='drStacky' date='2020-07-23T17:54:41Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='drStacky' date='2020-08-08T05:21:33Z'>
		You can set the default_root_dir arg in the Trainer. Is that what you want? Otherwise there is an option verbose in the ModelCheckpoint callback which, when turned on, should print the file path everytime it saves.
		</comment>
		<comment id='3' author='drStacky' date='2020-08-11T14:11:44Z'>
		Somehow I misread the explanation of default_root_dir. I thought it only changed the name of the default directory, not the whole path. This is exactly what I needed. Thanks!
		</comment>
	</comments>
</bug>