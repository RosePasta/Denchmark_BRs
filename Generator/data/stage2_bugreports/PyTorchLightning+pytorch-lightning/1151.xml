<bug id='1151' author='wxc-kumar' open_date='2020-03-15T01:12:01Z' closed_time='2020-03-15T01:32:45Z'>
	<summary>epoch_end Logs Default to Steps Instead of Epochs</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Logs generated within validation_epoch_end have their iteration set to the number of steps instead of number of epochs.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Create LightningModile with the below functions.
Train the module for 1 or more epochs
Run Tensorboard
Note the iteration for logs generated in validation_epoch_end

&lt;denchmark-h:h3&gt;Code Sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;    def training_step(self, train_batch, batch_idx):
        x, y = train_batch
        y_hat = self.forward(x)
        loss = self.cross_entropy_loss(y_hat, y)
        accuracy = self.accuracy(y_hat, y)
        logs = {'batch/train_loss': loss}
        return {'loss': loss, 'log': logs}

    def validation_step(self, val_batch, batch_idx):
        x, y = val_batch
        y_hat = self.forward(x)
        loss = self.cross_entropy_loss(y_hat, y)
        accuracy = self.accuracy(y_hat, y)
        return {'batch/val_loss': loss, 'batch/accuracy': accuracy}

    def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([x['batch/val_loss'] for x in outputs]).mean()
        avg_accuracy = torch.stack([x['batch/accuracy'] for x in outputs]).mean()
        tensorboard_logs = {'epoch/val_loss': avg_loss, 'epoch/accuracy' : avg_accuracy}
        return {'avg_val_loss': avg_loss, 'accuracy' : avg_accuracy, 'log': tensorboard_logs}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Version&lt;/denchmark-h&gt;

v0.7.1
&lt;denchmark-h:h3&gt;Screenshot&lt;/denchmark-h&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/47310078/76693247-3d7f6580-661f-11ea-9239-ef05b899c88e.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Logs generated in *_epoch_end functions use the epoch as their iteration on the y axis
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

The documentation seems unclear on the matter. The &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/loggers.html&gt;Loggers&lt;/denchmark-link&gt;
 documentation is empty. The &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/lightning-module.html#lightningmodule-class&gt;LightningModule&lt;/denchmark-link&gt;
 class doesn't describe logging in detail and the &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html#logging&gt;Introduction Guide&lt;/denchmark-link&gt;
 has a bug in the example  -&gt; .
Is there a workaround for this issue?
	</description>
	<comments>
		<comment id='1' author='wxc-kumar' date='2020-03-15T01:32:45Z'>
		Looks like the LightningModule documentation for validation_epoch_end has a note regarding this, to use step key as in: 'log': {'val_acc': val_acc_mean.item(), 'step': self.current_epoch}. This does work correctly as a workaround - perhaps this should be the default for epoch end?
		</comment>
		<comment id='2' author='wxc-kumar' date='2020-11-27T17:25:01Z'>
		
Looks like the LightningModule documentation for validation_epoch_end has a note regarding this, to use step key as in: 'log': {'val_acc': val_acc_mean.item(), 'step': self.current_epoch}. This does work correctly as a workaround - perhaps this should be the default for epoch end?

In the current version of PytorchLightening we are encouraged to use self.log() to log statistics, as opposed to returning a dictionary as mentioned in the previous comment. I can not see an obvious way to control the step with the new self.log() method?
		</comment>
		<comment id='3' author='wxc-kumar' date='2020-12-07T10:31:43Z'>
		Until the step functionality is introduced in self.log one could use self.logger.log_metrics and self.logger.agg_and_log_metrics instead which both have a step argument.
		</comment>
		<comment id='4' author='wxc-kumar' date='2020-12-15T15:33:06Z'>
		self.logger.log_metrics does work nicely, but it is not the ultimate solution I hope
		</comment>
	</comments>
</bug>