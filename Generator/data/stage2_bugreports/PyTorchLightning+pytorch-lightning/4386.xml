<bug id='4386' author='Vozf' open_date='2020-10-27T09:24:16Z' closed_time='2020-10-30T03:47:38Z'>
	<summary>After trainer resume_from_checkpoint checkpoint_callback doesn't restore best metric value</summary>
	<description>
After I restore training with
&lt;denchmark-code&gt;    pl_model = LightningModel.load_from_checkpoint(str(ckpt_path))

    trainer = Trainer(
        resume_from_checkpoint=str(ckpt_path.name),
        logger=instantiate(cfg.logger, experiment_key=cfg.experiment_id),
        checkpoint_callback=instantiate(cfg.checkpoint.model_checkpoint),
        callbacks=[instantiate(callback) for callback in cfg.callbacks],
    )
    trainer.fit(pl_model)
&lt;/denchmark-code&gt;

instantiate from facebook/hydra
The training process doesnt restore the best metric value and starts from scratch so I'm getting on the first restored epoch
&lt;denchmark-code&gt;INFO:lightning:Epoch 1129: val_mae reached 0.10418 (best 0.10418), saving model to
&lt;/denchmark-code&gt;

When there was a better checkpoint before interruption
	</description>
	<comments>
		<comment id='1' author='Vozf' date='2020-10-27T12:16:12Z'>
		Hey &lt;denchmark-link:https://github.com/Vozf&gt;@Vozf&lt;/denchmark-link&gt;
,
Could you mind reproducing the bug with our https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pl_examples/bug_report_model.py.
But my guess is a misuse of Hydra instantiate :) Will re-created ModelCheckpoint without reloading previously trained state instantiate(cfg.checkpoint.model_checkpoint)
Best, T.C
		</comment>
		<comment id='2' author='Vozf' date='2020-10-27T12:19:00Z'>
		ModelCheckpoint should be reloaded manually? Currently I create it with instantiate and expect trainer to restore its state? Isn't it an expected way of state restoring for ModelCheckpoint?
		</comment>
		<comment id='3' author='Vozf' date='2020-10-29T21:04:38Z'>
		Yes, I believe this is related to the bug &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4014&gt;#4014&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/4336&gt;#4336&lt;/denchmark-link&gt;
 will fix that.
		</comment>
		<comment id='4' author='Vozf' date='2020-10-30T03:52:25Z'>
		&lt;denchmark-link:https://github.com/Vozf&gt;@Vozf&lt;/denchmark-link&gt;
 this should be fixed now. make sure to pass your modelcheckpoint instance to the callbacks, i.e.:
trainer = Trainer(
        resume_from_checkpoint=str(ckpt_path.name),
        logger=instantiate(cfg.logger, experiment_key=cfg.experiment_id),
        # don't pass in an object here
        # checkpoint_callback=instantiate(cfg.checkpoint.model_checkpoint),
        # user-defined checkpoint callback must go into this list:
        callbacks=[instantiate(callback) for callback in cfg.callbacks] + [instantiate(cfg.checkpoint.model_checkpoint)],
    )
It's probably best if you change your configuration so that the model checkpoint is directly in cfg.callbacks.
		</comment>
		<comment id='5' author='Vozf' date='2020-10-30T06:51:09Z'>
		Thanks for advice. But what is the difference when passsing modelCheckpoint as callback vs chekpoint_callback?
		</comment>
		<comment id='6' author='Vozf' date='2020-10-30T06:53:49Z'>
		there isn't supposed to be a difference, however, the latter is now deprecated and will be unsupported.
all callbacks must be passed into the callbacks list going forward.
EDIT: I meant to say the latter
		</comment>
	</comments>
</bug>