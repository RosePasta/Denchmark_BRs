<bug id='558' author='mpariente' open_date='2019-11-28T16:22:16Z' closed_time='2019-11-30T19:50:50Z'>
	<summary>`trainer.on_gpu == True` for `gpus = 0` or `gpus=[]`</summary>
	<description>

 for  or  because of &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L135&gt;this line&lt;/denchmark-link&gt;
.
When resuming from a checkpoint, the model is transfered to gpu at &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/9785a3e78e6c5b5ff2bde45d36f5e1165dbe16ab/pytorch_lightning/trainer/trainer_io.py#L171&gt;this line&lt;/denchmark-link&gt;
, even if 
Expected behavior
gpus=0 should make training happen on CPU.
I can make a PR for that, the fix is pretty simple, I think we can just replace
self.on_gpu = gpus is not None and torch.cuda.is_available()
by
self.on_gpu = True if (gpus and torch.cuda.is_available()) else False
Am I missing something?
	</description>
	<comments>
		<comment id='1' author='mpariente' date='2019-11-28T23:17:21Z'>
		Thanks for bringing this up. To use no gpus just set
&lt;denchmark-code&gt;gpus=None
&lt;/denchmark-code&gt;

Or don't pass any arguments to trainer about gpu
If you think that gpus=0 or gpus=[] should also run on no GPUs feel free to submit a PR
		</comment>
	</comments>
</bug>