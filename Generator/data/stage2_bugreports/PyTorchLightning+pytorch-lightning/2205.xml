<bug id='2205' author='xiadingZ' open_date='2020-06-16T02:29:09Z' closed_time='2020-09-16T18:31:56Z'>
	<summary>[metrics] Accuracy Metric: Tensors must be CUDA and dense</summary>
	<description>
I try the new Accuracy Metric, but it throws error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "main.py", line 139, in &lt;module&gt;
    main(hparams)
  File "main.py", line 69, in main
    trainer.fit(model)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 820, in fit
    self.ddp_train(task, model)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_data_parallel.py", line 502, in ddp_train
    self.run_pretrain_routine(model)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 990, in run_pretrain_routine
    False)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 278, in _evaluate
    output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 418, in evaluation_forward
    output = model(*args)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 558, in __call__
    result = self.forward(*input, **kwargs)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 96, in forward
    output = self.module.validation_step(*inputs[0], **kwargs[0])
  File "/mnt/lustre/maxiao1/PVM/models/baseline.py", line 374, in validation_step
    acc = self.accuracy(labels_hat, labels)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/metric.py", line 147, in __call__
    return apply_to_collection(self._orig_call(*args, **kwargs), torch.Tensor,
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py", line 59, in new_func
    return func_to_apply(result, *dec_args, **dec_kwargs)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py", line 26, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/pytorch_lightning/metrics/converters.py", line 244, in _sync_ddp_if_available
    async_op=False)
  File "/mnt/lustre/maxiao1/anaconda3/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py", line 898, in all_reduce
    work = _default_pg.allreduce([tensor], opts)
RuntimeError: Tensors must be CUDA and dense
&lt;/denchmark-code&gt;

This is my code:
&lt;denchmark-code&gt;            pred = pred.view(-1, pred.shape[-1])
            labels = labels.view(-1)
            valid_index = torch.where(labels != -1)
            # select valid part to calculate
            pred = pred[valid_index].contiguous()
            labels = labels[valid_index].contiguous()
            loss = self.loss_fn(pred, labels)
            labels_hat = torch.argmax(pred, dim=1).type_as(labels)
            acc = self.accuracy(labels_hat, labels)
&lt;/denchmark-code&gt;

Also have a question, TensorMetric's default reduce_op is SUM, does it automatically calculate average acc?
	</description>
	<comments>
		<comment id='1' author='xiadingZ' date='2020-06-16T11:37:36Z'>
		1.) What are your devices for labels_hat and labels? Are you running in a DDP environment?
2.) No it doesn't. It does what it says (calculates the sum) unfortunately there is no DDP reduction  op that calculates the average. For averaging, you still need to divide by the size of your process group
		</comment>
		<comment id='2' author='xiadingZ' date='2020-06-16T11:47:34Z'>
		This is my code:
&lt;denchmark-code&gt;            imgs = batch['imgs']
            labels = batch['labels']
            result = self(imgs)

            pred = result['total']
            pred = pred.view(-1, pred.shape[-1])
            labels = labels.view(-1)
            valid_index = torch.where(labels != -1)
            # select valid part to calculate
            pred = pred[valid_index]
            labels = labels[valid_index]
            loss = self.loss_fn(pred, labels)
            labels_hat = torch.argmax(pred, dim=1).type_as(labels)
            acc = self.accuracy(labels_hat, labels)
&lt;/denchmark-code&gt;

I'm running in DDP environment, I think labels be automatically transfered to one gpu device, and I use type_as to ensure labels_hat on same device as labels
		</comment>
		<comment id='3' author='xiadingZ' date='2020-06-16T11:51:39Z'>
		can you try to call .contiguous() on the tensors before?
		</comment>
		<comment id='4' author='xiadingZ' date='2020-06-16T11:53:22Z'>
		I tried on labels and labels_hat, but it doesn't work
		</comment>
		<comment id='5' author='xiadingZ' date='2020-06-16T11:53:53Z'>
		do you use sparse tensors?
		</comment>
		<comment id='6' author='xiadingZ' date='2020-06-16T11:54:42Z'>
		No
		</comment>
		<comment id='7' author='xiadingZ' date='2020-06-16T11:59:43Z'>
		And I think 2) should add some example in docs. Now code example  in docs is
&lt;denchmark-code&gt;# PyTorch Lightning
class MyModule(LightningModule):
    def __init__(self):
        super().__init__()
        self.metric = Accuracy()

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = ...
        acc = self.metric(y_hat, y)
&lt;/denchmark-code&gt;

and it says can run in ddp mode, but it doesn't say we should divide by the size of process group by hand if using ddp
		</comment>
		<comment id='8' author='xiadingZ' date='2020-06-16T12:00:53Z'>
		But it also does not state, that it calculates the mean. I will have a look how much work it is, to integrate this.
		</comment>
		<comment id='9' author='xiadingZ' date='2020-09-01T18:02:47Z'>
		&lt;denchmark-link:https://github.com/xiadingZ&gt;@xiadingZ&lt;/denchmark-link&gt;
 are you still facing the  error?
Your second point, about dividing by result by process group can be achieved by setting the  argument to either  or  (solved by PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2568&gt;#2568&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='10' author='xiadingZ' date='2020-09-16T18:31:56Z'>
		closing this. please comment if this needs to be reopened.
		</comment>
		<comment id='11' author='xiadingZ' date='2020-10-03T21:23:33Z'>
		
@xiadingZ are you still facing the RuntimeError: Tensors must be CUDA and dense error?

I am running into this issue, using R2Score metric. Same traceback.
		</comment>
		<comment id='12' author='xiadingZ' date='2020-10-05T13:11:47Z'>
		&lt;denchmark-link:https://github.com/wconnell&gt;@wconnell&lt;/denchmark-link&gt;
 is am not able to reproduce on master using . Do you have an code example that can reproduce the error?
		</comment>
	</comments>
</bug>