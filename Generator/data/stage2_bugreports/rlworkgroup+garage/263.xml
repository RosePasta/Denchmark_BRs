<bug id='263' author='ryanjulian' open_date='2018-08-09T21:59:03Z' closed_time='2018-08-11T03:14:24Z'>
	<summary>CategorialMLPPolicy is broken</summary>
	<description>
import gym

from garage.baselines import LinearFeatureBaseline
from garage.misc.instrument import run_experiment
from garage.misc.instrument import stub
from garage.tf.algos import TRPO
from garage.tf.envs import TfEnv
from garage.tf.policies import CategoricalMLPPolicy

# Need to wrap in a tf environment and force_reset to true
# see https://github.com/openai/rllab/issues/87#issuecomment-282519288
env = TfEnv(gym.make("CartPole-v0"))

policy = CategoricalMLPPolicy(
    name="policy", env_spec=env.spec, hidden_sizes=(32, 32))

baseline = LinearFeatureBaseline(env_spec=env.spec)

algo = TRPO(
    env=env,
    policy=policy,
    baseline=baseline,
    batch_size=4000,
    max_path_length=200,
    n_itr=120,
    discount=0.99,
    step_size=0.01,
)

algo.train()
(garage) rjulian@tars:~/code/garage$ python examples/tf/trpo_gym_tf_cartpole.py 
WARN: gym.spaces.Box autodetected dtype as &lt;class 'numpy.float32'&gt;. Please provide explicit dtype.
Traceback (most recent call last):
  File "examples/tf/trpo_gym_tf_cartpole.py", line 27, in &lt;module&gt;
    step_size=0.01,
  File "/home/rjulian/code/garage/garage/tf/algos/trpo.py", line 40, in __init__
    **kwargs)
  File "/home/rjulian/code/garage/garage/tf/algos/npo.py", line 52, in __init__
    super(NPO, self).__init__(policy=policy, **kwargs)
  File "/home/rjulian/code/garage/garage/tf/algos/batch_polopt.py", line 90, in __init__
    self.init_opt()
  File "/home/rjulian/code/garage/garage/tf/algos/npo.py", line 62, in init_opt
    pol_loss, pol_kl = self._build_policy_loss(pol_loss_inputs)
  File "/home/rjulian/code/garage/garage/tf/algos/npo.py", line 218, in _build_policy_loss
    policy_entropy = self._build_entropy_term(i)
  File "/home/rjulian/code/garage/garage/tf/algos/npo.py", line 315, in _build_entropy_term
    name="policy_dist_info_flat")
  File "/home/rjulian/code/garage/garage/tf/policies/categorical_mlp_policy.py", line 71, in dist_info_sym
    return dict(prob)
  File "/home/rjulian/miniconda2/envs/garage/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 436, in __iter__
    "Tensor objects are not iterable when eager execution is not "
TypeError: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.
(garage) rjulian@tars:~/code/garage$ 
	</description>
	<comments>
		<comment id='1' author='ryanjulian' date='2018-08-09T22:14:31Z'>
		Similarly, once fixed with
    @overrides
    def dist_info_sym(self, obs_var, state_info_vars=None, name=None):
        with tf.name_scope(name, "dist_info_sym", [obs_var, state_info_vars]):
            with tf.name_scope(self._prob_network_name, values=[obs_var]):
                prob = L.get_output(
                    self._l_prob, {self._l_obs: tf.cast(obs_var, tf.float32)})
            return dict(prob=prob)  # fix here
Traceback (most recent call last):
  File "/home/rjulian/code/garage/scripts/run_experiment.py", line 191, in &lt;module&gt;
    run_experiment(sys.argv)
  File "/home/rjulian/code/garage/scripts/run_experiment.py", line 171, in run_experiment
    method_call(variant_data)
  File "examples/tf/ppo_pendulum.py", line 47, in run_task
    algo.train()
  File "/home/rjulian/code/garage/garage/tf/algos/batch_polopt.py", line 123, in train
    paths = self.obtain_samples(itr)
  File "/home/rjulian/code/garage/garage/tf/algos/batch_polopt.py", line 104, in obtain_samples
    return self.sampler.obtain_samples(itr)
  File "/home/rjulian/code/garage/garage/tf/samplers/vectorized_sampler.py", line 65, in obtain_samples
    next_obses, rewards, dones, env_infos = self.vec_env.step(actions)
  File "/home/rjulian/code/garage/garage/tf/envs/vec_env_executor.py", line 24, in step
    dones[self.ts &gt;= self.max_path_length] = True
IndexError: boolean index did not match indexed array along dimension 0; dimension is 1 but corresponding boolean dimension is 20
		</comment>
		<comment id='2' author='ryanjulian' date='2018-08-09T22:46:44Z'>
		Should we change the following code in garage/envs/proxy_env.py? Because gym.Env has no attribute log_diagnostics, why not set this to pass?
&lt;denchmark-code&gt;    def log_diagnostics(self, paths, *args, **kwargs):
        self._wrapped_env.log_diagnostics(paths, *args, **kwargs)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='ryanjulian' date='2018-08-09T22:49:29Z'>
		This should be addressed in &lt;denchmark-link:https://github.com/rlworkgroup/garage/issues/248&gt;#248&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>