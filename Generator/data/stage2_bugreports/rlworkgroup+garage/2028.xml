<bug id='2028' author='zfang399' open_date='2020-09-07T05:19:51Z' closed_time='2020-09-11T23:09:58Z'>
	<summary>MTSAC not learning</summary>
	<description>
&lt;denchmark-link:https://github.com/avnishn&gt;@avnishn&lt;/denchmark-link&gt;

Hi! Thank you for developing and maintaining this great repo. It makes developing and benchmarking models so much easier.
I am trying to run the baseline MTSAC on metaworld mt10 and mt50. However, it seems that the model is not learning anything (the success rate and return for each task are not changing much). For mt10, the success rate remains 0 at 3.6e+06 env steps / iteration 90 (with an average return of 3.08112). I'm observing similar things for mt50. Have you run into similar problems and do you have any suggestions on how I can approach those problems?
I am using the 2020-06 release of garage (installed from pip), with the correct metaworld version (the one provided in setup.py. The example scripts I'm using are from the 2020-06 release branch of the repo. The only thing I changed in the code was in python3.6/site-packages/garage/torch/algos/sac.py line 202, where I changed the is in the assert to a ==, due to an error at the runtime of mtsac_metaworld_mt10.py, which should not affect the algorithm's performance. I also tested the sac_half_cheetah_batch.py, which trains normally as the return goes to a few thousand after some iterations.
Thanks a lot for your help! Please let me know if there's anything unclear in my description, or if you need any other information about this problem.
	</description>
	<comments>
		<comment id='1' author='zfang399' date='2020-09-07T16:31:12Z'>
		Hey &lt;denchmark-link:https://github.com/zfang399&gt;@zfang399&lt;/denchmark-link&gt;
, thanks for checking out garage!
There's a few fixes that we are currently attempting to backport onto SAC and MTSAC, and you can find the pr where I do that here: &lt;denchmark-link:https://github.com/rlworkgroup/garage/pull/2002&gt;#2002&lt;/denchmark-link&gt;

Can you rebase your branch onto those changes and let me know if that solves your problem?
Thanks!
Avnish Narayan
		</comment>
		<comment id='2' author='zfang399' date='2020-09-07T19:59:07Z'>
		Hi Avnish, thanks for the reply!
I tried switching to the 2020.06-fix_various_sac_mtsac_bugs_backport branch, but it still gives me similar behaviors --- SAC runs correctly, but the MTSAC mt10 returns aren't changing (~32 for the reach-v1 task and ~negative 0.2 for all other tasks).
I also tried setting the reward normalization to False as suggested in &lt;denchmark-link:https://github.com/rlworkgroup/garage/issues/1561&gt;#1561&lt;/denchmark-link&gt;
 but it didn't help either. Does  work on your end? If so, could you point me to the branch of garage you're using? Thanks a lot!
		</comment>
		<comment id='3' author='zfang399' date='2020-09-08T02:17:35Z'>
		&lt;denchmark-link:https://github.com/zfang399&gt;@zfang399&lt;/denchmark-link&gt;
 Garage automatically generates tensor board log files. Can you go ahead and use &lt;denchmark-link:https://tensorboard.dev&gt;tensorboard.dev&lt;/denchmark-link&gt;
 to upload some of your experiments and link them here?
		</comment>
		<comment id='4' author='zfang399' date='2020-09-08T02:28:52Z'>
		&lt;denchmark-link:https://github.com/avnishn&gt;@avnishn&lt;/denchmark-link&gt;
 sure, here's the mtsac_metaworld_mt10 experiment (the one that's not learning): &lt;denchmark-link:https://tensorboard.dev/experiment/pHadIgeSQg21cr8rGfPXpw/&gt;https://tensorboard.dev/experiment/pHadIgeSQg21cr8rGfPXpw/&lt;/denchmark-link&gt;

here's the sac_half_cheetah_batch experiment (which learns normally): &lt;denchmark-link:https://tensorboard.dev/experiment/UR1GE11HRXuP4YqzlfVsWQ/&gt;https://tensorboard.dev/experiment/UR1GE11HRXuP4YqzlfVsWQ/&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='zfang399' date='2020-09-08T05:05:17Z'>
		There must be something wrong with how done signals are handled in this Garage release, or possibly you are using the incorrect Metaworld version somehow.
I was able to tell this because the completion rate of your eval trajectories is 1. That implies that each one of your eval trajectories ends with a done=True signal, or that your environment terminates. This however can't be the case in the correct situation, because versions of Metaworld starting in February or March stopped returning a done=True signal.
In the meantime, I ran the version of MTSAC on the master branch, with the version of Metaworld that you can install using our setup.py, by running pip install -e .[dev] in your development environment, and these were my results:
&lt;denchmark-link:https://tensorboard.dev/experiment/W5FRqD9BSymoofqvt7S1eg/#scalars&gt;https://tensorboard.dev/experiment/W5FRqD9BSymoofqvt7S1eg/#scalars&lt;/denchmark-link&gt;

I'll inspect the release 2020.06 branch and get back to you, but in the meantime, please switch the version that we are currently using on master, as I have verified that it works.
As always, let me know if you have any questions by @ ing me, I'm more than happy to be of help!
Best,
Avnish
		</comment>
		<comment id='6' author='zfang399' date='2020-09-08T05:28:50Z'>
		Hi Avnish, thank you so much for your help! This is a super helpful answer!
I will try switching to the version on master and re-install metaworld. I'll let you know if I have any other questions!
Best,
Andy
		</comment>
		<comment id='7' author='zfang399' date='2020-09-08T17:34:32Z'>
		Hey &lt;denchmark-link:https://github.com/zfang399&gt;@zfang399&lt;/denchmark-link&gt;
 it seems that you were right, there is a bug on our 2020.06 release that is causing some perceived performance regression. I'm going to inspect it this week and generate a back port. Thanks for bringing this up!
		</comment>
		<comment id='8' author='zfang399' date='2020-09-08T22:41:20Z'>
		Hi &lt;denchmark-link:https://github.com/avnishn&gt;@avnishn&lt;/denchmark-link&gt;
 thanks for letting me know! And your suggestion of going to the master's branch worked!
		</comment>
		<comment id='9' author='zfang399' date='2020-09-08T22:44:38Z'>
		&lt;denchmark-link:https://github.com/zfang399&gt;@zfang399&lt;/denchmark-link&gt;
 I've opened a backport onto 2020.06 that fixes the problem. I'll respond here and tag you again when we cut the updated 2020.06 release with changes to pypi.
		</comment>
		<comment id='10' author='zfang399' date='2020-09-09T21:12:19Z'>
		&lt;denchmark-link:https://github.com/avnishn&gt;@avnishn&lt;/denchmark-link&gt;
 does this affect master too, or only ?
		</comment>
		<comment id='11' author='zfang399' date='2020-09-09T22:09:18Z'>
		I benchmarked performance on master and then didn't observe the same issues. I think this may have been resolved during the Garage-&gt;GymEnv transition.
&lt;denchmark-link:https://tensorboard.dev/experiment/W5FRqD9BSymoofqvt7S1eg/#scalars&gt;https://tensorboard.dev/experiment/W5FRqD9BSymoofqvt7S1eg/#scalars&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='zfang399' date='2020-09-09T22:12:18Z'>
		....but does the root cause exist on master or not? please write a test which detects the error and see if it passes on master.
		</comment>
		<comment id='13' author='zfang399' date='2020-09-11T23:09:58Z'>
		&lt;denchmark-link:https://github.com/zfang399&gt;@zfang399&lt;/denchmark-link&gt;
 we merged &lt;denchmark-link:https://github.com/rlworkgroup/garage/pull/2029&gt;#2029&lt;/denchmark-link&gt;
 and your problems should be fixed! I'm going to close this for now.
Avnish
		</comment>
	</comments>
</bug>