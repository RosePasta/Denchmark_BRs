<bug id='1717' author='st2yang' open_date='2020-07-07T03:45:15Z' closed_time='2020-07-13T15:41:55Z'>
	<summary>Failed to reproduce example her_ddpg_fetchreach</summary>
	<description>
Hi,
I was trying to run examples/tf/&lt;denchmark-link:https://github.com/rlworkgroup/garage/blob/master/examples/tf/her_ddpg_fetchreach.py&gt;her_ddpg_fetchreach.py&lt;/denchmark-link&gt;
 but got a much worse performance. I attached the results as follows, and it seems that it's not working at all. Do you have any idea how to make it work? Though the default parameters look reasonable, should I try to tune some parameters?
Thank you in advance.

AverageSuccessRate                       0
Epoch                                   49
Evaluation/AverageDiscountedReturn      -9.94112
Evaluation/AverageReturn              -999.93
Evaluation/CompletionRate                0
Evaluation/Iteration                   980
Evaluation/MaxReturn                  -998
Evaluation/MinReturn                 -1000
Evaluation/NumTrajs                    100
Evaluation/StdReturn                     0.324191
Policy/AveragePolicyLoss                 4.17451
QFunction/AverageAbsQ                    4.19709
QFunction/AverageAbsY                    4.19412
QFunction/AverageQ                      -4.16916
QFunction/AverageQFunctionLoss           0.0232313
QFunction/AverageY                      -4.16946
QFunction/MaxQ                           2.87869
QFunction/MaxY                           2.62668
TotalEnvSteps                       100000

	</description>
	<comments>
		<comment id='1' author='st2yang' date='2020-07-07T18:05:15Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 thanks for the bug report! we will investigate in the next few weeks and get back to you.
in the meantime, if you find working parameters or the root cause, please let us know!
		</comment>
		<comment id='2' author='st2yang' date='2020-07-07T19:41:06Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 Sure, thanks for your help. I tried to change some parameters and might get a better result. But I'm not sure how good it is. Since I am new to garage, I am wondering if there is a way to evaluate the trained policy by rendering the environment?
		</comment>
		<comment id='3' author='st2yang' date='2020-07-07T19:43:59Z'>
		You can either set  in  or follow &lt;denchmark-link:https://garage--1642.org.readthedocs.build/en/1642/user/reuse_garage_policy.html&gt;this guide&lt;/denchmark-link&gt;
 (it is in a pull request now, but will appear on garage.readthedocs.io in the next day or two)
		</comment>
		<comment id='4' author='st2yang' date='2020-07-07T20:13:03Z'>
		Thanks &lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 , I'll try. BTW, when I tried the second option, it has some conflict error regarding tf

data = snapshotter.load('path/to/snapshot/dir')
File "/homes/yangyang/.local/lib/python3.6/site-packages/garage/experiment/snapshotter.py", line 153, in load
return joblib.load(file)
File "/homes/yangyang/.local/lib/python3.6/site-packages/joblib/numpy_pickle.py", line 588, in load
obj = _unpickle(fobj)
File "/homes/yangyang/.local/lib/python3.6/site-packages/joblib/numpy_pickle.py", line 526, in _unpickle
obj = unpickler.load()
File "/homes/yangyang/miniconda3/envs/mujoco-gym/lib/python3.6/pickle.py", line 1050, in load
dispatchkey[0]
File "/homes/yangyang/.local/lib/python3.6/site-packages/joblib/numpy_pickle.py", line 339, in load_build
Unpickler.load_build(self)
File "/homes/yangyang/miniconda3/envs/mujoco-gym/lib/python3.6/pickle.py", line 1507, in load_build
setstate(state)
File "/homes/yangyang/.local/lib/python3.6/site-packages/garage/tf/policies/continuous_mlp_policy.py", line 209, in setstate
self._initialize()
File "/homes/yangyang/.local/lib/python3.6/site-packages/garage/tf/policies/continuous_mlp_policy.py", line 85, in _initialize
shape=(None, self._obs_dim))


File "/homes/yangyang/miniconda3/envs/mujoco-gym/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py", line 3023, in placeholder
raise RuntimeError("tf.placeholder() is not compatible with "
RuntimeError: tf.placeholder() is not compatible with eager execution.

		</comment>
		<comment id='5' author='st2yang' date='2020-07-07T20:20:29Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 can you post the full error message? if it doesn't fit in github, you can use pastebin or similar.
		</comment>
		<comment id='6' author='st2yang' date='2020-07-07T20:39:38Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 Sorry I updated the error message. The error happens when loading tf policy in snapshotter.load('path/to/snapshot/dir').
		</comment>
		<comment id='7' author='st2yang' date='2020-07-07T20:41:10Z'>
		Can you post the full text of the script you're running? It looks like TF2 has been initialized in eager mode (rather than graph mode), which garage doesn't support.
		</comment>
		<comment id='8' author='st2yang' date='2020-07-07T20:50:19Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 I am using the exact example script as you mentioned. Disabling eager by disable_eager_execution() will throw another error. I think it's tf-related issue, I might use pytorch first?

from garage.experiment import Snapshotter
snapshotter = Snapshotter()
data = snapshotter.load('path/to/snapshot/dir')

		</comment>
		<comment id='9' author='st2yang' date='2020-07-07T22:35:37Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 yeah -- if you want an immediate solution, try the PyTorch version. However, I don't think HER is currently implemented in the torch version.
I don't think it's a difficult modification.
		</comment>
		<comment id='10' author='st2yang' date='2020-07-07T22:46:13Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 I thought HERBuffer is independent of the backend, and I can actually run pytorch code with HER. You mean HERBuffer wouldn't boost policy training in the torch vision? Like HERBuffer would be treated as a regular buffer?
		</comment>
		<comment id='11' author='st2yang' date='2020-07-07T22:51:18Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 you're right! we recently made HERReplayBuffer can be used independent of the algorithm.
the only caveat i'll add is that we haven't tested HERReplayBuffer+torch/DDPG -- let us know how it goes!
		</comment>
		<comment id='12' author='st2yang' date='2020-07-07T22:53:51Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 in your original attempt, did you replace  with the actual path to your algorithm's snapshot?
		</comment>
		<comment id='13' author='st2yang' date='2020-07-07T23:13:40Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;



snapshot loading
Yes, I replaced it. And the snapshot works in torch version. So there's some minor bug/conflict in tf version.


HER
HERBuffer + torch/ddpg is at least runnable and give some reasonable results. Since FetchReach is a simple task, I am not sure how much HERBuffer contributes in this case.


		</comment>
		<comment id='14' author='st2yang' date='2020-07-07T23:20:01Z'>
		Some updates regarding example script her_ddpg_fetchreach:
After some experiments, I think there're two types of bugs or errors
(1) the original parameters are not working at all. After I change some parameters, the training is indeed much better and give reasonable performance.
(2) statistic calculation might be wrong. Under a reasonably good performance (in terms of other statistics and evaluation rendering), AverageSuccessRate and Evaluation/CompletionRate are always 0, which doesn't make sense.
		</comment>
		<comment id='15' author='st2yang' date='2020-07-07T23:39:39Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 feel free to send us a PR with the updated params. We would love to have it!
As for (2), there might be a misunderstanding here around the definition of those metrics:


Evaluation/AverageSuccessRate calculates the average number of trajectories which have 'success=True' in their env_info field (see here). This applies only to metaworld environments, as far as I know. If you seeing this metrics in your log while using the fetch environments, that's a bug. To compute this for the gym Fetch environments, you would need to look for the key 'is_success' (see here). Feel free to send us a PR for that.


Evaluation/CompletionRate measures the average number of trajectories which end in a termination condition (i.e. done==True in the gym.Env interface). However, not all environments send termination signals, so it's quite common for this to be 0 for a working agent. As far as I can tell, the Fetch environments never send termination signals (see here), so this always being 0 is normal.


		</comment>
		<comment id='16' author='st2yang' date='2020-07-08T00:40:54Z'>
		&lt;denchmark-link:https://github.com/ryanjulian&gt;@ryanjulian&lt;/denchmark-link&gt;
 I see. Thanks a lot for your detailed explanation! I'll try to look into these and do more experiments, then send a PR about the issues.
		</comment>
		<comment id='17' author='st2yang' date='2020-07-08T06:51:21Z'>
		&lt;denchmark-link:https://github.com/st2yang&gt;@st2yang&lt;/denchmark-link&gt;
 Thanks for bringing this up. For now, could you try entering a  and see if loading tf policy works?
&lt;denchmark-code&gt;from garage.experiment import Snapshotter
import tensorflow as tf //import tf

snapshotter = Snapshotter()
with tf.compat.v1.Session(): //enter a tf session
        data = snapshotter.load('path/to/snapshot/dir')
	policy = data['algo'].policy
	env = data['env']

	# See what the trained policy can accomplish
	from garage.sampler.utils import rollout
	path = rollout(env, policy, animated=True)
	print(path)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='18' author='st2yang' date='2020-07-08T14:43:57Z'>
		&lt;denchmark-link:https://github.com/ahtsan&gt;@ahtsan&lt;/denchmark-link&gt;
 Thanks it works!
		</comment>
		<comment id='19' author='st2yang' date='2020-07-08T14:50:17Z'>
		&lt;denchmark-link:https://github.com/ahtsan&gt;@ahtsan&lt;/denchmark-link&gt;
 can you update the docs page accordingly?
		</comment>
		<comment id='20' author='st2yang' date='2020-07-13T15:41:55Z'>
		close this issue, related to PR &lt;denchmark-link:https://github.com/rlworkgroup/garage/pull/1739&gt;#1739&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>