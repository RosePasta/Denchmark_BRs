<bug id='54' author='ankitmundada' open_date='2018-01-24T13:00:07Z' closed_time='2018-03-01T16:55:18Z'>
	<summary>Num_time_steps calculation for batch inputs is wrong</summary>
	<description>
When using ctcdecode with sequential data of variable output lengths, the smaller outputs are generally padded with zeros to compensate for the extra size of the largest sample. So, logically, when the  loops through the timesteps of  at &lt;denchmark-link:https://github.com/parlance/ctcdecode/blob/master/ctcdecode/src/ctc_beam_search_decoder.cpp#L60&gt;Link for code&lt;/denchmark-link&gt;
, it should stop at the timestep corresponding to the actual size of that sample's output instead of the length of the , since  also has extra padding in batch mode. This causes in ctcdecode to add extra  characters at the end of its actual output.
Examples of such outputs are:
&lt;denchmark-code&gt;Example#1:
Prediction: didn't do before a ooooooh i o o t h o e l l e e e e e e e e e e e e e e o a o o ghx xxx xxx eee e

Reference: didn't god before
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Example#2:
Prediction: and it may be a lot of things that are kind of true ornette e e l e e e e e e e e e e e a u n ghx xxx eee et

Reference: and it may be a lot of things that are kind of truer
&lt;/denchmark-code&gt;

I am using ctcdecode with the outputs from deepspeech.pytorch
I can think of two possible solutions for this:


Pass the num_time_steps to ctc_beam_search_decoder as an argument:
i.e. instead of
size_t num_time_steps = probs_seq.size();  at line, it should be
size_t num_time_steps = size # which is passed as an argument


Add a check for some impossible probability outputs, such as -1 and break the loop whenever its true.
I am currently using this hack in our system, and it seems to work! You can find it here
For this to work, the outputs of the DeepSpeech model are changed a bit. The extra timestep values are intentionally set to -1. The changes are here


The transcripts for same examples, after using the second hacky method are:
&lt;denchmark-code&gt;Example#1:
Prediction: didn't do before
Reference: didn't god before
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Example#2:
Prediction: and it may be a lot of things that are kind of true or
Reference: and it may be a lot of things that are kind of truer
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ankitmundada' date='2018-01-24T14:09:09Z'>
		Thanks for the report and thorough investigation! I'll get a PR put together to address the issue.
		</comment>
		<comment id='2' author='ankitmundada' date='2018-01-31T06:23:37Z'>
		&lt;denchmark-link:https://github.com/ankitmundada&gt;@ankitmundada&lt;/denchmark-link&gt;
 could you checkout the PR &lt;denchmark-link:https://github.com/parlance/ctcdecode/pull/55&gt;#55&lt;/denchmark-link&gt;
 and see if this rectifies your issue? You will have to change a line in  to pass the sequence lengths (see &lt;denchmark-link:https://github.com/SeanNaren/deepspeech.pytorch/pull/239&gt;SeanNaren/deepspeech.pytorch#239&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='3' author='ankitmundada' date='2018-01-31T13:57:59Z'>
		&lt;denchmark-link:https://github.com/ryanleary&gt;@ryanleary&lt;/denchmark-link&gt;
 I have tested it and it seems to work now! Thanks for the quick update!
		</comment>
		<comment id='4' author='ankitmundada' date='2018-03-01T16:55:18Z'>
		Closed by &lt;denchmark-link:https://github.com/parlance/ctcdecode/pull/55&gt;#55&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>