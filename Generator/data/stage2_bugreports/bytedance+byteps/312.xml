<bug id='312' author='Rivendile' open_date='2020-10-30T08:29:47Z' closed_time='2020-11-14T08:27:46Z'>
	<summary>[ByteScheduler] Process does not stop</summary>
	<description>
When I use the ByteScheduler and mxnet parameter-server, I find that the process of worker will not stop. I use the recommended docker file on V100/T4. Any suggestions?
	</description>
	<comments>
		<comment id='1' author='Rivendile' date='2020-10-30T14:34:27Z'>
		Can you show the worker's log with PS_VERBOSE=1? How about the server and scheduler processes?
		</comment>
		<comment id='2' author='Rivendile' date='2020-10-31T03:12:40Z'>
		The logs are as follows:
worker:
[02:56:24] src/van.cc:290: Bind to role=worker, ip=172.31.87.62, port=55629, is_recovery=0
[02:56:24] src/van.cc:238: W[9] is connected to others
02:56:24.516 bytecore.py:40 INFO: use priority scheduler
02:56:24.517 comm.py:185 INFO: Comm host: localhost, port: 58888
02:56:24.517 search.py:119 INFO: Bayesian Search is enabled, space {'credit': (1.0, 16.0)}, max_num_steps 15.
02:56:24.517 bytecore.py:133 INFO: start Core 0: credit 4000000.0, partition 1000000, credit tuning 1, partition tuning 0.
2020-10-31 02:56:24,518.518 INFO: start with arguments Namespace(batch_size=32, benchmark=1, credit=None, data_nthreads=4, data_train=None, data_train_idx='', data_val=None, data_val_idx='', disp_batches=10, dtype='float32', gc_threshold=0.5, gc_type='none', gpus='0', image_shape='3,224,224', initializer='default', kv_store='dist_sync', load_epoch=None, loss='', lr=0.1, lr_factor=0.1, lr_step_epochs='30,60', macrobatch_size=0, max_random_aspect_ratio=0.25, max_random_h=36, max_random_l=50, max_random_rotate_angle=10, max_random_s=50, max_random_scale=1, max_random_shear_ratio=0.1, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='vgg', num_classes=1000, num_epochs=1, num_examples=1920, num_layers=16, optimizer='sgd', output=None, pad_size=0, partition=None, profile_server_suffix='', profile_worker_suffix='', random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0001)
[02:56:29] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)  
2020-10-31 02:56:43,270.270 INFO: Epoch[0] Batch [0-10] Speed: 32.24 samples/secaccuracy=0.034091
2020-10-31 02:56:52,250.250 INFO: Epoch[0] Batch [10-20]        Speed: 35.64 samples/sec        accuracy=0.028125
2020-10-31 02:57:01,525.525 INFO: Epoch[0] Batch [20-30]        Speed: 34.50 samples/sec        accuracy=0.040625
2020-10-31 02:57:10,343.343 INFO: Epoch[0] Batch [30-40]        Speed: 36.29 samples/sec        accuracy=0.034375
2020-10-31 02:57:18,753.753 INFO: Epoch[0] Batch [40-50]        Speed: 38.05 samples/sec        accuracy=0.065625
2020-10-31 02:57:26,802.802 INFO: Epoch[0] Train-accuracy=0.042188
2020-10-31 02:57:26,802.802 INFO: Epoch[0] Time cost=57.501
scheduler
[02:55:57] src/van.cc:290: Bind to role=scheduler, id=1, ip=172.31.92.208, port=8000, is_recovery=0
[02:56:24] src/van.cc:56: assign rank=8 to node role=server, ip=172.31.92.208, port=39463, is_recovery=0
[02:56:24] src/van.cc:56: assign rank=9 to node role=worker, ip=172.31.87.62, port=55629, is_recovery=0
[02:56:24] src/van.cc:83: the scheduler is connected to 1 workers and 1 servers
[02:56:24] src/van.cc:183: Barrier count for 7 : 1                             
[02:56:24] src/van.cc:183: Barrier count for 7 : 2                             
[02:56:24] src/van.cc:183: Barrier count for 7 : 3                             
[02:56:24] src/van.cc:183: Barrier count for 7 : 1 
server
[02:56:17] src/van.cc:290: Bind to role=server, ip=172.31.92.208, port=39463, is_recovery=0
[02:56:24] src/van.cc:238: S[8] is connected to others
All these processes are stuck after printing these logs. However, when I don't use ByteScheduler, i.e., set USE_BYTESCHEDULER=0, these processes can stop. The logs are as follows:
worker:
[03:03:59] src/van.cc:290: Bind to role=worker, ip=172.31.87.62, port=33349, is_recovery=0
[03:03:59] src/van.cc:238: W[9] is connected to others 
2020-10-31 03:03:59,161.161 INFO: start with arguments Namespace(batch_size=32, benchmark=1, credit=None, data_nthreads=4, data_train=None, data_train_idx='', data_val=None, data_val_idx='', disp_batches=10, dtype='float32', gc_threshold=0.5, gc_type='none', gpus='0', image_shape='3,224,224', initializer='default', kv_store='dist_sync', load_epoch=None, loss='', lr=0.1, lr_factor=0.1, lr_step_epochs='30,60', macrobatch_size=0, max_random_aspect_ratio=0.25, max_random_h=36, max_random_l=50, max_random_rotate_angle=10, max_random_s=50, max_random_scale=1, max_random_shear_ratio=0.1, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='vgg', num_classes=1000, num_epochs=1, num_examples=1920, num_layers=16, optimizer='sgd', output=None, pad_size=0, partition=None, profile_server_suffix='', profile_worker_suffix='', random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0001)
[03:04:03] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)       
2020-10-31 03:04:24,193.193 INFO: Epoch[0] Batch [0-10] Speed: 19.29 samples/secaccuracy=0.031250
2020-10-31 03:04:40,582.582 INFO: Epoch[0] Batch [10-20]        Speed: 19.53 samples/sec        accuracy=0.003125
2020-10-31 03:04:57,047.047 INFO: Epoch[0] Batch [20-30]        Speed: 19.43 samples/sec        accuracy=0.000000
2020-10-31 03:05:13,639.639 INFO: Epoch[0] Batch [30-40]        Speed: 19.29 samples/sec        accuracy=0.000000
2020-10-31 03:05:29,996.996 INFO: Epoch[0] Batch [40-50]        Speed: 19.56 samples/sec        accuracy=0.000000
2020-10-31 03:05:44,683.683 INFO: Epoch[0] Train-accuracy=0.006250
2020-10-31 03:05:44,683.683 INFO: Epoch[0] Time cost=101.185
[03:05:44] src/./zmq_van.h:50: W[9] is stopping
[03:05:44] src/van.cc:33: W[9] is stopped
scheduler:
[03:03:47] src/van.cc:290: Bind to role=scheduler, id=1, ip=172.31.92.208, port=8000, is_recovery=0
[03:03:59] src/van.cc:56: assign rank=8 to node role=server, ip=172.31.92.208, port=50671, is_recovery=0
[03:03:59] src/van.cc:56: assign rank=9 to node role=worker, ip=172.31.87.62, port=33349, is_recovery=0
[03:03:59] src/van.cc:83: the scheduler is connected to 1 workers and 1 servers
[03:03:59] src/van.cc:183: Barrier count for 7 : 1                             
[03:03:59] src/van.cc:183: Barrier count for 7 : 2                             
[03:03:59] src/van.cc:183: Barrier count for 7 : 3                             
[03:03:59] src/van.cc:183: Barrier count for 7 : 1                             
[03:05:44] src/van.cc:183: Barrier count for 7 : 2                             
[03:05:44] src/van.cc:183: Barrier count for 7 : 3                             
[03:05:44] src/./zmq_van.h:50: H[1] is stopping                                
[03:05:44] src/van.cc:33: H[1] is stopped 
server:
[03:03:51] src/van.cc:290: Bind to role=server, ip=172.31.92.208, port=50671, is_recovery=0
[03:03:59] src/van.cc:238: S[8] is connected to others                         
[03:05:44] src/./zmq_van.h:50: S[8] is stopping                                
[03:05:44] src/van.cc:33: S[8] is stopped   
Besides, I found that ByteScheduler is much faster than baseline even on one scheduler, one server and one worker. The results are different with those in paper. Each machine has one Tesla T4 gpu and 8 CPU.
		</comment>
		<comment id='3' author='Rivendile' date='2020-10-31T04:08:56Z'>
		&lt;denchmark-link:https://github.com/pengyanghua&gt;@pengyanghua&lt;/denchmark-link&gt;
: Seems that ByteScheduler worker process does not invoke .
		</comment>
		<comment id='4' author='Rivendile' date='2020-11-01T03:21:15Z'>
		&lt;denchmark-link:https://github.com/Rivendile&gt;@Rivendile&lt;/denchmark-link&gt;
 Thanks for the feedback. As said by ymjiang, this is a bug caused by failing to call ps::Finish().
" I found that ByteScheduler is much faster than baseline even on one scheduler, one server and one worker. The results are different with those in paper."
=&gt; In the paper, we did not use distributed training (i.e., no parameter server or scheduler) when there is only one worker. So the performance of baseline and bytescheduler are the same when num_worker is 1.
		</comment>
		<comment id='5' author='Rivendile' date='2020-11-01T03:56:55Z'>
		Thanks for your timely reply. Hope this bug will be fixed soon.
		</comment>
		<comment id='6' author='Rivendile' date='2020-11-09T02:10:38Z'>
		Is there any update?
		</comment>
		<comment id='7' author='Rivendile' date='2020-11-10T09:20:29Z'>
		I find that there is shutdown function in common/comm.py and common/bytecore.py. But they are not called. Thus the CommServer is stuck in a loop. Should I call the shutdown functions explicitly? Any suggestions about this bug?
		</comment>
		<comment id='8' author='Rivendile' date='2020-11-10T13:02:42Z'>
		&lt;denchmark-link:https://github.com/Rivendile&gt;@Rivendile&lt;/denchmark-link&gt;
 Yes you are right. Could you try calling shutdown function in common/bytecore.py explicitly when the training ends?
		</comment>
		<comment id='9' author='Rivendile' date='2020-11-11T02:28:47Z'>
		&lt;denchmark-link:https://github.com/pengyanghua&gt;@pengyanghua&lt;/denchmark-link&gt;
 I add core.shutdown at the end of the training. One more info is printed on the screen:

However, the process is still not ended.
		</comment>
		<comment id='10' author='Rivendile' date='2020-11-12T13:11:37Z'>
		&lt;denchmark-link:https://github.com/Rivendile&gt;@Rivendile&lt;/denchmark-link&gt;
 I think that is because pslite ps::Finish() is not called, though bytescheduler's scheduling thread is stopped. Could you try adding a delete method (&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/kvstore/kvstore.py#L72&gt;https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/kvstore/kvstore.py#L72&lt;/denchmark-link&gt;
) and see if it works?
		</comment>
		<comment id='11' author='Rivendile' date='2020-11-13T03:39:35Z'>
		&lt;denchmark-link:https://github.com/pengyanghua&gt;@pengyanghua&lt;/denchmark-link&gt;
 I have tried adding a delete method.
However, if I add  at the end of fit, the process will not stop.
If I add the following code in class  ScheduledKVStore:


and  at the end of fit, the worker process is stopped with an error "terminate called without an active exception", while the scheduler and server process are still not ended.
		</comment>
		<comment id='12' author='Rivendile' date='2020-11-14T07:47:21Z'>
		&lt;denchmark-link:https://github.com/Rivendile&gt;@Rivendile&lt;/denchmark-link&gt;
 Thanks for your feedback. I submitted a bug fix &lt;denchmark-link:https://github.com/bytedance/byteps/commit/1cf093564dc64a1a2274b4f6385f82985ac9c525&gt;1cf0935&lt;/denchmark-link&gt;
, please check if it works.
		</comment>
		<comment id='13' author='Rivendile' date='2020-11-14T08:27:46Z'>
		It works! Thanks a lot.
		</comment>
	</comments>
</bug>