<bug id='858' author='Li-Shu14' open_date='2018-04-20T03:38:38Z' closed_time='2019-03-13T17:39:19Z'>
	<summary>Problems on using preprocess codes between client and server.</summary>
	<description>
I want to pre-process the data sent by a asynchronous client before these data entering the model served by tensorflow_model_server.
These pre-process codes are too complex to be implemented by  tensorflow built-in functions so it's almost impossible to make the  pre-processing a part of the graph.
I also consider doing this on the client side, but the data after pre-processing will become 10 times larger ,which will greatly reduce the transmission efficiency between client and server.
Is there any walk-arounds? I have finished asynchronous part using ways like  mnist_client.py and the pre-process part in inception_saved_model.py cannot help me with this problem.
I really need as large throughput as possible.
	</description>
	<comments>
		<comment id='1' author='Li-Shu14' date='2018-08-05T08:30:35Z'>
		I meet the same problem with medical images, my preprocess include interpolate (with SimpleITK), padding, split with overlap (numpy), then request for each pieces。　Now I have to do this preprocess on client side, and the total size for transform is 10 times bigger.
		</comment>
		<comment id='2' author='Li-Shu14' date='2018-10-23T19:16:40Z'>
		&lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
  - Hi, could you please look into this issue ?
		</comment>
		<comment id='3' author='Li-Shu14' date='2019-02-27T21:44:49Z'>
		Not sure if you got a chance to use Tensorflow Transform, which produces a preprocessing graph which you can use at training time, as well as include as a part of the serving graph.
Please take a look at &lt;denchmark-link:https://ai.googleblog.com/2017/02/preprocessing-for-machine-learning-with.html&gt;this&lt;/denchmark-link&gt;
 which gives more information on this.
Also take a look at the existing issue &lt;denchmark-link:https://github.com/tensorflow/serving/issues/770&gt;#770&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Li-Shu14' date='2019-03-13T17:39:19Z'>
		Closing this issue as it is in "awaiting response" status for more than a week. Feel free to add your comments and we will reopen.
		</comment>
	</comments>
</bug>