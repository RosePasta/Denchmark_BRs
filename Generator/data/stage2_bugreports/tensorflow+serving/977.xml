<bug id='977' author='gr8Adakron' open_date='2018-07-06T08:09:52Z' closed_time='2019-02-11T18:25:21Z'>
	<summary>tensorflow model trained on 'N'-GPUs requires same number of GPU to get served using tf-serving</summary>
	<description>
I got tensorflow-model which is trained on 8-GPU power and it has been saved using &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/saved_model/builder/SavedModelBuilder&gt;SavedModelBuilder&lt;/denchmark-link&gt;
 as per the requirements of the tf-serving, to get the model file in this structure:
&lt;denchmark-link:https://user-images.githubusercontent.com/16715364/42367203-0cdb662a-8121-11e8-92f2-3bd5f1722d3a.png&gt;&lt;/denchmark-link&gt;

After saving it, I am serving it with tf-serving. But the problem is that if tf-serving is installed on CPU machince or less than 8 GPU machince it throws error(TF-serving doesn't accept the models file). And when I install TF-serving on 8 GPU machine the model gets serve properly.
Is there any parameter or flag which can help to save and serve the model on different configuration machine? and not be depended on training configuration of the machine?
Error it return when training and serving configuration of machine are not same:
&lt;denchmark-code&gt;2018-07-06 08:09:16.698221: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10743 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2018-07-06 08:09:16.698443: E external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:228] Illegal GPUOptions.experimental.num_dev_to_dev_copy_streams=0 set to 1 instead.
2018-07-06 08:09:17.844564: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { serve }; Status: fail. Took 1834084 microseconds.
2018-07-06 08:09:17.912314: E tensorflow_serving/util/retrier.cc:37] Loading servable: {name: default version: 2} failed: Invalid argument: Cannot assign a device for operation 'clone_7/gradients/clone_7/softmax_cross_entropy_loss/div_1_grad/BroadcastGradientArgs': Operation was explicitly assigned to /device:GPU:7 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.
         [[Node: clone_7/gradients/clone_7/softmax_cross_entropy_loss/div_1_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _output_shapes=[[?], [?]], _device="/device:GPU:7"](clone_7/gradients/clone_7/softmax_cross_entropy_loss/div_1_grad/Shape, clone_7/gradients/clone_7/softmax_cross_entropy_loss/div_1_grad/Shape_1)]]
&lt;/denchmark-code&gt;

Any help is appreciated, thanks.
	</description>
	<comments>
		<comment id='1' author='gr8Adakron' date='2018-07-06T08:12:08Z'>
		&lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kchodorow&gt;@kchodorow&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/montanaflynn&gt;@montanaflynn&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jart&gt;@jart&lt;/denchmark-link&gt;
 any clue about this?
		</comment>
		<comment id='2' author='gr8Adakron' date='2018-07-10T19:58:49Z'>
		I believe this is correct. Depending on the way your model is structured, you have probably explicitly encoded 8 GPUs in the training part. I'm going to assume you are using an Estimator. What gets served is defined in the model_fn when mode=PREDICT. If you again define a model specialized explicitly for 8 GPUs in that call, serving will require 8 GPUs. If you define one for a single GPU, it will work with a single GPU (and if soft placement is an option) it should also work if no GPU is present.
		</comment>
		<comment id='3' author='gr8Adakron' date='2018-07-11T11:22:07Z'>
		Facing the same problem. Any help is appreciated. Thank You.
		</comment>
		<comment id='4' author='gr8Adakron' date='2018-08-09T10:26:52Z'>
		There are some parameters to clear the "device placement" when exporting the model. It is a little difficult to specify devices just like training unless we modify the graph manually.
		</comment>
		<comment id='5' author='gr8Adakron' date='2018-10-23T18:57:26Z'>
		Is this still an issue ?
		</comment>
		<comment id='6' author='gr8Adakron' date='2018-10-23T19:10:54Z'>
		I believe this hasn't changed.
		</comment>
		<comment id='7' author='gr8Adakron' date='2018-10-24T06:37:46Z'>
		&lt;denchmark-link:https://github.com/tobegit3hub&gt;@tobegit3hub&lt;/denchmark-link&gt;
  thank you. The issue got resolved for me after clearing device info while exporting the model.
		</comment>
		<comment id='8' author='gr8Adakron' date='2018-11-06T14:19:45Z'>
		&lt;denchmark-link:https://github.com/bansarishah&gt;@bansarishah&lt;/denchmark-link&gt;
 Could you please give some hints on how you did it? Thanks in advance.
		</comment>
		<comment id='9' author='gr8Adakron' date='2018-11-07T09:39:11Z'>
		&lt;denchmark-link:https://github.com/frallain&gt;@frallain&lt;/denchmark-link&gt;
 , while exporting model, enable flag clear_devices=True. It will help to resolve this issue.

Thank You.
		</comment>
		<comment id='10' author='gr8Adakron' date='2018-12-03T22:44:50Z'>
		&lt;denchmark-link:https://github.com/gr8Adakron&gt;@gr8Adakron&lt;/denchmark-link&gt;
  Did you get a chance to try the above solution as suggested by &lt;denchmark-link:https://github.com/bansarishah&gt;@bansarishah&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='11' author='gr8Adakron' date='2018-12-04T06:19:35Z'>
		Besides  flag, is there a way to define the device placement in tf-serving, like stated in &lt;denchmark-link:https://github.com/tensorflow/serving/issues/311&gt;#311&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='12' author='gr8Adakron' date='2019-02-11T18:25:21Z'>
		Closing this at it is in "awaiting response" status for more than a week. Feel free to add comments(if any), we will reopen the issue. Thanks !
		</comment>
		<comment id='13' author='gr8Adakron' date='2019-07-11T08:31:43Z'>
		&lt;denchmark-link:https://github.com/Harshini-Gadige&gt;@Harshini-Gadige&lt;/denchmark-link&gt;
 Hi, any progress on device placement for tf-serving?
		</comment>
	</comments>
</bug>