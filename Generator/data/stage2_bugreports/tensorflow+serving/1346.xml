<bug id='1346' author='Gpwner' open_date='2019-05-13T09:05:36Z' closed_time='2019-06-21T16:04:59Z'>
	<summary>memory usage grows when reload a new  pb model</summary>
	<description>
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Feature Request&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Describe the problem the feature is intended to solve&lt;/denchmark-h&gt;

When I finish training a new model ,I  copy it to the folder where the current serving model is .
And I notice that the docker container memory usage grow  after tensorflow serving load the new model.Here is the docker container memory usage information：
&lt;denchmark-code&gt;lodap@ubuntu:~$ docker stats --no-stream
CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
2a75af76474a        OCS_2.0.0           1089.00%            756.3MiB / 94.36GiB   0.78%               9.52MB / 1.65GB     0B / 0B             154
9d931936faa7        OCS_1.0.0           0.06%               2.24GiB / 94.36GiB    2.37%               6.66MB / 255MB      8.16MB / 0B         154
lodap@ubuntu:~$ docker stats --no-stream
CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
2a75af76474a        OCS_2.0.0           0.05%               1.51GiB / 94.36GiB    1.60%               10.6MB / 1.81GB     0B / 0B             154
9d931936faa7        OCS_1.0.0           0.05%               2.657GiB / 94.36GiB   2.82%               6.85MB / 256MB      8.16MB / 0B         154
lodap@ubuntu:~$ docker stats --no-stream
CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
2a75af76474a        OCS_2.0.0           0.05%               1.51GiB / 94.36GiB    1.60%               10.6MB / 1.81GB     0B / 0B             154
9d931936faa7        OCS_1.0.0           0.07%               2.657GiB / 94.36GiB   2.82%               6.85MB / 256MB      8.16MB / 0B         154
lodap@ubuntu:~$ docker stats --no-stream
CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT     MEM %               NET I/O             BLOCK I/O           PIDS
2a75af76474a        OCS_2.0.0           0.07%               1.69GiB / 94.36GiB    1.79%               10.6MB / 1.81GB     0B / 0B             154
9d931936faa7        OCS_1.0.0           0.05%               2.978GiB / 94.36GiB   3.16%               6.86MB / 256MB      8.16MB / 0B         154
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Gpwner' date='2019-05-13T09:09:44Z'>
		has the same issue...
		</comment>
		<comment id='2' author='Gpwner' date='2019-05-13T19:15:56Z'>
		&lt;denchmark-link:https://github.com/Gpwner&gt;@Gpwner&lt;/denchmark-link&gt;
 Can you please take a look at the &lt;denchmark-link:https://github.com/tensorflow/serving/issues/1215&gt;issue&lt;/denchmark-link&gt;
 and let me know if that helps. Thanks!
		</comment>
		<comment id='3' author='Gpwner' date='2019-05-14T01:03:48Z'>
		@gowtham-kp I refer to the issue.But I just find out there  is only one solution which changes the  asynchronous request to synchronous request.But it didn't work in my situation.
		</comment>
		<comment id='4' author='Gpwner' date='2019-05-17T00:32:41Z'>
		Hi Gpwner, I think when a new version comes into the folder, the server will load the new version before unloading the old version. So memory increase is expected in this case.
Or are you seeing memory not decreasing long after that?
		</comment>
		<comment id='5' author='Gpwner' date='2019-05-17T01:07:37Z'>
		&lt;denchmark-link:https://github.com/nrobeR&gt;@nrobeR&lt;/denchmark-link&gt;
 Hi,in my situation,memory usage never decreases
		</comment>
		<comment id='6' author='Gpwner' date='2019-05-17T07:59:50Z'>
		&lt;denchmark-link:https://github.com/Gpwner&gt;@Gpwner&lt;/denchmark-link&gt;
 ,
Can you please check what is the size of your new pb model. If the Model Size increases with each save, then it may be possible that it may consume more memory, proportionately. You can refer this &lt;denchmark-link:https://stackoverflow.com/questions/55700083/tensorflow-savedmodel-file-size-increases-with-each-save&gt;Stack overflow Issue&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='Gpwner' date='2019-05-17T09:22:50Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 the new model's size is equal to the previous one.Even though I just copy the previous one and rename it in the same folder，the memory usage still grows up.
		</comment>
		<comment id='8' author='Gpwner' date='2019-05-17T15:16:31Z'>
		Could you please verify if the previous model get unloaded from your model server? Also just to make sure I understand, did you export your model under the same versioned folder where the old saved_model.pb existed?
		</comment>
		<comment id='9' author='Gpwner' date='2019-05-20T02:32:37Z'>
		&lt;denchmark-link:https://github.com/nrobeR&gt;@nrobeR&lt;/denchmark-link&gt;
 ,
The first answer:
I am not sure whether the previous model get  unloaded.But I am sure that the new model get loaded.Because the response I get from the server is different by the client.
The second answer：
First of all,I exported the new model to another folder，then I copy the new model to the folder where previous model is.
		</comment>
		<comment id='10' author='Gpwner' date='2019-05-20T15:27:40Z'>
		Ok I'm guessing that the old model didn't get unloaded due to the fact that there are two saved_model.pb in the same file. Could you try just exporting the new model into a different folder with version number larger than the previous one? This is the recommended way of uploading new version of a model
		</comment>
		<comment id='11' author='Gpwner' date='2019-05-22T06:04:05Z'>
		&lt;denchmark-link:https://github.com/nrobeR&gt;@nrobeR&lt;/denchmark-link&gt;
 There must  be  some mistake.When I  come to the new model ，I mean some folder like  1558497607 which contains a pb model and a sub-folder called  variables:
&lt;denchmark-code&gt;root@ubuntu:~/V500R006C70# ls
1558420482  1558497607
root@ubuntu:~/V500R006C70# tree .
.
├── 1558420482
│   ├── saved_model.pb
│   └── variables
│       ├── variables.data-00000-of-00001
│       └── variables.index
└── 1558497607
    ├── saved_model.pb
    └── variables
        ├── variables.data-00000-of-00001
        └── variables.index
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='Gpwner' date='2019-05-22T06:06:18Z'>
		&lt;denchmark-link:https://github.com/nrobeR&gt;@nrobeR&lt;/denchmark-link&gt;
 Also the previous model folder is corresponding to the 1558420482，and the new model is corresponding to 1558497607.
		</comment>
		<comment id='13' author='Gpwner' date='2019-06-13T16:57:30Z'>
		&lt;denchmark-link:https://github.com/Gpwner&gt;@Gpwner&lt;/denchmark-link&gt;
 we are having trouble reproducing this on our side. This is most likely because the old model version is not getting unloaded and we need to figure out why. You can do this a number of ways:

Look at the logs of the model server for line "Done unloading servable version {name: version}"
Tell us how you launch model server (config and exact steps to reproduce)

		</comment>
		<comment id='14' author='Gpwner' date='2019-06-21T16:04:59Z'>
		&lt;denchmark-link:https://github.com/Gpwner&gt;@Gpwner&lt;/denchmark-link&gt;
 we haven't heard from you on this for 7+ days, we will close this issue for now, lack of any more information. If you still need help, please feel free to reopen this issue with information asked by @unclepeddy.
		</comment>
	</comments>
</bug>