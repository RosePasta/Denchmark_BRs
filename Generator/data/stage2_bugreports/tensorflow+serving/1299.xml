<bug id='1299' author='secsilm' open_date='2019-04-07T08:06:15Z' closed_time='2019-04-30T04:07:32Z'>
	<summary>Check failed: NDIMS == dims() on latest-gpu docker image but not on others</summary>
	<description>
&lt;denchmark-h:h2&gt;Bug Report&lt;/denchmark-h&gt;

If this is a bug report, please fill out the following form in full:
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow Serving installed from (source or binary): docker
TensorFlow Serving version: 1.13.0

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I try to deploy the trained bert model with the docker version of tf serving and use the latest-gpu tag(currently is 1.13.0). Tensorflow Serving will accept the following input:
{
    "instances": [{
        "input_ids": input_ids,
        "input_mask": input_mask,
        "segment_ids": segment_ids,
        "label_ids": label_ids
    }]
}
After I run the Tensorflow Serving container and post a request, I get the following output and the container exit:
2019-04-07 04:09:55.899482: F external/org_tensorflow/tensorflow/core/framework/tensor_shape.cc:44] Check failed: NDIMS == dims() (2 vs. 4)Asking for tensor of 2 dimensions from a tensor of 4 dimensions
Aborted (core dumped)
However when I use the cpu version  or the 1.12.0-gpu version it all works fine. So I think this is a bug of latest-gpu version.
In addition, I also have tested the trained model with saved_model_cli run command and it works fine.
&lt;denchmark-h:h3&gt;Exact Steps to Reproduce&lt;/denchmark-h&gt;

input_ids = np.zeros((1, 128)).astype(int).tolist()
input_mask = np.zeros((1, 128)).astype(int).tolist()
segment_ids = np.zeros((1, 128)).astype(int).tolist()
label_ids = [0]
params = {
    "instances": [{
        "input_ids": input_ids,
        "input_mask": input_mask,
        "segment_ids": segment_ids,
        "label_ids": label_ids
    }]
}
r = requests.post(url, json=params)
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

2019-04-07 04:09:55.899482: F external/org_tensorflow/tensorflow/core/framework/tensor_shape.cc:44] Check failed: NDIMS == dims() (2 vs. 4)Asking for tensor of 2 dimensions from a tensor of 4 dimensions
Aborted (core dumped)
	</description>
	<comments>
		<comment id='1' author='secsilm' date='2019-04-08T19:28:16Z'>
		Can you please check if the input tensors are in a good shape for the ops used? Also could you please confirm if there is any external/custom op created?
		</comment>
		<comment id='2' author='secsilm' date='2019-04-09T02:56:38Z'>
		Thank you for your reply.
&lt;denchmark-h:h3&gt;Can you please check if the input tensors are in a good shape for the ops used?&lt;/denchmark-h&gt;

I use saved_model_cli to check the input and it's fine:
$ saved_model_cli run --dir projects/model/1/ --tag_set serve --signature_def serving_default --input_exprs 'input_ids=np.ones((1, 128));input_mask=np.zeros((1, 128));segment_ids=np.zeros((1, 128))'
/data/liyajun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2019-04-09 10:52:18.896200: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-09 10:52:19.565044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 11.90GiB freeMemory: 2.60GiB
2019-04-09 10:52:20.061823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:05:00.0
totalMemory: 11.90GiB freeMemory: 2.87GiB
2019-04-09 10:52:20.544397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:08:00.0
totalMemory: 11.90GiB freeMemory: 2.87GiB
2019-04-09 10:52:21.023625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:09:00.0
totalMemory: 11.90GiB freeMemory: 2.87GiB
2019-04-09 10:52:21.496812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 4 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:85:00.0
totalMemory: 11.90GiB freeMemory: 2.88GiB
2019-04-09 10:52:21.964288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 5 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:86:00.0
totalMemory: 11.90GiB freeMemory: 2.87GiB
2019-04-09 10:52:22.431090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 6 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:89:00.0
totalMemory: 11.90GiB freeMemory: 2.85GiB
2019-04-09 10:52:22.919696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 7 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:8a:00.0
totalMemory: 11.90GiB freeMemory: 2.85GiB
2019-04-09 10:52:22.922236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2019-04-09 10:52:25.672151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-09 10:52:25.672240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 4 5 6 7 
2019-04-09 10:52:25.672259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y N N N N 
2019-04-09 10:52:25.672270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y N N N N 
2019-04-09 10:52:25.672281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y N N N N 
2019-04-09 10:52:25.672290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N N N N N 
2019-04-09 10:52:25.672299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 4:   N N N N N Y Y Y 
2019-04-09 10:52:25.672308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 5:   N N N N Y N Y Y 
2019-04-09 10:52:25.672318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 6:   N N N N Y Y N Y 
2019-04-09 10:52:25.672327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 7:   N N N N Y Y Y N 
2019-04-09 10:52:25.674447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2293 MB memory) -&gt; physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:04:00.0, compute capability: 6.1)
2019-04-09 10:52:25.675483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 2575 MB memory) -&gt; physical GPU (device: 1, name: TITAN Xp, pci bus id: 0000:05:00.0, compute capability: 6.1)
2019-04-09 10:52:25.676359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 2571 MB memory) -&gt; physical GPU (device: 2, name: TITAN Xp, pci bus id: 0000:08:00.0, compute capability: 6.1)
2019-04-09 10:52:25.677107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 2575 MB memory) -&gt; physical GPU (device: 3, name: TITAN Xp, pci bus id: 0000:09:00.0, compute capability: 6.1)
2019-04-09 10:52:25.677857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 2579 MB memory) -&gt; physical GPU (device: 4, name: TITAN Xp, pci bus id: 0000:85:00.0, compute capability: 6.1)
2019-04-09 10:52:25.678523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 2571 MB memory) -&gt; physical GPU (device: 5, name: TITAN Xp, pci bus id: 0000:86:00.0, compute capability: 6.1)
2019-04-09 10:52:25.679236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 2553 MB memory) -&gt; physical GPU (device: 6, name: TITAN Xp, pci bus id: 0000:89:00.0, compute capability: 6.1)
2019-04-09 10:52:25.679928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 2555 MB memory) -&gt; physical GPU (device: 7, name: TITAN Xp, pci bus id: 0000:8a:00.0, compute capability: 6.1)
Result for output key probabilities:
[[1.27112971e-05 2.21859096e-04 9.95281279e-01 6.64391746e-06
  1.42880774e-03 1.09833727e-05 1.86398136e-03 3.05473040e-05
  7.60817420e-05 1.03793733e-04 1.04646126e-04 5.90456126e-04
  9.32950279e-05 1.74855464e-04]]
&lt;denchmark-h:h3&gt;Also could you please confirm if there is any external/custom op created?&lt;/denchmark-h&gt;

Sorry I don't kown how to check this.
		</comment>
		<comment id='3' author='secsilm' date='2019-04-16T23:56:05Z'>
		does this also happen with tensorflow/serving:nightly-gpu docker image (this is built with latest HEAD sources)?
		</comment>
		<comment id='4' author='secsilm' date='2019-04-18T09:50:33Z'>
		&lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
 I pulled the  docker image and  failed:
docker: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused "process_linux.go:402: container init caused \"process_linux.go:385: running prestart hook 1 caused \\\"error running hook: exit status 1, stdout: , stderr: exec command: [/usr/bin/nvidia-container-cli --load-kmods configure --ldconfig=@/sbin/ldconfig.real --device=all --compute --utility --require=cuda&gt;=10.0 brand=tesla,driver&gt;=384,driver&lt;385 brand=tesla,driver&gt;=410,driver&lt;411 --pid=32481 /data/docker/overlay/2daf375d989e7697522505aa2a37647c313e3655de622f7b84a203d4e6d5acd9/merged]\\\\nnvidia-container-cli: requirement error: invalid expression\\\\n\\\"\"": unknown.
		</comment>
		<comment id='5' author='secsilm' date='2019-04-23T19:28:16Z'>
		&lt;denchmark-link:https://github.com/secsilm&gt;@secsilm&lt;/denchmark-link&gt;
 are you using  flag on docker command line for gpu image?
see &lt;denchmark-link:https://www.tensorflow.org/tfx/serving/docker#gpu_serving_example&gt;https://www.tensorflow.org/tfx/serving/docker#gpu_serving_example&lt;/denchmark-link&gt;
 for details
		</comment>
		<comment id='6' author='secsilm' date='2019-04-25T01:58:30Z'>
		&lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
 Yes I used the  flag, here is my command:
docker run --runtime=nvidia -p 8501:8501 --mount type=bind,source=model/path,target=/models/mymodel -e MODEL_NAME=mymodel -t tensorflow/serving:nightly-gpu
		</comment>
		<comment id='7' author='secsilm' date='2019-04-25T02:10:53Z'>
		from the error message i suspect your nvidia driver probably does not support cuda10. since TF 1.13 we use cuda 10. TF 1.12 (and prior) were based on cuda9. can you verify that cuda 10 is installed correctly on your system and is working with your GPU?
maybe follow this:
&lt;denchmark-link:https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-installation&gt;https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#verify-installation&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='secsilm' date='2019-04-30T02:22:10Z'>
		&lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
 Sorry to reply late. I test the  image with cuda-10.0 installed and it works.
But it confused me that &lt;denchmark-link:https://www.tensorflow.org/install/docker&gt;the TensorFlow document&lt;/denchmark-link&gt;
 says cuda and cudnn is not required if using docker version.

Docker is the easiest way to enable TensorFlow GPU support on Linux since only the NVIDIA® GPU driver is required on the host machine (the NVIDIA® CUDA® Toolkit does not need to be installed).

So why do I have to install the corresponding cuda and cudnn version to use it tfs?
		</comment>
		<comment id='9' author='secsilm' date='2019-04-30T02:30:09Z'>
		my understanding is you need host driver. and each driver supports certain level of cuda version.
and looking at your failure, i suspected that your driver is not capable of doing cuda 10 (that our docker image is based off). IOW to use the latest docker image, you need driver w/ cuda 10 support.
adding &lt;denchmark-link:https://github.com/aaroey&gt;@aaroey&lt;/denchmark-link&gt;
 to ascertain or correct my understanding.
		</comment>
		<comment id='10' author='secsilm' date='2019-04-30T02:42:58Z'>
		Thank you for your quick reply.
That makes sense. Before my driver version was 384.130. It becomes 410.48 after I install cuda-10.0. According to &lt;denchmark-link:https://www.tensorflow.org/install/gpu#software_requirements&gt;TensorFlow document&lt;/denchmark-link&gt;
, cuda-10.0 requires 410.x or higher.
		</comment>
		<comment id='11' author='secsilm' date='2019-04-30T04:07:32Z'>
		Thanks for confirming the driver version and the fact that upgrading worked.
		</comment>
		<comment id='12' author='secsilm' date='2019-04-30T04:59:50Z'>
		&lt;denchmark-link:https://github.com/netfs&gt;@netfs&lt;/denchmark-link&gt;
 is right. &lt;denchmark-link:https://github.com/secsilm&gt;@secsilm&lt;/denchmark-link&gt;
 To use TensorFlow with docker, it only requires that the host GPU driver version supports the CUDA/cuDNN versions that was used to build the TensorFlow package. E.g. the latest TF release is built with CUDA 10, so it requires 410.x+ GPU driver. We don't need to install CUDA/cuDNN, which is included by the docker image.
		</comment>
	</comments>
</bug>