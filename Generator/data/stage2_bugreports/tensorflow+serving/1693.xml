<bug id='1693' author='tianyunzqs' open_date='2020-07-21T02:04:39Z' closed_time='2020-08-28T16:44:19Z'>
	<summary>the log refreshed over and over, and not stop until the docker of tensorflow/serving is stopped</summary>
	<description>
&lt;denchmark-h:h2&gt;Bug Report&lt;/denchmark-h&gt;

When I installed tensorflow/serving in docker, and run(add or delete) my model with model config file, I got an error(a bug I guess) which the log that described as follow refreshed over and over, and not stop until the docker of tensorflow/serving is stopped.
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.7.1908
TensorFlow Serving installed from (source or binary): source or binary both not work(by docker)
TensorFlow Serving version: 1.12.0 or lastest both not work

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

First, I install TensorFlow Serving with docker, and add or delete my model dynamically by updating the model config file, but the error(the log refreshed over and over, and not stop until the docker of tensorflow/serving is stopped)  encountered when I input the wrong model path.
Then, I compiled the source code in docker, it didn't work too.
2020-07-20 10:32:51.540889: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 2020-07-20 10:32:52.541001: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 2020-07-20 10:32:53.541070: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 2020-07-20 10:32:54.541168: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 2020-07-20 10:32:55.541366: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 dco2020-07-20 10:32:56.541409: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 ker 2020-07-20 10:32:57.541533: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 rm 2020-07-20 10:32:58.541649: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 -f 2020-07-20 10:32:59.541738: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415 14e2020-07-20 10:33:00.541917: E tensorflow_serving/sources/storage_path/file_system_storage_path_source.cc:362] FileSystemStoragePathSource encountered a filesystem access error: Could not find base path /home/code/docker_ai/user_models/ner_models/zhangsan/20200720114415 for servable zhangsan_20200720114415
my code to add model with model config file
&lt;denchmark-code&gt;def update_model(config_file, host_and_port, model_name, base_path):
    channel = grpc.insecure_channel(host_and_port)
    stub = model_service_pb2_grpc.ModelServiceStub(channel)
    request = model_management_pb2.ReloadConfigRequest()

    # read config file
    config_content = open(config_file, "r").read()
    model_server_config = model_server_config_pb2.ModelServerConfig()
    model_server_config = text_format.Parse(text=config_content, message=model_server_config)

    # create a new one config
    config_list = model_server_config_pb2.ModelConfigList()
    new_config = config_list.config.add()
    new_config.name = model_name
    new_config.base_path = base_path
    new_config.model_platform = "tensorflow"

    # add to origin config message
    model_server_config.model_config_list.MergeFrom(config_list)

    request.config.CopyFrom(model_server_config)
    request_response = stub.HandleReloadConfigRequest(request, 10)

    if request_response.status.error_code == 0:
        open(config_file, "w").write(str(request.config))
        return True
    else:
        logger.error(request_response.status.error_code)
        logger.error(request_response.status.error_message)
        return False
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Exact Steps to Reproduce&lt;/denchmark-h&gt;

step1. install tensorflow/serving(1.12.0 or lastest) with docker.
step2. train your own model and transform it to pb format that tensorflow/serving need.
step3. run tensorflow/serving docker, my command is
docker run -p 8500:8500 --name tfserving --mount type=bind,source=/home/code/docker_ai/user_models,target=/home/code/docker_ai/user_models -t tfs:20200720 --model_config_file=/home/code/docker_ai/user_models/models.config
step4. add the model with gRPC API described above with wrong base_path.
step5. take a look the docker, and you will encounter this error, it not stop until the docker of tensorflow/serving is stopped.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

You can find source code and logs above.
	</description>
	<comments>
		<comment id='1' author='tianyunzqs' date='2020-08-07T02:24:13Z'>
		hi, will this bug fix in next version?
		</comment>
		<comment id='2' author='tianyunzqs' date='2020-08-14T16:29:53Z'>
		&lt;denchmark-link:https://github.com/tianyunzqs&gt;@tianyunzqs&lt;/denchmark-link&gt;
,
Sorry for the delayed response. Can you please clarify what exactly your expectation is? Thanks!
		</comment>
		<comment id='3' author='tianyunzqs' date='2020-08-17T13:40:25Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 ,
Thanks for the replay. If the model path is given uncorrectly, the error information show once rather than unlimited times. So the program can continue.
		</comment>
		<comment id='4' author='tianyunzqs' date='2020-08-19T12:16:28Z'>
		&lt;denchmark-link:https://github.com/tianyunzqs&gt;@tianyunzqs&lt;/denchmark-link&gt;
,
Do you mean to say that if your config file comprises of multiple models and if path of one model is incorrect, it should report that error and then should continue with other models. Is this what you meant?
		</comment>
		<comment id='5' author='tianyunzqs' date='2020-08-21T07:57:31Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 ,
Yes! That's what I mean,
		</comment>
		<comment id='6' author='tianyunzqs' date='2020-08-28T16:44:18Z'>
		Hey thanks for opening this issue.
This is not a bug and is intended system behavior: The model server takes the models described in the config provided and will continually try to find them and serve them - this is useful and necessary when at model deployment time, there's a lag between when the config is provided to model server and the model is actually made available on the file system (which is the case if the storage is remote and/or the model is large and ingestion by the file system takes O(minute)).
		</comment>
	</comments>
</bug>