<bug id='1409' author='nielsgroen' open_date='2019-08-05T10:17:07Z' closed_time='2019-08-05T22:29:36Z'>
	<summary>[Bug] Using tf.feature_columns in exported estimators fails when using tf.feature_columns.indicator_column</summary>
	<description>
&lt;denchmark-h:h1&gt;Bug Report&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Using tensorflow 1.14.0 to export saved models
Using tensorflow serving docker image, tag latest, as of 05/08/2019 (August 5th):
TensorFlow ModelServer: 1.14.0-rc0
TensorFlow Library: 1.14.0

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Tensorflow serving doesn't handle a 'feature_columns input layer' in the Estimator model_fn.
When using tf.feature_columns.input_layer or tf.keras.layer.DenseFeatures to process feature_columns in the model_fn: If you have a feature_column that is a categorical_column wrapped by an indicator_column, Tensorflow serving fails.
Tensorflow serving doesn't seem to properly handle the indicator_column. It responds with:
{
    "error": "Input to reshape is a tensor with &lt;n&gt; values, but the requested shape has &lt;n squared&gt;\n\t [[{{node input_layer/&lt;feature name&gt;_indicator/Reshape}}]]"
}
&lt;denchmark-link:https://stackoverflow.com/questions/57327655/is-there-a-way-to-export-custom-tensorflow-r1-14-estimators-that-are-able-to-p&gt;I asked around on stackoverflow&lt;/denchmark-link&gt;
, if there were workarounds, no response so far.
The main advantage of tf.feature_columns happens to be the indicator_column (which allows for easy one-hot encoding of features in the model code). It is also pushed in multiple Tensorflow guides as something that's used. I think this bug blocks practical use of the tf.feature_columns module.
When not using the indicator_column as a feature_column, all seems well
&lt;denchmark-h:h3&gt;Exact Steps to Reproduce&lt;/denchmark-h&gt;

Script to export saved_models from estimators that use feature_columns:
&lt;denchmark-code&gt;"""Code for testing tensorflow serving reshape bug"""

import tensorflow as tf

feature_columns = [
    # Feature columns that use indicator column
    tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_identity('test', 2))
]

estimator_params = {
    'feature_columns': feature_columns
}


def model_fn(features, labels=None, mode=None, params=None):
    is_training = (mode == tf.estimator.ModeKeys.TRAIN)

    inputs = tf.feature_column.input_layer(features, params['feature_columns'])

    if not is_training:
        return tf.estimator.EstimatorSpec(
            mode,
            predictions=inputs
        )

    a = tf.Variable(1, dtype=tf.float32, trainable=True)

    # Doesn't need to train, but the model needs to be trainable for exporting to work
    loss = tf.reduce_mean(a * inputs)

    optimizer = params.get('optimizer', None) or tf.train.AdamOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())

    return tf.estimator.EstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op
    )


def input_fn():
    return {'test': tf.constant([1, 0], dtype=tf.int64)}, tf.constant([3, 2], dtype=tf.float32)


def serving_input_fn():
    receiver_tensors = {
        'test': tf.placeholder(tf.int64, shape=[None, 1], name='test')
    }

    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)


# Custom estimator
estimator = tf.estimator.Estimator(model_fn=model_fn, params=estimator_params)
# Canned estimator
# estimator = tf.estimator.DNNRegressor([2, 2, 1], feature_columns=feature_columns)

estimator.train(input_fn=input_fn, steps=5)

estimator.export_saved_model('./', serving_input_fn)
&lt;/denchmark-code&gt;

Serve the generated saved_model with Tensorflow serving.
Now make requests to it.
Example body for custom estimators:
&lt;denchmark-code&gt;{
	"inputs": {
		"test": [0, 1]
	}
}
&lt;/denchmark-code&gt;

Example body for the canned estimator:
&lt;denchmark-code&gt;{
	"signature_name": "predict",
	"inputs": {
		"test": [0, 1]
	}
}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

All I get as response from tensorflow serving:
&lt;denchmark-code&gt;{
    "error": "Input to reshape is a tensor with 2 values, but the requested shape has 4\n\t [[{{node input_layer/test_indicator/Reshape}}]]"
}
&lt;/denchmark-code&gt;

P.S.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/29ecfbf1e7ab2f073e69770753174667079d10b5/tensorflow/core/kernels/reshape_op.h#L92&gt;The reshape op is in the tensorflow library&lt;/denchmark-link&gt;
, perhaps I should make an issue over there?
	</description>
	<comments>
		<comment id='1' author='nielsgroen' date='2019-08-05T22:29:36Z'>
		&lt;denchmark-link:https://github.com/nielsgroen&gt;@nielsgroen&lt;/denchmark-link&gt;
 Please post this issue in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues&gt;Tensorflow/tensorflow&lt;/denchmark-link&gt;
 as the issue here is being caused by Tensorflow not Tensorflow serving. Thanks!
		</comment>
		<comment id='2' author='nielsgroen' date='2019-08-06T08:25:26Z'>
		Thanks for the feedback.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31360&gt;Here is the issue over at tensorflow/tensorflow&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='nielsgroen' date='2019-08-28T09:25:07Z'>
		For people stumbling on this, I found a stupidly simple workaround:
It turns out, when using the indicator_column, making the inputs strictly two-dimensional will work.
&lt;denchmark-code&gt;{
	"signature_name": "predict",
	"inputs": {
		"test": [[0], [1]]  // note the extra dimension
	}
}
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>