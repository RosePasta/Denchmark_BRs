<bug id='1354' author='farzaa' open_date='2019-05-19T14:11:06Z' closed_time='2019-06-21T16:08:23Z'>
	<summary>Issue with TF Serving at high load.</summary>
	<description>
I have 30 Docker containers. Each container is processing one frame from a video per second.
I also have a single GPU (w/ a NVIDIA Tesla P100 + 16 CPUs + 80GB RAM) server running  from the Docker image pulled directly from &lt;denchmark-link:https://hub.docker.com/r/tensorflow/serving&gt;here&lt;/denchmark-link&gt;
. I am using the image w/ the tag . It is hosting a Faster-RCNN model taking images as input and giving bounding boxes as output.
Each Docker container will take a frame (one per second) from the video and send it the GPU server via the gRPC port opened up by tf-serving. That means with 30 Docker containers - I am sending 30 frames per second to my tf-serving server. This works flawlessly. The average time per request is about 0.25 seconds.
The issue comes when I slightly increase the load. At 40 Docker containers I send 40 frames per second the my tf-serving server. The issue here is every request starts taking over 2.5 seconds. Soon - every request begins to timeout and it feels as if a few requests failing turns into all the requests failing.
This is a massive slowdown and I didn't even increase the load by much. I only increased it by 20 extra requests per second!
What could be causing these issues? Note: I ran htop and the CPUs are being very underutilized and aren't showing signs of a heavy load.
Here is graph to also illustrate the issue. At 22:00, this indicates the time per requests while hitting tf-serving with 30 requests per second. 23:00 shows request times massively jumping at 40 requests per second. You can see the massive jump from requests taking 0.25s to 2.1 seconds.
&lt;denchmark-link:https://user-images.githubusercontent.com/15614124/57995546-b01bc500-7a90-11e9-9af0-44dfd65c98ad.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='farzaa' date='2019-06-12T17:17:31Z'>
		&lt;denchmark-link:https://github.com/farzaa&gt;@farzaa&lt;/denchmark-link&gt;
 Can you please provide the model that you are working with or can you please use the timeline profiler in your model by look at this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/21312&gt;issue&lt;/denchmark-link&gt;
 and let me know if that helps. Thanks!
		</comment>
		<comment id='2' author='farzaa' date='2019-06-21T16:08:23Z'>
		&lt;denchmark-link:https://github.com/farzaa&gt;@farzaa&lt;/denchmark-link&gt;
, We haven't heard from you for many days now. We will close this for now, please feel free to reopen this issue if you still need help.
		</comment>
		<comment id='3' author='farzaa' date='2019-06-26T12:32:31Z'>
		
@farzaa Can you please provide the model that you are working with or can you please use the timeline profiler in your model by look at this issue and let me know if that helps. Thanks!

Any progress on this?
		</comment>
	</comments>
</bug>