<bug id='299' author='Almars12345' open_date='2016-11-30T19:52:40Z' closed_time='2016-12-02T16:12:16Z'>
	<summary>Memory Error</summary>
	<description>
When i loade google model, i get "out of memory"issue . I try  modifying the heap size from run configuration ,but it still not working.BTW,I'm using NetBeans to run the code below.
Here is the error
&lt;denchmark-code&gt;- &gt; Exception in thread "main" java.lang.OutOfMemoryError: Cannot allocate new FloatPointer(900000000), totalBytes = 160602582, physicalBytes = 941273088
- &gt; 	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:76)
- &gt; 	at org.nd4j.linalg.api.buffer.BaseDataBuffer.&lt;init&gt;(BaseDataBuffer.java:445)
- &gt; 	at org.nd4j.linalg.api.buffer.FloatBuffer.&lt;init&gt;(FloatBuffer.java:57)
- &gt; 	at org.nd4j.linalg.api.buffer.factory.DefaultDataBufferFactory.createFloat(DefaultDataBufferFactory.java:238)
- &gt; 	at org.nd4j.linalg.factory.Nd4j.createBuffer(Nd4j.java:1301)
- &gt; 	at org.nd4j.linalg.factory.Nd4j.createBuffer(Nd4j.java:1276)
- &gt; 	at org.nd4j.linalg.api.ndarray.BaseNDArray.&lt;init&gt;(BaseNDArray.java:253)
- &gt; 	at org.nd4j.linalg.cpu.nativecpu.NDArray.&lt;init&gt;(NDArray.java:112)
- &gt; 	at org.nd4j.linalg.cpu.nativecpu.CpuNDArrayFactory.create(CpuNDArrayFactory.java:248)
- &gt; 	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:4477)
- &gt; 	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:4439)
- &gt; 	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:3692)
- &gt; 	at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.readBinaryModel(WordVectorSerializer.java:238)
- &gt; 	at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.loadGoogleModel(WordVectorSerializer.java:134)
- &gt; 	at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.loadGoogleModel(WordVectorSerializer.java:111)
- &gt; 	at org.deeplearning4j.examples.nlp.word2vec.Word2VecRawTextExample.main(Word2VecRawTextExample.java:72)
- &gt; Caused by: java.lang.OutOfMemoryError: Cannot allocate 160602582 + 3600000000 bytes (&gt; Pointer.maxBytes)
- &gt; 	at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:543)
- &gt; 	at org.bytedeco.javacpp.Pointer.init(Pointer.java:121)
- &gt; 	at org.bytedeco.javacpp.FloatPointer.allocateArray(Native Method)
- &gt; 	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:68)
- &gt; 	... 15 more
- &gt; ------------------------------------------------------------------------
- &gt; BUILD FAILURE
- &gt; ------------------------------------------------------------------------
- &gt; Total time: 13.891 s
- &gt; Finished at: 2016-11-30T22:46:15+03:00
- &gt; Final Memory: 10M/155M
- &gt; ------------------------------------------------------------------------
- &gt; Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2.1:exec (default-cli) on project dl4j-examples: Command execution failed. Process exited with an error: 1 (Exit value: 1) -&gt; [Help 1]
- &gt; 
- &gt; To see the full stack trace of the errors, re-run Maven with the -e switch.
- &gt; Re-run Maven using the -X switch to enable full debug logging.
- &gt; 
- &gt; For more information about the errors and possible solutions, please read the following articles:
- &gt; [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
- &gt; 

Here is my source 

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;public static void main(String[] args) throws Exception {

    // Gets Path to Text file
    String filePath = new ClassPathResource("raw_sentences.txt").getFile().getAbsolutePath();

    log.info("Load &amp; Vectorize Sentences....");
    // Strip white space before and after for each line
    SentenceIterator iter = new BasicLineIterator(filePath);
    // Split on white spaces in the line to get words
    TokenizerFactory t = new DefaultTokenizerFactory();

    /*
        CommonPreprocessor will apply the following regex to each token: [\d\.:,"'\(\)\[\]|/?!;]+
        So, effectively all numbers, punctuation symbols and some special symbols are stripped off.
        Additionally it forces lower case for all tokens.
     */
    t.setTokenPreProcessor(new CommonPreprocessor());

    log.info("Building model....");
    Word2Vec vec = new Word2Vec.Builder()
            .minWordFrequency(5)
            .iterations(1)
            .layerSize(100)
            .seed(42)
            .windowSize(5)
            .iterate(iter)
            .tokenizerFactory(t)
            .build();

    log.info("Fitting Word2Vec model....");
    vec.fit();

    log.info("Writing word vectors to text file....");

    // Write word vectors to file
    WordVectorSerializer.writeWordVectors(vec, "pathToWriteto.txt");

    // Prints out the closest 10 words to "day". An example on what to do with these Word Vectors.
    log.info("Closest Words:");
    Collection&lt;String&gt; lst = vec.wordsNearest("day", 10);
    System.out.println("10 Words closest to 'day': " + lst);
       File gModel = new File("C:/Users/the king/Documents/NetBeansProjects/GoogleNews-vectors-negative300.bin.gz");
&lt;/denchmark-code&gt;

Word2Vec vec1 = WordVectorSerializer.loadGoogleModel(gModel, true);
Finally POM
&lt;denchmark-code&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;artifactId&gt;dl4j-examples&lt;/artifactId&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
        &lt;artifactId&gt;deeplearning4j-examples-parent&lt;/artifactId&gt;
        &lt;version&gt;0.7-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;

    &lt;name&gt;DeepLearning4j Examples&lt;/name&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;snapshots-repo&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;distributionManagement&gt;
        &lt;snapshotRepository&gt;
            &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt;
            &lt;name&gt;Sonatype Nexus snapshot repository&lt;/name&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
        &lt;/snapshotRepository&gt;
        &lt;repository&gt;
            &lt;id&gt;nexus-releases&lt;/id&gt;
            &lt;name&gt;Nexus Release Repository&lt;/name&gt;
            &lt;url&gt;http://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/distributionManagement&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
                &lt;artifactId&gt;nd4j-native-platform&lt;/artifactId&gt;
                &lt;version&gt;${nd4j.version}&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
                &lt;artifactId&gt;nd4j-cuda-7.5-platform&lt;/artifactId&gt;
                &lt;version&gt;${nd4j.version}&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
                &lt;artifactId&gt;nd4j-cuda-8.0-platform&lt;/artifactId&gt;
                &lt;version&gt;${nd4j.version}&lt;/version&gt;
            &lt;/dependency&gt;
       &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;dependencies&gt;
        &lt;!-- ND4J backend. You need one in every DL4J project. Normally define artifactId as either "nd4j-native-platform" or "nd4j-cuda-7.5-platform" --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
            &lt;artifactId&gt;${nd4j.backend}&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;!-- Core DL4J functionality --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;artifactId&gt;deeplearning4j-nlp&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- deeplearning4j-ui is used for HistogramIterationListener + visualization: see http://deeplearning4j.org/visualization --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;artifactId&gt;deeplearning4j-ui_2.10&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Force guava versions for using UI/HistogramIterationListener --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
            &lt;artifactId&gt;guava&lt;/artifactId&gt;
            &lt;version&gt;${guava.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- datavec-data-codec: used only in video example for loading video data --&gt;
        &lt;dependency&gt;
            &lt;artifactId&gt;datavec-data-codec&lt;/artifactId&gt;
            &lt;groupId&gt;org.datavec&lt;/groupId&gt;
            &lt;version&gt;${datavec.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Used in the feedforward/classification/MLP* and feedforward/regression/RegressionMathFunctions example --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;jfree&lt;/groupId&gt;
            &lt;artifactId&gt;jfreechart&lt;/artifactId&gt;
            &lt;version&gt;${jfreechart.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.jfree&lt;/groupId&gt;
            &lt;artifactId&gt;jcommon&lt;/artifactId&gt;
            &lt;version&gt;${jcommon.version}&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- Used for downloading data in some of the examples --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
            &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
            &lt;version&gt;4.3.5&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
                &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;${exec-maven-plugin.version}&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;exec&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
                &lt;configuration&gt;
                    &lt;executable&gt;java&lt;/executable&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;${maven-shade-plugin.version}&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;
                    &lt;shadedClassifierName&gt;${shadedClassifier}&lt;/shadedClassifierName&gt;
                    &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt;
                    &lt;filters&gt;
                        &lt;filter&gt;
                            &lt;artifact&gt;*:*&lt;/artifact&gt;
                            &lt;excludes&gt;
                                &lt;exclude&gt;org/datanucleus/**&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                            &lt;/excludes&gt;
                        &lt;/filter&gt;
                    &lt;/filters&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"&gt;
                                    &lt;resource&gt;reference.conf&lt;/resource&gt;
                                &lt;/transformer&gt;
                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"/&gt;
                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.5.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${java.version}&lt;/source&gt;
                    &lt;target&gt;${java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;



&lt;/denchmark-code&gt;

Could you please help me solve this problem .
	</description>
	<comments>
		<comment id='1' author='Almars12345' date='2016-12-01T01:46:27Z'>
		You'll need to increase the limit to about 40g of RAM to run that. Are you
saying that you are getting this error with unmodified example code?
		</comment>
		<comment id='2' author='Almars12345' date='2016-12-01T07:21:20Z'>
		@saudent Yes getting this error with the above code.Are sure i need 40g?
My laptop RAM is 8 G.I think 40 g too much .
		</comment>
		<comment id='3' author='Almars12345' date='2016-12-01T07:23:15Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Almars12345' date='2016-12-01T08:09:19Z'>
		What about Word2VecSentimentRNN? Do you have any problems executing that one?
		</comment>
		<comment id='5' author='Almars12345' date='2016-12-01T08:29:30Z'>
		I'm not sure why 40gb would be needed there. It's pure oom during w2v google model load, which uses around 4gb itself for floats only + strings.
		</comment>
		<comment id='6' author='Almars12345' date='2016-12-01T08:37:11Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 I executed the same code without loading the model, it works.However , loading the model gives me the error .Regarding to word2vecsentiment , it works .I believe the problem with loading the model.it consumes so much memory. I increased the heap size -Xmx6G , but still .Also, i run the same program with 16 RAM, the same issue appears.
		</comment>
		<comment id='7' author='Almars12345' date='2016-12-01T09:47:56Z'>
		Here's where google model loading happens: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/6c11cd24ed47c37d535ec38ca7a7afbcb1b50891/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/loader/WordVectorSerializer.java#L224-L224&gt;https://github.com/deeplearning4j/deeplearning4j/blob/6c11cd24ed47c37d535ec38ca7a7afbcb1b50891/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/loader/WordVectorSerializer.java#L224-L224&lt;/denchmark-link&gt;

TL/DR: syn0 is created, which matches model dimensionality, in case of Google Model - it's 3m x 300. After it's created - vectors are read one by one, and inserted into syn0.
I don't see any real "extra" memory use here.
		</comment>
		<comment id='8' author='Almars12345' date='2016-12-01T09:49:53Z'>
		Btw, as fast workaround you could use w2v models with smaller dimensionality.
		</comment>
		<comment id='9' author='Almars12345' date='2016-12-01T11:12:59Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 so , what i have to do to fix it? And how can I decrease the dimensionality ?
		</comment>
		<comment id='10' author='Almars12345' date='2016-12-01T11:27:19Z'>
		I'm not sure at this moment, if there's anything to be fixed. I've pointed you to the code, so you can see it yourself.
As for dimensionality: just download another pre-trained model, or train your own. There's plenty of other models available for download in the web. Google Model isn't the only :)
I.e. here: &lt;denchmark-link:https://github.com/3Top/word2vec-api&gt;https://github.com/3Top/word2vec-api&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='Almars12345' date='2016-12-01T18:04:11Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 i'm wondering if i can load GloVe model such as crawl, twitter..etc., using deeplearing4j library ? is there any sample i can have a look at
thank you
		</comment>
		<comment id='12' author='Almars12345' date='2016-12-01T18:06:44Z'>
		Yes, just use the same methods. There's 2 widely used formats out there, and we support them both. One is binary model (like google model) and other one is csv. So you'll definitely be fine using  WordVectorSerializer utility methods
		</comment>
		<comment id='13' author='Almars12345' date='2016-12-02T16:09:21Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 hi again , is it possible to run the word2vect code in  java project , i mean not maven? and what are the libraries needed in order to do that.
		</comment>
		<comment id='14' author='Almars12345' date='2016-12-02T16:12:16Z'>
		We don't really support setups without build systems being used. Sure, you're free to go that way, but you'll be on your own there. I.e. parse maven dependency tree, or something like that.
		</comment>
		<comment id='15' author='Almars12345' date='2017-03-03T09:16:49Z'>
		Even i am faced the same issue like "Unable to allocate memory" for the Google-news model, then tried with CBOW model (words.cbow.s200.w2v.bin.gz). It reads the 1st word in words.cbow.s200.w2v.bin file and exit with error message like unable to read the file format.
I have
RAM: 8GB,
IDE: IntelliJ,
xmx value: 1024M.
Can you please tell me, how to solve this error.?
		</comment>
		<comment id='16' author='Almars12345' date='2017-03-03T09:17:49Z'>
		Yeah you need a larger machine and larger heap space. You need a bigger machine to run the google model. There's nothing for us to do here.
		</comment>
	</comments>
</bug>