<bug id='217' author='ajallooeian' open_date='2016-08-16T12:25:31Z' closed_time='2016-08-17T17:42:18Z'>
	<summary>java.io.FileNotFoundException: Too many open files</summary>
	<description>
It seems that the files opened for reading are not always closed, and at some point the os runs out of file descriptors. (see this for a similar example: &lt;denchmark-link:http://stackoverflow.com/questions/2272908/too-many-open-files-how-many-are-open-what-they-are-and-how-many-can-the-jvm&gt;http://stackoverflow.com/questions/2272908/too-many-open-files-how-many-are-open-what-they-are-and-how-many-can-the-jvm&lt;/denchmark-link&gt;
)
This happens for example in org.deeplearning4j.examples.nlp.paragraphvectors.tools.FileLabelAwareIterator.nextDocument
(I am running the example code with considerably more number of files)
	</description>
	<comments>
		<comment id='1' author='ajallooeian' date='2016-08-16T12:34:53Z'>
		Related to issue &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/1829&gt;https://github.com/deeplearning4j/deeplearning4j/issues/1829&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ajallooeian' date='2016-08-17T17:42:18Z'>
		Fixed
		</comment>
	</comments>
</bug>