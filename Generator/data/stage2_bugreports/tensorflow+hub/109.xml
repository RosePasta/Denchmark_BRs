<bug id='109' author='jonkoi' open_date='2018-07-21T09:15:37Z' closed_time='2019-05-10T07:46:45Z'>
	<summary>label_image does not work with quantized MobilenetV1 .tflite</summary>
	<description>
Hi,
I used retrain.py to retrain quantized mobilenet v1 from &lt;denchmark-link:https://tfhub.dev/google/imagenet/mobilenet_v1_050_128/quantops/classification/1&gt;https://tfhub.dev/google/imagenet/mobilenet_v1_050_128/quantops/classification/1&lt;/denchmark-link&gt;
.
Then I converted the graph to tflite as following:
&lt;denchmark-code&gt;toco \
--input_format=TENSORFLOW_GRAPHDEF \
--input_file=/home/khoi/mobilenet_slim/exp2_1_1/graph.pb \
--output_format=TFLITE \
--output_file=/home/khoi/mobilenet_slim/exp2_1_1/exp2.tflite \
--inference_type=QUANTIZED_UINT8 \
--input_shape=1,128,128,3 \
--input_array=Placeholder \
--output_array=final_result \
--input_data_type=FLOAT
&lt;/denchmark-code&gt;

When I run the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/examples/label_image/label_image.cc&gt;label_image&lt;/denchmark-link&gt;
,
&lt;denchmark-code&gt;
bazel run --config=opt //tensorfl/lite/examples/label_image:label_image -- \
--tflite_model=/home/khoi/mobilenet_slim/exp2_1_1/exp2.tflite \
--image=/home/khoi/mobilenet_slim/exp2_1_1/3.bmp \
--labels=/home/khoi/mobilenet_slim/exp2_1_1/labels.txt
&lt;/denchmark-code&gt;

the process stop at resolved reporter without any error.
Does anyone know what the problem can be?
	</description>
	<comments>
		<comment id='1' author='jonkoi' date='2018-08-02T08:00:43Z'>
		Hi jonoki, thanks for the report. We're looking into it, not clear yet which component is even at fault...
		</comment>
		<comment id='2' author='jonkoi' date='2018-12-03T05:41:31Z'>
		How to run quantized mobilenet v1 inference model?
		</comment>
		<comment id='3' author='jonkoi' date='2019-05-09T08:58:31Z'>
		&lt;denchmark-link:https://github.com/jonkoi&gt;@jonkoi&lt;/denchmark-link&gt;
: This reproduces for me (and --config=dbg plus gdb shed some light). The issue appears to be a boundary condition in TFLite's handling of quantization scales. I'll see if I can work around that in the quantops modules itself...
		</comment>
		<comment id='4' author='jonkoi' date='2019-05-10T07:46:42Z'>
		Please try again with &lt;denchmark-link:https://tfhub.dev/google/imagenet/mobilenet_v1_050_128/quantops/classification/3&gt;https://tfhub.dev/google/imagenet/mobilenet_v1_050_128/quantops/classification/3&lt;/denchmark-link&gt;

For me, that fixed the problem. Please reopen (with repro details) if it persists for you. Thank you for your patience.
		</comment>
		<comment id='5' author='jonkoi' date='2019-11-18T05:57:35Z'>
		Hi, &lt;denchmark-link:https://github.com/arnoegw&gt;@arnoegw&lt;/denchmark-link&gt;
 . I'm curious about what did you do to build the V3? Did you do something in module_fn()?
By the way, are the module_fn() in ModuleSpec you guys used to generate TensorFlow hub modules open-sourced? Actually I'm also interested in them and I hope to learn these implementations.
Thank you very much.
		</comment>
		<comment id='6' author='jonkoi' date='2019-11-18T16:45:28Z'>
		Hi &lt;denchmark-link:https://github.com/XMK233&gt;@XMK233&lt;/denchmark-link&gt;
, the module_fn for google/imagenet/mobilenet_v1... is just a thin wrapper around the TF-Slim implementation (and likewise for any of our image models that mention TF-Slim in the documentation). Unfortunately, it is not open-sourced at this time.
That wrapper contains a scaling from the canonical input range [0,1] of pixel values to the one expected internally by slim, which is [-1,+1]. Before commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/01ebab40444bc20202336a36012aedc02210661e&gt;tensorflow/tensorflow@01ebab4&lt;/denchmark-link&gt;
, toco did not work when using the precise range [-1,+1] for quantization, so I worked around that and made it [-1,+1.001].
		</comment>
		<comment id='7' author='jonkoi' date='2019-11-18T18:33:49Z'>
		Thanks. ;-)
		</comment>
	</comments>
</bug>