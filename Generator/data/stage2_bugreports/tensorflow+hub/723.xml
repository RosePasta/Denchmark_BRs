<bug id='723' author='edend10' open_date='2021-01-13T18:19:20Z' closed_time='2021-01-20T03:40:57Z'>
	<summary>Exporting a TF Estimator with a `hub.text_embedding_column_v2` does not include the pretrained model</summary>
	<description>
Originally posted to : &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/46371&gt;tensorflow/tensorflow#46371&lt;/denchmark-link&gt;

Was asked to move it here though I'm not sure if it's a hub or estimator issue.
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): AI Platform runtime 2.3 or Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.4
Python version: 3.6.9
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

This issue has been observed with the estimator API only, not Keras. I'm not entirely sure if it's a problem with estimator, export, or a tf hub issue.
Describe the current behavior
When exporting a TF Estimator which uses a hub.text_embedding_column_v2 (the new version of tf-hub's text_embedding_column_v2 that supports pretrained models in TF 2 SavedModel format), the export directory does not include the pretrained model asset files. Instead, the model seems to reference the local path the model was trained with.
When text_embedding_column_v2 is fed with a url (i.e. tfhub.dev/../my-model), the model references the cached local path.
When the local path doesn't exist anymore, or when using the exported model in a different machine altogether, calling tf.saved_model.load fails with a FileNotFound exception:
When defining the embedding column with a local path to the pretrained model:
&lt;denchmark-code&gt; ...
 hub.text_embedding_column_v2('/home/.../my-local-model')
 ...
 estimator = ...
 ...
 tf.estimator.export_saved_model(...)

...
 # on another machine or when removing /home/.../my-local-model:
...
tf.saved_model.load(...)

NotFoundError:  /content/local_nnlm50_2/assets/tokens.txt; No such file or directory
	 [[{{node dnn/input_from_feature_columns/input_layer/text_feature0_hub_module_embedding/StatefulPartitionedCall_1/StatefulPartitionedCall/text_file_init/InitializeTableFromTextFileV2}}]] [Op:__inference_pruned_10883]
&lt;/denchmark-code&gt;

When defining the embedding column with a cached pretrained model from a tfhub.dev url (not reproducible in Colab since tf hub cache doesn't kick in there):
&lt;denchmark-code&gt; ...
 hub.text_embedding_column_v2('https://tfhub.dev/google/nnlm-en-dim50/2')
 ...
 estimator = ...
 ...
 tf.estimator.export_saved_model(...)

...
 # on another machine or when removing cache dir /tmp/tfhub_modules:
...
tf.saved_model.load(...)

  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.NotFoundError:  /tmp/tfhub_modules/74a841d6eb84e8d93d913d716fb5440d020cc291/assets/tokens.txt; No such file or directory
         [[{{node dnn/input_from_feature_columns/input_layer/topClickQuery_1st_hub_module_embedding/StatefulPartitionedCall_1/StatefulPartitionedCall/text_file_init/InitializeTableFromTextFileV2}}]] [Op:__inference_pruned_1658]
&lt;/denchmark-code&gt;

Describe the expected behavior
The expected behavior is for the export directory to include the pretrained model's assets, like it does when using hub.text_embedding_column (v1) with TF 1 format modules. And more importantly: loading the exported estimators should not fail even when loaded in a different machine, as well as not when the original local path to the pretrained model doesn't exist anymore.
The entire exported estimator should be contained within the export directory.

Here's a Colab replicating the issue:
&lt;denchmark-link:https://colab.research.google.com/drive/1Tr5M0m_EVRd5sFdgDX-EbVsk47UokPxD?usp=sharing&gt;https://colab.research.google.com/drive/1Tr5M0m_EVRd5sFdgDX-EbVsk47UokPxD?usp=sharing&lt;/denchmark-link&gt;

Overview of Colab:

Download both versions of nnlm50 to local (TF 1 module, TF 2 SavedModel)
Define two estimators: one with text_embedding_column (v1) and the local TF 1 format pretrained model, and the other with text_embedding_column_v2 and the local TF 2 format pretrained model
Train and export the estimators to SavedModels
Print contents of export dir: TF 1 format has the nnlm50 assets, TF 2 format does not
Try to load both estimators from disk: success
Delete both local nnlm50 directories used for training the estimators
Try to load the v1 estimator from disk again: success
Try to load the v2 estimator from disk again: fails

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='edend10' date='2021-01-18T14:05:50Z'>
		&lt;denchmark-link:https://github.com/edend10&gt;@edend10&lt;/denchmark-link&gt;
  please check  latest comment from &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
  in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/46371&gt;tensorflow/tensorflow#46371&lt;/denchmark-link&gt;
 and confirm if this issue can be closed.
Thanks.
		</comment>
		<comment id='2' author='edend10' date='2021-01-20T03:40:57Z'>
		Looks good to me. Thanks &lt;denchmark-link:https://github.com/arghyaganguly&gt;@arghyaganguly&lt;/denchmark-link&gt;
.
Closing both issues
		</comment>
	</comments>
</bug>