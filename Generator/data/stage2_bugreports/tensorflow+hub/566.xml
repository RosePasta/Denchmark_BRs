<bug id='566' author='CRosero' open_date='2020-04-21T13:42:43Z' closed_time='2020-04-29T09:01:37Z'>
	<summary>Input_shape changeable in some models but not in others.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4
TensorFlow version (use command below): Tensorflow 2.2 / tf-nightly 2.3.0 (installing nightly didn't help solve the problem)
Python version: 3.7.7


I want to do transfer learning but change the input_shape of the model. I used code from a Udacity tutorial on transfer learning, in which I reduce the input size of the tfhub feature_vector by more than half and everything works fine. When I tried to to this with another network, it doesn't work. Why is this?

Input shape should be changeable and the model's summary should be outputted without a problem.

&lt;denchmark-link:https://colab.research.google.com/drive/1AIH9d-sqISB1BVi01g7Eqtv6nzBiiAnR&gt;https://colab.research.google.com/drive/1AIH9d-sqISB1BVi01g7Eqtv6nzBiiAnR&lt;/denchmark-link&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
(Udacity)
2020-04-20 15:27:55.636605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a3907cc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-20 15:27:55.636646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Model: "sequential"
...
Total params: 21,813,029
Trainable params: 10,245
Non-trainable params: 21,802,784
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

vs.
(my code)
2020-04-20 15:35:21.610011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82a0172350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-20 15:35:21.610056: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
File "network_model.py", line 17, in 
tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')])
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py", line 456, in _method_wrapper
result = method(self, *args, **kwargs)
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py", line 137, in init
self.add(layer)
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py", line 456, in _method_wrapper
result = method(self, *args, **kwargs)
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py", line 210, in add
layer(x)
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/base_layer.py", line 930, in call
outputs = call_fn(cast_inputs, *args, **kwargs)
File "/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/autograph/impl/api.py", line 262, in wrapper
raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:
&lt;denchmark-code&gt;/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow_hub/keras_layer.py:229 call  *
    result = smart_cond.smart_cond(training,
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/load.py:486 _call_attribute  **
    return instance.__call__(*args, **kwargs)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:695 __call__
    result = self._call(*args, **kwds)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:737 _call
    self._initialize(args, kwds, add_initializers_to=initializers)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:617 _initialize
    *args, **kwds))
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2447 _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2775 _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2665 _create_graph_function
    capture_by_value=self._capture_by_value),
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/func_graph.py:981 func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:528 wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/function_deserialization.py:251 restored_function_body
    "\n\n".join(signature_descriptions)))

ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (4 total):
    * Tensor("inputs:0", shape=(None, 64, 64, 3), dtype=float32)
    * False
    * False
    * 0.99
  Keyword arguments: {}

Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (4 total):
    * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
    * True
    * True
    * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
  Keyword arguments: {}

Option 2:
  Positional arguments (4 total):
    * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
    * True
    * False
    * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
  Keyword arguments: {}

Option 3:
  Positional arguments (4 total):
    * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
    * False
    * False
    * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
  Keyword arguments: {}

Option 4:
  Positional arguments (4 total):
    * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
    * False
    * True
    * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
  Keyword arguments: {}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='CRosero' date='2020-04-29T09:01:33Z'>
		Hi &lt;denchmark-link:https://github.com/CRosero&gt;@CRosero&lt;/denchmark-link&gt;
, thank you for your report!
You are right that the various MobileNet versions (as well as some NASNets) do require a fixed input shape (as documented at their respective tfhub.dev URL), because of a limitation in the TF.Slim code they are exported from.  That said, we hope that the large range of input sizes spanned by the various versions let you find the right tradeoff between speed an accuracy.
Inception, ResNet and some other models have flexible input shapes because their original code does not carry the same restriction.
		</comment>
	</comments>
</bug>