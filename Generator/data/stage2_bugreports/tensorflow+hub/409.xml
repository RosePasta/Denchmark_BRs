<bug id='409' author='andriikrupka' open_date='2019-11-11T14:13:02Z' closed_time='2019-12-11T10:19:24Z'>
	<summary>Impossible to use saved model USE4 with KerasLayer</summary>
	<description>
According to sample (&lt;denchmark-link:https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub&gt;Transfer learning with TensorFlow Hub&lt;/denchmark-link&gt;
), I try to finetune universal sentence encoder (version 4):
&lt;denchmark-code&gt;use_url = "https://tfhub.dev/google/universal-sentence-encoder-large/4"


feature_extractor_layer = hub.KerasLayer(use_url, input_shape=[], 
                           dtype=tf.string, trainable=True)
model = tf.keras.Sequential([
    feature_extractor_layer,
    layers.Dense(16, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.summary()

model.predict([['hello']]) 

import time
t = time.time()

export_path = "/tmp/saved_models/{}".format(int(t))
model.save(export_path, save_format='tf')

reloaded = tf.keras.models.load_model(export_path)

&lt;/denchmark-code&gt;

when I try predict from my reloaded model I get error:
&lt;denchmark-code&gt;reloaded.predict([["hello"]])
&lt;/denchmark-code&gt;


FailedPreconditionError:  Table not initialized.
[[{{node keras_layer_22_1/cond/else/_1/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/text_preprocessor_1/hash_table_Lookup/hash_table_Lookup/LookupTableFindV2}}]] [Op:__inference_keras_scratch_graph_1888313]
Function call stack:
keras_scratch_graph

ps

tf.version
'2.0.0'

	</description>
	<comments>
		<comment id='1' author='andriikrupka' date='2019-11-11T19:32:14Z'>
		&lt;denchmark-link:https://github.com/arnoegw&gt;@arnoegw&lt;/denchmark-link&gt;
 Was able to replicate this bug. Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/8ab7605eb059a7c58f33fa557cd43ab9/untitled225.ipynb&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='andriikrupka' date='2019-11-14T17:29:29Z'>
		Thank you, &lt;denchmark-link:https://github.com/andriikrupka&gt;@andriikrupka&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
, for the report. Your code seems to work for &lt;denchmark-link:https://tfhub.dev/google/nnlm-en-dim50/2&gt;https://tfhub.dev/google/nnlm-en-dim50/2&lt;/denchmark-link&gt;
 (arguably the simplest text embedding with a lookup table). I've reached out to the module publisher for the specifics of U.S.E.
		</comment>
		<comment id='3' author='andriikrupka' date='2019-12-05T23:09:47Z'>
		It seems the model has been updated to solve this issue (&lt;denchmark-link:https://tfhub.dev/google/universal-sentence-encoder-large/5&gt;v5&lt;/denchmark-link&gt;
)
But I've filed another issue regarding trainable KerasLayer for this and for USEv4 (not large): &lt;denchmark-link:https://github.com/tensorflow/hub/issues/437&gt;#437&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='andriikrupka' date='2019-12-11T10:19:22Z'>
		Hi &lt;denchmark-link:https://github.com/eduardofv&gt;@eduardofv&lt;/denchmark-link&gt;
, let me close this issue then, and defer to &lt;denchmark-link:https://github.com/tensorflow/hub/issues/437&gt;#437&lt;/denchmark-link&gt;
 for the rest. (There seems to be a fix for it already.)
		</comment>
	</comments>
</bug>