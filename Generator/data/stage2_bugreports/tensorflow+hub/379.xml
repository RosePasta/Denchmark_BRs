<bug id='379' author='ifsheldon' open_date='2019-10-07T13:00:53Z' closed_time='2019-11-01T10:06:22Z'>
	<summary>hub.module_v2.load() returns a non-callable object</summary>
	<description>
System information

tf version: 2.0.0 gpu
tf_hub version: 0.6
python: 3.7 with Anaconda

model = "https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/3" # MobileNetV2
# both lines below cannot work
layer = hub.KerasLayer(model)
layer = hub.KerasLayer(model, tags="train")
Error messages are long, but those related to the issue are below:
~\anaconda\envs\tf2\lib\site-packages\tensorflow_hub\keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)
    102       self._func = handle
    103     else:
--&gt; 104       self._func = module_v2.load(handle)
    105       if not callable(self._func):
    106         raise ValueError("Non-callable result from hub.load('%s')" %
ValueError: Importing a SavedModel with tf.saved_model.load requires a 'tags=' argument if there is more than one MetaGraph. Got 'tags=None', but there are 2 MetaGraphs in the SavedModel with tag sets [[], ['train']]. Pass a 'tags=' argument to load this SavedModel.
then I realized if we just directly use hub.KerasLayer(), the 'tags=' argument will not be passed to module_v2.load(), which causes this error.
So then I modified the codes as below:
model = "https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/3"
mod = hub.module_v2.load(model,tags=['train']) # this line works fine
layer = hub.KerasLayer(mod) # error here
Howerver, this won't work, either. The error messages related to the error are:
&lt;denchmark-code&gt;~\anaconda\envs\tf2\lib\site-packages\tensorflow_hub\keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)
    102       self._func = handle
    103     else:
--&gt; 104       self._func = module_v2.load(handle)
    105       if not callable(self._func):
    106         raise ValueError("Non-callable result from hub.load('%s')" %
&lt;/denchmark-code&gt;

and
AttributeError: 'AutoTrackable' object has no attribute 'startswith'
It seems that it is related to the code in keras_layer.py and specificly codes below:
def __init__(self, handle, trainable=False, arguments=None, **kwargs):
    self._handle = handle
    # Resolve the handle to a callable `func`.
    if callable(handle):
      self._func = handle
    else:
      self._func = module_v2.load(handle)
      if not callable(self._func):
           raise ValueError("Non-callable result from hub.load('%s')" %
                         str(handle))
When I pass the mod object to hub.KerasLayer(), the code in if branch is expected to be executed, but the code in else branch is executed, which means the mod object returned by  module_v2.load() is not callable. That doesn't make sense.
So I wonder maybe it is a bug or there's something wrong with the MobileNet model or it just that the model doesn't fit in TF2.0.
	</description>
	<comments>
		<comment id='1' author='ifsheldon' date='2019-10-08T13:04:00Z'>
		I've had a similar issue with AutoTrackable not being callable when trying to use the universal sentence encoder. I wonder if TF2 updates inadvertently messed with the module and broke it?
		</comment>
		<comment id='2' author='ifsheldon' date='2019-10-09T10:31:48Z'>
		That SavedModel does not exposes an object based __call__ or other elements required to be compatible with hub.KerasLayer.
We are working in:

Republishing some models in this format.
Updating hub.KerasLayer to fallback to use .signatures["default"] if the saved model loaded via "tf.saved_model.load()" does not provides a __call__. In this case fine-tune the models is likely not to be supported out of the box as there details on how update ops can't be pruned from the graph.

At the moment you have the following options:

Use a SavedModel compatible with current "hub.KerasLayer": https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4
Create your own keras Layer from an old saved model by wiring the trainable variables properties, an implement a __call__ that calls the right signature exposed by an old SavedModel. See the migration guide for an example.
If you also want to fine-tune those and have correct handling of update ops such as batch norm maintaining of exponential moving averages then you have to go one layer deeper and prune the parts of a graph with the use of tf.compat.v1.wrap_function and old collections.

		</comment>
		<comment id='3' author='ifsheldon' date='2019-10-09T10:34:08Z'>
		The following link is relevant about implementing your own KerasLayer to wire an old SavedModel:
&lt;denchmark-link:https://github.com/tensorflow/hub/blob/master/docs/migration_tf2.md&gt;https://github.com/tensorflow/hub/blob/master/docs/migration_tf2.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ifsheldon' date='2019-11-01T10:06:22Z'>
		Marking this as closed since there are both TF-2 versions of these modules as well as hub.KerasLayer was updated to handle legacy hub Modules in &lt;denchmark-link:https://github.com/tensorflow/hub/commit/c3b29c32339542d89078d83368d4ef6b76f93a13&gt;c3b29c3&lt;/denchmark-link&gt;
 and that is present in the new r0.7 version of the library.
		</comment>
	</comments>
</bug>