<bug id='251' author='frogermcs' open_date='2019-03-09T10:16:55Z' closed_time='2019-03-13T18:16:17Z'>
	<summary>Logs of retrain.py break web browser when launched in Colab</summary>
	<description>
When you play with &lt;denchmark-link:https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py&gt;retrain.py&lt;/denchmark-link&gt;
 locally on your machine (I use Jupyter Notebook and Docker) it is fine to do 10k-20k training steps.
But when you try to launch it on Colab, it seems that the amount of logs is way too big, and usually it breaks Chrome, making it's card impossible to launch (tested on Macbook Pro 2017, 16GB Ram, i7).
Maybe it would be a good idea to define level of logs as a input argument in retrain.py script?
How to reproduce:
Launch my project in Colaboratory: &lt;denchmark-link:https://github.com/frogermcs/GTSRB-TensorFlow-Lite&gt;https://github.com/frogermcs/GTSRB-TensorFlow-Lite&lt;/denchmark-link&gt;
. It's pretty likely Chrome will crash during the learning process (3/4 tries crash).
	</description>
	<comments>
		<comment id='1' author='frogermcs' date='2019-03-11T22:05:47Z'>
		&lt;denchmark-link:https://github.com/frogermcs&gt;@frogermcs&lt;/denchmark-link&gt;
  Could you please confirm if you selected the "Hardware accelerator" from the Colab ? If so, which one you selected ?
		</comment>
		<comment id='2' author='frogermcs' date='2019-03-12T06:52:13Z'>
		Usually it's TPU. Do you think it can have something with it?
		</comment>
		<comment id='3' author='frogermcs' date='2019-03-12T09:21:01Z'>
		&lt;denchmark-link:https://github.com/frogermcs&gt;@frogermcs&lt;/denchmark-link&gt;
 it might be useful what specific error message(s) is overly verbose. In general if the messages are printed through standard Python or standard TF Logger, they could be disabled by tweaking the logging level before running the function from retrain.py.
For standard TF logger you can do something like "tf.logging.set_verbosity(tf.logging.FATAL)" before running the function in question. For standard Python logging it would be "logging.root.setLevel(logging.FATAL)"
If the message are produced by print() you could just redirect all stdin into a file, e.g.
sys.stdout = open('file', 'w')
print("Blah")  # Will be written to file.
		</comment>
		<comment id='4' author='frogermcs' date='2019-03-12T10:50:55Z'>
		I think setting logging level is not possible with current  implementation because of &lt;denchmark-link:https://github.com/tensorflow/hub/blob/master/examples/image_retraining/retrain.py#L970&gt;that&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;def main(_):
  # Needed to make sure the logging output is visible.
  # See https://github.com/tensorflow/tensorflow/issues/3047
  tf.logging.set_verbosity(tf.logging.INFO)
&lt;/denchmark-code&gt;

Maybe it would be good to differentiate logs a little bit? For example:
&lt;denchmark-code&gt;          tf.logging.info(
              str(how_many_bottlenecks) + ' bottleneck files created.')
&lt;/denchmark-code&gt;

should be logging.debug()? And just some final info about script outputs should be .info()? And then we could parametrize it via input args. What do you think ðŸ¤”?
		</comment>
		<comment id='5' author='frogermcs' date='2019-03-12T10:53:06Z'>
		And the issues I have? "Aww snap" from Chrome. Tab is either crashing or when I launch it, view isn't rendered. Usually when I'm in a half way of retrain.py - bottlenecks are probably already created, and training process is in progress.
		</comment>
		<comment id='6' author='frogermcs' date='2019-03-12T11:27:42Z'>
		What about as an immediate work-around, just redirecting stdout and stderr as I mentioned in my last post?
But in general I think it makes sense to add a flag to be able to set the logging level for the script. &lt;denchmark-link:https://github.com/arnoegw&gt;@arnoegw&lt;/denchmark-link&gt;
 to see if there are any concerns with the approach.
		</comment>
		<comment id='7' author='frogermcs' date='2019-03-12T13:11:34Z'>
		&lt;denchmark-link:https://github.com/frogermcs&gt;@frogermcs&lt;/denchmark-link&gt;
, I think tf.logging.info every 100 files is ok, but logging for each file (e.g., at line retrain.py:354) should be logging.debug.
Would you like to send me a pull request that adds a --logging_verbosity flag and fixes the per-file logging?
		</comment>
		<comment id='8' author='frogermcs' date='2019-03-13T07:51:00Z'>
		Just created Pull Request (&lt;denchmark-link:https://github.com/tensorflow/hub/pull/253&gt;#253&lt;/denchmark-link&gt;
). I also tested it in my &lt;denchmark-link:https://github.com/frogermcs/GTSRB-TensorFlow-Lite&gt;project&lt;/denchmark-link&gt;
 and works fine in Chrome and Colab. Finally I could leave the Chrome tab open and come back to it after an hour. :)
		</comment>
		<comment id='9' author='frogermcs' date='2019-03-13T18:15:58Z'>
		I merged the pull request earlier today.
Folks who like to train an image classifier in a colab  enjoy living on the cutting edge of TF 2.0.0alpha0 (&lt;denchmark-link:https://www.youtube.com/playlist?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB&gt;announced&lt;/denchmark-link&gt;
 last week) might want to take a look at  &lt;denchmark-link:https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb&gt;examples/colab/tf2_image_retraining.ipynb&lt;/denchmark-link&gt;
 which is considerably smaller, faster (if you use a GPU), and even supports fine-tuning the image module.
		</comment>
	</comments>
</bug>