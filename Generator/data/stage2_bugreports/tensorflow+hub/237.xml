<bug id='237' author='Louagyd' open_date='2019-02-21T15:31:09Z' closed_time='2019-02-28T17:50:13Z'>
	<summary>low performance when restore tfhub model for inference</summary>
	<description>
Hello,
I am using tensorflow_hub and I'm trying to fine tune a model to build a classifier so simply here is my code for creating graph:
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub

sess = tf.Session()
saver = tf.train.Saver()

module = hub.Module("https://tfhub.dev/google/imagenet/mobilenet_v2_050_160/feature_vector/2", trainable=True, tags = {"train"})
HEIGHT, WIDTH = hub.get_expected_image_size(module)
input_ph_init = tf.placeholder(tf.float32, [None, None, None, None])
input_ph = tf.image.resize_images(input_ph_init, [HEIGHT, WIDTH])
target_ph = tf.placeholder(tf.int32, [None, num_classes])


features = module(input_ph)
output_logits = tf.layers.dense(features, num_classes)
output_softmax = tf.nn.softmax(output_logits)
output_classes = tf.argmax(output_softmax, axis = 1)
accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output_softmax, 1), tf.argmax(target_ph, 1)), tf.float32))
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_ph, logits=output_logits))
opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)
&lt;/denchmark-code&gt;

now I train the model and then save it:
&lt;denchmark-code&gt;saver.save(sess, os.path.join(model_name, "HubModel"), global_step = epoch)
&lt;/denchmark-code&gt;

now for inference script, first I create the graph without setting tags and then restor variables:
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub

sess = tf.Session()
saver = tf.train.Saver()

module = hub.Module("https://tfhub.dev/google/imagenet/mobilenet_v2_050_160/feature_vector/2", trainable=True)
HEIGHT, WIDTH = hub.get_expected_image_size(module)
input_ph_init = tf.placeholder(tf.float32, [None, None, None, None])
input_ph = tf.image.resize_images(input_ph_init, [HEIGHT, WIDTH])
target_ph = tf.placeholder(tf.int32, [None, num_classes])


features = module(input_ph)
output_logits = tf.layers.dense(features, num_classes)
output_softmax = tf.nn.softmax(output_logits)
output_classes = tf.argmax(output_softmax, axis = 1)
accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output_softmax, 1), tf.argmax(target_ph, 1)), tf.float32))
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target_ph, logits=output_logits))
opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)
saver.restore(sess, "HubModel-20")
&lt;/denchmark-code&gt;

now with these scripts performance of trained model on validation set is about 80% but for the inference it reduces to 40%. do you know where is the problem?
	</description>
	<comments>
		<comment id='1' author='Louagyd' date='2019-02-22T22:43:42Z'>
		I think maybe it's because the batch normalization stat is not updated properly?
try this:
&lt;denchmark-code&gt;update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
      train_op =  ...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='Louagyd' date='2019-02-28T17:50:13Z'>
		The tensorflow hub team is not supporting requests for debugging ML accuracy performance.
		</comment>
	</comments>
</bug>