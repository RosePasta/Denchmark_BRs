<bug id='358' author='Aashish-1008' open_date='2019-08-29T09:05:16Z' closed_time='2019-10-03T02:29:12Z'>
	<summary>Distributed training not working properly: Waiting for model to be ready. Ready_for_local_init_op: Variables not initialized: global_step,</summary>
	<description>
Hello,
I am using tfhub elmo embedding for NER model training.
Training works fine for a single machine.
When I am training to do training on GCP ML engine with 1 master node, 2 parameter server, 3 worker node.
Training started on master node,
But on all three worker node, I am getting this logs continuously for 1 hours,
looks like training is not getting started on worker node.
I am using these versions which currently supported by Google cloud ML Engine:
Python: 3.5
Tensorflow: 1.13.1
Waiting for model to be ready. Ready_for_local_init_op: Variables not initialized: global_step, module/bilm/char_embed, module/bilm/CNN/W_cnn_0, module/bilm/CNN/b_cnn_0, module/bilm/CNN/W_cnn_1, module/bilm/CNN/b_cnn_1, module/bilm/CNN/W_cnn_2, module/bilm/CNN/b_cnn_2, module/bilm/CNN/W_cnn_3, module/bilm/CNN/b_cnn_3, module/bilm/CNN/W_cnn_4, module/bilm/CNN/b_cnn_4, module/bilm/CNN/W_cnn_5, module/bilm/CNN/b_cnn_5, module/bilm/CNN/W_cnn_6, module/bilm/CNN/b_cnn_6, module/bilm/CNN_high_0/W_carry, module/bilm/CNN_high_0/b_carry, module/bilm/CNN_high_0/W_transform, module/bilm/CNN_high_0/b_transform, module/bilm/CNN_high_1/W_carry, module/bilm/CNN_high_1/b_carry, module/bilm/CNN_high_1/W_transform, module/bilm/CNN_high_1/b_transform, module/bilm/CNN_proj/W_proj, module/bilm/CNN_proj/b_proj, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel, module/aggregation/weights, module/aggregation/scaling, lstm_fused_cell/kernel, lstm_fused_cell/bias, lstm_fused_cell_1/kernel, lstm_fused_cell_1/bias, dense/kernel, dense/bias, crf, beta1_power, beta2_power, lstm_fused_cell/kernel/Adam, lstm_fused_cell/kernel/Adam_1, lstm_fused_cell/bias/Adam, lstm_fused_cell/bias/Adam_1, lstm_fused_cell_1/kernel/Adam, lstm_fused_cell_1/kernel/Adam_1, lstm_fused_cell_1/bias/Adam, lstm_fused_cell_1/bias/Adam_1, dense/kernel/Adam, dense/kernel/Adam_1, dense/bias/Adam, dense/bias/Adam_1, crf/Adam, crf/Adam_1, ready: None
	</description>
	<comments>
		<comment id='1' author='Aashish-1008' date='2019-08-30T13:06:15Z'>
		This indeed looks like &lt;denchmark-link:https://github.com/tensorflow/benchmarks/issues/145&gt;tensorflow/benchmarks#145&lt;/denchmark-link&gt;
, could you please take a look?
		</comment>
		<comment id='2' author='Aashish-1008' date='2019-09-04T10:16:29Z'>
		&lt;denchmark-link:https://github.com/Aashish-1008&gt;@Aashish-1008&lt;/denchmark-link&gt;
 ,
Can you please respond to &lt;denchmark-link:https://github.com/vbardiovskyg&gt;@vbardiovskyg&lt;/denchmark-link&gt;
's comment. Thanks!
		</comment>
		<comment id='3' author='Aashish-1008' date='2019-09-05T12:38:26Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;

Here also  
This issue still open.
		</comment>
		<comment id='4' author='Aashish-1008' date='2019-09-09T08:47:20Z'>
		Hi, this is most likely not TF-Hub related. I would try to first try this with a simpler model, maybe with just one variable, then if it fails, reporting it to &lt;denchmark-link:https://github.com/tensorflow/tensorflow&gt;TensorFlow&lt;/denchmark-link&gt;
. Sorry for not being to help more.
		</comment>
		<comment id='5' author='Aashish-1008' date='2019-10-03T02:29:12Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>