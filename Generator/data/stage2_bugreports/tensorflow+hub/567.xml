<bug id='567' author='jefshe' open_date='2020-04-23T06:06:50Z' closed_time='2020-05-11T09:01:11Z'>
	<summary>Different USE output based on CPU</summary>
	<description>
We've been noticing differences in our dev and production environments when running the USE v5 model. We don't have full control on the CPU we get in this environment which leads to confusing results.
Running the following script gives me different results depending on cpu:
import tensorflow as tf
import tensorflow_hub as hub
module_url = 'https://tfhub.dev/google/universal-sentence-encoder-large/5'
embed = hub.KerasLayer(module_url)
embeddings = embed(["A", "B"])
print(embeddings)
On a Xeon Platinum 8170 CPU :
&lt;denchmark-code&gt;tf.Tensor(
[[-0.04415239  0.03059493  0.00927506 ... -0.06589141 -0.1707134
   0.06353934]
 [-0.0612096   0.0298451   0.02374913 ... -0.05380602 -0.21079066
   0.01050917]], shape=(2, 512), dtype=float32)
&lt;/denchmark-code&gt;

On a Xeon E5-2673:
&lt;denchmark-code&gt;tf.Tensor(
[[-0.04415239  0.03059493  0.00927504 ... -0.06589141 -0.1707134
   0.06353933]
 [-0.06120959  0.02984508  0.02374912 ... -0.05380601 -0.21079066
   0.01050917]], shape=(2, 512), dtype=float32)
&lt;/denchmark-code&gt;

Here are some other details:
OS: Ubunut 16.04
Tensorflow: 2.1
Python 3.6.9
Why would this be? Anything we can do to make our results consistent? My understanding is that floating point operations should yield the same results for these 2 CPU's.
	</description>
	<comments>
		<comment id='1' author='jefshe' date='2020-05-06T22:28:43Z'>
		Is this expected behaviour? Any input?
		</comment>
		<comment id='2' author='jefshe' date='2020-05-11T09:01:08Z'>
		What I see in your numbers is an occasional difference in the 6th or 7th significant digit. While I cannot speak authoritatively for TensorFlow, this matches (if not exceeds) my personal expectations for numerical stability of an advanced model in float32 arithmetic when deployed to different platforms. After all, TF promises to choose the most efficient implementation for a model's high-level operations on the platform at hand, and deep learning models have been observed to work in the presence of much greater errors (cf. TPU's bfloat16 arithmetic, or quantization).
Based on that, I believe there is no bug here about TensorFlow Hub or the model piece it provides.
		</comment>
		<comment id='3' author='jefshe' date='2020-05-13T05:45:46Z'>
		Unfortunately I don't have access to the same VMs and was not logging the CPU type at the time. However, last month I experienced accuracy in different environments only agreeing up to the 3rd significant digit not just the 6th or 7th. We noticed this issue least year when we believed it was only up to the 6th and 7th significant digit and decided to round the outputs to 3 decimal places to attempt to align the outputs on different environments. This is not sufficient enough to control the outputs and we are getting quite different conclusions. Below is the output of a larger calculation involving around 300 sentences but two of the output elements disagreed to 3 decimal places.



VM
input sentence
361st USE output element
432nd USE output element




1
i do not really pay attension to who acts in movies i just watch the movie
0.071
0.050


1
xxxxx
0.016
0.024


2
i do not really pay attension to who acts in movies i just watch the movie
0.070
0.050


2
xxxxx
0.016
0.025



We are logging and monitoring the situation now and I might be able to give more precise environment conditions in the near future. Is there a way of forcing the calculations to use a particular method to ensure they are consistent between environments?
		</comment>
		<comment id='4' author='jefshe' date='2020-05-13T06:33:29Z'>
		Hi &lt;denchmark-link:https://github.com/jrwishart&gt;@jrwishart&lt;/denchmark-link&gt;
, thanks for reporting your findings! Do you still have the USE outputs before they were rounded to 3 places after the decimal dot? Can you report the mean and a rough histogram of the relative and absolute differences between the outputs of the two VMs?
I'm asking because your current table might also be a chance result: If you change a real number by a displacement of +/- 10**-7, it has a 1:10000 chance to add or subtract 1 to the last digit after rounding to 10**-3 in the last place. This is a bit simplistic, but it could explain about a dozen of such minimal changes when computing 512 embedding values for each of 300 inputs... Likewise, if you take many classification decisions based on a linear combination of values, and some of them are close to the decision boundary, the result of rounding them to a discrete classification is essentially random, even if the underlying numerical calculations are "stable" (in the approximate sense of numerical analysis).
But before you dig deeper: this looks very much like a result of how core TensorFlow works across different platforms, unrelated to how TF Hub packages and ships model pieces. Even if you had more numbers, I'm not sure the TF Hub team could help with it.
		</comment>
	</comments>
</bug>