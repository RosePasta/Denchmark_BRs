<bug id='160' author='rahulgarg1' open_date='2018-09-17T11:16:26Z' closed_time='2019-05-14T12:39:07Z'>
	<summary>Tensor_flow text Similarty _issue</summary>
	<description>
Hello Every One ,
Can you please help out to resolve below issue.
2018-09-17 15:10:51.106133: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-09-17 15:10:52.536772: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties:
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.189
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.36GiB
2018-09-17 15:10:52.541692: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2018-09-17 15:10:59.482063: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-09-17 15:10:59.506852: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0
2018-09-17 15:10:59.521022: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N
2018-09-17 15:10:59.527459: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3081 MB memory) -&gt; physical GPU (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0)
[None, None]
2018-09-17 15:11:26.985779: E T:\src\github\tensorflow\tensorflow\core\common_runtime\executor.cc:697] Executor failed to create kernel. Not found: No registered 'Size' OpKernel for GPU devices compatible with node module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)
(OpKernel was found, but attributes didn't match)
.  Registered:  device='CPU'; out_type in [DT_INT32]
device='CPU'; out_type in [DT_INT64]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT32]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT64]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT32]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT64]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT32]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT64]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT32]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT64]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT32]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT64]
&lt;denchmark-code&gt;     [[Node: module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)]]
&lt;/denchmark-code&gt;

Traceback (most recent call last):
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1278, in _do_call
return fn(*args)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1263, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1350, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: No registered 'Size' OpKernel for GPU devices compatible with node module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)
(OpKernel was found, but attributes didn't match)
.  Registered:  device='CPU'; out_type in [DT_INT32]
device='CPU'; out_type in [DT_INT64]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT32]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT64]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT32]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT64]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT32]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT64]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT32]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT64]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT32]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT64]
&lt;denchmark-code&gt;     [[Node: module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)]]
&lt;/denchmark-code&gt;

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "", line 3, in 
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 877, in run
run_metadata_ptr)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1100, in _run
feed_dict_tensor, options, run_metadata)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1272, in _do_run
run_metadata)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\client\session.py", line 1291, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: No registered 'Size' OpKernel for GPU devices compatible with node module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)
(OpKernel was found, but attributes didn't match)
.  Registered:  device='CPU'; out_type in [DT_INT32]
device='CPU'; out_type in [DT_INT64]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT32]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT64]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT32]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT64]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT32]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT64]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT32]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT64]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT32]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT64]
&lt;denchmark-code&gt;     [[Node: module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)]]
&lt;/denchmark-code&gt;

Caused by op 'module_apply_default/compound_bigrams/boolean_mask/Prod', defined at:
File "", line 3, in 
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_hub\module.py", line 203, in call
name=name)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_hub\native_module.py", line 447, in create_apply_graph
restore_collections_predicate=(lambda key: key in import_collections))
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\saver.py", line 1939, in import_meta_graph
**kwargs)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\meta_graph.py", line 744, in import_scoped_meta_graph
producer_op_list=producer_op_list)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\deprecation.py", line 454, in new_func
return func(*args, **kwargs)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\importer.py", line 442, in import_graph_def
_ProcessNewOps(graph)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\importer.py", line 234, in _ProcessNewOps
for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py", line 3289, in _add_new_tf_operations
for c_op in c_api_util.new_tf_operations(self)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py", line 3289, in 
for c_op in c_api_util.new_tf_operations(self)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py", line 3180, in _create_op_from_tf_operation
ret = Operation(c_op, self)
File "C:\Users\Rahul\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\framework\ops.py", line 1717, in init
self._traceback = tf_stack.extract_stack()
NotFoundError (see above for traceback): No registered 'Size' OpKernel for GPU devices compatible with node module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)
(OpKernel was found, but attributes didn't match)
.  Registered:  device='CPU'; out_type in [DT_INT32]
device='CPU'; out_type in [DT_INT64]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT32]
device='GPU'; T in [DT_HALF]; out_type in [DT_INT64]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_BFLOAT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT32]
device='GPU'; T in [DT_FLOAT]; out_type in [DT_INT64]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT32]
device='GPU'; T in [DT_DOUBLE]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT64]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT16]; out_type in [DT_INT64]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_UINT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT8]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX64]; out_type in [DT_INT64]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT32]
device='GPU'; T in [DT_COMPLEX128]; out_type in [DT_INT64]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT32]
device='GPU'; T in [DT_BOOL]; out_type in [DT_INT64]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT32]
device='GPU'; T in [DT_VARIANT]; out_type in [DT_INT64]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT32]
device='GPU'; T in [DT_INT32]; out_type in [DT_INT64]
&lt;denchmark-code&gt;     [[Node: module_apply_default/compound_bigrams/boolean_mask/Prod = Size[T=DT_STRING, out_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](module_apply_default/compound_bigrams/concat_2/_91, ^module_apply_default/compound_bigrams/boolean_mask/Shape_1/_95)]]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rahulgarg1' date='2018-09-17T11:17:22Z'>
		Hi Every One ,
&lt;denchmark-code&gt;     Please help me resolve of this error ..
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='rahulgarg1' date='2018-09-18T08:32:57Z'>
		Hi &lt;denchmark-link:https://github.com/rahulgarg1&gt;@rahulgarg1&lt;/denchmark-link&gt;
,
can you please paste a minimal code snippet that reproduces this?
Also which version of tensorflow-gpu do you have installed?
		</comment>
		<comment id='3' author='rahulgarg1' date='2018-09-24T22:11:39Z'>
		have the same issue with google colab &lt;denchmark-link:https://github.com/vbardiovskyg&gt;@vbardiovskyg&lt;/denchmark-link&gt;
 -&gt; &lt;denchmark-link:https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb&gt;https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='rahulgarg1' date='2018-09-24T22:24:19Z'>
		and seems like it works with https://tfhub.dev/google/universal-sentence-encoder-large/3
		</comment>
		<comment id='5' author='rahulgarg1' date='2018-09-25T10:11:39Z'>
		Tried to reproduce by clicking on the link, then "Runtime -&gt; Run All", seems to work with "&lt;denchmark-link:https://tfhub.dev/google/universal-sentence-encoder/2&gt;https://tfhub.dev/google/universal-sentence-encoder/2&lt;/denchmark-link&gt;
".
Did you make any changes to the colab before it failed?
		</comment>
		<comment id='6' author='rahulgarg1' date='2018-09-25T11:17:07Z'>
		it works on CPU runtime, but GPU runtime has the same issues as from the original author cc &lt;denchmark-link:https://github.com/vbardiovskyg&gt;@vbardiovskyg&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='rahulgarg1' date='2018-09-25T20:37:29Z'>
		same issue here
		</comment>
		<comment id='8' author='rahulgarg1' date='2018-09-25T20:38:02Z'>
		minimal code that generates the issue:
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub

with tf.Graph().as_default():
    module_url = "https://tfhub.dev/google/universal-sentence-encoder/2"
    embed = hub.Module(module_url)
    embeddings = embed(["A long sentence.", "single-word",
                      "http://example.com"])

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.tables_initializer())
        print(sess.run(embeddings))
&lt;/denchmark-code&gt;

aka the code example provided in the website!
		</comment>
		<comment id='9' author='rahulgarg1' date='2018-09-28T12:58:40Z'>
		Thanks &lt;denchmark-link:https://github.com/rmanak&gt;@rmanak&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/lc0&gt;@lc0&lt;/denchmark-link&gt;
 for explaining the problem.
I've contacted the publisher and got an explanation:
"Yes, this is a known issue, the USE2 worked on GPU on tf 1.7 (and maybe 1.8). There are some ops removed or unregistered from GPU since tf 1.9, which caused the problem you pasted. A simple fix to make USE2 work on GPU is switching to a early version of tensorflow, e.g. 1.7."
So the way around this for now is to either use https://tfhub.dev/google/universal-sentence-encoder-large/3 or run this on tensorflow-gpu==1.7.
		</comment>
		<comment id='10' author='rahulgarg1' date='2018-09-28T13:08:56Z'>
		&lt;denchmark-link:https://github.com/vbardiovskyg&gt;@vbardiovskyg&lt;/denchmark-link&gt;
 should we update the docs in this case?
I am just not sure how make it nice, since when colab has CPU env the version works fine.
Otherwise, I would at least limit to pip install at &lt;denchmark-link:https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb&gt;https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb&lt;/denchmark-link&gt;

What do you think?
		</comment>
		<comment id='11' author='rahulgarg1' date='2018-09-28T15:58:04Z'>
		I think this should be documented on the module description.
Not sure if we should downgrade TF version on the Colab just because some modules do not work (there will always be modules that use older versions of TF).
We could add a comment next to the module selection that some modules might not be compatible with GPU, or pick two that are both compatible.
		</comment>
		<comment id='12' author='rahulgarg1' date='2018-12-10T15:40:40Z'>
		None of the following helped me:

Changing to https://tfhub.dev/google/universal-sentence-encoder-large/3
running on tensorflow-gpu==1.7.

		</comment>
		<comment id='13' author='rahulgarg1' date='2018-12-11T10:40:00Z'>
		Hi I tried on tensorflow-gpu==1.7 but somehow get this error
AttributeError: module 'tensorflow.python.estimator.estimator_lib' has no attribute 'Exporter'
		</comment>
		<comment id='14' author='rahulgarg1' date='2018-12-23T10:20:01Z'>
		
None of the following helped me:

Changing to https://tfhub.dev/google/universal-sentence-encoder-large/3
running on tensorflow-gpu==1.7.


I solved this problem by changing the module to https://tfhub.dev/google/universal-sentence-encoder-large/3.
Or you can try to set the device to tf.device('/cpu:0').
		</comment>
		<comment id='15' author='rahulgarg1' date='2019-01-08T15:46:02Z'>
		Yep,

running on tensorflow-gpu==1.7 doesn't help the DAN (https://tfhub.dev/google/universal-sentence-encoder/2) to work.
DAN (https://tfhub.dev/google/universal-sentence-encoder/2) runs only in the CPU.
Transformer architecture (https://tfhub.dev/google/universal-sentence-encoder-large/3) runs perfectly on the GPU without any error.

		</comment>
		<comment id='16' author='rahulgarg1' date='2019-03-12T01:42:06Z'>
		&lt;denchmark-link:https://github.com/vbardiovskyg&gt;@vbardiovskyg&lt;/denchmark-link&gt;
  Has this been updated in the module documentation ? If not, please let me know the module owner name and I will follow up on this. Thanks !
		</comment>
		<comment id='17' author='rahulgarg1' date='2019-04-28T23:18:01Z'>
		I tried using the &lt;denchmark-link:https://tfhub.dev/google/universal-sentence-encoder-large/3&gt;https://tfhub.dev/google/universal-sentence-encoder-large/3&lt;/denchmark-link&gt;
 version on a fresh install of

tensorflow==1.7
tensorflow_hub==0.2.0
with tf.device('/cpu:0')

Unfortunately the whole process is still running on the CPU
		</comment>
		<comment id='18' author='rahulgarg1' date='2019-05-03T11:28:25Z'>
		Hi &lt;denchmark-link:https://github.com/koolkao&gt;@koolkao&lt;/denchmark-link&gt;
, it seems like you are not installing tensorflow-gpu  placing it explicitly on CPU, so I am not sure why you expect to not run on CPU. (maybe a typo somewhere, but not clear where)
		</comment>
		<comment id='19' author='rahulgarg1' date='2019-05-03T13:55:09Z'>
		Aside from koolkao's immediate problem, there has been some progress on the root issue:
Commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/5c4d1c87a2794ed80d8c1da8bb6fe8b6eb86242a&gt;tensorflow/tensorflow@5c4d1c8&lt;/denchmark-link&gt;
 fixes an issue with Grappler (graph optimizer) that may have caused the failures ever since TF 1.8.
Community input is welcome whether the problem can be avoided in the field by any of the following:

Use a tf-nightly-gpu past that commit (1.14.1.dev20190503 should do, or a day after).
Turn off the incriminated optimization by setting
config.graph_options.rewrite_options.shape_optimization = 2
in the tf.ConfigProto passed to the tf.Session.

If yes, the module documentation could be updated for that (and maybe again once the fix hits a release; might be as late as 1.15/2.0).
		</comment>
		<comment id='20' author='rahulgarg1' date='2019-05-14T06:01:47Z'>
		tensorflow: 1.13.1
tensorflow-gpu: 1.13.1
I have got the same error. However, setting
config = tf.ConfigProto()
config.graph_options.rewrite_options.shape_optimization = 2
session = tf.Session(config=config)
fixed it for me. Thanks!
		</comment>
		<comment id='21' author='rahulgarg1' date='2019-05-14T12:39:05Z'>
		Thanks &lt;denchmark-link:https://github.com/arnoegw&gt;@arnoegw&lt;/denchmark-link&gt;
 for figuring out the state of and the solution for the problem. I will update the documentation to reflect this.
		</comment>
		<comment id='22' author='rahulgarg1' date='2020-11-09T12:27:43Z'>
		try doing failed ml operation within tf.device block
with tf.device('/cpu:0'):
Running on the CPU saved my day
		</comment>
	</comments>
</bug>