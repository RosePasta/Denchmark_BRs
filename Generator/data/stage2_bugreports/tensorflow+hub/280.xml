<bug id='280' author='eyaler' open_date='2019-04-21T22:34:24Z' closed_time='2020-07-24T11:20:59Z'>
	<summary>biggan-deep race condition / variable stripping issue</summary>
	<description>
i suspect the biggan-deep models have the same race condition issue with the previous truncation value, as the biggan vanilla v1 models, later fixed in v2. this also prevents stripping the graph for inference. can we have a biggan-deep v2 fixing this?
	</description>
	<comments>
		<comment id='1' author='eyaler' date='2019-05-09T03:59:39Z'>
		&lt;denchmark-link:https://github.com/eyaler&gt;@eyaler&lt;/denchmark-link&gt;
 ,
Sorry for the delayed response. Can you please provide the reproducible code so that we can check it at our end.
		</comment>
		<comment id='2' author='eyaler' date='2019-05-14T12:58:39Z'>
		this is indirect evidence, but using intel's export_tf from &lt;denchmark-link:https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/util/tf.py&gt;https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/util/tf.py&lt;/denchmark-link&gt;
 , you can see that deep_512/v1 fails in a similar fashion to 512/v1 addressing the variables related to the race condition, while in 512/v2 it's ok. so i suspect deep-512/v1 requires the same fix that was done from 512/v1 to 512/v2
`
import tensorflow as tf
import tensorflow_hub as hub
import os
from tf import export_tf #&lt;denchmark-link:https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/util/tf.py&gt;https://github.com/intel-analytics/analytics-zoo/blob/master/pyzoo/zoo/util/tf.py&lt;/denchmark-link&gt;

with tf.Session() as sess:
module = hub.Module('&lt;denchmark-link:https://tfhub.dev/deepmind/biggan-deep-512/1&gt;https://tfhub.dev/deepmind/biggan-deep-512/1&lt;/denchmark-link&gt;
') #fails
#module = hub.Module('&lt;denchmark-link:https://tfhub.dev/deepmind/biggan-512/1&gt;https://tfhub.dev/deepmind/biggan-512/1&lt;/denchmark-link&gt;
') #fails
#module = hub.Module('&lt;denchmark-link:https://tfhub.dev/deepmind/biggan-512/2&gt;https://tfhub.dev/deepmind/biggan-512/2&lt;/denchmark-link&gt;
') #works
sess.run(tf.global_variables_initializer())
inputs = {k: tf.placeholder(v.dtype, v.get_shape().as_list(), k) for k, v in module.get_input_info_dict().items()}
output = module(inputs)
export_tf(sess, "c:/temp/saved5", inputs=[inputs["y"], inputs["z"], inputs["truncation"]], outputs=[output])#, variable_names_blacklist='module/prev_truncation:0')
tf.reset_default_graph()
with tf.Session() as sess:
with tf.gfile.GFile(os.path.join('c:/temp/saved5', 'frozen_inference_graph.pb'), 'rb') as f:
gd = sess.graph_def
gd.ParseFromString(f.read())
tf.import_graph_def(gd, name='')
`
		</comment>
		<comment id='3' author='eyaler' date='2019-07-16T05:00:16Z'>
		&lt;denchmark-link:https://github.com/eyaler&gt;@eyaler&lt;/denchmark-link&gt;
 ,
Thank you for the code. Can you please elaborate the Issue which you are facing, and also the log of error, which you are facing. That will help us understand the issue exactly. Thanks.
		</comment>
		<comment id='4' author='eyaler' date='2019-07-16T16:08:35Z'>
		see here: &lt;denchmark-link:https://github.com/intel-analytics/analytics-zoo/issues/1271#issuecomment-485199439&gt;intel-analytics/analytics-zoo#1271 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):
File "C:\Anaconda3\lib\site-packages\tensorflow\python\framework\importer.py", line 418, in import_graph_def
graph._c_graph, serialized, options) # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 0 of node module_apply_default/cond/AssignVariableOp/Switch was passed float from module/prev_truncation:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File "C:/python/biggan/issue2.py", line 18, in
tf.import_graph_def(gd, name='')
File "C:\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py", line 488, in new_func
return func(*args, **kwargs)
File "C:\Anaconda3\lib\site-packages\tensorflow\python\framework\importer.py", line 422, in import_graph_def
raise ValueError(str(e))
ValueError: Input 0 of node module_apply_default/cond/AssignVariableOp/Switch was passed float from module/prev_truncation:0 incompatible with expected resource.

Process finished with exit code 1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='eyaler' date='2019-08-09T17:42:22Z'>
		Is there any easy way to overcome this and optimize the biggan-deep-512 for serving?
Only having what is needed for inference?
		</comment>
		<comment id='6' author='eyaler' date='2019-08-13T14:17:24Z'>
		Hi &lt;denchmark-link:https://github.com/eyaler&gt;@eyaler&lt;/denchmark-link&gt;
. I'm not sure what the problem is with exporting the  models using the Intel analytics script. The  models do not have the particular race condition issue I'm aware of with the original broken   models.  The  models were exported with essentially the same fixed script used to export the , and I've manually checked the  modules for the race condition I know of with the  models and it's not there.
Do you see the same error message for biggan (v1) modules as you do for biggan-deep (v1)?
It could be an issue with the Intel analytics export script rather than with these modules. In general all of these BigGAN modules do somewhat eccentric stuff (mainly, assigning variables as part of inference to use the correct BN stats depending on the trunc input, which looks like is what's giving you problems now) and I would have expected many "export for inference" type scripts tested against more conventional models (where all of the assign ops can be removed for inference) to break on these. (I'm rather surprised it seems to work on the biggan (v2) modules.) You might have to resort to manual graph editing to make some of these inference scripts work.
		</comment>
		<comment id='7' author='eyaler' date='2019-08-21T07:03:26Z'>
		&lt;denchmark-link:https://github.com/eyaler&gt;@eyaler&lt;/denchmark-link&gt;
 ,
Can you please respond to &lt;denchmark-link:https://github.com/jeffdonahue&gt;@jeffdonahue&lt;/denchmark-link&gt;
's comment and can we work towards closure of this issue.
		</comment>
		<comment id='8' author='eyaler' date='2019-08-24T03:10:58Z'>
		Thanks &lt;denchmark-link:https://github.com/jeffdonahue&gt;@jeffdonahue&lt;/denchmark-link&gt;
 . I am indeed seeing the same error message for biggan (v1) as i do for biggan-deep (v1). I moved to the intel script to overcome the issue I had here: &lt;denchmark-link:https://github.com/tensorflow/hub/issues/224&gt;#224&lt;/denchmark-link&gt;
 with freezing and loading the graph. As it was working with v2, and giving the same error for v1 and deep-v1, I conjectured that the issue might be the race condition solved in v1-&gt;v2 and though this condition may be present also in deep-v1.
		</comment>
	</comments>
</bug>