<bug id='712' author='xzxzhan' open_date='2020-12-16T07:23:59Z' closed_time='2020-12-16T19:27:05Z'>
	<summary>efficientnet/b7/feature-vector/1 failed to run in MirroredStrategy scope</summary>
	<description>
Setup:
OS: Ubuntu 18.04.4 LTS
Tensorflow: tensorflow==2.3.0 / tensorflow-hub==0.10.0
CUDA Version: 10.1 / Driver Version: 418.87.00
GPU: Tesla P100
Python version: 3.6.9
Issue:
I have a simple model based on EfficientNet-B7 (tf-hub: &lt;denchmark-link:https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1&gt;https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1&lt;/denchmark-link&gt;
)
&lt;denchmark-code&gt;    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),
        hub.KerasLayer(MODULE_HANDLE, trainable=False),
        tf.keras.layers.Dropout(rate=0.2),
        tf.keras.layers.Dense(train_generator.num_classes,
                              kernel_regularizer=tf.keras.regularizers.l2(0.0001))
    ]) 
&lt;/denchmark-code&gt;

The model runs fine on single GPU. When I run it in tf.distribute.MirroredStrategy().scope() on 4 GPUs, I got error:
&lt;denchmark-code&gt;... was not created in the distribution strategy scope of (&lt;tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f107d8c4f98&gt;). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
&lt;/denchmark-code&gt;

I've seen some similar issues in other threads but they were mostly about versioning issues. It seems to me that the versions on my setup are good. Please help figure out what is the issue.
Full code:
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub

strategy = tf.distribute.MirroredStrategy()

pixels = 600
MODULE_HANDLE ="https://tfhub.dev/google/efficientnet/b7/feature-vector/1"
data_dir = "/root/train"

IMAGE_SIZE = (pixels, pixels)
print("Using {} with input size {}".format(MODULE_HANDLE, IMAGE_SIZE))

BATCH_SIZE = 32

datagen_kwargs = dict(rescale=1./255, validation_split=.10)
dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                   interpolation="bilinear")

valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    **datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    data_dir, subset="validation", shuffle=False, **dataflow_kwargs)

train_datagen = valid_datagen
train_generator = train_datagen.flow_from_directory(
    data_dir, subset="training", shuffle=True, **dataflow_kwargs)

print("Building model with", MODULE_HANDLE)
with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),
        hub.KerasLayer(MODULE_HANDLE, trainable=False),
        tf.keras.layers.Dropout(rate=0.2),
        tf.keras.layers.Dense(train_generator.num_classes,
                              kernel_regularizer=tf.keras.regularizers.l2(0.0001))
    ])
    model.build((None,)+IMAGE_SIZE+(3,))
    model.summary()

    model.compile(
      optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),
      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),
      metrics=['accuracy'])

steps_per_epoch = train_generator.samples // train_generator.batch_size
validation_steps = valid_generator.samples // valid_generator.batch_size
hist = model.fit(
    train_generator,
    epochs=5, steps_per_epoch=steps_per_epoch,
    validation_data=valid_generator,
    validation_steps=validation_steps).history
&lt;/denchmark-code&gt;

Full log:
&lt;denchmark-code&gt;2020-12-16 06:53:05.992036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-12-16 06:53:07.588447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-16 06:53:07.784154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:07.787356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:07.790404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:08:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:07.793424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:09:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:07.793457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-12-16 06:53:07.795525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-12-16 06:53:07.797492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-16 06:53:07.797780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-16 06:53:07.799823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-16 06:53:07.801030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-12-16 06:53:07.805253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-12-16 06:53:07.845494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-12-16 06:53:07.846832: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-16 06:53:07.877935: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3192645000 Hz
2020-12-16 06:53:07.879623: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6241610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-16 06:53:07.879655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-16 06:53:08.343310: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62ad5c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-16 06:53:08.343356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-12-16 06:53:08.343367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-12-16 06:53:08.343376: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-12-16 06:53:08.343385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-12-16 06:53:08.355046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:04:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:08.356738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties:
pciBusID: 0000:05:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:08.358412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties:
pciBusID: 0000:08:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:08.360067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties:
pciBusID: 0000:09:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-12-16 06:53:08.360106: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-12-16 06:53:08.360141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-12-16 06:53:08.360162: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-16 06:53:08.360180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-16 06:53:08.360199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-16 06:53:08.360217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-12-16 06:53:08.360236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-12-16 06:53:08.373390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3
2020-12-16 06:53:08.373428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-12-16 06:53:11.529289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-16 06:53:11.529361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 2 3
2020-12-16 06:53:11.529376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N Y Y Y
2020-12-16 06:53:11.529385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   Y N Y Y
2020-12-16 06:53:11.529393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   Y Y N Y
2020-12-16 06:53:11.529402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   Y Y Y N
2020-12-16 06:53:11.538343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14951 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2020-12-16 06:53:11.540696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14951 MB memory) -&gt; physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
2020-12-16 06:53:11.542993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 14951 MB memory) -&gt; physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
2020-12-16 06:53:11.545312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 14951 MB memory) -&gt; physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)
Using https://tfhub.dev/google/efficientnet/b7/feature-vector/1 with input size (600, 600)
Found 29777 images belonging to 404 classes.
Found 269384 images belonging to 404 classes.
Building model with https://tfhub.dev/google/efficientnet/b7/feature-vector/1
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
keras_layer (KerasLayer)     (None, 2560)              64097680
_________________________________________________________________
dropout (Dropout)            (None, 2560)              0
_________________________________________________________________
dense (Dense)                (None, 404)               1034644
=================================================================
Total params: 65,132,324
Trainable params: 1,034,644
Non-trainable params: 64,097,680
_________________________________________________________________
Traceback (most recent call last):
  File "train.py", line 56, in &lt;module&gt;
    metrics=['accuracy'])
  File "/root/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 538, in compile
    self._validate_compile(optimizer, metrics, **kwargs)
  File "/root/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 2512, in _validate_compile
    '  model.compile(...)' % (v, strategy))
ValueError: Variable (&lt;tf.Variable 'efficientnet-b7/stem/conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32, numpy=
array([[[[-3.77828836e-01,  2.76361465e-01, -8.32918435e-02, ...,
....,
      dtype=float32)&gt;) was not created in the distribution strategy scope of (&lt;tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f107d8c4f98&gt;). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='xzxzhan' date='2020-12-16T08:32:31Z'>
		&lt;denchmark-link:https://github.com/xzxzhan&gt;@xzxzhan&lt;/denchmark-link&gt;
,
There is an existing bug, &lt;denchmark-link:https://github.com/tensorflow/hub/issues/295&gt;#295&lt;/denchmark-link&gt;
, which states . The root cause of the error in this issue also might be the same because we use  for .
Can you please confirm if we can close this issue, as it is already being tracked in &lt;denchmark-link:https://github.com/tensorflow/hub/issues/295&gt;#295&lt;/denchmark-link&gt;
. Thanks!
		</comment>
	</comments>
</bug>