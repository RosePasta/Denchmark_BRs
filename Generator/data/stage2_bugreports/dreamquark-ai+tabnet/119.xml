<bug id='119' author='queraq' open_date='2020-06-02T13:33:45Z' closed_time='2020-06-02T15:27:28Z'>
	<summary>Bug with unordered cat_idx</summary>
	<description>
Describe the bug
If the list of cat_idx is unordered the corresponding cat_dims used into embeddings will not match.
What is the current behavior?
The bug appear into the forward of EmbeddingGenerator.
A for loop walk througth features and take embedding corresponding to each categorical feature from the self.embeddings list wich is build in the same order as cat_idx.
If the current behavior is a bug, please provide the steps to reproduce.
Provide an unordered cat_idx list with corresponding cat_dims.
Solution
Sort the cat_dims and the corresponding emb_dims with respect to cat_idx
&lt;denchmark-code&gt;        self.embeddings = torch.nn.ModuleList()

        # Sort dims by cat_idx
        sorted_idxs = np.argsort(cat_idxs)
        cat_dims = [cat_dims[i] for i in sorted_idxs]
        self.cat_emb_dims = [self.cat_emb_dims[i] for i in sorted_idxs]

        for cat_dim, emb_dim in zip(cat_dims, self.cat_emb_dims):
            self.embeddings.append(torch.nn.Embedding(cat_dim, emb_dim))
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>