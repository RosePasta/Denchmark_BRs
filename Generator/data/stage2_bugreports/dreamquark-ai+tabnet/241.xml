<bug id='241' author='LanSaid' open_date='2020-11-23T11:24:38Z' closed_time='2020-12-06T12:20:37Z'>
	<summary>Type error int() argument must be a string in pytorch TabNetMultiTaskClassifier fit method</summary>
	<description>
Describe the bug
When fit TabNetMultiTaskClassifier with eval_set parameter, get error
TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType' 
Without eval_set it`s done properly.
Note: all features are numeric and labels too.
What is the current behavior?
Raise TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'  when TabNetMultiTaskClassifier fit start. All labels are numeric, features too
If the current behavior is a bug, please provide the steps to reproduce.
&lt;denchmark-code&gt;X_train = np.random.rand(2, 875)
y_train = np.zeros((2, 206))

X_valid = np.random.rand(2, 875)
y_valid = np.zeros((2, 206))

y_train[1][15] = 1
y_train[1][35] = 1
y_train[1][78] = 1

clf = TabNetMultiTaskClassifier(n_steps=5,
                                optimizer_fn=torch.optim.Adam,
                                optimizer_params=dict(lr=2e-2),
                                scheduler_params={"step_size":50,
                                                  "gamma":0.9},
                                scheduler_fn=torch.optim.lr_scheduler.StepLR,
                                mask_type='entmax', 
                                lambda_sparse=0                      
                      )
max_epochs = 200

clf.fit(
    X_train=X_train, y_train=y_train,
    eval_set=[(X_train, y_train), (X_valid, y_valid)],
    eval_name=['train', 'val'],
    max_epochs=max_epochs ,
    patience=50,
    batch_size=1024,
    virtual_batch_size=128,
    drop_last=False
)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-280-4d0315f56fb2&gt; in &lt;module&gt;
     11     virtual_batch_size=128,
     12    # num_workers=1,
---&gt; 13     drop_last=False,
     14 )

/opt/conda/lib/python3.7/site-packages/pytorch_tabnet/abstract_model.py in fit(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks)
    152 
    153         train_dataloader, valid_dataloaders = self._construct_loaders(
--&gt; 154             X_train, y_train, eval_set
    155         )
    156 

/opt/conda/lib/python3.7/site-packages/pytorch_tabnet/abstract_model.py in _construct_loaders(self, X_train, y_train, eval_set)
    581         y_train_mapped = self.prepare_target(y_train)
    582         for i, (X, y) in enumerate(eval_set):
--&gt; 583             y_mapped = self.prepare_target(y)
    584             eval_set[i] = (X, y_mapped)
    585 

/opt/conda/lib/python3.7/site-packages/pytorch_tabnet/multitask.py in prepare_target(self, y)
     19         for task_idx in range(y.shape[1]):
     20             task_mapper = self.target_mapper[task_idx]
---&gt; 21             y_mapped[:, task_idx] = np.vectorize(task_mapper.get)(y[:, task_idx])
     22         return y_mapped
     23 

/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py in __call__(self, *args, **kwargs)
   2089             vargs.extend([kwargs[_n] for _n in names])
   2090 
-&gt; 2091         return self._vectorize_call(func=func, args=vargs)
   2092 
   2093     def _get_ufunc_and_otypes(self, func, args):

/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py in _vectorize_call(self, func, args)
   2168 
   2169             if ufunc.nout == 1:
-&gt; 2170                 res = array(outputs, copy=False, subok=True, dtype=otypes[0])
   2171             else:
   2172                 res = tuple([array(x, copy=False, subok=True, dtype=t)

TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
&lt;/denchmark-code&gt;

Expected behavior
Eval_set is work without error.
Screenshots
None

poetry version:
python version: python 3.7
Operating System: Linux', release='5.4.49+', version='&lt;denchmark-link:https://github.com/dreamquark-ai/tabnet/pull/1&gt;#1&lt;/denchmark-link&gt;
 SMP
Additional tools:
torch version: '1.6.0'
pytorch_tabnet: '2.0.0'
Additional context
	</description>
	<comments>
		<comment id='1' author='LanSaid' date='2020-11-23T11:33:57Z'>
		Yes this is something that will be changed soon.
It's not really a bug but the Error Message is wrong. What happens is that you are training TabNetClassifier to predict only 0s, so the model only ouput one score which is 1 for the 0 class. But then you are trying to predict on multiple classes, which does not make sense. Even if you add a few ones to a few tasks, it does not change the fact that most of your tasks are nonsense.
A clearer error message should help, and this is a regression because it used to ouput a clearer error. However, the sample code you are sharing does not make sense because of what I explained earlier. Try to train your model with a number of classes consistent with what you are willing to predict.
The split for MOA competition is hard to do, that's why it's easier to treat this problem with TabNetRegressor please have a look at the notebooks shared on Kaggle :

https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer
https://www.kaggle.com/optimo/selfsupervisedtabnet

		</comment>
		<comment id='2' author='LanSaid' date='2020-11-23T11:43:44Z'>
		When I copy/paste the code on current develop I get another error though, which I think makes more sense:
ValueError: y_true contains only one label (0.0). Please provide the true labels explicitly through the labels argument.
Which version of pytorch-tabnet are you using, &lt;denchmark-link:https://github.com/LanSaid&gt;@LanSaid&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='3' author='LanSaid' date='2020-11-23T11:45:41Z'>
		&lt;denchmark-link:https://github.com/eduardocarvp&gt;@eduardocarvp&lt;/denchmark-link&gt;
 I think develop might be ahead
		</comment>
		<comment id='4' author='LanSaid' date='2020-11-23T11:51:08Z'>
		But I'm still confused :
when change dataset to one
&lt;denchmark-code&gt;X_train = np.random.rand(3, 25)
y_train = np.zeros((3, 5))

X_valid = np.random.rand(2, 25)
y_valid = np.zeros((2, 5))

y_train[0][1] = 1
y_train[0][3] = 1
y_train[1][2] = 1

y_valid[1][1] = 1
y_valid[0][2] = 1
y_valid[0][1] = 1


&lt;/denchmark-code&gt;

and fit clf without eval_set, it done like that:
&lt;denchmark-code&gt;No early stopping will be performed, last training weights will be used.
epoch 0  | loss: 0.93653 |  0:00:00s
epoch 1  | loss: 0.34817 |  0:00:00s
epoch 2  | loss: 0.34927 |  0:00:00s
&lt;/denchmark-code&gt;

But when on eval_set param I get the same error like &lt;denchmark-link:https://github.com/eduardocarvp&gt;@eduardocarvp&lt;/denchmark-link&gt;


&lt;denchmark-link:https://github.com/eduardocarvp&gt;@eduardocarvp&lt;/denchmark-link&gt;
 pytorch-tabnet version is  '2.0.0'
		</comment>
		<comment id='5' author='LanSaid' date='2020-11-23T14:52:51Z'>
		This is a bug from np.vectorize I think I'll come back with more details
		</comment>
		<comment id='6' author='LanSaid' date='2020-12-06T12:20:37Z'>
		I can't reproduce this on the latest version, so I'm closing it. Please reopen if this appears with the newest versions.
		</comment>
	</comments>
</bug>