<bug id='367' author='Jamaslab' open_date='2019-08-28T09:50:41Z' closed_time='2019-08-28T12:35:20Z'>
	<summary>Creating DnCNN</summary>
	<description>
Hello,
I'm trying to create a DnCNN. I wrote the following code (a bit confused, there are a lot of testing things).
public class DnCNN {
        private const int batch_size = 128;

        Tensor X, Y_, Y;
        Tensor loss;
        Operation optimizer;

        Session sess;

        public DnCNN() {
            sess = new Session();
            tf_with(tf.name_scope("Input"), delegate {
                Y_ = tf.placeholder(tf.float32, shape: (-1, 477, 500, 3), name: "clean_image");
                X = tf.placeholder(tf.float32, shape: (-1, 477, 500, 3));
            });

            var is_training = tf.placeholder(tf.@bool, name: "is_training");            
            Y = BuildModel(X);

            tf_with(tf.variable_scope("Train"), delegate {
                tf_with(tf.variable_scope("Loss"), delegate {
                    loss = (1.0 / batch_size) * tf.nn.relu(Y_ - Y);
                });

                tf_with(tf.variable_scope("Optimizer"), delegate {
                    optimizer = tf.train.AdamOptimizer(0.001f, name: "AdamOptimizer").minimize(loss);
                });
            });

            var init = tf.global_variables_initializer();
            sess.run(init);
        }

        private Tensor BuildModel(Tensor input, bool is_training = true) {
            Tensor output = null;
            tf_with(tf.variable_scope("block1"), delegate {
                output = tf.layers.conv2d(input, 64, new int[] { 3, 3 }, padding: "same");
            });

            for (int i = 2; i &lt; 20; i++) {
                tf_with(tf.variable_scope("block"+i), delegate {
                    output = tf.layers.conv2d(output, 64, new int[] { 3, 3 }, name:"conv"+i, padding: "same", use_bias: false);
                    //output = tf.nn.relu(tf.layers.batch_normalization(output, trainable: is_training));
                });
            }

            tf_with(tf.variable_scope("block20"), delegate {
                output = tf.layers.conv2d(output, 3, new int[] { 3, 3 }, padding: "same", use_bias: false);
            });

            return input - output;
        }

        public void Train(List&lt;Bitmap&gt; inputImages, List&lt;Bitmap&gt; outputImages, int epochs=1) {
            NDArray x_train = array(inputImages[0]);
            NDArray y_train = array(outputImages[0]);

            var sw = new Stopwatch();
            sw.Start();
            for (int i = 0; i &lt; epochs; i++) {
                sess.run(optimizer, (X, x_train), (Y_, y_train));
                // Calculate and display the batch loss and accuracy
                var result = sess.run(new[] { loss }, new FeedItem(X, x_train), new FeedItem(Y_, y_train));
                var loss_val = result[0];
                print($"iter {i.ToString("000")}: Loss={loss_val.ToString()} {sw.ElapsedMilliseconds}ms");
                sw.Restart();
            }
        }

        private NDArray BuildFromImageList(List&lt;Bitmap&gt; images) {
            var imagesArrays = new List&lt;NDArray&gt;();
            foreach (var image in images) {
                imagesArrays.Add(array(image));
            }

            NDArray x = new NDArray(imagesArrays.ToArray());
            var dataset = x.reshape(x.shape[0], images[0].Width, images[1].Height, 3).astype(np.float32);
            return dataset;
        }

        private static NDArray array(Bitmap image) {
            var imageArray = new NDArray(typeof(Byte));
            var bmpd = image.LockBits(new System.Drawing.Rectangle(0, 0, image.Width, image.Height), System.Drawing.Imaging.ImageLockMode.ReadOnly, image.PixelFormat);
            var dataSize = bmpd.Stride * bmpd.Height;
            var bytes = new byte[dataSize];
            System.Runtime.InteropServices.Marshal.Copy(bmpd.Scan0, bytes, 0, dataSize);
            image.UnlockBits(bmpd);

            imageArray = new NDArray(bytes, new Shape(1, bmpd.Height, bmpd.Width, 3));

            return imageArray;
        }
}
When I try to run the learn (I get only the first image for simplicity), it returns a memory corruption exception on sess.run(optimizer, (X, x_train), (Y_, y_train));.
I suppose this comes from badly initializing something, but I'm struggling to understand what. Could somebody help me?
	</description>
	<comments>
		<comment id='1' author='Jamaslab' date='2019-08-28T09:58:13Z'>
		Are you using master branch or latest nuget package?
Also please provide us with an image so we can reproduce locally.
		</comment>
		<comment id='2' author='Jamaslab' date='2019-08-28T11:30:55Z'>
		I'm using the latest nuget package. Attached you can find the image i'm using for testing the code. It's just a random image that I give in input and in output for testing the network. In future I'd like to have dynamic resolutions in input/output (I don't know if it is possible). I will try to run the code with the latest master
&lt;denchmark-link:https://user-images.githubusercontent.com/7974047/63852114-df977300-c997-11e9-88c3-0d998e1865e1.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Jamaslab' date='2019-08-28T11:49:25Z'>
		Ok, I just run it with the latest master and I get the same error.
The error comes from here
&lt;denchmark-code&gt;c_api.TF_SessionRun(_handle,
                run_options: null,
                inputs: feed_dict.Select(f =&gt; f.Key).ToArray(),
                input_values: feed_dict.Select(f =&gt; (IntPtr)f.Value).ToArray(),
                ninputs: feed_dict.Length,
                outputs: fetch_list,
                output_values: output_values,
                noutputs: fetch_list.Length,
                target_opers: target_list.Select(f =&gt; (IntPtr)f).ToArray(),
                ntargets: target_list.Count,
                run_metadata: IntPtr.Zero,
                status: status);
&lt;/denchmark-code&gt;

However, I noticed something. If I attempt to create the session using a Graph in the following way
&lt;denchmark-code&gt;Graph g = new Graph(Y_);
 sess = new Session(g);
 var init = tf.global_variables_initializer();
 sess.run(init);
&lt;/denchmark-code&gt;

I get the AccessViolationException already in var init = tf.global_variables_initializer();, so I'm more worried I'm doing something wrong rather than a bug in the library.
		</comment>
		<comment id='4' author='Jamaslab' date='2019-08-28T12:02:47Z'>
		I have tested this against our development branch but I assume the solution should be the same on nuget package version.
The problem is within this line:
sess.run(optimizer, (X, x_train), (Y_, y_train));
The fed items are expected to be of type Tensor but you pass in NDArray. In python that would be valid and we'll probably add a resolving internally.
Change this line to the following and your code will run:
sess.run(optimizer, (X, new Tensor(x_train)), (Y_, new Tensor(y_train)));
		</comment>
		<comment id='5' author='Jamaslab' date='2019-08-28T12:04:34Z'>
		And because your inputs are expected to be tf.float32 but the NDArray are uint8/byte,
tf_with(tf.name_scope("Input"), delegate {
     Y_ = tf.placeholder(tf.float32, shape: (-1, 477, 500, 3), name: "clean_image");
     X = tf.placeholder(tf.float32, shape: (-1, 477, 500, 3));
});
Change the following lines or modify array(NDArray array(Bitmap image) to return in float:
NDArray x_train = array(inputImages[0]).astype(NPTypeCode.Single); //we cast because expected input is tf.float32
NDArray y_train = array(outputImages[0]).astype(NPTypeCode.Single); //we cast because expected input is tf.float32
		</comment>
		<comment id='6' author='Jamaslab' date='2019-08-28T12:09:17Z'>
		It works, thank you very much. Do you know how could i remove the dependency from the resolution in the Input and output layers shape?
		</comment>
		<comment id='7' author='Jamaslab' date='2019-08-28T12:24:13Z'>
		I'm not  a pro when it comes to image classification/image related algorithms but I do know that image size is a difficult problem because of the nature of the algorithms,
you can't simply have a single model to match all possible sizes; mathematically that's impossible because the CNN blocks won't match since the number of weights and biases are dependent on the input shape.
What usually is done is either resize using  to a fixed size (&lt;denchmark-link:https://stackoverflow.com/questions/47929557/tensorflow-cnn-training-images-are-all-different-sizes&gt;source&lt;/denchmark-link&gt;
) or have couple of models for different 'categorical' sizes so you can resize to the closest resolution. This does increase complexity and training time but will work if you really need to support different sizes.
Even in algorithms like  which takes in an image and outputs an image, the size is fixed (&lt;denchmark-link:https://github.com/pytorch/examples/issues/70&gt;source&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='8' author='Jamaslab' date='2019-08-28T12:30:58Z'>
		Perfect! thank you very much for your support and congratulations for the great project
		</comment>
		<comment id='9' author='Jamaslab' date='2019-08-28T12:35:19Z'>
		Happy to help.
		</comment>
	</comments>
</bug>