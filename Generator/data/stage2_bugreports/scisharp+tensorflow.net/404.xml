<bug id='404' author='Nucs' open_date='2019-09-29T21:09:42Z' closed_time='2019-09-30T06:48:07Z'>
	<summary>Subtracting two Tensors returns null</summary>
	<description>
Consider the following code:
var inputs1 = tf.placeholder(tf.float32, (1, 16));
var W = tf.Variable(tf.random_uniform(new int[] {inputs1.shape[1], 2}, 0, 0.01f));
var Qout = tf.matmul(inputs1, W);
var predict = tf.argmax(Qout, 1);

//Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.
var nextQ = tf.placeholder(tf.float32, (1, 4));
Debug.Assert(nextQ != null); //passes
Debug.Assert(Qout != null); //passes
var q = nextQ - Qout; //throws NullReferenceException because null is returned
	</description>
	<comments>
		<comment id='1' author='Nucs' date='2019-09-29T21:55:17Z'>
		An exception is actually thrown but gets swallowed by a try-catch.
&lt;denchmark-link:https://user-images.githubusercontent.com/649919/65840080-f4f81800-e31c-11e9-91d2-16e8217abee5.png&gt;&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>