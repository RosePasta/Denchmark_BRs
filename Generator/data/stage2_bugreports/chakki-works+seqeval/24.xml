<bug id='24' author='NoYo25' open_date='2019-08-28T14:38:55Z' closed_time='2020-09-30T05:59:58Z'>
	<summary>macro avg calculations</summary>
	<description>
Hi, I've used seqval in a NER system and it predicted me this classification report.  Screenshot  of the report is &lt;denchmark-link:https://drive.google.com/file/d/12SN6IJGr7cUwmeME8hfRWRXSaIM9lYg0/view?usp=sharing&gt;here&lt;/denchmark-link&gt;

Based on my knowledge, the macro avg of whatever metric (e.g. precision) would be in this case like the following
macro avg - pr = (0.74 + 0.85 + 0.96 + 0.65 + 0.87 + 0.54 + 0.33 + 0.00)  / 8 = 0.6175, which is not the case.
	</description>
	<comments>
		<comment id='1' author='NoYo25' date='2020-02-13T14:19:43Z'>
		It seems this issue has not been resolved yet. I would like to take a look at this bug.
		</comment>
		<comment id='2' author='NoYo25' date='2020-06-07T11:02:29Z'>
		It looks like the average parameter is currently ignored in all score methods:



seqeval/seqeval/metrics/sequence_labeling.py


         Line 116
      in
      445d997






 def f1_score(y_true, y_pred, average='micro', suffix=False): 





Are there plans to add macro average calculation to seqeval?
		</comment>
		<comment id='3' author='NoYo25' date='2020-06-15T13:45:55Z'>
		Same problem here. macro and micro give different answers, but macro value for sure is not correctly calculated
&lt;denchmark-code&gt;       precision    recall  f1-score   support

  gpe       0.95      0.92      0.93      3159
  tim       0.83      0.82      0.83      4026
  geo       0.81      0.85      0.83      7527
  org       0.66      0.63      0.64      3980
  per       0.70      0.67      0.69      3395
  art       0.50      0.04      0.07        82
  eve       0.70      0.20      0.31        71
  nat       0.00      0.00      0.00        42
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;  micro_avg       0.79      0.78      0.79     22282
  macro_avg       0.79      0.78      0.78     22282
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='NoYo25' date='2020-07-16T20:39:15Z'>
		It's only the micro? average that is being computed if you look into the code.
I would guess the parameter is for future use or for compatibility with sklearn.
&lt;denchmark-link:https://github.com/Developers&gt;@Developers&lt;/denchmark-link&gt;
 But it might be better to throw an error if any value other than "micro" is supplied because the computation would be wrong or to just remove it as it is misleading ...
		</comment>
	</comments>
</bug>