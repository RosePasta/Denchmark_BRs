<bug id='39' author='yoeldk' open_date='2020-07-24T13:32:40Z' closed_time='2020-10-11T04:56:17Z'>
	<summary>Bug - labels are only taken from true data</summary>
	<description>
Example:
from seqeval.metrics import classification_report
y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]
y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'B-TEST']]
print(classification_report(y_true, y_pred))
&lt;denchmark-code&gt;The result is:
           precision    recall  f1-score   support

      PER       1.00      1.00      1.00         1
     MISC       0.00      0.00      0.00         1

micro avg       0.33      0.50      0.40         2
macro avg       0.50      0.50      0.50         2
&lt;/denchmark-code&gt;

As you can see B-TEST does not appear in the table even though it's a false positive (it only appears in the predicted labels). The complete label list should be comprised from the union of true_labels + predicted_labels.
	</description>
	<comments>
		<comment id='1' author='yoeldk' date='2020-08-04T07:15:47Z'>
		&lt;denchmark-link:https://github.com/icoxfog417&gt;@icoxfog417&lt;/denchmark-link&gt;
 isn't it a bug?
		</comment>
		<comment id='2' author='yoeldk' date='2020-09-26T05:56:40Z'>
		&lt;denchmark-link:https://github.com/icoxfog417&gt;@icoxfog417&lt;/denchmark-link&gt;
 Can you explain why it is labeled as a question and not a bug?
		</comment>
		<comment id='3' author='yoeldk' date='2020-10-11T08:54:05Z'>
		&lt;denchmark-link:https://github.com/yoeldk&gt;@yoeldk&lt;/denchmark-link&gt;
 As of v1.0.0:
&gt;&gt;&gt; from seqeval.metrics import classification_report
&gt;&gt;&gt; from seqeval.scheme import IOB2
&gt;&gt;&gt; y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]
&gt;&gt;&gt; y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'B-TEST']]
&gt;&gt;&gt; print(classification_report(y_true, y_pred, mode='strict', scheme=IOB2))
              precision    recall  f1-score   support

        MISC       0.00      0.00      0.00         1
         PER       1.00      1.00      1.00         1
        TEST       0.00      0.00      0.00         0

   micro avg       0.33      0.50      0.40         2
   macro avg       0.33      0.33      0.33         2
weighted avg       0.50      0.50      0.50         2
		</comment>
	</comments>
</bug>