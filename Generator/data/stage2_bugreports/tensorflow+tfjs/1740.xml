<bug id='1740' author='VjunetXuuftofi' open_date='2019-07-15T21:27:19Z' closed_time='2019-08-02T20:21:00Z'>
	<summary>Cannot convert saved model with nn.dropout</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

1.2.2.1
&lt;denchmark-h:h4&gt;Tensorflow version&lt;/denchmark-h&gt;

2.0.0b1
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

I am unable to convert a tensorflow saved model that uses nn.dropout.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

In python:
&lt;denchmark-code&gt;from tensorflow import keras
import tensorflow as tf
from tensorflow.python.ops import nn

class TestModel(keras.models.Model):
    def __init__(self):
        super(TestModel, self).__init__()

    @tf.function(
        input_signature=[tf.TensorSpec([None, None, None, 1], tf.float32)])
    def inference(self, inputs):
        inputs = nn.dropout(inputs, rate=0.25)
        return inputs

model = TestModel()
tf.saved_model.save(model, "saved_model_test")
&lt;/denchmark-code&gt;

Then, with the converter:
tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model saved_model_test web_model_test
Error is as follows:
Traceback (most recent call last):
File "/home/user/.conda/envs/general/bin/tensorflowjs_converter", line 10, in 
sys.exit(main())
File "/home/user/.conda/envs/general/lib/python3.7/site-packages/tensorflowjs/converters/converter.py", line 556, in main
strip_debug_ops=FLAGS.strip_debug_ops)
File "/home/user/.conda/envs/general/lib/python3.7/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py", line 291, in convert_tf_saved_model
skip_op_check=skip_op_check, strip_debug_ops=strip_debug_ops)
File "/home/user/.conda/envs/general/lib/python3.7/site-packages/tensorflowjs/converters/tf_saved_model_conversion_v2.py", line 129, in optimize_graph
', '.join(unsupported))
ValueError: Unsupported Ops in the model before optimization
StatefulPartitionedCall
The model can be loaded fine in Python with tf.saved_model.load("saved_model_test").
Thanks for looking at this.
	</description>
	<comments>
		<comment id='1' author='VjunetXuuftofi' date='2019-07-15T22:15:14Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 can you please help with this , look like a issue in this &lt;denchmark-link:https://github.com/tensorflow/tfjs-converter/blob/master/python/tensorflowjs/converters/converter.py&gt;file&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='VjunetXuuftofi' date='2019-07-19T23:21:31Z'>
		&lt;denchmark-link:https://github.com/VjunetXuuftofi&gt;@VjunetXuuftofi&lt;/denchmark-link&gt;
 dropout ops are usually not used in the inference graph, can you explain your use case here? thanks.
		</comment>
		<comment id='3' author='VjunetXuuftofi' date='2019-07-22T21:10:22Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 The dropout is used for bayesian approximation as described here: &lt;denchmark-link:https://arxiv.org/abs/1506.02142&gt;https://arxiv.org/abs/1506.02142&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='VjunetXuuftofi' date='2019-07-22T23:30:38Z'>
		&lt;denchmark-link:https://github.com/VjunetXuuftofi&gt;@VjunetXuuftofi&lt;/denchmark-link&gt;
 The issue is fixed upstream in TF grappler, but unfortunately you will need to wait for the next TF 1.14 updated before you can get this fix.
		</comment>
		<comment id='5' author='VjunetXuuftofi' date='2019-08-02T20:21:00Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>