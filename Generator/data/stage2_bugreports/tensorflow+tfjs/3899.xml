<bug id='3899' author='yudhiesh' open_date='2020-09-10T08:21:03Z' closed_time='2020-09-11T04:04:31Z'>
	<summary>[Unhandled promise rejection: Error: Size(150528) must match the product of shape 1]</summary>
	<description>
System information
Using a custom model I built that uses transfer learning with MobileNetV2


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
macOS Catalina 10.15.6


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Running the example from the Expo app on a Huawei Mate 20


TensorFlow.js version (use command below):
2.0.0
-Tensorflow React Native version:
0.3.0


Describe the current behavior
I am getting an error that there is an issue with the shape of the input with the model I am using
Describe the expected behavior
Tensors from the TensorCamera should be passed to make predictions and then return the predictions
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/CodePen/any notebook.
&lt;denchmark-link:https://github.com/yudhiesh1997/Driver-Drowsiness-Detection/blob/master/DriverDrowsiness%20(1).ipynb&gt;Link to the model I used&lt;/denchmark-link&gt;

Code for the model in python
&lt;denchmark-code&gt;baseModel = MobileNetV2(include_top=False,
         input_shape=INPUT_SHAPE,
         weights='imagenet')

headModel = baseModel.output
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(512, activation="relu")(headModel)
headModel = Dense(3, activation="softmax")(headModel)
# place the head FC model on top of the base model (this will become
# the actual model we will train)
model = Model(inputs=baseModel.input, outputs=headModel)
# loop over all layers in the base model and freeze them so they will
# *not* be updated during the training process
for layer in baseModel.layers:
	layer.trainable = False
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/tafsiri/tfjs-expo-managed-example/blob/master/App.js&gt;I am using this as a guide&lt;/denchmark-link&gt;



Code for making the predictions in Javascript
&lt;denchmark-code&gt;// get predictions from the model 

  const getPrediction = async tensor =&gt; {
    tensor = tensor.reshape(1, 224, 224, 3);


    if (!tensor) {
      console.log("Prediction not found");
      return;
    }
    const prediction = await loadedModel.predict(tensor, 32);
    console.log(`Predictions: ${JSON.stringify(prediction)}`);

    if (!prediction || prediction.length === 0) {
      return;
    }

    // Only take the predictions with a probability of 30% and greater
    if (prediction[0].probability &gt; 0.3) {
      //Stop looping
      cancelAnimationFrame(requestAnimationFrameId);
      setPredictionFound(true);
      setModelPrediction(prediction[0].className);
      tensor.dispose();
    }
  };

  // Load the model from the models folder
  const loadModel = async () =&gt; {
    const model = await tf.loadLayersModel(
      bundleResourceIO(modelJSON, modelWeights)
    );
    console.log("Model loaded!");
    return model;
  };


  // Handling the camera input and converting it into tensors to be used in the
  // model for predictions
  const handleCameraStream = imageAsTensors =&gt; {
    const loop = async () =&gt; {
      //loadedModel is the custom model I created and stored in state
      if (loadedModel !== null) {
        if (frameCount % makePredictionsEveryNFrames === 0) {
          const imageTensor = imageAsTensors.next().value;
          const faces = await getPrediction(imageTensor);
        }
      }

      frameCount += 1;
     //requestAnimationFrameID = 0
     // makePredictionsEveryNFrames = 3
      frameCount = frameCount % makePredictionsEveryNFrames;
      requestAnimationFrameId = requestAnimationFrame(loop);
    };
    // loop infinitely to constantly make predictions
    loop();
  };
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
[Unhandled promise rejection: Error: Size(150528) must match the product of shape 1]

node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js:704:12 in inferFromImplicitShape
node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js:5093:32 in reshape_
node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js:4351:12 in f2
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:293:29 in invoke
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:154:27 in invoke
node_modules/regenerator-runtime/runtime.js:189:16 in PromiseImpl$argument_0
node_modules/promise/setimmediate/core.js:45:6 in tryCallTwo
node_modules/promise/setimmediate/core.js:200:22 in doResolve
node_modules/promise/setimmediate/core.js:66:11 in Promise
node_modules/regenerator-runtime/runtime.js:188:15 in callInvokeWithMethodAndArg
node_modules/regenerator-runtime/runtime.js:211:38 in enqueue
node_modules/regenerator-runtime/runtime.js:238:8 in exports.async
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:293:29 in invoke
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:154:27 in invoke
node_modules/regenerator-runtime/runtime.js:189:16 in PromiseImpl$argument_0
node_modules/promise/setimmediate/core.js:45:6 in tryCallTwo
node_modules/promise/setimmediate/core.js:200:22 in doResolve
node_modules/promise/setimmediate/core.js:66:11 in Promise
node_modules/regenerator-runtime/runtime.js:188:15 in callInvokeWithMethodAndArg
node_modules/regenerator-runtime/runtime.js:211:38 in enqueue
node_modules/regenerator-runtime/runtime.js:238:8 in exports.async
node_modules/@tensorflow/tfjs-react-native/dist/camera/camera_stream.js:138:4 in cameraWithTensors
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:293:29 in invoke
node_modules/regenerator-runtime/runtime.js:63:36 in tryCatch
node_modules/regenerator-runtime/runtime.js:154:27 in invoke
node_modules/regenerator-runtime/runtime.js:164:18 in PromiseImpl.resolve.then$argument_0
node_modules/promise/setimmediate/core.js:37:13 in tryCallOne
node_modules/promise/setimmediate/core.js:123:24 in setImmediate$argument_0
node_modules/react-native/Libraries/Core/Timers/JSTimers.js:135:14 in _callTimer
node_modules/react-native/Libraries/Core/Timers/JSTimers.js:183:16 in _callImmediatesPass
node_modules/react-native/Libraries/Core/Timers/JSTimers.js:446:30 in callImmediates


[native code]:null in callImmediates


node_modules/react-native/Libraries/BatchedBridge/MessageQueue.js:396:6 in __callImmediates
node_modules/react-native/Libraries/BatchedBridge/MessageQueue.js:144:6 in __guard$argument_0
node_modules/react-native/Libraries/BatchedBridge/MessageQueue.js:373:10 in __guard
node_modules/react-native/Libraries/BatchedBridge/MessageQueue.js:143:4 in flushedQueue


[native code]:null in flushedQueue
[native code]:null in invokeCallbackAndReturnFlushedQueue

	</description>
	<comments>
		<comment id='1' author='yudhiesh' date='2020-09-11T04:04:27Z'>
		The error was in the input shape I was specifying .
The following solved the error:
&lt;denchmark-code&gt;const model = await loadedModel;
const prediction = model.predict(tensor.reshape([1, 224, 224, 3]));
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='yudhiesh' date='2020-09-11T04:04:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3899&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3899&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>