<bug id='263' author='decentralion' open_date='2018-05-04T02:36:16Z' closed_time='2019-10-08T22:27:28Z'>
	<summary>Long-running shaders result in webgl context lost</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.10.0
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

Chrome 64.0.3282.167 (Linux)
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

Consider the following toy example of matrix exponentiation:
const size = 10000;
const iters = 10;

let tensor, tmp;
tensor = tf.zeros([size, size]);
for (let i=0; i&lt;iters; i++) {
  tmp = tensor.matMul(tensor);
  tensor.dispose();
  tensor = tmp;
}
tensor.max().print();
&lt;denchmark-h:h4&gt;Expected:&lt;/denchmark-h&gt;

The program should always print 0, and neither the behavior nor memory usage should vary as iters increases, since it results in multiplying the exact same matrix, and the tensor is disposed after being used.
&lt;denchmark-h:h4&gt;Actual:&lt;/denchmark-h&gt;

With iters = 5, the program behaves as expected. With iters = 10 I have seen the following three behaviors:

Sometimes it prints NaN, and Chrome reports that "WebGL hit a snag"
Sometimes it errors with "Couldn't compile vertex shader"
Sometimes it errors with the long failed script compilation found here

&lt;denchmark-h:h4&gt;Reproduction&lt;/denchmark-h&gt;

Navigate to &lt;denchmark-link:https://js.tensorflow.org/&gt;https://js.tensorflow.org/&lt;/denchmark-link&gt;
, open the console, and post the example script there. If it works as expected, try increasing the number of iterations and see if it breaks.
	</description>
	<comments>
		<comment id='1' author='decentralion' date='2018-05-05T01:45:08Z'>
		Hey Dandelion, thanks for the detailed report! And hi again!
This is consistent with our observation of executing long-running shaders. A matmul of matrices of size 10Kx10K is ~2TFLOPS. The hypothesis is that Chrome is trying to protect itself (other tabs) by prematurely killing the WebGL context, if a single program takes more than x seconds, especially after several consecutive programs. This results in either a NaN or WebGL hit a Snag error.
The solution is non-trivial, but the idea is to use some &lt;denchmark-link:https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm#Divide_and_conquer_algorithm&gt;divide and conquer&lt;/denchmark-link&gt;
 where we internally divide our matmul job into several smaller matmul shader calls, each on the order GLOPS, instead of TFLOPS, which will keep Chrome and other browsers happy.
We won't be prioritizing this yet, since it hasn't come up in real use-cases (existing ML models), but happy to revisit this later, or take contributions!
		</comment>
		<comment id='2' author='decentralion' date='2018-05-05T01:46:56Z'>
		Cool, thanks for the info. Our conclusion was similar, namely that if we need to handle really big matrices, we should partition them. And ðŸ‘‹ back ðŸ™‚
		</comment>
		<comment id='3' author='decentralion' date='2018-10-30T21:51:19Z'>
		&lt;denchmark-link:https://github.com/decentralion&gt;@decentralion&lt;/denchmark-link&gt;
 please let us know if this is still an issue ?
		</comment>
		<comment id='4' author='decentralion' date='2018-10-31T18:31:13Z'>
		&lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;
 here's my result from running the reproduction in the issue locally:
&lt;denchmark-link:https://user-images.githubusercontent.com/1400023/47810366-5e803880-dd00-11e8-91ab-f423970c67b5.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='decentralion' date='2019-10-08T22:27:27Z'>
		I was not able to reproduce the error now with latest versions, so will be closing this issue , feel free to comment so that we can reopen.Thank you.
&lt;denchmark-link:https://user-images.githubusercontent.com/43972606/66437956-170a2e00-e9e0-11e9-908b-e758d5959880.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='decentralion' date='2020-01-21T03:58:48Z'>
		&lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;
 I'm getting a crash in Chrome 79:
&lt;denchmark-link:https://user-images.githubusercontent.com/1167575/72774057-5e4dbf00-3c5d-11ea-9219-f29f7d69fb43.png&gt;&lt;/denchmark-link&gt;

Here's a demo: &lt;denchmark-link:https://jsbin.com/jequtodute/1/edit?html,output&gt;https://jsbin.com/jequtodute/1/edit?html,output&lt;/denchmark-link&gt;
 (using latest version of tfjs) For me the crash occurs after about 1 minute.
I'm on an Ubuntu/PopOS 19.04, with a GTX 2070. As mentioned here: &lt;denchmark-link:https://github.com/snowme34/tone-the-ear/issues/21&gt;snowme34/tone-the-ear#21&lt;/denchmark-link&gt;
 the CPU back-end still works fine.
: Also, in case it's useful, I've pasted the error message that I get when running mobilenet + knn classifier (on thousands of images) &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/1644#issuecomment-576132325&gt;here&lt;/denchmark-link&gt;
. The messages are different, but I imagine that they have similar causes.
		</comment>
		<comment id='7' author='decentralion' date='2020-02-13T16:14:18Z'>
		Thanks! We won't be able to fix this for several reasons:

The fix for this is non-trivial and likely impossible without breaking the API since we would need to "release the GPU and the main thread", but we probably won't be able to keep the entire matmul operation synchronous (tf.matmul().dataSync() will break).
Huge matmuls like this do not show up in practical ML models, thus making this a low priority for the time being.

		</comment>
	</comments>
</bug>