<bug id='1169' author='Pravez' open_date='2019-01-29T17:22:06Z' closed_time='2020-01-03T22:51:02Z'>
	<summary>FrozenModel does not contain control flow or dynamic shape ops when using executeAsync()</summary>
	<description>
First of all, thank you for your wonderful library !
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.14.2
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

chrome latest
&lt;denchmark-h:h4&gt;Describe the problem&lt;/denchmark-h&gt;

When using the executeAsync method from a model loaded with loadFrozenModel, I end up with the following exception :
&lt;denchmark-code&gt;Error: The model does not contain control flow or dynamic shape ops, please use execute method for better performance.
    at e.&lt;anonymous&gt; (tf-converter.esm.js:6743)
    at tf-converter.esm.js:133
    at Object.next (tf-converter.esm.js:146)
    at tf-converter.esm.js:53
    at new Promise (&lt;anonymous&gt;)
    at __awaiter (tf-converter.esm.js:30)
    at e.executeAsync (tf-converter.esm.js:6738)
    at Model._callee2$ (Model.ts:5)
   ....
&lt;/denchmark-code&gt;

This thing is, it works when using predict() or execute() methods.
My code is as follows :
public async runAsync(
    inputImage: HTMLImageElement,
    outputCanvas: HTMLCanvasElement
  ): Promise&lt;tf.Tensor3D&gt; {
    return this._execAsync(
      tf.tidy(() =&gt;
        tf
          .fromPixels(inputImage)
          .toFloat()
          .expandDims()
      )
    ).then(
      value =&gt; {
        this.lastResult = tf.tidy(
          () =&gt;
            (value as tf.Tensor4D)
              .squeeze()
              .toInt()
              .clipByValue(0, 255) as tf.Tensor3D
        );

        tf.toPixels(this.lastResult, outputCanvas);
        return this.lastResult;
      }, rejected =&gt; rejected
    ).catch(err =&gt; console.log(err));
  }

  private async _execAsync(
    input: tf.Tensor
  ): Promise&lt;tf.Tensor&lt;Rank&gt; | tf.Tensor&lt;Rank&gt;[]&gt; {
    if (this.model != undefined) {
      return this.model.executeAsync({ Placeholder: input });
    }

    throw Error("Model is undefined");
  }
I found &lt;denchmark-link:https://github.com/tensorflow/tfjs-converter/pull/195&gt;this issue&lt;/denchmark-link&gt;
 which was about the same method generating the same exception but not in the same context. Can't say if it has anything to do with it ... The last update was in august, nothing new since then.
Thank you :)
	</description>
	<comments>
		<comment id='1' author='Pravez' date='2019-01-29T21:57:23Z'>
		The error message is just saying use model.execute instead of model.executeAsync since there are no asynchronous operations. execute and executeAsync do fundamentally the same thing, and you should use execute for models that can be executed synchronously.
cc &lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 maybe the error could be clearer.
		</comment>
		<comment id='2' author='Pravez' date='2019-01-30T09:31:11Z'>
		Thank you for your answer.
What are exactly asynchronous operations ? I must admit I am not sure exactly what is the difference with synchronous operations, and just thought this was a way to execute the model "in background".
My final goal was to make the execute() asynchronous in order to show a loader and update my webpage, since running in synchronous mode is provoking a nice ~1 second lag.
		</comment>
		<comment id='3' author='Pravez' date='2019-02-11T19:38:14Z'>
		&lt;denchmark-link:https://github.com/Pravez&gt;@Pravez&lt;/denchmark-link&gt;
 The reason for having executeAsync method is not performance specific, it is due to some of op's output shapes cannot be pre-determined during the compilation time.
It is interesting that you are experience 1 sec improvement on the your model when using executeAsync. The execute method for most part is actually async in term of javascript, since it pushes all the calculation to GPU, and only downloads the data, when you calls the output.dataSync(). And in the GPU all ops are serialized, so it not very likely that there will be such a large improvement when using executeAsync.
Maybe you can share some more details about your model, like how big is size, and what is the topologylike? (are there any preprocessing/postprocessing blocks)
		</comment>
		<comment id='4' author='Pravez' date='2019-02-26T14:00:09Z'>
		It is not really an improvement, actually it is a big lag causing my webpage to freeze for ~1 second (because it is a "blocking" call, not asynchronous).
My model is a loaded TFJS model from a converted TensorFlow model made from the paper "perceptual losses for real-time style transfer and super-resolution", so the style transfer. It contains a lightweight convolutional network and a VGG-16. Except concerning image pre-processing/post-processing with tasks like /255, type to float etc. there are no pre/post-processing blocks.
thank you for your interest ... :)
		</comment>
		<comment id='5' author='Pravez' date='2019-02-26T14:53:23Z'>
		The model.execute() itself, which is synchronous, should be very quick to execute (actually calling execute() only enqueues GPU programs, it doesn't wait for them to finish).
Only when you call dataSync() on the resulting tensor do you actually block the UI and wait for the GPU to finish. If you call data() on the result of model.execute() you shouldn't block the UI thread for a second.
		</comment>
		<comment id='6' author='Pravez' date='2019-04-17T02:24:45Z'>
		I use executeAsync method to handle my model and It takes one mistake - Error: Error in concat1D: rank of tensors[3] must be the same as the rank of the rest (1)
		</comment>
		<comment id='7' author='Pravez' date='2020-01-03T22:51:02Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>