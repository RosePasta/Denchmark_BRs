<bug id='421' author='caisq' open_date='2018-06-12T21:04:48Z' closed_time='2019-02-15T18:32:54Z'>
	<summary>Setting trainable of a tf.layers.Layer and/or a tf.Model should set the trainable bit of the underlying tf.Variable</summary>
	<description>
To get help from the community, check out our &lt;denchmark-link:https://groups.google.com/a/tensorflow.org/forum/#!forum/tfjs&gt;Google group&lt;/denchmark-link&gt;
.
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.11.6
	</description>
	<comments>
		<comment id='1' author='caisq' date='2018-06-12T21:26:06Z'>
		Question 1:
If a Layer contains multiple variables, should all the variables' trainable bit be set?
Question 2:
Given that there are two different locations for recording the trainable bit, i.e., Layer and Variable, what is the desired behavior in the following states?
A. Layer is trainable but Layer's Variables are not.
B. Layer is not trainable, but Layer's Variables are.
C. Layer has multiple variables, some are trainable and some are not.
I suspect that:

layer.fit() should have effect only when both layer and variable are trainable?  Fitting a trainable Layer in case C will only update the trainable variables.
tf.optimizer should only respect the variable's trainable bit?

		</comment>
		<comment id='2' author='caisq' date='2018-06-13T14:35:20Z'>
		Thanks, &lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;
, for the questions.
Let's consider the more general case: A trainable layer has N trainable variables M non-trainable variables initiailly.
When the user sets layer.trainable to false, all the N + M variables will be set to non-trainable.
Later, when the user sets layer.trainable to true, the state of the N trainable variables and M non-trainable variables will be all restored.
This means that a layer must keep track of the initial state of all its variables, namely which are trainable and which are not. I believe the Layer class is already doing that so it should be relatively easy to do that.
A layer that is non-trainable to begin with will always have 0 trainable variables no matter how its trainable attribute is set.
There is also the question of what happens when a Model's trainable attribute is set. The answer is that it's going to recursively set the trainable attribute of all the layers and (sub)Models it contains. This logic is orthogonal with the logic of setting a layer's weight variables as described above.
		</comment>
		<comment id='3' author='caisq' date='2018-10-26T18:18:06Z'>
		Is this fixed, &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='4' author='caisq' date='2019-02-15T19:22:15Z'>
		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 It is now :) Sorry for the delay.
		</comment>
	</comments>
</bug>