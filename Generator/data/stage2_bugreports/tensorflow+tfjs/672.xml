<bug id='672' author='MoonsuCha' open_date='2018-09-04T12:36:09Z' closed_time='2018-11-14T22:15:10Z'>
	<summary>Memory Overallocation from tfjs version 0.12.4</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.12.4 ~ 0.12.6
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

Chrome 68.0.3440.106 , Firefox 61.0.2
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

From tensorflow.js 0.12.4, when running a model with large input, RAM memory is abnormally allocated to the extent that it can't handle the data.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

With tfjs posenet demo official repository, the bug can be reproduced.
&lt;denchmark-h:h5&gt;To see working situation in 0.12.3&lt;/denchmark-h&gt;


clone the posenet demo repository,
link
version up the tfjs version to 0.12.3 by editing package.json
(before editing the version is 0.11.4 in master branch)
start the demo server: npm i &amp;&amp; npm run watch
change the input setting, and we can see the memory is in normal situation.


&lt;denchmark-h:h5&gt;To see memory bug situation in 0.12.4 ~ 0.12.6&lt;/denchmark-h&gt;


clone the posenet demo repository,
link
version up the tfjs version to 0.12.4 by editing package.json
(before editing the version is 0.11.4 in master branch)
start the demo server: npm i &amp;&amp; npm run watch
With the same input setting, we can see the memory overallocation with the demo application failing to work


	</description>
	<comments>
		<comment id='1' author='MoonsuCha' date='2018-09-04T14:15:18Z'>
		Does this occur only when using the webgl backend? I wonder if this is at all related to the memory issues I am experiencing with  with webgl as well &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/664&gt;#664&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='2' author='MoonsuCha' date='2018-09-04T15:28:47Z'>
		&lt;denchmark-link:https://github.com/MoonsuCha&gt;@MoonsuCha&lt;/denchmark-link&gt;
 Thanks for the detailed report. Could you let us know which operating system and browser you are using? Also if you post a screenshot of what you see when you visit &lt;denchmark-link:https://js.tensorflow.org/debug/&gt;https://js.tensorflow.org/debug/&lt;/denchmark-link&gt;
 that would be helpful.
I couldn't completely replicate this on my system, I did get higher memory usage in 0.12.4 by about 10-15MB so we can look into that, but it didn't cause the program to stop working.
		</comment>
		<comment id='3' author='MoonsuCha' date='2018-09-05T04:44:11Z'>
		&lt;denchmark-link:https://github.com/brannondorsey&gt;@brannondorsey&lt;/denchmark-link&gt;
 I used the "loadFrozenModel from @tensorflow/tfjs-converter" function for inference.
&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 Thanks for reply. It is my operating system and browser. My hardware uses the GTX 1070 graphic card for webgl.

Chrome - I used the non secure setting for dev (--unsafely-treat-insecure-origin-as-secure) 
Firefox 

[Note]
It is important to set the input config for reproducing the bug.

mobileNetArchitecture 1.01
outputStride 8
imageScaleFactor 1.0

		</comment>
		<comment id='4' author='MoonsuCha' date='2018-09-05T15:12:51Z'>
		Thanks, I still can't reproduce and since I can't fully understand the memory allocation results in the screenshot you posted. I have another suggestion to help determine if there is a memory leak or something else is going on. It involves adding two lines of code to camera.js and then re-running the demo.
Below line 17 (import * as posenet from '@tensorflow-models/posenet';) add:
&lt;denchmark-code&gt;import * as tf from '@tensorflow/tfjs';
&lt;/denchmark-code&gt;

And below line 280 (stats.end();) add:
&lt;denchmark-code&gt;console.log(performance.now(), tf.memory());
&lt;/denchmark-code&gt;

When you run the demo it should log how many tensors are present and how much memory they are using. Adjust the settings to the case where you see the issue and post some of that output here, or if it crashes completely let us know. On my computer it did take much longer for each frame, but the memory usage was unchanged. On my end it looks like this
&lt;denchmark-link:https://user-images.githubusercontent.com/26408/45102865-969e3d00-b0fc-11e8-9594-ba61ed34c611.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='MoonsuCha' date='2018-09-06T02:58:16Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 I tried to your suggestions on 0.12.3 and 0.12.4. It was not occurred the memory overallocation on tf.memory() function ouput, but my system memory reached the full memory. The difference between 0.12.3 and 0.12.4 is gpu numbytes. 0.12.4 version suddenly decreased 0 numbytes on gpu. Is there on association of nvidia-driver or hardware??


nvidia spec



0.12.3



0.12.4



		</comment>
		<comment id='6' author='MoonsuCha' date='2018-09-06T15:04:06Z'>
		&lt;denchmark-link:https://github.com/MoonsuCha&gt;@MoonsuCha&lt;/denchmark-link&gt;
 Thanks this gives us an idea of what could be the cause (paging). Could you add the following lines to camera.js at around line 24 (after the imports):
console.log(tf.getBackend());
console.log(
    'Window Info',
    window.screen.height * window.screen.width * window.devicePixelRatio);
console.log('Paging Threshold', tf.ENV.backend.NUM_BYTES_BEFORE_PAGING);
Could you paste the output you get from that here? It should be at the top of the console
If that paging threshold is too low for an activation it could cause the problem you are seeing (and provide some data for us to fix it).
A workaround you could try is adding the following line after those console logs (near the top of the file).
tf.ENV.backend.NUM_BYTES_BEFORE_PAGING = Infinity;
this should turn of paging and possibly solve the problem (if its what I think it is).
		</comment>
		<comment id='7' author='MoonsuCha' date='2018-09-07T10:56:03Z'>
		I encountered the same issue when running a model on mobile devices. It turns out it's easy to reproduce on a PC if you use a small screen width, which triggers paging.
		</comment>
		<comment id='8' author='MoonsuCha' date='2018-09-09T03:39:03Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 Your solution fix the problem. It currently works well on latest version (0.12.4 ~ latest).  I thinks that this problem related to the line 117 "const BEFORE_PAGING_CONSTANT = 300;" from "backend_webgl.ts"@tfjs-core. Depending on the gpu device, this heuristic variable value should be changed.  Thank you so much.
		</comment>
		<comment id='9' author='MoonsuCha' date='2018-09-13T16:12:38Z'>
		&lt;denchmark-link:https://github.com/MoonsuCha&gt;@MoonsuCha&lt;/denchmark-link&gt;
 Made another issue to track the fix. Thanks for reporting this!
		</comment>
		<comment id='10' author='MoonsuCha' date='2018-11-14T22:15:10Z'>
		Closing this  as the original raised  issue was addressed and new issue has been opened &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/699&gt;here&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>