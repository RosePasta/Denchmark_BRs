<bug id='1783' author='blechatellier' open_date='2019-07-31T12:39:55Z' closed_time='2019-08-01T00:14:27Z'>
	<summary>tfjs-converter "NonMaxSuppression" unsupported op</summary>
	<description>
Trying to convert a &lt;denchmark-link:https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb&gt;frozen model&lt;/denchmark-link&gt;
 using  as per the documentation.
Getting an error about an unsupported op:
&lt;denchmark-code&gt;ValueError: Unsupported Ops in the model before optimization
NonMaxSuppression
&lt;/denchmark-code&gt;

I can see that  should be supported from the list of &lt;denchmark-link:https://github.com/tensorflow/tfjs-converter/blob/0.8.x/docs/supported_ops.md&gt;supported ops&lt;/denchmark-link&gt;
.
Is there something obvious I'm missing?
	</description>
	<comments>
		<comment id='1' author='blechatellier' date='2019-07-31T15:15:57Z'>
		&lt;denchmark-link:https://github.com/blechatellier&gt;@blechatellier&lt;/denchmark-link&gt;
 thank you , did you try with latest version of  can you please provide instructions to reproduce the issue ?
		</comment>
		<comment id='2' author='blechatellier' date='2019-07-31T21:53:52Z'>
		&lt;denchmark-link:https://github.com/blechatellier&gt;@blechatellier&lt;/denchmark-link&gt;
 This an older version of NonMaxSuppression, we currently supports NonMaxSuppressionV2 and NonMaxSuppressionV3. Are you using a existing saved model, if not what version of TF you are using to generate this saved model?
		</comment>
		<comment id='3' author='blechatellier' date='2019-07-31T23:01:55Z'>
		&lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;
 I haven't tried the latest version as it doesn't support frozen models anymore, this is the command I used on the following model &lt;denchmark-link:https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb&gt;https://github.com/yeephycho/tensorflow-face-detection/blob/master/model/frozen_inference_graph_face.pb&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;tensorflowjs_converter \
    --input_format=tf_frozen_model \
    --output_json=true \
    --output_node_names='detection_boxes,detection_scores,num_detections,detection_classes' \
    --saved_model_tags=serve \
    frozen_inference_graph_face.pb \
    tfjs
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 that would make sense, this frozen model is already pre-trained but almost 2 years old. Should I retrain and export a new model with the latest version of tensorflow to support those ops? Is there a way to add this op manually on my side?
		</comment>
		<comment id='4' author='blechatellier' date='2019-08-01T00:10:56Z'>
		&lt;denchmark-link:https://github.com/blechatellier&gt;@blechatellier&lt;/denchmark-link&gt;
 yes, if you can retrain the model, and save it as saved model would be much better. Since even if we supported this op, it will be in the new converter, where the frozen model would not be supported.
		</comment>
	</comments>
</bug>