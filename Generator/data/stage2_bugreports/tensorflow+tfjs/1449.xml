<bug id='1449' author='tafsiri' open_date='2019-03-26T21:01:36Z' closed_time='2019-08-21T20:04:25Z'>
	<summary>errors executing async models loaded via tf.loadGraphModel.</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;"@tensorflow-models/coco-ssd": "^1.0.0",
"@tensorflow-models/mobilenet": "^1.0.0",
"@tensorflow-models/universal-sentence-encoder": "1.0.1",
"@tensorflow/tfjs": "1.0.0",
"@tensorflow/tfjs-node": "1.0.1",
&lt;/denchmark-code&gt;

Error also occurs on tfjs 1.0.2
&lt;denchmark-h:h4&gt;Node version&lt;/denchmark-h&gt;

Node 11.11
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

The following error occurs when making a prediction with either coco-ssd or universal-sentence-encoder (which are both models with control flow ops). But doesn't happen with mobilenet.
&lt;denchmark-code&gt;node:59415) UnhandledPromiseRejectionWarning: TypeError: Cannot read property 'id' of undefined
    at /Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_executor.js:295:99
    at Array.map (&lt;anonymous&gt;)
    at GraphExecutor.&lt;anonymous&gt; (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_executor.js:295:58)
    at step (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_executor.js:56:23)
    at Object.next (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_executor.js:37:53)
    at fulfilled (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_executor.js:28:58)
    at processTicksAndRejections (internal/process/next_tick.js:81:5)
&lt;/denchmark-code&gt;

From doing some console logging it looks like the tensors in the graph are undefined during executeAsync.
Note that I only get this error when using the node backend (tfjs-node), if i use the vanilla cpu backend (tfjs) it works.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;// const tf = require('@tensorflow/tfjs'); // using this import works
const tf = require('@tensorflow/tfjs-node');
const cocossd = require('@tensorflow-models/coco-ssd');
const mob = require('@tensorflow-models/mobilenet');
global.fetch = require('node-fetch');
const useLoader = require('@tensorflow-models/universal-sentence-encoder');

// This works
const model = await mob.load();
const res = await model.classify(tf.randomNormal([224, 224, 3]));
console.log(res);

// This fails.
const cocomodel = await cocossd.load();
const cocoa = await cocomodel.detect(tf.randomNormal([224, 224, 3]));
console.log(cocoa)
  
// this fails
console.time('Loading Universal Sentence Encoder');
const use = await useLoader.load();
console.timeEnd('Loading Universal Sentence Encoder');
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='tafsiri' date='2019-04-03T15:44:12Z'>
		Further info on this. This bug doesn't occer when using the following import pattern (where both tfjs and tfjs-node are required).
&lt;denchmark-code&gt;const tf = require('@tensorflow/tfjs');
require('@tensorflow/tfjs-node');
&lt;/denchmark-code&gt;

Note this was on a different code sample than listed in the issue, but hopefully provides a clue as to what the underlying issue might be.
		</comment>
		<comment id='2' author='tafsiri' date='2019-04-04T20:50:32Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 can you share your package.json file? I suspect that when you including multiple models, they installed different versions of tfjs.
		</comment>
		<comment id='3' author='tafsiri' date='2019-04-04T21:31:15Z'>
		Here are my dependencies. I only have one model loaded in my actual project, the multiple models in the example above was just to confirm that it wasn't specific to universal-sentence-encoder
&lt;denchmark-code&gt;"dependencies": {
    "@tensorflow-models/universal-sentence-encoder": "1.0.1",
    "@tensorflow/tfjs": "1.0.1",
    "@tensorflow/tfjs-node": "1.0.1",
    "d3-dsv": "^1.1.1",
    "lodash": "^4.17.11",
    "node-fetch": "^2.3.0"
  },
  "devDependencies": {
    "babel-core": "^6.26.3",
    "babel-plugin-transform-runtime": "^6.23.0",
    "babel-preset-env": "^1.7.0",
    "clang-format": "^1.2.4",
    "cross-env": "^5.2.0",
    "http-server": "^0.11.1",
    "parcel-bundler": "^1.12.3"
  }

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='tafsiri' date='2019-04-04T22:21:23Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 I believe tfjs-node has tfjs as one of the dependencies, you don't need to install tfjs separately. Can you try to remove tfjs from your package.json file?
		</comment>
		<comment id='5' author='tafsiri' date='2019-04-05T00:07:54Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 If i do that I get the following error
&lt;denchmark-code&gt;(node:56574) UnhandledPromiseRejectionWarning: Error: Found more than one (2) load handlers for URL 'https://storage.googleapis.com/tfjs-models/savedmodel/universal_sentence_encoder/model.json'
    at GraphModel.findIOHandler (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:147:23)
    at GraphModel.&lt;anonymous&gt; (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:163:30)
    at step (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:48:23)
    at Object.next (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:29:53)
    at /Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:23:71
    at new Promise (&lt;anonymous&gt;)
    at __awaiter (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:19:12)
    at GraphModel.load (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:158:16)
    at Object.&lt;anonymous&gt; (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:377:48)
    at step (/Users/yassogba/projects/intent-classifier/node_modules/@tensorflow/tfjs-converter/dist/src/executor/graph_model.js:48:23)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='tafsiri' date='2019-04-05T01:09:39Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 This is IOHandler error, probably https are register with both browser and node handlers.
Do you have repo or codepen for me to reproduce?
		</comment>
		<comment id='7' author='tafsiri' date='2019-04-05T14:43:23Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 This repo code demonstrates it &lt;denchmark-link:https://github.com/tafsiri/use-text-classifier/blob/master/training/train.js&gt;https://github.com/tafsiri/use-text-classifier/blob/master/training/train.js&lt;/denchmark-link&gt;
, update the package.json to remove the other models. However on your point about that I thought all the models specify tfjs as a peerDependency, so they won't install their own copy.
Also see &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/1454&gt;#1454&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='tafsiri' date='2019-04-05T23:16:27Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 The multiple io handler issue seems to be root in this code
&lt;denchmark-link:https://github.com/tensorflow/tfjs-node/blob/3f8f64a420711b3cf542bc97ce97cf3d78c471e1/src/io/node_http.ts&gt;https://github.com/tensorflow/tfjs-node/blob/3f8f64a420711b3cf542bc97ce97cf3d78c471e1/src/io/node_http.ts&lt;/denchmark-link&gt;

which register a handler for http url as the same time as core browser_http class.
If we allow multiple handlers, we need to update the model loaders to use a particular
handler (the last one)?
		</comment>
		<comment id='9' author='tafsiri' date='2019-05-03T20:22:59Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 is this issue resolved?
		</comment>
		<comment id='10' author='tafsiri' date='2019-08-21T20:04:25Z'>
		No longer an issue on latest tfjs.
		</comment>
	</comments>
</bug>