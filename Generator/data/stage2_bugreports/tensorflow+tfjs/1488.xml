<bug id='1488' author='Azaeres' open_date='2019-04-03T23:33:15Z' closed_time='2019-07-08T18:56:02Z'>
	<summary>Batch predictions are wrong on Chromebook using the WebGL backend</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

1.0.3 (latest)
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

Google Chrome OS version 71.0.3578.127
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

Batch predictions are wrong on Chromebook using the WebGL backend. In our tests, the first prediction in the batch actually match pretty closely between WebGL and CPU backends, but all the other predictions do not.
Conditions to reproduce:

On Chromebook, running TensorFlow.js inside ChromeOS extension.
WebGL backend only.
Batch image predictions only (the first prediction in each batch is consistently correct).

&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

Demo of this bug found at the repo below. Instructions in the README.
&lt;denchmark-link:https://github.com/ryancbarry/tensorflow-image-recognition-chrome-extension/&gt;https://github.com/ryancbarry/tensorflow-image-recognition-chrome-extension/&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Azaeres' date='2019-04-14T11:52:40Z'>
		We have a similar bug that shows in FF and Chrome on different computers with different GPUs. We trained our model (based on MobileNetV2) in Python and then exported to JS via tfjs.converters.save_keras_model. The model predicts face landmarks. The first screenshot shows the model working correctly when using the CPU backend:
&lt;denchmark-link:https://user-images.githubusercontent.com/48919647/56092308-d317ef80-5eba-11e9-8e0c-2c73f79f48e0.jpg&gt;&lt;/denchmark-link&gt;

Second screenshot shows Webgl backend. As you can see the landmark coordinates are way off, roughly by a factor of 1.5:
&lt;denchmark-link:https://user-images.githubusercontent.com/48919647/56092313-e925b000-5eba-11e9-9d3d-8016013813a3.jpg&gt;&lt;/denchmark-link&gt;

On both screenshots the two insets show the predictions when using the original model in Python (the difference to the cpu version comes from slighly different crops).
The actual face detection (green and yellow boxes) yields identical results in both versions. This is an older model (MobileNetV2 SSD) that was converted two weeks ago which makes me think that this bug is converter related.
		</comment>
		<comment id='2' author='Azaeres' date='2019-04-14T12:14:07Z'>
		Thanks for letting us know about this issue. &lt;denchmark-link:https://github.com/AxelWolf&gt;@AxelWolf&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/RyanCBarry&gt;@RyanCBarry&lt;/denchmark-link&gt;
 - could you try appending ?tfjsflags=WEBGL_PACK:false to the URL (or calling  right after tfjs is loaded) to see whether that changes the predictions? Let me know what you find.
		</comment>
		<comment id='3' author='Azaeres' date='2019-04-14T12:25:46Z'>
		Adding tf.ENV.set('WEBGL_PACK', false) before loading the model gives correct predictions on FF and Chrome with GTX1080. Interestingly, in Chrome (73.0.3683.103) it seems snappier than before.
Update: Fix also works on a Windows 10 box with integrated Intel graphics.
		</comment>
		<comment id='4' author='Azaeres' date='2019-04-14T12:41:38Z'>
		Thanks &lt;denchmark-link:https://github.com/AxelWolf&gt;@AxelWolf&lt;/denchmark-link&gt;
 - could you call  - this will print out the architecture of your model to the console along with kernel execution times. Could you share your console output with me - you should be able to copy / paste into a spreadsheet. Thanks!
		</comment>
		<comment id='5' author='Azaeres' date='2019-04-14T12:58:27Z'>
		Attaching two files: 177.log shows output when loading the two models, I then cleared the console. 206.log shows output when doing prediction.
&lt;denchmark-link:https://github.com/tensorflow/tfjs/files/3077370/192.168.2.106-1555246123206.log&gt;192.168.2.106-1555246123206.log&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tfjs/files/3077371/192.168.2.106-1555246516177.log&gt;192.168.2.106-1555246516177.log&lt;/denchmark-link&gt;

This is on Ubuntu 16.04 with 1080 in Chrome as above.
		</comment>
		<comment id='6' author='Azaeres' date='2019-04-14T13:05:13Z'>
		Thanks &lt;denchmark-link:https://github.com/AxelWolf&gt;@AxelWolf&lt;/denchmark-link&gt;
 - this is awesome. Could I ask you to do two more things:

try setting tf.ENV.set('WEBGL_PACK_DEPTHWISECONV', false') but leaving the WEBGL_PACK` flag alone - are predictions correct?
try setting tf.ENV.set('WEBGL_CONV_IM2COL', false') but leaving the WEBGL_PACK` flag alone - are predictions correct?

Thank you for helping us debug this! Actually is your repo somewhere I can take a look? Or are your saved model assets hosted so I can just load them locally? Then I can leave you alone :)
		</comment>
		<comment id='7' author='Azaeres' date='2019-04-14T13:24:22Z'>
		Leaving WEBGL_PACK at true I will only get correct predictions with DEPTHWISECONV to false; IM2COL makes no difference.
I've prepared a zip (&lt;denchmark-link:https://softmatic.com/f/WebGL&gt;https://softmatic.com/f/WebGL&lt;/denchmark-link&gt;
 Bug.zip) which contains the latest checkpoint and the converted model.json and shards. The model expects a (n,160,160,3) tensor and will return an array of 68 xy coordinates. I can provide additional JS code if you need it.
		</comment>
		<comment id='8' author='Azaeres' date='2019-04-14T13:35:07Z'>
		Thanks &lt;denchmark-link:https://github.com/AxelWolf&gt;@AxelWolf&lt;/denchmark-link&gt;
 - the converted outputs are what I need. I wasn't able to load the zip you provided - could you double check the link? Also if you have the JS code that makes the prediction that would be great.
		</comment>
		<comment id='9' author='Azaeres' date='2019-04-14T13:50:37Z'>
		The link was cutoff, try this one: &lt;denchmark-link:https://softmatic.com/f/WebGL_Bug.zip&gt;https://softmatic.com/f/WebGL_Bug.zip&lt;/denchmark-link&gt;

JS should look like this:
import * as tf from '@tensorflow/tfjs';
const LANDMARK_URL = './landmarks/model.json'
let landmarkPromise;
let landmark;
window.onload = () =&gt; {
landmarkPromise = tf.loadLayersModel(LANDMARK_URL);
landmark = await landmarkPromise;
await landmark.predict(tf.zeros([1,160,160,3]));
}
// this assumes a square img tag on the page with id=image with size 160,160
// prediction will usually be in an async function that is triggered by a button, like so:
const runButton = document.getElementById('run');
runButton.onclick = async () =&gt; {
var image = document.getElementById("image");
var pixels = tf.browser.fromPixels(image);
var norm = pixels.div(127.5).sub(1);
var lms = await landmark.predict(norm.reshape([1, ...norm.shape]));
var landmarks = lms.dataSync();
}
		</comment>
		<comment id='10' author='Azaeres' date='2019-04-14T13:57:02Z'>
		Perfect - thanks &lt;denchmark-link:https://github.com/AxelWolf&gt;@AxelWolf&lt;/denchmark-link&gt;
 - this should be everything I need. Thanks again for reporting this!
		</comment>
		<comment id='11' author='Azaeres' date='2019-04-18T20:32:09Z'>
		
Thanks for letting us know about this issue. @AxelWolf and @RyanCBarry - could you try appending ?tfjsflags=WEBGL_PACK:false to the URL (or calling tf.ENV.set('WEBGL_PACK', false) right after tfjs is loaded) to see whether that changes the predictions? Let me know what you find.

With WEBGL_PACK set to false:
&lt;denchmark-code&gt;{
  "windowscreen": 0.6159740686416626,
  "windowshade": 0.26258158683776855,
  "shoji": 0.018357258290052414,
  "digitalclock": 0.018023479729890823,
  "electricfan,blower": 0.014563548378646374,
  "strainer": 0.013532050885260105,
  "spotlight,spot": 0.003762525739148259,
  "loudspeaker,speaker,speakerunit,loudspeakersystem,speakersystem": 0.002997360657900572,
  "knot": 0.0027297139167785645,
  "radiator": 0.002250275108963251
}
&lt;/denchmark-code&gt;

With WEBGL_PACK set to true:
&lt;denchmark-code&gt;{
  "velvet": 0.16494502127170563,
  "windowscreen": 0.09491492062807083,
  "theatercurtain,theatrecurtain": 0.05020033195614815,
  "digitalclock": 0.04693294316530228,
  "spaceheater": 0.037753134965896606,
  "windowshade": 0.03272269293665886,
  "honeycomb": 0.02653188817203045,
  "doormat,welcomemat": 0.024251466616988182,
  "strainer": 0.023848969489336014,
  "dishrag,dishcloth": 0.02221301943063736
}
&lt;/denchmark-code&gt;

This is for the image at &lt;denchmark-link:https://r.hswstatic.com/w_907/gif/tesla-cat.jpg&gt;https://r.hswstatic.com/w_907/gif/tesla-cat.jpg&lt;/denchmark-link&gt;

&lt;denchmark-link:https://camo.githubusercontent.com/41a273b00821c70af3ed0085367d97e1dff1fe6782d795b32aee8b855fbcb1af/68747470733a2f2f722e6873777374617469632e636f6d2f775f3930372f6769662f7465736c612d6361742e6a7067&gt;&lt;/denchmark-link&gt;

Both times the backend was set to WEBGL.
Using tfjs v1.0.3
And for reference (using the CPU backend on the same image), we're looking for predictions that look like this:
&lt;denchmark-code&gt;{
  "Egyptiancat": 0.5521813631057739,
  "tabby,tabbycat": 0.10373528301715851,
  "tigercat": 0.07581817358732224,
  "Siamesecat,Siamese": 0.06736601144075394,
  "schipperke": 0.05536174029111862,
  "groenendael": 0.031074585393071175,
  "Bostonbull,Bostonterrier": 0.014214071445167065,
  "lynx,catamount": 0.013818344101309776,
  "Scotchterrier,Scottishterrier,Scottie": 0.006884398404508829,
  "carton": 0.006883499212563038
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='Azaeres' date='2019-07-01T14:47:05Z'>
		Is there any progress on this issue?
We also have to disable the  component for our Cordova application. I was using today's (2019/07/01) version of &lt;denchmark-link:https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js%22&gt;TFJS&lt;/denchmark-link&gt;
.
tf.setBackend('cpu', false);
Otherwise, the results from WebGL are completely wrong. Running it on the CPU is incredible slow.
		</comment>
		<comment id='13' author='Azaeres' date='2019-07-01T14:55:47Z'>
		Can you send us your model so we can take a look?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Jul 1, 2019 at 10:47 AM msektrier ***@***.***&gt; wrote:
 Is there any progress on this issue?
 We also have to disable the *WebGL* component for our Cordova
 application. I was using today's (2019/07/01) version of TFJS
 ***@***.***/tfjs/dist/tf.min.js%22&gt;.

 *tf.setBackend('cpu', false);*

 Otherwise, the results from WebGL are completely wrong. Running it on the
 CPU is incredible slow.

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;#1488?email_source=notifications&amp;email_token=AAIMXTMWSKI45LR6PVGGYMTP5IKGZA5CNFSM4HDOROEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY6LS2Q#issuecomment-507296106&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAIMXTPTTFUQ7LNBBLIEUODP5IKGZANCNFSM4HDOROEA&gt;
 .



		</comment>
		<comment id='14' author='Azaeres' date='2019-07-01T15:12:41Z'>
		
Can you send us your model so we can take a look?
…
On Mon, Jul 1, 2019 at 10:47 AM msektrier @.&gt; wrote: Is there any progress on this issue? We also have to disable the WebGL component for our Cordova application. I was using today's (2019/07/01) version of TFJS @./tfjs/dist/tf.min.js%22&gt;. tf.setBackend('cpu', false); Otherwise, the results from WebGL are completely wrong. Running it on the CPU is incredible slow. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub &lt;#1488?email_source=notifications&amp;email_token=AAIMXTMWSKI45LR6PVGGYMTP5IKGZA5CNFSM4HDOROEKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODY6LS2Q#issuecomment-507296106&gt;, or mute the thread https://github.com/notifications/unsubscribe-auth/AAIMXTPTTFUQ7LNBBLIEUODP5IKGZANCNFSM4HDOROEA .

Of course. It is a MobileNet V2 SSDLite Model.
&lt;denchmark-link:https://github.com/tensorflow/tfjs/files/3346226/webgl-problem-model.zip&gt;webgl-problem-model.zip&lt;/denchmark-link&gt;

We execute it with
&lt;denchmark-code&gt;const INPUT_TENSOR = 'image_tensor';
const OUTPUT_TENSOR = ['detection_boxes', 'detection_scores'] 
tfModelCache = await tf.loadGraphModel('./model.json');
tf.setBackend('cpu', false);

let preparedImage = preprocess(image);
let prediction = model.executeAsync( {[INPUT_TENSOR]: preparedImage}, OUTPUT_TENSOR ).then(function(result){
		console.log(result);
		return result;
});

function preprocess(img) {
    let tensor = tf.browser.fromPixels(img);
    let expanded = tensor.expandDims(0);
    return expanded;
}

&lt;/denchmark-code&gt;

If you need more information from our side please let us know.
		</comment>
		<comment id='15' author='Azaeres' date='2019-07-01T15:17:56Z'>
		Additionally, here a screenshot of the output tensor "detection_scores" with the same input image.
with CPU only - correct
&lt;denchmark-link:https://user-images.githubusercontent.com/49950048/60447629-1e24e180-9c24-11e9-9269-7d9988d252be.PNG&gt;&lt;/denchmark-link&gt;

with GPU - wrong results
&lt;denchmark-link:https://user-images.githubusercontent.com/49950048/60447636-23822c00-9c24-11e9-968f-27aa004789b8.PNG&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='Azaeres' date='2019-07-02T13:31:19Z'>
		&lt;denchmark-link:https://github.com/msektrier&gt;@msektrier&lt;/denchmark-link&gt;
 do you mind filing a separate issue about the Cordova platform?
&lt;denchmark-link:https://github.com/annxingyuan&gt;@annxingyuan&lt;/denchmark-link&gt;
 is this issue fixed with &lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1796&gt;tensorflow/tfjs-core#1796&lt;/denchmark-link&gt;
? If yes, we will close this issue.
		</comment>
		<comment id='17' author='Azaeres' date='2019-07-02T13:32:20Z'>
		&lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;
 It appears not because the results are incorrect regardless of 
EDIT: Sorry, the original issue is fixed. The Cordova issue is the one that's independent of packing.
		</comment>
		<comment id='18' author='Azaeres' date='2019-07-02T13:58:57Z'>
		Hi &lt;denchmark-link:https://github.com/msektrier&gt;@msektrier&lt;/denchmark-link&gt;
 - just wanted to confirm that this only happens within your Cordova application? FWIW in Chrome on my Macbook Pro and on a Chromebook I get the same values for 'detection_scores' on both WebGL/CPU.
Also would you mind sharing the image you used to obtain the output in your previous comment? I tried the black cat image from a few comments ago and got different results.
		</comment>
		<comment id='19' author='Azaeres' date='2019-07-03T09:58:50Z'>
		Hi &lt;denchmark-link:https://github.com/annxingyuan&gt;@annxingyuan&lt;/denchmark-link&gt;
 many thanks you take your time. I can share the picture. It contains a form of the German tax authority.
&lt;denchmark-link:https://user-images.githubusercontent.com/49950048/60582460-221e4400-9d89-11e9-9805-6792876f769e.JPG&gt;&lt;/denchmark-link&gt;

I can confirm that what you saw above is happening inside the Cordova application. Leaving out Cordova and hosting it on NGINX the model cannot execute on my phone running in Chrome.
&lt;denchmark-link:https://user-images.githubusercontent.com/49950048/60582531-4c700180-9d89-11e9-98d1-fc199f7c5c04.png&gt;&lt;/denchmark-link&gt;

It produces the &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/689&gt;texture_size error&lt;/denchmark-link&gt;
. On my computer it is running well.
&lt;denchmark-link:https://user-images.githubusercontent.com/49950048/60582622-75909200-9d89-11e9-80e1-d2f9f4b91301.png&gt;&lt;/denchmark-link&gt;

Therefore, it is rather a surprise to me it is running in Cordova since the available texture size is the same.
		</comment>
		<comment id='20' author='Azaeres' date='2019-07-03T15:51:47Z'>
		Hi &lt;denchmark-link:https://github.com/RyanCBarry&gt;@RyanCBarry&lt;/denchmark-link&gt;
 - sorry it took us a while to get to this. There's a few things going on - first of all we had a bug in our WebGL backend that caused  to produce different results - that's now fixed (&lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1796&gt;tensorflow/tfjs-core#1796&lt;/denchmark-link&gt;
).
Second we found that fromPixels behaves differently in WebGL / CPU for images that are resized. For what it's worth, when I tried your demo with 224x224 images the predictions matched.
We're gonna fix the WebGL / CPU discrepancy (&lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/1719&gt;#1719&lt;/denchmark-link&gt;
) but just wanted to give you some context in the meantime.
		</comment>
	</comments>
</bug>