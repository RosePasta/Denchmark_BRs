<bug id='1053' author='iacovlev-pavel' open_date='2018-12-24T16:18:20Z' closed_time='2019-02-12T11:52:24Z'>
	<summary>Updated @tensorflow/tfjs-node-gpu from 0.1.21 to 0.2.1 got: Cannot read property 'name' of null.</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.2.1
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

upon running the following code:
&lt;denchmark-code&gt;const model = await tf.loadFrozenModel(modelPath, weightsPath);
const shape = [1, 2560, 1920, 3];
const tensor = tf.fill(shape, 0, 'int32');
await model.executeAsync(
  { image_tensor: tensor },
  ['detection_boxes', 'detection_scores', 'detection_classes', 'num_detections'],
);
&lt;/denchmark-code&gt;

I get the following error:
&lt;denchmark-code&gt;error:  message=Cannot read property 'name' of null, stack=TypeError: Cannot read property 'name' of null
    at Engine.runKernel (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-core\dist\engine.js:124:42)
    at Object.cropAndResize_ [as cropAndResize] (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-core\dist\ops\image_ops.js:184:40)
    at Object.exports.executeOp (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\operations\executors\image_executor.js:26:31)
    at Object.executeOp (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\operations\operation_executor.js:36:26)
    at _loop_1 (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:301:52)
    at GraphExecutor.processStack (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:327:13)
    at GraphExecutor.&lt;anonymous&gt; (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:279:41)
    at step (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:40:23)
    at Object.next (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:21:53)
    at fulfilled (D:\Projects\pk-next\node_modules\@tensorflow\tfjs-converter\dist\src\executor\graph_executor.js:12:58)
&lt;/denchmark-code&gt;

The model is based on faster_rcnn_inception_v2_coco
With @tensorflow/tfjs-node-gpu@0.1.21 everything works as expected.
	</description>
	<comments>
		<comment id='1' author='iacovlev-pavel' date='2019-01-02T15:20:48Z'>
		There was an issue not to long ago dealing with underspecification of model formats.  That is my first suspicion.  Can you append your model (no need to append the weights for now, if they are very large.
		</comment>
		<comment id='2' author='iacovlev-pavel' date='2019-01-03T07:19:03Z'>
		I hope this is what is needed, I did not include the shards since they are 180mb.
&lt;denchmark-link:https://github.com/tensorflow/tfjs/files/2722928/model.zip&gt;model.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='iacovlev-pavel' date='2019-02-04T10:22:18Z'>
		&lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;

Still an issue in 0.2.3.
Here is a more reproducible use case:
Download the model:
&lt;denchmark-link:http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz&gt;http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz&lt;/denchmark-link&gt;

Convert the model:
&lt;denchmark-code&gt;tensorflowjs_converter --input_format=tf_saved_model --output_node_names="detection_boxes,detection_scores,num_detections,detection_classes" --saved_model_tags=serve model/faster_rcnn_resnet101_coco_2018_01_28/saved_model model/faster_rcnn_resnet101_coco_2018_01_28/web_model
&lt;/denchmark-code&gt;

Run the code
&lt;denchmark-code&gt;const model = await tf.loadFrozenModel(modelPath, weightsPath);

const shape = [1, 2560, 1920, 3];
const imageTensor = tf.fill(shape, 0, 'int32');
const predictions = await model.executeAsync(
  { image_tensor: imageTensor },
  ['detection_boxes', 'detection_scores', 'detection_classes', 'num_detections'],
);

imageTensor.dispose();
predictions.forEach(prediction =&gt; prediction.dispose());
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='iacovlev-pavel' date='2019-02-12T11:52:24Z'>
		Seems to be fixed in 0.3.0
		</comment>
	</comments>
</bug>