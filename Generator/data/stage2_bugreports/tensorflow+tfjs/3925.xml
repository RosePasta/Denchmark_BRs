<bug id='3925' author='hpssjellis' open_date='2020-09-15T04:02:59Z' closed_time='2020-09-25T04:59:50Z'>
	<summary>Possible Bug Tensorflowjs_converter Quantization Command Line Example</summary>
	<description>
Can someone check this bug it might be specific to my models. I am using TFJS version 2.3 with a fresh install of          pip install tensorflowjs
I used The Quantization example at &lt;denchmark-link:https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/README.md#converting-tfjs_layers_model-to-tfjs_layers_model-with-weight-sharding-and-quantization&gt;https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/README.md#converting-tfjs_layers_model-to-tfjs_layers_model-with-weight-sharding-and-quantization&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;tensorflowjs_converter \
   --input_format tfjs_layers_model \
   --output_format tfjs_layers_model \
   --quantize_uint16 \
   original_model/model.json
   quantized_model/
&lt;/denchmark-code&gt;

It does not seem to work unless --output_node_names is included with a comma separated list, for example:
&lt;denchmark-code&gt;tensorflowjs_converter  \
--input_format tfjs_layers_model \
--output_format tfjs_layers_model \
--quantize_uint16  \
--output_node_names logits,Bias \
./model.json \
./quantized_model

&lt;/denchmark-code&gt;

Can someone test if this is a bug?
	</description>
	<comments>
		<comment id='1' author='hpssjellis' date='2020-09-15T16:56:41Z'>
		&lt;denchmark-link:https://github.com/hpssjellis&gt;@hpssjellis&lt;/denchmark-link&gt;
 is it possible to share your model ?
		</comment>
		<comment id='2' author='hpssjellis' date='2020-09-15T19:14:31Z'>
		
@hpssjellis is it possible to share your model ?

&lt;denchmark-link:https://github.com/hpssjellis/my-examples-for-the-arduino-portentaH7/tree/master/m09-Tensoflow/tfjs-models&gt;tfjs-models from Jeremy&lt;/denchmark-link&gt;
 try this one first. It is called xor. Thanks for looking at this &lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;
 I can put more models there if needed.
For link below
&lt;denchmark-link:https://github.com/hpssjellis/my-examples-for-the-arduino-portentaH7/tree/master/m09-Tensoflow/tfjs-models&gt;https://github.com/hpssjellis/my-examples-for-the-arduino-portentaH7/tree/master/m09-Tensoflow/tfjs-models&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='hpssjellis' date='2020-09-15T19:26:47Z'>
		&lt;denchmark-link:https://github.com/hpssjellis&gt;@hpssjellis&lt;/denchmark-link&gt;
 can not access the path ?
		</comment>
		<comment id='4' author='hpssjellis' date='2020-09-16T00:58:58Z'>
		I updated above or use this. Not sure what happened &lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/hpssjellis/my-examples-for-the-arduino-portentaH7/tree/master/m09-Tensoflow/tfjs-models&gt;https://github.com/hpssjellis/my-examples-for-the-arduino-portentaH7/tree/master/m09-Tensoflow/tfjs-models&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='hpssjellis' date='2020-09-22T02:08:20Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 Hi Ping. Do you want some clarification of the problem?
		</comment>
		<comment id='6' author='hpssjellis' date='2020-09-24T20:35:25Z'>
		&lt;denchmark-link:https://github.com/hpssjellis&gt;@hpssjellis&lt;/denchmark-link&gt;
 This looks like argparser issue, if you use following command it should work:
tensorflowjs_converter \
   --quantize_uint16 \
   --input_format tfjs_layers_model \
   --output_format tfjs_layers_model \
   original_model/model.json
   quantized_model/
basically, the quantize_uint16 params is defined with nargs='?', means it can have an empty value, somehow when it is placed at the end, the argsparser thinks the input_path is its param.
you can also do:
tensorflowjs_converter \
   --input_format tfjs_layers_model \
   --output_format tfjs_layers_model \
   --quantize_uint16=* \
   original_model/model.json
   quantized_model/
		</comment>
		<comment id='7' author='hpssjellis' date='2020-09-25T04:59:50Z'>
		Thanks &lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 that works fine, so it basically was my bad luck that let me find that bug. One minor issue is your code would not compile for me without the backslash on the second to last line.
&lt;denchmark-code&gt;tensorflowjs_converter \
   --input_format tfjs_layers_model \
   --output_format tfjs_layers_model \
   --quantize_uint16=* \
   original_model/model.json \
   quantized_model/

&lt;/denchmark-code&gt;

We can close this issue, I can send a PR if you want to &lt;denchmark-link:https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/README.md#converting-tfjs_layers_model-to-tfjs_layers_model-with-weight-sharding-and-quantization&gt;the tfjs-converter README.md file &lt;/denchmark-link&gt;
. I would just move --quantize_uint16=* to the second row.
		</comment>
		<comment id='8' author='hpssjellis' date='2020-09-25T04:59:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3925&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3925&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>