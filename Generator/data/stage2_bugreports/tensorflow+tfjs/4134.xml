<bug id='4134' author='vladmandic' open_date='2020-10-26T21:12:13Z' closed_time='2021-01-20T16:02:16Z'>
	<summary>numBytesInGPUFree returns incorrect values</summary>
	<description>
when checking tf.memory() output while using tfjs-backend-webgl,
numBytesInGPUAllocated behaves as expected and correctly
but numBytesInGPUFree is incorrect:

initial value is not correct (example is from a system with 4GB GPU)
it increases with each inference run instead of decreasing
(since numBytesInGPUAllocated is increasing)

example output of tf.memory():
&lt;denchmark-code&gt;init: {numBytesInGPU: 0, numBytesInGPUAllocated: 0, numBytesInGPUFree: 0, numTensors: 0, …}
loadGraphModel complete: {numBytesInGPU: 0, numBytesInGPUAllocated: 0, numBytesInGPUFree: 0, numTensors: 843, …}
predict: 0 {numBytesInGPU: 146582848, numBytesInGPUAllocated:  990485844, numBytesInGPUFree:  843902996, numTensors: 843, …}
predict: 1 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 1683552696, numBytesInGPUFree: 1536969848, numTensors: 843, …}
predict: 2 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 2178435480, numBytesInGPUFree: 2031852632, numTensors: 843, …}
predict: 3 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 2362804332, numBytesInGPUFree: 2216221484, numTensors: 843, …}
predict: 4 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 2363028292, numBytesInGPUFree: 2216445444, numTensors: 843, …}
predict: 5 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 2623211680, numBytesInGPUFree: 2476628832, numTensors: 843, …}
predict: 6 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 3382406552, numBytesInGPUFree: 3235823704, numTensors: 843, …}
predict: 7 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 3789962920, numBytesInGPUFree: 3643380072, numTensors: 843, …}
predict: 8 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 3992988356, numBytesInGPUFree: 3846405508, numTensors: 843, …}
predict: 9 {numBytesInGPU: 146582848, numBytesInGPUAllocated: 4863173848, numBytesInGPUFree: 4716591000, numTensors: 843, …}
&lt;/denchmark-code&gt;

normally, this would be a cosmetic item, but when running large models it is important to set   WEBGL_DELETE_TEXTURE_THRESHOLD to a sane value to
avoid webgl out-of-memory conditions when running batched jobs.
if numBytesInGPUFree were to be correct, then user could estimate when to
force texture cleanup and dynamically set WEBGL_DELETE_TEXTURE_THRESHOLD
instead of running it at a fixed low value.
#Update: this bug seems to be chrome specific
i've tried with firefox v81 and values seem to match real state - allocated is increasing, free is decreasing and sum of both is near-perfect match for actual gpu memory
environment: tfjs 2.6.0 in ubuntu 20.10 with chrome v86
	</description>
	<comments>
		<comment id='1' author='vladmandic' date='2021-01-20T16:02:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4134&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4134&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>