<bug id='3823' author='vladmandic' open_date='2020-08-18T17:26:02Z' closed_time='2020-08-24T18:21:17Z'>
	<summary>error 'backend' undefined on a single model with tfjs@2.3.0</summary>
	<description>
anyone tried using openimages_v4/ssd/mobilenet_v2 &lt;denchmark-link:https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1&gt;https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1&lt;/denchmark-link&gt;
 model from tfhub and tfjs 2.0+ ?
i've converted it using:
tensorflowjs_converter --input_format tf_hub --output_format tfjs_graph_model --skip_op_check --strip_debug_ops=True --weight_shard_size_bytes 4194304 https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 .
and it works perfectly with tfjs@1.7.4.
but with tfjs@2.3.0, it processes one image just fine and then it fails on the second image with
&lt;denchmark-code&gt;TypeError: Cannot read property 'backend' of undefined
&lt;/denchmark-code&gt;

I've tried ~10 other models, some native tfjs and some converted from tfhub and none have this issue.
	</description>
	<comments>
		<comment id='1' author='vladmandic' date='2020-08-18T20:05:59Z'>
		&lt;denchmark-link:https://github.com/vladmandic&gt;@vladmandic&lt;/denchmark-link&gt;
 I tried this model, but I am having trouble getting it run properly. do you mind sharing a codepen example of this model? Thanks.
		</comment>
		<comment id='2' author='vladmandic' date='2020-08-19T00:56:48Z'>
		
@vladmandic I tried this model, but I am having trouble getting it run properly. do you mind sharing a codepen example of this model? Thanks.

It's a bit long for codepen, but you can see entire source of my project at &lt;denchmark-link:https://github.com/vladmandic/pigallery&gt;https://github.com/vladmandic/pigallery&lt;/denchmark-link&gt;

key code is in function client/modelDetect.js:detectSSD()
model is executed using:
const result = await model.executeAsync({ images: batched }, [  
  'module_apply_default/hub_input/strided_slice_1',  
  'module_apply_default/hub_input/strided_slice_2',  
  'module_apply_default/hub_input/strided_slice'  
]);
where batched is an image buffer cast to float32 and afterwards it's just logic to decode classes and detection boxes.
outputs are arrays of scores, classes, boxes.
classes are in assets/OpenImage-Labels.json
		</comment>
		<comment id='3' author='vladmandic' date='2020-08-20T20:54:36Z'>
		touch more info on the error:
stack trace:
&lt;denchmark-code&gt;Uncaught (in promise) TypeError: Cannot read property 'backend' of undefined
    at Engine.moveData (engine.js:270)
    at DataStorage.get (backend.js:29)
    at MathBackendWebGL.reshape (backend_webgl.js:1729)
    at forward (reshape.js:55)
    at engine.js:465
    at engine.js:308
    at Engine.scopedRun (engine.js:318)
    at Engine.tidy (engine.js:307)
    at kernelFunc (engine.js:465)
    at engine.js:477
&lt;/denchmark-code&gt;

problematic code:
moveData(backend, dataId) {
  const info = this.state.tensorInfo.get(dataId); // this works fine on first execute, but returns undefined second time execute is called
  const srcBackend = info.backend;
  const values = this.readSync(dataId);

dataId is always empty object, so that doesn't change
during first execute, moveData is called 183 times without issues
during second execute, moveData is called 22 times before info becomes undefined
but this.state.tensorInfo looks like a WeakMap with fixed 2890 entries

i've added this debug code after get function:
if (!info) {           
  console.log('dataId', dataId);
  console.log('state', this.state);
  console.log('tensorInfo', this.state.tensorInfo);
  console.log('info', this.state.tensorInfo.get({}))
}
and you can see the output:
&lt;denchmark-code&gt;dataId {}
state EngineState {registeredVariables: {…}, nextTapeNodeId: 0, numBytes: 88874728, numTensors: 1479, numStringTensors: 1, …}
tensorInfo WeakMap {{…} =&gt; {…}, {…} =&gt; {…}, {…} =&gt; {…}, {…} =&gt; {…}, {…} =&gt; {…}, …}
info undefined
&lt;/denchmark-code&gt;

and just to confirm, tf.backend() and tf.getBackend() are valid before and after error (using webgl).
i don't think there is anything wrong with moveData per say, as same this.state.tensorInfo.get(dataId) gets used all over the code
but it does seem that tensor map gets corrupt so getter fails to find value and by it's design it returns undefined
		</comment>
		<comment id='4' author='vladmandic' date='2020-08-23T01:12:00Z'>
		There are no immediate problems I can spot, but there are tensor leaks, added couple dispose calls:
async function detectCOCO(model, image) {
  const imgBuf = tf.browser.fromPixels(image, 3);
  const expanded = tf.expandDims(imgBuf, 0);
  let batched;
  if (!model.config.useFloat) {
    batched = expanded;
  } else {
    const cast = tf.cast(expanded, 'float32');
    batched = tf.mul(cast, [1.0 / 255.0]);
    tf.dispose(cast);
    tf.dispose(expanded);
  }
  const result = await model.executeAsync(batched);
  const [scores, classes] = calculateMaxScores(result);
  const reshaped = tf.tensor2d(result[1].dataSync(), [result[1].shape[1], result[1].shape[3]]);
  tf.dispose(result);
  // const index = tf.image.nonMaxSuppression(reshaped, scores, model.config.topK, model.config.overlap, model.config.score, model.config.softNmsSigma); // async version leaks 2 tensors
  const index = await tf.image.nonMaxSuppressionAsync(reshaped, scores, model.config.topK, model.config.overlap, model.config.score, model.config.softNmsSigma);
  const results = buildDetectedObjects(model, batched, result, scores, classes, index); // disposes of batched, result, index
  tf.dispose(imgBuf);
  tf.dispose(reshaped);
  tf.dispose(index);
  return results;
}
		</comment>
		<comment id='5' author='vladmandic' date='2020-08-23T01:15:53Z'>
		&lt;denchmark-link:https://github.com/vladmandic&gt;@vladmandic&lt;/denchmark-link&gt;
 can you try to disable cpu forwarding through this flag:
tf.env().setFlag('WEBGL_CPU_FORWARD', false);
		</comment>
		<comment id='6' author='vladmandic' date='2020-08-23T02:02:07Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;

FYI, Function used for OpenImages model is detectSSD(), not detectCoco(), but that shouldn't matter.
I've added additional dispose calls in both (except for index as that one is disposed of later in buildDetectedObjects()).
Anyhow, I've tried with tf.ENV.set('WEBGL_CPU_FORWARD', false); - no change, still fails on second image.
Then as a test I've tried disabling anything I could think of:
  tf.ENV.set('WEBGL_BUFFER_SUPPORTED', false);
  tf.ENV.set('WEBGL_CONV_IM2COL', false);
  tf.ENV.set('WEBGL_CPU_FORWARD', false);
  tf.ENV.set('WEBGL_FENCE_API_ENABLED', false);
  tf.ENV.set('WEBGL_FORCE_F16_TEXTURES', false);
  tf.ENV.set('WEBGL_LAZILY_UNPACK', false);
  tf.ENV.set('WEBGL_PACK', false);
  tf.ENV.set('WEBGL_PACK_ARRAY_OPERATIONS', false);
  tf.ENV.set('WEBGL_PACK_BINARY_OPERATIONS', false);
  tf.ENV.set('WEBGL_PACK_CLIP', false);
  tf.ENV.set('WEBGL_PACK_DEPTHWISECONV', false);
  tf.ENV.set('WEBGL_PACK_IMAGE_OPERATIONS', false);
  tf.ENV.set('WEBGL_PACK_UNARY_OPERATIONS', false);
Still no change - fails while processing second image.
And as a last test, I've tried executing two models sequentially in a large loop (CocoSSDv2 and OpenImages) while wrapping execute call in try...catch block.
Well, CocoSSDv2 model continues processing following 100+ images even after OpenImages fails - this shows that actual backend is perfectly fine.
And once OpenImages model fails (always on a second image), there is no way to bring it back to consistent state but to reload from scratch.
		</comment>
		<comment id='7' author='vladmandic' date='2020-08-23T03:54:24Z'>
		This might be an issue with the op implementation that used by OpenImage model, do you mind providing a simple demo that runs this model? I can try to identify the problematic op. thanks
		</comment>
		<comment id='8' author='vladmandic' date='2020-08-23T13:50:14Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;

I've created minimalistic project at &lt;denchmark-link:https://github.com/vladmandic/openimages&gt;https://github.com/vladmandic/openimages&lt;/denchmark-link&gt;

and you can run it directly from git pages &lt;denchmark-link:https://vladmandic.github.io/openimages/&gt;https://vladmandic.github.io/openimages/&lt;/denchmark-link&gt;

(weights and media samples are included and tfjs is loaded from cdnjs so it's 100% self-sufficient)
		</comment>
		<comment id='9' author='vladmandic' date='2020-08-24T17:29:40Z'>
		&lt;denchmark-link:https://github.com/vladmandic&gt;@vladmandic&lt;/denchmark-link&gt;
 Thank you for setting up the demo, I have found the issue, and submit a PR for the fix.
		</comment>
		<comment id='10' author='vladmandic' date='2020-08-24T18:21:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3823&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3823&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='vladmandic' date='2020-08-24T19:35:39Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 Nice &amp; Thank you!
I went to get the diff, but it's already been reviewed and checked into master - impressive.
I've done a checkout and clean build and can confirm that it works perfectly!
I'm closing this issue.
		</comment>
	</comments>
</bug>