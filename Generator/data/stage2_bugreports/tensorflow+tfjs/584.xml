<bug id='584' author='justadudewhohacks' open_date='2018-08-07T07:51:15Z' closed_time='2018-10-24T20:35:11Z'>
	<summary>optimizer.minimize + tf.maximum breaks tf.memory().numBytes counter</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;


tfjs-core 0.11.9
tfjs-core 0.12.9

&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;


chrome 67.0.3396.99 (64-Bit)
firefox 61.0.1 (64-Bit)

&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

There seems to be some memory leak in optimizer.minimize, no matter if I use adam or sgd:
const loss = optimizer.minimize(() =&gt; {
  const outTensor = window.net.forwardInput(batchInput, inputSize)
  return tf.sum(outTensor)
}, true)

loss.dispose()
await tf.nextFrame()
console.log(tf.memory())
After some time, chrome memory usage grows higher than multiple GB. Logging tf.memory() furthermore reveals some strange decrementing of numBytes (tracked memory of tensors in RAM I guess?):
&lt;denchmark-link:https://user-images.githubusercontent.com/31125521/43761371-36539208-9a25-11e8-9180-be42a2afc3f7.png&gt;&lt;/denchmark-link&gt;

Just to point out, the leak isn't occuring due to net.forwardInput or tf.sum, since the following code runs without any leaks:
const outTensor = window.net.forwardInput(batchInput, inputSize)
const sum = tf.sum(outTensor)
outTensor.dispose()
sum.dispose()
await tf.nextFrame()
console.log(tf.memory())
&lt;denchmark-link:https://user-images.githubusercontent.com/31125521/43761580-cd038546-9a25-11e8-8080-8aba8790700a.png&gt;&lt;/denchmark-link&gt;

Edit.:
Some more clarification: The net is a combination of separableConv2d's + max pooling ops, with a single 1x1 convolution at the end. The output of net.forwardInput in the example is a 1x13x13x25 tensor.
It might be, that the issue is due to backpropagation through separableConv2d's.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

I also ran the abovementioned example with a different net, which consists of conv2d's + max pooling ops, producing a 1x136 output tensor, coming up with different results for tfjs-core 0.11.9 and tfjs-core 0.12.9, running the exact same code:
tfjs-core 0.11.9: works fine, without any leaks
tfjs-core 0.12.9: crashes in the first iteration causing chromes memory to quickly rise above 3GB
	</description>
	<comments>
		<comment id='1' author='justadudewhohacks' date='2018-08-10T15:09:01Z'>
		Thanks for investigating this. Is there a chance you could share your repo with us? In the meantime, I'll try to reproduce this based on your pointers.
		</comment>
		<comment id='2' author='justadudewhohacks' date='2018-08-10T17:53:39Z'>
		Not sure if it helps, but here is the &lt;denchmark-link:https://github.com/justadudewhohacks/face-api.js/tree/tiny-yolov2-seperable-conv2d&gt;tiny-yolov2-seperable-conv2d&lt;/denchmark-link&gt;
 branch I am currently working on, which is where I am facing the issue.
Basically the first issue occurs when backpropagating through the tiny yolov2 implementation with separable convolutions. The code for training is under /tools/train/tinyYolov2.
The second issue occurs when backpropagating through the face landmark net (/tools/train/faceLandmarks).
I will try to come up with a repo with some simpler example code to reproduce the issue, as soon as I have time, which might be simpler to debug.
		</comment>
		<comment id='3' author='justadudewhohacks' date='2018-08-11T16:49:51Z'>
		Okay after setting up an example repo to reproduce the issue, I figured out, that the issue is not related to tf.separableConv2d, but it's caused by tf.maximum.
Example repo is &lt;denchmark-link:https://github.com/justadudewhohacks/tfjs-maximum-backprop-memoryleak-issue&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='justadudewhohacks' date='2018-08-13T16:02:41Z'>
		Okay after spending some more time on this problem I figured out, that using tf.maximum only messes with the numBytes counter, as shown in the screenshot. Apparently it doesn't cause the memory leak that I am facing.
I found what's causing the memory leak and opened a seperate issue for that: &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/604&gt;#604&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='justadudewhohacks' date='2018-10-24T20:35:11Z'>
		Closing since this got fixed.
		</comment>
	</comments>
</bug>