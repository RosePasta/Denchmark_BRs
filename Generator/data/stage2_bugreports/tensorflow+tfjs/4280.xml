<bug id='4280' author='ColinPeppler' open_date='2020-11-20T00:47:38Z' closed_time='2020-12-02T02:30:29Z'>
	<summary>model.save(url) | ValueError: Cannot find any save handlers for URL</summary>
	<description>
System information

OS Platform: Mac OSX 10.14.6
tfjs: 2.7
tfjs-node: 2.7

Standalone code to reproduce the issue
&lt;denchmark-code&gt;const serverAddr = "http://localhost:5001"
model = await tf.loadLayersModel(serverAddr + '/get-model')
model.compile({
    optimizer: tf.train.adam(),
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy']
  });
model.train(...)
await model.save(serverAddr + '/upload-model')    // ValueError occurs
&lt;/denchmark-code&gt;

A flask server is setup with endpoints /get-model and /upload-model. The /get-model endpoint provides an appropriate json, and so the model compile and trains properly. However, when trying to save the model to my Flask server, I receive the following error.
ValueError: Cannot find any save handlers for URL 'http://localhost:5001/upload-model' at new ValueError (/Users/colinpeppler/tfplayground/node_modules/@tensorflow/tfjs-layers/dist/tf-layers.node.js:186:28).
Running the code on the browser works good when saving to the url. I also tried saving to the filesystem and that worked fine, but the HTTP request method doesn't work with node.
	</description>
	<comments>
		<comment id='1' author='ColinPeppler' date='2020-11-20T20:29:49Z'>
		cc &lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;
 there is a similar issue for saving in file system that got resolved &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/723&gt;here&lt;/denchmark-link&gt;
. seems to be bug in tfjs-layers
		</comment>
		<comment id='2' author='ColinPeppler' date='2020-11-24T22:57:15Z'>
		A workaround in the meantime is to use &lt;denchmark-link:https://js.tensorflow.org/api/latest/#io.http&gt;https://js.tensorflow.org/api/latest/#io.http&lt;/denchmark-link&gt;
 directly and pass that to tf.loadLayersModel.
		</comment>
		<comment id='3' author='ColinPeppler' date='2020-12-02T02:30:29Z'>
		I ended up just saving the model to the file directory and creating a request with multipart/form-data encoding. See &lt;denchmark-link:https://www.tensorflow.org/js/guide/save_load#https_request&gt;this&lt;/denchmark-link&gt;
for how tfjs constructs the request's body.
		</comment>
		<comment id='4' author='ColinPeppler' date='2020-12-02T02:30:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4280&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4280&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>