<bug id='834' author='annxingyuan' open_date='2018-10-25T11:23:33Z' closed_time='2018-11-08T20:51:22Z'>
	<summary>Unpacking after reshaping can cause inaccurate packed sampling</summary>
	<description>
cc &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;

This bug was introduced by &lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1329&gt;tensorflow/tfjs-core#1329&lt;/denchmark-link&gt;

We impose a constraint on packed texels that they may contain only adjacent rows / columns from the same batch. This means if we reshape a tensor backed by a packed texture, we may also need to rearrange the values within the texture so that the constraint is maintained. For example, if we reshape a tensor from [9, 1] to [3, 3, 1], the texture grows from 5 texels to 6 texels:
[9, 1] vs [3, 3, 1]:
&lt;denchmark-code&gt;0|x          0|x
---          ---
1|x          1|x

2|x          2|x
---          ---
3|x          x|x

4|x          3|x
---          ---
5|x          4|x

6|x          5|x
---          ---
7|x          x|x

8|x          6|x
---          ---
x|x          7|x
               
             8|x
             ---
             x|x
&lt;/denchmark-code&gt;

Otherwise, the unpack shader has the wrong idea about how to sample its input (in this case, it thinks that the number of rows in the texture is 10, when it should be 12). This causes inaccurate values to be passed to the subsequent op, which was caught by several  tests: &lt;denchmark-link:https://github.com/tensorflow/tfjs-layers/blob/master/src/layers/convolutional_test.ts#L823&gt;https://github.com/tensorflow/tfjs-layers/blob/master/src/layers/convolutional_test.ts#L823&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='annxingyuan' date='2018-10-26T19:40:56Z'>
		Expensive reshapes are ones that require changing the texture layout. In theory we can't say whether 1x4 or 2x2 packing causes fewer expensive reshapes, because some reshapes are expensive for 2x2 and free for 1x4, and vice versa (e.g. [3, 2, 4] --&gt; [12, 2] is expensive for 1x4 packing, but free for 2x2 packing). However for the models I looked at 1x4 packing causes fewer expensive reshapes:
&lt;denchmark-h:h3&gt;MobileNet v2&lt;/denchmark-h&gt;

total reshapes: 367
expensive reshapes (2x2): 16
expensive reshapes (1x4): 0
&lt;denchmark-h:h3&gt;MobileNet v1&lt;/denchmark-h&gt;

total reshapes: 162
expensive reshapes (2x2): 4
expensive reshapes (1x4): 0
&lt;denchmark-h:h3&gt;COCO SSD&lt;/denchmark-h&gt;

total reshapes: 1010
expensive reshapes (2x2): 203
expensive reshapes (1x4): 126
&lt;denchmark-h:h3&gt;PoseNet&lt;/denchmark-h&gt;

total reshapes: 215
expensive reshapes (2x2): 34
expensive reshapes (1x4): 0
&lt;denchmark-h:h2&gt;Notes&lt;/denchmark-h&gt;

For MobileNet v1 and v2, all but one of the expensive reshapes are caused by going back and forth between matMul reshaping its input to 2D and batchNormalization reshaping its input to 4D ([1, 7, 7, 160] &lt;--&gt; [49, 160]). For COCO SSD, ~75% of the expensive reshapes are [1917, 1] &lt;--&gt; [1917] for the greater op.
cc &lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>