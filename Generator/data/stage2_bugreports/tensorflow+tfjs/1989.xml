<bug id='1989' author='rohanmuplara' open_date='2019-09-06T07:24:20Z' closed_time='2019-10-08T18:14:40Z'>
	<summary>Randomly cropping and resizing array is super slow</summary>
	<description>
To get help from the community, we encourage using Stack Overflow and the &lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow.js&gt;tensorflow.js&lt;/denchmark-link&gt;
 tag.
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

"@tensorflow/tfjs": "^1.2.7"
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

Version 76.0.3809.132 (
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

I have one network that takes in the webcam that identifies the face. I then take this detection box and slice it from the webcam video, resize the slice to 224, and then pass it into to another network. I have found that this slicing is extremely slow and is actually slower then running the second model. . The slicing is only slow when the detection box changes. If the detection box is kept constant,  the slicing is extremely quick.  However, my use case requires the detection box to keep changing.
In summary, if  I slice an tensor with different sizes every iteration, it is extremely slow.  I tried to create the simplest code possible below to illustrate the problem. Any suggestions or quick workarounds would be appreciated.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

let totalTime = 0.0;
for (let i = 0; i &lt; numSamples; i++) {
tf.tidy(() =&gt; {
const sampleImage = tf.randomNormal([ 700, 1280, 3])
let sliceStart = [5, 10];
let sliceSize = [100, 200];
if (i % 2 === 0) {
sliceSize = [Math.round(100 * Math.random()), Math.round(200 * Math.random())];
}
console.log("the slice size is", sliceSize)
const startTime = performance.now();
let sliceImage = tf.slice(sampleImage, sliceStart, sliceSize);
sliceImage.dataSync();
const endTime = performance.now();
let difference = endTime - startTime;
console.log("the difference is" + difference);
totalTime += difference;
})
}
	</description>
	<comments>
		<comment id='1' author='rohanmuplara' date='2019-09-06T21:02:09Z'>
		I am not sure but is related to this issue &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/604&gt;#604&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='rohanmuplara' date='2019-09-06T22:54:25Z'>
		&lt;denchmark-link:https://github.com/rohanmuplara&gt;@rohanmuplara&lt;/denchmark-link&gt;
 if you are cropping and resizing image from webcam, you can try &lt;denchmark-link:https://js.tensorflow.org/api/latest/#image.cropAndResize&gt;tf.image.cropAndResize&lt;/denchmark-link&gt;
. It is optimized for image cropping on GPU.
		</comment>
		<comment id='3' author='rohanmuplara' date='2019-09-06T22:57:56Z'>
		&lt;denchmark-link:https://github.com/kangyizhang&gt;@kangyizhang&lt;/denchmark-link&gt;
 I missed that. I didn't not this was also supported in tensorflow.js. I will try it and let you know.
Thanks,
Rohan
		</comment>
		<comment id='4' author='rohanmuplara' date='2019-09-06T23:28:19Z'>
		&lt;denchmark-link:https://github.com/kangyizhang&gt;@kangyizhang&lt;/denchmark-link&gt;
. I tried image cropping and it definitely reduce the variability from cropping random sizes. However, it is still quite slow compared to the rest of the net. The code below just crops and resizes bounding boxes.  This is taking me about 50 ms on a macbook pro in chrome.
let totalTime = 0.0;
for (let i = 0; i &lt; numSamples; i++) {
tf.tidy(() =&gt; {
const sampleImage = tf.zeros([1,  700, 1280, 3])
const startTime = performance.now();
let resultingImage = tf.image.cropAndResize(sampleImage,[[0.1, 0.1, 0.15, 0.15]], [0], [224, 224])
resultingImage.dataSync();
const endTime = performance.now();
let difference = endTime - startTime;
console.log("the difference is" + difference);
totalTime += difference;
})
}
		</comment>
		<comment id='8' author='rohanmuplara' date='2019-09-07T19:30:13Z'>
		Sorry &lt;denchmark-link:https://github.com/OVERSTANDING683&gt;@OVERSTANDING683&lt;/denchmark-link&gt;
 isn't 1989 this issue. I am very confused what you are saying.
		</comment>
		<comment id='9' author='rohanmuplara' date='2019-09-10T21:03:52Z'>
		&lt;denchmark-link:https://github.com/kangyizhang&gt;@kangyizhang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/rthadur&gt;@rthadur&lt;/denchmark-link&gt;

Any updates
		</comment>
		<comment id='10' author='rohanmuplara' date='2019-09-11T13:29:46Z'>
		&lt;denchmark-link:https://github.com/rohanmuplara&gt;@rohanmuplara&lt;/denchmark-link&gt;
 if the sizes are truly random you might always see some slowness due to the need to create new textures, and gpu programs (whereas we are able to cache quite a few things for tensors with the same shape). If you have a large number of different sizes (but not completely random) you can warm up the cache by doing inferences with those different shapes beforehand.
		</comment>
		<comment id='11' author='rohanmuplara' date='2019-10-08T18:14:40Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>