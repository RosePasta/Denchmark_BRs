<bug id='1093' author='rix0rrr' open_date='2019-01-15T08:06:10Z' closed_time='2020-04-13T16:43:29Z'>
	<summary>ReLU and LeakyReLU activations cannot be saved/loaded from model.json</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;    "@tensorflow/tfjs-node": "^0.2.1",
@tensorflow/tfjs-layers:   "version": "0.9.1"
@tensorflow/tfjs-core:   "version": "0.14.2"
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

I've tried building a model with leaky relu activation functions. I must spell this as:
&lt;denchmark-code&gt;                    tf.layers.dense({
                        units: 100,
                        activation: 'LeakyReLU',
                    }),
&lt;/denchmark-code&gt;

Otherwise it will not be picked up. When I save the model (using model.save()) the activation function gets serialized to model.json as "leaky_re_lu".
When I try to read the model again, I get an error that this activation function is not supported,but it's shown with a different case, showing "leakyReLu":
&lt;denchmark-code&gt;Unknown activation: leakyReLu. This may be due to one of the following reasons:
1. The activation is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom activation is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().
Creating new model.
&lt;/denchmark-code&gt;

Same happens if I specify "ReLU" as my activation function (but not if I specify "relu").
&lt;denchmark-h:h3&gt;Expectation&lt;/denchmark-h&gt;

I would expect that if my model successfully creates, I can save and load it as well.
	</description>
	<comments>
		<comment id='1' author='rix0rrr' date='2019-01-16T21:51:04Z'>
		&lt;denchmark-link:https://github.com/rix0rrr&gt;@rix0rrr&lt;/denchmark-link&gt;
  Looks like we have a serialization_utils problem.  Thanks for filing!
Looks like leakyReLU might need to be special cased.
&lt;denchmark-link:https://github.com/tensorflow/tfjs-layers/blob/11565ae1ff556bad97332fe11a64101303e5ebfd/src/utils/serialization_utils.ts#L44&gt;https://github.com/tensorflow/tfjs-layers/blob/11565ae1ff556bad97332fe11a64101303e5ebfd/src/utils/serialization_utils.ts#L44&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tfjs-layers/blob/3d7d0d5ccf74b88960fcac461b7f885e2ba660fd/src/utils/generic_utils.ts#L122&gt;https://github.com/tensorflow/tfjs-layers/blob/3d7d0d5ccf74b88960fcac461b7f885e2ba660fd/src/utils/generic_utils.ts#L122&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='rix0rrr' date='2019-01-27T23:05:46Z'>
		&lt;denchmark-link:https://github.com/rix0rrr&gt;@rix0rrr&lt;/denchmark-link&gt;
 Thanks for reporting this issue. As we investigate and fix this issue, you can use the following workaround to make a model with a LeakyReLU activation that can be saved and loaded (i.e., add the LeakyReLU activation as a separate layer, instead of a part of the dense layer):
    const model1 = tf.sequential();
    model1.add(tf.layers.dense({
      units: 100,
      inputShape: [200]
    }));
    model1.add(tf.layers.leakyReLU());  // Use the leakyReLU function under `tf.layers`.
		</comment>
		<comment id='3' author='rix0rrr' date='2020-03-31T15:29:07Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 Any progress so far?
		</comment>
		<comment id='4' author='rix0rrr' date='2020-04-10T10:35:56Z'>
		&lt;denchmark-link:https://github.com/lina128&gt;@lina128&lt;/denchmark-link&gt;
 can you help here? Or will you accept pull request for this particular issue?
		</comment>
		<comment id='5' author='rix0rrr' date='2020-04-10T18:04:48Z'>
		Hi &lt;denchmark-link:https://github.com/obenjiro&gt;@obenjiro&lt;/denchmark-link&gt;
, I see discussion in &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/918&gt;#918&lt;/denchmark-link&gt;
, reference &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 reply: "I'm pretty sure that 'leakyrelu' is not supported as a string activation even in Python Keras. It's accessible via tf.layers.* though." In this case, I think the workaround that &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 suggested is the solution for now, unless keras change this behavior in the future. We are trying to have feature parity with keras. Does this solution solve your problem?
		</comment>
		<comment id='6' author='rix0rrr' date='2020-04-13T08:38:01Z'>
		&lt;denchmark-link:https://github.com/lina128&gt;@lina128&lt;/denchmark-link&gt;
 Thank you! I didn't know about feature parity with Keras. I think we can close this issue then.
		</comment>
	</comments>
</bug>