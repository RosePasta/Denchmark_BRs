<bug id='4424' author='zholmes1' open_date='2020-12-17T21:20:51Z' closed_time='2021-01-05T16:41:09Z'>
	<summary>[TypeError: img.toFloat is not a function] When passing an image from decodeJpeg (tfjs-react-native) into model.classify (tfjs-auto-ml)</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow.js): Yes
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All mobile devices
TensorFlow.js installed from (npm or script link): npm
TensorFlow.js version (use command below): 2.7.0
tfjs-react-native 0.5.0
tfjs-automl: 1.0.0

Describe the current behavior
I can get the image from the react native file system (using expo-file-system), convert it from base64 to array buffer, decode it (with tfjs-react-native), but once I pass it to my ImageClassificationModel from tfjs-automl, it gives me the error. It seems like the object returned from decodeJpeg (tfjs-rn) doesn't have a method toFloat that ImageClassificationModel.classify expects it to have for preprocessing.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/CodePen/any notebook.
&lt;denchmark-code&gt;  const base64 = await ExpoFileSystem.readAsStringAsync(imageUri, {
    encoding: 'base64'
  })

  const raw = Uint8Array.from(toByteArray(base64)) // toByteArray is from npm package 'base64-js'

  const imageTensor = decodeJpeg(raw) // decodeJpeg is from tfjs-rn
  const predictions = await model.classify(imageTensor) // ImageClassificationModel from tfjs-automl
&lt;/denchmark-code&gt;

Here's how I create my ImageClassificationModel, if it's relevant. I'm using expo to grab the asset txt as a string, then I pass it along with my asset ids for my model.json and my model_weights.bin. I'm using metro bundler properly to make sure that the extensions .txt. and .bin are bundled.
&lt;denchmark-code&gt;async function loadModel(dictId: number, modelJsonId: any, weightsId: number) {
  const [dictAsset] = await Asset.loadAsync(dictId)
  const dictRaw = await ExpoFileSystem.readAsStringAsync(dictAsset.localUri)
  const dict = dictRaw.trim().split('\n')
  const model = await loadGraphModel(bundleResourceIO(modelJsonId, weightsId))
  return new ImageClassificationModel(model, dict)
}
&lt;/denchmark-code&gt;

Here's what I get when I log the imageTensor object. This is supposed to be of type Tensor.
{"dataId": {}, "dtype": "int32", "id": 324, "isDisposedInternal": false, "kept": false, "rankType": "3", "shape": [224, 126, 3], "size": 84672, "strides": [378, 3]}
I can definitely see why this is crashing. ImageClassificationModel from automl wants to call toFloat() on this Tensor as part of preprocessing before classification.
	</description>
	<comments>
		<comment id='1' author='zholmes1' date='2020-12-17T22:20:46Z'>
		Hi. Just to confirm something, do you get the same error if you manually call .toFloat() on the tensor after this line
&lt;denchmark-code&gt;const imageTensor = decodeJpeg(raw) // decodeJpeg is from tfjs-rn
// add 
const asFloat = imageTensor.toFloat();
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='zholmes1' date='2020-12-17T22:27:59Z'>
		Same error.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Dec 17, 2020, 4:21 PM Yannick Assogba ***@***.***&gt; wrote:
 Hi. Just to confirm something, do you get the same error if you manually
 call .toFloat() on the tensor after this line

 const imageTensor = decodeJpeg(raw) // decodeJpeg is from tfjs-rn
 // add
 const asFloat = imageTensor.toFloat();

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 &lt;#4424 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2ARQV5L5QNRXEMKB56LULSVJ74ZANCNFSM4VAIICDQ&gt;
 .



		</comment>
		<comment id='3' author='zholmes1' date='2020-12-17T22:32:51Z'>
		Thanks I'm going to try and reproduce this (if you have a link to a github repo that reproduces the error that would be helpful), a potential temporary workaround to try. Could you add:
import '@tensorflow/tfjs-core/dist/public/chained_ops/to_float';
To the imports list for that file and give it a try?
		</comment>
		<comment id='4' author='zholmes1' date='2020-12-17T22:47:29Z'>
		&lt;denchmark-link:https://github.com/tafsiri&gt;@tafsiri&lt;/denchmark-link&gt;

You're the man! It was a little deeper than just to_float, but I was able to follow the trail and get everything imported.
&lt;denchmark-code&gt;import '@tensorflow/tfjs-core/dist/public/chained_ops/to_float'
import '@tensorflow/tfjs-core/dist/public/chained_ops/expand_dims'
import '@tensorflow/tfjs-core/dist/public/chained_ops/div'
import '@tensorflow/tfjs-core/dist/public/chained_ops/sub'
import '@tensorflow/tfjs-core/dist/public/chained_ops/squeeze'
import '@tensorflow/tfjs-core/dist/public/chained_ops/reshape'
import '@tensorflow/tfjs-core/dist/public/chained_ops/as2d'
&lt;/denchmark-code&gt;

I know the way that I'm doing things may be a bit abnormal, so many I'm skipping some step where all those files would be imported.
My general flow is:

Load models (json/weights/dict) from RN bundle
Create graph models with loadGraphModel
Pass the graphModel and my parsed dictionary.txt over to new ImageClassificationModel

		</comment>
		<comment id='5' author='zholmes1' date='2020-12-17T22:51:21Z'>
		Oh actually your response gives me an idea, can you post all your other tfjs related imports? Do you have an import * as tfjs from '@tensorflow/tfjs' or import '@tensorflow/tfjs', import '@tensorflow/tfjs-core' in there somewhere?
		</comment>
		<comment id='6' author='zholmes1' date='2020-12-17T23:10:22Z'>
		I haven't been able to reproduce this so if you have a minimal repro in a github repo i wouldn't mind taking a look. You shouldn't need to import those files manually (assuming you have one of the imports in my prev message above), unless something funky is going on with the build/bundling/js optimization step.
Glad the workaround unblocks you, you can shorten the imports by replacing those individual op imports with.
import '@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops'
		</comment>
		<comment id='7' author='zholmes1' date='2020-12-18T02:40:01Z'>
		Thanks for the help. I just got off a flight. I'll mess around with it a
bit tomorrow and I'll see if I can isolate exactly why it's happening. It's
possible that I had a * import that got replaced with a named import.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Dec 17, 2020, 4:10 PM Yannick Assogba ***@***.***&gt; wrote:
 I haven't been able to reproduce this so if you have a minimal repro in a
 github repo i wouldn't mind taking a look. You shouldn't *need* to import
 those files manually (assuming you have one of the imports in my prev
 message above), unless something funky is going on with the
 build/bundling/js optimization step.

 Glad the workaround unblocks you, you can shorten the imports by replacing
 those individual op imports with.

 import
 ***@***.***/tfjs-core/dist/public/chained_ops/register_all_chained_ops'

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 &lt;#4424 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AA2ARQWFLUM32AGM6EMOBW3SVKFWXANCNFSM4VAIICDQ&gt;
 .



		</comment>
		<comment id='8' author='zholmes1' date='2021-01-04T14:30:25Z'>
		Switching from import { loadGraphModel } from '@tensorflow/tfjs' to import * as tf from '@tensorflow/tfjs'/tf.loadGraphModel allowed me to remove the all chained ops script.
		</comment>
		<comment id='9' author='zholmes1' date='2021-01-05T16:51:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4424&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/4424&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>