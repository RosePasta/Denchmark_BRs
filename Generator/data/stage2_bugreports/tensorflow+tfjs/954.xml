<bug id='954' author='suyash' open_date='2018-11-29T20:38:56Z' closed_time='2019-01-15T03:02:11Z'>
	<summary>Unable to execute a converted model with tf.nn.dynamic_rnn layer</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.13.5
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

Chrome Latest
Firefox Latest
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

Creating a basic model with tf.nn.dynamic_rnn layer and converting it to browser loads the model in the browser perfectly, but on calling model.executeAsync fails. Please see the screenshot below.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

Training
import numpy as np
import tensorflow as tf

def model_fn(features, labels, mode, params):
    if isinstance(features, dict):
        features = features["input_text"]

    embeddings = tf.contrib.layers.embed_sequence(features, vocab_size=1000, embed_dim=16)

    forward_cell = tf.nn.rnn_cell.GRUCell(16)
    output, _ = tf.nn.dynamic_rnn(forward_cell, embeddings, dtype=tf.float32)

    output = tf.reduce_sum(output, axis=1)
    
    logits = tf.layers.dense(output, 1, activation=None)
    predictions = tf.nn.sigmoid(logits, name="predictions")

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(
            mode=mode,
            predictions={
                "predictions": predictions,
            },
        )

    loss = tf.losses.sigmoid_cross_entropy(labels, logits)
        
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
    
    return tf.estimator.EstimatorSpec(
        mode=mode, 
        loss=loss, 
        eval_metric_ops={
            "accuracy": tf.metrics.accuracy(labels=labels, predictions=tf.round(predictions)),
        },
    )

runConfig = tf.estimator.RunConfig(model_dir="training", save_checkpoints_secs=60)
estimator = tf.estimator.Estimator(model_fn, config=runConfig)

data = tf.data.Dataset.from_tensors((
    np.random.randint(0, 999, (8, 8)), 
    np.random.randint(0, 1, (8, 1)),
))
estimator.train(lambda: data.make_one_shot_iterator().get_next())

serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({ 
    "input_text": tf.placeholder(dtype=tf.int32, shape=[None, 8]),
})
estimator.export_saved_model("saved", serving_input_receiver_fn)
then, convert
&lt;denchmark-code&gt;pipenv run tensorflowjs_converter \
    --input_format=tf_saved_model \
    --output_node_names='predictions' \
    --saved_model_tags=serve \
    ./saved/1543520745 \
    ./web
&lt;/denchmark-code&gt;

then, load
&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt;
    &lt;title&gt;Document&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.13.5"&gt;&lt;/script&gt;
    &lt;script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@0.7.0"&gt;&lt;/script&gt;
    &lt;script&gt;
        window.addEventListener("DOMContentLoaded", main);

        const MODEL_URL = "./web/tensorflowjs_model.pb";
        const WEIGHTS_URL = "./web/weights_manifest.json";

        async function main() {
            const model = await tf.loadFrozenModel(MODEL_URL, WEIGHTS_URL);
            console.log(model);

            const input = new Array(8).fill(1);

            const output = await model.executeAsync(tf.tensor2d([input], [1, 8], "int32"));
            console.log(output);
        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
fails with
&lt;denchmark-link:https://user-images.githubusercontent.com/16324837/49250345-97691580-f444-11e8-8ecb-95ec33f1d93d.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='suyash' date='2018-11-30T05:08:47Z'>
		Also, replacing tf.contrib.rnn.stack_bidirectional_dynamic_rnn with tf.contrib.rnn.stack_bidirectional_rnn and calling model.execute instead of model.executeAsync results in the same error
EDIT: I cannot get a demo working with tf.nn.dynamic_rnn layer in general, have modified the title and the reproduction code to reflect that
		</comment>
		<comment id='2' author='suyash' date='2018-12-01T02:04:05Z'>
		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 looks like our gather op is failing on following inputs
const x = tf.zeros([1000, 16]);
const indices = tf.ones([1, 8]);
x.gather(indices).print();
In tensorflow, the output is tensor with shape = [1, 8, 16]
		</comment>
		<comment id='3' author='suyash' date='2018-12-03T18:16:39Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 I'm pretty busy right now would this be something you'd be willing to take a look at?
		</comment>
		<comment id='4' author='suyash' date='2019-01-14T19:55:49Z'>
		&lt;denchmark-link:https://github.com/suyash&gt;@suyash&lt;/denchmark-link&gt;
 can you try again, with the support of high rank indices for gapther op, your model should work now.
		</comment>
		<comment id='5' author='suyash' date='2019-01-15T03:02:11Z'>
		&lt;denchmark-link:https://github.com/pyu10055&gt;@pyu10055&lt;/denchmark-link&gt;
 I have verified this to work on the given test case as well as for a model with  by building both core and tfjs from source. Looking forward to the next release.
		</comment>
	</comments>
</bug>