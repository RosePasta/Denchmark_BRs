<bug id='858' author='caisq' open_date='2018-10-29T21:20:58Z' closed_time='2018-10-30T14:34:52Z'>
	<summary>Stateful RNN: past states should not be kept under inference (non-training) mode</summary>
	<description>
Currently past states are always kept, which leads to increasing memory consumption during repeated inference (predict()) calls. This can be worked around by calling resetStates(). However, if the training arg is null or false, the past states should not be kept anyway. The current behavior doesn't match the behavior of Python keras/tf.keras.
	</description>
	<comments>
	</comments>
</bug>