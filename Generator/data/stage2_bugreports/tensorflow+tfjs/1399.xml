<bug id='1399' author='josei' open_date='2019-03-18T14:24:21Z' closed_time='2019-03-19T15:04:55Z'>
	<summary>Document Layer.apply() kwargs options</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

tfjs-core-0.15.2
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

When building a Layers model with a preLU, reLU, or leakyReLU layer, optimizing using the core API throws an error.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

Here's the code that builds a simple Layers model with an activation function. Using ELU as activation function throws no error (having no activation function works fine, as well). On the contrary, PreLU, reLU, and leakyReLU fail.
&lt;denchmark-code&gt;const tf =  require('@tensorflow/tfjs-node');
const model = tf.sequential();
model.add(tf.layers.dense({ inputDim: 1, units: 1 }));
model.add(tf.layers.leakyReLU()); // Fails
// model.add(tf.layers.prelu()); // Fails
// model.add(tf.layers.reLU()); // Fails
// model.add(tf.layers.elu()); // Works

const xs = tf.tensor2d([[Math.random()], [Math.random()]]);
const ys = tf.tensor2d([[Math.random() + 10], [Math.random() + 10]]);
tf.train.sgd(0.1).minimize(() =&gt; model.apply(xs).sub(ys).square().mean());
&lt;/denchmark-code&gt;

Output when using prelu:
&lt;denchmark-code&gt;2019-03-18 15:00:36.251109: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:107
            throw ex;
            ^

Error: Tensor is disposed.
    at Tensor.throwIfDisposed (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tensor.js:284:19)
    at Tensor.greater (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tensor.js:585:14)
    at grad (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js:59:23)
    at Object.tapeNode.gradient (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:144:45)
    at _loop_1 (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tape.js:84:35)
    at Object.backpropagateGradients (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tape.js:112:9)
    at /home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:363:20
    at /home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:91:22
    at Engine.scopedRun (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:101:23)
    at Engine.tidy (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:90:21)
&lt;/denchmark-code&gt;

Output when using reLU:
&lt;denchmark-code&gt;2019-03-18 15:02:00.429530: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:107
            throw ex;
            ^

Error: Tensor is disposed.
    at Tensor.throwIfDisposed (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tensor.js:284:19)
    at Tensor.step (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tensor.js:775:14)
    at grad (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js:17:26)
    at Object.tapeNode.gradient (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:144:45)
    at _loop_1 (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tape.js:84:35)
    at Object.backpropagateGradients (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tape.js:112:9)
    at /home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:363:20
    at /home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:91:22
    at Engine.scopedRun (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:101:23)
    at Engine.tidy (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:90:21)
&lt;/denchmark-code&gt;

Output when using leakyReLU:
&lt;denchmark-code&gt;/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:107
            throw ex;
            ^

TypeError: Cannot read property 'values' of undefined
    at NodeJSKernelBackend.getInputTensorIds (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-node/dist/nodejs_kernel_backend.js:142:26)
    at NodeJSKernelBackend.executeSingleOutput (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-node/dist/nodejs_kernel_backend.js:186:73)
    at NodeJSKernelBackend.greaterEqual (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-node/dist/nodejs_kernel_backend.js:429:21)
    at environment_1.ENV.engine.runKernel.$a (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/ops/compare.js:89:83)
    at /home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:129:26
    at Engine.scopedRun (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:101:23)
    at Engine.runKernel (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/engine.js:127:14)
    at greaterEqual_ (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/ops/compare.js:89:37)
    at Object.greaterEqual (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/ops/operation.js:23:29)
    at Tensor.greaterEqual (/home/ubuntu/issue/node_modules/@tensorflow/tfjs-core/dist/tensor.js:594:26)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='josei' date='2019-03-19T03:29:08Z'>
		Confirmed in tfjs 1.0.0 (in the browser, so this is not specific to node).
&lt;denchmark-link:https://github.com/dsmilkov&gt;@dsmilkov&lt;/denchmark-link&gt;
, might the tensors disposed issues already be addressed in &lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1604&gt;tensorflow/tfjs-core/pull/1604&lt;/denchmark-link&gt;
?
Also, this seems possibly related: &lt;denchmark-link:https://stackoverflow.com/questions/55151317/why-do-i-receive-the-error-tensor-is-disposed-when-using-tf-grad-to-implemen&gt;https://stackoverflow.com/questions/55151317/why-do-i-receive-the-error-tensor-is-disposed-when-using-tf-grad-to-implemen&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='josei' date='2019-03-19T03:48:29Z'>
		&lt;denchmark-link:https://github.com/josei&gt;@josei&lt;/denchmark-link&gt;
 This should fix your problem: . I.e., adding the training kwarg with  value .
		</comment>
		<comment id='3' author='josei' date='2019-03-19T04:42:24Z'>
		Thanks &lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
!  That led to the answer to the linked SO post, too.
It seems we should document the available  at &lt;denchmark-link:https://js.tensorflow.org/api/latest/#tf.layers.Layer.apply&gt;https://js.tensorflow.org/api/latest/#tf.layers.Layer.apply&lt;/denchmark-link&gt;
.  The docstring refers to , which is not part of the documented API.
		</comment>
		<comment id='4' author='josei' date='2019-03-19T14:54:22Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 Does Python Keras have  as an argument when calling a layer functionally, or is this specific to TF.js? If specific to TF.js, curious when did this option to  got added? Thanks!
		</comment>
		<comment id='5' author='josei' date='2019-03-19T15:04:55Z'>
		I just manually verified that this is fixed in &lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1604&gt;tensorflow/tfjs-core#1604&lt;/denchmark-link&gt;
 which will come in the next release  by end of week.
This means you don't need to pass {training: true} in the next release.
Thanks for the feedback and the great bug reproduce &lt;denchmark-link:https://github.com/josei&gt;@josei&lt;/denchmark-link&gt;
 !
		</comment>
	</comments>
</bug>