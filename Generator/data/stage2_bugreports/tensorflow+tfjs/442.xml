<bug id='442' author='bileschi' open_date='2018-06-18T17:28:52Z' closed_time='2018-07-30T22:55:45Z'>
	<summary>JS tf.oneHot disagrees with PY tf.oneHot on NaN input</summary>
	<description>
To get help from the community, check out our &lt;denchmark-link:https://groups.google.com/a/tensorflow.org/forum/#!forum/tfjs&gt;Google group&lt;/denchmark-link&gt;
.
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

0.11.6
&lt;denchmark-h:h4&gt;Browser version&lt;/denchmark-h&gt;

chrome: 68.0.3440.17
&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

tf.oneHot treats input NaN like 0
&lt;denchmark-link:https://user-images.githubusercontent.com/547150/41551962-6835c260-72fb-11e8-84ac-9c2a063a9bc0.png&gt;&lt;/denchmark-link&gt;

This disagrees with the same code in python.
&lt;denchmark-link:https://user-images.githubusercontent.com/547150/41551978-74204c1c-72fb-11e8-9e8c-eac4b7a12c6a.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

tf.oneHot(tf.tensor1d([0, 1, NaN], 'int32'), 3).print();
	</description>
	<comments>
		<comment id='1' author='bileschi' date='2018-07-02T12:04:04Z'>
		I saw tf.tensor regarded NaN as 0 when we specify dtype='int32'.
&lt;denchmark-code&gt;const t1 = tf.tensor1d([1, 2, NaN], 'int32');
t1.print();
// "Tensor
//    [1, 2, 0]"

const t2 = tf.tensor1d([1, 2, Nan]);
t2.print();
// "Tensor
//    [1, 2, NaN]"

&lt;/denchmark-code&gt;

In order to fix the issue, we need to keep NaN as NaN in tensor creation. But it can be a breaking change if user code already expects NaN to be converted into 0 in a tensor when we specify dtype='int32'.
And also using np.nan without wrapping with numpy array throws an exception in TensorFlow core.
&lt;denchmark-code&gt;&gt;&gt;&gt; tf.one_hot([0,1,2,np.nan], 3)
...
TypeError: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: uint8, int32, int64
&lt;/denchmark-code&gt;

We need to discuss how TensorFlow.js should behave with NaN input.
		</comment>
		<comment id='2' author='bileschi' date='2018-07-02T17:09:24Z'>
		Fixing the issue you are talking about &lt;denchmark-link:https://github.com/Lewuathe&gt;@Lewuathe&lt;/denchmark-link&gt;
 here: &lt;denchmark-link:https://github.com/tensorflow/tfjs/issues/442&gt;#442&lt;/denchmark-link&gt;

As for the first bug, we should follow TensorFlow python CPU. &lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;
 want to take that?
		</comment>
		<comment id='3' author='bileschi' date='2018-07-03T03:12:18Z'>
		&lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;
 I did a little digging and it seems that convertToTensor isn't handling NaN inputs properly, it converts them to zero. If this is fixed, then oneHot will ignore the value when mapping (but there might be other implications to storing NaN in the Tensor object).
I can make the fix if you'd like, but I don't want to snag this from you if you're trying to make contributions - let me know what you prefer!
		</comment>
		<comment id='4' author='bileschi' date='2018-07-03T13:54:02Z'>
		&lt;denchmark-link:https://github.com/zboldyga&gt;@zboldyga&lt;/denchmark-link&gt;
 please go right ahead!
FYI: Historically there have been inconsistence in NaN handling in different environments, such as iOS.  Please be sure to check the proposed fix using Travis
		</comment>
		<comment id='5' author='bileschi' date='2018-07-03T20:06:35Z'>
		&lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;
 Thanks for the heads-up!
&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 It looks like the issue stems from TypedArray constructors, and will occur anytime convertToTensor is called with dtype 'int32' and a NaN input.
As per ECMA2016 standards, TypedArrays will convert NaN to 0 for all data types except float32 and float64: &lt;denchmark-link:https://www.ecma-international.org/ecma-262/7.0/#sec-properties-of-the-%typedarrayprototype%-object&gt;https://www.ecma-international.org/ecma-262/7.0/#sec-properties-of-the-%typedarrayprototype%-object&lt;/denchmark-link&gt;
. More specifically, for dtype 'int32' the Int32Array constructor and resultant data type won't allow NaN as a value by default.
We could override the default behavior and preserve the NaN value while casting, but I wonder if that will have undesirable effects, since the data will no longer be coherent with it's labeled type?
Is it maybe better to reject inputs of type NaN for Tensor construction unless the dtype is 'float32'?
		</comment>
		<comment id='6' author='bileschi' date='2018-07-06T14:44:28Z'>
		Ah, thats right. NaN is not defined for integers, NaN is a float concept.
&lt;denchmark-link:https://github.com/bileschi&gt;@bileschi&lt;/denchmark-link&gt;
 this actually seems like undefined behavior, and I think we should not guarantee anything when NaN is being used. This fix otherwise is quite hairy.
		</comment>
		<comment id='7' author='bileschi' date='2018-07-06T14:49:56Z'>
		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 seems reasonable, but what avenues do we have at our disposal for alerting the user as early as possible that this behavior is undefined?
		</comment>
		<comment id='8' author='bileschi' date='2018-07-06T14:56:41Z'>
		We could throw an error when a NaN is passed to an int32 convertToTensor when debug mode is on!
		</comment>
		<comment id='9' author='bileschi' date='2018-07-06T21:33:20Z'>
		Makes sense to me!
I will go ahead with the debug mode error on Sunday night and submit a PR, let me know in the meantime if you want me to do anything differently!
		</comment>
		<comment id='10' author='bileschi' date='2018-07-10T21:29:57Z'>
		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;
 looks like I'll need to fix my use of the environment (checking for debug mode) in order to get the fix working. I've got a circular dependence by including the environment directly in util.ts, which I think might not be the intended way to check if DEBUG is enabled...
Should I pass the environment instance down thru whichever operation calls convertToTensor? Or maybe it's OK to reference the environment directly in util.ts, but perhaps I need to use a workaround to avoid the circular reference?
		</comment>
		<comment id='11' author='bileschi' date='2018-07-22T00:20:12Z'>
		&lt;denchmark-link:https://github.com/nsthorat&gt;@nsthorat&lt;/denchmark-link&gt;

PR for this is here: &lt;denchmark-link:https://github.com/tensorflow/tfjs-core/pull/1180&gt;tensorflow/tfjs-core#1180&lt;/denchmark-link&gt;

In order to check for debug mode in the converToTensor utility (and throw an error), environment.ts is loaded in util.ts. Loading environment.ts here gives a tslint circular dependency warning, because one of the dependencies in environment.ts loads a utility from util.ts.
I disabled this tslint warning because the dependency won't cause any conflicts in this case.
Another option would be to break util.ts into 2 or more fragments so the environment can be loaded only for the appropriate utilities (the environment is loaded to check for debug mode), thus avoiding the circular dependency... I started down this path, but there were more dependencies than I had anticipated and it started leading to lots of refactoring.
		</comment>
		<comment id='12' author='bileschi' date='2018-07-30T22:55:43Z'>
		This should be fixed now, thanks &lt;denchmark-link:https://github.com/zboldyga&gt;@zboldyga&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>