<bug id='3911' author='wtrevena' open_date='2020-09-12T05:27:52Z' closed_time='2020-10-13T17:12:16Z'>
	<summary>toxicity model always returns the same values in React Native</summary>
	<description>
&lt;denchmark-h:h4&gt;TensorFlow.js version&lt;/denchmark-h&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/55459400/92987830-22899300-f494-11ea-8ac9-4f51eb3037da.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Describe the problem or feature request&lt;/denchmark-h&gt;

Regardless of the string I input into the toxicity model, I receive the same probabilities for each result (identity_attack, obscene, etc.) as shown in the screenshot below. I am calling this using the code below.
One thing to note: I am running this on an expo-managed app, but one of the dependencies of tfjs-react-native is react-native-fs which would normally be replaced by expo-file-system in my implementation. To satisfy the dependency requirement I installed react-native-fs anyways, but I am not sure if should matter as I am not trying to import any custom models from memory using tfjs-react-native.
&lt;denchmark-h:h4&gt;Code to reproduce the bug / link to feature request&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-react-native';
var toxicity = require('@tensorflow-models/toxicity');
&lt;/denchmark-code&gt;

And I am calling the code in this way
&lt;denchmark-code&gt;async componentDidMount () { 
  await tf.setBackend('rn-webgl')
  await tf.ready();
  console.log("tf is ready!!!")
  // Load the model. Users optionally pass in a threshold and an array of
  // labels to include.
  await toxicity.load(0.9)
    .then(async(model) =&gt; {
      await model.classify(['you suck','I love you'])
        .then(async(predictions) =&gt; {

            await console.log(predictions);

            // `predictions` is an array of objects, one for each prediction head,
            // that contains the raw probabilities for each input along with the
            // final prediction in `match` (either `true` or `false`).
            // If neither prediction exceeds the threshold, `match` is `null`.
        
        });
  });
}
&lt;/denchmark-code&gt;

Printing in predictions:
&lt;denchmark-link:https://user-images.githubusercontent.com/55459400/92987947-3c77a580-f495-11ea-99ef-d36e693d24ad.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/55459400/92987938-29fd6c00-f495-11ea-8a4c-9551dc2e2e1d.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/55459400/92987927-1b16b980-f495-11ea-9fb8-069fc15b9f4f.png&gt;&lt;/denchmark-link&gt;

As seen in the output above, the toxicity model is returning the same probabilities regardless of the strings inputted. I also tried this with a variety of other very kind and very toxic strings which all resulted in the same output.
Any help addressing this issue would be greatly appreciated.
	</description>
	<comments>
		<comment id='1' author='wtrevena' date='2020-09-12T06:54:02Z'>
		I am having the same issue as well - regardless of the strings inputted, the model continues to return the same probabilities
		</comment>
		<comment id='2' author='wtrevena' date='2020-09-29T16:44:21Z'>
		Hi, I wasn't able to reproduce this, could you provide more device information. Another thing to try for debugging this is tf.setBackend('cpu').
I tried to &lt;denchmark-link:https://github.com/tafsiri/tfjs-expo-managed-example/tree/toxicity-model&gt;reproduce this here&lt;/denchmark-link&gt;
, feel free to download that repo and try it out yourself (make sure to switch to the 'toxicity-model' branch.
This is the output I got for model.classify(['you suck','I love you'])
&lt;denchmark-code&gt;model output len 7
Label identity_attack
Results Array [
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9659663438796997,
      0.03403365984559059,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.999956488609314,
      0.000043553249270189553,
    ],
  },
]
Label insult
Results Array [
  Object {
    "match": true,
    "probabilities": Float32Array [
      0.08124707639217377,
      0.918752908706665,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9995761513710022,
      0.00042380779632367194,
    ],
  },
]
Label obscene
Results Array [
  Object {
    "match": null,
    "probabilities": Float32Array [
      0.39931538701057434,
      0.6006845831871033,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9999582767486572,
      0.000041756517020985484,
    ],
  },
]
Label severe_toxicity
Results Array [
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9970395565032959,
      0.002960433252155781,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      1,
      4.12830054585811e-8,
    ],
  },
]
Label sexual_explicit
Results Array [
  Object {
    "match": null,
    "probabilities": Float32Array [
      0.7053250670433044,
      0.29467496275901794,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9999380111694336,
      0.0000619467900833115,
    ],
  },
]
Label threat
Results Array [
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9106739163398743,
      0.08932609856128693,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9998704195022583,
      0.00012954739213455468,
    ],
  },
]
Label toxicity
Results Array [
  Object {
    "match": true,
    "probabilities": Float32Array [
      0.031176727265119553,
      0.9688233137130737,
    ],
  },
  Object {
    "match": false,
    "probabilities": Float32Array [
      0.9989683628082275,
      0.00103162438608706,
    ],
  },
]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='wtrevena' date='2020-10-06T17:01:13Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 7 dyas if no further activity occurs. Thank you.
		</comment>
		<comment id='4' author='wtrevena' date='2020-10-13T17:12:15Z'>
		Closing as stale. Please @mention us if this needs more attention.
		</comment>
		<comment id='5' author='wtrevena' date='2020-10-13T17:12:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3911&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfjs/issues/3911&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>