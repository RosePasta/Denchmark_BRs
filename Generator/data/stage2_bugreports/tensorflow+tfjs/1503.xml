<bug id='1503' author='nsthorat' open_date='2019-04-08T19:23:36Z' closed_time='2019-04-09T01:51:37Z'>
	<summary>Stateful RNNs are disposing internal tensors incorrectly.</summary>
	<description>
JSFiddle: &lt;denchmark-link:https://jsfiddle.net/dfhn4qsc/&gt;https://jsfiddle.net/dfhn4qsc/&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;function createModel(inputSize = [16, 4], lstmLayerSize = 32, batchSize=1) {
	const model = tf.sequential();
	
	model.add(tf.layers.lstm({
		stateful: true,
		batchInputShape: [batchSize, ...inputSize],
		batchSize: batchSize,
		units: lstmLayerSize,
		inputShape: inputSize
	}));

	const dense = tf.layers.dense({
		units: inputSize[1],
		activation: 'relu'
	})
	model.add(dense);

	return model
}

const inputShape = [16, 4]

const model = createModel(inputShape)

const output1 = model.predict(tf.zeros([1, ...inputShape]))
output1.print()
//fails on second run bc internal state is disposed
const output2 = model.predict(tf.zeros([1, ...inputShape]))
output2.print()
&lt;/denchmark-code&gt;

Note the stateful: true. This causes a tensor disposed coming from the input: &lt;denchmark-link:https://github.com/tensorflow/tfjs-layers/blob/v1.0.4/src/layers/recurrent.ts#L2083&gt;https://github.com/tensorflow/tfjs-layers/blob/v1.0.4/src/layers/recurrent.ts#L2083&lt;/denchmark-link&gt;

	</description>
	<comments>
	</comments>
</bug>