<bug id='971' author='iizukak' open_date='2020-04-08T08:00:03Z' closed_time='2020-04-16T01:11:58Z'>
	<summary>UserWarning for LmSegnetV1Quantize</summary>
	<description>
I got UserWarning when convert LmSegnetV1Quantize.
Please update the network to fix this issue.
&lt;denchmark-code&gt;finish
import pb file
optimize graph step: start
optimize graph step: done!
generate code step: start
generate code step: done!
Output files are generated in /home/blueoil/saved/segmentation_20200408012343/export/save.ckpt-917/360x480/output
Please see /home/blueoil/saved/segmentation_20200408012343/export/save.ckpt-917/360x480/output/README.md to run prediction
/home/blueoil/blueoil/converter/core/operators.py:60: UserWarning: WRN Output channels need to be multiple of 32 for space2depth1 of SpaceToDepth, but got output channel size of 12
  self._check_consistency()
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='iizukak' date='2020-04-09T05:10:08Z'>
		&lt;denchmark-link:https://github.com/iizukak&gt;@iizukak&lt;/denchmark-link&gt;

I got same warning messages as yours.
But the generated lm_x86.elf and lm_fpga.elf work well at my environment.
Is this just warning at your environment ?
		</comment>
		<comment id='2' author='iizukak' date='2020-04-09T06:47:25Z'>
		&lt;denchmark-link:https://github.com/tk26eng&gt;@tk26eng&lt;/denchmark-link&gt;

Thanks.
Also work well with FPGA?
		</comment>
		<comment id='3' author='iizukak' date='2020-04-09T07:04:33Z'>
		&lt;denchmark-link:https://github.com/iizukak&gt;@iizukak&lt;/denchmark-link&gt;

Yes, the elf for FPGA also works well.
But anyway it's better to fix the warning.
I'll try to fix it.
		</comment>
		<comment id='4' author='iizukak' date='2020-04-09T07:09:40Z'>
		I see. Thanks.
		</comment>
	</comments>
</bug>