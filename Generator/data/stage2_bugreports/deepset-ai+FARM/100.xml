<bug id='100' author='amoelle' open_date='2019-09-24T09:43:17Z' closed_time='2019-09-24T12:50:52Z'>
	<summary>Expected input batch_size to match target batch_size</summary>
	<description>
Hello,
when running the Trainer for a multi-class classification (4 classes, batch_size=8) there seems to be a missmatch:
Expected input batch_size (8) to match target batch_size (32)
The error appears in this  context:
&lt;denchmark-code&gt;farm/modeling/prediction_head.py(262)logits_to_loss()
-&gt; return self.loss_fct(logits, label_ids.view(-1))
(Pdb)  logits
tensor([[ 0.0025,  0.1011,  0.0897,  0.5420],
        [-0.2871,  0.1540,  0.1067,  0.3153],
        [ 0.0552,  0.5559,  0.0795,  0.3348],
        [ 0.2319,  0.1192, -0.0756,  0.5185],
        [ 0.2457, -0.1189, -0.3208,  0.1301],
        [-0.1660,  0.1726, -0.0196,  0.0887],
        [-0.3584,  0.0351,  0.0103,  0.2665],
        [-0.3831,  0.0922,  0.2931,  0.2717]], grad_fn=&lt;A
(Pdb)  label_ids
tensor([[0, 1, 0, 0],
        [0, 0, 1, 0],
        [0, 1, 0, 0],
        [0, 0, 0, 1],
        [1, 0, 0, 0],
        [0, 1, 0, 0],
        [1, 0, 0, 0],
        [0, 1, 0, 0]])
&lt;/denchmark-code&gt;

.
.
.
&lt;denchmark-code&gt;--Call--
&gt; /usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py(537)__call__()
-&gt; def __call__(self, *input, **kwargs):
(Pdb)  input
(tensor([[ 0.0025,  0.1011,  0.0897,  0.5420],
        [-0.2871,  0.1540,  0.1067,  0.3153],
        [ 0.0552,  0.5559,  0.0795,  0.3348],
        [ 0.2319,  0.1192, -0.0756,  0.5185],
        [ 0.2457, -0.1189, -0.3208,  0.1301],
        [-0.1660,  0.1726, -0.0196,  0.0887],
        [-0.3584,  0.0351,  0.0103,  0.2665],
        [-0.3831,  0.0922,  0.2931,  0.2717]], grad_fn=&lt;AddmmBackward&gt;), tensor([0, 1, 0, 
        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
        1, 0, 0, 0, 0, 1, 0, 0]))
&lt;/denchmark-code&gt;

Then input and target missmatch:
&lt;denchmark-code&gt;--Call--
&gt; /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py(914)forward()
-&gt; def forward(self, input, target):
(Pdb)  input
tensor([[ 0.0025,  0.1011,  0.0897,  0.5420],
    [-0.2871,  0.1540,  0.1067,  0.3153],
    [ 0.0552,  0.5559,  0.0795,  0.3348],
    [ 0.2319,  0.1192, -0.0756,  0.5185],
    [ 0.2457, -0.1189, -0.3208,  0.1301],
    [-0.1660,  0.1726, -0.0196,  0.0887],
    [-0.3584,  0.0351,  0.0103,  0.2665],
    [-0.3831,  0.0922,  0.2931,  0.2717]], grad_fn=&lt;AddmmBackward&gt;)
(Pdb)  target
tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,
    1, 0, 0, 0, 0, 1, 0, 0])
&lt;/denchmark-code&gt;

Finally the error is thrown here:
&lt;denchmark-code&gt;&gt; /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py(1820)nll_loss()
-&gt; if input.size(0) != target.size(0):
-&gt; raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'
&lt;/denchmark-code&gt;

Is there something i can do to avoid this Value Error?
	</description>
	<comments>
		<comment id='1' author='amoelle' date='2019-09-24T11:47:37Z'>
		Hey &lt;denchmark-link:https://github.com/amoelle&gt;@amoelle&lt;/denchmark-link&gt;
  can you give a bit more background and try to adhere to our issue template.
Can you post the code you are running?
It seems as if label_ids are one hot encoded, which should not be the case in normal classification, only in multilabel_classification. label_ids should be integers ranging from 0 to number classes -1.
		</comment>
		<comment id='2' author='amoelle' date='2019-09-24T12:50:52Z'>
		Hi &lt;denchmark-link:https://github.com/Timoeller&gt;@Timoeller&lt;/denchmark-link&gt;
, thank you very much for the support!
I have changed the 'multilabel' parameter of the TextClassificationProcessor from True to False now and the issue seems to be resolved (miss-interpreted the parameter, sorry for the inconvenience! )
		</comment>
	</comments>
</bug>