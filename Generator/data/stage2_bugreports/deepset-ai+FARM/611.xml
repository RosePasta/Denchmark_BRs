<bug id='611' author='tholor' open_date='2020-10-29T20:00:27Z' closed_time='2020-12-01T15:31:21Z'>
	<summary>Inference Benchmarks of QA models are off</summary>
	<description>

EM and F1 are significantly low when running the &lt;denchmark-link:https://github.com/deepset-ai/haystack/blob/add_cml_benchmarks/test/benchmarks/reader.py&gt;reader benchmarks&lt;/denchmark-link&gt;
 in Haystack.
Latest Master




EM
f1
top_n_accuracy
top_n
reader_time
seconds_per_query
passages_per_second
reader
error




0
0.323024
0.37967
0.95584
5
123.854
0.0104377
99.7142
deepset/bert-base-cased-squad2




FARM 0.4.9




EM
f1
top_n_accuracy
top_n
reader_time
seconds_per_query
passages_per_second
reader
error




0
0.758975
0.806799
0.967133
5
135.263
0.0113992
91.3039
deepset/roberta-base-squad2




However, it doesn't seem to be any of the latest changes as already with this commit I get bad results.
FARM @ &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/dac388aa00eb63ad12452f97e40f51a218110b90&gt;dac388a&lt;/denchmark-link&gt;
 (Oct 21)




EM
f1
top_n_accuracy
top_n
reader_time
seconds_per_query
passages_per_second
reader
error




0
0.330777
0.383186
0.963341
5
134.598
0.0113432
91.7545
deepset/roberta-base-squad2




Expected behavior
Similar EM and F1
Additional context
I tried to switch transformers from 3.3.1 back to 3.1.0 (as it was used in FARM 0.4.9) =&gt; no effect
To Reproduce
Run the above benchmark script from the haystack branch
System:

OS: Ubuntu 18.04
GPU/CPU: GPU
FARM version: latest master  / 0.4.9

	</description>
	<comments>
		<comment id='1' author='tholor' date='2020-10-30T09:25:18Z'>
		Similar for &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/2ab42d220eda58eff3438e10324de41bf05f0fe9&gt;2ab42d2&lt;/denchmark-link&gt;
 (Oct 16)
		</comment>
		<comment id='2' author='tholor' date='2020-10-30T11:07:04Z'>
		Results are high again at &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/c106bca84f36a44ef890e43a1e3da6171e4a8bd8&gt;c106bca&lt;/denchmark-link&gt;
 (Oct 4)
		</comment>
		<comment id='3' author='tholor' date='2020-10-30T11:13:15Z'>
		Results are high at &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/7c38fc553577dc3e0cab314e77d6078ba94524c2&gt;7c38fc5&lt;/denchmark-link&gt;
 (Oct 14)
		</comment>
		<comment id='4' author='tholor' date='2020-10-30T11:23:00Z'>
		Results are high at  &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/b9dbd7de1720463fb22e0ab295db8ead28ede44e&gt;b9dbd7d&lt;/denchmark-link&gt;
 (Oct 15)
		</comment>
		<comment id='5' author='tholor' date='2020-10-30T11:28:55Z'>
		The problematic commit is &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/9055094e339285bb47b06a49cfb4589c735dc7b4&gt;9055094&lt;/denchmark-link&gt;
 (Oct 16)
		</comment>
		<comment id='6' author='tholor' date='2020-10-30T13:35:35Z'>
		On &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/9055094e339285bb47b06a49cfb4589c735dc7b4&gt;9055094&lt;/denchmark-link&gt;
, running the benchmark script using Reader.eval_on_file( ) instead of Reader.eval( ) gives the following results
{'EM': 0.7511159774277774, 'f1': 0.7991178464867065, 'top_n_accuracy': 0.9633622504842921}. This suggests there is some kind of interaction with the indexing in haystack that is causing this issue.
		</comment>
		<comment id='7' author='tholor' date='2020-10-30T14:35:17Z'>
		Please post issues related to haystack into the corresponding &lt;denchmark-link:https://github.com/deepset-ai/haystack&gt;github repository&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
  ;)
		</comment>
		<comment id='8' author='tholor' date='2020-10-30T14:38:03Z'>
		This seemed rather like a FARM related bug as performance changed between FARM versions, dear &lt;denchmark-link:https://github.com/Timoeller&gt;@Timoeller&lt;/denchmark-link&gt;
  ;)
		</comment>
		<comment id='9' author='tholor' date='2020-10-30T16:22:24Z'>
		This has been addressed by &lt;denchmark-link:https://github.com/deepset-ai/haystack/pull/531&gt;a new PR&lt;/denchmark-link&gt;
 in Haystack which corrects the creation of no_answer sample dictionaries in FARMReader.eval( ). In future we would like to fix this problem also on the FARM preprocessing side by filtering out empty string spans.
		</comment>
		<comment id='10' author='tholor' date='2020-11-04T09:41:17Z'>
		Just to clarify: we want to add a check in FARM preprocessing that identifies labels with:

empty string
start / end = 0
as no_answer and not as regular span labels.

		</comment>
		<comment id='11' author='tholor' date='2020-11-04T14:45:42Z'>
		Might be related to &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/614&gt;#614&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='tholor' date='2020-11-18T13:45:08Z'>
		Span labels with an empty string are now checked for and removed in FARM preprocessing &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/635&gt;#635&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='tholor' date='2020-12-01T15:31:21Z'>
		Closing by &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/635&gt;#635&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>