<bug id='413' author='agoeroeg' open_date='2020-06-18T12:47:44Z' closed_time='2020-06-22T08:58:23Z'>
	<summary>GloVe Tokenizer vocab_size NotImplementedError on farm==0.4.4</summary>
	<description>
Describe the bug
from farm.modeling.tokenization import Tokenizer
06/18/2020 13:27:30 - INFO - transformers.file_utils -   PyTorch version 1.5.0 available.
06/18/2020 13:27:32 - INFO - transformers.file_utils -   TensorFlow version 2.2.0 available.
tokenizer = Tokenizer.load(pretrained_model_name_or_path="glove-german-uncased", do_lower_case=True)
06/18/2020 13:27:34 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'EmbeddingTokenizer'
06/18/2020 13:27:34 - INFO - farm.file_utils -   loading file &lt;denchmark-link:https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-models/0.4.1/glove-german-uncased/vocab.txt&gt;https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-models/0.4.1/glove-german-uncased/vocab.txt&lt;/denchmark-link&gt;
 from cache at C:\Users\agorog/.cache\torch\transformers\908abcd9055659e8d52f6751e79f238725749cc63073a936a3db454a7249fa29.c46eea5c549ba988d36084631e2a61bc3778fe51b79972ea5451da8b1341e6e8
&lt;denchmark-h:h2&gt;print(tokenizer.vocab_size)&lt;/denchmark-h&gt;

NotImplementedError                       Traceback (most recent call last)
 in 
----&gt; 1 print(tokenizer.vocab_size)
C:\Anaconda3\envs\farmtest\lib\site-packages\transformers\tokenization_utils.py in vocab_size(self)
771     def vocab_size(self) -&gt; int:
772         """ Size of the base vocabulary (without the added tokens) """
--&gt; 773         raise NotImplementedError
774
775     &lt;denchmark-link:https://github.com/Property&gt;@Property&lt;/denchmark-link&gt;

NotImplementedError:
Error message
NotImplementedError:
Expected behavior
print tokenizer.vocab_size (i.e. 1309285)
Additional context
"bert-base-german-cased" works,  farm 0.4.3 works.
To Reproduce
Steps to reproduce the behavior
System:

OS: Windows 10, python 3.6.9
GPU/CPU: CPU
FARM version: 0.4.4

	</description>
	<comments>
		<comment id='1' author='agoeroeg' date='2020-06-18T13:38:18Z'>
		Hey &lt;denchmark-link:https://github.com/agoeroeg&gt;@agoeroeg&lt;/denchmark-link&gt;
 thanks for reporting.
Could you try print(tokenizer.vocab_size_farm)?
I cannot find the code responsible for the error inside FARM. Is this code print(tokenizer.vocab_size) somewhere in FARM? IF so we would need to adjust it.
		</comment>
		<comment id='2' author='agoeroeg' date='2020-06-18T15:38:22Z'>
		Hi, I posted only the core of the problem. It is originated in the examples/doc_classification_word_embedding_LM.py
trainer.train()
File "c:\users\agorog\desktop\work\farm\farm\train.py", line 232, in train
self.model.verify_vocab_size(vocab_size=len(self.data_silo.processor.tokenizer))
File "C:\Anaconda3\lib\site-packages\transformers\tokenization_utils.py", line 856, in len
return self.vocab_size + len(self.added_tokens_encoder)
File "C:\Anaconda3\lib\site-packages\transformers\tokenization_utils.py", line 773, in vocab_size
raise NotImplementedError
NotImplementedError
		</comment>
		<comment id='3' author='agoeroeg' date='2020-06-18T15:42:11Z'>
		print(tokenizer.vocab_size_farm) seems to work, len(self.data_silo.processor.tokenizer) does not work (in form of len(data_silo.processor.tokenizer))
		</comment>
		<comment id='4' author='agoeroeg' date='2020-06-18T16:33:06Z'>
		Understood.
I quickly fixed the EmbeddingTokenizer code by removing the "vocab_size_farm" parameter alltogether and implementing the missing "vocab_size()" method with &lt;denchmark-link:https://github.com/deepset-ai/FARM/commit/06e45f94852ecabb7ee19e757cc6795b6fc1b354&gt;this commit&lt;/denchmark-link&gt;
.
Could you try using the latest master and report if that works for you?
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Thanks again for spotting the problem. I will slightly adjust the naming of the issue so other people can find it.
		</comment>
		<comment id='5' author='agoeroeg' date='2020-06-19T09:11:45Z'>
		It works, thank you. I have a feature request too: farm.__version__ would be nice :)
		</comment>
		<comment id='6' author='agoeroeg' date='2020-06-19T09:54:20Z'>
		No problem, always glad if FARM gets improved.
About the version request: We can put this on our timeline, but would currently prefer to not introduce versions on code level since FARM is still in beta mode and under heavy development. That means we will not increment versions for each change. Having the same version for different code seems confusing and we kind of version through releases that are then on Pypi. If we switch to more stable development a code level version is the way forward indeed.
Or do you have a good suggestion/solution?
		</comment>
		<comment id='7' author='agoeroeg' date='2020-06-20T13:24:50Z'>
		"Having the same version for different code seems confusing and we kind of version through releases that are then on Pypi." I see. Personally I do not think it is more confusing than pip list.
		</comment>
		<comment id='8' author='agoeroeg' date='2020-06-22T08:58:23Z'>
		hehe sure, version control through pip can be quite mysterious at times.
Will keep your feature request on our list.
Closing this issue now since the vocab_size seems solved - feel free to reopen at any time.
		</comment>
	</comments>
</bug>