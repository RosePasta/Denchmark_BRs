<bug id='486' author='bipinkc19' open_date='2020-08-06T02:29:32Z' closed_time='2020-08-06T08:00:22Z'>
	<summary>Speed issue in inference in newer versions &amp;gt; 0.4.3 for Q/A</summary>
	<description>
Slow inference speed
Inference speed is really slow in new versions &gt; 0.4.3 gor Q/A
Additional context/To reproduce
Here is an example to reproduce the slow speed in inference
Collab notebook using farm==0.4.3
&lt;denchmark-link:https://colab.research.google.com/drive/1ki4-HsRvVx62HVPRacx9lkwOESZ_o0gF?usp=sharing&gt;https://colab.research.google.com/drive/1ki4-HsRvVx62HVPRacx9lkwOESZ_o0gF?usp=sharing&lt;/denchmark-link&gt;

The speed is very fine here
Collab notebook using farm==0.4.5
&lt;denchmark-link:https://colab.research.google.com/drive/1JIWmbEwvGHuArWy3xsdr9z_srMx63fH-?usp=sharing&gt;https://colab.research.google.com/drive/1JIWmbEwvGHuArWy3xsdr9z_srMx63fH-?usp=sharing&lt;/denchmark-link&gt;

The speed is very slow here.
I have tried it even on the latest farm version using dedicated QAInferencer but the speed is still huge problem as in version 0.4.3 it is very fast
System:
Collab
	</description>
	<comments>
		<comment id='1' author='bipinkc19' date='2020-08-06T02:30:34Z'>
		The reason for using the latest version is to get the context of the answers which is not provided in version 0.4.3
		</comment>
		<comment id='2' author='bipinkc19' date='2020-08-06T07:15:34Z'>
		Hey &lt;denchmark-link:https://github.com/bipinkc19&gt;@bipinkc19&lt;/denchmark-link&gt;
 thanks for the detailed report - we really appreciate issue reports that are being this reproducible.
That way we are able very fast to figure out the glitch. It is not the FARM version that slows it down but in the second example you do not have the GPU enable in the runtime. (The first notebook uses the GPU)
"INFO - farm.utils -   device: cpu n_gpu: 0, [...]"
		</comment>
		<comment id='3' author='bipinkc19' date='2020-08-06T07:27:26Z'>
		Thanks for the quick reply &lt;denchmark-link:https://github.com/Timoeller&gt;@Timoeller&lt;/denchmark-link&gt;
 . But the notebook uses GPU. I have updated the notebook above with a code snippet ina  cell to check GPU availibility.
Looks like due to some error FARM isn't detecting and utilizing the GPU. Maybe it is related to:
&lt;denchmark-link:https://github.com/deepset-ai/FARM/issues/117&gt;#117&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='bipinkc19' date='2020-08-06T07:53:00Z'>
		Nice, thanks for the additional input. Farm uses pytorch for utilizing the GPU - so I rather suspect it is a combination of colab + cuda + pytorch.

I tried the notebook with FARM version 0.4.6 and coulnt make it work right away.
I have seen "Found existing installation: torch 1.6.0+cu101".
So I installed the correct pytorch version with !pip install torch==1.5.1+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html in combination with farm==0.4.6. There it works

&lt;denchmark-code&gt;Inferencing Samples: 100%|██████████| 16/16 [00:01&lt;00:00,  8.02 Batches/s]CPU times: user 1.35 s, sys: 761 ms, total: 2.11 s
Wall time: 2.35 s
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='bipinkc19' date='2020-08-06T08:00:22Z'>
		Thanks a lot!
		</comment>
	</comments>
</bug>