<bug id='426' author='tstadel' open_date='2020-06-26T07:26:56Z' closed_time='2020-07-27T10:01:43Z'>
	<summary>Shouldn't we better shuffle data for pretraining on document level instead of sentence level?</summary>
	<description>
Question
farm.data_handler.utils.randomize_and_split_file() shuffles training data on sentence / line level. This not only introduces many warnings since empty lines get concatenated by chance thus producing empty documents. But it also breaks NextSentencePrediction learning tasks as they need correct sentence sequences. Even if NextSentencePrediction may be widely regarded as obsolete, I guess, we shouldn't destroy it implicitly...
So shouldn't we better shuffle on document level instead of sentence level?
Additional context
farm.data_handler.utils.randomize_and_split_file() is used in examples/train_from_scratch.py
	</description>
	<comments>
		<comment id='1' author='tstadel' date='2020-06-26T09:51:40Z'>
		Hi &lt;denchmark-link:https://github.com/tstadel&gt;@tstadel&lt;/denchmark-link&gt;
, thank you for raising the issue. &lt;denchmark-link:https://github.com/tholor&gt;@tholor&lt;/denchmark-link&gt;
 and I discussed potential solutions to resolve this. A quick fix with &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/427&gt;#427&lt;/denchmark-link&gt;
 is to refactor the  to , where a large train file is split in smaller files each having a document count of .
For the randomization, we can rely on farm.data_handler.data_silo._StreamingDataSet.shuffle_files() to shuffle the order of reading the split files during each training epoch. The docs_per_file param should be reasonably small for this approach to work well.
If we don't get good results with this approach, we can perhaps create a separate PR to implement an additional randomize_file() that can be called before each training epoch to randomize the order of docs in individual split files.
What do you think?
		</comment>
		<comment id='2' author='tstadel' date='2020-06-26T11:36:52Z'>
		Hi &lt;denchmark-link:https://github.com/tanaysoni&gt;@tanaysoni&lt;/denchmark-link&gt;
,
looks appropriate to me.
		</comment>
	</comments>
</bug>