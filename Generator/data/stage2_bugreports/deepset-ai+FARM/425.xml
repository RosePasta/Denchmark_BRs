<bug id='425' author='tstadel' open_date='2020-06-25T19:39:24Z' closed_time='2020-08-04T07:06:28Z'>
	<summary>Training from Scratch of loaded checkpoint fails in O2 AMP mode</summary>
	<description>
Describe the bug
When running the train_from_scratch.py script from examples and there is already a checkpoint, training crashes with the following exception:
Error message
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "train_from_scratch.py", line 159, in &lt;module&gt;
    train_from_scratch()
  File "train_from_scratch.py", line 150, in train_from_scratch
    trainer.train()
  File "/home/thomas/git/FARM/farm/train.py", line 293, in train
    loss = self.backward_propagate(per_sample_loss, step)
  File "/home/thomas/git/FARM/farm/train.py", line 400, in backward_propagate
    self.optimizer.step()
  File "/home/thomas/anaconda3/envs/ml/lib/python3.8/site-packages/torch/optim/lr_scheduler.py", line 67, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/thomas/anaconda3/envs/ml/lib/python3.8/site-packages/apex/amp/_process_optimizer.py", line 359, in new_step
    self._master_params_to_model_params()
  File "/home/thomas/anaconda3/envs/ml/lib/python3.8/site-packages/apex/amp/_process_optimizer.py", line 17, in _master_params_to_model_params
    if len(stash.all_fp16_params) &gt; 0:
AttributeError: 'AmpOptimizerState' object has no attribute 'all_fp16_params'
&lt;/denchmark-code&gt;

Expected behavior
Training can be resumed from checkpoint.
Additional Context
other AMP modes work fine
To Reproduce
run train_from_scratch.py until first checkpoint is created (right after start).
run train_from_scratch.py again.
System:

OS: Ubuntu 18.04
GPU/CPU: GPU (V100)
FARM version: latest from git
pytorch version: 1.5.1
CUDA version: 10.2

	</description>
	<comments>
		<comment id='1' author='tstadel' date='2020-07-30T06:35:40Z'>
		Hey &lt;denchmark-link:https://github.com/tstadel&gt;@tstadel&lt;/denchmark-link&gt;
 ,
Sorry, we somehow missed your issue here. Thanks for reporting this bug. We only use the O1 mode for training via AMP and therefore only tested this one.
Judging from the error message, it seems that there is an additional attribute of the optimizer for O2 (all_fp16_params) that we don't save properly in Trainer.save() or restore in Trainer._load_checkpoint(). Unfortunately, I currently don't have time to investigate this deeper.
Have you maybe already found the issue by now yourself or would be interested in investigating this further if O2 Mode is important to you?
		</comment>
		<comment id='2' author='tstadel' date='2020-08-03T18:31:28Z'>
		No prob...
I just haven't dealt with O2 before and stumbled upon it while executing the train_from_scratch script. As I see it, anything else than O1 is more or less experimental. So there is no special need for O2 from my side.
In addition, I don't think it makes much sence to invest more time into it, as AMP now gained first class support in pytorch 1.6.
		</comment>
		<comment id='3' author='tstadel' date='2020-08-04T07:06:28Z'>
		Ok got it. I also think that we should rather switch to AMP in pytorch 1.6 than fixing this one now.
		</comment>
	</comments>
</bug>