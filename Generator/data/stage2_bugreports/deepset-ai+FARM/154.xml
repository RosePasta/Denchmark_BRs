<bug id='154' author='tnhaider' open_date='2019-11-19T21:24:55Z' closed_time='2019-11-22T01:26:40Z'>
	<summary>German LM tuning data loading broken</summary>
	<description>
Describe the bug
Hi guys, I want to tune a german BERT model for poetry, to improve classification results.
The default script examples/lm_finetuning.py works fine out of the box with the nips data.
When I use the "bert-base-german-cased" model and supply my data in nips format (document per line), I get a "single block of text" error:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Loading data into the data silo ...
______
|o  |   !
__          |:`|---'-.
||___.-/ _ -----.|
(o)(o)------'\ _ /     ( )
I1119 22:07:10.454642 139878717925184 data_silo.py:136] Loading train set from: ../data/german_poetry/train.txt
Loading Dataset: 177469it [00:00, 571853.15it/s]
Traceback (most recent call last):
File "lm_finetuning_german_poetry.py", line 48, in 
data_silo = DataSilo(processor=processor, batch_size=batch_size)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 53, in init
self._load_data()
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 137, in _load_data
self.data["train"], self.tensor_names = self._get_dataset(train_file)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 81, in _get_dataset
dicts = self.processor.file_to_dicts(filename)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/processor.py", line 612, in file_to_dicts
dicts = read_docs_from_txt(filename=file, delimiter=self.delimiter, max_docs=self.max_docs, proxies=self.proxies)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/utils.py", line 207, in read_docs_from_txt
raise ValueError(f"Found only {len(all_docs)} docs in {filename}). You need at least 2! \n"
ValueError: Found only 1 docs in ../data/german_poetry/train.txt). You need at least 2!
Make sure that you comply with the format:
-&gt; One sentence per line and exactly one empty line between docs.
You might have a single block of text without empty lines inbetween.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

If I supply the data with newline inbetween (I concatenate '\n\n' instead of '\n' to my lines), it tells me that I cannot choose from an empty sequence:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Loading data into the data silo ...
______
|o  |   !
__          |:`|---'-.
||___.-/ _ -----.|
(o)(o)------'\ _ /     ( )
I1119 22:10:27.150327 139904560707392 data_silo.py:136] Loading train set from: ../data/german_poetry/train.txt
Loading Dataset: 0it [00:00, ?it/s]I1119 22:10:27.151846 139904560707392 utils.py:188] Reached number of max_docs (30). Skipping rest of file ...
I1119 22:10:27.202136 139904560707392 data_silo.py:95] Got ya 7 parallel workers to convert 30 dictionaries to pytorch datasets (chunksize = 4)...
I1119 22:10:27.202630 139904560707392 utils.py:217]  0    0    0    0    0    0    0
I1119 22:10:27.202736 139904560707392 utils.py:217] /w\  /w\  /w\  /w\  /w\  /w\  /w
I1119 22:10:27.202811 139904560707392 utils.py:217] /'\  / \  /'\  /'\  / \  / \  /'
I1119 22:10:27.202878 139904560707392 utils.py:217]
0%|                                                                                                      | 0/30 [00:00&lt;?, ? Dicts/s]I1119 22:10:27.237695 139904560707392 processor.py:308] *** Show 3 random examples ***
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 119, in worker
result = (True, func(*args, **kwds))
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 72, in _multiproc
dataset = processor.dataset_from_dicts(dicts=dicts, index=index)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/processor.py", line 299, in dataset_from_dicts
self._log_samples(3)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/processor.py", line 311, in _log_samples
random_sample = random.choice(random_basket.samples)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/python36-venv/lib64/python3.6/random.py", line 260, in choice
raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
"""
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
File "lm_finetuning_german_poetry.py", line 48, in 
data_silo = DataSilo(processor=processor, batch_size=batch_size)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 53, in init
self._load_data()
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 137, in _load_data
self.data["train"], self.tensor_names = self._get_dataset(train_file)
File "/mnt/beegfs/home/thomas.haider/Documents/workspace/poetry/farm/FARM/farm/data_handler/data_silo.py", line 108, in _get_dataset
for dataset, tensor_names in results:
File "/usr/lib64/python3.6/multiprocessing/pool.py", line 735, in next
raise value
IndexError: Cannot choose from an empty sequence
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

What's going on here???
I tried fixing it in the datahandler, but to no avail. If I touch something, it breaks somewhere else.
I'm on a CentOS high performance cluster in a python 3.6. virtual environment, with Xenon CPUs (no GPUs) and 256GB RAM on every node.
I already tried downloading your newest farm version (please note that scipy needs to be at least at 1.2.0 for softmax. I had to redo that after installing your requirements.txt)
Please help.
Thanks,
Tom
	</description>
	<comments>
		<comment id='1' author='tnhaider' date='2019-11-20T10:25:10Z'>
		Thanks for pointing out the requirements issue. It's now been fixed.
So there are a few things to check. With the data format, the model expects one line per sentence and an empty line separating documents.
e.g.
"sentence1
sentence2
sentence3
sentence4
sentence5
..."
You might also want to adjust the max_docs argument when you're initializing the Processor object. In the examples scripts it's set to 30 but you should try a higher number and see if that helps
		</comment>
		<comment id='2' author='tnhaider' date='2019-11-20T13:29:01Z'>
		Hi,
Thanks for getting back at me.
But this is the format that I supply. It's just that sometimes I might have two sentences per line.
So my format is
"
line1
line2
line3
line4
..."
This is what gets me the IndexError: Cannot choose from an empty sequence.
Removing the max_docs argument did nothing.
Best,
Tom
		</comment>
		<comment id='3' author='tnhaider' date='2019-11-20T14:25:05Z'>
		Hi Tom, I was able to replicate your error when I gave the model a file in the same format. The BERT model cannot process this kind of input because of the Next Sentence Prediction task which asks whether a pair of sentences occur in the same document and one after the other. Since your documents are only one sentence long, it's impossible to generate these pairs.
So I can think of 2 solutions off the top of my head:

If you are working with standardly formatted poetry, you might want to treat each stanza as a document.

"stanza_1_line_1
stanza_1_line_2
stanza_2_line_1
stanza_2_line_2
..."

Alternatively, if you are trying to preserve stanza breaks, you could try supply some substitute token.

"poem_1_line_1
poem_1_line_2
[STNZBRK]
poem_1_line_3
poem_1_line_4
poem_2_line_1
poem_2_line_2
..."
		</comment>
		<comment id='4' author='tnhaider' date='2019-11-20T14:43:08Z'>
		I should also mention that you can switch off Next Sentence Prediction in the Processor class with the next_sent_pred argument. This might work with your current data format
		</comment>
		<comment id='5' author='tnhaider' date='2019-11-20T15:23:35Z'>
		Alright, many thanks.
I will try asap.
		</comment>
		<comment id='6' author='tnhaider' date='2019-11-21T08:04:55Z'>
		When you try again, you also might wanna get this latest fix &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/158&gt;#158&lt;/denchmark-link&gt;
 here, which I merged into master this morning. There was a bug causing duplicate samples in the dataset.
		</comment>
		<comment id='7' author='tnhaider' date='2019-11-22T01:26:40Z'>
		Works great now. Keep up the good work.
		</comment>
	</comments>
</bug>