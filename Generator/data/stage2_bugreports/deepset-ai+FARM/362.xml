<bug id='362' author='stefan-it' open_date='2020-05-13T11:53:21Z' closed_time='2020-05-28T10:36:12Z'>
	<summary>Fix activation function for pooled ELECTRA output</summary>
	<description>
Hi,
inspired by &lt;denchmark-link:https://github.com/huggingface/transformers/pull/4257&gt;huggingface/transformers#4257&lt;/denchmark-link&gt;
 I just had a look at the original ELECTRA implementation, and it seems that they're using  instead of  for getting a pooled output:
&lt;denchmark-link:https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L247&gt;https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L247&lt;/denchmark-link&gt;

and:
&lt;denchmark-link:https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L45&gt;https://github.com/google-research/electra/blob/79111328070e491b287c307906701ebc61091eb2/model/modeling.py#L45&lt;/denchmark-link&gt;

Unfortunately, I used tanh in the ELECTRA model integration:



FARM/farm/modeling/language_model.py


         Line 1240
      in
      37591d1






 config.summary_activation = 'tanh' 





I will open a PR to fix that :)
	</description>
	<comments>
		<comment id='1' author='stefan-it' date='2020-05-28T10:36:11Z'>
		Implemented in &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/364&gt;#364&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>