<bug id='30' author='tholor' open_date='2019-08-01T11:00:30Z' closed_time='2019-08-02T14:24:06Z'>
	<summary>Accuracy metric in LM finetuning always zero</summary>
	<description>
The accuracy metric reported by the Evaluator for masked LM task during LM finetuning is wrong. This is due to the fact that we have there a nested list of predictions with different lengths (different number of masked tokens per sample). This leads to wrongly converted numpy arrays and a wrong metric. I am working on a fix.
	</description>
	<comments>
		<comment id='1' author='tholor' date='2019-08-02T14:24:05Z'>
		Fixed by &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/31&gt;#31&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>