<bug id='70' author='JulianGerhard21' open_date='2019-08-28T06:14:45Z' closed_time='2019-08-30T15:18:37Z'>
	<summary>'NERProcessor' has no attribute 'tokenizer'</summary>
	<description>
Python: 3.6.8
OS: Windows 10
FARM: 0.2.0
Hi guys,
if I want to run FARM to do some NER finetuning, I tried both approaches:
experiments = load_experiments("conll_de_config.json")
and the stick-your-blocks-together one. Both of them ended with the following error:
&lt;denchmark-code&gt;08/28/2019 07:47:35 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
08/28/2019 07:47:35 - INFO - pytorch_transformers.tokenization_utils -   loading file https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased-vocab.txt from cache at C:\Users\JulianGerhard\.cache\torch\pytorch_transformers\da299cdd121a3d71e1626f2908dda0d02658f42e925a3d6abd8273ec08cf41a6.2a48e6c60dcdb582effb718237ce5894652e3b4abb94f0a4d9a857b70333308d
08/28/2019 07:47:35 - INFO - farm.data_handler.data_silo -   
Loading data into the data silo ... 
              ______
               |o  |   !
   __          |:`_|---'-.
  |__|______.-/ _ \-----.|       
 (o)(o)------'\ _ /     ( )      
 
08/28/2019 07:47:35 - INFO - farm.data_handler.data_silo -   Loading train set from: data/conll03-de\train.txt 
08/28/2019 07:47:35 - INFO - farm.data_handler.utils -    Couldn't find data/conll03-de\train.txt locally. Trying to download ...
08/28/2019 07:47:35 - INFO - farm.data_handler.utils -   downloading and extracting file C:\Users\JulianGerhard\PycharmProjects\word_embeddings\ner_finetuning\data\conll03-de to dir 
08/28/2019 07:47:39 - INFO - farm.data_handler.processor -   Got ya 8 parallel workers to fill the baskets with samples (chunksize = 1000)...
  0%|          | 0/24000 [00:00&lt;?, ?it/s]multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "C:\Users\JulianGerhard\AppData\Local\Programs\Python\Python36\lib\multiprocessing\pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "C:\Users\JulianGerhard\AppData\Local\Programs\Python\Python36\lib\multiprocessing\pool.py", line 44, in mapstar
    return list(map(*args))
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\processor.py", line 310, in _multiproc_sample
    samples = cls._dict_to_samples(dict=basket.raw, all_dicts=all_dicts)
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\processor.py", line 555, in _dict_to_samples
    tokenized = tokenize_with_metadata(dict["text"], cls.tokenizer, cls.max_seq_len)
AttributeError: type object 'NERProcessor' has no attribute 'tokenizer'
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:/Users/JulianGerhard/PycharmProjects/word_embeddings/ner_finetuning/farm_experimen t.py", line 6, in &lt;module&gt;
    run_experiment(experiments[0])
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\experiment.py", line 87, in run_experiment
    distributed=distributed,
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\data_silo.py", line 39, in __init__
    self._load_data()
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\data_silo.py", line 47, in _load_data
    self.data["train"], self.tensor_names = self.processor.dataset_from_file(train_file)
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\processor.py", line 366, in dataset_from_file
    self._init_samples_in_baskets()
  File "c:\users\juliangerhard\pycharmprojects\farm\farm\data_handler\processor.py", line 304, in _init_samples_in_baskets
    zip(samples, self.baskets), total=len(self.baskets)
  File "C:\Users\JulianGerhard\AppData\Local\Programs\Python\Python36\lib\site-packages\tqdm\_tqdm.py", line 1034, in __iter__
    for obj in iterable:
  File "C:\Users\JulianGerhard\AppData\Local\Programs\Python\Python36\lib\multiprocessing\pool.py", line 320, in &lt;genexpr&gt;
    return (item for chunk in result for item in chunk)
  File "C:\Users\JulianGerhard\AppData\Local\Programs\Python\Python36\lib\multiprocessing\pool.py", line 735, in next
    raise value
AttributeError: type object 'NERProcessor' has no attribute 'tokenizer'
  0%|          | 0/24000 [00:06&lt;?, ?it/s]

&lt;/denchmark-code&gt;

I installed twice - from repo and with pip.
After investigating this shortly (I need to leave), I think it has something to do with your NERProcessor's classmethod implementation. I can confirm that the tokenizer is set properly:
 &lt;farm.modeling.tokenization.BertTokenizer object at 0x00000238DE551080&gt;
and the cls instance, _dict_to_samples is receiving is of type:
&lt;class 'farm.data_handler.processor.NERProcessor'&gt;
Any ideas?
Regards
	</description>
	<comments>
		<comment id='1' author='JulianGerhard21' date='2019-08-28T06:58:19Z'>
		I just did a quick check and couldn't reproduce this issue on my linux machine. Both modes seem to work for NER.
I suspect your error is due to how Windows handles multiprocessing (see &lt;denchmark-link:https://stackoverflow.com/questions/42148344/python-multiprocessing-linux-windows-difference&gt;https://stackoverflow.com/questions/42148344/python-multiprocessing-linux-windows-difference&lt;/denchmark-link&gt;
). Since the tokenizer is a class attribute of Processor and not an instance attribute, this might cause problems in inidividual processes.
We will investigate this further ...
		</comment>
		<comment id='2' author='JulianGerhard21' date='2019-08-30T15:18:37Z'>
		Hi &lt;denchmark-link:https://github.com/JulianGerhard21&gt;@JulianGerhard21&lt;/denchmark-link&gt;
. This issue has been resolved by &lt;denchmark-link:https://github.com/deepset-ai/FARM/pull/76&gt;#76&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>