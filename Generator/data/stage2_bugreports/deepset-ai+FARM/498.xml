<bug id='498' author='djstrong' open_date='2020-08-23T16:40:34Z' closed_time='2020-11-08T09:30:24Z'>
	<summary>legacy multi-label data representation in eval metrics</summary>
	<description>
Error message
Traceback (most recent call last):
File "ner.py", line 115, in 
ner()
File "ner.py", line 94, in ner
trainer.train()
File "/farm-train/FARM/farm/train.py", line 306, in train
result = evaluator_dev.eval(self.model)
File "/farm-train/FARM/farm/eval.py", line 104, in eval
compute_metrics(metric=head.metric, preds=preds_all[head_num], labels=label_all[head_num]
File "/farm-train/FARM/farm/evaluation/metrics.py", line 79, in compute_metrics
return acc_and_f1(preds, labels)
File "/farm-train/FARM/farm/evaluation/metrics.py", line 55, in acc_and_f1
f1 = f1_score(y_true=labels, y_pred=preds)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/utils/validation.py", line 72, in inner_f
return f(**kwargs)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1047, in f1_score
zero_division=zero_division)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/utils/validation.py", line 72, in inner_f
return f(**kwargs)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1175, in fbeta_score
zero_division=zero_division)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/utils/validation.py", line 72, in inner_f
return f(**kwargs)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1434, in precision_recall_fscore_support
pos_label)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1250, in _check_set_wise_labels
y_type, y_true, y_pred = _check_targets(y_true, y_pred)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 82, in _check_targets
type_true = type_of_target(y_true)
File "/farm-train/venv/lib/python3.7/site-packages/sklearn/utils/multiclass.py", line 263, in type_of_target
raise ValueError('You appear to be using a legacy multi-label data'
ValueError: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.
To Reproduce
Run ner example with metric changed to acc_f1 (as I need per token accuracy).
System:
scikit-learn 0.23.2
	</description>
	<comments>
		<comment id='1' author='djstrong' date='2020-08-25T17:20:38Z'>
		Thanks for reporting this bug &lt;denchmark-link:https://github.com/djstrong&gt;@djstrong&lt;/denchmark-link&gt;
 .
Solution seems straightforward: &lt;denchmark-link:https://stackoverflow.com/questions/34213199/scikit-learn-multilabel-classification-valueerror-you-appear-to-be-using-a-leg&gt;https://stackoverflow.com/questions/34213199/scikit-learn-multilabel-classification-valueerror-you-appear-to-be-using-a-leg&lt;/denchmark-link&gt;

Would you be interested in creating a PR? Otherwise, we will tackle it with our team.
		</comment>
		<comment id='2' author='djstrong' date='2020-08-25T17:38:17Z'>
		Actually I have used seqeval.metrics.acc_score, which works properly for sequences.
MultiLabelBinarizer solution would be wrong.
So, you should keep separate metrics for token classification and text classification or create more universal.
		</comment>
		<comment id='3' author='djstrong' date='2020-08-26T07:12:49Z'>
		Ok, we will have a look at it. As there are several workarounds (older sklearn version or acc_score metrics via register_metrics), this will have lower priority for us though.
		</comment>
		<comment id='4' author='djstrong' date='2020-10-25T07:25:56Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed in 14 days if no further activity occurs.
		</comment>
	</comments>
</bug>