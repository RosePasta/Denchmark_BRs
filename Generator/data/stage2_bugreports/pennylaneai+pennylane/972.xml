<bug id='972' author='l45k' open_date='2020-12-21T14:14:56Z' closed_time='2020-12-22T06:52:12Z'>
	<summary>Tensorflow interface gradients only work with backprop diff_method</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue description&lt;/denchmark-h&gt;

I have a quantum hybride model using the tensorflow interface. The QVC output is multiplied by a Tensorflow Variable befor it is returned. The model can be trained with using backprop mode on the default.qubit.tf device. When I change the diff-mode to parameter-shift or use the default.qubit device, the following error occoures.
&lt;denchmark-h:h4&gt;Traceback&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;2020-12-21 09:01:02.244446: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic     library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2020-12-21 09:01:02.244474: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not     have a GPU set up on your machine.
2020-12-21 09:01:04.098959: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-12-21 09:01:04.099109: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-12-21 09:01:04.099127: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2020-12-21 09:01:04.099144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shela): /proc/driver/nvidia/version does not exist
2020-12-21 09:01:04.100426: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:AutoGraph could not transform &lt;function to_tf at 0x7f95b4e3dd90&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &lt;gast.gast.Expr object at 0x7f95246c69e8&gt;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform &lt;function to_tf at 0x7f95b4e3dd90&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &lt;gast.gast.Expr object at 0x7f95246c69e8&gt;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Traceback (most recent call last):
  File "test.py", line 39, in &lt;module&gt;
    y_hat = tf.map_fn(model, x)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 605, in     new_func
    return func(*args, **kwargs)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 538, in new_func
    return func(*args, **kwargs)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/ops/map_fn.py", line 659, in map_fn_v2
   name=name)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 538, in new_func
return func(*args, **kwargs)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/ops/map_fn.py", line 515, in map_fn
maximum_iterations=n)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
loop_vars = body(*loop_vars)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2726, in &lt;lambda&gt;
body = lambda i, lv: (i + 1, orig_body(*lv))
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/ops/map_fn.py", line 499, in compute
result_value = autographed_fn(elems_value)
  File "/home/admin1/Documents/Python/py/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 670, in     wrapper
raise e.ag_error_metadata.to_exception(e)
    TypeError: in user code:

    test.py:26 __call__  *
        result = parallel_quantum_model(state, self.weights)

    TypeError: parallel_quantum_model() takes 2 positional arguments but 3 were given
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Sourcecode&lt;/denchmark-h&gt;

The following can reproduce the error. Note that  with diff_method='backprop' everything is fine.
import pennylane as qml
from pennylane import numpy as np
import tensorflow as tf
class Model:
&lt;denchmark-code&gt;    def __init__(self):

        weights = tf.ones([2])
        self.weights = tf.Variable(weights)

        self.lin = tf.Variable(tf.ones([1]))

        self.dev = qml.device("default.qubit.tf", wires=1)

    def __call__(self, state, *args, **kwargs):
        @qml.qnode(self.dev, interface='tf', diff_method='parameter-shift')
        def parallel_quantum_model(state, weights):
            qml.RX(state, wires=0)
            qml.RZ(weights[0], wires=0)
            qml.RY(weights[1], wires=0)

            return [qml.expval(qml.PauliZ(wires=i)) for i in range(1)]


        result = parallel_quantum_model(state, self.weights)
        result = tf.cast(result, tf.float32)
        result = self.lin * result
        return tf.keras.backend.softmax(result)

model = Model()
optim = tf.optimizers.Adam(learning_rate=0.01)
x = tf.cast(tf.linspace(0, 1, 10), tf.float32)
y = x**2

with tf.GradientTape() as tape:
    tape.watch(model.weights)
    tape.watch(model.lin)
    y_hat = tf.map_fn(model, x)
    loss = tf.reduce_mean((y_hat - y)**2)
dy = tape.gradient(loss, [model.weights, model.lin])
optim.apply_gradients(zip(dy, [model.weights, model.lin]))
&lt;/denchmark-code&gt;

I use tf=2.4.0 and pennylane=0.13.0. Here is the about() output.
Name: PennyLane
Version: 0.13.0
Summary: PennyLane is a Python quantum machine learning library by Xanadu Inc.
Home-page: &lt;denchmark-link:https://github.com/XanaduAI/pennylane&gt;https://github.com/XanaduAI/pennylane&lt;/denchmark-link&gt;

Author: None
Author-email: None
License: Apache License 2.0
Location: /home/admin1/Documents/Python/py/lib/python3.6/site-packages
Requires: appdirs, numpy, scipy, networkx, autograd, semantic-version, toml
Required-by: PennyLane-qiskit
Platform info:           Linux-5.4.0-58-generic-x86_64-with-Ubuntu-18.04-bionic
Python version:          3.6.9
Numpy version:           1.19.4
Scipy version:           1.5.4
Installed devices:

default.gaussian (PennyLane-0.13.0)
default.mixed (PennyLane-0.13.0)
default.qubit (PennyLane-0.13.0)
default.qubit.autograd (PennyLane-0.13.0)
default.qubit.tf (PennyLane-0.13.0)
default.tensor (PennyLane-0.13.0)
default.tensor.tf (PennyLane-0.13.0)
qiskit.aer (PennyLane-qiskit-0.13.0)
qiskit.basicaer (PennyLane-qiskit-0.13.0)
qiskit.ibmq (PennyLane-qiskit-0.13.0)

This issue is very unpleasent, since the tf interface only works with the default.qubit.tf device and the backprop method.
I am happy to solve it if, you havy any idea, where to start.
	</description>
	<comments>
		<comment id='1' author='l45k' date='2020-12-21T14:34:38Z'>
		Hi &lt;denchmark-link:https://github.com/l45k&gt;@l45k&lt;/denchmark-link&gt;
!
Thanks for reporting this bug. I had a go running your example, and found that it currently works in &lt;denchmark-link:https://pennylane.readthedocs.io/en/latest/code/qml_tape.html&gt;tape mode&lt;/denchmark-link&gt;
, the new PennyLane core (code attached below).
Let me know if it works for you! Tape mode is still experimental, but we are working on feature parity.
In the meantime, I will dig deeper, and see why this doesn't seem to work in non-tape mode.
import pennylane as qml
from pennylane import numpy as np
import tensorflow as tf

# enable tape mode
qml.enable_tape()


class Model:
    def __init__(self):

        weights = tf.ones([2], dtype=tf.float64)
        self.weights = tf.Variable(weights)

        self.lin = tf.Variable(tf.ones([1], dtype=tf.float64))

        self.dev = qml.device("default.qubit.tf", wires=1)

    def __call__(self, state, *args, **kwargs):

        @qml.qnode(self.dev, interface="tf", diff_method="parameter-shift")
        def parallel_quantum_model(state, weights):
            qml.RX(state, wires=0)
            qml.RZ(weights[0], wires=0)
            qml.RY(weights[1], wires=0)

            return [qml.expval(qml.PauliZ(wires=i)) for i in range(1)]

        result = parallel_quantum_model(state, self.weights)
        result = tf.cast(result, tf.float64)
        result = self.lin * result
        return tf.keras.backend.softmax(result)


model = Model()
optim = tf.optimizers.Adam(learning_rate=0.01)
x = tf.cast(tf.linspace(0, 1, 10), dtype=tf.float64)
y = x ** 2

with tf.GradientTape() as tape:
    tape.watch(model.weights)
    tape.watch(model.lin)
    y_hat = tf.map_fn(model, x)
    loss = tf.reduce_mean((y_hat - y) ** 2)

dy = tape.gradient(loss, [model.weights, model.lin])
optim.apply_gradients(zip(dy, [model.weights, model.lin]))
		</comment>
		<comment id='2' author='l45k' date='2020-12-21T14:48:57Z'>
		&lt;denchmark-link:https://github.com/l45k&gt;@l45k&lt;/denchmark-link&gt;
 I suspect this bug in non-tape mode is not a bug per se, but an unavoidable restriction of how non-tape mode works. In the original PennyLane QNode, we are quite restrictive in how QNode signatures must look:

Trainable arguments of the QNode must always be defined and passed as positional arguments
Non-trainable arguments of the QNode must always be defined and passed as keyword arguments, and only as NumPy arrays.

Currently, the state argument is non-trainable, but is being passed as a positional argument.
Part of the reason behind the new tape-mode is to remove these restrictions, which seems to get this particular construction working.
		</comment>
		<comment id='3' author='l45k' date='2020-12-21T21:25:16Z'>
		Hey &lt;denchmark-link:https://github.com/josh146&gt;@josh146&lt;/denchmark-link&gt;
,
thanks  for your help!
&lt;denchmark-code&gt;# enable tape mode
qml.enable_tape()
&lt;/denchmark-code&gt;

solved the issue. I wasn't aware of the feature, but it helped a lot!
Thank you very much!
		</comment>
		<comment id='4' author='l45k' date='2020-12-22T06:52:12Z'>
		No worries, glad it's working &lt;denchmark-link:https://github.com/l45k&gt;@l45k&lt;/denchmark-link&gt;
! Note that tape mode is still experimental, and not all parts of PennyLane yet work with it (but this is something we are actively improving). I'll close this issue for now, but if you notice anything else please feel free to open another issue!
		</comment>
	</comments>
</bug>