<bug id='888' author='mariaschuld' open_date='2020-11-04T08:29:15Z' closed_time='2020-11-06T09:27:36Z'>
	<summary>Arithmetic operations between pennylane.numpy arrays have inconsistent `requires_grad` output</summary>
	<description>
Issue
The PennyLane wrapper if the numpy library, which is used to optimise circuits with the standard autograd interface, has an inconsistent behaviour when using arithmetic functions such as +, -, * (here using the sum to demonstrate).
Summing two pennylane.numpy.array objects, one having gradients enabled and the other not, returns a differentiable array or not, depending on the order.
import pennylane as qml
from pennylane import numpy as np

a = np.array(1., requires_grad=True)
b = np.array(0., requires_grad=False)

c = a+b
print(c.requires_grad) # True

d = b+a
print(d.requires_grad) # False
Expected behaviour
The requires_grad = True flag should always be overwriting, and the output of the two print statements should be true in both cases. This is important for example in loss function where target outputs (which do not require gradients) and predictions (which depend on the parameters and require gradients) are compared, i.e. via np.sum(np.abs((target - prediction))**2).
System information
Reproducible with PennyLane v0.12 stable release, and with the current master, in tape mode or not in tape mode.
	</description>
	<comments>
	</comments>
</bug>