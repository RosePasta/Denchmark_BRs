<bug id='8760' author='felixglow' open_date='2019-04-12T03:57:00Z' closed_time='2019-05-01T05:54:24Z'>
	<summary>when i use spark, this error occurs: Failed to connect to MetricsMasterClient</summary>
	<description>
1. error:
when i use spark-shell to fetch file from alluxio, this error occurs......
scala&gt; val s = sc.textFile("alluxio://172.28.172.165:18998/LICENSE")
s: org.apache.spark.rdd.RDD[String] = alluxio://172.28.172.165:18998/LICENSE MapPartitionsRDD[1] at textFile at :24
scala&gt; s.count()
2019-04-12 03:22:36 WARN  AbstractClient:296 - Failed to handshake (1) with MetricsMasterClient @ spark-master/172.17.0.2:19998: Failed to handshake with master spark-master/172.17.0.2:19998 to load cluster default configuration values
2019-04-12 03:22:36 ERROR ClientMasterSync:66 - Failed to heartbeat to the metrics master:
alluxio.exception.status.UnavailableException: Failed to connect to MetricsMasterClient @ spark-master/172.17.0.2:19998 after 1 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:322)
at alluxio.client.metrics.MetricsMasterClient.heartbeat(MetricsMasterClient.java:84)
at alluxio.client.metrics.ClientMasterSync.heartbeat(ClientMasterSync.java:63)
at alluxio.heartbeat.HeartbeatThread.run(HeartbeatThread.java:74)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
2. deploy:
I use docker to deploy alluxio and spark
alluxio version: 1.8.1          1 master  2 workers
alluxio image:
&lt;denchmark-link:https://hub.docker.com/r/alluxio/alluxio&gt;https://hub.docker.com/r/alluxio/alluxio&lt;/denchmark-link&gt;

master docker run:
docker run -d --net=host -e ALLUXIO_MASTER_HOSTNAME=172.28.172.165 -e ALLUXIO_MASTER_PORT=18998 -e ALLUXIO.MASTER.WEB.PORT=18999 -e ALLUXIO_UNDERFS_ADDRESS=s3a://testfile/zzz -e ALLUXIO_UNDERFS_S3_ENDPOINT=&lt;denchmark-link:http://172.28.172.44:9000&gt;http://172.28.172.44:9000&lt;/denchmark-link&gt;
 -e ALLUXIO_USER_FILE_WRITETYPE_DEFAULT=CACHE_THROUGH -e ALLUXIO_UNDERFS_S3_DISABLE_DNS_BUCKETS=true -e ALLUXIO_UNDERFS_S3A_INHERIT_ACL=false -e AWS_ACCESSKEYID=admin1 -e AWS_SECRETKEY=wJalrXUtnFxxxxxxxxx alluxio/alluxio master
worker docker run:
docker run -d  -e ALLUXIO_MASTER_PORT=18998 --net=host -v /mnt/ramdisk:/opt/alluxio/ramdisk  -e ALLUXIO_UNDERFS_ADDRESS=s3a://testfile/zzz  -e ALLUXIO_WORKER_MEMORY_SIZE=100G -e ALLUXIO_UNDERFS_S3_ENDPOINT=&lt;denchmark-link:http://172.28.172.44:9000&gt;http://172.28.172.44:9000&lt;/denchmark-link&gt;
 -e ALLUXIO_USER_FILE_WRITETYPE_DEFAULT=CACHE_THROUGH -e ALLUXIO_UNDERFS_S3_DISABLE_DNS_BUCKETS=true -e ALLUXIO_UNDERFS_S3A_INHERIT_ACL=false -e AWS_ACCESSKEYID=admin -e AWS_SECRETKEY=wJalrXUtnxxxxxxxxxxxxxxxx  -e ALLUXIO_MASTER_HOSTNAME=172.28.172.165 -e ALLUXIO_RAM_FOLDER=/opt/alluxio/ramdisk    alluxio/alluxio worker
under stores:
minio
&lt;denchmark-link:https://www.alluxio.org/docs/1.8/en/ufs/Minio.html&gt;https://www.alluxio.org/docs/1.8/en/ufs/Minio.html&lt;/denchmark-link&gt;

I also used local storage

master docker run:
docker run --name spark-master -h spark-master -e ENABLE_INIT_DAEMON=false -p 8080:8080 -p 7077:7077 -p 6066:6066 -v /home/sre/software/alluxio/alluxio-1.8.1-hadoop-2.8/client:/jar -d bde2020/spark-master
spark image:
&lt;denchmark-link:https://github.com/big-data-europe/docker-spark&gt;https://github.com/big-data-europe/docker-spark&lt;/denchmark-link&gt;

Please help me, I have spent two days - -ÔºÅ
	</description>
	<comments>
		<comment id='1' author='felixglow' date='2019-04-12T15:16:35Z'>
		Hi &lt;denchmark-link:https://github.com/felixglow&gt;@felixglow&lt;/denchmark-link&gt;
 Can you check what the master logs say? From the spark-shell docker container, can it connect to the master container (172.17.0.2 from the error message)? It is strange that the alluxio URI has the port 18998, but the client is trying to connect to different port 19998.
Also, is the worker able to connect to the master? You can check by looking into the worker log, or by seeing the master UI to see if the worker is registered.
Lastly, you can try disabling the client metrics by adding this Java option to the spark-shell alluxio.user.metrics.collection.enabled=false
		</comment>
		<comment id='2' author='felixglow' date='2019-04-13T04:20:19Z'>
		I tried it as you said, it doesn't work. i redeploy an alluxio cluster without docker,  it's okay,  i don't know the reason, alluxio's configure is the same.

Hi @felixglow Can you check what the master logs say? From the spark-shell docker container, can it connect to the master container (172.17.0.2 from the error message)? It is strange that the alluxio URI has the port 18998, but the client is trying to connect to different port 19998.
Also, is the worker able to connect to the master? You can check by looking into the worker log, or by seeing the master UI to see if the worker is registered.
Lastly, you can try disabling the client metrics by adding this Java option to the spark-shell alluxio.user.metrics.collection.enabled=false

		</comment>
		<comment id='3' author='felixglow' date='2019-04-23T17:33:35Z'>
		&lt;denchmark-link:https://github.com/felixglow&gt;@felixglow&lt;/denchmark-link&gt;
 has this issue been resolved?
		</comment>
		<comment id='4' author='felixglow' date='2019-04-24T02:29:17Z'>
		
@felixglow has this issue been resolved?

I deployed it with a virtual machine, it's ok, the problem has not appeared again.
		</comment>
		<comment id='5' author='felixglow' date='2019-05-01T05:54:24Z'>
		I will close this issue for now. Feel free to reopen it if you see this happen again
		</comment>
	</comments>
</bug>