<bug id='9796' author='mkressirer' open_date='2019-08-27T16:10:02Z' closed_time='2020-05-01T23:03:42Z'>
	<summary>Eviction and Allocator on multi-tier storage not working</summary>
	<description>
Alluxio Version:
2.0.1
Describe the bug
Multi-Tier storage 3x MEM(25GB/SSD 24GB /HDD 99GB) on 8 cores 32GB 10GiB network is not evicting data from MEM to the configured SSD.
SpaceReserver failed to free 20132659200 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 20132659200 bytes space at location MEM 
It does look very much as this area of the code points into a looping issues.
/**
   * Tries to get an eviction plan to free a certain amount of space in the given location, and
   * carries out this plan with the best effort.
   *
   * @param sessionId the session id
   * @param availableBytes amount of space in bytes to free
   * @param location location of space
   * @param mode the eviction mode
   * @throws WorkerOutOfSpaceException if it is impossible to achieve the free requirement
   */
  private void freeSpaceInternal(long sessionId, long availableBytes, BlockStoreLocation location,
      Evictor.Mode mode) throws WorkerOutOfSpaceException, IOException {
    EvictionPlan plan;
    // NOTE:change the read lock to the write lock due to the endless-loop issue [ALLUXIO-3089]
    try (LockResource r = new LockResource(mMetadataWriteLock)) {
      plan = mEvictor.freeSpaceWithView(availableBytes, location, getUpdatedView(), mode);
      // Absent plan means failed to evict enough space.
      if (plan == null) {
        throw new WorkerOutOfSpaceException(
            ExceptionMessage.NO_EVICTION_PLAN_TO_FREE_SPACE, availableBytes, location.tierAlias());
      }
    }
To Reproduce
Standup Standalone cluster with 3 nodes - and write a distributed workload against Alluxio Cluster.
Expected behavior
Data is evicted from highest tier into the next configured tier
Urgency
Pretty much unusable for IO aware workloads and contradicts the purpose of a multi-tier storage system.

This is a fairly light workload just writing some files from multiple nodes.
Workload ran into storage limit on MEM:
&lt;denchmark-link:https://user-images.githubusercontent.com/20521073/63781692-1d24cf00-c8b8-11e9-8e87-3ad2d4809d9a.png&gt;&lt;/denchmark-link&gt;

restart one of the 3 nodes: (eviction happens as configured)
&lt;denchmark-link:https://user-images.githubusercontent.com/20521073/63781547-e9e24000-c8b7-11e9-8c8a-0e70d7320b5e.png&gt;&lt;/denchmark-link&gt;

the individual node (now correctly rebalanced after restart) - Also the ORDER of the configured storage levels is UPSIDEDOWN (when you go to the individual worker).
&lt;denchmark-link:https://user-images.githubusercontent.com/20521073/63781853-6e34c300-c8b8-11e9-9b5e-e1cb681c007b.png&gt;&lt;/denchmark-link&gt;

and the other two nodes ... not restarted no active workload running:
&lt;denchmark-link:https://user-images.githubusercontent.com/20521073/63781923-8e648200-c8b8-11e9-9f33-c073e6c349cb.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/20521073/63781935-91f80900-c8b8-11e9-90ab-114a9c874f30.png&gt;&lt;/denchmark-link&gt;

for simplicity you can also recreate the same issue by just configuring it without memory requirements as above and just use a two tier setup.
&lt;denchmark-code&gt;alluxio.user.file.readtype.default=CACHE_PROMOTE
alluxio.user.file.writetype.default=ASYNC_THROUGH

alluxio.worker.allocator.class=alluxio.worker.block.allocator.MaxFreeAllocator
alluxio.worker.evictor.class=alluxio.worker.block.evictor.LRUEvictor
alluxio.worker.tieredstore.reserver.enabled=true

alluxio.worker.tieredstore.levels=2

alluxio.worker.tieredstore.level0.alias=SSD
alluxio.worker.tieredstore.level0.dirs.path=/ssd
alluxio.worker.tieredstore.level0.dirs.quota=5GB
alluxio.worker.tieredstore.level0.watermark.high.ratio=0.70
alluxio.worker.tieredstore.level0.watermark.low.ratio=0.5
alluxio.worker.tieredstore.level1.alias=HDD
alluxio.worker.tieredstore.level1.dirs.path=/hdd
alluxio.worker.tieredstore.level1.dirs.quota=100GB
alluxio.worker.tieredstore.level1.watermark.high.ratio=0.9
alluxio.worker.tieredstore.level1.watermark.low.ratio=0.75
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mkressirer' date='2019-09-23T20:43:18Z'>
		Hi &lt;denchmark-link:https://github.com/mkressirer&gt;@mkressirer&lt;/denchmark-link&gt;
 Thanks for reporting the issue.
The alluxio.worker.tieredstore.reserver.enabled=true is an old property that is deprecated in 2.0+ Alluxio versions. In the new Alluxio version, reserver is enabled by default, and you can define the time period of space reserver by setting the value of alluxio.worker.tieredstore.reserver.interval.ms.
The tier storage will try to traverse the blocks to find out blocks to be evicted. NO_EVICTION_PLAN_TO_FREE_SPACE means we cannot find any blocks to be evicted belonging to the target tier.
I tried to reproduce the error by the following configuration:
&lt;denchmark-code&gt;alluxio.worker.allocator.class=alluxio.worker.block.allocator.MaxFreeAllocator
alluxio.worker.evictor.class=alluxio.worker.block.evictor.LRUEvictor

alluxio.master.journal.type=UFS
alluxio.master.journal.folder=hdfs://&lt;&gt;

alluxio.worker.tieredstore.levels=2
alluxio.worker.tieredstore.level0.alias=MEM
alluxio.worker.tieredstore.level0.dirs.path=/mnt/ramdisk
alluxio.worker.tieredstore.level0.dirs.quota=22GB

alluxio.worker.tieredstore.level1.alias=SSD
alluxio.worker.tieredstore.level1.dirs.path=/tmp/alluxio/tier_SSD
alluxio.worker.tieredstore.level1.dirs.quota=50GB

alluxio.master.mount.table.root.ufs=s3a://&lt;bucket&gt;
&lt;/denchmark-code&gt;

The cluster has 4 nodes (1 master and 3 workers [60GB mem])
and generate 1GB files from all 4 nodes.
Evictions do happen and keep evicting files from MEM to SSD.
One of my guesses is that the worker node may periodically have bad access to its memory tier.
Are evictions fail again after you restart the cluster?
		</comment>
		<comment id='2' author='mkressirer' date='2019-09-24T20:30:26Z'>
		&lt;denchmark-link:https://github.com/mkressirer&gt;@mkressirer&lt;/denchmark-link&gt;
 Could you provide me more details regarding the environment and workflow that introduce this error?
(1) What workflow are you running? What's the file size you are writing?
(2) What kind of UFS you are writing to with write type ASYNC_THROUGH?
(3) Does the error consistently occur and even happen after restarting the worker?
(4) Are the ramdisk/SSD accessible when the error occurs?
		</comment>
		<comment id='3' author='mkressirer' date='2019-10-23T00:26:28Z'>
		&lt;denchmark-link:https://github.com/mkressirer&gt;@mkressirer&lt;/denchmark-link&gt;
 - please help with a response to reproduce the issue, we will track this issue for another few weeks before closing.
		</comment>
		<comment id='4' author='mkressirer' date='2019-10-29T17:49:48Z'>
		1)The total size of this specific output job is roughly 80GB ... in block size 256MB ... from a spark cluster
2) I used S3 and NFS to check if they behave differently (they both fail the same way)
3) after restaring the alluxio worker it magically syncs and shuffles data down to the lower tier (based on the thresholds).
4) the ramdisks/SSD are full accessible and work just as expected when targeted as a single tier.
		</comment>
		<comment id='5' author='mkressirer' date='2020-01-18T01:32:42Z'>
		&lt;denchmark-link:https://github.com/LuQQiu&gt;@LuQQiu&lt;/denchmark-link&gt;
 Any further thoughts on the issue?
		</comment>
		<comment id='6' author='mkressirer' date='2020-01-20T19:14:00Z'>
		Still unable to reproduce the issue. This issue may be related to concrete env.
		</comment>
		<comment id='7' author='mkressirer' date='2020-01-20T21:19:03Z'>
		&lt;denchmark-link:https://github.com/mkressirer&gt;@mkressirer&lt;/denchmark-link&gt;
 Based on your configuration eviction failures are expected. To verify, could you please retry your tests with MUST_CACHE write-type?
		</comment>
		<comment id='8' author='mkressirer' date='2020-03-24T08:03:26Z'>
		I have the same problem
Alluxio Version:
2.1.1
Describe the bug
Multi-Tier storage 2x (MEM 10GB, HDD 100GB) on 8 cores 32GB
&lt;denchmark-code&gt;2020-03-24 03:59:22,262 WARN  SpaceReserver - SpaceReserver failed to free 1932735283 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 1932735283 bytes space at location MEM
&lt;/denchmark-code&gt;

alluxio-site.properties
&lt;denchmark-code&gt;alluxio.worker.memory.size=10GB
alluxio.worker.tieredstore.levels=2
alluxio.worker.tieredstore.level0.alias=MEM
alluxio.worker.tieredstore.level0.dirs.path=/mnt/ramdisk
alluxio.worker.tieredstore.level0.dirs.mediumtype=MEM
alluxio.worker.tieredstore.level0.dirs.quota=10GB
alluxio.worker.tieredstore.level0.watermark.high.ratio=0.9
alluxio.worker.tieredstore.level0.watermark.low.ratio=0.7
alluxio.worker.tieredstore.level1.alias=HDD
alluxio.worker.tieredstore.level1.dirs.path=/grid/0
alluxio.worker.tieredstore.level1.dirs.mediumtype=HDD
alluxio.worker.tieredstore.level1.dirs.quota=100GB
alluxio.worker.tieredstore.level1.watermark.high.ratio=0.9
alluxio.worker.tieredstore.level1.watermark.low.ratio=0.7

alluxio.user.file.readtype.default=CACHE_PROMOTE
alluxio.user.file.writetype.default=ASYNC_THROUGH
alluxio.user.file.replication.durable=2
alluxio.user.file.persist.on.rename=true
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>