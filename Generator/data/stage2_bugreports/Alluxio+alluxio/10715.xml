<bug id='10715' author='XiaochenCui' open_date='2020-01-09T07:07:01Z' closed_time='2020-01-09T07:36:47Z'>
	<summary>Failed to read hbase data through alluxio</summary>
	<description>
Alluxio Version:
2.1.1
Describe the bug
I have mount the hdfs folder of hbase to alluxio, but the read fails on some files.
It shows that the file is in alluxio file system, but not in hdfs.
So how can I sync the file system?
Client: fuse (POSIX API)
shell ls:
&lt;denchmark-code&gt;[root@cdh1 alluxio]# l /mnt/alluxio/mnt/hdfs/alert_record/ed742a580a62f217a6279d96b8ba2920/A/
total 164M
drwxr-xr-x 1 root root    3 Jan  9 14:19 .
drwxr-xr-x 1 root root    5 Jan  7 10:53 ..
-rw-r--r-- 1 root root  82M Jan  9 13:18 1c9f9b0aea944fc8b9f2096247794a70
-rw-r--r-- 1 root root 129K Jan  9 14:19 44b0e075c7a1437e87cc10abf9f8283f
-rw-r--r-- 1 root root  82M Jan  7 10:51 6f50b34221b44376bc77261f86d8bb3f
&lt;/denchmark-code&gt;

hdfs content:
&lt;denchmark-code&gt;[root@cdh1 alluxio]# hdfs dfs -ls  hdfs://cdh1:8020/data/apps/hbase/data/data/default/alert_record/ed742a580a62f217a6279d96b8ba2920/A/
Found 2 items
-rw-r--r--   3 hbase hdfs   85555291 2020-01-09 13:18 hdfs://cdh1:8020/data/apps/hbase/data/data/default/alert_record/ed742a580a62f217a6279d96b8ba2920/A/1c9f9b0aea944fc8b9f2096247794a70
-rw-r--r--   3 hbase hdfs     131555 2020-01-09 14:19 hdfs://cdh1:8020/data/apps/hbase/data/data/default/alert_record/ed742a580a62f217a6279d96b8ba2920/A/44b0e075c7a1437e87cc10abf9f8283f
&lt;/denchmark-code&gt;

fuse stat:
&lt;denchmark-code&gt;[root@cdh1 alluxio-2.1.1]# integration/fuse/bin/alluxio-fuse stat
pid     mount_point     alluxio_path
4122    /mnt/alluxio    /
&lt;/denchmark-code&gt;

admin report:
&lt;denchmark-code&gt;The service is temporarily unavailable. Failed to read block ID=85127593984 from tiered storage and UFS tier: File does not exist: /data/apps/hbase/data/data/default/alert_record/ed742a580a62f217a6279d96b8ba2920/A/6f50b34221b44376bc77261f86d8bb3f at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:86) at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76) at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:158) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1931) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) (Zero Copy GrpcDataReader)
&lt;/denchmark-code&gt;

script:
import time
import os


class FuseTest(object):
    def __init__(self):
        self.l_sum = 0
        self.file_count = 0

    def read_file(self, path):
        print path
        self.file_count += 1
        with open(path, "r") as f:
            content = f.read()
        return len(content)

    def read_dir(self, path):
        for subdir, dirs, files in os.walk(dir_path):
            for file in files:
                filepath = subdir + os.sep + file
                l = self.read_file(filepath)
                self.l_sum += l

import sys
dir_path = sys.argv[1]
print dir_path

tester = FuseTest()
before = time.time()
tester.read_dir(dir_path)
after = time.time()
size = float(tester.l_sum)
speed = size / (after - before)

print 'file count: {}'.format(tester.file_count)
print 'read time: {}'.format(after - before)
print 'read size (bytes): {}'.format(size)
print 'read size (kb): {}'.format(size / 1024)
print 'read size (mb): {}'.format(size / 1024 / 1024)
print 'read size (gb): {}'.format(size / 1024 / 1024 / 1024)
print 'read speed(bytes/s): {}'.format(speed)
print 'read speed(kb/s): {}'.format(speed / 1024)
print 'read speed(mb/s): {}'.format(speed / 1024 / 1024)
print 'read speed(gb/s): {}'.format(speed / 1024 / 1024 / 1024)
output:
&lt;denchmark-code&gt;[root@cdh1 alluxio]# python read_fuse.py /mnt/alluxio/mnt/hdfs/alert_record
/mnt/alluxio/mnt/hdfs/alert_record
/mnt/alluxio/mnt/hdfs/alert_record/ed742a580a62f217a6279d96b8ba2920/.regioninfo
/mnt/alluxio/mnt/hdfs/alert_record/ed742a580a62f217a6279d96b8ba2920/A/1c9f9b0aea944fc8b9f2096247794a70
/mnt/alluxio/mnt/hdfs/alert_record/ed742a580a62f217a6279d96b8ba2920/A/6f50b34221b44376bc77261f86d8bb3f
Traceback (most recent call last):
  File "read_fuse.py", line 30, in &lt;module&gt;
    tester.read_dir(dir_path)
  File "read_fuse.py", line 21, in read_dir
    l = self.read_file(filepath)
  File "read_fuse.py", line 14, in read_file
    content = f.read()
IOError: [Errno 5] Input/output error
&lt;/denchmark-code&gt;

To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='XiaochenCui' date='2020-01-09T07:36:47Z'>
		set alluxio.user.file.metadata.sync.interval=60s
		</comment>
	</comments>
</bug>