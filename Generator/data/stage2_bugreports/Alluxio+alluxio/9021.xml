<bug id='9021' author='maobaolong' open_date='2019-05-08T02:19:11Z' closed_time='2019-07-24T18:40:15Z'>
	<summary>Jar package conflict while using alluxio-assembly-server-2.0.0-SNAPSHOT-jar-with-dependencies.jar to hadoop-2.7.1</summary>
	<description>
Alluxio Version:
2.0.0
Describe the bug
I want our JobHistoryServer(Version: Hadoop2.7.1) use Alluxio as a cache tier to cache yarn log files from hdfs, but i met a lot of jar package and class conflict. Although i resolve the conflict by delete the conflict from the two jar package at the last, but i don't think this is a better way, So we must to resolve this problem graceful, and more component can use Alluxio.
To Reproduce

Deplay a Hadoop2.7.1 package to a machine
Configured the Hadoop2.7.1 as a jobhistoryServer to access log  from Alluxio://hostname:port/tmp/app-logs/
put the alluxio-assembly-server-2.0.0-SNAPSHOT-jar-with-dependencies.jar and /projects/IdeaProjects/alluxio/core/client/hdfs/target/alluxio-core-client-hdfs-2.0.0-SNAPSHOT.jar into $HADOOP_HOME/share/hadoop/hdfs/
hdfs dfs -ls alluxio:/alluxioMasterHost:19998/tmp/ will failed.
mr-jobhistory-daemon.sh start historyserver will failed.

Expected behavior
mr-jobhistory-daemon.sh start historyserver will succeed start, and the log can be view in the job history web page.
Urgency
High, i think this is a common issue, these kind of issue will be the obstruction to extend the use case of Alluxio.
Additional context
I find the conflict jar is:

guava-11.0.2.jar
netty-3.6.2.Final.jar
protobuf-java-2.5.0.jar

some of the error log
&lt;denchmark-code&gt;
[mapred@yarn-base-ip ~]$ hdfs dfs -ls alluxio://alluxioHost:19998/tmp/
-ls: Fatal internal error
java.lang.RuntimeException: java.lang.ClassNotFoundException: Class alluxio.hadoop.FileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2625)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3288)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:125)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3339)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:480)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:298)
	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:352)
	at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:250)
	at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:233)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:105)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:177)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:337)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:101)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:115)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:400)
Caused by: java.lang.ClassNotFoundException: Class alluxio.hadoop.FileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2529)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2623)
	... 16 more


[mapred@yarn-base-ip ~]$ hdfs dfs -ls alluxio://alluxiohost:19998/tmp/
Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;Ljava/lang/Object;)V
	at alluxio.hadoop.AbstractFileSystem.initialize(AbstractFileSystem.java:467)
	at alluxio.hadoop.FileSystem.initialize(FileSystem.java:26)
	at alluxio.hadoop.AbstractFileSystem.initialize(AbstractFileSystem.java:454)
	at alluxio.hadoop.FileSystem.initialize(FileSystem.java:26)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3322)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:125)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3339)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:480)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:298)
	at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:352)
	at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:250)
	at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:233)
	at org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:105)
	at org.apache.hadoop.fs.shell.Command.run(Command.java:177)
	at org.apache.hadoop.fs.FsShell.run(FsShell.java:337)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:101)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:115)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:400)
&lt;/denchmark-code&gt;

and, we modify one of the class of JobHistory, we add a new method isHSReadonly in the JobHistoryUtils, we hope jobhistoryserver use Hadoop2.7.1's JobHistoryUtils.class, but this jvm process use it from Alluxio fat jar.
&lt;denchmark-code&gt;2019-05-07 17:37:26,201 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-07 17:37:26,473 FATAL org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: Error starting JobHistoryServer
java.lang.NoSuchMethodError: org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.isHSReadonly(Lorg/apache/hadoop/conf/Configuration;)Z
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:141)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.launchJobHistoryServer(JobHistoryServer.java:234)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:244)
2019-05-07 17:37:26,475 INFO org.apache.hadoop.util.ExitUtil: Exiting with status -1
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='maobaolong' date='2019-05-08T04:21:09Z'>
		
put the alluxio-assembly-server-2.0.0-SNAPSHOT-jar-with-dependencies.jar and /projects/IdeaProjects/alluxio/core/client/hdfs/target/alluxio-core-client-hdfs-2.0.0-SNAPSHOT.jar into $HADOOP_HOME/share/hadoop/hdfs/

instead can you put alluxio/client/alluxio-2.0.0-SNAPSHOT-client.jar into $HADOOP_HOME/share/hadoop/hdfs/. This is because this client jar is runtime jar with shaded dep while alluxio-assembly-server-2.0.0-SNAPSHOT-jar-with-dependencies.jar and alluxio-core-client-hdfs-2.0.0-SNAPSHOT.jar are not
		</comment>
		<comment id='2' author='maobaolong' date='2019-05-08T10:17:48Z'>
		&lt;denchmark-link:https://github.com/apc999&gt;@apc999&lt;/denchmark-link&gt;
  Thank you, i will have a try.
		</comment>
		<comment id='3' author='maobaolong' date='2019-07-24T18:40:15Z'>
		&lt;denchmark-link:https://github.com/maobaolong&gt;@maobaolong&lt;/denchmark-link&gt;
 Closing this due to inactivity, please reopen if you still have this issue.
		</comment>
	</comments>
</bug>