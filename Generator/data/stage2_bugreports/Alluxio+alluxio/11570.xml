<bug id='11570' author='cheyang' open_date='2020-06-16T13:31:51Z' closed_time='2020-07-21T12:32:14Z'>
	<summary>Install alluxio failed with helm chart in kubernetes</summary>
	<description>
Alluxio Version:
master branch
Describe the bug
I tried to install alluxio with

#11554
#11563

The package is &lt;denchmark-link:http://kubeflow.oss-cn-beijing.aliyuncs.com/alluxio-0.6.3.tgz&gt;http://kubeflow.oss-cn-beijing.aliyuncs.com/alluxio-0.6.3.tgz&lt;/denchmark-link&gt;
.
The customization yaml is
&lt;denchmark-code&gt;# cat values.yaml
#
# The Alluxio Open Foundation licenses this work under the Apache License, version 2.0
# (the "License"). You may not use this work except in compliance with the License, which is
# available at www.apache.org/licenses/LICENSE-2.0
#
# This software is distributed on an "AS IS" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
# either express or implied, as more fully set forth in the License.
#
# See the NOTICE file distributed with this work for information regarding copyright ownership.
#

# This should not be modified in the usual case.
fullnameOverride: alluxio


## Common ##

# Docker Image
image: alluxio/alluxio
imageTag: 2.3.0-SNAPSHOT
imagePullPolicy: IfNotPresent

# Security Context
user: 1000
group: 1000
fsGroup: 1000

# Site properties for all the components
properties:
  # alluxio.user.metrics.collection.enabled: 'true'
  alluxio.security.stale.channel.purge.interval: 365d

# Recommended JVM Heap options for running in Docker
# Ref: https://developers.redhat.com/blog/2017/03/14/java-inside-docker/
# These JVM options are common to all Alluxio services
# jvmOptions:
#   - "-XX:+UnlockExperimentalVMOptions"
#   - "-XX:+UseCGroupMemoryLimitForHeap"
#   - "-XX:MaxRAMFraction=2"

# Mount Persistent Volumes to all components
# mounts:
# - name: &lt;persistentVolume claimName&gt;
#   path: &lt;mountPath&gt;

# Use labels to run Alluxio on a subset of the K8s nodes
# nodeSelector: {}

## Master ##

master:
  count: 1 # Controls the number of StatefulSets. For multiMaster mode increase this to &gt;1.
  replicas: 1 # Controls #replicas in a StatefulSet and should not be modified in the usual case.
  args: # Arguments to Docker entrypoint
    - master-only
    - --no-format
  # Properties for the master component
  properties:
    # Example: use ROCKS DB instead of Heap
    # alluxio.master.metastore: ROCKS
    # alluxio.master.metastore.dir: /metastore
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    embedded: 19200
    rpc: 19998
    web: 19999
  hostNetwork: true
  # dnsPolicy will be ClusterFirstWithHostNet if hostNetwork: true
  # and ClusterFirst if hostNetwork: false
  # You can specify dnsPolicy here to override this inference
  # dnsPolicy: ClusterFirst
  # JVM options specific to the master container
  jvmOptions:
  nodeSelector: {}

jobMaster:
  args:
    - job-master
  # Properties for the jobMaster component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    embedded: 20003
    rpc: 20001
    web: 20002
  # JVM options specific to the jobMaster container
  jvmOptions:

# Alluxio supports journal type of UFS and EMBEDDED
# UFS journal with HDFS example
# journal:
#   type: "UFS"
#   folder: "hdfs://{$hostname}:{$hostport}/journal"
# EMBEDDED journal to /journal example
# journal:
#   type: "EMBEDDED"
#   folder: "/journal"
journal:
  type: "UFS" # "UFS" or "EMBEDDED"
  ufsType: "local" # Ignored if type is "EMBEDDED". "local" or "HDFS"
  folder: "/journal" # Master journal folder
  # volumeType controls the type of journal volume.
  # It can be "persistentVolumeClaim" or "emptyDir"
  volumeType: emptyDir
  size: 1Gi
  # Attributes to use when the journal is persistentVolumeClaim
  storageClass: "standard"
  accessModes:
    - ReadWriteOnce
  # Attributes to use when the journal is emptyDir
  medium: ""
  # Configuration for journal formatting job
  format:
    runFormat: false # Change to true to format journal
    job:
      activeDeadlineSeconds: 30
      ttlSecondsAfterFinished: 10
    resources:
      limits:
        cpu: "1"
        memory: "1G"
      requests:
        cpu: "1"
        memory: "1G"


# You can enable metastore to use ROCKS DB instead of Heap
metastore:
  volumeType: emptyDir # Options: "persistentVolumeClaim" or "emptyDir"
  size: 1Gi
  mountPath: /metastore
# Attributes to use when the metastore is persistentVolumeClaim
  storageClass: "standard"
  accessModes:
   - ReadWriteOnce
# Attributes to use when the metastore is emptyDir
  medium: ""


## Worker ##

worker:
  args:
    - worker-only
    - --no-format
  # Properties for the worker component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "2G"
    requests:
      cpu: "1"
      memory: "2G"
  ports:
    rpc: 29999
    web: 30000
  hostNetwork: true
  # dnsPolicy will be ClusterFirstWithHostNet if hostNetwork: true
  # and ClusterFirst if hostNetwork: false
  # You can specify dnsPolicy here to override this inference
  # dnsPolicy: ClusterFirst
  # JVM options specific to the worker container
  jvmOptions:
  nodeSelector: {}

jobWorker:
  args:
    - job-worker
  # Properties for the jobWorker component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    rpc: 30001
    data: 30002
    web: 30003
  # JVM options specific to the jobWorker container
  jvmOptions:

# Tiered Storage
# emptyDir example
#  - level: 0
#    alias: MEM
#    mediumtype: MEM
#    path: /dev/shm
#    type: emptyDir
#    quota: 1G
#
# hostPath example
#  - level: 0
#    alias: MEM
#    mediumtype: MEM
#    path: /dev/shm
#    type: hostPath
#    quota: 1G
#
# persistentVolumeClaim example
#  - level: 1
#    alias: SSD
#    mediumtype: SSD
#    type: persistentVolumeClaim
#    name: alluxio-ssd
#    path: /dev/ssd
#    quota: 10G
#
# multi-part mediumtype example
#  - level: 1
#    alias: SSD,HDD
#    mediumtype: SSD,HDD
#    type: persistentVolumeClaim
#    name: alluxio-ssd,alluxio-hdd
#    path: /dev/ssd,/dev/hdd
#    quota: 10G,10G
tieredstore:
  levels:
  - level: 0
    alias: MEM
    mediumtype: MEM
    path: /dev/shm
    type: emptyDir
    quota: 1G
    high: 0.95
    low: 0.7

# Short circuit related properties
shortCircuit:
  enabled: true
  # The policy for short circuit can be "local" or "uuid",
  # local means the cache directory is in the same mount namespace,
  # uuid means interact with domain socket
  policy: local
  # volumeType controls the type of shortCircuit volume.
  # It can be "persistentVolumeClaim" or "hostPath"
  volumeType: hostPath
  size: 1Mi
  # Attributes to use if the domain socket volume is PVC
  pvcName: alluxio-worker-domain-socket
  accessModes:
    - ReadWriteOnce
  storageClass: standard
  # Attributes to use if the domain socket volume is hostPath
  hostPath: "/tmp/alluxio-domain" # The hostPath directory to use
  # Attributes to use if the domain socket volume is emptyDir
  medium: ""


## FUSE ##

fuse:
  image: alluxio/alluxio-fuse
  imageTag: 2.3.0-SNAPSHOT
  imagePullPolicy: IfNotPresent
  # Change both to true to deploy FUSE
  enabled: true
  clientEnabled: false
  # Properties for the jobWorker component
  properties:
  # Customize the MaxDirectMemorySize
  # These options are specific to the FUSE daemon
  jvmOptions:
    - "-XX:MaxDirectMemorySize=2g"
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
  user: 0
  group: 0
  fsGroup: 0
  args:
    - fuse
    - --fuse-opts=allow_other
  # Mount path in the host
  mountPath: /mnt/alluxio-fuse
  resources:
    requests:
      cpu: "0.5"
      memory: "1G"
    limits:
      cpu: "1"
      memory: "1G"


##  Secrets ##

# Format: (&lt;name&gt;:&lt;mount path under /secrets/&gt;):
# secrets:
#   master: # Shared by master and jobMaster containers
#     alluxio-hdfs-config: hdfsConfig
#   worker: # Shared by worker and jobWorker containers
#     alluxio-hdfs-config: hdfsConfig
&lt;/denchmark-code&gt;

The install command is helm install -f values.yaml alluxio alluxio
The result is
&lt;denchmark-code&gt;NAME                   READY   STATUS             RESTARTS   AGE

alluxio-master-0       0/2     Running            0          18m
alluxio-worker-2fdmd   0/2     CrashLoopBackOff   12         18m
alluxio-worker-j5j6v   0/2     CrashLoopBackOff   12         18m
alluxio-worker-ngwmn   0/2     CrashLoopBackOff   12         18m
&lt;/denchmark-code&gt;

And I found the endpoint is not ready
&lt;denchmark-code&gt;apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    endpoints.kubernetes.io/last-change-trigger-time: "2020-06-16T21:08:50+08:00"
  creationTimestamp: "2020-06-16T13:08:50Z"
  labels:
    app: alluxio
    chart: alluxio-0.6.3
    heritage: Helm
    release: alluxio
    role: alluxio-master
  name: alluxio-master-0
  namespace: default
  resourceVersion: "2532463"
  selfLink: /api/v1/namespaces/default/endpoints/alluxio-master-0
  uid: 85a0ad19-afd2-11ea-bf90-00163e08ca95
subsets:
- notReadyAddresses:
  - ip: 192.168.8.240
    nodeName: cn-beijing.192.168.8.240
    targetRef:
      kind: Pod
      name: alluxio-master-0
      namespace: default
      resourceVersion: "2532460"
&lt;/denchmark-code&gt;

When I tried to run alluxio-monitor.sh master in the master pod, I can see it's failed
&lt;denchmark-code&gt;# kubectl exec -it alluxio-master-0 bash
Defaulting container name to alluxio-master.
Use 'kubectl describe pod/alluxio-master-0 -n default' to see all of the containers in this pod.
bash-4.4$ alluxio-monitor.sh master
Jun 16, 2020 1:31:28 PM io.grpc.internal.ManagedChannelImpl$NameResolverListener handleErrorInSyncContext
WARNING: [Channel&lt;1&gt;: (alluxio-master-0:19998)] Failed to resolve name. status=Status{code=UNAVAILABLE, description=Unable to resolve host alluxio-master-0, cause=java.lang.RuntimeException: java.net.UnknownHostException: alluxio-master-0: Name does not resolve
	at io.grpc.internal.DnsNameResolver.resolveAll(DnsNameResolver.java:436)
	at io.grpc.internal.DnsNameResolver$Resolve.resolveInternal(DnsNameResolver.java:272)
	at io.grpc.internal.DnsNameResolver$Resolve.run(DnsNameResolver.java:228)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: alluxio-master-0: Name does not resolve
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at io.grpc.internal.DnsNameResolver$JdkAddressResolver.resolveAddress(DnsNameResolver.java:646)
	at io.grpc.internal.DnsNameResolver.resolveAll(DnsNameResolver.java:404)
	... 5 more
}
&lt;/denchmark-code&gt;

To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='cheyang' date='2020-06-17T06:09:39Z'>
		The mode of kube-proxy is iptables.
		</comment>
		<comment id='2' author='cheyang' date='2020-07-21T12:32:14Z'>
		Fixed in &lt;denchmark-link:https://github.com/Alluxio/alluxio/pull/11593&gt;#11593&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/Alluxio/alluxio/pull/11610&gt;#11610&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='cheyang' date='2020-08-13T05:53:39Z'>
		
Alluxio Version:
master branch
Describe the bug
I tried to install alluxio with

#11554
#11563

The package is http://kubeflow.oss-cn-beijing.aliyuncs.com/alluxio-0.6.3.tgz.
The customization yaml is
# cat values.yaml
#
# The Alluxio Open Foundation licenses this work under the Apache License, version 2.0
# (the "License"). You may not use this work except in compliance with the License, which is
# available at www.apache.org/licenses/LICENSE-2.0
#
# This software is distributed on an "AS IS" basis, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
# either express or implied, as more fully set forth in the License.
#
# See the NOTICE file distributed with this work for information regarding copyright ownership.
#

# This should not be modified in the usual case.
fullnameOverride: alluxio


## Common ##

# Docker Image
image: alluxio/alluxio
imageTag: 2.3.0-SNAPSHOT
imagePullPolicy: IfNotPresent

# Security Context
user: 1000
group: 1000
fsGroup: 1000

# Site properties for all the components
properties:
  # alluxio.user.metrics.collection.enabled: 'true'
  alluxio.security.stale.channel.purge.interval: 365d

# Recommended JVM Heap options for running in Docker
# Ref: https://developers.redhat.com/blog/2017/03/14/java-inside-docker/
# These JVM options are common to all Alluxio services
# jvmOptions:
#   - "-XX:+UnlockExperimentalVMOptions"
#   - "-XX:+UseCGroupMemoryLimitForHeap"
#   - "-XX:MaxRAMFraction=2"

# Mount Persistent Volumes to all components
# mounts:
# - name: &lt;persistentVolume claimName&gt;
#   path: &lt;mountPath&gt;

# Use labels to run Alluxio on a subset of the K8s nodes
# nodeSelector: {}

## Master ##

master:
  count: 1 # Controls the number of StatefulSets. For multiMaster mode increase this to &gt;1.
  replicas: 1 # Controls #replicas in a StatefulSet and should not be modified in the usual case.
  args: # Arguments to Docker entrypoint
    - master-only
    - --no-format
  # Properties for the master component
  properties:
    # Example: use ROCKS DB instead of Heap
    # alluxio.master.metastore: ROCKS
    # alluxio.master.metastore.dir: /metastore
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    embedded: 19200
    rpc: 19998
    web: 19999
  hostNetwork: true
  # dnsPolicy will be ClusterFirstWithHostNet if hostNetwork: true
  # and ClusterFirst if hostNetwork: false
  # You can specify dnsPolicy here to override this inference
  # dnsPolicy: ClusterFirst
  # JVM options specific to the master container
  jvmOptions:
  nodeSelector: {}

jobMaster:
  args:
    - job-master
  # Properties for the jobMaster component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    embedded: 20003
    rpc: 20001
    web: 20002
  # JVM options specific to the jobMaster container
  jvmOptions:

# Alluxio supports journal type of UFS and EMBEDDED
# UFS journal with HDFS example
# journal:
#   type: "UFS"
#   folder: "hdfs://{$hostname}:{$hostport}/journal"
# EMBEDDED journal to /journal example
# journal:
#   type: "EMBEDDED"
#   folder: "/journal"
journal:
  type: "UFS" # "UFS" or "EMBEDDED"
  ufsType: "local" # Ignored if type is "EMBEDDED". "local" or "HDFS"
  folder: "/journal" # Master journal folder
  # volumeType controls the type of journal volume.
  # It can be "persistentVolumeClaim" or "emptyDir"
  volumeType: emptyDir
  size: 1Gi
  # Attributes to use when the journal is persistentVolumeClaim
  storageClass: "standard"
  accessModes:
    - ReadWriteOnce
  # Attributes to use when the journal is emptyDir
  medium: ""
  # Configuration for journal formatting job
  format:
    runFormat: false # Change to true to format journal
    job:
      activeDeadlineSeconds: 30
      ttlSecondsAfterFinished: 10
    resources:
      limits:
        cpu: "1"
        memory: "1G"
      requests:
        cpu: "1"
        memory: "1G"


# You can enable metastore to use ROCKS DB instead of Heap
metastore:
  volumeType: emptyDir # Options: "persistentVolumeClaim" or "emptyDir"
  size: 1Gi
  mountPath: /metastore
# Attributes to use when the metastore is persistentVolumeClaim
  storageClass: "standard"
  accessModes:
   - ReadWriteOnce
# Attributes to use when the metastore is emptyDir
  medium: ""


## Worker ##

worker:
  args:
    - worker-only
    - --no-format
  # Properties for the worker component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "2G"
    requests:
      cpu: "1"
      memory: "2G"
  ports:
    rpc: 29999
    web: 30000
  hostNetwork: true
  # dnsPolicy will be ClusterFirstWithHostNet if hostNetwork: true
  # and ClusterFirst if hostNetwork: false
  # You can specify dnsPolicy here to override this inference
  # dnsPolicy: ClusterFirst
  # JVM options specific to the worker container
  jvmOptions:
  nodeSelector: {}

jobWorker:
  args:
    - job-worker
  # Properties for the jobWorker component
  properties:
  resources:
    limits:
      cpu: "1"
      memory: "1G"
    requests:
      cpu: "1"
      memory: "1G"
  ports:
    rpc: 30001
    data: 30002
    web: 30003
  # JVM options specific to the jobWorker container
  jvmOptions:

# Tiered Storage
# emptyDir example
#  - level: 0
#    alias: MEM
#    mediumtype: MEM
#    path: /dev/shm
#    type: emptyDir
#    quota: 1G
#
# hostPath example
#  - level: 0
#    alias: MEM
#    mediumtype: MEM
#    path: /dev/shm
#    type: hostPath
#    quota: 1G
#
# persistentVolumeClaim example
#  - level: 1
#    alias: SSD
#    mediumtype: SSD
#    type: persistentVolumeClaim
#    name: alluxio-ssd
#    path: /dev/ssd
#    quota: 10G
#
# multi-part mediumtype example
#  - level: 1
#    alias: SSD,HDD
#    mediumtype: SSD,HDD
#    type: persistentVolumeClaim
#    name: alluxio-ssd,alluxio-hdd
#    path: /dev/ssd,/dev/hdd
#    quota: 10G,10G
tieredstore:
  levels:
  - level: 0
    alias: MEM
    mediumtype: MEM
    path: /dev/shm
    type: emptyDir
    quota: 1G
    high: 0.95
    low: 0.7

# Short circuit related properties
shortCircuit:
  enabled: true
  # The policy for short circuit can be "local" or "uuid",
  # local means the cache directory is in the same mount namespace,
  # uuid means interact with domain socket
  policy: local
  # volumeType controls the type of shortCircuit volume.
  # It can be "persistentVolumeClaim" or "hostPath"
  volumeType: hostPath
  size: 1Mi
  # Attributes to use if the domain socket volume is PVC
  pvcName: alluxio-worker-domain-socket
  accessModes:
    - ReadWriteOnce
  storageClass: standard
  # Attributes to use if the domain socket volume is hostPath
  hostPath: "/tmp/alluxio-domain" # The hostPath directory to use
  # Attributes to use if the domain socket volume is emptyDir
  medium: ""


## FUSE ##

fuse:
  image: alluxio/alluxio-fuse
  imageTag: 2.3.0-SNAPSHOT
  imagePullPolicy: IfNotPresent
  # Change both to true to deploy FUSE
  enabled: true
  clientEnabled: false
  # Properties for the jobWorker component
  properties:
  # Customize the MaxDirectMemorySize
  # These options are specific to the FUSE daemon
  jvmOptions:
    - "-XX:MaxDirectMemorySize=2g"
  hostNetwork: true
  dnsPolicy: ClusterFirstWithHostNet
  user: 0
  group: 0
  fsGroup: 0
  args:
    - fuse
    - --fuse-opts=allow_other
  # Mount path in the host
  mountPath: /mnt/alluxio-fuse
  resources:
    requests:
      cpu: "0.5"
      memory: "1G"
    limits:
      cpu: "1"
      memory: "1G"


##  Secrets ##

# Format: (&lt;name&gt;:&lt;mount path under /secrets/&gt;):
# secrets:
#   master: # Shared by master and jobMaster containers
#     alluxio-hdfs-config: hdfsConfig
#   worker: # Shared by worker and jobWorker containers
#     alluxio-hdfs-config: hdfsConfig

The install command is helm install -f values.yaml alluxio alluxio
The result is
NAME                   READY   STATUS             RESTARTS   AGE

alluxio-master-0       0/2     Running            0          18m
alluxio-worker-2fdmd   0/2     CrashLoopBackOff   12         18m
alluxio-worker-j5j6v   0/2     CrashLoopBackOff   12         18m
alluxio-worker-ngwmn   0/2     CrashLoopBackOff   12         18m

And I found the endpoint is not ready
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    endpoints.kubernetes.io/last-change-trigger-time: "2020-06-16T21:08:50+08:00"
  creationTimestamp: "2020-06-16T13:08:50Z"
  labels:
    app: alluxio
    chart: alluxio-0.6.3
    heritage: Helm
    release: alluxio
    role: alluxio-master
  name: alluxio-master-0
  namespace: default
  resourceVersion: "2532463"
  selfLink: /api/v1/namespaces/default/endpoints/alluxio-master-0
  uid: 85a0ad19-afd2-11ea-bf90-00163e08ca95
subsets:
- notReadyAddresses:
  - ip: 192.168.8.240
    nodeName: cn-beijing.192.168.8.240
    targetRef:
      kind: Pod
      name: alluxio-master-0
      namespace: default
      resourceVersion: "2532460"

When I tried to run alluxio-monitor.sh master in the master pod, I can see it's failed
# kubectl exec -it alluxio-master-0 bash
Defaulting container name to alluxio-master.
Use 'kubectl describe pod/alluxio-master-0 -n default' to see all of the containers in this pod.
bash-4.4$ alluxio-monitor.sh master
Jun 16, 2020 1:31:28 PM io.grpc.internal.ManagedChannelImpl$NameResolverListener handleErrorInSyncContext
WARNING: [Channel&lt;1&gt;: (alluxio-master-0:19998)] Failed to resolve name. status=Status{code=UNAVAILABLE, description=Unable to resolve host alluxio-master-0, cause=java.lang.RuntimeException: java.net.UnknownHostException: alluxio-master-0: Name does not resolve
	at io.grpc.internal.DnsNameResolver.resolveAll(DnsNameResolver.java:436)
	at io.grpc.internal.DnsNameResolver$Resolve.resolveInternal(DnsNameResolver.java:272)
	at io.grpc.internal.DnsNameResolver$Resolve.run(DnsNameResolver.java:228)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.UnknownHostException: alluxio-master-0: Name does not resolve
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:929)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1324)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1277)
	at java.net.InetAddress.getAllByName(InetAddress.java:1193)
	at java.net.InetAddress.getAllByName(InetAddress.java:1127)
	at io.grpc.internal.DnsNameResolver$JdkAddressResolver.resolveAddress(DnsNameResolver.java:646)
	at io.grpc.internal.DnsNameResolver.resolveAll(DnsNameResolver.java:404)
	... 5 more
}

To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.

I ran into the same problem, how did you solve the final problem?Please. I use alluxio-2.3.0.
		</comment>
		<comment id='4' author='cheyang' date='2020-08-13T14:42:26Z'>
		&lt;denchmark-link:https://github.com/marrycheck&gt;@marrycheck&lt;/denchmark-link&gt;
 This issue should be resolved by the 2 PRs mentioned in the comment and should be gone in 2.3.0. If you still see a similar error that's probably a new problem. Can you please create another github issue?
		</comment>
		<comment id='5' author='cheyang' date='2020-08-14T02:33:05Z'>
		
@marrycheck This issue should be resolved by the 2 PRs mentioned in the comment and should be gone in 2.3.0. If you still see a similar error that's probably a new problem. Can you please create another github issue?

Ok,i'll submit another issue.Thanks for your reply.
		</comment>
		<comment id='6' author='cheyang' date='2020-08-14T03:25:31Z'>
		
@marrycheck This issue should be resolved by the 2 PRs mentioned in the comment and should be gone in 2.3.0. If you still see a similar error that's probably a new problem. Can you please create another github issue?

I hava created a new issue，please take a look at your convenience.The link is &lt;denchmark-link:https://github.com/Alluxio/alluxio/issues/11985&gt;#11985&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>