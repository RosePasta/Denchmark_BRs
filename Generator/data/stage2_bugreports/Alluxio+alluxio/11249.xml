<bug id='11249' author='martenlindblad' open_date='2020-04-08T08:15:50Z' closed_time='2020-04-08T10:52:27Z'>
	<summary>FileIncompleteException with Hive queries on transactional table</summary>
	<description>
Alluxio Version:
2.2.0
Describe the bug
Writing with hive hcatalog streaming from Flink, reading table data with Hive over Tez fails
Versions:

Hive: 2.3.6
Tez: 0.9.1

To Reproduce
Create a table in Hive with TBLPROPERTIES ('transactional'='true'). Write data to the table using org.apache.hive.hcatalog.streaming.StrictJsonWriter and org.apache.hive.hcatalog.streaming.TransactionBatch. While job is writing data, perform queries against the data in Hive using Tez as computation engine.
Expected behavior
Get data that has been written.
Urgency
High urgency
Additional context
Output from Tez is:
&lt;denchmark-code&gt;java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)
at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:206)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.&lt;init&gt;(TezGroupedSplitsInputFormat.java:145)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)
at org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:703)
at org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:662)
at org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:150)
at org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:114)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n\t... 14 more\nCaused by: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:379)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\n\t... 25 more\nCaused by: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:65)
at alluxio.hadoop.AbstractFileSystem.open(AbstractFileSystem.java:634)
at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
at org.apache.orc.impl.ReaderImpl.extractFileTail(ReaderImpl.java:517)
at org.apache.orc.impl.ReaderImpl.&lt;init&gt;(ReaderImpl.java:364)
at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:63)
at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:90)
at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&lt;init&gt;(OrcRawRecordMerger.java:491)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getReader(OrcInputFormat.java:1970)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1867)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\n\t... 26 more\nCaused by: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:351)
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:339)
at alluxio.client.file.FileSystem.openFile(FileSystem.java:415)
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:60)\n\t... 36 more\n]\nTaskAttempt 1 failed, info=[Error: Error while running task ( failure ) : attempt_1585836386386_0038_1_00_000013_1:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)
at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:206)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.&lt;init&gt;(TezGroupedSplitsInputFormat.java:145)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)
at org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:703)
at org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:662)
at org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:150)
at org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:114)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n\t... 14 more\nCaused by: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:379)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\n\t... 25 more\nCaused by: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:65)
at alluxio.hadoop.AbstractFileSystem.open(AbstractFileSystem.java:634)
at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
at org.apache.orc.impl.ReaderImpl.extractFileTail(ReaderImpl.java:517)
at org.apache.orc.impl.ReaderImpl.&lt;init&gt;(ReaderImpl.java:364)
at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:63)
at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:90)
at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&lt;init&gt;(OrcRawRecordMerger.java:491)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getReader(OrcInputFormat.java:1970)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1867)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\n\t... 26 more\nCaused by: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:351)
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:339)
at alluxio.client.file.FileSystem.openFile(FileSystem.java:415)
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:60)\n\t... 36 more\n]\nTaskAttempt 2 failed, info=[Error: Error while running task ( failure ) : attempt_1585836386386_0038_1_00_000013_2:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)
at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:206)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.&lt;init&gt;(TezGroupedSplitsInputFormat.java:145)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)
at org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:703)
at org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:662)
at org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:150)
at org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:114)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n\t... 14 more\nCaused by: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:379)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\n\t... 25 more\nCaused by: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:65)
at alluxio.hadoop.AbstractFileSystem.open(AbstractFileSystem.java:634)
at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
at org.apache.orc.impl.ReaderImpl.extractFileTail(ReaderImpl.java:517)
at org.apache.orc.impl.ReaderImpl.&lt;init&gt;(ReaderImpl.java:364)
at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:63)
at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:90)
at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&lt;init&gt;(OrcRawRecordMerger.java:491)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getReader(OrcInputFormat.java:1970)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1867)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\n\t... 26 more\nCaused by: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:351)
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:339)
at alluxio.client.file.FileSystem.openFile(FileSystem.java:415)
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:60)\n\t... 36 more\n]\nTaskAttempt 3 failed, info=[Error: Error while running task ( failure ) : attempt_1585836386386_0038_1_00_000013_3:java.lang.RuntimeException: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:211)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:168)
at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.RuntimeException: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:206)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.&lt;init&gt;(TezGroupedSplitsInputFormat.java:145)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat.getRecordReader(TezGroupedSplitsInputFormat.java:111)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setupOldRecordReader(MRReaderMapred.java:157)
at org.apache.tez.mapreduce.lib.MRReaderMapred.setSplit(MRReaderMapred.java:83)
at org.apache.tez.mapreduce.input.MRInput.initFromEventInternal(MRInput.java:703)
at org.apache.tez.mapreduce.input.MRInput.initFromEvent(MRInput.java:662)
at org.apache.tez.mapreduce.input.MRInputLegacy.checkAndAwaitRecordReaderInitialization(MRInputLegacy.java:150)
at org.apache.tez.mapreduce.input.MRInputLegacy.init(MRInputLegacy.java:114)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.getMRInput(MapRecordProcessor.java:525)
at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.init(MapRecordProcessor.java:171)
at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:184)\n\t... 14 more\nCaused by: java.io.IOException: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerChain.handleRecordReaderCreationException(HiveIOExceptionHandlerChain.java:97)
at org.apache.hadoop.hive.io.HiveIOExceptionHandlerUtil.handleRecordReaderCreationException(HiveIOExceptionHandlerUtil.java:57)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:379)
at org.apache.hadoop.mapred.split.TezGroupedSplitsInputFormat$TezGroupedSplitsRecordReader.initNextRecordReader(TezGroupedSplitsInputFormat.java:203)\n\t... 25 more\nCaused by: java.io.IOException: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:65)
at alluxio.hadoop.AbstractFileSystem.open(AbstractFileSystem.java:634)
at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
at org.apache.orc.impl.ReaderImpl.extractFileTail(ReaderImpl.java:517)
at org.apache.orc.impl.ReaderImpl.&lt;init&gt;(ReaderImpl.java:364)
at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.&lt;init&gt;(ReaderImpl.java:63)
at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:90)
at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.&lt;init&gt;(OrcRawRecordMerger.java:491)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getReader(OrcInputFormat.java:1970)
at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRecordReader(OrcInputFormat.java:1867)
at org.apache.hadoop.hive.ql.io.HiveInputFormat.getRecordReader(HiveInputFormat.java:376)\n\t... 26 more\nCaused by: alluxio.exception.FileIncompleteException: Cannot read from \/user\/hive\/warehouse\&lt;redacted&gt;/delta_0000144_0000153\/bucket_00013 because it is incomplete
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:351)
at alluxio.client.file.BaseFileSystem.openFile(BaseFileSystem.java:339)
at alluxio.client.file.FileSystem.openFile(FileSystem.java:415)
at alluxio.hadoop.HdfsFileInputStream.&lt;init&gt;(HdfsFileInputStream.java:60)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='martenlindblad' date='2020-04-08T08:34:56Z'>
		Hi marten,
Alluxio disallows reading files which are incomplete. I don't think this is an issue on our end. If you are still writing to the table and want to query information with Alluxio as your storage service, then hcatalog needs to somehow filter out the incomplete files and return them to the tez client.
Either that, or you can wait for your job to finish writing data before attempting to query the table
		</comment>
		<comment id='2' author='martenlindblad' date='2020-04-08T10:52:27Z'>
		
Hi marten,
Alluxio disallows reading files which are incomplete. I don't think this is an issue on our end. If you are still writing to the table and want to query information with Alluxio as your storage service, then hcatalog needs to somehow filter out the incomplete files and return them to the tez client.
Either that, or you can wait for your job to finish writing data before attempting to query the table

Yes you're right. The channel wasn't closed properly in the ingestion client. Not related to Alluxio at all.
		</comment>
	</comments>
</bug>