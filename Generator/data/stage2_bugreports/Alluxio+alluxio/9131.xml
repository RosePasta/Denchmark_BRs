<bug id='9131' author='borkd' open_date='2019-05-24T13:56:00Z' closed_time='2019-07-24T18:36:43Z'>
	<summary>gRPC message exceeds maximum size during fs copyFromLocal and fs load</summary>
	<description>
Alluxio Version:
What version of Alluxio are you using?
alluxio-2.0.0-preview
Describe the bug
A clear and concise description of what the bug is.
Unless I failed at RTFM my attempts to load a dataset with a larger number of files into alluxio via fs copyFromLocal or fs load consistently fail after some time with exit code 255 and the error message like below:
&lt;denchmark-code&gt;$ time ./bin/alluxio fs copyFromLocal /source/X/ /data/X/
Copied file:///X/Y to /data/X/Y
[... and so on for a bunch of other files (it would be nice to have a -quiet flag) for large sets ...]
ERRORS:
Failed to delete path /logs/jobs: gRPC message exceeds maximum size 104857600: 183519346
May 23, 2019 4:19:36 PM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 23, 2019 4:19:36 PM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 23, 2019 4:19:36 PM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream

real    10m40.995s
user    32m28.320s
sys     27m9.856s
&lt;/denchmark-code&gt;

After encountering this error fs ls /data/X will fail with exit code 255, spitting out:
&lt;denchmark-code&gt;$ time ./bin/alluxio fs ls /data/X
Getting directory status of 471207 files or sub-directories may take a while.May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
gRPC message exceeds maximum size 104857600: 183519346
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream
May 24, 2019 9:26:19 AM io.grpc.internal.AbstractClientStream$TransportState inboundDataReceived
INFO: Received data on closed stream

real    0m19.388s
user    0m2.424s
sys     0m0.244s
&lt;/denchmark-code&gt;

To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)


Prepare a directory with 500k-2M files in it.


Adjust configuration of alluxio-2.0.0-preview for larger number of files:



conf/alluxio-env.sh:

&lt;denchmark-code&gt;ALLUXIO_MASTER_JAVA_OPTS+=" -Xmx31G"
&lt;/denchmark-code&gt;


conf/alluxio-site.properties:

&lt;denchmark-code&gt;alluxio.master.metastore.dir=/nvme/metastore
alluxio.master.metastore.inode.cache.max.size=31000000
&lt;/denchmark-code&gt;


format the store and start a single-node configuration
Start fs loadFromLocal like in the example above
Wait

Expected behavior
A clear and concise description of what you expected to happen.
Total number of files per alluxio instance is well below 1 billion files. The command should take as long as needed, and finish without error assuming machine resources are sufficient for the dataset.
Urgency
Describe the impact and urgency of the bug.
It is a show stopper for me, since most of my datasets have between ~500k and 15M of files.
Additional context
Add any other context about the problem here.
Please consider adding an option to supress per-file status updates. "Copied ..." and "Failed to copy ... already exists" are not that helpful during large scale bulk copies/reloads.
	</description>
	<comments>
		<comment id='1' author='borkd' date='2019-05-24T19:07:46Z'>
		&lt;denchmark-link:https://github.com/bf8086&gt;@bf8086&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ggezer&gt;@ggezer&lt;/denchmark-link&gt;
  Can you take a look If this is an known issue
		</comment>
		<comment id='2' author='borkd' date='2019-05-24T19:19:55Z'>
		&lt;denchmark-link:https://github.com/borkd&gt;@borkd&lt;/denchmark-link&gt;
 Can you try a setting  in your client config? It's  as default and looks like it's not sufficient for your case.
		</comment>
		<comment id='3' author='borkd' date='2019-07-24T18:36:43Z'>
		&lt;denchmark-link:https://github.com/borkd&gt;@borkd&lt;/denchmark-link&gt;
 Closing this due to inactivity, please reopen if you still have this issue.
		</comment>
	</comments>
</bug>