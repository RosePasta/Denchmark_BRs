<bug id='9417' author='rblaine95' open_date='2019-07-04T13:03:47Z' closed_time='2019-07-31T10:28:50Z'>
	<summary>Unable to rename X to Y source does not exist</summary>
	<description>
Alluxio Version:
2.0.0
Describe the bug
When writing data to Alluxio via Spark, sometimes Alluxio will begin persisting the data to the UFS (in this case, Ceph Object Store) and will encounter the following error:
&lt;denchmark-code&gt;2019-07-04 12:44:35,696 ERROR ObjectUnderFileSystem - Unable to rename s3://alluxio/sample-2g/part-00054.alluxio.0x0000016BBCFCD36A.tmp to s3://alluxio/sample-2g/part-00054 because source does not exist or is a directory.
&lt;/denchmark-code&gt;

Which will then effectively lock up Alluxio until it eventually times out
&lt;denchmark-code&gt;2019-07-04 12:50:48,995 WARN  SleepingTimer - Master Persistence Scheduler last execution took 795724 ms. Longer than the interval 1000
&lt;/denchmark-code&gt;


Deploy Alluxio with the following config set (&lt;denchmark-link:https://docs.alluxio.io/os/user/stable/en/advanced/Performance-Tuning.html#optimized-commits-for-compute-frameworks&gt;docs&lt;/denchmark-link&gt;
):
alluxio.user.file.writetype.default=ASYNC_THROUGH
alluxio.user.file.persistence.initial.wait.time=-1
alluxio.user.file.persist.on.rename=true
Also deploy Zeppelin v0.8.1 and Spark 2.3.3
Create a notebook in Zeppelin to write the data into Alluxio
%spark
val glusterFile = sc.textFile("/tmp/data/sample-2g")
glusterFile.saveAsTextFile("alluxio://alluxio-master:19998/sample-2g")

%spark
val alluxioFile = sc.textFile("alluxio://alluxio-master:19998/sample-2g")
alluxioFile.count()
The alluxioFile.count() will hang until the persist job times out.
Expected behavior
When Spark is done writing data to Alluxio, it should commit the data with a rename and Alluxio should persist the data in UFS
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='rblaine95' date='2019-07-05T10:11:56Z'>
		This might be a Ceph S3 problem or even a network problem.
I'm running Ceph with the Rook operator in an OKD cluster.
&lt;denchmark-code&gt;2019-07-05 10:06:56,771 WARN  DefaultFileSystemMaster - The persist job (id=1562320802238) for file /sample-2g/part-00010 (id=352321535) failed: Task execution failed: com.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
2019-07-05 10:06:56,772 WARN  DefaultFileSystemMaster - The persist job (id=1562320802239) for file /sample-2g/part-00053 (id=1090519039) failed: Task execution failed: com.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
2019-07-05 10:06:56,773 WARN  DefaultFileSystemMaster - The persist job (id=1562320802240) for file /sample-2g/part-00012 (id=201326591) failed: Task execution failed: com.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
2019-07-05 10:06:58,379 ERROR S3AUnderFileSystem - Failed to delete sample-2g/part-00054.alluxio.0x0000016BC199DD30.tmp
com.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleRetryableException(AmazonHttpClient.java:1113)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1063)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:743)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:717)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4247)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4194)
	at com.amazonaws.services.s3.AmazonS3Client.deleteObject(AmazonS3Client.java:2084)
	at com.amazonaws.services.s3.AmazonS3Client.deleteObject(AmazonS3Client.java:2070)
	at alluxio.underfs.s3a.S3AUnderFileSystem.deleteObject(S3AUnderFileSystem.java:327)
	at alluxio.underfs.ObjectUnderFileSystem.deleteFile(ObjectUnderFileSystem.java:393)
	at alluxio.underfs.ObjectUnderFileSystem.lambda$deleteExistingFile$4(ObjectUnderFileSystem.java:398)
	at alluxio.underfs.ObjectUnderFileSystem.retryOnFalse(ObjectUnderFileSystem.java:1170)
	at alluxio.underfs.ObjectUnderFileSystem.deleteExistingFile(ObjectUnderFileSystem.java:398)
	at alluxio.underfs.UnderFileSystemWithLogging$14.call(UnderFileSystemWithLogging.java:286)
	at alluxio.underfs.UnderFileSystemWithLogging$14.call(UnderFileSystemWithLogging.java:283)
	at alluxio.underfs.UnderFileSystemWithLogging.call(UnderFileSystemWithLogging.java:949)
	at alluxio.underfs.UnderFileSystemWithLogging.deleteExistingFile(UnderFileSystemWithLogging.java:283)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$10.execute(ManagedBlockingUfsForwarder.java:172)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$10.execute(ManagedBlockingUfsForwarder.java:169)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.block(ManagedBlockingUfsForwarder.java:596)
	at alluxio.concurrent.jsr.ForkJoinPool.managedBlock(ForkJoinPool.java:1013)
	at alluxio.concurrent.ForkJoinPoolHelper.safeManagedBlock(ForkJoinPoolHelper.java:41)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.get(ManagedBlockingUfsForwarder.java:582)
	at alluxio.concurrent.ManagedBlockingUfsForwarder.deleteExistingFile(ManagedBlockingUfsForwarder.java:174)
	at alluxio.master.file.DefaultFileSystemMaster.cleanup(DefaultFileSystemMaster.java:4283)
	at alluxio.master.file.DefaultFileSystemMaster.access$3300(DefaultFileSystemMaster.java:223)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceScheduler.handleReady(DefaultFileSystemMaster.java:3941)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceScheduler.heartbeat(DefaultFileSystemMaster.java:4019)
	at alluxio.heartbeat.HeartbeatThread.run(HeartbeatThread.java:118)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.http.NoHttpResponseException: The target server failed to respond
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:141)
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)
	at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)
	at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)
	at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:165)
	at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)
	at com.amazonaws.http.protocol.SdkHttpRequestExecutor.doReceiveResponse(SdkHttpRequestExecutor.java:82)
	at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
	at com.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1235)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1055)
	... 36 more
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='rblaine95' date='2019-07-09T09:11:52Z'>
		Do you guys have any tips on figuring out how to debug this?
I've enabled debug logging on Alluxio and I'm trailing master and ceph rgw logs to see if there's something hinting at a problem.
When Alluxio encounters this problem, Spark can't access any data in Alluxio until it times out.
RGW Logs:
&lt;denchmark-code&gt;2019-07-09 08:55:52.397 7fd8bd7b9700  1 ====== starting new request req=0x7fd8bd7b0850 =====
2019-07-09 08:55:52.399 7fd8bd7b9700  1 ====== req done req=0x7fd8bd7b0850 op status=0 http_status=404 ======
2019-07-09 08:55:52.400 7fd8bd7b9700  1 civetweb: 0x55fcd97d69d8: 10.128.2.1 - - [09/Jul/2019:08:55:51 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:55:54.098 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:55:54.099 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:55:54.100 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:55:54 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:55:56.257 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:55:56.259 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:55:56.259 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:55:56 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:56:01.512 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:56:01.514 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:56:01.514 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:56:01 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:56:14.117 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:56:14.119 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:56:14.119 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:56:14 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:56:27.523 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:56:27.525 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:56:27.525 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:56:27 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
2019-07-09 08:56:57.530 7fd8bdfba700  1 ====== starting new request req=0x7fd8bdfb1850 =====
2019-07-09 08:56:57.536 7fd8bdfba700  1 ====== req done req=0x7fd8bdfb1850 op status=0 http_status=404 ======
2019-07-09 08:56:57.536 7fd8bdfba700  1 civetweb: 0x55fcd97d6000: 10.128.2.1 - - [09/Jul/2019:08:56:57 +0000] "HEAD /alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp HTTP/1.1" 404 230 - aws-sdk-java/1.11.215 Linux/3.10.0-957.5.1.el7.x86_64 OpenJDK_64-Bit_Server_VM/25.171-b11 java/1.8.0_171
&lt;/denchmark-code&gt;

Alluxio Logs:
&lt;denchmark-code&gt;2019-07-09 08:42:33,250 WARN  DefaultFileSystemMaster - Unexpected exception encountered when trying to complete persistence of a file /sample-2g/part-00024 (id=1509949439) : com.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
2019-07-09 08:42:38,237 ERROR S3AUnderFileSystem - Failed to copy file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024
com.amazonaws.services.s3.model.AmazonS3Exception: Not Found (Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found; Request ID: tx00000000000000001abc4-005d24537e-fc78f-my-store; S3 Extended Request ID: null), S3 Extended Request ID: null
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1638)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1303)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1055)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:743)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:717)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4247)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4194)
	at com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1253)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1977)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1910)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1862)
	at alluxio.underfs.s3a.S3AUnderFileSystem.copyObject(S3AUnderFileSystem.java:281)
	at alluxio.underfs.ObjectUnderFileSystem.renameFile(ObjectUnderFileSystem.java:746)
	at alluxio.underfs.ObjectUnderFileSystem.lambda$renameRenamableFile$20(ObjectUnderFileSystem.java:752)
	at alluxio.underfs.ObjectUnderFileSystem.retryOnFalse(ObjectUnderFileSystem.java:1170)
	at alluxio.underfs.ObjectUnderFileSystem.renameRenamableFile(ObjectUnderFileSystem.java:752)
	at alluxio.underfs.UnderFileSystemWithLogging$42.call(UnderFileSystemWithLogging.java:763)
	at alluxio.underfs.UnderFileSystemWithLogging$42.call(UnderFileSystemWithLogging.java:760)
	at alluxio.underfs.UnderFileSystemWithLogging.call(UnderFileSystemWithLogging.java:949)
	at alluxio.underfs.UnderFileSystemWithLogging.renameRenamableFile(UnderFileSystemWithLogging.java:760)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$37.execute(ManagedBlockingUfsForwarder.java:474)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$37.execute(ManagedBlockingUfsForwarder.java:471)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.block(ManagedBlockingUfsForwarder.java:596)
	at alluxio.concurrent.jsr.ForkJoinPool.managedBlock(ForkJoinPool.java:1013)
	at alluxio.concurrent.ForkJoinPoolHelper.safeManagedBlock(ForkJoinPoolHelper.java:41)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.get(ManagedBlockingUfsForwarder.java:582)
	at alluxio.concurrent.ManagedBlockingUfsForwarder.renameRenamableFile(ManagedBlockingUfsForwarder.java:476)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceChecker.handleSuccess(DefaultFileSystemMaster.java:4098)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceChecker.lambda$heartbeat$0(DefaultFileSystemMaster.java:4227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-09 08:42:38,238 ERROR S3AUnderFileSystem - Retrying copying file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024
2019-07-09 08:42:38,239 ERROR S3AUnderFileSystem - Failed to copy file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024
com.amazonaws.services.s3.model.AmazonS3Exception: Not Found (Service: Amazon S3; Status Code: 404; Error Code: 404 Not Found; Request ID: tx00000000000000001abc7-005d24537e-fc78f-my-store; S3 Extended Request ID: null), S3 Extended Request ID: null
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.handleErrorResponse(AmazonHttpClient.java:1638)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1303)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1055)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:743)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:717)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:699)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:667)
	at com.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:649)
	at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:513)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4247)
	at com.amazonaws.services.s3.AmazonS3Client.invoke(AmazonS3Client.java:4194)
	at com.amazonaws.services.s3.AmazonS3Client.getObjectMetadata(AmazonS3Client.java:1253)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1977)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1910)
	at com.amazonaws.services.s3.transfer.TransferManager.copy(TransferManager.java:1862)
	at alluxio.underfs.s3a.S3AUnderFileSystem.copyObject(S3AUnderFileSystem.java:281)
	at alluxio.underfs.ObjectUnderFileSystem.renameFile(ObjectUnderFileSystem.java:746)
	at alluxio.underfs.ObjectUnderFileSystem.lambda$renameRenamableFile$20(ObjectUnderFileSystem.java:752)
	at alluxio.underfs.ObjectUnderFileSystem.retryOnFalse(ObjectUnderFileSystem.java:1170)
	at alluxio.underfs.ObjectUnderFileSystem.renameRenamableFile(ObjectUnderFileSystem.java:752)
	at alluxio.underfs.UnderFileSystemWithLogging$42.call(UnderFileSystemWithLogging.java:763)
	at alluxio.underfs.UnderFileSystemWithLogging$42.call(UnderFileSystemWithLogging.java:760)
	at alluxio.underfs.UnderFileSystemWithLogging.call(UnderFileSystemWithLogging.java:949)
	at alluxio.underfs.UnderFileSystemWithLogging.renameRenamableFile(UnderFileSystemWithLogging.java:760)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$37.execute(ManagedBlockingUfsForwarder.java:474)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$37.execute(ManagedBlockingUfsForwarder.java:471)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.block(ManagedBlockingUfsForwarder.java:596)
	at alluxio.concurrent.jsr.ForkJoinPool.managedBlock(ForkJoinPool.java:1013)
	at alluxio.concurrent.ForkJoinPoolHelper.safeManagedBlock(ForkJoinPoolHelper.java:41)
	at alluxio.concurrent.ManagedBlockingUfsForwarder$ManagedBlockingUfsMethod.get(ManagedBlockingUfsForwarder.java:582)
	at alluxio.concurrent.ManagedBlockingUfsForwarder.renameRenamableFile(ManagedBlockingUfsForwarder.java:476)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceChecker.handleSuccess(DefaultFileSystemMaster.java:4098)
	at alluxio.master.file.DefaultFileSystemMaster$PersistenceChecker.lambda$heartbeat$0(DefaultFileSystemMaster.java:4227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-07-09 08:42:38,240 ERROR S3AUnderFileSystem - Retrying copying file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024
2019-07-09 08:42:38,245 ERROR S3AUnderFileSystem - Failed to copy file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024
...
2019-07-09 08:42:38,246 ERROR S3AUnderFileSystem - Failed to copy file sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to sample-2g/part-00024, after 3 retries
2019-07-09 08:42:38,399 ERROR ObjectUnderFileSystem - Unable to rename s3://alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to s3://alluxio/sample-2g/part-00024 because source does not exist or is a directory.
2019-07-09 08:42:38,652 ERROR ObjectUnderFileSystem - Unable to rename s3://alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to s3://alluxio/sample-2g/part-00024 because source does not exist or is a directory.
2019-07-09 08:42:39,206 ERROR ObjectUnderFileSystem - Unable to rename s3://alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to s3://alluxio/sample-2g/part-00024 because source does not exist or is a directory.
2019-07-09 08:42:40,814 ERROR ObjectUnderFileSystem - Unable to rename s3://alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to s3://alluxio/sample-2g/part-00024 because source does not exist or is a directory.
...
2019-07-09 09:15:42,089 WARN  DefaultFileSystemMaster - Unexpected exception encountered when trying to complete persistence of a file /sample-2g/part-00024 (id=1509949439) : Failed to rename s3://alluxio/sample-2g/part-00024.alluxio.0x0000016BD5E5F9CA.tmp to s3://alluxio/sample-2g/part-00024.
Jul 09, 2019 9:15:42 AM org.glassfish.jersey.server.ServerRuntime$Responder writeResponse
SEVERE: An I/O error has occurred while writing a response message entity to the container output stream.
org.glassfish.jersey.server.internal.process.MappableException: org.eclipse.jetty.io.EofException
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:92)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:162)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1130)
	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:697)
	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:432)
	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:422)
	at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:320)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:267)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:298)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:471)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:425)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:383)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:336)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:223)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:812)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:587)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1127)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1061)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52)
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52)
	at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)
	at org.eclipse.jetty.server.Server.handle(Server.java:499)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:311)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:257)
	at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:544)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:635)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:555)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.eclipse.jetty.io.EofException
	at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:192)
	at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:408)
	at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:302)
	at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:129)
	at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:694)
	at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:246)
	at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:208)
	at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:471)
	at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:763)
	at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:801)
	at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:147)
	at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:140)
	at org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:242)
	at org.glassfish.jersey.servlet.internal.ResponseWriter$NonCloseableOutputStreamWrapper.flush(ResponseWriter.java:330)
	at org.glassfish.jersey.message.internal.CommittingOutputStream.flush(CommittingOutputStream.java:292)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$UnCloseableOutputStream.flush(WriterInterceptorExecutor.java:304)
	at com.fasterxml.jackson.core.json.UTF8JsonGenerator.flush(UTF8JsonGenerator.java:1100)
	at com.fasterxml.jackson.databind.ObjectWriter.writeValue(ObjectWriter.java:915)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.writeTo(ProviderBase.java:650)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:265)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:250)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:162)
	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:106)
	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:162)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:86)
	... 36 more
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
	at sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
	at sun.nio.ch.IOUtil.write(IOUtil.java:148)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:504)
	at org.eclipse.jetty.io.ChannelEndPoint.flush(ChannelEndPoint.java:172)
	... 60 more
2019-07-09 09:15:42,144 WARN  SleepingTimer - Master Persistence Scheduler last execution took 1982996 ms. Longer than the interval 1000
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='rblaine95' date='2019-07-31T10:28:23Z'>
		Alright, so, I've been debugging this problem for a while now.
This definitely looks like it's a Ceph problem.
It looks like what happens is:

The data is written to Alluxio, and then asynchronously synchronized to the Ceph S3 UFS via the RGW.
Somewhere between the RGW and the OSD, something goes wrong.
I checked the logs of the OSD and the OSD reports that the file exists.
The RGW can't access the file.
Using an S3 client CLI (like minio/mc), the file is not visible (but other temporary Alluxio files are visible)
Alluxio tries to check on the status of the file it knows was written, but the RGW returns a 404.

I showed the issue to my department head and we compared our local deployment to our cloud deployment (where Alluxio runs without having this problem).
We believe the problem was that the Ceph OSD on our local deployment is using erasure coding, whereas the cloud deployment is using replicate 3, and that's causing this problem.
We believe that the issue is that the data itself is on the OSD, but the metadata is lagging behind.
		</comment>
		<comment id='4' author='rblaine95' date='2019-07-31T10:28:50Z'>
		I'm closing this issue as it appears it's not an Alluxio problem, but is instead a problem with our local Ceph deployment.
		</comment>
	</comments>
</bug>