<bug id='12227' author='Trevor-zhang' open_date='2020-10-10T06:23:58Z' closed_time='2020-10-11T05:42:17Z'>
	<summary>Apache Hudi writes data through Alluxio HA error</summary>
	<description>
Alluxio Version:
What version of Alluxio are you using?
&lt;denchmark-h:h3&gt;alluxio-enterprise-2.4.0-0.1&lt;/denchmark-h&gt;

Describe the bug
A clear and concise description of what the bug is.
To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='Trevor-zhang' date='2020-10-10T06:30:36Z'>
		1.When I specify an active port to write data to Alluxio, everything is normal
scala&gt; import org.apache.hudi.QuickstartUtils._
import org.apache.hudi.QuickstartUtils._
scala&gt; import scala.collection.JavaConversions._
import scala.collection.JavaConversions._
scala&gt; import org.apache.spark.sql.SaveMode._
import org.apache.spark.sql.SaveMode._
scala&gt; import org.apache.hudi.DataSourceReadOptions._
import org.apache.hudi.DataSourceReadOptions._
scala&gt; import org.apache.hudi.DataSourceWriteOptions._
import org.apache.hudi.DataSourceWriteOptions._
scala&gt; import org.apache.hudi.config.HoodieWriteConfig._
import org.apache.hudi.config.HoodieWriteConfig._
scala&gt; val tableName = "hudi_trips_cow_alluxio3"
tableName: String = hudi_trips_cow_alluxio3
scala&gt; val basePath = "alluxio://xx.3.67.71:19998/hdfs/hudi/0929/trip_cow_alluxio7"
basePath: String = alluxio://xx.3.67.71:19998/hdfs/hudi/0929/trip_cow_alluxio7
scala&gt; val df = spark.read.format("json").load("hdfs://nameservice1/zyx/source-file.json")
df: org.apache.spark.sql.DataFrame = [begin_lat: double, begin_lon: double ... 8 more fields]
scala&gt; df.write.format("hudi").
|   options(getQuickstartWriteConfigs).
|   option(PRECOMBINE_FIELD_OPT_KEY, "ts").
|   option(RECORDKEY_FIELD_OPT_KEY, "uuid").
|   option(PARTITIONPATH_FIELD_OPT_KEY, "partitionpath").
|   option(TABLE_NAME, tableName).
|   mode(Overwrite).
|   save(basePath)
20/10/10 14:26:00 WARN ConfigurationUtils: Alluxio CLIENT version (2.3.0) does not match Alluxio cluster version (enterprise-2.4.0-0.1)
20/10/10 14:26:01 WARN HoodieSparkSqlWriter$: hoodie table at alluxio://xx.3.67.71:19998/hdfs/hudi/0929/trip_cow_alluxio7 already exists. Deleting existing data &amp; overwriting with new data.
scala&gt;
		</comment>
		<comment id='2' author='Trevor-zhang' date='2020-10-10T06:38:10Z'>
		2.When I specify all Alluxio master ports to write data to Alluxio, an exception will be thrown
scala&gt; import org.apache.hudi.QuickstartUtils._
import org.apache.hudi.QuickstartUtils._
scala&gt; import scala.collection.JavaConversions._
import scala.collection.JavaConversions._
scala&gt; import org.apache.spark.sql.SaveMode._
import org.apache.spark.sql.SaveMode._
scala&gt; import org.apache.hudi.DataSourceReadOptions._
import org.apache.hudi.DataSourceReadOptions._
scala&gt; import org.apache.hudi.DataSourceWriteOptions._
import org.apache.hudi.DataSourceWriteOptions._
scala&gt; import org.apache.hudi.config.HoodieWriteConfig._
import org.apache.hudi.config.HoodieWriteConfig._
scala&gt; val tableName = "hudi_trips_cow_alluxio3"
tableName: String = hudi_trips_cow_alluxio3
scala&gt; val basePath = "alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7"
basePath: String = alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7
scala&gt; val df = spark.read.format("json").load("hdfs://nameservice1/zyx/source-file.json")
df: org.apache.spark.sql.DataFrame = [begin_lat: double, begin_lon: double ... 8 more fields]
scala&gt; df.write.format("hudi").
|   options(getQuickstartWriteConfigs).
|   option(PRECOMBINE_FIELD_OPT_KEY, "ts").
|   option(RECORDKEY_FIELD_OPT_KEY, "uuid").
|   option(PARTITIONPATH_FIELD_OPT_KEY, "partitionpath").
|   option(TABLE_NAME, tableName).
|   option(HIVE_DATABASE_OPT_KEY, "default").
|   option(HIVE_URL_OPT_KEY,  "jdbc:hive2://xx.3.67.77:xx000").
|   option(HIVE_USER_OPT_KEY, "lingqu").
|   option(HIVE_PASS_OPT_KEY, "lingqu@bigdata").
|   option(HIVE_TABLE_OPT_KEY,"trip_cow_alluxio_xx09_6").
|   option(HIVE_PARTITION_FIELDS_OPT_KEY,"partitionpath").
|   option(HIVE_SYNC_ENABLED_OPT_KEY, "true").
|   mode(Overwrite).
|   save(basePath)
20/xx/xx 14:05:54 WARN ConfigurationUtils: Alluxio CLIENT version (2.3.0) does not match Alluxio cluster version (enterprise-2.4.0-0.1)
[Stage 22:&gt;                                                         (0 + 3) / 3]20/xx/xx 14:08:00 WARN TaskSetManager: Lost task 1.0 in stage 22.0 (TID 28, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 2): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-28_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-28_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-28_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-28_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-28_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 45 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
[Stage 22:&gt;                                                         (0 + 2) / 3]20/xx/xx 14:08:01 WARN TaskSetManager: Lost task 0.0 in stage 22.0 (TID 27, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 1): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-27_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-27_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-27_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-27_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-27_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 44 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
[Stage 22:&gt;                                                         (0 + 3) / 3]20/xx/xx 14:08:06 WARN TaskSetManager: Lost task 2.0 in stage 22.0 (TID 29, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 3): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/03/d1d483ed-07d2-4000-82ea-2354fcb1db06-0_2-22-29_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/03/d1d483ed-07d2-4000-82ea-2354fcb1db06-0_2-22-29_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/03/d1d483ed-07d2-4000-82ea-2354fcb1db06-0_2-22-29_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/03/d1d483ed-07d2-4000-82ea-2354fcb1db06-0_2-22-29_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/03/d1d483ed-07d2-4000-82ea-2354fcb1db06-0_2-22-29_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 44 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
[Stage 22:&gt;                                                         (0 + 2) / 3]20/xx/xx 14:xx:01 WARN TaskSetManager: Lost task 0.1 in stage 22.0 (TID 31, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 2): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-31_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-31_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-31_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-31_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/02/988c3472-da8a-4111-89f0-7d4ae439599d-0_0-22-31_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 44 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
20/xx/xx 14:xx:01 WARN TaskSetManager: Lost task 1.1 in stage 22.0 (TID 30, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 1): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 44 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
[Stage 22:&gt;                                                         (0 + 1) / 3]20/xx/xx 14:12:01 WARN TaskSetManager: Lost task 2.1 in stage 22.0 (TID 32, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 2): TaskKilled (Stage cancelled)
org.apache.spark.SparkException: Job aborted due to stage failure:
Aborting TaskSet 22.0 because task 0 (partition 0)
cannot run anywhere due to node and executor blacklist.
Most recent failure:
Lost task 1.1 in stage 22.0 (TID 30, xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03, executor 1): java.lang.RuntimeException: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:121)
at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43)
at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
at org.apache.spark.storage.memory.MemoryStore.putIteratorAsBytes(MemoryStore.scala:349)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1193)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1xx2)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1167)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:893)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:407)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1408)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:413)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hudi.exception.HoodieException: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:124)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:44)
at org.apache.hudi.client.utils.LazyIterableIterator.next(LazyIterableIterator.java:119)
... 23 more
Caused by: org.apache.hudi.exception.HoodieException: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:143)
at org.apache.hudi.execution.LazyInsertIterable.computeNext(LazyInsertIterable.java:120)
... 25 more
Caused by: java.util.concurrent.ExecutionException: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.execute(BoundedInMemoryExecutor.java:141)
... 26 more
Caused by: org.apache.hudi.exception.HoodieInsertException: Failed to initialize HoodieStorageWriter for path alluxio://xx.3.67.71:19998;xx.3.67.72:19998;xx.3.67.77:19998/hdfs/hudi/0929/trip_cow_alluxio7/2020/01/01/9dc24ade-78df-4b22-9a1f-5c057418ee36-0_1-22-30_2020xxxx140553.parquet
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:83)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:62)
at org.apache.hudi.io.CreateHandleFactory.create(CreateHandleFactory.java:34)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:83)
at org.apache.hudi.execution.CopyOnWriteInsertHandler.consumeOneRecord(CopyOnWriteInsertHandler.java:40)
at org.apache.hudi.common.util.queue.BoundedInMemoryQueueConsumer.consume(BoundedInMemoryQueueConsumer.java:37)
at org.apache.hudi.common.util.queue.BoundedInMemoryExecutor.lambda$null$2(BoundedInMemoryExecutor.java:121)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
Caused by: alluxio.exception.status.UnavailableException: Failed to connect to FileSystemMasterClient @ xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 after 44 attempts
at alluxio.AbstractClient.connect(AbstractClient.java:278)
at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:518)
at alluxio.client.file.BaseFileSystem.createFile(BaseFileSystem.java:148)
at alluxio.hadoop.AbstractFileSystem.create(AbstractFileSystem.java:165)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx52)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:xx32)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:921)
at org.apache.hudi.common.fs.HoodieWrapperFileSystem.create(HoodieWrapperFileSystem.java:162)
at org.apache.parquet.hadoop.ParquetFileWriter.(ParquetFileWriter.java:244)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:273)
at org.apache.parquet.hadoop.ParquetWriter.(ParquetWriter.java:222)
at org.apache.hudi.io.storage.HoodieParquetWriter.(HoodieParquetWriter.java:57)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.newParquetFileWriter(HoodieFileWriterFactory.java:65)
at org.apache.hudi.io.storage.HoodieFileWriterFactory.getFileWriter(HoodieFileWriterFactory.java:46)
at org.apache.hudi.io.HoodieCreateHandle.(HoodieCreateHandle.java:81)
... xx more
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:504)
at alluxio.ClientContext.loadConf(ClientContext.java:134)
at alluxio.ClientContext.loadConfIfNotLoaded(ClientContext.java:155)
at alluxio.AbstractClient.beforeConnect(AbstractClient.java:175)
at alluxio.AbstractClient.connect(AbstractClient.java:224)
... 24 more
Caused by: alluxio.shaded.client.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
at alluxio.shaded.client.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:240)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:221)
at alluxio.shaded.client.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:140)
at alluxio.grpc.MetaMasterConfigurationServiceGrpc$MetaMasterConfigurationServiceBlockingStub.getConfiguration(MetaMasterConfigurationServiceGrpc.java:384)
at alluxio.util.ConfigurationUtils.loadConfiguration(ConfigurationUtils.java:498)
... 28 more
Caused by: alluxio.shaded.client.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03/xx.3.67.73:19998
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
at alluxio.shaded.client.io.netty.channel.unix.Errors.throwConnectException(Errors.java:124)
at alluxio.shaded.client.io.netty.channel.unix.Socket.finishConnect(Socket.java:243)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:672)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:649)
at alluxio.shaded.client.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:529)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:465)
at alluxio.shaded.client.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
at alluxio.shaded.client.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
at alluxio.shaded.client.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
at java.lang.Thread.run(Thread.java:748)
Blacklisting behavior can be configured via spark.blacklist.*.
at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1890)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1877)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:929)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:929)
at scala.Option.foreach(Option.scala:257)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:929)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2111)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2060)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2049)
at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:740)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2081)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2xx2)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2121)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2146)
at org.apache.spark.rdd.RDD.count(RDD.scala:1168)
at org.apache.hudi.HoodieSparkSqlWriter$.commitAndPerformPostOperations(HoodieSparkSqlWriter.scala:389)
at org.apache.hudi.HoodieSparkSqlWriter$.write(HoodieSparkSqlWriter.scala:205)
at org.apache.hudi.DefaultSource.createRelation(DefaultSource.scala:125)
at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)
at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)
at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)
at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)
at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)
at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)
at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)
at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)
... 75 elided
scala&gt;
		</comment>
		<comment id='3' author='Trevor-zhang' date='2020-10-11T04:18:02Z'>
		You'd better change the client to 2.4 version.
		</comment>
		<comment id='4' author='Trevor-zhang' date='2020-10-11T04:20:40Z'>
		It will make this issue more attractive while adding [2.4-beta] at the head of title
		</comment>
		<comment id='5' author='Trevor-zhang' date='2020-10-11T04:41:09Z'>
		Could you please show your spark-submit command? Thx~
		</comment>
		<comment id='6' author='Trevor-zhang' date='2020-10-11T04:55:13Z'>
		[masters]
xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01
xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01
xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02
[workers]
xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01
xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02
xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03
[alluxio-site]
alluxio.master.journal.type=EMBEDDED
alluxio.master.hostname=xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01
alluxio.master.mount.table.root.ufs=hdfs://xx-dev-cq-ecs-dtpbu-datalake-cdh-mansger-01:8020/alluxio-2.4
alluxio.master.journal.folder=hdfs://xx-dev-cq-ecs-dtpbu-datalake-cdh-mansger-01:8020/alluxio-2.4/journal
alluxio.master.embedded.journal.addresses=xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02:19200
alluxio.underfs.hdfs.configuration=/etc/hadoop/conf/core-site.xml:/etc/hadoop/conf/hdfs-site.xml
alluxio.master.security.impersonation.hive.users=*
alluxio.master.security.impersonation.yarn.users=*
alluxio.master.security.impersonation.zeppelin.users=*
alluxio.master.security.impersonation.root.users=*
alluxio.user.metrics.collection.enabled=true
alluxio.user.file.metadata.sync.interval=1m
alluxio.worker.memory.size=30GB
alluxio.worker.tieredstore.levels=1
alluxio.worker.tieredstore.level0.alias=MEM
alluxio.worker.tieredstore.level0.dirs.path=/data/ramdisk
Cc &lt;denchmark-link:https://github.com/jiacheliu3&gt;@jiacheliu3&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Trevor-zhang' date='2020-10-11T04:56:05Z'>
		
Could you please show your spark-submit command? Thx~
@JySongWithZhangCe

spark-shell --jars /data/hudi/jars/hudi-spark-bundle_2.11-0.6.0.jar,/data/hudi/jars/hive-jdbc.jar,/data/hudi/jars/hive-service.jar,/data/hudi/jars/alluxio-enterprise-2.4.0-0.1-client.jar  --conf 'spark.serializer=org.apache.spark.serializer.KryoSerializer'
		</comment>
		<comment id='8' author='Trevor-zhang' date='2020-10-11T05:00:41Z'>
		Your masters seem to be
&lt;denchmark-code&gt;alluxio.master.embedded.journal.addresses=xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02:19200
&lt;/denchmark-code&gt;

The error is complaining about a node that is NOT a master.
&lt;denchmark-code&gt;Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='Trevor-zhang' date='2020-10-11T05:08:26Z'>
		
Your masters seem to be
alluxio.master.embedded.journal.addresses=xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02:19200

The error is complaining about a node that is NOT a master.
Caused by: alluxio.exception.status.UnavailableException: Failed to handshake with master xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03:19998 to load cluster default configuration values: UNAVAILABLE: io exception


xx-dev-cq-ecs-dtpbu-datalake-cdh-work-03 just only a owrker, Why is it considered a master
		</comment>
		<comment id='10' author='Trevor-zhang' date='2020-10-11T05:10:25Z'>
		you can try conf below:
--deploy-mode client \
--conf spark.executor.extraJavaOptions="-Dalluxio.master.embedded.journal.addresses=xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02:19200 -Dalluxio.master.journal.type=EMBEDDED -Dalluxio.master.rpc.port=19998" \
--driver-java-options "-Dalluxio.master.embedded.journal.addresses=xx-dev-cq-ecs-dtpbu-datalake-cdh-edge-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-01:19200,xx-dev-cq-ecs-dtpbu-datalake-cdh-work-02:19200 -Dalluxio.master.journal.type=EMBEDDED -Dalluxio.master.rpc.port=19998"
		</comment>
		<comment id='11' author='Trevor-zhang' date='2020-10-11T05:42:13Z'>
		&lt;denchmark-link:https://github.com/JySongWithZhangCe&gt;@JySongWithZhangCe&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jiacheliu3&gt;@jiacheliu3&lt;/denchmark-link&gt;
  thanks for your help !
		</comment>
	</comments>
</bug>