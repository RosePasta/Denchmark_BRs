<bug id='9804' author='cheyang' open_date='2019-08-28T11:43:26Z' closed_time='2020-05-01T23:03:42Z'>
	<summary>Failed to load data into alluxio when data directory is pinned</summary>
	<description>
Alluxio Version:
2.1.0-SNAPSHOT
Describe the bug

Create two layers in alluxio: MEM and SSD

&lt;denchmark-code&gt;# /opt/alluxio/bin/alluxio fsadmin report capacity
Capacity information for all workers:
    Total Capacity: 320.00GB
        Tier: MEM  Size: 120.00GB
        Tier: SSD  Size: 200.00GB
    Used Capacity: 118.05GB
        Tier: MEM  Size: 118.05GB
        Tier: SSD  Size: 0B
    Used Percentage: 36%
    Free Percentage: 64%

Worker Name      Last Heartbeat   Storage       Total            MEM           SSD
192.168.0.118    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          28.29GB (35%)    28.29GB       0B
192.168.0.195    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
192.168.0.117    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
192.168.0.194    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
&lt;/denchmark-code&gt;


Pin the data directory

&lt;denchmark-code&gt;/opt/alluxio/bin/alluxio fs pin /training-data/images
&lt;/denchmark-code&gt;


Load the data into alluxio with distributedLoad

&lt;denchmark-code&gt;# /opt/alluxio/bin/alluxio fs -Dalluxio.user.ufs.block.read.location.policy=alluxio.client.block.policy.DeterministicHashPolicy  distributedLoad --replication 3 /training-data/images/
............................Failed to successfully complete the job.

&lt;/denchmark-code&gt;




From logging of the master
&lt;denchmark-code&gt;kubectl logs alluxio-master-0 -c alluxio-master
2019-08-28 03:25:58,460 WARN  SaslStreamServerDriver - Error received for channel: 1ce411a7-bef2-44bc-9b69-c05242ed1671. Error: io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
&lt;/denchmark-code&gt;

From logging from the job master
&lt;denchmark-code&gt;2019-08-28 03:25:02,002 INFO  JobCoordinator - Starting job LoadConfig{FilePath=/training-data/images/train-00585-of-01024, Replication=1}
2019-08-28 03:25:02,003 WARN  JobCoordinator - No executor was selected.
2019-08-28 03:25:02,012 INFO  JobCoordinator - Starting job LoadConfig{FilePath=/training-data/images/train-00622-of-01024, Replication=1}
2019-08-28 03:25:22,052 INFO  JobCoordinator - Starting job LoadConfig{FilePath=/training-data/images/train-00622-of-01024, Replication=1}
2019-08-28 03:25:34,076 INFO  JobCoordinator - Starting job LoadConfig{FilePath=/training-data/images/train-00622-of-01024, Replication=1}
2019-08-28 03:25:46,099 INFO  JobCoordinator - Starting job LoadConfig{FilePath=/training-data/images/train-00622-of-01024, Replication=1}
&lt;/denchmark-code&gt;


In the worker, it is failed to allocate the space in the MEM. But it doesn't turn to SSD tieredstore

&lt;denchmark-code&gt;2019-08-28 07:54:13,044 WARN  SpaceReserver - SpaceReserver failed to free 9663676416 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 9663676416 bytes space at location MEM
2019-08-28 07:54:14,044 WARN  SpaceReserver - SpaceReserver failed to free 9663676416 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 9663676416 bytes space at location MEM
2019-08-28 07:54:15,044 WARN  SpaceReserver - SpaceReserver failed to free 9663676416 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 9663676416 bytes space at location MEM
2019-08-28 07:54:16,044 WARN  SpaceReserver - SpaceReserver failed to free 9663676416 bytes on tier MEM for high watermarks: Failed to find an eviction plan to free 9663676416 bytes space at location MEM
&lt;/denchmark-code&gt;

We can see the MEM layer are used up, but SSD is not used.
&lt;denchmark-code&gt;# /opt/alluxio/bin/alluxio fsadmin report capacity
Capacity information for all workers:
    Total Capacity: 320.00GB
        Tier: MEM  Size: 120.00GB
        Tier: SSD  Size: 200.00GB
    Used Capacity: 118.05GB
        Tier: MEM  Size: 118.05GB
        Tier: SSD  Size: 0B
    Used Percentage: 36%
    Free Percentage: 64%

Worker Name      Last Heartbeat   Storage       Total            MEM           SSD
192.168.0.118    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          28.29GB (35%)    28.29GB       0B
192.168.0.195    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
192.168.0.117    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
192.168.0.194    0                capacity      80.00GB          30.00GB       50.00GB
                                  used          29.92GB (37%)    29.92GB       0B
&lt;/denchmark-code&gt;


In the job worker, here is the logging.

&lt;denchmark-code&gt;2019-08-28 03:25:02,344 INFO  TaskExecutorManager - Task 0 for job 1566803410444 started
2019-08-28 03:25:21,205 WARN  GrpcBlockingStream - Received error io.grpc.StatusRuntimeException: RESOURCE_EXHAUSTED: Failed to request 1048576 bytes after 10,000ms to create blockId 10452205568 for stream (GrpcDataWriter{request=type: ALLUXIO_BLOCK
id: 10452205568
tier: 0
medium_type: ""
pin_on_create: true
, address=WorkerNetAddress{host=192.168.0.194, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=/opt/domain/47f4f2cf-18e9-4fb0-823f-afaa8d844f11, tieredIdentity=TieredIdentity(node=192.168.0.194, rack=null)}})
2019-08-28 03:25:21,298 INFO  TaskExecutorManager - Task 0 for job 1566803410444 failed: Failed to request 1048576 bytes after 10,000ms to create blockId 10452205568 (GrpcDataWriter{request=type: ALLUXIO_BLOCK
id: 10452205568
tier: 0
medium_type: ""
pin_on_create: true
, address=WorkerNetAddress{host=192.168.0.194, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=/opt/domain/47f4f2cf-18e9-4fb0-823f-afaa8d844f11, tieredIdentity=TieredIdentity(node=192.168.0.194, rack=null)}})
2019-08-28 03:25:21,298 WARN  TaskExecutor - Exception running task for job Load([LoadTask{blockId=10452205568}]) : Failed to request 1048576 bytes after 10,000ms to create blockId 10452205568 (GrpcDataWriter{request=type: ALLUXIO_BLOCK
id: 10452205568
tier: 0
medium_type: ""
pin_on_create: true
&lt;/denchmark-code&gt;


But after I upin the data directory, it seems working fine. And I'm able to see the SSD layer can be used when MEM layer is used up.

The expection is that when the Memory is used up, it should turn to SSD no mater the data directory is pinned.
	</description>
	<comments>
		<comment id='1' author='cheyang' date='2019-08-28T21:10:31Z'>
		&lt;denchmark-link:https://github.com/cheyang&gt;@cheyang&lt;/denchmark-link&gt;
 Thanks for reporting this issue.
Currently the allocation strategy only attempts to allocate the highest tier, which is why it fails when you have the MEM tier completely pinned.
We can consider searching for space in lower tiers if the top tier cannot be allocated.
		</comment>
		<comment id='2' author='cheyang' date='2019-08-28T23:35:08Z'>
		Thank you, &lt;denchmark-link:https://github.com/calvinjia&gt;@calvinjia&lt;/denchmark-link&gt;
 . In the deep learning scenario, the data for training is highly possible larger than capacity of highest layer. And all of the data will participate training, so no cold and warm data. The reason of using allluxio is to make some of the data are in the memory level speed.
And at the same time, we hope to pin the data because we want to avoid to introduce overhead due to swap in/swap out.  So I think it's important if we'd like to support deep learning scenario.
		</comment>
		<comment id='3' author='cheyang' date='2019-08-29T01:14:50Z'>
		&lt;denchmark-link:https://github.com/cheyang&gt;@cheyang&lt;/denchmark-link&gt;
 I think this makes sense. Have you tried putting all your different media types in one tier, that might solve the issue until we have this feature.
		</comment>
		<comment id='4' author='cheyang' date='2019-08-29T12:27:04Z'>
		
@cheyang I think this makes sense. Have you tried putting all your different media types in one tier, that might solve the issue until we have this feature.

Could you provide a sample to help me understand better? Thanks.
		</comment>
		<comment id='5' author='cheyang' date='2019-08-29T18:15:19Z'>
		Check out the examples here: &lt;denchmark-link:https://docs.alluxio.io/os/user/stable/en/advanced/Alluxio-Storage-Management.html#single-tier-storage&gt;https://docs.alluxio.io/os/user/stable/en/advanced/Alluxio-Storage-Management.html#single-tier-storage&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>