<bug id='11859' author='cheyang' open_date='2020-07-29T22:43:57Z' closed_time='2020-11-18T21:44:46Z'>
	<summary>Failed to distribute load small files</summary>
	<description>
Alluxio Version:
alluxio version -r
2.3.1-SNAPSHOT-fd10ac016c6315275f1a91f845a545e28b2602ad
Describe the bug
The OSS bucket is 92G, the number of files is 3804847, the size of average file is 20K.

Install alluxio with the config, the meta data configuration is

&lt;denchmark-code&gt;alluxio.master.metadata.sync.concurrency.level: "64"
    alluxio.master.metadata.sync.executor.pool.size: "64"
    alluxio.master.metadata.sync.ufs.prefetch.pool.size: "64"
&lt;/denchmark-code&gt;

The full configuration are
&lt;denchmark-code&gt;image: registry.cn-huhehaote.aliyuncs.com/alluxio/alluxio
imageTag: "2.3.0-SNAPSHOT-fd10ac0"
imagePullPolicy: Always

properties:
    alluxio.user.ufs.block.read.location.policy: alluxio.client.block.policy.LocalFirstAvoidEvictionPolicy
    alluxio.master.metastore: ROCKS
    alluxio.master.metastore.inode.cache.max.size: "10000000"
    alluxio.master.metadata.sync.concurrency.level: "64"
    alluxio.master.metadata.sync.executor.pool.size: "64"
    alluxio.master.metadata.sync.ufs.prefetch.pool.size: "64"
    alluxio.master.journal.log.size.bytes.max: 500MB
    alluxio.fuse.jnifuse.enabled: true
    alluxio.user.client.cache.enabled: false
    #alluxio.master.journal.log.size.bytes.max: 100MB
    alluxio.user.update.file.accesstime.disabled: true
    alluxio.user.block.worker.client.pool.min: 512
    # It should be great than (120)*0.01 = 2GB
    alluxio.fuse.debug.enabled: "false"
    alluxio.web.ui.enabled: false
    alluxio.user.file.writetype.default: MUST_CACHE
    alluxio.user.block.write.location.policy.class: alluxio.client.block.policy.LocalFirstAvoidEvictionPolicy
    alluxio.worker.allocator.class: alluxio.worker.block.allocator.GreedyAllocator
    alluxio.user.block.size.bytes.default: 8MB
    fs.oss.endpoint: oss-cn-huhehaote-internal.aliyuncs.com
    fs.oss.accessKeyId: xxx
    fs.oss.accessKeySecret: yyy
    alluxio.master.mount.table.root.ufs: oss://insight-face-data-90g-huabei5/
    # alluxio.underfs.oss.socket.timeout: 3000sec
    alluxio.user.streaming.reader.chunk.size.bytes: 8MB
    alluxio.user.local.reader.chunk.size.bytes: 8MB
    alluxio.worker.network.reader.buffer.size: 8MB
    alluxio.worker.file.buffer.size: 320MB
    alluxio.job.worker.threadpool.size: 64
    alluxio.user.metrics.collection.enabled: false
    alluxio.master.rpc.executor.max.pool.size: 10240
    alluxio.master.rpc.executor.core.pool.size: 128
    alluxio.master.mount.table.root.readonly: true
    alluxio.user.update.file.accesstime.disabled: true
    alluxio.user.file.passive.cache.enabled: false
    alluxio.user.block.avoid.eviction.policy.reserved.size.bytes: 2GB
    alluxio.master.journal.folder: /journal
    alluxio.master.journal.type: UFS
    alluxio.user.block.master.client.pool.gc.threshold: 2day
    alluxio.user.file.master.client.threads: 1024
    alluxio.user.block.master.client.threads: 1024
    alluxio.user.file.readtype.default: CACHE
    alluxio.security.stale.channel.purge.interval: 365d
    alluxio.user.metadata.cache.enabled: true
    alluxio.user.metadata.cache.expiration.time: 2day
    alluxio.user.metadata.cache.max.size: "1000000"
    alluxio.user.direct.memory.io.enabled: true
    alluxio.fuse.cached.paths.max: "1000000"
    alluxio.job.worker.threadpool.size: 164
    alluxio.user.worker.list.refresh.interval: 2min
    alluxio.user.logging.threshold: 1000ms
    alluxio.fuse.logging.threshold: 1000ms
    alluxio.worker.block.master.client.pool.size: 1024

worker:
    jvmOptions: " -Xmx12G -XX:+UnlockExperimentalVMOptions -XX:MaxDirectMemorySize=32g  -XX:ActiveProcessorCount=8 "

master:
    jvmOptions: " -Xmx16G -XX:+UnlockExperimentalVMOptions -XX:ActiveProcessorCount=8 "

tieredstore:
  levels:
  - alias: MEM
    level: 0
    type: hostPath
    path: /dev/shm
    quota: 40GB
    high: 0.99
    low: 0.8

fuse:
  enaabled: true
  #clientEnabled: true
  mountPath: /mnt/alluxio-fuse
  image: registry.cn-huhehaote.aliyuncs.com/alluxio/alluxio-fuse
  imageTag: "2.3.0-SNAPSHOT-fd10ac0"
  imagePullPolicy: Always
  env:
    MAX_IDLE_THREADS: "64"
    SPENT_TIME: "1000"
  # Customize the MaxDirectMemorySize
  jvmOptions: " -Xmx16G -Xms16G -XX:+UseG1GC -XX:MaxDirectMemorySize=32g -XX:+UnlockExperimentalVMOptions -XX:ActiveProcessorCount=24 "
  shortCircuitPolicy: local
  args:
    - fuse
    - --fuse-opts=kernel_cache,ro,max_read=131072,attr_timeout=7200,entry_timeout=7200

&lt;/denchmark-code&gt;


Install the alluxio with helm chart

&lt;denchmark-code&gt;helm install alluxio -f config.yaml alluxio
&lt;/denchmark-code&gt;


Try to distributed load the data, it took 85 minutes to load the data. but it exits without finishing.

&lt;denchmark-code&gt;time /opt/alluxio/bin/alluxio fs  -Xmx100g  distributedLoad --replication 1 /
/images_2/2578803.png loading
/images_2/1363435.png loading
/images_2/20610.png loading
/images_2/2561851.png loading
/images_2/2652578.png loading
/images_2/2206772.png loading
/images_2/3506400.png loading
/images_2/2349272.png loading
/faces_ms1m_112x112_2.pickle loading

real    86m30.144s
user    21m2.235s
sys     14m57.111s
&lt;/denchmark-code&gt;

Check the status
&lt;denchmark-code&gt;alluxio fs -Xmx100g du -sh /
File Size     In Alluxio       Path
SLF4J: Failed toString() invocation on an object of type [java.util.ArrayList]
java.lang.OutOfMemoryError
	at java.lang.AbstractStringBuilder.hugeCapacity(AbstractStringBuilder.java:161)
	at java.lang.AbstractStringBuilder.newCapacity(AbstractStringBuilder.java:155)
	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:125)
	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448)
	at java.lang.StringBuilder.append(StringBuilder.java:136)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at java.util.AbstractCollection.toString(AbstractCollection.java:462)
	at org.slf4j.helpers.MessageFormatter.safeObjectAppend(MessageFormatter.java:304)
	at org.slf4j.helpers.MessageFormatter.deeplyAppendParameter(MessageFormatter.java:276)
	at org.slf4j.helpers.MessageFormatter.arrayFormat(MessageFormatter.java:230)
	at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:463)
	at alluxio.AbstractClient.retryRPC(AbstractClient.java:372)
	at alluxio.client.file.RetryHandlingFileSystemMasterClient.listStatus(RetryHandlingFileSystemMasterClient.java:224)
	at alluxio.client.file.BaseFileSystem.lambda$listStatus$9(BaseFileSystem.java:273)
	at alluxio.client.file.BaseFileSystem.rpc(BaseFileSystem.java:519)
	at alluxio.client.file.BaseFileSystem.listStatus(BaseFileSystem.java:269)
	at alluxio.client.file.MetadataCachingBaseFileSystem.listStatus(MetadataCachingBaseFileSystem.java:99)
	at alluxio.cli.fs.command.DuCommand.runPlainPath(DuCommand.java:94)
	at alluxio.cli.fs.command.AbstractFileSystemCommand.runWildCardCmd(AbstractFileSystemCommand.java:92)
	at alluxio.cli.fs.command.DuCommand.run(DuCommand.java:207)
	at alluxio.cli.AbstractShell.run(AbstractShell.java:137)
	at alluxio.cli.fs.FileSystemShell.main(FileSystemShell.java:66)
84.29GB       30.97GB (36%)    /

alluxio fsadmin report capacity
Capacity information for all workers:
    Total Capacity: 160.00GB
        Tier: MEM  Size: 160.00GB
    Used Capacity: 30.97GB
        Tier: MEM  Size: 30.97GB
    Used Percentage: 19%
    Free Percentage: 81%

Worker Name      Last Heartbeat   Storage       MEM
192.168.0.117    0                capacity      40.00GB
                                  used          7.73GB (19%)
192.168.0.194    0                capacity      40.00GB
                                  used          7.74GB (19%)
192.168.0.195    0                capacity      40.00GB
                                  used          7.75GB (19%)
192.168.0.118    0                capacity      40.00GB
                                  used          7.75GB (19%)
&lt;/denchmark-code&gt;


The diagnose log is below

&lt;denchmark-link:https://github.com/Alluxio/alluxio/files/4997840/diagnose_alluxio_1596061779.tar.gz&gt;diagnose_alluxio_1596061779.tar.gz&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/Alluxio/alluxio/files/4997843/user_root.log&gt;user_root.log&lt;/denchmark-link&gt;

To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='cheyang' date='2020-07-30T07:58:00Z'>
		what is 2.3.1-SNAPSHOT-fd10ac016c6315275f1a91f845a545e28b2602ad branch ?
		</comment>
		<comment id='2' author='cheyang' date='2020-07-31T00:43:38Z'>
		&lt;denchmark-link:https://github.com/Alluxio/alluxio/tree/branch-2.3-fuse&gt;https://github.com/Alluxio/alluxio/tree/branch-2.3-fuse&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='cheyang' date='2020-11-06T00:47:03Z'>
		The error that stands out the most here is:
"alluxio.job.plan.load.LoadConfig\221\331\273\213\236-(\b\002\000\002I\000\fmReplicationL\000\tmFilePatht\000\022Ljava/lang/String;xp\000\000\000\001t\000\025/images_2/2652578.png"
, Error=alluxio.exception.status.ResourceExhaustedException: Job master is at full capacity of 100,000 jobs"
The easiest ways to address this are:


Decrease alluxio.job.master.finished.job.retention.time: The default value is 5 minutes. Which means that no matter what, a finished job will be part of Job Master's capacity for at least 5 minutes. I personally think this might just be too high of a default in general and reduce it down to 1 minute.


Increase alluxio.job.master.job.capacity: This is probably unnecessary when 1 changes but there is a chance it may not address the issue in which case, this would be the next thing to increase.


		</comment>
		<comment id='4' author='cheyang' date='2020-11-18T21:44:44Z'>
		Closing and moving the discussion to &lt;denchmark-link:https://github.com/Alluxio/alluxio/issues/12517&gt;#12517&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>