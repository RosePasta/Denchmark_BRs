<bug id='12116' author='iluoeli' open_date='2020-09-20T09:27:27Z' closed_time='2020-11-17T06:20:36Z'>
	<summary>Failed to distributedLoad data</summary>
	<description>

&lt;denchmark-link:https://github.com/Alluxio/alluxio/tree/branch-2.3-fuse&gt;https://github.com/Alluxio/alluxio/tree/branch-2.3-fuse&lt;/denchmark-link&gt;

Describe the bug
Alluxio cluster consists of 1 master node and 4 worker nodes. The under storage is local, and data size is 144GB.
bash-4.4# alluxio fsadmin report capacity
Capacity information for all workers:
    Total Capacity: 200.00GB
        Tier: SSD  Size: 200.00GB
    Used Capacity: 0B
        Tier: SSD  Size: 0B
    Used Percentage: 0%
    Free Percentage: 100%

Worker Name      Last Heartbeat   Storage       SSD
192.168.1.11     0                capacity      50.00GB
                                  used          0B (0%)
192.168.1.16     0                capacity      50.00GB
                                  used          0B (0%)
192.168.1.15     0                capacity      50.00GB
                                  used          0B (0%)
192.168.1.17     0                capacity      50.00GB
                                  used          0B (0%)
bash-4.4# alluxio fs  du -sh /
File Size     In Alluxio       Path
143.67GB      0B (0%)          /
When I distributedLoad the data, it failed and say:
bash-4.4# alluxio fs distributedLoad  --replication 1 /
# ......
Successfully loaded path /nfs-imagenet/imagenet/validation/validation-00067-of-00128 after 1 attempts
/nfs-imagenet/imagenet/train/train-00370-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00060-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00075-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00090-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00359-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00964-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00024-of-01024 loading
/nfs-imagenet/imagenet/train/train-01013-of-01024 loading
/nfs-imagenet/imagenet/train/train-00564-of-01024 loading
/nfs-imagenet/imagenet/train/train-00653-of-01024 loading
/nfs-imagenet/imagenet/train/train-00215-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00784-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00742-of-01024 loading
Successfully loaded path /nfs-imagenet/imagenet/validation/validation-00052-of-00128 after 1 attempts
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00020-of-00128 failed because:
/nfs-imagenet/imagenet/train/train-00126-of-01024 loading
/nfs-imagenet/imagenet/train/train-00949-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00992-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00386-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00158-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00304-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00444-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00090-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00153-of-01024 failed because:
/nfs-imagenet/imagenet/train/train-00475-of-01024 loading
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00527-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00236-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00629-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00338-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00208-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00493-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00104-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00702-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00103-of-00128 failed because:
Successfully loaded path /nfs-imagenet/imagenet/validation/validation-00008-of-00128 after 1 attempts
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00069-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00071-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00174-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00091-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00707-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00106-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00846-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00465-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00125-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00416-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00600-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00498-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00009-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00080-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00789-of-01024 failed because:
Successfully loaded path /nfs-imagenet/imagenet/validation/validation-00068-of-00128 after 1 attempts
Attempt 1 to load /nfs-imagenet/imagenet/train/train-01014-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00203-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00411-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00034-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00366-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00023-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00730-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00347-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00813-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00375-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00096-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00605-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00004-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00019-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00120-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00890-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00118-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00109-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00210-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00051-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00801-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00562-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-01019-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00061-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00394-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00791-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00929-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00506-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00588-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00948-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00248-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00661-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00489-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00181-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00772-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00515-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00543-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00432-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00744-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00305-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00728-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00007-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00146-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00775-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00423-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00486-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00137-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00756-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00276-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00190-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00590-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00976-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00633-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00763-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00858-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00699-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00617-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00070-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00292-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00747-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00404-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00571-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00534-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00089-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00820-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00985-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00321-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00931-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00886-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00957-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00451-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00162-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00719-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00988-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00165-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00903-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00749-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00850-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-01002-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-01011-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00832-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00026-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00087-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00654-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00302-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00945-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00626-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00822-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00407-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00484-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00917-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00680-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00425-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00927-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/validation/validation-00033-of-00128 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00435-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00049-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00716-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00193-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00420-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00330-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00621-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00787-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00804-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00548-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00742-of-01024 failed because:
Attempt 1 to load /nfs-imagenet/imagenet/train/train-00383-of-01024 failed because:
Only 32GB data is loaded.
bash-4.4# alluxio fsadmin report capacity
Capacity information for all workers:
    Total Capacity: 200.00GB
        Tier: SSD  Size: 200.00GB
    Used Capacity: 32.31GB
        Tier: SSD  Size: 32.31GB
    Used Percentage: 16%
    Free Percentage: 84%

Worker Name      Last Heartbeat   Storage       SSD
192.168.1.11     0                capacity      50.00GB
                                  used          7.40GB (14%)
192.168.1.16     0                capacity      50.00GB
                                  used          9.20GB (18%)
192.168.1.15     0                capacity      50.00GB
                                  used          5.94GB (11%)
192.168.1.17     0                capacity      50.00GB
                                  used          9.76GB (19%)
To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)

distributedLoad data of large size

Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='iluoeli' date='2020-09-20T09:29:52Z'>
		The logs are here:
&lt;denchmark-link:https://github.com/Alluxio/alluxio/files/5251382/diagnose_fluid_1600592464.tar.gz&gt;diagnose_fluid_1600592464.tar.gz&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='iluoeli' date='2020-11-05T19:52:26Z'>
		&lt;denchmark-link:https://github.com/bradyoo&gt;@bradyoo&lt;/denchmark-link&gt;
  Can you take a look at this issue?
		</comment>
		<comment id='3' author='iluoeli' date='2020-11-05T23:24:16Z'>
		Everything appears to be dying to: Timeout waiting for response after 30000ms. (Zero Copy GrpcDataReader). This is the job worker asking the worker for data but worker (and likely underlying storage not being able to respond to it)
There are couple of suggestions here:


Increase this timeout. This is alluxio.user.network.data.timeout.ms which currently has a value of 30sec (30000 ms) but it may just be hiding the underlying storage being overloaded.


Decrease the threadpool size of job service: There is likely too many jobs being issued from the job workers causing the overload. The best way to decrease the parallelization of job workers is to decrease the size of the threadpool of the jobservice. It's default is 10 but try at first going down to 2 to see if there is any difference.


		</comment>
		<comment id='4' author='iluoeli' date='2020-11-06T06:42:48Z'>
		&lt;denchmark-link:https://github.com/gpang&gt;@gpang&lt;/denchmark-link&gt;
  do you think your recent fixes can mitigate the timeout issue (see Bradley's analysis)? if yes, I will make some cherrypick
		</comment>
		<comment id='5' author='iluoeli' date='2020-11-06T17:14:18Z'>
		&lt;denchmark-link:https://github.com/apc999&gt;@apc999&lt;/denchmark-link&gt;

Well, there should be an investigation on the worker side to see what is taking a long time. Is the already verified that it is the UFS taking over 30s to respond?
If so, the simplest fix is to increase the timeout, since my main change is related to increasing the default timeout and adding logging messages.
		</comment>
		<comment id='6' author='iluoeli' date='2020-11-06T21:05:44Z'>
		to summarize my discussion with &lt;denchmark-link:https://github.com/gpang&gt;@gpang&lt;/denchmark-link&gt;
 based on what &lt;denchmark-link:https://github.com/bradyoo&gt;@bradyoo&lt;/denchmark-link&gt;
 was suggesting:
For the failed load task, it times out first, see logs on client side (job worker)
&lt;denchmark-code&gt;2020-09-20 08:38:22,583 WARN  GrpcBlockingStream - Received error io.grpc.StatusRuntimeException: UNKNOWN for stream (GrpcDataWriter{request=type: ALLUXIO_BLOCK
id: 17699962881
tier: 0
medium_type: ""
pin_on_create: false
space_to_reserve: 16777216
, address=WorkerNetAddress{host=192.168.1.11, containerHost=, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=, tieredIdentity=TieredIdentity(node=192.168.1.11, rack=null)}})
2020-09-20 08:38:22,583 WARN  GrpcBlockingStream - Received error io.grpc.StatusRuntimeException: UNKNOWN for stream (GrpcDataWriter{request=type: ALLUXIO_BLOCK
id: 11626610694
tier: 0
medium_type: ""
pin_on_create: false
space_to_reserve: 16777216
, address=WorkerNetAddress{host=192.168.1.11, containerHost=, rpcPort=29999, dataPort=29999, webPort=30000, domainSocketPath=, tieredIdentity=TieredIdentity(node=192.168.1.11, rack=null)}})
&lt;/denchmark-code&gt;

a few minutes later,  on worker side, we see errors complaining grpc connection was closed:
&lt;denchmark-code&gt;2020-09-20 08:38:26,466 WARN  AbstractReadHandler - Exception occurred while processing read request onError sessionId: BlockReadRequest{chunkSize=33554432, end=16777216, id=11626610694, openUfsBlockOptions=ufs_path: "/underFSStorage/nfs-imagenet/imagenet/train/train-00192-of-01024"
offset_in_file: 100663296
block_size: 16777216
maxUfsReadConcurrency: 2147483647
mountId: 1
no_cache: true
, promote=false, sessionId=7601658885997970263, start=0, positionShort=false}, 7601658885997970263: io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
Sep 20, 2020 8:38:26 AM io.grpc.netty.NettyServerHandler onStreamError
WARNING: Stream Error
io.netty.handler.codec.http2.Http2Exception$StreamException: Stream closed before write could take place
	at io.netty.handler.codec.http2.Http2Exception.streamError(Http2Exception.java:167)
	at io.netty.handler.codec.http2.DefaultHttp2RemoteFlowController$FlowState.cancel(DefaultHttp2RemoteFlowController.java:481)
	at io.netty.handler.codec.http2.DefaultHttp2RemoteFlowController$1.onStreamClosed(DefaultHttp2RemoteFlowController.java:105)
	at io.netty.handler.codec.http2.DefaultHttp2Connection.notifyClosed(DefaultHttp2Connection.java:356)
	at io.netty.handler.codec.http2.DefaultHttp2Connection$ActiveStreams.removeFromActiveStreams(DefaultHttp2Connection.java:1000)
	at io.netty.handler.codec.http2.DefaultHttp2Connection$ActiveStreams.deactivate(DefaultHttp2Connection.java:956)
	at io.netty.handler.codec.http2.DefaultHttp2Connection$DefaultStream.close(DefaultHttp2Connection.java:512)
	at io.netty.handler.codec.http2.DefaultHttp2Connection.close(DefaultHttp2Connection.java:152)
	at io.netty.handler.codec.http2.Http2ConnectionHandler$BaseDecoder.channelInactive(Http2ConnectionHandler.java:209)
	at io.netty.handler.codec.http2.Http2ConnectionHandler.channelInactive(Http2ConnectionHandler.java:417)
	at io.grpc.netty.NettyServerHandler.channelInactive(NettyServerHandler.java:592)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:239)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:260)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:246)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:818)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:384)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;

Based on the discussion results, we believe &lt;denchmark-link:https://github.com/Alluxio/alluxio/pull/12449&gt;#12449&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/Alluxio/alluxio/pull/12463&gt;#12463&lt;/denchmark-link&gt;
 will help in

increase client-side timeout
add more useful logging to ease debugging.

&lt;denchmark-link:https://github.com/iluoeli&gt;@iluoeli&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/cheyang&gt;@cheyang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/TrafalgarZZZ&gt;@TrafalgarZZZ&lt;/denchmark-link&gt;
 I will update the branch-2.3-fuse with above improvement and please verify if it is fixed.
Thanks
		</comment>
		<comment id='7' author='iluoeli' date='2020-11-17T06:20:36Z'>
		verified with &lt;denchmark-link:https://github.com/cheyang&gt;@cheyang&lt;/denchmark-link&gt;
 , this issue was fixed. We will have a new issue on the incomplete results of small files
		</comment>
	</comments>
</bug>