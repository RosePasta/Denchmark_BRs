<bug id='10684' author='XiaochenCui' open_date='2019-12-30T09:17:00Z' closed_time='2020-01-03T18:11:44Z'>
	<summary>permission problem</summary>
	<description>
Alluxio Version:
2.1.1

I have followed the &lt;denchmark-link:https://docs.alluxio.io/os/user/stable/en/compute/Spark.html&gt;https://docs.alluxio.io/os/user/stable/en/compute/Spark.html&lt;/denchmark-link&gt;
 to run spark on alluxio, but when I type  in spark-shell, It complained that:

Finally, I have to set permission to 777, what a shit.
The hdfs permission:
&lt;denchmark-code&gt;[root@cdh1 alluxio-2.1.1]# hdfs dfs -ls  hdfs://cdh1:8020/alluxio/root/
Found 3 items
-rwxrwxrwx   3 root root      27040 2019-12-30 15:17 hdfs://cdh1:8020/alluxio/root/Input
-rwxrwxrwx   3 root root      27040 2019-12-30 15:44 hdfs://cdh1:8020/alluxio/root/Input_HDFS
drwxrwxrwx   - root root          0 2019-12-30 15:21 hdfs://cdh1:8020/alluxio/root/default_tests_files
&lt;/denchmark-code&gt;

alluxio permission:
&lt;denchmark-code&gt;[root@cdh1 alluxio-2.1.1]# alluxio fs ls /
-rwxrwxrwx  root           root                     27040       PERSISTED 12-30-2019 14:43:46:200 100% /Input
-rwxrwxrwx  root           root                     27040       PERSISTED 12-30-2019 15:39:45:558   0% /Input_HDFS
drwxr-xr-x  spark          hadoop                       0   NOT_PERSISTED 12-30-2019 17:02:57:367  DIR /Output_HDFS
drwxrwxrwx  root           root                        12       PERSISTED 12-30-2019 14:12:38:317  DIR /default_tests_files
&lt;/denchmark-code&gt;

The spark-shell must be ran under 'spark' user.
I tried to add 'spark' user to group 'root' or 'wheel', but it does not help.
btw, the hdfs super user is hdfs:hdfs
To Reproduce
Steps to reproduce the behavior (as minimally and precisely as possible)
Expected behavior
A clear and concise description of what you expected to happen.
Urgency
Describe the impact and urgency of the bug.
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='XiaochenCui' date='2019-12-30T09:20:36Z'>
		How can I add the user 'spark' to group 'root'?
The usermod command does not help
		</comment>
		<comment id='2' author='XiaochenCui' date='2020-01-03T18:11:43Z'>
		&lt;denchmark-link:https://github.com/XiaochenCui&gt;@XiaochenCui&lt;/denchmark-link&gt;
 I think you need to revisit your understanding of the Alluxio Security Model. I would start with this link here: &lt;denchmark-link:https://docs.alluxio.io/os/user/stable/en/operation/Security.html#client-side-hadoop-impersonation&gt;https://docs.alluxio.io/os/user/stable/en/operation/Security.html#client-side-hadoop-impersonation&lt;/denchmark-link&gt;

In your scenario, it looks like the owner/group of the HDFS directory hdfs://cdh1:8020/alluxio/root/ were set to 'root:root'. From there, when you mounted that HDFS to Alluxio, Alluxio permissions ended up syncing with the HDFS directory. Therefore, in the Alluxio FileSystem the owner and group of the directory alluxio:/// is also 'root:root'. This means, if you try to run as the spark user, Alluxio will not allow reads or writes to the root of the filesystem until you open the permissions to 777.
I would consider creating a directory like 'alluxio:///testSpark/' and then grant the spark user ownership of that directory. Since you're running Alluxio as the root user, you should be able to do this using 'alluxio fs chown/chmod /path/to/dir/'. Then you should direct your writes/reads to the new directory. If you face further issues, please feel free to reopen this issue.
To answer your comment on how to add user 'spark' to group 'root', make sure you have run the usermod command 'sudo usermod -a -G root spark' on the Alluxio Master and then restart the Alluxio Master Process. In HA mode, you need to do this on all machines.
Note: The colorful language, while amusing, really has no place on these type of forums. If you continue, there is a high chance a moderator will ban you from these forums.
		</comment>
		<comment id='3' author='XiaochenCui' date='2020-01-06T02:26:25Z'>
		
@XiaochenCui I think you need to revisit your understanding of the Alluxio Security Model. I would start with this link here: https://docs.alluxio.io/os/user/stable/en/operation/Security.html#client-side-hadoop-impersonation
In your scenario, it looks like the owner/group of the HDFS directory hdfs://cdh1:8020/alluxio/root/ were set to 'root:root'. From there, when you mounted that HDFS to Alluxio, Alluxio permissions ended up syncing with the HDFS directory. Therefore, in the Alluxio FileSystem the owner and group of the directory alluxio:/// is also 'root:root'. This means, if you try to run as the spark user, Alluxio will not allow reads or writes to the root of the filesystem until you open the permissions to 777.
I would consider creating a directory like 'alluxio:///testSpark/' and then grant the spark user ownership of that directory. Since you're running Alluxio as the root user, you should be able to do this using 'alluxio fs chown/chmod /path/to/dir/'. Then you should direct your writes/reads to the new directory. If you face further issues, please feel free to reopen this issue.
To answer your comment on how to add user 'spark' to group 'root', make sure you have run the usermod command 'sudo usermod -a -G root spark' on the Alluxio Master and then restart the Alluxio Master Process. In HA mode, you need to do this on all machines.
Note: The colorful language, while amusing, really has no place on these type of forums. If you continue, there is a high chance a moderator will ban you from these forums.

Thanks a lot
		</comment>
	</comments>
</bug>