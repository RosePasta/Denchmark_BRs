<bug id='1501' author='gabrieldemarmiesse' open_date='2020-03-30T17:46:13Z' closed_time='2020-04-05T02:50:39Z'>
	<summary>TimeStopping callback is untested.</summary>
	<description>
We have no way of knowing if it works or not. Some minimal tests would be greatly appreciated.
See &lt;denchmark-link:https://github.com/tensorflow/addons/issues/964&gt;#964&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='gabrieldemarmiesse' date='2020-03-31T14:38:24Z'>
		Currently all the Callbacks are not covered with tests. And they should be uniform. Any ideas how it should look like?
		</comment>
		<comment id='2' author='gabrieldemarmiesse' date='2020-03-31T14:41:24Z'>
		We should just have a fit() call and then we check that the callback is doing what we expect it to do. For the TimeStopping callback, we can check the running time of the fit call for example.
		</comment>
		<comment id='3' author='gabrieldemarmiesse' date='2020-04-02T08:32:16Z'>
		So here is a concept. It is so small that I put it here:
import sys

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

from tensorflow_addons.callbacks import TimeStopping


X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[0]])

model = Sequential()
model.add(Dense(2))
model.add(Dense(1))
model.compile(loss='mean_squared_error')

def test():
    try:
        time_stopping = TimeStopping(2, verbose=1) # Stop after 2 seconds, verbose on;
        model.fit(X, y, epochs=10000, verbose=0, callbacks=time_stopping)

        time_stopping = TimeStopping(2, verbose=0) # Stop after 2 seconds, verbose off;
        model.fit(X, y, epochs=10000, verbose=0, callbacks=time_stopping)

        time_stopping = TimeStopping(verbose=1) # Let it go till end, verbose on;
        model.fit(X, y, epochs=1000, verbose=0, callbacks=time_stopping)
    except:
        return 1
    return 0

if __name__ == "__main__":
    sys.exit(test())
If you need time checks, please point me to a module to use. However, since the execution time is a non-determinant entity and we do not rely on any external watchdog, the test might become flaky.
		</comment>
		<comment id='4' author='gabrieldemarmiesse' date='2020-04-02T08:43:51Z'>
		Thanks a lot for this proof of concept :)

However, since the execution time is a non-determinant entity and we do not rely on any external watchdog, the test might become flaky.

That's true. Maybe we can hack things. What about keeping your model and adding  layer with dynamic=True to force eager execution and put a time.sleep(1) inside the call? We can then measure the time for let's say 2 epochs and ensure 2&lt;= t &lt;=3. What do you think?
&lt;denchmark-link:https://github.com/shun-lin&gt;@shun-lin&lt;/denchmark-link&gt;
 who may have ideas.
		</comment>
		<comment id='5' author='gabrieldemarmiesse' date='2020-04-02T09:09:01Z'>
		
That's true. Maybe we can hack things. What about keeping your model and adding layer with dynamic=True to force eager execution and put a time.sleep(1) inside the call? We can then measure the time for let's say 2 epochs and ensure 2&lt;= t &lt;=3. What do you think?

Sounds feasible but looks too complicated. ðŸ˜„  What if to stay with a simple timing and see how it goes? Chances are, we are unreasonable pessimistic on non-determinant. ðŸ˜„
		</comment>
		<comment id='6' author='gabrieldemarmiesse' date='2020-04-02T09:15:40Z'>
		I'll try to do a PR based on your code with a wait layer and I'll let you review. If that's too complicated we'll drop the idea.
		</comment>
		<comment id='7' author='gabrieldemarmiesse' date='2020-04-02T09:35:23Z'>
		OK. But please keep in mind that there is a program code flow outside of layers. Also, what if the OS thread scheduler suspends the test's thread? Timing in a multitasking environment is a tricky job...
		</comment>
		<comment id='8' author='gabrieldemarmiesse' date='2020-04-02T09:36:27Z'>
		Thanks for all the pointers! That's definitly tricky.
		</comment>
	</comments>
</bug>