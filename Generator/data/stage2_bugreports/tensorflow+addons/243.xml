<bug id='243' author='seanpmorgan' open_date='2019-05-13T16:23:26Z' closed_time='2019-07-07T04:49:09Z'>
	<summary>Make image transforms compatible with TF Dataset</summary>
	<description>
From &lt;denchmark-link:https://github.com/tensorflow/addons/issues/242&gt;#242&lt;/denchmark-link&gt;
 we found that the tfa.image transforms are not compatible with dataset mapping. This is a very likely usecase for tfa.image so we need to address this. Here is a minimal example showing the differences in tfa.rotate(pi/2) and tf.image.rot90:
&lt;denchmark-link:https://colab.research.google.com/drive/1ZDhnGrorvSf04wzS-0utztZ6Nnzusvl7&gt;https://colab.research.google.com/drive/1ZDhnGrorvSf04wzS-0utztZ6Nnzusvl7&lt;/denchmark-link&gt;

Problems seem to occur because Dataset mapping runs in graph mode and this check fails:
&lt;denchmark-link:https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/transform_ops.py#L323&gt;https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/transform_ops.py#L323&lt;/denchmark-link&gt;

By comparison here is tf.image.rot90:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L514&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L514&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='seanpmorgan' date='2019-05-13T16:30:57Z'>
		Will think about this more tonight
		</comment>
		<comment id='2' author='seanpmorgan' date='2019-05-13T23:54:03Z'>
		According to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27811&gt;tensorflow/tensorflow#27811&lt;/denchmark-link&gt;
, TF2 transforms Data mappings to subgraphs for better performance.
Here is a non-performatic workaround to force Eager Mode and use tfa.image until there is a solution:
image_ds = path_ds.map(lambda path: tf.py_function(func=load_and_preprocess_image,inp=[path],Tout=tf.float32))
I noticed tfa.image.rotate is running on the CPU, so it is running very slowly, is this the expected behaviour?
		</comment>
		<comment id='3' author='seanpmorgan' date='2019-05-14T00:55:15Z'>
		Thanks for the temporary workaround! Yeah gpu kernels are on the way &lt;denchmark-link:https://github.com/tensorflow/addons/issues/118&gt;#118&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='seanpmorgan' date='2019-05-14T05:58:25Z'>
		Two thoughts:

I opened #244 to have a (failing) test case for this issue
The requirement of fixed and static image rank is not only in rotate, but upstream in transform: https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/transform_ops.py#L76  Is there a strong technical reason why this restriction exists?

		</comment>
		<comment id='5' author='seanpmorgan' date='2019-05-14T06:03:48Z'>
		
The rot90() code seems to assume that if no shape information is available, one can assume that the rank is 3.  Do we think that's safe for our transformations as well?

		</comment>
		<comment id='6' author='seanpmorgan' date='2019-05-14T08:30:12Z'>
		

I opened #244 to have a (failing) test case for this issue


Thank you, &lt;denchmark-link:https://github.com/kyleabeauchamp&gt;@kyleabeauchamp&lt;/denchmark-link&gt;
!


The requirement of fixed and static image rank is not only in rotate, but upstream in transform: https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/transform_ops.py#L76  Is there a strong technical reason why this restriction exists?


I think it is because the cpp implementation &lt;denchmark-link:https://github.com/tensorflow/addons/blob/master/tensorflow_addons/custom_ops/image/cc/kernels/image_projective_transform_op.cc#L75&gt;here&lt;/denchmark-link&gt;
 requires a static rank of 4 and each dimension will be fetched out for later computation.


The rot90() code seems to assume that if no shape information is available, one can assume that the rank is 3.  Do we think that's safe for our transformations as well?


Well, I do not think it is very safe though. I'd suppose it is designed for . (Not so sure about this). Hi, &lt;denchmark-link:https://github.com/facaiy&gt;@facaiy&lt;/denchmark-link&gt;
, would you mind taking a look at this?
		</comment>
		<comment id='7' author='seanpmorgan' date='2019-05-16T05:13:19Z'>
		&lt;denchmark-link:https://github.com/WindQAQ&gt;@WindQAQ&lt;/denchmark-link&gt;
 Thanks for ping me, Tzu-Wei.

Well, I do not think it is very safe though. I'd suppose it is designed for tf.dataset.

Yeah, it's not safe, and we can relax the restriction if we document it clearly: data must be 4-D.
&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 Hi, Derek, could you take a look? The rank of tensor seems unknown even in eager mode.
		</comment>
		<comment id='8' author='seanpmorgan' date='2019-05-23T08:56:24Z'>
		&lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;
 Karmel, do you know who could answer those questions about tf.data and tf.image? Thank you.
		</comment>
		<comment id='9' author='seanpmorgan' date='2019-05-23T16:44:37Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 -- can you advise?
		</comment>
		<comment id='10' author='seanpmorgan' date='2019-05-23T19:58:14Z'>
		One option is to fix the addons logic as discussed in this thread. Another option is to replace decode_image with decode_png. The problem arises because decode_image is executed by tf.data in graph-mode and shape inference fails to determine which one of the decode utilities is used (which seems to trip some addons logic).
		</comment>
		<comment id='11' author='seanpmorgan' date='2019-06-03T23:53:21Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 thank you for the answer and apologies for the slow reply back. I confirmed that switching to  does corrrectly infer the shape which is great. One lingering question though:

It's true that the addons logic got tripped up by the None shape coming out of decode_image... but in tf.image.rot90 None shape is handled by defaulting to a 3D shape. Is there a reason this is safe to do? We can copy the same logic but I'm not sure I'm following the rationale.

		</comment>
		<comment id='12' author='seanpmorgan' date='2019-06-04T02:28:35Z'>
		I tried digging through git history to find the person who might have the answer for you and as far as I could tell is should be &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 who introduced that logic in 2016.
		</comment>
		<comment id='13' author='seanpmorgan' date='2019-06-11T16:59:24Z'>
		Hi &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 Do you happen to have any comment on why its safe to default to 3D rotate when shape is ?
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L511&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py#L511&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='seanpmorgan' date='2019-06-11T17:20:00Z'>
		It probably is just so that if you don't know anything about the shape you can still proceed.  None of ndims means the rank is not known. so it's just a fallback.
		</comment>
		<comment id='15' author='seanpmorgan' date='2019-06-11T23:19:09Z'>
		So we should handle unknown rank, because it's valid in graph mode. And it seems that there are at least two solutions:

use dynamic shape if possible;
fallback to 3D data (perhaps unsafe).

		</comment>
	</comments>
</bug>