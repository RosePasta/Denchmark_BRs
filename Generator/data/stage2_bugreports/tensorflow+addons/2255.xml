<bug id='2255' author='fsx950223' open_date='2020-11-26T08:32:25Z' closed_time='2020-12-08T03:21:57Z'>
	<summary>AttributeError: 'TrackableWeightHandler' object has no attribute 'trainable'</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
TensorFlow version and how it was installed (source or binary): 2.3.0
TensorFlow-Addons version and how it was installed (source or binary): 0.11.2
Python version: 3.6.8
Is GPU used? (yes/no): yes

Describe the bug
TrackableWeightHandler doesn't have trainable and assign attributes but also to be appended to weights and trainable_weights. When I use AverageModelCheckpoint, I meet the bug. I'm not sure it's a bug of addons or tensorflow.
TrackableWeightHandler is added in TextVectorization
A clear and concise description of what the bug is.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/root/.vscode-server/extensions/ms-python.python-2020.11.371526539/pythonFiles/lib/python/debugpy/__main__.py", line 45, in &lt;module&gt;
    cli.main()
  File "/root/.vscode-server/extensions/ms-python.python-2020.11.371526539/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py", line 430, in main
    run()
  File "/root/.vscode-server/extensions/ms-python.python-2020.11.371526539/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py", line 267, in run_file
    runpy.run_path(options.target, run_name=compat.force_str("__main__"))
  File "/usr/lib/python3.6/runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "/usr/lib/python3.6/runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/usr/local/srv/automl/efficientdet/nlp.py", line 65, in &lt;module&gt;
    tfa.callbacks.AverageModelCheckpoint(update_weights=True, filepath=os.path.join(MODEL_DIR, 'ckpt_moving_average'))])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py", line 1137, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py", line 412, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py", line 1249, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/callbacks/average_model_checkpoint.py", line 76, in _save_model
    self.model.optimizer.assign_average_vars(self.model.trainable_weights)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/optimizers/average_wrapper.py", line 125, in assign_average_vars
    for var in var_list
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_addons/optimizers/average_wrapper.py", line 126, in &lt;listcomp&gt;
    if var.trainable
AttributeError: 'TrackableWeightHandler' object has no attribute 'trainable'
&lt;/denchmark-code&gt;


&lt;denchmark-link:https://colab.research.google.com/drive/1OM7kAA6aOcNSTTXpd74kUnw-EeeM2uH5?usp=sharing&gt;https://colab.research.google.com/drive/1OM7kAA6aOcNSTTXpd74kUnw-EeeM2uH5?usp=sharing&lt;/denchmark-link&gt;

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Change model.variables to model.trainable_weights could fix it temporarily.
	</description>
	<comments>
		<comment id='1' author='fsx950223' date='2020-11-28T05:24:37Z'>
		Thanks for reporting! Per &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/43834#issuecomment-706607049&gt;tensorflow/tensorflow#43834 (comment)&lt;/denchmark-link&gt;
, this should be our issue, though I think  API should return a list of . The solution that I can come up with is to replace



addons/tensorflow_addons/optimizers/average_wrapper.py


        Lines 106 to 113
      in
      8040bcf






 assign_op = tf.group( 



     [ 



 var.assign(self.get_slot(var, "average"), use_locking=self._use_locking) 



 for var in var_list 



 if var.trainable 



     ] 



 ) 



 return assign_op 





with a try-catch
ops = []

try:
    for var in var_list 
        ops.append(var.assign(self.get_slot(var, "average"), use_locking=self._use_locking))
except:
    logging.warning("some warning about there is no average slot for var.")

return tf.group(ops)
because we can not guarantee variables in var_list have average slot either (in some use cases).
What do you think &lt;denchmark-link:https://github.com/fsx950223&gt;@fsx950223&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='2' author='fsx950223' date='2020-11-29T02:37:14Z'>
		agree
		</comment>
	</comments>
</bug>