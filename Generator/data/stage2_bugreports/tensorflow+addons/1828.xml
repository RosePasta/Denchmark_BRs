<bug id='1828' author='WindQAQ' open_date='2020-05-13T19:54:05Z' closed_time='2020-05-15T00:45:52Z'>
	<summary>Testcase of tfa.image.sharpness is not robust</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18/04
TensorFlow version and how it was installed (source or binary): binary
TensorFlow-Addons version and how it was installed (source or binary): source
Python version: provided docker image
Is GPU used? (yes/no): no


The &lt;denchmark-link:https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/tests/color_ops_test.py#L67-L76&gt;testcase&lt;/denchmark-link&gt;
 of  is not robust, where the absolute tolerance is set to 1 for uint8. If setting it to 0, the testcase fails. The link down below shows the results are very different.
&lt;denchmark-code&gt;#23 168.9 factor = 0.5
#23 168.9
#23 168.9     @pytest.mark.parametrize("factor", [0, 0.25, 0.5, 0.75, 1])
#23 168.9     def test_sharpness_with_PIL(factor):
#23 168.9         np.random.seed(0)
#23 168.9         image = np.random.randint(low=0, high=255, size=(10, 5, 5, 3), dtype=np.uint8)
#23 168.9         sharpened = np.stack(
#23 168.9             [ImageEnhance.Sharpness(Image.fromarray(i)).enhance(factor) for i in image]
#23 168.9         )
#23 168.9         np.testing.assert_allclose(
#23 168.9 &gt;           color_ops.sharpness(tf.constant(image), factor).numpy(), sharpened, atol=0
#23 168.9         )
#23 168.9 E       AssertionError:
#23 168.9 E       Not equal to tolerance rtol=1e-07, atol=0
#23 168.9 E
#23 168.9 E       Mismatched elements: 59 / 750 (7.87%)
#23 168.9 E       Max absolute difference: 255
#23 168.9 E       Max relative difference: 6.53846154
#23 168.9 E        x: array([[[[172,  10, 127],
#23 168.9 E                [140,  47, 170],
#23 168.9 E                [196, 151, 117],...
#23 168.9 E        y: array([[[[172,  10, 127],
#23 168.9 E                [140,  47, 170],
#23 168.9 E                [196, 151, 117],...
&lt;/denchmark-code&gt;

Code to reproduce the issue
&lt;denchmark-link:https://colab.research.google.com/drive/1Lwa_FFhvk_DsUoLzq9DBSWi9ZKWNdQtK?usp=sharing&gt;https://colab.research.google.com/drive/1Lwa_FFhvk_DsUoLzq9DBSWi9ZKWNdQtK?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='WindQAQ' date='2020-05-13T19:55:54Z'>
		&lt;denchmark-link:https://github.com/WindQAQ&gt;@WindQAQ&lt;/denchmark-link&gt;
 all your colab are private 
		</comment>
		<comment id='2' author='WindQAQ' date='2020-05-13T20:03:47Z'>
		
@WindQAQ all your colab are private

&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 Thanks for the reminder! I've changed the permission. Please let me know if they are still private :-)
		</comment>
		<comment id='3' author='WindQAQ' date='2020-05-13T20:09:15Z'>
		It was almost ported from the official code &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/official/vision/image_classification/augment.py#L456-L482&gt;https://github.com/tensorflow/models/blob/master/official/vision/image_classification/augment.py#L456-L482&lt;/denchmark-link&gt;

We have just a different approach to casting in our code.
		</comment>
		<comment id='4' author='WindQAQ' date='2020-05-13T20:20:08Z'>
		Testing against uint8 is super hard as tf.nn.depthwise_conv2d does not support integer computation. For example, 2.99999999 is 3 in floating point, but when casting (floor operation) to uint8, it becomes 2 :-(
My opinion is not to use pillow, which is uint8 anywhere, as ground truth of testcase. However, this function tries to mimic the functionality in pillow...
Also, the testcases in the original repo do not really verify the correctness of sharpness's implementation.
&lt;denchmark-link:https://github.com/tensorflow/models/blob/master/official/vision/image_classification/augment_test.py&gt;https://github.com/tensorflow/models/blob/master/official/vision/image_classification/augment_test.py&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='WindQAQ' date='2020-05-13T20:27:14Z'>
		
Also, the testcases in the original repo do not really verify the correctness of sharpness's implementation.
https://github.com/tensorflow/models/blob/master/official/vision/image_classification/augment_test.py

And is it not under research folder ðŸ˜‰
		</comment>
		<comment id='6' author='WindQAQ' date='2020-05-13T21:48:00Z'>
		/cc &lt;denchmark-link:https://github.com/abhichou4&gt;@abhichou4&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='WindQAQ' date='2020-05-14T17:36:22Z'>
		The implementation might be slightly different. Maybe asking the atol to be lower than 1 is too much when working in uint8? Maybe I'm missing something.
		</comment>
		<comment id='8' author='WindQAQ' date='2020-05-15T00:45:52Z'>
		I assume the implementation should be the same with the one that we test against so the output should totally match. If they are different, then yep, maybe the value of 1 is negligible in for uint8.
		</comment>
	</comments>
</bug>