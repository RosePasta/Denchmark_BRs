<bug id='68' author='janden' open_date='2018-10-29T02:56:43Z' closed_time='2018-10-30T01:31:28Z'>
	<summary>1D classif example now fails</summary>
	<description>
Specifically, we get
&lt;denchmark-code&gt;TEST, average loss = nan, accuracy = 0.100
&lt;/denchmark-code&gt;

which is not very impressive. This used to work before (as of &lt;denchmark-link:https://github.com/kymatio/kymatio/commit/5b41a313e60e6d71c06c0721263a744328f4d693&gt;5b41a31&lt;/denchmark-link&gt;
), giving
&lt;denchmark-code&gt;TEST, average loss = 0.092, accuracy = 0.973
&lt;/denchmark-code&gt;

but no longer...
	</description>
	<comments>
		<comment id='1' author='janden' date='2018-10-29T03:58:10Z'>
		Hmm, so on the latest master, I get:
&lt;denchmark-code&gt;Epoch 45, average loss = 0.022, accuracy = 0.999
Epoch 46, average loss = 0.021, accuracy = 0.999
Epoch 47, average loss = 0.020, accuracy = 0.999
Epoch 48, average loss = 0.020, accuracy = 0.999
Epoch 49, average loss = 0.019, accuracy = 0.999
TEST, average loss = 0.092, accuracy = 0.973

&lt;/denchmark-code&gt;

When does it flip to Nan for you? Already during training or only at test?
		</comment>
		<comment id='2' author='janden' date='2018-10-29T13:28:40Z'>
		Yes the behavior is also not consistent between my laptop and desktop, it's not a very robust bug.. I will investigate further.
It's NaN during training, as well:
&lt;denchmark-code&gt;Epoch 0, average loss = nan, accuracy = 0.100
Epoch 1, average loss = nan, accuracy = 0.100
Epoch 2, average loss = nan, accuracy = 0.100
...
Epoch 47, average loss = nan, accuracy = 0.100
Epoch 48, average loss = nan, accuracy = 0.100
Epoch 49, average loss = nan, accuracy = 0.100
Aggregating individual scattering vectors for test
TEST, average loss = nan, accuracy = 0.100
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='janden' date='2018-10-29T14:01:51Z'>
		It is strange, do you use a GPU or CPU for both?
		</comment>
		<comment id='4' author='janden' date='2018-10-29T14:38:20Z'>
		On the laptop, I use CPU, it fails for both master and the old version (&lt;denchmark-link:https://github.com/kymatio/kymatio/commit/5b41a313e60e6d71c06c0721263a744328f4d693&gt;5b41a31&lt;/denchmark-link&gt;
). For the desktop, it fails for master, but not on the old version (&lt;denchmark-link:https://github.com/kymatio/kymatio/commit/5b41a313e60e6d71c06c0721263a744328f4d693&gt;5b41a31&lt;/denchmark-link&gt;
) when running on the GPU. I'm not sure how to disable GPU from the outside (I tried removing the CUDA libraries from the path, but it still seems to get a hold of them).
At any rate, I'm sure it's something stupid. Will let you know what I find.
		</comment>
		<comment id='5' author='janden' date='2018-10-29T14:40:06Z'>
		Never mind there's a use_cuda flag in the script that I can disable, it looks like. Will try it.
		</comment>
		<comment id='6' author='janden' date='2018-10-29T16:32:54Z'>
		Ok, so the old version (&lt;denchmark-link:https://github.com/kymatio/kymatio/commit/5b41a313e60e6d71c06c0721263a744328f4d693&gt;5b41a31&lt;/denchmark-link&gt;
) fails on the CPU but succeeds on the GPU.
Turns out the issue is zeros. For some reason, the CPU version will clamp certain small values to 0 while the GPU does not, keeping them around machine epsilon. As a result, when taking the log, the coefficients calculated on the CPU yield -inf (interestingly, torch does not warn about this while numpy does). These then get turned into nans farther down the road.
Adding a small 1e-6 term before taking the log seems to do the trick. Will make a PR.
		</comment>
		<comment id='7' author='janden' date='2018-10-30T01:31:28Z'>
		This is solved! Thanks! closing
		</comment>
	</comments>
</bug>