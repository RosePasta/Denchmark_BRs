<bug id='377' author='fritzo' open_date='2017-10-27T15:49:29Z' closed_time='2017-11-04T23:26:50Z'>
	<summary>enum_discrete segfaults on Pytorch 0.2.0 release (ok on master)</summary>
	<description>

No description provided.

	</description>
	<comments>
		<comment id='1' author='fritzo' date='2017-10-27T16:46:06Z'>
		This appears to be caused by a large number surrogate_elbo_particle terms being added together, and has caused a segfault even when enum_discrete=False and num_particles=20 in TraceGraph_ELBO (in the test tests/infer/test_enum.py::test_bern_elbo_gradient).
		</comment>
		<comment id='2' author='fritzo' date='2017-11-03T19:08:22Z'>
		&lt;denchmark-link:https://github.com/martinjankowiak&gt;@martinjankowiak&lt;/denchmark-link&gt;
 observe that in final Beta-Bernoulli example of the &lt;denchmark-link:https://github.com/uber/pyro/blob/dev/tutorial/source/svi_part_i.ipynb&gt;SVI Part I&lt;/denchmark-link&gt;
 tutorial, pyro currenly works with  but segfaults with , yet there was no segfault a couple weeks ago. This might be a good example for git-bisecting.
- svi = SVI(model, guide, optimizer, loss="ELBO", num_particles=1)
+ svi = SVI(model, guide, optimizer, loss="ELBO", num_particles=100)
		</comment>
	</comments>
</bug>