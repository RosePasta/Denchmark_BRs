<bug id='1982' author='sharrison5' open_date='2019-07-27T16:45:20Z' closed_time='2019-08-09T15:38:05Z'>
	<summary>[bug] TraceGraph_ELBO inconsistent in sign of ELBO</summary>
	<description>
&lt;denchmark-h:h3&gt;Issue Description&lt;/denchmark-h&gt;


TraceGraph_ELBO.loss() returns the negative ELBO (as expected).
TraceGraph_ELBO.loss_and_grads() returns the positive ELBO.

This doesn't affect the optimisation as the surrogate loss is based on the negative ELBO, but is confusing when monitoring convergence. May well happen in other ELBO classes, this is just the one that I've been using and hence spotted it in.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

MacOS, Python 3.7.1, PyTorch 1.1.0, Pyro 0.3.4
	</description>
	<comments>
		<comment id='1' author='sharrison5' date='2019-07-30T23:39:46Z'>
		I agree it seems a bit confusing. Not fully knowing the reasons behind the implementation, I would hazard a guess that pyro use a negative ELBO loss for minimization and use with optimizers, but ELBO (normally) is positive which is still helpful and accessible through TraceGraph_ELBO.loss_and_grads()?
		</comment>
		<comment id='2' author='sharrison5' date='2019-07-31T03:22:01Z'>
		This is just a bug, any ELBO implementation should return the "elbo loss" = -elbo from .loss_and_grads(). Anyone have time to submit a quick fix ðŸ˜„?
		</comment>
		<comment id='3' author='sharrison5' date='2019-07-31T03:26:47Z'>
		ðŸ˜‚ - I'm happy to fix it quickly.
		</comment>
	</comments>
</bug>