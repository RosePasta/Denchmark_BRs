<bug id='375' author='neerajprad' open_date='2017-10-27T07:00:30Z' closed_time='2017-10-27T21:14:50Z'>
	<summary>CUDA tests failing due to out of memory</summary>
	<description>
Rectify failing tests on CUDA due to out of memory issues - some distribution tests and map_data tests seem to fail due to OOM issues when run with CUDA
&lt;denchmark-code&gt;____________________________________________________________________ test_cuda[map_data_iter-20] ____________________________________________________________________
[gw36] linux2 -- Python 2.7.14 /home/npradhan/.conda/envs/pyro/bin/python

model = &lt;function map_data_iter_cuda_model at 0x7f6fee117f50&gt;, subsample_size = 20

    @requires_cuda
    @pytest.mark.parametrize('subsample_size', [5, 20])
    @pytest.mark.parametrize('model', [
        iarange_cuda_model,
        irange_cuda_model,
        map_data_vector_cuda_model,
        map_data_iter_cuda_model,
    ], ids=["iarange", "irange", "map_data_vector", "map_data_iter"])
    def test_cuda(model, subsample_size):
&gt;       tr = poutine.trace(model).get_trace(subsample_size)

tests/poutine/test_mapdata.py:303:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
pyro/poutine/trace_poutine.py:163: in get_trace
    self(*args, **kwargs)
pyro/poutine/trace_poutine.py:151: in __call__
    ret = super(TracePoutine, self).__call__(*args, **kwargs)
pyro/poutine/poutine.py:37: in __call__
    return self.fn(*args, **kwargs)
tests/poutine/test_mapdata.py:287: in map_data_iter_cuda_model
    mu = Variable(torch.zeros(20).cuda())
../../../.conda/envs/pyro/lib/python2.7/site-packages/torch/_utils.py:66: in _cuda
    return new_type(self.size()).copy_(self, async)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = &lt;class 'torch.cuda.DoubleTensor'&gt;, args = (torch.Size([20]),), kwargs = {}

    @staticmethod
    def _lazy_new(cls, *args, **kwargs):
        _lazy_init()
        # We need this method only for lazy init, so we can remove it
        del _CudaBase.__new__
&gt;       return super(_CudaBase, cls).__new__(cls, *args, **kwargs)
E       RuntimeError: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/THC/generic/THCStorage.cu:66

../../../.conda/envs/pyro/lib/python2.7/site-packages/torch/cuda/__init__.py:269: RuntimeError
----------------------------------------------------------------------- Captured stderr call ------------------------------------------------------------------------
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1503966894950/work/torch/lib/THC/generic/THCStorage.cu line=66 error=2 : out of memory
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='neerajprad' date='2017-10-27T14:35:07Z'>
		Did you see this failure locally or on travis?  I often see OOM issues locally when running pytest -n 50 or similar huge number or threads; as a quick fix I simply run with fewer threads: pytest -n 8.
		</comment>
		<comment id='2' author='neerajprad' date='2017-10-27T14:46:23Z'>
		One thing we could try is to clear the param store after each test, say in a global tearDown function.
		</comment>
		<comment id='3' author='neerajprad' date='2017-10-27T17:50:43Z'>
		
One thing we could try is to clear the param store after each test, say in a global tearDown function.

Good idea, will try it.
		</comment>
		<comment id='4' author='neerajprad' date='2017-10-27T21:14:50Z'>
		This seems to be fixed on dev, so closing this issue now. Will reopen if I see this again.
		</comment>
	</comments>
</bug>