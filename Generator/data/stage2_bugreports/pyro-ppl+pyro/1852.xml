<bug id='1852' author='sameerkhurana10' open_date='2019-05-06T23:53:29Z' closed_time='2019-06-06T00:08:13Z'>
	<summary>vae comparison example giving different results for Pyro and PyTorch implementations</summary>
	<description>
Hi,
Pyro version: 3.3
PyTorch: 1.1
Running examples/vae/vae_comparison.py
With PyTorch:
&lt;denchmark-code&gt;downloading data
download complete.
downloading data
download complete.
Running PyTorch VAE implementation
====&gt; Epoch: 0 
Training loss: 0.0022
Test set loss: 0.0027
====&gt; Epoch: 1 
Training loss: 0.0021
Test set loss: 0.0024
====&gt; Epoch: 2 
Training loss: 0.0021
Test set loss: 0.0022
====&gt; Epoch: 3 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 4 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 5 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 6 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 7 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 8 
Training loss: 0.0021
Test set loss: 0.0021
====&gt; Epoch: 9 
Training loss: 0.0021
Test set loss: 0.0021
&lt;/denchmark-code&gt;

With Pyro:
&lt;denchmark-code&gt;downloading data
download complete.
downloading data
download complete.
Running Pyro VAE implementation
====&gt; Epoch: 0 
Training loss: 0.0017
Test set loss: 0.0013
====&gt; Epoch: 1 
Training loss: 0.0012
Test set loss: 0.0012
====&gt; Epoch: 2 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 3 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 4 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 5 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 6 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 7 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 8 
Training loss: 0.0011
Test set loss: 0.0011
====&gt; Epoch: 9 
Training loss: 0.0011
Test set loss: 0.0011
&lt;/denchmark-code&gt;

Is this difference expected?
	</description>
	<comments>
		<comment id='1' author='sameerkhurana10' date='2019-05-07T01:10:24Z'>
		&lt;denchmark-link:https://github.com/neerajprad&gt;@neerajprad&lt;/denchmark-link&gt;
 shouldn't it be  here: &lt;denchmark-link:https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae_comparison.py#L106&gt;https://github.com/pyro-ppl/pyro/blob/dev/examples/vae/vae_comparison.py#L106&lt;/denchmark-link&gt;

Changing that line gives the following:
&lt;denchmark-code&gt;downloading data
download complete.
downloading data
download complete.
Running PyTorch VAE implementation
====&gt; Epoch: 0 
Training loss: 0.0016
Test set loss: 0.0012
====&gt; Epoch: 1 
Training loss: 0.0012
Test set loss: 0.0011
====&gt; Epoch: 2 
Training loss: 0.0011
Test set loss: 0.0010
====&gt; Epoch: 3 
Training loss: 0.0011
Test set loss: 0.0010
====&gt; Epoch: 4 
Training loss: 0.0011
Test set loss: 0.0010
====&gt; Epoch: 5 
Training loss: 0.0011
Test set loss: 0.0010
====&gt; Epoch: 6 
Training loss: 0.0011
Test set loss: 0.0010
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='sameerkhurana10' date='2019-05-07T01:23:42Z'>
		Good catch! That is being called from compute_loss_and_gradient in the PyTorch implementation. I was under the impression that its only being used during evaluation. Do you mind submitting your fix in a PR? ðŸ™‚
		</comment>
	</comments>
</bug>