<bug id='161' author='fritzo' open_date='2017-09-27T21:20:25Z' closed_time='2017-10-04T05:45:13Z'>
	<summary>Dirichlet distribution treats shape inconsistently</summary>
	<description>
While the tests for pyro.distributions.dirichlet test with a 1-dimensional tensor alpha, the Dirichlet constructor uses ad hoc logic to ensure there are at least 2 dimensions in the alpha. Moreover the ad hoc 2-dimensional tensor does not work, and is preventing me from using Dirichlet as a prior on component weights in a mixture model.
See &lt;denchmark-link:https://github.com/pyro-ppl/pyro/issues/153&gt;#153&lt;/denchmark-link&gt;
 for more comprehensive solution.
Example excerpt:
# This is inside a model:
ps = pyro.sample('ps', Dirichlet(alpha=Variable(torch.ones(10) / 0.5)))
Error message:

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
 in ()
      1 get_ipython().magic(u'pdb off')
----&gt; 2 inference(data)
/Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in call(self, *args, **kwargs)
51
52     def call(self, *args, **kwargs):
---&gt; 53         return self.step(*args, **kwargs)
54
55     def populate_traces(self, *args, **kwargs):
/Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in step(self, *args, **kwargs)
160
161         if 'loss_and_params' not in kwargs.keys():
--&gt; 162             [loss, all_trainable_params] = self.eval_grad(*args, **kwargs)
163         else:
164             [loss, all_trainable_params] = kwargs['loss_and_params']
/Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in eval_grad(self, *args, **kwargs)
109         """
110
--&gt; 111         [model_traces, guide_traces, log_r_per_sample] = self.populate_traces(*args, **kwargs)
112
113         elbo = 0.0
/Users/fritzobermeyer/github/uber/pyro/pyro/infer/kl_qp.pyc in populate_traces(self, *args, **kwargs)
64             guide_trace = poutine.trace(self.guide)(*args, **kwargs)
65             model_trace = poutine.trace(
---&gt; 66                 poutine.replay(self.model, guide_trace))(*args, **kwargs)
67
68             log_r = model_trace.log_pdf() - guide_trace.log_pdf()
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/init.pyc in _fn(*args, **kwargs)
25     def _fn(*args, **kwargs):
26         p = TracePoutine(fn)
---&gt; 27         return p(*args, **kwargs)
28
29     return _fn
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in call(self, *args, **kwargs)
28
29             # run the original function overloading the fcts
---&gt; 30             base_r_val = self.orig_fct(*args, **kwargs)
31
32             # then return the pyro global fcts to their previous state
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/init.pyc in _fn(*args, **kwargs)
49     def _fn(*args, **kwargs):
50         p = ReplayPoutine(fn, trace, sites=sites)
---&gt; 51         return p(*args, **kwargs)
52
53     return _fn
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in call(self, *args, **kwargs)
28
29             # run the original function overloading the fcts
---&gt; 30             base_r_val = self.orig_fct(*args, **kwargs)
31
32             # then return the pyro global fcts to their previous state
 in model(data)
6     # Global parameters.
7     if use_dirichlet_prior:
----&gt; 8         ps = pyro.sample('ps', Dirichlet(alpha=Variable(torch.ones(K) * 0.5)))
9     else:
10         # FIXME I would put a Dirichlet prior here, but Dirichlet is buggy.
/Users/fritzobermeyer/github/uber/pyro/pyro/init.pyc in sample(name, fn, *args, **kwargs)
105         }
106         # apply the stack and return its return value
--&gt; 107         out_msg = apply_stack(msg)
108         return out_msg["ret"]
109
/Users/fritzobermeyer/github/uber/pyro/pyro/init.pyc in apply_stack(initial_msg, stack)
71     # go until time to stop?
72     for j in range(0, len(stack)):
---&gt; 73         msg = stack[j].up(msg)
74         if msg["stop"]:
75             break
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in up(self, msg)
67             ret = self._pyro_sample(msg, msg["name"],
68                                     msg["fn"],
---&gt; 69                                     *msg["args"], **msg["kwargs"])
70         elif msg["type"] == "observe":
71             ret = self._pyro_observe(msg, msg["name"],
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/replay_poutine.pyc in _pyro_sample(self, msg, name, fn, *args, **kwargs)
67         # case 2: dict, negative: sample from model
68         elif name not in self.sites:
---&gt; 69             return super(ReplayPoutine, self)._pyro_sample(msg, name, fn, *args, **kwargs)
70         else:
71             raise ValueError(
/Users/fritzobermeyer/github/uber/pyro/pyro/poutine/poutine.pyc in _pyro_sample(self, msg, name, fn, *args, **kwargs)
128         if msg["done"]:
129             return msg["ret"]
--&gt; 130         val = fn(*args, **kwargs)
131         msg["done"] = True
132         return val
/Users/fritzobermeyer/github/uber/pyro/pyro/distributions/distribution.pyc in call(self, *args, **kwargs)
16         Samples on call
17         """
---&gt; 18         return self.sample(*args, **kwargs)
19
20     def sample(self, *args, **kwargs):
/Users/fritzobermeyer/github/uber/pyro/pyro/distributions/dirichlet.pyc in sample(self, alpha, *args, **kwargs)
45         # _alpha = Variable(torch.Tensor([[1,2],[3,4]]))
46         x = Variable(torch.Tensor(spr.dirichlet.rvs(
---&gt; 47                      _alpha.data.numpy()))
48                      .type_as(_alpha.data)).squeeze(0)
49         return x
/Users/fritzobermeyer/miniconda2/envs/pyro2/lib/python2.7/site-packages/scipy/stats/_multivariate.pyc in rvs(self, alpha, size, random_state)
1355
1356         """
-&gt; 1357         alpha = _dirichlet_check_parameters(alpha)
1358         random_state = self._get_random_state(random_state)
1359         return random_state.dirichlet(alpha, size=size)
/Users/fritzobermeyer/miniconda2/envs/pyro2/lib/python2.7/site-packages/scipy/stats/_multivariate.pyc in _dirichlet_check_parameters(alpha)
1075     elif alpha.ndim != 1:
1076         raise ValueError("Parameter vector 'a' must be one dimensional, "
-&gt; 1077                        "but a.shape = %s." % (alpha.shape, ))
1078     return alpha
1079
ValueError: Parameter vector 'a' must be one dimensional, but a.shape = (1, 2).


	</description>
	<comments>
		<comment id='1' author='fritzo' date='2017-09-27T21:21:19Z'>
		It's also concerning that we're not testing the codepath
x = Dirichlet(alpha=anything_other_than_None)
Has this codepath ever worked? What is its intended behavior?
		</comment>
		<comment id='2' author='fritzo' date='2017-09-27T22:21:21Z'>
		good call, the scipy Dirichlet only takes 1-d alphas, which mean that the expand in the constructor should be removed. This also means that you can never call batch_log_pdf on it because these samples are one dimensional. thats kind of annoying, we might need to implement batched alphas ourselves. numpy allows you to sample a specific shape, but those are using the same alpha and drawing m x n samples
		</comment>
	</comments>
</bug>