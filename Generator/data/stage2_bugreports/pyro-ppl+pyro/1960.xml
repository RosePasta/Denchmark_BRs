<bug id='1960' author='null-a' open_date='2019-07-16T13:12:39Z' closed_time='2019-07-16T20:14:20Z'>
	<summary>Bug (?) in the shape of samples from auto-guided LKJCorr</summary>
	<description>
&lt;denchmark-h:h3&gt;Issue Description&lt;/denchmark-h&gt;

In the following example, the shape of the value sampled at the LKJCorrCholesky distributed sample statement differs between the model and the auto-generated guide. Is this expected?
import torch
import pyro
import pyro.distributions as dist
from pyro.contrib.autoguide import AutoDiagonalNormal

d = dist.LKJCorrCholesky(2, torch.tensor(1.))

def model():
    return {'x': pyro.sample('x', d)}

guide = AutoDiagonalNormal(model)

print(model()['x'].shape) # == [2,2]
print(guide()['x'].shape) # == [1,2,2]
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

macos, python 3.7.3, pyro 0.3.3+bf2f9542

I dug into this a little while trying to understand what was happening. If this is a bug, it may be that the problem stems from the shape of the value returned by _unpack_latent:
import torch
import pyro
import pyro.distributions as dist
from torch.distributions import biject_to
from pyro.contrib.autoguide import AutoDiagonalNormal

d = dist.LKJCorrCholesky(2, torch.tensor(1.))
support = d.support

def model():
    return {'x': pyro.sample('x', d)}

guide = AutoDiagonalNormal(model)

latent = guide.sample_latent()
unconstrained_value = [val for site, val in guide._unpack_latent(latent)
                       if site['name'] == 'x'][0]
# The shape of the unconstrained value is [1,1]
print(unconstrained_value.shape) # == [1,1]
# Which gives a [1,2,2] tensor once transformed:
print(biject_to(support)(unconstrained_value).shape) # == [1,2,2]

# Reshaping the unconstrained value from [1,1] to [1] gives the result
# of the transform the expected shape.
print(biject_to(support)(unconstrained_value.reshape(-1)).shape) # == [2,2]

	</description>
	<comments>
		<comment id='1' author='null-a' date='2019-07-16T15:23:57Z'>
		Yes, I think it is a bug at &lt;denchmark-link:https://github.com/pyro-ppl/pyro/blob/dev/pyro/contrib/autoguide/__init__.py#L409&gt;this line&lt;/denchmark-link&gt;
. Probably we should replace it by
&lt;denchmark-code&gt;unconstrained_shape = broadcast_shape(unconstrained_shape, batch_shape + unconstrained_shape)
&lt;/denchmark-code&gt;

The reason is for LKJ transform, unconstrained value is a vector, while constrained value is a matrix.
		</comment>
		<comment id='2' author='null-a' date='2019-07-16T16:10:44Z'>
		&lt;denchmark-link:https://github.com/fehiepsi&gt;@fehiepsi&lt;/denchmark-link&gt;
 good sleuthing! I think we'll need to account for overlapping  and , thus I suspect  won't work. One fix that should work is
  def _unpack_latent(self, latent):
      ...
+     constrained_shape = site["value"].shape
      unconstrained_shape = self._unconstrained_shapes[name]
+     event_dim = site["fn"].event_dim + len(unconstrained_shape) - len(constrained_shape)
      unconstrained_shape = broadcast_shape(unconstrained_shape,
-                                           batch_shape + (1,) * site["fn"].event_dim)
+                                           batch_shape + (1,) * event_dim)
		</comment>
		<comment id='3' author='null-a' date='2019-07-16T16:13:22Z'>
		&lt;denchmark-link:https://github.com/fehiepsi&gt;@fehiepsi&lt;/denchmark-link&gt;
 do you have time to try one of the fixes?
		</comment>
		<comment id='4' author='null-a' date='2019-07-16T17:51:46Z'>
		Yup, I’ll try to fix shortly.
		</comment>
	</comments>
</bug>