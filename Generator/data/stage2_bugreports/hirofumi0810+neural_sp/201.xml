<bug id='201' author='Jungwon-Chang' open_date='2020-12-09T06:14:53Z' closed_time='2020-12-19T18:45:37Z'>
	<summary>Error while training models</summary>
	<description>
Hello, I'm trying to train MoCha with TED-LIUM 2(conf/asr/mocha/lstm_mocha.yaml).
However, there seems to be a problem, since I get an error which states,
Traceback (most recent call last):
  File "/mnt/data1/jungwonchang/projects/neural_sp/examples/tedlium/s5_r2/../../../neural_sp/bin/asr/train.py", line 516, in &lt;module&gt;
    save_path = pr.runcall(main)
  File "/home/jungwonchang/projects1/neural_sp/tools/miniconda/lib/python3.7/cProfile.py", line 121, in runcall
    return func(*args, **kw)
  File "/mnt/data1/jungwonchang/projects/neural_sp/examples/tedlium/s5_r2/../../../neural_sp/bin/asr/train.py", line 355, in main
    loss, observation = model(batch_dev, task=task, is_eval=True)
  File "/home/jungwonchang/projects1/neural_sp/tools/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jungwonchang/projects1/neural_sp/tools/miniconda/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 153, in forward
    return self.module(*inputs[0], **kwargs[0])
  File "/home/jungwonchang/projects1/neural_sp/tools/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/data1/jungwonchang/projects/neural_sp/neural_sp/models/seq2seq/speech2text.py", line 251, in forward
    loss, observation = self._forward(batch, task)
  File "/mnt/data1/jungwonchang/projects/neural_sp/neural_sp/models/seq2seq/speech2text.py", line 285, in _forward
    batch['trigger_points'])
  File "/home/jungwonchang/projects1/neural_sp/tools/miniconda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/mnt/data1/jungwonchang/projects/neural_sp/neural_sp/models/seq2seq/decoders/las.py", line 461, in forward
    ctc_trigger_points=ctc_trigger_points, forced_trigger_points=trigger_points)
  File "/mnt/data1/jungwonchang/projects/neural_sp/neural_sp/models/seq2seq/decoders/las.py", line 721, in forward_att
    loss, ppl = cross_entropy_lsm(logits, ys_out, self.lsm_prob, self.pad, self.training)
  File "/mnt/data1/jungwonchang/projects/neural_sp/neural_sp/models/criterion.py", line 76, in cross_entropy_lsm
    loss *= (ys != ignore_index).sum() / bs
RuntimeError: Integer division of tensors using div or / is no longer supported, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.
  7%|â–‹         | 18000/263002 [01:49&lt;24:52, 164.18it/s]
my environment settings are as followed
&lt;denchmark-code&gt;CUDA=10.2
pytorch=1.6.0
&lt;/denchmark-code&gt;

If there are specific versions for CUDA and pytorch that you suggest, please let me know.
	</description>
	<comments>
		<comment id='1' author='Jungwon-Chang' date='2020-12-09T06:17:12Z'>
		Also, is there a method to online decode .wav files or features via trained models(MoCha, MMA)?
		</comment>
		<comment id='2' author='Jungwon-Chang' date='2020-12-18T09:43:13Z'>
		&lt;denchmark-link:https://github.com/Jungwon-Chang&gt;@Jungwon-Chang&lt;/denchmark-link&gt;
 Thanks, I'll fix it today.
Regarding streaming recognition from mic. input and wav files, I'll support them by next month. Stay tune!
		</comment>
	</comments>
</bug>