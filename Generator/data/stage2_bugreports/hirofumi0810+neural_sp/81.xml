<bug id='81' author='Nakachi-S' open_date='2020-06-30T01:41:42Z' closed_time='2020-07-03T14:49:48Z'>
	<summary>How can I use external LM and fusion LM?</summary>
	<description>
Using the script here as an example, I ask the question.
&lt;denchmark-link:https://github.com/hirofumi0810/neural_sp/blob/master/examples/csj/s5/run.sh&gt;https://github.com/hirofumi0810/neural_sp/blob/master/examples/csj/s5/run.sh&lt;/denchmark-link&gt;

I think, If you run that script as is , you're not using the LM you learned in stage 3, are you?
So I stopped learning at stage 3 and started relearning at stage 4, specifying the language model created in stage 3.
Add the following options as arguments to train.py in run.sh.
&lt;denchmark-code&gt;external_lm=${model}/lm/train_nodev_all_vocaball_wpbpe10000/lstm1024H0P4L_emb1024_adam_lr0.001_bs64_bptt200_tie_residual_glu_dropI0.2H0.5_ls0.1_3/model.epoch-13

CUDA_VISIBLE_DEVICES=${gpu} ${NEURALSP_ROOT}/neural_sp/bin/asr/train.py \
        --corpus csj \
        --config ${conf} \
        --config2 ${conf2} \
        --n_gpus ${n_gpus} \
        --cudnn_benchmark ${benchmark} \
        --train_set ${data}/dataset/${train_set}_${unit}${wp_type}${vocab}.tsv \
        --dev_set ${data}/dataset/${dev_set}_${unit}${wp_type}${vocab}.tsv \
        --eval_sets ${asr_test_sets} \
        --unit ${unit} \
        --dict ${dict} \
        --wp_model ${wp_model}.model \
        --model_save_dir ${model}/asr \
        --asr_init ${asr_init} \
        --external_lm ${external_lm} \
        --lm_fusion 'cold' \
        --stdout ${stdout} \
        --resume ${resume} || exit 1;
&lt;/denchmark-code&gt;

Is this the right approach?
	</description>
	<comments>
		<comment id='1' author='Nakachi-S' date='2020-06-30T16:44:29Z'>
		&lt;denchmark-link:https://github.com/Nakachi-S&gt;@Nakachi-S&lt;/denchmark-link&gt;
 Yes. If you want to use cold/deep fusions, you have to stop at stage-3 once.
This is because the LM directory name is defined in python scripts.
		</comment>
		<comment id='2' author='Nakachi-S' date='2020-07-01T04:50:26Z'>
		&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
 Thank you for reply!
I resumed ASR training as you suggest, specifying the language model from stage 4.
(The added options, which are Lm_fusion and external_lm, are described above comment .)
Learning the first epoch works well.
But then, the following error occurs during the evaluation.
&lt;denchmark-code&gt;100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 370180/370189 [3:41:03&lt;00:01,  5.61it/s]Traceback (most recent call last):
  File "/home/jupyter-nakachi-s/neural_sp/examples/csj/s5/../../../neural_sp/bin/asr/train.py", line 529, in &lt;module&gt;
    save_path = pr.runcall(main)
  File "/opt/tljh/user/envs/ncr_env/lib/python3.7/cProfile.py", line 121, in runcall
    return func(*args, **kw)
  File "/home/jupyter-nakachi-s/neural_sp/examples/csj/s5/../../../neural_sp/bin/asr/train.py", line 424, in main
    optimizer.n_epochs + 1, logger)
  File "/home/jupyter-nakachi-s/neural_sp/examples/csj/s5/../../../neural_sp/bin/asr/train.py", line 481, in evaluate
    metric, cer = eval_wordpiece(models, dataset, recog_params, epoch=epoch)
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/evaluators/wordpiece.py", line 82, in eval_wordpiece
    ensemble_models=models[1:] if len(models) &gt; 1 else [])
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/seq2seq/speech2text.py", line 707, in decode
    exclude_eos, refs_id, utt_ids, speakers)
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/seq2seq/decoders/las.py", line 911, in greedy
    lmout, lmstate = self.lm.decode(self.lm(y), lmstate)
  File "/home/jupyter-nakachi-s/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/lm/lm_base.py", line 62, in forward
    loss, state, observation = self._forward(ys, state)
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/lm/lm_base.py", line 66, in _forward
    ys = [np2tensor(y, self.device_id) for y in ys]  # &lt;eos&gt; is included
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/lm/lm_base.py", line 66, in &lt;listcomp&gt;
    ys = [np2tensor(y, self.device_id) for y in ys]  # &lt;eos&gt; is included
  File "/home/jupyter-nakachi-s/neural_sp/neural_sp/models/torch_utils.py", line 49, in np2tensor
    tensor = torch.from_numpy(array)
TypeError: expected np.ndarray (got Tensor)
&lt;/denchmark-code&gt;

Have ever seen like this error?
		</comment>
		<comment id='3' author='Nakachi-S' date='2020-07-02T00:43:21Z'>
		&lt;denchmark-link:https://github.com/Nakachi-S&gt;@Nakachi-S&lt;/denchmark-link&gt;
 Thank you for your report. I fixed this in &lt;denchmark-link:https://github.com/hirofumi0810/neural_sp/pull/87&gt;#87&lt;/denchmark-link&gt;
.
Please try the latest code.
		</comment>
		<comment id='4' author='Nakachi-S' date='2020-07-03T14:49:48Z'>
		It works!!!
Thank you your help!
		</comment>
	</comments>
</bug>