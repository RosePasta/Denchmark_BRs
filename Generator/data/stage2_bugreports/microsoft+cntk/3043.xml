<bug id='3043' author='alexionby' open_date='2018-03-17T23:13:57Z' closed_time='2018-04-21T01:01:17Z'>
	<summary>RuntimeError: ONNX (Upsample) is not supported in CNTK</summary>
	<description>
I tried to run PyTorch U-net model in CNTK through ONNX, but got this message.
And i got the same message with TransposedConv.
How can i avoid this?
&lt;denchmark-code&gt;
Traceback (most recent call last):
  File "onnx_test.py", line 2, in &lt;module&gt;
    z = C.Function.load("our_unet.onnx", device=C.device.cpu(), format=C.ModelFormat.ONNX)
  File "/home/alex/anaconda3/lib/python3.6/site-packages/cntk/internal/swig_helper.py", line 69, in wrapper
    result = f(*args, **kwds)
  File "/home/alex/anaconda3/lib/python3.6/site-packages/cntk/ops/functions.py", line 1608, in load
    return cntk_py.Function.load(str(model), device, format.value)
RuntimeError: ONNX (Upsample) is not supported in CNTK

[CALL STACK]
[0x7fc854975ef9]                                                       + 0x8aeef9
[0x7fc854bfc05d]    CNTK::ONNXToCNTKHelper::  CreateFunction  (ONNXIR::Node const*,  std::vector&lt;CNTK::Variable,std::allocator&lt;CNTK::Variable&gt;&gt; const&amp;) + 0x874d
[0x7fc854bfd48e]    CNTK::ONNXToCNTKHelper::  CreateCNTKNode  (ONNXIR::Node const*,  std::vector&lt;CNTK::Variable,std::allocator&lt;CNTK::Variable&gt;&gt; const&amp;,  CNTK::DeviceDescriptor const&amp;) + 0x1ce
[0x7fc854bfda64]    CNTK::ONNXToCNTKHelper::  FromONNXNode  (ONNXIR::Node const*,  std::unordered_map&lt;ONNXIR::Node const*,std::vector&lt;std::shared_ptr&lt;CNTK::Function&gt;,std::allocator&lt;std::shared_ptr&lt;CNTK::Function&gt;&gt;&gt;,std::hash&lt;ONNXIR::Node const*&gt;,std::equal_to&lt;ONNXIR::Node const*&gt;,std::allocator&lt;std::pair&lt;ONNXIR::Node const* const,std::vector&lt;std::shared_ptr&lt;CNTK::Function&gt;,std::allocator&lt;std::shared_ptr&lt;CNTK::Function&gt;&gt;&gt;&gt;&gt;&gt;&amp;,  std::unordered_map&lt;std::__cxx11::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;,CNTK::Variable,std::hash&lt;std::__cxx11::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;&gt;,std::equal_to&lt;std::__cxx11::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt;&gt;,std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char,std::char_traits&lt;char&gt;,std::allocator&lt;char&gt;&gt; const,CNTK::Variable&gt;&gt;&gt;&amp;,  ONNXIR::Graph const*,  CNTK::DeviceDescriptor const&amp;) + 0x3a4
[0x7fc854bfde4e]    CNTK::ONNXToCNTK::  CreateGraph  (ONNXIR::Graph*,  CNTK::DeviceDescriptor const&amp;) + 0x17e
[0x7fc854c02a89]    CNTK::ONNXFormat::  Load  (std::__cxx11::basic_string&lt;wchar_t,std::char_traits&lt;wchar_t&gt;,std::allocator&lt;wchar_t&gt;&gt; const&amp;,  CNTK::DeviceDescriptor const&amp;) + 0x89
[0x7fc85497ad25]    CNTK::Function::  Load  (std::__cxx11::basic_string&lt;wchar_t,std::char_traits&lt;wchar_t&gt;,std::allocator&lt;wchar_t&gt;&gt; const&amp;,  CNTK::DeviceDescriptor const&amp;,  CNTK::ModelFormat) + 0x65
[0x7fc8557140a6]                                                       + 0x1bd0a6
[0x5636d1f512a1]    _PyCFunction_FastCallDict                          + 0x91
[0x5636d1fe3ebc]                                                       + 0x19eebc
[0x5636d200562a]    _PyEval_EvalFrameDefault                           + 0x30a
[0x5636d1fde8d9]    PyEval_EvalCodeEx                                  + 0x329
[0x5636d1fdf806]                                                       + 0x19a806
[0x5636d1f5116e]    PyObject_Call                                      + 0x3e
[0x5636d2006d28]    _PyEval_EvalFrameDefault                           + 0x1a08
[0x5636d1fdd0b6]                                                       + 0x1980b6
[0x5636d1fdddc1]                                                       + 0x198dc1
[0x5636d1fe3f95]                                                       + 0x19ef95
[0x5636d20063e7]    _PyEval_EvalFrameDefault                           + 0x10c7
[0x5636d1fde8d9]    PyEval_EvalCodeEx                                  + 0x329
[0x5636d1fdf67c]    PyEval_EvalCode                                    + 0x1c
[0x5636d2059ce4]                                                       + 0x214ce4
[0x5636d205a0e1]    PyRun_FileExFlags                                  + 0xa1
[0x5636d205a2e4]    PyRun_SimpleFileExFlags                            + 0x1c4
[0x5636d205ddaf]    Py_Main                                            + 0x5ff
[0x5636d1f248be]    main                                               + 0xee
[0x7fc85b53f830]    __libc_start_main                                  + 0xf0
[0x5636d200c0da]                                                       + 0x1c70da
&lt;/denchmark-code&gt;

Transposed one:
&lt;denchmark-code&gt;Inside File: Source/CNTKv2LibraryDll/proto/onnx/ONNXToCNTK.cpp  Line: 2667  Function: CreateCNTKConvTransposeNode  -&gt; Feature Not Implemented.
Traceback (most recent call last):
  File "onnx_test.py", line 2, in &lt;module&gt;
    z = C.Function.load("our_unet.onnx", device=C.device.cpu(), format=C.ModelFormat.ONNX)
  File "/home/alex/anaconda3/lib/python3.6/site-packages/cntk/internal/swig_helper.py", line 69, in wrapper
    result = f(*args, **kwds)
  File "/home/alex/anaconda3/lib/python3.6/site-packages/cntk/ops/functions.py", line 1608, in load
    return cntk_py.Function.load(str(model), device, format.value)
RuntimeError: Inside File: Source/CNTKv2LibraryDll/proto/onnx/ONNXToCNTK.cpp  Line: 2667  Function: CreateCNTKConvTransposeNode  -&gt; Feature Not Implemented.


&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='alexionby' date='2018-03-23T12:06:56Z'>
		I have the same problem:
PyTorch has next parameters for ConvTranspose layer:
torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)
CNTK code of this method ONNXToCNTKHelper::CreateCNTKConvTransposeNode expects the following parameter (else it will throw NOT_IMPLEMENTED):
if (HasNamedAttribute(node, "output_shape"))
Which parameters we have to setup for torch.nn.ConvTranspose2d to get the output_shape during conversion to ONNX?
		</comment>
		<comment id='2' author='alexionby' date='2018-03-28T01:25:41Z'>
		Is this in CNTK 2.5? There are multiple ONNX related convolution fixes in the latest release.
		</comment>
		<comment id='3' author='alexionby' date='2018-03-28T06:16:56Z'>
		&lt;denchmark-link:https://github.com/KeDengMS&gt;@KeDengMS&lt;/denchmark-link&gt;
 , yes it's in CNTK 2.5
		</comment>
		<comment id='4' author='alexionby' date='2018-04-11T05:21:33Z'>
		&lt;denchmark-link:https://github.com/alexionby&gt;@alexionby&lt;/denchmark-link&gt;
 Can you share the exact Pytorch model that you are trying to load in CNTK.
		</comment>
		<comment id='5' author='alexionby' date='2018-04-12T08:03:56Z'>
		The final model:
&lt;denchmark-code&gt;UNet(
  (down_path): ModuleList(
    (0): UNetConvBlock(
      (block): Sequential(
        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
    )
    (1): UNetConvBlock(
      (block): Sequential(
        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
    )
    (2): UNetConvBlock(
      (block): Sequential(
        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
    )
    (3): UNetConvBlock(
      (block): Sequential(
        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
    )
    (4): UNetConvBlock(
      (block): Sequential(
        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))
        (3): ReLU()
      )
    )
  )
  (up_path): ModuleList(
    (0): UNetUpBlock(
      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
      (conv_block): UNetConvBlock(
        (block): Sequential(
          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
          (3): ReLU()
        )
      )
    )
    (1): UNetUpBlock(
      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
      (conv_block): UNetConvBlock(
        (block): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
          (3): ReLU()
        )
      )
    )
    (2): UNetUpBlock(
      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
      (conv_block): UNetConvBlock(
        (block): Sequential(
          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
          (3): ReLU()
        )
      )
 
   )
    (3): UNetUpBlock(
      (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (conv_block): UNetConvBlock(
        (block): Sequential(
          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
          (3): ReLU()
        )
      )
    )
  )
  (last): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
)
&lt;/denchmark-code&gt;

And code for this model:
&lt;denchmark-code&gt;class UNet(nn.Module):
    def __init__(self, in_channels=3, n_classes=1, depth=5, wf=5, padding=False,
                 batch_norm=True, up_mode='upconv'):
        """
        Implementation of
        U-Net: Convolutional Networks for Biomedical Image Segmentation
        (Ronneberger et al., 2015)
        https://arxiv.org/abs/1505.04597
        Using the default arguments will yield the exact version used
        in the original paper
        Args:
            in_channels (int): number of input channels
            n_classes (int): number of output channels
            depth (int): depth of the network
            wf (int): number of filters in the first layer is 2**wf
            padding (bool): if True, apply padding such that the input shape
                            is the same as the output.
                            This may introduce artifacts
            batch_norm (bool): Use BatchNorm after layers with an
                               activation function
            up_mode (str): one of 'upconv' or 'upsample'.
                           'upconv' will use transposed convolutions for
                           learned upsampling.
                           'upsample' will use bilinear upsampling.
        """
        super(UNet, self).__init__()
        assert up_mode in ('upconv', 'upsample','repeat')
        self.padding = padding
        self.depth = depth
        prev_channels = in_channels
        self.down_path = nn.ModuleList()
        for i in range(depth):
            self.down_path.append(UNetConvBlock(prev_channels, 2**(wf+i),
                                                padding, batch_norm))
            prev_channels = 2**(wf+i)

        self.up_path = nn.ModuleList()
        for i in reversed(range(depth - 1)):
            self.up_path.append(UNetUpBlock(prev_channels, 2**(wf+i), up_mode,
                                            padding, batch_norm))
            prev_channels = 2**(wf+i)

        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)

    def forward(self, x):
        blocks = []
        for i, down in enumerate(self.down_path):
            x = down(x)
            if i != len(self.down_path)-1:
                blocks.append(x)
                x = F.avg_pool2d(x, 2)

        for i, up in enumerate(self.up_path):
            x = up(x, blocks[-i-1])

        return self.last(x)


class UNetConvBlock(nn.Module):
    def __init__(self, in_size, out_size, padding, batch_norm):
        super(UNetConvBlock, self).__init__()
        block = []

        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,
                               padding=int(padding)))
        block.append(nn.ReLU())
        if batch_norm:
            block.append(nn.BatchNorm2d(out_size))

        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,
                               padding=int(padding)))
        block.append(nn.ReLU())
        if batch_norm:
            block.append(nn.BatchNorm2d(out_size))

        self.block = nn.Sequential(*block)

    def forward(self, x):
        out = self.block(x)
        return out


class UNetUpBlock(nn.Module):
    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):
        super(UNetUpBlock, self).__init__()
        if up_mode == 'upconv':
            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,
                                         stride=2)
        elif up_mode == 'upsample':
            self.up = nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2),
                                    nn.Conv2d(in_size, out_size, kernel_size=1))

        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)

    def center_crop(self, layer, target_size):
        _, _, layer_height, layer_width = layer.size()
        diff_y = (layer_height - target_size[0]) // 2
        diff_x = (layer_width - target_size[1]) // 2
        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]

    def forward(self, x, bridge):
        up = self.up(x)
        crop1 = self.center_crop(bridge, up.shape[2:])
        out = torch.cat([up, crop1], 1)
        out = self.conv_block(out)

        return out
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='alexionby' date='2018-04-21T01:01:17Z'>
		&lt;denchmark-link:https://github.com/alexionby&gt;@alexionby&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/IvanKosik&gt;@IvanKosik&lt;/denchmark-link&gt;
 - I think the root cause of the issue is the same. ONNX spec (link below) for ConvTranspose op lists output_shape as a required attribute.
&lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose&gt;https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose&lt;/denchmark-link&gt;

But looks like this attribute is not being exported in your models. This may be an issue with Pytorch exporter. I can confirm this hypothesis if you share your model.
But the error message at CNTK end should be improved.
		</comment>
		<comment id='7' author='alexionby' date='2018-04-24T21:23:51Z'>
		&lt;denchmark-link:https://github.com/alexionby&gt;@alexionby&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/IvanKosik&gt;@IvanKosik&lt;/denchmark-link&gt;
 - I don't have your model, but if the issue is indeed the missing 'output_shape' attribute in ConvTranspose, could one of you please open an issue with Pytorch.
		</comment>
		<comment id='8' author='alexionby' date='2018-04-25T08:10:35Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 , sory for late response. I found the model. I am not sure whether it's correct, cause currently i can't reproduce it.
&lt;denchmark-link:https://cloud.mail.ru/public/158i/JKrBbrp4L&gt;model_1&lt;/denchmark-link&gt;

&lt;denchmark-link:https://cloud.mail.ru/public/D9nL/kEDtuL5Go&gt;model_2&lt;/denchmark-link&gt;

&lt;denchmark-link:https://cloud.mail.ru/public/FqW9/DeQTv2mrH&gt;model_3&lt;/denchmark-link&gt;

And yes, i can open an issue with Pytorch, but it will take some time cause currently I don't work with it.
		</comment>
		<comment id='9' author='alexionby' date='2018-04-25T16:42:12Z'>
		&lt;denchmark-link:https://github.com/alexionby&gt;@alexionby&lt;/denchmark-link&gt;
 Did you update your Pytorch version by any chance. That could be why you can't repro this because they fixed it recently.
		</comment>
		<comment id='10' author='alexionby' date='2018-07-12T14:17:57Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 I am getting a similar error with the latest pytorch (0.4.0).
From what I see in &lt;denchmark-link:https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose&gt;https://github.com/onnx/onnx/blob/master/docs/Operators.md#ConvTranspose&lt;/denchmark-link&gt;
 ,  is not mandatory and can be optional, which is not considered in CNTK currently. Do you know if this is this something that will be supported soon?
		</comment>
		<comment id='11' author='alexionby' date='2018-07-12T16:42:06Z'>
		&lt;denchmark-link:https://github.com/cbecker&gt;@cbecker&lt;/denchmark-link&gt;
 Yes, it is now an optional attribute. We are working to update the CNTK importer. This will be supported by the next release (sooner in master).
		</comment>
		<comment id='12' author='alexionby' date='2018-07-14T10:35:50Z'>
		Thanks. I am new to CNTK and I was wondering whether this would require changing other parts of the code or the function in CNTK that converts this operator from ONNX. If it's the latter I could have a look myself, can you give me more details on what needs to be done?
		</comment>
		<comment id='13' author='alexionby' date='2018-07-16T16:21:48Z'>
		I do not think that you will have to change much in your code when we have support for upsample. Unless, there are any complications (don't see any as of now), it should just export to ONNX seamlessly.
		</comment>
		<comment id='14' author='alexionby' date='2018-07-30T13:56:26Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 is this a core current limitation of CNTK, or an issue with the ONNX importer?
		</comment>
		<comment id='15' author='alexionby' date='2018-07-31T04:37:13Z'>
		&lt;denchmark-link:https://github.com/cbecker&gt;@cbecker&lt;/denchmark-link&gt;
 Are you asking about the output_shape attribute issue? If yes, then this is not a core limitation in CNTK. ONNX spec has changed and we have are in the process of updating our implementation to reflect the spec changes. We are hoping to get this in soon.
Regarding the upsample op - it is not supported in CNTK yet, but it is on the cards, but I don't have an ETA.
		</comment>
		<comment id='16' author='alexionby' date='2018-08-01T13:14:08Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 Isn't it implemented here &lt;denchmark-link:https://github.com/Microsoft/CNTK/blob/9ce967aa4614f2f870b5ab7a7e050f8c319c9d40/Source/CNTKv2LibraryDll/proto/onnx/ONNXToCNTK.cpp#L3002&gt;https://github.com/Microsoft/CNTK/blob/9ce967aa4614f2f870b5ab7a7e050f8c319c9d40/Source/CNTKv2LibraryDll/proto/onnx/ONNXToCNTK.cpp#L3002&lt;/denchmark-link&gt;
 ?
According to that, the issue is w.r.t. the ONNX parameters, or am I missing something?
		</comment>
		<comment id='17' author='alexionby' date='2018-08-02T11:16:58Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 I think I've fixed this, look at &lt;denchmark-link:https://github.com/microsoft/CNTK/pull/3335&gt;#3335&lt;/denchmark-link&gt;

The issue was not CNTK itself but its ONNX importing functionality.
		</comment>
		<comment id='18' author='alexionby' date='2018-08-20T09:45:21Z'>
		&lt;denchmark-link:https://github.com/spandantiwari&gt;@spandantiwari&lt;/denchmark-link&gt;
 Is there any interest in this issue? I created a fix in a PR 18 days ago.
		</comment>
		<comment id='19' author='alexionby' date='2018-08-21T17:40:57Z'>
		&lt;denchmark-link:https://github.com/cbecker&gt;@cbecker&lt;/denchmark-link&gt;
 - Thanks for creating the PR. I have replied on the PR thread. Please take a look. Your help is much appreciated.
		</comment>
	</comments>
</bug>