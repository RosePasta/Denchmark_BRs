<bug id='1838' author='kokostek' open_date='2017-05-02T09:37:17Z' closed_time='2018-03-21T20:52:35Z'>
	<summary>evaluation memory usage</summary>
	<description>
Hi!
I've encountered issue with (possibly) leaky memory while trying to evaluate large dataset with CNTK model. Here is my script which explains the situation:
import cntk as C
from cntk import relu
from cntk.layers import Convolution, MaxPooling, Dense
from cntk.initializer import glorot_uniform

import numpy as np


def memory():
    # taken from here: http://stackoverflow.com/questions/938733/total-memory-used-by-python-process
    import os
    from wmi import WMI
    w = WMI('.')
    result = w.query(
        "SELECT WorkingSet FROM Win32_PerfRawData_PerfProc_Process WHERE IDProcess=%d" % os.getpid())
    return int(result[0].WorkingSet)


def create_basic_model(input_var, out_dims):
    # just some baseline classification model
    # with convolutional layers

    # 1x64x64 -&gt; 32x32x32
    net = Convolution((5, 5), 32, init=glorot_uniform(), activation=relu, pad=True)(input_var)
    net = MaxPooling((3, 3), strides=(2, 2), pad=True)(net)

    # 32x32x32 -&gt; 32x16x16
    net = Convolution((5, 5), 32, init=glorot_uniform(), activation=relu, pad=True)(net)
    net = MaxPooling((3, 3), strides=(2, 2), pad=True)(net)

    # 32x16x16 -&gt; 64x8x8
    net = Convolution((5, 5), 64, init=glorot_uniform(), activation=relu, pad=True)(net)
    net = MaxPooling((3, 3), strides=(2, 2), pad=True)(net)

    # 64x8x8 -&gt; 64 -&gt; 3
    net = Dense(64, init=glorot_uniform())(net)
    net = Dense(out_dims, init=glorot_uniform(), activation=None)(net)

    return net


# input and output shapes
image_height = 64
image_width = 64
num_channels = 1
num_classes = 3

input_var = C.input((num_channels, image_height, image_width))
label_var = C.input((num_classes))

model = create_basic_model(input_var, num_classes)

# training ommited...

mem_x = []
mem_y = []

np.random.seed(42)  # just in case

# try different number of samples:
for n_test in [1, 2, 4, 8, 16, 32, 64, 128, 256]:

    # generate and evaluate some random data:
    X_test = np.random.randn(n_test * num_channels * image_height * image_width).reshape(
        (n_test, num_channels, image_height, image_width)).astype('float32')
    Y_pred = model.eval(X_test)

    # how much memory we used:
    used_mb = memory() / 1024 / 1024

    # record history for polyfit:
    mem_x += [n_test]
    mem_y += [used_mb]

    print('n_test: {:5}, memory usage: {:5.0f} MB'.format(n_test, used_mb))

# plot(mem_x, mem_y) seems to be linear,
# lets see how used memory scales with 1 sample
a, b = np.polyfit(mem_x, mem_y, deg=1)

# estimated usage just for storing X_test in memory:
sizeof_item = 4  # float32
estimated_a = (num_channels * image_height * image_width * sizeof_item) / 1024 / 1024

print('real usage:\t{:0.2f} MB per sample'.format(a))
print('estimated:\t{:0.2f} MB per sample'.format(estimated_a))
It yields this output:
&lt;denchmark-code&gt;n_test:     1, memory usage:    82 MB
n_test:     2, memory usage:    89 MB
n_test:     4, memory usage:    99 MB
n_test:     8, memory usage:   119 MB
n_test:    16, memory usage:   158 MB
n_test:    32, memory usage:   226 MB
n_test:    64, memory usage:   364 MB
n_test:   128, memory usage:   643 MB
n_test:   256, memory usage:  1196 MB
real usage:     4.35 MB per sample
estimated:      0.02 MB per sample
&lt;/denchmark-code&gt;

If I comment out the eval string (Y_pred = model.eval(X_test)), memory usage becomes normal:
&lt;denchmark-code&gt;n_test:     1, memory usage:    68 MB
n_test:     2, memory usage:    68 MB
n_test:     4, memory usage:    68 MB
n_test:     8, memory usage:    68 MB
n_test:    16, memory usage:    69 MB
n_test:    32, memory usage:    69 MB
n_test:    64, memory usage:    70 MB
n_test:   128, memory usage:    71 MB
n_test:   256, memory usage:    73 MB
real usage:     0.02 MB per sample
estimated:      0.02 MB per sample
&lt;/denchmark-code&gt;

Does CNTK really needs so much mem for evaluation? If so, how can I evaluate the validation dataset (which contains &gt; 1000 images of size 1x64x64)? Or maybe I'm missing something with Python API?
I'm using CNTK version 2.0rc2 CPU-only, Python 3.5.1 (Anaconda), Windows 7.
	</description>
	<comments>
		<comment id='1' author='kokostek' date='2017-05-07T13:51:36Z'>
		&lt;denchmark-link:https://github.com/kokostek&gt;@kokostek&lt;/denchmark-link&gt;
 Thanks for reporting the issue. Do you see the same problem when you evaluate a saved model, i.e. instead of creating the model on the fly, using cntk.ops.functions.load_model() to load a saved model and then call model.eval()? You can save a model by call save_model() to save a model into a file.
		</comment>
		<comment id='2' author='kokostek' date='2017-05-09T15:54:57Z'>
		&lt;denchmark-link:https://github.com/zhouwangzw&gt;@zhouwangzw&lt;/denchmark-link&gt;
 Yes, I'm getting the exact same results when loading previously saved model from a file. Also, I've tested this script on win10 laptop and got the same memory usage.
		</comment>
		<comment id='3' author='kokostek' date='2017-05-12T15:58:44Z'>
		&lt;denchmark-link:https://github.com/kokostek&gt;@kokostek&lt;/denchmark-link&gt;
  Thanks for update. We are investigating the issue.
		</comment>
		<comment id='4' author='kokostek' date='2017-08-04T18:49:43Z'>
		CPU memory was used to evaluation. Two factors that affect memory usage, memory sharing and input unrolling.
Kernel size affect increased memory usage by unrolling. Here if kernel size is reduced to 2, memory usage get halved. Memory sharing may explain partly of rest increased memory usage.
		</comment>
		<comment id='5' author='kokostek' date='2017-09-27T08:55:55Z'>
		I am also expirencing memory leaks evaluating model from C# CPU-only wrapper. It seems memory leak occuring somewhere in DLL.
I am using CNTK 2.2 CPU-only package from NuGet.
Here is the code I use:
&lt;denchmark-code&gt;internal sealed class CNTKModelEvaluator
{
	private const int CPU_MAX_THREADS = 1;

	private readonly Function m_modelFunc;
	private readonly DeviceDescriptor m_device = DeviceDescriptor.CPUDevice;
	private readonly Pool&lt;Function&gt; m_functionsPool;
	
	...

	internal CNTKModelEvaluator(string modelPath, string varInName, string varOutName, int poolSize)
	{
		// CNTK
		Utils.SetTraceLevel(TraceLevel.Warning);

		string modelFileName = Path.Combine(Path.GetDirectoryName(Assembly.GetExecutingAssembly().Location), modelPath);
		this.m_modelFunc = Function.Load(modelFileName, m_device);

		...

		this.m_functionsPool = new Pool&lt;Function&gt;(() =&gt; this.m_modelFunc.Clone(ParameterCloningMethod.Share), poolSize);
	}

	...
	
	internal float Evaluate(List&lt;float&gt; dataList)
	{
		if (dataList.Count != inputDataSize)
		{
			throw new Exception($"Error: data size should be {inputDataSize}, but got {dataList.Count}");
		};

		Function modelFuncLocal = this.m_functionsPool.GetObject();

		using (Variable inputVar = this.GetInputVariable(modelFuncLocal))
		using (Variable outputVar = this.GetOutputVariable(modelFuncLocal))
		using (Value inputVal = Value.CreateBatch(inputVar.Shape, dataList, m_device))
		{
			Dictionary&lt;Variable, Value&gt; inputMap = new Dictionary&lt;Variable, Value&gt;() {
				{ inputVar, inputVal }
			};

			Dictionary&lt;Variable, Value&gt; outMap = new Dictionary&lt;Variable, Value&gt;() {
				{ outputVar, null }
			};

			Utils.SetMaxNumCPUThreads(CPU_MAX_THREADS);
			modelFuncLocal.Evaluate(inputMap, outMap, m_device);

			using (Value outValue = outMap[outputVar])
			{
				float outValueFloat = outValue.GetDenseData&lt;float&gt;(outputVar)[0][0];

				// !!! Mandatory !!!
				// TODO: Rewrite returning using using() statement
				this.m_functionsPool.ReturnObject(modelFuncLocal);

				return outValueFloat;
			};
		};
	}
}
&lt;/denchmark-code&gt;

I use pool of Function objects, cloned with ParameterCloningMethod.Share.
Evaluate() is called from different threads (well, each time I need to evaluate the model - it will be brand new thread).
It seems every evaluation eats some memory, until there is no more.
Model itself is like this:
&lt;denchmark-code&gt;ConvolutionalLayer {64, (256:1), activation = ReLU} :
MaxPoolingLayer {(128:1), stride=(128:1)} :

ConvolutionalLayer {32, (64:1), activation = ReLU} :
MaxPoolingLayer {(4:1), stride=(2:1)} :

ConvolutionalLayer {16, (16:1), activation = ReLU} :
MaxPoolingLayer {(32:1), stride=(2:1)} :

ConvolutionalLayer {16, (8:1), activation = ReLU} :
MaxPoolingLayer {(3:1), stride=(2:1)} :

DenseLayer {16, activation = Tanh, init = "gaussian"} :
Dropout :
DenseLayer {8, activation = Tanh, init = "gaussian"} :
Dropout :

DenseLayer{1, activation = Sigmoid, init = "gaussian"}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='kokostek' date='2018-03-21T20:52:34Z'>
		This is by design. CNTK allocates memory for nodes' input/output according to minibatch size, so when minibatch size increase, the memory cost goes up. If you change the code to following there's no memory increase:
&lt;denchmark-code&gt;    model_tmp = model.clone(C.CloneMethod.share)
    Y_pred = model_tmp.eval(X_test)
    del model_tmp
    del X_test
    del Y_pred
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>