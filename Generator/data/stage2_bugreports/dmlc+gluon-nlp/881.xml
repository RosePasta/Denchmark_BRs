<bug id='881' author='eric-haibin-lin' open_date='2019-08-15T23:02:54Z' closed_time='2019-08-16T19:50:40Z'>
	<summary>Missing error log from CI</summary>
	<description>
The notebook tests in some cases don't report the error log:
&lt;denchmark-link:http://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-877/9/pipeline&gt;http://ci.mxnet.io/blue/organizations/jenkins/GluonNLP-py3-master-gpu-doc/detail/PR-877/9/pipeline&lt;/denchmark-link&gt;

Not sure if it's transient or consistent across runs
	</description>
	<comments>
		<comment id='1' author='eric-haibin-lin' date='2019-08-16T17:10:22Z'>
		Triggered it again and the log is still missing. cc &lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='eric-haibin-lin' date='2019-08-16T17:27:52Z'>
		I found some job status reports that indicate that your jobs were timing out. Are you sure &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/pull/877&gt;#877&lt;/denchmark-link&gt;
 does not introduce any regression that prevents the transformer example from running? The Cloudwath log does not contain any output after minute 2 (and until it is killed at minute 30)
		</comment>
		<comment id='3' author='eric-haibin-lin' date='2019-08-16T17:30:31Z'>
		I'll open a PR to make sure the stderr output is also sent to Cloudwatch. Currently we can't access stderr output as it is only logged to a file but that file is never uploaded to S3 due to the job timeout.
		</comment>
		<comment id='4' author='eric-haibin-lin' date='2019-08-16T18:41:16Z'>
		Yes I also find that the job exceeded 30 mins. There was indeed a bug that causes the translation regression.
		</comment>
	</comments>
</bug>