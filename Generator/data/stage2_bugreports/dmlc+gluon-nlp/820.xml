<bug id='820' author='rjk-git' open_date='2019-07-09T04:43:53Z' closed_time='2019-08-28T19:20:04Z'>
	<summary>FixedBucketSampler causes excessive memory consumption</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

I am having a problem with FixedBucketSampler. My language model uses a simple lstm, hidden_dim:300, num_layer:3. Batch_size: 32, max_seq_len: 100. However, the memory consumption will reach 15G after training 1000batch. In this process, the memory consumption has been increasing.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

There is an obvious rule: if the current batch has a length of 46 and the next batch is still 46, the memory will hardly increase. However, if the sentence length of the next batch is different, the memory consumption of less than or greater than 46 will continue to increase.
Then I fixed the length of each batch of sentences into same length, and the memory consumption will be fixed at around 3G.
I think that using batch data with different sentence lengths, the memory consumption is too large, is there a BUG.
	</description>
	<comments>
		<comment id='1' author='rjk-git' date='2019-07-09T04:44:52Z'>
		&lt;denchmark-link:https://github.com/kenjewu&gt;@kenjewu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/szhengac&gt;@szhengac&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='rjk-git' date='2019-07-09T05:26:06Z'>
		Try enabling the rounding memory pool. export MXNET_GPU_MEM_POOL_TYPE=Round before running the script will enable it. It should help stabilize the memory consumption
		</comment>
		<comment id='3' author='rjk-git' date='2019-07-09T06:52:09Z'>
		
Try enabling the rounding memory pool. export MXNET_GPU_MEM_POOL_TYPE=Round before running the script will enable it. It should help stabilize the memory consumption

After using export MXNET_GPU_MEM_POOL_TYPE=Round, the memory consumption is really reduced a lot, thank you very muchÔºÅ
		</comment>
	</comments>
</bug>