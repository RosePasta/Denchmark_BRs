<bug id='872' author='gemire' open_date='2019-08-11T11:38:38Z' closed_time='2019-08-14T11:09:09Z'>
	<summary>WordEmbedding Why train.step with batchsize 1</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

In scripts/word_embeddings/train_glove.py:319:             trainer.step(batch_size=1)
and scripts/word_embeddings/train_sg_cbow.py:240 trainer.step(batch_size=1)
why the batch_size set to 1?  why not average the loss first? or batch_size set to the real batchsize?
when the batch size is large, it would cause the loss large too.
Thank you for help!
	</description>
	<comments>
		<comment id='1' author='gemire' date='2019-08-14T11:09:09Z'>
		The  in  affects gradient rescaling. As an adaptive optimzer is used (actually blockwise adaptive, see &lt;denchmark-link:https://arxiv.org/pdf/1905.09899.pdf&gt;https://arxiv.org/pdf/1905.09899.pdf&lt;/denchmark-link&gt;
), the rescaling isn't essential. The gradient is already normalized based on the history of gradients.
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/b914d0a6296b5773499a1232dd8d4a3851b6a842/src/operator/contrib/optimizer_op-inl.h#L120-L136&gt;https://github.com/apache/incubator-mxnet/blob/b914d0a6296b5773499a1232dd8d4a3851b6a842/src/operator/contrib/optimizer_op-inl.h#L120-L136&lt;/denchmark-link&gt;

Setting the batch_size to the actually used batch_size seems not to help much: the gradient is sparse and many of the non-zero rows only depend on a small number of elements in the batch. Thus rescaling by batch_size is not correct for them (though to some degree this is counteracted by the adaptivity of the optimizer).
If you like, you can change the batch_size parameter and tune the learning rate. If the results match, let's update the code. But if I remember correctly, I got better results with batch_size=1.
I'm closing the issue for now, but please feel free to reopen if you like to discuss this further or have obtained good results with the suggested code change.
		</comment>
	</comments>
</bug>