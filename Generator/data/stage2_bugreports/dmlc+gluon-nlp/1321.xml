<bug id='1321' author='liuzh91' open_date='2020-08-27T08:44:21Z' closed_time='2020-09-01T07:08:04Z'>
	<summary>[Script] Valid sequence length used in Electra dynamic masking</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

 is used to mark the non-reserve tokens in the sequence in &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/pretraining_utils.py#L503&gt;https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/pretraining_utils.py#L503&lt;/denchmark-link&gt;
. For example, for a sequence like
&lt;denchmark-code&gt;[CLS] Manhattan is the core of New York City.[SEP][PAD][PAD][PAD]
&lt;/denchmark-code&gt;

The corresponding valid_candidates tokens should be like:
&lt;denchmark-code&gt;01111111110000
&lt;/denchmark-code&gt;

In short, valid_candidates mask out tokens like [CLS] [SEP] and [PAD]. Current implementation of valid_candidates is wrong. It will always output sequences with all 1s.
The problem is that the initialization of  is wrong, as in &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/pretraining_utils.py#L497&gt;https://github.com/dmlc/gluon-nlp/blob/master/scripts/pretraining/pretraining_utils.py#L497&lt;/denchmark-link&gt;

&lt;denchmark-code&gt; valid_candidates = F.np.ones_like(input_ids, dtype=np.bool)
&lt;/denchmark-code&gt;

valid_candidates is initialized to be all 1s. When doing subsequent operations, the value will never change.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:
&lt;denchmark-code&gt;curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python

# paste outputs here
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='liuzh91' date='2020-08-27T08:49:02Z'>
		This issue finds a fatal problem that makes valid_candidates invalidated
		</comment>
		<comment id='2' author='liuzh91' date='2020-08-27T08:53:13Z'>
		For a quick fix, we may change this section



gluon-nlp/scripts/pretraining/pretraining_utils.py


        Lines 497 to 503
      in
      970318d






 valid_candidates = F.np.ones_like(input_ids, dtype=np.bool) 



 ignore_tokens = [self.vocab.cls_id, self.vocab.sep_id, self.vocab.pad_id] 



 



 for ignore_token in ignore_tokens: 



 # TODO(zheyuye), Update when operation += supported 



 valid_candidates = valid_candidates + \ 



 F.np.not_equal(input_ids, ignore_token) 





We can change that to
valid_candidates = F.np.ones_like(input_ids, dtype=np.bool) 
for ignore_token in ignore_tokens: 
    valid_candidates = valid_candidates - F.np.equal(input_ids, ignore_token)
In addition, I think it will be better to move it to the preprocessing phase.
		</comment>
		<comment id='3' author='liuzh91' date='2020-08-27T09:34:09Z'>
		
For a quick fix, we may change this section



gluon-nlp/scripts/pretraining/pretraining_utils.py


        Lines 497 to 503
      in
      970318d






 valid_candidates = F.np.ones_like(input_ids, dtype=np.bool) 



 ignore_tokens = [self.vocab.cls_id, self.vocab.sep_id, self.vocab.pad_id] 



 



 for ignore_token in ignore_tokens: 



 # TODO(zheyuye), Update when operation += supported 



 valid_candidates = valid_candidates + \ 



 F.np.not_equal(input_ids, ignore_token) 





We can change that to
valid_candidates = F.np.ones_like(input_ids, dtype=np.bool) 
for ignore_token in ignore_tokens: 
    valid_candidates = valid_candidates - F.np.equal(input_ids, ignore_token)
In addition, I think it will be better to move it to the preprocessing phase.

You cannot use minus here, some of values may end being negative numbers after that. Use multiply will solve the problem.
		</comment>
	</comments>
</bug>