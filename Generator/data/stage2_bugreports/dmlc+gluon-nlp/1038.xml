<bug id='1038' author='JulianSlzr' open_date='2019-12-08T18:43:14Z' closed_time='2020-01-15T17:59:25Z'>
	<summary>Transformer en-de pretrained models are outdated</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/57a45aaf7e82a826e1bffb133c328f913844bd4c&gt;Recent changes to the API&lt;/denchmark-link&gt;
 (&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
) have made the Transformer en-de pretrained models out of date. The models I tried were:

The one listed in inference_transformer.py: https://github.com/dmlc/gluon-nlp/blame/3ce9995329fb0d18787019df541d4f229d7c9ded/scripts/machine_translation/inference_transformer.py#L169
The one listed in the Model Zoo: https://gluon-nlp.mxnet.io/master/model_zoo/machine_translation/index.html

(also these models are not the same!)
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Download and load either .params file, and load via --model_parameter in inference_transformer.py
	</description>
	<comments>
		<comment id='1' author='JulianSlzr' date='2019-12-13T18:08:55Z'>
		Another problem I find is the performance no longer  matches our README. I trained the transformer on WMT2014 using the latest master version:
&lt;denchmark-code&gt;MXNET_GPU_MEM_POOL_TYPE=Round python train_transformer.py --dataset WMT2014BPE \
                       --src_lang en --tgt_lang de --batch_size 2700 \
                       --optimizer adam --num_accumulated 16 --lr 2.0 --warmup_steps 4000 \
                       --save_dir transformer_en_de_u512 --epochs 30 --gpus 0,1,2,3,4,5,6,7 --scaled \
                       --average_start 5 --num_buckets 20 --bucket_scheme exp --bleu 13a --log_interval
&lt;/denchmark-code&gt;

The result is
&lt;denchmark-code&gt;[Epoch 29] valid Loss=1.5213, valid ppl=4.5783, valid bleu=25.79
[Epoch 29] test Loss=1.3180, test ppl=3.7360, test bleu=26.11
Best model valid Loss=1.4877, valid ppl=4.4270, valid bleu=26.03
Best model test Loss=1.2844, test ppl=3.6124, test bleu=26.62
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='JulianSlzr' date='2019-12-13T23:35:04Z'>
		We should fix this issue before 0.9 release
		</comment>
		<comment id='3' author='JulianSlzr' date='2019-12-14T00:56:51Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
  did you confirm it's due &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/pull/976&gt;#976&lt;/denchmark-link&gt;
 and not some change in MXNet? Should it be tracked separately?
The issue &lt;denchmark-link:https://github.com/JulianSlzr&gt;@JulianSlzr&lt;/denchmark-link&gt;
 points out is due to the script not being checked on our CI and thus not being updated in &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/pull/976&gt;#976&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='JulianSlzr' date='2019-12-14T00:57:42Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 I'm not sure about that. I feel that &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/pull/976&gt;#976&lt;/denchmark-link&gt;
 should not change the behavior because it passed the CI.
		</comment>
		<comment id='5' author='JulianSlzr' date='2019-12-14T01:10:21Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 Let me rerun using the version before the refactor.
		</comment>
		<comment id='6' author='JulianSlzr' date='2019-12-14T20:28:30Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 I trained using &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;

The bleu scores are:
&lt;denchmark-code&gt;2019-12-14 16:35:52,264 - root - [Epoch 29] valid Loss=1.5258, valid ppl=4.5989, valid bleu=25.83
2019-12-14 16:39:04,154 - root - [Epoch 29] test Loss=1.3263, test ppl=3.7669, test bleu=26.20
2019-12-14 16:42:39,363 - root - Best model valid Loss=1.4925, valid ppl=4.4484, valid bleu=26.22
2019-12-14 16:45:49,673 - root - Best model test Loss=1.2831, test ppl=3.6077, test bleu=26.93
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='JulianSlzr' date='2019-12-16T02:55:40Z'>
		Could the difference be to an effective difference in the sequence of random values used during training? While we use the same seeds before and after &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
, parts of the computational graph are moved from the imperative API to hybrid API (run by ). Thus there may be a change in the sequence in which the random number generators are called?
What next steps do you recommend to take?
		</comment>
		<comment id='8' author='JulianSlzr' date='2019-12-16T06:19:51Z'>
		Based on my previous experience on a version in Oct, the final bleu is generally 27.10 with std 0.1. So I think there should be some bugs in the master.
		</comment>
		<comment id='9' author='JulianSlzr' date='2019-12-16T06:21:52Z'>
		&lt;denchmark-link:https://github.com/szhengac&gt;@szhengac&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 should this be a release blocker for MXNet 1.6?
		</comment>
		<comment id='10' author='JulianSlzr' date='2019-12-16T06:26:31Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 Do you mean GluonNLP 0.9 or MXNet 1.6?
		</comment>
		<comment id='11' author='JulianSlzr' date='2019-12-16T06:39:14Z'>
		As already before &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 you obtain 0.4 less than the result on &lt;denchmark-link:https://gluon-nlp.mxnet.io/model_zoo/machine_translation/index.html#transformers&gt;https://gluon-nlp.mxnet.io/model_zoo/machine_translation/index.html#transformers&lt;/denchmark-link&gt;
 and as &lt;denchmark-link:https://github.com/szhengac&gt;@szhengac&lt;/denchmark-link&gt;
 reports std 0.1 we need to check running the version before &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 with MXNet 1.5. If this recovers the 0.4 bleu, it should be a MXNet release blocker. Or what do you think?
		</comment>
		<comment id='12' author='JulianSlzr' date='2019-12-16T06:46:50Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 I think &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 has test BLEU equals to . Also, it might be related to the variance. The numpy version has BLEU ranging from (the BLEU score reported here does not use the same evaluation method as in the ndarray version)
		</comment>
		<comment id='13' author='JulianSlzr' date='2019-12-18T05:48:21Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 with &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/394e69a6dc9cea357d188797a949f678f6df7894&gt;394e69a&lt;/denchmark-link&gt;
 and a the following patch
--- a/scripts/machine_translation/train_transformer.py
+++ b/scripts/machine_translation/train_transformer.py
@@ -53,9 +53,9 @@ from bleu import _bpe_to_words, compute_bleu
 from translation import BeamSearchTranslator
 from utils import logging_config

-np.random.seed(100)
-random.seed(100)
-mx.random.seed(10000)
+np.random.seed(101)
+random.seed(101)
+mx.random.seed(10001)
I obtain with MXNet &lt;denchmark-link:https://apache-mxnet.s3-us-west-2.amazonaws.com/dist/2019-12-15/dist/mxnet_cu100-1.6.0b20191215-py2.py3-none-manylinux1_x86_64.whl&gt;https://apache-mxnet.s3-us-west-2.amazonaws.com/dist/2019-12-15/dist/mxnet_cu100-1.6.0b20191215-py2.py3-none-manylinux1_x86_64.whl&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;2019-12-17 04:52:41,912 - root - [Epoch 29] valid Loss=1.5227, valid ppl=4.5845, valid bleu=25.44
2019-12-17 04:55:40,926 - root - [Epoch 29] test Loss=1.3274, test ppl=3.7712, test bleu=26.40
2019-12-17 04:58:49,950 - root - Best model valid Loss=1.4893, valid ppl=4.4340, valid bleu=26.03
2019-12-17 05:01:44,671 - root - Best model test Loss=1.2889, test ppl=3.6288, test bleu=26.73
&lt;/denchmark-code&gt;

You previously obtained (without the patch) . With &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 you got .
I'll try with another seed and an older MXNet version as well.
		</comment>
		<comment id='14' author='JulianSlzr' date='2020-01-02T10:38:02Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 with &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 and a the following patch
--- a/scripts/machine_translation/train_transformer.py
+++ b/scripts/machine_translation/train_transformer.py
@@ -53,9 +53,9 @@ from bleu import _bpe_to_words, compute_bleu
 from translation import BeamSearchTranslator
 from utils import logging_config

-np.random.seed(100)
-random.seed(100)
-mx.random.seed(10000)
+np.random.seed(101)
+random.seed(101)
+mx.random.seed(10001)
I obtain with MXNet &lt;denchmark-link:https://apache-mxnet.s3-us-west-2.amazonaws.com/dist/2019-12-15/dist/mxnet_cu100-1.6.0b20191215-py2.py3-none-manylinux1_x86_64.whl&gt;https://apache-mxnet.s3-us-west-2.amazonaws.com/dist/2019-12-15/dist/mxnet_cu100-1.6.0b20191215-py2.py3-none-manylinux1_x86_64.whl&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;2019-12-18 20:31:42,541 - root - [Epoch 29] valid Loss=1.5274, valid ppl=4.6062, valid bleu=25.87
2019-12-18 20:34:48,269 - root - [Epoch 29] test Loss=1.3206, test ppl=3.7458, test bleu=26.11
2019-12-18 20:38:05,245 - root - Best model valid Loss=1.4916, valid ppl=4.4444, valid bleu=26.22
2019-12-18 20:41:08,935 - root - Best model test Loss=1.2863, test ppl=3.6195, test bleu=26.67
&lt;/denchmark-code&gt;

You previously obtained (without the patch)  on &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
, which is better than the  you observed on &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/394e69a6dc9cea357d188797a949f678f6df7894&gt;394e69a&lt;/denchmark-link&gt;
.
With the patch (ie. different seed) &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/bfa5503e81ae53d26b9f202bce4fedcf09e47db4&gt;bfa5503&lt;/denchmark-link&gt;
 () performs worse than &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/394e69a6dc9cea357d188797a949f678f6df7894&gt;394e69a&lt;/denchmark-link&gt;
 ().
		</comment>
		<comment id='15' author='JulianSlzr' date='2020-01-14T22:35:19Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 I think it's due to the variance.
		</comment>
		<comment id='16' author='JulianSlzr' date='2020-01-14T22:42:54Z'>
		inference_transformer still needs to be added to CI test cases and updated.
		</comment>
		<comment id='17' author='JulianSlzr' date='2020-01-14T22:43:40Z'>
		&lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 Okay, I see, should not have closed it.
		</comment>
		<comment id='18' author='JulianSlzr' date='2020-01-15T17:59:24Z'>
		&lt;denchmark-link:https://github.com/JulianSlzr&gt;@JulianSlzr&lt;/denchmark-link&gt;
 I can't reproduce the issue you report.
I believe you were using an updated script but didn't update your Gluonnlp installation. Or the other way around.
On master, I obtain the following output:
&lt;denchmark-code&gt;2020-01-15 17:54:58,450 - root - Use beam_size=4, alpha=0.6, K=5
2020-01-15 17:54:58,450 - root - Inference on test_dataset!
2020-01-15 17:54:58,455 - root - Test Batch Sampler:
FixedBucketSampler:
  sample_num=2737, batch_num=370
  key=[7, 8, 9, 10, 11, 13, 14, 16, 19, 22, 26, 30, 36, 42, 50, 59, 71, 84, 100]
  cnt=[13, 18, 29, 41, 39, 123, 81, 147, 239, 233, 324, 285, 392, 271, 206, 181, 87, 23, 5]
  batch_size=[35, 32, 28, 25, 23, 19, 18, 16, 13, 11, 10, 8, 7, 6, 5, 4, 3, 3, 2]
2020-01-15 17:55:13,160 - root - batch id=10, batch_bleu=32.0886
2020-01-15 17:55:22,247 - root - batch id=20, batch_bleu=32.7186
2020-01-15 17:55:31,011 - root - batch id=30, batch_bleu=26.0578
2020-01-15 17:55:40,384 - root - batch id=40, batch_bleu=23.3480
2020-01-15 17:55:49,569 - root - batch id=50, batch_bleu=31.0670
2020-01-15 17:55:58,953 - root - batch id=60, batch_bleu=28.4725
2020-01-15 17:56:08,257 - root - batch id=70, batch_bleu=25.6273
2020-01-15 17:56:17,991 - root - batch id=80, batch_bleu=24.1941
2020-01-15 17:56:26,178 - root - batch id=90, batch_bleu=24.3124
2020-01-15 17:56:34,284 - root - batch id=100, batch_bleu=30.3633
&lt;/denchmark-code&gt;

And on &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/commit/505920827eb97a34c58c7694461b5dea672d925a&gt;5059208&lt;/denchmark-link&gt;
 exactly the same results:
&lt;denchmark-code&gt;2020-01-15 17:50:13,486 - root - Use beam_size=4, alpha=0.6, K=5
2020-01-15 17:50:13,486 - root - Inference on test_dataset!
/home/ubuntu/gluon-nlp/src/gluonnlp/data/batchify/batchify.py:233: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended
(e.g. value of padding index in the vocabulary).
  warnings.warn(
2020-01-15 17:50:13,491 - root - Test Batch Sampler:
FixedBucketSampler:
  sample_num=2737, batch_num=370
  key=[7, 8, 9, 10, 11, 13, 14, 16, 19, 22, 26, 30, 36, 42, 50, 59, 71, 84, 100]
  cnt=[13, 18, 29, 41, 39, 123, 81, 147, 239, 233, 324, 285, 392, 271, 206, 181, 87, 23, 5]
  batch_size=[35, 32, 28, 25, 23, 19, 18, 16, 13, 11, 10, 8, 7, 6, 5, 4, 3, 3, 2]
2020-01-15 17:50:28,319 - root - batch id=10, batch_bleu=32.0886
2020-01-15 17:50:37,401 - root - batch id=20, batch_bleu=32.7186
2020-01-15 17:50:46,119 - root - batch id=30, batch_bleu=26.0578
2020-01-15 17:50:55,485 - root - batch id=40, batch_bleu=23.3480
2020-01-15 17:51:04,610 - root - batch id=50, batch_bleu=31.0670
2020-01-15 17:51:13,958 - root - batch id=60, batch_bleu=28.4725
2020-01-15 17:51:23,202 - root - batch id=70, batch_bleu=25.6273
2020-01-15 17:51:32,925 - root - batch id=80, batch_bleu=24.1941
2020-01-15 17:51:41,173 - root - batch id=90, batch_bleu=24.3124
2020-01-15 17:51:49,363 - root - batch id=100, batch_bleu=30.3633
&lt;/denchmark-code&gt;

The difference in output (omitted here), is that logging.info(model) on master version prints the refactored model structure, and on the old version prints the old model structure..
To obtain the results I ran
wget http://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/transformer_en_de_512_WMT2014-e25287c5.zip
unzip transformer_en_de_512_WMT2014-e25287c5.zip
python3 ./inference_transformer.py --model_parameter transformer_en_de_512_WMT2014-e25287c5.params --gpu 0 --dataset WMT2014BPE --src_lang en --tgt_lang de --batch_size 2700 --scaled --num_buckets 20 --bucket_scheme exp --bleu 13a
I'll close the issue now, but please reopen if needed
		</comment>
	</comments>
</bug>