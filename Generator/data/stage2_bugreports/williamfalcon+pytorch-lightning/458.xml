<bug id='458' author='fellnerse' open_date='2019-11-04T15:02:39Z' closed_time='2019-11-20T09:12:04Z'>
	<summary>torch.cuda.empty_cache() adds memory allocation to gpu:0</summary>
	<description>

When running the gpu example with  (this does not work, but setting the default to one gpu different then gpu 0 &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pl_examples/basic_examples/gpu_template.py#L56&gt;here&lt;/denchmark-link&gt;
) and  the system crashes while trying to forward (&lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pl_examples/basic_examples/lightning_module_template.py#L38&gt;here&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/sebastian/.cache/pypoetry/virtualenvs/pl-iterator-_1H-4oww-py3.7/src/pytorch-lightning/pytorch_lightning/root_module/memory.py", line 62, in get_variable_sizes
    out = m(input_)
  File "/home/sebastian/.cache/pypoetry/virtualenvs/pl-iterator-_1H-4oww-py3.7/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/sebastian/.cache/pypoetry/virtualenvs/pl-iterator-_1H-4oww-py3.7/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/sebastian/.cache/pypoetry/virtualenvs/pl-iterator-_1H-4oww-py3.7/lib/python3.7/site-packages/torch/nn/functional.py", line 1370, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: arguments are located on different GPUs at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:277
&lt;/denchmark-code&gt;

When I copy the whole thing and just comment this line it works again. But during  &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L464&gt;emptying the cuda cache&lt;/denchmark-link&gt;
 somehow allocates 595mb on .
Expected behavior
Only gpus specified for the trainer should be used all the time.

Linux 5.0.0-32-generic &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/34&gt;#34&lt;/denchmark-link&gt;
~18.04.2-Ubuntu SMP Thu Oct 10 10:36:02 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

I cloned this commit version: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/commit/37729f0a17995e847fa8693f0fe694f8dd0b259b&gt;37729f0&lt;/denchmark-link&gt;

Can someone verify that? Am I doing something wrong?
	</description>
	<comments>
		<comment id='1' author='fellnerse' date='2019-11-04T15:46:26Z'>
		Did you run with --gpus=2 or CUDA_VISIBLE_DEVICES=2
		</comment>
		<comment id='2' author='fellnerse' date='2019-11-04T21:46:23Z'>
		I replaces this &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pl_examples/basic_examples/gpu_template.py#L56&gt;line&lt;/denchmark-link&gt;
 with , and &lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/master/pl_examples/basic_examples/gpu_template.py#L62&gt;this&lt;/denchmark-link&gt;
 with :
&lt;denchmark-code&gt;    parent_parser.add_argument(
        '--gpus',
        type=int,
        default=[1],
        help='how many gpus'
    )
    parent_parser.add_argument(
        '--distributed_backend',
        type=str,
        default=None,
        help='supports three options dp, ddp, ddp2'
    )
&lt;/denchmark-code&gt;

I did not use any CUDA_VISIBLE_DEVICES stuff.
		</comment>
		<comment id='3' author='fellnerse' date='2019-11-05T14:09:16Z'>
		&lt;denchmark-link:https://github.com/fellnerse&gt;@fellnerse&lt;/denchmark-link&gt;
 you don't need to modify cuda flags (it's specifically mentioned in the docs).
Could you post the exact code you're using?
		</comment>
		<comment id='4' author='fellnerse' date='2019-11-05T15:05:42Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 Yes I know, that's what I was trying to say.
Here the complete code snipped:
&lt;denchmark-code&gt;"""
Runs a model on a single node across N-gpus.
"""
import os
from argparse import ArgumentParser

import numpy as np
import torch

from pytorch_lightning import Trainer

# from lightning_module_template import LightningTemplateModel
from pl_examples.basic_examples.lightning_module_template import LightningTemplateModel

SEED = 2334
torch.manual_seed(SEED)
np.random.seed(SEED)


def main(hparams):
    """
    Main training routine specific for this project
    :param hparams:
    """
    # ------------------------
    # 1 INIT LIGHTNING MODEL
    # ------------------------
    model = LightningTemplateModel(hparams)

    # ------------------------
    # 2 INIT TRAINER
    # ------------------------
    trainer = Trainer(
        gpus=hparams.gpus,
        distributed_backend=hparams.distributed_backend,
        use_amp=hparams.use_16bit
    )

    # ------------------------
    # 3 START TRAINING
    # ------------------------
    trainer.fit(model)


if __name__ == '__main__':
    # ------------------------
    # TRAINING ARGUMENTS
    # ------------------------
    # these are project-wide arguments

    root_dir = os.path.dirname(os.path.realpath(__file__))
    parent_parser = ArgumentParser(add_help=False)

    # gpu args
    parent_parser.add_argument(
        '--gpus',
        type=int,
        default=[1],
        help='how many gpus'
    )
    parent_parser.add_argument(
        '--distributed_backend',
        type=str,
        default=None,
        help='supports three options dp, ddp, ddp2'
    )
    parent_parser.add_argument(
        '--use_16bit',
        dest='use_16bit',
        action='store_true',
        help='if true uses 16 bit precision'
    )

    # each LightningModule defines arguments relevant to it
    parser = LightningTemplateModel.add_model_specific_args(parent_parser, root_dir)
    hyperparams = parser.parse_args()

    # ---------------------
    # RUN TRAINING
    # ---------------------
    main(hyperparams)
&lt;/denchmark-code&gt;

I run it without flags or command line arguments.
The only difference to the original are the default values for --gpus and --distributed_backend.
		</comment>
		<comment id='5' author='fellnerse' date='2019-11-20T09:12:04Z'>
		This seems to be more related to pytorch then pytorch lightning...will close if nobody can replicate this.
		</comment>
		<comment id='6' author='fellnerse' date='2020-06-24T11:04:11Z'>
		I have the same problem, when mem in gpu0 is not enough, Cuda out of memory error occurs
		</comment>
	</comments>
</bug>