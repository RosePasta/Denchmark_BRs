<bug id='2818' author='GuillaumeRochette' open_date='2020-08-04T09:12:51Z' closed_time='2020-08-04T09:28:35Z'>
	<summary>Issue with resume_from_checkpoint (on CPU and GPU)</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Hi,
I've upgraded recently pytorch-lightning from 0.7.5 to 0.8.5, and I have encountered an issue with the resume_from_checkpoint from the Trainer class.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

The dummy example below shows the behaviour:

Run the script for a few loops in order to create a first checkpoint.
Stop.
Re-run the code, it should resume from the previously created checkpoint.

This script works well and resume properly in 0.7.5, however it does not for 0.8.5.
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

from munch import Munch
from pathlib import Path

import torch

from torch.utils.data import Dataset, DataLoader
from torch.nn import Linear, MSELoss
from torch.optim import Adam

from pytorch_lightning import LightningModule, Trainer


class MyDataset(Dataset):
    def __init__(self, n):
        self.n = n

    def __len__(self):
        return self.n

    def __getitem__(self, item):
        x = torch.randn(1)
        y = 1.5 * x + 2
        return {
            "x": x,
            "y": y,
        }


class MyModule(LightningModule):
    def __init__(self):
        super(MyModule, self).__init__()
        self.model = Linear(in_features=1, out_features=1)
        self.criterion = MSELoss()

    def configure_optimizers(self):
        return Adam(self.model.parameters())

    def forward(self, x):
        x = self.model(x)
        return x

    def training_step(self, input, batch_idx):
        input = Munch.fromDict(input)

        output = Munch()
        output.y = self(input.x)

        loss = self.criterion(input=output.y, target=input.y)
        return {"loss": loss}


if __name__ == "__main__":
    dataset = MyDataset(n=2 ** 15)
    train_dataloader = DataLoader(dataset, batch_size=32, num_workers=8)

    model = MyModule()

    path = Path("/home/guillaume/projects/test/models/scratch")

    checkpoints = sorted(path.rglob("*.ckpt"))
    if checkpoints:
        checkpoint = checkpoints[-1]
    else:
        checkpoint = None
    print(checkpoint)

    trainer = Trainer(
        default_root_dir=path,
        gpus=1,
        auto_select_gpus=True,
        resume_from_checkpoint=checkpoint,
    )

    trainer.fit(model=model, train_dataloader=train_dataloader)
&lt;denchmark-code&gt;GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type    | Params
--------------------------------------
0 | model     | Linear  | 2     
1 | criterion | MSELoss | 0     
Traceback (most recent call last):
  File "/home/guillaume/projects/test/src/scratch.py", line 75, in &lt;module&gt;
    trainer.fit(model=model, train_dataloader=train_dataloader)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1003, in fit
    results = self.single_gpu_train(model)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py", line 186, in single_gpu_train
    results = self.run_pretrain_routine(model)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1160, in run_pretrain_routine
    self.restore_weights(model)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py", line 182, in restore_weights
    self.restore(self.resume_from_checkpoint, on_gpu=self.on_gpu)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/trainer/training_io.py", line 295, in restore
    checkpoint = pl_load(checkpoint_path, map_location=lambda storage, loc: storage)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/site-packages/pytorch_lightning/utilities/cloud_io.py", line 8, in load
    if urlparse(path_or_url).scheme == '' or Path(path_or_url).drive:  # no scheme or with a drive letter
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py", line 367, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py", line 123, in _coerce_args
    return _decode_args(args) + (_encode_result,)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py", line 107, in _decode_args
    return tuple(x.decode(encoding, errors) if x else '' for x in args)
  File "/home/guillaume/miniconda3/envs/terrestrial/lib/python3.7/urllib/parse.py", line 107, in &lt;genexpr&gt;
    return tuple(x.decode(encoding, errors) if x else '' for x in args)
AttributeError: 'PosixPath' object has no attribute 'decode'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

This exact same code works well with pytorch-lightning: 0.7.5, which is the version I used previously.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
	- GPU:
		- GeForce GTX 970
	- available:         True
	- version:           10.2
* Packages:
	- numpy:             1.19.1
	- pyTorch_debug:     False
	- pyTorch_version:   1.6.0
	- pytorch-lightning: 0.8.5
	- tensorboard:       2.3.0
	- tqdm:              4.48.2
* System:
	- OS:                Linux
	- architecture:
		- 64bit
		- 
	- processor:         x86_64
	- python:            3.7.7
	- version:           #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='GuillaumeRochette' date='2020-08-04T09:27:07Z'>
		Actually, resume_from_checkpoint works well even in 0.8.5, but it doesn't support Path objects any more, hence the error.
The correct script below casts checkpoint to a string, and does not throw an error any more.
Sorry for the inconvenience.
from munch import Munch
from pathlib import Path

import torch

from torch.utils.data import Dataset, DataLoader
from torch.nn import Linear, MSELoss
from torch.optim import Adam

from pytorch_lightning import LightningModule, Trainer


class MyDataset(Dataset):
    def __init__(self, n):
        self.n = n

    def __len__(self):
        return self.n

    def __getitem__(self, item):
        x = torch.randn(1)
        y = 1.5 * x + 2
        return {
            "x": x,
            "y": y,
        }


class MyModule(LightningModule):
    def __init__(self):
        super(MyModule, self).__init__()
        self.model = Linear(in_features=1, out_features=1)
        self.criterion = MSELoss()

    def configure_optimizers(self):
        return Adam(self.model.parameters())

    def forward(self, x):
        x = self.model(x)
        return x

    def training_step(self, input, batch_idx):
        input = Munch.fromDict(input)

        output = Munch()
        output.y = self(input.x)

        loss = self.criterion(input=output.y, target=input.y)
        return {"loss": loss}


if __name__ == "__main__":
    dataset = MyDataset(n=2 ** 15)
    train_dataloader = DataLoader(dataset, batch_size=32, num_workers=8)

    model = MyModule()

    path = Path("/home/guillaume/projects/test/models/scratch")

    checkpoints = sorted(path.rglob("*.ckpt"))
    if checkpoints:
        checkpoint = checkpoints[-1]
        checkpoint = str(checkpoint)
    else:
        checkpoint = None
    print(checkpoint)

    trainer = Trainer(
        default_root_dir=path,
        gpus=1,
        auto_select_gpus=True,
        resume_from_checkpoint=checkpoint,
    )

    trainer.fit(model=model, train_dataloader=train_dataloader)
		</comment>
	</comments>
</bug>