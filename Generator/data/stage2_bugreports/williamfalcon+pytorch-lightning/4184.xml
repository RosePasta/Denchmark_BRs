<bug id='4184' author='ruotianluo' open_date='2020-10-16T04:01:54Z' closed_time='2020-10-16T19:33:31Z'>
	<summary>Resume training from a finished-training model will results in a new incorrect checkpoint</summary>
	<description>
To verify a model if a model has finished training. I ran the training script again.
However, when I try to evaluate with the model, I got error that:
&lt;denchmark-code&gt;pytorch_lightning.utilities.exceptions.MisconfigurationException:
            you restored a checkpoint with current_epoch=11
            but the Trainer(max_epochs=10)
&lt;/denchmark-code&gt;

After digging a little bit, it seems that since the model has finished training, it will directly go to on_train_end, and save the model checkpoint with currect_epoch+1.
I am wondering if the design of saving checkpoints with "next epoch" is reasonable? Why not add the epoch number after resuming?
	</description>
	<comments>
		<comment id='1' author='ruotianluo' date='2020-10-16T04:16:16Z'>
		I think it better to move +1 from 


pytorch-lightning/pytorch_lightning/trainer/connectors/checkpoint_connector.py


         Line 254
      in
      dec31b3






 'epoch': self.trainer.current_epoch + 1, 




 to 


pytorch-lightning/pytorch_lightning/trainer/connectors/checkpoint_connector.py


         Line 150
      in
      dec31b3






 self.trainer.global_step = checkpoint['global_step'] 





It will break the existing checkpoints though.
		</comment>
		<comment id='2' author='ruotianluo' date='2020-10-16T04:33:18Z'>
		Now I just add an if before 


pytorch-lightning/pytorch_lightning/trainer/training_loop.py


         Line 178
      in
      72f1976






 self.check_checkpoint_callback(should_save=True, is_last=True) 





&lt;denchmark-code&gt;         if self.trainer.current_epoch &lt; self.trainer.max_epochs and not self.interrupted:
             self.check_checkpoint_callback(should_save=True, is_last=True)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='ruotianluo' date='2020-10-16T09:14:29Z'>
		duplicate &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4176&gt;#4176&lt;/denchmark-link&gt;
 ?
I think a simple solution would be to not do anything if 
		</comment>
		<comment id='4' author='ruotianluo' date='2020-10-16T13:04:55Z'>
		&lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
 yes. It's the same.
		</comment>
	</comments>
</bug>