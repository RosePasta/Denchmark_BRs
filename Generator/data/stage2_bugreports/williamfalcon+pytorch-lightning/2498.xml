<bug id='2498' author='williamFalcon' open_date='2020-07-04T14:25:36Z' closed_time='2020-08-03T22:00:37Z'>
	<summary>TPU hangs when using only a train loop (ie: no val loop)</summary>
	<description>
I think it's somehow related to checkpointing.
Easiest way to debug is to get on colab.
	</description>
	<comments>
		<comment id='1' author='williamFalcon' date='2020-07-04T14:26:26Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='williamFalcon' date='2020-07-05T07:36:53Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 I struggle to reproduce this. PL does not even recognize the TPUs in the runtime, XLA_AVAILABLE gets set to false (mnist tpu colab). Tried different pytorch and xla versions, all the same.
Could you share the colab in which you observed the hangs?
		</comment>
		<comment id='3' author='williamFalcon' date='2020-07-12T23:43:07Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 checked again and now I am able to run the mnist colab without validation and it does not hang anymore (latest master). Not sure what fixed it.
		</comment>
	</comments>
</bug>