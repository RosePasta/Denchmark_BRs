<bug id='456' author='nikvaessen' open_date='2019-11-04T11:12:42Z' closed_time='2019-12-04T12:39:06Z'>
	<summary>Using custom ModelCheckPoint results in RunTimeError</summary>
	<description>
Describe the bug
Modifying  the  per  &lt;denchmark-link:https://williamfalcon.github.io/pytorch-lightning/Trainer/Checkpointing/&gt;https://williamfalcon.github.io/pytorch-lightning/Trainer/Checkpointing/&lt;/denchmark-link&gt;
 results in:
&lt;denchmark-code&gt;100%|██████████| 10/10 [00:02&lt;00:00,  4.04it/s, batch_nb=8, epoch=0, gpu=0, loss=2.707, train_acc=0.12, v_nb=6, val_acc=0.12, val_loss=2.88]Can save best model only with val_loss available, skipping. &lt;class 'RuntimeWarning'&gt;
&lt;/denchmark-code&gt;

To Reproduce
def main(hparams):
    # init module
    model = BnnOnCIFAR10(hparams)

    # DEFAULTS used by the Trainer
    checkpoint_callback = ModelCheckpoint(
        filepath="../../results",
        save_best_only=True,
        verbose=True,
        monitor="val_loss",
        mode="min",
        prefix="",
    )

    # most basic trainer, uses good defaults
    trainer = Trainer(
        max_nb_epochs=hparams.max_nb_epochs,
        gpus=hparams.gpus,
        nb_gpu_nodes=hparams.nodes,
        overfit_pct=0.01,
        checkpoint_callback=checkpoint_callback,
        default_save_path="../../results",
        check_val_every_n_epoch=1,
        show_progress_bar=True,
    )

    trainer.fit(model)
    def validation_step(self, batch, batch_idx):
        # OPTIONAL
        x, y = batch
        y_hat = self.forward(x)

        # validation metrics for monitoring
        labels_hat = torch.argmax(y_hat, dim=1)
        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
        val_loss = F.cross_entropy(y_hat, y)

        return OrderedDict(
            {
                "val_loss": val_loss.clone().detach(),
                "val_acc": torch.tensor(val_acc),
            }
        )

    def validation_end(self, outputs):
        """
        outputs -- list of outputs ftom each validation step
        """
        # The outputs here are strictly for progress bar
        avg_loss = torch.stack([x["val_loss"] for x in outputs]).mean()
        avg_acc = torch.stack([x["val_acc"] for x in outputs]).mean()

        logger_logs = {"val_acc": avg_acc, "val_loss": avg_loss}

        output = OrderedDict({"progress_bar": logger_logs, "log": logger_logs})

        return output
Expected behavior
Expected result is that my custom ModelCheckpoint is given the val_loss value and can function correctly.
Screenshots
&lt;denchmark-link:https://user-images.githubusercontent.com/7225987/68116864-2192e700-fefc-11e9-93bf-6df85dfe5f70.png&gt;&lt;/denchmark-link&gt;

Desktop (please complete the following information):

OS: xubuntu 18.04
Browser: not applicable

pip:
&lt;denchmark-code&gt;(venv) nik@nik-hmm:~/kth/y2/adl/Rethinking-Binarized-Neural-Network-Optimization$ pip list
Package                          Version              Location                                                             
-------------------------------- -------------------- ---------------------------------------------------------------------
absl-py                          0.8.1                
astor                            0.8.0                
cachetools                       3.1.1                
certifi                          2019.9.11            
chardet                          3.0.4                
cycler                           0.10.0               
dataclasses                      0.7                  
future                           0.18.0               
gast                             0.2.2                
google-auth                      1.6.3                
google-auth-oauthlib             0.4.1                
google-pasta                     0.1.7                
grpcio                           1.24.3               
h5py                             2.10.0               
idna                             2.8                  
imageio                          2.6.1                
Keras                            2.3.1                
Keras-Applications               1.0.8                
Keras-Preprocessing              1.1.0                
kiwisolver                       1.1.0                
larq                             0.7.4                
Markdown                         3.1.1                
matplotlib                       3.1.1                
numpy                            1.17.3               
oauthlib                         3.1.0                
opt-einsum                       3.1.0                
pandas                           0.25.1               
Pillow                           6.2.0                
pip                              19.0.3               
protobuf                         3.10.0               
pyasn1                           0.4.7                
pyasn1-modules                   0.2.7                
pyparsing                        2.4.2                
python-dateutil                  2.8.0                
pytorch-lightning                0.5.2.1              
pytz                             2019.3               
PyYAML                           5.1.2                
requests                         2.22.0               
requests-oauthlib                1.2.0                
research-seed                    0.0.1                /home/nik/kth/y2/adl/Rethinking-Binarized-Neural-Network-Optimization
rsa                              4.0                  
scipy                            1.3.1                
setuptools                       41.6.0               
six                              1.12.0               
tb-nightly                       2.1.0a20191103       
tensorflow                       2.0.0rc2             
tensorflow-estimator             2.0.1                
tensorflow-estimator-2.0-preview 2.0.0                
tensorflow-gpu                   2.0.0rc2             
termcolor                        1.1.0                
terminaltables                   3.1.0                
test-tube                        0.7.1                
tf-estimator-nightly             1.14.0.dev2019080601 
tf-nightly-2.0-preview           2.0.0.dev20191002    
torch                            1.3.0                
torchsummary                     1.5.1                
torchvision                      0.4.1                
tqdm                             4.36.1               
urllib3                          1.25.6               
Werkzeug                         0.16.0               
wheel                            0.33.6               
wrapt                            1.11.2          
&lt;/denchmark-code&gt;

NVIDIA:
&lt;denchmark-code&gt;(venv) nik@nik-hmm:~/kth/y2/adl/Rethinking-Binarized-Neural-Network-Optimization$ nvidia-smi 
Mon Nov  4 12:12:21 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 105...  Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   66C    P0    N/A /  N/A |    298MiB /  4042MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
&lt;/denchmark-code&gt;

Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='nikvaessen' date='2019-11-05T14:13:16Z'>
		&lt;denchmark-link:https://github.com/nikvaessen&gt;@nikvaessen&lt;/denchmark-link&gt;
 this was solved in master. Please install that and retry. New release coming on Nov 6.
		</comment>
	</comments>
</bug>