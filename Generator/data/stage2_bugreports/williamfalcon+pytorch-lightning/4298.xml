<bug id='4298' author='dsuess' open_date='2020-10-22T07:46:46Z' closed_time='2020-12-24T23:01:39Z'>
	<summary>auto_select_gpu does not free memory allocated on GPU for DDP/Horovod</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

If using both  and the ddp or horovod accelerator, the memory allocated by &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/tuner/auto_gpu_select.py#L32&gt;pick_single_gpu&lt;/denchmark-link&gt;
 is not freed by torch.
This can't be reproduced on Colab since DDP isn't supported.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Paste this code into a file and run it:
&lt;denchmark-code&gt;import pytorch_lightning as pl
from torch import nn
from torchvision.models import resnet18
from torchvision.datasets import CIFAR10
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from torch.optim import SGD


class Model(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.model = nn.Linear(3072, 10)

    def train_dataloader(self):
        dataset = CIFAR10("__pycache__", download=True, transform=ToTensor())
        return DataLoader(dataset)

    def configure_optimizers(self):
        return SGD(self.model.parameters(), lr=0.01)

    def training_step(self, batch, _):
        x, label = batch
        y = self.model(x.view(x.size(0), -1))
        return nn.functional.cross_entropy(y, label)


trainer = pl.Trainer(accelerator="ddp", gpus=2, auto_select_gpus=True)

model = Model()
trainer.fit(model)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The same amount of memory is allocated on both GPUs. However, nvidia-smi shows this:
&lt;denchmark-link:https://user-images.githubusercontent.com/5870291/96840880-c5bbc800-1496-11eb-8cc4-a2ae3ebc3ed1.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
        - GPU:
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
                - GeForce RTX 2080 Ti
        - available:         True
        - version:           10.2
* Packages:
        - numpy:             1.19.2
        - pyTorch_debug:     False
        - pyTorch_version:   1.6.0
        - pytorch-lightning: 1.0.3
        - tqdm:              4.50.1
* System:
        - OS:                Linux
        - architecture:
                - 64bit
                - ELF
        - processor:         x86_64
        - python:            3.8.5
        - version:           #110-Ubuntu SMP Tue Jun 23 02:39:32 UTC 2020
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='dsuess' date='2020-10-29T20:52:24Z'>
		&lt;denchmark-link:https://github.com/awaelchli&gt;@awaelchli&lt;/denchmark-link&gt;
 ideas?
		</comment>
		<comment id='2' author='dsuess' date='2020-11-05T17:17:31Z'>
		I will try to reproduce asap.
My guess is we need to run auto_select_gpus before we launch the child processes. It looks like currently, each child process is running the auto_select_gpus independently.
		</comment>
		<comment id='3' author='dsuess' date='2020-12-17T21:12:31Z'>
		This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!
		</comment>
	</comments>
</bug>