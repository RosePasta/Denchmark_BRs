<bug id='2424' author='ruotianluo' open_date='2020-06-29T23:55:52Z' closed_time='2020-07-01T03:07:06Z'>
	<summary>validation_epoch_end only gets the outputs from one process</summary>
	<description>
Hi,
I need the whole validation set to get the validation result.
Current validation_epoch_end only gets the outputs from current process.
Can I collect the gather the outputs from different gpus, and then run validation_epoch_end. And also I don't necessary need it to run on all processes, I only need it to run once.
How can I achieve that?
	</description>
	<comments>
		<comment id='1' author='ruotianluo' date='2020-06-30T00:32:41Z'>
		I found an ugly solution.
I use detectron2.utils.comm.all_gather and gather to achieve what I want.
But it would be better if anything builtin in lightning can work for this purpose.
		</comment>
		<comment id='2' author='ruotianluo' date='2020-06-30T13:34:23Z'>
		See also: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2413&gt;#2413&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ruotianluo' date='2020-06-30T18:48:20Z'>
		I have something like this in my validation loop:
&lt;denchmark-code&gt;def validation_epoch_end(self, outputs):
        loss_val = torch.stack([x['val_loss'] for x in outputs]).mean()
        log_dict = {'validation_loss': loss_val, 'step': self.current_epoch}
        return {'log': log_dict, 'val_loss': log_dict['validation_loss'], 'progress_bar': log_dict}
&lt;/denchmark-code&gt;

but this takes only one process into account. Is there a way to aggregate all the batches when using ddp? Is using dist.all_gatherthe way to do it?
I also see some reference to training_step_end and validation_step_end. Is that something we can use for this but I do not  see much examples of this? Could someone be so kind as to post an example of how one might use these to collect  the data from all batches?
		</comment>
		<comment id='4' author='ruotianluo' date='2020-06-30T20:15:19Z'>
		dist all gather only support torch tensor I believe. detectron2 all_gather can gather anything. It works well for me now.
		</comment>
		<comment id='5' author='ruotianluo' date='2020-06-30T20:20:30Z'>
		I see a few other posts that have been closed, so I am assuming this has somehow been sorted and is possible. I also opened another issue about this: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2435&gt;#2435&lt;/denchmark-link&gt;

Hope someone can help :)
		</comment>
		<comment id='6' author='ruotianluo' date='2020-07-01T02:52:41Z'>
		currently I use this to gather other processes' outputs:
&lt;denchmark-code&gt;    def test_epoch_end(self, outputs):
        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()
        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()

        dist.all_reduce(avg_acc, op=dist.ReduceOp.SUM)
        avg_acc = avg_acc / self.trainer.world_size
&lt;/denchmark-code&gt;

Now, new TensorMetric class can do dist_all_reduce automatically, but it only supports dist.ReduceOp, you have to divide by self.trainer.world_size if you want MEAN.  If you have dict outputs, you can iterate all values and use dist_all_reduce
		</comment>
		<comment id='7' author='ruotianluo' date='2020-07-01T03:07:06Z'>
		this is fixed on master
		</comment>
		<comment id='8' author='ruotianluo' date='2020-07-01T03:14:20Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

I don't think it is fixing my original quesiton. I asked if there is a way that the validation_epoch_end can gather the outputs from all the gpus, and do evaluation.
The reason is, in my case, the output of the validation set has to be evaluated as a whole. So I can't simply calculate the score in each process and all reduce them.
		</comment>
		<comment id='9' author='ruotianluo' date='2020-07-01T13:44:06Z'>
		
this is fixed on master
@williamFalcon
When you say fixed on master, what do you mean? Will this do it automatically or do we need to do something about it? Can you point us to the relevant bit in the lightning source code?

		</comment>
		<comment id='10' author='ruotianluo' date='2020-07-01T14:07:18Z'>
		My guess is this
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/commit/309ed75c5d6740538fca6d9a571d85606ac6d48b&gt;309ed75&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='ruotianluo' date='2020-07-01T14:14:38Z'>
		&lt;denchmark-link:https://github.com/dagap&gt;@dagap&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ruotianluo&gt;@ruotianluo&lt;/denchmark-link&gt;
 install the latest version!

		</comment>
		<comment id='12' author='ruotianluo' date='2020-07-01T14:45:48Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 Thanks for that. So, we do not need to do anything from the caller end? it will do this automagically in validation/test modes?
		</comment>
		<comment id='13' author='ruotianluo' date='2020-07-01T14:57:53Z'>
		yup!
We handle all the cross GPU syncing automagically
		</comment>
		<comment id='14' author='ruotianluo' date='2020-07-01T15:21:38Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 I am still confused.
What is the expected behavior? Is there any doc related to this?
I guess a concrete example would be helpful. If I have 2gpus with ddp, and the validation set has 500batches, so each gpu gets 250 batches.
What is the size of the input argument outputs for validaiton_epoch_end?
		</comment>
		<comment id='15' author='ruotianluo' date='2020-07-01T15:28:57Z'>
		the behavior is transparent to you. meaning, if you calculate accuracy on 2 gpus, then we average the accuracy across gpus, but it's transparent to you.
Gpu 0
&lt;denchmark-code&gt;def validation_step(...)
   return {'acc': 10}
&lt;/denchmark-code&gt;

Gpu 1
&lt;denchmark-code&gt;def validation_step(...)
   return {'acc': 20}
&lt;/denchmark-code&gt;

What is logged, printed, etc... is 15.0
		</comment>
		<comment id='16' author='ruotianluo' date='2020-07-01T15:51:25Z'>
		Thanks. It's the same as I understand.
The reason why I said it doesn't solve my question, because in my case the validation_step does not return an accuracy, not even a number, but a set of captions.
What I want to achieve, is to collect all the captions of the validation images. So the input of validation_epoch_end is all the captions, and validaiton_epoch_end can call an external library to evaluate the results.
I think it's fine to evaluate separately, but it is just safer to evaluate all as a whole. That's why I asked the question at the first place.
For now, I think my workaround is fine.
		</comment>
		<comment id='17' author='ruotianluo' date='2020-07-01T23:31:14Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 Now the outputs of validation_epoch_end have to be cuda tensor. You may want to improve that?
		</comment>
		<comment id='18' author='ruotianluo' date='2020-07-01T23:39:47Z'>
		yes! that shouldn’t happen, that’s an oversight
		</comment>
		<comment id='19' author='ruotianluo' date='2020-07-03T15:57:10Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

This does seem to be there on the latest master. Has this been removed again?
		</comment>
		<comment id='20' author='ruotianluo' date='2020-07-03T16:03:54Z'>
		it’s disabled on master at the moment because

it will blow up your ram
it may only work with certain tensors

so, we are cleaning it up and adding back in
		</comment>
		<comment id='21' author='ruotianluo' date='2020-07-13T12:36:06Z'>
		Now, my tensor not all the cross GPU syncing automagically
		</comment>
	</comments>
</bug>