<bug id='5039' author='ZhichaoDuan' open_date='2020-12-09T13:16:24Z' closed_time='2021-01-18T05:22:55Z'>
	<summary>validating bar keep showing 0 when check_val_every_n_epoch is bigger than 1</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Normally, the validating bar should update according to the procedure of validation_step, but when I set check_val_every_n_epoch bigger than 1, 2 for example, it keeps showing 0it.
I encountered this issue under a terminal environment.

PyTorch 1.6.0:
Linux

	</description>
	<comments>
		<comment id='1' author='ZhichaoDuan' date='2020-12-09T13:17:08Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='ZhichaoDuan' date='2020-12-09T15:04:52Z'>
		&lt;denchmark-link:https://github.com/ZhichaoDuan&gt;@ZhichaoDuan&lt;/denchmark-link&gt;
 can you reproduce this using the BoringModel?
		</comment>
		<comment id='3' author='ZhichaoDuan' date='2020-12-10T15:08:07Z'>
		Same issue here. Setting check_val_every_n_epoch to 2 gives me a validation progress bar stuck at Validating: 0it [00:00, ?it/s].
Perhaps related; the first epoch (either correctly or not depending on whether the Trainer should validate on epoch 0) shows the sum of train and validation batches, but never loops through the validation batches. E.g. I have 100/50 train/val batches, first epoch will show n/150 but will stop at 100. Second epoch will show the correct number (100).
This smells like an off-by-one error somewhere because after the validation loop finishes; the following epoch again shows the wrong batch number.

PyTorch 1.7.0
PyTorch Lightning 1.0.8
Linux

EDIT:
Think I've found it:



pytorch-lightning/pytorch_lightning/trainer/training_loop.py


         Line 884
      in
      6d2aeff






 is_val_check_epoch = (self.trainer.current_epoch + 1) % self.trainer.check_val_every_n_epoch == 0 








pytorch-lightning/pytorch_lightning/callbacks/progress.py


         Line 116
      in
      89e8796






 is_val_epoch = (self.trainer.current_epoch) % self.trainer.check_val_every_n_epoch == 0 





Progress bar is missing the +1 offset for the current epoch.
		</comment>
		<comment id='4' author='ZhichaoDuan' date='2020-12-11T02:01:20Z'>
		
@ZhichaoDuan can you reproduce this using the BoringModel?

Istefanou below have located the issue, could you take a look at it?
		</comment>
		<comment id='5' author='ZhichaoDuan' date='2020-12-11T21:27:33Z'>
		Anyone wants to try and submit a fix?
		</comment>
		<comment id='6' author='ZhichaoDuan' date='2021-01-11T03:31:34Z'>
		This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!
		</comment>
	</comments>
</bug>