<bug id='835' author='ibeltagy' open_date='2020-02-14T04:00:18Z' closed_time='2020-03-03T16:49:42Z'>
	<summary>Tensorboard logging should use `num_grad_updates` not `batch_idx`</summary>
	<description>
When accumulate_grad_batches &gt; 1, the x-axis in tensorboard should be number of gradient updates, not number of batches that have been processed.
	</description>
	<comments>
		<comment id='1' author='ibeltagy' date='2020-02-28T10:15:07Z'>
		Have the authors changed the logic in master branch? Now 1 tensorboard step == 1 optimizer step?
Thanks!
		</comment>
		<comment id='2' author='ibeltagy' date='2020-03-03T16:49:42Z'>
		AFAICT, this was fixed here &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/832&gt;#832&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>