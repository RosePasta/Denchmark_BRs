<bug id='84' author='preddy5' open_date='2019-08-09T15:09:13Z' closed_time='2019-08-09T15:32:41Z'>
	<summary>Returning None in validation_end method raises error</summary>
	<description>
Hey,
If we define a validation_end method like
&lt;denchmark-code&gt;    def validation_end(self, outputs):
        return
&lt;/denchmark-code&gt;

it is gonna raise an error
&lt;denchmark-code&gt;AttributeError: 'NoneType' object has no attribute 'items'
&lt;/denchmark-code&gt;

Is this intended, if not shouldnt this part of the code initialize the metrics dict
&lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/018b8da50e90638e8aa8d3eda1f8637656c25f2d/pytorch_lightning/models/trainer.py#L987&gt;https://github.com/williamFalcon/pytorch-lightning/blob/018b8da50e90638e8aa8d3eda1f8637656c25f2d/pytorch_lightning/models/trainer.py#L987&lt;/denchmark-link&gt;

like here
&lt;denchmark-link:https://github.com/williamFalcon/pytorch-lightning/blob/018b8da50e90638e8aa8d3eda1f8637656c25f2d/pytorch_lightning/models/trainer.py#L886&gt;https://github.com/williamFalcon/pytorch-lightning/blob/018b8da50e90638e8aa8d3eda1f8637656c25f2d/pytorch_lightning/models/trainer.py#L886&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='preddy5' date='2019-08-09T15:31:13Z'>
		return {} for now
		</comment>
		<comment id='2' author='preddy5' date='2019-08-09T15:32:01Z'>
		but we're adding support for not needing to implement a val function if not needed &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/82&gt;#82&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='preddy5' date='2020-09-25T21:23:18Z'>
		The recommended solution:
&lt;denchmark-code&gt;    def validation_epoch_end(self, validation_outputs):
        return {}
&lt;/denchmark-code&gt;

Also produces the error 'AttributeError: 'dict' object has no attribute 'callback_metrics':
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-27-f49f97955aea&gt; in &lt;module&gt;
      4     check_val_every_n_epoch=3,
      5 )
----&gt; 6 trainer.fit(model)

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/states.py in wrapped_fn(self, *args, **kwargs)
     46             if entering is not None:
     47                 self.state = entering
---&gt; 48             result = fn(self, *args, **kwargs)
     49 
     50             # The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in fit(self, model, train_dataloader, val_dataloaders, datamodule)
   1082             self.accelerator_backend = CPUBackend(self)
   1083             self.accelerator_backend.setup(model)
-&gt; 1084             results = self.accelerator_backend.train(model)
   1085 
   1086         # on fit end callback

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/cpu_backend.py in train(self, model)
     37 
     38     def train(self, model):
---&gt; 39         results = self.trainer.run_pretrain_routine(model)
     40         return results

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in run_pretrain_routine(self, model)
   1222 
   1223         # run a few val batches before training starts
-&gt; 1224         self._run_sanity_check(ref_model, model)
   1225 
   1226         # clear cache before training

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py in _run_sanity_check(self, ref_model, model)
   1255             num_loaders = len(self.val_dataloaders)
   1256             max_batches = [self.num_sanity_val_steps] * num_loaders
-&gt; 1257             eval_results = self._evaluate(model, self.val_dataloaders, max_batches, False)
   1258 
   1259             # allow no returns from eval

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py in _evaluate(self, model, dataloaders, max_batches, test_mode)
    397 
    398         # log callback metrics
--&gt; 399         self.__update_callback_metrics(eval_results, using_eval_result)
    400 
    401         # Write predictions to disk if they're available.

~/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py in __update_callback_metrics(self, eval_results, using_eval_result)
    419             if isinstance(eval_results, list):
    420                 for eval_result in eval_results:
--&gt; 421                     self.callback_metrics = eval_result.callback_metrics
    422             else:
    423                 self.callback_metrics = eval_results.callback_metrics

AttributeError: 'dict' object has no attribute 'callback_metrics'
&lt;/denchmark-code&gt;

Comment those two lines out and it works without any issue. This issue should not be closed until either the problem is fixed or the documentation is updated to show that it's not working.
		</comment>
	</comments>
</bug>