<bug id='4736' author='MartFire' open_date='2020-11-18T10:46:25Z' closed_time='2020-11-18T13:13:30Z'>
	<summary>Tensorboard save_dir overrides default_root_dir</summary>
	<description>
I am using PytorchLighting with Tensorboard and if I specify the argument save_dir in TensorBoardLogger then my checkpoints will be saved in this directory and not in the default_root_dir provided to the Trainer. Is this a normal behavior ?
&lt;denchmark-code&gt;tb_logger = pl_loggers.TensorBoardLogger(save_dir=config.TRAINING.log_path)  
began = BEGAN(config)  # My model
trainer = Trainer(logger=tb_logger, default_root_dir=config.TRAINING.ckpt_path)  
trainer.fit(model=began, datamodule=CIFAR10DataModule())  
# checkpoints are saved in config.TRAINING.log_path, not in config.TRAINING.ckpt_path
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='MartFire' date='2020-11-18T10:47:05Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='MartFire' date='2020-11-18T11:59:05Z'>
		This is the default behaviour of : &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#default-root-dir&gt;https://pytorch-lightning.readthedocs.io/en/latest/trainer.html#default-root-dir&lt;/denchmark-link&gt;

Could you try passing in a ModelCheckpoint object to the callbacks trainer list and see if this works for you?
tb_logger = pl_loggers.TensorBoardLogger(save_dir=config.TRAINING.log_path)  
began = BEGAN(config)  # My model
trainer = Trainer(logger=tb_logger, callbacks=[ModelCheckpoint(config.TRAINING.ckpt_path)])  
trainer.fit(model=began, datamodule=CIFAR10DataModule())  
		</comment>
		<comment id='3' author='MartFire' date='2020-11-18T13:13:29Z'>
		It's working, thank you !
		</comment>
	</comments>
</bug>