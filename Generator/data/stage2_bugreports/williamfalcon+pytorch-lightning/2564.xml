<bug id='2564' author='YuxianMeng' open_date='2020-07-09T08:42:24Z' closed_time='2020-07-09T10:39:01Z'>
	<summary>Logging loss is extremely large when training with fp16</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Logging loss is extremely large(e.g. 10000) when training with fp16, but I find that the loss in tfboard is quite normal(e.g. 1.0). I guess the loss in logging does not discard unstable training steps?
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Loss in logging should be approximate between turning on/off fp16. Also,  logging loss should be consistent with tfboard loss.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Please copy and paste the output from our
&lt;denchmark-link:https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py&gt;environment collection script&lt;/denchmark-link&gt;

(or fill out the checklist below manually).
You can get the script and run it with:
&lt;denchmark-code&gt;wget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py
# For security purposes, please check the contents of collect_env_details.py before running it.
python collect_env_details.py
&lt;/denchmark-code&gt;


PyTorch Version (e.g., 1.0): nightly
OS (e.g., Linux): Linux
How you installed PyTorch (conda, pip, source): pip
Build command you used (if compiling from source):
Python version: 3.6
CUDA/cuDNN version: 10.2
GPU models and configuration:
Any other relevant information:

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='YuxianMeng' date='2020-07-09T10:39:01Z'>
		fixed on master
		</comment>
	</comments>
</bug>