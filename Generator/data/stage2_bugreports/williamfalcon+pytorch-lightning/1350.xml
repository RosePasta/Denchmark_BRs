<bug id='1350' author='Dunrar' open_date='2020-04-02T17:54:37Z' closed_time='2020-04-19T13:57:53Z'>
	<summary>on_train_end seems to get called before logging of last epoch has finished</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Maybe not a bug, but unexpected behavior. When using the on_train_end method to either upload a models latest .csv file created by TestTube to neptune or to print the last numeric channel value of a metric send to neptune, the values from the final epoch have not yet been logged. When training has finished, the last line of metrics.csv is 2020-04-02 17:23:16.029189,0.04208208369463682,30.0, but for the outputs/uploads of on_train_end see code below:
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;def on_epoch_end(self):
    # Logging loss per epoch
    train_loss_mean = np.mean(self.training_losses)
    # Saves loss of final epoch for later visualization
    self.final_loss = train_loss_mean
    self.logger[0].experiment.log_metric('epoch/mean_absolute_loss', y=train_loss_mean, x=self.current_epoch)
    self.logger[1].experiment.log({'epoch/mean_absolute_loss': train_loss_mean, 'epoch': self.current_epoch}, global_step=self.current_epoch)
    self.training_losses = []  # reset for next epoch
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;def on_train_end(self):
    save_dir = Path(self.logger[1].experiment.get_logdir()).parent/'metrics.csv'
    self.logger[0].experiment.log_artifact(save_dir)
&lt;/denchmark-code&gt;

Last line of uploaded metrics.csv: 2020-04-02 15:27:57.044250 0.04208208404108882 29.0 
&lt;denchmark-code&gt;def on_train_end(self):
    log_last = self.logger[0].experiment.get_logs()
    print('Last logged values: ', log_last)
&lt;/denchmark-code&gt;

Output: Last logged values:  {'epoch/mean_absolute_loss': Channel(channelType='numeric', id='b00cd0e5-a427-4a3c-a10c-5033808a930e', lastX=29.0, name='epoch/mean_absolute_loss', x=29.0, y='0.04208208404108882')}
When printing self.final_loss in on_train_end I get the correct last value though.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The on_train_end  method to only get called after the last values have been logged.
	</description>
	<comments>
		<comment id='1' author='Dunrar' date='2020-04-04T03:44:09Z'>
		&lt;denchmark-link:https://github.com/Dunrar&gt;@Dunrar&lt;/denchmark-link&gt;
 could you link to a colab notebook to reproduce this? i checked in the training loop code and we are only calling  after training is complete
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/training_loop.py#L671&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/training_loop.py#L671&lt;/denchmark-link&gt;

if you can reproduce in a notebook i can dig in deeper as to why you're experience this problem
		</comment>
		<comment id='2' author='Dunrar' date='2020-04-14T15:01:27Z'>
		Hey &lt;denchmark-link:https://github.com/jeremyjordan&gt;@jeremyjordan&lt;/denchmark-link&gt;
, sorry, just got around to it. Here is the notebook:
&lt;denchmark-link:https://colab.research.google.com/drive/1WH5GmyvrSevWPp2_C2wfSMakIDgpy477&gt;https://colab.research.google.com/drive/1WH5GmyvrSevWPp2_C2wfSMakIDgpy477&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Dunrar' date='2020-04-17T01:21:19Z'>
		&lt;denchmark-link:https://github.com/Dunrar&gt;@Dunrar&lt;/denchmark-link&gt;
 Had a little look at this and your code. on_train_end is not being called before the epoch has finished. It just looks that way. What's actually happening is that the logs aren't being finalised/saved until after on_train_end has been called so it looks that way when you look at the logs inside on_train_end.
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/training_loop.py#L693&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/training_loop.py#L693&lt;/denchmark-link&gt;

Adding a self.logger[1].save() to the beginning of on_train_end() (or the end of on_epoch_end()) yields the result you'd expect for me for test_tube logger. I'm not familiar with Neptune but based on the structure of pytorch-lightning the result should be the same if you add self.logger[0].save() as well
		</comment>
		<comment id='4' author='Dunrar' date='2020-04-19T13:57:52Z'>
		&lt;denchmark-link:https://github.com/HenryJia&gt;@HenryJia&lt;/denchmark-link&gt;
 Just tried it, thank you! I'll close this then :)
		</comment>
		<comment id='5' author='Dunrar' date='2020-04-19T14:48:00Z'>
		Glad I could help :)
		</comment>
	</comments>
</bug>