<bug id='1763' author='mstewart141' open_date='2020-05-09T01:45:24Z' closed_time='2020-07-10T01:26:30Z'>
	<summary>`model.test()` can fail for `ddp` because `args` in `evaluation_forward` are malformed</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

model.test() can fail while training via dp because TrainerEvaluationLoopMixin.evaluation_forward doesn't handle an edge case.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Attempt to model.test() any lightning model in dp mode (I believe it fails in any of the modes at 


pytorch-lightning/pytorch_lightning/trainer/evaluation_loop.py


         Line 420
      in
      3a64260






 if self.use_ddp or self.use_dp or self.use_ddp2: 




).
Note that the validation and training steps work well, but test fails.
The bottom of the stack trace isn't super elucidating but the crux of the matter is captured in
&lt;denchmark-code&gt;    411     def evaluation_forward(self, model, batch, batch_idx, dataloader_idx, test_mode: bool = False):
    412         # make dataloader_idx arg in validation_step optional
    413         args = [batch, batch_idx]
    414 
    415         if (test_mode and len(self.test_dataloaders) &gt; 1) \
    416                 or (not test_mode and len(self.val_dataloaders) &gt; 1):
    417             args.append(dataloader_idx)
    418 
    419         # handle DP, DDP forward
    420         if self.use_ddp or self.use_dp or self.use_ddp2:
--&gt; 421             output = model(*args)
    422             return output
&lt;/denchmark-code&gt;

At line 421 the code that will run is output = model(*args[0][:-1]) but other things fail downstream of that hack. Note args[0] is the tuple of tensors and the last tensor is the target.
TL;DR: at this point (for test -- again val and train work perfectly) I believe that what we want is something similar to output = model.test_step(*args) instead (see later on in evaluation_forward, below the above trace).
However, i realized that the model, now a LightningDataParallel instance, no longer has the test_step that is defined in the original LightningModule, so my understanding of the system for making multi-GPU work is a limiting factor here.
This mock, I thought, would resolve the issue for me, but I then realized that the test_step method no longer existed per the above paragraph:
&lt;denchmark-code&gt;ORIG = pl.trainer.evaluation_loop.TrainerEvaluationLoopMixin.evaluation_forward

def _mock_evaluation_forward(self, model, batch, batch_idx, dataloader_idx, test_mode: bool = False):
    if not test_mode or (not (self.use_ddp or self.use_dp or self.use_ddp2)):
        return ORIG(self, model, batch, batch_idx, dataloader_idx, test_mode)
    
    output = model.test_step(*args)
    return output

from unittest import mock

@mock.patch('pytorch_lightning.trainer.evaluation_loop.TrainerEvaluationLoopMixin.evaluation_forward', _mock_evaluation_forward)
def train_my_model(): ...
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

Thanks for the great library! I can't precisely determine why train and eval work and then test fails. One thing to note is that the forward method to my model takes several tensors, not just one, which is a possible factor. Everything works perfectly with dp turned off.
	</description>
	<comments>
		<comment id='1' author='mstewart141' date='2020-05-09T01:46:08Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='mstewart141' date='2020-05-10T21:07:52Z'>
		ummm. good catch. Want to submit a PR? we'll help you finish it
		</comment>
		<comment id='3' author='mstewart141' date='2020-05-11T06:55:09Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 I'd like to take this up if no one else is working on it. Please tellme if its free in order to avoid duplication of effort.
		</comment>
		<comment id='4' author='mstewart141' date='2020-05-12T18:49:00Z'>
		@gingerboredman i've not looked into it any further yet, so i think you're likely in the clear if you want to give it a shot!
		</comment>
		<comment id='5' author='mstewart141' date='2020-05-12T18:50:55Z'>
		&lt;denchmark-link:https://github.com/mstewart141&gt;@mstewart141&lt;/denchmark-link&gt;
 yeah cool, I'm on it. Thanks 
		</comment>
		<comment id='6' author='mstewart141' date='2020-05-14T07:30:31Z'>
		For some reason, one of my gpus stopped working. Any way to work around this as i cant test any changes i make with ddp enabled and my new GPU will take a week or so to arrive? If not, id advise reassigning this task as it would cause further delay
&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/mstewart141&gt;@mstewart141&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='mstewart141' date='2020-05-18T05:00:21Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/mstewart141&gt;@mstewart141&lt;/denchmark-link&gt;
 Could i get some help regarding my previous message?
		</comment>
		<comment id='8' author='mstewart141' date='2020-07-10T01:26:30Z'>
		Fixed! 0.8.5
		</comment>
	</comments>
</bug>