<bug id='836' author='jeremyjordan' open_date='2020-02-14T04:00:38Z' closed_time='2020-02-16T04:43:44Z'>
	<summary>advanced profiler description fails for python 3.6</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Python 3.6 doesn't have the pstats.SortKey.CUMULATIVE enum so the profiler description breaks.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
Use Python 3.6, pass in the AdvancedProfiler, get report at end of a training run.
&lt;denchmark-code&gt;profiler = AdvancedProfiler(line_count_restriction=10)
trainer = Trainer(profiler=profiler)
trainer.fit(model)
&lt;/denchmark-code&gt;

Stack trace:
&lt;denchmark-code&gt;    164         for action_name, pr in self.profiled_actions.items():
    165             s = io.StringIO()
--&gt; 166             sortby = pstats.SortKey.CUMULATIVE
    167             ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(sortby)
    168             ps.print_stats(self.line_count_restriction)

AttributeError: module 'pstats' has no attribute 'SortKey'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;from pytorch_lightning import Trainer
from pytorch_lightning.profiler import AdvancedProfiler
from argparse import Namespace
from pl_examples.basic_examples.lightning_module_template import LightningTemplateModel


# define model
hparams = {
    "batch_size": 128,
    "in_features": 784,
    "hidden_dim": 512,
    "drop_prob": 0.0,
    "out_features": 10,
    "learning_rate": 5e-3,
    "data_root": "data"
}
hparams = Namespace(**hparams)
model = LightningTemplateModel(hparams)

# overfit on small batch
profiler = AdvancedProfiler(line_count_restriction=10)
trainer = Trainer(profiler=profiler, overfit_pct=0.05, min_epochs=10)
trainer.fit(model)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Collecting environment information...
PyTorch version: 1.4.0
Is debug build: No
CUDA used to build PyTorch: 10.1
OS: Ubuntu 18.04.3 LTS
GCC version: (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CMake version: version 3.12.0
Python version: 3.6
Is CUDA available: Yes
CUDA runtime version: 10.0.130
GPU models and configuration: GPU 0: Tesla P100-PCIE-16GB
Nvidia driver version: 418.67
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5
Versions of relevant libraries:
[pip3] numpy==1.17.5
[pip3] pytorch-lightning==0.6.1.dev0
[pip3] torch==1.4.0
[pip3] torchsummary==1.5.1
[pip3] torchtext==0.3.1
[pip3] torchvision==0.5.0
[conda] Could not collect
	</description>
	<comments>
		<comment id='1' author='jeremyjordan' date='2020-02-14T09:23:23Z'>
		just wondering, was it also falling while PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/782&gt;#782&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='2' author='jeremyjordan' date='2020-02-14T12:18:34Z'>
		there wasn‚Äôt test coverage for this case, it was failing in the describe() method. worked for me on local since i was using 3.7.
		</comment>
	</comments>
</bug>