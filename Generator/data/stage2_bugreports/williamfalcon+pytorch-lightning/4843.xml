<bug id='4843' author='edenlightning' open_date='2020-11-24T23:09:28Z' closed_time='2020-12-08T17:19:56Z'>
	<summary>DDP accelorator should have 'trainer=none' as default</summary>
	<description>
Add to DDP accelerator 'trainer=None' as a first argument (otherwise I cannot pass it to the Trainer instantiation)
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_accelerator.py#L49&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_accelerator.py#L49&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;class DDPAccelerator(Accelerator):
    def __init__(self, trainer, cluster_environment=None, ddp_plugin=None)
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>