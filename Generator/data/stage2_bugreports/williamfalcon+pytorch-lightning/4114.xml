<bug id='4114' author='shrinath-suresh' open_date='2020-10-13T10:04:22Z' closed_time='2020-10-13T20:47:24Z'>
	<summary>Unable to save model using torch.save in pytorch lightning version 0.10</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

torch.save(trainer.model, "model.pth") throwing error in pytorch lightning version 0.10
&lt;denchmark-h:h2&gt;Please reproduce using the following code&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import os
import torch
from torch import nn
import torch.nn.functional as F
from torchvision.datasets import MNIST
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
import pytorch_lightning as pl

class LitAutoEncoder(pl.LightningModule):

    def __init__(self):
        super().__init__()
        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))
        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))

    def forward(self, x):
        # in lightning, forward defines the prediction/inference actions
        embedding = self.encoder(x)
        return embedding

    def training_step(self, batch, batch_idx):
        # training_step defined the train loop. It is independent of forward
        x, y = batch
        x = x.view(x.size(0), -1)
        z = self.encoder(x)
        x_hat = self.decoder(z)
        loss = F.mse_loss(x_hat, x)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return optimizer

dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())
train, val = random_split(dataset, [55000, 5000])

autoencoder = LitAutoEncoder()
trainer = pl.Trainer(max_epochs=1)
trainer.fit(autoencoder, DataLoader(train), DataLoader(val))


torch.save(trainer.model, "model.pth")
&lt;/denchmark-code&gt;

`
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Install pytorch lightning 0.9 and run the script mentioned above. Model will get saved successfully.
Upgrade pytorch lightning version to 0.10 using pip install pytorch_lightning==0.10 and run the same script, the error would be reproduced
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Model should be saved as model.pth file.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:
available:         False
version:           10.2


Packages:

numpy:             1.19.2
pyTorch_debug:     False
pyTorch_version:   1.6.0
pytorch-lightning: 0.10.0
tqdm:              4.48.2


System:

OS:                Linux
architecture:

64bit
ELF


processor:         x86_64
python:            3.8.2
version:           119~16.04.1-Ubuntu SMP Tue Sep 8 14:54:40 UTC 2020



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

Stack Trace
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "encoder.py", line 43, in &lt;module&gt;
    torch.save(trainer.model, "model.pth")
  File "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/serialization.py", line 364, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/serialization.py", line 466, in _save
    pickler.dump(obj)
TypeError: 'NoneType' object is not callable

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='shrinath-suresh' date='2020-10-13T10:44:52Z'>
		torch.save(trainer.model.state_dict(), "model.pth")
or
torch.save(trainer.get_model().state_dict(), "model.pth")
		</comment>
		<comment id='2' author='shrinath-suresh' date='2020-10-13T11:01:17Z'>
		Yes. saving statedict works as expected in both version(0.9, 0.10). However, we are using library which dumps the entire model using torch.save. It was working in 0.9 and in the latest release we could find the error mentioned in the stack trace section.
		</comment>
		<comment id='3' author='shrinath-suresh' date='2020-10-13T14:26:11Z'>
		
However, we are using library which dumps the entire model using torch.save

sorry I didn't get this.
Also the code and stack trace doesn't match here.
torch.save(trainer.model, "model.pth")
Traceback (most recent call last):
  File "/tmp/test.py", line 43, in &lt;module&gt;
    torch.save(autoencoder, "autoencoder.pth")  &lt;---------- here
  File "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py", line 364, in save
    _save(obj, opened_zipfile, pickle_module, pickle_protocol)
  File "/home/ubuntu/anaconda3/lib/python3.8/site-packages/torch/serialization.py", line 466, in _save
    pickler.dump(obj)
TypeError: 'NoneType' object is not callable
		</comment>
		<comment id='4' author='shrinath-suresh' date='2020-10-13T14:57:07Z'>
		The idea is to log the entire model into mlflow using  - &lt;denchmark-link:https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html&gt;https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html&lt;/denchmark-link&gt;
 . The library dumps the entire model into mlflow using  and it is not working in 0.10 and 1.0 version.
Updated the stack trace.
		</comment>
		<comment id='5' author='shrinath-suresh' date='2020-10-13T15:49:31Z'>
		I found two attributes that are causing pickle to throw an error:
&lt;denchmark-code&gt;trainer.model.module._results
trainer.model.module.trainer.accelerator_backend.interactive_ddp_procs
&lt;/denchmark-code&gt;

Deleting these keys allows the model to be saved. First one is required for single proc/GPU, both are required for multiGPU/proc (instead of interactive_ddp_procs, you'll need to delete mp_queue)
The first is an object called Result: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/core/step_result.py#L26&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/core/step_result.py#L26&lt;/denchmark-link&gt;

This doesn't override __get_state__ __set_state__  functions or inherits any for serialization, thus throws an error (as it falls back to __get_attr__.
The second one is an accelerator class storing processes that are not cleaned up. This also happens in ddp_cpu as well.
ddp: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_accelerator.py#L134&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_accelerator.py#L134&lt;/denchmark-link&gt;

ddp_cpu: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_cpu_spawn_accelerator.py#L56&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/accelerators/ddp_cpu_spawn_accelerator.py#L56&lt;/denchmark-link&gt;

cc &lt;denchmark-link:https://github.com/rohitgr7&gt;@rohitgr7&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 not entirely sure the direction we'd like to go.  via lightning handles saving, excluding these unserialisable objects.
		</comment>
		<comment id='6' author='shrinath-suresh' date='2020-10-13T15:54:57Z'>
		&lt;denchmark-link:https://github.com/SeanNaren&gt;@SeanNaren&lt;/denchmark-link&gt;
 , let's make those two picklable?
		</comment>
		<comment id='7' author='shrinath-suresh' date='2020-10-13T15:56:31Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 sure, will do this!
		</comment>
	</comments>
</bug>