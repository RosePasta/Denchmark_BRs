<bug id='1578' author='mmiakashs' open_date='2020-04-23T18:24:27Z' closed_time='2020-04-28T00:06:52Z'>
	<summary>Error in training with ddp backend and checkpoint_callback</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I am getting the following error when I am using checkpoint_callback or early_stop_callback  in ddp mode with multi-GPUs. However, If I remove checkpoint_callback and early_stop_callback, then my code executes without any error.
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

Here is a sample google colab notebook (Please note that this colab error is not exactly the same actual error): &lt;denchmark-link:https://colab.research.google.com/drive/110kEtr1BjhPtTzQ7r8qOXbnb8VOwQQ6y&gt;Colab&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):
  File "../model.py", line 489, in &lt;module&gt;
    main(args=args)
  File "../model.py", line 357, in main
    trainer.fit(model)
  File "/home/machine/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 738, in fit
    mp.spawn(self.ddp_train, nprocs=self.num_processes, args=(model,))
  File "/home/machine/.local/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/machine/.local/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 149, in start_processes
    process.start()
  File "/usr/lib/python3.7/multiprocessing/process.py", line 112, in start
    self._popen = self._Popen(self)
  File "/usr/lib/python3.7/multiprocessing/context.py", line 284, in _Popen
    return Popen(process_obj)
  File "/usr/lib/python3.7/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/usr/lib/python3.7/multiprocessing/popen_fork.py", line 20, in __init__
    self._launch(process_obj)
  File "/usr/lib/python3.7/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;class 'torch._C._VariableFunctions'&gt;: it's not the same object as torch._C._VariableFunctions
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version : 1.5
PyTorch Lightning Version : 0.7.3rc3
OS (e.g., Linux): Ubuntu 18.04
How you installed PyTorch (conda, pip, source): pip
Python version: 3.7.5
CUDA/cuDNN version: 10.2
GPU models and configuration: RTX 6000

	</description>
	<comments>
		<comment id='1' author='mmiakashs' date='2020-04-23T18:25:06Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='mmiakashs' date='2020-04-27T12:12:29Z'>
		I have just update from

PyTorch 1.4 &amp; Pytorch Lightning 0.7.3

where "ddp" &amp; ModelCheckpoint worked just fine to

PyTorch 1.5 &amp; Pytorch Lightning 0.7.4

where I hit the same error.
		</comment>
		<comment id='3' author='mmiakashs' date='2020-04-27T23:59:54Z'>
		I have updated to PyTorch  &amp; Pytorch Lightning  and  in combination with  seems to work. Possibly a duplicate of &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/1628&gt;#1628&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='mmiakashs' date='2020-04-28T00:06:52Z'>
		resolved in 0.7.5
		</comment>
		<comment id='5' author='mmiakashs' date='2020-04-28T03:41:03Z'>
		Thanks &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 for resolving the issue. But, still I am getting the same error in 0.7.5, you can this &lt;denchmark-link:https://colab.research.google.com/drive/110kEtr1BjhPtTzQ7r8qOXbnb8VOwQQ6y&gt;colab notebook&lt;/denchmark-link&gt;
 to reproduce. Please let me know, whether I am missing anything. Thanks.
		</comment>
		<comment id='6' author='mmiakashs' date='2020-04-29T16:08:18Z'>
		&lt;denchmark-link:https://github.com/mmiakashs&gt;@mmiakashs&lt;/denchmark-link&gt;
 mind open a new issue?
		</comment>
	</comments>
</bug>