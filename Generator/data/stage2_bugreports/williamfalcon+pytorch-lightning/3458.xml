<bug id='3458' author='ananthsub' open_date='2020-09-11T03:56:32Z' closed_time='2020-10-01T10:49:48Z'>
	<summary>Model summarize displayed twice before training starts</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Model summarize is called in two spots, which results in duplication in the logs:

It's called once in the training loop: https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/training_loop.py#L160

And I'm unsure how it's called again
&lt;denchmark-link:https://user-images.githubusercontent.com/2382532/92856189-04deff80-f3a8-11ea-824c-35bd2aef2258.png&gt;&lt;/denchmark-link&gt;

The first time is with the logger.info(...) since it's formatted. The second time it appears to be logged with print(...) since the table formatting doesn't handle newlines
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Run any training with weights_summary set on the trainer
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

We only call summarize once
	</description>
	<comments>
		<comment id='1' author='ananthsub' date='2020-09-11T22:00:15Z'>
		Tried on master. Working fine. Is it happening with ddp backend only?
		</comment>
		<comment id='2' author='ananthsub' date='2020-09-11T22:18:55Z'>
		Yes this happens with DDP backend
		</comment>
		<comment id='3' author='ananthsub' date='2020-09-11T22:29:22Z'>
		on my windows machine, single gpu, happens too. but the logs also appear twice, including all warnings.
&lt;denchmark-code&gt;TPU available: False, using: 0 TPU cores
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
CUDA_VISIBLE_DEVICES: [0]
&lt;/denchmark-code&gt;

¬®
which means it is logging related, not model summary.
I will investigate
		</comment>
		<comment id='4' author='ananthsub' date='2020-09-22T11:18:19Z'>
		Just started migration of our codebase to Lightning and the first trainer I write have this issue... Could this be something related with duplicated handlers in logger? It might be that the logger.getLogger() which is a singleton is called twice, so it might be that 2 handlers are initialized, the root handler and another stream handler
This is my case:
&lt;denchmark-link:https://user-images.githubusercontent.com/6736158/93876004-5eafc580-fcd6-11ea-97fd-b0633ec0028a.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ananthsub' date='2020-09-22T11:20:43Z'>
		yes, I think that's the case. does my PR not resolve the problem for you? which os are you on?
		</comment>
		<comment id='6' author='ananthsub' date='2020-09-22T11:40:25Z'>
		I am using Ubuntu 18.04.
I tried you PR but unfortunately it does not solve the issue. Maybe I am doing something wrong?
&lt;denchmark-link:https://user-images.githubusercontent.com/6736158/93877718-29f13d80-fcd9-11ea-8adb-d1690a69f064.png&gt;&lt;/denchmark-link&gt;

I think this is what might be happening: &lt;denchmark-link:https://jdhao.github.io/2020/06/20/python_duplicate_logging_messages/&gt;https://jdhao.github.io/2020/06/20/python_duplicate_logging_messages/&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='ananthsub' date='2020-09-22T12:18:08Z'>
		&lt;denchmark-link:https://github.com/JVGD&gt;@JVGD&lt;/denchmark-link&gt;
 could you try again with my updated branch. sorry, I don't have much experience with this python logging, for me the duplicate messages are resolved locally. I need you as the tester 
I tried my windows and ubunut multi-gpu
		</comment>
		<comment id='8' author='ananthsub' date='2020-09-22T15:45:01Z'>
		Unfortunately is still showing duplicated logs. I am going to do further testing, but as far as I know I think the pytroch_lightning logger adds an extra StreamHandler to the base root logger. Maybe that is why there are duplicates
		</comment>
		<comment id='9' author='ananthsub' date='2020-09-22T15:51:05Z'>
		indeed, if we remove the streamhandler, this also solves the problem (for me). can you confirm?
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3514/files&gt;https://github.com/PyTorchLightning/pytorch-lightning/pull/3514/files&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='ananthsub' date='2020-09-22T16:06:29Z'>
		Amazing! it was just deleting that line and now it works like a charm. By the way, I did it in the pytorch-lightning==0.9.0 version, I was in my development environment. So I haven't been able to test it on your branch. But tomorrow I will!
Thank you for the support. Now it looks great:
&lt;denchmark-link:https://user-images.githubusercontent.com/6736158/93907924-4784ce00-fcfe-11ea-9f27-832315cebc9d.png&gt;&lt;/denchmark-link&gt;

I am not sure if that change alone suffices for avoiding duplicated logging in other platforms, but in my case it is indeed.
		</comment>
		<comment id='11' author='ananthsub' date='2020-09-22T22:28:57Z'>
		&lt;denchmark-link:https://github.com/JVGD&gt;@JVGD&lt;/denchmark-link&gt;
 this is all really strange. I checked again with a different machine (also ubuntu 18) and now It's not printing the model summary, while on my notebook it did.
I need to go through the python versions and see if there is a difference. ugh :(
		</comment>
		<comment id='12' author='ananthsub' date='2020-09-23T07:28:05Z'>
		Mmm really strange &lt;denchmark-link:https://github.com/ashwinb&gt;@ashwinb&lt;/denchmark-link&gt;
, I think we almost got this bug hunted down.
I got an hypothesis: maybe you don't see any logs because the root logger does not have any handlers. This means, pytorch_lightning did not add any handlers (because we removed it), and app you are running does not add any other handlers.
I think it works in my case because my app already adds a StreamHandler at the beginning. So there is at least one StreamHandler.
If it helps, in my python project I check explicitly that there is only one StreamHandler in the root base logger. Maybe doing something like this could help. The idea is to add a StreamHandler only if there is none, but if it is at least one, then use that one (instead of adding another that will print duplicated logs).
        # Checking if there is already a stream
        # handler for avoinding log repetition
        console_hanlder_configured = any(
            [isinstance(handler, logging.StreamHandler)
             for handler in root_logger.handlers])

        # If console handler not configured, then add it
        if not console_hanlder_configured:
            # Handler for logging to stdout
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            console_handler.setLevel(level)

            # Adding handler to logger
            root_logger.addHandler(console_handler)
		</comment>
		<comment id='13' author='ananthsub' date='2020-09-30T23:39:57Z'>
		are we good on this? i also made a bunch of stability fixes to ddp including duplicate logging and so on
		</comment>
		<comment id='14' author='ananthsub' date='2020-10-01T07:47:52Z'>
		Last time I checked it wasn't but I am happy to check it out. The branch to test is still bugfix/duplicated-logging right?
		</comment>
		<comment id='15' author='ananthsub' date='2020-10-01T07:55:59Z'>
		Tested, I am good on my side
&lt;denchmark-link:https://user-images.githubusercontent.com/6736158/94782957-4aea1a80-03cc-11eb-8687-96ef362e408f.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='ananthsub' date='2021-01-22T08:42:18Z'>
		I still have the duplicate log issue like this:
&lt;denchmark-code&gt;GPU available: True, used: True
[2021-01-22 07:43:17,623][INFO] lightning: GPU available: True, used: True
TPU available: None, using: 0 TPU cores
[2021-01-22 07:43:17,623][INFO] lightning: TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
[2021-01-22 07:43:17,623][INFO] lightning: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
&lt;/denchmark-code&gt;

I'm using pytorch-lightning version 1.1.1, and I configured the root log using logging.dictConfig with "disable_existing_loggers": False. The configuring was done after importing pytorch-lightning. I think it's a common approach.
I think these lines in __init__.py should be removed
&lt;denchmark-code&gt;_logger.addHandler(python_logging.StreamHandler())	
_logger.setLevel(python_logging.INFO)
&lt;/denchmark-code&gt;

This is the only library having this issue in my hundreds of dependencies.
related issue: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/1503&gt;#1503&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='ananthsub' date='2021-01-22T12:31:49Z'>
		&lt;denchmark-link:https://github.com/ianlini&gt;@ianlini&lt;/denchmark-link&gt;
 see &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/4621&gt;#4621&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/5509&gt;#5509&lt;/denchmark-link&gt;
 for progress on this issue
		</comment>
	</comments>
</bug>