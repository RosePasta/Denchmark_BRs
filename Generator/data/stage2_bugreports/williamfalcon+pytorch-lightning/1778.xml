<bug id='1778' author='karapostK' open_date='2020-05-11T12:03:22Z' closed_time='2020-08-03T19:37:53Z'>
	<summary>Tensorboard log_hyperparams(params, metrics) seems not to have effect</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Calling self.logger.log_hyperparams(hparams_dicts, metrics_dicts) in test_epoch_end doesn't have the desired effect. It should show the entries in the Hparams section with hparams and metrics specified but it shows nothing instead.
Looking at the code it seems to be caused by self.hparams and the pre-logging of the hyperparameters at the start of the training. In this way, calls to log_hyperparams won't be able to log the hyperparameters AND the metrics properly since they will clash with the previous log, hence, showing nothing.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Try to log metrics with self.logger.log_hyperparams.
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;def test_epoch_end(self, outputs):
    avg_recall = np.concatenate([x['recall'] for x in outputs]).mean()
    tensorboard_logs = {'test/avg_ndcg': avg_ndcg, "test/avg_recall": avg_recall}
    ## Log metrics
    self.logger.log_hyperparams(vars(self.params),tensorboard_logs)
    return tensorboard_logs
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Tensorboard should show me the section of Hparams with each entry composed by hyperparameters and metrics.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:
- GPU:
- available:         False
- version:           10.2
Packages:
- numpy:             1.18.1
- pyTorch_debug:     False
- pyTorch_version:   1.5.0
- pytorch-lightning: 0.7.5
- tensorboard:       2.2.1
- tqdm:              4.46.0
System:
- OS:                Linux
- architecture:
- 64bit
- ELF
- processor:         x86_64
- python:            3.8.2
- version:           #34~18.04.1-Ubuntu SMP Fri Feb 28 13:42:26 UTC 2020

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='karapostK' date='2020-05-11T12:04:06Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='karapostK' date='2020-05-11T15:14:09Z'>
		yes, hparams seems to not be working for some reason. looking into it.
		</comment>
		<comment id='3' author='karapostK' date='2020-05-11T15:27:53Z'>
		I played around the issue and I think I may know the problem. When calling log_hyperparams the function adds events to the log file instead of overwrite the existent one (the one created in the pre-train routine). It follows that tensorboard sees one file with different sets of metrics, { } from the first log and the last added with log_hyperparams. This leads to hparams not showing it properly since Tensorboard wants to have all set of metrics to be the same across the experiments.
In order to see if works, you can just have "del self.hparams" at the beginning of your pl.lightiningmodule. This effectively jumps the pre-train logging and correctly shows hparams in tensorboard. Downside? Cannot load from checkpoint anymore ;)
		</comment>
		<comment id='4' author='karapostK' date='2020-05-11T15:29:54Z'>
		&lt;denchmark-link:https://github.com/justusschock&gt;@justusschock&lt;/denchmark-link&gt;
 is this related to the changes with initializing tb?
		</comment>
		<comment id='5' author='karapostK' date='2020-05-12T07:47:47Z'>
		Probably it is (we used the writers internal  for this, which seems to create a separate file). Hopefully fixed this in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1630&gt;#1630&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/1647&gt;#1647&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='karapostK' date='2020-05-12T12:22:10Z'>
		Confirmed this is fixed on master,
&lt;denchmark-link:https://colab.research.google.com/drive/1K6Gxo99O6dEbzzj_lW8jAL74OvjojV9T&gt;https://colab.research.google.com/drive/1K6Gxo99O6dEbzzj_lW8jAL74OvjojV9T&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/3640001/81690696-ab7eb800-9429-11ea-89ad-0045f1454df0.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='karapostK' date='2020-05-12T15:22:16Z'>
		The issue is not fixed yet, unfortunately.
Callinglog_hyperparams(vars(self.hparams),{"SOME_METRIC":2012}) in test_epoch_end won't log the metric in hparams. The problem is still the same. The inital log of the hparameters interfers with the last call and won't allow to log metrics in hparams!
		</comment>
		<comment id='8' author='karapostK' date='2020-05-12T15:26:40Z'>
		As you can see, no metrics are shown on tensorboard
&lt;denchmark-link:https://user-images.githubusercontent.com/64972396/81713128-c840dd00-9475-11ea-9f0f-f8f88b53d8ef.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;def test_epoch_end(self, outputs):
    avg_ndcg = np.concatenate([x['ndcg'] for x in outputs]).mean()
    avg_recall = np.concatenate([x['recall'] for x in outputs]).mean()

    tensorboard_logs = {'test/avg_ndcg': avg_ndcg, "test/avg_recall": avg_recall}
    ## Log metrics
    #self.logger.log_metrics(tensorboard_logs)

    self.logger.log_hyperparams(vars(self.hparams),tensorboard_logs)
    return tensorboard_logs
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='karapostK' date='2020-05-12T16:25:31Z'>
		ummmm. this might be a design problem in TB.

there‚Äôs never a guarantee your model ends training (cluster interrupt, crash, etc..). In those instances you still want to know the hparams
the TB design assumes your training always completes for metrics...

so, looks like we have to get hacky to get this to work correctly?
		</comment>
		<comment id='10' author='karapostK' date='2020-05-12T16:46:58Z'>
		I think they may fix this in the future but I don't think in the short time :/
&lt;denchmark-link:https://github.com/tensorflow/tensorboard/issues/3597&gt;tensorflow/tensorboard#3597&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='karapostK' date='2020-05-21T23:14:31Z'>
		&lt;denchmark-link:https://github.com/karapostK&gt;@karapostK&lt;/denchmark-link&gt;
  any luck with finding a fix/workaround ?
		</comment>
		<comment id='12' author='karapostK' date='2020-05-22T08:54:51Z'>
		&lt;denchmark-link:https://github.com/singhay&gt;@singhay&lt;/denchmark-link&gt;
 I found one but it's not very nicey. In line 840 (run_pretrain_routine function) in Trainer.py there is this code:
&lt;denchmark-code&gt;    if self.logger is not None:
        # save exp to get started
        if hasattr(ref_model, "hparams"):
            self.logger.log_hyperparams(ref_model.hparams)
&lt;/denchmark-code&gt;

which logs the hparams too soon. Simply changing this to:
&lt;denchmark-code&gt;    if self.logger is not None:
        # save exp to get started
        if hasattr(ref_model, "hparams"):
            pass
&lt;/denchmark-code&gt;

does the job. However, remember to call log_hyperparams(hparams,metrics) somewhere in your code in order to properly log the metrics. EIther using the callback on_train_end() or on test_epoch_end.
		</comment>
		<comment id='13' author='karapostK' date='2020-06-06T18:44:40Z'>
		Have the same problem and I think pl should not log hparams blindly in trainer. What's the point of logging hparams without a metric? It is been saved to disk anyway, so one could look there. If someone can only look at tensorboard (without access to the machine), then it is better to log hparams as text.
But now the question becomes, where to actually do the logging? In model checkpoint?
		</comment>
		<comment id='14' author='karapostK' date='2020-06-06T21:00:12Z'>
		most of the time we interrupt training before it completes... a lot of code won‚Äôt ‚Äúcomplete‚Äù  but you still need checkpoints and to know what you ran.
the problem is not lightning, but tensorboard for assuming that training always ends.
		</comment>
		<comment id='15' author='karapostK' date='2020-07-04T07:26:21Z'>
		+1 Thanks everyone for looking into this. I've also been searching a way to use the hparams tab in tensorboard with lightning. I think &lt;denchmark-link:https://github.com/karapostK&gt;@karapostK&lt;/denchmark-link&gt;
's solution needs an update: now one should just comment out  in  in trainer.py.
Maybe one solution is to just have a Trainer option like pre_record_hyperparams which is default True, and when False, it turns off this line: 


pytorch-lightning/pytorch_lightning/trainer/trainer.py


         Line 1077
      in
      325852c






 if self.logger is not None: 





we can change it to be:
        if self.logger is not None and self.pre_record_hyperparams:
and then the user will manually call log_hyperparams whenever they see fit, and also include the desired metrics.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;For anybody trying to solve the same issue for their code, here is how I solved it with a hack:&lt;/denchmark-h&gt;


Change if self.logger is not None: to if False: in run_pretrain_routine in trainer.py.
Before training, I have

checkpointer = ModelCheckpoint(filepath='best')
(and add it as a callback to trainer: Trainer(..., checkpoint_callback=checkpointer)).
3. After training, run:
&lt;denchmark-code&gt;logger.log_hyperparams(params=model.hparams, metrics={'val_loss': checkpointer.best_model_score.item()})
logger.save()
&lt;/denchmark-code&gt;

Then the model will appear in your hparams tab with val_loss as a metric:
&lt;denchmark-link:https://user-images.githubusercontent.com/7593028/86507452-50709e00-bda6-11ea-9812-5a2c7c68760c.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='karapostK' date='2020-08-03T19:37:52Z'>
		Closing as this is a TB issue. &lt;denchmark-link:https://github.com/versatran01&gt;@versatran01&lt;/denchmark-link&gt;
 feel free to reopen if you have any other issues!
		</comment>
	</comments>
</bug>