<bug id='5120' author='8greg8' open_date='2020-12-14T09:54:51Z' closed_time='2020-12-19T00:35:47Z'>
	<summary>Invalid usage of torch.no_grad Context manager</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Using no_grad context manager in  the following line 


pytorch-lightning/pytorch_lightning/utilities/distributed.py


         Line 210
      in
      127454a






 with torch.no_grad: 





is incorrect as the context manager is callable. Parentheses are missing.
The line should be: with torch.no_grad():
&lt;denchmark-h:h2&gt;Please reproduce using the BoringModel and post here&lt;/denchmark-h&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1snyzXx4G6QCatbs6bN2GCsTFIMdItvmm?usp=sharing&gt;https://colab.research.google.com/drive/1snyzXx4G6QCatbs6bN2GCsTFIMdItvmm?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;


No AttributeError enter
gathered_loss == loss in BoringModel

&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Note: Bugs with code are solved faster ! Colab Notebook should be made public !


IDE: Please, use our python bug_report_model.py template.


Colab Notebook: Please copy and paste the output from our environment collection script (or fill out the checklist below manually).


You can get the script and run it with:
&lt;denchmark-code&gt;wget https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/tests/collect_env_details.py
# For security purposes, please check the contents of collect_env_details.py before running it.
python collect_env_details.py
&lt;/denchmark-code&gt;


CUDA:

GPU:

Tesla P100-PCIE-16GB


available:         True
version:           10.1


Packages:

numpy:             1.18.5
pyTorch_debug:     True
pyTorch_version:   1.7.0+cu101
pytorch-lightning: 1.1.0
tqdm:              4.41.1


System:

OS:                Linux
architecture:

64bit



processor:         x86_64
python:            3.6.9
version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

Training using "ddp" accelerator with arbitrary number of gpus.
	</description>
	<comments>
		<comment id='1' author='8greg8' date='2020-12-14T09:55:34Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
	</comments>
</bug>