<bug id='740' author='S-aiueo32' open_date='2020-01-24T03:02:41Z' closed_time='2020-02-02T14:31:46Z'>
	<summary>TensorBoardLogger creates another tfevents file.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

TensorBoardLogger creates another tfevents file when fit() is running.
It seems that no metrics are logged in the redundant file, but it will be shown in TensorBoard as a run.
I don't do anything about loggers in my LightningModules.
Expected file structure:
&lt;denchmark-code&gt;|
|- save_dir
|    |- name
|         |- version_0
|               |- events.out.tfevents.1579833025.ip-xxx-xxx-xxx-xxx.17584.0
|               |- meta_tags.csv
|- train.py
&lt;/denchmark-code&gt;

Observed file structure:
&lt;denchmark-code&gt;|
|- save_dir
|    |- name
|         |- version_0
|               |- 1579833032
|                     |- events.out.tfevents.1579833032.ip-xxx-xxx-xxx-xxx.17584.1
|               |- events.out.tfevents.1579833025.ip-xxx-xxx-xxx-xxx.17584.0
|               |- meta_tags.csv
|- train.py
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce / Code sample&lt;/denchmark-h&gt;

Basic training step of PyTorch  Lightning:
# define a logger
logger = TensorBoardLogger(
    save_dir='runs',
    name=args.model
)

# define callbacks
ckpt_path = Path(logger.experiment.log_dir) / 'ckpts'
checkpoint_callback = ModelCheckpoint(filepath=ckpt_path)

# instantiate trainer
trainer = Trainer(
    logger=logger,
    checkpoint_callback=checkpoint_callback,
    gpus=args.gpus
)

# define a model
model = CoolModel(args)

# start training!
trainer.fit(model)
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch  Lightning Version (e.g., 1.0): 0.6.0
PyTorch Version (e.g., 1.0): 1.3.1
OS (e.g., Linux): Ubuntu 16.04 LTS
How you installed PyTorch (conda, pip, source): pip
Build command you used (if compiling from source):
Python version: 3.7.4
CUDA/cuDNN version: 10.1

	</description>
	<comments>
	</comments>
</bug>