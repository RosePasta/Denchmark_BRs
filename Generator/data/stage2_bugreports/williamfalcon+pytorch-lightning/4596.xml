<bug id='4596' author='stas00' open_date='2020-11-09T21:39:20Z' closed_time='2020-11-12T01:08:28Z'>
	<summary>upgrading PL via pip uninstalls pytorch-1.8</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;$ pip install pytorch-lightning -U
[...]
Installing collected packages: torch, pytorch-lightning
  Attempting uninstall: torch
    Found existing installation: torch 1.8.0.dev20201106+cu110
    Uninstalling torch-1.8.0.dev20201106+cu110:
      Successfully uninstalled torch-1.8.0.dev20201106+cu110
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

It shouldn't uninstall pytorch-1.8.
Nvidia RTX-30* don't work with pytorch &lt; 1.8.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
        - GPU:
                - GeForce RTX 3090
                - GeForce GTX 1070 Ti
        - available:         True
        - version:           10.2
* Packages:
        - numpy:             1.19.4
        - pyTorch_debug:     True
        - pyTorch_version:   1.7.0
        - pytorch-lightning: 1.0.5
        - tqdm:              4.50.2
* System:
        - OS:                Linux
        - architecture:
                - 64bit
                - ELF
        - processor:         x86_64
        - python:            3.8.5
        - version:           #57-Ubuntu SMP Thu Oct 15 10:57:00 UTC 2020
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='stas00' date='2020-11-09T21:40:08Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='stas00' date='2020-11-09T21:46:53Z'>
		This is weird, the report says I still had pytorch-1.7 after removing pytorch-1.8, how would 2 of them co-exist in the same conda setup. But still PL works just fine with pt-nightly, so it probably shouldn't force &lt;1.8, right?
		</comment>
		<comment id='3' author='stas00' date='2020-11-09T22:53:19Z'>
		&lt;denchmark-link:https://github.com/stas00&gt;@stas00&lt;/denchmark-link&gt;
 I think it is a problem with your setting  which upgraded the package along with all its dependencies
Talking about  it is there as we do not have any testing for nightly 1.8 yet, but most likely it shall be fine and there is no special need for such limitation, &lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='4' author='stas00' date='2020-11-09T23:38:45Z'>
		not that I am aware.
Is there any bug on lightning then?
		</comment>
		<comment id='5' author='stas00' date='2020-11-10T00:37:54Z'>
		
@stas00 I think it is a problem with your setting -U which upgraded the package along with all its dependencies

I'm not sure why is it a problem with my setting? I intended to upgrade PL. I wasn't expecting as a result to lose pytorch-1.8.
rtx-3090 doesn't work with pytorch &lt; 1.8.
What I'm asking: is there a reason to force torch&lt;1.8 in PL requirements? Then pip won't remove it.
&lt;denchmark-code&gt;$grep torch requirements.txt
torch&gt;=1.3,&lt;1.8
&lt;/denchmark-code&gt;

Is my thinking correct?
		</comment>
		<comment id='6' author='stas00' date='2020-11-10T01:16:23Z'>
		Just stumbled upon another related to this issue:
We recently added a PL version check to handle breaking changes in PL,
&lt;denchmark-link:https://github.com/huggingface/transformers/blob/master/examples/lightning_base.py#L36&gt;https://github.com/huggingface/transformers/blob/master/examples/lightning_base.py#L36&lt;/denchmark-link&gt;

and it doesn't look it's what we want, since I get:
&lt;denchmark-code&gt;$ python -c 'import pkg_resources; pkg_resources.require("pytorch_lightning&gt;=1.0.4")'
Traceback (most recent call last):
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/stas/anaconda3/envs/main-38/lib/python3.8/site-packages/pkg_resources/__init__.py", line 884, in require
    needed = self.resolve(parse_requirements(requirements))
  File "/home/stas/anaconda3/envs/main-38/lib/python3.8/site-packages/pkg_resources/__init__.py", line 775, in resolve
    raise VersionConflict(dist, req).with_context(dependent_req)
pkg_resources.ContextualVersionConflict: (torch 1.8.0.dev20201106+cu110 (/mnt/nvme1/anaconda3/envs/main-38/lib/python3.8/site-packages), Requirement.parse('torch&lt;1.8,&gt;=1.3'), {'pytorch-lightning'})
&lt;/denchmark-code&gt;

So it fails despite having PL 1.0.5 installed. I guess pkg_resources either doesn't do what we want then or we should have a more elaborate exception catcher. In the case of the developers we surely must be able to test the application with pytorch-nightly, so this failure is not an option.
Which way would you recommend we check for the installed PL version - w/o the above issue? I see there is pytorch_lightning.__version__ - i.e. is this public API we can rely on? Thanks.
edit: this seems to work too, without caring for broken dependencies and doesn't need to know how a package stores its version number:
&lt;denchmark-code&gt;import pkg_resources
from packaging import version
pkg = "pytorch_lightning"
min_ver = "1.0.4"
got_ver = pkg_resources.get_distribution("pytorch_lightning").version
if version.parse(got_ver) &lt; version.parse(min_ver):
    raise pkg_resources.VersionConflict(f"{pkg}&gt;={min_ver} is needed, but found {pkg}=={got_ver}")
&lt;/denchmark-code&gt;

packaging gets installed by setuptools along with pkg_resources.
		</comment>
		<comment id='7' author='stas00' date='2020-11-10T03:45:04Z'>
		When I'm using non release versions of pytorch I install lightning and other torch depending libraries with --no-deps and haven't had any issues, though I guess it would be problematic if your env is very barebones...
		</comment>
		<comment id='8' author='stas00' date='2020-11-10T03:53:00Z'>
		given that conda has been choking on itself as of recent with just a handful of packages and their dozens of dependencies, I end up re-installing the env from scratch very often :( So tracking down all the dependencies would be a job on its own.
So the bare-bones setup to run transformers dev I have to do:
&lt;denchmark-code&gt;cd /hf/transformers-master
pip install -e .[dev]
pip install -r examples/requirements.txt
&lt;/denchmark-code&gt;

which pulls in PL and its deps.
And since there is no proper support for RTX-30 series yet, I have to use nightlies for tf/pt:
&lt;denchmark-code&gt;pip install tf-nightly-gpu tensorflow-datasets -U
pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu110/torch_nightly.html -U
&lt;/denchmark-code&gt;

that's all I have in my env (and a few jupyter packages) - which still is a lot of deps.
		</comment>
		<comment id='9' author='stas00' date='2020-11-12T00:19:31Z'>
		&lt;denchmark-link:https://github.com/stas00&gt;@stas00&lt;/denchmark-link&gt;
 FYI, we have fixed the version freeze on last 1.0.6 for PyPI, and for Conda, it shall be fine for all versions...
		</comment>
		<comment id='10' author='stas00' date='2020-11-12T01:08:28Z'>
		That's wonderful, thank you, &lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
!
		</comment>
	</comments>
</bug>