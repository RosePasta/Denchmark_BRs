<bug id='3780' author='edenlightning' open_date='2020-10-02T01:21:06Z' closed_time='2020-10-06T13:13:30Z'>
	<summary>auto_scale_batch_size doesnt use 'binsearch'</summary>
	<description>
I tried to following and it's still using power:
&lt;denchmark-code&gt;#####################
# 1. Init Model
##################### 

model = LitAutoEncoder()

#####################
# 2. Init Trainer
##################### 
trainer = pl.Trainer(auto_scale_batch_size='binsearch')

#####################
# 3. Tune
#####################
trainer.fit(model)
&lt;/denchmark-code&gt;

Did we remove support? or is that a bug?
	</description>
	<comments>
		<comment id='1' author='edenlightning' date='2020-10-02T12:48:14Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 any idea?
		</comment>
		<comment id='2' author='edenlightning' date='2020-10-02T13:06:03Z'>
		&lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
 it seems that this was changed during one of the refactors.
No matter what the  argument is set to, the tuning will not run as part of  anymore.
Instead user should call .
		</comment>
		<comment id='3' author='edenlightning' date='2020-10-02T13:42:17Z'>
		&lt;denchmark-link:https://github.com/SkafteNicki&gt;@SkafteNicki&lt;/denchmark-link&gt;
 mind fix it?
&lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
 where is this example so we shall edit it also there and make it as a tested example...
		</comment>
		<comment id='4' author='edenlightning' date='2020-10-02T13:47:05Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 i am not sure if there is anything to fix, as I think the intention with the refactors was that the user should call .
cc: &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='edenlightning' date='2020-10-02T13:57:27Z'>
		I see, then just update the docs... :]
		</comment>
		<comment id='6' author='edenlightning' date='2020-10-02T14:04:17Z'>
		It actually is described correctly in the &lt;denchmark-link:https://pytorch-lightning.readthedocs.io/en/latest/training_tricks.html#auto-scaling-of-batch-size&gt;docs&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/edenlightning&gt;@edenlightning&lt;/denchmark-link&gt;
 is it an old example you have the code from?
		</comment>
		<comment id='7' author='edenlightning' date='2020-10-04T16:22:20Z'>
		sorry, wrong screenshot.
&lt;denchmark-link:https://camo.githubusercontent.com/c9ba3dc746e23063cccb4916cb6b1baa152f4d8320f635f0d31cd98e582f8378/68747470733a2f2f696d616765732e7a656e68756275736572636f6e74656e742e636f6d2f3565643632303035666462393232336162396639633831382f39613165633566652d373162632d343735612d396164662d363465383739623839303863&gt;&lt;/denchmark-link&gt;

its just using power instead of binsearch
		</comment>
		<comment id='8' author='edenlightning' date='2020-10-04T18:07:33Z'>
		I don't see anything wrong here.
Seems like you are running on mnist. Mnist has 60000 samples, and it seems like you can fit it all in gpu memory. The batch size finder never go higher than the len of the train dataloader.
In this case there will be no difference between modes (power and binsearch), as the binary search will first kick in after the power scaling fails the first time.
		</comment>
		<comment id='9' author='edenlightning' date='2020-10-05T17:38:32Z'>
		ok so i guess this is just a matter of documentation. Can you help clarify this behaviour in the docs?
		</comment>
		<comment id='10' author='edenlightning' date='2020-10-05T19:43:31Z'>
		Yes, will send i PR :]
		</comment>
	</comments>
</bug>