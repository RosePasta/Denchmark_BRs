<bug id='330' author='annemariet' open_date='2019-10-08T11:47:19Z' closed_time='2019-10-09T12:25:14Z'>
	<summary>Validation loss in progress bar printed line by line</summary>
	<description>
&lt;denchmark-h:h3&gt;Common bugs:&lt;/denchmark-h&gt;

checked.
Describe the bug
When adding a "progress_bar" key to the validation_end output, the progress bar doesn't behave as expected and prints one line per iteration, eg:
&lt;denchmark-code&gt;80%|8| 3014/3750 [00:23&lt;00:01, 516.63it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
82%|8| 3066/3750 [00:23&lt;00:01, 517.40it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
83%|8| 3118/3750 [00:23&lt;00:01, 516.65it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 85%|8| 3170/3750 [00:23&lt;00:01, 517.42it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
86%|8| 3222/3750 [00:23&lt;00:01, 517.59it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_
87%|8| 3274/3750 [00:23&lt;00:00, 518.00it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
89%|8| 3326/3750 [00:23&lt;00:00, 518.16it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
90%|9| 3378/3750 [00:23&lt;00:00, 518.45it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_
91%|9| 3430/3750 [00:23&lt;00:00, 518.36it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
93%|9| 3482/3750 [00:23&lt;00:00, 518.02it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
94%|9| 3534/3750 [00:24&lt;00:00, 517.26it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
96%|9| 3586/3750 [00:24&lt;00:00, 517.68it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
97%|9| 3638/3750 [00:24&lt;00:00, 518.08it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_ 
98%|9| 3690/3750 [00:24&lt;00:00, 518.18it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_
100%|9| 3742/3750 [00:24&lt;00:00, 518.23it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_
100%|#| 3750/3750 [00:24&lt;00:00, 518.23it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_loss=1.16]
save callback...
100%|#| 3750/3750 [00:24&lt;00:00, 152.16it/s, batch_nb=1874, epoch=14, gpu=0, loss=1.070, training_loss=0.792, val_loss=1.16]
&lt;/denchmark-code&gt;

To Reproduce
Steps to reproduce the behavior:

Take MNIST script minimal example (https://williamfalcon.github.io/pytorch-lightning/LightningModule/RequiredTrainerInterface/)
with some code to run it

&lt;denchmark-code&gt;if __name__ == "__main__":
    model = CoolModel()

    # most basic trainer, uses good defaults
    default_save_path = '/tmp/checkpoints/'
    trainer = pl.Trainer(default_save_path=default_save_path,
                         show_progress_bar=True)
    trainer.fit(model)
&lt;/denchmark-code&gt;


Change validation_end method to:

&lt;denchmark-code&gt;    def validation_end(self, outputs):
        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
        tqdm_dict = {'val_loss': avg_loss}

        return {
                'progress_bar': tqdm_dict,
                'log': {'val_loss': avg_loss},
        }
&lt;/denchmark-code&gt;


Change training_step to:

&lt;denchmark-code&gt;    def training_step(self, batch, batch_nb):
        x, y = batch
        y_hat = self.forward(x)
        loss = F.cross_entropy(y_hat, y)
        output = {
            'loss': loss,  # required
            'progress_bar': {'training_loss': loss},  # optional (MUST ALL BE TENSORS)
        }
        return output
&lt;/denchmark-code&gt;


Run the script, see error at validation time.

Note that both steps 2 and 3 are necessary to reproduce the issue, each separately would run as expected.
Expected behavior
A progress bar on a single line.
Screenshots
If applicable, add screenshots to help explain your problem.
Desktop (please complete the following information):

OS: Linux
Version
pytorch-lightning==0.5.1.3
torch==1.2.0

Additional context
Actually I ran into this issue after trying to add EarlyStopping, which asked for val_loss, which I found out was to be added via the progress_bar metrics... which was quite unexpected for me (I would have had it in "log" or direct key?)
	</description>
	<comments>
		<comment id='1' author='annemariet' date='2019-10-08T11:53:42Z'>
		I just checked if that was the version of tqdm by upgrading from tqdm==4.35.0 to tqdm==4.36.1, to no avail.
		</comment>
		<comment id='2' author='annemariet' date='2019-10-08T11:55:51Z'>
		&lt;denchmark-link:https://github.com/annemariet&gt;@annemariet&lt;/denchmark-link&gt;
 thanks for finding this. Are you using this in jupyter notebook? that might be the issue.
But on a usability note, we'll move the early stopping to use keys not in progress_bar or log. Good point!
		</comment>
		<comment id='3' author='annemariet' date='2019-10-08T11:58:53Z'>
		Hi, thanks for your quick reply. I'm running this from command line.
		</comment>
		<comment id='4' author='annemariet' date='2019-10-09T12:25:13Z'>
		&lt;denchmark-link:https://github.com/annemariet&gt;@annemariet&lt;/denchmark-link&gt;
 this can happen if you resize your terminal window during training. this is a tqdm bug, not PL bug.
Re the earlystopping, i just sent a fix yesterday where any of the keys NOT in "progress_bar" or "log" will be used for all callbacks. This is on master now.
I can reopen this if you are still having issues
		</comment>
		<comment id='5' author='annemariet' date='2019-11-22T16:09:50Z'>
		This actually still happens in Spyder, but works fine in terminal.
pytorch-lightning==0.5.3.2
spyder==3.3.6
spyder-kernels==0.5.2
tqdm==4.38.0
ipython==7.9.0
		</comment>
		<comment id='6' author='annemariet' date='2020-01-22T06:02:55Z'>
		Sorry, although I searched for it I had not seen it was already discussed here. I think its still an important open issue.
&lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/721&gt;#721&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='annemariet' date='2020-01-22T19:53:27Z'>
		I am using Jupyter notebook and this happens in there. Is there a fix for it in Jupyter notebook? I like to develop there before moving to the command line.
		</comment>
		<comment id='8' author='annemariet' date='2020-01-23T12:42:46Z'>
		&lt;denchmark-link:https://github.com/sudarshan85&gt;@sudarshan85&lt;/denchmark-link&gt;
 it is issue of TQDM, not lightning, we cannot do much about it, try to upgrade...
		</comment>
		<comment id='9' author='annemariet' date='2020-01-23T13:16:01Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 nevertheless we could think of a solution to disable the val-progress bar individually, or otherwise give flexibility
		</comment>
		<comment id='10' author='annemariet' date='2020-01-23T14:12:09Z'>
		I'm curious whether something like &lt;denchmark-link:https://github.com/fastai/fastprogress&gt;fastpgross &lt;/denchmark-link&gt;
 could be included in Lightning. There is also . I wonder whether this can be passed into Lightning for using as progress bar.
		</comment>
		<comment id='11' author='annemariet' date='2020-01-25T05:03:26Z'>
		One option is to use from tqdm.auto import tqdm this way it will use Ipython widgets when in the notebook.
		</comment>
		<comment id='12' author='annemariet' date='2020-01-25T11:43:47Z'>
		is it just like it, import another tqdm class? Would you consider making a PR?
		</comment>
		<comment id='13' author='annemariet' date='2020-01-26T00:24:32Z'>
		Sure, it's PR &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/752&gt;#752&lt;/denchmark-link&gt;
. There will be some edge cases where someone is in a notebook environment but doesn't have their widgets set up. In that case they will get a warning message about what to do and their progress bar wont show.
So could potentially add a training parameter to override this, which may help those people.
FYI: &lt;denchmark-link:https://github.com/tqdm/tqdm/blob/master/tqdm/autonotebook.py&gt;this&lt;/denchmark-link&gt;
 is how tqdm does the notebook detection
		</comment>
		<comment id='14' author='annemariet' date='2020-03-02T23:15:10Z'>
		I will close this in favour of &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/765&gt;#765&lt;/denchmark-link&gt;
 so pls let's continue the discussion there... 
		</comment>
	</comments>
</bug>