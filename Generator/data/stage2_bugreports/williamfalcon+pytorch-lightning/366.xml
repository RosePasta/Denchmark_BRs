<bug id='366' author='koustuvsinha' open_date='2019-10-14T03:58:21Z' closed_time='2019-10-19T15:27:02Z'>
	<summary>meta_tags are not populated</summary>
	<description>
meta_tags.csv only contains key,value headers and no content in the latest bleeding edge version.
	</description>
	<comments>
		<comment id='1' author='koustuvsinha' date='2019-10-14T10:58:41Z'>
		good to know. can you post a quick snippet? you shouldn't log hyperparams on your own anymore (we do it internally)
		</comment>
		<comment id='2' author='koustuvsinha' date='2019-10-14T14:34:28Z'>
		I'm using the default TestTubeLogger:
&lt;denchmark-code&gt;logger = TestTubeLogger(
        save_dir=args.model_save_dir,
        name=args.id,
        debug=False,
        create_git_tag=False
    )

    # ------------------------
    # 3 DEFINE CALLBACKS
    # ------------------------
    # model_save_path = '{}/{}/version_{}/weights'.format(args.model_save_dir, exp.name, exp.version)
    early_stop = EarlyStopping(
        monitor='val_loss',
        patience=5,
        verbose=True,
        mode='min'
    )

    ckpt_path = '{}/{}/version_{}/{}'.format(
        args.model_save_dir,
        args.id,
        logger.experiment.version,
        'weights')

    checkpoint = ModelCheckpoint(
        filepath=ckpt_path,
        save_best_only=True,
        verbose=True,
        monitor='val_loss',
        mode='min'
    )

    # ------------------------
    # 4 INIT TRAINER
    # ------------------------
    trainer = Trainer(
        # experiment=exp,
        logger=logger,
        default_save_path=args.model_save_dir,
        checkpoint_callback=checkpoint,
        early_stop_callback=early_stop,
        gpus="0" if args.debug else args.gpus,
        show_progress_bar=args.use_cluster == False,
        row_log_interval=10,
        log_save_interval=1,
        # cluster=cluster,
        # fast_dev_run=True,
        train_percent_check=0.001 if args.debug else 1.0,
        val_percent_check=0.001 if args.debug else 1.0,
        test_percent_check=0.001 if args.debug else 1.0,
        distributed_backend='dp' if args.debug else 'ddp',  #  running on local gpus
        max_nb_epochs=10 if args.debug else 1000,
        # amp_level='O2', use_amp=True,
        #overfit_pct=0.005
    )
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='koustuvsinha' date='2019-10-14T14:36:49Z'>
		When I try to test my model in a different script, it loads the meta_tags.csv which is blank:
&lt;denchmark-code&gt;tag_path = "{}/meta_tags.csv".format(experiment_path)
model = MyModel.load_from_metrics(
        weights_path=model_save_path,
        tags_csv=tag_path,
    )
&lt;/denchmark-code&gt;

Where do you save the hyperparams now? How does it get loaded to the model?
		</comment>
		<comment id='4' author='koustuvsinha' date='2019-10-15T01:11:33Z'>
		ummm. The hyperparams are still saved to meta_tags.csv. Are you using the latest lightning-version? (from pip)


In the latest version, you don't need to pass in the checkpoint or earlystopping if you're going to use those default values (lightning will add those callbacks for you with those values)


Try not accessing exp.name, etc... In the new version we discourage calling the logger and/or properties about it from outside the trainer. Try that to see if it works


		</comment>
		<comment id='5' author='koustuvsinha' date='2019-10-18T23:00:12Z'>
		&lt;denchmark-link:https://github.com/koustuvsinha&gt;@koustuvsinha&lt;/denchmark-link&gt;
 did you figure this out? pull from master and try again?
The hyperparams in all the tests are being saved correctly.
Could you add a minimal working example that duplicates this issue?
		</comment>
		<comment id='6' author='koustuvsinha' date='2019-10-19T15:17:20Z'>
		&lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 the issue persists, the meta_tags are still not populated. I re-installed lightning from git. (0.5.2.1) I also tried using default loggers and callbacks :
&lt;denchmark-code&gt;trainer = Trainer(
        # experiment=exp,
        # logger=logger,
        default_save_path=args.model_save_dir,
        # checkpoint_callback=checkpoint,
        # early_stop_callback=early_stop,
        gpus="0" if args.debug else args.gpus,
        show_progress_bar=args.use_cluster == False,
        row_log_interval=10,
        log_save_interval=1,
        # cluster=cluster,
        # fast_dev_run=True,
        train_percent_check=0.001 if args.debug else args.train_per_check,
        val_percent_check=0.001 if args.debug else args.val_per_check,
        test_percent_check=0.001 if args.debug else args.test_per_check,
        distributed_backend='dp' if args.debug else 'ddp',  #  running on local gpus
        max_nb_epochs=10 if args.debug else 1000,
        # amp_level='O2', use_amp=True,
        #overfit_pct=0.005
    )

trainer.fit(model)
trainer.test()
&lt;/denchmark-code&gt;

When using default loggers, lightning creates a folder lightning_logs within my save directory which contains the version named folders. Changed the save directory too but still the same issue.
		</comment>
		<comment id='7' author='koustuvsinha' date='2019-10-19T15:27:01Z'>
		OK i figured the issue. It seems you need to keep the arguments in the variable named self.hparams, where as I was just saving them in self.args. I didn't see this in the docs, details like this are easy to miss I guess.
Can you instead pass the arguments to the Trainer object in future so as to not rely on variable names?
		</comment>
		<comment id='8' author='koustuvsinha' date='2019-10-19T16:10:31Z'>
		i’d love to but last time i dug into this it didn’t seem like pythonr suported it? something about local that might have that info. Know of a way to do that?  I agree it’s a much better approach.
&lt;denchmark-link:https://github.com/neggert&gt;@neggert&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='koustuvsinha' date='2019-10-19T18:38:58Z'>
		What i tried to convey was instead of passing the args to the model, pass it as a config dictionary in trainer itself. (or both, to help with backwards compatibility). As an use case:
&lt;denchmark-code&gt;trainer = Trainer(config=vars(args))
&lt;/denchmark-code&gt;

You also may want to use &lt;denchmark-link:https://github.com/mewwts/addict&gt;addict&lt;/denchmark-link&gt;
 to add a simple sugar to access the config variables within the model in dot notation:
&lt;denchmark-code&gt;args = self.trainer.config
# use your args
x = torch.randn((args.ndim, args.ndim))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='koustuvsinha' date='2019-10-21T15:23:08Z'>
		FWIW, this is documented &lt;denchmark-link:https://williamfalcon.github.io/pytorch-lightning/Trainer/Logging/#save-a-snapshot-of-all-hyperparameters&gt;here&lt;/denchmark-link&gt;
, but I agree it's easy to miss. I think passing the args to the trainer would require us to let the trainer initialize the model. I don't see anything inherently wrong with that, but it's substantially different from the current API.
		</comment>
	</comments>
</bug>