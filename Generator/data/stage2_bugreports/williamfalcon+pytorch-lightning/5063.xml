<bug id='5063' author='blisc' open_date='2020-12-10T16:57:27Z' closed_time='2020-12-16T21:07:18Z'>
	<summary>Self.log with multiple Optimizers errors out in 1.1.0 but works in 1.0.8</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

self.log results in the following error:
&lt;denchmark-code&gt;  File "/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/connectors/logger_connector/epoch_result_store.py", line 207, in auto_reduce_results_on_epoch_end
    opt_outputs = epoch_metrics[opt_idx]
&lt;/denchmark-code&gt;

when the following conditions are satisfied:

There are two optimizers
1 of the optimizers does not log anything in 1 training epoch

Note, that this bug is not present in v1.0.8 and was introduced in 1.1.0
&lt;denchmark-h:h2&gt;Please reproduce using the BoringModel and post here&lt;/denchmark-h&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1MkMmuzTmZU2hkPjoEQ8Mwd4qSh168QKn?usp=sharing&gt;https://colab.research.google.com/drive/1MkMmuzTmZU2hkPjoEQ8Mwd4qSh168QKn?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

See notebook
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The same behavious as 1.0.8.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

See notebook.
&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

See notebook.
	</description>
	<comments>
		<comment id='1' author='blisc' date='2020-12-11T21:29:09Z'>
		&lt;denchmark-link:https://github.com/tchaton&gt;@tchaton&lt;/denchmark-link&gt;
 mind taking a look?
		</comment>
	</comments>
</bug>