<bug id='3264' author='Erlemar' open_date='2020-08-30T09:13:54Z' closed_time='2020-09-23T01:27:16Z'>
	<summary>Incorrect aggregation when logging predictions into EvalResult with distributed_backend DP</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

It it possible to log some data in EvalResult like this:
&lt;denchmark-code&gt;result = pl.EvalResult(checkpoint_on=val_loss)
result.y_hat = y_hat.float()
&lt;/denchmark-code&gt;

Suppose I log some value with dimensions (32, 10) - batch size 32 and 10 classes. And I have N samples in total.
If distributed_backend is None, in validation_epoch_end outputs.y_hat.shape is (N, 10)
If distributed_backend is ddp, in validation_epoch_end outputs.y_hat.shape is (N, 10)
But if distributed_backend is dp, in validation_epoch_end outputs.y_hat.shape is (N) - the values are averaged over samples.
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/16NQaMTho5gI0URzgh3CNsZvXmHHyynvh?usp=sharing&gt;https://colab.research.google.com/drive/16NQaMTho5gI0URzgh3CNsZvXmHHyynvh?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Erlemar' date='2020-09-23T01:27:15Z'>
		Sorry about the delay! was wrapping up all the refactors :)
no, you have to log directly with the .log call...
result = pl.EvalResult(checkpoint_on=val_loss)
result.log('my_metric_name', y_hat)
		</comment>
	</comments>
</bug>