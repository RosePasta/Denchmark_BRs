<bug id='2612' author='Guitaricet' open_date='2020-07-14T23:32:33Z' closed_time='2020-09-23T14:45:41Z'>
	<summary>load_from_checkpoint raises TypeError when **kwargs is provided</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

The issue happens in case of .save_hyperparameters() is not used.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior: follow code sample
&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import os

import torch
from torch.nn import functional as F
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
from torchvision import transforms

import pytorch_lightning as pl
from pytorch_lightning.core.lightning import LightningModule

class LitModel(LightningModule):

    def __init__(self, some_stuff):
        super().__init__()
        self.l1 = torch.nn.Linear(28 * 28, 10)

    def forward(self, x):
        return torch.relu(self.l1(x.view(x.size(0), -1)))

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y)
        tensorboard_logs = {'train_loss': loss}
        return {'loss': loss, 'log': tensorboard_logs}

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=0.001)

    def train_dataloader(self):
        dataset = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())
        loader = DataLoader(dataset, batch_size=32, num_workers=4, shuffle=True)
        return loader


model = LitModel(42)
trainer = pl.Trainer(fast_dev_run=True)
trainer.fit(model)

trainer.save_checkpoint('checkpoint.pl')
model = LitModel.load_from_checkpoint('checkpoint.pl', some_stuff=42)

# TypeError: __init__() got multiple values for argument 'some_stuff'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Model is able to load
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


PyTorch Version (e.g., 1.0): 1.5.0
OS (e.g., Linux): Linux
How you installed PyTorch (conda, pip, source): pip
Build command you used (if compiling from source):
Python version: 3.7.6
CUDA/cuDNN version: N/A
GPU models and configuration: N/A
Any other relevant information:

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

I noticed that loading starts working if you call save_hyperparameters. It also works correctly if some_stuff is not inside save_hyperparameters, e.g.  if you change __init__ to this one
&lt;denchmark-code&gt;    def __init__(self, some_stuff, lr=42):
        super().__init__()
        self.l1 = torch.nn.Linear(28 * 28, 10)
        self.lr = 42
        self.save_hyperparameters('lr')
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Guitaricet' date='2020-07-14T23:33:38Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='Guitaricet' date='2020-07-15T22:33:18Z'>
		ok, it seems a bit tricky how to correctly interpret method arguments and still keep back-compatibility...
		</comment>
		<comment id='3' author='Guitaricet' date='2020-07-15T22:46:14Z'>
		Maybe let's wait until the next major version to fix it, but document the behaviour.
It's not a bug, if it is documented, right? üòÜ
And in my (reasonably complex) case it was resolved when I added .save_hyperparameters() at the end of __init__. No other code changes were needed.
		</comment>
		<comment id='4' author='Guitaricet' date='2020-07-16T18:04:30Z'>
		Similar &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2550&gt;#2550&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='5' author='Guitaricet' date='2020-07-16T23:10:19Z'>
		Yes, exactly the same issue
		</comment>
		<comment id='6' author='Guitaricet' date='2020-09-15T00:00:48Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='7' author='Guitaricet' date='2020-09-23T14:45:40Z'>
		&lt;denchmark-link:https://github.com/Borda&gt;@Borda&lt;/denchmark-link&gt;
 please check if issue persists on master
		</comment>
	</comments>
</bug>