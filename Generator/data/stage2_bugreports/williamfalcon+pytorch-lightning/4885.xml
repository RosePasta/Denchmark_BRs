<bug id='4885' author='pierresegonne' open_date='2020-11-28T08:27:21Z' closed_time='2020-11-28T14:47:40Z'>
	<summary>Tensorboard log_graph does not seem to do anything</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

While exploring Tensorboard's logging features I experimented with the  function, that was added after &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/issues/2915&gt;#2915&lt;/denchmark-link&gt;
 (issue) and &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3003&gt;#3003&lt;/denchmark-link&gt;
 (PR).
According to the docs the function has the following signature log_graph(model, input_array=None)
So I tried to call it doing, inside my PL module:
...

def __init__(self, ..):
    ...
    self.example_input_array = torch.rand((10, self.input_dim))
    ...

def test_step(self, batch, batch_idx):
    ...
    self.logger.log_graph(self)
    ...
without any success. No error message is displayed and Tensorboard does not recognise any logged graph.
Nevertheless if I change my code to:
...

def __init__(self, ..):
    ...
    self.example_input_array = torch.rand((10, self.input_dim))
    ...

def test_step(self, batch, batch_idx):
    ...
    self.logger.experiment.add_graph(self, self.example_input_array)
    ...
Which is what the log_graph function is supposed to call, then I do see my graph appearing in Tensorboard.
&lt;denchmark-h:h2&gt;Please reproduce using the BoringModel and post here&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Execute the following gist
&lt;denchmark-link:https://gist.github.com/pierresegonne/091a1d0e163f01a6f1c944c1bc4e9cf6&gt;https://gist.github.com/pierresegonne/091a1d0e163f01a6f1c944c1bc4e9cf6&lt;/denchmark-link&gt;

And change lines 123/124 to see the graph being logged or not
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;* CUDA:
        - GPU:
        - available:         False
        - version:           None
* Packages:
        - numpy:             1.19.2
        - pyTorch_debug:     True
        - pyTorch_version:   1.7.0
        - pytorch-lightning: 1.0.2
        - tqdm:              4.50.2
* System:
        - OS:                Darwin
        - architecture:
                - 64bit
                - 
        - processor:         i386
        - python:            3.8.6
        - version:           Darwin Kernel Version 19.6.0: Sun Jul  5 00:43:10 PDT 2020; root:xnu-6153.141.1~9/RELEASE_X86_64
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='pierresegonne' date='2020-11-28T08:28:06Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='pierresegonne' date='2020-11-28T13:37:03Z'>
		you need to set log_graph=True in TensorboardLogger instance. It's False by default.



pytorch-lightning/pytorch_lightning/loggers/tensorboard.py


         Line 79
      in
      f677efe






 log_graph: bool = False, 








pytorch-lightning/pytorch_lightning/loggers/tensorboard.py


        Lines 195 to 207
      in
      f677efe






 def log_graph(self, model: LightningModule, input_array=None): 



 if self._log_graph: 



 if input_array is None: 



 input_array = model.example_input_array 



 



 if input_array is not None: 



 input_array = model.transfer_batch_to_device(input_array, model.device) 



 self.experiment.add_graph(model, input_array) 



 else: 



 rank_zero_warn('Could not log computational graph since the' 



 ' `model.example_input_array` attribute is not set' 



 ' or `input_array` was not given', 



 UserWarning) 





		</comment>
		<comment id='3' author='pierresegonne' date='2020-11-28T14:47:38Z'>
		Oh right, I don't know how I missed that! Thanks a lot!
		</comment>
	</comments>
</bug>