<bug id='4561' author='miccio-dk' open_date='2020-11-07T00:08:28Z' closed_time='2020-12-11T21:36:33Z'>
	<summary>unreachable (dead) code in Trainer.test() and/or ambiguous behaviour</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

When passing a datamodule and a checkpoint to , the code at &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L735&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/trainer.py#L735&lt;/denchmark-link&gt;
 is effectively unreachable. This is because, when , the code in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/connectors/data_connector.py#L114&gt;https://github.com/PyTorchLightning/pytorch-lightning/blob/master/pytorch_lightning/trainer/connectors/data_connector.py#L114&lt;/denchmark-link&gt;
 raises:

AttributeError: 'NoneType' object has no attribute 'train_dataloader'

Note that this only happens on a "fresh" instance of the Trainer (i.e. one where fit() hasn't been called).
If we also pass a model, it will instead ignore the checkpoint provided and use the current model weights.
&lt;denchmark-h:h2&gt;Please reproduce using my copy of the notebook&lt;/denchmark-h&gt;

In the cell with test_stuff(tmpdir, checkpoint_path), replace the last two lines (trainer.test()) to show the two behaviors.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

Since I suspect that the two scenarios I mentioned are "illegal" (passing both a checkpoint and a model, passing only a checkpoint to a fresh instance of a trainer), I would expect a warning to be issued (or even better, a MisconfigurationException), suggesting the user to use ModelModule.load_from_checkpoint() for the desired outcome.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Note: Bugs with code are solved faster ! Colab Notebook should be made public ! ‚úÖ

Colab Notebook: Please copy and paste the output from our environment collection script (or fill out the checklist below manually).

&lt;denchmark-code&gt;* CUDA:
	- GPU:
		- Tesla T4
	- available:         True
	- version:           10.1
* Packages:
	- numpy:             1.18.5
	- pyTorch_debug:     True
	- pyTorch_version:   1.7.0+cu101
	- pytorch-lightning: 1.0.0
	- tqdm:              4.41.1
* System:
	- OS:                Linux
	- architecture:
		- 64bit
		- 
	- processor:         x86_64
	- python:            3.6.9
	- version:           #1 SMP Thu Jul 23 08:00:38 PDT 2020
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

Thanks for this amazing library :)
	</description>
	<comments>
		<comment id='1' author='miccio-dk' date='2020-11-07T17:45:24Z'>
		If we modify the code in your link a little bit, we could get around this issue:
        model = model or self.get_model()
        self.data_connector.attach_datamodule(model, datamodule, 'test')

        if ckpt_path is None:
            results = self.__test_given_model(model, test_dataloaders)
        else:
            results = self.__test_using_best_weights(ckpt_path, test_dataloaders)
What do you think, is this better?
Any edge cases I'm missing?
		</comment>
		<comment id='2' author='miccio-dk' date='2020-12-09T23:59:12Z'>
		This issue has been automatically marked as stale because it hasn't had any recent activity. This issue will be closed in 7 days if no further activity occurs. Thank you for your contributions, Pytorch Lightning Team!
		</comment>
		<comment id='3' author='miccio-dk' date='2020-12-11T21:36:33Z'>
		Closing for now, feel free to reopen if needed!
		</comment>
	</comments>
</bug>