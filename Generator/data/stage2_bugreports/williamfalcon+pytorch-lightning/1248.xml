<bug id='1248' author='thegyro' open_date='2020-03-26T15:05:35Z' closed_time='2020-03-27T02:07:23Z'>
	<summary>Disabling validation with val_percent_check=0.0 not working</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I am trying to train on a small subset of data by settting train_percent_check and val_percent_check flags. I am not able to disable validation by setting ver_percent_check=0.0. Despite it being set to 0, validation_epoch_end is executed.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior: Running the MNIST model on the Google Colab link
&lt;denchmark-link:https://user-images.githubusercontent.com/4838833/77662280-0c256480-6f52-11ea-873c-7a9d41bf347c.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;mnist_model = MNISTModel()

# most basic trainer, uses good defaults (1 gpu)
trainer = pl.Trainer(gpus=1, val_percent_check=0.0, train_percent_check=0.1)    
trainer.fit(mnist_model)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

I expected the validation_epoch_end to not be invoked but it is.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Running on Google Colab with the sample MNIST tutorial
	</description>
	<comments>
		<comment id='1' author='thegyro' date='2020-03-26T15:06:26Z'>
		Hi! thanks for your contribution!, great first issue!
		</comment>
		<comment id='2' author='thegyro' date='2020-03-26T17:40:55Z'>
		I can confirm there is an issue. I tested it with the pl_example gpu template on master. I get a different error:
&lt;denchmark-code&gt;...
  File "C:\Users\aeduw\Documents\Repositories\pytorch-lightning\pytorch_lightning\trainer\training_loop.py", line 437, in run_training_epoch
    self.run_evaluation(test_mode=self.testing)
  File "C:\Users\aeduw\Documents\Repositories\pytorch-lightning\pytorch_lightning\trainer\evaluation_loop.py", line 368, in run_evaluation
    eval_results = self.evaluate(self.model, dataloaders, max_batches, test_mode)
  File "C:\Users\aeduw\Documents\Repositories\pytorch-lightning\pytorch_lightning\trainer\evaluation_loop.py", line 312, in evaluate
    eval_results = model.validation_epoch_end(outputs)
  File "C:\Users\aeduw\Documents\Repositories\pytorch-lightning\pl_examples\basic_examples\lightning_module_template.py", line 190, in validation_epoch_end
    val_loss_mean /= len(outputs)
ZeroDivisionError: division by zero
&lt;/denchmark-code&gt;

I think I know how to fix it and will submit a PR soon + unit test.
		</comment>
		<comment id='3' author='thegyro' date='2020-03-27T02:26:58Z'>
		&lt;denchmark-link:https://github.com/thegyro&gt;@thegyro&lt;/denchmark-link&gt;
 This should now be fixed. I tested it in MNIST colab by installing PL from master branch:

Feel free to reopen if there are unresolved issues.
		</comment>
	</comments>
</bug>