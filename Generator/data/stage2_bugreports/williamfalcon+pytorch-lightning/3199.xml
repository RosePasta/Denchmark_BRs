<bug id='3199' author='Lucas-Steinmann' open_date='2020-08-26T17:53:25Z' closed_time='2020-09-18T21:08:06Z'>
	<summary>Early Stopping + result dictionary + no validation not working.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

The case where the user does not use validation and returns a dictionary (instead of a TrainResult) during training does not work in combination with early stopping.
The test case which should check this is here:



pytorch-lightning/tests/callbacks/test_early_stopping.py


        Lines 136 to 159
      in
      bd35c86






 def test_early_stopping_no_val_step(tmpdir): 



 """Test that early stopping callback falls back to training metrics when no validation defined.""" 



 



 class CurrentModel(EvalModelTemplate): 



 def training_step(self, *args, **kwargs): 



 output = super().training_step(*args, **kwargs) 



 output.update({'my_train_metric': output['loss']})  # could be anything else 



 return output 



 



 model = CurrentModel() 



 model.validation_step = None 



 model.val_dataloader = None 



 



 stopping = EarlyStopping(monitor='my_train_metric', min_delta=0.1) 



 trainer = Trainer( 



 default_root_dir=tmpdir, 



 early_stop_callback=stopping, 



 overfit_batches=0.20, 



 max_epochs=2, 



     ) 



 result = trainer.fit(model) 



 



 assert result == 1, 'training failed to complete' 



 assert trainer.current_epoch &lt; trainer.max_epochs 





The check in the last line is wrong. It should actually compare:
    assert trainer.current_epoch &lt; trainer.max_epochs - 1
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Fix the test case
Run tests.

&lt;denchmark-h:h4&gt;Code sample&lt;/denchmark-h&gt;

I guess using the test case is simpler and easier.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

That is an interesting question indeed. Possibilities are:

Test case should pass with correct comparison
The docs and  @williamFalcon in #3193 (comment) suggest that only 'loss' should work.

So before fixing this issue, it should be settled what the expected behavior is.
If you tell me, I'm happy to help.
I could also include it in the pull request where I already tried to bring the docs in line with the test cases.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;


CUDA:

GPU:

GeForce GTX 1080 Ti


available:         True
version:           10.1


Packages:

numpy:             1.19.1
pyTorch_debug:     False
pyTorch_version:   1.6.0
pytorch-lightning: 0.9.1dev
tensorboard:       2.2.0
tqdm:              4.48.2


System:

OS:                Linux
architecture:

64bit
ELF


processor:         x86_64
python:            3.8.3
version:           #113~16.04.1-Ubuntu SMP Fri Jul 10 04:37:08 UTC 2020



&lt;denchmark-h:h3&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='Lucas-Steinmann' date='2020-08-26T19:00:04Z'>
		&lt;denchmark-link:https://github.com/Lucas-Steinmann&gt;@Lucas-Steinmann&lt;/denchmark-link&gt;
 mind sending a PR for this?
		</comment>
		<comment id='2' author='Lucas-Steinmann' date='2020-08-26T19:41:11Z'>
		I'd love to, but what is the intended behavior?
Possibility 1, 2, or doesn't it matter?
Maybe we should wait on &lt;denchmark-link:https://github.com/williamFalcon&gt;@williamFalcon&lt;/denchmark-link&gt;
 answer, since he already expressed his opinion.
		</comment>
		<comment id='3' author='Lucas-Steinmann' date='2020-08-27T10:31:29Z'>
		There is a third possibility, which is suggested by the code which would have to be changed:



pytorch-lightning/pytorch_lightning/callbacks/early_stopping.py


         Line 169
      in
      4d98419






 # early stopping can also work in the train loop when there is no val loop and when using structured results 





This comment says, that the current behavior is correct. (assuming "structured result" means Result object)
So either code, docs or test is correct and the other two have to be adjusted. :)
		</comment>
		<comment id='4' author='Lucas-Steinmann' date='2020-08-27T14:10:02Z'>
		if you're not using the trainresult then the key 'loss' needs to be present
All of these are equivalent
return loss

return {'loss': loss}

return TrainResult(minimize=loss)

return TrainResult(loss)
But the recommended way is:
&lt;denchmark-code&gt;return TrainResult(loss)
&lt;/denchmark-code&gt;

We're moving away from plain dictionaries (TrainResult is just a dict also, but adds type checking)
		</comment>
		<comment id='5' author='Lucas-Steinmann' date='2020-08-27T14:18:33Z'>
		But return {'loss': loss} doesn't work with early stopping.
Also the test, which suggests that any key should work still contradicts you.
Furthermore the test is still wrong because the last line does not actually check whether early stopping was triggered (off-by-one error)
		</comment>
		<comment id='6' author='Lucas-Steinmann' date='2020-08-28T16:11:06Z'>
		&lt;denchmark-link:https://github.com/Lucas-Steinmann&gt;@Lucas-Steinmann&lt;/denchmark-link&gt;
 reopening this then!
		</comment>
		<comment id='7' author='Lucas-Steinmann' date='2020-09-01T13:24:41Z'>
		Just to be clear. The next step is for you (the project owners) to decide what the correct behaviour is:

The docs (only dicts with 'loss' key should work with early stopping): Then we have to fix the code and the tests.
The code (early stopping should only work with TrainResult): Then we have to remove the test and fix the docs
The test (early stopping should work with dicts and any key): Then we have to fix the code and the docs.

I would love to help but I think it is not for me to decide what is correct.
If you pick one, I'll implement it.
		</comment>
		<comment id='8' author='Lucas-Steinmann' date='2020-09-01T13:33:04Z'>
		The correct behavior is neither of the above...

if using dicts, it should work with whatever you put in the monitor argument of the EarlyStopping or ModelCheckpoint.

EarlyStopping(monitor='jiraffe')

# must have this key
return {'jiraffe': x}

If using results it should work with whatever is in the early_stop_on argument:

acc = ...
loss = ...
f1 = ...

# pick whatever you want to early stop on
key_i_care_about = f1 or loss or acc
result = pl.TrainResult(early_stop_on=key_i_care_about)
If you ALSO pass the key in the EvalResult then the EvalResult takes precedence...
def training_step(...):
   # early stop on has NO effect because you ALSO have one in validation_step
    result = TrainResult(early_stop_on=acc)

def validation_step(...)
    my_val_loss = MSE(y, y_hat)
    result = EvalResult(early_stop_on=my_val_loss)
Finally, I'm pretty sure this is how it works today given that I personally implemented these and wrote a ton of tests...
So, my question is:

does it not work like I described? then we need to fix the bugs
if it does work, then we need to clean up the docs to explain this better.

		</comment>
		<comment id='9' author='Lucas-Steinmann' date='2020-09-01T13:44:16Z'>
		Ok. 1. currently does not work (atleast a few days ago, when I wrote the issue, see my minimal example here: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3193#discussion_r478517184&gt;#3193 (comment)&lt;/denchmark-link&gt;
)
There is a test, which exactly checks 1.  but has an off-by-one error and would actually fail if the error is fixed (see my first comment on this issue).
If I understand the docs correctly, they currently say it should only work with 'loss' key. Maybe it was meant to say the default behaviour is that it only works with 'loss' key: 


pytorch-lightning/docs/source/results.rst


         Line 109
      in
      3910ad0






  # early stop + checkpoint can only use the `loss` when done manually via dictionaries 





I think the bug in the code is located here, where it only checks for the early_stop_on key:



pytorch-lightning/pytorch_lightning/callbacks/early_stopping.py


        Lines 170 to 173
      in
      3910ad0






 train_es_key = 'early_stop_on' 



 if trainer.callback_metrics.get(train_es_key, None) is not None: 



 self.monitor = train_es_key 



 should_check_early_stop = True 





		</comment>
		<comment id='10' author='Lucas-Steinmann' date='2020-09-04T15:27:20Z'>
		To prevent misunderstanding:
&lt;denchmark-code&gt;EarlyStopping(monitor='jiraffe')

# must have this key
return {'jiraffe': x}
&lt;/denchmark-code&gt;

the return {'jiraffe': x} is in training_step()?
I've implemented a pull request. &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/3347&gt;#3347&lt;/denchmark-link&gt;
.
It first corrects the test, which then fails. Then I fixed the issue.
Afterwards another bug was unveiled, which I fixed in the subsequent commits.
Then I also updated the docs.
		</comment>
	</comments>
</bug>