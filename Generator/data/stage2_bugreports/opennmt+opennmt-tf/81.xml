<bug id='81' author='Dagamies' open_date='2018-03-09T05:24:53Z' closed_time='2018-03-18T18:59:29Z'>
	<summary>FP16: ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16:</summary>
	<description>
Hi,
when trying to run FP16 model on Titan V &amp; Tensorflow 1.6rc1 I get following (both master and tf-1.6 branch):
CUDA_VISIBLE_DEVICES=1 python -m bin.main train --model config/models/nmt_ari_medium_fp16.py --config /data/a1/config/ari-defaults.yml /data/a1/config/cfg-anon16.yml
&lt;denchmark-code&gt;/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
2018-03-09 07:05:16.935002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: Graphics Device major: 7 minor: 0 memoryClockRate(GHz): 1.455
pciBusID: 0000:04:00.0
totalMemory: 11.78GiB freeMemory: 8.53GiB
2018-03-09 07:05:16.935032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-03-09 07:05:17.738979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-03-09 07:05:17.739003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-03-09 07:05:17.739009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-03-09 07:05:17.739214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/device:GPU:0 with 8225 MB memory) -&gt; physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:04:00.0, compute capability: 7.0)
INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f62269c2950&gt;, '_evaluation_master': '', '_save_checkpoints_steps': 5000, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 50, '_model_dir': '/data/a1/data_anon16', '_save_summary_steps': 50}
INFO:tensorflow:Calling model_fn.
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/home/ari/fp16/OpenNMT-tf/bin/main.py", line 135, in &lt;module&gt;
    main()
  File "/home/ari/fp16/OpenNMT-tf/bin/main.py", line 118, in main
    runner.train()
  File "opennmt/runner.py", line 140, in train
    train_spec.input_fn, hooks=train_spec.hooks, max_steps=train_spec.max_steps)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 824, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "opennmt/models/model.py", line 78, in _model_fn
    _loss_op, features_shards, labels_shards, params, mode, config)
  File "opennmt/utils/parallel.py", line 148, in __call__
    outputs.append(funs[i](*args[i], **kwargs[i]))
  File "opennmt/models/model.py", line 41, in _loss_op
    logits, _ = self._build(features, labels, params, mode, config)
  File "opennmt/models/sequence_to_sequence.py", line 178, in _build
    memory_sequence_length=encoder_sequence_length)
  File "opennmt/decoders/rnn_decoder.py", line 111, in decode
    dtype=inputs.dtype)
  File "opennmt/decoders/rnn_decoder.py", line 312, in _build_cell
    memory_sequence_length=memory_sequence_length)
  File "opennmt/decoders/rnn_decoder.py", line 248, in _build_attention_mechanism
    num_units, memory, memory_sequence_length=memory_sequence_length)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py", line 408, in __init__
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py", line 215, in __init__
    self.memory_layer(self._values) if self.memory_layer  # pylint: disable=not-callable
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py", line 709, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/core.py", line 151, in call
    inputs = ops.convert_to_tensor(inputs, dtype=self.dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 950, in convert_to_tensor
    as_ref=False)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1040, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 883, in _TensorTensorConversionFunction
    (dtype.name, t.dtype.name, str(t)))
ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor("seq2seq/parallel_0/seq2seq/decoder/LuongAttention/mul:0", shape=(?, ?, 1024), dtype=float16, device=/device:GPU:0)'

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Dagamies' date='2018-03-09T09:46:30Z'>
		Hello,
Looks like they changed the  behavior in TensorFlow 1.5 (cf. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/12007&gt;tensorflow/tensorflow#12007&lt;/denchmark-link&gt;
).
I pushed a &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/commit/e4742dfa5fa0657228cc954e647af2c3979dd4eb&gt;fix&lt;/denchmark-link&gt;
 in the branch  as  is still compatible with TensorFlow 1.4. You could also apply this small fix manually on :
diff --git a/opennmt/decoders/rnn_decoder.py b/opennmt/decoders/rnn_decoder.py
index 1824574..08f4bea 100644
--- a/opennmt/decoders/rnn_decoder.py
+++ b/opennmt/decoders/rnn_decoder.py
@@ -245,7 +245,7 @@ def _build_attention_mechanism(attention_mechanism,
   """Builds an attention mechanism from a class or a callable."""
   if inspect.isclass(attention_mechanism):
     return attention_mechanism(
-        num_units, memory, memory_sequence_length=memory_sequence_length)
+        num_units, memory, memory_sequence_length=memory_sequence_length, dtype=memory.dtype)
   elif callable(attention_mechanism):
     return attention_mechanism(
         num_units, memory, memory_sequence_length)
Related to &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/issues/57&gt;#57&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='Dagamies' date='2018-03-09T11:36:35Z'>
		Thanks. This solved the issue nicely. Performance using FP16 seems to be very poor tough:
Model with 4x1000 FP32:
&lt;denchmark-code&gt;2018-03-08 21:39:08.754636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9844 MB memory) -&gt; physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:02:00.0, compute capability: 7.0)
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1 into data_anon/model.ckpt.
INFO:tensorflow:loss = 773.9167, step = 0
INFO:tensorflow:global_step/sec: 1.40759
INFO:tensorflow:global_step/sec: 1.82778
INFO:tensorflow:words_per_sec/features: 2693.69
INFO:tensorflow:words_per_sec/labels: 1440.92
INFO:tensorflow:loss = 252.10657, step = 100 (62.879 sec)
INFO:tensorflow:global_step/sec: 0.956827
INFO:tensorflow:words_per_sec/features: 864.375
INFO:tensorflow:words_per_sec/labels: 443.794
INFO:tensorflow:global_step/sec: 0.606042
INFO:tensorflow:words_per_sec/features: 1306.99
INFO:tensorflow:words_per_sec/labels: 263.374
INFO:tensorflow:loss = 140.20569, step = 200 (134.759 sec)
INFO:tensorflow:global_step/sec: 0.533042
INFO:tensorflow:words_per_sec/features: 2120.19
INFO:tensorflow:words_per_sec/labels: 173.388
INFO:tensorflow:global_step/sec: 0.482318
INFO:tensorflow:words_per_sec/features: 1942.35
INFO:tensorflow:words_per_sec/labels: 210.117
INFO:tensorflow:loss = 122.355606, step = 300 (197.467 sec)
INFO:tensorflow:global_step/sec: 1.29127
INFO:tensorflow:words_per_sec/features: 5189.53
INFO:tensorflow:words_per_sec/labels: 3316.11
&lt;/denchmark-code&gt;

I had to decrease size to 4x800 and start learning rate from 0.1 for FP16 (got NAN), as  you can see the performance is quite much slower for some reason:
&lt;denchmark-code&gt;INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 1 into /data/a1/data_anon16/model.ckpt.
INFO:tensorflow:loss = 656.0, step = 0
INFO:tensorflow:global_step/sec: 0.352035
INFO:tensorflow:global_step/sec: 0.313872
INFO:tensorflow:words_per_sec/features: 1059.78
INFO:tensorflow:words_per_sec/labels: 455.767
INFO:tensorflow:loss = 177.5, step = 100 (301.333 sec)
INFO:tensorflow:global_step/sec: 0.838981
INFO:tensorflow:words_per_sec/features: 1112.54
INFO:tensorflow:words_per_sec/labels: 516.863
INFO:tensorflow:global_step/sec: 0.651511
INFO:tensorflow:words_per_sec/features: 635.454
INFO:tensorflow:words_per_sec/labels: 296.305
INFO:tensorflow:loss = 229.8, step = 200 (136.342 sec)
INFO:tensorflow:global_step/sec: 0.36005
INFO:tensorflow:words_per_sec/features: 188.415
INFO:tensorflow:words_per_sec/labels: 36.0844
INFO:tensorflow:global_step/sec: 0.232841
INFO:tensorflow:words_per_sec/features: 666.391
INFO:tensorflow:words_per_sec/labels: 82.2115
INFO:tensorflow:loss = 500.8, step = 300 (353.608 sec)
INFO:tensorflow:global_step/sec: 0.179984
INFO:tensorflow:words_per_sec/features: 480.043
INFO:tensorflow:words_per_sec/labels: 63.2896
INFO:tensorflow:global_step/sec: 0.295495
INFO:tensorflow:words_per_sec/features: 793.918
INFO:tensorflow:words_per_sec/labels: 296.535
INFO:tensorflow:loss = 267.8, step = 400 (447.010 sec)
INFO:tensorflow:global_step/sec: 0.335713
&lt;/denchmark-code&gt;

TF 1.6 has been built from the sources with CUDA 9.1 and CUDNN 7. Any ideas? My intuition is that FP16 should not at least be slower than FP32 on Volta (Titan V)...
		</comment>
		<comment id='3' author='Dagamies' date='2018-03-09T11:57:20Z'>
		I don't have much experience with FP16 but I think TensorFlow has still a limited support for it, especially for RNNs.
Also, OpenNMT-tf does not do anything smart: all data types are either FP16 or FP32. It's likely that some parts of the network and the trainable variables should run on a higher precision for accuracy or efficiency.
To get started, we should do some benchmarks on isolated network parts to see where a speedup can be obtained (if any). Unfortunately, I don't have access to a card with full FP16 support at the moment.
		</comment>
		<comment id='4' author='Dagamies' date='2018-03-09T12:30:34Z'>
		Apparently we have another issue with FP16. After running a while it was time to evaluate the set:
&lt;denchmark-code&gt;INFO:tensorflow:words_per_sec/features: 485.45
INFO:tensorflow:words_per_sec/labels: 63.9548
INFO:tensorflow:loss = 435.2, step = 1100 (486.676 sec)
INFO:tensorflow:Saving checkpoints for 1150 into /data/a1/data_anon16/model.ckpt.
INFO:tensorflow:Loss for final step: 615.0.
INFO:tensorflow:Calling model_fn.
Traceback (most recent call last):
  File "/usr/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/usr/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/home/ari/fp16/OpenNMT-tf/bin/main.py", line 135, in &lt;module&gt;
    main()
  File "/home/ari/fp16/OpenNMT-tf/bin/main.py", line 116, in main
    runner.train_and_evaluate()
  File "opennmt/runner.py", line 134, in train_and_evaluate
    tf.estimator.train_and_evaluate(self._estimator, train_spec, eval_spec)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py", line 425, in train_and_evaluate
    executor.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py", line 504, in run
    self.run_local()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py", line 643, in run_local
    eval_result = evaluator.evaluate_and_export()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py", line 833, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 417, in evaluate
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 931, in _evaluate_model
    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "opennmt/models/model.py", line 88, in _model_fn
    logits, predictions = self._build(features, labels, params, mode, config)
  File "opennmt/models/sequence_to_sequence.py", line 216, in _build
    dtype=target_dtype)
  File "opennmt/decoders/rnn_decoder.py", line 232, in dynamic_decode_and_search
    decoder, maximum_iterations=maximum_iterations)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py", line 201, in dynamic_decode
    initial_finished, initial_inputs, initial_state = decoder.initialize()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 308, in initialize
    dtype=nest.flatten(self._initial_cell_state)[0].dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py", line 2450, in one_hot
    "dtype parameter {1}".format(on_dtype, dtype))
TypeError: dtype &lt;dtype: 'float32'&gt; of on_value does not match dtype parameter &lt;dtype: 'float16'&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='Dagamies' date='2018-03-09T13:22:25Z'>
		Looks like there is a bug when using the  with a type different than FP32. I submitted a &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/17591&gt;patch&lt;/denchmark-link&gt;
 to TensorFlow.
In the meantime, you can still disable beam search during decoding:
params:
  beam_width: 1
		</comment>
		<comment id='6' author='Dagamies' date='2018-03-18T18:59:28Z'>
		The patch referenced above has been merged and the initial issue is also fixed on , so I'm closing this. Feel free to continue the discussion in the main FP16 thread: &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/issues/57&gt;#57&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>