<bug id='142' author='lockder' open_date='2018-05-31T18:21:57Z' closed_time='2018-07-13T19:02:25Z'>
	<summary>Tensors Sizes sometimes on Eval</summary>
	<description>
I am doing character translation and when i am training everything is fine. But when i do the eval i found some times while using the beam search i get a tensor size error. Tensorflow say they are expecting some size but they got another size. Its wierd because its not always but very often. While training everything is fine. Any suggestions?
	</description>
	<comments>
		<comment id='1' author='lockder' date='2018-06-01T07:53:40Z'>
		Can you copy-paste the error message?
		</comment>
		<comment id='2' author='lockder' date='2018-06-01T08:32:36Z'>
		Sure I will send you all the information.
if I set the beam_width to 1 then it doesn't crash
I added the data I'm using.
I'm translating human time format to machine time format.
My language is spanish but its easy to see the data :)
&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/files/2061820/data.zip&gt;data.zip&lt;/denchmark-link&gt;

#####Â The Model:
class CharacterSeq2Seq(onmt.models.SequenceToSequence):
"""Defines a small unidirectional LSTM encoder-decoder model."""
def init(self):
super(CharacterSeq2Seq, self).init(
source_inputter=onmt.inputters.WordEmbedder(
vocabulary_file_key="source_chars_vocabulary",
embedding_size=100,
tokenizer=CharacterTokenizer()),
target_inputter=onmt.inputters.WordEmbedder(
vocabulary_file_key="target_chars_vocabulary",
embedding_size=100,
tokenizer=CharacterTokenizer()),
encoder=onmt.encoders.GoogleRNNEncoder(
num_layers=2,
num_units=512,
dropout=0.3),
decoder=onmt.decoders.AttentionalRNNDecoder(
num_layers=2,
num_units=512,
bridge=onmt.layers.CopyBridge(),
attention_mechanism_class=tf.contrib.seq2seq.BahdanauAttention,
cell_class=tf.contrib.rnn.LSTMCell,
dropout=0.2,
residual_connections=False))
def model():
return CharacterSeq2Seq()
####### The configuration
&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-tf/files/2062265/config.yml.zip&gt;config.yml.zip&lt;/denchmark-link&gt;

I sent you the file .yml
&lt;denchmark-h:h4&gt;The crash&lt;/denchmark-h&gt;

INFO:tensorflow:Loading serialized model description from model/model_description.pkl
2018-06-01 10:27:57.278068: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x11f6868d0&gt;, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2018-06-01-08:27:58
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from model/model.ckpt-1500
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2018-06-01 10:28:06.245988: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at gather_nd_op.cc:50 : Invalid argument: flat indices[9759, :] = [15, 31, 6] does not index into param (shape: [81,128,5,41]).
Traceback (most recent call last):
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1322, in _do_call
return fn(*args)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1307, in _run_fn
options, feed_dict, fetch_list, target_list, run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1409, in _call_tf_sessionrun
run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[9759, :] = [15, 31, 6] does not index into param (shape: [81,128,5,41]).
[[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 24, in 
main()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 20, in main
evaluate()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 17, in evaluate
nnmtMain()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/bin/main.py", line 125, in main
runner.evaluate(checkpoint_path=args.checkpoint_path)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/runner.py", line 157, in evaluate
eval_spec.input_fn, hooks=eval_spec.hooks, checkpoint_path=checkpoint_path)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py", line 425, in evaluate
name=name)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py", line 1117, in _evaluate_model
config=self._session_config)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/evaluation.py", line 212, in _evaluate_once
session.run(eval_ops, feed_dict)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 567, in run
run_metadata=run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1043, in run
run_metadata=run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1134, in run
raise six.reraise(*original_exc_info)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/six.py", line 693, in reraise
raise value
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1119, in run
return self._sess.run(*args, **kwargs)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1191, in run
run_metadata=run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 971, in run
return self._sess.run(*args, **kwargs)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 900, in run
run_metadata_ptr)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1135, in _run
feed_dict_tensor, options, run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1316, in _do_run
run_metadata)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1335, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[9759, :] = [15, 31, 6] does not index into param (shape: [81,128,5,41]).
[[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]
Caused by op 'seq2seq/decoder_1/decoder_1/GatherNd', defined at:
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 24, in 
main()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 20, in main
evaluate()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/time_Translation/evaluate.py", line 17, in evaluate
nnmtMain()
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/bin/main.py", line 125, in main
runner.evaluate(checkpoint_path=args.checkpoint_path)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/runner.py", line 157, in evaluate
eval_spec.input_fn, hooks=eval_spec.hooks, checkpoint_path=checkpoint_path)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py", line 425, in evaluate
name=name)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py", line 1087, in _evaluate_model
features, labels, model_fn_lib.ModeKeys.EVAL, self.config)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py", line 831, in _call_model_fn
model_fn_results = self._model_fn(features=features, **kwargs)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/models/model.py", line 113, in _model_fn
logits, predictions = self._build(features, labels, params, mode, config=config)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/models/sequence_to_sequence.py", line 185, in _build
return_alignment_history=True))
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/opennmt/decoders/rnn_decoder.py", line 254, in dynamic_decode_and_search
decoder, maximum_iterations=maximum_iterations)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py", line 314, in dynamic_decode
final_outputs, final_state, final_sequence_lengths)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 458, in finalize
final_state.cell_state))
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 375, in map_structure
structure[0], [func(*x) for x in entries])
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 375, in 
structure[0], [func(*x) for x in entries])
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 457, in 
t, outputs.parent_ids, final_state.lengths),
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 620, in _maybe_sort_array_beams
return gather_tree_from_array(t, parent_ids, sequence_length)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 180, in gather_tree_from_array
ordered = array_ops.gather_nd(gather_from, indices)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py", line 2975, in gather_nd
"GatherNd", params=params, indices=indices, name=name)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3392, in create_op
op_def=op_def)
File "/Users/sergio/cognitive/NaturalLanguageRecognition/NaturalLanguageManager/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1718, in init
self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
InvalidArgumentError (see above for traceback): flat indices[9759, :] = [15, 31, 6] does not index into param (shape: [81,128,5,41]).
[[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]
Process finished with exit code 1
		</comment>
		<comment id='3' author='lockder' date='2018-06-04T05:33:25Z'>
		I am also having some similar issue, I trained my model on tensorflow-gpu==1.4.0, while running inferring I was getting following:
&lt;denchmark-code&gt;(translation) himanshu@StaquResearch2:~/virtualenv/translation/translation/OpenNMT-tf$ onmt-main infer --config config/opennmt-defaults.yml data/mandarin-english/translation.yml --features_file data/mandarin-english/evaluation.txt 
INFO:tensorflow:Loading serialized model description from data/mandarin-english-model/model_description.pkl
2018-06-04 10:46:29.534325: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
INFO:tensorflow:Using config: {'_service': None, '_keep_checkpoint_max': 5, '_save_checkpoints_steps': 5000, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_master': '', '_save_checkpoints_secs': None, '_log_step_count_steps': 50, '_is_chief': True, '_model_dir': 'data/mandarin-english-model', '_task_id': 0, '_save_summary_steps': 50, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f947d75def0&gt;, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:The current version of tf.contrib.seq2seq.BeamSearchDecoder does not support returning the alignment history. None will be returned instead. Consider upgrading TensorFlow.
INFO:tensorflow:Restoring parameters from data/mandarin-english-model/model.ckpt-1000000
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;

&lt;/denchmark-code&gt;

As it suggested that BeamSearch Decoder was not found so I upgraded the tensorflow to tensorflow==1.8.0 , but now I am getting similar error :
&lt;denchmark-code&gt;(translation) himanshu@StaquResearch2:~/virtualenv/translation/translation/OpenNMT-tf$ onmt-main infer --config config/opennmt-defaults.yml data/mandarin-english/translation.yml --features_file data/mandarin-english/evaluation.txt 
INFO:tensorflow:Loading serialized model description from data/mandarin-english-model/model_description.pkl
2018-06-04 10:52:17.416148: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_is_chief': True, '_num_worker_replicas': 1, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_master': '', '_save_checkpoints_steps': 5000, '_save_summary_steps': 50, '_model_dir': 'data/mandarin-english-model', '_task_type': 'worker', '_train_distribute': None, '_save_checkpoints_secs': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f09de4f84a8&gt;, '_tf_random_seed': None, '_task_id': 0, '_keep_checkpoint_max': 5, '_service': None, '_global_id_in_cluster': 0, '_log_step_count_steps': 50, '_num_ps_replicas': 0, '_evaluation_master': ''}
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from data/mandarin-english-model/model.ckpt-1000000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2018-06-04 10:52:21.658949: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at gather_nd_op.cc:50 : Invalid argument: flat indices[195, :] = [3, 9, 6] does not index into param (shape: [7,10,5,1]).
Traceback (most recent call last):
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1322, in _do_call
    return fn(*args)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[195, :] = [3, 9, 6] does not index into param (shape: [7,10,5,1]).
	 [[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/himanshu/virtualenv/translation/bin/onmt-main", line 11, in &lt;module&gt;
    load_entry_point('OpenNMT-tf==1.4.1', 'console_scripts', 'onmt-main')()
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/bin/main.py", line 137, in main
    log_time=args.log_prediction_time)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/runner.py", line 216, in infer
    hooks=infer_hooks):
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 509, in predict
    preds_evaluated = mon_sess.run(predictions)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 567, in run
    run_metadata=run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 1043, in run
    run_metadata=run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 1134, in run
    raise six.reraise(*original_exc_info)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/six.py", line 693, in reraise
    raise value
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 1119, in run
    return self._sess.run(*args, **kwargs)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 1191, in run
    run_metadata=run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py", line 971, in run
    return self._sess.run(*args, **kwargs)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 900, in run
    run_metadata_ptr)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1316, in _do_run
    run_metadata)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[195, :] = [3, 9, 6] does not index into param (shape: [7,10,5,1]).
	 [[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]

Caused by op 'seq2seq/decoder_1/decoder_1/GatherNd', defined at:
  File "/home/himanshu/virtualenv/translation/bin/onmt-main", line 11, in &lt;module&gt;
    load_entry_point('OpenNMT-tf==1.4.1', 'console_scripts', 'onmt-main')()
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/bin/main.py", line 137, in main
    log_time=args.log_prediction_time)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/runner.py", line 216, in infer
    hooks=infer_hooks):
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 496, in predict
    features, None, model_fn_lib.ModeKeys.PREDICT, self.config)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 831, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/models/model.py", line 128, in _model_fn
    _, predictions = self._build(features, labels, params, mode, config=config)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/models/sequence_to_sequence.py", line 185, in _build
    return_alignment_history=True))
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/decoders/rnn_decoder.py", line 258, in dynamic_decode_and_search
    decoder, maximum_iterations=maximum_iterations)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py", line 314, in dynamic_decode
    final_outputs, final_state, final_sequence_lengths)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 458, in finalize
    final_state.cell_state))
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/util/nest.py", line 375, in map_structure
    structure[0], [func(*x) for x in entries])
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/util/nest.py", line 375, in &lt;listcomp&gt;
    structure[0], [func(*x) for x in entries])
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 457, in &lt;lambda&gt;
    t, outputs.parent_ids, final_state.lengths),
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 620, in _maybe_sort_array_beams
    return gather_tree_from_array(t, parent_ids, sequence_length)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py", line 180, in gather_tree_from_array
    ordered = array_ops.gather_nd(gather_from, indices)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py", line 2975, in gather_nd
    "GatherNd", params=params, indices=indices, name=name)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 3392, in create_op
    op_def=op_def)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): flat indices[195, :] = [3, 9, 6] does not index into param (shape: [7,10,5,1]).
	 [[Node: seq2seq/decoder_1/decoder_1/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"](seq2seq/decoder_1/decoder_1/Reshape_2, seq2seq/decoder_1/decoder_1/stack)]]

&lt;/denchmark-code&gt;

Can anyone tell me why this is happening ? &lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
 Any updates on the bug previously reported ?
		</comment>
		<comment id='4' author='lockder' date='2018-06-04T07:27:34Z'>
		Thanks for the details. The issue seems to happen when reordering the alignment history coming from the attention layer based on the beam search path. I will try to pinpoint to issue and submit a patch. This looks like a bug within TensorFlow.
In the meantime, I suggest manually disabling the alignment history so that this code path is not used:
diff --git a/opennmt/models/sequence_to_sequence.py b/opennmt/models/sequence_to_sequence.py
index f961e91..fc87900 100644
--- a/opennmt/models/sequence_to_sequence.py
+++ b/opennmt/models/sequence_to_sequence.py
@@ -182,7 +182,7 @@ class SequenceToSequence(Model):
                   memory=encoder_outputs,
                   memory_sequence_length=encoder_sequence_length,
                   dtype=target_dtype,
-                  return_alignment_history=True))
+                  return_alignment_history=False))
 
       target_vocab_rev = tf.contrib.lookup.index_to_string_table_from_file(
           self.target_inputter.vocabulary_file,
Let me know if this workaround works for you.
		</comment>
		<comment id='5' author='lockder' date='2018-06-04T08:33:17Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
  Doing this gives following error, which is understandable since the method is now not returning  but it's a needed parameter for 
&lt;denchmark-code&gt;
(translation) himanshu@StaquResearch2:~/virtualenv/translation/translation/OpenNMT-tf$ onmt-main infer --config config/opennmt-defaults.yml data/mandarin-english/translation.yml --features_file data/mandarin-english/evaluation.txt 
INFO:tensorflow:Loading serialized model description from data/mandarin-english-model/model_description.pkl
2018-06-04 13:59:30.661537: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Using config: {'_save_checkpoints_steps': 5000, '_keep_checkpoint_max': 5, '_is_chief': True, '_save_summary_steps': 50, '_model_dir': 'data/mandarin-english-model', '_num_ps_replicas': 0, '_save_checkpoints_secs': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd78fa1a358&gt;, '_task_type': 'worker', '_task_id': 0, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_train_distribute': None, '_num_worker_replicas': 1, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 50, '_master': '', '_evaluation_master': '', '_service': None}
INFO:tensorflow:Calling model_fn.
Traceback (most recent call last):
  File "/home/himanshu/virtualenv/translation/bin/onmt-main", line 11, in &lt;module&gt;
    load_entry_point('OpenNMT-tf==1.4.1', 'console_scripts', 'onmt-main')()
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/bin/main.py", line 137, in main
    log_time=args.log_prediction_time)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/runner.py", line 216, in infer
    hooks=infer_hooks):
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 496, in predict
    features, None, model_fn_lib.ModeKeys.PREDICT, self.config)
  File "/home/himanshu/virtualenv/translation/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 831, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/models/model.py", line 128, in _model_fn
    _, predictions = self._build(features, labels, params, mode, config=config)
  File "/home/himanshu/virtualenv/translation/translation/OpenNMT-tf/opennmt/models/sequence_to_sequence.py", line 185, in _build
    return_alignment_history=False))
ValueError: not enough values to unpack (expected 5, got 4)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='lockder' date='2018-06-04T08:44:41Z'>
		Oh right. So let's revert this change and disable the flag at a lower level:
diff --git a/opennmt/decoders/rnn_decoder.py b/opennmt/decoders/rnn_decoder.py
index 9f7b229..7c7833f 100644
--- a/opennmt/decoders/rnn_decoder.py
+++ b/opennmt/decoders/rnn_decoder.py
@@ -217,7 +217,7 @@ class RNNDecoder(Decoder):
                       "be returned instead. Consider upgrading TensorFlow.")
       alignment_history = False
     else:
-      alignment_history = return_alignment_history
+      alignment_history = False
 
     batch_size = tf.shape(start_tokens)[0]
		</comment>
		<comment id='7' author='lockder' date='2018-06-04T08:51:14Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
  Now it's running, but it's printing nothing except , which means basically the output is all . Which again is a problem, just so inform you, the test file I am inferring has data from train set, and the model trained for about 1M steps, hence it must have learnt atleast something if not anything, hence all  doesn't make sense here. What do you think ?
&lt;denchmark-code&gt;(translation) himanshu@StaquResearch2:~/virtualenv/translation/translation/OpenNMT-tf$ onmt-main infer --config config/opennmt-defaults.yml data/mandarin-english/translation.yml --features_file data/mandarin-english/evaluation.txt 
INFO:tensorflow:Loading serialized model description from data/mandarin-english-model/model_description.pkl
2018-06-04 14:19:21.753868: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_task_type': 'worker', '_task_id': 0, '_log_step_count_steps': 50, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_session_config': gpu_options {
}
allow_soft_placement: true
, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2902cf82e8&gt;, '_master': '', '_num_ps_replicas': 0, '_save_summary_steps': 50, '_evaluation_master': '', '_tf_random_seed': None, '_global_id_in_cluster': 0, '_model_dir': 'data/mandarin-english-model', '_save_checkpoints_steps': 5000, '_service': None, '_is_chief': True, '_train_distribute': None, '_save_checkpoints_secs': None}
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from data/mandarin-english-model/model.ckpt-1000000
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;
&lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;/s&gt;

&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='lockder' date='2018-06-04T09:09:50Z'>
		I think this is an issue with the model you trained but it is unrelated to the error reported here. Maybe you want to open a separate issue, sharing your training parameters, the last training and eval loss, etc.
		</comment>
		<comment id='9' author='lockder' date='2018-06-04T09:50:48Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
 When  is  is the beam search decoder being used for decoding or that makes it similar to the case when 
		</comment>
		<comment id='10' author='lockder' date='2018-06-04T10:07:47Z'>
		The beam search decoder is used but will not return the alignment history produced by the attention layer.
		</comment>
		<comment id='11' author='lockder' date='2018-06-04T10:18:56Z'>
		Changing alignment_history = False, make it works :)
The weird thing its now when evaluating i see a failed prediction quite weird
I had to subtitute the end token with end_token, because since its html will not appear on the message
failed: 22:45end_tokenend_tokenend_tokenend_tokenend_tokenend_token expected: 22:45
show to me the end token its not well detected and it doesn't stop.
		</comment>
		<comment id='12' author='lockder' date='2018-06-04T13:40:19Z'>
		&lt;denchmark-link:https://github.com/lockder&gt;@lockder&lt;/denchmark-link&gt;
 How is your translation result ?
		</comment>
		<comment id='13' author='lockder' date='2018-06-04T16:51:33Z'>
		&lt;denchmark-link:https://github.com/lordzuko&gt;@lordzuko&lt;/denchmark-link&gt;
 Its working quite well. for now I'm just testing.
Since I'm doing character translation bleu will not work if I don't tokenize the eval files to setup every character like a word, so for now i'm using word_accuracy.
Time is almost 99.7 percent right now
Date is around 80 percent right now but I didn't tried to improve it yet
		</comment>
		<comment id='14' author='lockder' date='2018-07-09T08:07:07Z'>
		If someone is able and willing to share a checkpoint and input text for which this error is raised, that would be very helpful in trying to solve it. Thanks.
		</comment>
		<comment id='15' author='lockder' date='2018-07-09T16:12:52Z'>
		The checkpoint is too large (even after zip), so how to send you that?
		</comment>
		<comment id='16' author='lockder' date='2018-07-09T16:22:01Z'>
		I just need:

the last checkpoint, e.g. these files for a last step N:

checkpoint
model.ckpt-N.data-00000-of-00002
model.ckpt-N.data-00001-of-00002
model.ckpt-N.index
model.ckpt-N.meta
model_description.pkl


the word vocabularies
a test file

Via Google Drive or a similar service. Thanks!
		</comment>
		<comment id='17' author='lockder' date='2018-07-09T16:55:47Z'>
		The file is here:
&lt;denchmark-link:https://drive.google.com/file/d/1JkuhyJYjRZ7oLnwrfDLPHzvJFEpRpnQd/view?usp=sharing&gt;https://drive.google.com/file/d/1JkuhyJYjRZ7oLnwrfDLPHzvJFEpRpnQd/view?usp=sharing&lt;/denchmark-link&gt;

By the way, may I ask how to enable word features using openNMT-py, there is an instruction in Lua documentation but not in the pytorch one? Because I am labeling my characters with some annotation (both src and tgt side), I think this might help.
		</comment>
		<comment id='18' author='lockder' date='2018-07-09T16:59:02Z'>
		What I found is the bug happens to me only if I'm using tensorflow-cpu when I use tensorflow-gpu never crashes
		</comment>
		<comment id='19' author='lockder' date='2018-07-09T17:00:53Z'>
		I did use the cpu version. Thanks for your response. I have not tried it on gpu yet.
		</comment>
		<comment id='20' author='lockder' date='2018-07-10T09:53:09Z'>
		Thank you for sharing the model, it was very helpful to debug.
I submitted a fix to TensorFlow: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/20665&gt;tensorflow/tensorflow#20665&lt;/denchmark-link&gt;

		</comment>
		<comment id='21' author='lockder' date='2018-07-13T19:02:25Z'>
		The fix has been merged on the TensorFlow repository. It should be available in the next nightly package and, later, in TensorFlow 1.10.
Closing.
		</comment>
	</comments>
</bug>