<bug id='188' author='jordimas' open_date='2018-07-30T19:42:12Z' closed_time='2018-10-26T08:02:39Z'>
	<summary>Some translations return more than one &amp;lt;/s&amp;gt;</summary>
	<description>
When requesting a translation using the nmt_client.py with a generated model some translations return a &lt;/s&gt; at the end. nmt_client.py  removes one &lt;/s&gt; but some results contains two &lt;/s&gt;&lt;/s&gt;
You can reproduce the problem using this model:
&lt;denchmark-link:https://github.com/jordimas/nmt-softcatala/tree/master/models/1531713563&gt;https://github.com/jordimas/nmt-softcatala/tree/master/models/1531713563&lt;/denchmark-link&gt;

Making this change to nmt_client.py :
@@ -69,7 +69,7 @@ def main():
stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)
batch_tokens = [


 ["Hello", "world", "!"],





 ["The", "line", "join", "style", "to", "use"],
 ["My", "name", "is", "John", "."],
 ["I", "live", "on", "the", "West", "coast", "."]]



Tensorflow serving:
tensorflow_model_server --port=9000 --enable_batching=true --batching_parameters_file=batching_parameters.txt --model_name=1531713563 --model_base_path=$(realpath ../models)
Asking for the translation of sentence using:
python3 nmt_client.py --host=localhost --port=9000 --model_name=1531713563
The translation returned for 'The line join style to use' is ' L'estil de l√≠nia a utilitzar&lt;/s&gt;'
Extra details:

I have been unable to determine why some translations return more than one &lt;/s&gt;
I have been able to reproduce this with any model that I generate
I use TensorFlow 1.8, Python 3 and Ubuntu

	</description>
	<comments>
		<comment id='1' author='jordimas' date='2018-07-31T07:38:19Z'>
		Do you get the same output when you infer from a training checkpoint?
		</comment>
		<comment id='2' author='jordimas' date='2018-07-31T08:24:34Z'>
		Yes, running:
onmt-main infer --config config/opennmt-defaults.yml config/data/toy-ende.yml --features_file data/toy-ende/src-test.txt --predictions_file predictions.txt
I can reproduce the same problem
		</comment>
		<comment id='3' author='jordimas' date='2018-07-31T08:35:54Z'>
		So it's a model issue and not related to TensorFlow Serving.
What beam width are you using? There may be a bug in the TensorFlow beam search code as the returned length should only include the final &lt;/s&gt;. A simple workaround would be to print up to the first &lt;/s&gt;.
That being said, we never faced this issue on non toy datasets.
		</comment>
		<comment id='4' author='jordimas' date='2018-07-31T09:27:28Z'>
		I'm using the default opennmt-defaults.yml what set "beam_width: 5"
When I get the translations I removed all the  and this works but I think that it's good that you know about the issue
		</comment>
		<comment id='5' author='jordimas' date='2018-08-27T08:43:10Z'>
		I have the same problem, the beam search not end with 'eos' symbol. So, there are  same sentences generated by beam search. this condition is  resulted from many 'eos' symbol in one sentence. who can explain this problem about the tf beam search code?
		</comment>
		<comment id='6' author='jordimas' date='2018-09-03T07:57:49Z'>
		Which decoder type are you using?
		</comment>
		<comment id='7' author='jordimas' date='2018-09-03T08:06:31Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
 Thank your reply. I use api as follow:
inference_decoder = BeamSearchDecoder( cell=self.decoder_cell, embedding=embed_and_input_proj, start_tokens=start_tokens, end_token=end_token, initial_state=self.decoder_initial_state, beam_width=self.beam_width, output_layer=self.decoder_output_projection, )
...
(self.decoder_outputs_decode,self.final_state,_ )= (seq2seq.dynamic_decode( decoder=inference_decoder, output_time_major=self.time_major, # impute_finished=True, # error occurs maximum_iterations=max_decode_step, # parallel_iterations=self.parallel_iterations, swap_memory=True, scope=decoder_scope ))
		</comment>
		<comment id='8' author='jordimas' date='2018-09-03T08:10:17Z'>
		As these are pure TensorFlow APIs, you should probably open an issue on the TensorFlow repository.
		</comment>
		<comment id='9' author='jordimas' date='2018-09-03T08:14:01Z'>
		Yes, I have done, but nobody help. so I just want to ask if someone has encountered this problem here.
		</comment>
		<comment id='10' author='jordimas' date='2018-10-26T08:02:39Z'>
		Let's close this issue as it is fundamentally a TensorFlow bug. However, if someone is still facing the issue and is able to send me a checkpoint and files to reproduce, I can take another look.
		</comment>
	</comments>
</bug>