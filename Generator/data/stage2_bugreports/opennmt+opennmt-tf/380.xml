<bug id='380' author='Goofy-G' open_date='2019-03-11T06:54:49Z' closed_time='2019-03-11T11:34:57Z'>
	<summary>Error while serving nmtsmall model</summary>
	<description>
Hi
I trained nmtsmall model by using opennmt 1.21.3. Then I upgradeed to 1.21.4 for exporting model.
When I used export model serving, I have met this error.
Error
Traceback (most recent call last):
File "D:\GNMT\venv\lib\site-packages\grpc\beta_client_adaptations.py", line 95, in result
return self._future.result(timeout=timeout)
File "D:\GNMT\venv\lib\site-packages\grpc_channel.py", line 276, in result
raise self
grpc._channel._Rendezvous: &lt;_Rendezvous of RPC that terminated with:
status = StatusCode.INVALID_ARGUMENT
details = "Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
[[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=["loc:@seq2seq/cond/strided_slice/Switch"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]
[[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv&lt;denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_1187_seq2seq/decoder_1/while/concat_5", tensor_type=DT_BOOL, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]"
debug_error_string = "{"created":"@1552276258.713000000","description":"Error received from peer","file":"src/core/lib/surface/call.cc","file_line":1095,"grpc_message":"Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero\n\t [[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=["loc:@seq2seq/cond/strided_slice/Switch"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]\n\t [[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv&lt;denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_1187_seq2seq/decoder_1/while/concat_5", tensor_type=DT_BOOL, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]","grpc_status":3}"


During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "C:\Python35\Lib\unittest\case.py", line 59, in testPartExecutor
yield
File "C:\Python35\Lib\unittest\case.py", line 605, in run
testMethod()
File "D:\GNMT\tests\onmt_rpc_client_test.py", line 78, in test_request_from_file
address, result = client.request(line.strip("\n").split(" "))
File "D:\GNMT\address\client\onmt_rpc_client.py", line 11, in request
result = self._parse_translation_result(future.result())
File "D:\GNMT\venv\lib\site-packages\grpc\beta_client_adaptations.py", line 97, in result
raise _abortion_error(rpc_error_call)
grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details="Reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero
[[Node: seq2seq/Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _class=["loc:@seq2seq/cond/strided_slice/Switch"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](seq2seq/decoder_1/strided_slice_17, seq2seq/Reshape_1/shape)]]
[[Node: seq2seq/decoder_1/while/concat_5/_225 = _Recv&lt;denchmark-link:%5E_cloopseq2seq/decoder_1/while/decoder/decoder/attention_wrapper/assert_equal/Assert/Assert/data_0/_39&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_1187_seq2seq/decoder_1/while/concat_5", tensor_type=DT_BOOL, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]")
===============================================================================
[ERROR]
Traceback (most recent call last):
Failure: builtins.tuple: (&lt;class 'grpc.framework.interfaces.face.face.AbortionError'&gt;, AbortionError(), &lt;traceback object at 0x000000001C31D748&gt;)
&lt;denchmark-h:h2&gt;onmt_rpc_client_test.TestOpenNMTPredictRPCClient.test_request_from_file&lt;/denchmark-h&gt;

Ran 1 tests in 45.879s
FAILED (errors=1)
Process finished with exit code 1
	</description>
	<comments>
		<comment id='1' author='Goofy-G' date='2019-03-11T10:11:59Z'>
		Hi,
Can you post the configuration file that was used when exporting the model?
		</comment>
		<comment id='2' author='Goofy-G' date='2019-03-11T10:16:44Z'>
		Hi
Configuration:
params:
optimizer: GradientDescentOptimizer
learning_rate: 1.0
param_init: 0.1
clip_gradients: 5.0
decat_type: exponential_decay
decay_rate: 0.7
decay_steps: 50000
start_decay_steps: 500000
beam_width: 5
maximum_iterations: 250
replace_unknown_target: true
train:
batch_size: 64
bucket_width: 5
save_checkpoints_steps: 10000
save_summary_steps: 1000
train_steps: 1000000
maximum_features_length: 30
maximum_labels_length: 30
sample_buffer_size: -1
eval:
batch_size: 32
num_threads: 4
eval_delay: 36000
save_eval_predictions: true
external_evaluators: BLEU
exporters: last
infer:
batch_size: 32
num_threads: 1
n_best: 1
		</comment>
		<comment id='3' author='Goofy-G' date='2019-03-11T12:29:37Z'>
		There was a possible error when the generated alignment vector was empty. You should try re-exporting the model with the latest version and try again.
		</comment>
	</comments>
</bug>