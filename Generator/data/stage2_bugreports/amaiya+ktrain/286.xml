<bug id='286' author='NoraAlt' open_date='2020-12-05T12:55:54Z' closed_time='2020-12-05T18:22:03Z'>
	<summary>ArabicHotelReviews-AraBERT, ERROR: tokenize() takes 2 positional arguments but 3 were given</summary>
	<description>
Hello, I am trying to run the ArabicHotelReviews-AraBERT in &lt;denchmark-link:https://github.com/amaiya/ktrain/blob/master/examples/text/ArabicHotelReviews-AraBERT.ipynb&gt;this&lt;/denchmark-link&gt;

Every thing is correctly running before the line: val = t.preprocess_test(df_test.review.values, df_test.rating.values)
Error:
&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-23-dd26c7ff9ce5&gt; in &lt;module&gt;()
----&gt; 1 val = t.preprocess_test(df_test.review.values, df_test.rating.values)
      2 model = t.get_classifier()
      3 learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32)
      4 learner.fit_onecycle(5e-5, 1)

3 frames
/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py in preprocess_test(self, texts, y, verbose)
   1196         """
   1197         self.check_trained()
-&gt; 1198         return self.preprocess_train(texts, y=y, mode='test', verbose=verbose)
   1199 
   1200 

/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py in preprocess_train(self, texts, y, mode, verbose)
   1166           TransformerDataset if self.use_with_learner = True else tf.Dataset
   1167         """
-&gt; 1168         tseq = super().preprocess_train(texts, y=y, mode=mode, verbose=verbose)
   1169         if self.use_with_learner: return tseq
   1170         tseq.batch_size = self.batch_size

/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py in preprocess_train(self, texts, y, mode, verbose)
    941                                       pad_token_segment_id=4 if self.name in ['xlnet'] else 0,
    942                                       use_dynamic_shape=False if mode == 'train' else True,
--&gt; 943                                       verbose=verbose)
    944         self.set_multilabel(dataset, mode, verbose=verbose)
    945         if mode == 'train':  self.preprocess_train_called = True

/usr/local/lib/python3.6/dist-packages/ktrain/text/preprocessor.py in hf_convert_examples(texts, y, tokenizer, max_length, pad_on_left, pad_token, pad_token_segment_id, mask_padding_with_zero, use_dynamic_shape, verbose)
    341                 text_a = text
    342                 text_b = None
--&gt; 343             sentences.append(tokenizer.tokenize(text_a, text_b))
    344         maxlen = len(max([tokens for tokens in sentences], key=len,)) + 2
    345         if maxlen &lt; max_length: max_length = maxlen

TypeError: tokenize() takes 2 positional arguments but 3 were given
&lt;/denchmark-code&gt;

It would be very grateful if you help me to solve it. Thank You!!
	</description>
	<comments>
		<comment id='1' author='NoraAlt' date='2020-12-05T15:08:15Z'>
		Hello:  Thanks for reporting this issue.  This is a bug.  It should be fixed in the develop branch and will be included in an updated release soon.
If you'd like try the fix now, you can install the develop branch with:   pip3 install git+https://github.com/amaiya/ktrain@develop
Thanks again.
		</comment>
		<comment id='2' author='NoraAlt' date='2020-12-05T18:22:03Z'>
		This is fixed in ktrain&gt;=0.25.2. Thanks.
		</comment>
		<comment id='3' author='NoraAlt' date='2020-12-06T19:00:36Z'>
		Thank You!
It's working now.
		</comment>
	</comments>
</bug>