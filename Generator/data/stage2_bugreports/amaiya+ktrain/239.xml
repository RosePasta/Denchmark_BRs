<bug id='239' author='lambdaofgod' open_date='2020-08-27T21:21:57Z' closed_time='2020-08-28T02:36:51Z'>
	<summary>Problems with loading some huggingface models</summary>
	<description>
When I try to use roberta-base-openai-detector
&lt;denchmark-code&gt;
MODEL_NAME = 'roberta-base-openai-detector'
transformer = ktrain.text.Transformer(MODEL_NAME, maxlen=90)

model = transformer.get_classifier()
learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=32, workers=8)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;I get&lt;/denchmark-h&gt;

OSError                                   Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_utils.py in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)
461                 if resolved_archive_file is None:
--&gt; 462                     raise EnvironmentError
463             except EnvironmentError:
OSError:
&lt;denchmark-code&gt;

During handling of the above exception, another exception occurred:

OSError                                   Traceback (most recent call last)

3 frames

/usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_utils.py in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)
    467                     f"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a file named one of {TF2_WEIGHTS_NAME}, {WEIGHTS_NAME}.\n\n"
    468                 )
--&gt; 469                 raise EnvironmentError(msg)
    470             if resolved_archive_file == archive_file:
    471                 logger.info("loading weights file {}".format(archive_file))

OSError: Can't load weights for 'roberta-large-openai-detector'. Make sure that:

- 'roberta-large-openai-detector' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'roberta-large-openai-detector' is the correct path to a directory containing a file named one of tf_model.h5, pytorch_model.bin.


&lt;/denchmark-code&gt;

I'm pretty sure this is a valid Huggingface model, and it's actually downloaded, because I can run the following without any problems:
&lt;denchmark-code&gt;
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("roberta-base-openai-detector")

model = AutoModelForSequenceClassification.from_pretrained("roberta-base-openai-detector")

&lt;/denchmark-code&gt;

Is there a way to sidestep this? For example use AutoModelForSequenceClassification somewhere in ktrain model wrapper?
	</description>
	<comments>
		<comment id='1' author='lambdaofgod' date='2020-08-27T22:12:27Z'>
		Thanks for letting me know about this.  This will be fixed soon and released as an update to ktrain.   I will reply to this thread when it is available.
		</comment>
		<comment id='2' author='lambdaofgod' date='2020-08-28T02:36:51Z'>
		This now works if you upgrade to v0.20.2.  Note that this model  appears to be configured/fine-tuned to only output two classes: real vs fake.
		</comment>
	</comments>
</bug>