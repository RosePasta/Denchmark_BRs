<bug id='220' author='ShoubhikBanerjee' open_date='2020-08-01T15:28:36Z' closed_time='2020-08-03T14:04:32Z'>
	<summary>KeyError: 'loss' while trying out some examples</summary>
	<description>
I was trying out for experiments from &lt;denchmark-link:https://nbviewer.jupyter.org/github/amaiya/ktrain/blob/master/examples/text/20newsgroup-distilbert.ipynb&gt;this&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://nbviewer.jupyter.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb&gt;this&lt;/denchmark-link&gt;
 urls.
My transformer version is : 3.0.2
And I am getting error while trying to find the learning rate from the laerner :
`simulating training for different learning rates... this may take a few moments...
Train for 22326 steps
Epoch 1/2
0/22326 [..............................] - ETA: 0s
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in on_batch(self, step, mode, size)
783       try:
--&gt; 784         yield batch_logs
785       finally:
21 frames
InvalidArgumentError: 2 root error(s) found.
(0) Invalid argument:  logits and labels must be broadcastable: logits_size=[6,5] labels_size=[6,6]
[[node loss/output_1_loss/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py:119) ]]
[[Reshape_415/_286]]
(1) Invalid argument:  logits and labels must be broadcastable: logits_size=[6,5] labels_size=[6,6]
[[node loss/output_1_loss/softmax_cross_entropy_with_logits (defined at /usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py:119) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_53893]
Function call stack:
distributed_function -&gt; distributed_function
During handling of the above exception, another exception occurred:
KeyError                                  Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/ktrain/lroptimize/lrfinder.py in on_batch_end(self, batch, logs)
32
33         # Log the loss
---&gt; 34         loss = logs['loss']
35         self.batch_num +=1
36         self.avg_loss = self.beta * self.avg_loss + (1-self.beta) *loss
KeyError: 'loss'`
Any guess what is the issue ?
It would be very grateful if you help me to solve it. Thank You.
	</description>
	<comments>
		<comment id='1' author='ShoubhikBanerjee' date='2020-08-01T15:52:38Z'>
		it occured when the classes=[int_type, int_type, int_type].  Any way arround for it?
		</comment>
		<comment id='2' author='ShoubhikBanerjee' date='2020-08-01T16:52:54Z'>
		You provided URLs to two example notebooks.  Both of them have been verified to work on Google Colab, which suggests there something odd about your data.
It looks like there is a mismatch between the way the model is configured and the labels in your dataset.
Please provide more information on what your labels look like in your dataset.  What does y_train look like prior to supplying it to preprocess_train or texts_from_array?  Can you post the first few entries from y_train?
		</comment>
		<comment id='3' author='ShoubhikBanerjee' date='2020-08-02T08:36:12Z'>
		My df.head()  looks like this:
&lt;denchmark-link:https://user-images.githubusercontent.com/44529417/89119060-ecd2b100-d4c8-11ea-80e4-74d6657dd7a3.png&gt;&lt;/denchmark-link&gt;

and my df.info()  looks like this:
&lt;denchmark-link:https://user-images.githubusercontent.com/44529417/89119014-72099600-d4c8-11ea-931e-366a8837092b.png&gt;&lt;/denchmark-link&gt;

And my learner initialization  is as follows :
import ktrain
from ktrain import text
MODEL_NAME = 'distilbert-base-uncased'
t = text.Transformer(MODEL_NAME, maxlen=512,class_names=['1','2','3','4','5'])
trn = t.preprocess_train(TRAINING_X, TRAINING_Y)
val = t.preprocess_test(VALIDATION_X, VALIDATION_Y)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=10)
My Training Code is :
learner.fit_onecycle(3e-5, 6)
Then after 1 epoch I am getting error :
&lt;denchmark-link:https://user-images.githubusercontent.com/44529417/89119109-37542d80-d4c9-11ea-8cac-4fd65336eb73.png&gt;&lt;/denchmark-link&gt;

My Training Set Example :
print(TRAINING_X[0]) print(TRAINING_Y[0])
Output :  I have bought several of the Vitality canned dog food products and have found them all to be of good quality The product looks more like stew than processed meat and it smells better My Labrador is finicky and she appreciates this product better than most
5
My Testing Set Example :
print(VALIDATION_X[0]) print(VALIDATION_Y[0])
Output : I ve recently been spoiled by fresh roasted coffee from local roaster and was intrigued by all of the positive reviews Anyway this stuff was no better than what sits on grocery shelves for months and months waiting and waiting and going stale with every passing day Do yourself favor and buy FRESH whole bean coffee like Dark Brazilian Santos Whole Bean Coffee Pound Bag Grind it with burr grinder brew it with any of the manual methods and you will be in coffee nirvana And you will never buy this stuff again
2
Can you help me to resolve the issue?
		</comment>
		<comment id='4' author='ShoubhikBanerjee' date='2020-08-02T12:47:42Z'>
		The problem is that your labels must start with 0. So, if you have 5 labels, then the labels must be [0,1,2,3,4], instead of [1,2,3,4,5].
Assuming TRAINING_Y and VALIDATION_Y are NumPy arrays like [5,1,4,2,5], you should be able to simple do; TRAINING_Y = TRAINING_Y-1 to fix things, for example.
I will add a better error check for this situation in the next version of ktrain, so keeping this issue open.
		</comment>
		<comment id='5' author='ShoubhikBanerjee' date='2020-08-02T13:46:12Z'>
		Okay, but just one more concern :
My TRAINING_Y  is NumPy array of strings  like ['1']
Therefore, I have used class_names=['1','2','3','4','5']
So why do we need to convert it to [0,1,2,3,4] ?  I am bit confused here.
		</comment>
		<comment id='6' author='ShoubhikBanerjee' date='2020-08-02T14:23:27Z'>
		Are you sure that TRAINING_Y contains strings? Please check more closely.  The error isn't really possible when it contains strings.
The error you described can only occur when TRAINING_Y contains integers in which case the fix above works.  If TRAINING_Y contains strings, then everything works.  The example below replicates what you described (with 4 classes not 5) when Y contains integers in string format and, as you can see, everything works:
# load text data
categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']
from sklearn.datasets import fetch_20newsgroups
train_b = fetch_20newsgroups(subset='train', categories=categories, shuffle=True)
test_b = fetch_20newsgroups(subset='test',categories=categories, shuffle=True)
(x_train, y_train) = (train_b.data, train_b.target)
(x_test, y_test) = (test_b.data, test_b.target)

# transformations to replicate your dataset if `y_train` and `y_test` are strings
y_train = y_train+1
y_test = y_test+1
y_train = list(map(str, y_train))
y_test = list(map(str, y_test))

# build, train, and validate model (Transformer is wrapper around transformers library)
import ktrain
from ktrain import text
MODEL_NAME = 'distilbert-base-uncased'
t = text.Transformer(MODEL_NAME, maxlen=500, class_names=['1','2', '3', '4'])
trn = t.preprocess_train(x_train, y_train)
val = t.preprocess_test(x_test, y_test)
model = t.get_classifier()
learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)
learner.fit_onecycle(5e-5, 1)
The class_names parameter simply maps indices to string labels (e.g., class_names = ['negative', 'positive'] means  0-&gt;'negative', 1-&gt;'positive').  But, if  Y contains strings, then the labels are extracted from Y instead of class_names.
Also,if you're confused, I would recommend you look at STEP 1 of &lt;denchmark-link:https://nbviewer.jupyter.org/github/amaiya/ktrain/blob/master/tutorials/tutorial-A3-hugging_face_transformers.ipynb&gt;this tutorial&lt;/denchmark-link&gt;
, as everything is explained there.
		</comment>
		<comment id='7' author='ShoubhikBanerjee' date='2020-08-02T14:59:21Z'>
		Thanx a lot for your help, I am trying it again, and keep updated about this. Thanx Sir!
		</comment>
		<comment id='8' author='ShoubhikBanerjee' date='2020-08-03T05:41:04Z'>
		Hi, I have gone through the code and modified some changes.
But the problem is that, when I run the same code with smaller input size (Say, 50K rows from CSV), it works fine.
But when I am trying to load nearly 150K rows from CSV it gave an error after running the 1st epoch.
For more details, you can find my dataset &lt;denchmark-link:https://drive.google.com/file/d/1OMUSpziV-H_IrPwWDMxzcKgI12gqKbm5/view?usp=sharing&gt;here&lt;/denchmark-link&gt;
  and colab notebook &lt;denchmark-link:https://colab.research.google.com/drive/1EMey-dO_vtxhQEWBQzu4Z4V85-K8QhP8?usp=sharing&gt;here&lt;/denchmark-link&gt;
.
I have kept the error as it is so that you can see the logs.
Is it possible for you to go and check it there? Thanks.
		</comment>
		<comment id='9' author='ShoubhikBanerjee' date='2020-08-03T14:04:32Z'>
		Thanks for letting me know.  If you upgrade ktrain to v0.19.2, it will work.
A few other comments:

You can use the stratify argument to train_test_split to ensure the label distributions are consistent.  It seemed like validation set only contained two of the classes (1 and 2). so you should double-check this.
Since you are predicting numerical ratings, I would recommend treating this as a text regression problem instead of a classification problem.  Use integer values for labels but omit the class_names argument to treat as regression. Another user did this by transforming ratings from -2 to +2 instead of 1 through 5 for Yelp reviews. The pretrained model is available here.

I will close this issue for now, but feel free to reply (or open new issue) if you have further problems.
		</comment>
	</comments>
</bug>