<bug id='240' author='xirect' open_date='2020-09-02T15:19:13Z' closed_time='2020-09-03T17:10:12Z'>
	<summary>Translational method deprecated in transformers 3.1.0</summary>
	<description>
Hi &lt;denchmark-link:https://github.com/amaiya&gt;@amaiya&lt;/denchmark-link&gt;
,
I just wanted to notify you that with the new transformers update batch prepare has changed.
This is now the format
self.model.generate(**self.tokenizer.prepare_seq2seq_batch(sentences).to(self.torch_device))
This is what is in place
self.model.generate(**self.tokenizer.prepare_translation_batch(sentences).to(self.torch_device))
This should also speed up the translation a little bit.
	</description>
	<comments>
		<comment id='1' author='xirect' date='2020-09-02T20:23:14Z'>
		Thanks a lot, &lt;denchmark-link:https://github.com/xirect&gt;@xirect&lt;/denchmark-link&gt;
.  An update will be pushed and released soon.
		</comment>
		<comment id='2' author='xirect' date='2020-09-03T17:10:12Z'>
		Thank you - this is fixed in ktrain&gt;=0.21.0.
		</comment>
	</comments>
</bug>