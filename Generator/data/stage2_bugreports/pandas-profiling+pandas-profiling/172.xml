<bug id='172' author='set92' open_date='2019-06-04T11:02:17Z' closed_time='2019-06-19T20:39:42Z'>
	<summary>A couple errors in branch v2.0.0beta</summary>
	<description>
Describe the bug
I have a dataset of 11kk of rows, and after 20 minutes the process break to show "ValueError: f(a) and f(b) must have different signs". I was thinking if it was possible to detect this kind of problems before hand.
After it I tried to comment phi-k correlation which was the problem and there was another problem (ValueError: Unstacked DataFrame is too big, causing int32 overflow), I was going to create another issue to mention it but for not creating too many issues
To Reproduce
The line used to run is in the errors, the dataset to reproduce it.. is harder because it of the company, and not sure how I can create fake data that resembles the dataset and it has 11618532 rows. Maybe I could try to shift the numeric numbers to change the info, and with the categorical columns... not sure.
Version information:
alembic==1.0.7
astroid==2.2.5
async-generator==1.10
atomicwrites==1.3.0
attrs==18.2.0
backcall==0.1.0
bitarray==0.8.3
bleach==3.1.0
certifi==2018.11.29
chardet==3.0.4
cloudpickle==1.1.1
confuse==1.0.0
constants==0.6.0
cycler==0.10.0
dask==1.2.2
decorator==4.3.2
defusedxml==0.5.0
entrypoints==0.3
findspark==1.3.0
future==0.17.1
htmlmin==0.1.12
idna==2.8
importlib-metadata==0.17
impyla==0.14.2.2
ipykernel==5.1.0
ipython==7.3.0
ipython-genutils==0.2.0
isort==4.3.20
jedi==0.13.3
Jinja2==2.10
jsonschema==3.0.0
jupyter-client==5.2.4
jupyter-core==4.4.0
jupyterhub==0.9.4
jupyterhub-ldap-authenticator==0.3.1
kiwisolver==1.0.1
lazy-object-proxy==1.4.1
ldap3==2.5.2
llvmlite==0.29.0
locket==0.2.0
Mako==1.0.7
MarkupSafe==1.1.1
matplotlib==3.0.3
mccabe==0.6.1
missingno==0.4.1
missingpy==0.2.0
mistune==0.8.4
more-itertools==7.0.0
nbconvert==5.4.1
nbformat==4.4.0
notebook==5.7.4
numba==0.44.0
numpy==1.16.2
packaging==19.0
pamela==1.0.0
pandas==0.24.2
pandas-profiling==2.0.0
pandocfilters==1.4.2
parso==0.3.4
partd==0.3.10
pexpect==4.6.0
phik==0.9.8
pickleshare==0.7.5
plotly==3.10.0
pluggy==0.12.0
ply==3.11
prometheus-client==0.6.0
prompt-toolkit==2.0.9
ptyprocess==0.6.0
py==1.8.0
pyasn1==0.4.5
Pygments==2.3.1
PyHive==0.6.1
pyhs2==0.6.0
pylint==2.3.1
pyod==0.7.2
pyparsing==2.3.1
pyrsistent==0.14.11
pytest==4.6.1
pytest-pylint==0.14.0
python-dateutil==2.8.0
python-editor==1.0.4
python-oauth2==1.1.0
pytz==2018.9
PyYAML==5.1
pyzmq==18.0.0
requests==2.21.0
retrying==1.3.3
sasl==0.2.1
scikit-learn==0.20.3
scipy==1.2.1
seaborn==0.9.0
Send2Trash==1.5.0
six==1.12.0
SQLAlchemy==1.2.18
sudospawner==0.6.0.dev0
terminado==0.8.1
testpath==0.4.2
thrift==0.11.0
thrift-sasl==0.2.1
thriftpy==0.3.9
toolz==0.9.0
tornado==5.1.1
traitlets==4.3.2
typed-ast==1.3.5
urllib3==1.24.1
virtualenv==16.4.3
wcwidth==0.1.7
webencodings==0.5.1
wrapt==1.11.1
zipp==0.5.1
Additional context
&lt;denchmark-code&gt;ValueError                                Traceback (most recent call last)
&lt;ipython-input-12-b3ba44380000&gt; in &lt;module&gt;
----&gt; 1 df.profile_report(missing_diagrams={'dendrogram': False, 'heatmap': False}).to_file(output_file="report.html")

/usr/lib/python3.6/site-packages/pandas_profiling/controller/pandas_decorator.py in profile_report(df, **kwargs)
     14         A ProfileReport of the DataFrame.
     15     """
---&gt; 16     p = ProfileReport(df, **kwargs)
     17     return p
     18 

/usr/lib/python3.6/site-packages/pandas_profiling/__init__.py in __init__(self, df, **kwargs)
     37 
     38         # Get dataset statistics
---&gt; 39         description_set = describe_df(df)
     40 
     41         # Get sample

/usr/lib/python3.6/site-packages/pandas_profiling/model/describe.py in describe(df)
    415 
    416     # Get correlations
--&gt; 417     correlations = calculate_correlations(df, variables)
    418 
    419     # Check correlations between numerical variables

/usr/lib/python3.6/site-packages/pandas_profiling/model/correlations.py in calculate_correlations(df, variables)
    167                     continue
    168 
--&gt; 169             correlations["phi_k"] = df[selcols].phik_matrix(interval_cols=intcols)
    170 
    171     if config["correlations"]["cramers"].get(bool):

/usr/lib/python3.6/site-packages/phik/phik.py in phik_matrix(df, interval_cols, bins, quantile, noise_correction, dropna, drop_underflow, drop_overflow)
    154     data_binned, binning_dict = bin_data(df_clean, cols=interval_cols_clean, bins=bins, quantile=quantile, retbins=True)
    155     return phik_from_rebinned_df(data_binned, noise_correction, dropna=dropna, drop_underflow=drop_underflow,
--&gt; 156                                  drop_overflow=drop_overflow)
    157 
    158 

/usr/lib/python3.6/site-packages/phik/phik.py in phik_from_rebinned_df(data_binned, noise_correction, dropna, drop_underflow, drop_overflow)
    108 
    109         datahist.columns = datahist.columns.droplevel()
--&gt; 110         phikvalue = phik_from_hist2d(datahist.values, noise_correction=noise_correction)
    111         phiks[':'.join(comb)] = phikvalue
    112 

/usr/lib/python3.6/site-packages/phik/phik.py in phik_from_hist2d(observed, noise_correction)
     53 
     54     # phik calculation adds noise pedestal to theoretical chi2
---&gt; 55     phik = phik_from_chi2(chi2, observed.sum(), *observed.shape, None, None, pedestal)
     56 
     57     return phik

/usr/lib/python3.6/site-packages/phik/bivariate.py in phik_from_chi2(chi2, n, nx, ny, sx, sy, pedestal)
    145         return 0
    146 
--&gt; 147     rho = optimize.brentq(chi2_from_phik, 0, 1, args=(n, chi2, corr0, scale, sx, sy, pedestal))
    148     return rho

/usr/lib64/python3.6/site-packages/scipy/optimize/zeros.py in brentq(f, a, b, args, xtol, rtol, maxiter, full_output, disp)
    752     if rtol &lt; _rtol:
    753         raise ValueError("rtol too small (%g &lt; %g)" % (rtol, _rtol))
--&gt; 754     r = _zeros._brentq(f, a, b, xtol, rtol, maxiter, args, full_output, disp)
    755     return results_c(full_output, r)
    756 

ValueError: f(a) and f(b) must have different signs
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-6-f7c582662276&gt; in &lt;module&gt;
----&gt; 1 df.profile_report(missing_diagrams={'dendrogram': False, 'heatmap': False}, correlations={'phi_k': False}).to_file(output_file="report.html")

/usr/lib/python3.6/site-packages/pandas_profiling/controller/pandas_decorator.py in profile_report(df, **kwargs)
     14         A ProfileReport of the DataFrame.
     15     """
---&gt; 16     p = ProfileReport(df, **kwargs)
     17     return p
     18 

/usr/lib/python3.6/site-packages/pandas_profiling/__init__.py in __init__(self, df, **kwargs)
     37 
     38         # Get dataset statistics
---&gt; 39         description_set = describe_df(df)
     40 
     41         # Get sample

/usr/lib/python3.6/site-packages/pandas_profiling/model/describe.py in describe(df)
    415 
    416     # Get correlations
--&gt; 417     correlations = calculate_correlations(df, variables)
    418 
    419     # Check correlations between numerical variables

/usr/lib/python3.6/site-packages/pandas_profiling/model/correlations.py in calculate_correlations(df, variables)
    175 
    176     if config["correlations"]["recoded"].get(bool):
--&gt; 177         correlation = recoded_matrix(df, variables)
    178         if len(correlation) &gt; 0:
    179             correlations["recoded"] = correlation

/usr/lib/python3.6/site-packages/pandas_profiling/model/correlations.py in recoded_matrix(df, variables)
     70         A recoded matrix for categorical variables.
     71     """
---&gt; 72     return categorical_matrix(df, variables, partial(check_recoded, count=len(df)))
     73 
     74 

/usr/lib/python3.6/site-packages/pandas_profiling/model/correlations.py in categorical_matrix(df, variables, correlation_function)
    101         categoricals.items(), 2
    102     ):
--&gt; 103         confusion_matrix = pd.crosstab(data1, data2)
    104         correlation_matrix.loc[name2, name1] = correlation_matrix.loc[
    105             name1, name2

/usr/lib64/python3.6/site-packages/pandas/core/reshape/pivot.py in crosstab(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)
    519     table = df.pivot_table('__dummy__', index=rownames, columns=colnames,
    520                            margins=margins, margins_name=margins_name,
--&gt; 521                            dropna=dropna, **kwargs)
    522 
    523     # Post-process

/usr/lib64/python3.6/site-packages/pandas/core/frame.py in pivot_table(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)
   5757                            aggfunc=aggfunc, fill_value=fill_value,
   5758                            margins=margins, dropna=dropna,
-&gt; 5759                            margins_name=margins_name)
   5760 
   5761     def stack(self, level=-1, dropna=True):

/usr/lib64/python3.6/site-packages/pandas/core/reshape/pivot.py in pivot_table(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name)
    107             else:
    108                 to_unstack.append(name)
--&gt; 109         table = agged.unstack(to_unstack)
    110 
    111     if not dropna:

/usr/lib64/python3.6/site-packages/pandas/core/frame.py in unstack(self, level, fill_value)
   5990         """
   5991         from pandas.core.reshape.reshape import unstack
-&gt; 5992         return unstack(self, level, fill_value)
   5993 
   5994     _shared_docs['melt'] = ("""

/usr/lib64/python3.6/site-packages/pandas/core/reshape/reshape.py in unstack(obj, level, fill_value)
    386     if isinstance(obj, DataFrame):
    387         if isinstance(obj.index, MultiIndex):
--&gt; 388             return _unstack_frame(obj, level, fill_value=fill_value)
    389         else:
    390             return obj.T.stack(dropna=False)

/usr/lib64/python3.6/site-packages/pandas/core/reshape/reshape.py in _unstack_frame(obj, level, fill_value)
    409                                value_columns=obj.columns,
    410                                fill_value=fill_value,
--&gt; 411                                constructor=obj._constructor)
    412         return unstacker.get_result()
    413 

/usr/lib64/python3.6/site-packages/pandas/core/reshape/reshape.py in __init__(self, values, index, level, value_columns, fill_value, constructor)
    122 
    123         if num_rows &gt; 0 and num_columns &gt; 0 and num_cells &lt;= 0:
--&gt; 124             raise ValueError('Unstacked DataFrame is too big, '
    125                              'causing int32 overflow')
    126 

ValueError: Unstacked DataFrame is too big, causing int32 overflow
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='set92' date='2019-06-05T10:45:09Z'>
		Thank you for your report. Could you add the output of df.info()? If necessary, you may want anonymize the column names.
		</comment>
		<comment id='2' author='set92' date='2019-06-05T14:23:09Z'>
		df.info()
&lt;denchmark-code&gt;&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 11618559 entries, 0 to 11618558
Data columns (total 33 columns):
company_code                  object
shop_code                     object
system_reference              object
line_reference                object
stock_code                    object
tax_code                      object
price                         float64
quantity                      float64
tax_amount                    float64
discount_amount               float64
amount_line                   float64
amount_shop                   float64
price_trans_item              float64
trans_reference               object
trans_date                    object
trans_type                    object
amount                        float64
posted_on                     object
pos_user_code                 object
trans_date_di                 object
handle                        object
flight_number                 object
airport                       object
flight_date                   object
type_flight                   object
description_stock_category    object
description_stock             object
category_code                 object
pos_code                      object
name_pos                      object
external_pos_code             object
name_shop                     object
external_shop_code            object
dtypes: float64(8), object(25)
memory usage: 2.9+ GB
&lt;/denchmark-code&gt;

I'll try to create a fake dataframe after work. I was thinking if it is possible to do the process incrementally because it takes a lot of RAM.
And another unrelated problem is the font, since I'm in a cluster with linux, and I can't install the Windows fonts.
&lt;denchmark-code&gt;/usr/lib64/python3.6/site-packages/matplotlib/font_manager.py:1241: UserWarning:
findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.
&lt;/denchmark-code&gt;

EDIT: And now I'm joining this dataframe with a csv, so now I have 57 columns, although I have to clean it a little bit.
		</comment>
		<comment id='3' author='set92' date='2019-06-12T16:35:50Z'>
		&lt;denchmark-link:https://github.com/set92&gt;@set92&lt;/denchmark-link&gt;
 are you still planning to provide us with some fake data?
		</comment>
		<comment id='4' author='set92' date='2019-06-16T14:35:59Z'>
		&lt;denchmark-link:https://github.com/sbrugman&gt;@sbrugman&lt;/denchmark-link&gt;
 here you have, at the end I had to take most of the string columns bcs I couldnt fake them much, so not sure if it will be useful &lt;denchmark-link:https://drive.google.com/open?id=1nzlkaw8AMQwWIf-vLxQLwKXwoeA5ocZ0&gt;https://drive.google.com/open?id=1nzlkaw8AMQwWIf-vLxQLwKXwoeA5ocZ0&lt;/denchmark-link&gt;
. But if not you can always use it to do tests of performance.
		</comment>
		<comment id='5' author='set92' date='2019-06-17T21:26:06Z'>
		Thank you &lt;denchmark-link:https://github.com/set92&gt;@set92&lt;/denchmark-link&gt;
, working with this data was very fruitful.
Testing your dataset provided the following observations:

posted_on, trans_date and trans_date_di are datetimes, but no feedback is given if they are passed as categoricals. Mitigated by giving a warning for datetimes mascaraded as categoricals.
(mini) histograms break for the full DataFrame. The problem is that too many plots remain open, due to a missing closing statements in a specific execution flow. Solved by closing the plots.
For this larger dataset, percentages of near 0 and 100 are rounded so that they appear to that number exactly, which is confusing. These edge cases are now displayed as &lt; 0.1% and &gt; 99.9%.

The source of the errors seem to be the categorical variables with a high number of distinct values. I improved the detection for these scenario's and drop variables if they exceed a configurable threshold.
		</comment>
	</comments>
</bug>