<bug id='434' author='zkid18' open_date='2020-04-14T07:55:59Z' closed_time='2020-05-07T17:43:15Z'>
	<summary>Profiling stuck on variables reaching 99%</summary>
	<description>
Describe the bug
The profiling being stuck on variables stage reaching 99%.
Been waiting for about 2 hours without any further progress.
This error occurs when I sample my data while it working fine on the initial dataset
Any hints how I can debug this issue?
variables:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏ | 103/104 [22:26&lt;03:12, 192.91s/it]
To Reproduce
Data:
&lt;denchmark-code&gt;Int64Index: 860029 entries, 2264008 to 2388942
Columns: 103 entries, access_date to log_date
dtypes: Int64(69), float64(5), object(29)
memory usage: 739.0+ MB
None
2020.04.14 16:41:35] I Start profiling for df with shape (860 029, 103)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;def create_eda_html(df, report_file_name, is_sampled):
     df_to_profile = df
     if is_sampled:
         split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
         for _, sampled_index in split.split(df, df['label']):
             strat_df = df.loc[sampled_index]
         df_to_profile = strat_df
     logging.info("DF info \n", df_profile.info())
     logging.info("Start profiling for df with shape {}".format(df_to_profile.shape))
     profile = ProfileReport(df_to_profile, title='Pandas Profiling Report', html={'style': {'full_width': True}})
     if os.path.exists(os.path.join(ROOT_DIR, report_file_name)) and report_file_name.endswith('.html'):
         profile.to_file(output_file=os.path.join(ROOT_DIR, report_file_name))
     else:
         profile.to_file(output_file="your_report.html")
     logging.info("Pandas profiling file created")
&lt;/denchmark-code&gt;

Version information:
Version information is essential in reproducing and resolving bugs. Please report:

Python version: Python 3.6.7
Environment:  cmd
pip:

Click to expand 

appnope==0.1.0
astroid==2.3.3
astropy==4.0.1.post1
attr==0.3.1
attrs==19.3.0
backcall==0.1.0
beautifulsoup4==4.8.2
bleach==3.1.4
bs4==0.0.1
certifi==2019.11.28
chardet==3.0.4
confuse==1.0.0
cycler==0.10.0
decorator==4.4.2
defusedxml==0.6.0
entrypoints==0.3
et-xmlfile==1.0.1
flake8==3.7.9
htmlmin==0.1.12
idna==2.8
importlib-metadata==1.6.0
ipykernel==5.2.0
ipython==7.13.0
ipython-genutils==0.2.0
ipywidgets==7.5.1
isort==4.3.21
jedi==0.16.0
Jinja2==2.11.1
joblib==0.14.1
jsonschema==3.2.0
jupyter-client==5.3.4
jupyter-core==4.6.1
kaggle==1.5.6
kiwisolver==1.2.0
lazy-object-proxy==1.4.3
llvmlite==0.31.0
lxml==4.5.0
MarkupSafe==1.1.1
matplotlib==3.2.1
mccabe==0.6.1
missingno==0.4.2
mistune==0.8.4
more-itertools==8.2.0
nbconvert==5.6.1
nbformat==5.0.5
networkx==2.4
notebook==6.0.3
numba==0.48.0
numpy==1.18.2
packaging==20.3
pandas==0.25.3
pandas-profiling==2.5.0
pandocfilters==1.4.2
parso==0.6.2
pexpect==4.8.0
phik==0.9.9
pickleshare==0.7.5
pluggy==0.13.1
prometheus-client==0.7.1
prompt-toolkit==3.0.5
ptyprocess==0.6.0
py==1.8.1
pycodestyle==2.5.0
pyflakes==2.1.1
Pygments==2.6.1
pylint==2.4.4
pyparsing==2.4.7
pyrsistent==0.16.0
pytest==5.4.1
pytest-pylint==0.15.1
python-dateutil==2.8.1
python-slugify==4.0.0
pytz==2019.3
PyYAML==5.3
pyzmq==19.0.0
requests==2.22.0
scikit-learn==0.22.2.post1
scipy==1.4.1
seaborn==0.10.0
Send2Trash==1.5.0
six==1.14.0
sklearn==0.0
soupsieve==2.0
tangled-up-in-unicode==0.0.3
terminado==0.8.3
testpath==0.4.4
text-unidecode==1.3
tornado==6.0.4
tqdm==4.42.0
traitlets==4.3.3
typed-ast==1.4.1
urllib3==1.24.3
visions==0.2.2
wcwidth==0.1.9
webencodings==0.5.1
websocket-client==0.57.0
widgetsnbextension==3.5.1
wrapt==1.11.2
zipp==3.1.0



	</description>
	<comments>
		<comment id='1' author='zkid18' date='2020-04-14T09:18:44Z'>
		It could be that one of the columns is computationally intensive. Have you tried using the minimal mode?
		</comment>
		<comment id='2' author='zkid18' date='2020-04-14T09:50:50Z'>
		I thought about it, but as it works fine on a larger dataset with the same set of features, I think the problem occurs at the stratification stage.
		</comment>
		<comment id='3' author='zkid18' date='2020-04-14T11:21:46Z'>
		&lt;denchmark-code&gt;train_df = pd.read_csv(config_dict['DF_PATH'],names = train_columns.keys(), encoding='utf-8', dtype=train_columns, header=None, sep='\t')

from sklearn.model_selection import StratifiedShuffleSplit

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for _, sampled_index in split.split(train_df, train_df['label']):
    strat_df = train_df.loc[sampled_index]
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;train_df.info()
&lt;/denchmark-code&gt;


&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 5627871 entries, 0 to 5627870
Columns: 103 entries, access_date to log_date
dtypes: Int64(69), float64(5), object(29)
memory usage: 4.7+ GB

&lt;denchmark-code&gt;strat_df.info()
&lt;/denchmark-code&gt;


&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 1125575 entries, 5045554 to 431325
Columns: 103 entries, access_date to log_date
dtypes: Int64(69), float64(5), object(29)
memory usage: 967.2+ MB

If I launch my code with negative is_sampled flag the profiler works as expected although the size of the dataframe is 4 times larger.
		</comment>
		<comment id='4' author='zkid18' date='2020-04-14T11:23:28Z'>
		Can I somehow log the features through the progress bar
		</comment>
		<comment id='5' author='zkid18' date='2020-04-14T12:37:55Z'>
		
Can I somehow log the features through the progress bar

Add pbar.set_postfix({'feature_name': column[0]}) in src/pandas_profiling/model/describe.py line 599 may help you find out which variable stuck the progress
		</comment>
		<comment id='6' author='zkid18' date='2020-05-07T17:43:15Z'>
		The solution proposed by &lt;denchmark-link:https://github.com/loopyme&gt;@loopyme&lt;/denchmark-link&gt;
 will be in the next release.
		</comment>
	</comments>
</bug>