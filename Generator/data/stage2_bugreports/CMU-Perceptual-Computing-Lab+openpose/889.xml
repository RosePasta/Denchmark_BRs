<bug id='889' author='sergionegri' open_date='2018-10-23T08:30:33Z' closed_time='2019-01-06T06:25:45Z'>
	<summary>3D module behavior: perfoming worse adding cameras</summary>
	<description>
&lt;denchmark-h:h3&gt;Type of Issue&lt;/denchmark-h&gt;


Question

We are running the 3D module on the CMU-Panoptic dataset (dance).
We extracted 3, 4 and 5 HD videos.
We have noticed (qualitatively) that in general it performs better (in terms of segment plotted) with just 3 videos. Please keep in mind that when we have 4 videos we keep the first 3 as the 3-videos version and simply add a new one.
Let's have a look at one frame in specific:
&lt;denchmark-link:https://user-images.githubusercontent.com/10323575/47346621-dc639480-d6ad-11e8-8f7a-f84a94a64b8f.png&gt;&lt;/denchmark-link&gt;

A 1 in the table means we are getting the segment.
First 5 columns are the 2d views.
Last 3 columns are the 3d views with 3,4 and 5 videos respectively.
In rows we have the segment number.
In the first highlighted area (segment 3) we notice that in spite of the fact that the system in 2d works like a charm, in 3d (with 4 videos) it fails. We are tempted to say: hey, that's because the reprojection error for that point in that camera is bad. But shouldn't the system simply drop it and do the job with the other 3 views which work just fine?
EDIT: we realized that there is this option "--3d_min_views" which is by default set to -1 (all views). This should explain why adding cameras it performs worse: if any of the cameras is not detecting a keypoint it drops the point altogether. The logic is in this portion of code of poseTriangulation.cpp:
&lt;denchmark-code&gt;                   // If visible from all views (minViews3d &lt; 0)
                    // or if visible for at least minViews3d views
                    if ((minViews3d &lt; 0 &amp;&amp; cameraMatricesElement.size() == cameraMatrices.size())
                        || (minViews3d &gt; 1 &amp;&amp; minViews3d &lt;= (int)xyPointsElement.size()))
                    {
                        indexesUsed.emplace_back(part);
                        xyPoints.emplace_back(xyPointsElement);
                        cameraMatricesPerPoint.emplace_back(cameraMatricesElement);
                    } 
&lt;/denchmark-code&gt;

But this does not explain another phenomenon: in another frame (see below), with just 3 cameras, we have 2 cameras detecting the keypoint, and the third missing it...but nevertheless it detects the point in 3d (as if we had set the --3d_min_views to 2, which we never did). Also, in the example above, the 5 videos experiment should fail if the 4 videos does, bit it doesn't. How is this possible?
&lt;denchmark-link:https://user-images.githubusercontent.com/10323575/47413395-7428b780-d76e-11e8-987e-151300f53303.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='sergionegri' date='2018-10-29T16:55:37Z'>
		Ok so we found a couple of bugs that might cause the issue, and we've created a corresponding pull request &lt;denchmark-link:https://github.com/CMU-Perceptual-Computing-Lab/openpose/pull/904&gt;#904&lt;/denchmark-link&gt;
 . Fixing those improve performances greatly in terms of number of keypoints detected adding cameras.
There is still a bug which might cause the behavior*, but it can be ruled out for most of the cases.
What's even more worrying is that we've identified some frames in which the 2d keypoints are detected differently in the same image depending if we are using a 3 views or a 4 views setup. So basically we have 3 images, we run OP and read the JSON of the first view. Then we add an additional view and re-run it. Surprisingly the numbers are similar but not identical. Like it's performing a different scaling on the same image. We are talking about a few decimals, but this should not happen. The exact same image should deliver the same 2d points. We'll create a set of files so that anybody can play.
-* the bug happens in the following scenario: we have 3 cameras, the 3 of them with a low reprojection error on a given keypoint. We add 1 camera with a lousy reprojection error: cool, it gets killed by LOO algorithm. If we add an additional camera with lousy reprojection error one of the 2 bad cameras "survives" the LOO, and it worsen the reprojectionError globally compared to a 3 cameras setup. This might cause a point to be dropped. We acknoledge that this case is way more rare then the other 2 bugs we identified, and a decent camera setup should minimize that. The alternative would be a recursive solution that leaves out one or several cameras until the reprojection error is minimized. But this might generate second order issues.
		</comment>
		<comment id='2' author='sergionegri' date='2018-10-29T21:44:24Z'>
		&lt;denchmark-link:https://github.com/sergionegri&gt;@sergionegri&lt;/denchmark-link&gt;
 Yes, you are right,  is the reason of why more cameras results in less detections. I have re-thought a lot about what the default value of  should be, I believe -1 is not the ideal one, to avoid issues like in your case.
Do you believe the default value of 3d_min_views should be 3 to avoid confusion to other people? (as long as there are at least 3 cameras, the projection error can be checked to know if the reconstruction is good or not). Of course, if only 2 cameras is used, then, 3d_min_views should be 2 for that case.
(For your other questions, I'll need more time to answer it, as I implemented this long time ago and I haven't revisited it in a while)
		</comment>
		<comment id='3' author='sergionegri' date='2018-10-30T14:17:51Z'>
		I'd definitely consider a different value for 3d_min_views. We use 2 at the moment. In a normal environment it's quite likely to have a self occlusion in multi-view, and the story here IMHO is to reconstruct a skeleton, not just a handful of keypoints, so the priority should be get as many point as possible. Then of course, once we have as many keypoints as possible we have ditch the bad views.
		</comment>
		<comment id='4' author='sergionegri' date='2019-05-16T23:24:42Z'>
		Added &lt;denchmark-link:https://github.com/CMU-Perceptual-Computing-Lab/openpose/pull/904&gt;#904&lt;/denchmark-link&gt;
 to OpenPose.
In addition, the default --3d_min_views will now be max(2, min(4, #cameras-1)). For many camera views, 4 is the optimal value for our code because it enables non-linear optimization. However, if there are only 2-4 cameras, we cannot do that.
Note: I also found another bug thanks to your PR. You updated the value of projectionError at the end, which I forgot to update. But the problem is that I also forgot to actually update the 3D reconstructed point (reconstructedPoint), so it making no effect. It was indeed being partially improved because the non-linear optimization were omitting the noisy camera (that is removed in this step). But it was starting from the noisy initial point rather than the new less noisy one.
So the new code that I have just pushed fixes this issue and should hopefully close all the problems you were facing! Thanks for the PR, I would have not caught it without it.
		</comment>
	</comments>
</bug>