<bug id='723' author='AllardJM' open_date='2019-10-25T00:49:08Z' closed_time='2019-11-14T17:08:37Z'>
	<summary>LightGBMClassifier Very Slow</summary>
	<description>
Describe the bug
I am attempting to train a LightGBMClassifier on a dataframe with 2.5 million rows and ~30 columns. This is a very basic MLLIB pipeline where the model is being fit with essentially all default settings. It took 1 hour and 54 minutes to complete. For comparison, a similar run with the commented out GBTClassifier() took about 5 minutes.
Are there any known issues with this version (the newest version appears unavailable - see &lt;denchmark-link:https://github.com/Azure/mmlspark/issues/718&gt;#718&lt;/denchmark-link&gt;
) or settings recommended with the Spark?
&lt;denchmark-code&gt;#set up pipeline and fit

stages = []

#target label
label_stringIdx = StringIndexer(inputCol = target_col[0], outputCol = 'label')
stages += [label_stringIdx]

#numeric (would also build up with categorical using StringIndexer and OneHotEncoderEstimator)
assembler = VectorAssembler(inputCols=input_cols, outputCol="features")
stages += [assembler]


#model
#gbt = GBTClassifier(labelCol="label", featuresCol="features", maxIter=50)
#stages += [gbt]




lgb_estimator = LightGBMClassifier(learningRate=0.1,
                                   earlyStoppingRound=10,
                                   featuresCol='features',
                                   labelCol="label" )
stages += [lgb_estimator]

#pipeline
pipelineModel = Pipeline(stages=stages)


start = time.time()
#fit train
model = pipelineModel.fit(train)

end = time.time()
print(elapsedtime(start,end))


#predict
preds=model.transform(test)
#preds.show(10)

&lt;/denchmark-code&gt;

Info (please complete the following information):

MMLSpark Version: pyspark --packages com.microsoft.ml.spark:mmlspark_2.11:0.18.1
Spark Version 2.4.3
Spark Platform EMR

	</description>
	<comments>
		<comment id='1' author='AllardJM' date='2019-10-25T00:49:10Z'>
		üëã Thanks for opening your first issue here! If you're reporting a üêû bug, please make sure you include steps to reproduce it.
		</comment>
		<comment id='2' author='AllardJM' date='2019-11-04T04:30:56Z'>
		&lt;denchmark-link:https://github.com/AllardJM&gt;@AllardJM&lt;/denchmark-link&gt;
  sorry about the trouble you are having.  Could you please send the spark logs?  Also, how many executors are you seeing running?  My guess is that not all of the executors are running during training.  It may be a cluster configuration that the code might not be expecting and it might be underutilizing the available resources.
		</comment>
		<comment id='3' author='AllardJM' date='2019-11-14T17:08:37Z'>
		This appears to have been fixed by not using the defaults for pyspark (driver memory etc). I am able to get a model trained in 2 minutes and am closing this issue.
		</comment>
	</comments>
</bug>