<bug id='664' author='chris-smith-zocdoc' open_date='2019-08-23T23:37:18Z' closed_time='2019-08-31T04:14:25Z'>
	<summary>java.lang.ClassCastException during training</summary>
	<description>
Describe the bug
java.lang.ClassCastException during training of LightGBMRanker
Exception appears to come from &lt;denchmark-link:https://github.com/Azure/mmlspark/blob/master/src/main/scala/com/microsoft/ml/spark/lightgbm/LightGBMBase.scala#L88&gt;this line&lt;/denchmark-link&gt;

I am using BarrierExecutionMode
Info (please complete the following information):

MMLSpark Version: com.microsoft.ml.spark:mmlspark_2.11:0.18.1
Spark Version 2.4.3
Spark Platform Databricks
5.5 ML Runtime

** Stacktrace**
&lt;denchmark-code&gt;Py4JJavaError: An error occurred while calling o1203.fit.
: org.apache.spark.SparkException: Job aborted due to stage failure: Could not recover from a failed barrier ResultStage. Most recent failure reason: Stage failed because barrier task ResultTask(54, 1) finished unsuccessfully.
java.lang.ClassCastException

	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2355)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2343)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2342)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2342)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:2131)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2571)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2510)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:893)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2243)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2341)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1051)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:379)
	at org.apache.spark.rdd.RDD.reduce(RDD.scala:1033)
	at com.microsoft.ml.spark.lightgbm.LightGBMBase$class.innerTrain(LightGBMBase.scala:88)
	at com.microsoft.ml.spark.lightgbm.LightGBMRanker.innerTrain(LightGBMRanker.scala:25)
	at com.microsoft.ml.spark.lightgbm.LightGBMBase$class.train(LightGBMBase.scala:38)
	at com.microsoft.ml.spark.lightgbm.LightGBMRanker.train(LightGBMRanker.scala:25)
	at com.microsoft.ml.spark.lightgbm.LightGBMRanker.train(LightGBMRanker.scala:25)
	at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)
	at py4j.Gateway.invoke(Gateway.java:295)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:251)
	at java.lang.Thread.run(Thread.java:748)
&lt;/denchmark-code&gt;


Possibly a duplicate of &lt;denchmark-link:https://github.com/Azure/mmlspark/issues/629&gt;#629&lt;/denchmark-link&gt;
 ?
Please let me know if I can provide additional details to help debug
More logs
The connection between the nodes appears to succeed and it is failing when trying to &lt;denchmark-link:https://github.com/Azure/mmlspark/blob/master/src/main/scala/com/microsoft/ml/spark/lightgbm/LightGBMBase.scala#L88&gt;reduce the results&lt;/denchmark-link&gt;
.
&lt;denchmark-code&gt;19/08/23 23:19:20 INFO LightGBMRanker: LightGBM worker listening on: 12407
19/08/23 23:19:20 INFO LightGBMRanker: LightGBM worker listening on: 12401
19/08/23 23:19:20 INFO LightGBMRanker: LightGBM worker got nodes for network init: 10.222.225.246:12402,10.222.225.246:12403,10.222.225.246:12404,10.222.236.57:12408,10.222.225.246:12401,10.222.225.246:12407,10.222.225.246:12406,10.222.225.246:12400,10.222.225.246:12405,10.222.236.57:12409,10.222.236.57:12411,10.222.236.57:12413,10.222.236.57:12412,10.222.236.57:12410,10.222.236.57:12414,10.222.236.57:12415
19/08/23 23:19:20 INFO LightGBMRanker: LightGBM worker listening on: 12405
19/08/23 23:19:20 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8945 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8145 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8057 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8045 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8234 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8469 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 8671 rows and 79 columns
19/08/23 23:19:30 INFO LightGBMRanker: LightGBM worker generating sparse dataset with 7921 rows and 79 columns
19/08/23 23:19:30 ERROR Executor: Exception in task 8.0 in stage 76.0 (TID 1275)
java.lang.ClassCastException
19/08/23 23:19:30 ERROR Executor: Exception in task 14.0 in stage 76.0 (TID 1281)
java.lang.ClassCastException
19/08/23 23:19:30 ERROR Executor: Exception in task 10.0 in stage 76.0 (TID 1277)
java.lang.ClassCastException
19/08/23 23:19:30 ERROR Executor: Exception in task 12.0 in stage 76.0 (TID 1279)
java.lang.ClassCastException
19/08/23 23:19:30 ERROR Executor: Exception in task 2.0 in stage 76.0 (TID 1269)
java.lang.ClassCastException
19/08/23 23:19:30 ERROR Executor: Exception in task 0.0 in stage 76.0 (TID 1267)
java.lang.ClassCastException
19/08/23 23:19:30 INFO Executor: Executor is trying to kill task 4.0 in stage 76.0 (TID 1271), reason: Task ResultTask(76, 11) from barrier stage ResultStage 76 (reduce at LightGBMBase.scala:88) failed.
19/08/23 23:19:30 INFO Executor: Executor is trying to kill task 6.0 in stage 76.0 (TID 1273), reason: Task ResultTask(76, 11) from barrier stage ResultStage 76 (reduce at LightGBMBase.scala:88) failed.
19/08/23 23:19:30 INFO Executor: Executor is trying to kill task 0.0 in stage 76.0 (TID 1267), reason: Task ResultTask(76, 11) from barrier stage ResultStage 76 (reduce at LightGBMBase.scala:88) failed.
19/08/23 23:19:30 INFO Executor: Executor interrupted and killed task 6.0 in stage 76.0 (TID 1273), reason: Task ResultTask(76, 11) from barrier stage ResultStage 76 (reduce at LightGBMBase.scala:88) failed.
19/08/23 23:19:30 INFO Executor: Executor interrupted and killed task 4.0 in stage 76.0 (TID 1271), reason: Task ResultTask(76, 11) from barrier stage ResultStage 76 (reduce at LightGBMBase.scala:88) failed.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='chris-smith-zocdoc' date='2019-08-23T23:37:19Z'>
		üëã Thanks for opening your first issue here! If you're reporting a üêû bug, please make sure you include steps to reproduce it.
		</comment>
		<comment id='2' author='chris-smith-zocdoc' date='2019-08-25T20:40:18Z'>
		Was able to narrow this one down. This appears to be occurring when the group column is not an integer type.
I believe the exception is actually thrown here &lt;denchmark-link:https://github.com/Azure/mmlspark/blob/master/src/main/scala/com/microsoft/ml/spark/lightgbm/TrainUtils.scala#L101-L106&gt;https://github.com/Azure/mmlspark/blob/master/src/main/scala/com/microsoft/ml/spark/lightgbm/TrainUtils.scala#L101-L106&lt;/denchmark-link&gt;

There should probably be a check to validate the groupColumn is a numeric type and give the user a clearer error message if it is not. I'd be happy to submit the PR if this seems like a good approach
import mmlspark
import pandas as pd 
import numpy as np
import pyspark.sql.functions as fn

from pyspark.sql.types import *
from pyspark.ml.feature import VectorAssembler
from mmlspark.lightgbm import LightGBMRanker
from scipy.sparse import rand

model = LightGBMRanker(learningRate=0.3,
                        numIterations=5,
                        numLeaves=31)

model.setGroupCol('search_id')
model.setUseBarrierExecutionMode(True)

num_cols = 60
num_rows = 1000

def create_row(i):
  m = np.array(rand(1, num_cols + 2, density=.2, format='csr').todense())[0]
  m[0] = int(i // 10) # search id
  m[1] = int(i % 10 == 0) # label
  return m.tolist()

feat_cols = ['feat_{}'.format(c) for c in range(num_cols)]

df = spark.createDataFrame(pd.DataFrame([create_row(i) for i in range(num_rows)], columns=[ 'search_id', 'label'] + feat_cols ))

df = df.withColumn('label', fn.col('label').cast(IntegerType()))
df = df.withColumn('search_id', fn.col('search_id').cast(StringType())) # &lt;-- Accidentally a string instead of an int

assembler = VectorAssembler().setInputCols(feat_cols).setOutputCol('features')
transformed = assembler.transform(df)

transformed = transformed.repartition(sc.defaultParallelism, 'search_id')

m = model.fit(transformed)
		</comment>
		<comment id='3' author='chris-smith-zocdoc' date='2019-08-26T04:23:52Z'>
		&lt;denchmark-link:https://github.com/chris-smith-zocdoc&gt;@chris-smith-zocdoc&lt;/denchmark-link&gt;
 thank you for narrowing down the issue and figuring out what the fix should be.  I definitely wouldn't have been able to figure this out from the stack trace above, since it does not point to this line of code.  If you can submit a fix, that would be great.  Otherwise I can submit a fix after I get through a couple other issues.
		</comment>
	</comments>
</bug>