<bug id='3714' author='lcy-seso' open_date='2017-08-28T03:20:51Z' closed_time='2017-10-09T06:55:04Z'>
	<summary>get_grad returns zero matrix when use_gpu=True</summary>
	<description>
I use this PR &lt;denchmark-link:https://github.com/PaddlePaddle/Paddle/pull/3085&gt;#3085&lt;/denchmark-link&gt;
 to print parameter values and gradients in .
My usage is as the follows:
def show_parameter_status(parameters):
    # for debug print
    for p in parameters:
        value = parameters.get(p)
        grad = parameters.get_grad(p)

        avg_abs_value = np.average(np.abs(value))
        avg_abs_grad = np.average(np.abs(grad))

        logger.info(
            ("%s avg_abs_value=%.6f avg_abs_grad=%.6f "
             "min_value=%.6f max_value=%.6f min_grad=%.6f max_grad=%.6f") %
            (p, avg_abs_value, avg_abs_grad, value.min(), value.max(),
             grad.min(), grad.max()))

But I found when set use_gpu=True in train.init(), get_grad always returns an all-zero matrix.
when I change use_gpu=False and keep all the other things unchanged, it returns a non-zeros matrix.
My training cost decreases so I think the gradient matrices should be non-zeros.

	</description>
	<comments>
		<comment id='1' author='lcy-seso' date='2017-08-29T03:52:16Z'>
		Hi, I found this may due to my own problem. Please let me check my program first. Thanks for the help.
		</comment>
		<comment id='2' author='lcy-seso' date='2017-09-08T07:28:01Z'>
		Is this still affect your program?
		</comment>
		<comment id='3' author='lcy-seso' date='2017-09-26T05:27:46Z'>
		Sorry, I gave a wrong information and forgot to reply you, very sorry.
Finally, I still found get_grad cannot get the gradient matrix in GPU mode. I guess gradient matrix is not correctly copied.
		</comment>
		<comment id='4' author='lcy-seso' date='2017-09-26T05:29:43Z'>
		Will try to fix.
		</comment>
	</comments>
</bug>