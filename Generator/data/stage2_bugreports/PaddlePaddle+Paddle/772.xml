<bug id='772' author='CrossLee1' open_date='2016-12-08T05:35:46Z' closed_time='2017-07-29T13:46:54Z'>
	<summary>Questions regarding "rank_cost"</summary>
	<description>
I use the provided rank_cost loss function for my training, with trainer_count = 4.
In the end of each pass, the log will print the info of pos/neg.
At the end of Pass-00000, the log info is as follows:
13:14:26.505049  9642 CostLayer.cpp:283] calc pos/neg: 1.71909 pos= 4088 neg= 2378
13:14:26.505116  9642 CostLayer.cpp:283] calc pos/neg: 1.82728 pos= 4179 neg= 2287
13:14:26.505129  9642 CostLayer.cpp:283] calc pos/neg: 1.80886 pos= 4164 neg= 2302
13:14:26.505141  9642 CostLayer.cpp:283] calc pos/neg: 1.81664 pos= 4171 neg= 2296
13:14:26.505161  9642 TrainerInternal.cpp:179]  Pass=0 Batch=203 samples=25865 AvgCost=0.629527 Eval:
13:14:27.374795  9642 Tester.cpp:111]  Test samples=1450 cost=0.459305 Eval:
13:14:27.374897  9642 GradientMachine.cpp:112] Saving parameters to ./models/pass-00000
The sum of the number of samples in each trainer (4088+2378+4179+2287+4164+2302+4171+2296)
is just equal to the number of training samples (25856), which is correct.
However, at the end of Pass-00001, the log is:
13:14:42.750605  9642 CostLayer.cpp:283] calc pos/neg: 2.94454 pos= 5097 neg= 1731
13:14:42.750634  9642 CostLayer.cpp:283] calc pos/neg: 3.07215 pos= 5152 neg= 1677
13:14:42.750646  9642 CostLayer.cpp:283] calc pos/neg: 3.32152 pos= 5248 neg= 1580
13:14:42.750658  9642 CostLayer.cpp:283] calc pos/neg: 3.20567 pos= 5206 neg= 1624
13:14:42.750675  9642 TrainerInternal.cpp:179]  Pass=1 Batch=203 samples=25865 AvgCost=0.525822 Eval:
13:14:43.613981  9642 Tester.cpp:111]  Test samples=1450 cost=0.404172 Eval:
13:14:43.614042  9642 GradientMachine.cpp:112] Saving parameters to ./models/pass-00001
The sum of the number of samples in each trainer (5097+1731+5152+1677+5248+1580+5206+1624)
does not equal to 25865, but is 27315, the sum of training samples and testing samples (25865+1450).
Also in the subsequent pass, this sum number is always 27315, rather than 25865.
It seems to count the pos/neg ratio using the training samples and test samples together, which is not appropriate in my opinion.
Then how could I get the pos/neg ratio of training and testing samples separately?
Thanks~
	</description>
	<comments>
		<comment id='1' author='CrossLee1' date='2016-12-08T09:45:08Z'>
		Thank you for pointing out this. This is a bug in PaddlePaddle.
The ratio of positive pairs versus negative pairs are now evaluated in forward in CostLayer, and CostLayer dose not distinguish training and testing process. Finally, leading to the problem you pointed out.
I guess you both provide training and testing set in PyDataprovider, so that PaddlePaddle training and testing in a same process.
The easiest way to fix the bug is to train and to test in separate process, by starting 2 processes with only specifying training or testing set for each one.
We will fix this bug soon.
		</comment>
		<comment id='2' author='CrossLee1' date='2017-07-19T08:35:11Z'>
		We will fix this bug soon.
		</comment>
	</comments>
</bug>