<bug id='902' author='wchange' open_date='2016-12-15T03:23:54Z' closed_time='2017-09-10T09:01:36Z'>
	<summary>单层softmax训练报错NotImplementedError</summary>
	<description>
Traceback (most recent call last):
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py", line 3408, in parse_config_and_serialize
Thu Dec 15 11:16:14 2016[1,37]:    config = parse_config(config_file, config_arg_str)
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py", line 3384, in parse_config
Thu Dec 15 11:16:14 2016[1,37]:    execfile(config_file, make_config_environment(config_file, config_args))
Thu Dec 15 11:16:14 2016[1,37]:  File "conf/trainer_config.conf", line 63, in 
Thu Dec 15 11:16:14 2016[1,37]:    regularization=L2Regularization(8e-4)
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py", line 53, in wrapper
Thu Dec 15 11:16:14 2016[1,37]:    return func(*args, **kwargs)
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py", line 53, in wrapper
Thu Dec 15 11:16:14 2016[1,37]:    return func(*args, **kwargs)
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/optimizers.py", line 422, in settings
Thu Dec 15 11:16:14 2016[1,37]:    kwargs = extends(kwargs, learning_method.to_setting_kwargs())
Thu Dec 15 11:16:14 2016[1,37]:  File "workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/optimizers.py", line 71, in to_setting_kwargs
Thu Dec 15 11:16:14 2016[1,37]:    raise NotImplementedError()
Thu Dec 15 11:16:14 2016[1,37]:NotImplementedError
	</description>
	<comments>
		<comment id='1' author='wchange' date='2016-12-15T03:28:37Z'>
		请贴上你的网络配置
		</comment>
		<comment id='2' author='wchange' date='2016-12-15T04:49:51Z'>
		&lt;denchmark-code&gt;define_py_data_sources2(train_list=trn,
                        test_list=tst,
                        module="user_image_provider",
                        obj=process,
                        args={})

batch_size = 16 if not is_predict else 1
settings(
    batch_size=batch_size,
    learning_rate=2e-4,
    learning_method=BaseSGDOptimizer(),
    regularization=L2Regularization(8e-4)
)

data = data_layer(name="input", size=40135)
output = fc_layer(input=data, size=2, act=SoftmaxActivation())

if not is_predict:
    label = data_layer(name="label", size=2)

    classification_cost(input=output, label=label)
    cls = classification_cost(input=output, label=label)
    outputs(cls)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='wchange' date='2016-12-15T05:20:05Z'>
		learning_method=BaseSGDOptimizer()这行可以去掉，默认就是SGD
		</comment>
		<comment id='4' author='wchange' date='2016-12-15T05:24:03Z'>
		不好使啊，之前是下面的配置
&lt;denchmark-code&gt;settings(
    batch_size=batch_size,
    learning_rate=2e-4,
    learning_method=AdamOptimizer(),
    regularization=L2Regularization(8e-4),
    gradient_clipping_threshold=25
)
&lt;/denchmark-code&gt;

报Floating point exception
		</comment>
		<comment id='5' author='wchange' date='2016-12-15T05:24:20Z'>
		&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;

BaseSGDOptimizer这个基类不应该被暴露的吧， 感觉要发个pr，用__all__避免这个基类的导出。
		</comment>
		<comment id='6' author='wchange' date='2016-12-15T05:29:08Z'>
		现在其实就想做个ctr预估，训练一个lr模型，请问能否提供一个比较通用的配置？
		</comment>
		<comment id='7' author='wchange' date='2016-12-15T05:30:49Z'>
		&lt;denchmark-link:https://github.com/backyes&gt;@backyes&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/reyoung&gt;@reyoung&lt;/denchmark-link&gt;
 在__all__中把BaseSGDOptimizer直接去掉可以么？
		</comment>
		<comment id='8' author='wchange' date='2016-12-16T09:32:08Z'>
		sparse_vector有什么使用限制吗？定义域之类的？
		</comment>
		<comment id='9' author='wchange' date='2017-09-10T09:01:36Z'>
		I close this issue due to inactivity. please feel free to reopen it.
		</comment>
	</comments>
</bug>