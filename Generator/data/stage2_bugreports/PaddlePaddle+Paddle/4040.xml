<bug id='4040' author='xinrenax' open_date='2017-09-12T09:17:52Z' closed_time='2018-07-03T11:48:34Z'>
	<summary>paddle infer 调用报错</summary>
	<description>
&lt;denchmark-code&gt;I0912 16:43:00.254079 31956 Util.cpp:166] commandline:  --use_gpu=False --trainer_count=10
F0912 16:50:59.816350 32132 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295)
*** Check failure stack trace: ***
    @     0x7f320cdf5e6d  google::LogMessage::Fail()
    @     0x7f320cdf991c  google::LogMessage::SendToLog()
    @     0x7f320cdf5993  google::LogMessage::Flush()
    @     0x7f320cdfae2e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f320cd570fe  paddle::SparseRowCpuMatrix::getRow()
F0912 16:50:59.824956 32139 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295)
*** Check failure stack trace: ***
    @     0x7f320cd5a9b1  paddle::CpuMatrix::mul&lt;&gt;()
    @     0x7f320cdf5e6d  google::LogMessage::Fail()
    @     0x7f320cd543f3  paddle::CpuMatrix::mul()
    @     0x7f320cdf991c  google::LogMessage::SendToLog()
    @     0x7f320cdf5993  google::LogMessage::Flush()
    @     0x7f320cb17193  paddle::FullyConnectedLayer::forward()
    @     0x7f320cdfae2e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f320cc5c690  paddle::NeuralNetwork::forward()
    @     0x7f320cc3bb6c  paddle::TrainerThread::forward()
    @     0x7f320cc3dd38  paddle::TrainerThread::computeThread()
    @     0x7f320cd570fe  paddle::SparseRowCpuMatrix::getRow()
    @     0x7f321793a8a0  execute_native_thread_routine
    @     0x7f320cd5a9b1  paddle::CpuMatrix::mul&lt;&gt;()
    @     0x7f320cd543f3  paddle::CpuMatrix::mul()
    @     0x7f320cb17193  paddle::FullyConnectedLayer::forward()
    @     0x7f320cc5c690  paddle::NeuralNetwork::forward()
F0912 16:50:59.824956 32139 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F0912 16:50:59.845768 32135 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295v
s. 4294967295)
*** Check failure stack trace: ***
    @     0x7f320cc3bb6c  paddle::TrainerThread::forward()
*** Check failure stack trace: ***
    @     0x7f320cc3bb6c  paddle::TrainerThread::forward()
F0912 16:50:59.824956 32139 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F0912 16:50:59.845768 32135 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295v
s. 4294967295) F0912 16:50:59.847061 32134 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295)
*** Check failure stack trace: ***
    @     0x7f320cdf5e6d  google::LogMessage::Fail()
    @     0x7f328c9d91c3  start_thread
    @     0x7f320cdf5e6d  google::LogMessage::Fail()
    @     0x7f320cc3dd38  paddle::TrainerThread::computeThread()
    @     0x7f320cdf991c  google::LogMessage::SendToLog()
    @     0x7f320cdf991c  google::LogMessage::SendToLog()
    @     0x7f321793a8a0  execute_native_thread_routine
    @     0x7f320cdf5993  google::LogMessage::Flush()
F0912 16:50:59.824956 32139 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F0912 16:50:59.845768 32135 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295v
s. 4294967295) F0912 16:50:59.847061 32134 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F0912 16:50:59.850940 32140 SparseRowMatrix.h:61] Check failed: globalIndices_[row] != kUnusedI
d_ (4294967295 vs. 4294967295)
*** Check failure stack trace: ***
    @     0x7f320cdf5993  google::LogMessage::Flush()
    @     0x7f328c00112d  __clone
    @     0x7f320cdfae2e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f320cdf5e6d  google::LogMessage::Fail()
    @     0x7f320cdfae2e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7f328c9d91c3  start_thread
    @     0x7f320cd570fe  paddle::SparseRowCpuMatrix::getRow()
    @     0x7f320cdf991c  google::LogMessage::SendToLog()
    @     0x7f320cd5a9b1  paddle::CpuMatrix::mul&lt;&gt;()
    @     0x7f320cdf5993  google::LogMessage::Flush()
    @              (nil)  (unknown)
    @     0x7f328c00112d  __clone
&lt;/denchmark-code&gt;

已放弃
	</description>
	<comments>
		<comment id='1' author='xinrenax' date='2017-09-12T09:26:45Z'>
		请描述一下问题背景，使用的是什么模型，在什么环境下进行infer，python还是capi。
		</comment>
		<comment id='2' author='xinrenax' date='2017-09-12T09:32:42Z'>
		用的的python，本地模式，模型的网络结果是自己写的，参考了ctr预估的模型
		</comment>
		<comment id='3' author='xinrenax' date='2017-09-12T09:34:08Z'>
		网络训练正常，看loss的下降和auc的evaluate也是合理的
		</comment>
		<comment id='4' author='xinrenax' date='2017-09-12T09:37:16Z'>
		能把python的infer程序贴一下吗
		</comment>
		<comment id='5' author='xinrenax' date='2017-09-12T09:37:46Z'>
		怀疑是稀疏输入的稀疏率不够高，导致缓存超出了默认buf的大小，我们先确认下。还是先将infer代码贴下，方便我们跟进
		</comment>
		<comment id='6' author='xinrenax' date='2017-09-12T09:39:47Z'>
		infer的代码如下
paddle.init(use_gpu=False, trainer_count=10)
model = Model(config.FEA_DIMS)
predict = model.predict
&lt;denchmark-code&gt;with gzip.open(model_path, 'r') as f:
    parameters = Parameters.from_tar(f)

test_data = []
for d in dataset.infer():
    test_data.append(d)

probs = paddle.infer(
            output_layer=predict,
            parameters=parameters,
            input=test_data,
            feeding=config.FEEDING_INPUT)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='xinrenax' date='2017-09-12T09:48:35Z'>
		把
&lt;denchmark-code&gt;paddle.init(use_gpu=False, trainer_count=10)
&lt;/denchmark-code&gt;

改为
&lt;denchmark-code&gt;paddle.init(use_gpu=False)
&lt;/denchmark-code&gt;

试一下
		</comment>
		<comment id='8' author='xinrenax' date='2017-09-12T10:31:59Z'>
		刚刚试了一下，现在跑出结果了。谢谢~~~
		</comment>
		<comment id='9' author='xinrenax' date='2017-09-15T07:08:39Z'>
		Reopen for this bug has not been fixed in paddle.
		</comment>
		<comment id='10' author='xinrenax' date='2018-07-03T11:48:34Z'>
		Upgrade to fluid now is the best resolution.
		</comment>
	</comments>
</bug>