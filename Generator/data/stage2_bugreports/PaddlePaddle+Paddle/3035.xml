<bug id='3035' author='Damon-wyg' open_date='2017-07-24T14:24:27Z' closed_time='2017-10-31T01:54:02Z'>
	<summary>集群train的过程卡死</summary>
	<description>
在集群上跑模型时，任务挂了，单机跑测试时是可以正常运行的。paddle版本是v1.相关报错信息如下：
train.log里
&lt;denchmark-code&gt;Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;:*********************Shell Script Stack Trace********************
Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;: @: [./log.sh: 41] log_fatal
Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;: @: [./common.sh: 399] kill_pserver2_exit
Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;: @: [./train.sh: 210] main
Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;:
Mon Jul 24 18:41:05 2017[1,3]&lt;stderr&gt;:+ exit 1
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:+ log_fatal 'paddle_trainer failed kill paddle_pserver2 and exit'
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:+ echo '[./common.sh : 399] [kill_pserver2_exit]'
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:[./common.sh : 399] [kill_pserver2_exit]
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:+ echo '[FATAL]: paddle_trainer failed kill paddle_pserver2 and exit'
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:[FATAL]: paddle_trainer failed kill paddle_pserver2 and exit
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:+ get_stack
Mon Jul 24 18:41:05 2017[1,25]&lt;stderr&gt;:+ set +x
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:+ log_fatal 'paddle_trainer failed kill paddle_pserver2 and exit'
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:+ echo '[./common.sh : 399] [kill_pserver2_exit]'
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:[./common.sh : 399] [kill_pserver2_exit]
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:+ echo '[FATAL]: paddle_trainer failed kill paddle_pserver2 and exit'
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:[FATAL]: paddle_trainer failed kill paddle_pserver2 and exit
Mon Jul 24 18:41:05 2017[1,6]&lt;stderr&gt;:+ get_stack

堆栈信息：
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:.*** Error in `./paddle_trainer': free(): invalid pointer: 0x00000000083da0c0 ***
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:======= Backtrace: =========
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x7354f)[0x7fa0eb39f54f]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x78dbe)[0x7fa0eb3a4dbe]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:/opt/compiler/gcc-4.8.2/lib/libc.so.6(+0x79a97)[0x7fa0eb3a5a97]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer[0x74a983]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer(_ZN6paddle15TrainerInternal13trainOneBatchElRKNS_9DataBatchEPSt6vectorINS_8ArgumentESaIS5_EE+0xb33)[0x74bf23]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer(_ZN6paddle7Trainer17trainOneDataBatchERNS_9DataBatchE+0x166)[0x749616]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer(_ZN6paddle7Trainer12trainOnePassEv+0x13d)[0x749abd]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer(_ZN6paddle7Trainer5trainEm+0x95)[0x74a375]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer(main+0x350)[0x5a3d70]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:/opt/compiler/gcc-4.8.2/lib/libc.so.6(__libc_start_main+0xf5)[0x7fa0eb34dbd5]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:./paddle_trainer[0x5b2169]
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:======= Memory map: ========

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Damon-wyg' date='2017-07-25T00:21:28Z'>
		Additional info:
&lt;denchmark-code&gt;Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:*** Aborted at 1500892864 (unix time) try "date -d @1500892864" if you are using GNU date ***
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:PC: @                0x0 (unknown)
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:*** SIGABRT (@0x1fa0000313e) received by PID 12606 (TID 0x7fa0ec94e780) from PID 12606; stack trace: ***
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0ec109160 (unknown)
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb3613f7 __GI_raise
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb3627d8 __GI_abort
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb39f554 __libc_message
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb3a4dbe malloc_printerr
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb3a5a97 _int_free
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x74a983 _ZNSt14_Function_base13_Base_managerIZN6paddle15TrainerInternal13trainOneBatchElRKNS1_9DataBatchEPSt6vectorINS1_8ArgumentESaIS7_EEEUlPNS1_9ParameterEE_E10_M_managerERSt9_Any_dataRKSF_St18_Manager_operation
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x74bf23 paddle::TrainerInternal::trainOneBatch()
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x749616 paddle::Trainer::trainOneDataBatch()
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x749abd paddle::Trainer::trainOnePass()
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x74a375 paddle::Trainer::train()
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x5a3d70 main
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @     0x7fa0eb34dbd5 __libc_start_main
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @           0x5b2169 (unknown)
Mon Jul 24 18:41:04 2017[1,34]&lt;stderr&gt;:    @                0x0 (unknown)
Mon Jul 24 18:41:05 2017[1,34]&lt;stderr&gt;:./train.sh: line 207: 12606 Aborted                 PYTHONPATH=./paddle:$PYTHONPATH GLOG_logtostderr=0 GLOG_log_dir="./log" ./paddle_trainer --num_gradient_servers=${OMPI_COMM_WORLD_SIZE} --trainer_id=${OMPI_COMM_WORLD_RANK} --pservers=$ipstring --rdma_tcp=${rdma_tcp} --nics=${nics} ${train_arg} --config=conf/trainer_config.conf --save_dir=./${save_dir} ${extern_arg}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='Damon-wyg' date='2017-07-25T06:26:15Z'>
		能否检查下是否是

是否是内存不足了？
libc和libgcc等库的版本兼容问题

		</comment>
		<comment id='3' author='Damon-wyg' date='2017-07-26T03:17:09Z'>
		这个是在集群跑的，没有权限登陆诶
		</comment>
		<comment id='4' author='Damon-wyg' date='2017-07-26T12:30:03Z'>
		&lt;denchmark-link:https://github.com/Damon-wyg&gt;@Damon-wyg&lt;/denchmark-link&gt;
 可以本地跑下程序，使用一部分样本，观察下内存的占用情况么？
		</comment>
		<comment id='5' author='Damon-wyg' date='2017-07-26T14:07:21Z'>
		只观测到在训练过程中的内存分配错误。如果能抓到现场环境，看一下当时内存是否爆掉了。如果当时该节点只有paddle job在跑，那么使用固定数量的样本，例如10000条，观察一个batch时候内存占用情况。
暂时在代码层面没有找到bug。
&lt;denchmark-link:https://github.com/Damon-wyg&gt;@Damon-wyg&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='Damon-wyg' date='2017-10-31T01:54:02Z'>
		Closing due to low activity. Feel free to reopen it.
		</comment>
	</comments>
</bug>