<bug id='329' author='Lzc6996' open_date='2016-11-03T05:25:30Z' closed_time='2017-07-18T10:52:16Z'>
	<summary>GPU测试，用的核数量不同，导致测试结果有差。</summary>
	<description>
分别用1,2,3个GPU进行test,得到auc分别是76,71,67。数据用的proto格式。单核test的结果和cpu结果一致。
	</description>
	<comments>
		<comment id='1' author='Lzc6996' date='2016-11-03T05:35:56Z'>
		能贴出详细一点的信息么，比如网络配置、数据格式么？单核test的结果和cpu结果一致：是指单个GPU和单个CPU结果比么？
		</comment>
		<comment id='2' author='Lzc6996' date='2016-11-03T05:42:33Z'>
		&lt;denchmark-link:https://github.com/baidu/Paddle/files/568246/trainer_config.txt&gt;trainer_config.txt&lt;/denchmark-link&gt;

这是配置文件。
数据是proto的
格式是0;0 denseslot(200);1 denseslot(200);2 sparseslot(9246);3 0;第三个特征没用到
我的cpu测试结果是提交cpu集群训练的时候测试的。集群测试的结果与单个gpu测试的结果相同。
&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 您看一下
		</comment>
		<comment id='3' author='Lzc6996' date='2016-11-03T08:13:02Z'>
		你是用同样的模型来做test，得到不同的auc么？
		</comment>
		<comment id='4' author='Lzc6996' date='2016-11-03T08:40:00Z'>
		&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 是的 完全一样的模型，只修改了batchsize和gpu个数
		</comment>
		<comment id='5' author='Lzc6996' date='2016-11-03T11:14:35Z'>
		是总的batchsize数都一样？
		</comment>
		<comment id='6' author='Lzc6996' date='2016-11-11T03:23:54Z'>
		&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 修改的是测试的batchsize，保持和gpu个数一样。比如用单gpu的时候batchsize设定1，用双卡的时候设的2
		</comment>
		<comment id='7' author='Lzc6996' date='2016-11-11T03:26:28Z'>
		所以，batch_size其实变大了呀。尝试按比例调小学习率试试，不过即使调小学习率也不是精准一致的
		</comment>
		<comment id='8' author='Lzc6996' date='2016-11-11T03:37:11Z'>
		能保持batchsize整体数目一样再测下么
		</comment>
		<comment id='9' author='Lzc6996' date='2016-11-11T03:50:13Z'>
		&lt;denchmark-link:https://github.com/reyoung&gt;@reyoung&lt;/denchmark-link&gt;

SGD优化的时候，学习率和batchsize之间默认应该就有一种关系，比如如果使用了学习率调度算法，学习率会参照 有所变化，这个隐含的跟batch_size相关的了。但是，某些优化算法是自动调整学习率，所以情况可能不一样了。
综合起来，学习率调整应该有两个层面：

算法上，随着训练不断的迭代，学习率做适当的调整，这个应该是学习率调度算法或者自动调整学习率sgd变种算法的思路。
工程上，由于Paddle的模型配置里的setting(...)设置的batch_size是单机batch size，当多机多卡并行使能的时候，实际每轮迭代的batch size会跟并行粒度成线性增长关系，所以这里也存在一种对学习率修改的策略。

这块文档不是很清晰，&lt;denchmark-link:https://github.com/reyong&gt;@reyong&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 你们怎么看？ 可以这里明确一下。
		</comment>
		<comment id='10' author='Lzc6996' date='2016-11-11T03:58:24Z'>
		这不单单是学习率的问题，如果batch size变大，nn对于训练集合下的整体误差和优化方向估算的会更准确。就会有几种可能性。

更容易拟合训练集，所以训练误差可能变小
更容易拟合训练集，包括训练集上的噪声，所以过拟合可能会严重。即测试误差可能变大。
更容易拟合训练集，但梯度的方向引导到了一个局部最好情况，不能出来。那么训练集和测试集的误差都会变大。

发自 Smartisan T2
backyes &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;
 于 2016年11月11日，上午11:50写道：
@reyounghttps://github.com/reyoung
SGD优化的时候，学习率和batchsize之间默认应该就有一种关系，比如如果使用了学习率调度算法，学习率会参照numSamplesProcessed 有所变化，这个隐含的跟batch_size相关的了。但是，某些优化算法是自动调整学习率，所以情况可能不一样了。
综合起来，学习率调整应该有两个层面：

算法上，随着训练不断的迭代，学习率做适当的调整，这个应该是学习率调度算法或者自动调整学习率sgd变种算法的思路。
工程上，由于Paddle的模型配置里的setting(...)设置的batch_size是单机batch size，当多机多卡并行使能的时候，实际每轮迭代的batch size会跟并行粒度成线性增长关系，所以这里也存在一种对学习率修改的策略。这块文档不是很清晰，@reyonghttps://github.com/reyong @luotao1https://github.com/luotao1 你们怎么看？ 可以这里明确一下。

―
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHubhttps://github.com/&lt;denchmark-link:https://github.com/PaddlePaddle/Paddle/issues/329&gt;/issues/329&lt;/denchmark-link&gt;
#issuecomment-259874822, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AAseezOK1bg9HIkonLX7UUBIzlMYHJ50ks5q8-X3gaJpZM4KoA4y.
		</comment>
		<comment id='11' author='Lzc6996' date='2016-11-11T04:08:01Z'>
		&lt;denchmark-link:https://github.com/reyoung&gt;@reyoung&lt;/denchmark-link&gt;

主要我们要明确下， Paddle中关于学习率、batch_size 等几个参数的意义，避免用户理解上的偏差导致一些疑问。
		</comment>
		<comment id='12' author='Lzc6996' date='2016-11-11T04:32:55Z'>
		&lt;denchmark-link:https://github.com/reyoung&gt;@reyoung&lt;/denchmark-link&gt;
 我这里只做了test，没有训练，所以应该与学习率无关吧？
&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 抱歉我没懂你的意思，保持batchsize整体数目一样是指的什么？ 是说保持batchsize=1分别用单卡和多卡测一下吗？
		</comment>
		<comment id='13' author='Lzc6996' date='2016-11-11T04:42:08Z'>
		&lt;denchmark-link:https://github.com/Lzc6996&gt;@Lzc6996&lt;/denchmark-link&gt;
 有道理。是相同的模型对吧。。&lt;denchmark-link:https://github.com/luotao1&gt;@luotao1&lt;/denchmark-link&gt;
 可以复现这个问题么？就用最简单的LR试一试
		</comment>
		<comment id='14' author='Lzc6996' date='2016-11-11T04:54:58Z'>
		&lt;denchmark-link:https://github.com/Lzc6996&gt;@Lzc6996&lt;/denchmark-link&gt;
 ，能在你的github上提供你训练好的模型、数据、脚本么，这样比较好复现
		</comment>
		<comment id='15' author='Lzc6996' date='2016-11-11T06:51:19Z'>
		&lt;denchmark-link:https://github.com/Lzc6996/paddle_test&gt;https://github.com/Lzc6996/paddle_test&lt;/denchmark-link&gt;
 模型和脚本放在这里了。您看一下。
		</comment>
		<comment id='16' author='Lzc6996' date='2016-12-06T08:18:59Z'>
		paddle 并不需要在预测时候 fix batch size = 1 的，完全可以在预测时批量测试。
		</comment>
		<comment id='17' author='Lzc6996' date='2016-12-08T10:09:20Z'>
		0@nva 1 no
		</comment>
	</comments>
</bug>