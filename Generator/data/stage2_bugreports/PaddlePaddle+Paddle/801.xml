<bug id='801' author='PseudoProgrammer' open_date='2016-12-09T07:34:19Z' closed_time='2017-07-18T11:01:35Z'>
	<summary>sparse update error</summary>
	<description>
when i add sparse_remote_update=True to input of hidden layer,it returns error
my paddle version is 1.1.0.3
my config:
Layer(type = "data", name = "input1", size = 806867)
Layer(inputs = [Input("input1", parameter_name = "_layer1_1.w", sparse_remote_update = True)], name = "layer1_1", bias = Bias(parameter_name = "_layer1_1.bias"), active_type = "tanh", type = "fc", size = 80)
the error:
Thu Dec  8 21:44:02 2016[1,0]:+ ./paddle_trainer --num_gradient_servers=1 --trainer_id=0 --pservers=10.90.164.41 --rdma_tcp=tcp --nics=xgbe0 --saving_period=1 --port=7164 --ports_num=1 --local=0 --comment=job.14582.instances --dot_period=1000 --log_period=1000 --num_passes=100 --trainer_count=10 --ports_num_for_sparse=1 --use_sparse_updater=1 --use_old_updater=1 --config=conf/trainer_config.conf --save_dir=./output --python_path=./python-gcc345 --python_bin=python2.7 --use_gpu=0
Thu Dec  8 21:44:09 2016[1,0]:F1208 21:44:09.404992  9555 SparseRowMatrix.cpp:257] Check failed: blockSize % this-&gt;width == 0
Thu Dec  8 21:44:09 2016[1,0]:*** Check failure stack trace: ***
Thu Dec  8 21:44:09 2016[1,0]:    @           0x8d7788  google::LogMessage::Fail()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x8d76e0  google::LogMessage::SendToLog()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x8d7175  google::LogMessage::Flush()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x8d9f36  google::LogMessageFatal::~LogMessageFatal()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x84aa89  paddle::SparsePrefetchRowCpuMatrix: :setBlockSize()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x76ef2d  paddle::ParameterClient2::init()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x7553c5  paddle::SparseRemoteParameterUpdater::init()
Thu Dec  8 21:44:09 2016[1,0]:    @           0x74b437  _ZNSt6thread5_ImplISt12_Bind_resultIvFZN6paddle14SyncThreadPool5startEvEUliE_mEEE6_M_runEv
Thu Dec  8 21:44:09 2016[1,0]:    @     0x7f0d5d408462  execute_native_thread_routine
Thu Dec  8 21:44:09 2016[1,0]:    @     0x7f0d5da91d30  start_thread
Thu Dec  8 21:44:09 2016[1,0]:    @     0x7f0d5cc58afd  clone
	</description>
	<comments>
		<comment id='1' author='PseudoProgrammer' date='2016-12-09T07:49:18Z'>
		最新版本仍然有未定义BUG，预计下周内修复。多谢关注。
		</comment>
		<comment id='2' author='PseudoProgrammer' date='2016-12-09T07:54:51Z'>
		&lt;denchmark-link:https://github.com/backyes&gt;@backyes&lt;/denchmark-link&gt;
 我的版本是1103版本，不是开源版本
		</comment>
		<comment id='3' author='PseudoProgrammer' date='2016-12-09T07:56:06Z'>
		&lt;denchmark-link:https://github.com/backyes&gt;@backyes&lt;/denchmark-link&gt;
 两版本都在尝试，1103版本是为了稀疏加速，开源版本是想fellow下
		</comment>
		<comment id='4' author='PseudoProgrammer' date='2016-12-09T08:01:11Z'>
		&lt;denchmark-link:https://github.com/backyes&gt;@backyes&lt;/denchmark-link&gt;
 2kw数据，不用稀疏加速，训练一天多，时间代价太高了
		</comment>
		<comment id='5' author='PseudoProgrammer' date='2016-12-09T15:34:34Z'>
		&lt;denchmark-link:https://github.com/backyes&gt;@backyes&lt;/denchmark-link&gt;

when i change the num of hidden units to 128 from 80,it's well done
		</comment>
	</comments>
</bug>