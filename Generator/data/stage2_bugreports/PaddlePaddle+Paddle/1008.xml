<bug id='1008' author='liusiye' open_date='2016-12-23T10:39:33Z' closed_time='2016-12-28T08:30:34Z'>
	<summary>model_zoo词向量训练数据规模</summary>
	<description>
关于model_zoo中提供的预训练的词向量，我想询问下你们训练该词向量使用的数据规模是多大？关于数据规模的描述，我并没有在paddle的网站上找到。
非常感谢你们为开源社区做出的贡献！
	</description>
	<comments>
		<comment id='1' author='liusiye' date='2016-12-23T12:54:25Z'>
		训练语料的总规模是58亿个token，但训练中因为集群的问题，重启过几次，所以实际扫过的token数可能会有一些差别。
		</comment>
		<comment id='2' author='liusiye' date='2016-12-23T15:39:49Z'>
		thank you!
我在使用model_256.emb的时候发现数据异常, 数值范围明显不对.
例如: 6292:'北大', embedding 的前5位是-59656884224.0000000,-468485.9375000,-97301448774998133082866919145472.0000000,0.1795625,0.0000000
我是用Paddle/demo/model_zoo/embedding/pre_DictAndModel.sh下载的数据
用Paddle/demo/model_zoo/embedding/paraconvert.py将数据转换为txt文本处理
另外我对model_128.emb进行类似的统计, 该文件的均值、方差正常
对model_128和model_64进行语义相似性比较(采用欧式距离), 似乎128比64的效果要差不少.
我随机挑选了和我研究相关的6个词，其中model_128给出的结果中有2个有问题, 而model_64则没有问题
例子:
model_128:
'寿司',   top4 近义词: '沉浮', '桂南', 't211', '土默川'
'大阪',   top4 近义词: '时速', '窖', '漂浮', '充沛'
model_64:
'寿司',   top4 近义词: '烤鱼', '牛排', '煎饼', '奶茶'
'大阪',   top4 近义词: '名古屋', '旧金山', '横滨', '莫斯科'
		</comment>
		<comment id='3' author='liusiye' date='2016-12-27T11:21:56Z'>
		&lt;denchmark-link:https://github.com/liusiye&gt;@liusiye&lt;/denchmark-link&gt;
 似乎model_256.emb这个文件有一些错误。我们核对一下。
		</comment>
		<comment id='4' author='liusiye' date='2016-12-28T05:52:06Z'>
		&lt;denchmark-link:https://github.com/liusiye&gt;@liusiye&lt;/denchmark-link&gt;

您好，抱歉我们之前传到CDN上的embedding文件有一些错误。这些错误已经更正了。请重新下载一下这些embedding。
这些embedding的md5值是
&lt;denchmark-code&gt;f88c8325ee6da6187f1080e8fe66c1cd  model_32.emb
927cf70f27f860aff1a5703ebf7f1584  model_64.emb
a52e43655cd25d279777ed509a1ae27b  model_128.emb
b92c67fe9ff70fea53596080e351ac80  model_256.emb
&lt;/denchmark-code&gt;

稍后，我们会将md5检验也加入到这个下载脚本里。
		</comment>
		<comment id='5' author='liusiye' date='2016-12-28T06:36:35Z'>
		&lt;denchmark-link:https://github.com/beckett1124&gt;@beckett1124&lt;/denchmark-link&gt;
 另外，麻烦QA同事在回归测试里面加一下这个用例吧。
在model zoo里面，Paddle提供了一些预训练好的模型。这些模型在上传的过程中，可能会出一些错误，导致有错误的值。
所以每次发新版本的时候，需要检测一下这个值是不是正确。
检测方法如下
curl http://paddlepaddle.bj.bcebos.com/model_zoo/embedding/model_256.emb | od -j 16 -f | grep e+[0-9][4-9]
如果这个命令grep出东西了，一般就是错了。。
原理是，paddle的参数文件前16字节是文件头，后面就是一个一个的float型。然后如果grep e+[0-9][4-9]了，那么某一维度的参数就会大于 1e3，这基本上是不现实的。也就可以判断文件可能有错误。
不过，也可以弄一个更加科学的检查办法。
		</comment>
		<comment id='6' author='liusiye' date='2016-12-28T11:53:27Z'>
		好的
		</comment>
		<comment id='7' author='liusiye' date='2016-12-28T13:08:47Z'>
		&lt;denchmark-link:https://github.com/reyoung&gt;@reyoung&lt;/denchmark-link&gt;
  thank you! 刚下载了新的文件，貌似现在baidu.dict中有3206325个词，但是embedding文件中有3206326个embedding? 似乎我直接丢弃第一行embedding的话，embedding文件貌似可用
		</comment>
		<comment id='8' author='liusiye' date='2016-12-30T02:25:33Z'>
		
thank you! 刚下载了新的文件，貌似现在baidu.dict中有3206325个词，但是embedding文件中有3206326个embedding? 似乎我直接丢弃第一行embedding的话，embedding文件貌似可用

抱歉，那个baidu.dict也有更新，我们重传另一个baidu.dict。请直接wget一下吧。
&lt;denchmark-code&gt;wget http://paddlepaddle.bj.bcebos.com/model_zoo/embedding/baidu.dict
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>