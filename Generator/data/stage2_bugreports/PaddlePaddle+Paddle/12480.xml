<bug id='12480' author='bhan1111' open_date='2018-07-31T13:20:01Z' closed_time='2018-10-10T08:55:57Z'>
	<summary>关于fluid版本对大规模离散特征支持的问题</summary>
	<description>
使用fluid版本(0.14.0)对特征做embedding时，需要输入size=[A, B] 当A比较大时，目前遇到了两个问题。
第一, A赋为大的int值，比如9999999999, 会报
&lt;denchmark-link:https://user-images.githubusercontent.com/29255596/43461571-682e6236-9506-11e8-974b-bee2b487fb75.png&gt;&lt;/denchmark-link&gt;
这样的类型错误
第二， A赋为较小的int值，比如99999999, 会提示内存不够。这个与版本相关，使用老版本fluid跑过，并没有报内存错误
	</description>
	<comments>
		<comment id='1' author='bhan1111' date='2018-07-31T14:08:15Z'>
		第一个问题，麻烦贴下模型配置的关键代码信息吧，最好能给出具体的复现方法。
99999999 * 32 * 4.0 / 1024 / 1024 / 1024 = 12 GB 这个embedding至少需要12GB的内存，请确保有足够的内存
		</comment>
		<comment id='2' author='bhan1111' date='2018-08-01T02:16:10Z'>
		设为稀疏的话也需要这么大的内存吗？
第一个问题复现的话应该很简单，就是个embedding层
&lt;denchmark-link:https://user-images.githubusercontent.com/29255596/43497268-e4c3ddfe-9573-11e8-8584-73ccc0c27f38.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='bhan1111' date='2018-08-01T02:43:01Z'>
		

embedding layer的is_sparse是表示训练使用稀疏的gradient更新，embedding table仍然是一个dense的矩阵，embedding本身也是一个dense的，需要保存词表每个词的vector。不过现在Fluid可以支持通过把embedding table分布式存放在pserver端的方式训练，可以减小trainer本地的内存占用，使用这种方式，需要开启分布式训练，并在定义embedding layer时加上is_distributed=True参数，表示某个embedding是在pserver端存放。


embedding那个报错已经可以复现了，应该是个bug。我跟进下。


		</comment>
		<comment id='4' author='bhan1111' date='2018-10-10T08:55:57Z'>
		您好，此issue在近一个月内暂无更新，我们将于今天内关闭。若在关闭后您仍需跟进提问，可重新开启此问题， 我们将在24小时内回复您。因关闭带来的不便我们深表歉意，请您谅解~感谢您对PaddlePaddle的支持!
		</comment>
	</comments>
</bug>