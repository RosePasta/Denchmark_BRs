<bug id='20019' author='yeyupiaoling' open_date='2019-09-26T03:51:13Z' closed_time='2019-10-20T08:07:58Z'>
	<summary>动态图在保存模型的时候出错</summary>
	<description>
&lt;denchmark-h:h1&gt;环境&lt;/denchmark-h&gt;


PaddlePaddle 1.5.2 GPU版本
Windows 10
Python 3.5

&lt;denchmark-h:h1&gt;问题&lt;/denchmark-h&gt;

在调用这个接口保存模型的时候，就会提示无法保存优化方法
fluid.dygraph.save_persistables(model_dict=cnn.state_dict(), dirname="models", optimizers=sgd)
错误信息：
&lt;denchmark-code&gt;  "Optimizer not saved, Only optimizer with 'LearningRateDecay' under DyGraph mode need to be saved"
&lt;/denchmark-code&gt;

官网的例子明明是这样写的：&lt;denchmark-link:https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/dygraph_cn.html#save-persistables&gt;https://www.paddlepaddle.org.cn/documentation/docs/zh/api_cn/dygraph_cn.html#save-persistables&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='yeyupiaoling' date='2019-09-26T04:05:07Z'>
		目前optimizer的save 有问题，我们在修复中，目前 optimizer对于 momentum power这类的信息 没有被正确存储下来，我们在修复中，
对于sgd来说 由于没有momentum power之间的优化器相关信息，也可以怎么用，请忽略warning， adam就不能这么用
		</comment>
		<comment id='2' author='yeyupiaoling' date='2019-09-26T06:12:13Z'>
		&lt;denchmark-link:https://github.com/phlrain&gt;@phlrain&lt;/denchmark-link&gt;
 哦哦，原来是PaddlePaddle的问题，一开始我也是用 MomentumOptimizer ，结果保存，所以我又换成了官网的 SGDOptimizer结果还是不行。我还以为是我的代码问题。
		</comment>
		<comment id='3' author='yeyupiaoling' date='2019-09-26T06:39:37Z'>
		&lt;denchmark-link:https://github.com/phlrain&gt;@phlrain&lt;/denchmark-link&gt;
  我突然发现，不是保存优化方法有问题而已，而是整个接口都有问题，fluid.dygraph.load_persistables 和 fluid.dygraph.save_persistables 都有问题。
fluid.dygraph.load_persistables 就算文件不存在它也没有报错，而是自己初始化了，而且是随机的。根本就不能够正常执行预测。
		</comment>
		<comment id='4' author='yeyupiaoling' date='2019-09-26T06:52:54Z'>
		&lt;denchmark-link:https://github.com/phlrain&gt;@phlrain&lt;/denchmark-link&gt;
 如果 fluid.dygraph.load_persistables 返回值只设置一个，并不会保存，而是没有加载模型，自己初始化了。毫无提示。
		</comment>
		<comment id='5' author='yeyupiaoling' date='2019-09-26T08:32:30Z'>
		这个问题我们修复一下
		</comment>
		<comment id='6' author='yeyupiaoling' date='2019-10-08T11:16:59Z'>
		
@phlrain 哦哦，原来是PaddlePaddle的问题，一开始我也是用 MomentumOptimizer ，结果保存，所以我又换成了官网的 SGDOptimizer结果还是不行。我还以为是我的代码问题。

目前版本1.5.2 save optimizer实际上是save了optimizer的状态，比如你用到了学习率衰减，他会记录batch和衰减值，这样在load的时候可以让learningrate decay参数是训练时衰减的状态。因为现在load实际上是把optimizer的参数灌入，optimizer需要声明。预计1.6会可以save optimizer本身。官网上的示例不是很贴切。
load失败没有提示这个是一个已知问题，原因是动态图构建初始化会生成随机权重，然后load的时候会把权重替换掉，所以即使没有load成功也不会dump。这个后续会修复。十分感谢反馈。
		</comment>
	</comments>
</bug>