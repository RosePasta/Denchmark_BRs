<bug id='580' author='77QIQI' open_date='2019-06-10T06:15:36Z' closed_time='2019-06-10T08:57:13Z'>
	<summary>concat with same input</summary>
	<description>
Hi,
I am using this command:

python -m tf2onnx.convert --input=.../frozen_model_2.pb --inputs='input_tensor:0' --output='output_tensor:0' --output='..../model.onnx' --verbose

My part codes which cause this bug:
&lt;denchmark-code&gt;a_copy = a
a_copy = tf.concat([a_copy,a],axis=3)
&lt;/denchmark-code&gt;

BTW, this code can work:
&lt;denchmark-code&gt;a_copy = a
a = tf.conv2d(a,....)
a_copy = tf.concat([a_copy,a],axis=3)

&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;And I found this error:
Although it can generate onnx successfully, but it cannot be used by my following codes without optimizor. So does tf2onnx not support concat two same tensor? Thanks in advance.&lt;/denchmark-h&gt;

2019-06-10 05:53:56,345 - INFO - tf2onnx.tfonnx: Using tensorflow=1.12.0, onnx=1.4.1, tf2onnx=1.5.1/0c735a
2019-06-10 05:53:56,345 - INFO - tf2onnx.tfonnx: Using opset &lt;onnx, 7&gt;
2019-06-10 05:53:56,769 - VERBOSE - tf2onnx.tfonnx: Mapping TF node to ONNX node(s)
2019-06-10 05:53:56,935 - VERBOSE - tf2onnx.tfonnx: Summay Stats:
tensorflow ops: Counter({'Const': 123, 'Add': 60, 'Conv2D': 38, 'Relu': 35, 'Mul': 14, 'DepthwiseConv2dNative': 13, 'ConcatV2': 4, 'ResizeBilinear': 3, 'BiasAdd': 3, 'Identity': 2, 'Placeholder': 2, 'Sigmoid': 1})
tensorflow attr: Counter({'T': 173, 'dtype': 125, 'value': 123, 'data_format': 54, 'strides': 51, 'dilations': 51, 'padding': 51, 'use_cudnn_on_gpu': 38, 'Tidx': 4, 'N': 4, 'align_corners': 3, 'shape': 2})
onnx mapped: Counter({'Const': 123, 'Add': 60, 'Conv2D': 38, 'Relu': 35, 'Mul': 14, 'DepthwiseConv2dNative': 13, 'ConcatV2': 4, 'BiasAdd': 3, 'ResizeBilinear': 3, 'Identity': 2, 'Placeholder': 2, 'Sigmoid': 1})
onnx unmapped: Counter()
2019-06-10 05:53:56,962 - INFO - tf2onnx:
2019-06-10 05:53:56,994 - INFO - tf2onnx.optimizer: Optimizing ONNX model
2019-06-10 05:53:56,995 - VERBOSE - tf2onnx.optimizer: Apply optimize_transpose
2019-06-10 05:53:57,133 - WARNING - tf2onnx.optimizer: Failed to apply optimize_transpose
Traceback (most recent call last):
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/init.py", line 44, in optimize_graph
graph = factory().optimize(current)
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/optimizer_base.py", line 32, in optimize
graph = self._optimize(graph)
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/transpose_optimizer.py", line 144, in _optimize
if self._handle_nhwc_tranpose(n):
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/transpose_optimizer.py", line 263, in _handle_nhwc_tranpose
return op_handler(trans, p)
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/transpose_optimizer.py", line 424, in _concat_handler
if self._handle_node_having_branches(node):
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/optimizer/transpose_optimizer.py", line 200, in _handle_node_having_branches
self._g.remove_node(n.name)
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/graph.py", line 512, in remove_node
utils.make_sure(node_name in self._nodes_by_name, "node %s not in current graph, cannot remove", node_name)
File "/usr/local/lib/python3.5/dist-packages/tf2onnx/utils.py", line 289, in make_sure
raise ValueError("make_sure failure: " + error_msg % args)
ValueError: make_sure failure: node MobilenetV2/gmm/Conv2D__8 not in current graph, cannot remove
2019-06-10 05:53:57,134 - VERBOSE - tf2onnx.optimizer: Apply fold_constants
2019-06-10 05:53:57,179 - VERBOSE - tf2onnx.optimizer.ConstFoldOptimizer: no change
2019-06-10 05:53:57,179 - VERBOSE - tf2onnx.optimizer: Apply merge_duplication
2019-06-10 05:53:57,262 - VERBOSE - tf2onnx.optimizer.MergeDuplicatedNodesOptimizer: Transpose -1 (108-&gt;107)
2019-06-10 05:53:57,262 - VERBOSE - tf2onnx.optimizer: Apply remove_identity
2019-06-10 05:53:57,310 - VERBOSE - tf2onnx.optimizer.IdentityOptimizer: Identity -4 (4-&gt;0)
2019-06-10 05:53:57,311 - INFO - tf2onnx.optimizer: After optimization: Identity -4 (4-&gt;0), Transpose -1 (108-&gt;107)
2019-06-10 05:53:57,347 - INFO - tf2onnx:
2019-06-10 05:53:57,348 - INFO - tf2onnx: Successfully converted TensorFlow model checkpoint/frozen_model_2.pb to ONNX
2019-06-10 05:53:57,352 - INFO - tf2onnx: ONNX model is saved at checkpoint/model.onnx
frozen bp to onnx done
	</description>
	<comments>
		<comment id='1' author='77QIQI' date='2019-06-10T08:37:37Z'>
		I modified the test case in test_backend.py, , could you do same modification to see if it also still works in your side?
the snapshot below is the tf graph I created.
&lt;denchmark-link:https://user-images.githubusercontent.com/43435212/59183110-e59e6480-8b9d-11e9-951d-eecbf7a0f9be.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='77QIQI' date='2019-06-10T08:41:45Z'>
		It can finish convert, but the optimizer failed. In fact, I got the model.onnx but the graph optimizer didn't  &lt;denchmark-link:https://github.com/zhijxu-MS&gt;@zhijxu-MS&lt;/denchmark-link&gt;

Without optimizer, the node number is too large.
Like the output:

INFO - tf2onnx: Successfully converted TensorFlow model checkpoint/frozen_model_2.pb to ONNX
2019-06-10 05:53:57,352 - INFO - tf2onnx: ONNX model is saved at checkpoint/model.onnx

But before this note, there are some errors.
		</comment>
		<comment id='3' author='77QIQI' date='2019-06-10T08:45:39Z'>
		hmm, i created a simple test, and tf2onnx can convert it and onnxruntime can run it.
it looks like the bug is not concat related, would you share with me the tf model you are trying to convert?
		</comment>
		<comment id='4' author='77QIQI' date='2019-06-10T08:49:16Z'>
		I know, but I tried different concat input like zero shape to replace this part and it worked. So how can i share your model?
		</comment>
		<comment id='5' author='77QIQI' date='2019-06-10T08:52:16Z'>
		&lt;denchmark-link:mailto:zhijxu@microsoft.com&gt;zhijxu@microsoft.com&lt;/denchmark-link&gt;
 is my eamil address, you could try it first. and if it's too large, you could try google-drive.
		</comment>
		<comment id='6' author='77QIQI' date='2019-06-10T08:57:13Z'>
		solved it by adding tf.identity(a), i.e. deepcopy this tensor.
Thanks a lot.
		</comment>
	</comments>
</bug>