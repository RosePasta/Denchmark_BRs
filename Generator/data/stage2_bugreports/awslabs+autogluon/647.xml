<bug id='647' author='SamanthaSHan' open_date='2020-09-01T17:37:56Z' closed_time='2020-09-14T22:26:55Z'>
	<summary>RuntimeError: The best config {'search_space▁optimization.lr': 5.5e-05} is not found in config history = OrderedDict().</summary>
	<description>
Using SageMaker, tried conda_python3 (and downloaded mxnet as suggested in &lt;denchmark-link:https://autogluon.mxnet.io/install.html#installation-faq&gt;https://autogluon.mxnet.io/install.html#installation-faq&lt;/denchmark-link&gt;
) and conda_mxnet_36, error is reproduced in both kernels.
Just following the text prediction quick start example, but running into following:
&lt;denchmark-code&gt;!pip install --upgrade pip
!pip install --upgrade 'scikit-learn&lt;0.23,&gt;=0.22.0'
!pip install --upgrade mxnet autogluon
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;from autogluon import TextPrediction as task
from autogluon.utils.tabular.utils.loaders.load_pd import load
import pandas as pd
import numpy as np
train_data = load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')
dev_data = load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')
rand_idx = np.random.permutation(np.arange(len(train_data)))[:2000]
train_data = train_data.iloc[rand_idx]
train_data.head(10)

predictor = task.fit(train_data, label='label',
                     time_limits=60,
                     seed=123,
                     output_directory='./ag_sst')
&lt;/denchmark-code&gt;

(No gpu configuration as my instance does not have gpu)
Running into: RuntimeError: The best config {'search_space▁optimization.lr': 5.5e-05} is not found in config history = OrderedDict(). This should never happen! error
Edit: tried on both 0.0.13 and 0.0.14, same error.
I did check the setup.py and verified that all packages were installed. Not sure if there's a version mismatch?
	</description>
	<comments>
		<comment id='1' author='SamanthaSHan' date='2020-09-01T18:22:48Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 Could you take a look?
		</comment>
		<comment id='2' author='SamanthaSHan' date='2020-09-01T19:14:28Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 One possibility is that the speed is too slow because you are not using GPU. Thus, the training loop cannot find a model within 60 seconds. There are two options:

Change time_limits=None, which will wait until all trials are finished.
To have the best user experience of TextPrediction, I recommend to use the SageMaker instance with GPU support, e.g., the p3.2x instance in SageMaker.

		</comment>
		<comment id='3' author='SamanthaSHan' date='2020-09-01T20:32:27Z'>
		
@SamanthaSHan One possibility is that the speed is too slow because you are not using GPU. Thus, the training loop cannot find a model within 60 seconds. There are two options:

Change time_limits=None, which will wait until all trials are finished.
To have the best user experience of TextPrediction, I recommend to use the SageMaker instance with GPU support, e.g., the p3.2x instance in SageMaker.


Can we make clearer error messages if no models were trained in time?
		</comment>
		<comment id='4' author='SamanthaSHan' date='2020-09-02T15:41:30Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;

Thanks for your reply. In the meantime, I did try it in p2.xlarge and p3.2x. Though both had 1 GPU, it didn't work in p2.xlarge vs p3.2x.
Following &lt;denchmark-link:https://github.com/Innixma&gt;@Innixma&lt;/denchmark-link&gt;
 's comment, I do think that it would be necessary to make the error message clearer.
		</comment>
		<comment id='5' author='SamanthaSHan' date='2020-09-02T15:46:08Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 Would you try again by launching a SageMaker notebook with “conda_py36” kernel and inside the Jupyter notebook, install the following MXNet?
python3 -m pip install -U --pre "mxnet_cu101&gt;=1.7.0b20200713, &lt;2.0.0" -f &lt;denchmark-link:https://sxjscience.github.io/KDD2020/&gt;https://sxjscience.github.io/KDD2020/&lt;/denchmark-link&gt;

I previously tested the command on SageMaker and it should runs fine.
		</comment>
		<comment id='6' author='SamanthaSHan' date='2020-09-02T15:53:17Z'>
		I noticed that in your previous installation command, you are doing “ !pip install --upgrade mxnet autogluon” Basically, you may try to remove “pip install --upgrade mxnet” and install MXNet with the previous command. Also, you should make sure that you are using the conda_python3 kernel instead of the conda_mxnet_py36 kernel.
		</comment>
		<comment id='7' author='SamanthaSHan' date='2020-09-02T17:03:09Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 Apologies if my previous comment was not clear. It did work on p3.2x using the initial installation command.
I am now training my own custom data, but running into the same error. Can TextPrediction take symbols? (i.e @!# etc)? That is the only difference between the example data.
		</comment>
		<comment id='8' author='SamanthaSHan' date='2020-09-02T17:06:49Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 It can take symbols. Basically, you will have to use a larger  if you are working on your custom data. You may try to set time_limits to  so that it will be trained into convergence.
predictor = task.fit(train_data, label='label',
                     time_limits=None,
                     seed=123,
                     output_directory='./ag_sst')
		</comment>
		<comment id='9' author='SamanthaSHan' date='2020-09-02T17:33:26Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;

Got it to work without symbols. I did previously try with and without symbols by applying
&lt;denchmark-code&gt;predictor = task.fit(train_data, label='label',
                     time_limits=None,
                     ngpus_per_trial=1,
                     seed=123,
                     output_directory='./&lt;outpit&gt;')
&lt;/denchmark-code&gt;

Pertaining to the initial issue that I've created, the error thrown was RuntimeError: The best config {'search_space▁optimization.lr': 5.5e-05} is not found in config history = OrderedDict(). This should never happen! when there were symbols in the text, as well as timeout error mentioned above -- I do want to point out that the error message should be more specific :)
		</comment>
		<comment id='10' author='SamanthaSHan' date='2020-09-02T17:37:32Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 Yeah, thanks for your suggestion! We will improve our error message and the way to deal with the time limits. Stay tuned :) For now, just open issues in case you met any problems and we are always happy to help!
		</comment>
		<comment id='11' author='SamanthaSHan' date='2020-09-02T17:43:34Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 Thank you.
It may also be good to find any limitations with the use of symbols. I haven't delved deeper into what symbols are in my custom dataset (I assume ASCII characters are ok while utf-8 ones may not be?). I'd like to contribute should time permit!
		</comment>
		<comment id='12' author='SamanthaSHan' date='2020-09-02T17:45:56Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 The TextPrediction task should work even if your data contain symbols or any UTF-8 characters. Are you seeing errors when you are have symbols in the data?
		</comment>
		<comment id='13' author='SamanthaSHan' date='2020-09-02T19:17:07Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 Yes, correct. I'm seeing the same error as above, relating to the RuntimeError
		</comment>
		<comment id='14' author='SamanthaSHan' date='2020-09-02T19:30:03Z'>
		&lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 Thanks for reporting this. This is definitely a bug and we should solve it. Would you know if it's possible for us to connect so that I can may debug the issue? I think it's related to certain non-unicode characters, e.g., emojis like '' in the dataset.
		</comment>
		<comment id='15' author='SamanthaSHan' date='2020-09-02T21:00:49Z'>
		
@sxjscience Thank you.
It may also be good to find any limitations with the use of symbols. I haven't delved deeper into what symbols are in my custom dataset (I assume ASCII characters are ok while utf-8 ones may not be?). I'd like to contribute should time permit!

Great to hear that you are interested in contributing! If you can send me an email at &lt;denchmark-link:mailto:neerick@amazon.com&gt;neerick@amazon.com&lt;/denchmark-link&gt;
, I can invite you to our collaborator slack channel.
		</comment>
		<comment id='16' author='SamanthaSHan' date='2020-09-05T07:41:03Z'>
		I am facing the same issue , even though i did try after removing the symbols. I am try to execute this in colab. Code given below for reference.
!pip install mxnet
!pip install autogluon
import autogluon as ag
import pandas as pd
from autogluon import TextPrediction as task
import regex as re
train=pd.read_csv("Train.csv") #Have attached the file as Train.txt since csv was not supported.
trn = train.copy()
def split_it(x):
return re.sub(r'[^\w][^\x00-\x7F][^A-Za-z0-9]',' ',x)
trn['Product_Description']=trn['Product_Description'].apply(split_it)
trn.head()
predictor = task.fit(train_data=trn,eval_metric='log_loss',time_limits=None, seed=123,ngpus_per_trial=1,label='Sentiment',output_directory='ps-example-out/')
&lt;denchmark-link:https://github.com/awslabs/autogluon/files/5177715/Train.txt&gt;Train.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='SamanthaSHan' date='2020-09-05T07:43:59Z'>
		Thanks for reporting. Let me take a look tomorrow.

Get Outlook for iOS&lt;&lt;denchmark-link:https://aka.ms/o0ukef&gt;https://aka.ms/o0ukef&lt;/denchmark-link&gt;
&gt;
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


________________________________
From: Ganesh MG &lt;notifications@github.com&gt;
Sent: Saturday, September 5, 2020 12:41:15 AM
To: awslabs/autogluon &lt;autogluon@noreply.github.com&gt;
Cc: Xingjian SHI &lt;xshiab@connect.ust.hk&gt;; Mention &lt;mention@noreply.github.com&gt;
Subject: Re: [awslabs/autogluon] RuntimeError: The best config {'search_space▁optimization.lr': 5.5e-05} is not found in config history = OrderedDict(). (#647)


I am facing the same issue , even though i did try after removing the symbols. I am try to execute this in colab. Code given below for reference.

!pip install mxnet
!pip install autogluon
import autogluon as ag
import pandas as pd
from autogluon import TextPrediction as task
import regex as re

train=pd.read_csv("Train.csv") #Have attached the file as Train.txt since csv was not supported.
trn = train.copy()

def split_it(x):
return re.sub(r'[^\w][^\x00-\x7F][^A-Za-z0-9]',' ',x)

trn['Product_Description']=trn['Product_Description'].apply(split_it)
trn.head()

predictor = task.fit(train_data=trn,eval_metric='log_loss',time_limits=None, seed=123,ngpus_per_trial=1,label='Sentiment',output_directory='ps-example-out/')
Train.txt&lt;https://github.com/awslabs/autogluon/files/5177715/Train.txt&gt;

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub&lt;#647 (comment)&gt;, or unsubscribe&lt;https://github.com/notifications/unsubscribe-auth/ABHQH3RVU4AUQOOSHELLU6DSEHTRXANCNFSM4QR7UEWA&gt;.

		</comment>
		<comment id='18' author='SamanthaSHan' date='2020-09-05T07:50:50Z'>
		&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 Sorry that I do not have access to the laptop and will investigate tomorrow. Meanwhile, would you try to specify the “feature_column” in ‘.fit()’ and try to include only the “Product_Description”, and “ Product_Type”? Basically, the “Text_ID” is an ID Column and the text prediction task cannot deal with the ID column currently.
		</comment>
		<comment id='19' author='SamanthaSHan' date='2020-09-05T08:46:10Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
  I tried with only the Product_Description and Product_Type as features for the .fit(), but i still i receive the same error. I even tried converting the Product_Type to categorical (string) even though it has numerical values, just in case if it wasn't expecting any numerical columns, but still the same error persists.
		</comment>
		<comment id='20' author='SamanthaSHan' date='2020-09-05T08:57:14Z'>
		For me, It seems that you are not installing MXNet with GPU support. Would you try again with pip install mxnet_cu101 or pip install mxnet_cu102?

Get Outlook for iOS&lt;&lt;denchmark-link:https://aka.ms/o0ukef&gt;https://aka.ms/o0ukef&lt;/denchmark-link&gt;
&gt;
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


________________________________
From: Ganesh MG &lt;notifications@github.com&gt;
Sent: Saturday, September 5, 2020 1:46:22 AM
To: awslabs/autogluon &lt;autogluon@noreply.github.com&gt;
Cc: Xingjian SHI &lt;xshiab@connect.ust.hk&gt;; Mention &lt;mention@noreply.github.com&gt;
Subject: Re: [awslabs/autogluon] RuntimeError: The best config {'search_space▁optimization.lr': 5.5e-05} is not found in config history = OrderedDict(). (#647)


@sxjscience&lt;https://github.com/sxjscience&gt; I tried with only the Product_Description and Product_Type as features for the .fit(), but i still i receive the same error. I even tried converting the Product_Type to categorical (string) even though it has numerical values, just in case if it wasn't expecting any numerical columns, but still the same error persists.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub&lt;#647 (comment)&gt;, or unsubscribe&lt;https://github.com/notifications/unsubscribe-auth/ABHQH3QEI3UXLOCQVYSALGTSEH3F5ANCNFSM4QR7UEWA&gt;.

		</comment>
		<comment id='21' author='SamanthaSHan' date='2020-09-05T09:33:07Z'>
		I tried pip install with both mxnet_cu101 and mxnet_cu102, but still the same error in both the cases. Are there any predefined steps or order that needs to be taken care for installing autogluon,mxnet,mxnet_cu101,mxnet_cu102?
After pip install the only things that i import are the ones mentioned below.
import autogluon as ag
from autogluon import TextPrediction as task
Is there anything that i am missing?
		</comment>
		<comment id='22' author='SamanthaSHan' date='2020-09-05T09:51:02Z'>
		&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 I just tried locally in a g4dn.4xlarge instance and there is no such issue.
import autogluon as ag
from autogluon import TextPrediction as task
import pandas as pd
df = pd.read_csv('Train.txt')
predictor = task.fit(df, feature_columns='Product_Description', label='Sentiment', verbosity=3)
predictor.evaluate(df, metrics='acc')
It gives
&lt;denchmark-code&gt;OrderedDict([('acc', 0.7124450031426776)])
&lt;/denchmark-code&gt;

Are you seeing this issue when using the Google Colab? Also, would you try to train with verbosity=3 and paste the error message here so I can help debug?
		</comment>
		<comment id='23' author='SamanthaSHan' date='2020-09-05T11:22:29Z'>
		Yes, I am using Google Colab. Attached are the log files of the fit() executed with "verbosity=3" with one and two features. If i execute only with 'Product_Description' it succeeds and fails if i add 'Product_Type'. Is there a way where i can include 'Product_Type' as well in training?
&lt;denchmark-link:https://github.com/awslabs/autogluon/files/5177975/Error_Log_2_Features.txt&gt;Error_Log_2_Features.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/awslabs/autogluon/files/5177976/LogFile_1_Feature.txt&gt;LogFile_1_Feature.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='24' author='SamanthaSHan' date='2020-09-06T06:33:57Z'>
		&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/SamanthaSHan&gt;@SamanthaSHan&lt;/denchmark-link&gt;
 Thanks so much for trying out AutoGluon! The error message is improved in &lt;denchmark-link:https://github.com/awslabs/autogluon/pull/651&gt;#651&lt;/denchmark-link&gt;
. Also, I fixed the bug found by &lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
. In order to try out this fix, you may use:
pip uninstall autogluon
pip install git+https://github.com/sxjscience/autogluon.git@fix_bug
		</comment>
		<comment id='25' author='SamanthaSHan' date='2020-09-07T07:45:40Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 I tried the fit() with both 'Product_Description' and 'Product_Type' as feature_columns and find attached the log file.
The fit() function succeeded, however under the Train/Tuning dataset section in the log file, i do not see any mention on 'Product_Type'. Not sure whether this means that 'Product_Type' was not considered for training?
&lt;denchmark-link:https://github.com/awslabs/autogluon/files/5181723/Error_Log.txt&gt;Error_Log.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='SamanthaSHan' date='2020-09-07T08:11:49Z'>
		I've verified that Product_Type is used, if it is not used, the validation loss can only reach 70%. It can get 88% if Product_Type is used together with the text feature.
However, the previous fix introduced another problem that the specified  will be ignored so I created another fix in &lt;denchmark-link:https://github.com/awslabs/autogluon/pull/653&gt;#653&lt;/denchmark-link&gt;
.
To try it out, use the following command:
pip uninstall autogluon
pip install git+https://github.com/sxjscience/autogluon.git@fix_text_bug2
from autogluon import TextPrediction as task
import pandas as pd
df = pd.read_csv('Train.txt')
predictor = task.fit(df, feature_columns=['Product_Description', 'Product_Type'], label='Sentiment', verbosity=3)
predictor.evaluate(df, metrics='acc')
&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 Would you help to try again?
		</comment>
		<comment id='27' author='SamanthaSHan' date='2020-09-07T10:15:27Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 The fit() function succeeded and under the Train/Tuning dataset section in the log file, i could now see the 'Product_Type' being mentioned. Find attached the log for reference.
&lt;denchmark-link:https://github.com/awslabs/autogluon/files/5182538/Error_Log_1.txt&gt;Error_Log_1.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='28' author='SamanthaSHan' date='2020-09-07T20:25:10Z'>
		&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 Really appreciate your help! Is it possible for you to provide some details about the dataset? We can use it for our internal benchmarking. In addition, you may try to change the backbone to be , which performs better than the default value, which is .
The following is the example script for using google_electra_base:
from autogluon import TextPrediction as task
import pandas as pd
df = pd.read_csv('Train.txt')

hyperparameters = {
      'models': {
            'BertForTextPredictionBasic': {
                'search_space': {
                    'model.backbone.name': 'google_electra_base'
                }
             }
       }
}

df = pd.read_csv('Train.txt')
predictor = task.fit(df, feature_columns=['Product_Description', 'Product_Type'], label='Sentiment', verbosity=3, hyperparameters=hyperparameters)
		</comment>
		<comment id='29' author='SamanthaSHan' date='2020-09-08T06:01:57Z'>
		&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 Thanks for the example script. Will give it a try.
The dataset shared was of a hackathon conducted by Machinehack. Hope it helps.
		</comment>
		<comment id='30' author='SamanthaSHan' date='2020-09-14T22:26:54Z'>
		&lt;denchmark-link:https://github.com/ganeshmg&gt;@ganeshmg&lt;/denchmark-link&gt;
 I will mark it as resolved now. Feel free to reopen!
		</comment>
	</comments>
</bug>