<bug id='562' author='sxjscience' open_date='2020-07-18T07:59:00Z' closed_time='2020-07-18T08:01:50Z'>
	<summary>[HPO] Autogluon will only use one GPU</summary>
	<description>
I've set the num_gpu in resource to be 4. However, it will still have only 1 GPU available.
Reproducible example:
import numpy as np
import autogluon as ag
import mxnet as mx
from mxnet.gluon import nn, Trainer
from mxnet.util import use_np


def get_mxnet_visible_gpus():
    """Get the number of GPUs that are visible to MXNet.
    Returns
    -------
    ctx_l
        The ctx list
    """
    import mxnet as mx
    gpu_count = 0
    while True:
        try:
            arr = mx.np.array(1.0, ctx=mx.gpu(gpu_count))
            arr.asnumpy()
            gpu_count += 1
        except Exception:
            break
        finally:
            break
    return [mx.gpu(i) for i in range(gpu_count)]



@use_np
class Net:
    def train_fn(self, args, reporter):
        print('num_gpus:', get_mxnet_visible_gpus())
        np.random.seed(123)
        mx.random.seed(123)
        net = nn.HybridSequential()
        net.add(nn.Dense(16))
        net.add(nn.Activation('relu'))
        net.add(nn.Dense(4))
        net.hybridize()
        net.initialize()
        trainer = Trainer(net.collect_params(), 'adam')
        for i in range(10):
            with mx.autograd.record():
                data = mx.np.random.normal(0, 1, (8, 4))
                out = net(data)
                loss = mx.np.square(out - data).sum()
                loss.backward()
                reporter(loss=loss.asnumpy().item(), iteration=i)
            trainer.step(1.0)



def run_tuning_jobs(fn, search_space):
    args_decorator = ag.args(**search_space)
    scheduler = ag.scheduler.FIFOScheduler(args_decorator(fn),
                                       resource={'num_cpus': 2, 'num_gpus': 4},
                                       num_trials=20,
                                       reward_attr='loss',
                                       time_attr='iteration')
    scheduler.run()
    scheduler.join_jobs()
    return scheduler


search_space = {
    'num_hidden': ag.space.Int(16, 32),
    'lr': ag.space.Real(1e-3, 1e-2)
}

net = Net()

scheduler = run_tuning_jobs(net.train_fn, search_space)
Output:
&lt;denchmark-code&gt;...
num_gpus: [gpu(0)]
&lt;/denchmark-code&gt;

For installing the MXNet, following the guide here: &lt;denchmark-link:https://sxjscience.github.io/KDD2020/&gt;https://sxjscience.github.io/KDD2020/&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='sxjscience' date='2020-07-18T08:01:50Z'>
		Confirmed that it's not a bug. The reason is that I've made the mistake in get_mxnet_visible_gpus.
		</comment>
	</comments>
</bug>