<bug id='657' author='JanSellner' open_date='2020-06-30T12:41:16Z' closed_time='2020-07-26T23:27:48Z'>
	<summary>Incorrect results for MaskedDiceLoss when softmax=True</summary>
	<description>
When the softmax parameter softmax=True is used in MaskedDiceLoss, the masked pixels are not excluded from the computation since the softmax is still applied to the zeroed-out pixels. Example:
import math
import torch
from monai.losses import MaskedDiceLoss, DiceLoss

# shape: (batch, classes, height, width)
input_prob = torch.tensor([[[[0.1, 0.8]], [[0.9, 0.2]]]])  # [1, 2, 1, 2]
input_logits = torch.tensor([[[[math.log(0.1), math.log(0.8)]], [[math.log(0.9), math.log(0.2)]]]]) # [1, 2, 1, 2]
target = torch.tensor([[[[1, 0]]]])  # [1, 1, 1, 2]
mask = torch.tensor([[[[1, 0]]]])  # [1, 1, 1, 2]

dice_loss_prob = MaskedDiceLoss(to_onehot_y=True, softmax=False, reduction='none')
dice_loss_logits = MaskedDiceLoss(to_onehot_y=True, softmax=True, reduction='none')

# This yields the same result
dice_loss_prob(input_prob, target)  # tensor([[0.1579, 0.1429]])
dice_loss_logits(input_logits, target)  # tensor([[0.1579, 0.1429]])

# This does not (the first one is the correct result)
dice_loss_prob(input_prob, target, mask=mask)  # tensor([[1.0000, 0.0526]])
dice_loss_logits(input_logits, target, mask=mask)  # tensor([[0.3750, 0.2500]])
The problem is that the &lt;denchmark-link:https://github.com/Project-MONAI/MONAI/blob/master/monai/losses/dice.py#L173&gt;zeroing happens before the softmax&lt;/denchmark-link&gt;
.
My solution would be to apply the masking before &lt;denchmark-link:https://github.com/Project-MONAI/MONAI/blob/master/monai/losses/dice.py#L118&gt;this line&lt;/denchmark-link&gt;
. Actually, I don't know why there is a  class in the first place. I think an additional (optional) argument to the forward function of  would be sufficient. So, I propose:

Remove the MaskedDiceLoss class.
Add an additional (optional) argument to the DiceLoss class for the mask.
Add the example above to the tests.

If this is fine with you, I could make a PR :-)
Bug is present in commit &lt;denchmark-link:https://github.com/Project-MONAI/MONAI/commit/11fc31dc1b6b37cf3ed6a3a89e39739629cd3147&gt;11fc31d&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='JanSellner' date='2020-06-30T16:38:19Z'>
		I feel the docstring of  is kind of misleading &lt;denchmark-link:https://github.com/Project-MONAI/MONAI/blob/master/monai/losses/dice.py#L149&gt;https://github.com/Project-MONAI/MONAI/blob/master/monai/losses/dice.py#L149&lt;/denchmark-link&gt;
 IMO the mask is more like a differentiable attention map and this is different from 
		</comment>
	</comments>
</bug>