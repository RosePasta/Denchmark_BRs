<bug id='746' author='YaYaB' open_date='2020-06-28T12:07:10Z' closed_time='2020-07-20T13:23:05Z'>
	<summary>Inversed precision &amp; recall</summary>
	<description>
If Ok, please give as many details as possible to help us solve the problem more efficiently.
&lt;denchmark-h:h4&gt;Configuration&lt;/denchmark-h&gt;


Version of DeepDetect:

 Locally compiled on:

 Ubuntu 14.04 LTS
 Mac OSX
 Other:


 Docker
 Amazon AMI


Commit (shown by the server when starting):
88e9325

&lt;denchmark-h:h4&gt;Your question / the problem you're facing:&lt;/denchmark-h&gt;

I was trying to train a specific model. However after finishing the training and launching some predictions on the test set I saw that the metrics during the trainings were a bit weird. I used sklearn to compute precision and recall and saw that the metrics precision and recall are inverted.
I have checked the code and indeed if you check &lt;denchmark-link:https://github.com/jolibrain/deepdetect/blob/badb7d03d760fe229526391da7c2a5a740890a65/src/supervisedoutputconnector.h#L1609-L1610&gt;here&lt;/denchmark-link&gt;
 the names do not correspond.
&lt;denchmark-code&gt; dMat conf_csum = conf_matrix.colwise().sum()
&lt;/denchmark-code&gt;

will compute the sum for reach row, and
&lt;denchmark-code&gt; dMat conf_rsum = conf_matrix.rowwise().sum();
&lt;/denchmark-code&gt;

will compute the sum for reach row.
However those are used to compute precision and recall in &lt;denchmark-link:https://github.com/jolibrain/deepdetect/blob/badb7d03d760fe229526391da7c2a5a740890a65/src/supervisedoutputconnector.h#L1613-L1614&gt;here&lt;/denchmark-link&gt;

I can prepare an MR that would fix this easily:
&lt;denchmark-code&gt;dMat conf_rsum = conf_matrix.colwise().sum()
dMat conf_csum = conf_matrix.rowwise().sum();
&lt;/denchmark-code&gt;

Moreoever I saw that I was not able to replicate the f1-score metric computed in DD.
In &lt;denchmark-link:https://github.com/jolibrain/deepdetect/blob/badb7d03d760fe229526391da7c2a5a740890a65/src/supervisedoutputconnector.h#L1615-L1618&gt;here&lt;/denchmark-link&gt;
.
We see that the f1-score is computed in the global precision / recall of the model. However I think it would be better to compute the mean f1-score for each class to compute the global f1-score (as sklearn does with the average "macro" or "weighted").
In the same time getting more metrics (precision, recall, f1score for each class) would be nice.
It is a bit complicated to replicate this with a model as I would need to train a model and give you access to data to test it.
You can try all of this with mnist or something like this just to see that the metrics seem wrong.
	</description>
	<comments>
		<comment id='1' author='YaYaB' date='2020-07-07T10:16:36Z'>
		Hi
thank you for the bug report. This PR should fix things up:
&lt;denchmark-link:https://github.com/jolibrain/deepdetect/pull/757&gt;#757&lt;/denchmark-link&gt;

moreover, with this PR ,  if you add "f1full" to your measure list (or replace "f1" by "f1full") dede will output per class precision recall and f1.
		</comment>
		<comment id='2' author='YaYaB' date='2020-07-07T10:17:55Z'>
		let me know if this seems ok for your needs
		</comment>
		<comment id='3' author='YaYaB' date='2020-07-15T12:45:24Z'>
		Sounds perfect for me!
I'll close the ticket as soon as it is merged :)
		</comment>
	</comments>
</bug>