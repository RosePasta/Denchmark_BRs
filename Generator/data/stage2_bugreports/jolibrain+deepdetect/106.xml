<bug id='106' author='pranky89' open_date='2016-04-22T12:18:47Z' closed_time='2016-06-19T08:10:57Z'>
	<summary>Error while running GET service info #2</summary>
	<description>
Hello, i m using the following command to create the service.
&lt;denchmark-code&gt;root@cv:~/dev/deepdetect/build# curl -X PUT "http://localhost:8080/services/p" -d "{\"mllib\":\"caffe\",\"description\":\"p classification service\",\"type\":\"supervised\",\"parameters\":{\"input\":{\"connector\":\"image\",\"width\":224,\"height\":224},\"mllib\":{\"template\":\"mlp\",\"nclasses\":5,\"layers\":[512,512,512],\"activation\":\"prelu\"}},\"model\":{\"templates\":\"../templates/caffe/\",\"repository\":\"../../../test_images\"}}"
&lt;/denchmark-code&gt;

Using the following command to train the service
&lt;denchmark-code&gt;curl -X POST "http://localhost:8080/train" -d "{\"service\":\"p\",\"async\":true,\"parameters\":{\"mllib\":{\"gpu\":false,\"net\":{\"batch_size\":32},\"solver\":{\"test_interval\":500,\"iterations\":30000,\"base_lr\":0.001,\"stepsize\":1000,\"gamma\":0.9}},\"input\":{\"connector\":\"image\",\"test_split\":0.1,\"shuffle\":true,\"width\":224,\"height\":224},\"output\":{\"measure\":[\"acc\",\"mcll\",\"f1\"]}},\"data\":[\"../../../test_images\"]}"

&lt;/denchmark-code&gt;

In the dede logs, i can see that it started working on the images directory(attached is the dede log from console output)
&lt;denchmark-link:https://github.com/beniz/quick_cdiscount/files/231719/dede-errorlog.txt&gt;dede-errorlog.txt&lt;/denchmark-link&gt;

And then, if i run the GET training service info, it crashes the Training job with the error:
&lt;denchmark-code&gt;curl -X GET "http://localhost:8080/train?service=p&amp;job=1"
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;INFO - 20:11:47 - Solver scaffolding done.
INFO - 20:11:47 - Ignoring source layer inputl
INFO - 20:11:47 - Ignoring source layer loss
INFO - 20:11:47 - Opened lmdb ../../../test_images/test.lmdb

&gt; ERROR - 20:12:32 - service p training status call failed
&gt; 
&gt; ERROR - 20:12:32 - {"code":500,"msg":"InternalError","dd_code":1007,"dd_msg":"src/caffe/data_transformer.cpp:177 / Check failed (custom): (datum_height) == (height)"}
&lt;/denchmark-code&gt;

If i don't run the check training service info call, i can see the screen is stuck at the following lines in dede console logs:
&lt;denchmark-code&gt;INFO - 20:12:59 - act0 does not need backward computation.
INFO - 20:12:59 - ip0 does not need backward computation.
INFO - 20:12:59 - inputlt does not need backward computation.
INFO - 20:12:59 - This network produces output label
INFO - 20:12:59 - This network produces output losst
INFO - 20:12:59 - Network initialization done.
INFO - 20:12:59 - Solver scaffolding done.
INFO - 20:12:59 - Ignoring source layer inputl
INFO - 20:12:59 - Ignoring source layer loss
&lt;/denchmark-code&gt;

Does it mean its still running and meanwhile, i should not run any check call?
Please assist, thanks
	</description>
	<comments>
		<comment id='1' author='pranky89' date='2016-04-22T12:24:35Z'>
		So, see &lt;denchmark-link:https://github.com/beniz/quick_cdiscount/issues/2#issuecomment-213401451&gt;beniz/quick_cdiscount#2 (comment)&lt;/denchmark-link&gt;

And I don't believe the  template can handle images, especially color ones, since it may not deal with the number of channels. Try the  template instead.
		</comment>
		<comment id='2' author='pranky89' date='2016-04-22T12:37:47Z'>
		Tried covnet and stil the same issue.
&lt;denchmark-code&gt;instantiating model template convnet
I0421 20:57:04.490691 19475 caffelib.cc:76] source=../templates/caffe/convnet/
I0421 20:57:04.490840 19475 caffelib.cc:77] dest=../../../test2_images/convnet.prototxt

WARNING - 20:58:19 - image db file ../../../test2_images/train.lmdb already exists, bypassing creation but checking on records, may take a while...

INFO - 20:58:19 - Opened lmdb ../../../test2_images/train.lmdb
WARNING - 20:58:19 - image db file ../../../test2_images/train.lmdb with 1443 records

WARNING - 20:58:19 - image db file ../../../test2_images/test.lmdb already exists, bypassing creation but checking on records, may take a while...

INFO - 20:58:19 - Opened lmdb ../../../test2_images/test.lmdb
WARNING - 20:58:19 - image db file ../../../test2_images/test.lmdb with 161 records

WARNING - 20:58:19 - image mean file ../../../test2_images/mean.binaryproto already exists, bypassing creation
I0421 20:58:19.226686 19592 caffelib.cc:2093] user batch_size=32 / inputc batch_size=1443
I0421 20:58:19.226711 19592 caffelib.cc:2130] batch_size=37 / test_batch_size=23 / test_iter=7

INFO - 20:58:19 - Initializing solver from parameters:
INFO - 20:58:19 - Creating training net specified in net_param.
INFO - 20:58:19 - The NetState phase (0) differed from the phase (1) specified by a rule in layer inputlt
INFO - 20:58:19 - The NetState phase (0) differed from the phase (1) specified by a rule in layer losst
INFO - 20:58:19 - Initializing net from parameters:
&lt;/denchmark-code&gt;

..........
..........
..........
..........
Ran the check again, and it failed with the same error
&lt;denchmark-code&gt;INFO - 20:58:19 - Opened lmdb ../../../test2_images/test.lmdb
ERROR - 20:58:56 - service p2 training status call failed

ERROR - 20:58:56 - {"code":500,"msg":"InternalError","dd_code":1007,"dd_msg":"src/caffe/data_transformer.cpp:177 / Check failed (custom): (datum_height) == (height)"}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='pranky89' date='2016-04-22T12:39:02Z'>
		Commands used:
&lt;denchmark-code&gt;root@cv:~/dev/deepdetect/build# curl -X PUT "http://localhost:8080/services/p2" -d "{\"mllib\":\"caffe\",\"description\":\"p2 classification service\",\"type\":\"supervised\",\"parameters\":{\"input\":{\"connector\":\"image\",\"width\":224,\"height\":224},\"mllib\":{\"template\":\"convnet\",\"nclasses\":5,\"activation\":\"prelu\"}},\"model\":{\"templates\":\"../templates/caffe/\",\"repository\":\"../../../test2_images\"}}"
{"status":{"code":201,"msg":"Created"}}root@cv:~/dev/deepdetect/build#
&lt;/denchmark-code&gt;

curl -X POST "http://localhost:8080/train" -d "{\"service\":\"p2\",\"async\":true,\"parameters\":{\"mllib\":{\"gpu\":false,\"net\":{\"batch_size\":32},\"solver\":{\"test_interval\":500,\"iterations\":30000,\"base_lr\":0.001,\"stepsize\":1000,\"gamma\":0.9}},\"input\":{\"connector\":\"image\",\"test_split\":0.1,\"shuffle\":true,\"width\":224,\"height\":224},\"output\":{\"measure\":[\"acc\",\"mcll\",\"f1\"]}},\"data\":[\"../../../test2_images\"]}"
Notice that i removed the Layers parameter...as it was giving error:
ERROR - 20:53:26 - service creation mllib bad param: convnet template requires specifying a string array of layers
curl -X GET "http://localhost:8080/train?service=p2&amp;job=1"
		</comment>
		<comment id='4' author='pranky89' date='2016-04-22T13:05:17Z'>
		
Notice that i removed the Layers parameter...as it was giving error:
ERROR - 20:53:26 - service creation mllib bad param: convnet template requires specifying a string array of layers

Look the &lt;denchmark-link:http://www.deepdetect.com/api/?shell#create-a-service&gt;API&lt;/denchmark-link&gt;
 up, it is all explained there. Any bad param error is on your side.
		</comment>
		<comment id='5' author='pranky89' date='2016-04-22T13:10:51Z'>
		Also look at the dedicated examples in &lt;denchmark-link:http://www.deepdetect.com/overview/examples/&gt;http://www.deepdetect.com/overview/examples/&lt;/denchmark-link&gt;
 under the section "Convolutional Neural Network (CNN) for images".
		</comment>
		<comment id='6' author='pranky89' date='2016-04-22T13:43:10Z'>
		Thanks a lot for your quick turnaround time which let the continuation of troubleshooting this issue.
It seems like its my environment specific issue but can be faced by anyone who does what i did.
First, there are two issues here:

MLP can't be used for Images
Checkfailed because MLP corresp.txt and data files were used by Convnet

Issue : Checkfailed
ERROR - 20:58:56 - {"code":500,"msg":"InternalError","dd_code":1007,"dd_msg":"src/caffe/data_transformer.cpp:177 / Check failed (custom): (datum_height) == (height)"}
Cause :
As you noticed in my commands, I used the same directory for MLP and same for CONVNET, which let to the same mlp corresp.txt being used for CONVNET.
I cleaned the repo directory using rm -rf . and started the training creation and train process again, and this time, it displays the following status üëç
root@cv:~/dev/deepdetect/build/main# python cov.py
&lt;denchmark-code&gt;{u'iteration': 0.0}
{u'f1': inf, u'train_loss': 76.35569763183594, u'mcll': inf, u'recall': 0.0, u'iteration': 1.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': 53.90297317504883, u'mcll': inf, u'recall': 0.0, u'iteration': 2.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': 44.35055160522461, u'mcll': inf, u'recall': 0.0, u'iteration': 4.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll':** inf,** u'recall': 0.0, u'iteration': 6.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 7.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 9.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 10.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 12.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 14.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 15.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 17.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 19.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 20.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 22.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 23.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 25.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 27.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 28.0, u'precision': 0.0, u'accp': 0.0}
{u'f1': inf, u'train_loss': inf, u'mcll': inf, u'recall': 0.0, u'iteration': 30.0, u'precision': 0.0, u'accp': 0.0}

&lt;/denchmark-code&gt;

Output from .dede logs
&lt;denchmark-code&gt;INFO - 21:57:13 - Solver scaffolding done.
INFO - 21:57:13 - Ignoring source layer loss
I0421 21:57:18.102923 19789 caffelib.cc:1480] batch size=128
I0421 21:57:18.102996 19789 caffelib.cc:1486] train_loss=nan
I0421 21:57:18.103021 19789 caffelib.cc:1486] mcll=inf
I0421 21:57:18.103034 19789 caffelib.cc:1486] accp=0
I0421 21:57:18.103051 19789 caffelib.cc:1486] recall=0
I0421 21:57:18.103065 19789 caffelib.cc:1486] iteration=0
I0421 21:57:18.103076 19789 caffelib.cc:1486] precision=0
I0421 21:57:18.103088 19789 caffelib.cc:1486] f1=-nan
I0421 21:57:24.772783 19789 caffelib.cc:1533] smoothed_loss=76.3557

&lt;/denchmark-code&gt;

Please confirm if my training indeed seems to be started.
Thanks again!!!
		</comment>
		<comment id='7' author='pranky89' date='2016-04-22T13:46:26Z'>
		Here is the output from CURL:
root@cv:~/dev/test2_images# curl -X GET "http://localhost:8080/train?service=peter&amp;job=1"
{"status":{"code":200,"msg":"OK"},"head":{"method":"/train","job":1,"status":"running","time":741.0},"body":{"measure":{"iteration":118.0,"precision":0.0,"train_loss":2.696539702293474e308,"mcll":1.797693134862316e308,"accp":0.0,"recall":0.0,"f1":2.696539702293474e308}}}
		</comment>
		<comment id='8' author='pranky89' date='2016-04-22T14:07:33Z'>
		Indeed it appears to have started the training phase. You may want to lower your learning rate via base_lr and make sure you are using a GPU.
Are you using 224x224 images ?
		</comment>
		<comment id='9' author='pranky89' date='2016-04-22T14:46:33Z'>
		Here is the output of my images dimension. Its random.
&lt;denchmark-code&gt;root@cv:~/dev/test2_images/n00288000# exiv2 n00288000_894.jpg
File name       : n00288000_894.jpg
File size       : 144142 Bytes
MIME type       : image/jpeg
Image size      : 333 x 500
n00288000_894.jpg: No Exif data found in the file
root@cv:~/dev/test2_images/n00288000# exiv2 n00288000_8866.jpg
File name       : n00288000_8866.jpg
File size       : 12610 Bytes
MIME type       : image/jpeg
Image size      : 221 x 194
n00288000_8866.jpg: No Exif data found in the file
root@cv:~/dev/test2_images/n00288000# exiv2 n00288000_8818.jpg
File name       : n00288000_8818.jpg
File size       : 65725 Bytes
MIME type       : image/jpeg
Image size      : 250 x 349
&lt;/denchmark-code&gt;

Here is the script that i am using:
&lt;denchmark-link:https://github.com/beniz/deepdetect/files/232014/convnet.py.txt&gt;convnet.py.txt&lt;/denchmark-link&gt;

And i get this error:
&lt;denchmark-code&gt;INFO - 22:40:27 - This network produces output label
INFO - 22:40:27 - This network produces output losst
INFO - 22:40:27 - Network initialization done.
INFO - 22:40:27 - Solver scaffolding done.
ERROR - 22:40:28 - service peter training status call failed

ERROR - 22:40:28 - {"code":500,"msg":"InternalError","dd_code":1007,"dd_msg":"src/caffe/net.cpp:696 / Check failed (custom): target_blobs[j]-&gt;shape() == source_blob-&gt;shape()"}


&lt;/denchmark-code&gt;

I am sorry if this is dragging too far...but i need help.
		</comment>
		<comment id='10' author='pranky89' date='2016-04-22T15:40:35Z'>
		
Check failed (custom): target_blobs[j]-&gt;shape() == source_blob-&gt;shape()

Yes I saw this earlier and this is why I was asking about the image size. This requires a fix I have, I'll push it in a few mins. Thanks for reporting this.
		</comment>
		<comment id='11' author='pranky89' date='2016-04-22T15:53:54Z'>
		Thanks, sounds good Beniz.
		</comment>
		<comment id='12' author='pranky89' date='2016-04-22T15:56:03Z'>
		Here. There was a way to set the size by hand, but the commit above automates it.
		</comment>
		<comment id='13' author='pranky89' date='2016-04-22T18:00:24Z'>
		Thanks, this worked. Training process completed. Here is the output:
&lt;denchmark-code&gt;root@cv:~/dev/deepdetect/build/main# python cov.py
{}
{u'iteration': 0.0}
{u'iteration': 0.0}
{u'f1': 0.11869065567509052, u'train_loss': inf, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 0.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 52.40192794799805, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 2.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 57.82695007324219, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 4.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 64.04679870605469, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 6.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 46.579490661621094, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 7.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 81.51411437988281, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 10.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 69.8692398071289, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 12.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 52.40192794799805, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 14.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 46.579490661621094, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 14.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 46.579490661621094, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 14.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'f1': 0.11869065567509052, u'train_loss': 46.579490661621094, u'mcll': inf, u'recall': 0.1782231668459716, u'iteration': 14.0, u'precision': 0.0889712696070292, u'accp': 0.1111111111111111}
{u'status': {u'msg': u'OK', u'code': 200}, u'body': {u'measure': {u'f1': 0.1355102040705706, u'train_loss': 46.579490661621094, u'mcll': inf, u'recall': 0.10246913579614388, u'iteration': 14.0, u'precision': 0.19999999997590362, u'accp': 0.5123456790123457}}, u'head': {u'status': u'finished', u'job': 1, u'method': u'/train', u'time': 147.0}}

&lt;/denchmark-code&gt;

I am continuing with the next steps.
I have plans on creating a noobs friendly guide as well :)
Thanks again for rapid fast support. You've been great.
		</comment>
		<comment id='14' author='pranky89' date='2016-04-22T18:10:55Z'>
		Thanks for your patience, and for catching that error!
		</comment>
		<comment id='15' author='pranky89' date='2016-04-22T18:24:23Z'>
		Ok next step :
Training got completed as you saw the output but somehow service got destroyed after the training completed.
Expect it to be there after the training completes or atleast recreate if needed.
I tried recreating the service with the trained model that i got.
root@cv:~/dev/deepdetect/build/main# curl -X PUT "http://localhost:8080/services/imageserv" -d "{\"mllib\":\"caffe\",\"description\":\"image classification service\",\"type\":\"supervised\",\"parameters\":{\"input\":{\"connector\":\"image\",\"width\":224,\"height\":224},\"mllib\":{\"template\":\"convnet\",\"nclasses\":5}},\"model\":{\"templates\":\"../templates/caffe/\",\"repository\":\"../../../test2_images\"}}"
{"status":{"code":201,"msg":"Created"}}
Now, i tried performing the prediction using this service and received the FATAL caffee error.
root@cv:~/dev/deepdetect/build/main# curl -X POST "http://localhost:8080/predict" -d "{\"service\":\"imageserv\",\"parameters\":{\"input\":{\"width\":224,\"height\":224},\"output\":{\"best\":3}},\"data\":[\"http://previews.123rf.com/images/leonido/leonido1105/leonido110500282/9551752-Modern-ambulance-van-over-white-Colored-vector-illustration-Stock-Vector.jpg\"]}"
**{"status":{"code":500,"msg":"InternalError","dd_code":1007,"dd_msg":"/root/dev/deepdetect/build/caffe_dd/src/caffe_dd/include/caffe/llogging.h:158 / Fatal Caffe error"}}**
dede console output shows only this info
&lt;denchmark-code&gt;INFO - 02:42:28 - Initializing net from parameters:

ERROR - 02:42:28 - service imageserv prediction call failed

&lt;/denchmark-code&gt;

How can i :

Increase the verbosity of dede logs, i can't seem to find a relevant flag for this?
How can i fix this prediction error?

		</comment>
		<comment id='16' author='pranky89' date='2016-04-22T18:30:38Z'>
		You need to look carefully at the rules of thumb section, last bullet point on this page &lt;denchmark-link:http://www.deepdetect.com/overview/examples/&gt;http://www.deepdetect.com/overview/examples/&lt;/denchmark-link&gt;
.
Typically, avoid the template at service re-creation, or your previous neural net template will be erased. We wish to have a protection against this, but I'm still pondering whether the PUT /services call should simply error away when a model already exists and a template is called on.
Also see the bottom section of &lt;denchmark-link:http://www.deepdetect.com/tutorials/txt-training/&gt;http://www.deepdetect.com/tutorials/txt-training/&lt;/denchmark-link&gt;
 and use the  at the bottom of the page to fix your current model definition.
		</comment>
		<comment id='17' author='pranky89' date='2016-04-22T18:34:03Z'>
		
Expect it to be there after the training completes or atleast recreate if needed.

You very certainly deleted it. A training call does not delete the service.
		</comment>
		<comment id='18' author='pranky89' date='2016-04-22T18:35:16Z'>
		

Increase the verbosity of dede logs, i can't seem to find a relevant flag for this


There's no verbosity parameter at the moment. One of the reasons is that we're still slowly consolidating an integrated logging header across the supported machine learning libraries, a hellish job.
		</comment>
		<comment id='19' author='pranky89' date='2016-04-26T08:05:52Z'>
		The commit above adds protection against erasing an existing Caffe model definition. This thread made it clear that conservative protection might be better than full freedom wrt to the templates.
		</comment>
		<comment id='20' author='pranky89' date='2016-05-05T16:22:55Z'>
		&lt;denchmark-link:https://github.com/pranky89&gt;@pranky89&lt;/denchmark-link&gt;
 what's the status ?
		</comment>
		<comment id='21' author='pranky89' date='2016-05-05T16:50:29Z'>
		Sorry, we couldn't get some features to work, thus we stopped putting more efforts on this Project.
Thanks for all your assistance here.
		</comment>
		<comment id='22' author='pranky89' date='2016-05-05T17:02:09Z'>
		OK, I'll close the issue then. Let us know of the features that did not work for you, I believe it's the first tim e I hear this ^^
		</comment>
	</comments>
</bug>