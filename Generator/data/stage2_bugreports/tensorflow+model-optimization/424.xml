<bug id='424' author='joyalbin' open_date='2020-06-11T03:57:18Z' closed_time='2020-06-12T20:47:39Z'>
	<summary>Is there any way to apply QuantizeConfig for Model used from Keras Modelzoo?</summary>
	<description>
System information

TensorFlow version (you are using): 2.2
Are you willing to contribute it (Yes/No): yes

I tried use predefined models from keras using tf.keras.applications.MobileNetV2()
I could see there are provisions to configure the quantization (bits, range or algos) for each layer using tfmot.quantization.keras.quantize_annotate_layer() and apply with tfmot.quantization.keras.quantize_apply()
But in case of keras.applications models, user is not dealing with model layers directly. So if I have set the customised QuantizeConfig then what should be the approach?
	</description>
	<comments>
		<comment id='1' author='joyalbin' date='2020-06-11T19:58:56Z'>
		See this documentation: &lt;denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#quantize_some_layers&gt;https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#quantize_some_layers&lt;/denchmark-link&gt;

and use QuantizeConfig together as described in the other documentation.
		</comment>
		<comment id='2' author='joyalbin' date='2020-06-12T01:21:27Z'>
		Got it. Thank you very much
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, 12 Jun, 2020, 1:29 am alanchiao, ***@***.***&gt; wrote:
 See this documentation:
 https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide#quantize_some_layers

 and use QuantizeConfig together as described in the other documentation.

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 &lt;#424 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AAOFJIXMIKKEC7LJVFJDNLTRWEZQ5ANCNFSM4N3A7JAQ&gt;
 .



		</comment>
	</comments>
</bug>