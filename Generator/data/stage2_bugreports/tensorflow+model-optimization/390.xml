<bug id='390' author='Craftsman381' open_date='2020-05-14T08:48:13Z' closed_time='2020-05-15T08:19:49Z'>
	<summary>AttributeError: 'NoneType' object has no attribute 'iterations'</summary>
	<description>
Describe the bug
I'm trying to prune MobileNet model but its giving me error when I call fit_generator. I don't know why is it so...
System information
Linux Ubuntu 19.10
TensorFlow installed from (source or binary):
binary
TensorFlow version:
1.14
TensorFlow Model Optimization version:
0.3.0
Python version:
3.6
Describe the expected behavior
Should start pruning model
Describe the current behavior
Giving an error on optimizer
CODE:
&lt;denchmark-code&gt;NUM_EPOCHS = 50
num_train_images = 2000

#-----------pruning-------------
num_train_samples=train_generator.samples

end_step = np.ceil(1.0 * num_train_samples / BATCH_SIZE).astype(np.int32) * NUM_EPOCHS
print(end_step)

new_pruning_params = {
      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,
                                                   final_sparsity=0.90,
                                                   begin_step=5,
                                                   end_step=end_step,
                                                   frequency=5)
}

new_pruned_model = sparsity.prune_low_magnitude(finetune_model, **new_pruning_params, )
new_pruned_model.summary()
#-------------------------------

new_pruned_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

filepath="warm_up.h5"

checkpoint = [ModelCheckpoint(filepath, monitor=["acc"], verbose=1, mode='max'),
              sparsity.UpdatePruningStep(),
              sparsity.PruningSummaries(log_dir="./prune_logs/", profile_batch=0)]

history = new_pruned_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, 
                                       steps_per_epoch=num_train_images // BATCH_SIZE, 
                                       shuffle=True, callbacks=checkpoint,
                                       validation_data=val_generator,
                                       validation_steps=1000 // BATCH_SIZE
                                      )
&lt;/denchmark-code&gt;

ERROR:
&lt;denchmark-code&gt;&gt; AttributeError                            Traceback (most recent call last)
&gt; &lt;ipython-input-7-2f5496fc60ea&gt; in &lt;module&gt;
&gt;      39                                        shuffle=True, callbacks=checkpoint,
&gt;      40                                        validation_data=val_generator,
&gt; ---&gt; 41                                        validation_steps=1000 // BATCH_SIZE
&gt;      42                                       )
&gt; 
&gt; ~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
&gt;    1431         shuffle=shuffle,
&gt;    1432         initial_epoch=initial_epoch,
&gt; -&gt; 1433         steps_name='steps_per_epoch')
&gt;    1434 
&gt;    1435   def evaluate_generator(self,
&gt; 
&gt; ~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
&gt;     193 
&gt;     194   callbacks.model.stop_training = False
&gt; --&gt; 195   callbacks._call_begin_hook(mode)
&gt;     196   progbar.on_train_begin()
&gt;     197 
&gt; 
&gt; ~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py in _call_begin_hook(self, mode)
&gt;     260     """Helper function for on_{train|test|predict}_begin methods."""
&gt;     261     if mode == ModeKeys.TRAIN:
&gt; --&gt; 262       self.on_train_begin()
&gt;     263     elif mode == ModeKeys.TEST:
&gt;     264       self.on_test_begin()
&gt; 
&gt; ~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py in on_train_begin(self, logs)
&gt;     376     """
&gt;     377     for callback in self.callbacks:
&gt; --&gt; 378       callback.on_train_begin(logs)
&gt;     379 
&gt;     380   def on_train_end(self, logs=None):
&gt; 
&gt; ~/anaconda3/envs/unet/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks.py in on_train_begin(self, logs)
&gt;      58 
&gt;      59   def on_train_begin(self, logs=None):
&gt; ---&gt; 60     self.step = K.get_value(self.model.optimizer.iterations)
&gt;      61 
&gt;      62   def on_train_batch_begin(self, batch, logs=None):
&gt; 
&gt; AttributeError: 'NoneType' object has no attribute 'iterations'
&lt;/denchmark-code&gt;


Error raised from this &lt;denchmark-link:https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks.py&gt;file&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Craftsman381' date='2020-05-18T23:50:04Z'>
		For others in the future, can you mention how you resolved this issue?
Looks like the optimizer wasn't attached to the model (hence it thought model.optimizer was None), even though you called model.compile.
		</comment>
		<comment id='2' author='Craftsman381' date='2020-11-27T13:13:40Z'>
		&lt;denchmark-link:https://github.com/alanchiao&gt;@alanchiao&lt;/denchmark-link&gt;
 is right, I faced the same problem and I compiled the pruning model again with the optimiser and the issue was fixed.
		</comment>
	</comments>
</bug>