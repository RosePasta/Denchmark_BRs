<bug id='457' author='aa12356jm' open_date='2020-07-12T13:11:30Z' closed_time='2020-09-07T06:31:14Z'>
	<summary>Quantization aware training can not save weights  as uint8?</summary>
	<description>
i use tf1.x to  quantization aware training , the weights of model  can  be saved to uint8 , but tf2.x can not  save weights  as uint8,   because  the DSP need uint8  model to  accelerate the inference ,  have you the  plan to  support  unit8  ,thanks
	</description>
	<comments>
		<comment id='1' author='aa12356jm' date='2020-09-07T06:31:14Z'>
		tflite have already support full int8 model on dsp,  thanks
		</comment>
	</comments>
</bug>