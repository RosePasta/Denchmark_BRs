<bug id='2076' author='VoVAllen' open_date='2020-08-20T10:02:00Z' closed_time='2020-08-26T16:23:34Z'>
	<summary>[Bug?] Empty cuda graph raise error when create_formats_</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

import dgl
g = dgl.graph([])
g = g.to("cuda:0")
g.create_format_()
# raise error
&lt;denchmark-code&gt;~/dev/csr/dgl/python/dgl/heterograph_index.py in create_format_(self)
    912     def create_format_(self):
    913         """Create all sparse matrices allowed for the graph."""
--&gt; 914         return _CAPI_DGLHeteroCreateFormat(self)
    915
    916     def reverse(self):

~/dev/csr/dgl/python/dgl/_ffi/_cython/function.pxi in dgl._ffi._cy3.core.FunctionBase.__call__()

~/dev/csr/dgl/python/dgl/_ffi/_cython/function.pxi in dgl._ffi._cy3.core.FuncCall()

~/dev/csr/dgl/python/dgl/_ffi/_cython/function.pxi in dgl._ffi._cy3.core.FuncCall3()

~/dev/csr/dgl/python/dgl/_ffi/_cython/base.pxi in dgl._ffi._cy3.core.CALL()

DGLError: [08:55:53] /home/ubuntu/dev/csr/dgl/src/array/cuda/./utils.h:26: Check failed: dim != 0 (0 vs. 0) :
Stack trace:
  [bt] (0) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x34) [0x7f233982251a]
  [bt] (1) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dgl::cuda::FindNumThreads(int, int)+0xd1) [0x7f233a8e6596]
  [bt] (2) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR&lt;(DLDeviceType)2, long&gt;(dgl::aten::COOMatrix)+0x2a8) [0x7f233a92df0f]
  [bt] (3) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dgl::aten::COOToCSR(dgl::aten::COOMatrix)+0x4ab) [0x7f23398163e8]
  [bt] (4) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dgl::UnitGraph::GetOutCSR(bool) const+0x3d4) [0x7f233a894888]
  [bt] (5) /home/ubuntu/dev/csr/dgl/build/libdgl.so(dgl::UnitGraph::GetFormat(dgl::SparseFormat) const+0x49) [0x7f233a895477]
  [bt] (6) /home/ubuntu/dev/csr/dgl/build/libdgl.so(+0x22410b3) [0x7f233a7b00b3]
  [bt] (7) /home/ubuntu/dev/csr/dgl/build/libdgl.so(+0x224a70a) [0x7f233a7b970a]
  [bt] (8) /home/ubuntu/dev/csr/dgl/build/libdgl.so(std::function&lt;void (dgl::runtime::DGLArgs, dgl::runtime::DGLRetValue*)&gt;::operator()(dgl::runtime::DGLArgs, dgl::runtime::DGLRetValue*) const+0x5a) [0x7f233a7075de]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:





&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


DGL Version (e.g., 1.0):
Backend Library &amp; Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3):
OS (e.g., Linux):
How you installed DGL (conda, pip, source):
Build command you used (if compiling from source):
Python version:
CUDA/cuDNN version (if applicable):
GPU models and configuration (e.g. V100):
Any other relevant information:

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='VoVAllen' date='2020-08-21T04:14:25Z'>
		Yep 0 threads is not a desired behavior, we should add some checks in the future.
		</comment>
	</comments>
</bug>