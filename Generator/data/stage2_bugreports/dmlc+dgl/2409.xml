<bug id='2409' author='zrqiao' open_date='2020-12-09T01:53:31Z' closed_time='2021-01-05T14:22:04Z'>
	<summary>Batching fails when remove_edges is called on part of the graphs</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

In my graph dataloader, g.remove_edges(zero_eid) is called on each graph before batching, but for some graphs zero_eid has no elements. When calling dgl.batch, I got the following error:

dgl._ffi.base.DGLError: Expect all graphs to have the same schema on nodes["ao"].data, but graph 6 got
{'n': Scheme(shape=(), dtype=torch.int64), 'l': Scheme(shape=(), dtype=torch.int64)}
which is different from
{'n': Scheme(shape=(), dtype=torch.int64), 'l': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)}.

&lt;denchmark-h:h2&gt;Suggested changes&lt;/denchmark-h&gt;

I used the following workaround that changes &lt;denchmark-link:https://github.com/dmlc/dgl/blob/master/python/dgl/heterograph.py#L680&gt;L680-690 of dgl/heterograph.py&lt;/denchmark-link&gt;
 to:
&lt;denchmark-code&gt;         if len(eids) &gt; 0:
             assert self.number_of_edges(etype) &gt; F.as_scalar(F.max(eids, dim=0)), \
                 "The input eid {} is out of the range [0:{})".format(
                     F.as_scalar(F.max(eids, dim=0)), self.number_of_edges(etype))

         # edge_subgraph
         edges = {}
         u_type, e_type, v_type = self.to_canonical_etype(etype)
         for c_etype in self.canonical_etypes:
             # the target edge type
             if c_etype == (u_type, e_type, v_type) and len(eids) &gt; 0:
                 origin_eids = self.edges(form='eid', order='eid', etype=c_etype)
                 edges[c_etype] = utils.compensate(eids, origin_eids)
             else:
                 edges[c_etype] = self.edges(form='eid', order='eid', etype=c_etype)
&lt;/denchmark-code&gt;

which enforce self.edge_subgraph to be called when the number of edges to be removed is zero. I can make a PR if this is a desirable solution. Thanks!
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


DGL Version: 0.5.3
Backend Library &amp; Version: PyTorch 1.7.0
OS: Linux
How you installed DGL: pip
Python version: 3.7
CUDA/cuDNN version (if applicable): 10.2
GPU models and configuration: V100

	</description>
	<comments>
		<comment id='1' author='zrqiao' date='2020-12-10T07:12:28Z'>
		Thanks for the report and I confirmed the error with the code snippet below.
import dgl
import torch

g1 = dgl.graph(([1, 2], [2, 3]))
g2 = dgl.graph(([1], [0]))
g3 = dgl.graph(([1, 1, 1,], [2, 3, 0]))
node_feats = 2
edge_feats = 3
graphs = [g1, g2, g3]
for g in graphs:
    g.ndata['hv'] = torch.randn(g.num_nodes(), node_feats)
    g.edata['he'] = torch.randn(g.num_edges(), edge_feats)

g1.remove_edges([])
g2.remove_edges([0])
g3.remove_edges([0, 2])
bg = dgl.batch([g1, g2, g3])
It seems that remove_edges invokes edge_subgraph, which records the original IDs for the nodes/edges in the subgraph. Meanwhile, it skips the operation when remove_edges has no elements at all. I guess a similar issue also exists for remove_nodes. I can think of the following options:

Enforcing the call of subgraph extraction as you proposed. The drawback is that this brings additional unnecessary overhead.
Simply not storing the original node/edge IDs. This is not mentioned in the doc as well.
Add an additional argument to enable/disable storing the original node/edge IDs.

What do you think? Copy &lt;denchmark-link:https://github.com/jermainewang&gt;@jermainewang&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='zrqiao' date='2020-12-10T17:58:39Z'>
		Thanks. As for now, to avoid mutating the source code I used a tricky workaround: I just create a new graph with the subgraph indices/features to manually remove the original EIDs.
My opinion is that if we do not change the current function, the issue can be circumvented in the application code. But I agree that this behavior of remove_edges should be elaborated on in the documentation to avoid confusion.
		</comment>
	</comments>
</bug>