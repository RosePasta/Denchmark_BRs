<bug id='2477' author='zjost' open_date='2020-12-31T22:00:02Z' closed_time='2021-01-11T06:32:22Z'>
	<summary>Interacts with aws-data-wrangler to cause crashes</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

In a Jupyter notebook, if I import DGL before aws-data-wrangler (wr), the kernel will crash when I try to use wr.  If I import DGL after wr, it works fine.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import dgl # results in crash if imported here
import awswrangler as wr
# import dgl # works fine if imported here

df = wr.s3.read_parquet(
    "s3://&lt;MY_PARQUET&gt;", 
    dataset=True,
)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


DGL Version (e.g., 1.0): 0.5.2 (dgl-cu100==0.5.2)
Backend Library &amp; Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3): PyTorch 1.5.0
OS (e.g., Linux):  Amazon Linux?  (SageMaker notebook on p3)
How you installed DGL (conda, pip, source):  I don't remember.  Probably pip.  Definitely not from source.
Python version:  Python 3.6.10
CUDA/cuDNN version (if applicable): 10.0
GPU models and configuration (e.g. V100):  p3 instance

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

As mentioned, the above code will crash the Jupyter kernel.  However, running in a terminal gives the following output:
&lt;denchmark-code&gt;terminate called after throwing an instance of 'std::regex_error'
  what():  Number of NFA states exceeds limit. Please use shorter regex string, or use smaller braceexpression, or make _GLIBCXX_REGEX_STATE_LIMIT larger.
Aborted
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='zjost' date='2021-01-01T10:07:29Z'>
		Probably related to &lt;denchmark-link:https://github.com/dmlc/dgl/issues/2255&gt;#2255&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/BarclayII&gt;@BarclayII&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='zjost' date='2021-01-06T03:45:39Z'>
		Same question. Have you solved this?
		</comment>
		<comment id='3' author='zjost' date='2021-01-06T09:22:37Z'>
		I cannot reproduce it on my own machine (ubuntu 16.04) but can reproduce it on the aws sagemaker instances.
Sample code below
import dgl
bucket = 'xxxx'
path = f"s3://{bucket}/test_parquet/"
from datetime import date
import awswrangler as wr
import pandas as pd
df = pd.DataFrame({
    "id": [1, 2],
    "value": ["foo", "boo"],
    "date": [date(2020, 1, 1), date(2020, 1, 2)]
})
wr.s3.to_parquet(
    df=df,
    path=path,
    dataset=True,
    mode="overwrite"
)
wr.s3.read_parquet(path, dataset=True)
		</comment>
		<comment id='4' author='zjost' date='2021-01-06T10:36:12Z'>
		I found this is solved by using the nightly build of dgl. Probably related to the RTLD_GLOBAL flag
		</comment>
		<comment id='5' author='zjost' date='2021-01-07T11:47:31Z'>
		&lt;denchmark-link:https://github.com/zjost&gt;@zjost&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/YankeeTsao&gt;@YankeeTsao&lt;/denchmark-link&gt;
 Would you please try install DGL's nightly build to see whether the issue still exists?
		</comment>
		<comment id='6' author='zjost' date='2021-01-07T15:56:12Z'>
		
@zjost @YankeeTsao Would you please try install DGL's nightly build to see whether the issue still exists?

I'll try later. Thanks!
		</comment>
		<comment id='7' author='zjost' date='2021-01-09T08:09:20Z'>
		
@zjost @YankeeTsao Would you please try install DGL's nightly build to see whether the issue still exists?
@jermainewang I have tried the nightly build of DGL with different versions of PyTorch(1.5.0, 1.6.0, 1.7.0), and all work fine.

		</comment>
	</comments>
</bug>