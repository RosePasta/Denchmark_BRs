<bug id='2500' author='leodestiny' open_date='2021-01-06T14:18:15Z' closed_time='2021-01-14T07:00:50Z'>
	<summary>Memory leak when deleting shared memory ndarray at runtime</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

We are using shared memory ndarray in DGL. We found when dynamical allocating and freeing ndarray, they cannot correctly be deleted correctly on real physical memory, which lead to memory leak on shared memory at runtime.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

run below codes

Python 3.8.2 (default, May 20 2020, 12:05:48)
[GCC 6.3.0 20170516] on linux
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import dgl
Using backend: pytorch
/home/tiger/github/dgl/python/dgl/base.py:45: DGLWarning: Detected an old version of PyTorch. Suggest using torch&gt;=1.5.0 for the best experience.
  return warnings.warn(message, category=category, stacklevel=1)
&gt;&gt;&gt; from dgl._ffi.ndarray import empty_shared_mem
&gt;&gt;&gt; for i in range(10):
...     s = empty_shared_mem("test{:d}".format(i), True, (10000,100))
...     print(s)
...     del s
...
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test0 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test1 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test2 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test3 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test4 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test5 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test6 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test7 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test8 for shared memory
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
[21:46:41] /home/tiger/github/dgl/src/runtime/shared_mem.cc:58: remove test9 for shared memory
&gt;&gt;&gt;
&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

We expect these ndarray should be deleted both on the directory /dev/shm and real psychical memory.
Shared memory objects on /dev/shm have been deleted as expected.
$ ls /dev/shm
$
However, these ndarray still using psychical memory.
$ df -h
Filesystem      Size  Used Avail Use% Mounted on
shm             178G   39M  178G   1% /dev/shm
If we dive into the /proc/PID/maps, we can find these ndarray are only labeled by "deleted" but still in psychical memory.
These shared memory will be freed only when this process is terminated.
$ cd /proc/2774772
$ cat maps | grep test
7f0e3b81c000-7f0e3bbed000 rw-s 00000000 00:3e 1635644643                 /dev/shm/test9 (deleted)
7f0e3bbed000-7f0e3bfbe000 rw-s 00000000 00:3e 1635644642                 /dev/shm/test8 (deleted)
7f0e3bfbe000-7f0e3c38f000 rw-s 00000000 00:3e 1635644641                 /dev/shm/test7 (deleted)
7f0e3c38f000-7f0e3c760000 rw-s 00000000 00:3e 1635644640                 /dev/shm/test6 (deleted)
7f0e3c760000-7f0e3cb31000 rw-s 00000000 00:3e 1635644639                 /dev/shm/test5 (deleted)
7f0e3cb31000-7f0e3cf02000 rw-s 00000000 00:3e 1635644638                 /dev/shm/test4 (deleted)
7f0e3cf02000-7f0e3d2d3000 rw-s 00000000 00:3e 1635644637                 /dev/shm/test3 (deleted)
7f0e3d2d3000-7f0e3d6a4000 rw-s 00000000 00:3e 1635644636                 /dev/shm/test2 (deleted)
7f0e3d6a4000-7f0e3da75000 rw-s 00000000 00:3e 1635644635                 /dev/shm/test1 (deleted)
7f0e3da75000-7f0e3de46000 rw-s 00000000 00:3e 1635644634                 /dev/shm/test0 (deleted)

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


DGL Version (e.g., 1.0): 0.6
Backend Library &amp; Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3): PyTorch 1.4.0
OS (e.g., Linux): Linux
How you installed DGL (conda, pip, source): source
Build command you used (if compiling from source): same as the official command
Python version: 3.8.2
CUDA/cuDNN version (if applicable):
GPU models and configuration (e.g. V100):
Any other relevant information:

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

If using shared memory provided by &lt;denchmark-link:https://docs.python.org/3/library/multiprocessing.shared_memory.html&gt;python offical&lt;/denchmark-link&gt;
, it can delete shared memory both on /dev/shm and real physical memory correctly.
	</description>
	<comments>
		<comment id='1' author='leodestiny' date='2021-01-07T12:42:11Z'>
		Seems that during  the size argument passed in is always 0 in the above case.  &lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>