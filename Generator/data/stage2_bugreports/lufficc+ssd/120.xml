<bug id='120' author='kongbia' open_date='2019-12-09T08:22:30Z' closed_time='2020-11-13T19:03:55Z'>
	<summary>distributed test</summary>
	<description>
When I did distributed test with 2 gpus on my own dataset,  the following error occurs. But it can run successfully with single gpu.
2019-12-09 15:49:02,634 SSD.inference INFO: Evaluating mocod_val_sp dataset(22177 images): 0%|                                                                                                      | 0/1109 [00:00&lt;?, ?it/s]index created! 100%|███████████████████████████████████████████████████████████████████████████████████████████| 1109/1109 [05:48&lt;00:00,  3.18it/s] 100%|███████████████████████████████████████████████████████████████████████████████████████████| 1109/1109 [06:07&lt;00:00,  3.02it/s] 2019-12-09 15:55:17,072 SSD.inference WARNING: Number of images that were gathered from multiple processes is not a contiguous set. Some images might be missing from the evaluation Traceback (most recent call last): File "test.py", line 87, in &lt;module&gt; main() File "test.py", line 83, in main evaluation(cfg, ckpt=args.ckpt, distributed=distributed) File "test.py", line 27, in evaluation do_evaluation(cfg, model, distributed) File "/home/zhangjinpu/.conda/envs/mmdet/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 49, in decorate_no_grad return func(*args, **kwargs) File "/mnt/zhangjinpu/CODE/SSD/ssd/engine/inference.py", line 82, in do_evaluation eval_result = inference(model, data_loader, dataset_name, device, output_folder, **kwargs) File "/mnt/zhangjinpu/CODE/SSD/ssd/engine/inference.py", line 67, in inference return evaluate(dataset=dataset, predictions=predictions, output_dir=output_folder, **kwargs) File "/mnt/zhangjinpu/CODE/SSD/ssd/data/datasets/evaluation/__init__.py", line 24, in evaluate return coco_evaluation(**args) File "/mnt/zhangjinpu/CODE/SSD/ssd/data/datasets/evaluation/coco/__init__.py", line 10, in coco_evaluation img_info = dataset.get_img_info(i) File "/mnt/zhangjinpu/CODE/SSD/ssd/data/datasets/mocod.py", line 70, in get_img_info image_id = self.ids[index] IndexError: list index out of range 
	</description>
	<comments>
		<comment id='1' author='kongbia' date='2020-10-22T09:53:26Z'>
		please，Could you tell me how to solve this problem by yourself ? When i train my own dataset by one GPU also meet this question
		</comment>
		<comment id='2' author='kongbia' date='2020-10-22T12:25:09Z'>
		In -&gt;ssd/data/build.py
line 49:batch_sampler = torch.utils.data.sampler.BatchSampler(sampler=sampler, batch_size=batch_size, drop_last=False)
setting the parameter of drop_last=False
this can put all of the test dataset into test
		</comment>
	</comments>
</bug>