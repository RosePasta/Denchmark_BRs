<bug id='3234' author='crockpotveggies' open_date='2017-04-12T00:04:01Z' closed_time='2017-04-13T09:13:46Z'>
	<summary>PW + AsyncIterator leaks memory</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

After 7 epochs using Inception on a long-running training process, AsyncIterator will leak memory and eventually throw this exception:
&lt;denchmark-code&gt;[AsyncIterator thread] ERROR java.lang.Throwable - Exception in thread "AsyncIterator thread" java.lang.OutOfMemoryError: Cannot allocate new FloatPointer(8644): totalBytes = -439058375, physicalBytes = 57G
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:76)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:41)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.buffer.BaseCudaDataBuffer.set(BaseCudaDataBuffer.java:429)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.buffer.BaseCudaDataBuffer.&lt;init&gt;(BaseCudaDataBuffer.java:115)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.buffer.CudaFloatDataBuffer.&lt;init&gt;(CudaFloatDataBuffer.java:102)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.buffer.factory.CudaDataBufferFactory.createFloat(CudaDataBufferFactory.java:171)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.factory.Nd4j.createBuffer(Nd4j.java:1212)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.api.ndarray.BaseNDArray.&lt;init&gt;(BaseNDArray.java:393)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.api.ndarray.BaseNDArray.&lt;init&gt;(BaseNDArray.java:636)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.JCublasNDArray.&lt;init&gt;(JCublasNDArray.java:297)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.jcublas.JCublasNDArrayFactory.create(JCublasNDArrayFactory.java:332)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.factory.BaseNDArrayFactory.create(BaseNDArrayFactory.java:1375)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:3415)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.util.NDArrayUtil.toNDArray(NDArrayUtil.java:35)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.nd4j.linalg.util.FeatureUtil.toOutcomeVector(FeatureUtil.java:39)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.getDataSet(RecordReaderDataSetIterator.java:256)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:199)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:411)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:53)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.iterator.AsyncDataSetIterator$IteratorRunnable.run(AsyncDataSetIterator.java:364)
[AsyncIterator thread] ERROR java.lang.Throwable - Caused by: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes = 57G &gt; maxPhysicalBytes = 56G
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:572)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.Pointer.init(Pointer.java:121)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.FloatPointer.allocateArray(Native Method)
[AsyncIterator thread] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:68)
[AsyncIterator thread] ERROR java.lang.Throwable - 	... 19 more
[Thread-71] ERROR org.deeplearning4j.parallelism.ParallelWrapper - Uncaught exception: java.lang.OutOfMemoryError: Cannot allocate new FloatPointer(1): totalBytes = -439058623, physicalBytes = 56G
&lt;/denchmark-code&gt;

Unsure how to address it. With new workspace I have GC disabled, and I'm unsure if GC can solve this problem.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j MASTER
ubuntu 16.04
CUDA 8, cuDNN 6
NVIDIA driver 378

	</description>
	<comments>
		<comment id='1' author='crockpotveggies' date='2017-04-12T13:32:26Z'>
		Where can i see the code, which reproduces this behavior?
		</comment>
		<comment id='2' author='crockpotveggies' date='2017-04-12T13:33:34Z'>
		And what happens with periodic GC enabled?
		</comment>
		<comment id='3' author='crockpotveggies' date='2017-04-12T13:39:15Z'>
		And why do you think it's ADSI leaking? Not sure too...
		</comment>
		<comment id='4' author='crockpotveggies' date='2017-04-13T03:35:05Z'>
		FYI ran into this again on your branch:
&lt;denchmark-code&gt;[main] INFO RCROPSTAGE1-0.1LR-72BATCH - *** Completed epoch 8, time: 845588 ***
[main] ERROR java.lang.Throwable - Exception in thread "main" java.lang.OutOfMemoryError: Cannot allocate new BytePointer(33631): totalBytes = -439058631, physicalBytes = 28G
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.BytePointer.&lt;init&gt;(BytePointer.java:103)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.BytePointer.&lt;init&gt;(BytePointer.java:68)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:14907)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.opencv_core$Mat.&lt;init&gt;(opencv_core.java:14906)
[main] ERROR java.lang.Throwable - 	at org.datavec.image.loader.NativeImageLoader.asMatrix(NativeImageLoader.java:194)
[main] ERROR java.lang.Throwable - 	at org.datavec.image.loader.NativeImageLoader.asMatrix(NativeImageLoader.java:187)
[main] ERROR java.lang.Throwable - 	at org.datavec.image.recordreader.BaseImageRecordReader.next(BaseImageRecordReader.java:216)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:198)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:411)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:53)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.nn.graph.ComputationGraph.doEvaluation(ComputationGraph.java:2634)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.nn.graph.ComputationGraph.evaluate(ComputationGraph.java:2516)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.nn.graph.ComputationGraph.evaluate(ComputationGraph.java:2490)
[main] ERROR java.lang.Throwable - 	at org.deeplearning4j.nn.graph.ComputationGraph.evaluate(ComputationGraph.java:2469)
[main] ERROR java.lang.Throwable - 	at ai.bernie.train.TrainClassifier.run(TrainClassifier.java:207)
[main] ERROR java.lang.Throwable - 	at ai.bernie.train.TrainerRunner.run(TrainerRunner.java:141)
[main] ERROR java.lang.Throwable - 	at ai.bernie.train.TrainerRunner.main(TrainerRunner.java:163)
[main] ERROR java.lang.Throwable - Caused by: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes = 28G &gt; maxPhysicalBytes = 28G
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:572)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.Pointer.init(Pointer.java:121)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.BytePointer.allocateArray(Native Method)
[main] ERROR java.lang.Throwable - 	at org.bytedeco.javacpp.BytePointer.&lt;init&gt;(BytePointer.java:95)
[main] ERROR java.lang.Throwable - 	... 16 more
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='crockpotveggies' date='2017-04-13T09:13:46Z'>
		Issue is fixed, ParallelWrapper wasn't reusing MQ instance, so after each epoch new MQ was instantiated.
		</comment>
		<comment id='6' author='crockpotveggies' date='2018-09-29T20:44:00Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>