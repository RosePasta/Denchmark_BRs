<bug id='1655' author='vzamboni' open_date='2016-06-07T11:03:13Z' closed_time='2016-11-30T09:42:27Z'>
	<summary>Scala mismatch in dl4j-spark in sbt project</summary>
	<description>
I am using dl4j-spark with scala 2.10 and building with sbt on a Windows machine with java 8. When I try with sbt assembly I get the error:
&lt;denchmark-link:https://gist.github.com/vzamboni/9022a3e135733e04d64560e33d9ac943&gt;https://gist.github.com/vzamboni/9022a3e135733e04d64560e33d9ac943&lt;/denchmark-link&gt;

My build.sbt is:
&lt;denchmark-link:https://gist.github.com/vzamboni/b9eb16786e55411876161b88e524bb38&gt;https://gist.github.com/vzamboni/b9eb16786e55411876161b88e524bb38&lt;/denchmark-link&gt;

There a scala mismatch between scala 2.10 and 2.11 in dl4j-spark module.
Its pom creates the artifact from a scala.binary.version variable (in my case should be 2.10) but I cannot find a way to set it in my build.sbt.
	</description>
	<comments>
		<comment id='1' author='vzamboni' date='2016-07-29T06:19:55Z'>
		There was (with previous releases) some issues with spark versions (specifically wrong spark versions being included due to bugs with how maven handles properties - i.e., spark 2.11 in dl4j-spark_2.10). Thas should be fixed here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/1904&gt;https://github.com/deeplearning4j/deeplearning4j/pull/1904&lt;/denchmark-link&gt;

Next release (0.5.0) will be out soon (few days at most). That should fix these issues properly. If you still run into issues with that, re-open the issue.
		</comment>
		<comment id='2' author='vzamboni' date='2016-08-19T08:00:05Z'>
		Hi &lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 ,
I've a similar build.sbt as of &lt;denchmark-link:https://github.com/vzamboni&gt;@vzamboni&lt;/denchmark-link&gt;
 . I'm currently using the version 0.5.0, however I still face incompatible version issue when using scala 2.10.6
Following is the relevant error log.
[error] Modules were resolved with conflicting cross-version suffixes in {file:&lt;REDACTED&gt;
[error]    org.apache.spark:spark-launcher _2.10, _2.11
[error]    org.apache.spark:spark-graphx _2.10, _2.11
[error]    org.json4s:json4s-ast _2.10, _2.11
[error]    org.apache.spark:spark-catalyst _2.10, _2.11
[error]    org.apache.spark:spark-network-shuffle _2.10, _2.11
[error]    com.typesafe.akka:akka-actor _2.10, _2.11
[error]    com.twitter:chill _2.10, _2.11
[error]    org.apache.spark:spark-streaming _2.10, _2.11
[error]    org.apache.spark:spark-sql _2.10, _2.11
[error]    org.json4s:json4s-jackson _2.10, _2.11
[error]    com.fasterxml.jackson.module:jackson-module-scala _2.10, _2.11
[error]    org.scalanlp:breeze-macros _2.10, _2.11
[error]    org.json4s:json4s-core _2.10, _2.11
[error]    org.apache.spark:spark-unsafe _2.10, _2.11
[error]    org.spire-math:spire _2.10, _2.11
[error]    org.scalanlp:breeze _2.10, _2.11
[error]    com.typesafe.akka:akka-remote _2.10, _2.11
[error]    com.typesafe.akka:akka-slf4j _2.10, _2.11
[error]    org.spire-math:spire-macros _2.10, _2.11
[error]    org.apache.spark:spark-core _2.10, _2.11
[error]    org.apache.spark:spark-network-common _2.10, _2.11
[error]    org.apache.spark:spark-mllib _2.10, _2.11
java.lang.RuntimeException: Conflicting cross-version suffixes in: org.apache.spark:spark-launcher, org.apache.spark:spark-graphx, org.json4s:json4s-ast, org.apache.spark:spark-catalyst, org.apache.spark:spark-network-shuffle, com.typesafe.akka:akka-actor, com.twitter:chill, org.apache.spark:spark-streaming, org.apache.spark:spark-sql, org.json4s:json4s-jackson, com.fasterxml.jackson.module:jackson-module-scala, org.scalanlp:breeze-macros, org.json4s:json4s-core, org.apache.spark:spark-unsafe, org.spire-math:spire, org.scalanlp:breeze, com.typesafe.akka:akka-remote, com.typesafe.akka:akka-slf4j, org.spire-math:spire-macros, org.apache.spark:spark-core, org.apache.spark:spark-network-common, org.apache.spark:spark-mlliv
		</comment>
		<comment id='3' author='vzamboni' date='2016-09-26T21:10:06Z'>
		Seeing scala version issues. OS X / MAC / Scala
This is my build.sbt file:
&lt;denchmark-link:https://gist.github.com/LooooongTran/d69fbe455ab9c8399a898dfe09225cfd&gt;https://gist.github.com/LooooongTran/d69fbe455ab9c8399a898dfe09225cfd&lt;/denchmark-link&gt;

And this is the error log I get when I run "sbt clean; sbt compile"
&lt;denchmark-link:https://gist.github.com/LooooongTran/d5a2bca96fabfc812ad2b2781063d236&gt;https://gist.github.com/LooooongTran/d5a2bca96fabfc812ad2b2781063d236&lt;/denchmark-link&gt;

This error goes away when I change my build.sbt file to use scala version 2.11.x  instead of 2.10.x.
I've tried scala versions 2.10.6/5/4/3/2/1  all with the same result.
		</comment>
		<comment id='4' author='vzamboni' date='2016-09-26T23:59:22Z'>
		&lt;denchmark-link:https://github.com/LooooongTran&gt;@LooooongTran&lt;/denchmark-link&gt;
 Can you run the equivalent of "mvn dependency:tree" with SBT? (I'm not that familiar with it, but looks like there's a few options there to print out the whole dependency tree).
That'll hopefully tell us where this is being pulled in from.
		</comment>
		<comment id='5' author='vzamboni' date='2016-09-27T14:45:44Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 please see attached files for the dependency trees.  I generated one for scala 2.10 and one for 2.11.  They're big files, hope they can help.  The only dependency in the project at the time was
libraryDependencies ++= Seq(
"org.deeplearning4j" %% "dl4j-spark" % VERSIONS("dl4j")
)
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/495834/scala2.10dependencytree.txt&gt;scala2.10dependencytree.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/495835/scala2.11dependencytree.txt&gt;scala2.11dependencytree.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='vzamboni' date='2016-11-30T09:42:27Z'>
		This has been fixed.
		</comment>
		<comment id='7' author='vzamboni' date='2019-01-20T07:57:37Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>