<bug id='4756' author='blackredscarf' open_date='2018-03-05T11:22:54Z' closed_time='2018-05-17T11:10:48Z'>
	<summary>DL4J and Keras predictions differ (Conv2D)</summary>
	<description>
I have a network in keras, and I implement it in DL4j.
I try to use layer.setParam import the weights from keras for each layer,but the predictions is very different in same data.
I check the weights and summary, it is no problem. I guess maybe some layers is error.
So I use model.feedForward(data, false).get(layer) to print the output of each layer, and compared with keras. I went looking for the first layer that made a huge difference and I found it.
I print its configuration, but I can not find the configuration error:
this layer configuration in keras:
&lt;denchmark-code&gt;{'activation': 'linear',
 'activity_regularizer': None,
 'bias_constraint': None,
 'bias_initializer': {'class_name': 'Zeros', 'config': {}},
 'bias_regularizer': None,
 'data_format': 'channels_last',
 'dilation_rate': (1, 1),
 'filters': 32,
 'kernel_constraint': None,
 'kernel_initializer': {'class_name': 'VarianceScaling',
  'config': {'distribution': 'uniform',
   'mode': 'fan_avg',
   'scale': 1.0,
   'seed': None}},
 'kernel_regularizer': None,
 'kernel_size': (3, 3),
 'name': 'Conv2d_1a_3x3',
 'padding': 'valid',
 'strides': (2, 2),
 'trainable': True,
 'use_bias': False}
&lt;/denchmark-code&gt;

this layer configuration in DL4j:
&lt;denchmark-code&gt;"Conv2d_2a_3x3" : {
  "LayerVertex" : {
	"layerConf" : {
	  "cacheMode" : "NONE",
	  "epochCount" : 0,
	  "iterationCount" : 0,
	  "l1ByParam" : {
		"W" : 0.0
	  },
	  "l2ByParam" : {
		"W" : 0.0
	  },
	  "layer" : {
		"convolution" : {
		  "activationFn" : {
			"Identity" : { }
		  },
		  "biasInit" : 0.0,
		  "biasUpdater" : null,
		  "constraints" : null,
		  "convolutionMode" : "Truncate",
		  "cudnnAlgoMode" : "PREFER_FASTEST",
		  "cudnnBwdDataAlgo" : null,
		  "cudnnBwdFilterAlgo" : null,
		  "cudnnFwdAlgo" : null,
		  "dilation" : [ 1, 1 ],
		  "dist" : null,
		  "gradientNormalization" : "None",
		  "gradientNormalizationThreshold" : 1.0,
		  "hasBias" : false,
		  "idropout" : {
			"@class" : "org.deeplearning4j.nn.conf.dropout.Dropout",
			"p" : 1.0,
			"pschedule" : null
		  },
		  "iupdater" : {
			"@class" : "org.nd4j.linalg.learning.config.Sgd",
			"learningRate" : 0.001
		  },
		  "kernelSize" : [ 3, 3 ],
		  "l1" : 0.0,
		  "l1Bias" : 0.0,
		  "l2" : 0.0,
		  "l2Bias" : 0.0,
		  "layerName" : "Conv2d_2a_3x3",
		  "nin" : 32,
		  "nout" : 32,
		  "padding" : [ 0, 0 ],
		  "stride" : [ 1, 1 ],
		  "weightInit" : "VAR_SCALING_NORMAL_FAN_AVG",
		  "weightNoise" : null
		}
	  },
	  "maxNumLineSearchIterations" : 5,
	  "miniBatch" : true,
	  "minimize" : true,
	  "optimizationAlgo" : "STOCHASTIC_GRADIENT_DESCENT",
	  "pretrain" : false,
	  "seed" : 123,
	  "stepFunction" : null,
	  "variables" : [ "W" ]
	},
	"outputVertex" : false,
	"preProcessor" : null
  }
},
&lt;/denchmark-code&gt;

Version: 0.9.1 / 0.9.2-SNAPSHOTS
This problem has troubled me for a long time, can you provide some suggestions?
	</description>
	<comments>
		<comment id='1' author='blackredscarf' date='2018-03-05T23:17:58Z'>
		Can you also post information about your hardware, and which backend (native, cuda, cuda+cudnn etc) you are using?
		</comment>
		<comment id='2' author='blackredscarf' date='2018-03-06T09:32:54Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;

Intel CPU
backend: native
		</comment>
		<comment id='3' author='blackredscarf' date='2018-04-17T15:27:52Z'>
		&lt;denchmark-link:https://github.com/blackredscarf&gt;@blackredscarf&lt;/denchmark-link&gt;
 I'm doing some general bug-hunting right now. I need more info to tackle this.
Can you provide me with a minimal example (ideally one conv layer with activations) for which you get discrepancies? If not, give me any example.
		</comment>
		<comment id='4' author='blackredscarf' date='2018-04-19T07:42:05Z'>
		&lt;denchmark-link:https://github.com/blackredscarf&gt;@blackredscarf&lt;/denchmark-link&gt;
 could you please provide me with your example?
		</comment>
		<comment id='5' author='blackredscarf' date='2018-04-19T14:51:00Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;

the example: &lt;denchmark-link:https://drive.google.com/file/d/1ERkOvYqtOA23_l5MsLHqsNev47MyNmh7/view?usp=sharing&gt;example.rar&lt;/denchmark-link&gt;

This is a complete example, maybe a little complicated.
You can use the idea to open it. And the python folder can use jupyter to open it.
&lt;denchmark-h:h3&gt;python&lt;/denchmark-h&gt;

python/exportWeights.ipynb	-	export the weights from the model
&lt;denchmark-h:h3&gt;java&lt;/denchmark-h&gt;

java/..../FaceInceptionResNetV1	-	the implement of model
&lt;denchmark-h:h3&gt;scala&lt;/denchmark-h&gt;

scala/.../FaceNetTest	-	test enterance
scala/.../LoadWeights	-	load the weights from file
&lt;denchmark-h:h3&gt;resources&lt;/denchmark-h&gt;

conf	-	the configuration of weights
weights -	the weights file
		</comment>
		<comment id='6' author='blackredscarf' date='2018-05-14T15:18:15Z'>
		&lt;denchmark-link:https://github.com/blackredscarf&gt;@blackredscarf&lt;/denchmark-link&gt;
 I tried to load your model back into keras, which fails due to bad marshalling. I assume you have some  layers in there. Could you please tell me:

what your model config looks like (json of your architecture)
which layers feed into Conv2d_2a_3x3?

We have an e2e test on master for a conv net that checks predictions and gradients (and passes):
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/9d782c260dfac22f8e6560cd66243080aba6e0d6/deeplearning4j-modelimport/src/test/java/org/deeplearning4j/nn/modelimport/keras/e2e/KerasModelEndToEndTest.java#L127&gt;https://github.com/deeplearning4j/deeplearning4j/blob/9d782c260dfac22f8e6560cd66243080aba6e0d6/deeplearning4j-modelimport/src/test/java/org/deeplearning4j/nn/modelimport/keras/e2e/KerasModelEndToEndTest.java#L127&lt;/denchmark-link&gt;

So I want to find out if this is due to some utility layer before that layer that produces wrong input to Conv2d_2a_3x3.
		</comment>
		<comment id='7' author='blackredscarf' date='2018-05-15T14:31:59Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;

You must import this model in python3.6 and keras2.1+ environment. May report , but does not affect this model.
This is the summary of keras model:
&lt;denchmark-link:https://gist.github.com/blackredscarf/8e64ba2663f6e6ec807883065ee4ef68&gt;https://gist.github.com/blackredscarf/8e64ba2663f6e6ec807883065ee4ef68&lt;/denchmark-link&gt;

Conv2d_2a_3x3 is the fifth layer. There is no Lambda layer in front of it.
		</comment>
		<comment id='8' author='blackredscarf' date='2018-05-17T09:35:36Z'>
		&lt;denchmark-link:https://github.com/blackredscarf&gt;@blackredscarf&lt;/denchmark-link&gt;
 ok, upon inspecting this a little more closely, few things:


Conv2d_2a_3x3 and Conv2d_1a_3x3 are identical in their definition. if Conv2d_2a_3x3 is off and Conv2d_1a_3x3 isn't, I highly doubt that the problem comes from the conv layers.


right before Conv2d_2a_3x3 you have a batchnorm layer. I've seen that this layer has issues on import. For instance, no momentum or scale parameters are properly used. I need to fix that. I'm 98% your problem stems from this. To back my claim, note that we have a lot of prediction and grad checks for plain conv nets here:


&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/f50908f24c9f828973c4ccaf37283d7820d97d03/deeplearning4j-modelimport/src/test/java/org/deeplearning4j/nn/modelimport/keras/e2e/KerasModelEndToEndTest.java#L121-L142&gt;https://github.com/deeplearning4j/deeplearning4j/blob/f50908f24c9f828973c4ccaf37283d7820d97d03/deeplearning4j-modelimport/src/test/java/org/deeplearning4j/nn/modelimport/keras/e2e/KerasModelEndToEndTest.java#L121-L142&lt;/denchmark-link&gt;


In your attempt to recreate the model in DL4J I also see a few things that don't match. For instance:

&lt;denchmark-code&gt;        String bn_name = _generate_layer_name("BatchNorm", name);
        graph.addLayer(bn_name, new BatchNormalization.Builder()
                        .activation(Activation.SIGMOID)
                        .eps(0.001).decay(0.995).l2(0)
                        .dropOut(new Dropout(1.0))
                        .updater(new Sgd(0.001))
                        .weightInit(WeightInit.XAVIER).build(), x);
&lt;/denchmark-code&gt;

why would you put Sigmoid activation here? It should be linear, since you follow up with a ReLU activation layer.
OK, depending on how this goes I might actually close this issue in favour of a more indicative batchnorm ticket.
		</comment>
		<comment id='9' author='blackredscarf' date='2018-05-17T11:13:28Z'>
		&lt;denchmark-link:https://github.com/blackredscarf&gt;@blackredscarf&lt;/denchmark-link&gt;
 I've created a test here
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/5228/files#diff-54b41956f01cdb86d7a290961773a2df&gt;https://github.com/deeplearning4j/deeplearning4j/pull/5228/files#diff-54b41956f01cdb86d7a290961773a2df&lt;/denchmark-link&gt;

that replicates the first 5 layers of your model (and tops it off with a Flatten and Dense(1) to predict single outputs). I predict random inputs in keras with fixed seed, import the model and input data into dl4j and predict there as well. there are no discrepancies.
		</comment>
		<comment id='10' author='blackredscarf' date='2018-09-22T01:24:04Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>