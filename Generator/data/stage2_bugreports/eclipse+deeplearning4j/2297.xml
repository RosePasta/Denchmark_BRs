<bug id='2297' author='AlexDBlack' open_date='2016-11-10T09:30:29Z' closed_time='2016-11-10T22:39:46Z'>
	<summary>Model serializer: limited to ~500M parameters</summary>
	<description>
Trying to save a model with more than ~500M parameters (i.e., at float precision, &gt; Integer.MAX_VALUE bytes) will result in an exception, due to using a ByteArrayOutputStream internally.
&lt;denchmark-code&gt;Exception in thread "main" java.lang.OutOfMemoryError: Requested array size exceeds VM limit
at java.util.Arrays.copyOf(Arrays.java:3236)
at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)
at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)
at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:135)
at java.io.DataOutputStream.writeInt(DataOutputStream.java:198)
at java.io.DataOutputStream.writeFloat(DataOutputStream.java:242)
at org.nd4j.linalg.api.buffer.BaseDataBuffer.write(BaseDataBuffer.java:1348)
at org.nd4j.linalg.factory.Nd4j.write(Nd4j.java:2276)
at org.deeplearning4j.util.ModelSerializer.writeModel(ModelSerializer.java:99)
at org.deeplearning4j.util.ModelSerializer.writeModel(ModelSerializer.java:65)
at org.deeplearning4j.earlystopping.saver.LocalFileGraphSaver.save(LocalFileGraphSaver.java:80)
at org.deeplearning4j.earlystopping.saver.LocalFileGraphSaver.saveBestModel(LocalFileGraphSaver.java:70)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2016-11-10T22:39:46Z'>
		Fixed
		</comment>
		<comment id='2' author='AlexDBlack' date='2019-01-20T17:00:56Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>