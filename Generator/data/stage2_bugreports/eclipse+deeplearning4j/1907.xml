<bug id='1907' author='justineyster' open_date='2016-07-28T18:50:40Z' closed_time='2016-07-31T20:02:23Z'>
	<summary>"o.d.o.l.ScoreIterationListener - Score at iteration ____ is NaN" when training on GPU's with Cuda</summary>
	<description>
Getting a "Score at iteration ____ is NaN" message when training a CNN on GPU's/Cuda on the latest version of dl4j. Was told to open an issue by Alex Black when I brought this up in the gitter. Note that if I just change the dl4j backend to native-dl4j, everything runs completely fine and this issue does not occur with all else equal. Everything you need to see should be in this gist: &lt;denchmark-link:https://gist.github.com/justineyster/1f10745c957dfd7d8f7bbee70255920b&gt;https://gist.github.com/justineyster/1f10745c957dfd7d8f7bbee70255920b&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='justineyster' date='2016-07-28T19:09:53Z'>
		What os and gpu you have there?
		</comment>
		<comment id='2' author='justineyster' date='2016-07-28T19:21:41Z'>
		Ubuntu 16.04 and an NVIDIA Tesla K40m
		</comment>
		<comment id='3' author='justineyster' date='2016-07-28T19:23:09Z'>
		and there's no error messages or something like that? exceptions? CUDA errors?
		</comment>
		<comment id='4' author='justineyster' date='2016-07-28T19:35:00Z'>
		Right. No exceptions or CUDA errors.
		</comment>
		<comment id='5' author='justineyster' date='2016-07-29T18:19:39Z'>
		I want to reproduce your issue on my hardware. Please provide some more details:

number of images per class
image format (doubt that matters, though)
CNNConfiguration source

Currently i suspect some kind of overflow at reductions, or something like that. But don't see any options besides full reproduction :(
		</comment>
		<comment id='6' author='justineyster' date='2016-07-29T21:04:13Z'>
		And one more question:
Could you please run LenetMnistExample on the same box, using CUDA, and post its results?
		</comment>
		<comment id='7' author='justineyster' date='2016-07-29T21:25:29Z'>
		Right. Here's the info:

Number of images per class: ~5,000 x 5 classes
Image format: .jpg or .JPG
CNN configuration source: code is already in the gitter. Custom. Loosely based on Alexnet. See the file named "Source Code" in the gitter. Lines 59-61 provide the breakdown on the values we're using to train.

Will run LenetMnistExample now and post results to the gitter.
		</comment>
		<comment id='8' author='justineyster' date='2016-07-30T07:47:06Z'>
		Thanks for the details, that's helpful.
Any results for LenetMnistExample available?
		</comment>
		<comment id='9' author='justineyster' date='2016-07-30T12:24:42Z'>
		So, i've grabbed your source code, and Caltech102 dataset. Got 5 categories, 200 images per category.
Here's training results:
&lt;denchmark-link:https://gist.github.com/raver119/4dc3d428ce7ba105838ea84148df4480&gt;https://gist.github.com/raver119/4dc3d428ce7ba105838ea84148df4480&lt;/denchmark-link&gt;

Results are pretty equal for both CPU and CUDA.
Memory use during traing 4.7GB - 6GB.
		</comment>
		<comment id='10' author='justineyster' date='2016-07-30T12:25:31Z'>
		The only modification i've added to your source code, is resize transformer applied, since i had not 200x200 images available. So images were resized on the fly using DataVec.
		</comment>
		<comment id='11' author='justineyster' date='2016-07-30T12:43:12Z'>
		So, waiting for your response about LenetMnist example. Issue is definitey not reproducible for me.
		</comment>
		<comment id='12' author='justineyster' date='2016-07-30T13:03:03Z'>
		Also, i've checked this configuration against FLOAT and HALF dataType - everything works as intended. However, i'm unable to test on DOUBLE, just don't have enough gpu ram.
		</comment>
		<comment id='13' author='justineyster' date='2016-07-30T21:54:47Z'>
		I've managed to reproduce something that looks like your issue, not sure if that's it though, since i don't see any special CUDA configuration options in your sources. But maybe that's tesla, or ppc or whatever.
Anyway, i'm working on it now.
Thanks for flagging this issue.
		</comment>
		<comment id='14' author='justineyster' date='2016-07-30T22:13:18Z'>
		As temporary workaround please try this configuration:
CudaEnvironment.getInstance().getConfiguration()
.allowMultiGPU(false)
.setMaximumGridSize(512)
.setMaximumBlockSize(512)
.setMaximumDeviceCacheableLength(1024 * 1024 * 1024L)
.setMaximumDeviceCache(6L * 1024 * 1024 * 1024L)
.setMaximumHostCacheableLength(1024 * 1024 * 1024L)
.setVerbose(false)
.enableDebug(true);
Add this as first line in main() method.
		</comment>
		<comment id='15' author='justineyster' date='2016-07-31T20:02:23Z'>
		Hypothetically your issue is fixed here: &lt;denchmark-link:https://github.com/deeplearning4j/nd4j/pull/1167&gt;deeplearning4j/nd4j#1167&lt;/denchmark-link&gt;

Tomorrow we'll have release day, so we'll find out if that helps you as well as me.
		</comment>
		<comment id='16' author='justineyster' date='2016-08-01T14:12:03Z'>
		Right. Thank you very much for working on this issue. I added the LenetMnistExample output, in case you still wanted to take a look. It completed successfully but with some errors printed out at the end. Again, thanks for the support.
		</comment>
		<comment id='17' author='justineyster' date='2016-08-03T14:07:10Z'>
		Release is available now. Let me know if your issue is fixed now.
		</comment>
		<comment id='18' author='justineyster' date='2016-08-05T19:49:54Z'>
		The fix worked! Thank you very much for your involvement in DL4J. You're incredible valuable to this community &lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='19' author='justineyster' date='2019-01-20T21:52:52Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>