<bug id='1248' author='AlexDBlack' open_date='2016-03-09T04:41:31Z' closed_time='2016-03-12T01:36:33Z'>
	<summary>NPE during score calculation for softmax + MSE</summary>
	<description>
softmax + mcxent or softmax + negative log likelihood: OK
softmax + mse: results in NPE during score calculation
tanh etc + mse: ok
This is probably due to the fact that we pass pre-activation output to score function (to use log softmax) instead of just softmax, to avoid numerical underflow in the latter method.
        int nIn = 10;
        int lstmSize = 8;
        int nOut = 5;
        int tsLength = 4;

        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .list()
                .layer(0, new GravesLSTM.Builder().nIn(nIn).nOut(lstmSize).build())
                .layer(1, new RnnOutputLayer.Builder().nIn(lstmSize).nOut(nOut).activation("softmax").lossFunction(LossFunctions.LossFunction.MSE).build())   //Fails: NPE
//                .layer(1, new RnnOutputLayer.Builder().nIn(lstmSize).nOut(nOut).activation("tanh").lossFunction(LossFunctions.LossFunction.MSE).build())        //Works
                .pretrain(false).backprop(true).build();


        MultiLayerNetwork net = new MultiLayerNetwork(conf);
        net.init();

        INDArray in = Nd4j.ones(1,nIn,tsLength);
        INDArray out = Nd4j.ones(1,nOut,tsLength);
        net.fit(in,out);
Exception in thread "main" java.lang.NullPointerException
at org.nd4j.linalg.api.ndarray.BaseNDArray.subi(BaseNDArray.java:2640)
at org.nd4j.linalg.api.ndarray.BaseNDArray.subi(BaseNDArray.java:2628)
at org.nd4j.linalg.api.ndarray.BaseNDArray.sub(BaseNDArray.java:2409)
at org.nd4j.linalg.lossfunctions.LossCalculation.scoreArray(LossCalculation.java:129)
at org.nd4j.linalg.lossfunctions.LossCalculation.score(LossCalculation.java:37)
at org.deeplearning4j.nn.layers.BaseOutputLayer.setScore(BaseOutputLayer.java:148)
at org.deeplearning4j.nn.layers.BaseOutputLayer.computeScore(BaseOutputLayer.java:89)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:1705)
at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:146)
at org.deeplearning4j.optimize.solvers.BaseOptimizer.optimize(BaseOptimizer.java:165)
at org.deeplearning4j.optimize.Solver.optimize(Solver.java:51)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1394)
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-01-21T08:38:04Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>