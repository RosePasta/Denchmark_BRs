<bug id='2319' author='Mi5ke' open_date='2016-11-15T10:57:17Z' closed_time='2016-11-15T11:55:44Z'>
	<summary>Nd4j.scalar infinite recusrion</summary>
	<description>
It is possible for Nd4j.scalar to recurse infinitely. If the ND4j.dtype is FLOAT, but the working type is set to be HALF for a GPU (using DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);), then everything works fine, except for Nd4j.scalar(float), as used by the DataSet.normalize() method, and elsewhere.
The scalar method tests for the data type being FLOAT or DOUBLE, and otherwise re-calls the scalar method with the float argument cast to an int. Unfortunately, the only matching method in those circumstances, is the scalar(float) method itself - so infinite recursion occurs.
Not a problem if the datatypes are all set consistently - but that may not be the case with saved/loaded DataSets?
	</description>
	<comments>
		<comment id='1' author='Mi5ke' date='2016-11-15T10:58:28Z'>
		How you've managed to get Nd4j.dtype as float, if context was set to HALF?
		</comment>
		<comment id='2' author='Mi5ke' date='2016-11-15T11:00:16Z'>
		hm. are you using Nd4j.dtype field directly? as in not a Nd4j.dataType() method?
		</comment>
		<comment id='3' author='Mi5ke' date='2016-11-15T11:09:40Z'>
		&lt;denchmark-code&gt;    DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
    Nd4j.dtype = DataBuffer.Type.FLOAT;
    ..... load stuff ......
    dataset.normalize();
&lt;/denchmark-code&gt;

fails, but the other way around works....
&lt;denchmark-code&gt;    Nd4j.dtype = DataBuffer.Type.FLOAT;
    DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
          ......
&lt;/denchmark-code&gt;

Example code on deeplearning4j seems to use the Nd4j.dtype directly, which is what I copied.
		</comment>
		<comment id='4' author='Mi5ke' date='2016-11-15T11:12:44Z'>
		Right, i'm making Nd4j.dtype protected now. Nd4j.dataType() getter should be used, since it honors context properly &amp; does honor concurrent access.
Thanks for the highlighting this issue
		</comment>
		<comment id='5' author='Mi5ke' date='2016-11-15T11:13:34Z'>
		The dataType method only seems to return the datatype, not set it.
		</comment>
		<comment id='6' author='Mi5ke' date='2016-11-15T11:16:18Z'>
		The TSNEStandardExample uses this directly, as do some example(s) in the documentation.
		</comment>
		<comment id='7' author='Mi5ke' date='2016-11-15T11:17:01Z'>
		yes. To set dataType different method is used:
&lt;denchmark-link:https://github.com/deeplearning4j/dl4j-examples/blob/050a14c1623671e290afa637869c5e4abde0a2bc/dl4j-cuda-specific-examples/src/main/java/org/deeplearning4j/examples/multigpu/MultiGpuLenetMnistExample.java#L43-L43&gt;https://github.com/deeplearning4j/dl4j-examples/blob/050a14c1623671e290afa637869c5e4abde0a2bc/dl4j-cuda-specific-examples/src/main/java/org/deeplearning4j/examples/multigpu/MultiGpuLenetMnistExample.java#L43-L43&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='Mi5ke' date='2016-11-15T11:27:10Z'>
		I think that is a mistake.... just using
DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
alone causes the same problem. Try calling normalize on any DataSet, and it recurses infinitely.
A quick google shows several hundred examples of code using it directly too.
		</comment>
		<comment id='9' author='Mi5ke' date='2016-11-15T11:33:31Z'>
		Show me minimal code that reproduces such recursion please
		</comment>
		<comment id='10' author='Mi5ke' date='2016-11-15T11:38:13Z'>
		&lt;denchmark-code&gt;public static void main(String[] args) {
    DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF);
    INDArray first = Nd4j.rand(20, 10);   // arbitrary sizes
    INDArray second = Nd4j.rand(3, 20);
    DataSet data = new DataSet(first, second);

    data.normalize();
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='Mi5ke' date='2016-11-15T11:55:44Z'>
		Fixed, thanks for highlighting this issue
		</comment>
		<comment id='12' author='Mi5ke' date='2016-11-15T14:35:04Z'>
		OK... so the workaround for my currently crashing program is... to still set Nd4j.dtype directly?
What happens about all the example code out there in web-land, if dtype will be protected?
When will the fixed code be available to download from Maven?
Thanks
Mike
		</comment>
		<comment id='13' author='Mi5ke' date='2016-11-15T14:42:02Z'>
		I've already updated that TSNE example:

use Nd4j.dataType() to get current value
use Nd4j.setDataType(your_datatype) to set new value.

Basically, old mechanics you were using before was a bug, because technically you were getting inconsistent dtype in different methods. In other words: Nd4.dtype field was a legacy code, and i had to remove that use.
		</comment>
		<comment id='14' author='Mi5ke' date='2016-11-15T14:45:14Z'>
		I don't have a Nd4j.setDatatype(...) method.... might have a v0.5 lingering in the classpath somewhere... will check.
		</comment>
		<comment id='15' author='Mi5ke' date='2016-11-15T14:57:07Z'>
		My Nd4j is coming from nd4j-api-0.6.0.jar - and no setDataType method is there. Will continue to set dtype manually for now.
		</comment>
		<comment id='16' author='Mi5ke' date='2016-11-15T15:20:26Z'>
		You don't have it because i've added it to master few minutes ago. But for 0.6.0 there's another approach also available, i've posted it before.
DataTypeUtil.setDTypeForContext(DataBuffer.Type.HALF); &lt;--- this one
And anyway, in nearest hours release process will begin, testing &amp; polishing is almost done now.
		</comment>
		<comment id='17' author='Mi5ke' date='2016-11-15T15:55:57Z'>
		Yes - but that's the line of code in my minimal code (above) which crashes when normalising, if you remember. Look forward to the new release :-)
		</comment>
		<comment id='18' author='Mi5ke' date='2016-11-15T15:59:42Z'>
		Yes, and that recursion is caused by a bug, which is fixed on master after your report :)

15 нояб. 2016 г., в 18:56, Mi5ke notifications@github.com написал(а):
Yes - but that's the line of code in my minimal code (above) which crashes when normalising, if you remember. Look forward to the new release :-).
—
You are receiving this because you modified the open/close state.
Reply to this email directly, view it on GitHub https://github.com/deeplearning4j/deeplearning4j/issues/2319#issuecomment-260680239, or mute the thread https://github.com/notifications/unsubscribe-auth/ALru_5vsYIU6i3n7TNhYIqKQdd4jmij6ks5q-dYWgaJpZM4KyY-b.

		</comment>
		<comment id='19' author='Mi5ke' date='2019-01-20T17:00:41Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>