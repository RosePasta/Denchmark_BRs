<bug id='4453' author='CarsonBeckett' open_date='2017-12-28T14:18:42Z' closed_time='2018-01-10T09:02:44Z'>
	<summary>DL4JInvalidInputException: Input size is invalid: does not match layer input size</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

I am using RL4J to try to train a DQN on a simple MDP but am getting an exception after running the program:
DL4JInvalidInputException: Input size (1 columns; shape = [1, 1]) is invalid: does not match layer input size (layer # inputs = 2) (layer name: layer0, layer index: 0)
Could it be related to my action space only being 2 (Action = Integer, ActionSpace = DiscreteSpace)?
The guys over at the DL4J Gitter told me to ask &lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 to have a look :)
Thanks!
Code below. You should know that I am still a beginner in ML in general and very new in RL4J/DL4J etc, so there are probably many horrible mistakes in the code :)
Main program:
&lt;denchmark-code&gt;public static QLearning.QLConfiguration ELECTRONICS_QL =
        new QLearning.QLConfiguration(
                123,   //Random seed
                100000,//Max step By epoch
                80000, //Max step
                10000, //Max size of experience replay
                32,    //size of batches
                100,   //target update (hard)
                0,     //num step noop warmup
                0.05,  //reward scaling
                0.99,  //gamma
                10.0,  //td-error clipping
                0.1f,  //min epsilon
                2000,  //num step for eps greedy anneal
                true   //double DQN
        );

public static DQNFactoryStdDense.Configuration ELECTRONICS_NET =
        DQNFactoryStdDense.Configuration.builder()
                .l2(0.01).learningRate(1e-2).numLayer(3).numHiddenNodes(16).build();

public static void electronics() throws IOException {

    //record the training data in rl4j-data in a new folder
    DataManager manager = new DataManager();

    //define the MDP
    MDP mdp = new Electronics();

    //define the training
    ILearning&lt;ElectronicsState, Integer, DiscreteSpace&gt; dql = new QLearningDiscreteDense&lt;ElectronicsState&gt;(mdp, ELECTRONICS_NET, ELECTRONICS_QL, manager);

    //start the training
    dql.train();

    mdp.close();
}

public static void simpleElectronics() throws IOException {

    //record the training data in rl4j-data in a new folder
    DataManager manager = new DataManager();

    //define the MDP
    Electronics mdp = new Electronics();

    //define the training method
    Learning&lt;ElectronicsState, Integer, DiscreteSpace, IDQN&gt; dql = new QLearningDiscreteDense&lt;ElectronicsState&gt;(mdp, ELECTRONICS_NET, ELECTRONICS_QL, manager);

    //enable some logging for debug purposes
    //mdp.setFetchable(dql);

    //start the training
    dql.train();

    mdp.close();

}
&lt;/denchmark-code&gt;

MDP:
&lt;denchmark-code&gt;public class Electronics implements MDP&lt;ElectronicsState, Integer, DiscreteSpace&gt;
{
final private static int MAX_STEP = 100;
final private static int SEED = 938765835;
final private static int ACTION_SIZE = 2;
final private static ElectronicsState[] states = genElectronicsStates(MAX_STEP, SEED);
private DiscreteSpace actionSpace = new DiscreteSpace(ACTION_SIZE);
private ObservationSpace&lt;ElectronicsState&gt; observationSpace = new ArrayObservationSpace(new int[] {ACTION_SIZE});
private ElectronicsState electronicsState;

//Constructor
public Electronics()
{

}

public ObservationSpace&lt;ElectronicsState&gt; getObservationSpace()
{
    return observationSpace;
}

public DiscreteSpace getActionSpace()
{
    return actionSpace;
}

public ElectronicsState reset()
{
    return electronicsState = states[0];
}

public void close()
{
    //Empty
}

public StepReply&lt;ElectronicsState&gt; step(Integer toggle)
{
    double reward = 0;
    Integer overPressure = electronicsState.getBloodPressure().getLeft();
    Integer underPressure = electronicsState.getBloodPressure().getRight();

    if(overPressure &lt;= 110 &amp;&amp; underPressure &lt;= 70 &amp;&amp; electronicsState.getPulse() &lt;= 60)
    {
        if(electronicsState.isOn() &amp;&amp; toggle == 0)
        {
            reward += 1;
        }
    }

    electronicsState = states[electronicsState.getStep() + 1];
    try
    {
        return new StepReply(electronicsState, reward, isDone(), new JSONObject("{}"));
    }
    catch(JSONException jse)
    {
        System.out.println("An error occurred: " + jse.getMessage());
        return new StepReply(electronicsState, reward, isDone(), null);
    }
}

public boolean isDone()
{
    return electronicsState.getStep() == MAX_STEP - 1;
}

public Electronics newInstance()
{
    return new Electronics();
}

public static ElectronicsState[] genElectronicsStates(int size, int seed)
{
    Random rd = new Random(seed);
    ElectronicsState[] electronicsStates = new ElectronicsState[size];

    for (int i = 0; i &lt; size; i++)
    {
        boolean isOn = rd.nextBoolean();
        Pair&lt;Integer, Integer&gt; bloodPressure = Pair.of(rd.nextInt(220), rd.nextInt(110));// Pair&lt;&gt;(rd.nextInt(220), rd.nextInt(110));
        int pulse = rd.nextInt(200);

        electronicsStates[i] = new ElectronicsState(isOn, bloodPressure, pulse, new Date(), i);
    }

    return electronicsStates;
}

public static void printTest(IDQN idqn) {
    INDArray input = Nd4j.create(MAX_STEP, ACTION_SIZE);
    for (int i = 0; i &lt; MAX_STEP; i++) {
        input.putRow(i, Nd4j.create(states[i].toArray()));
    }
    INDArray output = Nd4j.max(idqn.output(input), 1);
    Logger.getAnonymousLogger().info(output.toString());
}
}
&lt;/denchmark-code&gt;

State:
&lt;denchmark-code&gt;public class ElectronicsState implements Encodable
{
private boolean isOn;
private Pair&lt;Integer, Integer&gt; bloodPressure;
private int pulse;
private Date dateTime;
private int step;


public ElectronicsState(boolean isOn, Pair&lt;Integer, Integer&gt; bloodPressure, int pulse, Date dateTime, int step)
{
    this.isOn = isOn;
    this.bloodPressure = bloodPressure;
    this.pulse = pulse;
    this.dateTime = dateTime;
    this.step = step;
}

public int getStep()
{
    return step;
}

public boolean isOn()
{
    return isOn;
}

public Pair&lt;Integer, Integer&gt; getBloodPressure()
{
    return bloodPressure;
}

public int getPulse()
{
    return pulse;
}

public Date getDateTime()
{
    return dateTime;
}

/*public void setStep(int i)
{
    step = i;
}*/

public void onOff(boolean state)
{
    isOn = state;
}

public void setBloodPressure(Pair&lt;Integer, Integer&gt; bp)
{
    bloodPressure = bp;
}

public void setPulse(int p)
{
    pulse = p;
}

public void setDateTime(Date d)
{
    dateTime = d;
}

@Override
public double[] toArray() {
    double[] ar = new double[1];
    ar[0] = (20);
    return ar;
}
}
&lt;/denchmark-code&gt;


Expected behavior:
DQN should start to train
Encountered behaviour:
Exception just after training started log message:
org.deeplearning4j.exception.DL4JInvalidInputException: Input size (1 columns; shape = [1, 1]) is invalid: does not match layer input size (layer # inputs = 2) (layer name: layer0, layer index: 0)

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

IntelliJ CE 2016.3.7
JDK 1.8

Deeplearning4j version: 0.9.1
Windows 10 1703 15063.786
CUDA version, if used: N/A
NVIDIA driver version, if in use: N/A

Full stack trace:
&lt;denchmark-code&gt;org.deeplearning4j.exception.DL4JInvalidInputException: Input size (1 columns; shape = [1, 1]) is invalid: does not match layer input size (layer # inputs = 2) (layer name: layer0, layer index: 0)
	at org.deeplearning4j.nn.layers.BaseLayer.preOutput(BaseLayer.java:310)
	at org.deeplearning4j.nn.layers.BaseLayer.activate(BaseLayer.java:328)
	at org.deeplearning4j.nn.layers.AbstractLayer.activate(AbstractLayer.java:309)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.activationFromPrevLayer(MultiLayerNetwork.java:789)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForwardToLayer(MultiLayerNetwork.java:929)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:870)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:861)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1906)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.output(MultiLayerNetwork.java:1898)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.output(MultiLayerNetwork.java:1871)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.output(MultiLayerNetwork.java:1952)
	at org.deeplearning4j.rl4j.network.dqn.DQN.output(DQN.java:49)
	at org.deeplearning4j.rl4j.learning.sync.qlearning.discrete.QLearningDiscrete.trainStep(QLearningDiscrete.java:133)
	at org.deeplearning4j.rl4j.learning.sync.qlearning.QLearning.trainEpoch(QLearning.java:91)
	at org.deeplearning4j.rl4j.learning.sync.SyncLearning.train(SyncLearning.java:38)
	at ElectronicsMain.simpleElectronics(ElectronicsMain.java:98)
	at ElectronicsMain.main(ElectronicsMain.java:24)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='CarsonBeckett' date='2018-01-09T17:34:58Z'>
		solved this?
		</comment>
		<comment id='2' author='CarsonBeckett' date='2018-01-10T09:02:44Z'>
		Commit &lt;denchmark-link:https://github.com/deeplearning4j/rl4j/commit/59ff35f009a8c7969d9b27436eed4d79c7560305&gt;deeplearning4j/rl4j@59ff35f&lt;/denchmark-link&gt;
 should fix this issue. If you're still having problems after trying with that patch, please reopen another issue in the rl4j repository, thanks!
		</comment>
		<comment id='3' author='CarsonBeckett' date='2018-09-23T19:26:10Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>