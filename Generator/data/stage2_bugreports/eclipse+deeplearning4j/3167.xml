<bug id='3167' author='liujxing' open_date='2017-03-31T15:13:31Z' closed_time='2018-04-26T07:10:11Z'>
	<summary>Inconsistent Output of Imported Keras Model with Batch Normalization</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

The output in DL4J of model imported from Keras is different from the output in python, as long as batch normalization layer is used. The discrepancy ranges from 2% to 100% in some extreme cases even with very simple feedforward network.
Json of example network from Keras:
{'class_name': 'Model',
'config': {'input_layers': [['input_49', 0, 0]],
'layers': [{'class_name': 'InputLayer',
'config': {'batch_input_shape': [None, 10],
'input_dtype': 'float32',
'name': 'input_49',
'sparse': False},
'inbound_nodes': [],
'name': 'input_49'},
{'class_name': 'Dense',
'config': {'W_constraint': None,
'W_regularizer': None,
'activation': 'relu',
'activity_regularizer': None,
'b_constraint': None,
'b_regularizer': None,
'bias': True,
'init': 'normal',
'input_dim': 10,
'name': 'dense_130',
'output_dim': 30,
'trainable': True},
'inbound_nodes': [[['input_49', 0, 0]]],
'name': 'dense_130'},
{'class_name': 'BatchNormalization',
'config': {'axis': -1,
'beta_regularizer': None,
'epsilon': 0.001,
'gamma_regularizer': None,
'mode': 0,
'momentum': 0.99,
'name': 'batchnormalization_57',
'trainable': True},
'inbound_nodes': [[['dense_130', 0, 0]]],
'name': 'batchnormalization_57'},
{'class_name': 'Dense',
'config': {'W_constraint': None,
'W_regularizer': None,
'activation': 'linear',
'activity_regularizer': None,
'b_constraint': None,
'b_regularizer': None,
'bias': True,
'init': 'glorot_uniform',
'input_dim': 30,
'name': 'dense_131',
'output_dim': 1,
'trainable': True},
'inbound_nodes': [[['batchnormalization_57', 0, 0]]],
'name': 'dense_131'}],
'name': 'model_32',
'output_layers': [['dense_131', 0, 0]]},
'keras_version': '1.2.0'}
	</description>
	<comments>
		<comment id='1' author='liujxing' date='2017-03-31T17:54:36Z'>
		&lt;denchmark-link:https://github.com/turambar&gt;@turambar&lt;/denchmark-link&gt;
 We may need more information on this. First however,  I am seeing if &lt;denchmark-link:https://github.com/turambar&gt;@turambar&lt;/denchmark-link&gt;
 knows if Batch Normalization is an issue or not.
		</comment>
		<comment id='2' author='liujxing' date='2017-03-31T19:41:47Z'>
		&lt;denchmark-link:https://github.com/crockpotveggies&gt;@crockpotveggies&lt;/denchmark-link&gt;
 wanna have a look, given your background on &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3021&gt;#3021&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='3' author='liujxing' date='2017-03-31T19:51:56Z'>
		&lt;denchmark-link:https://github.com/liujxing&gt;@liujxing&lt;/denchmark-link&gt;
 you using the imported model purely for inference (i.e., you import it and then make predictions without training) or are you doing further training? If it's the latter, I think there may be subtle differences between the way DL4J's and Keras' respective BN layers behave during training.
		</comment>
		<comment id='4' author='liujxing' date='2017-03-31T19:55:51Z'>
		&lt;denchmark-link:https://github.com/turambar&gt;@turambar&lt;/denchmark-link&gt;
 Right now only for inference, and the discrepancy is found in inference.
		</comment>
		<comment id='5' author='liujxing' date='2017-03-31T23:25:00Z'>
		My guess here is we're mathematically different from Keras BatchNorm. I'll have to take a look at the underlying mechanics. I may need to poke &lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 for some help on this. Basically, step-by-step of Keras impl, then look at DL4J impl and check if:

we have mathematical differences
params weren't copied appropriately on import
there's an underlying bug in BatchNorm impl

		</comment>
		<comment id='6' author='liujxing' date='2017-04-10T18:51:11Z'>
		A note that this commit
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/commit/9c2326e4a63ec0d64db0d8a61cd4b518669b5cd0&gt;deeplearning4j@9c2326e&lt;/denchmark-link&gt;

addresses
a problem in batch norm and LRN. I'll be testing to see if this addresses
this problem.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Mar 31, 2017 at 12:56 PM Jiaxing Liu ***@***.***&gt; wrote:
 @turambar &lt;https://github.com/turambar&gt; Right now only for inference.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;https://github.com/deeplearning4j/deeplearning4j/issues/3167#issuecomment-290814033&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABYNry0LFWyvtlFtiyuQy8fX_cxnBZqfks5rrVpXgaJpZM4MvzDP&gt;
 .



		</comment>
		<comment id='7' author='liujxing' date='2017-08-01T09:49:15Z'>
		See also &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3659&gt;#3659&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3423&gt;#3423&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/liujxing&gt;@liujxing&lt;/denchmark-link&gt;
 do you have any insights into how this restricts to batchnorm? i.e. have you seen discrepancies for other layer types and models as well?
I will slowly dive into the root cause of this and update model import in the next weeks.
		</comment>
		<comment id='8' author='liujxing' date='2018-04-25T22:43:23Z'>
		Is this still an issue?
		</comment>
		<comment id='9' author='liujxing' date='2018-04-26T07:10:11Z'>
		haven't seen any indication of this and no feedback, so I'll close this due to inactivity for now. feel free to reopen, though. there are a few other open batchnorm tickets that I'll look into anyway
		</comment>
		<comment id='10' author='liujxing' date='2018-09-22T15:13:40Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>