<bug id='2773' author='oliverdain' open_date='2017-01-29T23:46:07Z' closed_time='2017-01-31T08:33:02Z'>
	<summary>ParagraphVectors throws NPE</summary>
	<description>
I trained a ParagrphVectors model and then used it to tag some existing text. One of the existing texts is just the string "?". Clearly not a very good piece of text, but it causes an NPE:
&lt;denchmark-code&gt;    java.lang.NullPointerException
        at org.nd4j.linalg.ops.transforms.Transforms.unitVec(Transforms.java:92)
        at org.deeplearning4j.models.paragraphvectors.ParagraphVectors.nearestLabels(ParagraphVectors.java:376)
        at org.deeplearning4j.models.paragraphvectors.ParagraphVectors.nearestLabels(ParagraphVectors.java:345)
        at org.deeplearning4j.models.paragraphvectors.ParagraphVectors.nearestLabels(ParagraphVectors.java:332)
        at com.analyticspot.nlp.transforms.LabeledDoc2Vec.transform(LabeledDoc2Vec.kt:60)
        at com.analyticspot.nlp.transforms.LabeledDoc2Vec.trainTransform(LabeledDoc2Vec.kt:98)
        at com.analyticspot.nlp.transforms.LabeledDoc2VecTest.testRealStuff(LabeledDoc2VecTest.kt:80)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='oliverdain' date='2017-01-29T23:53:04Z'>
		It also throws an NPE on longer texts. This one caused an NPE: Summera Fallea Springa Wintera
		</comment>
		<comment id='2' author='oliverdain' date='2017-01-30T00:29:32Z'>
		Another examples that results in an NPE: tei eleookses eleike tehey aeree juesete studyeing ani woirking.
		</comment>
		<comment id='3' author='oliverdain' date='2017-01-30T08:47:18Z'>
		Show paravec configuration you've used to build initial model please.
Upd. and code your have in com.analyticspot.nlp.transforms.LabeledDoc2VecTest
		</comment>
		<comment id='4' author='oliverdain' date='2017-01-30T19:29:09Z'>
		ParagraphVectors is built as follows (in Kotlin):
&lt;denchmark-code&gt;        doc2Vec = ParagraphVectors.Builder()
                .iterate(docIter)
                .iterations(3)
                .windowSize(5)
                .layerSize(100)
                .learningRate(0.1)
                .minWordFrequency(5)
                .tokenizerFactory(DefaultTokenizerFactory())
                // DM appears to be necessary. Passing DBOW causes it not to learn anything.
                .sequenceLearningAlgorithm(DM())
                .build()
&lt;/denchmark-code&gt;

Then fit:
&lt;denchmark-code&gt; doc2Vec.fit()
&lt;/denchmark-code&gt;

Then used to make predictions:
&lt;denchmark-code&gt;    override fun transform(dataSet: DataSet): CompletableFuture&lt;DataSet&gt; {
        val labelList = mutableListOf&lt;String?&gt;()
        val distList = mutableListOf&lt;Double?&gt;()
        dataSet.column(docColumn).forEachIndexed { idx, doc -&gt;
            try {
                val inferred = doc2Vec.inferVector(doc)
                val label = doc2Vec.nearestLabels(doc, 1).first()
                val labelVec = doc2Vec.lookupTable.vector(label)
                val dist = Transforms.cosineSim(inferred, labelVec)
                distList.add(dist)
                labelList.add(label)
            } catch (e: NullPointerException) {
                // The catch is needed because ParagraphVectors throws on short texts, texts that contain words not
                // in the vocabulary, etc. See https://github.com/deeplearning4j/deeplearning4j/issues/2773.
                log.warn("ParagraphVectors threw an NPE on the text: {}", doc)
                distList.add(null)
                labelList.add(null)
            }
            if (idx % 1000 == 0) {
                log.debug("Transformed {} items", idx)
            }
        }
        val ds = DataSet.build {
            addColumn(ColumnId.create&lt;String&gt;("label"), labelList)
            addColumn(ColumnId.create&lt;Double&gt;("dist"), distList)
        }
        return CompletableFuture.completedFuture(ds)
    }
&lt;/denchmark-code&gt;

The catch block there is necessary due to the bug reported here. I don't think you'll find the unit test code very helpful as it's mostly code that uses our ML framework (the DataSet class, etc.) to feed in 300k text examples. The texts are short Spanish snippets - usually a hundred words or so each.
		</comment>
		<comment id='5' author='oliverdain' date='2017-01-30T21:20:31Z'>
		Well, the only suspect i can see here is simple, but i'll need you to check if that's the case:
For any doc that throws NPE - tokenize it manually, and check if it has at least one word matching your vocab.
		</comment>
		<comment id='6' author='oliverdain' date='2017-01-30T21:28:12Z'>
		Yes, I think you're correct that it happens only for texts that contain only words that aren't in the vocab. I understand why you can't get a valid inference for such texts. However, since that isn't a crazy edge case (e.g. this would be very common if processing tweets) it seems like something other than an NPE would be a more appropriate outcome -- maybe just return null?
		</comment>
		<comment id='7' author='oliverdain' date='2017-01-31T07:39:43Z'>
		Yep, you're right, since you've confirmed that's the case - i'll add proper handling there right now.
		</comment>
		<comment id='8' author='oliverdain' date='2017-01-31T08:33:02Z'>
		Issue fixed, appropriate exceptions/notifications were added.
Thanks for highlighting this issue.
		</comment>
		<comment id='9' author='oliverdain' date='2019-01-19T18:26:23Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>