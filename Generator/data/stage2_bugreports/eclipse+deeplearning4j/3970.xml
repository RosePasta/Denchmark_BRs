<bug id='3970' author='AlexDBlack' open_date='2017-08-29T10:59:56Z' closed_time='2017-12-15T03:59:04Z'>
	<summary>Spark evaluation NPEs</summary>
	<description>
Under some rare circumstances, Spark evaluation can lead to a NPE here:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/multilayer/evaluation/IEvaluationReduceFunction.java#L19-L21&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/multilayer/evaluation/IEvaluationReduceFunction.java#L19-L21&lt;/denchmark-link&gt;

I'm not totally sure on the cause here - I suspect this can occur with empty partitions, or fewer partitions than executors (10 objects on 16 workers causes NPE, but 10 objects on 8 workers doesn't). Either way, a defensive null check in that merge function should help.
Tested with Spark 2.1.0.
&lt;denchmark-code&gt;Caused by: java.lang.NullPointerException
	at org.deeplearning4j.spark.impl.multilayer.evaluation.IEvaluationReduceFunction.call(IEvaluationReduceFunction.java:22)
	at org.deeplearning4j.spark.impl.multilayer.evaluation.IEvaluationReduceFunction.call(IEvaluationReduceFunction.java:16)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2017-12-14T09:15:56Z'>
		Hi! I'm experiencing the same issue in evaluation phase using DL4J 0.9.1 with Spark 2.1:
&lt;denchmark-code&gt;Caused by: java.lang.NullPointerException
	at org.deeplearning4j.spark.impl.multilayer.evaluation.IEvaluationReduceFunction.call(IEvaluationReduceFunction.java:19)
	at org.deeplearning4j.spark.impl.multilayer.evaluation.IEvaluationReduceFunction.call(IEvaluationReduceFunction.java:13)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037)
&lt;/denchmark-code&gt;

Is there any workaround I could try to make it work? I tried running it with different number of workers with no success.
Thanks!
		</comment>
		<comment id='2' author='AlexDBlack' date='2017-12-14T09:38:28Z'>
		&lt;denchmark-link:https://github.com/GregaVrbancic&gt;@GregaVrbancic&lt;/denchmark-link&gt;
 only thing I can suggest: take the code from here
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/802ea94617d2eb7c43b554d29f28636430b92abc/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/multilayer/SparkDl4jMultiLayer.java#L596-L600&gt;https://github.com/deeplearning4j/deeplearning4j/blob/802ea94617d2eb7c43b554d29f28636430b92abc/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/multilayer/SparkDl4jMultiLayer.java#L596-L600&lt;/denchmark-link&gt;

and adapt it in your project to use the fix from this PR (i.e., the modified IEvaluationReduceFunction) :
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4394&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4394&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='AlexDBlack' date='2017-12-15T03:59:03Z'>
		&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4394&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4394&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='AlexDBlack' date='2018-09-23T22:26:26Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>