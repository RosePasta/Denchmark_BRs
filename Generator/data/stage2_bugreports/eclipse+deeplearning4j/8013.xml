<bug id='8013' author='RobAltena' open_date='2019-07-16T06:20:07Z' closed_time='2019-07-30T03:24:34Z'>
	<summary>Nd4j.create checks data sizes inconsistent.</summary>
	<description>
The create methods work most of the time when too much data is provided. But some methods have an extra  check sprinkled in (and copied/pasta-ed around) for the 1d case. For example:
&lt;denchmark-code&gt;@Test
void testCreateSizeChecks() {
    INDArray x;
    double [] data = new double[]{1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13, 14, 15, 16};

    // This is accepted:
    x = Nd4j.create(data , new int[]{3, 2, 2});
    x = Nd4j.create(data , new int[]{6, 2});

    // This is not.
    // linalg.exception.ND4JIllegalStateException: Shape of the new array [9] doesn't match data length: 12
    x = Nd4j.create(data , new int[]{12});
}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

With all the checking done in Nd4j.java I can help out on this one. We just need to decide on the checking strictnes and on which create methods to keep/discard/deprecate,
	</description>
	<comments>
		<comment id='1' author='RobAltena' date='2019-07-30T03:24:34Z'>
		Fixed here: &lt;denchmark-link:https://github.com/SkymindIO/deeplearning4j/pull/87&gt;SkymindIO#87&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>