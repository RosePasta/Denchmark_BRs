<bug id='4440' author='Mocuto' open_date='2017-12-20T06:30:06Z' closed_time='2018-05-01T02:26:36Z'>
	<summary>Type Inference on Common Layer Configurations FAILS for given configuration</summary>
	<description>
For configuration given in:
&lt;denchmark-link:https://gist.github.com/Mocuto/58f8f32635efa0563bbe3ce940045cc0&gt;https://gist.github.com/Mocuto/58f8f32635efa0563bbe3ce940045cc0&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;  // From: "Character-Aware Neural Language Models" https://arxiv.org/abs/1508.06615

    object TrainingExample {
      val IntentVecSize = 2
      val InsideOutsideVecSize = 3
      val EntityTypeVecSize = 2
    }
    val c2ohLength = 259
    val w2ohLength = 100003
    val kernelsPerWidth = 5
    val numKernels = kernelWidths.length * kernelsPerWidth

    val biasInterval = scala.util.Random.nextGaussian() / 0.5

    log.info("Build model....")
    val confWithoutConv = new NeuralNetConfiguration.Builder()
      .learningRate(0.01)
      .graphBuilder()
      .addInputs("input")
    val confWithConv = kernelWidths.zipWithIndex.foldLeft(confWithoutConv) { case (c, (w, i)) =&gt;
      val cn = s"C$i"
      val pn = s"P$i"
      val huLength = w2ohLength - w  + 1
      // Convolution
      val nc = c.addLayer(cn, new ConvolutionLayer.Builder(c2ohLength, w)
        .nIn(1) // Number of channels in
        .stride(1, 1)
        .nOut(kernelsPerWidth) // Number of kernels (filters) out
        .activation("tanh")
        .build(), "input"
      // Pooling
      ).addLayer(pn, new SubsamplingLayer.Builder(SubsamplingLayer.PoolingType.MAX)
              .kernelSize(1, huLength)
              .stride(1,1)
              .build(), cn)
      nc
    }

    val conf = confWithConv.addVertex("merge", new MergeVertex(), (0 until kernelWidths.length).map(i =&gt; s"P$i").toArray : _* )
      // Highway Network behaviour
      .addLayer("t_sigmoid", new DenseLayer.Builder()
        .activation("sigmoid")
        .biasInit(-2.0 + biasInterval)
        .nOut(numKernels)
        .build(), "merge")
      .addLayer("g", new DenseLayer.Builder()
        .activation("relu")
        .nOut(numKernels)
        .build(), "merge")
      // Take hammard product of transform gate and nonlinearity
      .addVertex("t hammard g", new ElementWiseVertex(ElementWiseVertex.Op.Product), "t_sigmoid", "g")
      .addVertex("-t", new ScaleVertex(-1), "t_sigmoid")
      .addVertex("1 - t", new ShiftVertex(1), "-t")
      .addVertex("(1 - t) hammard merge", new ElementWiseVertex(ElementWiseVertex.Op.Product), "1 - t", "merge")
      .addVertex("H1", new ElementWiseVertex(ElementWiseVertex.Op.Add), "t hammard g", "(1 - t) hammard merge")
      .addLayer("out-intent", new RnnOutputLayer.Builder()
        .activation("sigmoid")
        .lossFunction(LossFunctions.LossFunction.XENT)
        .nIn(numKernels)
        .nOut(TrainingExample.IntentVecSize)
        .build(), "H1")
      .addLayer("out-iobe", new RnnOutputLayer.Builder()
        .activation("sigmoid")
        .lossFunction(LossFunctions.LossFunction.XENT)
        .nIn(numKernels)
        .nOut(TrainingExample.InsideOutsideVecSize)
        .build(), "H1")
      .addLayer("out-entityType", new RnnOutputLayer.Builder()
        .activation("sigmoid")
        .lossFunction(LossFunctions.LossFunction.XENT)
        .nIn(numKernels)
        .nOut(TrainingExample.EntityTypeVecSize)
        .build(), "H1")
      .addLayer("out-onehotword", new RnnOutputLayer.Builder()
        .activation("sigmoid")
        .lossFunction(LossFunctions.LossFunction.XENT)
        .nIn(numKernels)
        .nOut(w2ohLength)
        .build(), "H1")
      .setOutputs("out-intent","out-iobe", "out-entityType", "out-onehotword")
      .setInputTypes(InputType.convolutionalFlat(c2ohLength, w2ohLength, 1))
      .build();

    val model = new ComputationGraph(conf)
&lt;/denchmark-code&gt;

The following error is produced:
&lt;denchmark-code&gt;[error] (run-main-0) org.deeplearning4j.nn.conf.inputs.InvalidInputTypeException: Invalid input: ElementWise vertex cannot process activations of different types: first type = FF, input type 2 = CNN org.deeplearning4j.nn.conf.inputs.InvalidInputTypeException: Invalid input: ElementWise vertex cannot process activations of different types: first type = FF, input type 2 = CNN
&lt;/denchmark-code&gt;

This is remedied by adding a PreProcessorVertex + CnnToFeedForwardPreProcessor after the merge vertex.
	</description>
	<comments>
		<comment id='1' author='Mocuto' date='2018-04-27T18:30:29Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 was this ever fixed?
		</comment>
		<comment id='2' author='Mocuto' date='2018-04-28T05:43:49Z'>
		Maybe? Needs to be checked.
		</comment>
		<comment id='3' author='Mocuto' date='2018-05-01T02:26:36Z'>
		I'm unable to reproduce this which what I think is an equivalent configuration.
If this is still occurring on 1.0.0-alpha, we can re-open.
		</comment>
		<comment id='4' author='Mocuto' date='2018-09-22T06:24:24Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>