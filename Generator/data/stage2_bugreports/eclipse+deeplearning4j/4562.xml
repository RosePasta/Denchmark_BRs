<bug id='4562' author='yylonly' open_date='2018-01-28T14:15:39Z' closed_time='2018-04-25T09:10:21Z'>
	<summary>Custom loss functions not directly implementing ILossFunction not found by reflections</summary>
	<description>
I use self define loss in last "task" layer shown as following.

    .addLayer("TASKS", new OutputLayer.Builder().activation(Activation.SIGMOID)
                  .lossFunction(new WeightedL2Loss(1))
                  .nIn(1000).nOut(157).build(), "HIDDEN")


It can successfully store into "deeppharm.zip" by

    File locationToSave = new File("DeepPharm.zip");       //Where to save the network. Note: the file is in .zip format - can be opened externally
    boolean saveUpdater = true;                                             //Updater: i.e., the state for Momentum, RMSProp, Adagrad etc. Save this if you want to train your network more in the future
    try {
  	ModelSerializer.writeModel(net, locationToSave, saveUpdater);
  } catch (IOException e) {
  	// TODO Auto-generated catch block
  	e.printStackTrace();
  }


But it can not be succesfully restore because it is a un-know type of function ModelSerializer.restoreComputationGraph()

Caused by: org.nd4j.shade.jackson.databind.JsonMappingException: Could not resolve type id 'WeightedL2Loss' into a subtype of [simple type, class org.nd4j.linalg.lossfunctions.ILossFunction]: known type ids = [BinaryXENT, CosineProximity, FMeasure, Hinge, ILossFunction, KLD, L1, L2, MAE, MAPE, MCXENT, MSE, MSLE, NegativeLogLikelihood, Poisson, SquaredHinge]

How could let the restoreComputationGraph() let know the new loss type? Thanks
	</description>
	<comments>
		<comment id='1' author='yylonly' date='2018-01-29T00:01:09Z'>
		This should occur automatically. The fact that it isn't picking it up suggests one of two things:
(a) the custom loss function simply isn't on the classpath when you are loading the network.
(b) there is an issue with the Reflections library that DL4J uses internally for custom layers etc.
So far the only real issue we've seen with reflections is on Android. What's your OS?
If we can't work out why this is happening, then you can try the following workaround:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/4504#issuecomment-357555845&gt;https://github.com/deeplearning4j/deeplearning4j/issues/4504#issuecomment-357555845&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='yylonly' date='2018-01-29T12:49:13Z'>
		I use Mac OS 10.13.2 and DL4j 0.9.1, I will follow &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/4504&gt;#4504&lt;/denchmark-link&gt;
 to see whether I can find the resolution.
		</comment>
		<comment id='3' author='yylonly' date='2018-01-29T13:13:02Z'>
		Btw, the new loss class is in the same package of my train and test main class, and I also try to add the class and jar into classpath, it does not help. for your (b), I did not use custom layers, only use custom cost function.
Thanks
		</comment>
		<comment id='4' author='yylonly' date='2018-01-29T13:33:30Z'>
		I think I found the bugs, the customer loss function required not only extend from pre-defined loss function, but also require implements the ILossFunction. But I checked the L2 loss function already implemented the interface ILossFunction. Why need explicit define the implements here?

public class WeightedL2Loss extends LossL2 implements org.nd4j.linalg.lossfunctions.ILossFunction

This will make save and load model correctly. but this will lead the error

public class WeightedL2Loss extends LossL2

I think this issue can be closed right now.
		</comment>
		<comment id='5' author='yylonly' date='2018-01-29T23:56:36Z'>
		Ah, thanks. I'll actually keep this issue open, to remind us to fix it and as a workaround for other users.
I'm pretty sure this is another issue with the reflections library (which we are going to remove) - it's very likely not picking up transitive interface implements...
i.e., you have two classes (A and B), where B extends A, where A implements X.... then we scan for classes implementing X (using Reflections library), and it'll only find A and not B - because B does not directly implement X.
		</comment>
		<comment id='6' author='yylonly' date='2018-04-25T09:10:21Z'>
		Reflections library has been removed from DL4J entirely - addressed here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4956&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4956&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4950&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4950&lt;/denchmark-link&gt;

This should no longer be an issue.
		</comment>
		<comment id='7' author='yylonly' date='2018-09-22T21:14:00Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>