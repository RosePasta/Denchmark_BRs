<bug id='8335' author='AlexDBlack' open_date='2019-11-01T01:52:45Z' closed_time='2019-11-13T06:01:23Z'>
	<summary>libnd4j: batchnorm_bp op backprop incorrect for dL/dIn</summary>
	<description>
&lt;denchmark-link:https://github.com/KonduitAI/deeplearning4j/blob/master/libnd4j/include/ops/declarable/generic/nn/batchnorm.cpp#L184&gt;https://github.com/KonduitAI/deeplearning4j/blob/master/libnd4j/include/ops/declarable/generic/nn/batchnorm.cpp#L184&lt;/denchmark-link&gt;

We've got one of the terms for dL/dIn, but we need to account for the gradient contribution from the mean and variance.
Compare:
&lt;denchmark-link:https://chrisyeh96.github.io/2017/08/28/deriving-batchnorm-backprop.html&gt;https://chrisyeh96.github.io/2017/08/28/deriving-batchnorm-backprop.html&lt;/denchmark-link&gt;

&lt;denchmark-link:https://deepnotes.io/batchnorm&gt;https://deepnotes.io/batchnorm&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/normalization/BatchNormalization.java#L313-L316&gt;https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/layers/normalization/BatchNormalization.java#L313-L316&lt;/denchmark-link&gt;

I've also validated the DL4J implementation against cuDNN again (both manually and using the existing tests), it's fine. The other components of backprop look ok, it's just dL/dIn (aka dLdI) that's wrong.
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-11-01T02:31:26Z'>
		Also the MKLDNN implementation seems to be returning the wrong values also for dL/dIn, not sure why though.
I know MKLDNN is definitely being used here, as I've sen MKLDNN_VERBOSE=1 environment variable:
&lt;denchmark-code&gt;org.deeplearning4j.nn.layers.mkldnn.MKLDNNBatchNormHelper@4721d212
mkldnn_verbose,info,Intel MKL-DNN v1.0.2 (commit 3289d3c06e07b55fdbec927461bd89f8989eff5d)
mkldnn_verbose,info,Detected ISA is Intel AVX2
mkldnn_verbose,exec,cpu,batch_normalization,ncsp_bnorm:any,forward_inference,data_f32::blocked:abcd:f0 diff_undef::undef::f0,flags:3,mb1ic3ih15iw15,0.1296
mkldnn_verbose,exec,cpu,batch_normalization,ncsp_bnorm:any,backward,data_f32::blocked:abcd:f0 diff_f32::blocked:abcd:f0,flags:3,mb1ic3ih15iw15,0.4736
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/67998206-b94dc680-fcab-11e9-8efc-414f66674dce.png&gt;&lt;/denchmark-link&gt;

Again, same test, cuDNN gives the exact same result to DL4J.
Backprop code for calling op (and hence MKLDNN):
&lt;denchmark-link:https://gist.github.com/AlexDBlack/844beacd0f09b233daa94f4f6ebd546b&gt;https://gist.github.com/AlexDBlack/844beacd0f09b233daa94f4f6ebd546b&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='AlexDBlack' date='2019-11-13T06:01:23Z'>
		Confirmed passing now, matching DL4J (and hence cuDNN)
		</comment>
	</comments>
</bug>