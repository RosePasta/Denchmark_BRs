<bug id='2826' author='wmeddie' open_date='2017-02-06T13:08:46Z' closed_time='2017-02-07T14:22:56Z'>
	<summary>BatchNormalization layer runs on CPU but fails on CUDA</summary>
	<description>
I have a network (Full code and sample dataset here: &lt;denchmark-link:https://github.com/wmeddie/lstm-recommender&gt;https://github.com/wmeddie/lstm-recommender&lt;/denchmark-link&gt;
) that seems to run fine on the CPU but throws the following error when I run with nd4j-cuda-8.0.  Removing the BatchNormalization fixes the issue.
&lt;denchmark-code&gt;[info] 13:10:36.071 [main] INFO  com.yumusoft.lstmrecommender.Train$ - Starting epoch 0 of 100
[info] 13:10:36.076 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [67] to device [0], out of [2] devices...
[info] 13:10:36.106 [main] INFO  org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 0
[error] Exception in thread "main" java.lang.IllegalArgumentException: Invalid size: cannot get size of dimension 2 for rank 2 NDArray (array shape: [40, 10])
[error]         at org.nd4j.linalg.api.ndarray.BaseNDArray.size(BaseNDArray.java:4183)
[error]         at org.deeplearning4j.nn.layers.normalization.CudnnBatchNormalizationHelper.preOutput(CudnnBatchNormalizationHelper.
java:213)
[error]         at org.deeplearning4j.nn.layers.normalization.BatchNormalization.preOutput(BatchNormalization.java:301)
[error]         at org.deeplearning4j.nn.layers.normalization.BatchNormalization.activate(BatchNormalization.java:228)
[error]         at org.deeplearning4j.nn.graph.vertex.impl.LayerVertex.doForward(LayerVertex.java:92)
[error]         at org.deeplearning4j.nn.graph.ComputationGraph.feedForward(ComputationGraph.java:1069)
[error]         at org.deeplearning4j.nn.graph.ComputationGraph.computeGradientAndScore(ComputationGraph.java:963)
[error]         at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:151)
[error]         at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:54)
[error]         at org.deeplearning4j.optimize.Solver.optimize(Solver.java:51)
[error]         at org.deeplearning4j.nn.graph.ComputationGraph.fit(ComputationGraph.java:781)
[error]         at com.yumusoft.lstmrecommender.Train$$anonfun$train$1.apply$mcVI$sp(Train.scala:190)
[error]         at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
[error]         at com.yumusoft.lstmrecommender.Train$.train(Train.scala:180)
[error]         at com.yumusoft.lstmrecommender.Train$.main(Train.scala:140)
[error]         at com.yumusoft.lstmrecommender.Train.main(Train.scala)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='wmeddie' date='2017-02-07T13:43:59Z'>
		That should be something else.

Exception in thread "main" java.lang.IllegalArgumentException: Invalid size: cannot get size of dimension 2 for rank 2 NDArray (array shape: [40, 10])

This exception says that you have 2d array of [40,10], and normalizer expects 3D at very least, since it's asking for dimension 2.
This check was added somewhere around 0.7.2.
		</comment>
		<comment id='2' author='wmeddie' date='2017-02-07T13:52:22Z'>
		Can you please try without cudnn enabled? Just to see what happens?
		</comment>
		<comment id='3' author='wmeddie' date='2017-02-07T13:59:59Z'>
		Yes it runs fine after removing deeplearning4j-cuda from build.sbt.
		</comment>
		<comment id='4' author='wmeddie' date='2017-02-07T14:04:55Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 what's the diff between our &amp; cuda impl for batchnorm? Is, by chance, our use of cudnn batchnorm tailored for cnn architectures at this moment?
		</comment>
		<comment id='5' author='wmeddie' date='2017-02-07T14:17:47Z'>
		AFAIU, cuDNN's batch norm works only with rank 4: &lt;denchmark-link:https://github.com/bytedeco/javacpp-presets/blob/master/cuda/src/main/java/org/bytedeco/javacpp/cudnn.java#L1628&gt;https://github.com/bytedeco/javacpp-presets/blob/master/cuda/src/main/java/org/bytedeco/javacpp/cudnn.java#L1628&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='wmeddie' date='2017-02-07T14:22:56Z'>
		Won't fix then. Workaround, obviously: stick to nd4j cuda instead of cudnn.
		</comment>
		<comment id='7' author='wmeddie' date='2019-01-19T18:26:09Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>