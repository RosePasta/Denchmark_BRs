<bug id='2595' author='ErikTromp' open_date='2016-12-28T19:16:01Z' closed_time='2018-04-26T04:14:02Z'>
	<summary>Long running time in Doc2Vec</summary>
	<description>
I am running Doc2Vec (using code here: &lt;denchmark-link:https://gist.github.com/ErikTromp/2a975d332104a7c0cfa9281e067886ef&gt;https://gist.github.com/ErikTromp/2a975d332104a7c0cfa9281e067886ef&lt;/denchmark-link&gt;
) for over 30 hours now and still not finished.
Running on 2.3gb of data, ~500M words and ~23M sentences.
Running on 4xi7 4.00Ghz and 32GB RAM.
CPU Load is about 15%, 5.5GB RAM is used.
	</description>
	<comments>
		<comment id='1' author='ErikTromp' date='2016-12-28T19:49:07Z'>
		Please provide the following:

gist of pom.xml
gist of console output (as full as possible please)
if possible, it would be nice to see profiler screenshots with hot spots &amp; cpu tab

		</comment>
		<comment id='2' author='ErikTromp' date='2016-12-28T20:01:21Z'>
		The pom is a bit complex, it's part of &lt;denchmark-link:https://github.com/UnderstandLingBV/Tuktu/blob/master/build.sbt&gt;https://github.com/UnderstandLingBV/Tuktu/blob/master/build.sbt&lt;/denchmark-link&gt;
 with the DL4J specific bits (not in there), being (had to rip out some stuff due to conflicts):
&lt;denchmark-code&gt;"org.deeplearning4j" % "deeplearning4j-core" % "0.7.2" excludeAll(ExclusionRule(organization = "org.spark-project"),ExclusionRule(organization = "org.spark-project.akka"), ExclusionRule(organization = "io.netty"), ExclusionRule(organization = "com.typesafe.akka"), ExclusionRule(artifact = "akka-remote")),
    "org.deeplearning4j" % "deeplearning4j-nlp" % "0.7.2" excludeAll(ExclusionRule(organization = "org.spark-project"),ExclusionRule(organization = "org.spark-project.akka"), ExclusionRule(organization = "io.netty"), ExclusionRule(organization = "com.typesafe.akka"), ExclusionRule(artifact = "akka-remote"), ExclusionRule("org.deeplearning4j","spark")),
    "org.nd4j" % "nd4j-native-platform" % "0.7.2",
    "org.nd4j" % "nd4j-native" % "0.7.2" classifier "windows-x86_64"
&lt;/denchmark-code&gt;

As I mentioned, I am not getting any logging, so my console output (in the REPL) is just this &lt;denchmark-link:https://gist.github.com/ErikTromp/df717260e330e01ad69bbd91ff7ab38a&gt;https://gist.github.com/ErikTromp/df717260e330e01ad69bbd91ff7ab38a&lt;/denchmark-link&gt;

I'll see if I can post some profiler stuff later
EDIT: Profiler shows this:
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/8345408/21530863/05df071a-cd44-11e6-93da-dbbe61796a13.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://cloud.githubusercontent.com/assets/8345408/21530906/563aca00-cd44-11e6-8b87-7269f4944a07.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://cloud.githubusercontent.com/assets/8345408/21530907/598ef122-cd44-11e6-8c12-cbac14a86e41.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://cloud.githubusercontent.com/assets/8345408/21531499/d7f8cf48-cd48-11e6-9be1-db00062df370.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ErikTromp' date='2016-12-28T21:01:04Z'>
		I made a separate SBT project and got logging to run. Turns out DL4J doesn't like it if logback is used by default (as is the case for Play apps), so I made a separate project and added SLF4J explicitly. I am now getting the following output
&lt;denchmark-code&gt;[run-main-0] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [CpuBackend] backend
[run-main-0] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 4
[run-main-0] INFO org.reflections.Reflections - Reflections took 116 ms to scan 12 urls, producing 29 keys and 176 values
[run-main-0] INFO org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 4
[run-main-0] INFO org.deeplearning4j.models.sequencevectors.SequenceVectors - Starting vocabulary building...
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [100000]; Current vocabulary size: [121760]; Sequences/sec: 658,71; Words/sec: 17972,41;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [200000]; Current vocabulary size: [180415]; Sequences/sec: 384,32; Words/sec: 10292,67;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='ErikTromp' date='2016-12-29T07:33:46Z'>
		Dl4j works flawlessly with logback, we use it everywhere. But that's not a problem.
Real problem is performance you post here. 10k words/sec - it's even slower then my scientific calculator, born in 1985. For whitespace tokenizer, average speed on i7 cpu should be x150-x200 times faster.
Try to launch that as regular app in java and in scala, and check speed there.
		</comment>
		<comment id='5' author='ErikTromp' date='2016-12-29T07:41:35Z'>
		I did make a regular app out of it, doesnt help, the logging I pasted is from that app. What worries me more is that the performance also decreases steadily. The first 100k words take about twice as little time as the second 100k and I didnt even bother waiting for the third 100k.
		</comment>
		<comment id='6' author='ErikTromp' date='2016-12-29T07:45:11Z'>
		Does 0.7.1/0.7.2 makes any difference?
		</comment>
		<comment id='7' author='ErikTromp' date='2016-12-29T07:50:58Z'>
		This is what I am using: &lt;denchmark-link:https://github.com/ErikTromp/Doc2VecTest&gt;https://github.com/ErikTromp/Doc2VecTest&lt;/denchmark-link&gt;

Will test with 0.7.1
		</comment>
		<comment id='8' author='ErikTromp' date='2016-12-29T07:56:29Z'>
		Mind trying java as well? It would be nice to exclude scala from suspects.
		</comment>
		<comment id='9' author='ErikTromp' date='2016-12-29T07:58:10Z'>
		Will do, 0.7.1 gives me
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [100000]; Current vocabulary size: [121760]; Sequences/sec: 962,32; Words/sec: 26256,26;
		</comment>
		<comment id='10' author='ErikTromp' date='2016-12-29T07:59:03Z'>
		So, still 2 suspects:

Scala
Iterator/IO subsystem

		</comment>
		<comment id='11' author='ErikTromp' date='2016-12-29T10:03:02Z'>
		Well running it in a java app (Maven) kills my logging, so I cannot tell how far it is. Also VisualVM won't attach to it for whatever reason. I do see my CPU being used for 70-80% though. I was thinking that maybe the way I read in the data (as a scala mutable list and then turning it into a java one) might be the cause, Scala might do this in some lazy unfurl manner.
I will try to modify my Scala code to read data into a java list directly and see how that works out and report back.
		</comment>
		<comment id='12' author='ErikTromp' date='2016-12-29T10:16:43Z'>
		Okay so that didn't help, reading in as a java list, but in scala gives me:
&lt;denchmark-code&gt;[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [100000]; Current vocabulary size: [121760]; Sequences/sec: 926,82; Words/sec: 25287,74;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [200000]; Current vocabulary size: [180415]; Sequences/sec: 376,15; Words/sec: 10073,77;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='ErikTromp' date='2016-12-29T10:42:23Z'>
		You're doing something wrong. Please, just adopt one of paravec examples, and run it with your corpus from java. You should get somewhere between 1m-2m words per second for vocab construction phase.
		</comment>
		<comment id='14' author='ErikTromp' date='2016-12-29T12:22:23Z'>
		I cheered too soon, the fact that CPU load seemed high and logging was off, was due to insufficient memory (it didn't pick up my Xmx param) - it never got to the DL4J bit. Now that I properly increased memory usage, I am back to the old situation in java as well - 15% CPU load and very poor speed.
		</comment>
		<comment id='15' author='ErikTromp' date='2016-12-29T13:07:16Z'>
		&lt;denchmark-link:https://github.com/ErikTromp&gt;@ErikTromp&lt;/denchmark-link&gt;
 Do you have a custom tokenizer or something? I know raver's numbers are assuming english with the default tokenizer.
		</comment>
		<comment id='16' author='ErikTromp' date='2016-12-29T13:20:09Z'>
		No, I am using everything copy/pasted over from an example, hence with the default tokenizer. The data is a French wikipedia-dump
		</comment>
		<comment id='17' author='ErikTromp' date='2016-12-29T15:04:22Z'>
		Ok, please share your current java implementation, and link to corpus you're using. I'll run it at my desktop. However, i've tested default impl and russian corpus i have here, and i still see 2m words/sec.
Upd. sure, i mean the same frame: 1m-2m words/sec there's enough volatility involved.
		</comment>
		<comment id='18' author='ErikTromp' date='2016-12-29T17:58:12Z'>
		Java version is here: &lt;denchmark-link:https://github.com/ErikTromp/Doc2VecTestJava&gt;https://github.com/ErikTromp/Doc2VecTestJava&lt;/denchmark-link&gt;

I am using this version of the French wikipedia dump: &lt;denchmark-link:https://docs.google.com/uc?id=0B5lWReQPSvmGekFBUjZDMzM5NDA&amp;export=download&gt;https://docs.google.com/uc?id=0B5lWReQPSvmGekFBUjZDMzM5NDA&amp;export=download&lt;/denchmark-link&gt;

Also &lt;denchmark-link:https://github.com/agibsonccc&gt;@agibsonccc&lt;/denchmark-link&gt;
 from the profiler information I gather that tokenization is not doing anything - the single AsyncIterator Reader thread is hogging up 'all' CPU (being 15-20% of my total CPU power). Also take note how the speed degrades steadily from first 100k to second 100k seqs:
&lt;denchmark-code&gt;[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [100000]; Current vocabulary size: [121760]; Sequences/sec: 838,83; Words/sec: 22887,15;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [200000]; Current vocabulary size: [180415]; Sequences/sec: 358,16; Words/sec: 9592,16;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [300000]; Current vocabulary size: [228711]; Sequences/sec: 175,80; Words/sec: 4564,98;
&lt;/denchmark-code&gt;

EDIT: I just ran the same code on a different machine (quad-core i7 too, but 2 generations older, 8GB RAM) and am experience the same poor performance, &lt;10k words/sec and only 15-20% CPU usage.
EDIT: Also ran it on my server on Ubuntu (other machines I used were all Windows), same behavior observed.
		</comment>
		<comment id='19' author='ErikTromp' date='2016-12-29T18:40:18Z'>
		Ok, so I seem to have finally found the root cause of this issue. It seems to be with the iterator after all.
As per the examples, I used a different iterator now, the BasicLineIterator with LabelsSource("DOC_") instead of the SimpleLabelAwareIterator and my own labels (which were unique per sentence too).
Even in my Scala project, I am now getting much better throughput (and RAM usage is about 16GB, CPU is steadily 80-90%). Could this be an issue with the SimpleLabelAwareIterator?
&lt;denchmark-code&gt;[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [100000]; Current vocabulary size: [102201]; Sequences/sec: 88417,33; Words/sec: 2088925,73;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [200000]; Current vocabulary size: [149105]; Sequences/sec: 117924,53; Words/sec: 2742788,92;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [300000]; Current vocabulary size: [186374]; Sequences/sec: 128700,13; Words/sec: 2882426,00;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [400000]; Current vocabulary size: [216703]; Sequences/sec: 128865,98; Words/sec: 2946713,92;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [500000]; Current vocabulary size: [247351]; Sequences/sec: 123152,71; Words/sec: 2776868,23;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [600000]; Current vocabulary size: [276226]; Sequences/sec: 130378,10; Words/sec: 2799653,19;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [700000]; Current vocabulary size: [302906]; Sequences/sec: 129701,69; Words/sec: 2901534,37;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [800000]; Current vocabulary size: [328235]; Sequences/sec: 128369,70; Words/sec: 2812318,36;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [900000]; Current vocabulary size: [352186]; Sequences/sec: 125786,16; Words/sec: 2718823,90;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1000000]; Current vocabulary size: [373702]; Sequences/sec: 136798,91; Words/sec: 3031417,24;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1100000]; Current vocabulary size: [392993]; Sequences/sec: 129870,13; Words/sec: 2830193,51;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1200000]; Current vocabulary size: [413325]; Sequences/sec: 118764,85; Words/sec: 2645276,72;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1300000]; Current vocabulary size: [434192]; Sequences/sec: 123609,39; Words/sec: 2690782,45;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1400000]; Current vocabulary size: [453780]; Sequences/sec: 144717,80; Words/sec: 3121574,53;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1500000]; Current vocabulary size: [473211]; Sequences/sec: 114942,53; Words/sec: 2433556,32;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1600000]; Current vocabulary size: [491862]; Sequences/sec: 144092,22; Words/sec: 3073389,05;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1700000]; Current vocabulary size: [508857]; Sequences/sec: 30562,35; Words/sec: 648781,17;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1800000]; Current vocabulary size: [526946]; Sequences/sec: 125944,58; Words/sec: 2652607,05;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [1900000]; Current vocabulary size: [543269]; Sequences/sec: 137931,03; Words/sec: 2954655,17;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2000000]; Current vocabulary size: [560025]; Sequences/sec: 126903,55; Words/sec: 2727124,37;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2100000]; Current vocabulary size: [576475]; Sequences/sec: 145348,84; Words/sec: 3049138,08;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2200000]; Current vocabulary size: [593941]; Sequences/sec: 144092,22; Words/sec: 3008048,99;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2300000]; Current vocabulary size: [609460]; Sequences/sec: 120336,94; Words/sec: 2459306,86;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2400000]; Current vocabulary size: [624450]; Sequences/sec: 146627,57; Words/sec: 3022196,48;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2500000]; Current vocabulary size: [638549]; Sequences/sec: 147710,49; Words/sec: 2990664,70;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2600000]; Current vocabulary size: [653350]; Sequences/sec: 90991,81; Words/sec: 1814207,46;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2700000]; Current vocabulary size: [668409]; Sequences/sec: 146627,57; Words/sec: 2972960,41;
[run-main-0] INFO org.deeplearning4j.models.word2vec.wordstore.VocabConstructor - Sequences checked: [2800000]; Current vocabulary size: [684242]; Sequences/sec: 147275,41; Words/sec: 2970811,49;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='20' author='ErikTromp' date='2016-12-29T18:43:25Z'>
		Aha. Up to 3m words/sec. Way better.
I'll check iterator then.
		</comment>
		<comment id='21' author='ErikTromp' date='2018-09-22T15:13:52Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>