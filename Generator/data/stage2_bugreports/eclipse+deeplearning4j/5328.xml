<bug id='5328' author='ilyaivensky' open_date='2018-05-25T05:12:59Z' closed_time='2018-06-06T06:22:39Z'>
	<summary>Unsupported keras layer type Conv1D (deeplearning4j-modelimport:jar:1.0.0-beta)</summary>
	<description>
Please add support. It is crucial for NLP algorithms
	</description>
	<comments>
		<comment id='1' author='ilyaivensky' date='2018-05-25T05:14:48Z'>
		Conv1D is available. Post your model file please, and full stack trace.
		</comment>
		<comment id='2' author='ilyaivensky' date='2018-05-25T05:16:24Z'>
		That is the copy of exception:
import org.deeplearning4j.nn.modelimport.keras.KerasModelImport
org.deeplearning4j.nn.modelimport.keras.UnsupportedKerasConfigurationException: Unsupported keras layer type Conv1D. Please file an issue at &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues&gt;http://github.com/deeplearning4j/deeplearning4j/issues&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='ilyaivensky' date='2018-05-25T05:35:41Z'>
		
Post your model file please

We can't reproduce or debug this without the model file.
		</comment>
		<comment id='4' author='ilyaivensky' date='2018-05-25T16:02:31Z'>
		Keras code:
&lt;denchmark-code&gt;def vanilla_conv1D(wordDepth, nFilters):  
        
    inputLayer = Input(shape = (None, wordDepth), name="input")
    
    convLayer = Convolution1D(
           nFilters, 1, padding = "same", name="conv1")(inputLayer)
           
    activationLayer = LeakyReLU()(convLayer) 
    
   # dropLayer = SpatialDropout1D(0.2)(activationLayer)
           
   # poolLayer = Lambda(lambda x: K.max(x, axis = 1), output_shape = (nFilters, ), name="max_pool")(activationLayer) 
         
    denseLayer = Dense(nFilters, name="dense")(activationLayer) 
    outputLayer = LeakyReLU()(denseLayer) 
    
    return Model(inputLayer, outputLayer, name="doc_network")
&lt;/denchmark-code&gt;

Json file:
{"class_name": "Model", "keras_version": "2.1.5", "config": {"layers": [{"class_name": "InputLayer", "config": {"dtype": "float32", "batch_input_shape": [null, null, 1000], "name": "input", "sparse": false}, "inbound_nodes": [], "name": "input"}, {"class_name": "Conv1D", "config": {"kernel_constraint": null, "kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "scale": 1.0, "seed": null, "mode": "fan_avg"}}, "name": "conv1", "bias_regularizer": null, "bias_constraint": null, "activation": "linear", "trainable": true, "padding": "same", "strides": [1], "dilation_rate": [1], "kernel_regularizer": null, "filters": 64, "bias_initializer": {"class_name": "Zeros", "config": {}}, "use_bias": true, "activity_regularizer": null, "kernel_size": [1]}, "inbound_nodes": [[["input", 0, 0, {}]]], "name": "conv1"}, {"class_name": "LeakyReLU", "config": {"alpha": 0.30000001192092896, "trainable": true, "name": "leaky_re_lu_1"}, "inbound_nodes": [[["conv1", 0, 0, {}]]], "name": "leaky_re_lu_1"}, {"class_name": "Dense", "config": {"kernel_initializer": {"class_name": "VarianceScaling", "config": {"distribution": "uniform", "scale": 1.0, "seed": null, "mode": "fan_avg"}}, "name": "dense", "kernel_constraint": null, "bias_regularizer": null, "bias_constraint": null, "activation": "linear", "trainable": true, "kernel_regularizer": null, "bias_initializer": {"class_name": "Zeros", "config": {}}, "units": 64, "use_bias": true, "activity_regularizer": null}, "inbound_nodes": [[["leaky_re_lu_1", 0, 0, {}]]], "name": "dense"}, {"class_name": "LeakyReLU", "config": {"alpha": 0.30000001192092896, "trainable": true, "name": "leaky_re_lu_2"}, "inbound_nodes": [[["dense", 0, 0, {}]]], "name": "leaky_re_lu_2"}], "input_layers": [["input", 0, 0]], "output_layers": [["leaky_re_lu_2", 0, 0]], "name": "doc_network"}, "backend": "tensorflow"}
Actual code in Zeppelin 0.8.0 with Spark 2.3.0:
&lt;denchmark-code&gt;%spark

import org.deeplearning4j.nn.modelimport.keras.KerasModelImport

val computationGraphConfig = KerasModelImport.importKerasModelConfiguration("PATH TO JSON FILE")
&lt;/denchmark-code&gt;

Can it be the issue to use Java class from Scala?
		</comment>
		<comment id='5' author='ilyaivensky' date='2018-05-25T16:06:34Z'>
		The stack trace:
&lt;denchmark-code&gt;import org.deeplearning4j.nn.modelimport.keras.KerasModelImport
org.deeplearning4j.nn.modelimport.keras.UnsupportedKerasConfigurationException: Unsupported keras layer type Conv1D. Please file an issue at http://github.com/deeplearning4j/deeplearning4j/issues.
  at org.deeplearning4j.nn.modelimport.keras.KerasLayer.getKerasLayerFromConfig(KerasLayer.java:261)
  at org.deeplearning4j.nn.modelimport.keras.KerasModel.helperPrepareLayers(KerasModel.java:191)
  at org.deeplearning4j.nn.modelimport.keras.KerasModel.&lt;init&gt;(KerasModel.java:165)
  at org.deeplearning4j.nn.modelimport.keras.KerasModel.&lt;init&gt;(KerasModel.java:98)
  at org.deeplearning4j.nn.modelimport.keras.KerasModel$ModelBuilder.buildModel(KerasModel.java:641)
  at org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasModelConfiguration(KerasModelImport.java:270)
  ... 48 elided
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='ilyaivensky' date='2018-05-25T16:27:09Z'>
		Could you also post your pom.xml please? Just to make sure you're not on some legacy version?
		</comment>
		<comment id='7' author='ilyaivensky' date='2018-05-28T19:09:49Z'>
		That issue seems to be a Zeppelin issue. I was able to load the same model (vanilla_conv1D) in Java
		</comment>
		<comment id='8' author='ilyaivensky' date='2018-05-28T19:11:08Z'>
		So you probably have outdated dl4j version in Zepp environment then?
		</comment>
		<comment id='9' author='ilyaivensky' date='2018-05-29T15:03:27Z'>
		I don't think so: org.deeplearning4j:deeplearning4j-modelimport:jar:1.0.0-beta
		</comment>
		<comment id='10' author='ilyaivensky' date='2018-05-29T16:11:48Z'>
		few messages above i've asked for pom.xml, show it please.
		</comment>
		<comment id='11' author='ilyaivensky' date='2018-05-31T23:31:06Z'>
		I was able to import that model to DL4J without issues both in Java and in Scala outside Zeppelin.
I don't know whether Zeppelin generates pom.xml files for its interpreters. I have added these dependencies for Spark interpreter using Interpreters page of Zeppelin:
org.deeplearning4j:deeplearning4j-modelimport:jar:1.0.0-beta
org.deeplearning4j:deeplearning4j-core:jar:1.0.0-beta
		</comment>
		<comment id='12' author='ilyaivensky' date='2018-06-06T06:23:50Z'>
		&lt;denchmark-link:https://github.com/ilyaivensky&gt;@ilyaivensky&lt;/denchmark-link&gt;
 feel free to open another issue, if necessary.
		</comment>
		<comment id='13' author='ilyaivensky' date='2018-09-21T21:00:06Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>