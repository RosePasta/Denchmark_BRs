<bug id='7581' author='raver119' open_date='2019-04-19T08:23:23Z' closed_time='2019-04-26T09:57:33Z'>
	<summary>MKL-DNN/non-MKL-DNN pooling backprop results disparity</summary>
	<description>
Hi, guys
We've checked max/avgpool2d_bp and have to say following:
when type is float then mkl-dnn works and results are wrong, for example for this test
deeplearning4j/libnd4j/tests_cpu/layers_tests/DeclarableOpsTests7.cpp
Line 3215 in &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/commit/dc7fdcb6708d7609370f3f5d5c29c40d547b9f46&gt;dc7fdcb&lt;/denchmark-link&gt;

TEST_F(DeclarableOpsTests7, avgpool2d_bp_test4) {
expected vs output are as follows
&lt;denchmark-link:https://gist.github.com/shyrma/3d55dc630d3af1f8d7a2ba6d2c6f730f&gt;https://gist.github.com/shyrma/3d55dc630d3af1f8d7a2ba6d2c6f730f&lt;/denchmark-link&gt;

cc &lt;denchmark-link:https://github.com/shyrma&gt;@shyrma&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='raver119' date='2019-04-19T12:05:38Z'>
		Hi &lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;


I'm inclined to think that the results for the non-MKL-DNN are wrong.
@shyrma Is there an easy way to check that the tests are correct?

Usually we get expected numbers for our tests by means of corresponding ops from tf/torch/chainer if such are present of course.
In case of TypedDeclarableOpsTests7/1.avgpool2d_bp_test4 we used following tf code, numbers produced exactly in this tf test are quoted in our c++ test
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.python.ops import gen_nn_ops
from tensorflow.python.ops import nn_ops
from tensorflow.python.ops import nn_grad

bS=2; iH=4;iW=3;  iC=3;  kH=3;kW=2;  sH=1;sW=1;  pH=0;pW=0;  
oH=2;oW=2;

inp   = tf.Variable(np.linspace(1., bS*iC*iH*iW, bS*iC*iH*iW, dtype=np.float32).reshape([bS, iH, iW, iC]))		
gradO = tf.Variable(np.float32(np.linspace(0.1, bS*iC*oH*oW*0.1, bS*iC*oH*oW).reshape([bS, oH, oW, iC])))
kern  = [kH,kW]
strid = [sH,sW]
dilat = [1,1]

output = tf.nn.pool(inp, window_shape = kern, pooling_type="AVG", padding="VALID", dilation_rate=dilat, strides= strid, name="opp", data_format = 'NHWC')
op = tf.get_default_graph().get_operation_by_name('opp')
gradI = nn_grad._AvgPoolGrad(op, gradO)  

sess = tf.Session()
init =tf.global_variables_initializer()
sess.run(init)
np.set_printoptions(precision=5, suppress=True)
print(np.array2string(sess.run(gradI), separator=', '))
print(gradI.shape)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='raver119' date='2019-05-26T10:46:34Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>