<bug id='4673' author='AlexDBlack' open_date='2018-02-19T08:32:40Z' closed_time='2018-04-25T09:57:34Z'>
	<summary>deeplearning4j-core tests fail/stall on CUDA</summary>
	<description>
To reproduce: simply run deeplearning4j-core tests... (failure seems consistent, same exception at same place, 3 out of 3 runs)
Test system: Kubuntu 17.04, CUDA 9, GTX 970 x2, default memory settings (equiv. Xmx 8g?)
&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/36368300-b2d8a53e-15aa-11e8-9fdc-3411b1384b81.png&gt;&lt;/denchmark-link&gt;

It just stalls, at this point. GPU memory use is about 1.6 out of 4GB.
No issues on CPU/native.
Note that if I run DataSetIteratorTest or just testCifarModel separately, it's fine (all pass, even on CUDA).
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2018-02-23T09:02:32Z'>
		Seems like this is is a problem with CifarLoader - note it's trying to allocate 2.5GB. In CifarLoader, if useSpecialPreProcessCifar it'll roll  over the entire dataset - this all occurs in the workspace...
		</comment>
		<comment id='2' author='AlexDBlack' date='2018-04-25T09:57:34Z'>
		I haven't seen this in any of the recent test runs on CUDA - closing.
		</comment>
		<comment id='3' author='AlexDBlack' date='2018-09-22T21:13:40Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>