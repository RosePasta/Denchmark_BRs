<bug id='4097' author='kac53211' open_date='2017-09-21T16:57:56Z' closed_time='2019-02-13T10:17:26Z'>
	<summary>VectorsConfiguration does not reflect actual settings for ParagraphVectors model object</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

VectorsConfiguration does not reflect the actual settings for ParagraphVectors model object,
I configured ParagraphVectors to have elementsLearningAlgorithm set to CBOW and used the debugger to examine the ParagraphVectors model object,
the elementsLearningAlgorithm member was set to CBOW as it should be,
however, the value for elementsLearningAlgorithm in the VectorsConfiguration member was set to null
Here is the code used and console output:
-- CODE --
&lt;denchmark-code&gt;    // create iterator and tokenizer
    ClassPathResource resource = new ClassPathResource("paravec/labeled");

    LabelAwareIterator iterator = new FileLabelAwareIterator.Builder()
        .addSourceFolder(resource.getFile())
        .build();

    TokenizerFactory tokenizer = new DefaultTokenizerFactory();
    tokenizer.setTokenPreProcessor(new CommonPreprocessor());

    // some stop words...
    ArrayList&lt;String&gt; stop = new ArrayList&lt;String&gt;();
    stop.add("the");
    stop.add("and");

    // specify learners
    CBOW&lt;VocabWord&gt; elem_learner = new CBOW&lt;VocabWord&gt;();
    DM&lt;VocabWord&gt; seq_learner = new DM&lt;VocabWord&gt;();

    // configure builder
    ParagraphVectors.Builder builder = new ParagraphVectors.Builder()
        .minWordFrequency(3)
        .windowSize(5)
        .stopWords(stop)
        .iterate(iterator)
        .tokenizerFactory(tokenizer)
        .layerSize(100)
        .seed(42)
        .batchSize(256)
        .iterations(10)
        .epochs(2)
        .learningRate(0.025)
        .minLearningRate(0.0001)
        .negativeSample(0)
        .sampling(0)
        .trainElementsRepresentation(true)
        .elementsLearningAlgorithm(elem_learner)
        .trainSequencesRepresentation(true)
        .sequenceLearningAlgorithm(seq_learner)
        .resetModel(true)
        .useHierarchicSoftmax(true);

    log.info("*** configuring Doc2Vec model....");
    ParagraphVectors model = builder.build();

    log.info("*** inspecting model configuration....");
    log.info(model.getConfiguration().toString());

    log.info("*** inspecting model configuration.elementsLearningAlgorithm....");
    log.info(model.getConfiguration().getElementsLearningAlgorithm());
&lt;/denchmark-code&gt;

-- CONSOLE --

o.d.e.n.p.Doc2VecConfigTest - *** configuring Doc2Vec model....
o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
o.n.n.NativeOpsHolder - Number of threads used for NativeOps: 4
o.n.n.Nd4jBlas - Number of threads used for BLAS: 4
o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Mac OS X]
o.n.l.a.o.e.DefaultOpExecutioner - Cores: [8]; Memory: [3.6GB];
o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration....
o.d.e.n.p.Doc2VecConfigTest - VectorsConfiguration(minWordFrequency=3, learningRate=0.025, minLearningRate=1.0E-4, layersSize=100, useAdaGrad=false, batchSize=256, iterations=10, epochs=2, window=5, seed=42, negative=0.0, useHierarchicSoftmax=true, sampling=0.0, learningRateDecayWords=0, variableWindows=null, hugeModelExpected=false, useUnknown=false, scavengerActivationThreshold=2000000, scavengerRetentionDelay=3, elementsLearningAlgorithm=null, sequenceLearningAlgorithm=org.deeplearning4j.models.embeddings.learning.impl.sequence.DM, modelUtils=org.deeplearning4j.models.embeddings.reader.impl.BasicModelUtils, tokenizerFactory=org.deeplearning4j.text.tokenization.tokenizerfactory.DefaultTokenizerFactory, tokenPreProcessor=org.deeplearning4j.text.tokenization.tokenizer.preprocessor.CommonPreprocessor, nGram=0, UNK=UNK, STOP=STOP, stopList=[the, and], vocabSize=0, trainElementsVectors=true, trainSequenceVectors=true, allowParallelTokenization=true, preciseWeightInit=false)
o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration.elementsLearningAlgorithm....
o.d.e.n.p.Doc2VecConfigTest - null
Process finished with exit code 0

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


Deeplearning4j version 0.9.1
OSX 10.12.6

Aha! Link: &lt;denchmark-link:https://skymindai.aha.io/features/ND4J-180&gt;https://skymindai.aha.io/features/ND4J-180&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='kac53211' date='2017-09-21T17:01:13Z'>
		Does it affect training in any way?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 21 сент. 2017 г., в 19:58, kac53211 ***@***.***&gt; написал(а):

 Issue Description

 VectorsConfiguration does not reflect the actual settings for ParagraphVectors model object,

 I configured ParagraphVectors to have elementsLearningAlgorithm set to CBOW and used the debugger to examine the ParagraphVectors model object,
 the elementsLearningAlgorithm member was set to CBOW as it should be,
 however, the value for elementsLearningAlgorithm in the VectorsConfiguration member was set to null

 Here is the code used and console output:

 -- CODE --

     // create iterator and tokenizer
     ClassPathResource resource = new ClassPathResource("paravec/labeled");

     LabelAwareIterator iterator = new FileLabelAwareIterator.Builder()
         .addSourceFolder(resource.getFile())
         .build();

     TokenizerFactory tokenizer = new DefaultTokenizerFactory();
     tokenizer.setTokenPreProcessor(new CommonPreprocessor());

     // some stop words...
     ArrayList&lt;String&gt; stop = new ArrayList&lt;String&gt;();
     stop.add("the");
     stop.add("and");

     // specify learners
     CBOW&lt;VocabWord&gt; elem_learner = new CBOW&lt;VocabWord&gt;();
     DM&lt;VocabWord&gt; seq_learner = new DM&lt;VocabWord&gt;();

     // configure builder
     ParagraphVectors.Builder builder = new ParagraphVectors.Builder()
         .minWordFrequency(3)
         .windowSize(5)
         .stopWords(stop)
         .iterate(iterator)
         .tokenizerFactory(tokenizer)
         .layerSize(100)
         .seed(42)
         .batchSize(256)
         .iterations(10)
         .epochs(2)
         .learningRate(0.025)
         .minLearningRate(0.0001)
         .negativeSample(0)
         .sampling(0)
         .trainElementsRepresentation(true)
         .elementsLearningAlgorithm(elem_learner)
         .trainSequencesRepresentation(true)
         .sequenceLearningAlgorithm(seq_learner)
         .resetModel(true)
         .useHierarchicSoftmax(true);

     log.info("*** configuring Doc2Vec model....");
     ParagraphVectors model = builder.build();

     log.info("*** inspecting model configuration....");
     log.info(model.getConfiguration().toString());

     log.info("*** inspecting model configuration.elementsLearningAlgorithm....");
     log.info(model.getConfiguration().getElementsLearningAlgorithm());
 -- CONSOLE --

 o.d.e.n.p.Doc2VecConfigTest - *** configuring Doc2Vec model....
 o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
 o.n.n.NativeOpsHolder - Number of threads used for NativeOps: 4
 o.n.n.Nd4jBlas - Number of threads used for BLAS: 4
 o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Mac OS X]
 o.n.l.a.o.e.DefaultOpExecutioner - Cores: [8]; Memory: [3.6GB];
 o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
 o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration....
 o.d.e.n.p.Doc2VecConfigTest - VectorsConfiguration(minWordFrequency=3, learningRate=0.025, minLearningRate=1.0E-4, layersSize=100, useAdaGrad=false, batchSize=256, iterations=10, epochs=2, window=5, seed=42, negative=0.0, useHierarchicSoftmax=true, sampling=0.0, learningRateDecayWords=0, variableWindows=null, hugeModelExpected=false, useUnknown=false, scavengerActivationThreshold=2000000, scavengerRetentionDelay=3, elementsLearningAlgorithm=null, sequenceLearningAlgorithm=org.deeplearning4j.models.embeddings.learning.impl.sequence.DM, modelUtils=org.deeplearning4j.models.embeddings.reader.impl.BasicModelUtils, tokenizerFactory=org.deeplearning4j.text.tokenization.tokenizerfactory.DefaultTokenizerFactory, tokenPreProcessor=org.deeplearning4j.text.tokenization.tokenizer.preprocessor.CommonPreprocessor, nGram=0, UNK=UNK, STOP=STOP, stopList=[the, and], vocabSize=0, trainElementsVectors=true, trainSequenceVectors=true, allowParallelTokenization=true, preciseWeightInit=false)
 o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration.elementsLearningAlgorithm....
 o.d.e.n.p.Doc2VecConfigTest - null

 Process finished with exit code 0

 Version Information

 Deeplearning4j version 0.9.1
 OSX 10.12.6
 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub &lt;https://github.com/deeplearning4j/deeplearning4j/issues/4097&gt;, or mute the thread &lt;https://github.com/notifications/unsubscribe-auth/ALru_wq2O3rq8to2dEjYr4CcTRmODASsks5skpW6gaJpZM4Pfn2V&gt;.



		</comment>
		<comment id='2' author='kac53211' date='2017-09-21T17:13:17Z'>
		No, the model is trained as it should be, as far as I can tell,
I added the code:
&lt;denchmark-code&gt;    log.info("*** fitting Doc2Vec model....");
    model.fit();

    log.info("*** inspecting model configuration again....");
    log.info(model.getConfiguration().toString());

    log.info("*** inspecting model configuration.elementsLearningAlgorithm again....");
    log.info(model.getConfiguration().getElementsLearningAlgorithm());
&lt;/denchmark-code&gt;

which gave the output:

o.d.e.n.p.Doc2VecConfigTest - *** fitting Doc2Vec model....
o.d.m.s.SequenceVectors - Starting vocabulary building...
o.d.m.w.w.VocabConstructor - Sequences checked: [30], Current vocabulary size: [525]; Sequences/sec: [14.25];
o.d.m.e.l.WordVectorSerializer - Projected memory use for model: [0.40 MB]
o.d.m.e.i.InMemoryLookupTable - Initializing syn1...
o.d.m.s.SequenceVectors - Building learning algorithms:
o.d.m.s.SequenceVectors -           building SequenceLearningAlgorithm: [PV-DM]
o.d.m.s.SequenceVectors -           building ElementsLearningAlgorithm: [CBOW]
o.d.m.s.SequenceVectors - Starting learning process...
o.d.m.s.SequenceVectors - Epoch [1] finished; Elements processed so far: [48320];  Sequences processed: [300]
o.d.m.s.SequenceVectors - Epoch [2] finished; Elements processed so far: [96640];  Sequences processed: [300]
o.d.m.s.SequenceVectors - Time spent on training: 6316 ms
o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration again....
o.d.e.n.p.Doc2VecConfigTest - VectorsConfiguration(minWordFrequency=3, learningRate=0.025, minLearningRate=1.0E-4, layersSize=100, useAdaGrad=false, batchSize=256, iterations=10, epochs=2, window=5, seed=42, negative=0.0, useHierarchicSoftmax=true, sampling=0.0, learningRateDecayWords=0, variableWindows=null, hugeModelExpected=false, useUnknown=false, scavengerActivationThreshold=2000000, scavengerRetentionDelay=3, elementsLearningAlgorithm=null, sequenceLearningAlgorithm=org.deeplearning4j.models.embeddings.learning.impl.sequence.DM, modelUtils=org.deeplearning4j.models.embeddings.reader.impl.BasicModelUtils, tokenizerFactory=org.deeplearning4j.text.tokenization.tokenizerfactory.DefaultTokenizerFactory, tokenPreProcessor=org.deeplearning4j.text.tokenization.tokenizer.preprocessor.CommonPreprocessor, nGram=0, UNK=UNK, STOP=STOP, stopList=[the, and], vocabSize=0, trainElementsVectors=true, trainSequenceVectors=true, allowParallelTokenization=true, preciseWeightInit=false)
o.d.e.n.p.Doc2VecConfigTest - *** inspecting model configuration.elementsLearningAlgorithm again....
o.d.e.n.p.Doc2VecConfigTest - null

		</comment>
		<comment id='3' author='kac53211' date='2019-02-13T10:17:25Z'>
		Fixed, will be merged later today.
		</comment>
		<comment id='4' author='kac53211' date='2019-03-15T10:47:46Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>