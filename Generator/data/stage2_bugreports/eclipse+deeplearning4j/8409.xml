<bug id='8409' author='kris1710' open_date='2019-11-16T10:34:44Z' closed_time='2019-11-16T12:09:42Z'>
	<summary>Backprop Error with embedding layer inputs</summary>
	<description>
Hi I am using the following computation graph for dl4j. I ve written the full model which has 3 parts


factorization machine
8382


Linear model


Deep Network


The output from the three networks is then taken in the output layer. Following is the code:
&lt;denchmark-code&gt;class tensors_sum extends SameDiffLambdaLayer {
  override def defineLayer(sd: SameDiff, x: SDVariable): SDVariable = sd.sum(x,false,1)
}
class tensors_sumk extends SameDiffLambdaLayer {
  override def defineLayer(sd: SameDiff, x: SDVariable): SDVariable = sd.sum(x,true,1)
}

class tensors_square extends SameDiffLambdaLayer {
  override def defineLayer(sd: SameDiff, x: SDVariable): SDVariable = sd.math.square(x)
}

class tensors_by_2 extends SameDiffLambdaLayer {
  override def defineLayer(sd: SameDiff, x: SDVariable): SDVariable = x.mul(0.5)
  //override def getOutputType(layerIndex: Int, inputType: InputType): InputType = inputType
}



object comp_graph {

  def main(args: Array[String]): Unit = {

    val conf =new NeuralNetConfiguration.Builder()
      .seed(1)
      .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
      .updater(new Nadam(0.01))
      .l2(1e-05)
      .graphBuilder()
      .addInputs("input1","input2","input3") //inputs

      //factorization machine
      .addLayer("e_1", new EmbeddingLayer.Builder().nIn(1000).nOut(5).build(), "input1")
      .addLayer("e_2", new EmbeddingLayer.Builder().nIn(1000).nOut(5).build(), "input2")
      .addLayer("d_1",new DenseLayer.Builder().nIn(1).nOut(5).weightInit(WeightInit.XAVIER).build(),"input3")
      .addVertex("e_1_reshape", new ReshapeVertex(-1,1,5),"e_1")
      .addVertex("e_2_reshape", new ReshapeVertex(-1,1,5),"e_2")
   .addVertex("d_1_reshape", new ReshapeVertex(-1,1,5),"d_1")
     .addVertex("stacking_1", new MergeVertex(),"e_1_reshape","e_2_reshape","d_1_reshape")
   .addLayer("a_plus_b",new tensors_sum,"stacking_1")
      .addLayer("a_plus_b_square",new tensors_square,"a_plus_b")
   .addLayer("a_square_b_square",new tensors_square,"stacking_1")
      .addLayer("a_sq_plus_b_sq",new tensors_sum,"a_square_b_square")
       .addVertex("2ab",new ElementWiseVertex(Op.Subtract),"a_plus_b_square","a_sq_plus_b_sq")
     .addLayer("ab",new tensors_by_2,"2ab")
      .addLayer("2d_out",new tensors_sumk,"ab")

      //linear machine
      .addLayer("e_1_linear", new EmbeddingLayer.Builder().nIn(1000).nOut(1).build(), "input1")
      .addLayer("e_2_linear", new EmbeddingLayer.Builder().nIn(1000).nOut(1).build(), "input2")
      .addLayer("d_1_linear",new DenseLayer.Builder().nIn(1).nOut(1).build(),"input3")
      .addVertex("linear_out",new ElementWiseVertex(Op.Add),"e_1_linear","e_2_linear","d_1_linear")

      //dnn_machine

      .addVertex("flattened", new ReshapeVertex(-1,15),"stacking_1")
      .addLayer("dnn_1",new DenseLayer.Builder().nIn(15).nOut(128).weightInit(WeightInit.XAVIER).build(),"flattened")
      .addLayer("dropout1",new DropoutLayer(0.8),"dnn_1")
      .addLayer("relu1", new ActivationLayer(Activation.RELU),"dropout1")
      .addLayer("bn_1",new BatchNormalization.Builder().nIn(128).nOut(128).build(),"relu1")
      .addLayer("dnn_2",new DenseLayer.Builder().nIn(128).nOut(128).weightInit(WeightInit.XAVIER).build(),"bn_1")
      .addLayer("dropout2",new DropoutLayer(0.8),"dnn_2")
      .addLayer("relu2", new ActivationLayer(Activation.RELU),"dropout2")
      .addLayer("bn_2",new BatchNormalization.Builder().nIn(128).nOut(128).build(),"relu2")
      .addLayer("dnn",new DenseLayer.Builder().nIn(128).nOut(1).weightInit(WeightInit.XAVIER).build(),"bn_2")
      .addLayer("dnn_activations", new ActivationLayer(Activation.RELU),"dnn")
      .addLayer("dnn_out", new BatchNormalization.Builder().nIn(1).nOut(1).build(),"dnn_activations")

      //final out
      .addVertex("final_merge",new MergeVertex(),"2d_out","linear_out","dnn_out")
      .addLayer("output",new OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD).activation(Activation.SOFTMAX).nIn(3).nOut(2).build(),"final_merge")
      .setOutputs("output")
      .build()

    val net2 = new ComputationGraph(conf);
    net2.init()

&lt;/denchmark-code&gt;

I created a sample data to check the fit method of the initiated model
. Here is the code for that.
&lt;denchmark-code&gt;val rr = new CSVRecordReader(0,',')
    import org.datavec.api.split.FileSplit


 rr.initialize(new FileSplit(new File("/home/karunsingla/nov2/src/main/resources/Untitled1.csv")))
   val iterator: MultiDataSetIterator  = new RecordReaderMultiDataSetIterator.Builder(5)
      .addReader("my_reader",rr)
      .addInput("my_reader",0,0)
     .addInput("my_reader",1,1)
     .addInput("my_reader",2,2)
     .addOutputOneHot("my_reader",3,2)
      .build();

    net2.fit(iterator)
&lt;/denchmark-code&gt;

However, it fails giving the error:
&lt;denchmark-code&gt;Exception in thread "main" java.lang.NullPointerException
	at org.deeplearning4j.nn.graph.ComputationGraph.calcBackpropGradients(ComputationGraph.java:2736)
	at org.deeplearning4j.nn.graph.ComputationGraph.computeGradientAndScore(ComputationGraph.java:1381)
	at org.deeplearning4j.nn.graph.ComputationGraph.computeGradientAndScore(ComputationGraph.java:1341)
	at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:170)
	at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:63)
	at org.deeplearning4j.optimize.Solver.optimize(Solver.java:52)
	at org.deeplearning4j.nn.graph.ComputationGraph.fitHelper(ComputationGraph.java:1165)
	at org.deeplearning4j.nn.graph.ComputationGraph.fit(ComputationGraph.java:1115)
	at org.deeplearning4j.nn.graph.ComputationGraph.fit(ComputationGraph.java:1082)
	at comp_graph$.main(comp_graph.scala:139)
	at comp_graph.main(comp_graph.scala)

Process finished with exit code 1
&lt;/denchmark-code&gt;

I did some debugging and the error is coming from this line in computationgraph.java, when graphvertex gv=InputVertex(id=1,name="input2")
which is an input to the embedding layer.
&lt;denchmark-code&gt;//Set epsilons for the vertices that provide inputs to this vertex:
                if (inputVertices != null) {
                    int j = 0;
                    for (VertexIndices v : inputVertices) {
                        GraphVertex gv = vertices[v.getVertexIndex()];
                        if (setVertexEpsilon[gv.getVertexIndex()]) {
                            //This vertex: must output to multiple vertices... we want to add the epsilons here
                            INDArray currentEps = gv.getEpsilon();
                            gv.setEpsilon(currentEps.addi(epsilons[j++]));  //TODO is this always safe?
                        } else {
                            gv.setEpsilon(epsilons[j++]);
                        }
&lt;/denchmark-code&gt;

I am attaching the sample csv file as well.
&lt;denchmark-link:https://github.com/eclipse/deeplearning4j/files/3854078/Untitled1.zip&gt;Untitled1.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='kris1710' date='2019-11-16T12:11:08Z'>
		Thanks for reporting and for the code to reproduce it.
I have merged a fix here: &lt;denchmark-link:https://github.com/KonduitAI/deeplearning4j/pull/52&gt;KonduitAI#52&lt;/denchmark-link&gt;

I'll post here once it's pushed to the eclipse/deeplearning4j repo - it'll be in snapshots soon after that.
		</comment>
		<comment id='2' author='kris1710' date='2019-11-16T12:28:28Z'>
		Fix is now in eclipse master, so it'll be available in the next snapshot build (usually takes a few hours for new snapshots to go out).
&lt;denchmark-link:https://deeplearning4j.org/docs/latest/deeplearning4j-config-snapshots&gt;https://deeplearning4j.org/docs/latest/deeplearning4j-config-snapshots&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='kris1710' date='2019-11-19T09:18:11Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 : Thanks for the fix, However, after configuring the snapshots build, I am getting the following error for the same code:
&lt;denchmark-code&gt;Exception in thread "main" java.lang.NoClassDefFoundError: org/nd4j/autodiff/samediff/internal/SessionMemMgr
	at org.deeplearning4j.nn.conf.layers.samediff.SameDiffLayer.instantiate(SameDiffLayer.java:103)
	at org.deeplearning4j.nn.conf.graph.LayerVertex.instantiate(LayerVertex.java:107)
	at org.deeplearning4j.nn.graph.ComputationGraph.init(ComputationGraph.java:574)
	at org.deeplearning4j.nn.graph.ComputationGraph.init(ComputationGraph.java:441)
	at graph2$.main(Demo1.scala:95)
	at graph2.main(Demo1.scala)
Caused by: java.lang.ClassNotFoundException: org.nd4j.autodiff.samediff.internal.SessionMemMgr
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 6 more
&lt;/denchmark-code&gt;

I ve configured the sbt as follows,keeping nd4j-native version to be 1.0.0.5-beta and deeplearning4j.core to be the snapshot. (Attaching the sbt for reference),  cause there were issues in the nd4j snapshot version &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/8418&gt;8418&lt;/denchmark-link&gt;

Do you think it could be due to  setting different versions of deeplearning4j(SNAPSHOT) and nd4j(1.0.0-beta5) in the build?
SBT for the project
&lt;denchmark-code&gt;name := "scala1"

version := "0.1"

scalaVersion := "2.11.12"

ThisBuild / useCoursier := false

classpathTypes += "maven-plugin"

val d4jVersion = "1.0.0-SNAPSHOT"
val sparkVersion = "2.4.4"

libraryDependencies += "org.apache.spark" %% "spark-core" % sparkVersion
libraryDependencies += "org.apache.spark" %% "spark-sql" % sparkVersion
libraryDependencies += "org.bytedeco.javacpp-presets" % "openblas" % "0.2.20-1.4.1" classifier "" classifier "linux-x86_64"
libraryDependencies += "org.deeplearning4j" % "deeplearning4j-core" % d4jVersion
//libraryDependencies += "org.deeplearning4j" % "deeplearning4j-modelimport" % d4jVersion
resolvers += "snapshots-repo" at "https://oss.sonatype.org/content/repositories/snapshots"
libraryDependencies += "org.nd4j" % "nd4j-native-platform" % "1.0.0-beta5"
libraryDependencies += "org.datavec" %% "datavec-spark" % d4jVersion
libraryDependencies += "org.deeplearning4j" % "deeplearning4j-datavec-iterators" % d4jVersion

updateOptions := updateOptions.value.withLatestSnapshots(false )

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='kris1710' date='2019-11-19T09:30:32Z'>
		You're mixing 1.0.0-SNAPSHOT and 1.0.0-beta5 versions here. Don't do that, and your app will work
		</comment>
	</comments>
</bug>