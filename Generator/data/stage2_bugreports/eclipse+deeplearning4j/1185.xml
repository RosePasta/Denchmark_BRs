<bug id='1185' author='vvpreetham' open_date='2016-02-23T21:06:30Z' closed_time='2016-03-04T13:27:53Z'>
	<summary>Heap breaks at the time of W2V Model reload</summary>
	<description>
Created a w2v Model with the following specs (gist : &lt;denchmark-link:https://gist.github.com/vvpreetham/5562c8cfd0527a29c1ee&gt;https://gist.github.com/vvpreetham/5562c8cfd0527a29c1ee&lt;/denchmark-link&gt;
)
file sizes as follows (This is a scaled down corpus to show the effect of the error)
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/16869974/13266676/0e918428-da2e-11e5-94f3-f40cf9a45b88.jpg&gt;&lt;/denchmark-link&gt;


Using : unstemmed_product_desc.txt as input corpus
Model Saved : noinit_unstemmed_adagrad_v1000_5f.bin

While I was able to fit the model in probably about 4G or less RAM, saving and loading the model at load time breaks the heap.
Its the same machine, same RAM allocation. No changes...
	</description>
	<comments>
		<comment id='1' author='vvpreetham' date='2016-03-04T13:27:53Z'>
		This issue looks to be fixed within this pr: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/1133&gt;https://github.com/deeplearning4j/deeplearning4j/pull/1133&lt;/denchmark-link&gt;

However, it will be merged to master a bit later.
		</comment>
		<comment id='2' author='vvpreetham' date='2019-01-21T09:37:32Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>