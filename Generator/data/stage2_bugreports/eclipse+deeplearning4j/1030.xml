<bug id='1030' author='AlexDBlack' open_date='2016-01-08T10:54:54Z' closed_time='2017-01-21T07:58:42Z'>
	<summary>Fix variable length time series + bidirectional LSTM</summary>
	<description>
The new bidirectional LSTM implementation will not work correctly with the current variable length time series (masking) implementation.
The issue is that the bidirectional LSTM reverse pass will be receiving non-zero activations from times beyond the end of the shorter/padded time series. This will likely adversely affect network performance.
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2016-06-04T15:06:57Z'>
		Did you ever get around to this?
		</comment>
		<comment id='2' author='AlexDBlack' date='2016-06-04T23:54:43Z'>
		Still needs to be done.
		</comment>
		<comment id='3' author='AlexDBlack' date='2016-11-23T14:24:18Z'>
		Still relevant?
		</comment>
		<comment id='4' author='AlexDBlack' date='2017-01-21T07:58:42Z'>
		Implemented here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/2699&gt;https://github.com/deeplearning4j/deeplearning4j/pull/2699&lt;/denchmark-link&gt;

Will  be merged soon.
		</comment>
		<comment id='5' author='AlexDBlack' date='2019-01-19T21:54:20Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>