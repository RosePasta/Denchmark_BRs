<bug id='8597' author='AlexDBlack' open_date='2020-01-07T06:24:43Z' closed_time='2020-01-31T09:40:24Z'>
	<summary>libnd4j: batchnorm op (cpu, no mkldnn) with permuted input gives incorrect output</summary>
	<description>
&lt;denchmark-code&gt;    @Test
    public void test(){
        Nd4j.getEnvironment().allowHelpers(false);

        INDArray in = Nd4j.rand(DataType.FLOAT, 3, 3, 15, 15);
        INDArray m = Nd4j.zeros(DataType.FLOAT, 3);
        INDArray v = Nd4j.ones(DataType.FLOAT, 3);
        INDArray g = Nd4j.ones(DataType.FLOAT, 3);
        INDArray b = Nd4j.zeros(DataType.FLOAT, 3);

        INDArray out = in.ulike();

        DynamicCustomOp op = DynamicCustomOp.builder("batchnorm")
                .addInputs(in, m, v, g, b)
                .addOutputs(out)
                .addFloatingPointArguments(1e-5)
                .addIntegerArguments(1,1,1)
                .build();

        Nd4j.exec(op);

        INDArray inPermute = Nd4j.create(DataType.FLOAT, 3, 15, 15, 3).permute(0,3,1,2);
        inPermute.assign(in);
        INDArray out2 = out.ulike();
        op.setInputArgument(0, inPermute);
        op.setOutputArgument(0, out2);

        Nd4j.exec(op);

        assertEquals(out, out2);     //Fails here
    }
&lt;/denchmark-code&gt;

Note MKLDNN is disabled here. I will confirm it passes (or not) with MKLDNN soon.
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2020-01-07T07:07:25Z'>
		Confirmed passing on MKLDNN, so it's only our batchnorm implementation that is impacted.
		</comment>
		<comment id='2' author='AlexDBlack' date='2020-01-07T07:30:33Z'>
		Confirmed OK on CUDA
		</comment>
		<comment id='3' author='AlexDBlack' date='2020-01-31T09:40:24Z'>
		Should be fixed by now.
		</comment>
	</comments>
</bug>