<bug id='3846' author='vladtc' open_date='2017-08-11T15:44:06Z' closed_time='2017-11-29T03:26:21Z'>
	<summary>toPreProcess NullPointerException when using MinMaxNormalizer</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Expected behavior: I was expecting to have no errors, since the equivalent classes used in 0.8.0 work just fine.
Encountered behavior: I got the following error after all the training epochs for the first neural network candidate produced by the CandidateGenerator class were finished:
Exception in thread "ADSI prefetch thread" java.lang.RuntimeException: java.lang.NullPointerException: toPreProcess	at org.deeplearning4j.datasets.iterator.AsyncDataSetIterator$AsyncPrefetchThread.run(AsyncDataSetIterator.java:442)
Caused by: java.lang.NullPointerException: toPreProcess	at org.nd4j.linalg.dataset.api.preprocessor.AbstractDataSetNormalizer.preProcess(AbstractDataSetNormalizer.java:113)	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:295) at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:393)	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:51) at org.deeplearning4j.datasets.iterator.AsyncDataSetIterator$AsyncPrefetchThread.run(AsyncDataSetIterator.java:417)
The code producing this is mentioned in &lt;denchmark-link:https://gist.github.com/vladtc/f854164ce05d887ee377df3964de5251&gt;https://gist.github.com/vladtc/f854164ce05d887ee377df3964de5251&lt;/denchmark-link&gt;

and &lt;denchmark-link:https://gist.github.com/vladtc/7ffefec6eca2b56c42305c47c5d0d43d&gt;https://gist.github.com/vladtc/7ffefec6eca2b56c42305c47c5d0d43d&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j version: 0.9.1-SNAPSHOT and 0.9.1
platform information (OS, etc): 16.04.2-Ubuntu
CUDA version, if used: no GPU used but cuda 7.5 and 8.0 were present in the arbiter pom
NVIDIA driver version, if in use: no driver used

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

If you'd like to help us fix the issue by contributing some code, but would
like guidance or help in doing so, please mention it!
	</description>
	<comments>
		<comment id='1' author='vladtc' date='2017-08-11T15:55:17Z'>
		Attached are the 4 data files needed to reproduce this. Extension needs to be changed from .txt to .csv
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1218385/smth_test.txt&gt;smth_test.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1218384/smth_train.txt&gt;smth_train.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1218386/smth_validate.txt&gt;smth_validate.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1218388/smth_whole.txt&gt;smth_whole.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='vladtc' date='2017-08-14T09:33:55Z'>
		Got the same error using the recently released 0.9.1 version.
		</comment>
		<comment id='3' author='vladtc' date='2017-08-15T12:47:41Z'>
		Attached are the normalized data files that can be used to execute the program without using the normalizer. The exception mentioned above doesn't appear but all optimization tasks fail with the message:
[main] INFO org.deeplearning4j.arbiter.optimize.runner.BaseOptimizationRunner - Task [i] failed during execution
Note: trainFile/validateFile/testFile/wholeFile variables need to be initialized to "smth_train_normalized.txt", "smth_validate_normalized.txt" etc.
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1225040/smth_test_normalized.txt&gt;smth_test_normalized.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1225042/smth_train_normalized.txt&gt;smth_train_normalized.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1225041/smth_validate_normalized.txt&gt;smth_validate_normalized.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1225043/smth_whole_normalized.txt&gt;smth_whole_normalized.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='vladtc' date='2017-10-04T09:03:44Z'>
		This is a bug in the RecordReaderDataSetIterator class.  Specifically, you need to set last = ds in the mdsToDataSet function.  If I get a chance, I'll create a patch, but for now we can work around the bug.
&lt;denchmark-code&gt;    private DataSet mdsToDataSet(MultiDataSet mds) {

       // code cut for brevity

        if (preProcessor != null) {
            preProcessor.preProcess(ds);
        }

        last = ds;

        return ds;
    }
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='vladtc' date='2017-11-29T03:26:21Z'>
		&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4326&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4326&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='vladtc' date='2018-09-24T06:43:56Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>