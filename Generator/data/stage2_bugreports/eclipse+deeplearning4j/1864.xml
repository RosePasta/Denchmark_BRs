<bug id='1864' author='vzamboni' open_date='2016-07-22T14:05:58Z' closed_time='2016-11-30T14:32:26Z'>
	<summary>Train with Spark generates ExecutorLostFailure</summary>
	<description>
I'm training a Convolutional Neural Network on a small dataset of images (15 classes, 70imgs per class).
I tried with 2 different clusters:

7 nodes, 8gb, 8 cores, physical nodes with Spark 1.6.0 standalone
3 nodes, 60gb, 8 cores, AWS with Spark 1.6.2 standalone

And I'm always facing ExecutorLostFailure:

ERROR TaskSchedulerImpl: Lost executor 36 on &lt; ip-of-the-node &gt;: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.

Training keeps going but a lot of executors get disassociated till it crashes. Before it crashes the training is performing good and it reaches 40-50% f1-score.
From the Spark UI the situation is &lt;denchmark-link:https://s32.postimg.org/7r5k9urv9/exec.png&gt;this&lt;/denchmark-link&gt;

my code is &lt;denchmark-link:https://gist.github.com/vzamboni/e8997b4a01ea1a5dc262fe7a5dc3473c&gt;here&lt;/denchmark-link&gt;

I'm using version 0.4.0 but I had the same problem with previous version.
I compiled deepleraning4j, nd4j and canova with scala 2.10 and I'm using spark 1.6
Launch configuration is:

spark-submit --conf spark.driver.maxResultSize=2g --jars  --master -my-spark-master- --driver-memory 4g --executor-memory 50g --class SparkConvolutional my-jar

Dependencies of the projects are &lt;denchmark-link:https://gist.github.com/vzamboni/da1be46d8c46b259a6fccdc6c2fded1e&gt;here&lt;/denchmark-link&gt;

&lt;denchmark-h:h1&gt;UPDATE&lt;/denchmark-h&gt;

I tried with the examples in the dl4j-spark-cdh5-examples repo (MnistExample and GravesLSTMCharModellingExample) in the 7 nodes cluster with scala 2.11 and building with maven and I'm facing the same problem.
MnistExample reaches the end (epoch 4) but throws some ExecutorLostFailure during the training.
GravesLSTMCharModellingExample does not finish and crashes after 50 minutes and a lot of ExecutorLostFailure.
In both the executions I'm having a lot of

WARN TaskSetManager: Stage 0 contains a task of very large size (3898 KB). The maximum recommended task size is 100 KB
which I noticed increasing with dataset size increasing.

I have both full logs of &lt;denchmark-link:https://gist.github.com/vzamboni/cc3816341a1dfb0304aef0084bbf5364&gt;MnistExample&lt;/denchmark-link&gt;
 (example of ExecutorLostFailure at line 903) and &lt;denchmark-link:https://gist.github.com/vzamboni/a733aefe9a0bc7820afb4313b397d94a&gt;GravesLSTMCharModellingExample &lt;/denchmark-link&gt;
 (example of ExecutorLostFailure at line 132)
	</description>
	<comments>
		<comment id='1' author='vzamboni' date='2016-07-28T16:30:59Z'>
		As a workaround I had to decrease the amount of memory given to the executors. In a 7 nodes x 6g cluster I start the program with:

--driver-memory 2g --executor-memory 2g

Decreasing the memory dedicated to the executors I have the program performing good now.
I am now trying with a bigger network, (I used &lt;denchmark-link:https://github.com/deeplearning4j/hadoop-summit-scenes/blob/master/src/main/java/org/deeplearning4j/Train.java&gt;this&lt;/denchmark-link&gt;
 with the same parameter used in the example) and I got an ExecutorLostFailure after 13 minutes, but the situation is far better now.
		</comment>
		<comment id='2' author='vzamboni' date='2016-11-30T14:32:26Z'>
		This seems to be fixed now?
		</comment>
		<comment id='3' author='vzamboni' date='2019-01-20T07:57:11Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>