<bug id='3990' author='shengc' open_date='2017-08-31T16:31:05Z' closed_time='2019-11-10T14:24:54Z'>
	<summary>ParallelWrapper throws ClosedByInterruptException</summary>
	<description>
I am using latest release version 0.9.1, and running on CPU back end.
relevant code:
 val pw = new ParallelWrapper.Builder(nn).workers(2).prefetchBuffer(2).build()
 pw.fit(ds(trainDataPath))
stack trace:
Exception in thread "ADSI prefetch thread" java.lang.RuntimeException: edu.stanford.nlp.io.RuntimeIOException: java.nio.channels.ClosedByInterruptException
    at org.deeplearning4j.datasets.iterator.AsyncDataSetIterator$AsyncPrefetchThread.run(AsyncDataSetIterator.java:442)
Caused by: edu.stanford.nlp.io.RuntimeIOException: java.nio.channels.ClosedByInterruptException
    at edu.stanford.nlp.process.PTBTokenizer.getNext(PTBTokenizer.java:294)
    at edu.stanford.nlp.process.PTBTokenizer.getNext(PTBTokenizer.java:176)
    at edu.stanford.nlp.process.AbstractTokenizer.hasNext(AbstractTokenizer.java:60)
    at edu.stanford.nlp.process.AbstractTokenizer.tokenize(AbstractTokenizer.java:99)
    at experiment.ExperimentProducer$.produce(ExperimentProducer.scala:90)
    at experiment.ExperimentFileCallback$class.call(ExperimentFileCallback.scala:19)
experiment 2017-08-31 12:26:19,584 [] INFO  [main] o.d.p.ParallelWrapper          - Starting ParallelWrapper training round...
    at org.deeplearning4j.datasets.iterator.FileSplitDataSetIterator.next(FileSplitDataSetIterator.java:109)
    at org.deeplearning4j.datasets.iterator.FileSplitDataSetIterator.next(FileSplitDataSetIterator.java:20)
    at org.deeplearning4j.datasets.iterator.AsyncDataSetIterator$AsyncPrefetchThread.run(AsyncDataSetIterator.java:417)
Caused by: java.nio.channels.ClosedByInterruptException
    at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
    at sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:164)
    at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:65)
    at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109)
    at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103)
    at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
    at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
    at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
    at java.io.InputStreamReader.read(InputStreamReader.java:184)
    at java.io.BufferedReader.read1(BufferedReader.java:210)
    at java.io.BufferedReader.read(BufferedReader.java:286)
    at edu.stanford.nlp.process.PTBLexer.zzRefill(PTBLexer.java)
    at edu.stanford.nlp.process.PTBLexer.next(PTBLexer.java)
    at edu.stanford.nlp.process.PTBTokenizer.getNext(PTBTokenizer.java:292
	</description>
	<comments>
		<comment id='1' author='shengc' date='2017-08-31T17:19:51Z'>
		Can you get me some code that reproduces this exception?
		</comment>
		<comment id='2' author='shengc' date='2017-08-31T17:52:58Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;

Using a  instead of  makes the error go away. Is it somehow related to &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/3281&gt;https://github.com/deeplearning4j/deeplearning4j/issues/3281&lt;/denchmark-link&gt;
 that  should not be used when in  ?
		</comment>
		<comment id='3' author='shengc' date='2017-08-31T18:08:42Z'>
		Ok, another problem for ParallelWrapper....
The following one throws UnsupportOperationException on AbstractList, which comes from nn.addListeners(new StatsListener(st))
    nn.setListeners(new ScoreIterationListener(numIterations / 10))
    import org.deeplearning4j.parallelism.ParallelWrapper
    val pw= new ParallelWrapper.Builder(nn).workers(2).prefetchBuffer(2).build()
    ui foreach { server =&gt;
      val st = new InMemoryStatsStorage()
      server.attach(st)
      nn.addListeners(new StatsListener(st))
    }
    pw.fit(ds(trainDataPath)
However by moving the line that instantiates ParallelWrapper after the call to nn.addListeners(...), the error disappears,
    nn.setListeners(new ScoreIterationListener(numIterations / 10))
    ui foreach { server =&gt;
      val st = new InMemoryStatsStorage()
      server.attach(st)
      nn.addListeners(new StatsListener(st))
    }
    import org.deeplearning4j.parallelism.ParallelWrapper
    val pw= new ParallelWrapper.Builder(nn).workers(2).prefetchBuffer(2).build()
    pw.fit(ds(trainDataPath))
		</comment>
	</comments>
</bug>