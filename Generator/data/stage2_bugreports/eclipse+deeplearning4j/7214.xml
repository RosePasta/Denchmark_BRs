<bug id='7214' author='Flips01' open_date='2019-02-21T14:58:24Z' closed_time='2019-03-16T07:34:48Z'>
	<summary>Model Serialization fails if DataNormalization supplied</summary>
	<description>
Calling ModelSerializer.writeModel with a DataNormalization-Instance yields the following Exception:

Exception in thread "main" java.io.IOException: flush() failed: stream is closed
at org.apache.commons.io.output.ClosedOutputStream.flush(ClosedOutputStream.java:57)
at org.apache.commons.io.output.ProxyOutputStream.flush(ProxyOutputStream.java:103)
at java.base/java.util.zip.DeflaterOutputStream.flush(DeflaterOutputStream.java:283)
at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:143)
at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182)
at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191)
at org.deeplearning4j.util.ModelSerializer.writeModel(ModelSerializer.java:193)
at org.deeplearning4j.util.ModelSerializer.writeModel(ModelSerializer.java:91)
at TrainModel.main(TrainModel.java:116)
Suppressed: java.io.IOException: flush() failed: stream is closed
at org.apache.commons.io.output.ClosedOutputStream.flush(ClosedOutputStream.java:57)
at org.apache.commons.io.output.ProxyOutputStream.flush(ProxyOutputStream.java:103)
at java.base/java.util.zip.DeflaterOutputStream.flush(DeflaterOutputStream.java:283)
at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:143)
at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123)
at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182)
... 3 more

A model file is still beeing generated. Calling ModelSerializer.writeModel without an DataNormalization instance doesn't result in an exception.
This exception can be reproduced as follows:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/2889762/dl4j_exception.txt&gt;dl4j_exception.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Flips01' date='2019-02-21T15:14:28Z'>
		Are you using latest dl4j/nd4j version?
		</comment>
		<comment id='2' author='Flips01' date='2019-02-21T15:20:04Z'>
		I am using 1.0.0-beta3. This should be the latest version shouldn't it?
		</comment>
		<comment id='3' author='Flips01' date='2019-02-22T00:01:30Z'>
		Yes, 1.0.0-beta3 is the latest version.
This definitely looks like a bug. In the mean time, you can add the normalizer separately - i.e., writeModel to save the model, then addNormalizerToModel to update the file to include the normalizer.
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/3c66853115e0d500cf1cafc0e060478766de4f03/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java#L714-L722&gt;https://github.com/deeplearning4j/deeplearning4j/blob/3c66853115e0d500cf1cafc0e060478766de4f03/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java#L714-L722&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Flips01' date='2019-03-16T07:34:48Z'>
		I'm unable to reproduce this - I've tried 1.0.0-beta3 and current master/snapshots, Windows 10 and Kubuntu 17.10, with and without saving updater, running 1000x in a loop, trying both NormalizerStandardize and NormalizerMinMaxScaler, etc.
I've also looked at the ModelSerializer implementation and can't see how this bug could occur.
I'd be happy to take another look if I could reproduce the problem; I'll close this as not reproducible for now.
		</comment>
		<comment id='5' author='Flips01' date='2019-04-15T08:30:19Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>