<bug id='1834' author='renuka98' open_date='2016-07-16T16:29:49Z' closed_time='2017-02-17T05:53:07Z'>
	<summary>Using NGramTokenizerFactory for vectors</summary>
	<description>
I would like to vectorize ngrams and hence used the ngram tokenizer.  It does not seem to be working fine. Here is the code I tried using NGramTokenizerFactory
&lt;denchmark-code&gt;// Split on white spaces in the line to get words
&lt;/denchmark-code&gt;

TokenizerFactory t1 = new DefaultTokenizerFactory();
t1.setTokenPreProcessor(new CommonPreprocessor());
TokenizerFactory t = new NGramTokenizerFactory(t1, 1, 3);
&lt;denchmark-code&gt;     System.out.println("Building model....");
   Word2Vec vec = new Word2Vec.Builder()
           .minWordFrequency(5)
           .iterations(1)
           .layerSize(100)
           .seed(42)
           .windowSize(5)
           .iterate(iter)
           .tokenizerFactory(t)
           .build();
vec.fit();
double weight = vec.similarity("memory", "semantic");  //returns a null.
&lt;/denchmark-code&gt;

However, if I just use the DefaultTokernizerFactory, it returns the similarity measure.
A small part of the serialized vectors is shown below
Az92[seems,_Az92_to] -0.012880571186542511 -0.002391873626038432 ..........
Az92[then] -0.008083909749984741 -0.013380923308432102.........................
Az92[for,_Az92_breakfast] 0.04253905266523361 0.024196598678827286  .........
Az92[type,_Az92_of] .......
	</description>
	<comments>
		<comment id='1' author='renuka98' date='2016-07-16T19:57:57Z'>
		Az92 is just temporary delimiter for tokens within n-gram. I'll check why it's not replaced back on output.
As temporary workaround just replace it to whatever you want.
		</comment>
		<comment id='2' author='renuka98' date='2016-10-02T17:47:49Z'>
		raver119,
Can you please tell if there is any progress with this issue?
On version 0.6.0 I see same error:
Az92[calvin,_Az92_klein] -0.06634753197431564 0.2689773440361023 0.41148582100868225
		</comment>
		<comment id='3' author='renuka98' date='2019-01-19T12:52:28Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>