<bug id='8751' author='shan760107' open_date='2020-03-05T07:03:09Z' closed_time='2020-03-06T01:01:21Z'>
	<summary>GridSearchCandidateGenerator</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Please describe our issue, along with:
I want to use GridSearchCandidateGenerator for hyperparameter tuning.
I put LearningRate Param and layerSize Param to multilayerspace like below.
and parameter doesn't change at all.
I guess that there is bug at getCandiate method.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


Deeplearning4j version: 1.0.0-beta6
Platform information (OS, etc): win 10

&lt;denchmark-h:h4&gt;Additional Information&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;    ParameterSpace&lt;Integer&gt; layerSizeParam = new DiscreteParameterSpace&lt;&gt;(32, 48, 64);
ParameterSpace&lt;Double&gt; learningRateParam = new DiscreteParameterSpace&lt;&gt;(0.005, 0.007, 0.01);

    MultiLayerSpace hyperParamaterSpace = new MultiLayerSpace.Builder()
                .seed(seed)
                .biasInit(1)
                .l2(1e-4)
                .updater(new NesterovsSpace(learningRateParam))
                .addLayer(new DenseLayerSpace.Builder().nIn(numInputs).nOut(layerSizeParam)
                    .weightInit(WeightInit.XAVIER)
                    .activation(Activation.RELU)
                    .build())
                .addLayer(new DenseLayerSpace.Builder().nIn(layerSizeParam).nOut(layerSizeParam)
                    .weightInit(WeightInit.XAVIER)
                    .activation(Activation.RELU)
                    .build())
                .addLayer(new OutputLayerSpace.Builder()
                    .lossFunction(LossFunctions.LossFunction.MSE)
                    .weightInit(WeightInit.XAVIER)
                    .activation(Activation.SOFTMAX)
                    .nIn(layerSizeParam).nOut(numOutputs).build())
                .build();

    CandidateGenerator candidateGenerator = new GridSearchCandidateGenerator(hyperParamaterSpace, 30, GridSearchCandidateGenerator.Mode.Sequential, null);

    OptimizationConfiguration optimizationConfiguration = new OptimizationConfiguration.Builder()
            .candidateGenerator(candidateGenerator)
            .dataSource(ExampleDataSource.class,dataSourceProperties)
            .modelSaver(modelSaver)
            .scoreFunction(scoreFunction)
            .terminationConditions(conditions)
            .build();
    
    
    IOptimizationRunner runner = new LocalOptimizationRunner(optimizationConfiguration, new MultiLayerNetworkTaskCreator());
    //Uncomment this if you want to store the model.
    StatsStorage ss = new FileStatsStorage(new File("HyperParamOptimizationStats.dl4j"));
    runner.addListeners(new ArbiterStatusListener(ss));
    UIServer.getInstance().attach(ss);
    //runner.addListeners(new LoggingStatusListener()); //new ArbiterStatusListener(ss)
    runner.execute();
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='shan760107' date='2020-03-06T01:02:13Z'>
		Thanks for reporting this issue.
It has been fixed here: &lt;denchmark-link:https://github.com/KonduitAI/deeplearning4j/pull/292&gt;KonduitAI#292&lt;/denchmark-link&gt;

The fix will be made available on snapshots within a few days at the latest.
Instructions for using snapshots can be found here: &lt;denchmark-link:https://deeplearning4j.org/docs/latest/deeplearning4j-config-snapshots&gt;https://deeplearning4j.org/docs/latest/deeplearning4j-config-snapshots&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>