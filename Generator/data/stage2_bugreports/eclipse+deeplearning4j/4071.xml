<bug id='4071' author='StefanoSamele' open_date='2017-09-14T15:04:40Z' closed_time='2017-12-05T08:29:15Z'>
	<summary>Different result of max pooling layer using cpu and gpu backend</summary>
	<description>
We used the following simple network to test the max pooling layer effect with different backends:
&lt;denchmark-link:https://gist.github.com/StefanoSamele/93a3d602d3c55585cf79d8f4c807da75&gt;https://gist.github.com/StefanoSamele/93a3d602d3c55585cf79d8f4c807da75&lt;/denchmark-link&gt;

Using cpu native backend we got the following output:
[[[[108.00,  135.00,  162.00,  189.00,  216.00],
[135.00,  162.00,  189.00,  216.00,  243.00],
[162.00,  189.00,  216.00,  243.00,  270.00],
[189.00,  216.00,  243.00,  270.00,  297.00],
[216.00,  243.00,  270.00,  297.00,  324.00]]]]
Using CUDA backend we got:
[[[[81.00,  108.00,  135.00,  162.00,  189.00],
[108.00,  135.00,  162.00,  189.00,  216.00],
[135.00,  162.00,  189.00,  216.00,  243.00],
[162.00,  189.00,  216.00,  243.00,  270.00],
[189.00,  216.00,  243.00,  270.00,  297.00]]]]
It looks like the CUDA output is somehow "shifted".
We also did a test comparing a Keras net output (involving max pooling operations), with the same net imported in DL4J. The cpu output matched the keras output, while the CUDA output didn't.
	</description>
	<comments>
		<comment id='1' author='StefanoSamele' date='2017-09-14T15:07:00Z'>
		Is CUDNN used?
		</comment>
		<comment id='2' author='StefanoSamele' date='2017-09-14T15:12:46Z'>
		And yes, that's strange. Dl4j pooling 2d uses the same code for cpu &amp; CUDA...
		</comment>
		<comment id='3' author='StefanoSamele' date='2017-09-14T15:14:29Z'>
		So, we noticed we didn't have the following dependency:

org.deeplearning4j
deeplearning4j-cuda-8.0
${dl4j.version}

We will immediately try again.
		</comment>
		<comment id='4' author='StefanoSamele' date='2017-09-14T15:15:13Z'>
		hm, so it gives different result without cuDNN. Now i'm really surprised...
		</comment>
		<comment id='5' author='StefanoSamele' date='2017-09-14T15:27:33Z'>
		Can you please also check Convolution layer output on different backends? Maybe that's the place where  difference comes from?
		</comment>
		<comment id='6' author='StefanoSamele' date='2017-09-14T15:28:41Z'>
		No, we checked it. It appears to be the same.
		</comment>
		<comment id='7' author='StefanoSamele' date='2017-09-14T15:33:16Z'>
		Amazing…
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 14 сент. 2017 г., в 18:29, Stefano Samele ***@***.***&gt; написал(а):

 No, we checked it. It appears to be the same.

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub &lt;https://github.com/deeplearning4j/deeplearning4j/issues/4071#issuecomment-329518768&gt;, or mute the thread &lt;https://github.com/notifications/unsubscribe-auth/ALru_wxbSHE0CFQXH82wXoCEbx-kULegks5siUY-gaJpZM4PXuuH&gt;.



		</comment>
		<comment id='8' author='StefanoSamele' date='2017-09-14T15:43:02Z'>
		We had the chance to use cuDNN, and it gives the same result as cpu
		</comment>
		<comment id='9' author='StefanoSamele' date='2017-09-14T17:17:35Z'>
		Unfortunately with cuDNN, we noticed that Atrous Convolution (dilated) no longer works correctly. Should we open another issue?
		</comment>
		<comment id='10' author='StefanoSamele' date='2017-09-14T17:55:02Z'>
		Yes, file new issue please.
		</comment>
		<comment id='11' author='StefanoSamele' date='2017-12-05T08:29:15Z'>
		I'm going to close this: I'm unable to reproduce it (edit: I tested both cuda 8 on windows and cuda 9 on linux). There have been a number of changes/fixes since this issue was opened.
&lt;denchmark-code&gt;o.n.l.f.Nd4jBackend - Loaded [JCublasBackend] backend
[[[[108.00,  135.00,  162.00,  189.00,  216.00],  
   [135.00,  162.00,  189.00,  216.00,  243.00],  
   [162.00,  189.00,  216.00,  243.00,  270.00],  
   [189.00,  216.00,  243.00,  270.00,  297.00],  
   [216.00,  243.00,  270.00,  297.00,  324.00]]]]
   
     
o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
[[[[108.00,  135.00,  162.00,  189.00,  216.00],  
   [135.00,  162.00,  189.00,  216.00,  243.00],  
   [162.00,  189.00,  216.00,  243.00,  270.00],  
   [189.00,  216.00,  243.00,  270.00,  297.00],  
   [216.00,  243.00,  270.00,  297.00,  324.00]]]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='StefanoSamele' date='2018-09-24T04:43:44Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>