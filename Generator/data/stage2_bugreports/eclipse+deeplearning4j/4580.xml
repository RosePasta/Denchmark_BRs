<bug id='4580' author='kullanici0606' open_date='2018-01-31T08:41:35Z' closed_time='2018-04-19T13:38:15Z'>
	<summary>Merge fails when embedding layer used in Keras model</summary>
	<description>
&lt;denchmark-h:h4&gt;Imported keras model fails to output when there is an embedding layer.&lt;/denchmark-h&gt;

I import a keras model with embedding layer and concatenation and import method works fine. However when I try to make prediction with the imported model, output method fails with the exception below. I am attaching the keras model, keras code and deepleaning4j code I am using
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1680903/embed_merge_import.zip&gt;embed_merge_import.zip&lt;/denchmark-link&gt;

When I debug the keras code with tenflow debugger, I see that activation tensors have the shape of (1, 5):
&lt;denchmark-link:https://user-images.githubusercontent.com/35795498/35612840-3791b3ae-067b-11e8-9878-9fb7223ad887.png&gt;&lt;/denchmark-link&gt;

and concatenation tensor has the shape of (1, 10):
&lt;denchmark-link:https://user-images.githubusercontent.com/35795498/35612904-5e094cc2-067b-11e8-9cd6-69cf28bb57e0.png&gt;&lt;/denchmark-link&gt;

However, when I try to debug deeplearning4j code, I see that (and as exception says) merge layer's input has the shape of (256, 5). Am I doing something wrong? If this is not a bug, could you please help me what is wrong with my deeplearning4j code?
&lt;denchmark-code&gt;java.lang.IllegalStateException: Cannot merge activations with different number of examples (activations[0] shape: [256, 5], activations[1] shape: [1, 5]
	at org.deeplearning4j.nn.graph.vertex.impl.MergeVertex.doForward(MergeVertex.java:102)
	at org.deeplearning4j.nn.graph.ComputationGraph.feedForward(ComputationGraph.java:1632)
	at org.deeplearning4j.nn.graph.ComputationGraph.feedForward(ComputationGraph.java:1545)
	at org.deeplearning4j.nn.graph.ComputationGraph.silentOutput(ComputationGraph.java:1762)
	at org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1748)
	at org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1711)
	at org.deeplearning4j.nn.graph.ComputationGraph.outputSingle(ComputationGraph.java:1786)
	at org.deeplearning4j.nn.graph.ComputationGraph.outputSingle(ComputationGraph.java:1699)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;    embed_input = Input(shape=(256, ), name='embed_input')
    embed_model = Embedding(input_dim=50, output_dim=128, input_length=128)(embed_input)
    embed_model = LSTM(128)(embed_model)
    embed_model = Dense(5)(embed_model)
    embed_model = Activation('sigmoid', name="activation_embed")(embed_model)
    mlp_input = Input(shape=(10, ), name='mlp_input')
    mlp_model = Dense(5)(mlp_input)
    mlp_model = Activation('sigmoid')(mlp_model)
    final = concatenate([embed_model, mlp_model], axis=-1)
    final = Dense(1)(final)
    final = Activation('sigmoid')(final)
    model = Model(inputs=[embed_input, mlp_input], outputs=final)
    model.compile(loss='binary_crossentropy',
                  optimizer='Adam',
                  metrics=['accuracy'])
&lt;/denchmark-code&gt;

Here is the relevant Java code:
&lt;denchmark-code&gt;ComputationGraph graph = KerasModelImport.importKerasModelAndWeights("embed_model.h5", false);

Random random = new Random();
double [] embed_arr = new double[256];
for(int i=0; i &lt; embed_arr.length; i++) {
	embed_arr[i] = random.nextInt(50);
}

INDArray embed_input = Nd4j.create(embed_arr).reshape(256, 1);

double [] mlp_arr = new double[10];
for(int i=0; i &lt; mlp_arr.length; i++) {
	mlp_arr[i] = random.nextInt();
}

INDArray mlp_input = Nd4j.create(mlp_arr);

INDArray result = graph.outputSingle(embed_input, mlp_input);
System.out.println(result);
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Expected Behavior&lt;/denchmark-h&gt;

Should make the prediction and output a single result
&lt;denchmark-h:h4&gt;Encountered Behavior&lt;/denchmark-h&gt;

Fails with IllegalStateException: Cannot merge activations with different number of examples (activations[0] shape: [256, 5], activations[1] shape: [1, 5]
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


deeplearning4j version 0.9.2-SNAPSHOT
Keras version: 2.1.1
Tensorflow version 1.4.0
Windows 10
No CUDA
No NVIDIA driver

	</description>
	<comments>
		<comment id='1' author='kullanici0606' date='2018-04-19T13:38:14Z'>
		&lt;denchmark-link:https://github.com/kullanici0606&gt;@kullanici0606&lt;/denchmark-link&gt;
 this one is similar to your other issue, the shapes aren't right. You reshape your embedding input to , which tells DL4J you want a mini-batch of size 256. But if I'm reading this correctly you want a batch size of 1 and hence embed a single sequence of 256 indices, followed up by an LSTM with 5 units, resulting in shape . This can then be concatenated to your other output.
I think you can solve this by reshaping the input of the embedding layer to (1, 1, 256). Closing for now, but let me know if it doesn't work so I can re-open.
		</comment>
		<comment id='2' author='kullanici0606' date='2018-04-20T06:53:49Z'>
		I think I was confused by the name and the difference between two frameworks. I tried it however I got the exception below. This may still be related to my lack of knowledge of the framework, so I will look at it. However, there is another issue. When I load model and get computational graph, it consumes more than 32gb memory and takes approximately 2 minutes. Is it normal?
The following part is taking time and allocation memory (initialization of LSTM layer):
    public static INDArray initWeights(double fanIn, double fanOut, int[] shape, WeightInit initScheme,
                    Distribution dist, char order, INDArray paramView) {
        switch (initScheme) {
            case DISTRIBUTION:
                dist.sample(paramView);
                break;
Thanks for your help.
Exception in thread "main" java.lang.IllegalStateException: Rank is 3 columns() call is not valid
	at org.nd4j.linalg.api.ndarray.BaseNDArray.columns(BaseNDArray.java:4469)
	at org.deeplearning4j.nn.layers.feedforward.embedding.EmbeddingLayer.preOutput(EmbeddingLayer.java:88)
	at org.deeplearning4j.nn.layers.feedforward.embedding.EmbeddingLayer.activate(EmbeddingLayer.java:121)
	at org.deeplearning4j.nn.graph.vertex.impl.LayerVertex.doForward(LayerVertex.java:105)
	at org.deeplearning4j.nn.graph.ComputationGraph.feedForward(ComputationGraph.java:1680)
	at org.deeplearning4j.nn.graph.ComputationGraph.feedForward(ComputationGraph.java:1566)
	at org.deeplearning4j.nn.graph.ComputationGraph.silentOutput(ComputationGraph.java:1835)
	at org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1895)
	at org.deeplearning4j.nn.graph.ComputationGraph.outputSingle(ComputationGraph.java:1868)
	at org.deeplearning4j.nn.graph.ComputationGraph.outputSingle(ComputationGraph.java:1854)
	at org.deeplearning4j.nn.graph.ComputationGraph.outputSingle(ComputationGraph.java:1772)
	at tr.gov.btk.DeepLearning.EmbedTest.main(EmbedTest.java:36)
		</comment>
		<comment id='3' author='kullanici0606' date='2018-04-20T07:44:14Z'>
		&lt;denchmark-link:https://github.com/kullanici0606&gt;@kullanici0606&lt;/denchmark-link&gt;
 can you tell me how you call this? hard to tell how this  call comes about.
		</comment>
		<comment id='4' author='kullanici0606' date='2018-04-20T07:50:13Z'>
		about the memory issue, just eyeballing this, your keras model is really small... so this seems excessive. so you're saying 32gb for the model pasted in your original message?
		</comment>
		<comment id='5' author='kullanici0606' date='2018-04-24T13:11:44Z'>
		Sorry for responding late, it was holiday in my country.
Yes. memory issue occurs when I try to load the model in the original message. When I load it to Keras, it consumes approximately 760mb memory.
For the first comment, I call like this:
KerasModelBuilder builder = new KerasModel().modelBuilder().modelHdf5Filename("embed_model.h5")
				.enforceTrainingConfig(false);
		
		KerasModel model = builder.buildModel();
		Random random = new Random();
		double [] embed_arr = new double[256];
		for(int i=0; i &lt; embed_arr.length; i++) {
			embed_arr[i] = random.nextInt(50);
		}

		INDArray embed_input = Nd4j.create(embed_arr).reshape(1, 1, 256);

		double [] mlp_arr = new double[10];
		for(int i=0; i &lt; mlp_arr.length; i++) {
			mlp_arr[i] = random.nextInt();
		}

		INDArray mlp_input = Nd4j.create(mlp_arr).reshape(1, 1, 10);

		INDArray result = model.getComputationGraph().outputSingle(embed_input, mlp_input);
		System.out.println(result);
		</comment>
		<comment id='6' author='kullanici0606' date='2018-04-30T03:30:06Z'>
		I've been also getting the same exception with the following toy model:
&lt;denchmark-code&gt;inputs = Input((5, ))
x = Embedding(10, 784, input_length=5, name='embedding_1')(inputs)
x = LSTM(64, activation='relu', return_sequences=True, name='lstm_1')(x)
predictions = TimeDistributed(Dense(10, activation='softmax', name='timedistributed_1'))(x)
model = Model(input=inputs, output=predictions)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;java.lang.IllegalStateException: Rank is 3 columns() call is not valid
	at org.deeplearning4j.nn.modelimport.keras.configurations.Keras1ModelConfigurationTest.forwardModelConfigTest(Keras1ModelConfigurationTest.java:184)
	at org.deeplearning4j.nn.modelimport.keras.configurations.Keras1ModelConfigurationTest.lstmTimeDistributedSoftmaxAPITest(Keras1ModelConfigurationTest.java:147)

&lt;/denchmark-code&gt;

I have noticed that, when the first layer of the model is an Input layer, dl4j infers the InputType of the imported model from the input shape of the Input layer. In consequence, for the previous case, as the Input layer is one-dimensional, the InputType inferred is InputTypeFeedForward instead of InputTypeRecurrent and this seems to be the cause of the exception.
I have tried the following patch that is working. I have added a new attribute (embOutBoundShape) to the KerasLayer class where I store the output shape of the embedding layer. Then, I have made the following change in the getOutputType method in the KerasInput class:
&lt;denchmark-code&gt;        switch (this.inputShape.length) {
            case 1:
		if (this.embOutBoundShape == null)
		    myInputType = new InputType.InputTypeFeedForward(this.inputShape[0]);
		else if (this.embOutBoundShape.length == 1)
		    myInputType = new InputType.InputTypeFeedForward(this.inputShape[0]);
		else
		    myInputType = new InputType.InputTypeRecurrent(this.inputShape[0]);
		break;

&lt;/denchmark-code&gt;

I am probably missing something and there are surely better ways to solve this, but I hope this can help.
		</comment>
		<comment id='7' author='kullanici0606' date='2018-05-03T15:00:16Z'>
		&lt;denchmark-link:https://github.com/EgoLaparra&gt;@EgoLaparra&lt;/denchmark-link&gt;
 thanks for this. We've been discussing internally and there's a PR inbound &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/pull/5033&gt;#5033&lt;/denchmark-link&gt;
 that will hopefully solve this once and for all. Under the hood there's a new layer called  that always produces RNN output.
		</comment>
		<comment id='8' author='kullanici0606' date='2018-05-28T22:32:33Z'>
		Sorry for the late response, I couldn't try the PR until today. The exception is still there, but now it is given by the EmbeddingSequenceLayer class:
&lt;denchmark-code&gt;java.lang.IllegalStateException: Rank is [3]; columns() call is not valid
    at org.nd4j.linalg.api.ndarray.BaseNDArray.columns (BaseNDArray.java:4867)
    at org.deeplearning4j.nn.layers.feedforward.embedding.EmbeddingSequenceLayer.preOutput (EmbeddingSequenceLayer.java:106)
    at org.deeplearning4j.nn.layers.feedforward.embedding.EmbeddingSequenceLayer.activate (EmbeddingSequenceLayer.java:156)
    at org.deeplearning4j.nn.graph.vertex.impl.LayerVertex.doForward (LayerVertex.java:105)
    at org.deeplearning4j.nn.graph.ComputationGraph.ffToLayerActivationsDetached (ComputationGraph.java:1804)
    at org.deeplearning4j.nn.graph.ComputationGraph.feedForward (ComputationGraph.java:1498)
    at org.deeplearning4j.nn.graph.ComputationGraph.feedForward (ComputationGraph.java:1488)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='kullanici0606' date='2018-09-21T23:24:20Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>