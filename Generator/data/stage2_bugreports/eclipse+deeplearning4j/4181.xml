<bug id='4181' author='Dathiou' open_date='2017-10-16T18:33:33Z' closed_time='2018-04-26T21:18:27Z'>
	<summary>Container failures while training</summary>
	<description>
EDIT 2:
It may be the consequence of a misconfigured kryo serializer (I've always had this warning and it used to be working even with this warning before). See warning:
&lt;denchmark-link:https://gist.github.com/Dathiou/adc09c2bd065f643fd60c2fc9b7f70a3&gt;https://gist.github.com/Dathiou/adc09c2bd065f643fd60c2fc9b7f70a3&lt;/denchmark-link&gt;

EDIT:
I removed ".workerPrefetchNumBatches(2) "from the definition of the training master and I didn''t see any containers failing this time. Not sure it is related. I will write updates as I run the jobs to try to understand what is causing it.
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Containers fail one by one during the training.
Initial error:
&lt;denchmark-code&gt;17/10/16 16:49:35 WARN YarnAllocator: Container marked as failed: container_1508169681417_0001_01_000034 on host: ****.
Exit status: 50. Diagnostics: Exception from container-launch.
Container id: container_1508169681417_0001_01_000034
Exit code: 50
Stack trace: ExitCodeException exitCode=50: 
    at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
    at org.apache.hadoop.util.Shell.run(Shell.java:479)
    at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
    at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
    at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)

Container exited with a non-zero exit code 50
&lt;/denchmark-code&gt;

Log of the specific container is here:
&lt;denchmark-link:https://gist.github.com/Dathiou/02ce5e1a0bb2110b8ac6cc0e9fdf0470&gt;https://gist.github.com/Dathiou/02ce5e1a0bb2110b8ac6cc0e9fdf0470&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

training master:
&lt;denchmark-code&gt;val tm = new ParameterAveragingTrainingMaster.Builder(1)
		.workerPrefetchNumBatches(2)    //Async prefetch 2 batches for each worker 
		.averagingFrequency(6)
		.batchSizePerWorker(1024)
		.saveUpdater(true)
		.build()
&lt;/denchmark-code&gt;



dl4j version: 0.9.1


AWS EMR cluster: 7 r4.4xlarge task nodes - 7 executors - 4 cores per exec - 90G of exec memory - driver memory: 5G



I tried several values of:
spark.yarn.executor.memoryOverhead=20480


the first part of the job is pre-processing data and is not related to dl4j.


I have tried to add: ".trainingWorkspaceMode(WorkspaceMode.SEPARATE)" but not difference


&lt;denchmark-link:https://user-images.githubusercontent.com/7745592/31628493-b35e85f8-b265-11e7-8192-10399e927b63.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Dathiou' date='2017-10-16T22:43:46Z'>
		The log message you're providing really look like the relatively benign &lt;denchmark-link:https://github.com/ronmamo/reflections/issues/80&gt;ronmamo/reflections#80&lt;/denchmark-link&gt;

It's probably a consequence of the  in your classpath.
What are the adverse behaviors you observe, aside of this polluting the logs? I can see the interrupted exception, but it's unclear to me that it would be related.
		</comment>
		<comment id='2' author='Dathiou' date='2017-10-16T23:22:30Z'>
		it seems to make the job much slower and more importantly, it fails after a certain amount of trials.
		</comment>
		<comment id='3' author='Dathiou' date='2017-10-16T23:25:16Z'>
		The Reflections constructor produces a trace of its scan with a loglevel of debug:
&lt;denchmark-link:https://github.com/ronmamo/reflections/blob/master/src/main/java/org/reflections/Reflections.java#L179&gt;https://github.com/ronmamo/reflections/blob/master/src/main/java/org/reflections/Reflections.java#L179&lt;/denchmark-link&gt;

would you mind turning that on in a test run?
I expect we'll learn a lot.
		</comment>
		<comment id='4' author='Dathiou' date='2017-10-17T03:19:50Z'>
		I set the level of the log to debug and got this:
&lt;denchmark-link:https://gist.github.com/Dathiou/a4c9e96a4a290924498e52b8a1fbddc4&gt;https://gist.github.com/Dathiou/a4c9e96a4a290924498e52b8a1fbddc4&lt;/denchmark-link&gt;

is it what you were looking for?
		</comment>
		<comment id='5' author='Dathiou' date='2018-03-26T03:17:33Z'>
		I have the similar bug as &lt;denchmark-link:https://github.com/Dathiou&gt;@Dathiou&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/huitseeker&gt;@huitseeker&lt;/denchmark-link&gt;
 can you explain it and solve the bug?
		</comment>
		<comment id='6' author='Dathiou' date='2018-03-26T23:44:08Z'>
		&lt;denchmark-link:https://github.com/hy-2013&gt;@hy-2013&lt;/denchmark-link&gt;
 "similar" doesn't mean it's the same. Perhaps open a new issue with your ntetwork and full configuration. We can't say much without that information.
		</comment>
		<comment id='7' author='Dathiou' date='2018-04-26T21:18:27Z'>
		Closing due to inactivity. Feel free to file new issue if you'll have updates.
		</comment>
		<comment id='8' author='Dathiou' date='2018-09-22T13:13:50Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>