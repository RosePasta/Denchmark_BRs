<bug id='1166' author='akioWS' open_date='2016-02-18T14:57:53Z' closed_time='2016-02-23T17:38:44Z'>
	<summary>Standalone and Spark's Word2Vec giving very different results</summary>
	<description>
I've extensively talked to &lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 about this over gitter, and we have not found the problem yet, so he asked me to file an issue.
I ran both standalone and spark's version of Word2Vec (using rc3.9-SNAPSHOT, where both have similiar Builder API), and running for exactly the same setup the spark returns a bad model (using wordsNearest to take a look a the result), where I expected a very similar result.
For experimenting, I ran for a &lt;denchmark-link:https://dl.dropboxusercontent.com/u/14190231/word2vec/part-00000&gt;fraction of my data&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://gist.github.com/akioWS/7fe38bc53d6079baeb74&gt;Here is the standalone&lt;/denchmark-link&gt;
 code and &lt;denchmark-link:https://gist.github.com/akioWS/2d4f0bf5be941f63c85b&gt;here the spark one&lt;/denchmark-link&gt;
.
I've also used the &lt;denchmark-link:https://github.com/deeplearning4j/dl4j-0.4-examples/blob/master/src/main/resources/raw_sentences.txt&gt;raw_sentences&lt;/denchmark-link&gt;
 from the DL4j's test, and the result looks good. So &lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 and I are assuming the problem is in how the spark's model deals with this corpus, somehow it is doing something wrong processing it. Both cases were trained on Ubuntu on similar setups, so possible encoding problems due to OS were initially discarded.
The training setup was:
val batchSize = 10
val minCount = 5
val vectorSize = 100
val maxIter = 1
val learningRate = 0.03
val minLearningRate = 1e-3
Following the results for standalone model:
&lt;denchmark-code&gt;Local Word2Vec predictions for day:removed, someone, thousands, departure, automatically
Local Word2Vec predictions for google:twitter, instrigam, instagram, bing, adsense
Local Word2Vec predictions for davi:filho, abraao, isaque, cordeiro, patriarca
Local Word2Vec predictions for ccbb:enomoto, spdata, expominas, satyros, rebou
Local Word2Vec predictions for carro:caminhao, veiculo, carreta, camionete, colisao
&lt;/denchmark-code&gt;

And here for the spark model:
&lt;denchmark-code&gt;Spark Word2Vec predictions for day:twittam, every, incoming, automatically, thousands
Spark Word2Vec predictions for google:twittam, linkedin, adsense, twitter, feedfetcher
Spark Word2Vec predictions for davi:twittam, cordeiro, profecia, guerreiro, profeta
Spark Word2Vec predictions for ccbb:twittam, buritizal, holambra, severinia, canabrava
Spark Word2Vec predictions for carro:twittam, onibus, parou, silencioso, guindaste
&lt;/denchmark-code&gt;

Observe the weird presence of twittam (which has nothing to do with any of the words) in all cases.
	</description>
	<comments>
		<comment id='1' author='akioWS' date='2016-02-23T14:18:23Z'>
		Can you confirm or decline similarity of these two samples?
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Words close to [carro]:
'veiculo': [0.5011561309688267], 'poste': [0.49600510032930917], 'fusca': [0.43890815519041987], 'acidente': [0.4386222098992436], 'vertiginosa': [0.42702386708819745], 'acordou': [0.4214829493287974], 'loto': [0.4078695209393579], 'onibus': [0.40625408921067063], 'automovel': [0.4051085725464383], 'engasgar': [0.403963355163064],
Words close to [davi]:
'isaque': [0.524592245250934], 'reinado': [0.5087225117810947], 'unigenito': [0.5076461979776153], 'cume': [0.49560491240369486], 'sobrinho': [0.4931079420052272], 'guerreiro': [0.49286920990399263], 'marambaia': [0.48232677988817035], 'entregou': [0.47962641572153863], 'ordenou': [0.47719913955752125], 'pilatos': [0.46938706397512125],
		</comment>
		<comment id='2' author='akioWS' date='2016-02-23T14:24:57Z'>
		Yeah, it looks reasonable. For carro is a bit better (veiculo, fusca, onibus, automovel, are spot on), for davi not so much, but I do expect to davi be a little harder to contextualize.
		</comment>
		<comment id='3' author='akioWS' date='2016-02-23T14:26:40Z'>
		it's impossible to have proper model with given corpus without preprocessing over it: too much meaningless noise there.
But besides that fact: yes, bug was reproduced &amp; confirmed. Working on it right now.
		</comment>
		<comment id='4' author='akioWS' date='2016-02-23T14:27:21Z'>
		p.s. if you want, there's quick workaround available in rc3.9-SNAPSHOT
		</comment>
		<comment id='5' author='akioWS' date='2016-02-23T14:32:23Z'>
		Yeah, I agree with the noise, I've implemented some pre-processor to help cleaning it a bit better.
I'd like to know a bit better what this bug was all about, and a quick workaround would also be nice, I can double check here if it indeed fixes the problem. You can send be over gitter if you want to avoid noise here, your call.
Nice job!
		</comment>
		<comment id='6' author='akioWS' date='2016-02-23T14:33:55Z'>
		Quick workaround is simple. Just add this 1 line after train() method:
word2Vec.setModelUtils(new FlatModelUtils());
		</comment>
		<comment id='7' author='akioWS' date='2016-02-23T17:31:50Z'>
		Please confirm this set of results, since i still don't know portugese:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Words close to [carro]:
'biarticulado': [0.4280869097482694], 'veiculo': [0.4204754150127981], 'sai': [0.3906924201697397], 'coloca': [0.3893799561679503], 'bate': [0.3890235726874756], 'rapaz': [0.3870361561204033], 'vizinho': [0.3795371046712031], 'perdedor': [0.37789292514915573], 'acordou': [0.3772743216432384], 'destino': [0.37528346942943686],
Words close to [davi]:
'conjuro': [0.5729328503176958], 'fostes': [0.5058748376625273], 'dizeis': [0.5037745328298058], 'dizendo': [0.5000788253872341], 'josue': [0.4990717470865972], 'acautelai': [0.49777733526189955], 'achado': [0.49257870455694286], 'vigiai': [0.4922747008237263], 'abraao': [0.4867526086920113], 'esau': [0.4861343664684656],
		</comment>
		<comment id='8' author='akioWS' date='2016-02-23T17:36:52Z'>
		Probably your issue is fixed here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/1133&gt;https://github.com/deeplearning4j/deeplearning4j/pull/1133&lt;/denchmark-link&gt;

Since i get pretty similar results from both modelreaders, but i'd like to have your confirmation first :)
p.s. roots of this issue is definitely weird corpus with bad formatting, and mixture of languages and domains.
p.s. feel free to reopen issue if something is wrong there :)
		</comment>
		<comment id='9' author='akioWS' date='2016-02-23T18:02:40Z'>
		I don't think the last result is good enough, the one before that looked better. I'll run more tests with your suggested fix and I'll reopen it if I find necessary.
Thanks!
		</comment>
		<comment id='10' author='akioWS' date='2016-02-23T18:54:24Z'>
		To obtain good results you'll need to apply proper preprocessing to your corpus, since right now it's just a bunch of meaningless lines of text mostly. At least that part you shared with me.
		</comment>
		<comment id='11' author='akioWS' date='2019-01-21T09:38:04Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>