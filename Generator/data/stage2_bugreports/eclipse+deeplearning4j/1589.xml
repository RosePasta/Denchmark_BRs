<bug id='1589' author='Habitats' open_date='2016-05-24T01:40:19Z' closed_time='2016-06-05T14:42:23Z'>
	<summary>Logger complaining about l1/l2, when it's not even in the config</summary>
	<description>
I get this message quite often:
WARN  - Layer not named l1 or l2 has been added to configuration but useRegularization is set to false.
Config:
    val conf = new NeuralNetConfiguration.Builder()
      .seed(123)
      .iterations(1)
      .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
      .learningRate(learningRate)
      .updater(Updater.RMSPROP)
      .weightInit(WeightInit.XAVIER)
      .list()
      .layer(0, new DenseLayer.Builder()
        .nIn(numInputs)
        .nOut(firstLayer)
        .activation("tanh")
        .build()
      )
      .layer(1, new DenseLayer.Builder()
        .nIn(firstLayer)
        .nOut(secondLayer)
        .activation("tanh")
        .build()
      )
      .layer(2, new OutputLayer.Builder(LossFunctions.LossFunction.MCXENT)
        .activation("softmax")
        .nIn(secondLayer)
        .nOut(numOutputs)
        .build()
      )
      .pretrain(false)
      .backprop(true)
      .build()
	</description>
	<comments>
		<comment id='1' author='Habitats' date='2016-05-31T19:12:09Z'>
		I am facing same issue. Using deeplearning4j-core-0.4-rc3.9
		</comment>
		<comment id='2' author='Habitats' date='2016-06-05T14:42:23Z'>
		Fixed: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/1645&gt;https://github.com/deeplearning4j/deeplearning4j/pull/1645&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Habitats' date='2019-01-21T00:53:20Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>