<bug id='3649' author='andr3a87' open_date='2017-07-10T08:47:11Z' closed_time='2017-07-10T09:09:42Z'>
	<summary>InferenceMode.BATCHED does not work</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Please describe our issue, along with:

expected behavior: app run
encountered behavior: exception

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j version: 0.8.1-SNAPSHOT
platform information (OS, etc): ubuntu 17.04
CUDA version, if used:  8.0
NVIDIA driver version, if in use

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

val network = ModelSerializer.restoreComputationGraph(netPath, true)
val inf = new ParallelInference.Builder(network)
.inferenceMode(InferenceMode.BATCHED)
.batchLimit(10)
.workers(4)
.build()
images.par.foreach( img: opencv_core.Mat =&gt;
val indarray_reg = new NativeImageLoader().asMatrix(img)
val pred: INDArray = inf.output(indarray_reg)
)
Exception: "Got rank 5 array as input to ConvolutionLayer (layer name = block1_conv1, layer index = 1) with shape [5, 1, 3, 224, 224]. Expected rank 4 array with shape [minibatchSize, layerInputDepth, inputHeight, inputWidth]."
if I remove .par from collection images it work. If I use InferenceMode.SEQUENTIAL it work.
	</description>
	<comments>
		<comment id='1' author='andr3a87' date='2017-07-10T08:59:30Z'>
		Looks like Nd4j.pile() bug. Fix incoming.
		</comment>
		<comment id='2' author='andr3a87' date='2017-07-10T09:09:42Z'>
		Fixed, thanks for highlighting this issue.
		</comment>
		<comment id='3' author='andr3a87' date='2018-09-26T04:57:33Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>