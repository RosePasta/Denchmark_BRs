<bug id='3420' author='sethah' open_date='2017-05-16T22:45:04Z' closed_time='2017-07-14T13:06:03Z'>
	<summary>[SPARK] Null pointer exception using learning rate schedule on Spark</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Ran with the following code:
val confBuilder = new NeuralNetConfiguration.Builder()
        .seed(params.seed)
        .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
        .iterations(1)
        .activation(Activation.SOFTMAX)
        .weightInit(WeightInit.XAVIER)
        .learningRate(params.learningRate)
        .learningRateDecayPolicy(LearningRatePolicy.Schedule)  
        .learningRateSchedule(schedule)  
        .updater(params.updater)
        .momentum(params.momentum)
        .regularization(true)
        .l2(params.regularization)
        .graphBuilder()
        .addLayer("predictions",
          new OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD)
            .activation(Activation.SOFTMAX)
            .nIn(4096)
            .nOut(257)
            .build(),
          "in")
        .setOutputs("predictions")
        .addInputs("in")
        .backprop(true)
        .pretrain(false)
        .build()
      val graph = new ComputationGraph(conf)
      val tm = new ParameterAveragingTrainingMaster.Builder(1)
        .averagingFrequency(params.averagingFrequency)
        .workerPrefetchNumBatches(2)
        .batchSizePerWorker(params.batchSizePerWorker)
        .rddTrainingApproach(RDDTrainingApproach.Export)
        .build()
     val model = new SparkComputationGraph(sc, graph, tm)
(0 until params.numEpochs).foreach { i =&gt;
  model.fit(rdd)
}
Spark submit args
&lt;denchmark-code&gt;spark2-submit \
--master yarn \
--deploy-mode client \
--conf spark.driver.extraJavaOptions="-XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Dorg.bytedeco.javacpp.maxretries=100 -Dorg.bytedeco.javacpp.maxbytes=13000000000" \
--conf spark.executor.extraJavaOptions="-XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Dorg.bytedeco.javacpp.maxretries=100 -Dorg.bytedeco.javacpp.maxbytes=13000000000" \
--conf spark.locality.wait=0 \
--conf spark.driver.maxResultSize=10g \
--conf spark.yarn.executor.memoryOverhead=15g \
--conf spark.yarn.driver.memoryOverhead=15g \
--conf spark.executor.cores=8 \
--conf spark.kryo.registrator=org.nd4j.Nd4jRegistrator \
--conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
--conf spark.kryoserializer.buffer.max=2047m \
--executor-memory 10g \
--driver-memory 10g \
--num-executors=5 \
&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;Caused by: com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException
Serialization trace:
learningRateSchedule (org.deeplearning4j.nn.conf.layers.BatchNormalization)
layer (org.deeplearning4j.nn.conf.NeuralNetConfiguration)
layerConf (org.deeplearning4j.nn.conf.graph.LayerVertex)
vertices (org.deeplearning4j.nn.conf.ComputationGraphConfiguration)
graphConfiguration (org.deeplearning4j.spark.api.worker.NetBroadcastTuple)
	at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144)
	at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j version: 0.8.0
platform information (OS, etc): CentOS Linux 7 (Core)
Spark 2.1.0
YARN cluster manager, on top of CDH

	</description>
	<comments>
		<comment id='1' author='sethah' date='2017-05-16T22:45:12Z'>
		cc &lt;denchmark-link:https://github.com/huitseeker&gt;@huitseeker&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='sethah' date='2017-07-03T15:07:19Z'>
		i also have such issues.
run with following code:
&lt;denchmark-code&gt;int batchSizePerWorker=Integer.parseInt(settings.getProperty("batchSizePerWorker","16"));
        int numEpochs =Integer.parseInt(settings.getProperty("numEpochs","1"));

        //Load the data into memory then parallelize

        //This isn't a good approach in general - but is simple to use for this example
        DataSetIterator iterTrain = new MnistDataSetIterator(batchSizePerWorker, true, 12345);
        DataSetIterator iterTest = new MnistDataSetIterator(batchSizePerWorker, true, 12345);
        List&lt;DataSet&gt; trainDataList = new ArrayList&lt;&gt;();
        List&lt;DataSet&gt; testDataList = new ArrayList&lt;&gt;();
        while (iterTrain.hasNext()) {
            trainDataList.add(iterTrain.next());
        }
        while (iterTest.hasNext()) {
            testDataList.add(iterTest.next());
        }



        JavaRDD&lt;DataSet&gt; trainData = sc.parallelize(trainDataList);
        JavaRDD&lt;DataSet&gt; testData = sc.parallelize(testDataList);


        //----------------------------------
        //Create network configuration and conduct network training
        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(12345)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT).iterations(1)
                .activation(Activation.LEAKYRELU)
                .weightInit(WeightInit.XAVIER)
                .learningRate(0.02)
                .updater(Updater.NESTEROVS).momentum(0.9)
                .regularization(true).l2(1e-4)
                .list()
                .layer(0, new DenseLayer.Builder().nIn(28 * 28).nOut(500).build())
                .layer(1, new DenseLayer.Builder().nIn(500).nOut(100).build())
                .layer(2, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                        .activation(Activation.SOFTMAX).nIn(100).nOut(10).build())
                .pretrain(false).backprop(true)
                .build();

        //Configuration for Spark training: see http://deeplearning4j.org/spark for explanation of these configuration options
        TrainingMaster tm = new ParameterAveragingTrainingMaster.Builder(batchSizePerWorker)    //Each DataSet object: contains (by default) 32 examples
                .averagingFrequency(5)
                .workerPrefetchNumBatches(0)            //Async prefetching: 2 examples per worker
                .batchSizePerWorker(batchSizePerWorker)
                .storageLevel(StorageLevel.MEMORY_AND_DISK_SER())

                .build();

        //Create the Spark network
        SparkDl4jMultiLayer sparkNet = new SparkDl4jMultiLayer(sc, conf, tm);

        //Execute training:
        for (int i = 0; i &lt; numEpochs; i++) {
            sparkNet.fit(trainData);
            log.info("Completed Epoch {}", i);
        }

        //Perform evaluation (distributed)
        Evaluation evaluation = sparkNet.evaluate(testData);
        log.info("***** Evaluation *****");
        log.info(evaluation.stats());

        //Delete the temp training files, now that we are done with them
        tm.deleteTempFiles(sc);

        log.info("***** Example Complete *****");
&lt;/denchmark-code&gt;

ERROR:
&lt;denchmark-code&gt;17/07/03 22:37:08 ERROR TaskResultGetter: Exception while getting task result
com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException
Serialization trace:
matrix (org.deeplearning4j.eval.ConfusionMatrix)
confusion (org.deeplearning4j.eval.Evaluation)
        at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:144)
        at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
        at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
        at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
        at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:551)
        at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
        at com.twitter.chill.SomeSerializer.read(SomeSerializer.scala:25)
        at com.twitter.chill.SomeSerializer.read(SomeSerializer.scala:19)
        at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790)
        at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:327)
        at org.apache.spark.scheduler.DirectTaskResult.value(TaskResult.scala:88)
        at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:72)
        at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
        at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
        at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NullPointerException
        at java.util.Collections$SynchronizedMap.put(Collections.java:2588)
        at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:162)
        at com.esotericsoftware.kryo.serializers.MapSerializer.read(MapSerializer.java:39)
        at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:708)
        at com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)
        ... 18 more
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='sethah' date='2017-07-04T01:24:53Z'>
		&lt;denchmark-link:https://github.com/huitseeker&gt;@huitseeker&lt;/denchmark-link&gt;
  how this issues going?
		</comment>
		<comment id='4' author='sethah' date='2017-07-04T01:34:10Z'>
		&lt;denchmark-link:https://github.com/jasstionzyf&gt;@jasstionzyf&lt;/denchmark-link&gt;
 I'll take a look at this today
		</comment>
		<comment id='5' author='sethah' date='2017-07-04T01:45:13Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
  thanks very much, it seems spark kryo shaded jar has confilicts with nd4j-kryo_2.11 (0.8.1-SNAPSHOT)
		</comment>
		<comment id='6' author='sethah' date='2017-07-04T02:02:10Z'>
		&lt;denchmark-link:https://github.com/jasstionzyf&gt;@jasstionzyf&lt;/denchmark-link&gt;
 Could I also have your full pom.xml file to help reproduce/debug this?
EDIT: nevermind, I've been able to reproduce this on snapshots.
FYI I suspect it might be a separate issue to &lt;denchmark-link:https://github.com/sethah&gt;@sethah&lt;/denchmark-link&gt;
 - I'll look into that next though.
		</comment>
		<comment id='7' author='sethah' date='2017-07-04T02:46:20Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
  ok, anyway &lt;denchmark-link:https://gist.github.com/jasstionzyf/9f0784c04c1a579182dcd144abb2da4a&gt;https://gist.github.com/jasstionzyf/9f0784c04c1a579182dcd144abb2da4a&lt;/denchmark-link&gt;
   this is my all pom,  it all use 0.8.1-snapshot
		</comment>
		<comment id='8' author='sethah' date='2017-07-04T02:52:49Z'>
		Turns out: This is just Kryo failing on synchronized maps: this (with kryo configured) is enough to reproduce it...
&lt;denchmark-code&gt;        Map&lt;Object,Object&gt; m = Collections.synchronizedMap(new HashMap&lt;&gt;());
        m.put("Key", "Value");
        SerializerInstance si = sc.env().serializer().newInstance();
        ByteBuffer bb = si.serialize(m, null);
        Map&lt;Object,Object&gt; m2 = si.deserialize(bb, null);
&lt;/denchmark-code&gt;

The (well, one possible) fix is easy enough - don't use synchronized maps - but I'll do a more thorough check on other classes that Kryo would serialize during the course of training.
		</comment>
		<comment id='9' author='sethah' date='2017-07-04T03:52:07Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 Could we just reuse &lt;denchmark-link:https://github.com/magro/kryo-serializers&gt;https://github.com/magro/kryo-serializers&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='10' author='sethah' date='2017-07-04T05:17:21Z'>
		&lt;denchmark-link:https://github.com/huitseeker&gt;@huitseeker&lt;/denchmark-link&gt;
 fyi: &lt;denchmark-link:https://github.com/deeplearning4j/nd4j/pull/1913/files&gt;https://github.com/deeplearning4j/nd4j/pull/1913/files&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/jasstionzyf&gt;@jasstionzyf&lt;/denchmark-link&gt;
 Fix is tested + merged to master
&lt;denchmark-link:https://github.com/sethah&gt;@sethah&lt;/denchmark-link&gt;
 I've been unable to reproduce your specific issue - I suspect it may depend on the specific type of map you are using for the learning rate schedule (but that isn't provided in the issue). Can you provide that - or at least enough that I can run/reproduce it?
Alternatively, try testing on snapshots - it's possible I've caught the issue with some of the kryo changes I've made.
		</comment>
		<comment id='11' author='sethah' date='2017-07-14T13:06:03Z'>
		Closing this due to inactivity + being unable to reproduce.
&lt;denchmark-link:https://github.com/sethah&gt;@sethah&lt;/denchmark-link&gt;
 If you still have a problem, we can re-open this and I can look into it more.
		</comment>
		<comment id='12' author='sethah' date='2018-09-26T01:57:36Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>