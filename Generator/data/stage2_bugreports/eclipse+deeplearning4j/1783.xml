<bug id='1783' author='ghost(ghost)' open_date='2016-07-05T11:23:31Z' closed_time='2017-02-28T09:33:01Z'>
	<summary>Persistence issue (Spark) when Serialization is disabled (aka .cache()) and allegedly unnecessary re-caching</summary>
	<description>

It appears that a Memory-Serialized RDD[DataSet] of ~300MB will become ~60GB if cached Memory-DE-Serialized.
By using the SparkDl4jMultiLayer binding to spark, the original dataset (points) gets re-cached into memory on each epoch, despite being already cached, deserialized (I get the reason behind it, but I guess nd4j objects are poorly cached when deserialized). As far as I understand, there is basically no reason to re-cache the original dataset, as it actually stays as is across all epochs, and what actually changes is the network's weights.

	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2019-01-19T12:20:19Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>