<bug id='5416' author='raver119' open_date='2018-06-01T02:08:58Z' closed_time='2018-10-30T07:00:12Z'>
	<summary>Aeron MaxMessageLength limit</summary>
	<description>
Aeron has own max message length limit, which prevents sending messages with length above some threshold (rather small actually)
&lt;denchmark-link:https://github.com/eclipse/deeplearning4j-examples/issues/628&gt;eclipse/deeplearning4j-examples#628&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='raver119' date='2018-07-05T10:05:21Z'>
		OK, so I ran into this while training on Spark, thought I would try to gain some insights here
We have a few issues here:
Global max message length is 16MB: &lt;denchmark-link:https://github.com/real-logic/aeron/blob/ab56167dfa2b4ac939ff3c2ffc83a8d4d4208da7/aeron-client/src/main/java/io/aeron/logbuffer/FrameDescriptor.java#L53-L57&gt;https://github.com/real-logic/aeron/blob/ab56167dfa2b4ac939ff3c2ffc83a8d4d4208da7/aeron-client/src/main/java/io/aeron/logbuffer/FrameDescriptor.java#L53-L57&lt;/denchmark-link&gt;

Below that, it's a function of the term buffer length
According to my testing and the link below, it's term buffer length / 8:
Term buffer of 32MB: max message 4MB.
&lt;denchmark-link:https://github.com/real-logic/aeron/blob/ab56167dfa2b4ac939ff3c2ffc83a8d4d4208da7/aeron-client/src/main/java/io/aeron/logbuffer/FrameDescriptor.java#L109-L118&gt;https://github.com/real-logic/aeron/blob/ab56167dfa2b4ac939ff3c2ffc83a8d4d4208da7/aeron-client/src/main/java/io/aeron/logbuffer/FrameDescriptor.java#L109-L118&lt;/denchmark-link&gt;

So the naive solution here is to increase term buffer length to give us a 16MB max message length (8*16=128MB term buffer).
(Note that it must be exactly a power of 2: &lt;denchmark-link:https://github.com/real-logic/Aeron/wiki/Configuration-Options&gt;https://github.com/real-logic/Aeron/wiki/Configuration-Options&lt;/denchmark-link&gt;
)
However, memory requirements seem to be a multiple of the term buffer... I was seeing a single log buffer of around 400mb when set to 128mb; 800mb when set to 256mb: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/5814&gt;https://github.com/deeplearning4j/deeplearning4j/issues/5814&lt;/denchmark-link&gt;

I can't find any details on hard requirements (I don't even know if this is depends on configuration, it probably does)
only thing close is a "12x term buffer memory requirement" for akka: &lt;denchmark-link:https://github.com/akka/akka/issues/21923#issuecomment-264707476&gt;akka/akka#21923 (comment)&lt;/denchmark-link&gt;

If that generalizes (again, no idea if it does) we'd need 1.5GB.
Edit: after restarting the driver, looks like it's happy to run with a term buffer of 128MB. Total /dev/shm use is 6.1GB during training; no idea how much of that is Aeron-related. (but we can test that by altering term buffer size with the same net config)
Network is Resnet50, approx. 25M parameters.
		</comment>
		<comment id='2' author='raver119' date='2018-07-06T23:19:05Z'>
		As discussed in pm:
during N-rank implementation, we could just implement chunked messaging, and in this case we won't need longer messages at all.
		</comment>
		<comment id='3' author='raver119' date='2018-10-30T07:00:12Z'>
		Chunked messaging add a while ago now.
		</comment>
		<comment id='4' author='raver119' date='2018-11-29T07:13:48Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>