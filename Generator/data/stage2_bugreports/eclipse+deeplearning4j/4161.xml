<bug id='4161' author='eypros' open_date='2017-10-11T13:29:50Z' closed_time='2019-11-10T15:04:03Z'>
	<summary>setting workspace value is not responding in transfer learning</summary>
	<description>
I have tried to modify the code of EditLastLayerOthersFrozen.java so as not to use deprecated classes.
So, I changes just the few lines involving ZooModel. Other lines of code are essentially untouched (there are few minor changes).
The model imported is VGG16 and the first run gave out of memory exception. Even assigning 10G was not enough to execute all iterations. (I don't know if it's natural since the fully untrained model VGG16 required 14G to be trained). Anyway I tried changing the workspaces being used (after some remarks made).
The problem is that setting the workspace values was not the expected one.
1st remark:
Using new VGG16(numClasses, seed, 1, WorkspaceMode.SEPARATE); instead of new VGG16(); passes the parameter to zooModel as I could examine in dedugger but it was lost in ComputationGraph pretrainedNet.
2nd remark:
I tried invoking the parameter in various places and they all work as expected

just after TransferLearning.GraphBuilder(pretrainedNet)
after the build(); of ComputationGraph as vgg16Transfer.getConfiguration().setTrainingWorkspaceMode(WorkspaceMode.SINGLE); and
As ComputationGraphConfiguration conf  = vgg16Transfer.getConfiguration(); conf.setTrainingWorkspaceMode(WorkspaceMode.SEPARATE);

Of course they do not propagate those changes and this is the expected behavior (at first I was just checking the info messages and could not see any changes). I just notice the message:

o.d.n.g.ComputationGraph - Starting ComputationGraph with WorkspaceModes set to [training: NONE; inference: SINGLE]
and interpret it as the final convgraph configuration.
So, the problem is that the constructor does not pass it's parameters correctly.

&lt;denchmark-code&gt;package org.deeplearning4j.examples.transferlearning.vgg16;

import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.examples.transferlearning.vgg16.dataHelpers.FlowerDataSetIterator;
import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.WorkspaceMode;
import org.deeplearning4j.nn.conf.distribution.NormalDistribution;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.graph.ComputationGraph;
import org.deeplearning4j.nn.modelimport.keras.InvalidKerasConfigurationException;
import org.deeplearning4j.nn.modelimport.keras.UnsupportedKerasConfigurationException;
import org.deeplearning4j.nn.transferlearning.FineTuneConfiguration;
import org.deeplearning4j.nn.transferlearning.TransferLearning;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.zoo.PretrainedType;
import org.deeplearning4j.zoo.ZooModel;
import org.deeplearning4j.zoo.model.VGG16;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.nd4j.linalg.lossfunctions.LossFunctions;
import org.slf4j.Logger;

import java.io.IOException;

/**
 * @author susaneraly on 3/9/17.
 *
 * We use the transfer learning API to construct a new model based of org.deeplearning4j.transferlearning.vgg16
 * We will hold all layers but the very last one frozen and change the number of outputs in the last layer to
 * match our classification task.
 * In other words we go from where fc2 and predictions are vertex names in org.deeplearning4j.transferlearning.vgg16
 *  fc2 -&gt; predictions (1000 classes)
 *  to
 *  fc2 -&gt; predictions (5 classes)
 * The class "FitFromFeaturized" attempts to train this same architecture the difference being the outputs from the last
 * frozen layer is presaved and the fit is carried out on this featurized dataset.
 * When running multiple epochs this can save on computation time.
 */
public class EditLastLayerOthersFrozen2Issue {
    private static final Logger log = org.slf4j.LoggerFactory.getLogger(EditLastLayerOthersFrozen2Issue.class);

    protected static final int numClasses = 5;
    protected static final long seed = 12345;

    private static final int trainPerc = 80;
    private static final int batchSize = 15;
    private static final String featureExtractionLayer = "fc2";

    public static void main(String [] args) throws UnsupportedKerasConfigurationException, IOException, InvalidKerasConfigurationException {

        //Import vgg
        //Note that the model imported does not have an output layer (check printed summary)
        //  nor any training related configs (model from keras was imported with only weights and json)
        // the following code is deprecated and replaced by the new classes
/*
        TrainedModelHelper modelImportHelper = new TrainedModelHelper(TrainedModels.VGG16);
        log.info("\n\nLoading org.deeplearning4j.transferlearning.vgg16...\n\n");
        ComputationGraph vgg16 = modelImportHelper.loadModel();
*/
        ZooModel zooModel =
//            new VGG16();
            new VGG16(numClasses, seed, 1, WorkspaceMode.SEPARATE);
        ComputationGraph pretrainedNet = (ComputationGraph) zooModel.initPretrained(PretrainedType.IMAGENET);
        System.out.println("Workspace in initiation: " + pretrainedNet.getConfiguration().getTrainingWorkspaceMode());

        log.info(pretrainedNet.summary());

        //Decide on a fine tune configuration to use.
        //In cases where there already exists a setting the fine tune setting will
        //  override the setting for all layers that are not "frozen".
        FineTuneConfiguration fineTuneConf = new FineTuneConfiguration.Builder()
            .learningRate(5e-5)
            .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
            .updater(Updater.NESTEROVS)
            .seed(seed)
            .build();

        //Construct a new model with the intended architecture and print summary
        ComputationGraph vgg16Transfer = new TransferLearning.GraphBuilder(pretrainedNet)
//            .setWorkspaceMode(WorkspaceMode.SEPARATE) //this doesn't seem to have any effect attempt #1
            .fineTuneConfiguration(fineTuneConf)
            .setFeatureExtractor(featureExtractionLayer) //the specified layer and below are "frozen"
            .removeVertexKeepConnections("predictions") //replace the functionality of the final vertex
            .addLayer("predictions",
                new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)
                    .nIn(4096).nOut(numClasses)
                    .weightInit(WeightInit.DISTRIBUTION)
                    .dist(new NormalDistribution(0,0.2*(2.0/(4096+numClasses)))) //This weight init dist gave better results than Xavier
                    .activation(Activation.SOFTMAX).build(),
                "fc2")
            .build();
        System.out.println("Workspace before: " + vgg16Transfer.getConfiguration().getTrainingWorkspaceMode());

        // also tried with no luck attempt #2
        vgg16Transfer.getConfiguration().setTrainingWorkspaceMode(WorkspaceMode.SEPARATE);
        vgg16Transfer.getConfiguration().setInferenceWorkspaceMode(WorkspaceMode.SEPARATE);

        // set workspaces //these also don't seem to have any effect attempt #3
//        ComputationGraphConfiguration conf  = vgg16Transfer.getConfiguration();
//        conf.setTrainingWorkspaceMode(WorkspaceMode.SEPARATE);
//        conf.setInferenceWorkspaceMode(WorkspaceMode.SEPARATE);

        System.out.println("Workspace after: " + vgg16Transfer.getConfiguration().getTrainingWorkspaceMode());

        log.info(vgg16Transfer.summary());

        //Dataset iterators
        FlowerDataSetIterator.setup(batchSize,trainPerc);
        DataSetIterator trainIter = FlowerDataSetIterator.trainIterator();
        DataSetIterator testIter = FlowerDataSetIterator.testIterator();

        Evaluation eval;
        eval = vgg16Transfer.evaluate(testIter);
        log.info("Eval stats BEFORE fit.....");
        log.info(eval.stats() + "\n");
        testIter.reset();

        int iter = 0;
        while(trainIter.hasNext()) {
            vgg16Transfer.fit(trainIter.next());
            if (iter % 10 == 0) {
                log.info("Evaluate model at iter "+iter +" ....");
                eval = vgg16Transfer.evaluate(testIter);
                log.info(eval.stats());
                testIter.reset();
            }
            iter++;
        }

        log.info("Model build complete");
    }
}

&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


Deeplearning4j 0.9.1
platform information Win7
CUDA no

	</description>
	<comments>
	</comments>
</bug>