<bug id='4291' author='schrum2' open_date='2017-11-13T04:02:55Z' closed_time='2017-11-29T03:26:32Z'>
	<summary>Layers do not clear inputs, even when they are invalidated by workspaces</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

This short code gist runs VGG16 with image net weights and then tries to analyze the intermediate activation of a particular layer:
&lt;denchmark-link:https://gist.github.com/schrum2/254dec555ba6908c8f8a21f3141e023c&gt;https://gist.github.com/schrum2/254dec555ba6908c8f8a21f3141e023c&lt;/denchmark-link&gt;

I have successfully used VGG16 before, but only the final outputs. However, when I run this code, it crashes with a Fatal Error:
&lt;denchmark-link:https://gist.github.com/schrum2/1cc1fb41971c9a4d0a284f366ecc7706&gt;https://gist.github.com/schrum2/1cc1fb41971c9a4d0a284f366ecc7706&lt;/denchmark-link&gt;

The full error contents of the error report file are here:
&lt;denchmark-link:https://gist.github.com/schrum2/5e47cf3d7023b8d06b5291f6d0e38943&gt;https://gist.github.com/schrum2/5e47cf3d7023b8d06b5291f6d0e38943&lt;/denchmark-link&gt;

It's possible I'm using the activate() method wrong, but even if I am, it seems in appropriate to receive a fatal error rather than a more straight forward exception.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j version: 0.9.1
platform information (OS, etc): Windows 10

	</description>
	<comments>
		<comment id='1' author='schrum2' date='2017-11-13T06:49:28Z'>
		This appears to be due to workspaces, and (given the use of workspaces by default for inference).
In short, it's trying to do forward pass with memory that has already been deallocated.
If you aren't familiar with workspaces, read this: &lt;denchmark-link:https://deeplearning4j.org/workspaces&gt;https://deeplearning4j.org/workspaces&lt;/denchmark-link&gt;

Moving forward, no-arg methods like activate() will be for internal use only - in part because this sort of "stateful" behaviour will be changed.
Anyway, to get the activations you want: you can use the feedForward methods on ComputationGraph, with return a Map&lt;String, INDArray&gt; of activations.
Edit: another workaround (though beware of the memory cost in general) is to disable the inference workspace:
vgg16.getConfiguration().setInferenceWorkspaceMode(WorkspaceMode.NONE);
		</comment>
		<comment id='2' author='schrum2' date='2017-11-13T16:35:55Z'>
		The feedForward method seems to work fine. Thanks for the quick response.
From my perspective, the issue is resolved, but I don't know if you want to leave it open until the activate method is made private.
		</comment>
		<comment id='3' author='schrum2' date='2017-11-13T23:49:20Z'>
		Yeah, I'll leave the issue open as a reminder to fix this - regardless of what we do here, we don't want users running into this in the future.
		</comment>
		<comment id='4' author='schrum2' date='2017-11-29T03:26:31Z'>
		&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4326&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4326&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='schrum2' date='2018-09-24T06:43:52Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>