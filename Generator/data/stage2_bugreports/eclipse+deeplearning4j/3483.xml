<bug id='3483' author='SergeyZYX' open_date='2017-06-05T12:22:08Z' closed_time='2018-04-25T09:12:31Z'>
	<summary>Deeplearning4j memory leakage</summary>
	<description>
I deployed an application using Deeplearning4j, it starts with 8Gb memory usage and after about 48h it runs out of memory (32Gb). In a loop it creates new instance of MultiLayerNetwork, do some calculations than drops it. Ends up with java process consuming entire memory, the leakage is somehow outside of java heap.
I took and modified your official example UCISequenceClassificationExample to reproduce the error.
The following example will end up consuming all memory (depends on RAM and CPU) in 40+ hours.
Also I took screenshots of average memory usage of this example, and it shows the process uses 200mb more memory after 1 hour of run.
Deeplearning4j 0.8-SNAPSHOT
CentOS 7 x64
2x Intel Xeon E5-2420
32Gb RAM
Blas vendor MKL
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/28604810/26783705/aad2561c-4a0a-11e7-91a8-4a75958b9dac.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1051974/NetLeak.txt&gt;NetLeak.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='SergeyZYX' date='2017-06-05T12:24:08Z'>
		Show your pom.xml please.
		</comment>
		<comment id='2' author='SergeyZYX' date='2017-06-05T12:27:03Z'>
		Also, please add some info about your JVM. Vendor, version etc.
		</comment>
		<comment id='3' author='SergeyZYX' date='2017-06-05T12:29:54Z'>
		And, depending on jvm params, such fluctuations aren't symptoms of leak. JVM can easily use more or less ram, in bounds defined by Xmx.
		</comment>
		<comment id='4' author='SergeyZYX' date='2017-06-05T12:31:02Z'>
		openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)
also tested with
java version "1.8.0_121"
Java(TM) SE Runtime Environment (build 1.8.0_121-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1051983/pom.txt&gt;pom.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='SergeyZYX' date='2017-06-05T12:32:29Z'>
		my run params:
-Xms1G -Xmx28G
		</comment>
		<comment id='6' author='SergeyZYX' date='2017-06-05T12:37:28Z'>
		Aha, that explains.
DL4j uses off-heap memory, and it's usually bad idea to allow &gt; 50% total RAM, because JVM might be happy to use that amount eventually, and at the same time we might the same amount in off-heap memory. So, run with -Xmx16G instead, and you should be fine.
		</comment>
		<comment id='7' author='SergeyZYX' date='2017-06-05T12:38:09Z'>
		Alternatively, you can set smaller Xmx, and configure our max off-heap allocation via jcpp variables
		</comment>
		<comment id='8' author='SergeyZYX' date='2017-06-05T12:43:55Z'>
		I tried already with -Xmx14G not helped. Probably I should play with jcpp variables. Do you have any manual on it?
		</comment>
		<comment id='9' author='SergeyZYX' date='2017-06-05T12:44:25Z'>
		Show me full console output with your crash. As full as possible, sure :)
		</comment>
		<comment id='10' author='SergeyZYX' date='2017-06-05T12:44:52Z'>
		And what task you had when you've spotted issue? Images, by any chance?
		</comment>
		<comment id='11' author='SergeyZYX' date='2017-06-05T12:54:16Z'>
		Jun  2 03:59:28 localhost kernel: 54910 total pagecache pages
Jun  2 03:59:28 localhost kernel: 36346 pages in swap cache
Jun  2 03:59:28 localhost kernel: Swap cache stats: add 1637683, delete 1601337, find 3848110/3896195
Jun  2 03:59:28 localhost kernel: Free swap  = 0kB
Jun  2 03:59:28 localhost kernel: Total swap = 4194300kB
Jun  2 03:59:28 localhost kernel: 8379742 pages RAM
Jun  2 03:59:28 localhost kernel: 0 pages HighMem/MovableOnly
Jun  2 03:59:28 localhost kernel: 194943 pages reserved
Jun  2 03:59:28 localhost kernel: [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
Jun  2 03:59:28 localhost kernel: [  534]     0   534    32802     8214      68       44             0 systemd-journal
Jun  2 03:59:28 localhost kernel: [  549]     0   549    11097       78      22      274         -1000 systemd-udevd
Jun  2 03:59:28 localhost kernel: [  554]     0   554    29723        0      28       85             0 lvmetad
Jun  2 03:59:28 localhost kernel: [  747]     0   747    13854      112      25        1         -1000 auditd
Jun  2 03:59:28 localhost kernel: [  766]     0   766     4855       55      13       41             0 irqbalance
Jun  2 03:59:28 localhost kernel: [  768]     0   768   138290      167      88     3033             0 tuned
Jun  2 03:59:28 localhost kernel: [  769]   998   769   132432      600      58     1271             0 polkitd
Jun  2 03:59:28 localhost kernel: [  770]     0   770     6062       41      15       43             0 systemd-logind
Jun  2 03:59:28 localhost kernel: [  771]     0   771    77442     4938      79       97             0 rsyslogd
Jun  2 03:59:28 localhost kernel: [  777]   997   777     2131        7       9       29             0 lsmd
Jun  2 03:59:28 localhost kernel: [  782]    81   782     6633       59      17       67          -900 dbus-daemon
Jun  2 03:59:28 localhost kernel: [  808]     0   808    31968       21      19      125             0 smartd
Jun  2 03:59:28 localhost kernel: [  813]     0   813    26370       38      53      207         -1000 sshd
Jun  2 03:59:28 localhost kernel: [  818]     0   818    53153       24      57      391             0 abrtd
Jun  2 03:59:28 localhost kernel: [  820]   996   820    28962       30      26       68             0 chronyd
Jun  2 03:59:28 localhost kernel: [  822]     0   822    52571        9      56      331             0 abrt-watch-log
Jun  2 03:59:28 localhost kernel: [  830]     0   830    31555       80      18       75             0 crond
Jun  2 03:59:28 localhost kernel: [  832]     0   832     6461        5      16       47             0 atd
Jun  2 03:59:28 localhost kernel: [ 1104]     0  1104    22780       18      43      243             0 master
Jun  2 03:59:28 localhost kernel: [ 1106]    89  1106    22850       23      45      240             0 qmgr
Jun  2 03:59:28 localhost kernel: [ 2414]     0  2414    27509        1      10       32             0 agetty
Jun  2 03:59:28 localhost kernel: [ 7543]    26  7543    58601       45      52      238             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7544]    26  7544    48537       29      42      242             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7546]    26  7546    58627     3090      63      267             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7547]    26  7547    58601     2357      63      249             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7548]    26  7548    58601       21      46      257             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7549]    26  7549    58806      147      62      350             0 postgres
Jun  2 03:59:28 localhost kernel: [ 7550]    26  7550    48577       51      42      241             0 postgres
Jun  2 03:59:28 localhost kernel: [62911]  1000 62911    28280        0      13       49             0 sh
Jun  2 03:59:28 localhost kernel: [62912]  1000 62912  9208519  5193261   11969   849278             0 java
Jun  2 03:59:28 localhost kernel: [49851]  1000 49851    28280        0      14       49             0 sh
Jun  2 03:59:28 localhost kernel: [49861]  1000 49861  6090553  2781163    5965   185660             0 java
Jun  2 03:59:28 localhost kernel: [10185]    89 10185    22806      258      46        0             0 pickup
Jun  2 03:59:28 localhost kernel: [44803]     0 44803    25839      237      53        0             0 sshd
Jun  2 03:59:28 localhost kernel: [42289]    26 42289    58778      226      47      197             0 postgres
Jun  2 03:59:28 localhost kernel: Out of memory: Kill process 62912 (java) score 655 or sacrifice child
Jun  2 03:59:28 localhost kernel: Killed process 62912 (java) total-vm:36834076kB, anon-rss:20773044kB, file-rss:0kB, shmem-rss:0kB
		</comment>
		<comment id='12' author='SergeyZYX' date='2017-06-05T12:54:41Z'>
		it used 35Gb with  -Xmx14G
		</comment>
		<comment id='13' author='SergeyZYX' date='2017-06-05T12:55:26Z'>
		no, it's plain data no images
		</comment>
		<comment id='14' author='SergeyZYX' date='2017-06-05T12:57:24Z'>
		Is it hard requirement to re-instantiate the network, to cause oom?
		</comment>
		<comment id='15' author='SergeyZYX' date='2017-06-05T13:00:14Z'>
		If yes, the first suspect will be RNG i think. I'll check it out.
		</comment>
		<comment id='16' author='SergeyZYX' date='2017-06-05T13:03:16Z'>
		it took about 40+ hours, today I stop the process myself when I saw memory usage 99% and just restart with fresh copy, otherwise it should crash.
		</comment>
		<comment id='17' author='SergeyZYX' date='2017-06-05T13:05:42Z'>
		Can you please check, if this issue is reproducible for you with 0.8.1-SNAPSHOT?
		</comment>
		<comment id='18' author='SergeyZYX' date='2017-06-05T13:07:59Z'>
		ok i'll check
		</comment>
		<comment id='19' author='SergeyZYX' date='2017-06-05T13:23:04Z'>
		No ideas what leaks for you yet, but after 100 "runs", i have the same 928MB allocated on GPU as after first run. So, if something is wrong, it's definitely not happening with CUDA backend, and probably not happening with ND4J, since underlying mechanics is +- the same for both backends :/
		</comment>
		<comment id='20' author='SergeyZYX' date='2017-06-05T13:27:49Z'>
		Same 928MB after 200 runs. Will check CPU then...
		</comment>
		<comment id='21' author='SergeyZYX' date='2017-06-05T13:37:17Z'>
		are you running 0.8.1-SNAPSHOT? yes, please check cpu.
		</comment>
		<comment id='22' author='SergeyZYX' date='2017-06-05T13:39:30Z'>
		Yes, i'm on current master. So, slightly beyond snapshot, but that doesn't matters
		</comment>
		<comment id='23' author='SergeyZYX' date='2017-06-05T14:02:04Z'>
		Well, with CPU backend i've found something i don't like, but that's not your case, minor issue was introduced at 0.8.1... However, nice to fix.
Besides that only thing i've found - stuff looks ok for both CPU &amp; CUDA :/
		</comment>
		<comment id='24' author='SergeyZYX' date='2017-06-05T14:11:56Z'>
		I'll keep your app running tonight, maybe we'll see something at morning... But looks stable so far
		</comment>
		<comment id='25' author='SergeyZYX' date='2017-06-05T19:45:47Z'>
		11827 runs after - still runs. JVM profiling shows nothing major. overall memory use is slightly below allowed 3GB.
		</comment>
		<comment id='26' author='SergeyZYX' date='2017-06-05T19:46:42Z'>
		&lt;denchmark-link:https://cloud.githubusercontent.com/assets/12250879/26800145/d615263e-4a40-11e7-9faa-67491688571a.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='27' author='SergeyZYX' date='2017-06-06T02:45:19Z'>
		ok, it won't appear if nothing changed for hours. today I try to reproduce it with 0.8.1-SNAPSHOT.
		</comment>
		<comment id='28' author='SergeyZYX' date='2017-06-06T05:47:57Z'>
		32469 runs finished, unfortunately can't run longer: i have to reboot to windows.
Please show me your original code, that caused your issue.
		</comment>
		<comment id='29' author='SergeyZYX' date='2017-06-06T15:37:11Z'>
		The project is very big. In this file calculateDNAPerformance() is the only function in a whole project which has a call to DL4j. It uses as evaluation. I have an alternate evaluate option, and it works without leakage.
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1055522/BaseEvolution.txt&gt;BaseEvolution.txt&lt;/denchmark-link&gt;

anyway, if infinite loop app will work well for 48h+ means I have wrong memory settings for DL4j, sorry.
		</comment>
		<comment id='30' author='SergeyZYX' date='2017-06-06T16:30:44Z'>
		Any chance for data dimensionality changes between runs?
		</comment>
		<comment id='31' author='SergeyZYX' date='2017-06-06T17:50:10Z'>
		data dimensionality depends on exact DNA we are evaluating and could vary
		</comment>
		<comment id='32' author='SergeyZYX' date='2017-06-06T17:58:04Z'>
		Aha. Add some more details please :)
I'm speaking specifically about DataSet features/labels dimensionality here.
		</comment>
		<comment id='33' author='SergeyZYX' date='2017-06-06T18:03:58Z'>
		DNA could have different columns number, so features/labels could change, yes
		</comment>
		<comment id='34' author='SergeyZYX' date='2017-06-06T18:10:26Z'>
		as for RNN we have 3d (X,Y,Z) data, so for a single colony Y (columns) is variable but X&amp;Z are fixed. between colonies X&amp;Z could vary. different colonies runs in separate threads.
		</comment>
		<comment id='35' author='SergeyZYX' date='2017-06-06T18:14:24Z'>
		Okay, i'll check various caches then.
		</comment>
		<comment id='36' author='SergeyZYX' date='2017-06-07T02:42:48Z'>
		mem usage grows very slowly but stable, 51.3% as for now.
jvmtop shows heap max 12.7Gb
started with -Xmx 14G
		</comment>
		<comment id='37' author='SergeyZYX' date='2017-06-07T02:50:33Z'>
		It might help to know if this is memory not deallocated by JavaCPP, and thus ND4J. We can check that by calling the org.bytedeco.javacpp.Pointer.totalBytes() static method.
		</comment>
		<comment id='38' author='SergeyZYX' date='2017-06-07T12:12:32Z'>
		still slowly climbing 52.9% now
java HeapMax 12.7Gb - no change, the reason is outside of heap.
i stop it.
		</comment>
		<comment id='39' author='SergeyZYX' date='2017-06-07T12:26:57Z'>
		Can you show me screenshots (or better dump) from any java profiler? I'm interested in objects within heap.
Yourkit profiler dump would be best fit here
		</comment>
		<comment id='40' author='SergeyZYX' date='2017-06-07T12:50:17Z'>
		Ok, so we know it's off-heap memory, but I'm wondering if it's being tracked by JavaCPP, which would indicate a bug in ND4J, or not, which might indicate an issue with the OS, as with &lt;denchmark-link:https://github.com/bytedeco/javacpp-presets/issues/423&gt;bytedeco/javacpp-presets#423&lt;/denchmark-link&gt;
 .
		</comment>
		<comment id='41' author='SergeyZYX' date='2017-06-08T13:27:13Z'>
		I have modified NetLeak example to output org.bytedeco.javacpp.Pointer.totalBytes()
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1061094/NetLeak.txt&gt;NetLeak.txt&lt;/denchmark-link&gt;

and that's what I found in output:
09:17:50.827 [pool-1-thread-3] INFO  org.nd4j.linalg.factory.Nd4jBackend - Loaded [CpuBackend] backend
09:17:51.082 [pool-1-thread-3] INFO  org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 6
09:17:51.553 [pool-1-thread-3] INFO  org.reflections.Reflections - Reflections took 424 ms to scan 1 urls, producing 29 keys and 189 values
09:17:52.923 [pool-1-thread-3] INFO  org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 6
09:17:52.931 [pool-1-thread-3] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Linux]
09:17:52.932 [pool-1-thread-3] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Cores: [24]; Memory: [7.1GB];
09:17:52.932 [pool-1-thread-3] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [MKL]
09:17:57.546 [pool-1-thread-2] INFO  org.reflections.Reflections - Reflections took 4231 ms to scan 4 urls, producing 4309 keys and 24049 values
09:17:58.567 [pool-1-thread-6] INFO  org.reflections.Reflections - Reflections took 391 ms to scan 1 urls, producing 373 keys and 1449 values
09:18:03.231 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 490563229 byte(s)
09:18:03.318 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 494068497 byte(s)
09:18:03.739 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 508059381 byte(s)
09:18:06.816 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 830956937 byte(s)
09:18:06.904 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 838832941 byte(s)
09:18:07.216 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 858230421 byte(s)
09:18:10.492 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 1200077517 byte(s)
09:18:10.495 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 1200234157 byte(s)
09:18:10.541 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 1201964781 byte(s)
09:18:13.710 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 1535898081 byte(s)
09:18:14.115 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 1561784353 byte(s)
09:18:14.179 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 1562910209 byte(s)
09:18:17.037 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 1893605125 byte(s)
09:18:17.154 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 1907688933 byte(s)
09:18:17.238 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 1911769009 byte(s)
09:18:32.910 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 2066754481 byte(s)
09:18:33.072 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 2081103949 byte(s)
09:18:33.511 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 2105404953 byte(s)
09:18:36.477 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 2432031037 byte(s)
09:18:36.480 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 2432326205 byte(s)
09:18:36.725 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 2447219461 byte(s)
09:18:39.625 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 2769158033 byte(s)
09:18:39.692 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 2773403725 byte(s)
09:18:40.464 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 2792932797 byte(s)
09:18:43.219 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 3106540281 byte(s)
09:18:43.250 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 3108703069 byte(s)
09:18:43.645 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 3129794061 byte(s)
09:18:46.449 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 3426387077 byte(s)
09:18:46.740 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 3455260861 byte(s)
09:18:47.616 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 3507017149 byte(s)
09:19:04.706 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 3592325737 byte(s)
09:19:04.931 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 3608944493 byte(s)
09:19:05.099 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 3617493573 byte(s)
09:19:08.041 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 3937727597 byte(s)
09:19:08.294 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 3963582857 byte(s)
09:19:08.378 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 3968170869 byte(s)
09:19:11.481 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 4279735745 byte(s)
09:19:11.928 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 4313512397 byte(s)
09:19:12.241 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 4329774385 byte(s)
09:19:15.096 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 4644794001 byte(s)
09:19:15.517 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 4671655705 byte(s)
09:19:15.756 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 4681395545 byte(s)
09:19:18.679 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 4991541333 byte(s)
09:19:18.829 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5007978201 byte(s)
09:19:19.199 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5024786485 byte(s)
09:19:50.687 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 5047346337 byte(s)
09:19:52.178 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5236410229 byte(s)
13:45:33.356 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5272850289 byte(s)
13:58:26.982 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5312774353 byte(s)
13:58:27.463 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 5361951833 byte(s)
14:05:12.233 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5363670025 byte(s)
14:06:20.775 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5377207353 byte(s)
14:07:28.711 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5393544673 byte(s)
14:09:09.604 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5425845557 byte(s)
14:20:22.312 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5468312293 byte(s)
14:20:23.967 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5481160057 byte(s)
14:29:00.567 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 5490013045 byte(s)
14:33:31.881 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 5502909333 byte(s)
14:39:42.319 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5528103421 byte(s)
14:46:22.335 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5534613313 byte(s)
14:46:22.612 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5544040337 byte(s)
14:48:38.273 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5559463429 byte(s)
14:50:17.298 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5643002973 byte(s)
15:03:01.470 [pool-1-thread-5] INFO  com.ddx.netleak.NetLeak - 5663616469 byte(s)
15:03:01.626 [pool-1-thread-3] INFO  com.ddx.netleak.NetLeak - 5674072121 byte(s)
15:03:01.822 [pool-1-thread-1] INFO  com.ddx.netleak.NetLeak - 5684587785 byte(s)
It holds 4 hours running from 09:19 to 13:45 and than starting to allocate more.
raver119, Yourkit is not free, if you can recommend java profiler which is free and can output to file or console, it would be great. I can dump whole process memory or any part of it in linux, but I can't figure out where is heap/noheap part of it.
		</comment>
		<comment id='42' author='SergeyZYX' date='2017-06-08T13:33:56Z'>
		Yourkit offers free trial for 15 days, and that's the best possible profiler.
There's also jvisualvm profiler, bundled with jdk, it has support for snapshots too. However, yourkit is way better, and if you can use free trial - that would be awesome.
		</comment>
		<comment id='43' author='SergeyZYX' date='2017-06-17T16:17:54Z'>
		Sorry, I was on vacation, couldn't write here.
I started 2 NetLeak applications (netleak.zip) with following params:
-Xmx8G
and connected Yourkit on em.
MAX (org.bytedeco.javacpp.Pointer.totalBytes) was around 6Gb on each
Heap MAX (by Yourkit) 3.4Gb
Non-Heap MAX (by Yourkit) 42Mb
Everything was just fine, BUT, each thread consuming more and more memory as time progressed, and
finally they both consumed 50% of total ram each and both oomed.
It took 80+ hours.
Under real load on different datasets it happens faster.
		</comment>
		<comment id='44' author='SergeyZYX' date='2017-06-17T16:31:42Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/28604810/27254585-f7b5ab24-539b-11e7-9812-29a2dfddd889.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='45' author='SergeyZYX' date='2017-06-17T16:35:27Z'>
		This is under real application, the picture is fine
&lt;denchmark-link:https://user-images.githubusercontent.com/28604810/27254593-50751f60-539c-11e7-9f1f-ee96b90cf356.png&gt;&lt;/denchmark-link&gt;

but
Caused by: java.lang.OutOfMemoryError: Cannot allocate new IntPointer(10): totalBytes = 759M, physicalBytes = 14G
at org.bytedeco.javacpp.IntPointer.(IntPointer.java:86)
		</comment>
		<comment id='46' author='SergeyZYX' date='2017-06-18T08:42:32Z'>
		Can i have memory snapshot/dump from yourkit?
		</comment>
		<comment id='47' author='SergeyZYX' date='2017-06-18T09:33:12Z'>
		&lt;denchmark-link:https://yadi.sk/d/ql05qVZj3KEAMF&gt;https://yadi.sk/d/ql05qVZj3KEAMF&lt;/denchmark-link&gt;

		</comment>
		<comment id='48' author='SergeyZYX' date='2017-06-18T14:26:02Z'>
		It sounds like problems with memory fragmentation...
		</comment>
		<comment id='49' author='SergeyZYX' date='2017-06-18T15:16:19Z'>
		Mmmm, i think i can write simple app &amp; micro nd4j tweak, that'll notify on each and every allocation &amp; deallocation that happen in native codebase. At least for CUDA backend that's trivial. And simple perl/bash/whatever script that'll do summary of all malloc/free calls each hour. If stuff sums up to 0 at the end of process - it's not a leak then.
		</comment>
		<comment id='50' author='SergeyZYX' date='2017-06-18T15:16:51Z'>
		Hm. Actually no, i want that in ND4j codebase as debugging option!
		</comment>
		<comment id='51' author='SergeyZYX' date='2017-06-19T03:15:09Z'>
		Are you saying that you cannot reproduce the issue with the example code?
A low value for Pointer.totalBytes() indicates that something else is probably leaking memory, not ND4J. Test the other components in your application for any leaks there.
		</comment>
		<comment id='52' author='SergeyZYX' date='2017-06-19T07:15:47Z'>
		Yes, Pointer.totalBytes(), stop growing at some point. I guess it's reproducible on example, but I didn't test it till the end. Netleak.zip is pretty much an official example but with piece of my dataset. I made dirty workaround, just restarting the process, before it reaches critical point, now it works just fine)
		</comment>
		<comment id='53' author='SergeyZYX' date='2017-06-20T01:47:06Z'>
		When the memory gets too fragmented, it can cause memory allocation and deallocation to slow down too much to the point of generating OutOfMemoryError. As mentioned above though, the new "workspace" feature that is in 0.8.1-SNAPSHOT should help with that.
		</comment>
		<comment id='54' author='SergeyZYX' date='2018-04-25T09:12:31Z'>
		Closing this as obsolete - considerable improvements to memory management have been made since this issue was last looked at.
		</comment>
		<comment id='55' author='SergeyZYX' date='2018-09-22T21:13:56Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>