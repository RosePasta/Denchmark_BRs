<bug id='1505' author='wutzebaer' open_date='2016-05-04T22:49:35Z' closed_time='2016-05-14T06:13:30Z'>
	<summary>OutOfMemoryError: Cannot allocate 3740963793 bytes on moderate network</summary>
	<description>
When running the class i get an OOM after ~5mins
OS Ubuntu 16.04 x64
libnd4j &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/commit/d88c07964267217618e728530e31e7b9db15c492&gt;d88c079&lt;/denchmark-link&gt;

nd4j &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/commit/a59714a5502a578bc361cb141fd5b4ecefb1e84c&gt;a59714a&lt;/denchmark-link&gt;

dl4j &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/commit/ba4fe100a6c8d574ee29a00c493e8f80f90c8b47&gt;ba4fe10&lt;/denchmark-link&gt;

code to run
&lt;denchmark-code&gt;mvn clean package
java -jar target/deeplearning4j-examples-0.4-rc0-SNAPSHOT-bin.jar
&lt;/denchmark-code&gt;

pom
&lt;denchmark-code&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;prerequisites&gt;
        &lt;maven&gt;3.0.5&lt;/maven&gt;
    &lt;/prerequisites&gt;

    &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
    &lt;artifactId&gt;deeplearning4j-examples&lt;/artifactId&gt;
    &lt;version&gt;0.4-rc0-SNAPSHOT&lt;/version&gt;

    &lt;name&gt;DeepLearning4j Examples&lt;/name&gt;
    &lt;description&gt;Examples of training different data sets&lt;/description&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;shadedClassifier&gt;bin&lt;/shadedClassifier&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;nd4j.version&gt;0.4-rc3.9-SNAPSHOT&lt;/nd4j.version&gt;
        &lt;dl4j.version&gt;0.4-rc3.9-SNAPSHOT&lt;/dl4j.version&gt;
        &lt;maven-shade-plugin.version&gt;2.4.3&lt;/maven-shade-plugin.version&gt;
        &lt;exec-maven-plugin.version&gt;1.4.0&lt;/exec-maven-plugin.version&gt;
    &lt;/properties&gt;

    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;snapshots-repo&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

    &lt;distributionManagement&gt;
        &lt;snapshotRepository&gt;
            &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt;
            &lt;name&gt;Sonatype Nexus snapshot repository&lt;/name&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
        &lt;/snapshotRepository&gt;
        &lt;repository&gt;
            &lt;id&gt;nexus-releases&lt;/id&gt;
            &lt;name&gt;Nexus Release Repository&lt;/name&gt;
            &lt;url&gt;http://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt;
        &lt;/repository&gt;
    &lt;/distributionManagement&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.json&lt;/groupId&gt;
            &lt;artifactId&gt;json&lt;/artifactId&gt;
            &lt;version&gt;20090211&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;artifactId&gt;dl4j-spark&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
            &lt;artifactId&gt;nd4j-native&lt;/artifactId&gt;
            &lt;!-- &lt;artifactId&gt;nd4j-cuda-7.5&lt;/artifactId&gt; --&gt;
            &lt;!-- &lt;artifactId&gt;nd4j-native&lt;/artifactId&gt; --&gt;
            &lt;version&gt;${nd4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
            &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
            &lt;version&gt;4.5.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.guava&lt;/groupId&gt;
            &lt;artifactId&gt;guava&lt;/artifactId&gt;
            &lt;version&gt;19.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
            &lt;artifactId&gt;commons-collections4&lt;/artifactId&gt;
            &lt;version&gt;4.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
                &lt;artifactId&gt;exec-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;${exec-maven-plugin.version}&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;exec&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
                &lt;configuration&gt;
                    &lt;executable&gt;java&lt;/executable&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;${maven-shade-plugin.version}&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;
                    &lt;shadedClassifierName&gt;${shadedClassifier}&lt;/shadedClassifierName&gt;
                    &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt;
                    &lt;filters&gt;
                        &lt;filter&gt;
                            &lt;artifact&gt;*:*&lt;/artifact&gt;
                            &lt;excludes&gt;
                                &lt;exclude&gt;org/datanucleus/**&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                            &lt;/excludes&gt;
                        &lt;/filter&gt;
                    &lt;/filters&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;transformers&gt;
                                &lt;transformer
                                    implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer"&gt;
                                    &lt;resource&gt;reference.conf&lt;/resource&gt;
                                &lt;/transformer&gt;
                                &lt;transformer
                                    implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" /&gt;
                                &lt;transformer
                                    implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;

            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.5.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${java.version}&lt;/source&gt;
                    &lt;target&gt;${java.version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;archive&gt;
                        &lt;manifest&gt;
                            &lt;addClasspath&gt;true&lt;/addClasspath&gt;
                            &lt;mainClass&gt;test.CrashSample&lt;/mainClass&gt;
                        &lt;/manifest&gt;
                    &lt;/archive&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;

&lt;/denchmark-code&gt;

exception
&lt;denchmark-code&gt;java.lang.OutOfMemoryError: Cannot allocate 3740963793 bytes
        at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:433)
        at org.bytedeco.javacpp.Pointer.init(Pointer.java:118)
        at org.bytedeco.javacpp.FloatPointer.allocateArray(Native Method)
        at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:68)
        at org.nd4j.linalg.api.buffer.BaseDataBuffer.&lt;init&gt;(BaseDataBuffer.java:563)
        at org.nd4j.linalg.api.buffer.FloatBuffer.&lt;init&gt;(FloatBuffer.java:40)
        at org.nd4j.linalg.api.buffer.factory.DefaultDataBufferFactory.createFloat(DefaultDataBufferFactory.java:227)
        at org.nd4j.linalg.factory.Nd4j.createBuffer(Nd4j.java:1157)
        at org.nd4j.linalg.api.ndarray.BaseNDArray.&lt;init&gt;(BaseNDArray.java:225)
        at org.nd4j.linalg.cpu.nativecpu.NDArray.&lt;init&gt;(NDArray.java:107)
        at org.nd4j.linalg.cpu.nativecpu.CpuNDArrayFactory.create(CpuNDArrayFactory.java:239)
        at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:4026)
        at org.nd4j.linalg.api.shape.Shape.toOffsetZeroCopyHelper(Shape.java:147)
        at org.nd4j.linalg.api.shape.Shape.toOffsetZeroCopy(Shape.java:103)
        at org.nd4j.linalg.api.ndarray.BaseNDArray.dup(BaseNDArray.java:1420)

&lt;/denchmark-code&gt;

CrashSample.java
&lt;denchmark-code&gt;package test;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;

import org.deeplearning4j.nn.api.OptimizationAlgorithm;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration.ListBuilder;
import org.deeplearning4j.nn.conf.Updater;
import org.deeplearning4j.nn.conf.distribution.GaussianDistribution;
import org.deeplearning4j.nn.conf.layers.DenseLayer;
import org.deeplearning4j.nn.conf.layers.OutputLayer;
import org.deeplearning4j.nn.conf.layers.OutputLayer.Builder;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.lossfunctions.LossFunctions;

public class CrashSample {

    private static final double factor = 800;
    private static final int maxRandomFutureCount = 1440 * 1;
    private static final int maxRandomHistoryCount = 1440 * 5;
    private static final double minPlus = 2 / factor;
    private static final Random r = new Random(System.currentTimeMillis());
    private static final List&lt;Double&gt; values = new ArrayList&lt;&gt;();

    public static void main(String[] args) throws IOException, Exception {
        for (int x = 0; x &lt; 179916; x++) {
            values.add(0d);
        }

        int cores = 6;
        for (int c = 0; c &lt; cores; c++) {
            new Thread(new Runnable() {
                public void run() {
                    while (true)
                        try {
                            runRamdomHyperParameters();
                        } catch (Throwable e) {
                            e.printStackTrace();
                            System.exit(0);
                        }
                }
            }).start();
        }

    }

    private static void runRamdomHyperParameters() throws IOException {
        int historycount = (int) (maxRandomHistoryCount * r.nextDouble());
        int futurecount = (int) (maxRandomFutureCount * r.nextDouble());
        int hiddenLayerCount = 1 + r.nextInt(6);
        int hiddenLayerWidth = 10 + r.nextInt(150);
        int samplesPerDataSet = 1;
        int iterations = 1;
        double weightA = 0;
        double weightB = r.nextDouble();

        GaussianDistribution weightDist = new GaussianDistribution(weightA, weightB);

        NeuralNetConfiguration.Builder builder = new NeuralNetConfiguration.Builder();
        builder.iterations(iterations);
        builder.learningRate(1e-5);
        builder.seed(123);

        builder.regularization(true);

        builder.updater(Updater.SGD);

        builder.optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT);
        builder.biasInit(0);
        builder.miniBatch(true);
        builder.weightInit(WeightInit.DISTRIBUTION);
        builder.dist(weightDist);
        builder.activation("relu");
        // builder.gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue);

        ListBuilder listBuilder = builder.list();
        for (int i = 0; i &lt; hiddenLayerCount; i++) {
            DenseLayer.Builder hiddenLayerBuilder = new DenseLayer.Builder();
            hiddenLayerBuilder.nIn(i == 0 ? historycount : hiddenLayerWidth);
            hiddenLayerBuilder.nOut(hiddenLayerWidth);
            listBuilder.layer(i, hiddenLayerBuilder.build());
        }

        Builder outputLayerBuilder = new OutputLayer.Builder(LossFunctions.LossFunction.SQUARED_LOSS);
        outputLayerBuilder.nIn(hiddenLayerWidth);
        outputLayerBuilder.nOut(1);
        outputLayerBuilder.activation("sigmoid");
        listBuilder.layer(hiddenLayerCount, outputLayerBuilder.build());

        listBuilder.pretrain(false);
        listBuilder.backprop(true);
        listBuilder.build();

        MultiLayerConfiguration conf = listBuilder.build();
        MultiLayerNetwork net = new MultiLayerNetwork(conf);
        net.init();
        net.setListeners(new ScoreIterationListener(1));

        for (int epoch = 0; epoch &lt; 2000; epoch++) {
            DataSet ds = createDataset(samplesPerDataSet, historycount, futurecount, minPlus);
            net.fit(ds);
        }

    }

    public static DataSet createDataset(int samplesPerDataset, int historycount, int futurecount, double minPlus) {
        INDArray input = Nd4j.zeros(samplesPerDataset, historycount);
        INDArray labels = Nd4j.zeros(samplesPerDataset, 1);
        for (int sampleindex = 0; sampleindex &lt; samplesPerDataset; sampleindex++) {
            int startindex = (int) ((values.size() - (historycount + futurecount)) * r.nextDouble());
            fillFromStartIndex(input, labels, sampleindex, startindex, historycount, futurecount, minPlus);
        }
        DataSet ds = new DataSet(input, labels);
        return ds;
    }

    static void fillFromStartIndex(INDArray input, INDArray labels, int sampleindex, int startindex, int historycount, int futurecount, double minPlus) {

        double firstvalue = values.get(startindex);
        for (int samplePos = 0; samplePos &lt; historycount; samplePos++) {
            input.putScalar(new int[] { sampleindex, samplePos }, values.get(startindex + samplePos) - firstvalue);
        }

        labels.putScalar(new int[] { sampleindex, 0 }, 0);
        double lastvalue = values.get(startindex + (historycount - 1));
        for (int futureindex = 0; futureindex &lt; futurecount; futureindex++) {
            Double newValue = values.get(startindex + historycount + futureindex);
            if (newValue - lastvalue &gt; minPlus) {
                labels.putScalar(new int[] { sampleindex, 0 }, 1);
                break;
            }
        }
    }
}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='wutzebaer' date='2016-05-06T07:07:31Z'>
		Mind adding some system info? What's -Xmx? How much ram your system actually has?
		</comment>
		<comment id='2' author='wutzebaer' date='2016-05-06T09:37:54Z'>
		i started without xmx params, the system had 16GB ram and 8 cores
		</comment>
		<comment id='3' author='wutzebaer' date='2016-05-06T14:28:44Z'>
		I'm able to reproduce the error on my machine. It's not possible to guarantee that garbage collection will actually take place after a , but if we make the CPU idle long enough it should eventually kick in. 1 second in total seems to be enough on my machine: &lt;denchmark-link:https://github.com/bytedeco/javacpp/commit/f55847f442f304fa60af70023604c6eff4262392&gt;bytedeco/javacpp@f55847f&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/wutzebaer&gt;@wutzebaer&lt;/denchmark-link&gt;
 Could you try again with this change and let me know if this looks good enough?
		</comment>
		<comment id='4' author='wutzebaer' date='2016-05-14T06:13:30Z'>
		&lt;denchmark-link:https://github.com/wutzebaer&gt;@wutzebaer&lt;/denchmark-link&gt;
 if you still see an issue please reopen
		</comment>
		<comment id='5' author='wutzebaer' date='2017-03-09T14:49:09Z'>
		Hi,
I am running the word2VecSentimentRNN, and downloaded the GoogleNews-vectors-negative300.bin model.
I got the following error,
Exception in thread "main" java.lang.OutOfMemoryError: Cannot allocate new FloatPointer(300): totalBytes = 3G, physicalBytes = 7G
at org.bytedeco.javacpp.FloatPointer.(FloatPointer.java:76)
at org.bytedeco.javacpp.FloatPointer.(FloatPointer.java:41)
at org.nd4j.compression.impl.AbstractCompressor.compress(AbstractCompressor.java:127)
at org.nd4j.compression.impl.AbstractCompressor.compress(AbstractCompressor.java:102)
at org.nd4j.storage.CompressedRamStorage.store(CompressedRamStorage.java:68)
at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.loadStaticModel(WordVectorSerializer.java:2450)
at org.deeplearning4j.examples.recurrent.word2vecsentiment.Word2VecSentimentRNN.main(Word2VecSentimentRNN.java:94)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
Caused by: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes = 7G &gt; maxPhysicalBytes = 7G
at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:562)
at org.bytedeco.javacpp.Pointer.init(Pointer.java:121)
at org.bytedeco.javacpp.FloatPointer.allocateArray(Native Method)
at org.bytedeco.javacpp.FloatPointer.(FloatPointer.java:68)
... 11 more
I have the following in my idea.exe.vmoptions.
-server
-Xms128m
-Xmx10000m
-XX:ReservedCodeCacheSize=240m
-XX:+UseConcMarkSweepGC
-XX:SoftRefLRUPolicyMSPerMB=50
-ea
-Dsun.io.useCanonCaches=false
-Djava.net.preferIPv4Stack=true
-XX:+HeapDumpOnOutOfMemoryError
-XX:-OmitStackTraceInFastThrow
-XX:+UseG1GC
-XX:MaxGCPauseMillis=100
OS: 64bit windows 7
RAM : 16GB.
Kindly help me to resolve the issue. Please.
		</comment>
		<comment id='6' author='wutzebaer' date='2017-03-09T14:52:33Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 I know this is not related to the arbiter. But can you help me in the query i raised above.?
		</comment>
		<comment id='7' author='wutzebaer' date='2017-03-09T14:54:31Z'>
		You should set -Xmx value for your app, NOT for intelli idea. idea.exe.vmoptions has nothing to do with your application.
If you're launching your app from intellij idea - you should go to Run -&gt; Edit configurations -&gt; find the file you're ruinning in the lst -&gt; add -Xmx10G to VM options text box.
		</comment>
		<comment id='8' author='wutzebaer' date='2017-03-09T14:55:34Z'>
		And please stop spamming in closed issues. Your issue has nothing to do with issues like this one.
Got problem? File new issue.
		</comment>
	</comments>
</bug>