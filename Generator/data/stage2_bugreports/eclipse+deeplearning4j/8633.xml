<bug id='8633' author='lpaatero' open_date='2020-01-22T19:19:51Z' closed_time='2020-02-07T07:39:33Z'>
	<summary>Memory leak in inference</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Attached model and simple inference program (maven project) seems to demonstrate memory leak.
Program makes inference calls and as byproduct generates AllocationPoint (and some other) objects, until it runs out of memory (in some hours of time).
Maven project &amp; model zip file in &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/files/4099475/memleak.zip&gt;memleak.zip&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


beta6
CUDA V10.0.130
NVIDIA driver 418.56
5.2.1-2.gbf5c01b-default #1 SMP Mon Jul 15 05:32:47 UTC 2019 (bf5c01b) x86_64 x86_64

	</description>
	<comments>
		<comment id='1' author='lpaatero' date='2020-01-22T19:23:07Z'>
		please upgrade to beta6 or add System.gc() call somewhere in your training loop too fix this. Just not enough pressure to trigger gc. Fixed in beta6.

With best regards,
raver119
22 янв. 2020 г., 22:20 +0300, Lauri Paatero &lt;notifications@github.com&gt;, писал:
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 Issue Description
 Attached model and simple inference program (maven project) seems to demonstrate memory leak.
 Program makes inference calls and as byproduct generates AllocationPoint (and some other) objects, until it runs out of memory (in some hours of time).
 Maven project &amp; model zip file in memleak.zip
 Version Information

 • beta5
 • CUDA V10.0.130
 • NVIDIA driver 418.56
 • 5.2.1-2.gbf5c01b-default #1 SMP Mon Jul 15 05:32:47 UTC 2019 (bf5c01b) x86_64 x86_64

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub, or unsubscribe.


		</comment>
		<comment id='2' author='lpaatero' date='2020-01-22T19:39:43Z'>
		Sorry, I put wrong version into report; Corrected the version to beta6, as it is in pom.xml.
System.gc() does NOT resolve the problem.
There is no training at all, but just inference.
		</comment>
		<comment id='3' author='lpaatero' date='2020-01-23T06:34:39Z'>
		Native/GPU memory use seems to be absolutely flat. So whatever happens - happens in java.
Thanks for highlighting this problem, I'll take a look, and once it's confirmed fixed - it'll be in snapshots. However, we've already got rid of AllocationPoint references in current dev master, so it might be already resolved.
		</comment>
		<comment id='4' author='lpaatero' date='2020-01-27T05:16:02Z'>
		Updated snapshots should be out tomorrow. Can you please try to run your app with snapshots, and confirm issue is gone?
		</comment>
		<comment id='5' author='lpaatero' date='2020-01-28T21:01:57Z'>
		Testing full application with current snapshot:
Java -side memory leak is gone.
Unfortunately there is even faster native side leak. I will try to create testcase for it.
Another observation is that toFoatMatrix is now a quite a bit slower.
		</comment>
		<comment id='6' author='lpaatero' date='2020-01-28T21:30:54Z'>
		The original example seems to create native side memory leak with current snapshot, when evaluation loop is changed to
&lt;denchmark-code&gt;        for (;;) {
          INDArray in[] = new INDArray[]{ Nd4j.create(data,'c').reshape(new long[]{1, 75, 9, 9}) };
          INDArray[] out = g.output(false, in);          
          
          float fout[][][] = new float[out.length][][];
          for (int ct=0; ct&lt;fout.length; ct++) {
            INDArray w = out[ct].dup('c');
            long[] shape = w.shape();
            w = w.reshape(shape[0],w.length()/shape[0]);
            fout[ct] = w.toFloatMatrix();
          }          
        }
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='lpaatero' date='2020-01-29T04:44:18Z'>
		Thank you very much! Let me check it out.
		</comment>
		<comment id='8' author='lpaatero' date='2020-01-31T11:13:53Z'>
		Confirmed. Fix coming.
		</comment>
		<comment id='9' author='lpaatero' date='2020-02-07T07:39:33Z'>
		Thanks for highlighting this problem. Things were fixed, and will be available in snapshots later today/early tomorrow.
		</comment>
	</comments>
</bug>