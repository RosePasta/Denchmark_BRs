<bug id='3968' author='cqiaoYc' open_date='2017-08-29T02:37:16Z' closed_time='2018-05-11T05:54:41Z'>
	<summary>bug in BaseOutputLayer.getLabels2d()?</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;batchSize=64;
timeStep=1;
featureCount=4;
outputColumns=5;
MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(seed)
                .iterations(iterations)
                .activation(Activation.RRELU)
                .weightInit(WeightInit.XAVIER)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
                .learningRate(learnRate)
                .updater(new RmsProp(0.95))
                .regularization(true).l2(1e-3)
                .gradientNormalization(GradientNormalization.RenormalizeL2PerLayer)
                .list()
                .layer(0, new GravesLSTM.Builder().activation(Activation.SOFTSIGN).nIn(this.featureCount).nOut(this.featureCount * 8).build())
                .layer(1, new GravesLSTM.Builder().activation(Activation.SOFTSIGN).nIn(this.featureCount * 8).nOut(this.featureCount * 6).learningRate(1e-1f).build())
                .layer(2, new GravesLSTM.Builder().activation(Activation.SOFTSIGN).nIn(this.featureCount * 6).nOut(this.featureCount * 4).learningRate(1e-1f).build())
                .layer(3, new DenseLayer.Builder().nIn(featureCount * 4).nOut(featureCount * 2).build())
                .layer(4, new OutputLayer.Builder().lossFunction(new LossMCXENT(getClassWeights())).weightInit(WeightInit.XAVIER)
                        .activation(Activation.SOFTMAX).nIn(featureCount * 2).nOut(this.levelCount*2+1).build())                
                .inputPreProcessor(3, new RnnToFeedForwardPreProcessor())
                .pretrain(false)
                .backprop(true)
                .build();
        return conf;
&lt;/denchmark-code&gt;

Exception:
Exception in thread "main" java.lang.IllegalStateException: Mismatched shapes (shape = [64, 5], row vector shape =[1, 1])
at org.nd4j.linalg.api.ndarray.BaseNDArray.doColumnWise(BaseNDArray.java:2229)
at org.nd4j.linalg.api.ndarray.BaseNDArray.muliColumnVector(BaseNDArray.java:2666)
at org.nd4j.linalg.api.ndarray.BaseNDArray.mulColumnVector(BaseNDArray.java:2677)
at org.nd4j.linalg.lossfunctions.impl.LossMCXENT.computeGradient(LossMCXENT.java:155)
at org.deeplearning4j.nn.layers.BaseOutputLayer.getGradientsAndDelta(BaseOutputLayer.java:169)
at org.deeplearning4j.nn.layers.BaseOutputLayer.backpropGradient(BaseOutputLayer.java:148)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.calcBackpropGradients(MultiLayerNetwork.java:1323)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.backprop(MultiLayerNetwork.java:1273)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:2237)
at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:174)
at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:60)
at org.deeplearning4j.optimize.Solver.optimize(Solver.java:53)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1780)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

I traced into the  BaseOutputLayer.getLabels2d() method:
&lt;denchmark-code&gt;protected INDArray getLabels2d() {
        if (labels.rank() &gt; 2) {
            return labels.reshape(labels.size(2), labels.size(1));
        }
        return labels;
    }
&lt;/denchmark-code&gt;

the labes is 3D, reshape to 2D, the (0,1) dimensions should be retained.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

org.deeplearning4j 0.9.1
	</description>
	<comments>
		<comment id='1' author='cqiaoYc' date='2017-08-29T14:30:43Z'>
		It is a very little bug, but it results to RnnToFeedForwardPreProcessor cannt work.
		</comment>
		<comment id='2' author='cqiaoYc' date='2017-08-29T22:27:46Z'>
		I am guessing you are giving it a 3d dataset of shape minibatch,label_size,timesteps. This is the only way I was able to get it to throw an exception with your config.
If you want to have an intermediate dense layer and then still maintain your label shape to be 3d you need to do the following:
Change the output layer from OutputLayer to RnnOutputLayer which is functionally equivalent to the OutputLayer, but handles output and label reshaping automatically. &lt;denchmark-link:https://deeplearning4j.org/doc/org/deeplearning4j/nn/layers/recurrent/RnnOutputLayer.html&gt;Javadoc&lt;/denchmark-link&gt;

Note that you don't have to manually add the preprocessors since they are actually inferred correctly from the config. What ends up happening is there is a FeedForwardToRnnPreProcessor preprocessor correctly inferred in the last layer when you change it to RnnOutputLayer.
		</comment>
		<comment id='3' author='cqiaoYc' date='2017-08-30T00:49:03Z'>
		I might re-open this - I suspect that we might want to just remove that code block. On reflection, that reshaping isn't correct (at the very least, should always be reshape with order) - but I suspect it will never be triggered with the appropriate preprocessors.
		</comment>
		<comment id='4' author='cqiaoYc' date='2017-09-01T20:34:02Z'>
		I can remove that code block.
		</comment>
		<comment id='5' author='cqiaoYc' date='2018-04-27T20:39:36Z'>
		Is this issue still viable? &lt;denchmark-link:https://github.com/eraly&gt;@eraly&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='cqiaoYc' date='2018-05-02T16:27:52Z'>
		Just remove the code block I think? &lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='cqiaoYc' date='2018-05-11T05:54:41Z'>
		This was likely bad labels for that config.
I've refactored/cleaned up the method in this PR and will merge it soon.
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/5134&gt;https://github.com/deeplearning4j/deeplearning4j/pull/5134&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='cqiaoYc' date='2018-09-22T02:24:28Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>