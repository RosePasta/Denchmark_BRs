<bug id='8691' author='liweigu' open_date='2020-02-08T14:50:54Z' closed_time='2020-03-02T05:15:51Z'>
	<summary>FineTune failed by SameDiffLayer's UnsupportedOperationException</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

Please describe our issue, along with:

expected behavior


define a graph model with RecurrentAttentionLayer, the layer is added by the code like
graphBuilder.addLayer("attension1", new RecurrentAttentionLayer.Builder().activation(Activation.SOFTSIGN) .updater(new Adam(learningRateSchedule)).nHeads(5).headSize(40).nIn(nIn).nOut(nOut).build() , "lstm1");
train the model, and save it to file.
load the saved model, and do finetuning by the code like
model = graphBuilder .removeVertexAndConnections("output") .addLayer("newOutput", outputLayer , "dense2") .setOutputs(outputNames) .build();
this code only replace the outputLayer, so that the model layers are changed.
train the new model, expected to run without Exception.


encountered behavior


train the new model, and get UnsupportedOperationException from org.deeplearning4j.nn.layers.samediff.SameDiffLayer.setParams(),
which is from org.deeplearning4j.nn.transferlearning.TransferLearning.build() at line 990:
https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java#L990

By rewrite the org.deeplearning4j.nn.layers.samediff.SameDiffLayer.setParams() method to omit the code throw new UnsupportedOperationException("Not supported"); , the finetuned model can run training.
I think other layers extended from SameDiffLayer would produce the same exception.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Please indicate relevant versions, including, if relevant:

Deeplearning4j version
1.0.0-beta6
Platform information (OS, etc)
ubuntu 16.04
CUDA version, if used
NVIDIA driver version, if in use

&lt;denchmark-h:h4&gt;Additional Information&lt;/denchmark-h&gt;

Where applicable, please also provide:

Full log or exception stack trace (ideally in a Gist: gist.github.com)
pom.xml file or similar (also in a Gist)

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

If you'd like to help us fix the issue by contributing some code, but would
like guidance or help in doing so, please mention it!
	</description>
	<comments>
		<comment id='1' author='liweigu' date='2020-02-10T03:30:49Z'>
		Thanks for reporting this, I'll take a look and report here once I have something to share.
		</comment>
	</comments>
</bug>