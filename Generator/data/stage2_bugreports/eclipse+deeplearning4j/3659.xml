<bug id='3659' author='caozuo' open_date='2017-07-11T10:58:49Z' closed_time='2018-05-07T08:13:52Z'>
	<summary>Outputs  inconsistent for model imported to dl4j that trained by keras (LSTMs)</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;I used a model  to pridict result both in dl4j and keras  that trained by keras , but the outputs inconsistent.
Here is the code in python:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
tstep = 10
vecs = [[1.0 if i &lt; 100 else 0.0 for i in xrange(1468)] for j in xrange(10)]
pred_x = np.array([vecs[:10]])


predict_model = Sequential(name='test')
predict_model.add(LSTM(128, dropout_W=0.2, name="lstm_1",
                       batch_input_shape=(1,tstep, 1468),
                       return_sequences=True,
                       stateful=False))
predict_model.add(LSTM(64, dropout_W=0.2, name="lstm_2",
                       return_sequences=True,
                       stateful=False))
predict_model.add(LSTM(64, dropout_W=0.2, name="lstm_3",
                       return_sequences=True,
                       stateful=False))
predict_model.add(
    Dense(66, activation='softmax'))
predict_model.compile(loss='cosine_proximity', optimizer='rmsprop', batch_size=1)


predict_model.load_weights(
    "/Users/acouzo/Downloads/tmp_batch1.model")

res = predict_model.predict(pred_x,1)
&lt;/denchmark-code&gt;

The layers  and parameters of the network  for training is the same as above.
&lt;denchmark-h:h2&gt;output is:
[ 0.0537132   0.0218515   0.0030996   0.00283214  0.00702331  0.00512185
0.09551867  0.03654516  0.03285046  0.01273406  0.02943875  0.01887065
0.02224374  0.01013126  0.03341065  0.01580815  0.00289342  0.00401812
0.00332686  0.00300365  0.04830471  0.0028953   0.00442217  0.00536297
0.04670355  0.00713607  0.00576499  0.01723406  0.00623572  0.00352393
0.00333194  0.00513643  0.00406783  0.00612169  0.03180168  0.00434502
0.00466972  0.00496646  0.00575797  0.00590429  0.01465094  0.00510816
0.00622903  0.01134238  0.05289311  0.02794224  0.02430911  0.00750555
0.00454416  0.00547271  0.00714901  0.00667866  0.0055298   0.00496655
0.00474627  0.01939307  0.11019427  0.00341729  0.00600688  0.00361823
0.00295191  0.009061    0.0045646   0.00492299  0.0029672   0.00571316]&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;And here is the code in java&lt;/denchmark-h&gt;

List&lt;double[]&gt; retList = Lists.newArrayList();
int tstep = 10;
for (int i = 0; i &lt; tstep; i++)
{
double[] tmp = new double[1468];
for (int j = 0; j &lt; 1468; j++)
{
//                tmp[j] = Math.exp(-j);
if (j&lt;100){
tmp[j] = 1.0;
}else{
tmp[j] = 0;
}
}
retList.add(tmp);
}
List&lt;double[]&gt; samples = retList;
System.out.println("-----------sample len " + samples.size());
double[] timeStepSample = ArrayUtils.doubleArraysCopy(samples.get(0).length, samples);
INDArray indArray = Nd4j.create(new int[]{samples.get(0).length, samples.size()}, timeStepSample);
MultiLayerNetwork model = null;
try
{
model = KerasModelImport.importKerasSequentialModelAndWeights("/Users/acouzo/Downloads/tmp_batch1.model", false);
} catch (IOException e)
{
e.printStackTrace();
} catch (InvalidKerasConfigurationException e)
{
e.printStackTrace();
} catch (UnsupportedKerasConfigurationException e)
{
e.printStackTrace();
}
double[] predicts = model.output(indArray).getRow(tstep - 1).data().asDouble();
&lt;denchmark-h:h2&gt;output is
[0.052297499030828476, 0.01956908032298088, 0.004131146240979433, 0.003902100259438157, 0.009222811087965965, 0.008322488516569138, 0.08216545730829239, 0.029268743470311165, 0.034252505749464035, 0.013951266184449196, 0.03299041464924812, 0.019392499700188637, 0.02307056076824665, 0.009996328502893448, 0.02862134389579296, 0.01934395730495453, 0.0039426591247320175, 0.0061045363545417786, 0.004975264426320791, 0.0038989209569990635, 0.0400262214243412, 0.004392190370708704, 0.0054209292866289616, 0.007225644774734974, 0.04456043243408203, 0.009198641404509544, 0.008061391301453114, 0.019772881641983986, 0.007863360457122326, 0.005392916966229677, 0.0034100229386240244, 0.007208484690636396, 0.005581115372478962, 0.007226245012134314, 0.027135208249092102, 0.0057985978201031685, 0.006340994033962488, 0.006867381278425455, 0.0066977632232010365, 0.007761198561638594, 0.015462375245988369, 0.006025400478392839, 0.008056793361902237, 0.011397640220820904, 0.041448384523391724, 0.02770979329943657, 0.027737554162740707, 0.009202836081385612, 0.005474049597978592, 0.008147388696670532, 0.007273019757121801, 0.008197784423828125, 0.006756486836820841, 0.008344130590558052, 0.005894321016967297, 0.020225821062922478, 0.07940426468849182, 0.005214216187596321, 0.007561299949884415, 0.005559094250202179, 0.004872848279774189, 0.011348326690495014, 0.0055109853856265545, 0.0066768815740942955, 0.004175104200839996, 0.006961996667087078]&lt;/denchmark-h&gt;

It's very interesting that  when a use  a simple lstm model and input_dim =1 the output  consistent, and in  the previous model  the input_dim is 1468.
&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


Deeplearning4j version 0.8.0
Keras version 1.2.2
os  OSX

	</description>
	<comments>
		<comment id='1' author='caozuo' date='2017-07-11T12:33:38Z'>
		Does the same thing happen with 0.8.1-SNAPSHOT?
		</comment>
		<comment id='2' author='caozuo' date='2017-07-11T13:28:01Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
  When I migrate  to 0.8.1-SNAPSHOT both for DL4J and ND4J the result is the same as 0.8.0,nothing changes!
		</comment>
		<comment id='3' author='caozuo' date='2017-08-01T09:18:54Z'>
		&lt;denchmark-link:https://github.com/caozuo&gt;@caozuo&lt;/denchmark-link&gt;
 I'll investigate this issue, might be a bug on our side. Give me a little time, though! Thanks for reporting this behaviour.
		</comment>
		<comment id='4' author='caozuo' date='2017-08-01T12:30:04Z'>
		I have the same inconsistency problem .. &lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 waiting your feedback please
		</comment>
		<comment id='5' author='caozuo' date='2017-08-01T13:22:06Z'>
		&lt;denchmark-link:https://github.com/AntoineSaliba0&gt;@AntoineSaliba0&lt;/denchmark-link&gt;
 on gitter your output was all 0's and 1's, which seems strange. Are you positive this is the same issue?
		</comment>
		<comment id='6' author='caozuo' date='2017-08-03T10:51:16Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 yes I confirm it is the same issue
		</comment>
		<comment id='7' author='caozuo' date='2017-08-03T13:55:48Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;

The h5 model produced by keras is attached.
When I try to classify the image (1.jpg) , I get the following outputs :
with keras :
[ 6.72305048e-01   1.57080940e-05   2.16145456e-01   5.21290523e-04
8.24158662e-04   9.36770216e-02   1.89176248e-03   1.21844059e-03
1.21220741e-02   1.27909088e-03]
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/1197391/bug.zip&gt;bug.zip&lt;/denchmark-link&gt;

with dl4j
[0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 0.00, 0.00]
My Java (dl4j) and python (keras) code are also attached.
		</comment>
		<comment id='8' author='caozuo' date='2017-08-04T06:53:05Z'>
		&lt;denchmark-link:https://github.com/AntoineSaliba0&gt;@AntoineSaliba0&lt;/denchmark-link&gt;
 while I have a look at this, at least now I know which model you use. Please have a look at &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3423&gt;#3423&lt;/denchmark-link&gt;
, which I think is closer to your problem. Also not that there is &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3664&gt;#3664&lt;/denchmark-link&gt;
 (problem with flatten, which you also use).
		</comment>
		<comment id='9' author='caozuo' date='2017-08-04T11:45:33Z'>
		&lt;denchmark-link:https://github.com/AntoineSaliba0&gt;@AntoineSaliba0&lt;/denchmark-link&gt;
 turns out you don't have a problem if you ... divide by 255 as well and you're fine.
&lt;denchmark-link:https://gist.github.com/maxpumperla/1d3c67f8c787bdb534c462c314839e63&gt;https://gist.github.com/maxpumperla/1d3c67f8c787bdb534c462c314839e63&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='caozuo' date='2017-08-08T12:39:26Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 Thanks .. it works !!
		</comment>
		<comment id='11' author='caozuo' date='2017-09-13T14:13:57Z'>
		&lt;denchmark-link:https://github.com/caozuo&gt;@caozuo&lt;/denchmark-link&gt;
 we recently changed the mapping of keras' LSTM to our LSTM (was GravesLSTM before). This might have caused the discrepancies.
Also, if I'm looking at the results above, I'm actually not so sure we should consider this a bug/issue per se. There will always be minor implementation details that differ, so it might not be realistic to expect the exact same numbers, especially if you chain many LSTMs. I'd rather focus on similar prediction metrics tbh.
		</comment>
		<comment id='12' author='caozuo' date='2018-05-07T08:13:52Z'>
		closing this one in favour of &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/4738&gt;#4738&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='caozuo' date='2018-09-22T05:24:08Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>