<bug id='3444' author='bikashg' open_date='2017-05-23T13:37:47Z' closed_time='2018-07-25T09:09:16Z'>
	<summary>Early stop on meeting any one of the several epoch termination type conditions</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

I wanted an early stop : either when the desired number of epochs (eg: 200) had been met or the score at any epoch was less than the desired threshold (eg: 0.008). So I did this :
EarlyStoppingConfiguration esConf = new EarlyStoppingConfiguration.Builder()
.epochTerminationConditions(new MaxEpochsTerminationCondition(200),new BestScoreEpochTerminationCondition(0.008, true))
.scoreCalculator(new DataSetLossCalculatorCG(validationDataSetIterator, true))
.evaluateEveryNEpochs(1)
.modelSaver(new LocalFileGraphSaver(outputBaseDir))
.build();
but my training continues for 200 epoch even when the loss was already less than 0.008 (For example : it was already 0 well ahead of 200 epochs)
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/17159812/26356853/c0408c9a-3fcd-11e7-9ccc-43f5854c3851.jpg&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;


Deeplearning4j version : 0.8.1-SNAPSHOT
platform information (OS, etc) : Ubuntu 14.04, 64 bits
CUDA version, if used : 7.5
NVIDIA driver version, if in use : 367.48

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

If you'd like to help us fix the issue by contributing some code, but would
like guidance or help in doing so, please mention it!
	</description>
	<comments>
		<comment id='1' author='bikashg' date='2018-07-25T09:09:16Z'>
		Closing this - (a) outdated, and (b) there's 2 different scores here.
The score the termination condition is evaluated on is provided by the DataSetLossCalculator; the score you show in the graph is the score on the minibatch. They are different things.
		</comment>
		<comment id='2' author='bikashg' date='2018-09-21T13:58:56Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>