<bug id='6834' author='AlexDBlack' open_date='2018-12-11T06:47:36Z' closed_time='2018-12-17T05:41:45Z'>
	<summary>DL4J: Cifar iterator can crash (array workspace leak?)</summary>
	<description>
To reproduce: Run on CUDA (maybe CPU too, not sure):
&lt;denchmark-code&gt;    private static int height = 32;
    private static int width = 32;
    private static int channels = 3;
    private static int batchSize = 48;
    private static boolean preProcessCifar = true;//use Zagoruyko's preprocess for Cifar

    public static void main(String[] args) throws Exception {
        CifarDataSetIterator cifar = new CifarDataSetIterator(batchSize, CifarLoader.NUM_TRAIN_IMAGES,
            new int[] {height, width, channels}, preProcessCifar, true);

        //This is fine:
//        int iter = 0;
//        while(cifar.hasNext()){
//            DataSet ds = cifar.next();
//            System.out.println(iter++);
//        }

        //This is not:
        DataSetIterator async = new AsyncDataSetIterator(cifar);
        int iter = 0;
        while(async.hasNext()){
            DataSet ds = async.next();
            System.out.println(iter++);
        }
    }
&lt;/denchmark-code&gt;

Workaround: use async shield iterator
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2018-12-11T06:53:52Z'>
		Also to add to this, when running with AsyncShieldDataSetIterator there's another error:
&lt;denchmark-code&gt;Exception in thread "main" java.lang.IllegalArgumentException: invalid example number: must be 0 to 9999, got 10000
	at org.nd4j.linalg.dataset.DataSet.get(DataSet.java:649)
	at org.datavec.image.loader.CifarLoader.next(CifarLoader.java:429)
	at org.deeplearning4j.datasets.iterator.impl.CifarDataSetIterator.next(CifarDataSetIterator.java:141)
	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:440)
	at org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator.next(RecordReaderDataSetIterator.java:84)
	at org.deeplearning4j.datasets.iterator.AsyncShieldDataSetIterator.next(AsyncShieldDataSetIterator.java:166)
	at org.deeplearning4j.datasets.iterator.AsyncShieldDataSetIterator.next(AsyncShieldDataSetIterator.java:35)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fitHelper(MultiLayerNetwork.java:1571)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1521)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1508)
	at org.deeplearning4j.examples.convolution.Cifar.main(Cifar.java:88)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='AlexDBlack' date='2018-12-11T06:57:43Z'>
		As noted in slack: that's a separate bug in CIFAR iterator.
Seems like it loads batches of 10k examples into memory (5 batches total I think?)
But then doesn't account for those splits when it tries to get a subset from what it has in memory.
Overall looks like cifar iterator needs some work/optimization and proper tests...
		</comment>
		<comment id='3' author='AlexDBlack' date='2018-12-11T07:09:11Z'>
		After discussion: we might just remove this CIFAR 10 iterator.
However, we may add a thin CIFAR 10 iterator that downloads PNG format and uses ImageRecordReader internally...
		</comment>
		<comment id='4' author='AlexDBlack' date='2018-12-17T05:20:14Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/6875&gt;https://github.com/deeplearning4j/deeplearning4j/pull/6875&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='AlexDBlack' date='2019-01-16T06:35:47Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>