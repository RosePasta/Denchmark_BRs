<bug id='1181' author='VenumadhavVedula' open_date='2016-02-23T01:25:18Z' closed_time='2016-04-20T00:55:05Z'>
	<summary>Error: Unable to split on size larger than the number of rows</summary>
	<description>
Hi,
Am trying to run the CNN for custom data set. It works fine for certain values of batchsize and throws error: "Unable to split on size larger than the number of rows" for some other values.
Here is the gist: &lt;denchmark-link:https://gist.github.com/VenumadhavVedula/867220d16f141973592d&gt;https://gist.github.com/VenumadhavVedula/867220d16f141973592d&lt;/denchmark-link&gt;

Can you suggest what should be the optimal value of batchSize. From the DataSet exception it seems, numHoldout is greater than the numExamples (or) numFeatures (#rows).
	</description>
	<comments>
		<comment id='1' author='VenumadhavVedula' date='2016-02-23T05:55:35Z'>
		Can you give us the full stack trace?
		</comment>
		<comment id='2' author='VenumadhavVedula' date='2016-02-23T06:13:29Z'>
		Here is the stack trace:
Exception in thread "main" java.lang.IllegalArgumentException: Unable to split on size larger than the number of rows
at org.nd4j.linalg.dataset.DataSet.splitTestAndTrain(DataSet.java:621)
at org.deeplearning4j.examples.convolution.PoCDeepLearningCNN.main(PoCDeepLearningCNN.java:139)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)
		</comment>
		<comment id='3' author='VenumadhavVedula' date='2016-02-24T06:05:25Z'>
		I suspect that you may be trying to split a data set, where the requested number of examples in the test set is larger than the total number of examples in the DataSet.
For example, we can reproduce that sort of exception using the following code, tring to get a training set size of 10 from 8 total examples:
INDArray features = Nd4j.create(8, 10);     //8 examples, input size of 10
INDArray labels = Nd4j.create(8, 3);        //8 examples, output size of 3

DataSet ds = new DataSet(features, labels);

SplitTestAndTrain split = ds.splitTestAndTrain(6);
System.out.println(split.getTrain().numExamples());     //6 examples in training set
System.out.println(split.getTest().numExamples());      //2 examples in test set

SplitTestAndTrain split2 = ds.splitTestAndTrain(10);    //Exception: "Unable to split on size larger than the number of rows"
Let us know if that's the cause. If not, we'll need some more details to look into this further.
		</comment>
		<comment id='4' author='VenumadhavVedula' date='2016-02-24T10:24:44Z'>
		As you can see from the gist above, am using splitTrainNum = (int) (batchSize*.8) . Also the dataset is created using ImageRecordReader and RecordReaderDataSetIterator. Assuming Numfeatures is taken care internally.
Can you please check the gist  and let me know if am missing anything.
Dataset used (file system) is having 2 classes as shown below:
/Hand
/Hand/Left
/Hand/Left/Left_0000.jpg
....
/Hand/Left/Left_0006.jpg
/Hand/Right
/Hand/Right/Right_0000.jpg
....
/Hand/Right/Right_0005.jpg
		</comment>
		<comment id='5' author='VenumadhavVedula' date='2016-02-24T11:07:20Z'>
		After using the percentage overload function, am not getting the previous error. However, new exception is thrown as can be seen from the stack trace below:
Exception in thread "main" java.lang.IllegalArgumentException: Invalid input: length 0 (shape: [1, 0])
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.setInput(MultiLayerNetwork.java:1843)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1477)
at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1529)
at org.deeplearning4j.examples.convolution.PoCDeepLearningCNN.main(PoCDeepLearningCNN.java:146)
		</comment>
		<comment id='6' author='VenumadhavVedula' date='2016-02-24T11:29:20Z'>
		repeating my comments here from gitter, for context:
ok, looking at your gist: I have an idea of what might be happening
imagine you have 100 images total, and want a batch size of 40. In practice, this means ending up with 3 batches of size (40,40,20) per epoch
then you split into 0.8*40 = 32 examples, which fails for the 20 minibatch (can't get 32 examples from 20 examples)
one solution to that is to use the splitTrainAndTest(double percentTrain) instead of splitTrainAndTest(int numHoldout)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

As for the new error: this basically says that your input array has 1 row and 0 columns. clearly, this isn't a valid array.
I'm not sure why this is occurring though. Is there any way you can give me something I can run, to reproduce this locally? Even if the data/images are synthetic/nonsense, that's fine.
		</comment>
		<comment id='7' author='VenumadhavVedula' date='2016-02-24T11:32:45Z'>
		One more observation is that for the batch size where the code runs well, one of the classes is completely ignored. Such as in the case below left class is ignored.
Console Output:
Examples labeled as Left classified by model as Right: 4 times
Examples labeled as Right classified by model as Right: 2 times
Warning: class Left was never predicted by the model. This class was excluded from the average precision
==========================Scores========================================
Accuracy:  0.3333
Precision: 0.3333
Recall:    0.5
&lt;denchmark-h:h1&gt;F1 Score:  0.4&lt;/denchmark-h&gt;

		</comment>
		<comment id='8' author='VenumadhavVedula' date='2016-02-24T11:43:36Z'>
		Code you can use the gist &lt;denchmark-link:https://gist.github.com/VenumadhavVedula/0faf976c7b05a84eaa2e&gt;https://gist.github.com/VenumadhavVedula/0faf976c7b05a84eaa2e&lt;/denchmark-link&gt;
. And for data, am trying to send you the zip file (~18MB), its failing to attach here. If you share the mail id, i can send it to you via e-mail.
		</comment>
		<comment id='9' author='VenumadhavVedula' date='2016-02-24T11:56:53Z'>
		send it to me at &lt;denchmark-link:mailto:alex@skymind.io&gt;alex@skymind.io&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='VenumadhavVedula' date='2016-02-24T13:02:24Z'>
		Ok, I've had a look at the code and your data. I believe that we're looking at an edge case bug for splitting: the data you sent me was 13 images, using batch size of 2 -&gt; eventually we end up with a single example. Then splitting on that single example is giving non-sensical results.
I've opened an issue on that here: &lt;denchmark-link:https://github.com/deeplearning4j/nd4j/issues/609&gt;deeplearning4j/nd4j#609&lt;/denchmark-link&gt;

As for network tuning to get good performance, there's probably a lot we can do there to improve the results. Perhaps we can discuss this further via email.
		</comment>
		<comment id='11' author='VenumadhavVedula' date='2016-02-24T14:10:47Z'>
		Thank you Alex! Will perform further tests and update you.
		</comment>
		<comment id='12' author='VenumadhavVedula' date='2019-01-21T06:53:17Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>