<bug id='7860' author='daanvdn' open_date='2019-06-06T07:38:21Z' closed_time='2019-07-03T07:29:28Z'>
	<summary>SequenceVectors  serialized with 1.0.0-beta3 cannot be deserialized with 1.0.0-beta4</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

hi, I'm experiencing issues when deserializing a binary org.deeplearning4j.models.sequencevectors.SequenceVectors object from file.
The SequenceVectors were serialized with version 1.0.0-beta3, I'm trying to deserialize using version 1.0.0-beta4
The code to serialize is as follows:
FileOutputStream fos =...;
SequenceVectors&lt;VocabWord&gt; sequenceVectors = ..;
WordVectorSerializer.writeSequenceVectors(sequenceVectors, new VocabWordFactory(), fos);
The code to deserialize is as follows:
File file = ...;
WordVectorSerializer.readSequenceVectors(new VocabWordFactory(), file)
This throws the following Exception:
org.nd4j.shade.jackson.databind.JsonMappingException: Unexpected token (END_OBJECT), expected FIELD_NAME: missing property '@class' that is to contain type id  (for class org.deeplearning4j.models.word2vec.VocabWord)
 at [Source: {"affinityId":null,"codeLength":7,"codes":[1,1,1,1,0,1,0],"elementFrequency":1946382.0,"historicalGradient":null,"index":0,"init":false,"label":"some_label","sequencesCount":1946382,"special":false,"storageId":2063836095177457530,"vocabId":null,"word":"some_word"}; line: 1, column: 281]
	at org.nd4j.shade.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)
	at org.nd4j.shade.jackson.databind.DeserializationContext.wrongTokenException(DeserializationContext.java:927)
	at org.nd4j.shade.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:151)
	at org.nd4j.shade.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:103)
	at org.nd4j.shade.jackson.databind.deser.BeanDeserializerBase.deserializeWithType(BeanDeserializerBase.java:966)
	at org.nd4j.shade.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)
	at org.nd4j.shade.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3562)
	at org.nd4j.shade.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2578)
	at org.deeplearning4j.models.sequencevectors.serialization.VocabWordFactory.deserialize(VocabWordFactory.java:41)
	at org.deeplearning4j.models.sequencevectors.serialization.VocabWordFactory.deserialize(VocabWordFactory.java:29)
	at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.readSequenceVectors(WordVectorSerializer.java:2153)
	at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.readSequenceVectors(WordVectorSerializer.java:2124)
Is there any way I can work around this without having to retrain my SequenceVectors?
	</description>
	<comments>
		<comment id='1' author='daanvdn' date='2019-06-06T08:09:51Z'>
		Hm... looks like a JSON format change between versions:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/word2vec/VocabWord.java#L35&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/word2vec/VocabWord.java#L35&lt;/denchmark-link&gt;

Looks like we need better NLP regression tests if this wasn't picked up... :/
Pretty sure this is trivial to fix in DL4J code: the annotation above becomes:
&lt;denchmark-code&gt;@JsonTypeInfo(use = JsonTypeInfo.Id.CLASS, include = JsonTypeInfo.As.PROPERTY, property = "@class", defaultImpl = VocabWord.class)
&lt;/denchmark-code&gt;

(though adding the fully qualified class name to each vocab entry isn't exactly efficient)
As for doing this from the user side on 1.0.0-beta4: good question.... I may have a way, but I'll need something to test it on first.
		</comment>
		<comment id='2' author='daanvdn' date='2019-06-06T08:24:20Z'>
		&lt;denchmark-link:https://github.com/daanvdn&gt;@daanvdn&lt;/denchmark-link&gt;
 In the absence of a way to test this, here's by best guess for a workaround:
&lt;denchmark-code&gt;        final ObjectMapper om = new ObjectMapper();
        SimpleModule module = new SimpleModule();
        module.addDeserializer(VocabWord.class, new StdDeserializer&lt;VocabWord&gt;() {
            @Override
            public VocabWord deserialize(JsonParser jp, DeserializationContext ctx) throws IOException, JsonProcessingException {
                String str = jp.readValueAsTree().toString();
                return om.readValue(str, VocabWord.class);
            }
        });
        SequenceElement.mapper().registerModule(module);
&lt;/denchmark-code&gt;

However we might need one more step:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/serde/JsonMappers.java#L193&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/serde/JsonMappers.java#L193&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;om.setAnnotationIntrospector(new IgnoreJsonTypeInfoIntrospector(Collections.&lt;Class&gt;singletonList(VocabWord.class)));
&lt;/denchmark-code&gt;

But with some reflection magic to create that private class (or copy/paste instead)
		</comment>
		<comment id='3' author='daanvdn' date='2019-06-06T08:25:21Z'>
		Ouch.
Other workaround would be switch to beta3, save to csv format, switch back to beta4 and deserialized it back again.
		</comment>
		<comment id='4' author='daanvdn' date='2019-06-06T08:50:15Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 I'll first try &lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
's suggestion; looks like that might be the easiest fix. I'll let you know if it works
		</comment>
		<comment id='5' author='daanvdn' date='2019-06-06T08:57:17Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 I thought there was a method in  to save as CSV but can't find it. There's only . Should I write custom logic for writing CSV?
		</comment>
		<comment id='6' author='daanvdn' date='2019-06-06T09:42:41Z'>
		Hm. once you serialize your model, it's a zip. CSV files are within.
		</comment>
		<comment id='7' author='daanvdn' date='2019-06-06T09:43:28Z'>
		That's how old format worked. It was non efficient, but allowed interop with anything else. Now there's new format, which is binary for weights + json for everything else.
		</comment>
		<comment id='8' author='daanvdn' date='2019-06-06T09:51:47Z'>
		As far as I can see, CSV serialization as you describe it is only supported for writing Word2Vec not  for writing  SequenceVectors
		</comment>
		<comment id='9' author='daanvdn' date='2019-06-06T09:54:45Z'>
		But Word2Vec extends SequenceVectors... It's been quite a while since i've looked into it though :(
		</comment>
		<comment id='10' author='daanvdn' date='2019-06-06T10:13:07Z'>
		yeah but for Word2Vec there is custom logic for serializing the WeightLookupTable as csv.  For SequenceVectors it's always serialized as json. I'll implement my own csv logic for the latter and then take it from there
		</comment>
		<comment id='11' author='daanvdn' date='2019-07-03T07:29:22Z'>
		&lt;denchmark-link:https://github.com/alexanderst&gt;@alexanderst&lt;/denchmark-link&gt;
 ok to close now, i suppose?
		</comment>
	</comments>
</bug>