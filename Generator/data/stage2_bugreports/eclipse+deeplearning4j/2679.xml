<bug id='2679' author='rohrl' open_date='2017-01-14T01:18:58Z' closed_time='2017-02-17T05:50:23Z'>
	<summary>Inception v3 (with weights) imported from Keras gives meaningless output</summary>
	<description>
I'm trying to import Inception v3 from Keras to dl4j.
I managed to import the model from json+h5 by making few small tweaks to latest KerasModel class. However when I feed same data as to Keras's model, I get different results.
Actually I'm always getting very similar, meaningless output - all 1000 values nearly equal to 0.001.
I figured that during import dimensions are re-shuffled - Keras model takes shape of [1, 299, 299, 3], while dl4j expects [1, 3, 299, 299]. However, no matter how I permute/flatten the input, I never get anything meaningful - just this flat distribution of numbers close to 0.001. Also 5 largest outputs always come from same 5 categories (not always same order).
I tried nd4j's ArrayUtil.flattenDoubleArray as well as my own implementation of flattening and permuting, tried both 'c' and 'f' for Nd4j.create. All of these always resulted in similar output described above.
One thing I noticed is in KerasModel.copyWeightsToModel() convolution layers dimensions are permuted for TF using: .permute(3, 2, 0, 1). However if I apply this permuation to Keras's input, the resulting shape is not compatible to the dl4j's expected shape. So instead I permute the input with (0, 3, 2, 1), not sure if this is correct but at least the shape matches.
This was done using 0.7.2 core + 0.7.3-snapshot of import module.
I had to add few tweaks to the KerasModel.copyWeightsToModel() to make the import successful:
weights import was breaking on layers named "batchnormalization_1_running" (the numbers went from 1 to 94). I assumed the 'running' suffix was parameter name, because it couldn't find the dl4j layer unless I took off the suffix, so I did. I also added parameter mapping from 'running' to 'var' - not sure if this was correct, but I couldn't find anything sensible among the available constants in KerasModel.mapParameterName().
There were following warnings during import:
Layer "Layer batchnormalization_1" momentum has been set but will not be applied unless the updater is set to NESTEROVS. (for layers batchnormalization_1 to batchnormalization_94)
The Keras model I used was keras.applications.inception_v3
Below is the script I used to run Python model, which gives correct predictions.
It also prints the network input, which I tried to use with imported model in dl4j (first permuting its shape as described above).
`from keras.preprocessing import image
from imagenet_utils import preprocess_input, decode_predictions
import numpy as np
from keras.applications.inception_v3 import InceptionV3
def preprocess_input(x):
x /= 255.
x -= 0.5
x *= 2.
return x
model = InceptionV3(weights='imagenet', include_top=True)
np.set_printoptions(threshold=np.nan)
img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(299, 299))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
print('\n\nInput array:\n')
print(x)
preds = model.predict(x)
print('\n\nPredicted:', decode_predictions(preds))`
	</description>
	<comments>
		<comment id='1' author='rohrl' date='2017-01-14T01:41:24Z'>
		&lt;denchmark-link:https://github.com/rohrl&gt;@rohrl&lt;/denchmark-link&gt;
 which backend? If TensorFlow, this is known problem with a fix on its way.
		</comment>
		<comment id='2' author='rohrl' date='2017-01-14T01:53:28Z'>
		Yes, TensorFlow.
Can you give an estimate when the fix will be available?
Is there anything I could do to make it work for me locally before the fix is released?
		</comment>
		<comment id='3' author='rohrl' date='2017-02-17T05:50:23Z'>
		Nothing more to do here except release. Just keep an eye on that.
		</comment>
		<comment id='4' author='rohrl' date='2019-01-19T14:06:58Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>