<bug id='3153' author='AlexDBlack' open_date='2017-03-30T04:52:26Z' closed_time='2017-04-03T00:02:56Z'>
	<summary>ParallelWrapper + LR schedules not handled correctly?</summary>
	<description>
LR schedules are derived from the iteration count in the model and updated during training. But the master model doesn't get updated by the averaging process. Learning rate schedules are handled in Spark by manually updating the iteration counts in the master model:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/paramavg/ParameterAveragingTrainingMaster.java#L929&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/main/java/org/deeplearning4j/spark/impl/paramavg/ParameterAveragingTrainingMaster.java#L929&lt;/denchmark-link&gt;

Furthermore, tests for PW iteration counts like this would be a good idea too:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/test/java/org/deeplearning4j/spark/impl/paramavg/TestSparkMultiLayerParameterAveraging.java#L705&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-scaleout/spark/dl4j-spark/src/test/java/org/deeplearning4j/spark/impl/paramavg/TestSparkMultiLayerParameterAveraging.java#L705&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2017-03-30T05:58:58Z'>
		&lt;denchmark-link:https://cloud.githubusercontent.com/assets/1445295/24489569/20c70c5e-14d3-11e7-8173-512ca2b8c162.png&gt;&lt;/denchmark-link&gt;

Confirmed this happens with any model trained with PW. The LR in the image above should be 0.005, but it is 0.1
		</comment>
		<comment id='2' author='AlexDBlack' date='2017-03-30T08:00:42Z'>
		I've fixed it in my branch.
		</comment>
		<comment id='3' author='AlexDBlack' date='2018-09-30T20:26:50Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>