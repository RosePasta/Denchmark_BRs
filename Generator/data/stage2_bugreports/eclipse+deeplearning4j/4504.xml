<bug id='4504' author='abhaybd' open_date='2018-01-12T05:27:41Z' closed_time='2018-04-25T09:10:42Z'>
	<summary>Android: Cannot use reflections - Keras and custom layers can't be used as a result</summary>
	<description>
I trained a model in keras 1.2.2, and I'm trying to load it into DL4J 0.9.1 on Android.
I've followed the steps at &lt;denchmark-link:https://github.com/eclipse/deeplearning4j/issues/3261&gt;#3261&lt;/denchmark-link&gt;
 to convert the model into a zip file using . I was able to import the keras model and export it into the DL4J format on desktop. However, when I try to import it on android, it fails, talking about a .
This is the relevant line in the stacktrace:
Caused by: java.lang.RuntimeException: org.nd4j.shade.jackson.databind.JsonMappingException: Could not resolve type id 'TensorFlowCnnToFeedForwardPreProcessor' into a subtype of [simple type, class org.deeplearning4j.nn.conf.InputPreProcessor]: known type ids = [InputPreProcessor, binomialSampling, cnnToFeedForward, cnnToRnn, composableInput, feedForwardToCnn, feedForwardToRnn, rnnToCnn, rnnToFeedForward, unitVariance, zeroMean, zeroMeanAndUnitVariance]
The full stacktrace is here: &lt;denchmark-link:https://pastebin.com/ajTDzPS9&gt;https://pastebin.com/ajTDzPS9&lt;/denchmark-link&gt;

My build.gradle file is here: &lt;denchmark-link:https://pastebin.com/HmhS9kJK&gt;https://pastebin.com/HmhS9kJK&lt;/denchmark-link&gt;

I'm trying to load the model using ModelSerializer.restoreMultiLayerNetwork().
The github repo with all the code is here: &lt;denchmark-link:https://github.com/coolioasjulio/devanagari-excercise-app/tree/with-model-import&gt;https://github.com/coolioasjulio/devanagari-excercise-app/tree/with-model-import&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='abhaybd' date='2018-01-12T05:54:54Z'>
		Looks like TensorFlowCnnToFeedForwardPreProcessor is missing from the list here:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/InputPreProcessor.java#L39&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/conf/InputPreProcessor.java#L39&lt;/denchmark-link&gt;

Is it just a matter of adding it there &lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='2' author='abhaybd' date='2018-01-12T06:25:35Z'>
		Probably not, unfortunately - they are in different modules - hence we can't reference the Keras classes in InputPreProcessor annotations.
It should in theory get picked up via reflection (that's how it works normally) but whether reflection works properly on Android is another thing... (removing reflection entirely here is on my to-do list, but that won't happen right away).
		</comment>
		<comment id='3' author='abhaybd' date='2018-01-12T06:35:19Z'>
		Ah, reflection. @coolioasjulio You might need to disable ProGuard on these classes to get reflection to work properly.
		</comment>
		<comment id='4' author='abhaybd' date='2018-01-12T06:39:15Z'>
		If that doesn't work, I can probably work out a manual (and ugly) workaround to manually register the Keras classes for JSON (de)serialization. But I'd recommend trying to get reflection working properly first :)
		</comment>
		<comment id='5' author='abhaybd' date='2018-01-12T07:03:35Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 How do you disable proguard? I added this to proguard-rules.pro:
&lt;denchmark-code&gt;-dontoptimize
-dontshrink
-dontusemixedcaseclassnames
-dontskipnonpubliclibraryclasses
-dontpreverify
-verbose
&lt;/denchmark-code&gt;

However, the same error showed up. Then I tried setting this in the build.gradle in android &gt; buildTypes &gt; release:
&lt;denchmark-code&gt;useProguard false
&lt;/denchmark-code&gt;

Even with this on, the same error persists. Am I disabling proguard correctly?
		</comment>
		<comment id='6' author='abhaybd' date='2018-01-12T07:39:17Z'>
		Probably safe to say it's disabled. Is there anything in the log that shows something related to errors with reflection?
		</comment>
		<comment id='7' author='abhaybd' date='2018-01-12T07:53:24Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 No, it doesn't say anything about reflection or proguard. It just says:

It then prints out the entire JSON structure of the model, and then references some classes. After disabling proguard the stack trace hasn't changed at all from before, even after cleaning and rebuilding. The full stack trace is at the top in the original issue, if you want to read the whole thing.
		</comment>
		<comment id='8' author='abhaybd' date='2018-01-12T07:57:46Z'>
		Use Logback, Log4j, or something to display debug messages from DL4J and see what it says.
The dl4j-examples uses Logback, for example:
&lt;denchmark-link:https://github.com/deeplearning4j/dl4j-examples/blob/master/dl4j-examples/pom.xml#L142&gt;https://github.com/deeplearning4j/dl4j-examples/blob/master/dl4j-examples/pom.xml#L142&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/resources&gt;https://github.com/deeplearning4j/dl4j-examples/tree/master/dl4j-examples/src/main/resources&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='abhaybd' date='2018-01-14T06:28:07Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 I set up logback and this is what I got: (these are only the lines printed by logback)
&lt;denchmark-code&gt;I/System.out: 22:24:00.822 [AsyncTask #1] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [CpuBackend] backend
I/System.out: 22:24:00.872 [AsyncTask #1] WARN org.reflections.Reflections - given scan urls are empty. set urls in the configuration
I/System.out: 22:24:01.009 [AsyncTask #1] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 4
I/System.out: 22:24:01.014 [AsyncTask #1] WARN org.reflections.Reflections - given scan urls are empty. set urls in the configuration
I/System.out: 22:24:01.430 [AsyncTask #1] INFO org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 4
I/System.out: 22:24:01.431 [AsyncTask #1] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Backend used: [CPU]; OS: [Linux]
I/System.out: 22:24:01.431 [AsyncTask #1] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Cores: [8]; Memory: [0.3GB];
I/System.out: 22:24:01.432 [AsyncTask #1] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
I/System.out: 22:24:01.636 [AsyncTask #1] WARN org.reflections.Reflections - given scan urls are empty. set urls in the configuration
&lt;/denchmark-code&gt;

So it looks like it has something to do with reflection. What does it mean given scan urls are empty. set urls in the configuration? Is that something I can do on my end?
		</comment>
		<comment id='10' author='abhaybd' date='2018-01-14T23:35:22Z'>
		
given scan urls are empty. set urls in the configuration

I'm not 100% sure, but I suspect this indicates that the reflections library can't find (or access?) JARs on the classpath. Normally it'll get a list of dependency JARs to scan, and then scan all of them for classes/resources. It's not something that the user should be messing with, generally.
		</comment>
		<comment id='11' author='abhaybd' date='2018-01-15T00:09:20Z'>
		I've already turned off proguard to see if that helps with the reflections. What else can I do?
Is this a fix that would have to be implemented in the library? (not on my end)
		</comment>
		<comment id='12' author='abhaybd' date='2018-01-15T00:24:37Z'>
		
removing reflection entirely here is on my to-do list, but that won't happen right away

That is something we can do to fix it, but it's not a simple/easy fix...
Beyond that, I'm not sure why reflections is having trouble here.
As to the ugly workaround that I mentioned previously - you can try this before loading your network:
&lt;denchmark-code&gt;import org.nd4j.shade.jackson.databind.jsontype.NamedType;
List&lt;NamedType&gt; types = new ArrayList&lt;&gt;();
types.add(new NamedType(TensorFlowCnnToFeedForwardPreProcessor.class, "TensorFlowCnnToFeedForwardPreProcessor"));
//Do this "new NamedType(...) for the other layers and preprocessors you are having trouble with
NeuralNetConfiguration.reinitMapperWithSubtypes(types);
&lt;/denchmark-code&gt;

Note that I have not tested this, but in theory this (or something close) should work.
		</comment>
		<comment id='13' author='abhaybd' date='2018-01-15T00:44:28Z'>
		Looks like Reflections doesn't work so well on Android, so yeah we shouldn't be relying on it...
&lt;denchmark-link:https://github.com/ronmamo/reflections/issues/127&gt;ronmamo/reflections#127&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='abhaybd' date='2018-01-16T00:48:27Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 Yeah, that works! I needed to add  to my dependencies to access , but after that, the model is working like normal!
Thanks so much, I was having a hell of a time trying to get this to work!
		</comment>
		<comment id='15' author='abhaybd' date='2018-01-16T00:52:43Z'>
		Great. I'll re-open this actually, until we have a confirmed real/proper solution for it (i.e., no more reflections required)
		</comment>
		<comment id='16' author='abhaybd' date='2018-04-25T09:10:41Z'>
		Reflections library has been removed from DL4J entirely - addressed here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4956&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4956&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/4950&gt;https://github.com/deeplearning4j/deeplearning4j/pull/4950&lt;/denchmark-link&gt;

This should no longer be an issue.
		</comment>
		<comment id='17' author='abhaybd' date='2018-09-22T21:13:58Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>