<bug id='8838' author='AlexDBlack' open_date='2020-04-15T12:42:04Z' closed_time='2020-04-17T01:18:58Z'>
	<summary>lstmLayer_bp: not taking into account gradient contribution from last cell state</summary>
	<description>
Suppose during LSTM forward pass we return the full time series, yLast and cLast.
It appears that if we use the cLast output for something that impacts the loss function, we'll be passing gradients backward through this variable too. The lstmLayer_bp implementation doesn't seem to take it into account.
Java test case: compare line 57 vs. 58
&lt;denchmark-link:https://gist.github.com/AlexDBlack/41f37a66eff1619e9598588403a25fc0&gt;https://gist.github.com/AlexDBlack/41f37a66eff1619e9598588403a25fc0&lt;/denchmark-link&gt;

Line 57 fails gradient check, line 58 passes.
Essentially, the mul(0) guarantees that the dLdcLast passed into the backprop op is 0s, as the loss function now doesn't depend (directly) on that variable/output. Put another way: a non-zero gradient contribution for dLdcLast results in a gradient check failure.
The solution should be simple: at the last time step, just add the passed in dLdcLast array to the calculated dLdc at that time step.
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2020-04-17T01:18:58Z'>
		Confirmed fixed, thanks
		</comment>
	</comments>
</bug>