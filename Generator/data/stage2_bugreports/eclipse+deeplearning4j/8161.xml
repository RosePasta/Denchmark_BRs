<bug id='8161' author='ocean211' open_date='2019-08-28T13:04:42Z' closed_time='2019-09-05T08:30:05Z'>
	<summary>CUDNN_STATUS_MAPPING_ERROR on CudnnLSTMHelper.activate</summary>
	<description>
########
Error description:
########
java.lang.RuntimeException: cuDNN status = 7: CUDNN_STATUS_MAPPING_ERROR using snapshots and CUDA (no errors on beta4)
########
Steps to reproduce the problem:
########
Run org.deeplearning4j.examples.recurrent.basic.BasicRNNExample
I used a modified but equivalent version of this code
########
System configuration:
########
32GB RAM
980ti GPU
Windows 10 Pro - 64
CUDA 10.0.130_411.31 + cuDNN 7.6.3.30 installed unzipping under C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\
########
Output including stack trace:
########
&lt;denchmark-code&gt;[main] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [JCublasBackend] backend
CUDA device 0: [GeForce GTX 980 Ti]; cc: [5.2]; Total memory: [6442450944];
[main] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 32
[main] INFO org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 0
[main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Backend used: [CUDA]; OS: [Windows 10]
[main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Cores: [12]; Memory: [7,1GB];
[main] INFO org.nd4j.linalg.api.ops.executioner.DefaultOpExecutioner - Blas vendor: [CUBLAS]
[main] INFO org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner - Device Name: [GeForce GTX 980 Ti]; CC: [5.2]; Total/free memory: [6442450944]
[main] INFO org.deeplearning4j.nn.multilayer.MultiLayerNetwork - Starting MultiLayerNetwork with WorkspaceModes set to [training: ENABLED; inference: ENABLED], cacheMode set to [NONE]
Epoch 0
Exception in thread "main" java.lang.RuntimeException: cuDNN status = 7: CUDNN_STATUS_MAPPING_ERROR
	at org.deeplearning4j.nn.layers.BaseCudnnHelper.checkCudnn(BaseCudnnHelper.java:48)
	at org.deeplearning4j.nn.layers.recurrent.CudnnLSTMHelper.activate(CudnnLSTMHelper.java:535)
	at org.deeplearning4j.nn.layers.recurrent.LSTMHelpers.activateHelper(LSTMHelpers.java:202)
	at org.deeplearning4j.nn.layers.recurrent.LSTM.activateHelper(LSTM.java:160)
	at org.deeplearning4j.nn.layers.recurrent.LSTM.activate(LSTM.java:132)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.ffToLayerActivationsInWs(MultiLayerNetwork.java:1126)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:2724)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.computeGradientAndScore(MultiLayerNetwork.java:2682)
	at org.deeplearning4j.optimize.solvers.BaseOptimizer.gradientAndScore(BaseOptimizer.java:170)
	at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:63)
	at org.deeplearning4j.optimize.Solver.optimize(Solver.java:52)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fitHelper(MultiLayerNetwork.java:2286)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:2244)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:2307)
	at org.ocean211.dl4jtest.Main.main(Main.java:113)

&lt;/denchmark-code&gt;

########
Source:
########
&lt;denchmark-code&gt;/**
 * Main.java
 *
 * Created on 28-ago-2019 14.05.45
 */

package org.ocean211.dl4jtest;

import java.util.ArrayList;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Random;
import org.deeplearning4j.nn.conf.MultiLayerConfiguration;
import org.deeplearning4j.nn.conf.NeuralNetConfiguration;
import org.deeplearning4j.nn.conf.layers.LSTM;
import org.deeplearning4j.nn.conf.layers.RnnOutputLayer;
import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
import org.deeplearning4j.nn.weights.WeightInit;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.nd4j.linalg.activations.Activation;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.api.ops.impl.indexaccum.IMax;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.factory.Nd4j;
import org.nd4j.linalg.learning.config.RmsProp;
import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction;

public class Main {
    private static final char[] LEARNSTRING = "*A bad workman always complains of his tools.".toCharArray();

    // a list of all possible characters
    private static final List&lt;Character&gt; LEARNSTRING_CHARS_LIST = new ArrayList&lt;&gt;();

    // RNN dimensions
    private static final int HIDDEN_LAYER_WIDTH = 50;
    private static final int HIDDEN_LAYER_CONT = 2;
    private static final Random r = new Random(12345);

    public static void main(String[] args) {

        // create a dedicated list of possible chars in LEARNSTRING_CHARS_LIST
        final LinkedHashSet&lt;Character&gt; LEARNSTRING_CHARS = new LinkedHashSet&lt;&gt;();
        for (final char c : LEARNSTRING) {LEARNSTRING_CHARS.add(c);}
        LEARNSTRING_CHARS_LIST.addAll(LEARNSTRING_CHARS);

        // some common parameters
        final NeuralNetConfiguration.Builder builder = new NeuralNetConfiguration.Builder();
        builder.seed(123);
        builder.biasInit(0);
        builder.miniBatch(false);
        builder.updater(new RmsProp(0.001));
        builder.weightInit(WeightInit.XAVIER);

        final NeuralNetConfiguration.ListBuilder listBuilder = builder.list();

        // first difference, for rnns we need to use LSTM.Builder
        for (int i = 0; i &lt; HIDDEN_LAYER_CONT; i++) {
            final LSTM.Builder hiddenLayerBuilder = new LSTM.Builder();
            hiddenLayerBuilder.nIn(i == 0 ? LEARNSTRING_CHARS.size() : HIDDEN_LAYER_WIDTH);
            hiddenLayerBuilder.nOut(HIDDEN_LAYER_WIDTH);
            // adopted activation function from LSTMCharModellingExample
            // seems to work well with RNNs
            hiddenLayerBuilder.activation(Activation.TANH);
            listBuilder.layer(i, hiddenLayerBuilder.build());
        }

        // we need to use RnnOutputLayer for our RNN
        final RnnOutputLayer.Builder outputLayerBuilder = new RnnOutputLayer.Builder(LossFunction.MCXENT);
        // softmax normalizes the output neurons, the sum of all outputs is 1
        // this is required for our sampleFromDistribution-function
        outputLayerBuilder.activation(Activation.SOFTMAX);
        outputLayerBuilder.nIn(HIDDEN_LAYER_WIDTH);
        outputLayerBuilder.nOut(LEARNSTRING_CHARS.size());
        listBuilder.layer(HIDDEN_LAYER_CONT, outputLayerBuilder.build());

        // create network
        final MultiLayerConfiguration conf = listBuilder.build();
        final MultiLayerNetwork net = new MultiLayerNetwork(conf);
        net.init();
        net.setListeners(new ScoreIterationListener(1));

        /*
		 * CREATE OUR TRAINING DATA
         */
        // create input and output arrays: SAMPLE_INDEX, INPUT_NEURON,
        // SEQUENCE_POSITION
        final INDArray input = Nd4j.zeros(1, LEARNSTRING_CHARS_LIST.size(), LEARNSTRING.length);
        final INDArray labels = Nd4j.zeros(1, LEARNSTRING_CHARS_LIST.size(), LEARNSTRING.length);
        // loop through our sample-sentence
        int samplePos = 0;
        for (char currentChar : LEARNSTRING) {
            // small hack: when currentChar is the last, take the first char as
            // nextChar - not really required. Added to this hack by adding a starter first character.
            char nextChar = LEARNSTRING[(samplePos + 1) % (LEARNSTRING.length)];
            // input neuron for current-char is 1 at "samplePos"
            input.putScalar(new int[]{0, LEARNSTRING_CHARS_LIST.indexOf(currentChar), samplePos}, 1);
            // output neuron for next-char is 1 at "samplePos"
            labels.putScalar(new int[]{0, LEARNSTRING_CHARS_LIST.indexOf(nextChar), samplePos}, 1);
            ++samplePos;
        }
        final DataSet trainingData = new DataSet(input, labels);

        // some epochs
        for (int epoch = 0; epoch &lt; 100; epoch++) {

            System.out.println("Epoch " + epoch);

            // train the data
            net.fit(trainingData);

            // clear current stance from the last example
            net.rnnClearPreviousState();

            // put the first character into the rrn as an initialisation
            final INDArray testInit = Nd4j.zeros(1, LEARNSTRING_CHARS_LIST.size(), 1);
            testInit.putScalar(LEARNSTRING_CHARS_LIST.indexOf(LEARNSTRING[0]), 1);

            // run one step -&gt; IMPORTANT: rnnTimeStep() must be called, not
            // output()
            // the output shows what the net thinks what should come next
            INDArray output = net.rnnTimeStep(testInit);

            // now the net should guess LEARNSTRING.length more characters
            for (char dummy : LEARNSTRING) {

                // first process the last output of the network to a concrete
                // neuron, the neuron with the highest output has the highest
                // chance to get chosen
                int sampledCharacterIdx = Nd4j.getExecutioner().exec(new IMax(output, 1)).getInt(0);

                // print the chosen output
                System.out.print(LEARNSTRING_CHARS_LIST.get(sampledCharacterIdx));

                // use the last output as input
                INDArray nextInput = Nd4j.zeros(1, LEARNSTRING_CHARS_LIST.size(), 1);
                nextInput.putScalar(sampledCharacterIdx, 1);
                output = net.rnnTimeStep(nextInput);

            }
            System.out.print("\n");
        }
    }
}

&lt;/denchmark-code&gt;

########
pom.xml
########
&lt;denchmark-code&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;org.ocean211&lt;/groupId&gt;
    &lt;artifactId&gt;dl4jtest&lt;/artifactId&gt;
    &lt;version&gt;0.5&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;
    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;snapshots-repo&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
                &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;dl4j.version&gt;1.0.0-SNAPSHOT&lt;/dl4j.version&gt;
        &lt;!--&lt;dl4j.version&gt;1.0.0-beta4&lt;/dl4j.version&gt;--&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
            &lt;!--&lt;artifactId&gt;nd4j-native-platform&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;nd4j-cuda-9.2&lt;/artifactId&gt;--&gt;
            &lt;artifactId&gt;nd4j-cuda-10.0&lt;/artifactId&gt;
            &lt;!--&lt;artifactId&gt;nd4j-cuda-10.1&lt;/artifactId&gt;--&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-cuda-9.2&lt;/artifactId&gt;--&gt;
            &lt;artifactId&gt;deeplearning4j-cuda-10.0&lt;/artifactId&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-cuda-10.1&lt;/artifactId&gt;--&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;
            &lt;version&gt;1.7.28&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.6.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;
                                    &lt;mainClass&gt;com.genetica.app.nnprepdata.MainFrame&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ocean211' date='2019-08-29T00:46:59Z'>
		
CUDA 10.0.130_411.31 + cuDNN 7.6.3.30 installed unzipping under C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\

With CUDA 10.0, please try to use cuDNN 7.4.x instead.
		</comment>
		<comment id='2' author='ocean211' date='2019-08-29T07:10:39Z'>
		Thanks, under nVidia repositories I found 2 cuDNN 7.4.x libraries, cudnn-10.0-windows10-x64-v7.4.1.5 and cudnn-10.0-windows10-x64-v7.4.2.24, but none of them worked, I have the same error.
		</comment>
		<comment id='3' author='ocean211' date='2019-08-29T11:06:49Z'>
		Does it happen with CUDA 10.1?
		</comment>
		<comment id='4' author='ocean211' date='2019-08-29T11:23:50Z'>
		With CUDA 10.1 I have an error related to an unsupported function, perhaps because of the 980ti compute capability (5.2).
		</comment>
		<comment id='5' author='ocean211' date='2019-08-29T11:37:42Z'>
		&lt;denchmark-link:https://github.com/ocean211&gt;@ocean211&lt;/denchmark-link&gt;
 show stack trace of that "error related to an unsupported function" please
		</comment>
		<comment id='6' author='ocean211' date='2019-08-29T12:37:18Z'>
		Sorry, I didn't remember well: I have the same error with 10.1 and the snapshots and the following error with the beta4 which instead works with cuda 10.0 and 9.2:
&lt;denchmark-code&gt;[main] INFO org.nd4j.linalg.factory.Nd4jBackend - Loaded [JCublasBackend] backend
[main] INFO org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for NativeOps: 32
Exception in thread "main" java.lang.ExceptionInInitializerError
	at org.deeplearning4j.nn.conf.NeuralNetConfiguration$Builder.seed(NeuralNetConfiguration.java:671)
	at org.ocean211.dl4jtest.Main.main(Main.java:52)
Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:5900)
	at org.nd4j.linalg.factory.Nd4j.initContext(Nd4j.java:5766)
	at org.nd4j.linalg.factory.Nd4j.&lt;clinit&gt;(Nd4j.java:202)
	... 2 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.nd4j.linalg.factory.Nd4j.initWithBackend(Nd4j.java:5860)
	... 4 more
Caused by: java.lang.UnsatisfiedLinkError: no jnicusparse in java.library.path
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867)
	at java.lang.Runtime.loadLibrary0(Runtime.java:870)
	at java.lang.System.loadLibrary(System.java:1122)
	at org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1336)
	at org.bytedeco.javacpp.Loader.load(Loader.java:1077)
	at org.bytedeco.javacpp.Loader.load(Loader.java:947)
	at org.bytedeco.cuda.global.cusparse.&lt;clinit&gt;(cusparse.java:15)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.bytedeco.javacpp.Loader.load(Loader.java:1006)
	at org.bytedeco.javacpp.Loader.load(Loader.java:947)
	at org.bytedeco.cuda.global.cusolver.&lt;clinit&gt;(cusolver.java:19)
	at org.nd4j.jita.allocator.context.impl.BasicContextPool.createNewSolverHandle(BasicContextPool.java:220)
	at org.nd4j.jita.allocator.context.impl.LimitedContextPool.fillPoolWithResources(LimitedContextPool.java:115)
	at org.nd4j.jita.allocator.context.impl.LimitedContextPool.&lt;init&gt;(LimitedContextPool.java:80)
	at org.nd4j.jita.handler.impl.CudaZeroHandler.&lt;init&gt;(CudaZeroHandler.java:145)
	at org.nd4j.jita.allocator.impl.AtomicAllocator.&lt;init&gt;(AtomicAllocator.java:145)
	at org.nd4j.jita.allocator.impl.AtomicAllocator.&lt;clinit&gt;(AtomicAllocator.java:93)
	at org.nd4j.linalg.jcublas.JCublasNDArrayFactory.&lt;init&gt;(JCublasNDArrayFactory.java:85)
	... 9 more
Caused by: java.lang.UnsatisfiedLinkError: C:\Users\ocean211\.javacpp\cache\cuda-10.1-7.5-1.5-windows-x86_64.jar\org\bytedeco\cuda\windows-x86_64\jnicusparse.dll: Specified procedure could not be found	
at java.lang.ClassLoader$NativeLibrary.load(Native Method)
	at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941)
	at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824)
	at java.lang.Runtime.load0(Runtime.java:809)
	at java.lang.System.load(System.java:1086)
	at org.bytedeco.javacpp.Loader.loadLibrary(Loader.java:1316)
	... 24 more
&lt;/denchmark-code&gt;

Now my pom.xml is as follows:
&lt;denchmark-code&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;org.ocean211&lt;/groupId&gt;
    &lt;artifactId&gt;dl4jtest&lt;/artifactId&gt;
    &lt;version&gt;0.5&lt;/version&gt;
    &lt;packaging&gt;jar&lt;/packaging&gt;
    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;snapshots-repo&lt;/id&gt;
            &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
                &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
        &lt;!--&lt;dl4j.version&gt;1.0.0-SNAPSHOT&lt;/dl4j.version&gt;--&gt;
        &lt;dl4j.version&gt;1.0.0-beta4&lt;/dl4j.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
            &lt;!--&lt;artifactId&gt;nd4j-native-platform&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;nd4j-cuda-9.2&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;nd4j-cuda-10.0&lt;/artifactId&gt;--&gt;
            &lt;artifactId&gt;nd4j-cuda-10.1&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-cuda-9.2&lt;/artifactId&gt;--&gt;
            &lt;!--&lt;artifactId&gt;deeplearning4j-cuda-10.0&lt;/artifactId&gt;--&gt;
            &lt;artifactId&gt;deeplearning4j-cuda-10.1&lt;/artifactId&gt;
            &lt;version&gt;${dl4j.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;
            &lt;version&gt;1.7.28&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.6.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.2.1&lt;/version&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;shade&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;shadedArtifactAttached&gt;true&lt;/shadedArtifactAttached&gt;
                            &lt;filters&gt;
                                &lt;filter&gt;
                                    &lt;artifact&gt;*:*&lt;/artifact&gt;
                                    &lt;excludes&gt;
                                        &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;
                                        &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;
                                    &lt;/excludes&gt;
                                &lt;/filter&gt;
                            &lt;/filters&gt;
                            &lt;transformers&gt;
                                &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt;
                                    &lt;mainClass&gt;com.ocean211.dl4jtest.Main&lt;/mainClass&gt;
                                &lt;/transformer&gt;
                            &lt;/transformers&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.1.0&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;encoding&gt;${project.build.sourceEncoding}&lt;/encoding&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='ocean211' date='2019-08-29T13:13:34Z'>
		That can't happen, your pom.xml file doesn't contain any reference to cuda-10.1-7.5-1.5-windows-x86_64, which BTW isn't going to work with 1.0.0-SNAPSHOT.
		</comment>
		<comment id='8' author='ocean211' date='2019-08-29T13:23:21Z'>
		The very last stack trace is relative to beta4 and cuda 10.1. With snapshots I have the initial error: cuDNN status = 7: CUDNN_STATUS_MAPPING_ERROR. Ultimately, I have the same error with the last 3 versions of cuda using snapshots. But everything works with cuda 10.0 and 9.2 and beta4.
To leave nothing to chance, I rebooted after deinstalling and reinstalling a new cuda version and I cleared folder org under my maven repository and folder c:\users\ocean211\.javacpp.
Clean and rebuild after that
		</comment>
		<comment id='9' author='ocean211' date='2019-08-30T07:13:40Z'>
		Ok, so you're getting that error with snapshots and CUDA 10.1 + cuDNN 7.6?
		</comment>
		<comment id='10' author='ocean211' date='2019-08-30T08:01:21Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 Not exactly. Let me clarify it this way:

snapshots + cuda 9.2 + cuDNN -&gt; CUDNN_STATUS_MAPPING_ERROR
snapshots + cuda 10.0 + cuDNN (7.4.x and 7.6) -&gt; CUDNN_STATUS_MAPPING_ERROR
snapshots + cuda 10.1 + cuDNN (7.6) -&gt; CUDNN_STATUS_MAPPING_ERROR
beta4 + cuda 9.2 + cuDNN -&gt; OK
beta4 + cuda 10.0 + cuDNN (7.4.x and 7.6) -&gt; OK
beta4 + cuda 10.1 + cuDNN (7.6) -&gt; UnsatisfiedLinkError

The only think I have changed in the last few weeks is my monitor (from 24" 1600x1200 to 35" 3440x1440). It's a lot of video memory more than before.
		</comment>
		<comment id='11' author='ocean211' date='2019-08-30T08:06:49Z'>
		&lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 Are the snapshots being built for CC 5.2 now? Or just CC 5.0?
		</comment>
		<comment id='12' author='ocean211' date='2019-08-30T08:30:57Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 I tried a fresh installation of cuda 10.0 (cuda + gpu driver) using my old monitor (just in case...), but with snapshots it ends with CUDNN_STATUS_MAPPING_ERROR.
		</comment>
		<comment id='13' author='ocean211' date='2019-08-31T07:03:25Z'>
		Well, I guess we'll look at this at some point, but since you're the only person experiencing this it might not be before long.
		</comment>
		<comment id='14' author='ocean211' date='2019-08-31T09:01:47Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 Thanks anyway for your time
		</comment>
		<comment id='15' author='ocean211' date='2019-09-04T08:19:14Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 I just tried today snapshot and, I don't know what you did, but it works now, thanks!
		</comment>
	</comments>
</bug>