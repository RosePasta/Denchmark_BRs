<bug id='4182' author='eypros' open_date='2017-10-16T19:54:21Z' closed_time='2018-04-26T23:25:32Z'>
	<summary>GoogleNet pretrained ImageNet weights cannot be loaded</summary>
	<description>
I just used the example FeaturizedPreSave.java and modified it to load a GoogleNet network with the corresponding ImageNet weights. The changes are minimal but the execution fails with

Exception in thread "main" java.lang.RuntimeException: org.nd4j.shade.jackson.databind.JsonMappingException: Could not resolve type id 'PoolHelperVertex' into a subtype of [simple type, class org.deeplearning4j.nn.conf.graph.GraphVertex]: known type ids = [DuplicateToTimeSeriesVertex, ElementWiseVertex, GraphVertex, L2NormalizeVertex, L2Vertex, LastTimeStepVertex, LayerVertex, MergeVertex, PreprocessorVertex, ScaleVertex, StackVertex, SubsetVertex, UnstackVertex]
exception.

The code is below.
&lt;denchmark-code&gt;package org.deeplearning4j.examples.transferlearning.vgg16.dataHelpers;

import org.deeplearning4j.nn.graph.ComputationGraph;
import org.deeplearning4j.nn.modelimport.keras.InvalidKerasConfigurationException;
import org.deeplearning4j.nn.modelimport.keras.UnsupportedKerasConfigurationException;
import org.deeplearning4j.nn.transferlearning.TransferLearningHelper;
import org.deeplearning4j.zoo.PretrainedType;
import org.deeplearning4j.zoo.ZooModel;
import org.deeplearning4j.zoo.model.GoogLeNet;
import org.nd4j.linalg.dataset.DataSet;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import org.slf4j.Logger;

import java.io.File;
import java.io.IOException;

/**
 * The TransferLearningHelper class allows users to "featurize" a dataset at specific intermediate vertices/layers of a model
 * This example demonstrates how to presave these
 * Refer to the "FitFromFeaturized" example for how to fit a model with these featurized datasets
 * @author susaneraly on 2/28/17.
 */
public class FeaturizedPreSaveGoogleNetIssue {
    private static final Logger log = org.slf4j.LoggerFactory.getLogger(FeaturizedPreSaveGoogleNetIssue.class);

    private static final int trainPerc = 80;
    protected static final int batchSize = 15;
    public static final String featurizeExtractionLayer = "fc2";
    private static final String trainFolder = "trainFolder/flowers";
    private static final String testFolder = "testFolder/flowers";

    public static void main(String [] args) throws UnsupportedKerasConfigurationException, IOException, InvalidKerasConfigurationException {

        ZooModel zooModel =
            new GoogLeNet();
        ComputationGraph pretrainedNet = (ComputationGraph) zooModel
            .initPretrained(PretrainedType.IMAGENET);
        log.info("\n\nLoading org.deeplearning4j.transferlearning.vgg16...\n\n");
        log.info(pretrainedNet.summary());

        //use the TransferLearningHelper to freeze the specified vertices and below
        //NOTE: This is done in place! Pass in a cloned version of the model if you would prefer to not do this in place
        TransferLearningHelper transferLearningHelper = new TransferLearningHelper(pretrainedNet, featurizeExtractionLayer);
        log.info(pretrainedNet.summary());

        FlowerDataSetIterator.setup(batchSize,trainPerc);
        DataSetIterator trainIter = FlowerDataSetIterator.trainIterator();
        DataSetIterator testIter = FlowerDataSetIterator.testIterator();

        int trainDataSaved = 0;
        while(trainIter.hasNext()) {
            DataSet currentFeaturized = transferLearningHelper.featurize(trainIter.next());
            saveToDisk(currentFeaturized,trainDataSaved,true);
            trainDataSaved++;
        }

        int testDataSaved = 0;
        while(testIter.hasNext()) {
            DataSet currentFeaturized = transferLearningHelper.featurize(testIter.next());
            saveToDisk(currentFeaturized,testDataSaved,false);
            testDataSaved++;
        }

        log.info("Finished pre saving featurized test and train data");
    }

    private static void saveToDisk(DataSet currentFeaturized, int iterNum, boolean isTrain) {
        File fileFolder = isTrain ? new File(trainFolder): new File(testFolder);
        if (iterNum == 0) {
            fileFolder.mkdirs();
        }
        String fileName = "flowers-" + featurizeExtractionLayer + "-";
        fileName += isTrain ? "train-" : "test-";
        fileName += iterNum + ".bin";
        currentFeaturized.save(new File(fileFolder,fileName));
        log.info("Saved " + (isTrain?"train ":"test ") + "dataset #"+ iterNum);
    }
}

&lt;/denchmark-code&gt;

The full stack trace (as appearing in my console) is

Exception in thread "main" java.lang.RuntimeException: org.nd4j.shade.jackson.databind.JsonMappingException: Could not resolve type id 'PoolHelperVertex' into a subtype of [simple type, class org.deeplearning4j.nn.conf.graph.GraphVertex]: known type ids = [DuplicateToTimeSeriesVertex, ElementWiseVertex, GraphVertex, L2NormalizeVertex, L2Vertex, LastTimeStepVertex, LayerVertex, MergeVertex, PreprocessorVertex, ScaleVertex, StackVertex, SubsetVertex, UnstackVertex]
at [Source: java.io.StringReader@430fa4ef; line: 289, column: 7] (through reference chain: org.deeplearning4j.nn.conf.ComputationGraphConfiguration["vertices"]-&gt;java.util.LinkedHashMap["poolhelper_17"])
at org.deeplearning4j.nn.conf.ComputationGraphConfiguration.fromJson(ComputationGraphConfiguration.java:160)
at org.deeplearning4j.util.ModelSerializer.restoreComputationGraph(ModelSerializer.java:462)
at org.deeplearning4j.util.ModelSerializer.restoreComputationGraph(ModelSerializer.java:362)
at org.deeplearning4j.zoo.ZooModel.initPretrained(ZooModel.java:88)
at org.deeplearning4j.examples.transferlearning.vgg16.dataHelpers.FeaturizedPreSave.main(FeaturizedPreSave.java:46)
Caused by: org.nd4j.shade.jackson.databind.JsonMappingException: Could not resolve type id 'PoolHelperVertex' into a subtype of [simple type, class org.deeplearning4j.nn.conf.graph.GraphVertex]: known type ids = [DuplicateToTimeSeriesVertex, ElementWiseVertex, GraphVertex, L2NormalizeVertex, L2Vertex, LastTimeStepVertex, LayerVertex, MergeVertex, PreprocessorVertex, ScaleVertex, StackVertex, SubsetVertex, UnstackVertex]
at [Source: java.io.StringReader@430fa4ef; line: 289, column: 7] (through reference chain: org.deeplearning4j.nn.conf.ComputationGraphConfiguration["vertices"]-&gt;java.util.LinkedHashMap["poolhelper_17"])
at org.nd4j.shade.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)
at org.nd4j.shade.jackson.databind.DeserializationContext.unknownTypeException(DeserializationContext.java:948)
at org.nd4j.shade.jackson.databind.jsontype.impl.TypeDeserializerBase._handleUnknownTypeId(TypeDeserializerBase.java:275)
at org.nd4j.shade.jackson.databind.jsontype.impl.TypeDeserializerBase._findDeserializer(TypeDeserializerBase.java:162)
at org.nd4j.shade.jackson.databind.jsontype.impl.AsWrapperTypeDeserializer._deserialize(AsWrapperTypeDeserializer.java:100)
at org.nd4j.shade.jackson.databind.jsontype.impl.AsWrapperTypeDeserializer.deserializeTypedFromObject(AsWrapperTypeDeserializer.java:49)
at org.nd4j.shade.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:131)
at org.nd4j.shade.jackson.databind.deser.std.MapDeserializer._readAndBindStringMap(MapDeserializer.java:475)
at org.nd4j.shade.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:330)
at org.nd4j.shade.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:25)
at org.nd4j.shade.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:523)
at org.nd4j.shade.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:95)
at org.nd4j.shade.jackson.databind.deser.impl.BeanPropertyMap.findDeserializeAndSet(BeanPropertyMap.java:285)
at org.nd4j.shade.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:248)
at org.nd4j.shade.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:136)
at org.deeplearning4j.nn.conf.serde.ComputationGraphConfigurationDeserializer.deserialize(ComputationGraphConfigurationDeserializer.java:28)
at org.deeplearning4j.nn.conf.serde.ComputationGraphConfigurationDeserializer.deserialize(ComputationGraphConfigurationDeserializer.java:18)
at org.nd4j.shade.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3562)
at org.nd4j.shade.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2578)
at org.deeplearning4j.nn.conf.ComputationGraphConfiguration.fromJson(ComputationGraphConfiguration.java:158)


Deeplearning4j 0.9.1
platform information Win7
CUDA no

	</description>
	<comments>
		<comment id='1' author='eypros' date='2017-10-16T23:05:02Z'>
		What about current master?
		</comment>
		<comment id='2' author='eypros' date='2017-10-17T10:43:39Z'>
		You mean version 0.9.2-SNAPSHOT? I check it also but fails again. Same message.
		</comment>
		<comment id='3' author='eypros' date='2017-11-18T06:17:28Z'>
		Same issue here with version 0.9.1. In addition, the params initialization from pretrained model takes a long time (more than 1 minute) before going into this issue on my Nexus 6 device. Any progress on this? &lt;denchmark-link:https://github.com/eypros&gt;@eypros&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='eypros' date='2018-04-26T22:50:20Z'>
		&lt;denchmark-link:https://github.com/crockpotveggies&gt;@crockpotveggies&lt;/denchmark-link&gt;
 is this issue still viable?
		</comment>
		<comment id='5' author='eypros' date='2018-04-26T23:25:32Z'>
		We've made the decision to deprecate GoogLeNet. The problem with GoogLeNet is that it has a unique architecture and layer that's only been used for that specific model. It appears when we upgraded to support Keras 2, the import may have also been broken? Many other convolutional models perform better than GoogLeNet, and instead I believe it would be worthwhile to introduce more convolutional models such as InceptionV3, Xception, and InceptionResNetV2.
		</comment>
		<comment id='6' author='eypros' date='2018-09-22T12:13:42Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>