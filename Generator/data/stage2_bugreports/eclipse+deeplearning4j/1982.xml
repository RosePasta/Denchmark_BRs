<bug id='1982' author='anovstrup' open_date='2016-08-08T21:52:19Z' closed_time='2016-08-12T21:45:12Z'>
	<summary>Exception in HistogramIterationListener propagates out</summary>
	<description>
An error in an iteration listener (specifically, HistogramIterationListener) is causing the training process to stop early. In my case, it would be preferable to log a warning and move on with training.
Workaround: wrap the listener?
&lt;denchmark-code&gt;WARN  [2016-08-08 21:41:03,574] org.deeplearning4j.earlystopping.trainer.BaseEarlyStoppingTrainer: Early stopping training terminated due to exception at epoch 0, iteration 0
! java.lang.NumberFormatException: Infinite or NaN
! at java.math.BigDecimal.&lt;init&gt;(BigDecimal.java:895) ~[na:1.8.0_73]
! at java.math.BigDecimal.&lt;init&gt;(BigDecimal.java:872) ~[na:1.8.0_73]
! at org.deeplearning4j.ui.weights.HistogramBin.calcHistogram(HistogramBin.java:60) ~[deeplearning4j-ui-0.5.0.jar:na]
! at org.deeplearning4j.ui.weights.HistogramBin.access$300(HistogramBin.java:20) ~[deeplearning4j-ui-0.5.0.jar:na]
! at org.deeplearning4j.ui.weights.HistogramBin$Builder.build(HistogramBin.java:127) ~[deeplearning4j-ui-0.5.0.jar:na]
! at org.deeplearning4j.ui.weights.HistogramIterationListener.iterationDone(HistogramIterationListener.java:169) ~[deeplearning4j-ui-0.5.0.jar:na]
! at org.deeplearning4j.optimize.solvers.StochasticGradientDescent.optimize(StochasticGradientDescent.java:65) ~[deeplearning4j-core-0.5.0.jar:na]
! at org.deeplearning4j.optimize.Solver.optimize(Solver.java:51) ~[deeplearning4j-core-0.5.0.jar:na]
! at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.doTruncatedBPTT(MultiLayerNetwork.java:1215) ~[deeplearning4j-core-0.5.0.jar:na]
! at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.fit(MultiLayerNetwork.java:1477) ~[deeplearning4j-core-0.5.0.jar:na]
! at org.deeplearning4j.earlystopping.trainer.EarlyStoppingTrainer.fit(EarlyStoppingTrainer.java:59) ~[deeplearning4j-core-0.5.0.jar:na]
! at org.deeplearning4j.earlystopping.trainer.BaseEarlyStoppingTrainer.fit(BaseEarlyStoppingTrainer.java:109) ~[deeplearning4j-core-0.5.0.jar:na]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='anovstrup' date='2016-08-12T21:45:12Z'>
		I've added temporary workaround here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/2005&gt;https://github.com/deeplearning4j/deeplearning4j/pull/2005&lt;/denchmark-link&gt;

But right now i think it's wrong approach. Instead, probably Min op should be checked, if it really should return NaN as minimal value in the array. As well as Max, returning INF as maximal value in the array.
		</comment>
		<comment id='2' author='anovstrup' date='2019-01-20T20:53:08Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>