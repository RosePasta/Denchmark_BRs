<bug id='4246' author='Tschigger' open_date='2017-11-04T14:12:42Z' closed_time='2017-11-04T18:57:02Z'>
	<summary>Using Workspaces and disabling GC calls ends in java.lang.OutOfMemoryError</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

When I switch my neural net from JVM gc to workspaces by adding .trainingWorkspaceMode(WorkspaceMode.SEPARATE) to my model and disabling periodic gc calls with Nd4j.getMemoryManager().togglePeriodicGc(false);, memory consumption explodes during training, and after a few epochs, I get:
&lt;denchmark-code&gt;java.lang.OutOfMemoryError: Cannot allocate new FloatPointer(1): totalBytes = -3051750267, physicalBytes = 6G

	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:76)
	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:41)
	at org.nd4j.linalg.jcublas.blas.JcublasLevel3.sgemm(JcublasLevel3.java:107)
	at org.nd4j.linalg.api.blas.impl.BaseLevel3.gemm(BaseLevel3.java:57)
	at org.nd4j.linalg.api.ndarray.BaseNDArray.mmuli(BaseNDArray.java:3011)
	at org.nd4j.linalg.api.ndarray.BaseNDArray.mmul(BaseNDArray.java:2812)
	at org.deeplearning4j.nn.layers.BaseLayer.preOutput(BaseLayer.java:317)
	at org.deeplearning4j.nn.layers.BaseLayer.activate(BaseLayer.java:328)
	at org.deeplearning4j.nn.layers.recurrent.RnnOutputLayer.output(RnnOutputLayer.java:149)
	at org.deeplearning4j.nn.layers.BaseOutputLayer.activate(BaseOutputLayer.java:189)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.activationFromPrevLayer(MultiLayerNetwork.java:789)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForwardToLayer(MultiLayerNetwork.java:929)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:870)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:861)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1906)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1936)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.doEvaluation(MultiLayerNetwork.java:2892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at com.intellij.junit4.JUnit45ClassesRequestBuilder$1$1$2$2.runChild(JUnit45ClassesRequestBuilder.java:82)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
Caused by: java.lang.OutOfMemoryError: Physical memory usage is too high: physicalBytes = 6G &gt; maxPhysicalBytes = 6G
	at org.bytedeco.javacpp.Pointer.deallocator(Pointer.java:576)
	at org.bytedeco.javacpp.Pointer.init(Pointer.java:121)
	at org.bytedeco.javacpp.FloatPointer.allocateArray(Native Method)
	at org.bytedeco.javacpp.FloatPointer.&lt;init&gt;(FloatPointer.java:68)
	... 38 more
&lt;/denchmark-code&gt;

With normal JVM gc, only a fraction of the memory is used, and training is a little bit faster, too. Which should not be the case. Also tried to disable evaluation after each epoch, but same issue. Here is the java code of the neural net config and the iterator I am using:
&lt;denchmark-link:https://gist.github.com/Tschigger/e451fdc68b13d19157478b7b4084ec62&gt;https://gist.github.com/Tschigger/e451fdc68b13d19157478b7b4084ec62&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

Ubuntu
System RAM: 16gb
GPU RAM: 8GB (1070)

deeplearning4j-cuda-8.0, version 0.9.1
nd4j-cuda-8.0-platform, version 0.9.1
datavec-api, version 0.9.1

&lt;denchmark-h:h4&gt;Contributing&lt;/denchmark-h&gt;

If you'd like to help us fix the issue by contributing some code, but would
like guidance or help in doing so, please mention it!
	</description>
	<comments>
		<comment id='1' author='Tschigger' date='2017-11-04T14:29:57Z'>
		Hm. According to this stack trace, workspace isn't used.
		</comment>
		<comment id='2' author='Tschigger' date='2017-11-04T14:45:23Z'>
		I added the whole output to &lt;denchmark-link:https://gist.github.com/Tschigger/e451fdc68b13d19157478b7b4084ec62&gt;https://gist.github.com/Tschigger/e451fdc68b13d19157478b7b4084ec62&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Tschigger' date='2017-11-04T14:47:23Z'>
		So, yes. Workspace is definitely skipped somewhere in your app. With workspaces enabled you just shouldn't ever touch CudaZeroHandler. I'll investigate that.
		</comment>
		<comment id='4' author='Tschigger' date='2017-11-04T14:48:41Z'>
		Ah. There you go.
&lt;denchmark-code&gt;@Override
    public boolean asyncSupported() {
        return false;
    }
&lt;/denchmark-code&gt;

With this thing, you prevent Workspace use in your iterator. And with disabled GC you're eventually go oom. Change that to true
		</comment>
		<comment id='5' author='Tschigger' date='2017-11-04T14:52:25Z'>
		I mean: there are different workspaces etc.
And with that asyncSupported == false - you're disabled workspaces in iterator. So your neural network uses workspace, but iterator which creates new DataSets - doesn't. And then you eventually go oom.
		</comment>
		<comment id='6' author='Tschigger' date='2017-11-04T14:53:42Z'>
		Ah ok. Was setting it to false because I am prefetching my data, and this was recommended in a guide. Oops. However, with true I am getting a different error now:
&lt;denchmark-code&gt;Number of parameters in layer 0: 30080
Number of parameters in layer 1: 19360
Number of parameters in layer 2: 82
Total number of network parameters: 49522
15:50:29.067 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [26] to device [0], out of [1] devices...
15:50:29.087 [main] INFO  org.nd4j.nativeblas.Nd4jBlas - Number of threads used for BLAS: 0
15:50:58.965 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [27] to device [0], out of [1] devices...
15:50:58.970 [ADSI prefetch thread] DEBUG o.n.l.memory.abstracts.Nd4jWorkspace - Steps: 4

Disconnected from the target VM, address: '127.0.0.1:38969', transport: 'socket'

java.lang.RuntimeException: Failed to allocate 289657824 bytes from DEVICE [0] memory

	at org.nd4j.jita.memory.CudaMemoryManager.allocate(CudaMemoryManager.java:58)
	at org.nd4j.jita.workspace.CudaWorkspace.init(CudaWorkspace.java:69)
	at org.nd4j.linalg.memory.abstracts.Nd4jWorkspace.initializeWorkspace(Nd4jWorkspace.java:390)
	at org.nd4j.linalg.memory.abstracts.Nd4jWorkspace.close(Nd4jWorkspace.java:530)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForwardToLayer(MultiLayerNetwork.java:933)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:870)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:861)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1906)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1936)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.doEvaluation(MultiLayerNetwork.java:2892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at com.intellij.junit4.JUnit45ClassesRequestBuilder$1$1$2$2.runChild(JUnit45ClassesRequestBuilder.java:82)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)


Process finished with exit code 255
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='Tschigger' date='2017-11-04T14:55:30Z'>
		set equal settings for training/inference. Start with SEPARATE.
However, that might be the issue of tbptt. Quite of known issue for us.
		</comment>
		<comment id='8' author='Tschigger' date='2017-11-04T14:59:09Z'>
		Same issue:
&lt;denchmark-code&gt;java.lang.RuntimeException: Failed to allocate 289657824 bytes from DEVICE [0] memory

	at org.nd4j.jita.memory.CudaMemoryManager.allocate(CudaMemoryManager.java:58)
	at org.nd4j.jita.workspace.CudaWorkspace.init(CudaWorkspace.java:69)
	at org.nd4j.linalg.memory.abstracts.Nd4jWorkspace.initializeWorkspace(Nd4jWorkspace.java:390)
	at org.nd4j.linalg.memory.abstracts.Nd4jWorkspace.close(Nd4jWorkspace.java:530)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForwardToLayer(MultiLayerNetwork.java:933)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:870)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.feedForward(MultiLayerNetwork.java:861)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1906)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.silentOutput(MultiLayerNetwork.java:1936)
	at org.deeplearning4j.nn.multilayer.MultiLayerNetwork.doEvaluation(MultiLayerNetwork.java:2892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at com.intellij.junit4.JUnit45ClassesRequestBuilder$1$1$2$2.runChild(JUnit45ClassesRequestBuilder.java:82)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:157)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)

Disconnected from the target VM, address: '127.0.0.1:38439', transport: 'socket'

Process finished with exit code 255
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='Tschigger' date='2017-11-04T15:02:50Z'>
		Yes, that's it then. When you do TBPTT training - you don't have timeseries of 3k. You have only 40 steps. But then when you start evaluation - all out of sudden you have loop for 3k timesteps. With totally different memory requirements.
I'll take a look to confirm, sure, but i've already saw this behavior, and we have issue open for it: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/3482&gt;https://github.com/deeplearning4j/deeplearning4j/issues/3482&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='Tschigger' date='2017-11-04T15:03:48Z'>
		Btw, what exactly takes your memory? 8Gb is quite too much for your nn. How you do prefetch?
		</comment>
		<comment id='11' author='Tschigger' date='2017-11-04T15:10:20Z'>
		It hovers around 6-7gb GPU memory and then fails, but it only takes so much when I use workspaces. BTW, the error also happens when I outcomment the evaluation part.
Not sure what you mean with the question "how do you do prefetch?", since the code for my iterator is up there. Normal csv files, nothing fancy.
		</comment>
		<comment id='12' author='Tschigger' date='2017-11-04T15:11:42Z'>
		Well, when monitoring my GPU memory, I see the java process using around 6gb of the 6.5gb total used, 1.5 still available, but then it suddenly fails.
		</comment>
		<comment id='13' author='Tschigger' date='2017-11-04T15:11:46Z'>
		Can you please post stack trace with commented out eval then?
		</comment>
		<comment id='14' author='Tschigger' date='2017-11-04T15:12:17Z'>
		And just for reference: input is 100 x 13 x 3000
		</comment>
		<comment id='15' author='Tschigger' date='2017-11-04T15:28:24Z'>
		Just outcommented evaluation part, and of course, I am not getting it to fail now. But training is much slower (x3-x4 of the time) and uses much more memory (x3) with workspaces compared to non-workspaces. And without evaluation, I get
&lt;denchmark-code&gt;16:25:06.750 [main] WARN  o.n.j.handler.impl.CudaZeroHandler - No available [HOST] memory, sleeping for a while...
16:25:06.750 [main] DEBUG o.n.j.handler.impl.CudaZeroHandler - Currently used: [6251056500], allocated objects: [null]
16:25:23.612 [main] WARN  o.n.j.handler.impl.CudaZeroHandler - No available [HOST] memory, sleeping for a while...
16:25:23.612 [main] DEBUG o.n.j.handler.impl.CudaZeroHandler - Currently used: [6251060636], allocated objects: [null]
epoch took 45.258 seconds
16:25:25.045 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [27] to device [0], out of [1] devices...
16:25:40.023 [main] WARN  o.n.j.handler.impl.CudaZeroHandler - No available [HOST] memory, sleeping for a while...
16:25:40.023 [main] DEBUG o.n.j.handler.impl.CudaZeroHandler - Currently used: [6250699796], allocated objects: [null]
16:25:54.880 [main] WARN  o.n.j.handler.impl.CudaZeroHandler - No available [HOST] memory, sleeping for a while...
16:25:54.880 [main] DEBUG o.n.j.handler.impl.CudaZeroHandler - Currently used: [6250550224], allocated objects: [null]
epoch took 31.286 seconds
16:25:56.331 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [28] to device [0], out of [1] devices...
16:26:25.980 [main] WARN  o.n.j.handler.impl.CudaZeroHandler - No available [HOST] memory, sleeping for a while...
16:26:25.981 [main] DEBUG o.n.j.handler.impl.CudaZeroHandler - Currently used: [6251051972], allocated objects: [null]
epoch took 31.272 seconds
16:26:27.603 [main] DEBUG o.n.j.c.CudaAffinityManager - Manually mapping thread [29] to device [0], out of [1] devices...
&lt;/denchmark-code&gt;

all the time.
BTW, the exact timestep length differs for each dataset, but is between 2k and 4k I think.
		</comment>
		<comment id='16' author='Tschigger' date='2017-11-04T15:46:10Z'>
		Ah, so that's variable timeseries edge case :)
P.s. I still see CudaZeroHandler. You're still not using Workspaces. Post updated source code which reproduces THIS behavior, and i'll take it from here.
		</comment>
		<comment id='17' author='Tschigger' date='2017-11-04T15:49:38Z'>
		I'm really sorry, but.
You have such code:
&lt;denchmark-code&gt; MultiLayerNetwork net;
        if (locationToSave.exists()) {
            net = ModelSerializer.restoreMultiLayerNetwork(locationToSave);
        } else {
            net = new MultiLayerNetwork(conf);
        }
        net.init();
&lt;/denchmark-code&gt;

Are you sure you're not testing restored model, which was saved without workspaces enabled?
		</comment>
		<comment id='18' author='Tschigger' date='2017-11-04T15:50:37Z'>
		Can you comment out restoration part, and ensure only new model with enabled workspaces runs?
		</comment>
		<comment id='19' author='Tschigger' date='2017-11-04T16:01:52Z'>
		Yes, definitely 100% sure. Always deleting the network after each run. Still outcommenting it though to lower your blood pressure :D.
The code that produces this error is the code I posted, just with evaluation outcommented. Interesting that it doesn't use workspaces. But now comes the real interesting part. In the output (and also in the output I posted on gist), I find the line
&lt;denchmark-code&gt;16:58:24.145 [main] INFO  o.d.nn.multilayer.MultiLayerNetwork - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]
&lt;/denchmark-code&gt;

although I explicitly set both, training AND inference as you can clearly see in the code. Very weird.
		</comment>
		<comment id='20' author='Tschigger' date='2017-11-04T16:02:44Z'>
		So it makes sense that it doesn't use workspaces when I outcomment evaluation... Still don't know WHY it doesn't accept the training workspace parameter.
		</comment>
		<comment id='21' author='Tschigger' date='2017-11-04T16:04:05Z'>
		So issue definitely seems to be that it does not use workspaces when training, so disabling gc makes the memory usage explode.
		</comment>
		<comment id='22' author='Tschigger' date='2017-11-04T16:20:29Z'>
		It doesn`t matter if I set training or inference workspaces to single or separate or if I outcomment the parameters completely in the network building process. The result is always
[training: NONE; inference: SEPARATE]
no matter what I do or set.
		</comment>
		<comment id='23' author='Tschigger' date='2017-11-04T16:34:47Z'>
		ffs.
Please move these 2 lines BEFORE layers builder:
&lt;denchmark-code&gt;.trainingWorkspaceMode(WorkspaceMode.SEPARATE)
.inferenceWorkspaceMode(WorkspaceMode.SEPARATE)
&lt;/denchmark-code&gt;

p.s. It was an issue, fixed long ago in master, so i've forgot to check that in your conf, sorry.
		</comment>
		<comment id='24' author='Tschigger' date='2017-11-04T17:13:13Z'>
		wow... lost for for words
Thank you very much though. Appreciate it.
		</comment>
		<comment id='25' author='Tschigger' date='2017-11-04T17:28:09Z'>
		So, what's up there now?
		</comment>
		<comment id='26' author='Tschigger' date='2017-11-04T18:56:07Z'>
		Everything working as expected with workspaces set properly. Faster and less memory as with jvm gc, wonderful.
Forgot to close the issue.
		</comment>
		<comment id='27' author='Tschigger' date='2017-11-04T18:57:45Z'>
		Phew :)
		</comment>
		<comment id='28' author='Tschigger' date='2017-11-04T19:01:08Z'>
		Evaluating still draws a lot of memory though, which might be linked to the issue you linked: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/issues/3482&gt;https://github.com/deeplearning4j/deeplearning4j/issues/3482&lt;/denchmark-link&gt;

		</comment>
		<comment id='29' author='Tschigger' date='2017-11-04T19:25:27Z'>
		Unfortunately, 99% chance it is.
		</comment>
		<comment id='30' author='Tschigger' date='2018-09-24T12:26:26Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>