<bug id='8734' author='AlexDBlack' open_date='2020-02-25T06:17:50Z' closed_time='2020-03-20T07:23:14Z'>
	<summary>ND4J/libnd4j CUDA: Mmul op can provide incorrect results in multi-threaded environment</summary>
	<description>
Take a look at the following gist: &lt;denchmark-link:https://gist.github.com/AlexDBlack/985c6ce4fa15786b0b6f865ae240c503&gt;https://gist.github.com/AlexDBlack/985c6ce4fa15786b0b6f865ae240c503&lt;/denchmark-link&gt;

Note that:

The mmul op can sometimes randomly provide incorrect results in multi-threaded environments
No arrays or ops are shared between threads
Using whole numbers in input - so no rounding issues should be possible
The l3 BLAS gemm method is OK (never fails) (similarly INDArray.mmul(...) is OK as that's what is used internally)

This was run on Windows 10, CUDA 10.2, Titan X
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2020-03-20T07:23:13Z'>
		confirmed fixed for Mmul op. Still possible to happen with direct level3 BLAS gemm calls, but as discussed with &lt;denchmark-link:https://github.com/raver119&gt;@raver119&lt;/denchmark-link&gt;
 we'll deprecate those in favor of using ops only
		</comment>
	</comments>
</bug>