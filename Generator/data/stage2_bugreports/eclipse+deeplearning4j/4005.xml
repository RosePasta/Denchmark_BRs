<bug id='4005' author='iRazvan' open_date='2017-09-05T09:28:43Z' closed_time='2017-09-11T12:35:57Z'>
	<summary>Cannot import Keras model: mis matched lengths / output is not an IOutputLayer / model cannot be trained</summary>
	<description>
Hi, I'm having a lot of issues importing a simple keras model.
The model is here: &lt;denchmark-link:https://gist.github.com/iRazvan/3cd24dc5b6e5f49e0d928b3b7ad2d237&gt;https://gist.github.com/iRazvan/3cd24dc5b6e5f49e0d928b3b7ad2d237&lt;/denchmark-link&gt;

Keras version: 1.1.0
Tensorflow version: 0.12.1
DL4J version: 0.9.1
The code for DL4J is actually based on the examples:
&lt;denchmark-code&gt;String modelHDF5Path = "/media/razvan/FC202B84202B454C/Razvan/CNN/VP/new_model3.hdf5";
MultiLayerNetwork nn = KerasModelImport.importKerasSequentialModelAndWeights(modelHDF5Path);
        log.info(nn.summary());
&lt;/denchmark-code&gt;

I get this error:
&lt;denchmark-code&gt;org.deeplearning4j.examples.multigpu.TestImportKeras
o.n.l.f.Nd4jBackend - Loaded [JCublasBackend] backend
o.n.n.NativeOpsHolder - Number of threads used for NativeOps: 32
o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CUDA]; OS: [Linux]
o.n.l.a.o.e.DefaultOpExecutioner - Cores: [8]; Memory: [14.0GB];
o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [CUBLAS]
o.n.l.j.o.e.CudaExecutioner - Device name: [GeForce GTX 1080 Ti]; CC: [6.1]; Total/free memory: [11711807488]
o.n.l.j.o.e.CudaExecutioner - Device name: [GeForce GTX 1080 Ti]; CC: [6.1]; Total/free memory: [11715084288]
o.d.n.m.k.KerasSequentialModel - Model cannot be trained: output layer dense_3_loss is not an IOutputLayer (no loss function specified)
o.d.n.c.l.LayerValidation - Layer "batchnormalization_1" momentum has been set but will not be applied unless the updater is set to NESTEROVS.
o.d.n.m.MultiLayerNetwork - Starting MultiLayerNetwork with WorkspaceModes set to [training: NONE; inference: SEPARATE]
Exception in thread "main" java.lang.IllegalStateException: Mis matched lengths: [3] != [48]
	at org.nd4j.linalg.util.LinAlgExceptions.assertSameLength(LinAlgExceptions.java:40)
	at org.nd4j.linalg.api.ops.BaseTransformOp.&lt;init&gt;(BaseTransformOp.java:47)
	at org.nd4j.linalg.api.ops.impl.transforms.Set.&lt;init&gt;(Set.java:24)
	at org.nd4j.linalg.api.ndarray.BaseNDArray.assign(BaseNDArray.java:1267)
	at org.deeplearning4j.nn.layers.BaseLayer.setParam(BaseLayer.java:218)
	at org.deeplearning4j.nn.modelimport.keras.KerasLayer.copyWeightsToLayer(KerasLayer.java:475)
	at org.deeplearning4j.nn.modelimport.keras.KerasModel.helperCopyWeightsToModel(KerasModel.java:701)
	at org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:227)
	at org.deeplearning4j.nn.modelimport.keras.KerasSequentialModel.getMultiLayerNetwork(KerasSequentialModel.java:213)
	at org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasSequentialModelAndWeights(KerasModelImport.java:157)
	at org.deeplearning4j.examples.multigpu.TestImportKeras.main(TestImportKeras.java:69)

Process finished with exit code 1

&lt;/denchmark-code&gt;

Any ideas? I'm stuck with this for a while now.. found nothing useful in the forums. My end goal would be to import the model in Android.
	</description>
	<comments>
		<comment id='1' author='iRazvan' date='2017-09-05T10:43:58Z'>
		&lt;denchmark-link:https://github.com/iRazvan&gt;@iRazvan&lt;/denchmark-link&gt;
 I'll look into this soon and will include your case in integration tests for reference.
In the mean time, would you mind stepping through the debugger and telling me at which layer, for which weight the assignment of weights fails?
		</comment>
		<comment id='2' author='iRazvan' date='2017-09-07T11:54:33Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/7549265/30162213-98d4ada4-93dc-11e7-9ddd-e2a354fca27a.png&gt;&lt;/denchmark-link&gt;

Crashes at batchnormalization_1, I have attached a screenshot.
I have tried numerous ways to import it, still no luck.
&lt;denchmark-code&gt;MultiLayerNetwork graph;
graph = KerasModelImport.importKerasSequentialModelAndWeights(modelJsonPath, weightsH5Path, false);
&lt;/denchmark-code&gt;

The code above gives the same error message.
Edit: seems that "gamma" gives the mismatch, it's initialized to a 3 dim array, but in the imported file it's a 48 dim array.
&lt;denchmark-link:https://user-images.githubusercontent.com/7549265/30162918-7e4637b6-93df-11e7-9105-4b46fdffa564.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='iRazvan' date='2017-09-07T12:55:56Z'>
		hey &lt;denchmark-link:https://github.com/iRazvan&gt;@iRazvan&lt;/denchmark-link&gt;
 thanks for all the details, very helpful. The problem is this: keras has an  argument that we currently do not support. You want to batch along , which indeed has length 48. We currently only support batching of the  batch dimension (here length 3).
I'd have to go back and extend our batchnorm layer to really address this, which might take a while. Not sure if I have time for this right now.
In the meantime, what you can do is this: reshape your input so that your batch-dimension is in fact last. Might have to shuffle dims again afterwards.
		</comment>
		<comment id='4' author='iRazvan' date='2017-09-07T13:16:16Z'>
		&lt;denchmark-link:https://github.com/iRazvan&gt;@iRazvan&lt;/denchmark-link&gt;
 at least on master we now have an informative error message for your use case.
&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 what's your take here? Would it take a lot of effort to support batch normalisation along other axes than the last?
		</comment>
		<comment id='5' author='iRazvan' date='2017-09-08T00:07:51Z'>
		batch norm in DL4J operates along dimension 1 (depth for CNNs, or values per  time step for time series, or each column for dense).
default ordering of data in keras CNNs is channels_last - i.e., [N, H, W, C]. Is there a use case where batch norm along the height dimension (sharing across width/channels) makes sense? If that's the layout (it's not explicitly configured) then it seems invalid to me...
&lt;denchmark-link:https://keras.io/layers/convolutional/&gt;https://keras.io/layers/convolutional/&lt;/denchmark-link&gt;

that said, if it is channels_first [N, C, H, W] (which is also what DL4J uses) then dimension 1 makes sense and it should work out of the box...
As for supporting batch norm along other axes: I'v very hestitant. Show me a published paper that actually does something other than what we do, and I'd consider it :)
		</comment>
		<comment id='6' author='iRazvan' date='2017-09-08T09:32:19Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 cool, that's fine with me. I also don't really see a real-world use case here. will make sure to double check that we take into account the two data formats properly in model import, though.
		</comment>
		<comment id='7' author='iRazvan' date='2017-09-11T12:34:35Z'>
		My default ordering was: [batch size, height, width, channels], I changed it in keras batch norm and at conv2d to use dim_ordering = 'th' and now it's compatible with dl4j [batch size, channels, height, width].
Thanks for the help!
		</comment>
		<comment id='8' author='iRazvan' date='2018-09-24T21:58:45Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>