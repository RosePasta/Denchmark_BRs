<bug id='3348' author='siddharthBohra' open_date='2017-05-02T14:16:20Z' closed_time='2018-04-26T04:17:48Z'>
	<summary>Error in Loading sequence vector model</summary>
	<description>
Hi, I am facing some issues while loading the sequenceVector Model from the path.
Find the code below,
public class SequenceVectorsTextExample {
&lt;denchmark-code&gt;protected static final Logger logger = LoggerFactory.getLogger(SequenceVectorsTextExample.class);

public static void main(String[] args) throws Exception {

    SequenceVectorsTextExample trainModel = new SequenceVectorsTextExample();
    SequenceVectorsTextExample testModel = new SequenceVectorsTextExample();
    trainModel.saveSequenceModel();
    testModel.LoadSequenceModel();

}

private void saveSequenceModel() throws IOException {

        ClassPathResource resource = new ClassPathResource("raw_sentences.txt");
        File file = resource.getFile();

        AbstractCache&lt;VocabWord&gt; vocabCache = new AbstractCache.Builder&lt;VocabWord&gt;().build();

    /*
        First we build line iterator
     */
        BasicLineIterator underlyingIterator = new BasicLineIterator(file);


    /*
        Now we need the way to convert lines into Sequences of VocabWords.
        In this example that's SentenceTransformer
     */
        TokenizerFactory t = new DefaultTokenizerFactory();
        t.setTokenPreProcessor(new CommonPreprocessor());

        SentenceTransformer transformer = new SentenceTransformer.Builder()
            .iterator(underlyingIterator)
            .tokenizerFactory(t)
            .build();


    /*
        And we pack that transformer into AbstractSequenceIterator
     */
        AbstractSequenceIterator&lt;VocabWord&gt; sequenceIterator =
            new AbstractSequenceIterator.Builder&lt;&gt;(transformer).build();


    /*
        Now we should build vocabulary out of sequence iterator.
        We can skip this phase, and just set AbstractVectors.resetModel(TRUE), and vocabulary will be mastered internally
    */
        VocabConstructor&lt;VocabWord&gt; constructor = new VocabConstructor.Builder&lt;VocabWord&gt;()
            .addSource(sequenceIterator, 5)
            .setTargetVocabCache(vocabCache)
            .build();

        constructor.buildJointVocabulary(false, true);

    /*
        Time to build WeightLookupTable instance for our new model
    */

        WeightLookupTable&lt;VocabWord&gt; lookupTable = new InMemoryLookupTable.Builder&lt;VocabWord&gt;()
            .lr(0.025)
            .vectorLength(150)
            .useAdaGrad(false)
            .cache(vocabCache)
            .build();

     /*
         reset model is viable only if you're setting AbstractVectors.resetModel() to false
         if set to True - it will be called internally
    */
        lookupTable.resetWeights(true);

    /*
        Now we can build AbstractVectors model, that suits our needs
     */
        SequenceVectors&lt;VocabWord&gt; vectors = new SequenceVectors.Builder&lt;VocabWord&gt;(new VectorsConfiguration())
            // minimum number of occurencies for each element in training corpus. All elements below this value will be ignored
            // Please note: this value has effect only if resetModel() set to TRUE, for internal model building. Otherwise it'll be ignored, and actual vocabulary content will be used
            .minWordFrequency(5)

            // WeightLookupTable
            .lookupTable(lookupTable)

            // abstract iterator that covers training corpus
            .iterate(sequenceIterator)

            // vocabulary built prior to modelling
            .vocabCache(vocabCache)

            // batchSize is the number of sequences being processed by 1 thread at once
            // this value actually matters if you have iterations &gt; 1
            .batchSize(250)

            // number of iterations over batch
            .iterations(1)

            // number of iterations over whole training corpus
            .epochs(1)

            // if set to true, vocabulary will be built from scratches internally
            // otherwise externally provided vocab will be used
            .resetModel(false)


            /*
                These two methods define our training goals. At least one goal should be set to TRUE.
             */
            .trainElementsRepresentation(true)
            .trainSequencesRepresentation(false)

            /*
                Specifies elements learning algorithms. SkipGram, for example.
             */
            .elementsLearningAlgorithm(new SkipGram&lt;VocabWord&gt;())

            .build();

    /*
        Now, after all options are set, we just call fit()
     */
        vectors.fit();

    SequenceElementFactory&lt;VocabWord&gt; SeqEFactory = new VocabWordFactory();

    WordVectorSerializer.writeSequenceVectors(vectors, SeqEFactory, "SaveModel/SequenceVectorModel.bin");
    }

private void LoadSequenceModel() throws IOException {

    /*
        As soon as fit() exits, model considered built, and we can test it.
        Please note: all similarity context is handled via SequenceElement's labels, so if you're using AbstractVectors to build models for complex
        objects/relations please take care of Labels uniqueness and meaning for yourself.
     */
    File ModelPath = new File("SaveModel/SequenceVectorModel.bin");
    SequenceElementFactory&lt;VocabWord&gt; SeqEFactory = new VocabWordFactory();
    SequenceVectors&lt;VocabWord&gt; vector = WordVectorSerializer.readSequenceVectors(SeqEFactory, ModelPath);
    double sim = vector.similarity("day", "night");
    logger.info("Day/night similarity: " + sim);

}
&lt;/denchmark-code&gt;

Errors,
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/C:/Users/siddharth.premkumar/.m2/repository/ch/qos/logback/logback-classic/1.1.3/logback-classic-1.1.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/C:/Users/siddharth.premkumar/.m2/repository/org/slf4j/slf4j-log4j12/1.6.2/slf4j-log4j12-1.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/C:/Users/siddharth.premkumar/.m2/repository/org/slf4j/slf4j-simple/1.5.8/slf4j-simple-1.5.8.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See &lt;denchmark-link:http://www.slf4j.org/codes.html#multiple_bindings&gt;http://www.slf4j.org/codes.html#multiple_bindings&lt;/denchmark-link&gt;
 for an explanation.
o.d.m.w.w.VocabConstructor - Sequences checked: [97162], Current vocabulary size: [242]; Sequences/sec: [60461.73];
o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
o.n.n.NativeOpsHolder - Number of threads used for NativeOps: 4
o.d.m.e.i.InMemoryLookupTable - Initializing syn1...
o.n.n.Nd4jBlas - Number of threads used for BLAS: 4
o.d.m.s.SequenceVectors - Building learning algorithms:
o.d.m.s.SequenceVectors -           building ElementsLearningAlgorithm: [SkipGram]
o.d.m.s.SequenceVectors - Starting learning process...
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [634303];  Lines vectorized so far: [97162]; learningRate: [1.0E-4]
o.d.m.s.SequenceVectors - Time spent on training: 6798 ms
Exception in thread "main" java.lang.RuntimeException: org.nd4j.shade.jackson.databind.JsonMappingException: No content to map due to end-of-input
at [Source: ; line: 1, column: 1]
at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer$ElementPair.fromEncodedJson(WordVectorSerializer.java:2212)
at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.readSequenceVectors(WordVectorSerializer.java:2071)
at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer.readSequenceVectors(WordVectorSerializer.java:2048)
at org.deeplearning4j.examples.nlp.sequencevectors.SequenceVectorsTextExample.LoadSequenceModel(SequenceVectorsTextExample.java:177)
at org.deeplearning4j.examples.nlp.sequencevectors.SequenceVectorsTextExample.main(SequenceVectorsTextExample.java:48)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)
Caused by: org.nd4j.shade.jackson.databind.JsonMappingException: No content to map due to end-of-input
at [Source: ; line: 1, column: 1]
at org.nd4j.shade.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)
at org.nd4j.shade.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3607)
at org.nd4j.shade.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3547)
at org.nd4j.shade.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2578)
at org.deeplearning4j.models.embeddings.loader.WordVectorSerializer$ElementPair.fromEncodedJson(WordVectorSerializer.java:2210)
... 9 more
Process finished with exit code 1
Please help me to resolve this issue. Why i get no content to map error.??
Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='siddharthBohra' date='2018-09-22T15:13:50Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>