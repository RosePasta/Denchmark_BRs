<bug id='7678' author='AlexDBlack' open_date='2019-05-06T10:15:56Z' closed_time='2019-06-03T01:11:54Z'>
	<summary>DL4J: BERT iterator can get into infinite loop with bad character encoding</summary>
	<description>
Best guess to cause of infinite loop: If the string to be tokenized has a character that doesn't appear in the vocab (due to bad encoding of the vocab, or of the string to be tokenized) an infinite loop will occur... the following runs until we hit: java.lang.OutOfMemoryError: Java heap space.
&lt;denchmark-code&gt;    @Test
    public void testBertWordPieceTokenizer1() throws Exception {
        String toTokenize = "I saw a girl with a telescope. bad" + (char) 8 + "word";
        TokenizerFactory t = new BertWordPieceTokenizerFactory(pathToVocab, c);
        Tokenizer tokenizer = t.create(toTokenize);
        Tokenizer tokenizer2 = t.create(new ByteArrayInputStream(toTokenize.getBytes()));
        int position = 1;
        while (tokenizer2.hasMoreTokens()) {
            String tok1 = tokenizer.nextToken();
            String tok2 = tokenizer2.nextToken();
            log.info("Position: [" + position + "], token1: '" + tok1 + "', token 2: '" + tok2 + "'");
            position++;
            assertEquals(tok1, tok2);
        }
    }
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-05-25T03:41:22Z'>
		Fixed here, and merged to dev branch; will be merged from dev branch to master soon: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/7774&gt;https://github.com/deeplearning4j/deeplearning4j/pull/7774&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='AlexDBlack' date='2019-06-03T01:11:54Z'>
		&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/7792&gt;https://github.com/deeplearning4j/deeplearning4j/pull/7792&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>