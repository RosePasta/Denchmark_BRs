<bug id='4030' author='hendriks73' open_date='2017-09-08T08:51:29Z' closed_time='2017-09-08T09:14:30Z'>
	<summary>Please support ELU activation function (Keras 2 import)</summary>
	<description>
&lt;denchmark-h:h4&gt;Issue Description&lt;/denchmark-h&gt;

The elu (not relu) activation function is not supported.
When importing a Keras 2 model with elu, an exception is thrown:
&lt;denchmark-code&gt;org.deeplearning4j.nn.modelimport.keras.exceptions.UnsupportedKerasConfigurationException: Unknown Keras activation function elu. Please file an issue at http://github.com/deeplearning4j/deeplearning4j/issues.
	at org.deeplearning4j.nn.modelimport.keras.utils.KerasActivationUtils.mapActivation(KerasActivationUtils.java:62)
	at org.deeplearning4j.nn.modelimport.keras.utils.KerasActivationUtils.getActivationFromConfig(KerasActivationUtils.java:82)
&lt;/denchmark-code&gt;

ELU is described in &lt;denchmark-link:https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289&gt;https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289&lt;/denchmark-link&gt;
 :

The exponential linear unit (ELU) with 0 &lt; α is

&lt;denchmark-code&gt;f(x) = x              if x &gt; 0
f(x) = α(exp(x)−1)    if x ≤ 0

f'(x) = 1             if x &gt; 0
f'(x) = f(x)+α        if x ≤ 0

By default, α is 1.0
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://keras.io/layers/advanced-activations/#elu&gt;Keras docs&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/fchollet/keras/blob/master/keras/layers/advanced_activations.py#L141&gt;Keras source&lt;/denchmark-link&gt;

&lt;denchmark-h:h4&gt;Version Information&lt;/denchmark-h&gt;

This is on the most recent snapshot, i.e. 0.9.2-20170906.063037-230
&lt;denchmark-h:h4&gt;Note&lt;/denchmark-h&gt;

I'm aware that this is not a bug, but a feature request (especially given that I've used the snapshot).
Thanks.
	</description>
	<comments>
		<comment id='1' author='hendriks73' date='2017-09-08T08:53:05Z'>
		Just realized, the function itself is already implemented in org.nd4j.linalg.api.ops.impl.transforms.ELU. Just the mapping is missing.
		</comment>
		<comment id='2' author='hendriks73' date='2017-09-08T09:13:33Z'>
		I suspect, modifying KerasActivationUtils.mapActivation() like this, might do the trick:
&lt;denchmark-code&gt;    public static IActivation mapActivation(String kerasActivation, KerasLayerConfiguration conf)
            throws UnsupportedKerasConfigurationException {
        IActivation dl4jActivation = null;
        /* Keras and DL4J use the same name for most activations. */
        if (kerasActivation.equals(conf.getKERAS_ACTIVATION_SOFTMAX())) {
            dl4jActivation = new ActivationSoftmax();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_SOFTPLUS())) {
            dl4jActivation = new ActivationSoftPlus();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_SOFTSIGN())) {
            dl4jActivation = new ActivationSoftSign();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_RELU())) {
            dl4jActivation = new ActivationReLU();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_TANH())) {
            dl4jActivation = new ActivationTanH();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_SIGMOID())) {
            dl4jActivation = new ActivationSigmoid();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_HARD_SIGMOID())) {
            dl4jActivation = new ActivationHardSigmoid();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_LINEAR())) {
            dl4jActivation = new ActivationIdentity();
        // ========= SELU and ELU are new ========= //
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_SELU())) {
            dl4jActivation = new ActivationSELU();
        } else if (kerasActivation.equals(conf.getKERAS_ACTIVATION_ELU())) {
            dl4jActivation = new ActivationELU();
        } else {
            throw new UnsupportedKerasConfigurationException(
                    "Unknown Keras activation function " + kerasActivation);
        }
        return dl4jActivation;
    }
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='hendriks73' date='2017-09-08T09:14:30Z'>
		done, check master :)
		</comment>
		<comment id='4' author='hendriks73' date='2018-09-24T22:58:47Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>