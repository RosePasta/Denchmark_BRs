<bug id='911' author='AlexDBlack' open_date='2015-11-30T08:22:05Z' closed_time='2015-11-30T18:37:29Z'>
	<summary>Score based learning rate decay modifying LR when not enabled</summary>
	<description>
Score based decay feature: this is being triggered and hence modifying learning rate of layers when it is not set/enabled.
Easiest way to check/reproduce run test below with breakpoint here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-core/src/main/java/org/deeplearning4j/optimize/solvers/BaseOptimizer.java#L212&gt;https://github.com/deeplearning4j/deeplearning4j/blob/master/deeplearning4j-core/src/main/java/org/deeplearning4j/optimize/solvers/BaseOptimizer.java#L212&lt;/denchmark-link&gt;

@Test
    public void scoreBasedLRDecayBug() {

        DataSet ds = new IrisDataSetIterator(150,150).next();
        ds.normalizeZeroMeanZeroUnitVariance();

        Nd4j.getRandom().setSeed(12345);

        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
                .regularization(false)
                .optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT)
                .learningRate(1.0)
                .seed(12345L)
                .list(2)
                .layer(0, new DenseLayer.Builder()
                        .nIn(4).nOut(3)
                        .weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0, 1))
                        .activation("sigmoid")
                        .updater(Updater.SGD)
                        .build())
                .layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.MSE)
                        .activation("tanh")
                        .nIn(3).nOut(3)
                        .weightInit(WeightInit.DISTRIBUTION).dist(new NormalDistribution(0, 1))
                        .updater(Updater.SGD)
                        .build())
                .pretrain(false).backprop(true)
                .build();
        MultiLayerNetwork mln = new MultiLayerNetwork(conf);
        mln.init();

        //Run a number of iterations of learning
        mln.setInput(ds.getFeatureMatrix());
        mln.setLabels(ds.getLabels());
        mln.computeGradientAndScore();
        for( int j=0; j&lt;1; j++ ) mln.fit(ds);
        mln.computeGradientAndScore();

        double lr0 = mln.getLayer(0).conf().getLayer().getLearningRate();
        double lr1 = mln.getLayer(1).conf().getLayer().getLearningRate();
        assertEquals(1.0, lr0, 0.0);
        assertEquals(1.0, lr1, 0.0);
    }
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-01-21T13:37:42Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>