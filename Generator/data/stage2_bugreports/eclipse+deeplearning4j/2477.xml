<bug id='2477' author='reidswanson' open_date='2016-12-12T04:05:41Z' closed_time='2017-08-22T12:22:01Z'>
	<summary>Cuda backend slows down over time</summary>
	<description>
Training a mini-batch takes longer and longer each iteration when using the cuda backend, but I don't see the same issue when switching to the native/cpu backend. On the first few iterations it processes about 110 examples/sec. After about 50-60 iterations it starts training at about half that speed and by 150 iterations it is processing less then 1 example a second. With the cpu backend it consistently processes about 30 examples/sec for over 300 iterations/batches.
Some relevant hardward/software specs
GPU: GTX 1080
OS: Linux
Driver: 375.20
CUDA: 8.0.44
PCIE v2 x16
Here is my network config with some relevant parameters:
&lt;denchmark-code&gt;nin = 12715
options.hiddenStates = 200
nout = 19
numberOfTimesteps = 20
batchSize = 128
&lt;/denchmark-code&gt;

Note the LossIntegerMSE is virtually the same as LossMSE except I round all values to the nearest integer.
&lt;denchmark-code&gt;NeuralNetConfiguration.Builder builder = new NeuralNetConfiguration.Builder();

 ListBuilder listBuilder =
	builder
		.optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
		.iterations(1)
		.learningRate(0.01)
		.dropOut(0.5)
		.seed(0)
		.regularization(true)
		.l2(0.0001)
		.weightInit(WeightInit.XAVIER)
		.updater(Updater.NESTEROVS)
		.momentum(0.95)
		.learningRateDecayPolicy(LearningRatePolicy.Inverse)
		.lrPolicyDecayRate(0.99)
		.lrPolicyPower(0.0005)
		.list();

int layerNumber = 0;
listBuilder
	.layer(
		layerNumber++, 
			new GravesLSTM.Builder()
				.nIn(nin)
				.nOut(options.hiddenStates)
				.activation("tanh")
				.gradientNormalization(GradientNormalization.ClipL2PerParamType)
				.build()
		);

int nHiddenLayers = 1;
for (int i = 0; i &lt; nHiddenLayers; ++i) {
	listBuilder
		.layer(
			layerNumber++, 
			new GravesLSTM.Builder()
				.nIn(options.hiddenStates)
				.nOut(options.hiddenStates)
				.activation("tanh")
				.gradientNormalization(GradientNormalization.ClipL2PerParamType)
				.build()
			);
}

listBuilder
	.layer(
		layerNumber,
		new RnnOutputLayer.Builder(new LossIntegerMSE())
			.nIn(options.hiddenStates)
			.nOut(nout)
			.activation("identity")
			.build()
		);

return
	listBuilder
		.backpropType(BackpropType.TruncatedBPTT)
		.tBPTTForwardLength(options.truncatedBackPropSteps)
		.tBPTTBackwardLength(options.truncatedBackPropSteps)
		.pretrain(false)
		.backprop(true)
		.build();
       
&lt;/denchmark-code&gt;

Here's a snapshot of jvisualvm starting roughly at the beginning during some data preprocessing through about 100 iterations.
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/802748/21087628/8ed7d404-bfdc-11e6-9e9d-f8114c31c8ee.png&gt;&lt;/denchmark-link&gt;

And a snapshot of nvidia-smi around the same time
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/802748/21087638/a825c470-bfdc-11e6-9037-1e97d95019c7.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='reidswanson' date='2016-12-12T07:35:01Z'>
		74% of time is GC, sure it's getting slower.
Please check this two issues, it explains what happens:

https://github.com/deeplearning4j/deeplearning4j/issues/2416
https://github.com/deeplearning4j/deeplearning4j/issues/2355

		</comment>
		<comment id='2' author='reidswanson' date='2016-12-12T15:42:50Z'>
		Ok, it looks like it's the issue where I generate a bunch of stuff before computation and then the GC spends a bunch of time traversing the objects each iteration. If I understood the other threads correctly, you're trying to implement a way to avoid the garbage collector in a (hopefully) next release, which should help with this problem.
Thanks for the pointers and sorry I didn't see them earlier.
		</comment>
		<comment id='3' author='reidswanson' date='2017-04-02T21:22:19Z'>
		This issue is addressed here: &lt;denchmark-link:https://github.com/deeplearning4j/nd4j/pull/1731&gt;deeplearning4j/nd4j#1731&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='reidswanson' date='2017-08-22T12:22:01Z'>
		Closing this - was addressed long ago with workspaces.
		</comment>
		<comment id='5' author='reidswanson' date='2018-09-25T08:18:13Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>