<bug id='2504' author='ErikTromp' open_date='2016-12-14T13:55:00Z' closed_time='2016-12-16T12:35:45Z'>
	<summary>NullPointerException when training ParagraphVectors</summary>
	<description>
I am getting a NullPointerException when calling fit on ParagraphVectors (running on GPU, using 0.7.1):
&lt;denchmark-code&gt;java.lang.NullPointerException: null
at org.deeplearning4j.models.embeddings.inmemory.InMemoryLookupTable.consume(InMemoryLookupTable.java:689) ~[deeplearning4j-nlp-0.7.1.jar:na]
at org.deeplearning4j.models.sequencevectors.SequenceVectors.buildVocab(SequenceVectors.java:103) ~[deeplearning4j-nlp-0.7.1.jar:na]
at org.deeplearning4j.models.sequencevectors.SequenceVectors.fit(SequenceVectors.java:178) ~[deeplearning4j-nlp-0.7.1.jar:na]
at org.deeplearning4j.models.paragraphvectors.ParagraphVectors.fit(ParagraphVectors.java:448) ~[deeplearning4j-nlp-0.7.1.jar:na]
at tuktu.deeplearn.models.Doc2Vec.train(Doc2Vec.scala:141) ~[classes/:na]
&lt;/denchmark-code&gt;

The code I am using can be found here (excerpt): &lt;denchmark-link:https://gist.github.com/ErikTromp/87c6ffc11dbecf79174b74b2ea538743&gt;https://gist.github.com/ErikTromp/87c6ffc11dbecf79174b74b2ea538743&lt;/denchmark-link&gt;

Running on a small dataset works fine (same code), but running it on a larger one (larger word embedding file too) results in this error.
Parameters:
&lt;denchmark-code&gt;"min_word_frequency": 5,
"iterations": 5,
"epochs": 5,
"layer_size": 50,
"learning_rate": 0.025,
"window_size": 5,
"sampling": 0,
"batch_size": 4000,
"word2vec_model": "vectors.bin"
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ErikTromp' date='2016-12-14T14:20:24Z'>
		Right, fit() is the issue here, which isn't supposed to be used with existingWordVectors being set.
I'll provide proper handling on this usecase.
		</comment>
		<comment id='2' author='ErikTromp' date='2016-12-15T07:33:27Z'>
		Are you saying that I shouldn't call .fit on doc2vec entirely when I load existing word vectors? I was planning on using my pre-trained word vectors (on large unlabeled data) as starting point to next load in DL4J and use doc2vec for classification purposes. Is this not possible then?
		</comment>
		<comment id='3' author='ErikTromp' date='2016-12-15T07:40:35Z'>
		At least that's not in list of currently supported functionality. Probably, if existingModel is full - why not then... I should think about it. But right now nobody tested thing you're trying to do.
		</comment>
		<comment id='4' author='ErikTromp' date='2016-12-15T09:50:00Z'>
		Okay, clear. Weird thing is though, that when I use the exact same code, also with pre-trained word vectors from the google implementation, but then on a significantly smaller dataset, it does finish properly and I do not encounter the error.
		</comment>
		<comment id='5' author='ErikTromp' date='2016-12-15T09:54:52Z'>
		As i've said - that use scenario looks possible (NOT FOR GOOGLE MODEL!), i just need to check math for that use case, and ensure that model contains not the weights only, but HS/Neg states.
		</comment>
		<comment id='6' author='ErikTromp' date='2016-12-15T10:24:07Z'>
		OK, looking forward - I'll continue on a different path for now then. Will monitor this issue.
		</comment>
		<comment id='7' author='ErikTromp' date='2016-12-16T12:35:45Z'>
		Issue is addressed here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/2520&gt;https://github.com/deeplearning4j/deeplearning4j/pull/2520&lt;/denchmark-link&gt;

Now we explicitly check, if existingModel contains syn1/syn1Neg defined.
		</comment>
		<comment id='8' author='ErikTromp' date='2019-01-20T02:56:24Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>