<bug id='8392' author='AlexDBlack' open_date='2019-11-14T11:29:04Z' closed_time='2019-11-22T13:28:06Z'>
	<summary>libnd4j: deconv2d op failures (MKLDNN?)</summary>
	<description>
On CPU, built with MKLDNN:
&lt;denchmark-code&gt;        DynamicCustomOp op = DynamicCustomOp.builder("deconv2d")
                .addInputs(
                        Nd4j.create(DataType.FLOAT, 1, 3, 3, 2),
                        Nd4j.create(DataType.FLOAT, 2, 2, 3, 2),
                        Nd4j.create(DataType.FLOAT, 3)
                )
                .addOutputs(Nd4j.create(DataType.FLOAT, 1, 5, 5, 3))
                .addIntegerArguments(2, 2, 1, 1, 0, 0, 2, 2, 0, 1)
                .build();

        Nd4j.exec(op);
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
o.n.n.NativeOpsHolder - Number of threads used for OpenMP: 8
o.n.n.Nd4jBlas - Number of threads used for OpenMP BLAS: 8
o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Windows 10]
o.n.l.a.o.e.DefaultOpExecutioner - Cores: [16]; Memory: [7.1GB];
o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
o.n.l.c.n.o.NativeOpExecutioner - Failed to execute op deconv2d. Attempted to execute with 3 inputs, 1 outputs, 0 targs,0 bargs and 10 iargs. Inputs: [(FLOAT,[1,3,3,2],c), (FLOAT,[2,2,3,2],c), (FLOAT,[3],c)]. Outputs: [(FLOAT,[1,5,5,3],c)]. tArgs: -. iArgs: [2, 2, 1, 1, 0, 0, 2, 2, 0, 1]. bArgs: -. Op own name: "c3d254b7-c926-4013-9009-06f59aa791a2" - Please see above message (printed out from c++) for a possible cause of error.



java.lang.RuntimeException: Op [deconv2d] execution failed

	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:1710)
	at org.nd4j.linalg.factory.Nd4j.exec(Nd4j.java:6560)
	at org.nd4j.Temp.test(Temp.java:23)
...
Caused by: java.lang.RuntimeException: could not create a dilated deconvolution forward descriptor
	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:2006)
	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:1700)
	... 24 more
&lt;/denchmark-code&gt;

Note this was pulled out of this test case (also reproducible there)
&lt;denchmark-link:https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/convolution/DeconvTests.java&gt;https://github.com/eclipse/deeplearning4j/blob/master/nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/linalg/convolution/DeconvTests.java&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-11-14T11:56:52Z'>
		A separate failure: it's failing with FP16 also (not sure if we should be using mkldnn or not for this case). This is pulled out of a test that was previously passing...
Float32 is fine for this case.
&lt;denchmark-code&gt;    @Test
    public void testDeconv2dHalf(){
        for(DataType dt : new DataType[]{DataType.FLOAT, DataType.HALF}) {
            System.out.println("STARTING: " + dt);

            INDArray in = Nd4j.create(dt, 2, 3, 4, 4);
            INDArray w = Nd4j.create(dt, 2, 2, 3, 3);
            INDArray b = Nd4j.create(dt, 3);

            INDArray out = Nd4j.create(dt, 2, 3, 8, 8);

            DynamicCustomOp op = DynamicCustomOp.builder("deconv2d")
                    .addInputs(in, w, b)
                    .addOutputs(out)
                    .addIntegerArguments(2, 2, 2, 2, 6, 6, 1, 1, 1, 0)
                    .build();
            Nd4j.exec(op);
            System.out.println("FINISHED: " + dt);
        }
    }
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;o.n.l.f.Nd4jBackend - Loaded [CpuBackend] backend
o.n.n.NativeOpsHolder - Number of threads used for OpenMP: 8
o.n.n.Nd4jBlas - Number of threads used for OpenMP BLAS: 8
o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CPU]; OS: [Windows 10]
o.n.l.a.o.e.DefaultOpExecutioner - Cores: [16]; Memory: [7.1GB];
o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [OPENBLAS]
STARTING: FLOAT
FINISHED: FLOAT
STARTING: HALF
o.n.l.c.n.o.NativeOpExecutioner - Failed to execute op deconv2d. Attempted to execute with 3 inputs, 1 outputs, 0 targs,0 bargs and 10 iargs. Inputs: [(HALF,[2,3,4,4],c), (HALF,[2,2,3,3],c), (HALF,[3],c)]. Outputs: [(HALF,[2,3,8,8],c)]. tArgs: -. iArgs: [2, 2, 2, 2, 6, 6, 1, 1, 1, 0]. bArgs: -. Op own name: "e0d62a99-9f8d-492c-8e84-e353e5a7a236" - Please see above message (printed out from c++) for a possible cause of error.



java.lang.RuntimeException: Op [deconv2d] execution failed

	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:1710)
	at org.nd4j.linalg.factory.Nd4j.exec(Nd4j.java:6560)
	at org.deeplearning4j.Temp.testDeconv2dHalf(Temp.java:42)
...
Caused by: java.lang.RuntimeException: could not create a primitive descriptor iterator
	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:2006)
	at org.nd4j.linalg.cpu.nativecpu.ops.NativeOpExecutioner.exec(NativeOpExecutioner.java:1700)
	... 24 more
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='AlexDBlack' date='2019-11-15T16:50:06Z'>
		Are these two tests still failing?
		</comment>
		<comment id='3' author='AlexDBlack' date='2019-11-21T12:52:51Z'>
		The two original test cases (above) are both passing now.
I tested master with the simple dilation_mkldnn = dilation_ours - 1, based on MKLDNN's docs
That's instead of this equation here:
&lt;denchmark-link:https://github.com/KonduitAI/deeplearning4j/blob/master/libnd4j/include/ops/declarable/helpers/convolutions.h#L205&gt;https://github.com/KonduitAI/deeplearning4j/blob/master/libnd4j/include/ops/declarable/helpers/convolutions.h#L205&lt;/denchmark-link&gt;

with that "subtract 1" adjustment, everything passes (libnd4j and nd4j) except for 3 of 28 cases from DeconvTests.compareKeras
The 3 cases are:
mb3_k3_sz3_s1_same_d2_nchw
mb3_k3_sz8_s1_same_d2_nhwc
mb3_k4_sz3_s1_same_d2_nchw
that's minibatch / kernel / input size / stride / mode / dilation / format
note that these 3 fail on master also - which is expected, the equation I replaced is for valid mode only.
so dilation 2 + same mode fails
d2 + valid is fine; d1 + same is also fine
Essentially, yes, we should just use dH = dH - 1 everywhere for MKLDNN, and fix whatever this other issue is...
As for what's going on:
We have an effective kernel size of k+(k-1)*(d-1)
mb3_k3_sz3_s1_same_d2_nchw  -  3+(3-1)*(2-1) = 5
mb3_k3_sz8_s1_same_d2_nhwc  -  3+(3-1)*(2-1) = 5
mb3_k4_sz3_s1_same_d2_nchw  -  4+(4-1)*(2-1) = 7
Which gives me 3 hypotheses:

MKLDNN doesn't support dilated deconv with same mode (could explain all 3)
MKLDNN doesn't support dilated deconv when effective kernel size is greater than input (can only explain first and 3rd)

Unless we can find another explanation, I suggest that we just don't use mkldnn for dilated deconv + same mode. It's a rare case anyway.
cc &lt;denchmark-link:https://github.com/shyrma&gt;@shyrma&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='AlexDBlack' date='2019-11-22T13:28:05Z'>
		Confirmed passing now
		</comment>
	</comments>
</bug>