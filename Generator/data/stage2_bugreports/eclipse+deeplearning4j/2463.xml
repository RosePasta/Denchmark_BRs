<bug id='2463' author='ironflood' open_date='2016-12-08T10:22:35Z' closed_time='2016-12-14T22:07:18Z'>
	<summary>ParagraphVectors method inferVector(String) doesn't work as expected</summary>
	<description>
The method is supposed to infer a vector from the learned model on a raw new String but doesn't, it's only able to extract the vector of an existing document label, example inferVector("DOC_3720").
inferredVectorA for example has the following value in intelliJ:
[0.00, 0.00, 0.00, -0.00, 0.00, -0.00, -0.00, 0.00, 0.00, -0.00, 0.00, 0.00, 0.00, 0.00, -0.00, -0.00, -0.00, 0.00, -0.00, -0.00, 0.00, -0.00, -0.00, -0.00, -0.00, 0.00, 0.00, -0.00, 0.00, 0.00, -0.00, 0.00, 0.00, -0.00, -0.00, 0.00, 0.00, 0.00, -0.00, -0.00, -0.00, -0.00, -0.00, 0.00, 0.00, -0.00, 0.00, 0.00, -0.00, 0.00, -0.00, 0.00, 0.00, 0.00, -0.00, 0.00, -0.00, -0.00, -0.00, -0.00, -0.00, 0.00, -0.00, -0.00, 0.00, 0.00, 0.00, -0.00, -0.00, -0.00, 0.00, -0.00, 0.00, -0.00, -0.00, -0.00, -0.00, -0.00, 0.00, -0.00, -0.00, -0.00, -0.00, -0.00, 0.00, 0.00, 0.00, -0.00, -0.00, -0.00, 0.00, 0.00, -0.00, 0.00, 0.00, 0.00, -0.00, 0.00, -0.00, 0.00]
All of the example's cosine similarities produce "1.0" as a result.
Transforms.cosineSim(inferredVectorA, inferredVectorB) = 0.0
	</description>
	<comments>
		<comment id='1' author='ironflood' date='2016-12-08T10:24:45Z'>
		As i see there's some incompatibility between saved earlier paravec model (simple.pv) and current dl4j version.
When i build new model on the fly, i get totally expected output:
&lt;denchmark-code&gt;o.n.n.NativeOps - Number of threads used for NativeOps: 4
o.n.n.Nd4jBlas - Number of threads used for BLAS: 4
o.d.m.s.SequenceVectors - Starting vocabulary building...
o.d.m.w.w.VocabConstructor - Sequences checked: [97162], Current vocabulary size: [97406]; Sequences/sec: [114848.70];
o.d.m.e.i.InMemoryLookupTable - Initializing syn1...
o.d.m.s.SequenceVectors - Building learning algorithms:
o.d.m.s.SequenceVectors -           building SequenceLearningAlgorithm: [PV-DM]
o.d.m.s.SequenceVectors -           building ElementsLearningAlgorithm: [CBOW]
o.d.m.s.SequenceVectors - Starting learning process...
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [653844];  Lines vectorized so far: [100000]; learningRate: [0.020530650607680424]
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [1306625];  Lines vectorized so far: [200022]; learningRate: [0.016069394506951756]
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [1959492];  Lines vectorized so far: [300032]; learningRate: [0.0116070310470696]
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [2611207];  Lines vectorized so far: [400003]; learningRate: [0.007151140853350105]
o.d.m.s.SequenceVectors - Epoch: [1]; Words vectorized so far: [3171520];  Lines vectorized so far: [485805]; learningRate: [1.0E-4]
o.d.m.s.SequenceVectors - Time spent on training: 3261 ms
o.d.e.n.p.ParagraphVectorsInferenceExample - Cosine similarity W1/W2: 0.5782473683357239
o.d.e.n.p.ParagraphVectorsInferenceExample - Cosine similarity A/B: 0.48454561829566956
o.d.e.n.p.ParagraphVectorsInferenceExample - Cosine similarity A/A2: 1.0000001192092896
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='ironflood' date='2016-12-08T10:25:13Z'>
		Where W1 and W2 are different words, "world" and "way" respectively.
		</comment>
		<comment id='3' author='ironflood' date='2016-12-08T10:55:01Z'>
		The model generated in ParagraphsVectorsTextExample.class do not produce correct vectors if we don't add to the model build:
.sequenceLearningAlgorithm(new DM())
.trainWordVectors(true)
Is it normal that I get the following results in vector space ("This is my way ." is closer to "My work, my one" than to "This is my work ."):

o.d.m.s.SequenceVectors - Time spent on training: 5495 ms
o.d.e.n.p.ParagraphVectorsTextExample - 9836/12493 ('This is my house .'/'This is my world .') similarity: 0.28618353605270386
o.d.e.n.p.ParagraphVectorsTextExample - 3721/16393 ('This is my way .'/'This is my work .') similarity: 0.19029979407787323
o.d.e.n.p.ParagraphVectorsTextExample - 6348/3721 ('This is my case .'/'This is my way .') similarity: 0.43039995431900024
o.d.e.n.p.ParagraphVectorsTextExample - 3721/9853 ('This is my way .'/'We now have one .') similarity: 0.09798576682806015(should be significantly lower)
o.d.e.n.p.ParagraphVectorsTextExample - Inferrence test -
V1("This is my way .")/V2("This is my way ."): 0.9999999403953552
V1("This is my way .")/V3("This is my work .") 0.12710878252983093
V1("This is my way .")/V4("My work, my one") 0.2517058849334717

		</comment>
		<comment id='4' author='ironflood' date='2016-12-14T18:44:54Z'>
		Facing very similar bug
Adding this to build
.sequenceLearningAlgorithm(new DM())
.trainWordVectors(true)
doesn't solve problem.
In my case I am calling .useExistingWordVectors
		</comment>
		<comment id='5' author='ironflood' date='2016-12-14T18:46:44Z'>
		In original issue this wasn't an issue, and was discussed/explained in gitter :)
Now, what you're facing? Your post contains almost no information, add some details please.
		</comment>
		<comment id='6' author='ironflood' date='2016-12-14T22:07:18Z'>
		Hswick, raver119 explained it on Gitter actually. You're loading an already built word2vec model, which was probably trained using a different algorithm. You need to be sure the algorithms match between word2vec and ParagraphVector. If you built word2vec using skipgram you can't build paravec using DM, quoting raver119:
Word2vec            Paravec
skipgram     -&gt;    dbow
cbow            -&gt;    dm
Closing the issue as it really isn't one, the model for demo in the version I was using was just not updated.
		</comment>
		<comment id='7' author='ironflood' date='2019-01-20T07:46:24Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>