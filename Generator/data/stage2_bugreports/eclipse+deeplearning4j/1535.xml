<bug id='1535' author='crockpotveggies' open_date='2016-05-13T22:28:29Z' closed_time='2016-05-20T04:52:03Z'>
	<summary>SparkEarlyStoppingTrainer parameters appear to not be functioning?</summary>
	<description>
Took a look at the source but was unable to fully understand the SparkEarlyStoppingTrainer parameters. What are examplesPerFit and totalExamples based on?
In other words, is that arbitrary per Spark node or is total examples == the actual total examples in the entire dataset?
	</description>
	<comments>
		<comment id='1' author='crockpotveggies' date='2016-05-13T22:31:00Z'>
		In addition, setting those parameters doesn't seem to actually do anything. In my logs I see:
&lt;denchmark-code&gt;16/05/13 22:28:05 INFO multilayer.SparkDl4jMultiLayer: Running distributed training:  (averaging each iteration = true), (iterations = 5), (num partions = 2)
&lt;/denchmark-code&gt;

But in my code I've set the trainer to:
&lt;denchmark-code&gt;val trainer: SparkEarlyStoppingTrainer = new SparkEarlyStoppingTrainer(sc, esConf, nn, trainRDD, 50, 150, 5, earlyStoppingListener)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='crockpotveggies' date='2016-05-20T04:52:03Z'>
		Fixed by &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/1571&gt;https://github.com/deeplearning4j/deeplearning4j/pull/1571&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='crockpotveggies' date='2019-01-21T02:52:50Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>