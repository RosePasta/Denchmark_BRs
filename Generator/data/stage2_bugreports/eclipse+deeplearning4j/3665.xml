<bug id='3665' author='AlexDBlack' open_date='2017-07-12T07:59:07Z' closed_time='2017-07-13T09:17:56Z'>
	<summary>PrecisionRecallCurve.getConfusionMatrixAtPoint() returning incorrect values</summary>
	<description>
&lt;denchmark-code&gt;-- Point at precision 0.85 --
PrecisionRecallCurve.Point(idx=245974, threshold=0.6900250911712646, precision=0.8501374125480652, recall=0.09870869666337967)
PrecisionRecallCurve.Confusion(point=PrecisionRecallCurve.Point(idx=245974, threshold=0.6900250911712646, precision=0.8501374125480652, recall=0.09870869666337967), tpCount=154448, fpCount=1503650, fnCount=2215, tnCount=243758)
&lt;/denchmark-code&gt;

Note that precision = tp / (tp + fp) = 154448 / (154448+1503650) = 0.0931 != 0.85
	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2017-07-12T11:40:58Z'>
		Fixed here: will merge soon.
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/3653&gt;https://github.com/deeplearning4j/deeplearning4j/pull/3653&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='AlexDBlack' date='2018-09-26T02:57:35Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>