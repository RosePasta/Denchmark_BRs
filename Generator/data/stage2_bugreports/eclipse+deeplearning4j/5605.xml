<bug id='5605' author='bekkon' open_date='2018-06-15T09:37:42Z' closed_time='2018-06-19T07:49:49Z'>
	<summary>Unable to broadcast dimension 1 due to shape mismatch exception with Deconvolution2D layers</summary>
	<description>
I tried to set up a neural net using a ComputationGraph based on some research paper. This net has an encoder-decoder like structure: it uses Deconvolution2D layers for the decoding part. After putting together the net, I found that I can run the training with batch size 1, but any higher batch size value causes the net to stop with a message similar to the below:
Exception in thread "main" java.lang.IllegalArgumentException: Unable to broadcast dimension 1 due to shape mismatch. Right shape must be 1. Left array shape: [2, 16, 33, 33], right array shape: [16, 2, 33, 33]
I spent a lot of time debugging the issue to see what did I miss. I simplified the net to the smallest possible size, it now only has a Convolution, Deconvolution2D and an Output layer. I can still reproduce my original problem: with batch size 1, it works fine, otherwise it stops.
Looking at the array shapes in the error message it seems that the minibatch size and the number of channels is mixed up whenever I receive this error.
I created a GIST for this in the hope that someone could check and give me a hint on how to fix this.
&lt;denchmark-link:https://gist.github.com/bekkon/7fd406d21d1320d08a5d2fe82e2a0331&gt;https://gist.github.com/bekkon/7fd406d21d1320d08a5d2fe82e2a0331&lt;/denchmark-link&gt;

After tracing back the calls, I found that I can seemingly fix this error by modifying the backpropGradient method in Deconvolution2D class. At the very end of the method, it does a permutation of the previously prepared outEps:
"outEps = outEps.permute(1, 0, 2 , 3);"
If I change this to "outEps = outEps.permute(0, 1, 2 , 3);", the exception goes away, backpropagation succeeds in the preceding layer.
Please check if this is indeed an error in Deconvolution2D. If not, please help me understand what did I do wrong in my network setup to end up with this error. (The attached net in the GIST is just for reproducing the error, it is not supposed to be meaningful, for network-help I'll share the complex net in a separate GIST  )
Thanks :)
	</description>
	<comments>
		<comment id='1' author='bekkon' date='2018-06-15T10:33:17Z'>
		&lt;denchmark-link:https://github.com/bekkon&gt;@bekkon&lt;/denchmark-link&gt;
 thanks for reporting. would you mind checking your case against our existing tests?
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/883f23cb4f3bcbd23387e79b4aaa48313f2ec963/deeplearning4j/deeplearning4j-cuda/src/test/java/org/deeplearning4j/gradientcheck/CNNGradientCheckTest.java#L861&gt;https://github.com/deeplearning4j/deeplearning4j/blob/883f23cb4f3bcbd23387e79b4aaa48313f2ec963/deeplearning4j/deeplearning4j-cuda/src/test/java/org/deeplearning4j/gradientcheck/CNNGradientCheckTest.java#L861&lt;/denchmark-link&gt;

It shows you how to use the layer and covers various cases. Let us know if yours isn't covered by it.
		</comment>
		<comment id='2' author='bekkon' date='2018-06-16T18:06:32Z'>
		I'm getting the same issue with multiple Deconvolution2D layers when calling model.fit(myDataSet). That "outEps = outEps.permute(1, 0, 2 , 3);" line is swapping the minibatch size and the channel size which is a very strange thing to do, as the previous layer then has to have a number of output channels equal to the minibatch size, which makes no sense as the minibatch size could be anything (e.g. depending on available data/memory). Removing that line entirely prevents the exception (&lt;denchmark-link:https://github.com/bekkon&gt;@bekkon&lt;/denchmark-link&gt;
 suggestion of permute(0, 1, 2, 3) is actually no-op), but I do wonder why it was there at all. Attached is a failing unit test I wrote:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/files/2108413/Deconvolution2DLayerTest.zip&gt;Deconvolution2DLayerTest.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='bekkon' date='2018-06-16T21:16:52Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
: I had a look at the unit test and amended it to cover this case as well:
&lt;denchmark-link:https://gist.github.com/bekkon/7fd406d21d1320d08a5d2fe82e2a0331#file-testdeconvolution2dv2-java&gt;https://gist.github.com/bekkon/7fd406d21d1320d08a5d2fe82e2a0331#file-testdeconvolution2dv2-java&lt;/denchmark-link&gt;

I applied two changes:


Changed miniBatch size from '3' to '4'
This is to make sure that a possible swap of the 'miniBatch' and 'inputChannels' values would get noticed by looking at the array shapes.


Added another layer before the Deconvolution2D layer to make sure that the activation gradient returned by backpropGradient method would be used rather than discarded.


Now the test fails with the usual exception when running it for the original Deconvolution2D class. The test succeeds for the modified version.
&lt;denchmark-link:https://github.com/ryanbennitt&gt;@ryanbennitt&lt;/denchmark-link&gt;
: thanks for confirming my find.
		</comment>
		<comment id='4' author='bekkon' date='2018-06-17T12:21:25Z'>
		&lt;denchmark-link:https://github.com/bekkon&gt;@bekkon&lt;/denchmark-link&gt;
 that's great to hear! Do you mind opening a PR for this (including the test)? Otherwise I'll fix it, let me know.
		</comment>
		<comment id='5' author='bekkon' date='2018-06-18T00:50:45Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 I'd be happy to, if you can wait a few days for me to get there. I'll have to find time for setting up a complete dl4j build env and also to find another way for testing the epsilon value returned by the layer. The modified test case runs for about 20 mins which was not a problem for validating the fix but won't do as a unit test.
		</comment>
		<comment id='6' author='bekkon' date='2018-06-19T07:50:46Z'>
		&lt;denchmark-link:https://github.com/bekkon&gt;@bekkon&lt;/denchmark-link&gt;
 just fixed this issue. Thanks for reporting  identifying the root cause! 
		</comment>
		<comment id='7' author='bekkon' date='2018-06-23T21:28:36Z'>
		&lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 Thanks for fixing the issue.
		</comment>
		<comment id='8' author='bekkon' date='2018-09-21T17:59:12Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>