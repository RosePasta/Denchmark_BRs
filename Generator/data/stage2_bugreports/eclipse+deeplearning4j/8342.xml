<bug id='8342' author='longzhendong' open_date='2019-11-03T13:25:04Z' closed_time='2019-11-06T04:06:47Z'>
	<summary>libnd4j: strided_slice_bp bug</summary>
	<description>
Please indicate relevant versions, including, if relevant:

Deeplearning4j version :1.0.0-beta5
Platform information ：win10

public class LN4 {
&lt;denchmark-code&gt;public static void main(String[] args) {

	

	SameDiff sd = SameDiff.create();

	SDVariable input = sd.var("input", DataType.FLOAT, 1, 2);

	SDVariable label = sd.var("label", DataType.FLOAT, 1, 2);

	INDArray inputArr = Nd4j.linspace(2, 3, 2).reshape(new int[] { 1,2 });
	INDArray labelArr = Nd4j.linspace(1, 4, 2).reshape(new int[] { 1,2 });
	
	
	SDVariable a= input.get(SDIndex.all(),SDIndex.point(0));
	SDVariable b= input.get(SDIndex.all(),SDIndex.point(1));

	SDVariable c=sd.stack("stack", 1, a,b);

	SDVariable m= sd.math().pow(c.sub(label), 2) ;
	sd.setLossVariables(m);
	
	System.out.println(sd.summary());
	
	for(int i=0;i&lt;5;i++){
		sd.associateArrayWithVariable(inputArr, input);
		sd.associateArrayWithVariable(labelArr, label);
		sd.execBackwards(null,Operation.INFERENCE);
		System.out.println(input.getGradient().getArr());
		System.out.println(c.getGradient().getArr());
		System.out.println("==============");
		sd.clearPlaceholders(true);
        sd.clearOpInputs();
	}
}
&lt;/denchmark-code&gt;

}
Result：
&lt;denchmark-h:h1&gt;[[         0,         0]]
[[    2.0000,   -2.0000]]&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;[[    2.0000,    2.0000]]
[[    2.0000,   -2.0000]]&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;[[    2.0000,    2.0000]]
[[    2.0000,   -2.0000]]&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;[[         0,         0]]
[[    2.0000,   -2.0000]]&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;[[   -2.0000,   -2.0000]]
[[    2.0000,   -2.0000]]&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='longzhendong' date='2019-11-03T13:25:35Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='longzhendong' date='2019-11-03T13:45:55Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 The differential value of c and input should be the same！
		</comment>
		<comment id='3' author='longzhendong' date='2019-11-04T03:13:35Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 Do you have time to look at this issue？
		</comment>
		<comment id='4' author='longzhendong' date='2019-11-04T08:22:05Z'>
		Thanks for reporting.
This is a bug in strided slice backprop - reproducible with the following test case:
&lt;denchmark-link:https://gist.github.com/AlexDBlack/a2e9f87e46dc20dbc5eadcab39a8a993&gt;https://gist.github.com/AlexDBlack/a2e9f87e46dc20dbc5eadcab39a8a993&lt;/denchmark-link&gt;

I have checked the array shapes and iargs, that looks reasonable to me, so it is likely a bug in the implementation.
		</comment>
		<comment id='5' author='longzhendong' date='2019-11-04T08:30:39Z'>
		&lt;denchmark-link:https://github.com/AlexDBlack&gt;@AlexDBlack&lt;/denchmark-link&gt;
 I want to implement BPTT with samediff, which will slice the input in time steps and then stack it into a new tensor to calculate the gradient. Can I calculate the gradient of loss to the input?
		</comment>
		<comment id='6' author='longzhendong' date='2019-11-04T08:58:41Z'>
		&lt;denchmark-link:https://github.com/longzhendong&gt;@longzhendong&lt;/denchmark-link&gt;
 on the current master (and snapshots, as soon as they are back up) you could use SameDiff.calculateGradients method and specify that you want the input gradient returned.
Another way to implement TBPTT would be to have placeholders for both the initial RNN state and the normal input... split it externally, using INDArray.get instead of internally using SDVariable.get.
Your outputs are the activations and the RNN last time step (which you can store to feed in as placeholders for the next step)
		</comment>
		<comment id='7' author='longzhendong' date='2019-11-06T04:06:47Z'>
		Confirmed fixed and merged to eclipse master also
Thanks for reporting &lt;denchmark-link:https://github.com/longzhendong&gt;@longzhendong&lt;/denchmark-link&gt;
, and for the fix &lt;denchmark-link:https://github.com/shugeo&gt;@shugeo&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>