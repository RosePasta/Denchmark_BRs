<bug id='4761' author='AlexDBlack' open_date='2018-03-06T04:26:10Z' closed_time='2018-04-03T23:45:33Z'>
	<summary>Windows - CUDA gradient check failures</summary>
	<description>
Test platform: Windows, CUDA 9.0
Edit: Windows CUDA 9.1 fails with exact same symptoms.
Fails when run through intellij or maven
These tests fail on CUDA when all CNNGradientCheckTests are run, but pass:
(a) On CPU
(b) When run in isolation (i.e., one test at a time)
(c) on Linux, CUDA 9.1 (Kubuntu 17.10, GTX 970s)
&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/37014124-9b42dfd0-2152-11e8-814a-a5c05e1e6057.png&gt;&lt;/denchmark-link&gt;

Note that it's inconsistent - different tests fail during different runs...
&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/37014593-d5f1dc82-2155-11e8-862e-7883d6b28e67.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/37014618-03d67d92-2156-11e8-9ea7-17b502bbefa4.png&gt;&lt;/denchmark-link&gt;

Results when run through maven: &lt;denchmark-link:https://gist.github.com/AlexDBlack/ca782023187fa0786054b733c6e10960&gt;https://gist.github.com/AlexDBlack/ca782023187fa0786054b733c6e10960&lt;/denchmark-link&gt;

Not sure what's going on here or why...
Edit: so far I've ruled out:

Workspaces (setting WorkspaceMode.NONE makes no difference)
RNG seeds (setting before each test - no difference)
Destroying workspaces before each gradient check is run

There seems to be some degree of randomness - and possibly multiple issues...

Some tests clearly fail due to subsampling layer backprop
Other tests fail with a single, very wrong gradient (see below)
Other tests just fail outright - all gradients fail, but other tests (very similar params/config) all pass
Some tests I can run for a thousand times, without any issues :/

&lt;denchmark-code&gt;o.d.g.GradientCheckUtil - Param 1812 (2_W) passed: grad= 0.04007660303681882, numericalGrad= 0.04007660303617655, relError= 8.01304140042311E-12
o.d.g.GradientCheckUtil - Param 1813 (2_W) FAILED: grad= 0.0034388891218970277, numericalGrad= 48836.31517098053, relError= 0.9999998591667342, scorePlus=0.693761944443137, scoreMinus= 0.5960893141011759
o.d.g.GradientCheckUtil - Param 1814 (2_W) passed: grad= -0.021406821076271437, numericalGrad= -0.021406821093528094, relError= 4.030644680906441E-10
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2018-03-13T05:45:07Z'>
		Update here: this is still occuring on Windows, still passing consistently on Linux.
As an additional experiment, I've run testCnnSamePaddingModeStrided (so far) 84 times in a loop without any issues at all. :/
		</comment>
		<comment id='2' author='AlexDBlack' date='2018-03-26T03:46:24Z'>
		Quick update: this is definitely some kind of race condition. Bug isn't reproducible on Azure K80 gpu, and isn't reproducible in debug mode on my desktop.
		</comment>
		<comment id='3' author='AlexDBlack' date='2018-03-28T18:40:03Z'>
		Update:

definitely not caused by workspace mode
original idea that it might be caused by im2col/col2im/pooling2d ops wasn't confirmed :/
layers themselves look ok.

		</comment>
		<comment id='4' author='AlexDBlack' date='2018-03-29T03:51:00Z'>
		Update:

definitely might happen on FF or BP pass or both
difference looks to be concentrated around Conv2D layer
Conv2D layer produces different outputs given the same inputs.

		</comment>
		<comment id='5' author='AlexDBlack' date='2018-03-29T03:51:14Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/12250879/38069152-bfc41468-32c9-11e8-9624-c83603a9d7ab.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='AlexDBlack' date='2018-04-03T23:45:33Z'>
		Confirmed fixed.
		</comment>
		<comment id='7' author='AlexDBlack' date='2018-09-22T23:28:20Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>