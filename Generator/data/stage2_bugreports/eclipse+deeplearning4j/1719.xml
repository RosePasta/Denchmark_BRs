<bug id='1719' author='davireis' open_date='2016-06-19T04:34:20Z' closed_time='2016-11-30T14:42:07Z'>
	<summary>Not able to use word2vec with spark</summary>
	<description>
Hi,
I have been trying to move away from the local word2vec model to the spark based code, and so far I have not succeeded in doing so. I am using the released rc3.10 jars, and I usually run with ~10 m4.10xlarge machines in amazon, including one for the driver. I allocate 40g for the driver and executors. There are two classes of problems:
When training with large data (&gt;1B phrases), the code gets stuck in  buildVocabWordListRDD(), more specifically in totalWordCount = sentenceCountRDD.reduce(new ReduceSentenceCount()).get();. Progress progressively degrades, the driver machine becomes unresponsive and eventually the job aborts. With smaller inputs, I can get past the vocabulary building and the code finishes fine.
When training finishes with smaller data, the vectors do not seem to have quality anywhere close to the locally trained models. For example, in my unit tests, where I have 100k phrases mixing portuguese and english, I usually check for english words, which predicts mostly other english words. This works fine for the locally trained model, not for the spark one.
&lt;denchmark-code&gt;Spark Word2Vec predictions for day:me, proprias, uol, sorvete, melhoria
Driver Word2Vec predictions for day:guide, five, number, song, making
Spark Word2Vec predictions for google:borboleta, carrinho, pinos, importa, moldes
Driver Word2Vec predictions for google:chrome, firefox, explorer, windows, mozilla 
&lt;/denchmark-code&gt;

I probably can do similar tests with more easily reproduced cases, like comparing to tensorflow over text8.zip.
Is the spark word2vec implementation in rc3.10 considered stable or should I just wait for another release?
	</description>
	<comments>
		<comment id='1' author='davireis' date='2016-06-19T13:17:51Z'>
		Show what you have there please.
pom.xml, source code you're using + add some details on your training corpus.
		</comment>
		<comment id='2' author='davireis' date='2016-06-19T13:27:41Z'>
		Important question there. Are you, by any chance, have totally unformatted text? Like one string for the whole corpus? :)
		</comment>
		<comment id='3' author='davireis' date='2016-06-19T14:15:16Z'>
		My own corpus is a bit complicated, but I have reproduced the problem with the text8.zip corpus used by tensorflow examples. I unzip and split it into lines before using, so no totally unformatted text.
&lt;denchmark-code&gt;wget http://mattmahoney.net/dc/text8.zip
unzip text8.zip
fold -s -w240 text8 &gt; text8lines  # http://superuser.com/questions/826679/split-very-long-line-of-words-into-separate-lines-of-max-length
&lt;/denchmark-code&gt;

What I believe are the relevant parts of my pom.xml are below. My nd4j.version and dl4j.version are rc3.10, my spark version is 1.6.1, I am using scala 2.11. I run my code in both mac and linux (the latter with openblas installed).
&lt;denchmark-code&gt;    &lt;dependency&gt;
      &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
      &lt;artifactId&gt;nd4j-native&lt;/artifactId&gt;
      &lt;version&gt;${nd4j.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
      &lt;artifactId&gt;nd4j-native&lt;/artifactId&gt;
      &lt;version&gt;${nd4j.version}&lt;/version&gt;
      &lt;classifier&gt;linux-x86_64&lt;/classifier&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
      &lt;artifactId&gt;nd4j-native&lt;/artifactId&gt;
      &lt;version&gt;${nd4j.version}&lt;/version&gt;
      &lt;classifier&gt;macosx-x86_64&lt;/classifier&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
      &lt;artifactId&gt;nd4j-kryo_2.11&lt;/artifactId&gt;
      &lt;version&gt;0.4-rc3.10&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
      &lt;artifactId&gt;deeplearning4j-core&lt;/artifactId&gt;
      &lt;version&gt;${dl4j.version}&lt;/version&gt;
      &lt;exclusions&gt;
        &lt;exclusion&gt;
          &lt;!-- Will be provided by jcl-over-slf4j --&gt;
          &lt;groupId&gt;commons-logging&lt;/groupId&gt;
          &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
        &lt;/exclusion&gt;
      &lt;/exclusions&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.nd4j&lt;/groupId&gt;
      &lt;artifactId&gt;nd4j-api&lt;/artifactId&gt;
      &lt;version&gt;${nd4j.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
      &lt;artifactId&gt;dl4j-spark-nlp_${scala.binary.version}&lt;/artifactId&gt;
      &lt;version&gt;${dl4j.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
      &lt;groupId&gt;org.deeplearning4j&lt;/groupId&gt;
      &lt;artifactId&gt;deeplearning4j-ui&lt;/artifactId&gt;
      &lt;version&gt;${dl4j.version}&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/denchmark-code&gt;

I have training code for dl4j spark, dl4j in the driver, and spark ml word2vec. The only one with strange results is dl4j spark (it is also the fastest):
&lt;denchmark-code&gt; def trainModel(validSentencesRdd: RDD[String], distributedTraining: Boolean, sparkMl: Boolean): Word2Vec = {
    val tokenizer = new DefaultTokenizerFactory()
    tokenizer.setTokenPreProcessor(new CommonPreprocessor())
    if (sparkMl) {
      val sql = new SQLContext(validSentencesRdd.sparkContext)
      import sql.implicits._
      val validSentencesDf = validSentencesRdd.map(s =&gt; StringList(s.split(" "))).toDF()
      // Learn a mapping from words to Vectors.
      val word2vec = new SparkMlWord2Vec()
          .setInputCol("sentences")
          .setOutputCol("wordvectors")
          .setVectorSize(100)
          .setMinCount(100)
      val model = word2vec.fit(validSentencesDf)
      val result = model.transform(validSentencesDf)
      result.select("wordvectors").take(3).foreach(println)
      val localModel = new Word2Vec()
      val arrays = new util.ArrayList[INDArray]()
      val cache = new AbstractCache.Builder[VocabWord]().build()
      model.getVectors.collect() foreach { row =&gt;
        val word = row.getString(0)
        val vector: Array[Double] = row.get(1).asInstanceOf[DenseVector].values
        val word1 = new VocabWord(1.0, word)
        word1.setIndex(cache.numWords())
        cache.addToken(word1)
        cache.addWordToIndex(word1.getIndex, word)
        val nd4jrow = Nd4j.create(vector)
        arrays.add(nd4jrow);
      }
      localModel.setVocab(cache)
      val lookupTable: InMemoryLookupTable[VocabWord] = new InMemoryLookupTable.Builder[VocabWord]()
          .vectorLength(arrays.get(0).columns).cache(cache).build
          .asInstanceOf[InMemoryLookupTable[VocabWord]]
      val syn: INDArray = Nd4j.vstack(arrays)
      Nd4j.clearNans(syn)
      lookupTable.setSyn0(syn)
      localModel.setLookupTable(lookupTable)
      localModel

    } else if (distributedTraining) {
     logger.info("Building spark based word2vec model....")
      val model = new SparkWord2Vec.Builder()
          .batchSize(batchSize)
          .minWordFrequency(minCount)
          .useAdaGrad(false)
          .layerSize(vectorSize)
          .iterations(maxIter)
          .learningRate(learningRate)
          .minLearningRate(minLearningRate)
          .tokenizerFactory(tokenizer)
          .build()
      model.train(validSentencesRdd.toJavaRDD())
      model.setModelUtils(new FlatModelUtils())
      // The spark model has no serialization machinery, so convert it to a local model.
      // https://github.com/deeplearning4j/deeplearning4j/issues/1718
      val localModel = new Word2Vec()
      localModel.setLookupTable(model.getLookupTable)
      localModel.setVocab(model.getVocab)
      localModel.setModelUtils(new FlatModelUtils())
      localModel
    } else {
      logger.info("Building driver based word2vec model....")
      val iter = new RddSentenceIterator(validSentencesRdd)
      val model: Word2Vec = new Word2Vec.Builder()
          .batchSize(batchSize)
          .minWordFrequency(minCount)
          .useAdaGrad(false)
          .layerSize(vectorSize)
          .iterations(maxIter)
          .learningRate(learningRate)
          .minLearningRate(minLearningRate)
          .tokenizerFactory(tokenizer)
          .iterate(iter)
          .build()
      model.fit()
      model
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='davireis' date='2016-06-19T14:28:25Z'>
		What is SparkWord2Vec? Can i see it's definition?
		</comment>
		<comment id='5' author='davireis' date='2016-06-19T14:34:06Z'>
		It is simply an import rename:
import org.apache.spark.ml.feature.{Word2Vec =&gt; SparkMlWord2Vec}
		</comment>
		<comment id='6' author='davireis' date='2016-06-19T14:34:34Z'>
		And: import org.deeplearning4j.spark.models.embeddings.word2vec.{Word2Vec =&gt; SparkWord2Vec}
		</comment>
		<comment id='7' author='davireis' date='2016-06-19T14:38:21Z'>
		Ok, give me some time to reproduce your issue locally.
		</comment>
		<comment id='8' author='davireis' date='2016-06-19T16:33:55Z'>
		After running stuff a bit more carefully, I believe the difference on quality is not that big. See the output for sparkml and dl4jspark wordvector runs:
dl4jspark
&lt;denchmark-code&gt;NFO  [2016-06-19 16:02:44,902] com.worldsense.spark.SerializedSparkJobGroup: Starting job group sentencesample:localword2vecsample
INFO  [2016-06-19 16:02:44,906] com.worldsense.deeplearning.DL4jWord2Vec: Loading sentences....
INFO  [2016-06-19 16:02:59,547] com.worldsense.deeplearning.DL4jWord2Vec: Corpus of size 422014
INFO  [2016-06-19 16:02:59,550] com.worldsense.deeplearning.DL4jWord2Vec: Training word2vec model with trainer dl4jspark
INFO  [2016-06-19 16:02:59,551] com.worldsense.deeplearning.DL4jWord2Vec: Building spark based word2vec model....
INFO  [2016-06-19 16:02:59,582] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Start training ...
INFO  [2016-06-19 16:02:59,589] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Tokenization and building VocabCache ...
INFO  [2016-06-19 16:03:19,747] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Building Huffman Tree ...
INFO  [2016-06-19 16:03:19,747] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Calculating cumulative sum of sentence counts ...
INFO  [2016-06-19 16:03:20,132] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Mapping to RDD(vocabWordList, cumulative sentence count) ...
INFO  [2016-06-19 16:03:20,146] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Broadcasting word2vec variables to workers ...
INFO  [2016-06-19 16:03:20,169] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Training word2vec sentences ...
INFO  [2016-06-19 16:05:18,914] com.worldsense.deeplearning.DL4jWord2Vec: word2vec time: 0:02:19.360
INFO  [2016-06-19 16:05:18,915] com.worldsense.deeplearning.DL4jWord2Vec: Saving local Word2Vec model....
INFO  [2016-06-19 16:05:22,629] org.deeplearning4j.models.embeddings.loader.WordVectorSerializer: Wrote 47134 with size of 100
INFO  [2016-06-19 16:05:30,003] com.worldsense.deeplearning.DL4jWord2Vec: Saving vocab....
INFO  [2016-06-19 16:05:40,604] com.worldsense.deeplearning.DL4jWord2Vec: Testing local Word2Vec model....
INFO  [2016-06-19 16:05:40,772] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for have:has, reduce, argue, allow, make
INFO  [2016-06-19 16:05:40,808] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for during:after, war, before, took, saw
INFO  [2016-06-19 16:05:40,834] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for five:six, seven, eight, four, three
INFO  [2016-06-19 16:05:40,857] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for while:because, though, although, however, only
INFO  [2016-06-19 16:05:40,879] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for was:had, became, gave, wrote, took
INFO  [2016-06-19 16:05:40,900] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for is:makes, are, means, requires, gives
INFO  [2016-06-19 16:05:40,918] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for on:at, from, into, with, upon
INFO  [2016-06-19 16:05:40,937] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for or:acids, behaviors, heat, enzymes, compounds
INFO  [2016-06-19 16:05:40,954] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for his:her, him, she, himself, later
INFO  [2016-06-19 16:05:40,971] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for in:from, within, between, by, on
INFO  [2016-06-19 16:05:40,989] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for however:but, because, always, reason, though
INFO  [2016-06-19 16:05:42,077] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for most:many, often, very, some, common
INFO  [2016-06-19 16:05:42,097] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for no:so, any, all, evidence, if
INFO  [2016-06-19 16:05:42,114] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for called:sometimes, given, inverse, hence, very
INFO  [2016-06-19 16:05:42,132] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for has:have, had, having, makes, subversive
INFO  [2016-06-19 16:05:42,150] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for known:well, regarded, such, described, referred
INFO  [2016-06-19 16:05:42,167] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for google:resource, websites, maps, forum, chat
INFO  [2016-06-19 16:05:42,167] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for carro:
INFO  [2016-06-19 16:05:42,167] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for davi:
INFO  [2016-06-19 16:05:42,167] com.worldsense.spark.StageParser: Stage sentencesample:localword2vecsample outcome is success
&lt;/denchmark-code&gt;

sparkml
&lt;denchmark-code&gt;INFO  [2016-06-19 16:09:22,743] com.worldsense.spark.StageParser: Running Stage sentencesample:localword2vecsample.
INFO  [2016-06-19 16:09:22,744] com.worldsense.spark.SerializedSparkJobGroup: Starting job group sentencesample:localword2vecsample
INFO  [2016-06-19 16:09:22,750] com.worldsense.deeplearning.DL4jWord2Vec: Loading sentences....
INFO  [2016-06-19 16:09:37,411] com.worldsense.deeplearning.DL4jWord2Vec: Corpus of size 422014
INFO  [2016-06-19 16:09:37,419] com.worldsense.deeplearning.DL4jWord2Vec: Training word2vec model with trainer sparkml
WARN  [2016-06-19 16:10:31,713] com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
WARN  [2016-06-19 16:10:31,713] com.github.fommil.netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
INFO  [2016-06-19 16:10:42,756] com.worldsense.deeplearning.DL4jWord2Vec: word2vec time: 0:01:05.332
INFO  [2016-06-19 16:10:42,756] com.worldsense.deeplearning.DL4jWord2Vec: Saving local Word2Vec model....
INFO  [2016-06-19 16:10:46,213] org.deeplearning4j.models.embeddings.loader.WordVectorSerializer: Wrote 47134 with size of 100
INFO  [2016-06-19 16:10:51,384] com.worldsense.deeplearning.DL4jWord2Vec: Saving vocab....
INFO  [2016-06-19 16:10:54,533] com.worldsense.deeplearning.DL4jWord2Vec: Testing local Word2Vec model....
INFO  [2016-06-19 16:10:54,692] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for have:having, has, had, give, previously
INFO  [2016-06-19 16:10:54,722] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for during:under, after, against, before, following
INFO  [2016-06-19 16:10:54,745] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for five:four, three, six, births, two
INFO  [2016-06-19 16:10:54,766] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for while:although, into, upon, among, however
INFO  [2016-06-19 16:10:54,787] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for was:became, took, is, later, began
INFO  [2016-06-19 16:10:54,807] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for is:means, makes, was, making, are
INFO  [2016-06-19 16:10:54,825] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for on:from, under, through, into, following
INFO  [2016-06-19 16:10:54,843] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for or:using, complex, specific, contain, special
INFO  [2016-06-19 16:10:54,862] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for his:her, later, him, he, himself
INFO  [2016-06-19 16:10:54,881] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for in:under, from, between, during, throughout
INFO  [2016-06-19 16:10:54,899] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for however:although, though, but, because, that
INFO  [2016-06-19 16:10:54,918] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for most:basic, many, some, legal, traditional
INFO  [2016-06-19 16:10:54,936] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for no:little, almost, still, always, though
INFO  [2016-06-19 16:10:54,954] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for called:here, now, highly, usually, today
INFO  [2016-06-19 16:10:54,972] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for has:had, have, having, long, includes
INFO  [2016-06-19 16:10:54,992] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for known:well, regarded, described, such, cited
INFO  [2016-06-19 16:10:55,010] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for google:sites, transport, racing, videos, tourism
INFO  [2016-06-19 16:10:55,010] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for carro:
INFO  [2016-06-19 16:10:55,010] com.worldsense.deeplearning.DL4jWord2Vec: Local Word2Vec predictions for davi:
INFO  [2016-06-19 16:10:55,011] com.worldsense.spark.StageParser: Stage sentencesample:localword2vecsample outcome is success
&lt;/denchmark-code&gt;

Probably with more data, this should converge. However, vocabulary creation phase still bottlenecks dl4jspark when I use &gt;1B sentences in the input, as described in the first message of this issue.
		</comment>
		<comment id='9' author='davireis' date='2016-06-19T16:47:55Z'>
		Hold on there please, i'm going to investigate your issue thoroughly, but right now i still have high-prio things to finish. As soon as i'm done there, i'll pay proper attention to your issue, since spark environment is very important for dl4j
		</comment>
		<comment id='10' author='davireis' date='2016-06-19T17:00:47Z'>
		No worries, I am doing progress myself. Will keep updating the issue, feel free to pay attention to other priorities.
		</comment>
		<comment id='11' author='davireis' date='2016-06-20T04:04:00Z'>
		So, after a long struggle, I can't really get past  buildVocabWordListRDD with a vocabulary of 500k words. It puts too much pressure on the garbage collector, doesn't matter the setup I do. Here is the log until I get stuck and eventually tasks start to die due to gc high rate. This run is using 8192 partitions, but I also tried 512 (close to my number of cores, which is 400).
&lt;denchmark-code&gt;INFO  [2016-06-20 03:38:20,741] com.worldsense.spark.StageParser: Stage sentence:localword2vec registered.
INFO  [2016-06-20 03:38:20,742] com.worldsense.spark.StageParser: Skipping Stage bow:sentence.
INFO  [2016-06-20 03:38:20,805] com.worldsense.spark.StageParser: Running Stage sentence:localword2vec.
INFO  [2016-06-20 03:38:20,805] com.worldsense.spark.SerializedSparkJobGroup: Starting job group sentence:localword2vec
INFO  [2016-06-20 03:38:20,808] com.worldsense.deeplearning.DL4jWord2Vec: Loading sentences....
INFO  [2016-06-20 03:51:14,211] com.worldsense.deeplearning.DL4jWord2Vec: Corpus with 1018737815 sentences and 6.0876987617E10 total tokens.
INFO  [2016-06-20 03:52:28,278] com.worldsense.deeplearning.DL4jWord2Vec: Expected vocabulary of size 501176 with a min count of 215
INFO  [2016-06-20 03:52:30,133] com.worldsense.deeplearning.DL4jWord2Vec: Training word2vec model with trainer dl4jspark
INFO  [2016-06-20 03:52:30,135] com.worldsense.deeplearning.DL4jWord2Vec: Building spark based word2vec model....
INFO  [2016-06-20 03:52:30,172] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Start training ...
INFO  [2016-06-20 03:52:30,180] org.deeplearning4j.spark.models.embeddings.word2vec.Word2Vec: Tokenization and building VocabCache ...
[Stage 22:============&gt;                                     (2044 + 494) / 8192]
&lt;/denchmark-code&gt;

The (non dl4j) spark word2vec implementation has no trouble building the vocabulary, and runs fine until the end (around 3 hours in my setup), but the quality of the vectors is quite poor, I suspect due to the distribution (their docs explicitly say accuracy drops with number of partitions, and I used 512 partitions).
		</comment>
		<comment id='12' author='davireis' date='2016-06-20T05:58:57Z'>
		&lt;denchmark-link:https://github.com/davireis&gt;@davireis&lt;/denchmark-link&gt;
 Is the load too much even with concurrent GC () ?
		</comment>
		<comment id='13' author='davireis' date='2016-06-20T07:38:32Z'>
		500k words is pretty equal to 0, in terms of word2vec. Show full pom.xml please this time.
		</comment>
		<comment id='14' author='davireis' date='2016-06-20T12:51:42Z'>
		Notice my input is 60 billion words (probably 10x english wikipedia size), as shown in the log lines. What is 500k is the number of distinct words above mincount, i.e., the number of vectors that the system is generating. This is pretty typical, I would say (e.g., glove generates 1-2M vectors).
Also notice that the system gets stuck before word2vec itself starts, in  buildVocabWordListRDD, more specifically in totalWordCount = sentenceCountRDD.reduce(new ReduceSentenceCount()).get(). This is usually due to too much cache(), too large broadcasts, too much memory overhead per partition, or a combination of those.
Let me give concurrent GC a try. My pom.xml is super complicated, so it is probably better I try to build a reduced project for you. In the meantime, here is the output of mvn dependency:tree:
&lt;denchmark-code&gt;
[INFO] com.worldsense:linker:jar:0.0.5-SNAPSHOT
[INFO] +- io.dropwizard:dropwizard-core:jar:0.9.1:compile
[INFO] |  +- io.dropwizard:dropwizard-util:jar:0.9.1:compile
[INFO] |  +- io.dropwizard:dropwizard-jackson:jar:0.9.1:compile
[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk7:jar:2.6.3:compile
[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile
[INFO] |  |  +- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.6.3:compile
[INFO] |  |  \- com.fasterxml.jackson.datatype:jackson-datatype-joda:jar:2.6.3:compile
[INFO] |  +- io.dropwizard:dropwizard-validation:jar:0.9.1:compile
[INFO] |  |  +- org.hibernate:hibernate-validator:jar:5.2.2.Final:compile
[INFO] |  |  |  +- org.jboss.logging:jboss-logging:jar:3.2.1.Final:compile
[INFO] |  |  |  \- com.fasterxml:classmate:jar:1.1.0:compile
[INFO] |  |  \- org.glassfish:javax.el:jar:3.0.0:compile
[INFO] |  +- io.dropwizard:dropwizard-configuration:jar:0.9.1:compile
[INFO] |  +- io.dropwizard:dropwizard-metrics:jar:0.9.1:compile
[INFO] |  +- io.dropwizard:dropwizard-jersey:jar:0.9.1:compile
[INFO] |  |  +- org.glassfish.jersey.ext:jersey-bean-validation:jar:2.21:compile
[INFO] |  |  +- io.dropwizard.metrics:metrics-jersey2:jar:3.1.2:compile
[INFO] |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile
[INFO] |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile
[INFO] |  |  |  \- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.6.3:compile
[INFO] |  |  +- org.glassfish.jersey.containers:jersey-container-servlet:jar:2.21:compile
[INFO] |  |  +- org.eclipse.jetty:jetty-server:jar:9.2.13.v20150730:compile
[INFO] |  |  |  \- org.eclipse.jetty:jetty-io:jar:9.2.13.v20150730:compile
[INFO] |  |  +- org.eclipse.jetty:jetty-webapp:jar:9.2.13.v20150730:compile
[INFO] |  |  |  \- org.eclipse.jetty:jetty-xml:jar:9.2.13.v20150730:compile
[INFO] |  |  \- org.eclipse.jetty:jetty-continuation:jar:9.2.13.v20150730:compile
[INFO] |  +- io.dropwizard:dropwizard-servlets:jar:0.9.1:compile
[INFO] |  |  \- io.dropwizard.metrics:metrics-annotation:jar:3.1.2:compile
[INFO] |  +- io.dropwizard:dropwizard-jetty:jar:0.9.1:compile
[INFO] |  |  +- io.dropwizard.metrics:metrics-jetty9:jar:3.1.2:compile
[INFO] |  |  +- org.eclipse.jetty:jetty-servlets:jar:9.2.13.v20150730:compile
[INFO] |  |  \- org.eclipse.jetty:jetty-http:jar:9.2.13.v20150730:compile
[INFO] |  +- io.dropwizard:dropwizard-lifecycle:jar:0.9.1:compile
[INFO] |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile
[INFO] |  +- io.dropwizard.metrics:metrics-jvm:jar:3.1.2:compile
[INFO] |  +- io.dropwizard.metrics:metrics-servlets:jar:3.1.2:compile
[INFO] |  +- io.dropwizard.metrics:metrics-healthchecks:jar:3.1.2:compile
[INFO] |  \- org.eclipse.jetty.toolchain.setuid:jetty-setuid-java:jar:1.0.3:compile
[INFO] +- io.dropwizard:dropwizard-logging:jar:0.9.1:compile
[INFO] |  +- io.dropwizard.metrics:metrics-logback:jar:3.1.2:compile
[INFO] |  +- org.slf4j:jul-to-slf4j:jar:1.7.12:compile
[INFO] |  +- ch.qos.logback:logback-core:jar:1.1.3:compile
[INFO] |  +- ch.qos.logback:logback-classic:jar:1.1.3:compile
[INFO] |  +- org.slf4j:log4j-over-slf4j:jar:1.7.12:compile
[INFO] |  +- org.slf4j:jcl-over-slf4j:jar:1.7.12:compile
[INFO] |  \- org.eclipse.jetty:jetty-util:jar:9.2.13.v20150730:compile
[INFO] +- io.dropwizard:dropwizard-auth:jar:0.9.1:compile
[INFO] +- io.dropwizard:dropwizard-metrics-graphite:jar:0.9.1:compile
[INFO] |  \- io.dropwizard.metrics:metrics-graphite:jar:3.1.2:compile
[INFO] +- com.bazaarvoice.dropwizard:dropwizard-configurable-assets-bundle:jar:0.2.2:compile
[INFO] +- de.thomaskrille:dropwizard-template-config:jar:1.2.0:compile
[INFO] +- nl.grons:metrics-scala_2.11:jar:3.5.2:compile
[INFO] |  \- org.scala-lang:scala-library:jar:2.11.7:compile
[INFO] +- org.stuartgunter:dropwizard-logging-config:jar:0.1:compile
[INFO] +- net.logstash.logback:logstash-logback-encoder:jar:4.5.1:compile
[INFO] |  \- com.fasterxml.jackson.core:jackson-databind:jar:2.6.3:compile
[INFO] +- com.tradier:dropwizard-raven:jar:0.9.1:compile
[INFO] |  \- com.getsentry.raven:raven-logback:jar:7.0.0:compile
[INFO] |     \- com.getsentry.raven:raven:jar:7.0.0:compile
[INFO] +- com.wikia:dropwizard-logstash-encoder:jar:1.0.2:compile
[INFO] |  +- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.3:compile
[INFO] |  \- com.fasterxml.jackson.core:jackson-core:jar:2.6.3:compile
[INFO] +- com.softwaremill.macwire:macros_2.11:jar:2.2.2:compile
[INFO] |  \- org.scala-lang:scala-reflect:jar:2.11.7:compile
[INFO] +- com.softwaremill.quicklens:quicklens_2.11:jar:1.4.1:compile
[INFO] +- org.slf4j:slf4j-api:jar:1.7.12:compile
[INFO] +- org.scalactic:scalactic_2.11:jar:2.2.5:compile
[INFO] +- com.carrotsearch.randomizedtesting:randomizedtesting-runner:jar:2.1.13:test
[INFO] +- org.scalatest:scalatest_2.11:jar:2.2.5:test
[INFO] |  \- org.scala-lang.modules:scala-xml_2.11:jar:1.0.2:compile
[INFO] +- org.scalacheck:scalacheck_2.11:jar:1.12.1:test
[INFO] |  +- org.scala-lang.modules:scala-parser-combinators_2.11:jar:1.0.2:compile
[INFO] |  \- org.scala-sbt:test-interface:jar:1.0:test
[INFO] +- com.google.guava:guava:jar:18.0:compile
[INFO] +- org.seleniumhq.selenium:selenium-chrome-driver:jar:2.46.0:test
[INFO] |  \- org.seleniumhq.selenium:selenium-remote-driver:jar:2.46.0:test
[INFO] |     +- cglib:cglib-nodep:jar:2.1_3:test
[INFO] |     +- com.google.code.gson:gson:jar:2.3.1:compile
[INFO] |     +- org.seleniumhq.selenium:selenium-api:jar:2.46.0:test
[INFO] |     +- org.apache.commons:commons-exec:jar:1.3:test
[INFO] |     +- net.java.dev.jna:jna:jar:4.1.0:test
[INFO] |     \- net.java.dev.jna:jna-platform:jar:4.1.0:test
[INFO] +- org.seleniumhq.selenium:selenium-support:jar:2.46.0:test
[INFO] +- org.apache.lucene:lucene-test-framework:jar:5.5.0:test
[INFO] |  \- org.apache.lucene:lucene-codecs:jar:5.5.0:test
[INFO] +- org.elasticsearch:elasticsearch:test-jar:tests:2.3.2:test
[INFO] |  +- org.apache.lucene:lucene-backward-codecs:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-queries:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-memory:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-highlighter:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-queryparser:jar:5.5.0:compile
[INFO] |  |  \- org.apache.lucene:lucene-sandbox:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-suggest:jar:5.5.0:compile
[INFO] |  |  \- org.apache.lucene:lucene-misc:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-join:jar:5.5.0:compile
[INFO] |  |  \- org.apache.lucene:lucene-grouping:jar:5.5.0:compile
[INFO] |  +- org.apache.lucene:lucene-spatial:jar:5.5.0:compile
[INFO] |  |  +- org.apache.lucene:lucene-spatial3d:jar:5.5.0:compile
[INFO] |  |  \- com.spatial4j:spatial4j:jar:0.5:compile
[INFO] |  +- org.elasticsearch:securesm:jar:1.0:compile
[INFO] |  +- com.carrotsearch:hppc:jar:0.7.1:compile
[INFO] |  +- joda-time:joda-time:jar:2.8.2:compile
[INFO] |  +- org.joda:joda-convert:jar:1.2:compile
[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.6.2:compile
[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.2:compile
[INFO] |  +- io.netty:netty:jar:3.10.5.Final:compile
[INFO] |  +- com.ning:compress-lzf:jar:1.0.2:compile
[INFO] |  +- com.tdunning:t-digest:jar:3.0:compile
[INFO] |  +- org.hdrhistogram:HdrHistogram:jar:2.1.6:compile
[INFO] |  +- commons-cli:commons-cli:jar:1.3.1:compile
[INFO] |  \- com.twitter:jsr166e:jar:1.1.0:compile
[INFO] +- com.github.spullara.mustache.java:compiler:jar:0.9.1:compile
[INFO] +- org.elasticsearch:elasticsearch:jar:2.3.2:compile
[INFO] +- org.jsoup:jsoup:jar:1.8.3:compile
[INFO] +- org.apache.lucene:lucene-core:jar:5.5.0:compile
[INFO] +- org.apache.lucene:lucene-analyzers-common:jar:5.5.0:compile
[INFO] +- org.jwat:jwat-warc:jar:1.0.2:compile
[INFO] |  +- org.jwat:jwat-common:jar:1.0.2:compile
[INFO] |  +- org.jwat:jwat-archive-common:jar:1.0.2:compile
[INFO] |  \- org.jwat:jwat-gzip:jar:1.0.2:compile
[INFO] +- com.twitter:scrooge-core_2.11:jar:4.6.0:compile
[INFO] +- com.amazonaws:aws-java-sdk-cognitoidentity:jar:1.10.32:compile
[INFO] +- com.amazonaws:aws-java-sdk-dynamodb:jar:1.10.32:compile
[INFO] +- com.amazonaws:aws-java-sdk-sts:jar:1.10.32:compile
[INFO] +- com.amazonaws:aws-java-sdk-s3:jar:1.10.32:compile
[INFO] |  \- com.amazonaws:aws-java-sdk-kms:jar:1.10.32:compile
[INFO] +- com.amazonaws:aws-java-sdk-core:jar:1.10.32:compile
[INFO] |  \- org.apache.httpcomponents:httpclient:jar:4.4.1:compile
[INFO] |     +- org.apache.httpcomponents:httpcore:jar:4.4.1:compile
[INFO] |     \- commons-codec:commons-codec:jar:1.5:compile
[INFO] +- org.apache.parquet:parquet-hadoop:jar:1.7.0:compile
[INFO] |  +- org.apache.parquet:parquet-column:jar:1.7.0:compile
[INFO] |  |  +- org.apache.parquet:parquet-common:jar:1.7.0:compile
[INFO] |  |  \- org.apache.parquet:parquet-encoding:jar:1.7.0:compile
[INFO] |  |     \- org.apache.parquet:parquet-generator:jar:1.7.0:compile
[INFO] |  +- org.apache.parquet:parquet-format:jar:2.3.0-incubating:compile
[INFO] |  +- org.apache.parquet:parquet-jackson:jar:1.7.0:compile
[INFO] |  +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.11:compile
[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.11:compile
[INFO] |  \- org.xerial.snappy:snappy-java:jar:1.1.1.6:compile
[INFO] +- org.apache.parquet:parquet-thrift:jar:1.7.0:compile
[INFO] |  +- com.twitter.elephantbird:elephant-bird-core:jar:4.4:compile
[INFO] |  |  +- com.twitter.elephantbird:elephant-bird-hadoop-compat:jar:4.4:compile
[INFO] |  |  +- org.apache.thrift:libthrift:jar:0.9.3:compile
[INFO] |  |  +- com.googlecode.json-simple:json-simple:jar:1.1:compile
[INFO] |  |  \- com.hadoop.gplcompression:hadoop-lzo:jar:0.4.16:compile
[INFO] |  +- com.twitter.elephantbird:elephant-bird-pig:jar:4.4:compile
[INFO] |  \- org.apache.parquet:parquet-pig:jar:1.7.0:compile
[INFO] +- org.jhades:jhades:jar:1.0.4:compile
[INFO] +- org.apache.spark:spark-core_2.11:jar:1.6.1:compile
[INFO] |  +- org.apache.avro:avro-mapred:jar:hadoop2:1.7.7:compile
[INFO] |  |  +- org.apache.avro:avro-ipc:jar:1.7.7:compile
[INFO] |  |  |  \- org.apache.avro:avro:jar:1.7.7:compile
[INFO] |  |  \- org.apache.avro:avro-ipc:jar:tests:1.7.7:compile
[INFO] |  +- com.twitter:chill_2.11:jar:0.5.0:compile
[INFO] |  +- com.twitter:chill-java:jar:0.5.0:compile
[INFO] |  +- org.apache.xbean:xbean-asm5-shaded:jar:4.4:compile
[INFO] |  +- org.apache.hadoop:hadoop-client:jar:2.7.1:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-common:jar:2.7.1:compile
[INFO] |  |  |  +- xmlenc:xmlenc:jar:0.52:compile
[INFO] |  |  |  +- commons-httpclient:commons-httpclient:jar:3.1:compile
[INFO] |  |  |  +- commons-collections:commons-collections:jar:3.2.2:compile
[INFO] |  |  |  +- javax.servlet.jsp:jsp-api:jar:2.1:runtime
[INFO] |  |  |  +- org.apache.hadoop:hadoop-auth:jar:2.7.1:compile
[INFO] |  |  |  |  \- org.apache.directory.server:apacheds-kerberos-codec:jar:2.0.0-M15:compile
[INFO] |  |  |  |     +- org.apache.directory.server:apacheds-i18n:jar:2.0.0-M15:compile
[INFO] |  |  |  |     +- org.apache.directory.api:api-asn1-api:jar:1.0.0-M20:compile
[INFO] |  |  |  |     \- org.apache.directory.api:api-util:jar:1.0.0-M20:compile
[INFO] |  |  |  +- org.apache.curator:curator-client:jar:2.7.1:compile
[INFO] |  |  |  \- org.apache.htrace:htrace-core:jar:3.1.0-incubating:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-hdfs:jar:2.7.1:compile
[INFO] |  |  |  \- org.mortbay.jetty:jetty-util:jar:6.1.26:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-app:jar:2.7.1:compile
[INFO] |  |  |  +- org.apache.hadoop:hadoop-mapreduce-client-common:jar:2.7.1:compile
[INFO] |  |  |  |  +- org.apache.hadoop:hadoop-yarn-client:jar:2.7.1:compile
[INFO] |  |  |  |  \- org.apache.hadoop:hadoop-yarn-server-common:jar:2.7.1:compile
[INFO] |  |  |  \- org.apache.hadoop:hadoop-mapreduce-client-shuffle:jar:2.7.1:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-yarn-api:jar:2.7.1:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-core:jar:2.7.1:compile
[INFO] |  |  |  \- org.apache.hadoop:hadoop-yarn-common:jar:2.7.1:compile
[INFO] |  |  |     +- com.sun.jersey:jersey-client:jar:1.9:compile
[INFO] |  |  |     +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.11:compile
[INFO] |  |  |     \- org.codehaus.jackson:jackson-xc:jar:1.9.11:compile
[INFO] |  |  +- org.apache.hadoop:hadoop-mapreduce-client-jobclient:jar:2.7.1:compile
[INFO] |  |  \- org.apache.hadoop:hadoop-annotations:jar:2.7.1:compile
[INFO] |  +- org.apache.spark:spark-launcher_2.11:jar:1.6.1:compile
[INFO] |  +- org.apache.spark:spark-network-common_2.11:jar:1.6.1:compile
[INFO] |  +- org.apache.spark:spark-network-shuffle_2.11:jar:1.6.1:compile
[INFO] |  |  \- org.fusesource.leveldbjni:leveldbjni-all:jar:1.8:compile
[INFO] |  +- org.apache.spark:spark-unsafe_2.11:jar:1.6.1:compile
[INFO] |  +- net.java.dev.jets3t:jets3t:jar:0.9.0:compile
[INFO] |  |  \- com.jamesmurty.utils:java-xmlbuilder:jar:0.4:compile
[INFO] |  +- org.apache.curator:curator-recipes:jar:2.4.0:compile
[INFO] |  |  +- org.apache.curator:curator-framework:jar:2.4.0:compile
[INFO] |  |  \- org.apache.zookeeper:zookeeper:jar:3.4.5:compile
[INFO] |  |     \- jline:jline:jar:0.9.94:compile
[INFO] |  +- org.eclipse.jetty.orbit:javax.servlet:jar:3.0.0.v201112011016:provided
[INFO] |  +- org.apache.commons:commons-lang3:jar:3.3.2:compile
[INFO] |  +- org.apache.commons:commons-math3:jar:3.4.1:compile
[INFO] |  +- com.google.code.findbugs:jsr305:jar:1.3.9:compile
[INFO] |  +- net.jpountz.lz4:lz4:jar:1.3.0:compile
[INFO] |  +- org.roaringbitmap:RoaringBitmap:jar:0.5.11:compile
[INFO] |  +- commons-net:commons-net:jar:3.1:compile
[INFO] |  +- org.json4s:json4s-jackson_2.11:jar:3.2.10:compile
[INFO] |  |  \- org.json4s:json4s-core_2.11:jar:3.2.10:compile
[INFO] |  |     +- org.json4s:json4s-ast_2.11:jar:3.2.10:compile
[INFO] |  |     \- org.scala-lang:scalap:jar:2.11.7:compile
[INFO] |  +- org.apache.mesos:mesos:jar:shaded-protobuf:0.21.1:compile
[INFO] |  +- io.netty:netty-all:jar:4.0.29.Final:compile
[INFO] |  +- com.clearspring.analytics:stream:jar:2.7.0:compile
[INFO] |  +- io.dropwizard.metrics:metrics-json:jar:3.1.2:compile
[INFO] |  +- org.apache.ivy:ivy:jar:2.4.0:compile
[INFO] |  +- oro:oro:jar:2.0.8:compile
[INFO] |  +- org.tachyonproject:tachyon-client:jar:0.8.2:compile
[INFO] |  |  +- org.tachyonproject:tachyon-underfs-hdfs:jar:0.8.2:compile
[INFO] |  |  +- org.tachyonproject:tachyon-underfs-s3:jar:0.8.2:compile
[INFO] |  |  \- org.tachyonproject:tachyon-underfs-local:jar:0.8.2:compile
[INFO] |  +- net.razorvine:pyrolite:jar:4.9:compile
[INFO] |  +- net.sf.py4j:py4j:jar:0.9:compile
[INFO] |  \- org.spark-project.spark:unused:jar:1.0.0:compile
[INFO] +- org.apache.spark:spark-mllib_2.11:jar:1.6.1:compile
[INFO] |  +- org.apache.spark:spark-graphx_2.11:jar:1.6.1:compile
[INFO] |  |  +- com.github.fommil.netlib:core:jar:1.1.2:compile
[INFO] |  |  \- net.sourceforge.f2j:arpack_combined_all:jar:0.1:compile
[INFO] |  +- org.scalanlp:breeze_2.11:jar:0.11.2:compile
[INFO] |  |  +- org.scalanlp:breeze-macros_2.11:jar:0.11.2:compile
[INFO] |  |  +- net.sf.opencsv:opencsv:jar:2.3:compile
[INFO] |  |  +- com.github.rwl:jtransforms:jar:2.4.0:compile
[INFO] |  |  \- org.spire-math:spire_2.11:jar:0.7.4:compile
[INFO] |  |     \- org.spire-math:spire-macros_2.11:jar:0.7.4:compile
[INFO] |  \- org.jpmml:pmml-model:jar:1.1.15:compile
[INFO] |     +- org.jpmml:pmml-agent:jar:1.1.15:compile
[INFO] |     +- org.jpmml:pmml-schema:jar:1.1.15:compile
[INFO] |     \- com.sun.xml.bind:jaxb-impl:jar:2.2.7:compile
[INFO] |        \- com.sun.xml.bind:jaxb-core:jar:2.2.7:compile
[INFO] +- org.apache.spark:spark-sql_2.11:jar:1.6.1:compile
[INFO] |  \- org.apache.spark:spark-catalyst_2.11:jar:1.6.1:compile
[INFO] |     \- org.codehaus.janino:janino:jar:2.7.8:compile
[INFO] |        \- org.codehaus.janino:commons-compiler:jar:2.7.8:compile
[INFO] +- org.apache.spark:spark-streaming_2.11:jar:1.6.1:compile
[INFO] +- org.apache.spark:spark-repl_2.11:jar:1.6.1:compile
[INFO] |  +- org.apache.spark:spark-bagel_2.11:jar:1.6.1:runtime
[INFO] |  \- org.scala-lang:scala-compiler:jar:2.11.7:compile
[INFO] +- net.sourceforge.argparse4j:argparse4j:jar:0.6.0:compile
[INFO] +- com.squareup.okhttp3:okhttp:jar:3.1.2:compile
[INFO] |  \- com.squareup.okio:okio:jar:1.6.0:compile
[INFO] +- com.google.api-ads:dfp-appengine:jar:2.8.0:compile
[INFO] |  +- com.google.api-ads:ads-lib-appengine:jar:2.8.0:compile
[INFO] |  |  \- com.google.api-client:google-api-client-appengine:jar:1.20.0:compile
[INFO] |  |     +- com.google.oauth-client:google-oauth-client-appengine:jar:1.20.0:compile
[INFO] |  |     |  +- com.google.oauth-client:google-oauth-client-servlet:jar:1.20.0:compile
[INFO] |  |     |  |  \- com.google.http-client:google-http-client-jdo:jar:1.20.0:compile
[INFO] |  |     |  \- javax.servlet:servlet-api:jar:2.5:provided
[INFO] |  |     +- com.google.api-client:google-api-client-servlet:jar:1.20.0:compile
[INFO] |  |     |  \- javax.jdo:jdo2-api:jar:2.3-eb:compile
[INFO] |  |     |     \- javax.transaction:transaction-api:jar:1.1:compile
[INFO] |  |     \- com.google.http-client:google-http-client-appengine:jar:1.20.0:compile
[INFO] |  +- com.google.api-ads:ads-lib:jar:2.8.0:compile
[INFO] |  |  +- com.google.inject:guice:jar:4.0:compile
[INFO] |  |  |  +- javax.inject:javax.inject:jar:1:compile
[INFO] |  |  |  \- aopalliance:aopalliance:jar:1.0:compile
[INFO] |  |  +- com.google.inject.extensions:guice-assistedinject:jar:4.0:compile
[INFO] |  |  +- com.google.inject.extensions:guice-multibindings:jar:4.0:compile
[INFO] |  |  +- commons-configuration:commons-configuration:jar:1.7:compile
[INFO] |  |  |  +- commons-logging:commons-logging:jar:1.1.1:compile
[INFO] |  |  |  +- commons-digester:commons-digester:jar:1.8.1:compile
[INFO] |  |  |  \- commons-beanutils:commons-beanutils:jar:1.9.2:compile
[INFO] |  |  +- com.google.api-client:google-api-client:jar:1.20.0:compile
[INFO] |  |  |  \- com.google.oauth-client:google-oauth-client:jar:1.20.0:compile
[INFO] |  |  \- com.google.http-client:google-http-client-jackson2:jar:1.20.0:compile
[INFO] |  |     \- com.google.http-client:google-http-client:jar:1.20.0:compile
[INFO] |  \- commons-lang:commons-lang:jar:2.6:compile
[INFO] +- org.elasticsearch:elasticsearch-spark_2.11:jar:2.2.0-rc1:compile
[INFO] +- junit:junit:jar:4.12:test
[INFO] |  \- org.hamcrest:hamcrest-core:jar:1.3:test
[INFO] +- org.assertj:assertj-core:jar:3.3.0:test
[INFO] +- org.apache.tika:tika-core:jar:1.12:compile
[INFO] +- com.optimaize.languagedetector:language-detector:jar:0.5:compile
[INFO] |  +- net.arnx:jsonic:jar:1.2.11:compile
[INFO] |  \- com.intellij:annotations:jar:12.0:compile
[INFO] +- org.log4s:log4s_2.11:jar:1.1.5:compile
[INFO] +- edu.stanford.nlp:stanford-corenlp:jar:3.6.0:compile
[INFO] |  +- com.io7m.xom:xom:jar:1.2.10:compile
[INFO] |  |  +- xml-apis:xml-apis:jar:1.3.03:compile
[INFO] |  |  +- xerces:xercesImpl:jar:2.8.0:compile
[INFO] |  |  \- xalan:xalan:jar:2.7.0:compile
[INFO] |  +- de.jollyday:jollyday:jar:0.4.7:compile
[INFO] |  |  \- javax.xml.bind:jaxb-api:jar:2.2.7:compile
[INFO] |  +- com.googlecode.efficient-java-matrix-library:ejml:jar:0.23:compile
[INFO] |  \- javax.json:javax.json-api:jar:1.0:compile
[INFO] +- org.glassfish.jersey.core:jersey-server:jar:2.21:compile
[INFO] |  +- org.glassfish.jersey.core:jersey-common:jar:2.21:compile
[INFO] |  |  +- org.glassfish.jersey.bundles.repackaged:jersey-guava:jar:2.21:compile
[INFO] |  |  \- org.glassfish.hk2:osgi-resource-locator:jar:1.0.1:compile
[INFO] |  +- org.glassfish.jersey.core:jersey-client:jar:2.21:compile
[INFO] |  +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile
[INFO] |  +- org.glassfish.jersey.media:jersey-media-jaxb:jar:2.21:compile
[INFO] |  +- javax.annotation:javax.annotation-api:jar:1.2:compile
[INFO] |  +- org.glassfish.hk2:hk2-api:jar:2.4.0-b31:compile
[INFO] |  |  +- org.glassfish.hk2:hk2-utils:jar:2.4.0-b31:compile
[INFO] |  |  \- org.glassfish.hk2.external:aopalliance-repackaged:jar:2.4.0-b31:compile
[INFO] |  +- org.glassfish.hk2.external:javax.inject:jar:2.4.0-b31:compile
[INFO] |  +- org.glassfish.hk2:hk2-locator:jar:2.4.0-b31:compile
[INFO] |  |  \- org.javassist:javassist:jar:3.18.1-GA:compile
[INFO] |  \- javax.validation:validation-api:jar:1.1.0.Final:compile
[INFO] +- org.glassfish.jersey.containers:jersey-container-servlet-core:jar:2.21:compile
[INFO] +- org.glassfish.jersey.test-framework.providers:jersey-test-framework-provider-inmemory:jar:2.21:test
[INFO] |  +- org.glassfish.jersey.test-framework:jersey-test-framework-core:jar:2.21:test
[INFO] |  |  \- javax.servlet:javax.servlet-api:jar:3.0.1:compile
[INFO] |  \- org.ow2.asm:asm-debug-all:jar:5.0.4:test
[INFO] +- org.glassfish.jersey.ext.rx:jersey-rx-client-java8:jar:2.21:compile
[INFO] |  \- org.glassfish.jersey.ext.rx:jersey-rx-client:jar:2.21:compile
[INFO] +- org.eclipse.jetty:jetty-servlet:jar:9.2.13.v20150730:compile
[INFO] |  \- org.eclipse.jetty:jetty-security:jar:9.2.13.v20150730:compile
[INFO] +- com.likethecolor:alchemy:jar:1.1.6:compile
[INFO] |  \- org.json:json:jar:20090211:compile
[INFO] +- com.github.worldsense:hadoop-aws-shaded:jar:master-aaeff87293-1:compile
[INFO] +- com.ibm.icu:icu4j:jar:56.1:compile
[INFO] +- com.sun.jersey:jersey-server:jar:1.9:compile
[INFO] |  \- asm:asm:jar:3.1:compile
[INFO] +- com.sun.jersey:jersey-core:jar:1.9:compile
[INFO] +- net.debasishg:redisclient_2.11:jar:3.0:compile
[INFO] |  \- commons-pool:commons-pool:jar:1.6:compile
[INFO] +- org.nd4j:nd4j-native:jar:0.4-rc3.10:compile
[INFO] |  \- org.nd4j:nd4j-native-api:jar:0.4-rc3.10:compile
[INFO] |     \- org.bytedeco:javacpp:jar:1.2.1:compile
[INFO] +- org.nd4j:nd4j-native:jar:linux-x86_64:0.4-rc3.10:compile
[INFO] +- org.nd4j:nd4j-native:jar:macosx-x86_64:0.4-rc3.10:compile
[INFO] +- org.nd4j:nd4j-kryo_2.11:jar:0.4-rc3.10:compile
[INFO] |  \- com.esotericsoftware.kryo:kryo:jar:2.21:compile
[INFO] |     +- com.esotericsoftware.reflectasm:reflectasm:jar:shaded:1.07:compile
[INFO] |     |  \- org.ow2.asm:asm:jar:4.0:compile
[INFO] |     \- com.esotericsoftware.minlog:minlog:jar:1.2:compile
[INFO] +- org.deeplearning4j:deeplearning4j-core:jar:0.4-rc3.10:compile
[INFO] |  +- io.netty:netty-buffer:jar:4.0.29.Final:provided
[INFO] |  |  \- io.netty:netty-common:jar:4.0.29.Final:provided
[INFO] |  +- org.nd4j:canova-api:jar:0.0.0.16:compile
[INFO] |  +- org.nd4j:canova-nd4j-image:jar:0.0.0.16:compile
[INFO] |  |  +- org.nd4j:canova-nd4j-common:jar:0.0.0.16:compile
[INFO] |  |  +- org.nd4j:canova-data-image:jar:0.0.0.16:compile
[INFO] |  |  +- com.github.jai-imageio:jai-imageio-core:jar:1.3.0:compile
[INFO] |  |  +- com.twelvemonkeys.imageio:imageio-jpeg:jar:3.1.1:compile
[INFO] |  |  |  +- com.twelvemonkeys.imageio:imageio-core:jar:3.1.1:compile
[INFO] |  |  |  +- com.twelvemonkeys.imageio:imageio-metadata:jar:3.1.1:compile
[INFO] |  |  |  +- com.twelvemonkeys.common:common-lang:jar:3.1.1:compile
[INFO] |  |  |  +- com.twelvemonkeys.common:common-io:jar:3.1.1:compile
[INFO] |  |  |  \- com.twelvemonkeys.common:common-image:jar:3.1.1:compile
[INFO] |  |  +- com.twelvemonkeys.imageio:imageio-tiff:jar:3.1.1:compile
[INFO] |  |  +- com.twelvemonkeys.imageio:imageio-psd:jar:3.1.1:compile
[INFO] |  |  +- com.twelvemonkeys.imageio:imageio-bmp:jar:3.1.1:compile
[INFO] |  |  +- org.bytedeco:javacv:jar:1.2:compile
[INFO] |  |  +- org.bytedeco.javacpp-presets:opencv:jar:3.1.0-1.2:compile
[INFO] |  |  |  \- org.bytedeco.javacpp-presets:opencv:jar:macosx-x86_64:3.1.0-1.2:compile
[INFO] |  |  +- org.bytedeco.javacpp-presets:ffmpeg:jar:3.0.2-1.2:compile
[INFO] |  |  |  \- org.bytedeco.javacpp-presets:ffmpeg:jar:macosx-x86_64:3.0.2-1.2:compile
[INFO] |  |  \- org.bytedeco.javacpp-presets:leptonica:jar:1.73-1.2:compile
[INFO] |  |     \- org.bytedeco.javacpp-presets:leptonica:jar:macosx-x86_64:1.73-1.2:compile
[INFO] |  +- commons-io:commons-io:jar:2.4:compile
[INFO] |  +- org.apache.commons:commons-compress:jar:1.8:compile
[INFO] |  |  \- org.tukaani:xz:jar:1.5:compile
[INFO] |  \- org.projectlombok:lombok:jar:1.16.4:compile
[INFO] +- org.nd4j:nd4j-api:jar:0.4-rc3.10:compile
[INFO] |  +- org.nd4j:nd4j-buffer:jar:0.4-rc3.10:compile
[INFO] |  |  \- org.nd4j:nd4j-common:jar:0.4-rc3.10:compile
[INFO] |  |     \- org.reflections:reflections:jar:0.9.10:compile
[INFO] |  |        \- com.google.code.findbugs:annotations:jar:2.0.1:compile
[INFO] |  \- org.nd4j:nd4j-context:jar:0.4-rc3.10:compile
[INFO] +- org.deeplearning4j:dl4j-spark-nlp_2.11:jar:0.4-rc3.10:compile
[INFO] |  +- com.hazelcast:hazelcast-all:jar:3.4.2:compile
[INFO] |  |  +- net.sourceforge.findbugs:annotations:jar:1.3.2:compile
[INFO] |  |  \- com.eclipsesource.minimal-json:minimal-json:jar:0.9.1:compile
[INFO] |  +- org.deeplearning4j:deeplearning4j-nlp:jar:0.4-rc3.10:compile
[INFO] |  |  +- org.apache.directory.studio:org.apache.commons.codec:jar:1.8:compile
[INFO] |  |  +- it.unimi.dsi:dsiutils:jar:2.2.2:compile
[INFO] |  |  |  +- it.unimi.dsi:fastutil:jar:6.5.15:compile
[INFO] |  |  |  \- com.martiansoftware:jsap:jar:2.1:compile
[INFO] |  |  +- org.cleartk:cleartk-snowball:jar:2.0.0:compile
[INFO] |  |  |  +- org.apache.lucene:lucene-snowball:jar:3.0.3:compile
[INFO] |  |  |  +- org.cleartk:cleartk-util:jar:2.0.0:compile
[INFO] |  |  |  |  +- org.apache.uima:uimaj-core:jar:2.5.0:compile
[INFO] |  |  |  |  \- org.apache.uima:uimafit-core:jar:2.0.0:compile
[INFO] |  |  |  |     +- commons-logging:commons-logging-api:jar:1.1:compile
[INFO] |  |  |  |     +- org.springframework:spring-core:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  |     |  \- org.springframework:spring-asm:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  |     +- org.springframework:spring-context:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  |     |  +- org.springframework:spring-aop:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  |     |  \- org.springframework:spring-expression:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  |     \- org.springframework:spring-beans:jar:3.1.2.RELEASE:compile
[INFO] |  |  |  \- org.cleartk:cleartk-type-system:jar:2.0.0:compile
[INFO] |  |  \- org.cleartk:cleartk-opennlp-tools:jar:2.0.0:compile
[INFO] |  |     +- org.apache.opennlp:opennlp-maxent:jar:3.0.3:compile
[INFO] |  |     +- org.apache.opennlp:opennlp-tools:jar:1.5.3:compile
[INFO] |  |     |  \- net.sf.jwordnet:jwnl:jar:1.3.3:compile
[INFO] |  |     \- org.apache.opennlp:opennlp-uima:jar:1.5.3:compile
[INFO] |  +- org.deeplearning4j:dl4j-spark_2.11:jar:0.4-rc3.10:compile
[INFO] |  |  \- org.nd4j:canova-spark_2.11:jar:0.0.0.16:compile
[INFO] |  \- org.deeplearning4j:deeplearning4j-scaleout-api:jar:0.4-rc3.10:compile
[INFO] +- org.deeplearning4j:deeplearning4j-ui:jar:0.4-rc3.10:compile
[INFO] |  +- io.dropwizard:dropwizard-assets:jar:0.8.0:compile
[INFO] |  +- io.dropwizard:dropwizard-client:jar:0.9.1:compile
[INFO] |  |  +- io.dropwizard.metrics:metrics-httpclient:jar:3.1.2:compile
[INFO] |  |  \- org.glassfish.jersey.connectors:jersey-apache-connector:jar:2.22.1:compile
[INFO] |  +- io.dropwizard:dropwizard-forms:jar:0.9.1:compile
[INFO] |  +- org.glassfish.jersey.media:jersey-media-multipart:jar:2.21:compile
[INFO] |  |  \- org.jvnet.mimepull:mimepull:jar:1.9.6:compile
[INFO] |  +- io.dropwizard:dropwizard-views-mustache:jar:0.9.1:compile
[INFO] |  |  \- io.dropwizard:dropwizard-views:jar:0.9.1:compile
[INFO] |  +- io.dropwizard:dropwizard-views-freemarker:jar:0.9.1:compile
[INFO] |  |  \- org.freemarker:freemarker:jar:2.3.23:compile
[INFO] |  \- org.nd4j:nd4j-jackson:jar:0.4-rc3.10:compile
[INFO] +- com.fasterxml.jackson.module:jackson-module-scala_2.11:jar:2.6.3:compile
[INFO] |  \- com.fasterxml.jackson.module:jackson-module-paranamer:jar:2.6.3:compile
[INFO] |     \- com.thoughtworks.paranamer:paranamer:jar:2.6:compile
[INFO] +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.6.3:compile
[INFO] |  \- org.yaml:snakeyaml:jar:1.15:compile
[INFO] +- org.mockito:mockito-core:jar:1.10.19:test
[INFO] |  \- org.objenesis:objenesis:jar:2.1:compile
[INFO] +- org.hamcrest:hamcrest-library:jar:1.3:test
[INFO] +- com.github.tototoshi:scala-csv_2.11:jar:1.2.2:compile
[INFO] +- com.typesafe.akka:akka-remote_2.11:jar:2.3.11:compile
[INFO] |  +- com.google.protobuf:protobuf-java:jar:2.5.0:compile
[INFO] |  \- org.uncommons.maths:uncommons-maths:jar:1.2.2a:compile
[INFO] +- com.typesafe.akka:akka-actor_2.11:jar:2.3.11:compile
[INFO] |  \- com.typesafe:config:jar:1.2.1:compile
[INFO] +- com.typesafe.akka:akka-cluster_2.11:jar:2.3.11:compile
[INFO] +- com.typesafe.akka:akka-contrib_2.11:jar:2.3.11:compile
[INFO] |  \- com.typesafe.akka:akka-persistence-experimental_2.11:jar:2.3.11:compile
[INFO] |     \- org.iq80.leveldb:leveldb:jar:0.5:compile
[INFO] |        \- org.iq80.leveldb:leveldb-api:jar:0.5:compile
[INFO] \- com.typesafe.akka:akka-slf4j_2.11:jar:2.3.11:compile
&lt;/denchmark-code&gt;

		</comment>
		<comment id='15' author='davireis' date='2016-06-20T14:55:44Z'>
		Well, i'm on it now. I've got multiple different corpuses in russian language from my backups, so i'm training on them sequentially, and will check each one, one by one using dl4j spark w2v.
		</comment>
		<comment id='16' author='davireis' date='2016-11-30T14:42:07Z'>
		Closing due to inactivity.
		</comment>
		<comment id='17' author='davireis' date='2019-01-20T07:56:57Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>