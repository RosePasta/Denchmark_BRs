<bug id='7466' author='AlexDBlack' open_date='2019-04-08T01:48:47Z' closed_time='2019-04-25T14:21:22Z'>
	<summary>ND4J: Error in Nd4j.toNpyByteArray(INDArray) format?</summary>
	<description>
Reported in Gitter:
&lt;denchmark-code&gt;Jose A. Corbacho @mccorby 02:59
Hi,

I am working on a project that requires transferring tensors from DL4J to Pytorch. I am using the npy format to move the data from one side (Android) to another (a server running Pytorch)
I can successfully send a byte array from the server to the client where I build an INDArray using Nd4j.createNpyFromByteArray
I do then some operations and return an INDArray as a byte array using Nd4j.toNpyByteArray(myINDArray)
However when the byte array is received on the server side I get errors. I have seen that when doing toNpyByteArray(myINDArra) the byte array starts with

\x93NUMPY1\x93NUMPY\x01F'descr': '&lt;?4', 'fortran_order': False, 'shape': (5,), } rest of data

This is what the server sends (using numpy.save()) and this can be parsed by DL4J
\x93NUMPY\x01\x00v\x00{'descr': '&lt;f4', 'fortran_order': False, 'shape': (5,), } rest of data

I am using DL4J 1.0.0-beta3 in Android

Am I missing something?

Thanks
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AlexDBlack' date='2019-04-08T04:08:58Z'>
		We need source code.
		</comment>
		<comment id='2' author='AlexDBlack' date='2019-04-08T06:04:00Z'>
		This is the code on the Android side
&lt;denchmark-code&gt;    public byte[] add(@NotNull byte[] tensor1, @NotNull byte[] tensor2) {
        INDArray array1 = Nd4j.createNpyFromByteArray(tensor1);
        INDArray array2 = Nd4j.createNpyFromByteArray(tensor2);
        INDArray result = array1.add(array2);

        try {
            return Nd4j.toNpyByteArray(result);
        } catch (IOException e) {
            e.printStackTrace();
            return null;
        }
    }
&lt;/denchmark-code&gt;

On the server side, this is what is used
&lt;denchmark-code&gt;def numpy_tensor_deserializer(tensor_bin) -&gt; torch.Tensor:
    """"Strategy to deserialize a binary input in npy format into a Torch tensor"""
    input_file = TemporaryFile()
    input_file.write(tensor_bin)
    # read data from file
    input_file.seek(0)
    return torch.from_numpy(numpy.load(input_file))
&lt;/denchmark-code&gt;

numpy.load(input_file) fails as pickle cannot load the input
Numpy version is 1.16.2
I will try the snapshot with npz and let you know if I find something else
Thanks
		</comment>
		<comment id='3' author='AlexDBlack' date='2019-04-08T06:05:35Z'>
		Note that the byte[] obtained after doing add in Android already starts with the bytes Python cannot parse
		</comment>
		<comment id='4' author='AlexDBlack' date='2019-04-08T11:16:39Z'>
		It looks as if numpyHeaderForNd4j is also adding the magic header for numpy. I've got some progress (still not working though) by removing the magic header in convertToNumpy
I'll keep you posted if I progress more
		</comment>
		<comment id='5' author='AlexDBlack' date='2019-04-10T10:59:46Z'>
		I ran into this issue too. Here is some extra info:
&lt;denchmark-code&gt;INDArray mat = Nd4j.zeros(3, 3);
  byte[] buf = Nd4j.toNpyByteArray(mat);
  System.out.printf("First 6 bytes are %c %c %c %c %c %c\n", buf[0], buf[1], buf[2], buf[3], buf[4], buf[5]);
  // First 6 bytes are \ x 9 3 N U
  // But should be 0x93 N U M P Y
&lt;/denchmark-code&gt;

Hex dump of files produced by Nd4j:
&lt;denchmark-code&gt;$ hexyl signalmatrix.npy  | head -n 10
┌────────┬─────────────────────────┬─────────────────────────┬────────┬────────┐
│00000000│ 5c 78 39 33 4e 55 4d 50 ┊ 59 31 93 4e 55 4d 50 59 │\x93NUMP┊Y1×NUMPY│
│00000010│ 01 46 27 64 65 73 63 72 ┊ 27 3a 20 27 3c 3f 34 27 │•F'descr┊': '&lt;?4'│
│00000020│ 2c 20 27 66 6f 72 74 72 ┊ 61 6e 5f 6f 72 64 65 72 │, 'fortr┊an_order│
│00000030│ 27 3a 20 46 61 6c 73 65 ┊ 2c 20 27 73 68 61 70 65 │': False┊, 'shape│
&lt;/denchmark-code&gt;

Hex dump of a different file (3x3 identity matrix) saved in Numpy (not from Java):
&lt;denchmark-code&gt;$ hexyl m.npy 
┌────────┬─────────────────────────┬─────────────────────────┬────────┬────────┐
│00000000│ 93 4e 55 4d 50 59 01 00 ┊ 76 00 7b 27 64 65 73 63 │×NUMPY•0┊v0{'desc│
│00000010│ 72 27 3a 20 27 3c 69 38 ┊ 27 2c 20 27 66 6f 72 74 │r': '&lt;i8┊', 'fort│
│00000020│ 72 61 6e 5f 6f 72 64 65 ┊ 72 27 3a 20 46 61 6c 73 │ran_orde┊r': Fals│
│00000030│ 65 2c 20 27 73 68 61 70 ┊ 65 27 3a 20 28 33 2c 29 │e, 'shap┊e': (3,)│
│00000040│ 2c 20 7d 20 20 20 20 20 ┊ 20 20 20 20 20 20 20 20 │, }     ┊        │
&lt;/denchmark-code&gt;

Looks like the header is added twice in Nd4j.
		</comment>
		<comment id='6' author='AlexDBlack' date='2019-04-10T11:25:16Z'>
		Yes, that is what I saw. Also it seems that is affecting the padding of blanks.
		</comment>
		<comment id='7' author='AlexDBlack' date='2019-04-10T12:20:05Z'>
		OK, some progress, but not a solution yet: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/pull/7518/files&gt;https://github.com/deeplearning4j/deeplearning4j/pull/7518/files&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/deeplearning4j/dl4j-test-resources/pull/190&gt;deeplearning4j/dl4j-test-resources#190&lt;/denchmark-link&gt;

Header was definitely incorrectly added in BaseNativeNDArrayFactory.java (see removed magicPointer in PR).
However, that still leaves us with a difference between numpy-generated and ND4J-generated arrays:
&lt;denchmark-link:https://user-images.githubusercontent.com/2360237/55877923-a0ca7180-5bde-11e9-8174-0f6798b3ac4b.png&gt;&lt;/denchmark-link&gt;

First is ND4J generated, second is Numpy generated.
Header and content is ultimately coming from here: &lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/e5125b56d9803f2c970bf3f85f21d3ec20293ccf/libnd4j/include/cnpy/cnpy.cpp#L582-L603&gt;https://github.com/deeplearning4j/deeplearning4j/blob/e5125b56d9803f2c970bf3f85f21d3ec20293ccf/libnd4j/include/cnpy/cnpy.cpp#L582-L603&lt;/denchmark-link&gt;

And, the wrong type ("&lt;?4" instead of "&lt;f4") from here:
&lt;denchmark-link:https://github.com/deeplearning4j/deeplearning4j/blob/e5125b56d9803f2c970bf3f85f21d3ec20293ccf/libnd4j/include/cnpy/cnpy.cpp#L65&gt;https://github.com/deeplearning4j/deeplearning4j/blob/e5125b56d9803f2c970bf3f85f21d3ec20293ccf/libnd4j/include/cnpy/cnpy.cpp#L65&lt;/denchmark-link&gt;

cnpy.cpp is a 3rd party library. Might be old, outdated, or simply wrong?
&lt;denchmark-link:https://github.com/rogersce/cnpy&gt;https://github.com/rogersce/cnpy&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='AlexDBlack' date='2019-04-25T14:21:22Z'>
		Fixed. Thanks for highlighting this problem.
		</comment>
		<comment id='9' author='AlexDBlack' date='2019-05-25T15:02:18Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>