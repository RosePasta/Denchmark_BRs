<bug id='49' author='xplip' open_date='2020-08-22T10:41:16Z' closed_time='2020-08-25T14:17:11Z'>
	<summary>Run_squad script does not parse adapter args correctly and does not save adapters</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Information&lt;/denchmark-h&gt;

Model I am using (Bert, XLNet ...):
mBERT
Language I am using the model on (English, Chinese ...):
Arabic, but the issue is language/dataset independent
Adapter setup I am using (if any):
Arabic lang adapter from adapterhub, new squad task adapter
The problem arises when using:

 the official example scripts: (give details below)
 my own modified scripts: (give details below)

The tasks I am working on is:

 an official GLUE/SQUaD task:
 my own task or dataset: (give details below)
Arabic Reading Comprehension Dataset (ARCD) but should be the same for any dataset

&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
&lt;denchmark-h:h4&gt;Issue of args not being parsed correctly:&lt;/denchmark-h&gt;


Try to define language adapter by providing --load_lang_adapter [adapter name]
Script fails as argument parser expects it to be --load_language_adapter
Try to define language adapter by providing --load_language_adapter instead
Script fails as setup_task_adapter_training function of adapter_training.py expects it to be --load_lang_adapter

&lt;denchmark-h:h4&gt;Issue of adapters not being saved:&lt;/denchmark-h&gt;


Run script to finetune adapters
Script stores full model for each checkpoint and at the end of training

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

I should be able to define the language adapter with the --load_lang_adapter flag and its config with the --lang_adapter_config flag. When using adapters to finetune my model, I would usually like to store the adapters, not the full model.
&lt;denchmark-h:h2&gt;Environment info&lt;/denchmark-h&gt;


transformers version: 2.11.0
Platform: macOS-10.15.6-x86_64-i386-64bit
Python version: 3.8.5
PyTorch version (GPU?): 1.5.1 (False)
Tensorflow version (GPU?): 2.3.0 (False)
Using GPU in script?: False
Using distributed or parallel set-up in script?: False

	</description>
	<comments>
	</comments>
</bug>