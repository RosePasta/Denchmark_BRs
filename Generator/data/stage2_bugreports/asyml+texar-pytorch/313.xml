<bug id='313' author='tanyuqian' open_date='2020-07-06T03:03:45Z' closed_time='2020-07-21T20:04:11Z'>
	<summary>A bug in GPT2Tokenizer.</summary>
	<description>
GPT2Tokenizer fails to recover a sentence "BART is a seq2seq model." with encoded ids of it. The output sentence is "BART is a seqseq model.". It should be related to numbers' processing.
A script to show the bug is here: &lt;denchmark-link:https://github.com/tanyuqian/texar-pytorch/blob/master/examples/bart/gpt2_tokenizer_bug.py&gt;https://github.com/tanyuqian/texar-pytorch/blob/master/examples/bart/gpt2_tokenizer_bug.py&lt;/denchmark-link&gt;

	</description>
	<comments>
	</comments>
</bug>