<bug id='388' author='wwhgh' open_date='2017-11-21T01:50:48Z' closed_time='2017-12-05T17:49:30Z'>
	<summary>Not all arguments have the same value, in translate</summary>
	<description>
Hi, I used the master code and completed the training process. But when I translate test data, there is a error in "aeq". How to solve it ? Thanks.
&lt;denchmark-code&gt;Loading model parameters.
Traceback (most recent call last):
  File "translate.py", line 136, in &lt;module&gt;
    main()
  File "translate.py", line 77, in main
    = translator.translate(batch, data)
  File "*/onmt/Translator.py", line 200, in translate
    pred, predScore, attn, goldScore = self.translateBatch(batch, data)
  File "*/onmt/Translator.py", line 149, in translateBatch
    self.model.decoder(inp, context, decStates)
  File "*/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "*/onmt/Models.py", line 175, in forward
    self._run_forward_pass(input, context, state)
  File "*/onmt/Models.py", line 327, in _run_forward_pass
    emb = self.embeddings(input)
  File "/home/Wang_Weihua/anaconda2/envs/python36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "*/onmt/modules/Embeddings.py", line 137, in forward
    **aeq(nfeat, len(self.emb_luts))**
  File "*/onmt/Utils.py", line 8, in aeq
    "Not all arguments have the same value: " + str(args)
AssertionError: Not all arguments have the same value: (1, 2)
&lt;/denchmark-code&gt;

The model is :
NMTModel (
(encoder): RNNEncoder (
(embeddings): Embeddings (
(make_embedding): Sequential (
(emb_luts): Elementwise (
(0): Embedding(32, 128, padding_idx=1)
(1): Embedding(5271, 403, padding_idx=1))
)
)
(rnn): LSTM(531, 128, dropout=0.3, bidirectional=True)
)
(decoder): InputFeedRNNDecoder (
(embeddings): Embeddings (
(make_embedding): Sequential (
(emb_luts): Elementwise (
(0): Embedding(35, 128, padding_idx=1)
(1): Embedding(5400, 409, padding_idx=1)
)
)
)
(dropout): Dropout (p = 0.3)
(rnn): StackedLSTM (
(dropout): Dropout (p = 0.3)
(layers): ModuleList (
(0): LSTMCell(793, 256)
)
)
(attn): GlobalAttention (
(linear_context): BottleLinear (256 -&gt; 256)
(linear_query): Linear (256 -&gt; 256)
(v): BottleLinear (256 -&gt; 1)
(linear_out): Linear (512 -&gt; 256)
(sm): Softmax ()
(tanh): Tanh ()
)
)
(generator): Sequential (
(0): Linear (256 -&gt; 35)
(1): LogSoftmax ()
)
)
	</description>
	<comments>
		<comment id='1' author='wwhgh' date='2017-12-05T17:43:10Z'>
		Can you post your translate.py options?
		</comment>
		<comment id='2' author='wwhgh' date='2017-12-05T17:49:30Z'>
		I think the issue is that you trained with a model that have 1 feature, but your test data does not have that feature.
If that was not the problem, please reopen.
		</comment>
		<comment id='3' author='wwhgh' date='2017-12-06T04:16:46Z'>
		Thank you ! &lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;

Actually, my test datas also have the 1 feature.
I output the size in function translateBatch at line 90, in file Translator.py :
The size of src after make_features is [11,1,2],
The size of encStates is ([2,1,128],[2,1,128]),
The size of context is [11,1,256]
My translate.py option is:
python translate.py -model bestmodel.pt -src data/src-test.txt -output pred.txt -replace_unk -verbose
Thank you !
		</comment>
	</comments>
</bug>