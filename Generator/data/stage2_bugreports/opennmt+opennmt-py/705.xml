<bug id='705' author='xiadingZ' open_date='2018-04-25T01:07:36Z' closed_time='2018-06-24T02:37:27Z'>
	<summary>Migrate to pytorch 0.4</summary>
	<description>
pytorch 0.4 has released, please migrate to 0.4
	</description>
	<comments>
		<comment id='1' author='xiadingZ' date='2018-04-25T01:29:22Z'>
		Yup, Hi-pri.

 - Need to fix detach issue
 - Need to fix softmax
 - Need to remove all the Variable calls
 - Try out the new multi-gpu
 - get rid of the cuda calls
 - Try out checkpoint

		</comment>
		<comment id='2' author='xiadingZ' date='2018-04-27T04:33:20Z'>
		Until then, I think it's a good idea to say that we still use pytorch 0.3.1 in the README?
BTW, Can I start working on this?
		</comment>
		<comment id='3' author='xiadingZ' date='2018-05-03T17:17:00Z'>
		Is there an approximate ETA on this? I updated to PyTorch 0.4 for a different project and now OpenNMT is breaking for me :(. I can create another virtualenv for older pytorch version if this porting is going to a while.
		</comment>
		<comment id='4' author='xiadingZ' date='2018-05-03T17:18:32Z'>
		I made a working version, but have not fully tested it yet, in &lt;denchmark-link:https://github.com/da03/OpenNMT-py/tree/pytorch0.4&gt;https://github.com/da03/OpenNMT-py/tree/pytorch0.4&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='xiadingZ' date='2018-05-03T17:26:22Z'>
		Awesome thanks. Let me give it a try.
		</comment>
		<comment id='6' author='xiadingZ' date='2018-05-07T22:22:50Z'>
		This is a duplicate of 403
&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/403&gt;#403&lt;/denchmark-link&gt;

there are instructions there on patching the distro to run on pytorch 0.4
I have run this with Cuda 9.1 cudnn 7.1.2
		</comment>
		<comment id='7' author='xiadingZ' date='2018-05-08T04:11:14Z'>
		&lt;denchmark-link:https://github.com/David-Levinthal&gt;@David-Levinthal&lt;/denchmark-link&gt;
 I think &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/403&gt;#403&lt;/denchmark-link&gt;
 is just a workaround to make the current distro work with pytorch 0.4. It only has the minimal changes. This however, is a more complete solution which involves many more &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/705#issuecomment-384132016&gt;changes&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='xiadingZ' date='2018-05-08T08:52:31Z'>
		The &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/403&gt;#403&lt;/denchmark-link&gt;
 works fine for the first test in test/rebuild_models.sh but the second fails
Traceback (most recent call last):
File "train.py", line 493, in 
main()
File "train.py", line 485, in main
train_model(model, fields, optim, data_type, model_opt)
File "train.py", line 257, in train_model
train_stats = trainer.train(train_iter, epoch, report_func)
File "/home/moses/pytorchwork/OpenNMT-py/onmt/Trainer.py", line 185, in train
report_stats)
File "train.py", line 103, in report_func
report_stats.output(epoch, batch + 1, num_batches, start_time)
File "/home/moses/pytorchwork/OpenNMT-py/onmt/Trainer.py", line 72, in output
self.n_src_words / (t + 1e-5),
RuntimeError: invalid argument 3: divide by zero at /pytorch/aten/src/THC/generic/THCTensorMathPairwise.cu:88
		</comment>
		<comment id='9' author='xiadingZ' date='2018-05-08T15:08:28Z'>
		Nikhilweee, excuse my confusion but the link "changes" in your comment points to this report. Are you saying I should install &lt;denchmark-link:https://github.com/da03/OpenNMT-py/tree/pytorch0.4&gt;https://github.com/da03/OpenNMT-py/tree/pytorch0.4&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='10' author='xiadingZ' date='2018-05-08T18:13:57Z'>
		&lt;denchmark-link:https://github.com/David-Levinthal&gt;@David-Levinthal&lt;/denchmark-link&gt;
 By changes I meant srush's checklist &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/705#issuecomment-384132016&gt;#705 (comment)&lt;/denchmark-link&gt;
, which happens to be the second comment on this issue. About installing &lt;denchmark-link:https://github.com/da03&gt;@da03&lt;/denchmark-link&gt;
's fork, I think he is a better person to comment.
		</comment>
		<comment id='11' author='xiadingZ' date='2018-05-08T18:26:39Z'>
		&lt;denchmark-link:https://github.com/vince62s&gt;@vince62s&lt;/denchmark-link&gt;
 maybe try to cast that to a python number first? Something like 
		</comment>
		<comment id='12' author='xiadingZ' date='2018-05-08T18:28:39Z'>
		AHHH...a bit of background
I am trying to evaluate/establish a multi framework HW evaluation benchmark
suite that can be used by HW vendors/startups and cloud providers (for
purchase decisions)
&lt;denchmark-link:https://github.com/David-Levinthal/machine-learning/&gt;https://github.com/David-Levinthal/machine-learning/&lt;/denchmark-link&gt;

see the csv file
so I am a bit desperate on getting something working at ~ top of tree as HW
startups do not have the resources to support anything else
The workaround in 403 ran and produced "nice" output and appeared to
converge but seems to fail to translate.

any prognosis on when a Pytorch 0.4 version might become available..or a
version people would like me to test?
one added comment
I am trying to use the same data sets for TF/NMT, MxNet/Sockeye and
Pytorch/OpenNMT
but using the preprocess .py step for the files given to OpenNMT after
following the preparation outlined by TF/NMT (they were the first ones with
an available source base)
that appears to work for sockeye

so the first two sentences in the src-val file
Die Premierminister Indi@@ ens und Japans tra@@ fen sich in Tok@@ io .
Indi@@ ens neuer Premierminister Nar@@ end@@ ra Mo@@ di trifft bei seinem
ersten wichtigen Auslands@@ besu@@ ch seit seinem Wahl@@ sie@@ g im Mai
seinen japanischen Amts@@ kol@@ legen Shin@@ zo A@@ be in Tok@@ o , um
wirtschaftliche und sicherheits@@ politische Beziehungen zu bes@@ prechen .

which look like the following in the tgt-val file
India and Japan prime ministers meet in Tokyo
India &amp;apos;s new prime minister , Nar@@ end@@ ra Mo@@ di , is meeting his
Japanese counter@@ part , Shin@@ zo A@@ be , in Tokyo to discuss economic
and security ties , on his first major foreign visit since winning May
&amp;apos;s election .

is this formatting usable?

d
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, May 8, 2018 at 11:14 AM, Nikhil Verma ***@***.***&gt; wrote:
 @David-Levinthal &lt;https://github.com/David-Levinthal&gt; By changes I meant
 srush's checklist #705 (comment)
 &lt;#705 (comment)&gt;,
 which happens to be the second comment on this issue.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuTzEiXLfU1pyzZxkLqo6meJPoP64-ks5tweBqgaJpZM4Tio05&gt;
 .



		</comment>
		<comment id='13' author='xiadingZ' date='2018-05-16T18:23:49Z'>
		&lt;denchmark-link:https://github.com/Ubiqus/OpenNMT-py&gt;https://github.com/Ubiqus/OpenNMT-py&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/pltrdy&gt;@pltrdy&lt;/denchmark-link&gt;
 and I fixed many things to make it pytorch 0.4 compatible + huge refactoring.
RNN: LSTM GRU SRU work fine
CNN: works fine
Transformer: works fine
We have not tested Image and Audio datasets, if someone could do it, would be great.
TODO
Fix some doc things following the refactoring
implement the multi-gpu
double check Variable() removals
		</comment>
		<comment id='14' author='xiadingZ' date='2018-05-16T23:33:49Z'>
		fantastic! is this in the main tree?
did you try translation inference, see issue 725?
d
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, May 16, 2018 at 11:23 AM, Vincent Nguyen ***@***.***&gt; wrote:
 https://github.com/Ubiqus/OpenNMT-py
@pltrdy &lt;https://github.com/pltrdy&gt; and I fixed many things to make it
 pytorch 0.4 compatible + huge refactoring.
 RNN: LSTM GRU SRU work fine
 CNN: works fine
 Transformer: works fine

 We have not tested Image and Audio datasets, if someone could do it, would
 be great.

 TODO
 Fix some doc things following the refactoring
 implement the multi-gpu
 double check Variable() removals

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuT9_CFIc4j1k1uVunHlIwfkodCe2vks5tzG66gaJpZM4Tio05&gt;
 .



		</comment>
		<comment id='15' author='xiadingZ' date='2018-05-17T06:59:41Z'>
		not sure by what you mean by "main tree". it on &lt;denchmark-link:https://github.com/Ubiqus/OpenNMT-py&gt;https://github.com/Ubiqus/OpenNMT-py&lt;/denchmark-link&gt;
 master.
Translation ran fine for us but give it a try.
		</comment>
		<comment id='16' author='xiadingZ' date='2018-05-17T14:47:43Z'>
		I meant
&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py&gt;https://github.com/OpenNMT/OpenNMT-py&lt;/denchmark-link&gt;

will the Ubiqus fork be merged with the one I am listing?
d
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, May 16, 2018 at 11:59 PM, Vincent Nguyen ***@***.***&gt; wrote:
 not sure by what you mean by "main tree". it on https://github.com/Ubiqus/
 OpenNMT-py master.
 Translation ran fine for us but give it a try.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuT63HJkzc5m-RRWtqz140ZI8TyT-zks5tzR_jgaJpZM4Tio05&gt;
 .



		</comment>
		<comment id='17' author='xiadingZ' date='2018-06-05T23:13:09Z'>
		I was trying to use &lt;denchmark-link:https://github.com/Ubiqus/OpenNMT-py&gt;https://github.com/Ubiqus/OpenNMT-py&lt;/denchmark-link&gt;
 but it seems like it has diverged a fair bit from the baseline repo. In particular, no more epochs but training_steps instead. Is that something the base repo is also moving towards?
		</comment>
		<comment id='18' author='xiadingZ' date='2018-06-06T04:56:50Z'>
		Most toolkits use steps now (onmt-tf, marian, t2t, ...) it's more meaningful especially when it comes to big corpus.
		</comment>
		<comment id='19' author='xiadingZ' date='2018-06-06T21:55:04Z'>
		How far along is this update? I tried both the master version and da03's version and still get an error about using detach_() instead of detach(). When I change it in the code I get to the following error:
Traceback (most recent call last):
File "train.py", line 418, in 
main()
File "train.py", line 410, in main
train_model(model, fields, optim, data_type, model_opt)
File "train.py", line 231, in train_model
train_stats = trainer.train(train_iter, epoch, report_func)
File "/data/esther/Projects/lts_experiments/scripts/OpenNMT-pytorch0.4/onmt/Trainer.py", line 180, in train
report_stats)
File "train.py", line 95, in report_func
report_stats.output(epoch, batch + 1, num_batches, start_time)
File "/data/esther/Projects/lts_experiments/scripts/OpenNMT-pytorch0.4/onmt/Trainer.py", line 67, in output
self.ppl(),
File "/data/esther/Projects/lts_experiments/scripts/OpenNMT-pytorch0.4/onmt/Trainer.py", line 48, in ppl
return math.exp(min(self.loss / self.n_words, 100))
RuntimeError: Expected object of type torch.cuda.FloatTensor but found type torch.cuda.LongTensor for argument &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/2&gt;#2&lt;/denchmark-link&gt;
 'other'
		</comment>
		<comment id='20' author='xiadingZ' date='2018-06-07T15:08:20Z'>
		I have the same problem that &lt;denchmark-link:https://github.com/dreamk73&gt;@dreamk73&lt;/denchmark-link&gt;
 posted. Waiting for the update!
		</comment>
		<comment id='21' author='xiadingZ' date='2018-06-07T18:23:29Z'>
		guys, if you want a working repo use our fork for the time being. sorry for the delay.
		</comment>
		<comment id='22' author='xiadingZ' date='2018-06-07T22:30:02Z'>
		I downloaded the Ubiqus fork and have verified that I can run the code now using pytorch 0.4.
		</comment>
		<comment id='23' author='xiadingZ' date='2018-06-24T02:37:27Z'>
		The main branch now supports 0.4, we are working to get most of the other Ubiqus changes in as well.
		</comment>
		<comment id='24' author='xiadingZ' date='2018-06-24T15:25:51Z'>
		Thank you
Working actively to incorporate OpenNMT into MLPerf
d
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sat, Jun 23, 2018 at 7:37 PM, srush ***@***.***&gt; wrote:
 The main branch now supports 0.4, we are working to get most of the other
 Ubiqus changes in as well.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuT0deR1BtI-7YqgZh2JBEkRd3TUNaks5t_vtqgaJpZM4Tio05&gt;
 .



		</comment>
		<comment id='25' author='xiadingZ' date='2018-06-24T15:30:22Z'>
		Very neat, sorry I have been out of touch. Trying to put some time in the next couple weeks to get all the updates checked and in. In particular the main aim is multi-gpu.
		</comment>
		<comment id='26' author='xiadingZ' date='2018-06-24T15:49:07Z'>
		can 771 get looked at?

this blocks the use of openmt for the pytorch entry for the transformer
translation test.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sun, Jun 24, 2018 at 8:30 AM, srush ***@***.***&gt; wrote:
 Very neat, sorry I have been out of touch. Trying to put some time in the
 next couple weeks to get all the updates checked and in. In particular the
 main aim is multi-gpu.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuT2vxR2sXn-gMS-pr8wKVoqOZb_UWks5t_7CRgaJpZM4Tio05&gt;
 .



		</comment>
		<comment id='27' author='xiadingZ' date='2018-06-25T21:39:51Z'>
		Yes, will prioritize.
&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/771&gt;#771&lt;/denchmark-link&gt;

		</comment>
		<comment id='28' author='xiadingZ' date='2018-06-25T21:47:25Z'>
		Thank you
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Jun 25, 2018 at 2:39 PM, srush ***@***.***&gt; wrote:
 Yes, will prioritize.

 #771 &lt;#771&gt;

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#705 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AIUuT6whSQHY-zK_RIfcLUqW8sgFRyOuks5uAVisgaJpZM4Tio05&gt;
 .



		</comment>
	</comments>
</bug>