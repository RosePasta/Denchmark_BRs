<bug id='338' author='antspy' open_date='2017-10-13T08:40:12Z' closed_time='2018-08-02T19:58:31Z'>
	<summary>Translate does unk replacement from the wrong dictionary</summary>
	<description>
Hello,
In the translator, with the option replace_unk set to true, unk token in the translation are replaced with the token in the source corresponding to the highest attention. The problem is that in a lot of cases also the source token will be unk (for example a person's name will probably be unk both in the source and the target language vocabulary).
Is this the intended behavior? My understanding was that we should put the actual word from the source sentence instead.
I was looking into it to try to fix it, but the problem is that all source sentences are given as onmt.IO.ONMTDataset objects, which do not retain the information about the words they replaced with unk during preprocessing, so it's not clear how to access the required words at translation time. What do you think?
	</description>
	<comments>
		<comment id='1' author='antspy' date='2017-10-13T10:35:07Z'>
		Did you preprocess your data with the -dynamic_dict -share_vocab options?
		</comment>
		<comment id='2' author='antspy' date='2017-10-13T10:37:14Z'>
		Hi!
No I didn't.. since by default that is off I did not think of changing it.
		</comment>
		<comment id='3' author='antspy' date='2017-10-13T10:46:51Z'>
		Yeh there's not great documentation on the new features yet. Also just to be sure, you're using -copy_attn during training
		</comment>
		<comment id='4' author='antspy' date='2017-10-13T11:12:55Z'>
		Alright, thank you!
So I should always run with dynamic_dict share_vocab and copy_attn set to True, correct?
		</comment>
		<comment id='5' author='antspy' date='2017-10-13T11:19:47Z'>
		Run the preprocess.py script with  and . Then with train.py use  and possibly  depending on what your input data looks like. &lt;denchmark-link:https://github.com/sebastianGehrmann&gt;@sebastianGehrmann&lt;/denchmark-link&gt;
 might have a better idea if there's anything else you need to change from the defaults to get  working correctly.
&lt;denchmark-link:https://github.com/Henry-E/opennmt-gen/blob/master/train_gen.sh&gt;This model&lt;/denchmark-link&gt;
 is using features and is probably pretty different from what you're doing but it shows how to use the copy options.
		</comment>
		<comment id='6' author='antspy' date='2017-10-13T13:39:59Z'>
		Theoretically you should not need to train with -copy_attn for -replace_unk. I think this could actually a bug since we want the actual source word and not the self.fields["src"].vocab.itos version that could also be UNK. Let me look into this
		</comment>
		<comment id='7' author='antspy' date='2017-10-13T19:55:59Z'>
		Yeah, this is actually incorrect advice. -replace_unk is a different mode than -copy_attn.
&lt;denchmark-link:https://github.com/sebastianGehrmann&gt;@sebastianGehrmann&lt;/denchmark-link&gt;
 notes correctly that we should fix this.
The --copy_attn is a different approach that you could try instead if you have lots of copied words.
		</comment>
		<comment id='8' author='antspy' date='2017-10-13T22:05:20Z'>
		Ah ok. I was making the perhaps mistaken assumption that the replace unk option was linked to Abigail See summarisation paper which can handle UNKs in the source sequence by using the pointer network / copy attention.
		</comment>
		<comment id='9' author='antspy' date='2017-10-14T09:21:43Z'>
		Thank you for your answers :) At the moment I implemented a dirty hack to do actual word replacement.
In general, do you suggest preprocessing the files with dynamic dict and share_vocab? I am not sure what these options do, but if they improve the results I will use them :)
		</comment>
		<comment id='10' author='antspy' date='2017-10-25T05:20:56Z'>
		I thought the option dynamic_dict is necessary for copy_attn? Since copy mechanism needs to figure out the alignment in the input sequence, and dynamic_dict takes care of that. (I think)
		</comment>
		<comment id='11' author='antspy' date='2017-11-05T17:46:48Z'>
		Sorry, I lost this thread. Is there still a bug here?
		</comment>
		<comment id='12' author='antspy' date='2017-11-12T06:15:38Z'>
		Yes, this bug still exists.
		</comment>
		<comment id='13' author='antspy' date='2017-12-08T18:27:53Z'>
		Hi all, is there progress in this thread?  I face the same issue too, tried adding in -dynamic_dict and -share_vocab, and -copy_attn, but NMT still does not translate the name entities right, hope to find solution soon. Let me know when there is progress! Thanks!
		</comment>
		<comment id='14' author='antspy' date='2017-12-14T23:42:52Z'>
		Hi all, I am also facing the same issue here. Please, let me know if you have a solution for that. Thanks a lot! Meanwhile, &lt;denchmark-link:https://github.com/antspy&gt;@antspy&lt;/denchmark-link&gt;
 could you share your "dirty hack"? :)
		</comment>
		<comment id='15' author='antspy' date='2017-12-15T10:15:18Z'>
		&lt;denchmark-link:https://github.com/carolscarton&gt;@carolscarton&lt;/denchmark-link&gt;
 Hi, it's pretty ugly really. I pass to the translate function also the original string; then I access the attention values returned from the translator, compute the maxIndex, and replace it with the word at the index in the original string. Something like
&lt;denchmark-code&gt;            for pred_sents, gold_sent, pred_score, gold_score, src_sent in z_batch:
                n_best_preds = [pred for pred in pred_sents[:translate_options.n_best]]
                if replace_unk_hack and is_source_file:
                    original_line = next(lines_iterator).split(' ')
                    for pred in n_best_preds:
                        for idx_tok, tok in enumerate(pred):
                            if tok == '&lt;unk&gt;':
                                _, maxIndex = attn[0][0][idx_tok].max(0)
                                pred[idx_tok] = original_line[maxIndex[0]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='16' author='antspy' date='2017-12-15T13:10:43Z'>
		&lt;denchmark-link:https://github.com/antspy&gt;@antspy&lt;/denchmark-link&gt;
 Thanks for sharing it :) sorry, I am not familiar with the code and I may ask some rather simplistic/stupid questions:

where does line_iterator como from? I think it is some kind of data structure with the source sentences on it?
replace_unk_hack and is_source_file are boolean variables right? Why do you need an is_source_file?

Many thanks for your help!!
		</comment>
		<comment id='17' author='antspy' date='2017-12-15T14:44:45Z'>
		&lt;denchmark-link:https://github.com/carolscarton&gt;@carolscarton&lt;/denchmark-link&gt;
 So, I modified the standard translate function; I pass to it the original text string, and whether it should use the hack (so yes, replace_unk_hack is a boolean).
I usually deal with files though, so is_source_file is a boolean that indicates whether the string passed is the original sentence to be translated, or a path to a text file that contains the sentences.
If it is a source file, then lines_iterator is an iterator that reads every line of the file
&lt;denchmark-code&gt;    if replace_unk_hack and is_source_file:
        if data_generator.batch_size != 1:
            raise ValueError('For now the replace_unk_hack only works with batch size 1')
        source_file = open(source_file_path, 'r')
        lines_iterator = (line for line in source_file)
&lt;/denchmark-code&gt;

(Note also that I modified this function quite some time ago, so in the meanwhile the translate function may have changed significantly)
		</comment>
		<comment id='18' author='antspy' date='2017-12-15T14:50:04Z'>
		Hi Antonio! Thanks :)
		</comment>
		<comment id='19' author='antspy' date='2017-12-17T14:42:32Z'>
		&lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;
  Hello. Notify you that this is still a bug now, and this should be fixed asap since it will hugely affect the test performance. Thanks.
		</comment>
		<comment id='20' author='antspy' date='2017-12-17T14:44:28Z'>
		Thanks for the heads up. I will look into it today.
		</comment>
		<comment id='21' author='antspy' date='2017-12-21T20:18:05Z'>
		This should be fixed now.
		</comment>
		<comment id='22' author='antspy' date='2018-01-02T11:19:27Z'>
		&lt;denchmark-link:https://github.com/srush&gt;@srush&lt;/denchmark-link&gt;
  Hi, can I understand this feature in this way:

In the preprocessing, you have to use
 -dynamic_dict -share_vocab
if you are doing tasks like paraphrasing or summarization, where there are lots of same words in source and target. Then, you need to -copy_attn anyway.  However, if you are just doing translation task, then you don't have to utilize copy mechanism.
in the translating process, then you can work with replace_unk now. When your input source sentences have unknown words, the prediction target will copy that unknown words.

		</comment>
	</comments>
</bug>