<bug id='503' author='abaheti95' open_date='2018-01-08T18:46:05Z' closed_time='2018-09-05T09:45:43Z'>
	<summary>Warn users not to use special symbols.</summary>
	<description>
Hi all,
I have used the following format in my data
&lt;denchmark-code&gt;BOS = '&lt;s&gt;'
EOS = '&lt;/s&gt;'
UNK = '&lt;unk&gt;'
&lt;/denchmark-code&gt;

All of my data is in the following format
&lt;s&gt; w w w &lt;unk&gt; w &lt;unk&gt; &lt;/s&gt;
where w represents various words. But now when I try to translate the decoder prints  multiple times. For example
&lt;denchmark-code&gt;PRED 15: &lt;s&gt; le &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; &lt;/s&gt; T30
PRED SCORE: -10.3222
&lt;/denchmark-code&gt;

How do I explicitly specify these in the parameters? Or if I cannot specify them how should I organize my data in OpenNMT?



OpenNMT-py/onmt/translate/Beam.py


         Line 18
      in
      af24c9b






 def __init__(self, size, pad, bos, eos, 





	</description>
	<comments>
		<comment id='1' author='abaheti95' date='2018-01-08T23:44:49Z'>
		Eos and bos are automatically added to data, you dont need to add them manually.
		</comment>
		<comment id='2' author='abaheti95' date='2018-01-08T23:46:30Z'>
		See onmt.io.TextDataset.get_fields and torchtext.data.fields.Fields for detail.
		</comment>
		<comment id='3' author='abaheti95' date='2018-01-09T02:57:09Z'>
		So why do some predictions have more than one eos symbol?? Is it because of the replace_unk flag??
		</comment>
		<comment id='4' author='abaheti95' date='2018-01-09T17:28:33Z'>
		In perspective of human eyes, your symbols are identical to default special symbols used in OPENNMT.
However,

torchtext 0.3 adds preprocessing step which decodes all corpus tokens to UNICODE format.
special symbols in OpenNMT are directly passed to field opjects, so they are NOT decoded into UNICODE format.
that means, default symbols are not unicode, your special symbols in corpus are unicode. So the system recognize them as distinct symbols.
for example, dictionary would looks like: {"&lt;unk&gt;": 0,  "&lt;blank&gt;" : 1, "&lt;s&gt;" : 2, "&lt;/s&gt;": 3, ... ... u'&lt;/s&gt;' : k ...}, so actually &lt;/s&gt; in your corpus is u'&lt;/s&gt;', which is not considered as stop symbol.

Just remove them from corpus, and it will be solved.
		</comment>
		<comment id='5' author='abaheti95' date='2018-01-09T17:36:16Z'>
		So what should be the format of my data?
No start and end symbol in the data?
For example
&lt;s&gt; Hi , I am &lt;unk&gt; &lt;/s&gt; to Hi , I am &lt;unk&gt; in the data file?
		</comment>
		<comment id='6' author='abaheti95' date='2018-01-09T17:38:32Z'>
		You don't need to convert them to any format, tokenized plain text would be fine. Words with frequency rank lower than max_vocab_size will be automatically replaced with &lt;unk&gt;, you don't needed to convert them manually.
		</comment>
		<comment id='7' author='abaheti95' date='2018-01-09T19:10:02Z'>
		But what if I have preprocessed data from some other application? When I have  marked in my corpus already. How do I specify those  to OpenNMT?
		</comment>
		<comment id='8' author='abaheti95' date='2018-01-09T19:21:02Z'>
		They are declared in onmt/io/DatasetBase.py.
You can change them to uncode format.
But still, your translation result will contains start symbols.
I suggest do pre-processing again.
		</comment>
		<comment id='9' author='abaheti95' date='2018-01-09T19:27:30Z'>
		The problem with that is that the data I have is collected by a totally different project so all I have is the preprocessed data. So do I have to change the preprocessing code to enforce OpenNMT to recognize the s?
		</comment>
		<comment id='10' author='abaheti95' date='2018-01-09T19:33:34Z'>
		You can remove start and end symbols from your file by additional pre-processing, and modify the default &lt;unk&gt; symbol to unicode format, that would be fine.
I think that's quite simple to do.
		</comment>
		<comment id='11' author='abaheti95' date='2018-01-10T03:32:17Z'>
		Yeah, you should not use , ,  in your code.
We should throw an error when we see them. I will add that to our preprocessing code.
		</comment>
	</comments>
</bug>