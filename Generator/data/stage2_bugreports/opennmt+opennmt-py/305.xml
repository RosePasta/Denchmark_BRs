<bug id='305' author='Henry-E' open_date='2017-09-27T13:06:49Z' closed_time='2017-10-05T18:04:37Z'>
	<summary>bug with arguments for computing loss</summary>
	<description>
&lt;denchmark-code&gt;  File "/home/henrye/downloads/OpenNMT-py/onmt/Loss.py", line 38, in forward
    return self.compute_loss(batch, output, target, **kwargs)
TypeError: compute_loss() got an unexpected keyword argument 'coverage'
&lt;/denchmark-code&gt;

Another strange bug I'm not sure how to handle. If it's using kwargs it shouldn't care about extra keyword arguments? Which makes me think there's possibly some syntax issue. Maybe the other parts of gen_state are being conflated together.



OpenNMT-py/onmt/Loss.py


        Lines 116 to 121
      in
      819448d






 return {"output": output, 



 "target": batch.tgt[range_[0] + 1: range_[1]], 



 "copy_attn": attns.get("copy"), 



 "align": None if not copy_attn 



 else batch.alignment[range_[0] + 1: range_[1]], 



 "coverage": attns.get("coverage")} 





&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipdb/__main__.py", line 198, in main
    pdb._runscript(mainpyfile)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/pdb.py", line 1548, in _runscript
    self.run(statement)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/bdb.py", line 431, in run
    exec(cmd, globals, locals)
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 289, in &lt;module&gt;
    main()
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 285, in main
    train_model(model, train, valid, fields, optim)
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 149, in train_model
    valid_stats = trainer.validate()
  File "/home/henrye/downloads/OpenNMT-py/onmt/Trainer.py", line 161, in validate
    _, batch_stats = self.valid_loss(batch, **gen_state)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/henrye/downloads/OpenNMT-py/onmt/Loss.py", line 38, in forward
    return self.compute_loss(batch, output, target, **kwargs)
TypeError: compute_loss() got an unexpected keyword argument 'coverage'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Henry-E' date='2017-09-27T14:23:20Z'>
		So your code is actually calling this function 


OpenNMT-py/onmt/modules/CopyGenerator.py


         Line 93
      in
      819448d






 def compute_loss(self, batch, output, target, copy_attn, align): 





Could you add a **kwargs there and try again?
		</comment>
		<comment id='2' author='Henry-E' date='2017-09-27T14:37:14Z'>
		It's still running and hasn't reached validation again yet but that looks like the problem for sure
		</comment>
		<comment id='3' author='Henry-E' date='2017-09-27T14:46:46Z'>
		maybe just comment out &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/blob/master/train.py#L144&gt;https://github.com/OpenNMT/OpenNMT-py/blob/master/train.py#L144&lt;/denchmark-link&gt;
 and test.
		</comment>
		<comment id='4' author='Henry-E' date='2017-09-27T15:08:48Z'>
		Hi Henry.

Due to a bug, I didn't test the CopyGeneratorLoss. For your case, adding a
coverage option to CopyGeneratorLoss forward is Ok. But seems we currently
dont use it.

Henry-E &lt;notifications@github.com&gt;于2017年9月27日 周三22:37写道：
 It's still running and hasn't reached validation again yet but that looks
 like the problem for sure

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;&lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/issues/305#issuecomment-332542557&gt;#305 (comment)&lt;/denchmark-link&gt;
&gt;,
 or mute the thread
 &lt;&lt;denchmark-link:https://github.com/notifications/unsubscribe-auth/AAnnUphkLQ96ylR_GQLyO_pZ8iuBFOW6ks5sml2bgaJpZM4PlvD3&gt;https://github.com/notifications/unsubscribe-auth/AAnnUphkLQ96ylR_GQLyO_pZ8iuBFOW6ks5sml2bgaJpZM4PlvD3&lt;/denchmark-link&gt;
&gt;
 .

-- 

Regards,
Jianyu Zhan
		</comment>
		<comment id='5' author='Henry-E' date='2017-09-27T15:14:16Z'>
		Changing to **kwargs fixes it but another bug pops up.
&lt;denchmark-code&gt;  File "/home/henrye/downloads/OpenNMT-py/onmt/modules/CopyGenerator.py", line 104, in compute_loss
    align = align.view(-1)
AttributeError: 'NoneType' object has no attribute 'view'
&lt;/denchmark-code&gt;

This one is caused by not including a copy_attn argument in this function call. So copy_attn is None by default and thus align ends up also as None. Going back up the stack though I haven't been able to figure out where I can get the right info to use in the argument.  


OpenNMT-py/onmt/Trainer.py


        Lines 159 to 160
      in
      819448d






 gen_state = onmt.Loss.make_gen_state( 



 outputs, batch, attns, (0, batch.tgt.size(0))) 








OpenNMT-py/onmt/Loss.py


         Line 107
      in
      819448d






 def make_gen_state(output, batch, attns, range_, copy_attn=None): 





&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipdb/__main__.py", line 198, in main
    pdb._runscript(mainpyfile)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/pdb.py", line 1548, in _runscript
    self.run(statement)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/bdb.py", line 431, in run
    exec(cmd, globals, locals)
  File "&lt;string&gt;", line 1, in &lt;module&gt;
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 1, in &lt;module&gt;
    from __future__ import division
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 284, in main
    train_model(model, train, valid, fields, optim)
  File "/home/henrye/downloads/OpenNMT-py/train.py", line 149, in train_model
    valid_stats = trainer.validate()
  File "/home/henrye/downloads/OpenNMT-py/onmt/Trainer.py", line 161, in validate
    _, batch_stats = self.valid_loss(batch, **gen_state)
  File "/home/henrye/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/henrye/downloads/OpenNMT-py/onmt/Loss.py", line 38, in forward
    return self.compute_loss(batch, output, target, **kwargs)
  File "/home/henrye/downloads/OpenNMT-py/onmt/modules/CopyGenerator.py", line 104, in compute_loss
    align = align.view(-1)
AttributeError: 'NoneType' object has no attribute 'view'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='Henry-E' date='2017-09-27T15:24:01Z'>
		I see.
&lt;denchmark-link:https://github.com/JianyuZhan&gt;@JianyuZhan&lt;/denchmark-link&gt;
 it looks like this line needs an extra argument &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Trainer.py#L159&gt;https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Trainer.py#L159&lt;/denchmark-link&gt;
 . But that trainer doesn't know about copy atten. How should it get that argument?
		</comment>
		<comment id='7' author='Henry-E' date='2017-09-27T15:33:29Z'>
		Okay, here's a fix.
Replace these lines:
&lt;denchmark-code&gt;            gen_state = onmt.Loss.make_gen_state(
                outputs, batch, attns, (0, batch.tgt.size(0)))
            _, batch_stats = self.valid_loss(batch, **gen_state)
&lt;/denchmark-code&gt;

with the line _, batch_stats = self.valid_loss.compute_full_loss(outputs, batch, attns)
and then add that function to  &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Loss.py#L40&gt;https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Loss.py#L40&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;def compute_full_loss(self, outputs, batch, attns):
            gen_state = make_gen_state(
                outputs, batch, attns, (0, batch.tgt.size(0)), self.copy_attn)
            return self.forward(batch, **gen_state)
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/JianyuZhan&gt;@JianyuZhan&lt;/denchmark-link&gt;
 there are a couple things I don't like about the new . Let's talk about this before you go work on attention. For one, function should not be called . Also I don't think the base class should know about copy_attn.
		</comment>
		<comment id='8' author='Henry-E' date='2017-09-27T15:50:20Z'>
		yep that works. Do you want a pull request for that and the **kwargs thing?
		</comment>
		<comment id='9' author='Henry-E' date='2017-09-28T08:28:26Z'>
		
@JianyuZhan it looks like this line needs an extra argument https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Trainer.py#L159 . But that trainer doesn't know about copy atten. How should it get  that argument?

Ok, let me try to clarify things a little bit.
Actually the  doesn't  need to know , in my initial design, the  just needs to know  ,  and , and an  kwargs for subclass that needs more info. But involving in  , specifically, the  dictionary, it is complicated a little: the standalone  needs all possible args for two classes, including (default None), thus in the base class, we need to know about  . I've said in the &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/pull/290&gt;Extened Loss PR&lt;/denchmark-link&gt;
 that we need to hone the interface between  and , now we have another qualification to do this. I will have a try.
		</comment>
		<comment id='10' author='Henry-E' date='2017-09-28T13:30:55Z'>
		Well, it seems not that complex.
I make the make_gen_state() *LossCompute class specific,  so now we don't need to know copy_attn in base class, also it helps get rid of if...else... in  the gen_state dictionary.  Now the interfaces look more natural, tidy and minimal.  I renamed make_gen_state() to make_shard_state(),  and compute_full_loss() to monolithic_compute_loss() for naming consistency.
The ComputeLossBase class:
&lt;denchmark-link:https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/Loss.py#L15&gt;https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/Loss.py#L15&lt;/denchmark-link&gt;

The NMTComputeLoss class:
&lt;denchmark-link:https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/Loss.py#L101&gt;https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/Loss.py#L101&lt;/denchmark-link&gt;

The CopyGeneratorComputeLoss class:
&lt;denchmark-link:https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/modules/CopyGenerator.py#L79&gt;https://github.com/JianyuZhan/OpenNMT-py/blob/loss_compute_rework/onmt/modules/CopyGenerator.py#L79&lt;/denchmark-link&gt;

The patch is here: &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/compare/master...JianyuZhan:loss_compute_rework&gt;master...JianyuZhan:loss_compute_rework&lt;/denchmark-link&gt;
.  I've tested it for the non- case, and assume it should also fix the problem in this issue too.
		</comment>
		<comment id='11' author='Henry-E' date='2017-10-02T15:32:27Z'>
		hey &lt;denchmark-link:https://github.com/JianyuZhan&gt;@JianyuZhan&lt;/denchmark-link&gt;
 do you have a reference anywhere for what you based the copy generator implementation on? Just reading through the code and trying to get a better idea of it. The other implementation I've seen and coded up before was from Abigail See's summarization paper but I can't tell if this works the same or not as that
		</comment>
		<comment id='12' author='Henry-E' date='2017-10-03T13:39:22Z'>
		&lt;denchmark-link:https://github.com/Henry-E&gt;@Henry-E&lt;/denchmark-link&gt;
 ,  I just  refactored this part of code. I think it is based on the Abigail See's "Get to the Point" paper that you talked about.
		</comment>
	</comments>
</bug>