<bug id='531' author='LeenaShekhar' open_date='2018-01-22T22:49:40Z' closed_time='2018-08-02T19:59:01Z'>
	<summary>Pre-trained model throws error during inference.</summary>
	<description>
Hello,
I am using the pre-trained model mentioned in the README file with the current code, but that results in the following error:
python translate.py -model ../demo.rnn__acc_47.64_ppl_20.48_e13.pt -src data/src-test.txt -output pred.txt -replace_unk -verbose
&lt;denchmark-code&gt;Loading model parameters.
Traceback (most recent call last):
  File "translate.py", line 141, in &lt;module&gt;
    main()
  File "translate.py", line 62, in main
    onmt.ModelConstructor.load_test_model(opt, dummy_opt.__dict__)
  File "/home/leena/Downloads/NMT/OpenNMT-py-master/onmt/ModelConstructor.py", line 124, in load_test_model
    use_gpu(opt), checkpoint)
  File "/home/leena/Downloads/NMT/OpenNMT-py-master/onmt/ModelConstructor.py", line 199, in make_base_model
    model.load_state_dict(checkpoint['model'])
  File "/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.py", line 490, in load_state_dict
    .format(name))
&lt;/denchmark-code&gt;

Could you please provide the latest model? If not, then point me to the correct version?
	</description>
	<comments>
		<comment id='1' author='LeenaShekhar' date='2018-01-23T04:38:27Z'>
		After some debugging I figured that the key names in the loaded  checkpoint and the NMT model constructed in the code were different, but the value types were all the same.
added these 2 lines in ModelConstructor.py just before model.load_state_dict(checkpoint['model']):

checkpoint['model']['decoder.embeddings.make_embedding.emb_luts.0.weight'] = checkpoint['model'].pop('decoder.embeddings.emb_luts.0.weight')
checkpoint['model']['encoder.embeddings.make_embedding.emb_luts.0.weight'] = checkpoint['model'].pop('encoder.embeddings.emb_luts.0.weight')

		</comment>
		<comment id='2' author='LeenaShekhar' date='2018-01-24T18:44:23Z'>
		Thanks. We'll retrain and update.
		</comment>
	</comments>
</bug>