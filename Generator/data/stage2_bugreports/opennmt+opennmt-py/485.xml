<bug id='485' author='howardyclo' open_date='2017-12-27T11:11:26Z' closed_time='2018-09-03T15:12:41Z'>
	<summary>Ensure that different encoder + decoder combinations work together.</summary>
	<description>
I got the error when using CNN encoder + RNN decoder.
I'm wondering that whether this is a bug or not.
&lt;denchmark-code&gt;python $OPENNMT_HOME/train.py \
  -data $OPENNMT_HOME/data/efcamdat2_char.changed \
  -save_model $OPENNMT_HOME/gec-experiment/checkpoints/cnn_charnmt0 \
  -gpuid 1 \
  -seed 1 \
  -batch_size 128 \
  -max_generator_batches 64 \
  -epochs 16 \
  -optim 'adam' \
  -learning_rate 0.001 \
  -word_vec_size 300 \
  -max_grad_norm 2 \
  -encoder_type 'cnn' \
  -decoder_type 'rnn' \
  -enc_layers 2 \
  -dec_layers 2 \
  -rnn_size 1024 \
  -rnn_type 'LSTM' \
  -cnn_kernel_width 6 \
  -input_feed 1 \
  -global_attention 'general' \
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Building model...
Intializing model parameters.
NMTModel(
  (encoder): CNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(96, 300, padding_idx=1)
        )
      )
    )
    (linear): Linear(in_features=300, out_features=1024)
    (cnn): StackedCNN(
      (layers): ModuleList(
        (0): GatedConv(
          (conv): WeightNormConv2d (1024, 2048, kernel_size=(6, 1), stride=(1, 1), padding=(3, 0))
          (dropout): Dropout(p=0.3)
        )
        (1): GatedConv(
          (conv): WeightNormConv2d (1024, 2048, kernel_size=(6, 1), stride=(1, 1), padding=(3, 0))
          (dropout): Dropout(p=0.3)
        )
      )
    )
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(96, 300, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(1324, 1024)
        (1): LSTMCell(1024, 1024)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=1024, out_features=1024)
      (linear_out): Linear(in_features=2048, out_features=1024)
      (sm): Softmax()
      (tanh): Tanh()
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=1024, out_features=96)
    (1): LogSoftmax()
  )
)
* number of parameters: 46806368
encoder:  25511040
decoder:  21295328

main()
  File "/home/nlplab/howard/gec/nmt.gec/train.py", line 501, in main
    train_model(model, train_dataset, valid_dataset, fields, optim, model_opt)
  File "/home/nlplab/howard/gec/nmt.gec/train.py", line 312, in train_model
    train_stats = trainer.train(epoch, report_func)
  File "/home/nlplab/howard/gec/nmt.gec/onmt/Trainer.py", line 154, in train
    self.model(src, tgt, src_lengths, dec_state)
  File "/opt/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 325, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nlplab/howard/gec/nmt.gec/onmt/Models.py", line 546, in forward
    enc_hidden, context = self.encoder(src, lengths)
  File "/opt/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 325, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nlplab/howard/gec/nmt.gec/onmt/modules/Conv2Conv.py", line 87, in forward
    out = self.cnn(emb_remap)
  File "/opt/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 325, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/nlplab/howard/gec/nmt.gec/onmt/modules/Conv2Conv.py", line 55, in forward
    x = x + conv(x)
RuntimeError: The size of tensor a (35) must match the size of tensor b (36) at non-singleton dimension 2
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='howardyclo' date='2017-12-27T11:49:07Z'>
		Can you add some print size statement from onmt/modules/Conv2Conv.py:55 back, and see where something starts getting wrong.  I guess there might be bugs in  WeightNormConv2d.
		</comment>
		<comment id='2' author='howardyclo' date='2017-12-27T14:32:24Z'>
		&lt;denchmark-link:https://github.com/JianyuZhan&gt;@JianyuZhan&lt;/denchmark-link&gt;
  Ok, I'll try.
		</comment>
		<comment id='3' author='howardyclo' date='2017-12-27T18:30:01Z'>
		Hmm, yeah, we haven't tested the different combinations yet. We should add this.
		</comment>
		<comment id='4' author='howardyclo' date='2018-07-11T10:46:43Z'>
		have this bug fixed?
		</comment>
		<comment id='5' author='howardyclo' date='2018-07-30T16:46:32Z'>
		The bug does exist, not all encoder + decoder configurations work. However, the error message of this thread is caused by setting the kernel size as an even number, which is something unusual for obvious reasons (symmetry).
		</comment>
		<comment id='6' author='howardyclo' date='2018-09-03T15:12:41Z'>
		adding this to "Projects", not sure someone will pick it up though.
		</comment>
	</comments>
</bug>