<bug id='137' author='ketranm' open_date='2017-07-17T23:23:35Z' closed_time='2017-07-22T21:44:36Z'>
	<summary>Beam search bug</summary>
	<description>
The output of translate.py is inconsistent with different -batch_size option. When I trained on IWSLT data and test on ted2013 de-&gt;en, the difference is significant, about 9 BLEU between -batch_size 1 and -batch_size 30.
I think one of the culprits is in  &lt;denchmark-link:https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Translator.py#L201&gt;https://github.com/OpenNMT/OpenNMT-py/blob/master/onmt/Translator.py#L201&lt;/denchmark-link&gt;

When a completed hypothesis is found, we shouldn't advance the beam, otherwise, it will overwrite the best found hypothesis. This can be fixed for example
def advance(self, wordLk, attnOut):
    return True if self.is_done 
    numWords = wordLk.size(1)
    ...
at the beginning of Beam.advance.
There is still another bug somewhere, I haven't figured out. I would appreciate for any pointer to fix this bug.
	</description>
	<comments>
		<comment id='1' author='ketranm' date='2017-07-17T23:35:21Z'>
		Does the issue you describe have to do with batch_size? seems like it would always apply.
When you get a working model, let's setup an integration test to make sure this dataset remains correct.
		</comment>
		<comment id='2' author='ketranm' date='2017-07-18T02:33:42Z'>
		There are lots of ways to write batched beam search that have subtle dependencies on the batch size, typically because they allow the fact that one example in the batch has output an EOS to affect the termination of other examples. I'm not super familiar with the OpenNMT implementation though.
		</comment>
		<comment id='3' author='ketranm' date='2017-07-19T22:24:01Z'>
		no this is clearly a bug. batch beam search must be identical to regular.
		</comment>
		<comment id='4' author='ketranm' date='2017-07-19T22:34:48Z'>
		Is it a bug if the (yes, incorrect) batched beam search implementation gets slightly better BLEU than regular beam search because it's doing some kind of implicit length normalization? Because that's something I've seen before...
		</comment>
		<comment id='5' author='ketranm' date='2017-07-19T22:46:40Z'>
		not sure what do you mean by implicit length normalization. Current OpenNMT-py considers a beam is finished if EOS is generated at the top of the beam. This is also an issue I wonder is there any reason we don't normalize the log probabilities by sentence length as it's done in Google's paper.
		</comment>
		<comment id='6' author='ketranm' date='2017-07-22T14:39:23Z'>
		I can confirm that results on my multilingual grapheme-to-phoneme task became markedly better when I reduced my batch_size to 1. Discovering this is a big deal for me; it seems to explain a lot of my trouble reproducing my OpenNMT-lua results in python.
		</comment>
		<comment id='7' author='ketranm' date='2017-07-22T17:27:11Z'>
		This sounds more like a padding management issue than a beam search issue. The sequence lengths were not passed to the encoder during translation, thus the encoder's states were incorrect with variable length inputs.
According to my quick validation test, this is the fix for the issue. Can anyone confirm?
		</comment>
		<comment id='8' author='ketranm' date='2017-07-22T17:35:45Z'>
		Oh, this sounds right to me.
		</comment>
		<comment id='9' author='ketranm' date='2017-07-22T17:53:41Z'>
		it looks good. I get comparable results now.
		</comment>
		<comment id='10' author='ketranm' date='2017-07-22T21:44:30Z'>
		Thanks Guilluime. Closing up. Tests coming soon.
		</comment>
	</comments>
</bug>