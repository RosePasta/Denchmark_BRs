<bug id='155' author='bpopeters' open_date='2017-08-07T15:05:18Z' closed_time='2017-08-29T02:08:48Z'>
	<summary>Incorrect scores when using translate.py</summary>
	<description>
I've noticed that I get a lot of results that look like this when I run translate.py:
PRED 397: β i s̪ j o̞ n̪
PRED SCORE: -3.0023
GOLD 397: β i s̪ j o̞ n̪
GOLD SCORE: -0.4212
In cases where the prediction is exactly correct, the scores for gold and predicted are almost always different.
	</description>
	<comments>
		<comment id='1' author='bpopeters' date='2017-08-20T13:01:22Z'>
		Looking into this.
		</comment>
		<comment id='2' author='bpopeters' date='2017-08-29T02:08:48Z'>
		This is now fixed and is included in the continuous integration.
		</comment>
	</comments>
</bug>