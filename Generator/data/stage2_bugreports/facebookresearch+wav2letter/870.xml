<bug id='870' author='MrityunjoyS' open_date='2020-10-27T14:20:37Z' closed_time='2020-10-27T14:26:48Z'>
	<summary>Bad transcription output from Streaming_ASR</summary>
	<description>
Trying to used [https://github.com/facebookresearch/wav2letter/tree/master/recipes/models/sota/2019] for simple_streaming_asr_example and interactive_streaming_asr_example .
Using below command :-
&lt;denchmark-code&gt;cat /path/tmp2.wav | \
 /path/wav2letter/build/inference/inference/examples/simple_streaming_asr_example \
 acoustic_module_file /path/sota/am_resnet_ctc_librivox_dev_clean_icml.bin \
 feature_module_file /path/sota/feature_extractor.bin \
 language_model_file /path/sota/lm_librispeech_kenlm_word_4g_200kvocab.bin \
 lexicon_file /path/sota/librispeech-train+dev-unigram-10000-nbest10.lexicon \
 tokens_file /path/sota/librispeech-train-all-unigram-10000.tokens \
 decoder_options_file /path/wav2letter/decoder_options.json
&lt;/denchmark-code&gt;

decoder.json file -&gt;
&lt;denchmark-code&gt;{
  "beamSize" : 100,
  "beamSizeToken" : 100,
  "beamThreshold" : 100,
  "lmWeight" : 0.674,
  "wordScore" : 0.628,
  "unkScore" : -Infinity,
  "silScore" : 0.0,
  "eosScore" : 0.0,
  "logAdd" : false,
  "criterionType" : "CTC"
}

&lt;/denchmark-code&gt;

But the transcription output is very poor as in, the audio not getting recognised properly. Any suggestion on how to improve the recognision quality please.
Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='MrityunjoyS' date='2020-11-11T18:34:48Z'>
		&lt;denchmark-link:https://github.com/MrityunjoyS&gt;@MrityunjoyS&lt;/denchmark-link&gt;
 I am facing a similar issue with the streaming ASR quality. At the same time, the accuracy of the same model in the decoding mode is much higher.
Did you figure out the reason/solution for it?
		</comment>
		<comment id='2' author='MrityunjoyS' date='2020-11-12T06:41:11Z'>
		Could you send more details on repro? cc &lt;denchmark-link:https://github.com/avidov&gt;@avidov&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='MrityunjoyS' date='2020-11-16T13:44:12Z'>
		Hi &lt;denchmark-link:https://github.com/tlikhomanenko&gt;@tlikhomanenko&lt;/denchmark-link&gt;
. When running the same audios with  and , I would get different transcripts, the one run in the streaming having wrong words and missing words. Apparently, it was caused by pruning in the inference mode. Got an answer &lt;denchmark-link:https://github.com/facebookresearch/wav2letter/issues/885&gt;here&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>