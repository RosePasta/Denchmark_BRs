<bug id='869' author='abhinavkulkarni' open_date='2020-10-25T18:19:21Z' closed_time='2020-11-15T08:44:21Z'>
	<summary>Unable to run streaming convnet recipe model in streaming fashion</summary>
	<description>
&lt;denchmark-h:h3&gt;Bug Description&lt;/denchmark-h&gt;

Hi,
I am unable to run &lt;denchmark-link:https://github.com/facebookresearch/wav2letter/tree/v0.2/recipes/models/streaming_convnets/librispeech&gt;streaming convnet recipe models&lt;/denchmark-link&gt;
 using example binaries (streaming or interactive ASR examples).
&lt;denchmark-h:h4&gt;Reproduction Steps&lt;/denchmark-h&gt;

I have all the requisite files present:
$ ls -1
3-gram.pruned.3e-7.bin.qt
am_500ms_future_context_dev_other.bin
decoder-unigram-10000-nbest10.lexicon
feature_extractor.bin
librispeech-train-all-unigram-10000.tokens
I'm running the command as follows:
$ ~/Projects/wav2letter/cmake-build-debug/inference/inference/examples/simple_streaming_asr_example \
  -acoustic_module_file am_500ms_future_context_dev_other.bin \
  -feature_module_file feature_extractor.bin \
  -language_model_file 3-gram.pruned.3e-7.bin.qt \
  -lexicon_file decoder-unigram-10000-nbest10.lexicon \
  -tokens_file librispeech-train-all-unigram-10000.tokens 
I get the following error:
Started features model file loading ... 
Completed features model file loading elapsed time=111 milliseconds

Started acoustic model file loading ... 
terminate called after throwing an instance of 'cereal::Exception'
  what():  Error while trying to deserialize a polymorphic pointer. Could not find type id 3
Aborted (core dumped)
Please note that I am able to  run the models provided on the &lt;denchmark-link:https://github.com/facebookresearch/wav2letter/wiki/Inference-Run-Examples&gt;inference wiki&lt;/denchmark-link&gt;
:
$ ~/Projects/wav2letter/cmake-build-debug/inference/inference/examples/simple_streaming_asr_example \
  -acoustic_module_file acoustic_model.bin \
  -feature_module_file feature_extractor.bin \
  -language_model_file language_model.bin \
  -lexicon_file lexicon.txt \
  -tokens_file tokens.txt 
&lt;denchmark-h:h3&gt;Platform and Hardware&lt;/denchmark-h&gt;

Ubuntu 20.04, CPU
Thanks!
	</description>
	<comments>
		<comment id='1' author='abhinavkulkarni' date='2020-10-27T04:24:34Z'>
		cc &lt;denchmark-link:https://github.com/vineelpratap&gt;@vineelpratap&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/avidov&gt;@avidov&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='abhinavkulkarni' date='2020-10-28T16:12:44Z'>
		Hi,
Models which are serialized using wav2letter can't be run directly with inference pipeline. Please use this tool to convert the model to a format which inference pipeline can load -  &lt;denchmark-link:https://github.com/facebookresearch/wav2letter/blob/v0.2/Train.cpp#L436&gt;https://github.com/facebookresearch/wav2letter/blob/v0.2/Train.cpp#L436&lt;/denchmark-link&gt;
 .
Note that it only works with streaming_convnets recipe.
		</comment>
		<comment id='3' author='abhinavkulkarni' date='2020-11-15T08:44:20Z'>
		Thanks, &lt;denchmark-link:https://github.com/vineelpratap&gt;@vineelpratap&lt;/denchmark-link&gt;
.
I have asked a &lt;denchmark-link:https://github.com/facebookresearch/wav2letter/issues/888&gt;follow-up question &lt;/denchmark-link&gt;
regarding converting the sota/2019/am_tds_ctc model to an FBGEMM streaming convnets, you may want to take a look at it.
Thanks again!
		</comment>
	</comments>
</bug>