<bug id='11448' author='zheng-da' open_date='2018-06-28T05:55:08Z' closed_time='2018-08-29T04:13:02Z'>
	<summary>fail to fall back when sparse arrays are passed to MKLDNN-enabled operators.</summary>
	<description>
Currently, the MKLDNN-enabled operators, such as convolution and pooling, can't handle sparse arrays correctly. The reason is that the storage inference of these operators doesn't return the right dispatch mode.
The MKLDNN-enabled operators include:

 Activation @azai91
 BatchNorm @zheng-da
 Convolution @ZhennanQin
 Deconvolution @ZhennanQin
 FullyConnected @haojin2
 LRN @azai91
 Pooling @luobao-intel
 Softmax @luobao-intel

We may also need to test the operators below:

 Concat
 Copy
 Sum
 Flatten

&lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/azai91&gt;@azai91&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='zheng-da' date='2018-06-28T08:39:51Z'>
		&lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
 Could you help provide a test case?
Does cuDNN backend handle these cases?
		</comment>
		<comment id='2' author='zheng-da' date='2018-06-28T16:04:31Z'>
		Thank you for submitting the issue!  &lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 requesting this be labeled.
		</comment>
		<comment id='3' author='zheng-da' date='2018-06-28T16:18:28Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
  could you please provide a test case?
		</comment>
		<comment id='4' author='zheng-da' date='2018-06-28T16:31:56Z'>
		Thereâ€™s an existing test batch norm training test disabled due to flakyness
		</comment>
		<comment id='5' author='zheng-da' date='2018-06-28T18:17:33Z'>
		concat is tested and fixed.
		</comment>
		<comment id='6' author='zheng-da' date='2018-06-28T19:11:51Z'>
		I'll take FullyConnected if no one's working on it right now.
		</comment>
		<comment id='7' author='zheng-da' date='2018-06-28T22:46:21Z'>
		i created a PR for batchnorm.
		</comment>
		<comment id='8' author='zheng-da' date='2018-06-29T02:00:53Z'>
		what else need to cover? &lt;denchmark-link:https://github.com/luobao-intel&gt;@luobao-intel&lt;/denchmark-link&gt;
 can help
		</comment>
		<comment id='9' author='zheng-da' date='2018-07-02T21:28:13Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 @zouluobao everything I listed needs to be covered. The fix for BatchNorm has been merged and &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 is working on FullyConnected. We need to fix other operators.
		</comment>
		<comment id='10' author='zheng-da' date='2018-07-03T02:47:01Z'>
		&lt;denchmark-link:https://github.com/luobao-intel&gt;@luobao-intel&lt;/denchmark-link&gt;
 will handle other OPs :)
		</comment>
		<comment id='11' author='zheng-da' date='2018-07-03T05:07:07Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/luobao-intel&gt;@luobao-intel&lt;/denchmark-link&gt;
 we need to fix them and merge the PRs to the v1.3 release, which is probably before the end of next week.
		</comment>
		<comment id='12' author='zheng-da' date='2018-07-18T07:19:42Z'>
		&lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
 fullyconnected is done in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11498&gt;#11498&lt;/denchmark-link&gt;
, if you want to add the MKLDNN backward storage type inference for it please go ahead and do so. Thanks!
		</comment>
		<comment id='13' author='zheng-da' date='2018-07-22T07:00:37Z'>
		&lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 I thought you have fixed its backward storage type inference.
		</comment>
		<comment id='14' author='zheng-da' date='2018-07-22T07:18:44Z'>
		&lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
 checkout &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/11498/files#diff-f2984a387afd7a02b74fe43b9ef50ee1R214&gt;https://github.com/apache/incubator-mxnet/pull/11498/files#diff-f2984a387afd7a02b74fe43b9ef50ee1R214&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='zheng-da' date='2018-08-29T04:02:57Z'>
		&lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
 related PR are merged. Could you verify if all issues are fixed and close the issue?
		</comment>
	</comments>
</bug>