<bug id='10599' author='chinakook' open_date='2018-04-18T08:28:41Z' closed_time='2018-07-09T17:18:12Z'>
	<summary>[MKLDNN Bug] MKLDNN eats lots of memory and then crash down.</summary>
	<description>
MKLDNN eats lots of memory and crash down with  input image. You can try &lt;denchmark-link:https://github.com/chinakook/hr101_mxnet&gt;a project of mine&lt;/denchmark-link&gt;
 to issue that. The ordinary MKL can run it successfully in 8GB memory, but MKLDNN eat all 64GB of my PC.
 input data are very common used in little object detection in a big scene and regular scene segmentation.
	</description>
	<comments>
		<comment id='1' author='chinakook' date='2018-04-18T08:36:34Z'>
		&lt;denchmark-link:https://github.com/juliusshufan&gt;@juliusshufan&lt;/denchmark-link&gt;
 please help take a look at this issue.
		</comment>
		<comment id='2' author='chinakook' date='2018-04-18T13:10:34Z'>
		The case consumes about 40G peak memory w/ MKL-DNN in 8.4 seconds while 12G w/ default CPU path in 14.5 seconds.
We're looking into this issue.

[patric@mlt-skx084 hr101_mxnet]$ python tiny_detection_mxnet.py
[20:53:27] src/operator/nn/mkldnn/mkldnn_base.cc:60: Allocate 37632 bytes with malloc directly
[20:53:27] src/operator/nn/mkldnn/mkldnn_base.cc:60: Allocate 65536 bytes with malloc directly
[20:53:27] src/operator/nn/mkldnn/mkldnn_base.cc:60: Allocate 524288 bytes with malloc directly
[20:53:27] src/operator/nn/mkldnn/mkldnn_base.cc:60: Allocate 2097152 bytes with malloc directly
('time', 8.401818037033081, 'secs.')
(729, 5)
[patric@mlt-skx084 hr101_mxnet]$ python tiny_detection_mxnet.py
('time', 14.575803995132446, 'secs.')
(729, 5)

		</comment>
		<comment id='3' author='chinakook' date='2018-04-18T13:16:50Z'>
		Thanks! As I've tested before, when inferencing a scene segmentation network such as Deeplab or U-Net,  MKL-DNN also consume far more momery.
		</comment>
		<comment id='4' author='chinakook' date='2018-04-19T07:24:26Z'>
		is the memory used by the temp space? i just learned that there might be multiple pieces of temp space. we might need to limit the number of temp space.
		</comment>
		<comment id='5' author='chinakook' date='2018-04-19T15:22:11Z'>
		&lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 : Please label as : MKL, bug. We might need a label for MKLDNN.
		</comment>
		<comment id='6' author='chinakook' date='2018-04-20T05:24:14Z'>
		I think the MKLDNN may use its own allocation engine, other than MXNet allocation engine. The former may not have memory sharing tech.
As I've tested before, Caffe also consumes &gt;40GB in this case as It has no memory sharing tech.
		</comment>
		<comment id='7' author='chinakook' date='2018-04-20T06:09:17Z'>
		The memory used by MKLDNN is also allocated by the MXNet memory allocator. MKLDNN NDArrays are reused in the computation graph as normal NDArrays. The difference between MKLDNN operators and the normal operators is the temp space. MKLDNN operators use it for layout conversion. The temp space isn't required by most of the normal operators. The temp space may consume huge amount of memory and the MXNet executor may maintain multiple temp space in order to execute multiple operators simultaneously.
&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 could you investigate the issue further? I think we should reduce the unnecessary memory consumption.
		</comment>
		<comment id='8' author='chinakook' date='2018-04-20T06:47:21Z'>
		&lt;denchmark-link:https://github.com/zheng-da&gt;@zheng-da&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;

I reproduced this case, and per the memory allocation profiling (via the content of smaps file), there are large size memory allocated on heap (over 15GB).
Is it possible to analyze from the model arch perspective??
Thanks.
		</comment>
		<comment id='9' author='chinakook' date='2018-04-20T07:21:12Z'>
		&lt;denchmark-link:https://github.com/lionel92&gt;@lionel92&lt;/denchmark-link&gt;
 The model is a widely used Caffe-Resnet101 with some 1x1 convolutions added and with big input image.
		</comment>
		<comment id='10' author='chinakook' date='2018-05-08T13:59:15Z'>
		On a 24-core Haswell, every Resnet v1 network crashes at the first step.
		</comment>
		<comment id='11' author='chinakook' date='2018-05-08T14:05:24Z'>
		&lt;denchmark-link:https://github.com/al-rigazzi&gt;@al-rigazzi&lt;/denchmark-link&gt;
 could you share the script with us?
Did you build the code in the Haswell machine as well?
		</comment>
		<comment id='12' author='chinakook' date='2018-05-09T11:17:59Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 I simply ran:

Yes, I built on the same Haswell machine.
		</comment>
		<comment id='13' author='chinakook' date='2018-05-10T05:59:47Z'>
		&lt;denchmark-link:https://github.com/al-rigazzi&gt;@al-rigazzi&lt;/denchmark-link&gt;
  I tested on &lt;denchmark-link:https://ark.intel.com/products/81706/Intel-Xeon-Processor-E5-2660-v3-25M-Cache-2_60-GHz&gt;https://ark.intel.com/products/81706/Intel-Xeon-Processor-E5-2660-v3-25M-Cache-2_60-GHz&lt;/denchmark-link&gt;
 and it works fine with latest master (#5088ca9)

[zhaopen1@ortce-awsc4 ~/incubator-mxnet]$ python example/image-classification/train_imagenet.py --image-shape 3,224,224 --num-epochs 500 --network resnet --kv-store local --num-layers 50 --benchmark 1 --batch-size 128 --lr 0.045 --data-nthreads 8
INFO:root:start with arguments Namespace(batch_size=128, benchmark=1, data_nthreads=8, data_train=None, data_train_idx='', data_val=None, data_val_idx='', disp_batches=20, dtype='float32', gc_threshold=0.5, gc_type='none', gpus=None, image_shape='3,224,224', initializer='default', kv_store='local', load_epoch=None, loss='', lr=0.045, lr_factor=0.1, lr_step_epochs='50,80,110', macrobatch_size=0, max_random_aspect_ratio=0.25, max_random_h=36, max_random_l=50, max_random_rotate_angle=10, max_random_s=50, max_random_scale=1, max_random_shear_ratio=0.1, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='resnet', num_classes=1000, num_epochs=500, num_examples=1281167, num_layers=50, optimizer='sgd', pad_size=0, random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0001)
[22:18:26] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 147456 bytes with malloc directly
[22:18:27] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 589824 bytes with malloc directly
[22:18:27] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 2359296 bytes with malloc directly
[22:18:28] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 9437184 bytes with malloc directly
[22:18:28] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 51380224 bytes with malloc directly
[22:18:28] src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 51380224 bytes with malloc directly
INFO:root:Epoch[0] Batch [20]   Speed: 28.81 samples/sec        accuracy=0.070312
INFO:root:Epoch[0] Batch [40]   Speed: 31.23 samples/sec        accuracy=0.818359
INFO:root:Epoch[0] Batch [60]   Speed: 30.34 samples/sec        accuracy=1.000000
INFO:root:Epoch[0] Batch [80]   Speed: 29.74 samples/sec        accuracy=1.000000
INFO:root:Epoch[0] Batch [100]  Speed: 30.17 samples/sec        accuracy=1.000000

		</comment>
		<comment id='14' author='chinakook' date='2018-05-11T12:53:56Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;

May I ask you what BLAS libraries and MKL versions you are using?
Still crashes for me:

INFO:root:start with arguments Namespace(batch_size=32, benchmark=1, data_nthreads=2, data_train=None, data_train_idx='', data_val=None, data_val_idx='', disp_batches=20, dtype='float32', gc_threshold=0.5, gc_type='none', gpus=None, image_shape='3,224,224', initializer='default', kv_store='local', load_epoch=None, loss='', lr=0.045, lr_factor=0.1, lr_step_epochs='30,60', macrobatch_size=0, max_random_aspect_ratio=0.25, max_random_h=36, max_random_l=50, max_random_rotate_angle=10, max_random_s=50, max_random_scale=1, max_random_shear_ratio=0.1, min_random_scale=1, model_prefix=None, mom=0.9, monitor=0, network='resnet', num_classes=1000, num_epochs=500, num_examples=1281167, num_layers=50, optimizer='sgd', pad_size=0, random_crop=1, random_mirror=1, rgb_mean='123.68,116.779,103.939', test_io=0, top_k=0, warmup_epochs=5, warmup_strategy='linear', wd=0.0001)
[20:52:45] /home/arigazzi/mxnet/src/operator/nn/mkldnn/mkldnn_base.cc:68: Allocate 147456 bytes with malloc directly
error: Segmentation fault

		</comment>
		<comment id='15' author='chinakook' date='2018-05-21T12:57:06Z'>
		Hi &lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
, I switched to gcc 7 (from 4.9.3), it seems to work now.
Thanks.
		</comment>
		<comment id='16' author='chinakook' date='2018-06-22T17:36:21Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
  Can we close this issue?
		</comment>
		<comment id='17' author='chinakook' date='2018-06-23T01:20:43Z'>
		&lt;denchmark-link:https://github.com/al-rigazzi&gt;@al-rigazzi&lt;/denchmark-link&gt;
 I used MKL2018 (USE_BLAS=mkl), you can download in &lt;denchmark-link:https://software.intel.com/en-us/mkl&gt;https://software.intel.com/en-us/mkl&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/azai91&gt;@azai91&lt;/denchmark-link&gt;
 I think we can close it now. &lt;denchmark-link:https://github.com/al-rigazzi&gt;@al-rigazzi&lt;/denchmark-link&gt;
 feel free to re-open if you still encounter the issue.
		</comment>
	</comments>
</bug>