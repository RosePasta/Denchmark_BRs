<bug id='17479' author='icemelon9' open_date='2020-01-30T07:13:34Z' closed_time='2020-01-31T03:03:48Z'>
	<summary>Bug in RNN and LSTM with multiple layers for mxnet-mkl</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

When gluon.rnn.RNN and gluon.rnn.LSTM have multiple layers and input size is not equal to hidden size, the output tensors and output states (except the state for the first layer) are incorrect. This bug only appears in mxnet-mkl package (I checked 1.5.0, 1.5.1, and 1.6.0, all have this bug), not in mxnet package.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

(Paste the complete error message. Please also include stack trace by setting environment variable DMLC_LOG_STACK_TRACE_DEPTH=10 before running your script.)
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

mxnet and mxnet-mkl returns different output results for the following code, where the results from mxnet-mkl are wrong.
import numpy as np
import mxnet as mx
from mxnet import gluon

np.random.seed(0)
mx.random.seed(0)

dtype = 'float32'
batch = 1
seq_len = 3
hidden_size = 10
input_size = 5
num_layers = 2
data_shape = (seq_len, batch, input_size)
state_shape = (num_layers, batch, hidden_size)

layer = gluon.rnn.RNN(hidden_size, num_layers, input_size=input_size,
                      bidirectional=False)
num_states = 1
# layer = gluon.rnn.LSTM(hidden_size, num_layers, bidirectional=False)
# num_states = 2
layer.initialize()
layer.hybridize()

data_np = np.random.uniform(size=data_shape).astype(dtype)
data_mx = mx.nd.array(data_np)
states_mx = []
for i in range(num_states):
    s = np.random.uniform(size=state_shape).astype(dtype)
    states_mx.append(mx.nd.array(s))
mx_out, mx_states = layer(data_mx, states_mx)
print(mx_out.asnumpy())
print(mx_states[0].asnumpy())
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:
&lt;denchmark-code&gt;curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python

# paste outputs here

----------Python Info----------
Version      : 3.7.3
Compiler     : GCC 7.3.0
Build        : ('default', 'Mar 27 2019 22:11:17')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 19.3.1
Directory    : /home/ubuntu/anaconda3/lib/python3.7/site-packages/pip
----------MXNet Info-----------
Version      : 1.5.0
Directory    : /home/ubuntu/anaconda3/lib/python3.7/site-packages/mxnet
Num GPUs     : 0
Commit Hash   : 75a9e187d00a8b7ebc71412a02ed0e3ae489d91f
----------System Info----------
Platform     : Linux-4.15.0-1057-aws-x86_64-with-debian-buster-sid
system       : Linux
node         : ip-172-31-24-84
release      : 4.15.0-1057-aws
version      : #59-Ubuntu SMP Wed Dec 4 10:02:00 UTC 2019
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
CPU(s):              8
On-line CPU(s) list: 0-7
Thread(s) per core:  2
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               79
Model name:          Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:            1
CPU MHz:             2215.251
CPU max MHz:         3000.0000
CPU min MHz:         1200.0000
BogoMIPS:            4600.10
Hypervisor vendor:   Xen
Virtualization type: full
L1d cache:           32K
L1i cache:           32K
L2 cache:            256K
L3 cache:            46080K
NUMA node0 CPU(s):   0-7
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0020 sec, LOAD: 0.4746 sec.
Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0005 sec, LOAD: 0.3909 sec.
Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1271 sec, LOAD: 0.3758 sec.
Timing for D2L: http://d2l.ai, DNS: 0.0084 sec, LOAD: 0.0419 sec.
Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0089 sec, LOAD: 0.0692 sec.
Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0527 sec, LOAD: 0.1357 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0113 sec, LOAD: 0.3577 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0093 sec, LOAD: 0.0664 sec.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='icemelon9' date='2020-01-30T11:49:33Z'>
		cc &lt;denchmark-link:https://github.com/PatricZhao&gt;@PatricZhao&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='icemelon9' date='2020-01-30T13:24:39Z'>
		Hi &lt;denchmark-link:https://github.com/icemelon9&gt;@icemelon9&lt;/denchmark-link&gt;
, as 1.6.0 is not released yet, could you please be more specific about the commit id or build date if you're using a nightly release? Also cc &lt;denchmark-link:https://github.com/zixuanweeei&gt;@zixuanweeei&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='icemelon9' date='2020-01-30T14:25:12Z'>
		Hi &lt;denchmark-link:https://github.com/icemelon9&gt;@icemelon9&lt;/denchmark-link&gt;
 , thanks for reporting this issue. I have a test on v1.6x branch (commit-id &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/6eec9da55c5096079355d1f1a5fa58dcf35d6752&gt;6eec9da&lt;/denchmark-link&gt;
) for 3-layer LSTM. The differences between the results of those two releases are less than 1e-5. Could you give a try on v1.6.x? It would be highly appreciated. Further investigation of v1.5.x is in progress. I will confirm the result later. Sorry for the inconvenience.

mxnet: make -j  USE_MKLDNN=0 USE_BLAS=mkl USE_INTEL_PATH=/opt/intel USE_OPENMP=1 USE_OPENCV=0

&lt;denchmark-code&gt;[[[ 0.11122619  0.18695417  0.036056    0.18501873  0.00461666
    0.19519787  0.11368521  0.22313197  0.16217268  0.19069287]]

 [[ 0.05666452  0.09940925  0.02025517  0.0998227  -0.00323086
    0.10185727  0.05466421  0.12510833  0.09242072  0.10603023]]

 [[ 0.03004576  0.05036608  0.01141703  0.05086566 -0.00455239
    0.05140195  0.02738635  0.06676298  0.05007396  0.05527211]]]
[[[ 0.05855561  0.0166911  -0.02148632  0.02531915 -0.04765372
   -0.00133875 -0.00242618  0.07877947  0.00234905  0.03731738]]

 [[ 0.00935058  0.02891479  0.01008102  0.04661271  0.01876344
   -0.00332517 -0.00967842  0.03273115  0.02256259  0.02182308]]

 [[ 0.03004576  0.05036608  0.01141703  0.05086566 -0.00455239
    0.05140195  0.02738635  0.06676298  0.05007396  0.05527211]]]
&lt;/denchmark-code&gt;


mxnet-mkl: make -j  USE_MKLDNN=1 USE_BLAS=mkl USE_INTEL_PATH=/opt/intel USE_OPENMP=1 USE_OPENCV=0

&lt;denchmark-code&gt;[[[ 0.1112262   0.18695419  0.036056    0.18501873  0.00461666
    0.19519788  0.11368521  0.22313201  0.16217265  0.19069287]]

 [[ 0.05666453  0.09940924  0.02025516  0.09982269 -0.00323086
    0.10185728  0.05466421  0.12510836  0.0924207   0.10603023]]

 [[ 0.03004576  0.05036609  0.01141703  0.05086566 -0.00455239
    0.05140197  0.02738635  0.066763    0.05007394  0.05527212]]]
[[[ 0.05855562  0.01669111 -0.02148631  0.02531913 -0.04765372
   -0.00133875 -0.00242618  0.07877947  0.00234905  0.03731737]]

 [[ 0.00935059  0.02891479  0.01008102  0.04661271  0.01876344
   -0.00332517 -0.00967842  0.03273115  0.02256259  0.02182308]]

 [[ 0.03004576  0.05036609  0.01141703  0.05086566 -0.00455239
    0.05140197  0.02738635  0.066763    0.05007394  0.05527212]]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='icemelon9' date='2020-01-30T18:44:19Z'>
		I installed mxnet through pip. The output of the script I attached is:

pip install mxnet-mkl==1.6.0b20191023

&lt;denchmark-code&gt;[[[0.         0.         0.07724057 0.0566524  0.         0.04362311
   0.03751738 0.00556269 0.0550974  0.        ]]

 [[0.         0.         0.00398349 0.         0.01183925 0.01306902
   0.0047982  0.         0.         0.        ]]

 [[0.         0.         0.         0.         0.01282815 0.00460393
   0.         0.         0.         0.        ]]]
[[[0.07427667 0.04290958 0.         0.         0.05070981 0.
   0.         0.07841663 0.12032647 0.00205634]]

 [[0.         0.         0.         0.         0.01282815 0.00460393
   0.         0.         0.         0.        ]]]
&lt;/denchmark-code&gt;


pip install mxnet==1.6.0b20191023

&lt;denchmark-code&gt;[[[0.         0.00465954 0.0188278  0.04177516 0.         0.
   0.         0.         0.02623909 0.        ]]

 [[0.         0.         0.         0.         0.01337615 0.00938206
   0.00011961 0.         0.         0.        ]]

 [[0.         0.         0.         0.         0.01263414 0.00438385
   0.         0.         0.         0.        ]]]
[[[0.07427667 0.04290957 0.         0.         0.05070981 0.
   0.         0.07841662 0.12032647 0.00205634]]

 [[0.         0.         0.         0.         0.01263414 0.00438385
   0.         0.         0.         0.        ]]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='icemelon9' date='2020-01-31T01:11:10Z'>
		I compiled the mxnet master with mkldnn. And the output results are correct now.
		</comment>
		<comment id='6' author='icemelon9' date='2020-01-31T01:25:56Z'>
		
I compiled the mxnet master with mkldnn. And the output results are correct now.

Thanks for trying out the master. Yes, I can confirm that the nightly build 1.6.0b20191023 has the problem. Would you mind using the latest build? Or please tell us if there is any incompatible usage in your application.
		</comment>
		<comment id='7' author='icemelon9' date='2020-01-31T02:13:21Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 This problem happens on the codebase with the old MKL-DNN version (&lt; v1.0). After &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/aa1074dc1704d3732ab205c43d48083ef8c69680&gt;aa1074d&lt;/denchmark-link&gt;
, we brought the refactor of rnn operators into MXNet, which could give the correct result. I also tested with &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/b5d07e30321da47d604b99048c1b57c03ec819b0&gt;b5d07e3&lt;/denchmark-link&gt;
 (1 commit before &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/aa1074dc1704d3732ab205c43d48083ef8c69680&gt;aa1074d&lt;/denchmark-link&gt;
), turning out to have the wrong result. For now, we can fix it on v1.5.x branch only. Shall we?
		</comment>
		<comment id='8' author='icemelon9' date='2020-01-31T02:50:19Z'>
		
@pengzhao-intel @TaoLv This problem happens on the codebase with the old MKL-DNN version (&lt; v1.0). After aa1074d, we brought the refactor of rnn operators into MXNet, which could give the correct result. I also tested with b5d07e3 (1 commit before aa1074d), turning out to have the wrong result. For now, we can fix it on v1.5.x branch only. Shall we?

Since the fix is in v1.6.x, I suggest switching to v1.6.x. Actually, it depends on their deployment requirements. If it is necessary, we can evaluate how difficult to backport to v1.5.x.
		</comment>
		<comment id='9' author='icemelon9' date='2020-01-31T03:03:48Z'>
		Hi &lt;denchmark-link:https://github.com/icemelon9&gt;@icemelon9&lt;/denchmark-link&gt;
, I'm closing this issue as it's already fixed on the master branch and will be included in the v1.6.0 release. You can get the latest nightly build through .
		</comment>
	</comments>
</bug>