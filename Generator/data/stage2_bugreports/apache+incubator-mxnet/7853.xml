<bug id='7853' author='altosaar' open_date='2017-09-11T20:47:06Z' closed_time='2019-03-04T17:53:39Z'>
	<summary>ndarray.choose_element_0index not differentiable / bug in gradients after slicing?</summary>
	<description>
&lt;denchmark-h:h2&gt;Environment info&lt;/denchmark-h&gt;

Operating System: OSX
MXNet version: 0.11.0
Python version and distribution: python3/anaconda
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

I want to differentiate through ndarray.choose_element_0index:
&lt;denchmark-code&gt;In [2]: from mxnet import autograd

In [3]: from mxnet import gluon

In [4]: from mxnet import nd

In [5]: params = gluon.ParameterDict()

In [6]: w = params.get('var', shape=(1, 10))

In[7]: params.initialize()

In [8]: with autograd.record():
   ...:     element = nd.choose_element_0index(w.data(), nd.array([0]))
   ...:     y = nd.square(element)
   ...:     y.backward()
&lt;/denchmark-code&gt;

Returns:
&lt;denchmark-code&gt;----&gt; 4     y.backward()
      5

/usr/local/anaconda3/envs/yumi/lib/python3.6/site-packages/mxnet/ndarray.py in backward(self, out_grad, retain_graph, train_mode)
   1100             c_array(NDArrayHandle, ograd_handles),
   1101             ctypes.c_int(retain_graph),
-&gt; 1102             ctypes.c_int(train_mode)))
   1103
   1104

/usr/local/anaconda3/envs/yumi/lib/python3.6/site-packages/mxnet/base.py in check_call(ret)
    127     """
    128     if ret != 0:
--&gt; 129         raise MXNetError(py_str(_LIB.MXGetLastError()))
    130
    131 if sys.version_info[0] &lt; 3:

MXNetError: [16:38:03] src/ndarray/autograd.cc:237: Check failed: !i.entry_.is_none() Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward.

Stack trace returned 5 entries:
[bt] (0) 0   libmxnet.so                         0x0000000107519ad8 _ZN4dmlc15LogMessageFatalD2Ev + 40
[bt] (1) 1   libmxnet.so                         0x0000000107cfaca4 _ZN5mxnet8autograd15AutogradRuntime15ComputeGradientERKNSt3__16vectorINS_7NDArrayENS2_9allocatorIS4_EEEES9_bb + 9236
[bt] (2) 2   libmxnet.so                         0x0000000107c1bc88 MXAutogradBackwardEx + 488
[bt] (3) 3   _ctypes.cpython-36m-darwin.so       0x0000000106d2d2b7 ffi_call_unix64 + 79
[bt] (4) 4   ???                                 0x00007fff5afbcd60 0x0 + 140734719839584
&lt;/denchmark-code&gt;

But this works and behaves as expected:
&lt;denchmark-code&gt;In [19]: with autograd.record():
    ...:     y = nd.square(w.data()[0][0])
    ...:     y.backward()
    ...:     print(w.grad())
    ...:

[[ 0.01366779  0.          0.          0.          0.          0.          0.
   0.          0.          0.        ]]
&lt;NDArray 1x10 @cpu(0)&gt;
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='altosaar' date='2017-12-22T22:44:42Z'>
		&lt;denchmark-link:https://github.com/orgs/apache/teams/mxnet-committers&gt;@apache/mxnet-committers&lt;/denchmark-link&gt;
: This issue has been inactive for the past 90 days. It has no label and needs triage.
For general "how-to" questions, our &lt;denchmark-link:https://discuss.mxnet.io/&gt;user forum&lt;/denchmark-link&gt;
 (and &lt;denchmark-link:https://discuss.gluon.ai/&gt;Chinese version&lt;/denchmark-link&gt;
) is a good place to get help.
		</comment>
		<comment id='2' author='altosaar' date='2019-02-14T23:51:52Z'>
		Error on MXNet v1.5 (built from source). Tested on OSX
&lt;denchmark-code&gt;---------------------------------------------------------------------------
MXNetError                                Traceback (most recent call last)
&lt;ipython-input-13-b04ee09a6160&gt; in &lt;module&gt;()
     12      element = nd.choose_element_0index(w.data(), nd.array([0]))
     13      y = nd.square(element)
---&gt; 14      y.backward()

~/Documents/mxnet/incubator-mxnet/python/mxnet/ndarray/ndarray.py in backward(self, out_grad, retain_graph, train_mode)
   2213             ctypes.c_int(train_mode),
   2214             ctypes.c_void_p(0),
-&gt; 2215             ctypes.c_void_p(0)))
   2216 
   2217     def tostype(self, stype):

~/Documents/mxnet/incubator-mxnet/python/mxnet/base.py in check_call(ret)
    250     """
    251     if ret != 0:
--&gt; 252         raise MXNetError(py_str(_LIB.MXGetLastError()))
    253 
    254 

MXNetError: [15:24:46] src/pass/gradient.cc:192: Operator choose_element_0index is non-differentiable because it didn't register FGradient attribute.

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000011232dbd6 dmlc::StackTrace() + 1238
[bt] (1) 1   libmxnet.so                         0x000000011232d5c5 dmlc::LogMessageFatal::~LogMessageFatal() + 53
[bt] (2) 2   libmxnet.so                         0x00000001162009ea nnvm::pass::(anonymous namespace)::Gradient(nnvm::Graph) + 13066
[bt] (3) 3   libmxnet.so                         0x00000001156de032 nnvm::Graph std::__1::__invoke_void_return_wrapper&lt;nnvm::Graph&gt;::__call&lt;nnvm::Graph (*&amp;)(nnvm::Graph), nnvm::Graph&gt;(nnvm::Graph (*&amp;&amp;&amp;)(nnvm::Graph), nnvm::Graph&amp;&amp;) + 162
[bt] (4) 4   libmxnet.so                         0x00000001156dded0 std::__1::__function::__func&lt;nnvm::Graph (*)(nnvm::Graph), std::__1::allocator&lt;nnvm::Graph (*)(nnvm::Graph)&gt;, nnvm::Graph (nnvm::Graph)&gt;::operator()(nnvm::Graph&amp;&amp;) + 64
[bt] (5) 5   libmxnet.so                         0x00000001161e5e18 nnvm::ApplyPasses(nnvm::Graph, std::__1::vector&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;, std::__1::allocator&lt;std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; &gt; &gt; const&amp;) + 1448
[bt] (6) 6   libmxnet.so                         0x000000011512548e nnvm::ApplyPass(nnvm::Graph, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;) + 590
[bt] (7) 7   libmxnet.so                         0x00000001152376fc nnvm::pass::Gradient(nnvm::Graph, std::__1::vector&lt;nnvm::NodeEntry, std::__1::allocator&lt;nnvm::NodeEntry&gt; &gt;, std::__1::vector&lt;nnvm::NodeEntry, std::__1::allocator&lt;nnvm::NodeEntry&gt; &gt;, std::__1::vector&lt;nnvm::NodeEntry, std::__1::allocator&lt;nnvm::NodeEntry&gt; &gt;, std::__1::function&lt;nnvm::NodeEntry (std::__1::vector&lt;nnvm::NodeEntry, std::__1::allocator&lt;nnvm::NodeEntry&gt; &gt;&amp;&amp;)&gt;, std::__1::function&lt;int (nnvm::Node const&amp;)&gt;, std::__1::function&lt;nnvm::NodeEntry (nnvm::NodeEntry const&amp;, nnvm::NodeEntry const&amp;)&gt;, std::__1::vector&lt;nnvm::Op const*, std::__1::allocator&lt;nnvm::Op const*&gt; &gt;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt;) + 8764
[bt] (8) 8   libmxnet.so                         0x000000011537a8c5 mxnet::Imperative::Backward(std::__1::vector&lt;mxnet::NDArray*, std::__1::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::__1::vector&lt;mxnet::NDArray*, std::__1::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::__1::vector&lt;mxnet::NDArray*, std::__1::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, bool, bool, bool) + 13445
[bt] (9) 9   libmxnet.so                         0x00000001150d434d MXAutogradBackwardEx + 3293
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>