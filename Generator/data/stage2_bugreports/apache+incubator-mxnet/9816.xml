<bug id='9816' author='DickJC123' open_date='2018-02-17T03:10:17Z' closed_time='2018-08-22T03:59:49Z'>
	<summary>Dropout may mask values even when ratio=0.0</summary>
	<description>
One reasonable expectation is that a dropout layout would pass no values when the dropout ratio=1.0 and would pass all values with the dropout ratio=0.0.  However, the current dropout test fails a ratio=0.0 test under some seeds because some values are masked.  Adapting from the current nn/dropout-inl.h, we have essentially:
&lt;denchmark-code&gt;prob_keep = 1.0 - ratio;
rand_pick = random_uniform_pick(0.0,1.0);
mask_out = (rand_pick &lt; prob_keep ? 1.0 : 0.0) * (1.0/prob_keep);
dropout_out = input_data * mask_out;
&lt;/denchmark-code&gt;

It must be that rand_pick above can include the 1.0 endpoint, so mask_out becomes 0.0.  A quick fix might change the '&lt;' to '&lt;=', but then some values might be passed when the dropout ratio = 1.0 if the rand_pick can be 0.0.  The possible differences between rng properties between cpu and gpu's should be considered: CUDNN rngs return values in (0.0,1.0] while most others are in the range [0.0,1.0).  This can be reproduced in any of the commits of the ci_test_randomness3 PR &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/9791&gt;#9791&lt;/denchmark-link&gt;
 if you edit the line above 'def test_dropout()' in test_operator.py to be only "@with_seed()", then execute: (output shown)
&lt;denchmark-code&gt;MXNET_TEST_SEED=990952066 nosetests --verbose tests/python/unittest/test_operator.py:test_dropout
[INFO] Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=881809903 to reproduce.
[WARNING] *** test-level seed set: all "@with_seed()" tests run deterministically ***
test_operator.test_dropout ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=990952066 to reproduce.
FAIL
======================================================================
FAIL: test_operator.test_dropout
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/nose/case.py", line 197, in runTest
    self.test(*self.arg)
  File "/home/dcarter/mxnet_dev/dgx/mxnet/tests/python/unittest/common.py", line 152, in test_new
    orig_test(*args, **kwargs)
  File "/home/dcarter/mxnet_dev/dgx/mxnet/tests/python/unittest/test_operator.py", line 4596, in test_dropout
    check_dropout_ratio(0.0, shape)
  File "/home/dcarter/mxnet_dev/dgx/mxnet/tests/python/unittest/test_operator.py", line 4561, in check_dropout_ratio
    assert exe.outputs[0].asnumpy().min() == min_value
AssertionError: 
-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------
common: INFO: Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=881809903 to reproduce.
common: WARNING: *** test-level seed set: all "@with_seed()" tests run deterministically ***
common: INFO: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=990952066 to reproduce.
--------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='DickJC123' date='2018-02-19T21:37:55Z'>
		This needs to be fix.
One possible fix is to use identity pass through when rate=0
		</comment>
		<comment id='2' author='DickJC123' date='2018-02-19T23:11:40Z'>
		I like making ratio=0 a special case with an identity pass-through.  During the same fix, how about making ratio=1 a special case also to output all 0's (current behavior is to pass inf or nan I think)?
		</comment>
		<comment id='3' author='DickJC123' date='2018-02-19T23:41:36Z'>
		There was an issue in mshadow about this &lt;denchmark-link:https://github.com/dmlc/mshadow/issues/213&gt;dmlc/mshadow#213&lt;/denchmark-link&gt;
. The cuda rng generates (0.0, 1.0].
		</comment>
		<comment id='4' author='DickJC123' date='2018-07-30T21:02:11Z'>
		&lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 re-running the test with your scenario appears to be working for me (today). Are you still experiencing a problem or can we close this issue?
		</comment>
		<comment id='5' author='DickJC123' date='2018-07-31T18:35:00Z'>
		&lt;denchmark-link:https://github.com/samskalicky&gt;@samskalicky&lt;/denchmark-link&gt;
 Able to reproduce the issue with seeds 111913613, 211508467, 1329041279
Traceback (most recent call last): File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/nose/case.py", line 197, in runTest self.test(*self.arg) File "/home/ubuntu/incubator-mxnet/tests/python/unittest/common.py", line 172, in test_new orig_test(*args, **kwargs) File "/home/ubuntu/incubator-mxnet/tests/python/unittest/test_operator.py", line 5610, in test_dropout check_dropout_ratio(0.0, shape) File "/home/ubuntu/incubator-mxnet/tests/python/unittest/test_operator.py", line 5554, in check_dropout_ratio assert exe.outputs[0].asnumpy().min() == min_value AssertionError: 
		</comment>
		<comment id='6' author='DickJC123' date='2018-08-01T19:41:30Z'>
		On running this on CPU, the flaky error is reproducible, as mentioned in the above comments.
On running this on GPU for 100k times, the test does not fail.
&lt;denchmark-code&gt;MXNET_TEST_COUNT=100000  nosetests --logging-level=DEBUG --verbose -s tests/python/gpu/test_operator_gpu.py:test_dropout
/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/home/ubuntu/anaconda3/lib/python3.6/site-packages/nose/util.py:453: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  inspect.getargspec(func)
[INFO] Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=1058042572 to reproduce.
test_operator_gpu.test_dropout ... [DEBUG] 1 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1077219613 to reproduce.
[DEBUG] 2 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1986463962 to reproduce.
[DEBUG] 3 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1446820082 to reproduce.
[DEBUG] 4 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1300194532 to reproduce.
[DEBUG] 5 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=576630976 to reproduce.
[DEBUG] 6 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1613399106 to reproduce.
.
.
.

[DEBUG] 99996 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=92629950 to reproduce.
[DEBUG] 99997 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=104203650 to reproduce.
[DEBUG] 99998 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1609587233 to reproduce.
[DEBUG] 99999 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=194799359 to reproduce.
[DEBUG] 100000 of 100000: Setting test np/mx/python random seeds, use MXNET_TEST_SEED=675994555 to reproduce.
ok

----------------------------------------------------------------------
Ran 1 test in 7130.900s

OK
&lt;/denchmark-code&gt;

On running on GPU with the failure seeds for CPU : 111913613, 211508467, 1329041279, the test still does not fail.
&lt;denchmark-code&gt;MXNET_TEST_SEED=1329041279 nosetests --logging-level=DEBUG --verbose -s tests/python/gpu/test_operator_gpu.py:test_dropout
/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
/home/ubuntu/anaconda3/lib/python3.6/site-packages/nose/util.py:453: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()
  inspect.getargspec(func)
[INFO] Setting module np/mx/python random seeds, use MXNET_MODULE_SEED=1997611840 to reproduce.
/home/ubuntu/incubator-mxnet/tests/python/gpu/../unittest/common.py:244: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn('*** test-level seed set: all "@with_seed()" tests run deterministically ***')
[WARNING] *** test-level seed set: all "@with_seed()" tests run deterministically ***
test_operator_gpu.test_dropout ... [INFO] Setting test np/mx/python random seeds, use MXNET_TEST_SEED=1329041279 to reproduce.
ok

----------------------------------------------------------------------
Ran 1 test in 2.103s

OK
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='DickJC123' date='2018-08-08T00:08:39Z'>
		Bug can be worked around by adding a threshold_eq (&lt;=) operator in mshadow_op.h and calling that one instead in dropout-inl.h
Tested working with seed 111913613
		</comment>
		<comment id='8' author='DickJC123' date='2018-08-22T03:34:18Z'>
		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 Related fix for this issue is merged, this issue should be good to close.
		</comment>
		<comment id='9' author='DickJC123' date='2019-01-16T21:39:37Z'>
		Unfortunately the issue with dropout operator is not fully solved - when using seed 579061237 on the GPU, rng produces 0 for one of the outputs in ratio=1.0 case, which, because of the usage of &lt;=, ends up being  instead of . Issue encountered in CI for my unrelated PR (and I tested it without the PR, it is reproducible): &lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-13890/2/pipeline&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-13890/2/pipeline&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/samskalicky&gt;@samskalicky&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>