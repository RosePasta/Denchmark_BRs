<bug id='13951' author='yifeim' open_date='2019-01-21T21:01:34Z' closed_time='2019-03-28T02:40:31Z'>
	<summary>Gluon RNN memory leaks with extra variables</summary>
	<description>
Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.
For Q &amp; A and discussion, please start a discussion thread at &lt;denchmark-link:https://discuss.mxnet.io&gt;https://discuss.mxnet.io&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Gluon allows one to define extra variables that may not lead to model outcome. However, having them may cause memory leak.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;----------Python Info----------
Version      : 3.6.5
Compiler     : GCC 7.2.0
Build        : ('default', 'Apr 29 2018 16:14:56')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 10.0.1
Directory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pip
----------MXNet Info-----------
Version      : 1.3.1
Directory    : /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet
Commit Hash   : 19c501680183237d52a862e6ae1dc4ddc296305b
----------System Info----------
Platform     : Linux-4.14.77-70.82.amzn1.x86_64-x86_64-with-glibc2.9
system       : Linux
node         : ip-172-16-95-144
release      : 4.14.77-70.82.amzn1.x86_64
version      : #1 SMP Mon Dec 3 20:01:27 UTC 2018
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                8
On-line CPU(s) list:   0-7
Thread(s) per core:    2
Core(s) per socket:    4
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               2706.669
BogoMIPS:              4600.11
Hypervisor vendor:     Xen
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              46080K
NUMA node0 CPU(s):     0-7
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0020 sec, LOAD: 1.0198 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0912 sec, LOAD: 0.1530 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.5845 sec, LOAD: 0.1434sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0089 sec, LOAD: 0.1170 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0100 sec, LOAD: 0.3888 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0104 sec, LOAD: 0.0782 sec.```
&lt;/denchmark-code&gt;

Package used (Python/R/Scala/Julia): Python
&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

If you run watch -n0.1 nvidia-smi, you may observe memory growth every by 2MB every few seconds.
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

See &lt;denchmark-link:https://github.com/apache/incubator-mxnet/files/2780496/mxnet-memory-leak.tar.gz&gt;mxnet-memory-leak.tar.gz&lt;/denchmark-link&gt;

The main differences between the attachment and  are to add  on Line 56 in  add to add  on Line 166 and 183 in 
&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)
&lt;denchmark-code&gt;1. python train.py --cuda --tied --nhid 200 --emsize 200 --epochs 20 --dropout 0.2 &amp;
2. watch -n0.1 nvidia-smi
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;


Add a dummy link between all inputs and outputs. However, this may not always be possible / convenient / readable.
I previously suggested a feature request to allow None input types in the gluon models. Communicated with @szha that this would not be fundamentally challenging. However, this has not been acted upon and may be a low-hanging fruit alongside the memory fix leak.

Related: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/13247&gt;#13247&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='yifeim' date='2019-01-22T07:13:05Z'>
		&lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
 Add [Gluon, Performance]
		</comment>
		<comment id='2' author='yifeim' date='2019-01-22T07:58:47Z'>
		&lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
 add [backend, cuda]
		</comment>
		<comment id='3' author='yifeim' date='2019-01-22T07:59:43Z'>
		&lt;denchmark-link:https://github.com/yifeim&gt;@yifeim&lt;/denchmark-link&gt;
 I am looking into this issue.
		</comment>
		<comment id='4' author='yifeim' date='2019-02-01T20:46:27Z'>
		&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 Why is this not a bug?
		</comment>
		<comment id='5' author='yifeim' date='2019-02-01T21:06:28Z'>
		&lt;denchmark-link:https://github.com/yifeim&gt;@yifeim&lt;/denchmark-link&gt;
 Sorry, got too busy and haven't got chance to dive deep into this. Yes, I think it's a bug. &lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
 add [Bug]
		</comment>
		<comment id='6' author='yifeim' date='2019-03-07T19:05:00Z'>
		The memory leak is related to the extra unused variable you passed into your RNN model but it is NOT specific to RNN. In your repro script, you created a size-zero ndarray in each loop which caused the memory leak.
&lt;denchmark-code&gt;for epoch in range(args.epochs):
    ...
    for i, (data, target) in enumerate(train_data):
        ...
        with autograd.record():
            ....
            output, hidden = model(data, hidden, mx.nd.array([], ctx=context))
&lt;/denchmark-code&gt;

However, since the size-zero ndarray is unused anywhere, it is a better code practice to create once outside the loop and use it throughout your training. The same change applies to the eval() function in your repro script.
&lt;denchmark-code&gt;extra = mx.nd.array([], ctx=context)
for epoch in range(args.epochs):
    ...
    for i, (data, target) in enumerate(train_data):
        ...
        with autograd.record():
            ....
            output, hidden = model(data, hidden, extra)
&lt;/denchmark-code&gt;

With this change, I ran your repro script for 10 epochs with mxnet_cu90mkl 1.3.1 and 1.4.0 packages and did not see memory leak.
But there is indeed a memory leak issue which is the root cause for this issue. Please refer to &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/14358&gt;#14358&lt;/denchmark-link&gt;
 for more details.
		</comment>
		<comment id='7' author='yifeim' date='2019-03-07T22:37:15Z'>
		&lt;denchmark-link:https://github.com/yifeim&gt;@yifeim&lt;/denchmark-link&gt;
 After a little bit more digging, I think the issue is specifically related the usage of size-zero ndarray for your extra variable. If you just use mx.nd.array([1], ctx=context) as the extra variable in the loop of your repro script, you will not observe any memory leak. The true problem is creating size-zero ndarray in a loop.
		</comment>
		<comment id='8' author='yifeim' date='2019-03-08T01:22:37Z'>
		Very interesting. Thanks a lot for the insights!
		</comment>
		<comment id='9' author='yifeim' date='2019-03-11T16:12:04Z'>
		Thanks for handling &lt;denchmark-link:https://github.com/yuxihu&gt;@yuxihu&lt;/denchmark-link&gt;
!
		</comment>
		<comment id='10' author='yifeim' date='2019-03-20T16:03:23Z'>
		&lt;denchmark-link:https://github.com/anirudh2290&gt;@anirudh2290&lt;/denchmark-link&gt;
 Could you please reopen this? The original fix has been reverted due to test flakiness. I am working on alternative fix.
		</comment>
	</comments>
</bug>