<bug id='11115' author='imgemp' open_date='2018-05-31T21:38:57Z' closed_time='2019-03-10T07:54:31Z'>
	<summary>ReLU Clips NaNs to Zero</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

In tracking down a bug, I found that the relu in mxnet.ndarray clips NaN’s to zero. Ideally, I would think the relu should propagate NaN’s so that bugs are not “covered up” for downstream operations.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

mxnet version ‘1.2.0’
numpy version ‘1.14.3’
&lt;denchmark-code&gt;----------Python Info----------
Version      : 3.6.5
Compiler     : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)
Build        : ('default', 'Apr 26 2018 08:42:37')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 10.0.1
Directory    : /anaconda3/envs/mxnet/lib/python3.6/site-packages/pip
----------MXNet Info-----------
Version      : 1.2.0
Directory    : /anaconda3/envs/mxnet/lib/python3.6/site-packages/mxnet
Commit Hash   : b011eccd17d660b2f1ecf901e0db0007706df35c
----------System Info----------
Platform     : Darwin-16.7.0-x86_64-i386-64bit
system       : Darwin
node         : 8c85904326b5.ant.amazon.com
release      : 16.7.0
version      : Darwin Kernel Version 16.7.0: Tue Jan 30 11:27:06 PST 2018; root:xnu-3789.73.11~1/RELEASE_X86_64
----------Hardware Info----------
machine      : x86_64
processor    : i386
b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'
b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
b'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0041 sec, LOAD: 0.4787 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0133 sec, LOAD: 1.7585 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.9810 sec, LOAD: 0.6178 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0148 sec, LOAD: 0.3849 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0104 sec, LOAD: 0.2880 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0122 sec, LOAD: 0.1161 sec.
&lt;/denchmark-code&gt;

Package used (Python/R/Scala/Julia):
I'm using Python version 3.6.5
Compiler (gcc/clang/mingw/visual studio):
GCC 4.2.1 Compatible Clang 4.0.1
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

import numpy as np
from mxnet import nd
nd.relu(np.NaN*nd.ones(1))
–&gt; [0.] &lt;NDArray 1 &lt;denchmark-link:https://github.com/cpu&gt;@cpu&lt;/denchmark-link&gt;
(0)&gt;
	</description>
	<comments>
		<comment id='1' author='imgemp' date='2018-06-04T07:42:41Z'>
		&lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 please label this - "Bug", "Operator"
I see that this behavior is not found in other activation functions such as - nd.sigmoid(np.NaN*nd.ones(1)), nd.softmax(np.NaN*nd.ones(1)), nd.tanh(np.NaN*nd.ones(1))
		</comment>
		<comment id='2' author='imgemp' date='2018-10-09T18:36:24Z'>
		&lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
 [Operator]
		</comment>
	</comments>
</bug>