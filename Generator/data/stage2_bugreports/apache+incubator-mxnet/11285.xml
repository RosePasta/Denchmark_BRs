<bug id='11285' author='msharmavikram' open_date='2018-06-14T16:02:11Z' closed_time='2018-07-20T22:49:28Z'>
	<summary>Crash while running gluon image-classification.py example with float16</summary>
	<description>
Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues and bug reports. For non-technical issues and feature requests, feel free to present the information in what you believe is the best form.
For Q &amp; A and discussion, please start a discussion thread at &lt;denchmark-link:https://discuss.mxnet.io&gt;https://discuss.mxnet.io&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

(Brief description of the problem in no more than 2 sentences.)
When trying to train a network (Alexnet and Resnet50) using --dtype float16 I get an error at some point in the training that data type of float32 was expected but got  float16. The issue does not occur if float32 is used for training. Also, there doesn't seem to be a way to train using synthetic data with this example, (ie. the script doesn't accept --benchmark 1) although the Read for the example/image_classification claims its possible.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;----------Python Info----------
Version      : 3.5.2
Compiler     : GCC 5.4.0 20160609
Build        : ('default', 'Nov 23 2017 16:37:01')
Arch         : ('64bit', 'ELF')
------------Pip Info-----------
Version      : 10.0.1
Directory    : /usr/local/lib/python3.5/dist-packages/pip
----------MXNet Info-----------
Version      : 1.3.0
Directory    : /usr/local/lib/python3.5/dist-packages/mxnet
Commit Hash   : b434b8ec18f774c99b0830bd3ca66859212b4911
----------System Info----------
Platform     : Linux-4.13.0-45-generic-x86_64-with-Ubuntu-16.04-xenial
system       : Linux
node         : css-host-8
release      : 4.13.0-45-generic
version      : #50~16.04.1-Ubuntu SMP Wed May 30 11:18:27 UTC 2018
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                40
On-line CPU(s) list:   0-39
Thread(s) per core:    2
Core(s) per socket:    10
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2640 v4 @ 2.40GHz
Stepping:              1
CPU MHz:               1200.189
CPU max MHz:           3400.0000
CPU min MHz:           1200.0000
BogoMIPS:              4799.72
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              25600K
NUMA node0 CPU(s):     0-9,20-29
NUMA node1 CPU(s):     10-19,30-39
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 invpcid_single pti retpoline intel_ppin intel_pt spec_ctrl tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdt_a rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts
----------Network Test----------
Setting timeout: 10
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0255 sec, LOAD: 0.1334 sec.
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0100 sec, LOAD: 0.5690 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.3449 sec, LOAD: 1.6452 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0099 sec, LOAD: 0.3464 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.2326 sec, LOAD: 0.6122 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.3419 sec, LOAD: 2.3122 sec.
&lt;/denchmark-code&gt;

Package used (Python/R/Scala/Julia):
Python3 with MXNET-CU91
For Scala user, please provide: NA

Java version: (java -version)
Maven version: (mvn -version)
Scala runtime if applicable: (scala -version)

For R user, please provide R sessionInfo():
&lt;denchmark-h:h2&gt;Build info (Required if built from source)&lt;/denchmark-h&gt;

Compiler (gcc/clang/mingw/visual studio): NA
MXNet commit hash: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/b434b8ec18f774c99b0830bd3ca66859212b4911&gt;b434b8e&lt;/denchmark-link&gt;

(Paste the output of  here.)
Build config: NA (python package)
(Paste the content of config.mk, or the build command.)
&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

(Paste the complete error message, including stack trace.)
&lt;denchmark-code&gt;INFO:root:[Epoch 0] training: accuracy=1.000000, top_k_accuracy_5=0.990000
INFO:root:[Epoch 0] time cost: 23.480652
Traceback (most recent call last):
  File "../gluon/image_classification.py", line 290, in &lt;module&gt;
    main()
  File "../gluon/image_classification.py", line 274, in main
    train(opt, context)
  File "../gluon/image_classification.py", line 242, in train
    name, val_acc = test(ctx, val_data)
  File "../gluon/image_classification.py", line 166, in test
    outputs.append(net(x))
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 481, in __call__
    out = self.forward(*args)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 821, in forward
    return self.hybrid_forward(ndarray, x, *args, **params)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/model_zoo/vision/resnet.py", line 279, in hybrid_forward
    x = self.features(x)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 481, in __call__
    out = self.forward(*args)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 821, in forward
    return self.hybrid_forward(ndarray, x, *args, **params)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/nn/basic_layers.py", line 117, in hybrid_forward
    x = block(x)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 481, in __call__
    out = self.forward(*args)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py", line 821, in forward
    return self.hybrid_forward(ndarray, x, *args, **params)
  File "/usr/local/lib/python3.5/dist-packages/mxnet/gluon/nn/conv_layers.py", line 133, in hybrid_forward
    act = getattr(F, self._op_name)(x, weight, name='fwd', **self._kwargs)
  File "&lt;string&gt;", line 167, in Convolution
  File "/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py", line 92, in _imperative_invoke
    ctypes.byref(out_stypes)))
  File "/usr/local/lib/python3.5/dist-packages/mxnet/base.py", line 210, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [11:24:02] src/operator/nn/convolution.cc:283: Check failed: (*in_type)[i] == dtype (2 vs. 0) This layer requires uniform type. Expected 'float32' v.s. given 'float16' at 'weight'

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x34d0ea) [0x7fcc47e1a0ea]
[bt] (1) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x34d711) [0x7fcc47e1a711]
[bt] (2) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x59284c) [0x7fcc4805f84c]
[bt] (3) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x26d963f) [0x7fcc4a1a663f]
[bt] (4) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x26e2cad) [0x7fcc4a1afcad]
[bt] (5) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x25ffe99) [0x7fcc4a0cce99]
[bt] (6) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7fcc4a0cd48f]
[bt] (7) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7fccd70f7e20]
[bt] (8) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7fccd70f788b]
[bt] (9) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(_ctypes_callproc+0x49a) [0x7fccd70f201a]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)
&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)

python3 ../gluon/image_classification.py --dataset dummy --gpus 2 --epochs 10  --mode imperative  --model resnet50_v2  --batch-size 128 --log-interval 1 --dtype float16
The error is repeatable with Alexnet with below command - python3 ../gluon/image_classification.py --dataset dummy --gpus 2 --epochs 10  --mode imperative  --model alexnet  --batch-size 128 --log-interval 1 --dtype float16

&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;


Tried on a different machine with different system configuration with new installation of MXNET. Issue persists and is same.

	</description>
	<comments>
		<comment id='1' author='msharmavikram' date='2018-06-14T16:21:53Z'>
		Same issue &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/11284&gt;#11284&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='msharmavikram' date='2018-06-15T18:49:18Z'>
		Thanks for submitting this issue &lt;denchmark-link:https://github.com/msharmavikram&gt;@msharmavikram&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 could you add label "Bug", "Gluon", "Example" here?
		</comment>
		<comment id='3' author='msharmavikram' date='2018-06-19T18:40:42Z'>
		&lt;denchmark-link:https://github.com/rahul003&gt;@rahul003&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='msharmavikram' date='2018-06-23T03:17:26Z'>
		How are you passing data? Have you cast it to float16 if it is not already? Are you using DataLoader?
Can you pull in my changes here and try?
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/10391&gt;#10391&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='msharmavikram' date='2018-07-16T01:31:48Z'>
		I have cloned the most recent version of the mxnet source, to get the latest version of the example. I also installed the latest version of mxnet gpu pip install mxnet-cu90 --pre.
If I run the code with the following command (the only difference only with gpus count - I use only 1 gpu with index 0):
python example/gluon/image_classification.py --dataset dummy --gpus 0 --epochs 10 --mode imperative --model resnet50_v2 --batch-size 128 --log-interval 1 --dtype float16
It works fine all 10 epochs. Here is what I receive in the end:

INFO:root:Epoch[9] Batch [98]	Speed: 63.934812 samples/sec	accuracy=1.000000, top_k_accuracy_5=1.000000
INFO:root:Epoch[9] Batch [99]	Speed: 64.144605 samples/sec	accuracy=1.000000, top_k_accuracy_5=1.000000
INFO:root:[Epoch 9] training: accuracy=1.000000, top_k_accuracy_5=1.000000
INFO:root:[Epoch 9] time cost: 198.581029
INFO:root:[Epoch 9] validation: accuracy=1.000000, top_k_accuracy_5=1.000000
INFO:root:[Epoch 9] Saving checkpoint to resnet50_v2_9_acc_1.0000.params with Accuracy: 1.0000
Average epoch time: 198.65544162856207

		</comment>
		<comment id='6' author='msharmavikram' date='2018-07-18T22:14:59Z'>
		I have created a JIRA to track this issue: &lt;denchmark-link:https://issues.apache.org/jira/browse/MXNET-577&gt;https://issues.apache.org/jira/browse/MXNET-577&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='msharmavikram' date='2018-07-19T20:21:11Z'>
		Confirmed the fix using one GPU. &lt;denchmark-link:https://github.com/msharmavikram&gt;@msharmavikram&lt;/denchmark-link&gt;
 Please let me know if you still see the issue.
		</comment>
		<comment id='8' author='msharmavikram' date='2018-07-20T22:49:27Z'>
		Resolving as it is not reproducible. Please reopen if issue still persist.
		</comment>
	</comments>
</bug>