<bug id='17684' author='Justobe' open_date='2020-02-25T08:22:39Z' closed_time='2020-03-24T10:39:40Z'>
	<summary>The output of the ReLU layer in MXNET is different from that in tensorflow and cntk</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Hi, I encountered a problem when I used keras's MobileNetV1 for image classification task. The prediction result of backend MXNet is different from TensorFlow and CNTK. The input picture is sampled from the ImageNet DataSet.
&lt;denchmark-link:https://user-images.githubusercontent.com/15032308/75228076-619f1200-57ea-11ea-9c8e-e0e28f06b893.png&gt;&lt;/denchmark-link&gt;

The outputs ( Top-1 prediction) of three backends are shown below:
TensorFlow: [('n04209239', 'shower_curtain', 0.5855479)]
CNTK: [('n04209239', 'shower_curtain', 0.58554786)]
MXNet: [('n04525038', 'velvet', 0.0072950013)]
It seems that there is something wrong with MXNet. Then I put image into the model and recorded the ouputs of each layers to see how this happens. It seems that the outputs on CNTK and TensorFlow are very close, but for MXNet, the outputs of a ReLU layer and all the layers after this layer are very different from CNTK and TensorFlow .
The results are attached below.
TensorFlow vs CNTK
&lt;denchmark-link:https://user-images.githubusercontent.com/15032308/75228107-77143c00-57ea-11ea-90bd-9e90ea2e2af8.png&gt;&lt;/denchmark-link&gt;

TensorFlow vs MXNet
&lt;denchmark-link:https://user-images.githubusercontent.com/15032308/75228114-7f6c7700-57ea-11ea-9c36-bc2c63f9843f.png&gt;&lt;/denchmark-link&gt;

MXNet vs CNTK
&lt;denchmark-link:https://user-images.githubusercontent.com/15032308/75228133-8bf0cf80-57ea-11ea-9d6b-d5d7424c42c9.png&gt;&lt;/denchmark-link&gt;

The delta column shows the discrepancy, which is calculated as:
&lt;denchmark-link:https://user-images.githubusercontent.com/15032308/75228177-a9259e00-57ea-11ea-9e8c-d93860de3a37.png&gt;&lt;/denchmark-link&gt;

Based on the results, the deviation seems to be caused by conv1_relu of MXNet backend.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

The code of getting prediction result of each backend  is really simple.
get_prediction.py :
import os
import sys
import numpy as np
from PIL import Image
bk = sys.argv[1]
os.environ['KERAS_BACKEND'] = bk
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

import keras
from keras import backend as K
from keras.applications.imagenet_utils import decode_predictions
print("Using backend :{}".format(K.backend()))


def image_resize(x, shape):
    x_return = []
    for x_test in x:
        tmp = np.copy(x_test)
        img = Image.fromarray(tmp.astype('uint8')).convert('RGB')
        img = img.resize(shape, Image.ANTIALIAS)
        x_return.append(np.array(img))
    return np.array(x_return)

base_model = keras.applications.mobilenet.MobileNet(weights='imagenet', include_top=True, input_shape=(224,224,3))
# base_model.summary()
# print("Done")
adam = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)
base_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])

imagename = 'imagenet-0.png'
img = Image.open(imagename)
img = img.resize((224,224), Image.ANTIALIAS)
x_test = np.array(img)
select_data = np.expand_dims(x_test, axis=0)

prediction = base_model.predict(select_data)
res = decode_predictions(prediction)[0]
print(f"Prediction of {bk}: {res}")
You can run the script like this ():

python get_prediction.py mxnet

Change mxnet to 'tensorflow' and 'cntk'
I provide scripts to get outputs of the middle layers and calculate the difference:
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/files/4248815/mxnet-relu.zip&gt;mxnet-relu.zip&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;

I encountered this problem on mxnet-cu101(Version 1.5.1.post0). When I upgraded mxnet to 1.6, the bug still exists.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


MXNet: mxnet-cu101==1.5.1.post0
keras-mxnet: 2.2.4.2
CUDA: 10.1

You can use the following command to configure the environment
pip install keras-mxnet
pip install mxnet-cu101
pip install tensorflow-gpu==1.14.0
pip install cntk-gpu==2.7
	</description>
	<comments>
		<comment id='1' author='Justobe' date='2020-02-29T11:13:07Z'>
		As given &lt;denchmark-link:https://mxnet.apache.org/api/python/docs/api/gluon/model_zoo/index.html&gt;here&lt;/denchmark-link&gt;
 make sure that you are normalizing your image as below
image = image/255
normalized = mx.image.color_normalize(image,
                                      mean=mx.nd.array([0.485, 0.456, 0.406]),
                                      std=mx.nd.array([0.229, 0.224, 0.225]))
		</comment>
		<comment id='2' author='Justobe' date='2020-02-29T21:37:45Z'>
		&lt;denchmark-link:https://github.com/braindotai&gt;@braindotai&lt;/denchmark-link&gt;


As given here make sure that you are normalizing your image as below

I don't think the normalization is the culprit, if the previous layer outputs match. Keras probably uses the same network weights with all backends.
&lt;denchmark-link:https://github.com/Justobe&gt;@Justobe&lt;/denchmark-link&gt;

I don't have the other frameworks installed, so I can't reproduce this, but my suggestion is:
check the inputs to relu. Since it's a very simple function
&lt;denchmark-code&gt;x * (x &gt; 0)
&lt;/denchmark-code&gt;

it should be easy to check that the output is what it's supposed to be. If it is not, use the input and output of conv1_relu to try to create a reproducible case that doesn't need other frameworks.
		</comment>
		<comment id='3' author='Justobe' date='2020-03-24T10:03:16Z'>
		I could reproduce the difference with your code. However, when I use the output of "conv1_bn" layer as the input of ReLU, the output results of both mxnet and TensorFlow backend are the same. Here is my code:
&lt;denchmark-code&gt;import pickle
import tensorflow as tf
import mxnet as mx
import numpy as np

imagename = 'imagenet-0.png'
with open("output/{}_{}.pkl".format("mxnet",imagename[:-4]), "rb+") as f:
	backend_output_dict = pickle.load(f)
count = 0
for each in backend_output_dict:
	count += 1
	if count == 3: # the 3rd layer is conv1_bn
		input_mxnet = each
		break

with open("output/{}_{}.pkl".format("tensorflow",imagename[:-4]), "rb+") as f:
	backend_output_dict = pickle.load(f)
count = 0
for each in backend_output_dict:
	count += 1
	if count == 3: # the 3rd layer is conv1_bn
		input_tf = each
		break

def delta(x, y):
	x = np.reshape(x, [np.shape(x)[0], -1])
	y = np.reshape(y, [np.shape(y)[0], -1])
	return np.mean(np.abs(x - y), axis=1)

mxoutput = mx.nd.relu(mx.nd.array(input_tf))
tfoutput = tf.nn.relu(input_tf)
print(delta(mxoutput.asnumpy(), tfoutput))

mxoutput2 = mx.nd.relu(mx.nd.array(input_mxnet))
tfoutput2 = tf.nn.relu(input_mxnet)
print(delta(mxoutput2.asnumpy(), tfoutput2))
print(delta(tfoutput, mxoutput2.asnumpy()))
&lt;/denchmark-code&gt;

The output of the code is:
&lt;denchmark-code&gt;[0.]
[0.]
[3.0203162e-06]
&lt;/denchmark-code&gt;

This result is quite different from the result of your code. Therefore, I suppose there might be a problem in Keras.
		</comment>
		<comment id='4' author='Justobe' date='2020-03-24T10:39:40Z'>
		@MonicaGu Thanks for your reply. It seems that the relu of mxnet is bug-free and the inconsistency of two backends may be caused by other factors in Keras. I temporarily closed the issue until I had some new findings.
		</comment>
	</comments>
</bug>