<bug id='7073' author='Almclean' open_date='2017-07-17T14:02:28Z' closed_time='2018-04-06T03:56:23Z'>
	<summary>Segfault when context = mx.gpu() Runs fine when context=mx.cpu()</summary>
	<description>
&lt;denchmark-h:h2&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Amazon Linux Deep Learning 2.3 Jun_2017
Compiler: GCC 4.8.3
Package used (Python/R/Scala/Julia): Python
MXNet version: 0.10.0
Python version and distribution: Python 2.7.12
&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

N/A Segfault
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import mxnet as mx
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

np.random.seed(1337) # for reproducibility

import logging
logging.getLogger().setLevel(logging.DEBUG)

def load_train_data(path):
    df = pd.read_csv(path)
    X = df.values.copy()
    np.random.shuffle(X)
    X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]
    X = np.sqrt(X)
    encoder = LabelEncoder()
    y = encoder.fit_transform(labels).astype(np.int32)
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    return X, y, encoder, scaler

def load_test_data(path, scaler):
    df = pd.read_csv(path)
    X = df.values.copy()
    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)
    X = scaler.transform(X)
    return X, ids

def make_submission(y_prob, ids, encoder, fname):
    with open(fname, 'w') as f:
        f.write('id,')
        f.write(','.join([str(i) for i in encoder.classes_]))
        f.write('\n')
        for i, probs in zip(ids, y_prob):
            probas = ','.join([i] + [str(p) for p in probs.tolist()])
            f.write(probas)
            f.write('\n')
    print("Wrote submission to file {}.".format(fname))

print("Loading data...")

X, y, encoder, scaler = load_train_data('train.csv')
# X_test, ids = load_test_data('test.csv', scaler)

batch_size = 256
ntrain = int(X.shape[0]*0.7)

print(X[:ntrain, :].shape)
print(y[:ntrain].shape)

print(X[ntrain:, :].shape)
print(y[ntrain:].shape)

train_iter = mx.io.NDArrayIter(X[:ntrain, :], y[:ntrain], batch_size, shuffle=True)
val_iter = mx.io.NDArrayIter(X[ntrain:, :], y[ntrain:], batch_size, shuffle=False)

print("Data Loaded.")

print("Building model...")
net = mx.sym.Variable('data')
net = mx.sym.FullyConnected(net, name='fc1', num_hidden=94)
net = mx.sym.Activation(net, name='relu1', act_type="relu")
net = mx.sym.Dropout(net, p=0.5)
net = mx.sym.FullyConnected(net, name='fc2', num_hidden=256)
net = mx.sym.Activation(net, name='relu2', act_type="relu")
net = mx.sym.FullyConnected(net, name='fc3', num_hidden=9)
net = mx.sym.SoftmaxOutput(net, name='softmax')
# mx.viz.plot_network(net)

print("Training model")
num_epoch = 20
learning_rate = 0.08
momentum = 0.9

import logging
logging.getLogger().setLevel(logging.DEBUG)

mod = mx.mod.Module(symbol=net, context=mx.cpu())
mod.fit(
    train_iter,
    eval_data=val_iter,
    optimizer='adam',
    optimizer_params={'learning_rate':learning_rate},
    eval_metric='acc',
    batch_end_callback = mx.callback.Speedometer(batch_size, 100), 
    num_epoch=num_epoch
)

score = mod.score(val_iter, ['ce', 'acc'])
print("Accuracy score is %s" % str((score)))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

Please download the Kaggle test/training data at
&lt;denchmark-link:https://www.kaggle.com/c/otto-group-product-classification-challenge/data&gt;OttoTrainingData&lt;/denchmark-link&gt;


Run the above code python &lt;script_name.py&gt; with context=mx.cpu()
Observe the net trains to completion
Change to context=mx.gpu()
Observe the script segfaults and if configured writes out a core file.

&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;


Running on different AMIs (Both Deep Learning AMIs : Ubuntu and AMZN Linux)
Running on different EC2 instances
Asking colleagues to run the steps - all fail with the same error.

	</description>
	<comments>
		<comment id='1' author='Almclean' date='2017-07-17T16:32:44Z'>
		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 has the fix been rolled out to amis?
		</comment>
		<comment id='2' author='Almclean' date='2017-07-17T16:54:48Z'>
		New AMIs with fix - In progress. Please expect new AMIs by July 24.
Documentation to patch the fixes to existing AMIs - July 19.
&lt;denchmark-link:https://github.com/Almclean&gt;@Almclean&lt;/denchmark-link&gt;
 - &lt;denchmark-link:https://github.com/dmlc/mxnet/tree/v0.10.0-support&gt;https://github.com/dmlc/mxnet/tree/v0.10.0-support&lt;/denchmark-link&gt;

this is a support branch with fixes. If possible, can you please use this by the time we will be releasing new AMIs and patching instructions.
		</comment>
		<comment id='3' author='Almclean' date='2017-07-17T16:55:13Z'>
		Will update the issue with relevant links and references.
		</comment>
		<comment id='4' author='Almclean' date='2017-07-17T17:04:10Z'>
		Perfect, thank you very much.  What is the nature of the problem &lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='5' author='Almclean' date='2017-10-13T06:42:11Z'>
		I faced the same issue when changing the context from mx.cpu() to mx.gpu(0). I'm running this on NVIDIA TX2 board. Was there any fix rolled out for it? What's the exact problem?
		</comment>
		<comment id='6' author='Almclean' date='2018-03-30T17:46:20Z'>
		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 Which fix are we talking about here? Was the issue identified?
		</comment>
		<comment id='7' author='Almclean' date='2018-04-05T22:05:45Z'>
		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
 Please close this issue. I've verified that it doesn't segfault on master now.
		</comment>
	</comments>
</bug>