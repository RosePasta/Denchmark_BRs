<bug id='16653' author='sxjscience' open_date='2019-10-28T07:16:16Z' closed_time='2020-05-22T18:30:32Z'>
	<summary>[Bug][Numpy] The data type of power is not correct</summary>
	<description>
import mxnet as mx
mx.npx.set_np()
a = mx.np.array(2, dtype=mx.np.int32)
b = a ** 3.1
print(b)
Returns
&lt;denchmark-code&gt;8
&lt;/denchmark-code&gt;

In the numpy the result should be:
&lt;denchmark-code&gt;import numpy as np
print(np.array(2) ** 3.1)
&lt;/denchmark-code&gt;

Returns
&lt;denchmark-code&gt;8.574187700290345
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sxjscience' date='2019-10-28T11:28:12Z'>
		I believe  &lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/np_elemwise_broadcast_op.cc#L32&gt;https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/np_elemwise_broadcast_op.cc#L32&lt;/denchmark-link&gt;
  is the root cause of this problem.
Also,  is not the only operator suffering from this bug :
&lt;denchmark-code&gt;&gt;&gt;&gt; from mxnet import np, npx, autograd
&gt;&gt;&gt; npx.set_np()
&gt;&gt;&gt; a = np.array(2, dtype=np.int32)
&gt;&gt;&gt; a
array(2, dtype=int32)
&gt;&gt;&gt; a + 1.1
array(3, dtype=int32)
&lt;/denchmark-code&gt;

The  mechanism introduced in  &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/16631&gt;#16631&lt;/denchmark-link&gt;
 may be a solution to this issue. &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='sxjscience' date='2019-10-28T23:44:47Z'>
		&lt;denchmark-link:https://github.com/xidulu&gt;@xidulu&lt;/denchmark-link&gt;
 yes, the mixed precision binary ops is the effort that aims to solve this kind of problem. Right now we have multiplication between  and all other types, later we'll expand this support to more combinations. &lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='sxjscience' date='2019-10-29T08:03:08Z'>
		This is a known issue of many operators from which floats are expected with integral inputs. Instead of tweaking many TYPE_SWITCH macros to make it work, we plan to solve it using TVM to generate appropriate kernels for integral dtypes.
		</comment>
		<comment id='4' author='sxjscience' date='2019-11-18T19:46:58Z'>
		&lt;denchmark-link:https://github.com/lanking520&gt;@lanking520&lt;/denchmark-link&gt;
 assign &lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='sxjscience' date='2019-12-09T10:18:26Z'>
		The latest master branch today has this behavior:
&lt;denchmark-code&gt;&gt;&gt;&gt; import mxnet as mx
&gt;&gt;&gt; mx.npx.set_np()
&gt;&gt;&gt; a = mx.np.array(2, dtype=mx.np.int32)
&gt;&gt;&gt; b = a ** mx.np.array(3.1, dtype=mx.np.float32)
&gt;&gt;&gt; b
array(8.574187)
&lt;/denchmark-code&gt;

But still has a little bit problem with the scalar case:
&lt;denchmark-code&gt;&gt;&gt;&gt; import mxnet as mx
&gt;&gt;&gt; mx.npx.set_np()
&gt;&gt;&gt; a = mx.np.array(2, dtype=mx.np.int32)
&gt;&gt;&gt; b = a ** 3.1
&gt;&gt;&gt; print(b)
8
&lt;/denchmark-code&gt;

I think this is a new case for the binary scalar op, I'll work on a solution to this.
		</comment>
		<comment id='6' author='sxjscience' date='2020-04-30T06:02:03Z'>
		&lt;denchmark-link:https://github.com/Tommliu&gt;@Tommliu&lt;/denchmark-link&gt;
 is working on this.
		</comment>
		<comment id='7' author='sxjscience' date='2020-05-22T18:30:32Z'>
		closed by &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/18277&gt;#18277&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>