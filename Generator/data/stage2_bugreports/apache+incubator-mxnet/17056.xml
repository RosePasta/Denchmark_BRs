<bug id='17056' author='eric-haibin-lin' open_date='2019-12-13T00:28:46Z' closed_time='2019-12-14T16:28:58Z'>
	<summary>Gluon Trainer does not handle non-deterministic parameter order for distributed training</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Currently gluon Trainer iterates over the parameter dict and assign indices for multi-machine training. The index is used to identify the gradient/parameters. This relies on a deterministic order of param dict iteration and deterministic order of parameter creation. However, that is not be true if the user's code defines parameters in a random order (e.g. &lt;denchmark-link:https://github.com/dmlc/gluon-nlp/blob/v0.9.x/src/gluonnlp/model/attention_cell.py#L223&gt;https://github.com/dmlc/gluon-nlp/blob/v0.9.x/src/gluonnlp/model/attention_cell.py#L223&lt;/denchmark-link&gt;
)
	</description>
	<comments>
	</comments>
</bug>