<bug id='16879' author='liuzh91' open_date='2019-11-21T08:59:51Z' closed_time='2019-11-25T18:07:07Z'>
	<summary>loss for training and evaluation in estimator could be different</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

In current estimator implementation, fit_batch and evaluate_batch use the same loss function.
Code snippet in the fit_batch is shown below:
&lt;denchmark-code&gt;     with autograd.record():
            pred = [self.net(x) for x in data]
            loss = [self.loss(y_hat, y) for y_hat, y in zip(pred, label)]
&lt;/denchmark-code&gt;

The code snippet for evaluate_batch is shown below:
&lt;denchmark-code&gt;        data, label = self._get_data_and_label(val_batch, self.context, batch_axis)
        pred = [self.net(x) for x in data]
        loss = [self.loss(y_hat, y) for y_hat, y in zip(pred, label)]
&lt;/denchmark-code&gt;

both training and evaluation are using the same loss function self.loss to compute the batch loss. In many use cases, it does not hold true. For example, when training LSTM, user may use joint
regularization loss during training whereas standard cross entropy during evaluation.
When writing customized estimator, it is cumbersome to define a new loss when evaluation does not share the same loss with training. So it would be good if estimator api could include two losses: self.train_loss and self.evaluate_loss to tackle different cases separately.
	</description>
	<comments>
		<comment id='1' author='liuzh91' date='2019-11-21T09:30:16Z'>
		How about introducing a new evaluation_loss or evaluate_loss argument to the constructor. If it is None, we use the train loss during evaluation. For backwards compatibility, let's keep self.loss and just introduce a new self.evaluation_loss. What do you think?
Will you open a PR to fix this issue?
		</comment>
		<comment id='2' author='liuzh91' date='2019-11-21T09:49:09Z'>
		
How about introducing a new evaluation_loss or evaluate_loss argument to the constructor. If it is None, we use the train loss during evaluation. For backwards compatibility, let's keep self.loss and just introduce a new self.evaluation_loss. What do you think?
Will you open a PR to fix this issue?

It is viable to do that. I'll fix this issue.
		</comment>
		<comment id='3' author='liuzh91' date='2019-11-25T18:07:27Z'>
		Fixed in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/16888&gt;#16888&lt;/denchmark-link&gt;
, Thanks &lt;denchmark-link:https://github.com/liuzh91&gt;@liuzh91&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>