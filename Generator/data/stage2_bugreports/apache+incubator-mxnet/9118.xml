<bug id='9118' author='marfago' open_date='2017-12-18T06:58:30Z' closed_time='2018-03-20T22:43:13Z'>
	<summary>argmax causes python VM to crash</summary>
	<description>
The code
&lt;denchmark-code&gt;&gt;&gt;&gt; import mxnet.ndarray as nd
&gt;&gt;&gt; A=nd.array([0,1,2])
&gt;&gt;&gt; nd.argmax(A)
&lt;/denchmark-code&gt;

causes python to crash with
&lt;denchmark-code&gt;[22:56:20] /Users/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [22:56:20] src/operator/tensor/./broadcast_reduce_op.h:395: Global reduction not supported yet

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x0000000109af78d8 _ZN4dmlc15LogMessageFatalD2Ev + 40
[bt] (1) 1   libmxnet.so                         0x0000000109af5499 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so                         0x0000000109c4e1f5 _ZN5mxnet2op17SearchAxisComputeIN7mshadow3cpuENS2_3red7maximumEEEvRKN4nnvm9NodeAttrsERKNS_9OpContextERKNSt3__16vectorINS_5TBlobENSD_9allocatorISF_EEEERKNSE_INS_9OpReqTypeENSG_ISL_EEEESK_ + 1941
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='marfago' date='2017-12-18T18:49:43Z'>
		Reproducable in version 0.11.1b20170929),
&lt;denchmark-code&gt;$ pip list | grep mxnet
mxnet (0.11.1b20170929)
$ python
Python 3.6.3 (default, Oct  4 2017, 06:09:15) 
[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from mxnet import nd
&gt;&gt;&gt; A=nd.array([0,1,2])
&gt;&gt;&gt; nd.argmax(A)
[10:40:37] /Users/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [10:40:37] src/operator/tensor/./broadcast_reduce_op.h:352: Global reduction not supported yet

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x000000010d0f7408 _ZN4dmlc15LogMessageFatalD2Ev + 40
[bt] (1) 1   libmxnet.so                         0x000000010d0f4fc9 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so 
&lt;/denchmark-code&gt;

And in version 1.0.0.post1,
&lt;denchmark-code&gt;$ pip list | grep mxnet
mxnet (1.0.0.post1)
$ python
Python 3.6.3 (default, Oct  4 2017, 06:09:15) 
[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from mxnet import nd
&gt;&gt;&gt; A=nd.array([0,1,2])
&gt;&gt;&gt; nd.argmax(A)
[10:45:02] /Users/travis/build/dmlc/mxnet-distro/mxnet-build/dmlc-core/include/dmlc/logging.h:308: [10:45:02] src/operator/tensor/./broadcast_reduce_op.h:396: Global reduction not supported yet

Stack trace returned 10 entries:
[bt] (0) 0   libmxnet.so                         0x0000000105b40898 _ZN4dmlc15LogMessageFatalD2Ev + 40
[bt] (1) 1   libmxnet.so                         0x0000000105b3e599 _ZN4dmlc15LogMessageFatalD1Ev + 9
[bt] (2) 2   libmxnet.so
&lt;/denchmark-code&gt;

Looking at the specified line of code &lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/operator/tensor/broadcast_reduce_op.h#L396&gt;broadcast_reduce_op.h:396&lt;/denchmark-link&gt;
,
  if (!param.axis) LOG(FATAL) &lt;&lt; "Global reduction not supported yet";
It hints that including axis works, which is a pretty stupid error.
&lt;denchmark-code&gt;$ python
Python 3.6.3 (default, Oct  4 2017, 06:09:15) 
[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.37)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from mxnet import nd
&gt;&gt;&gt; A=nd.array([0,1,2])
&gt;&gt;&gt; nd.argmax(A, axis=0)

[ 2.]
&lt;NDArray 1 @cpu(0)&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='marfago' date='2018-03-20T22:28:52Z'>
		tested on 1.1 and confirm that it still crashes
		</comment>
		<comment id='3' author='marfago' date='2018-03-20T22:32:23Z'>
		&lt;denchmark-link:https://github.com/nswamy&gt;@nswamy&lt;/denchmark-link&gt;
 exception handling change went after 1.1 . can you check with master ?
		</comment>
		<comment id='4' author='marfago' date='2018-03-20T22:32:43Z'>
		&lt;denchmark-code&gt;Python 2.7.12 (default, Nov 20 2017, 18:23:56)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import mxnet as mx
&gt;&gt;&gt; A=mx.nd.array([0,1,2])
&gt;&gt;&gt; A

[ 0.  1.  2.]
&lt;NDArray 3 @cpu(0)&gt;
&gt;&gt;&gt; mx.nd.argmax(A)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/ubuntu/sparse_support/mxnet/python/mxnet/ndarray/ndarray.py", line 189, in __repr__
    return '\n%s\n&lt;%s %s @%s&gt;' % (str(self.asnumpy()),
  File "/home/ubuntu/sparse_support/mxnet/python/mxnet/ndarray/ndarray.py", line 1826, in asnumpy
    ctypes.c_size_t(data.size)))
  File "/home/ubuntu/sparse_support/mxnet/python/mxnet/base.py", line 149, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [22:31:57] ../src/operator/tensor/./broadcast_reduce_op.h:392: Global reduction not supported yet

Stack trace returned 10 entries:
[bt] (0) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(dmlc::StackTrace[abi:cxx11]()+0x54) [0x7fbf70eb4337]
[bt] (1) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x2a) [0x7fbf70eb461e]
[bt] (2) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::op::SearchAxisCompute&lt;mshadow::cpu, mshadow::red::maximum&gt;(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)+0xcc) [0x7fbf74e57bb9]
[bt] (3) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;), void (*)(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt;::_M_invoke(std::_Any_data const&amp;, nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)+0x91) [0x7fbf70fe8b6c]
[bt] (4) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt;::operator()(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;) const+0xa6) [0x7fbf755a6f6c]
[bt] (5) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x203) [0x7fbf756f949d]
[bt] (6) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x44) [0x7fbf7570191c]
[bt] (7) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(std::function&lt;void (mxnet::RunContext)&gt;::operator()(mxnet::RunContext) const+0x56) [0x7fbf754b978c]
[bt] (8) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(+0x63c0ec9) [0x7fbf754d5ec9]
[bt] (9) /home/ubuntu/sparse_support/mxnet/python/mxnet/../../build/libmxnet.so(+0x63c2058) [0x7fbf754d7058]


&gt;&gt;&gt; exit()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='marfago' date='2018-03-20T22:43:13Z'>
		&lt;denchmark-link:https://github.com/marfago&gt;@marfago&lt;/denchmark-link&gt;
 closing this ticket as &lt;denchmark-link:https://github.com/anirudh2290&gt;@anirudh2290&lt;/denchmark-link&gt;
 fixed the issue and the VM does not crash anymore.
		</comment>
		<comment id='6' author='marfago' date='2018-05-04T22:30:45Z'>
		&lt;denchmark-link:https://github.com/nswamy&gt;@nswamy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/anirudh2290&gt;@anirudh2290&lt;/denchmark-link&gt;
 what's the commit sha? I'd like to follow this ticket.
		</comment>
		<comment id='7' author='marfago' date='2018-05-05T02:24:32Z'>
		&lt;denchmark-link:https://github.com/laszukdawid&gt;@laszukdawid&lt;/denchmark-link&gt;
 Please see: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/9681&gt;#9681&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>