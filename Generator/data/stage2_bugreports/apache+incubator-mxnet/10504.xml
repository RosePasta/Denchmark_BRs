<bug id='10504' author='jinhuang415' open_date='2018-04-11T14:05:01Z' closed_time='2019-07-25T17:54:52Z'>
	<summary>Can MXNet operator profiling work well using gluon model?</summary>
	<description>
I tried 2 models written in Gluon and try to do operator level profiling, but the generated profile.json doesn't contain any operator information (while it contains MXNET_C_API profiling info), by adding debug in OP level code it is confirmed conv/pooling/Eltwise OP is indeed invoked.
I have set below env variables before start running gluon model but no use (it works well in previous MXNet version):
export MXNET_EXEC_BULK_EXEC_INFERENCE=0
export MXNET_EXEC_BULK_EXEC_TRAIN=0
export MXNET_PROFILER_AUTOSTART=1
Would any MXNet expert help to check if my configurations/steps are correct or if this is an issue for Gluon model profiling? Thanks.
	</description>
	<comments>
		<comment id='1' author='jinhuang415' date='2018-04-11T15:28:24Z'>
		Below is a simple gluon model I used (mainly copied from &lt;denchmark-link:https://mxnet.incubator.apache.org/tutorials/gluon/gluon.html&gt;https://mxnet.incubator.apache.org/tutorials/gluon/gluon.html&lt;/denchmark-link&gt;
, only added wait_to_wait() call at the end in order to make sure OPs are executed):
&lt;denchmark-code&gt;# import dependencies
from __future__ import print_function
import numpy as np
import mxnet as mx
import mxnet.ndarray as F
import mxnet.gluon as gluon
from mxnet.gluon import nn
from mxnet import autograd

class Net(gluon.Block):
    def __init__(self, **kwargs):
        super(Net, self).__init__(**kwargs)
        with self.name_scope():
            # layers created in name_scope will inherit name space
            # from parent layer.
            self.conv1 = nn.Conv2D(6, kernel_size=5)
            self.pool1 = nn.MaxPool2D(pool_size=(2,2))
            self.conv2 = nn.Conv2D(16, kernel_size=5)
            self.pool2 = nn.MaxPool2D(pool_size=(2,2))
            self.fc1 = nn.Dense(120)
            self.fc2 = nn.Dense(84)
            self.fc3 = nn.Dense(10)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))
        # 0 means copy over size from corresponding dimension.
        # -1 means infer size from the rest of dimensions.
        x = x.reshape((0, -1))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = Net()
# Initialize on CPU. Replace with `mx.gpu(0)`, or `[mx.gpu(0), mx.gpu(1)]`,
# etc to use one or more GPUs.
net.collect_params().initialize(mx.init.Xavier(), ctx=mx.cpu())

data = mx.nd.random_normal(shape=(10, 1, 32, 32))  # dummy data
output = net(data)
output.wait_to_read()
&lt;/denchmark-code&gt;

I also attached the generated profile json zip file FYI:
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/files/1899450/profile_gluon.zip&gt;profile_gluon.zip&lt;/denchmark-link&gt;

I tried both CPU and GPU context and the same result.
		</comment>
		<comment id='2' author='jinhuang415' date='2018-04-11T23:21:41Z'>
		&lt;denchmark-link:https://github.com/KellenSunderland&gt;@KellenSunderland&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='jinhuang415' date='2018-04-12T01:37:51Z'>
		Could you use mx.profiler.set_config and set the option profile_all=True, and try again? Note that this is a different way of profiling with more flexibility than MXNET_PROFILER_AUTOSTART, so when you use this don't set that environment variable.
&lt;denchmark-code&gt;mx.profiler.set_config(profile_all=True, filename='profile_output.json')
mx.profiler.set_state('run')

    # Code to be profiled goes here...

mx.profiler.set_state('stop')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='jinhuang415' date='2018-04-12T02:00:08Z'>
		&lt;denchmark-link:https://github.com/rahul003&gt;@rahul003&lt;/denchmark-link&gt;
 Thanks, the way you mentioned works. For the environment variable way,  do we also need to support that when we want to do whole program profiling and don't want to change the code (also keep backward compatible) ?
		</comment>
		<comment id='5' author='jinhuang415' date='2018-04-12T03:00:27Z'>
		Btw, is there any way to selectively do the profiling? Like only perform operator profiling, I asked this because in many cases the generated profile data are very huge (&gt;100MB) if profile all data, it would save a lot of time if we can do profile selectively.
I tried to use mx.profiler.set_config(profile_imperative=True, filename='profile_output.json') to filter operators but seems still all types are profiled.
		</comment>
		<comment id='6' author='jinhuang415' date='2018-04-12T03:06:18Z'>
		For selective profiling, I figured out myself that we need to use mx.profiler.set_config(profile_imperative=True, profile_symbolic=False, profile_memory=False, profile_api=False, filename='profile_output.json') to set related profile types to False since the default type is True.
		</comment>
		<comment id='7' author='jinhuang415' date='2018-04-12T04:09:04Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='jinhuang415' date='2018-04-12T05:47:52Z'>
		&lt;denchmark-link:https://github.com/cjolivier01&gt;@cjolivier01&lt;/denchmark-link&gt;
  We noticed there is profiling enhancement recently, may I know how to get below statistics text output from the profile data? (I see that you pasted this output in another thread but we don't know how to get that)  Thanks.
&lt;denchmark-link:https://user-images.githubusercontent.com/34262351/38658448-d79aa306-3e57-11e8-9ff6-c2594fde7cec.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='jinhuang415' date='2018-04-12T05:52:46Z'>
		Have you tried this ?



incubator-mxnet/python/mxnet/profiler.py


         Line 127
      in
      ceb810c






 def dumps(reset=False): 





		</comment>
		<comment id='10' author='jinhuang415' date='2018-04-12T06:21:39Z'>
		&lt;denchmark-link:https://github.com/rahul003&gt;@rahul003&lt;/denchmark-link&gt;
  thanks for the help, it works, we need first to enable profiler aggregate_stats to True and then use dumps() will work.
&lt;denchmark-code&gt;mx.profiler.set_config(...&lt;other options&gt;..., aggregate_stats=True)
mx.profiler.set_state('run')

&lt;.. application code here ...&gt;

mx.profiler.set_state('stop')
print(mx.profiler.dumps())
&lt;/denchmark-code&gt;

But I found the operator counter is not very accurate, I used the simple gluon model (see above gluon model code), but all operator counters are doubled of actual count (For example, above gluon model only has 2 convolution OPs but the output stats gave 4, the same with other OPs). Looks like an issue here.
		</comment>
		<comment id='11' author='jinhuang415' date='2018-04-12T06:32:14Z'>
		I'd suggest creating an issue so we can track and fix this. If you identify the issue please feel free to submit a PR. Could you check if the counts are the same or different to those in the json file generated in the above steps?
		</comment>
		<comment id='12' author='jinhuang415' date='2018-04-12T09:05:03Z'>
		&lt;denchmark-link:https://github.com/rahul003&gt;@rahul003&lt;/denchmark-link&gt;
  Raised &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/10520&gt;#10520&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='jinhuang415' date='2018-04-19T00:23:22Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
  Can you please add labels-
Python, Gluon, Profiler
		</comment>
		<comment id='14' author='jinhuang415' date='2019-07-24T22:24:32Z'>
		&lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;
  this issue seems resolved. we can probably close. Also, my PR fixed the other issue linked above
		</comment>
	</comments>
</bug>