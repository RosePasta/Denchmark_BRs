<bug id='18022' author='sxjscience' open_date='2020-04-10T19:09:03Z' closed_time='2020-05-09T19:21:25Z'>
	<summary>[Numpy] Weird bug with mixed dtype</summary>
	<description>
Minimal reproducible example:
import mxnet as mx
from mxnet.gluon import nn
import os
os.environ['MXNET_EXEC_INPLACE_GRAD_SUM_CAP'] = '4'
os.environ['DMLC_LOG_STACK_TRACE_DEPTH'] = '20'

mx.npx.set_np()

ctx = mx.gpu()

batch_size = 2
sequence_length = 10

mask = mx.np.random.randint(0, 2, (batch_size, sequence_length), ctx=ctx)
contextual_embeddings = mx.np.random.normal(0, 1, (2, sequence_length, 256), ctx=ctx, dtype=mx.np.float32)

p_mask = 1 - mask

l_start_scores = nn.Dense(1, flatten=False)
l_end_scores = nn.Dense(1, flatten=False)
l_start_scores.initialize(ctx=ctx)
l_end_scores.initialize(ctx=ctx)
with mx.autograd.record():
    start_scores = mx.np.squeeze(l_start_scores(contextual_embeddings), -1)
    start_logits = start_scores * p_mask + (1 - p_mask) * (-1e18)
    contextual_embeddings = mx.np.expand_dims(contextual_embeddings, axis=1)  # (B, 1, T, C)
    end_scores = l_end_scores(contextual_embeddings)
    end_scores = mx.np.squeeze(end_scores, -1)
    p_mask = mx.np.expand_dims(p_mask, axis=-1)
    end_logits = p_mask * end_scores + (1 - p_mask) * -1e18
    end_logits = end_logits * p_mask + (1 - p_mask) * -1e18
    loss = end_logits.sum()
loss.backward()
mx.npx.waitall()
Error:
&lt;denchmark-code&gt;MXNetError: Traceback (most recent call last):
  [bt] (14) /lib/x86_64-linux-gnu/libc.so.6(clone+0x3f) [0x7f1f4f32e88f]
  [bt] (13) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76db) [0x7f1f4eff56db]
  [bt] (12) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xbd6df) [0x7f1e074b96df]
  [bt] (11) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(std::thread::_State_impl&lt;std::thread::_Invoker&lt;std::tuple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt; &gt; &gt;::_M_run()+0x4a) [0x7f1e4cf17caa]
  [bt] (10) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;)+0x4e) [0x7f1e4cf1c70e]
  [bt] (9) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker&lt;(dmlc::ConcurrentQueueType)0&gt;(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock&lt;(dmlc::ConcurrentQueueType)0&gt;*, std::shared_ptr&lt;dmlc::ManualEvent&gt; const&amp;)+0x11d) [0x7f1e4cf1c44d]
  [bt] (8) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::engine::ThreadedEngine::ExecuteOprBlock(mxnet::RunContext, mxnet::engine::OprBlock*)+0x121) [0x7f1e4cf18cb1]
  [bt] (7) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete), mxnet::engine::ThreadedEngine::BulkFlush()::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;, mxnet::engine::CallbackOnComplete&amp;&amp;)+0xba) [0x7f1e4cf111aa]
  [bt] (6) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(std::_Function_handler&lt;void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;)+0x17) [0x7f1e4cfe33f7]
  [bt] (5) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(mxnet::imperative::PushFComp
ute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const+0x1559) [0x7f1e4cfe2cf9]
  [bt] (4) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(std::enable_if&lt;std::is_same&lt;mshadow::gpu, mshadow::gpu&gt;::value, void&gt;::type mxnet::op::BinaryBroadcastBackwardUseNone&lt;mshadow::gpu, mxnet::op::mshadow_op::identity, mxnet::op::mshadow_op::identity&gt;(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)+0x71c) [0x7f1e574fb114]
  [bt] (3) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::op::broadcast::Reduce&lt;mshadow::red::sum, 2, float, mxnet::op::mshadow_op::identity, false&gt;(mshadow::Stream&lt;mshadow::gpu&gt;*, mxnet::TBlob const&amp;, mxnet::OpReqType, mshadow::Tensor&lt;mshadow::gpu, 1, char&gt; const&amp;, mxnet::TBlob const&amp;)+0xc2) [0x7f1e5338f583]
  [bt] (2) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(void mxnet::op::broadcast::ReduceImpl&lt;mshadow::red::sum, 2, float, float, float, mxnet::op::mshadow_op::identity&gt;(CUstream_st*, mxnet::TBlob const&amp;, mxnet::OpReqType, mxnet::TBlob const&amp;, mshadow::Tensor&lt;mshadow::gpu, 1, char&gt; const&amp;, mxnet::op::broadcast::ReduceImplConfig&lt;2&gt; const&amp;)+0x262) [0x7f1e5340f75d]
  [bt] (1) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(float* mxnet::TBlob::dptr&lt;float&gt;() const+0x160) [0x7f1e4ceba0a0]
  [bt] (0) /home/ubuntu/mxnet/python/mxnet/../../build/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x72) [0x7f1e4cd15852]
  File "../include/mxnet/././tensor_blob.h", line 256
MXNetError: Check failed: mshadow: :DataType&lt;DType&gt;::kFlag == type_flag_: TBlob.get_with_shape: data type do not match specified type.Expected: long long v.s. given float
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sxjscience' date='2020-04-10T19:11:24Z'>
		&lt;denchmark-link:https://github.com/ptrendx&gt;@ptrendx&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/haojin2&gt;@haojin2&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
  Are you able to reproduce this one? I came across this issue after solving &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/17989&gt;#17989&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='sxjscience' date='2020-04-10T19:21:05Z'>
		It's a very weird issue. Currently I think one reason is that we haven't correctly handled the mixed dtype:
We will internally call into BackwardUseNone:



incubator-mxnet/src/operator/tensor/elemwise_binary_broadcast_op-inl.cuh


        Lines 37 to 48
      in
      1679ade






 BinaryBroadcastBackwardUseNone(const nnvm::NodeAttrs&amp; attrs, 



 const OpContext&amp; ctx, 



 const std::vector&lt;TBlob&gt;&amp; inputs, 



 const std::vector&lt;OpReqType&gt;&amp; req, 



 const std::vector&lt;TBlob&gt;&amp; outputs) { 



 using namespace broadcast; 



   mxnet::TShape new_lshape, new_rshape, new_oshape; 



 int ndim = BinaryBroadcastShapeCompact(outputs[0].shape_, outputs[1].shape_, inputs[0].shape_, 



                                          &amp;new_lshape, &amp;new_rshape, &amp;new_oshape); 



 if (!ndim) { 



     ElemwiseBinaryOp::BackwardUseNone&lt;gpu, LOP, ROP&gt;(attrs, ctx, inputs, req, outputs); 



   } else { 





However, this operator uses the dtype of the output[0] as the dtype of all the tblobs, which will be wrong:



incubator-mxnet/src/operator/tensor/elemwise_binary_op.h


        Lines 697 to 699
      in
      1679ade






 MSHADOW_TYPE_SWITCH(outputs[0].type_flag_, DType, { 



   BackwardUseNone_&lt;xpu, LOP, ROP, DType&gt;(attrs, ctx, inputs, req, outputs); 



 }); 





Then, we raise the error because some tblobs have different dtypes than DType in BackwardUseNone_:



incubator-mxnet/src/operator/tensor/elemwise_binary_op.h


        Lines 109 to 136
      in
      1679ade






 template&lt;typename xpu, typename LOP, typename ROP, typename DType&gt; 



 static void BackwardUseNone_(const nnvm::NodeAttrs &amp;attrs, 



 const OpContext &amp;ctx, 



 const std::vector&lt;TBlob&gt; &amp;inputs, 



 const std::vector&lt;OpReqType&gt; &amp;req, 



 const std::vector&lt;TBlob&gt; &amp;outputs) { 



 using namespace mxnet_op; 



   Stream&lt;xpu&gt; *s = ctx.get_stream&lt;xpu&gt;(); 



 const int size = static_cast&lt;int&gt;((outputs[0].Size() + DataType&lt;DType&gt;::kLanes - 1) 



                                     / DataType&lt;DType&gt;::kLanes); 



 const DType *ograd_dptr = inputs[0].dptr&lt;DType&gt;(); 



 if (std::is_same&lt;LOP, mshadow_op::identity&gt;::value &amp;&amp; req[0] == kWriteInplace) { 



 CHECK_EQ(ograd_dptr, outputs[0].dptr&lt;DType&gt;()); 



   } else if (req[0] != kNullOp) { 



     DType *lgrad_dptr = outputs[0].dptr&lt;DType&gt;(); 



 MXNET_ASSIGN_REQ_SWITCH(req[0], Req, { 



       Kernel&lt;mxnet_op::op_with_req&lt;LOP, Req&gt;, xpu&gt;::Launch(s, size, lgrad_dptr, ograd_dptr); 



     }); 



   } 



 if (std::is_same&lt;ROP, mshadow_op::identity&gt;::value &amp;&amp; req[1] == kWriteInplace) { 



 CHECK_EQ(ograd_dptr, outputs[1].dptr&lt;DType&gt;()); 



   } else if (req[1] != kNullOp) { 



     DType *rgrad_dptr = outputs[1].dptr&lt;DType&gt;(); 



 MXNET_ASSIGN_REQ_SWITCH(req[1], Req, { 



       Kernel&lt;mxnet_op::op_with_req&lt;ROP, Req&gt;, xpu&gt;::Launch(s, size, rgrad_dptr, ograd_dptr); 



     }); 



   } 



 } 





Important Notice!!
The weird thing is we should have req = kNull for value that has the long long type, which is p_mask in the example above. Thus, it should never try to calculate the gradient of values with the long-long type.
		</comment>
		<comment id='3' author='sxjscience' date='2020-04-10T19:38:04Z'>
		I used the nightly version of MXNet.
		</comment>
		<comment id='4' author='sxjscience' date='2020-04-10T19:56:18Z'>
		Confirmed that this bug exists in the latest master. Also, we can change the ctx to cpu and it still persists.
		</comment>
		<comment id='5' author='sxjscience' date='2020-04-10T23:39:06Z'>
		For this bug, the most weird thing is that it won't raise an error if I commented two lines, i.e., the following one will run well (commented two lines).
import mxnet as mx
from mxnet.gluon import nn
import os
os.environ['MXNET_EXEC_INPLACE_GRAD_SUM_CAP'] = '4'
os.environ['DMLC_LOG_STACK_TRACE_DEPTH'] = '20'

mx.npx.set_np()

ctx = mx.cpu()

batch_size = 2
sequence_length = 10

mask = mx.np.random.randint(0, 2, (batch_size, sequence_length), ctx=ctx)
contextual_embeddings = mx.np.random.normal(0, 1, (2, sequence_length, 256), ctx=ctx, dtype=mx.np.float32)

p_mask = 1 - mask

l_start_scores = nn.Dense(1, flatten=False)
l_end_scores = nn.Dense(1, flatten=False)
l_start_scores.initialize(ctx=ctx)
l_end_scores.initialize(ctx=ctx)
with mx.autograd.record():
    # start_scores = mx.np.squeeze(l_start_scores(contextual_embeddings), -1)
    # start_logits = start_scores * p_mask + (1 - p_mask) * (-1e18)
    contextual_embeddings = mx.np.expand_dims(contextual_embeddings, axis=1)  # (B, 1, T, C)
    end_scores = l_end_scores(contextual_embeddings)
    end_scores = mx.np.squeeze(end_scores, -1)
    p_mask = mx.np.expand_dims(p_mask, axis=-1)
    end_logits = p_mask * end_scores + (1 - p_mask) * -1e18
    end_logits = end_logits * p_mask + (1 - p_mask) * -1e18
    loss = end_logits.sum()
loss.backward()
mx.npx.waitall()
		</comment>
		<comment id='6' author='sxjscience' date='2020-05-09T19:21:25Z'>
		fixed by &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/18250&gt;#18250&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>