<bug id='16942' author='liuzh91' open_date='2019-11-29T04:21:00Z' closed_time='2019-12-13T06:27:40Z'>
	<summary>Validation model can be different from fit model in estimator class</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

In current estimator class implementation, validation model is the same network as the training model self.net. Code of evaluate_batch() is shown below:
&lt;denchmark-code&gt;        data, label = self._get_data_and_label(val_batch, self.context, batch_axis)
        pred = [self.net(x) for x in data]
        loss = [self.evaluation_loss(y_hat, y) for y_hat, y in zip(pred, label)]
&lt;/denchmark-code&gt;

This assumption does not hold true in the general case. It is common to have a different validation model than the training model on many tasks, e.g., the language model.
&lt;denchmark-code&gt;   model_eval = nlp.model.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,
                                  args.tied, args.dropout, args.weight_dropout,
                                  args.dropout_h, args.dropout_i, args.dropout_e)
   model = nlp.model.train.AWDRNN(args.model, len(vocab), args.emsize, args.nhid, args.nlayers,
                                   args.tied, args.dropout, args.weight_dropout,
                                   args.dropout_h, args.dropout_i, args.dropout_e)
&lt;/denchmark-code&gt;

Please refer to (&lt;denchmark-link:https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py#L154&gt;https://github.com/dmlc/gluon-nlp/blob/master/scripts/language_model/word_language_model.py#L154&lt;/denchmark-link&gt;
) for a detailed reference.
	</description>
	<comments>
	</comments>
</bug>