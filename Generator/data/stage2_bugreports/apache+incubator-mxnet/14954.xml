<bug id='14954' author='DickJC123' open_date='2019-05-15T02:18:54Z' closed_time='2019-06-06T21:19:28Z'>
	<summary>broadcast_to() behavior change after new 0D and uninitialized shape support added?</summary>
	<description>
The documentation for broadcast_to(..., shape=&lt;output_shape&gt;,...) suggests that '0' can appear as a placeholder that means 'keep the same dimension as the input' for the given dimension.  However, the C++ code requires -1 for this.  Which is correct?  Are we changing the behavior?  &lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/KellenSunderland&gt;@KellenSunderland&lt;/denchmark-link&gt;

Documentation:
&lt;denchmark-code&gt;Broadcasting is allowed on axes with size 1, such as from (2,1,3,1) to (2,8,3,9). Elements will be duplicated on the broadcasted axes.  For example:

broadcast_to([[1,2,3]], shape=(2,3)) = [[ 1.,  2.,  3.],
                                        [ 1.,  2.,  3.]])

The dimension which you do not want to change can also be kept as 0 which means copy the original value. So with shape=(2,0), we will obtain the same result as in the above example.

Defined in src/operator/tensor/broadcast_reduce_op_value.cc:L262
&lt;/denchmark-code&gt;

But in the C++ code, we have:



incubator-mxnet/src/operator/tensor/broadcast_reduce_op.h


        Lines 380 to 401
      in
      1eba37a






 inline bool BroadcastToShape(const nnvm::NodeAttrs&amp; attrs, 



                              mxnet::ShapeVector *in_attrs, 



                             mxnet::ShapeVector *out_attrs) { 



 CHECK_EQ(in_attrs-&gt;size(), 1U); 



 CHECK_EQ(out_attrs-&gt;size(), 1U); 



   mxnet::TShape&amp; ishape = (*in_attrs)[0]; 



 if (!mxnet::ndim_is_known(ishape)) return false; 



 const BroadcastToParam&amp; param = nnvm::get&lt;BroadcastToParam&gt;(attrs.parsed); 



 CHECK_EQ(ishape.ndim(), param.shape.ndim()) 



     &lt;&lt; "Operand of shape " &lt;&lt; ishape &lt;&lt; " cannot be broadcasted to " &lt;&lt; param.shape; 



   mxnet::TShape oshape = param.shape; 



 for (int i = 0; i &lt; ishape.ndim(); ++i) { 



 if (oshape[i] != -1) { 



 CHECK(ishape[i] == oshape[i] || ishape[i] == 1) 



         &lt;&lt; "Array cannot be broadcasted from " &lt;&lt; ishape &lt;&lt; " to " &lt;&lt; param.shape; 



     } else { 



       oshape[i] = ishape[i]; 



     } 



   } 



 SHAPE_ASSIGN_CHECK(*out_attrs, 0, oshape); 



 return true; 



 } 





For Q &amp; A and discussion, please start a discussion thread at &lt;denchmark-link:https://discuss.mxnet.io&gt;https://discuss.mxnet.io&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

(Brief description of the problem in no more than 2 sentences.)
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;What to do:
1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py
2. Run the script using `python diagnose.py` and paste its output here.

&lt;/denchmark-code&gt;

Package used (Python/R/Scala/Julia):
(I'm using ...)
For Scala user, please provide:

Java version: (java -version)
Maven version: (mvn -version)
Scala runtime if applicable: (scala -version)

For R user, please provide R sessionInfo():
&lt;denchmark-h:h2&gt;Build info (Required if built from source)&lt;/denchmark-h&gt;

Compiler (gcc/clang/mingw/visual studio):
MXNet commit hash:
(Paste the output of git rev-parse HEAD here.)
Build config:
(Paste the content of config.mk, or the build command.)
&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

(Paste the complete error message, including stack trace.)
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)
&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)




&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;





	</description>
	<comments>
		<comment id='1' author='DickJC123' date='2019-05-15T02:18:57Z'>
		Hey, this is the MXNet Label Bot.
Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it.
Here are my recommended labels: Feature
		</comment>
		<comment id='2' author='DickJC123' date='2019-05-15T04:03:03Z'>
		Thanks for reporting this. That was changed by mistake. I will revert this change for broadcast_to and add a unit test for it.
		</comment>
		<comment id='3' author='DickJC123' date='2019-05-15T17:26:14Z'>
		Thank you for fixing this!  Some additional suggestions:

If you allow both 0 and -1 for the output dimension 'wildcard', you probably should update the documentation to reflect this.  Going forward, would you suggest people to use -1 in the shape, with the use of 0 being deprecated?
As you noticed, there's no unit test for this case.  It was a number of the Sockeye unit tests that flushed out the issue for me.  Even after I apply a trial fix to this problem, I still see errors in the Sockeye tests.  I will be investigating these further, but you may want to try your fix against the Sockeye test suite as well.

		</comment>
		<comment id='4' author='DickJC123' date='2019-05-15T18:41:20Z'>
		&lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 Could you point me to the sockeye's specific failing test? Thanks.
		</comment>
		<comment id='5' author='DickJC123' date='2019-05-15T20:04:36Z'>
		I've been running in the top-level sockeye directory python setup.py test.  I saw 22 unit tests fail.  After changing line 392 in the above-posted snippet to:
&lt;denchmark-code&gt; if (oshape[i] != -1  &amp;&amp; oshape[i] != 0) {
&lt;/denchmark-code&gt;

I'm down to 5 tests failing.  I assume you're asking about these 5? They are:
&lt;denchmark-code&gt;test/unit/test_data_io.py::test_parallel_data_set FAILED                 [ 39%]
test/unit/test_data_io.py::test_sharded_parallel_sample_iter FAILED      [ 43%]
test/integration/test_seq_copy_int.py::test_seq_copy ... FAILED [ 97%]
test/integration/test_seq_copy_int.py::test_seq_copy ... FAILED [ 97%]
test/integration/test_seq_copy_int.py::test_seq_copy ...FAILED [ 97%]
&lt;/denchmark-code&gt;

In each case the error is a device_type == 0 (neither cpu nor gpu) on a read-in NDArray.  It's reading in a file that has neither of the 2 magic numbers (so 'legacy' loading) and getting confused (I think) on the reading in of a shape.
		</comment>
		<comment id='6' author='DickJC123' date='2019-05-16T00:07:55Z'>
		The 5 tests that fail do so because the test is trying to save and restore a 2D NDArray with a 0 size for one of the dimensions.  I have not played with numpy compatibility modes for the tests, but in each case the last 3 of the following code lines is causing problems by converting for example (0,1) -&gt; (-1,1):



incubator-mxnet/src/ndarray/ndarray.cc


        Lines 1713 to 1718
      in
      c5265fb






 // load shape 



 mxnet::TShape shape; 



 if (!shape.Load(strm)) return false; 



 if (!Imperative::Get()-&gt;is_np_comp()) { 



 common::ConvertToNumpyShape(&amp;shape); 



 } 





So you might say 'put the 5 tests in numpy_compatibility_mode.'  However, I started thinking about the notion of TShape serialization.  Ideally, the representation (and what it means) should not depend on the mode of the writer.  Why not always save TShapes in the expanded 'numpy_compatibility mode' representation (unknown = -1, known-0 = 0, known-non-zero = N), regardless of the mode of the writer?
The code in ndarray.cc might then be:
&lt;denchmark-code&gt;void NDArray::Save(dmlc::Stream *strm) const {
...
  // save shape
  auto stored_shape = shape_;
  if (!Imperative::Get()-&gt;is_np_comp()) {
    common::ConvertToNumpyShape(&amp;stored_shape);
  }
  stored_shape.Save(strm);
...
}

bool NDArray::Load(dmlc::Stream *strm) {
...
  // load shape
  mxnet::TShape shape;
  if (!shape.Load(strm)) return false;
  if (!Imperative::Get()-&gt;is_np_comp()) {
    common::ConvertToLegacyShape(&amp;shape);
  }
...
} 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='DickJC123' date='2019-05-19T21:35:55Z'>
		&lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 Sorry for the late reply and thanks for the analysis and suggestion. I agree with what you proposed up there. The ndarrays in memory in the backend are indeed as what you described, i.e. -1 means unknown, 0 means known zero size, etc. The conversion to numpy shape in the NDArray's Save function was somehow missed to be implemented. Would you mind submitting a fix or if you are busy, I can take care of it? Thanks.
Another question on side, since zero-size tensors cannot be digested by any operators in MXNet without numpy compatibility mode, what's the purpose of saving zero-size tensors in sockeye's tests?
		</comment>
		<comment id='8' author='DickJC123' date='2019-05-22T03:38:42Z'>
		Sorry for not getting to the review yet (sidetracked preparing issue 15034).  During my review tomorrow, I'll be looking to see that a serialized NDArray (and its shapes) can be interpreted purely on the state of the file, without knowing the 'numpy compatibility mode' of the writer, and without the reader being in a particular mode.  I'm not sure if this can be achieved with the current set of magic numbers.
I'm assuming there's value in being able to save NDArray's with both unknown and 0 dims and dim-sizes going forward.
		</comment>
		<comment id='9' author='DickJC123' date='2019-05-22T04:12:31Z'>
		&lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 The PR14998 only reverts the change on broadcast_to param shape without addressing the problem of loading zero-size ndarrays from files w/ or w/o numpy compatibility. For that, I think you already provided a feasible solution which keeps backward compatibility and we can go for that implementation, either you or I can do it. It's just not clear to me that why in sockeye's unit tests, zero-size tensors are saved since they cannot be in any operators without numpy compatibility.
		</comment>
		<comment id='10' author='DickJC123' date='2019-05-25T02:23:34Z'>
		&lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 I think you're really the one with the best 'big picture' of this new Shape facility, and where the definition is going.  Perhaps you could attempt the fix for the remaining issues with Sockeye unittests?  I picked the first test that I mentioned above and see that it is indeed trying to save/restore NDArrays with 0 dim-sizes:
&lt;denchmark-link:https://github.com/awslabs/sockeye/blob/bb588ecbe874ae29ede33af2709e251910778bb3/test/unit/test_data_io.py#L255-L297&gt;https://github.com/awslabs/sockeye/blob/bb588ecbe874ae29ede33af2709e251910778bb3/test/unit/test_data_io.py#L255-L297&lt;/denchmark-link&gt;

It looks like &lt;denchmark-link:https://github.com/fhieber&gt;@fhieber&lt;/denchmark-link&gt;
 has some involvement with Sockeye.  Are you seeing unittest failures still, even after the latest PR (not yet merged) from &lt;denchmark-link:https://github.com/reminisce&gt;@reminisce&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='11' author='DickJC123' date='2019-05-25T08:14:09Z'>
		&lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 I have submitted the PR reverting the changes in save/load functions. See &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/15073&gt;#15073&lt;/denchmark-link&gt;
 for analysis. Could you please give a review? Thanks.
		</comment>
		<comment id='12' author='DickJC123' date='2019-05-27T06:27:52Z'>
		Hi &lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
,
sorry for seeing this issue only now.
I just checked with latest nightly build of mxnet: all unit tests pass for latest sockeye. The issue I observed with  (Usage in Sockeye here: &lt;denchmark-link:https://github.com/awslabs/sockeye/blob/master/sockeye/layers.py#L378&gt;https://github.com/awslabs/sockeye/blob/master/sockeye/layers.py#L378&lt;/denchmark-link&gt;
) was addressed.
		</comment>
		<comment id='13' author='DickJC123' date='2019-06-06T21:19:28Z'>
		Fixed by
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/15073&gt;#15073&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/14998&gt;#14998&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>