<bug id='18014' author='eric-haibin-lin' open_date='2020-04-10T04:46:00Z' closed_time='2020-10-13T21:04:33Z'>
	<summary>segfault with bytePS</summary>
	<description>
I am using bytepsimage/mxnet docker image to test bytePS. However, I find recent MXNet versions lead to segfault.
Specifically, if i build mxnet-cu100 variant with commit &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/b6b1de092b2bbc6ab7207a98dcb1c08fe67ca14b&gt;b6b1de0&lt;/denchmark-link&gt;
, the following command works:
&lt;denchmark-code&gt;docker pull bytepsimage/mxnet

nvidia-docker run -it --net=host --shm-size=32768m bytepsimage/mxnet bash

# now you are in docker environment
export NVIDIA_VISIBLE_DEVICES=0,1,2,3  # gpus list
export DMLC_WORKER_ID=0 # your worker id
export DMLC_NUM_WORKER=1 # one worker
export DMLC_ROLE=worker 

# the following value does not matter for non-distributed jobs 
export DMLC_NUM_SERVER=1 
export DMLC_PS_ROOT_URI=10.0.0.1 
export DMLC_PS_ROOT_PORT=1234 

bpslaunch python3 /usr/local/byteps/example/mxnet/train_gluon_mnist_byteps.py

&lt;/denchmark-code&gt;

However, if i use commit &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/2f6cdd383abbf46a37b84a5fad013726b5c62169&gt;2f6cdd3&lt;/denchmark-link&gt;
, it gives me segfault.
I used  to build the pip package.
And if I use the latest nightly build, it also gives me segfault
&lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 any idea why?
related issue &lt;denchmark-link:https://github.com/bytedance/byteps/issues/222&gt;bytedance/byteps#222&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='eric-haibin-lin' date='2020-04-10T04:52:35Z'>
		Is there any test case for bytePS to cover this kind of issue?
BTW, is "bytepsimage/mxnet"  the official MXNet?
"I am using bytepsimage/mxnet docker image to test bytePS. "
		</comment>
		<comment id='2' author='eric-haibin-lin' date='2020-04-10T06:39:28Z'>
		bytePS CI only test stable mxnet, not mxnet nightly.
I assume bytepsimage/mxnet uses official mxnet - &lt;denchmark-link:https://github.com/ymjiang&gt;@ymjiang&lt;/denchmark-link&gt;
 please correct me if i'm wrong
		</comment>
		<comment id='3' author='eric-haibin-lin' date='2020-04-10T06:46:52Z'>
		Yes,  uses official mxnet, and not nightly version: &lt;denchmark-link:https://github.com/bytedance/byteps/blob/master/docker/Dockerfile#L46&gt;https://github.com/bytedance/byteps/blob/master/docker/Dockerfile#L46&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='eric-haibin-lin' date='2020-04-10T12:53:16Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ymjiang&gt;@ymjiang&lt;/denchmark-link&gt;
 Sorry, I have no idea because the back trace doesn't provide useful information. Can you try to disable  before running the model?
		</comment>
		<comment id='5' author='eric-haibin-lin' date='2020-04-10T17:12:05Z'>
		I also tried to build both mxnet and bytePS from source, with gcc 7.4, and the following is the stacktrace:
&lt;denchmark-code&gt;BytePS launching worker
warning: Error disabling address space randomization: Operation not permitted
--------------------------------------------------------------------------------
        Layer (type)                                Output Shape         Param #
================================================================================
               Input                              (1, 1, 28, 28)               0
        Activation-1   &lt;Symbol hybridsequential0_conv0_relu_fwd&gt;               0
        Activation-2                             (1, 20, 24, 24)               0
            Conv2D-3                             (1, 20, 24, 24)             520
         MaxPool2D-4                             (1, 20, 12, 12)               0
        Activation-5   &lt;Symbol hybridsequential0_conv1_relu_fwd&gt;               0
        Activation-6                               (1, 50, 8, 8)               0
            Conv2D-7                               (1, 50, 8, 8)           25050
         MaxPool2D-8                               (1, 50, 4, 4)               0
           Flatten-9                                    (1, 800)               0
       Activation-10  &lt;Symbol hybridsequential0_dense0_relu_fwd&gt;               0
       Activation-11                                    (1, 512)               0
            Dense-12                                    (1, 512)          410112
            Dense-13                                     (1, 10)            5130
================================================================================
Parameters in forward computation graph, duplicate included
   Total params: 440812
   Trainable params: 440812
   Non-trainable params: 0
Shared params in forward computation graph: 0
Unique parameters in model: 440812
--------------------------------------------------------------------------------
Thread 1 "python3" received signal SIGSEGV, Segmentation fault.
__GI___pthread_mutex_lock (mutex=0x20) at ../nptl/pthread_mutex_lock.c:65
65      ../nptl/pthread_mutex_lock.c: No such file or directory.
#0  __GI___pthread_mutex_lock (mutex=0x20) at ../nptl/pthread_mutex_lock.c:65
#1  0x00007f283d52f170 in mxnet::engine::ThreadedVar::AppendWriteDependency(mxnet::engine::OprBlock*) () from /mxnet/python/mxnet/../../build/libmxnet.so
#2  0x00007f283d52ad3f in mxnet::engine::ThreadedEngine::Push(mxnet::engine::Opr*, mxnet::Context, int, bool) () from /mxnet/python/mxnet/../../build/libmxnet.so
#3  0x00007f283d527b85 in mxnet::engine::ThreadedEngine::PushAsync(std::function&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, mxnet::FnProperty, int, char const*, bool) () from /mxnet/python/mxnet/../../build/libmxnet.so
#4  0x00007f283d3dbcb1 in MXEnginePushAsync () from /mxnet/python/mxnet/../../build/libmxnet.so
#5  0x00007f271d56618d in byteps::mxnet::byteps_mxnet_push_pull_async (tensor=0x45797570, name=&lt;optimized out&gt;, version=0, priority=0, is_average=&lt;optimized out&gt;) at byteps/mxnet/ops.cc:116
#6  0x00007f28f290edae in ffi_call_unix64 () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#7  0x00007f28f290e71f in ffi_call () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#8  0x00007f28f2b225c4 in _ctypes_callproc () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
#9  0x00007f28f2b22c33 in ?? () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
&lt;/denchmark-code&gt;

setting MXNET_MKLDNN_ENABLED=0 did not help.
		</comment>
		<comment id='6' author='eric-haibin-lin' date='2020-04-10T17:12:28Z'>
		&lt;denchmark-link:https://github.com/ymjiang&gt;@ymjiang&lt;/denchmark-link&gt;
 have you seen this err before? . It shows up when I used gdb though. might not be related to the original problem
Update: Error disabling address space randomization: Operation not permitted is resolved by --security-opt seccomp=unconfined. It does not help the segmentation fault problem
		</comment>
		<comment id='7' author='eric-haibin-lin' date='2020-04-10T17:38:02Z'>
		With &lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
 's help I built mxnet in debug mode with commit &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/2f6cdd383abbf46a37b84a5fad013726b5c62169&gt;2f6cdd3&lt;/denchmark-link&gt;
. Here's the stacktrace with line number:
&lt;denchmark-code&gt;Thread 1 "python3" received signal SIGSEGV, Segmentation fault.
__GI___pthread_mutex_lock (mutex=0x20) at ../nptl/pthread_mutex_lock.c:65
65      ../nptl/pthread_mutex_lock.c: No such file or directory.
#0  __GI___pthread_mutex_lock (mutex=0x20) at ../nptl/pthread_mutex_lock.c:65
#1  0x00007fff5314d857 in __gthread_mutex_lock (__mutex=0x20) at /usr/include/x86_64-linux-gnu/c++/7/bits/gthr-default.h:748
#2  0x00007fff5316b1c6 in std::mutex::lock (this=0x20) at /usr/include/c++/7/bits/std_mutex.h:103
#3  0x00007fff53182d14 in std::lock_guard&lt;std::mutex&gt;::lock_guard (this=0x7fffffffcb30, __m=...) at /usr/include/c++/7/bits/std_mutex.h:162
#4  0x00007fff53359852 in mxnet::engine::ThreadedVar::AppendWriteDependency (this=0x0, opr_block=0x294c2a8) at ../src/engine/threaded_engine.cc:74
#5  0x00007fff53355fd2 in mxnet::engine::ThreadedEngine::Push (this=0x2946590, op=0x294a708, exec_ctx=..., priority=0, profiling=false) at ../src/engine/threaded_engine.cc:311
#6  0x00007fff53356400 in mxnet::engine::ThreadedEngine::PushAsync(std::function&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, mxnet::FnProperty, int, char const*, bool) (this=0x2946590, fn=..., exec_ctx=..., const_vars=std::vector of length 0, capacity 0, mutable_vars=std::vector of length 1, capacity 1 = {...}, prop=mxnet::FnProperty::kCPUPrioritized, priority=0, opr_name=0x7ffe356374ac "BytePSPushPull", wait=false) at ../src/engine/threaded_engine.cc:343
#7  0x00007fff53164592 in MXEnginePushAsync (async_func=0x7ffe355663e0 &lt;byteps::mxnet::DoPushPull(void*, void*, void*)&gt;, func_param=0x40f29520, deleter=0x7ffe35565a30 &lt;byteps::mxnet::(anonymous namespace)::DeletePushPullParam(void*)&gt;, ctx_handle=0x7ffe3bff8a40 &lt;byteps::mxnet::(anonymous namespace)::MX_EXEC_CTX&gt;, const_vars_handle=0x0, num_const_vars=0, mutable_vars_handle=0x7fffffffd168, num_mutable_vars=1, prop_handle=0x7ffe35637540 &lt;byteps::mxnet::(anonymous namespace)::MX_FUNC_PROP&gt;, priority=0, opr_name=0x7ffe356374ac "BytePSPushPull", wait=false) at ../src/c_api/c_api.cc:2482
#8  0x00007ffe3556618d in byteps::mxnet::byteps_mxnet_push_pull_async (tensor=0x409bf190, name=&lt;optimized out&gt;, version=0, priority=0, is_average=&lt;optimized out&gt;) at byteps/mxnet/ops.cc:116
#9  0x00007ffff65a6dae in ffi_call_unix64 () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#10 0x00007ffff65a671f in ffi_call () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#11 0x00007ffff67ba5c4 in _ctypes_callproc () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
#12 0x00007ffff67bac33 in ?? () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='eric-haibin-lin' date='2020-04-10T18:40:46Z'>
		Based on the backtrace, it appears that some mutex may not be initialized correctly leading to segfault?
		</comment>
		<comment id='9' author='eric-haibin-lin' date='2020-04-10T21:15:41Z'>
		another data point: mxnet-cu100 (1.6.0b20200212) works, but mxnet-cu100mkl (1.6.0b20200212) doesn't
		</comment>
		<comment id='10' author='eric-haibin-lin' date='2020-04-10T21:36:00Z'>
		https://repo.mxnet.io/dist/python/cu100/mxnet_cu100-1.6.0-py2.py3-none-manylinux1_x86_64.whl works,
https://repo.mxnet.io/dist/python/cu100mkl/mxnet_cu100mkl-1.6.0-py2.py3-none-manylinux1_x86_64.whl doesn't.
So, the issue has been there for a while ..
		</comment>
		<comment id='11' author='eric-haibin-lin' date='2020-04-11T01:34:24Z'>
		
@ymjiang have you seen this err before? Error disabling address space randomization: Operation not permitted. It shows up when I used gdb though. might not be related to the original problem
Update: Error disabling address space randomization: Operation not permitted is resolved by --security-opt seccomp=unconfined. It does not help the segmentation fault problem

&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 I am not aware of this before. Is there any version of MXNet-MKL that works? I suspect it might be due to some incompatibility between BytePS and MKL, if none of existing MKL works.
		</comment>
		<comment id='12' author='eric-haibin-lin' date='2020-04-11T07:13:22Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ymjiang&gt;@ymjiang&lt;/denchmark-link&gt;
 I still can't see anything related to MKL-DNN operators from the back trace. Agree that there might be some incompatibility issues between MKL-DNN integration and later BytePS integration.
BTW, have you ever tried NaiveEngine? Can we have some clues from there?
		</comment>
		<comment id='13' author='eric-haibin-lin' date='2020-04-11T09:19:12Z'>
		Build latest MXNet w/o MKLDNN also encounter this issue:
&lt;denchmark-code&gt;cmake -DCMAKE_BUILD_TYPE=Debug -DUSE_MKL_IF_AVAILABLE=OFF -DUSE_CUDA=ON -DUSE_MKLDNN=OFF -G Ninja ..
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Thread 1 "python3" received signal SIGSEGV, Segmentation fault.
__GI___pthread_mutex_lock (mutex=0x3a6772617f) at ../nptl/pthread_mutex_lock.c:65
65	../nptl/pthread_mutex_lock.c: No such file or directory.
#0  __GI___pthread_mutex_lock (mutex=0x3a6772617f) at ../nptl/pthread_mutex_lock.c:65
#1  0x00007fa43648b65b in __gthread_mutex_lock (__mutex=0x3a6772617f) at /usr/include/x86_64-linux-gnu/c++/7/bits/gthr-default.h:748
#2  0x00007fa4364adf3a in std::mutex::lock (this=0x3a6772617f) at /usr/include/c++/7/bits/std_mutex.h:103
#3  0x00007fa4364c5bf4 in std::lock_guard&lt;std::mutex&gt;::lock_guard (this=0x7ffd3340e270, __m=...) at /usr/include/c++/7/bits/std_mutex.h:162
#4  0x00007fa4366b2d6e in mxnet::engine::ThreadedVar::AppendWriteDependency (this=0x3a6772615f, opr_block=0x2f08190) at ../src/engine/threaded_engine.cc:74
#5  0x00007fa4366af4f7 in mxnet::engine::ThreadedEngine::Push (this=0x2f053a0, op=0x2f06630, exec_ctx=..., priority=0, profiling=false) at ../src/engine/threaded_engine.cc:311
#6  0x00007fa4366af924 in mxnet::engine::ThreadedEngine::PushAsync(std::function&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)&gt;, mxnet::Context, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, mxnet::FnProperty, int, char const*, bool) (this=0x2f053a0, fn=..., exec_ctx=..., const_vars=std::vector of length 0, capacity 0, mutable_vars=std::vector of length 1, capacity 1 = {...}, prop=mxnet::FnProperty::kCPUPrioritized, priority=0, opr_name=0x7fa2b16372ec "BytePSPushPull", wait=false) at ../src/engine/threaded_engine.cc:343
#7  0x00007fa4364a72f6 in MXEnginePushAsync (async_func=0x7fa2b15659f0 &lt;byteps::mxnet::DoPushPull(void*, void*, void*)&gt;, func_param=0x6ee84170, deleter=0x7fa2b1565040 &lt;byteps::mxnet::(anonymous namespace)::DeletePushPullParam(void*)&gt;, ctx_handle=0x7fa2b7ff8a40 &lt;byteps::mxnet::(anonymous namespace)::MX_EXEC_CTX&gt;, const_vars_handle=0x0, num_const_vars=0, mutable_vars_handle=0x7ffd3340e8a8, num_mutable_vars=1, prop_handle=0x7fa2b1637380 &lt;byteps::mxnet::(anonymous namespace)::MX_FUNC_PROP&gt;, priority=0, opr_name=0x7fa2b16372ec "BytePSPushPull", wait=false) at ../src/c_api/c_api.cc:2665
#8  0x00007fa2b156579d in byteps::mxnet::byteps_mxnet_push_pull_async (tensor=0x6d41f620, name=&lt;optimized out&gt;, version=0, priority=0, is_average=&lt;optimized out&gt;) at byteps/mxnet/ops.cc:116
#9  0x00007fa50630fdae in ffi_call_unix64 () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#10 0x00007fa50630f71f in ffi_call () from /usr/lib/x86_64-linux-gnu/libffi.so.6
#11 0x00007fa5065235c4 in _ctypes_callproc () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
#12 0x00007fa506523c33 in ?? () from /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='eric-haibin-lin' date='2020-04-11T23:05:37Z'>
		&lt;denchmark-link:https://github.com/xinyu-intel&gt;@xinyu-intel&lt;/denchmark-link&gt;
 the pip wheel is built using make. Actually, I'm not sure if there's which version/commit built with cmake that works with BytePS..
		</comment>
		<comment id='15' author='eric-haibin-lin' date='2020-04-12T00:30:50Z'>
		&lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 The communication API uses the PushAsync api from engine, which unfortunately is not supported by the NaiveEngine..
		</comment>
		<comment id='16' author='eric-haibin-lin' date='2020-04-12T00:32:33Z'>
		
@eric-haibin-lin I am not aware of this before. Is there any version of MXNet-MKL that works? I suspect it might be due to some incompatibility between BytePS and MKL, if none of existing MKL works.

&lt;denchmark-link:https://github.com/ymjiang&gt;@ymjiang&lt;/denchmark-link&gt;
 that's possible.. I have not tested BytePS with mxnet-mkl before
		</comment>
		<comment id='17' author='eric-haibin-lin' date='2020-04-19T06:10:55Z'>
		
https://repo.mxnet.io/dist/python/cu100/mxnet_cu100-1.6.0-py2.py3-none-manylinux1_x86_64.whl works,
https://repo.mxnet.io/dist/python/cu100mkl/mxnet_cu100mkl-1.6.0-py2.py3-none-manylinux1_x86_64.whl doesn't.
So, the issue has been there for a while ..

&lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ciyongch&gt;@ciyongch&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/xinyu-intel&gt;@xinyu-intel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/PatricZhao&gt;@PatricZhao&lt;/denchmark-link&gt;
 can someone look into why mxnet-cuxx-mkl build leads to the segfault? This may be a potential blocker for mxnet 1.7. If possible we should also patch it with the mxnet 1.6.1 release
cc &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='eric-haibin-lin' date='2020-04-19T23:15:21Z'>
		Another thing is that even if I build mxnet 1.6.x from source using make as the following (without MKLDNN), running a simple push pull test also leads to segmentation fault:
&lt;denchmark-code&gt;cp make/config.mk .
echo "USE_BLAS=openblas" &gt;&gt;config.mk
echo "ADD_CFLAGS += -I/usr/include/openblas" &gt;&gt;config.mk
echo "USE_CUDA=1" &gt;&gt;config.mk
echo "USE_CUDA_PATH=/usr/local/cuda" &gt;&gt;config.mk
echo "USE_CUDNN=0" &gt;&gt;config.mk
echo "USE_OPENCV=0" &gt;&gt;config.mk
make -j
&lt;/denchmark-code&gt;

I also tried to upgrade to gcc 9 (suggested by &lt;denchmark-link:https://github.com/leezu&gt;@leezu&lt;/denchmark-link&gt;
) but got error including cuda headers:
&lt;denchmark-code&gt;[April 19, 2020, 3:47 PM] Lin, Haibin: /usr/local/cuda/include/crt/host_config.h:129:2: error: #error -- unsupported GNU version! gcc versions later than 7 are not supported!
  129 | #error -- unsupported GNU version! gcc versions later than 7 are not supported!
      |  ^~~~~
In file included from /usr/local/cuda/include/cuda_runtime.h:83,
                 from &lt;command-line&gt;:
/usr/local/cuda/include/crt/host_config.h:129:2: error: #error -- unsupported GNU version! gcc versions later than 7 are not supported!
  129 | #error -- unsupported GNU version! gcc versions later than 7 are not supported!
      |  ^~~~~

&lt;/denchmark-code&gt;

		</comment>
		<comment id='19' author='eric-haibin-lin' date='2020-04-20T00:59:34Z'>
		For cuda 10.1, gcc8 is supported
		</comment>
		<comment id='20' author='eric-haibin-lin' date='2020-04-20T03:00:15Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 based on the comments from &lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/xinyu-intel&gt;@xinyu-intel&lt;/denchmark-link&gt;
, we don't see anything related to MKLDNN. I think bytePS developer should spend some efforts to locate the reason and get back with clear analysis.
		</comment>
		<comment id='21' author='eric-haibin-lin' date='2020-04-20T03:17:36Z'>
		We will investigate this from BytePS-side.
		</comment>
		<comment id='22' author='eric-haibin-lin' date='2020-04-20T06:08:13Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 Could you try this PR? &lt;denchmark-link:https://github.com/bytedance/byteps/pull/244&gt;bytedance/byteps#244&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='eric-haibin-lin' date='2020-04-21T20:57:53Z'>
		&lt;denchmark-link:https://github.com/xinyu-intel&gt;@xinyu-intel&lt;/denchmark-link&gt;
 could the issue you report in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/18014#issuecomment-612375492&gt;#18014 (comment)&lt;/denchmark-link&gt;
 be the same as &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/18090&gt;#18090&lt;/denchmark-link&gt;

BytePS side fixed some bugs that caused a different crash when using MXNet MKLDNN build, so the remaining issue now is only ThreadedEngine.
		</comment>
		<comment id='24' author='eric-haibin-lin' date='2020-04-21T21:42:47Z'>
		
Another thing is that even if I build mxnet 1.6.x from source using make as the following (without MKLDNN), running a simple push pull test also leads to segmentation fault:
cp make/config.mk .
echo "USE_BLAS=openblas" &gt;&gt;config.mk
echo "ADD_CFLAGS += -I/usr/include/openblas" &gt;&gt;config.mk
echo "USE_CUDA=1" &gt;&gt;config.mk
echo "USE_CUDA_PATH=/usr/local/cuda" &gt;&gt;config.mk
echo "USE_CUDNN=0" &gt;&gt;config.mk
echo "USE_OPENCV=0" &gt;&gt;config.mk
make -j

This PR &lt;denchmark-link:https://github.com/bytedance/byteps/pull/244&gt;bytedance/byteps#244&lt;/denchmark-link&gt;
 also resolves the segfault issue when MXNet is built from source with MKLDNN=0.
		</comment>
	</comments>
</bug>