<bug id='19362' author='Zha0q1' open_date='2020-10-16T18:49:11Z' closed_time='2020-10-21T04:28:01Z'>
	<summary>Float16 Argmin/max gives wrong results</summary>
	<description>
import mxnet as mx
from mxnet import np, nd, npx, profiler
import numpy as _np
from mxnet.gluon import HybridBlock

AA = np.random.normal(0, 10, size=(2,5,99999), dtype='float16', ctx=mx.gpu())

BB = np.argmin(AA, 2)
CC = _np.argmin(AA.asnumpy(), 2)

print(BB)
print(CC)
outputs:
&lt;denchmark-code&gt;[              39904               48736               58816
                2708               36896               11056
               45600 9223372036854775807                8020
 9223372036854775807 9223372036854775807 9223372036854775807
 9223372036854775807               34176               30160
               19456 9223372036854775807               12008
 9223372036854775807               52640] @gpu(0)
[39904 48728 58812  2709 36908 11059 45615 69962  8019 68762 83795 96961
 89943 34176 30167 19451 65951 12011 75882 52637]
&lt;/denchmark-code&gt;

This is reproducible on master and 1.7, both on cpu and gpu. This has not been noticed before because in  we were only using very small tensors. I added in a large tensor case yesterday and multiple ci failed &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/19359&gt;#19359&lt;/denchmark-link&gt;
.
This might be a memory alignment issue. We probably also need to see if any other operators are affected too.
&lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Zha0q1' date='2020-10-16T18:50:40Z'>
		I can also reproduce.
		</comment>
	</comments>
</bug>