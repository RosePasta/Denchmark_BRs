<bug id='17893' author='sxjscience' open_date='2020-03-23T19:52:15Z' closed_time='2020-04-15T23:12:30Z'>
	<summary>[Bug][Numpy] Wrong gradient of np.where</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Example 1: Using np.where(array, array, scalar)
import mxnet as mx
mx.npx.set_np()

a = mx.np.array([1, 0, 1])
b = mx.np.array([2, 3, 4])

b.attach_grad()

with mx.autograd.record():
    c = mx.np.where(a, b, -1)
    c.backward()
print(b.grad)
Output: [0. 1. 0.]
Example 2: Using np.where(array, array, array)
import mxnet as mx
mx.npx.set_np()

a = mx.np.array([1, 0, 1])
b = mx.np.array([2, 3, 4])

b.attach_grad()

with mx.autograd.record():
    c = mx.np.where(a, b, mx.np.array([-1, -1, -1]))
    c.backward()
print(b.grad)
Output: [1. 0. 1.]
The second one is correct.
	</description>
	<comments>
		<comment id='1' author='sxjscience' date='2020-03-24T06:16:39Z'>
		&lt;denchmark-link:https://github.com/hgt312&gt;@hgt312&lt;/denchmark-link&gt;
 I think that there might be some issue in the backward + scalar case of where: 

		</comment>
		<comment id='2' author='sxjscience' date='2020-03-24T08:43:26Z'>
		Fixed in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/17899&gt;#17899&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>