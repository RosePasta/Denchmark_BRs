<bug id='15662' author='eric-haibin-lin' open_date='2019-07-26T01:18:25Z' closed_time='2020-09-26T00:16:29Z'>
	<summary>cudnn Dropout reproducibility</summary>
	<description>
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L491-L493&gt;https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L491-L493&lt;/denchmark-link&gt;

The seed of CUDNN dropout does not respect the random seed in mxnet
	</description>
	<comments>
		<comment id='1' author='eric-haibin-lin' date='2019-07-26T01:18:28Z'>
		Hey, this is the MXNet Label Bot.
Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it.
Here are my recommended labels: Cuda, Bug
		</comment>
		<comment id='2' author='eric-haibin-lin' date='2019-07-26T01:41:49Z'>
		I did a quick recursive grep and found several other usages of the rand function. Here is the full list I found (some of these may be correct):

https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L95
https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L491
https://github.com/apache/incubator-mxnet/blob/master/src/operator/random/sampler.h#L110
https://github.com/apache/incubator-mxnet/blob/master/src/operator/rnn-inl.h#L1551
https://github.com/apache/incubator-mxnet/blob/master/src/operator/rnn_impl.h#L159
https://github.com/apache/incubator-mxnet/blob/master/src/operator/rnn_impl.h#L1004
https://github.com/apache/incubator-mxnet/blob/master/src/operator/rnn_impl.h#L1891

		</comment>
		<comment id='3' author='eric-haibin-lin' date='2019-09-02T00:12:22Z'>
		&lt;denchmark-link:https://github.com/ptrendx&gt;@ptrendx&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/DickJC123&gt;@DickJC123&lt;/denchmark-link&gt;
 just FYI
		</comment>
		<comment id='4' author='eric-haibin-lin' date='2019-10-10T21:38:04Z'>
		So all those places should be seeded propperly correct?
		</comment>
		<comment id='5' author='eric-haibin-lin' date='2019-10-11T00:24:51Z'>
		random/sampler.* and rnn_impl.* are for other operators, not dropout. But yes, in general those should also be fixed, and deserve separate github issues
		</comment>
		<comment id='6' author='eric-haibin-lin' date='2019-10-11T05:22:40Z'>
		below is a test case:
&lt;denchmark-code&gt;import mxnet as mx

a = mx.nd.ones((10,10), ctx=mx.gpu())
dropout = mx.gluon.nn.Dropout(0.5)
seed = 1234

mx.random.seed(seed)

with mx.autograd.record():
    b = dropout(a)

mx.random.seed(seed)

with mx.autograd.record():
    c = dropout(a)

print(b)
print(c)
mx.test_utils.assert_almost_equal(b.asnumpy(), c.asnumpy())
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='eric-haibin-lin' date='2019-10-11T05:25:30Z'>
		we need to delay the initialization of the seed in &lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L497&gt;https://github.com/apache/incubator-mxnet/blob/master/src/operator/nn/dropout-inl.h#L497&lt;/denchmark-link&gt;

request a random resource: 

get a random number generator: 

do sampling with the generator: 

		</comment>
		<comment id='8' author='eric-haibin-lin' date='2020-04-23T21:14:39Z'>
		Reopen as fix is reverted due to performance issue.
		</comment>
	</comments>
</bug>