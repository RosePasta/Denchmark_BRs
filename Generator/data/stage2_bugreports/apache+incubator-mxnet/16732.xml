<bug id='16732' author='access2rohit' open_date='2019-11-05T19:19:31Z' closed_time='2019-11-09T02:03:03Z'>
	<summary>MKLDNN-1.0 doesn't support slice operator for Large Tensor</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

when MXNet is built for CPU MKL slice operator doesn't work.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

could not initialize a sub-memory
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Use MXNET cpu build with MKL and MKLDNN enabled from master
&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)

Run command MXNET_TEST_COUNT=1 nosetests --logging-level=DEBUG --verbose -s tests/nightly/test_large_array.py:test_slice

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

Ubuntu 16.04 DeepLearning AMI
We recommend using our script for collecting the diagnositc information. Run the following command and paste the outputs below:
&lt;denchmark-code&gt;curl --retry 10 -s https://raw.githubusercontent.com/dmlc/gluon-nlp/master/tools/diagnose.py | python

# paste outputs here

----------Python Info----------
Version      : 3.6.4
Compiler     : GCC 7.2.0
Build        : ('default', 'Jan 16 2018 18:10:19')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 18.0
Directory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip
----------MXNet Info-----------
/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Version      : 1.6.0
Directory    : /home/ubuntu/incubator-mxnet/python/mxnet
Num GPUs     : 0
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Linux-4.4.0-1095-aws-x86_64-with-debian-stretch-sid
system       : Linux
node         : ip-172-31-82-110
release      : 4.4.0-1095-aws
version      : #106-Ubuntu SMP Wed Sep 18 13:33:48 UTC 2019
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                32
On-line CPU(s) list:   0-31
Thread(s) per core:    2
Core(s) per socket:    16
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz
Stepping:              1
CPU MHz:               2700.882
CPU max MHz:           3000.0000
CPU min MHz:           1200.0000
BogoMIPS:              4600.08
Hypervisor vendor:     Xen
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              46080K
NUMA node0 CPU(s):     0-31
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx xsaveopt
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0127 sec, LOAD: 0.4722 sec.
Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0003 sec, LOAD: 0.3578 sec.
Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.0976 sec, LOAD: 0.0698 sec.
Timing for D2L: http://d2l.ai, DNS: 0.0259 sec, LOAD: 0.1256 sec.
Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.1084 sec, LOAD: 0.1252 sec.
Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0288 sec, LOAD: 0.4309 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0025 sec, LOAD: 0.0944 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0015 sec, LOAD: 0.0324 sec.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='access2rohit' date='2019-11-05T19:20:03Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='access2rohit' date='2019-11-05T19:35:36Z'>
		&lt;denchmark-link:https://github.com/mxnet-label-bot&gt;@mxnet-label-bot&lt;/denchmark-link&gt;
 add [MKLDNN]
		</comment>
		<comment id='3' author='access2rohit' date='2019-11-06T01:35:32Z'>
		&lt;denchmark-link:https://github.com/rongzha1&gt;@rongzha1&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/wuxun-zhang&gt;@wuxun-zhang&lt;/denchmark-link&gt;
  could you take a look ASAP?
		</comment>
		<comment id='4' author='access2rohit' date='2019-11-06T01:41:01Z'>
		&lt;denchmark-link:https://github.com/access2rohit&gt;@access2rohit&lt;/denchmark-link&gt;
 is this a necessary part for r1.6 or we can fix in master?
		</comment>
		<comment id='5' author='access2rohit' date='2019-11-06T01:43:11Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 I am looking into this.
		</comment>
		<comment id='6' author='access2rohit' date='2019-11-06T02:53:19Z'>
		Can't reproduce this case in our skylake machine . Will keep debug
(mxnet) [rongzha1@mlt-skx141 rong_git_mxnet]$ MXNET_TEST_COUNT=1 nosetests --logging-level=DEBUG --verbose -s tests/nightly/test_large_array.py:test_slice
test_large_array.test_slice ... mkldnn_verbose,info,Intel(R) MKL-DNN v1.0.0 (Git Hash 553c23fc020dfda19f8145e92e57b0e40ecdff56),Intel(R) Advanced Vector Extensions 512 (Intel(R) AVX-512) with AVX512BW, AVX512VL, and AVX512DQ extensions
mkldnn_verbose,create,cpu,reorder,simple:any,undef,src_f32:0:blockedðŸ†Žf0 dst_f32::blockedðŸ†Žf0,num:1,1000x49,0.00610352
mkldnn_verbose,exec,cpu,reorder,simple:any,undef,src_f32:0:blockedðŸ†Žf0 dst_f32::blockedðŸ†Žf0,num:1,1000x49,0.092041
ok
		</comment>
		<comment id='7' author='access2rohit' date='2019-11-06T03:02:02Z'>
		&lt;denchmark-link:https://github.com/access2rohit&gt;@access2rohit&lt;/denchmark-link&gt;
 could you add some bt info? thanks
		</comment>
		<comment id='8' author='access2rohit' date='2019-11-06T03:06:04Z'>
		&lt;denchmark-link:https://github.com/rongzha1&gt;@rongzha1&lt;/denchmark-link&gt;
 Have you ever tried to build MXNet with ?
		</comment>
		<comment id='9' author='access2rohit' date='2019-11-06T04:31:42Z'>
		&lt;denchmark-link:https://github.com/TaoLv&gt;@TaoLv&lt;/denchmark-link&gt;
 Yes, we have enabled the int64 flag, building command is .
I also cannot reproduce this issue. However, I found another bug about the offset assignment in slice and will file a PR soon.
		</comment>
		<comment id='10' author='access2rohit' date='2019-11-06T05:43:09Z'>
		Also tested with AWS EC2 m5.8 instance, and found no error (master commit &lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/3c404a512829d2894ffe3612dc3cb29a12a36597&gt;3c404a5&lt;/denchmark-link&gt;
).
&lt;denchmark-code&gt;ubuntu@ip-172-29-133-38:~/incubator-mxnet/tests/nightly$ MXNET_TEST_COUNT=1 nosetests --logging-level=DEBUG --verbose -s test_large_array.py:test_slice
test_large_array.test_slice ... mkldnn_verbose,info,Intel MKL-DNN v1.0.4 (commit a0a87d662edeef38d01db4ac5dd25f59a1f0881f)
mkldnn_verbose,info,Detected ISA is Intel AVX-512 with AVX512BW, AVX512VL, and AVX512DQ extensions
mkldnn_verbose,exec,cpu,reorder,simple:any,undef,src_f32:0:blocked:ab:f0 dst_f32::blocked:ab:f0,num:1,1000x49,0.045166
ok

----------------------------------------------------------------------
Ran 1 test in 1.625s

OK
&lt;/denchmark-code&gt;

Env Configuration:
&lt;denchmark-code&gt;----------Python Info----------
Version      : 3.6.6
Compiler     : GCC 7.2.0
Build        : ('default', 'Jun 28 2018 17:14:51')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 19.3.1
Directory    : /home/ubuntu/anaconda3/lib/python3.6/site-packages/pip
----------MXNet Info-----------
Version      : 1.6.0
Directory    : /home/ubuntu/incubator-mxnet/python/mxnet
Num GPUs     : 0
Hashtag not found. Not installed from pre-built package.
----------System Info----------
Platform     : Linux-4.4.0-1096-aws-x86_64-with-debian-stretch-sid
system       : Linux
node         : ip-172-29-133-38
release      : 4.4.0-1096-aws
version      : #107-Ubuntu SMP Thu Oct 3 01:51:58 UTC 2019
----------Hardware Info----------
machine      : x86_64
processor    : x86_64
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                32
On-line CPU(s) list:   0-31
Thread(s) per core:    2
Core(s) per socket:    16
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 85
Model name:            Intel(R) Xeon(R) Platinum 8175M CPU @ 2.50GHz
Stepping:              4
CPU MHz:               2499.998
BogoMIPS:              4999.99
Hypervisor vendor:     KVM
Virtualization type:   full
L1d cache:             32K
L1i cache:             32K
L2 cache:              1024K
L3 cache:              33792K
NUMA node0 CPU(s):     0-31
Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc aperfmperf tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single kaiser fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f rdseed adx smap clflushopt clwb avx512cd xsaveopt xsavec xgetbv1 ida arat pku
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0013 sec, LOAD: 0.4353 sec.
Timing for GluonNLP GitHub: https://github.com/dmlc/gluon-nlp, DNS: 0.0002 sec, LOAD: 0.5455 sec.
Timing for GluonNLP: http://gluon-nlp.mxnet.io, DNS: 0.1184 sec, LOAD: 0.0858 sec.
Timing for D2L: http://d2l.ai, DNS: 0.0190 sec, LOAD: 0.2150 sec.
Timing for D2L (zh-cn): http://zh.d2l.ai, DNS: 0.0027 sec, LOAD: 0.1508 sec.
Timing for FashionMNIST: https://repo.mxnet.io/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0250 sec, LOAD: 0.4320 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0011 sec, LOAD: 0.1035 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0017 sec, LOAD: 0.0272 sec.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='access2rohit' date='2019-11-06T07:52:30Z'>
		&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;
 I tried with branch v1.6.x &lt;denchmark-link:https://github.com/rongzha1&gt;@rongzha1&lt;/denchmark-link&gt;
 can you try with that branch too.
Also, I never got this message in my run
&lt;denchmark-code&gt;mkldnn_verbose,info,Intel MKL-DNN v1.0.4 (commit a0a87d662edeef38d01db4ac5dd25f59a1f0881f)
mkldnn_verbose,info,Detected ISA is Intel AVX-512 with AVX512BW, AVX512VL, and AVX512DQ extensions
mkldnn_verbose,exec,cpu,reorder,simple:any,undef,src_f32:0:blocked:ab:f0 dst_f32::blocked:ab:f0,num:1,1000x49,0.045166
&lt;/denchmark-code&gt;

It seems this was run on an instance that supports AVX512. Can you try on an instance that has just AVX2 ?
		</comment>
		<comment id='12' author='access2rohit' date='2019-11-06T07:55:32Z'>
		
@access2rohit is this a necessary part for r1.6 or we can fix in master?

&lt;denchmark-link:https://github.com/pengzhao-intel&gt;@pengzhao-intel&lt;/denchmark-link&gt;

Yes, it is very important for Deep Graph Library(DGL) support that relies heavily on  operator.
		</comment>
		<comment id='13' author='access2rohit' date='2019-11-06T07:58:20Z'>
		You can try to use export MKLDNN_VERBOSE=1 to get these logs.
Also I just filed a &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/16737&gt;PR &lt;/denchmark-link&gt;
related to slice op, but not sure if it will resolve this issue. Could you help double check?
		</comment>
		<comment id='14' author='access2rohit' date='2019-11-07T21:36:09Z'>
		PR: &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/16737&gt;#16737&lt;/denchmark-link&gt;

fixes the issue
		</comment>
		<comment id='15' author='access2rohit' date='2019-11-08T01:06:46Z'>
		Glad it works.
		</comment>
	</comments>
</bug>