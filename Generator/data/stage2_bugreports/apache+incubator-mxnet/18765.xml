<bug id='18765' author='chinakook' open_date='2020-07-21T09:25:22Z' closed_time='2020-07-22T06:35:16Z'>
	<summary>Race-condition and crash with SymbolBlock on GPU</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Severe Bug with nn.SymbolBlock when ctx=mx.gpu(0), cpu is OK.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

malloc or free or Segmentation fault error may appears randomly
&lt;denchmark-code&gt;/home/xxxxxx/anaconda3/envs/solo/lib/python3.7/site-packages/mxnet/gluon/block.py:1517: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
        data: None
  input_sym_arg_type = in_param.infer_type()[0]
[17:15:59] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[(1, 256, 56, 56), (1, 512, 28, 28), (1, 1024, 14, 14), (1, 2048, 7, 7)]
malloc(): unsorted double linked list corrupted
[1]    87116 abort (core dumped)  python symbolblockbug.py

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;/home/xxxxxx/anaconda3/envs/solo/lib/python3.7/site-packages/mxnet/gluon/block.py:1517: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
        data: None
  input_sym_arg_type = in_param.infer_type()[0]
[17:21:29] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[(1, 256, 56, 56), (1, 512, 28, 28), (1, 1024, 14, 14), (1, 2048, 7, 7)]

Segmentation fault: 11

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;/home/xxxxxx/anaconda3/envs/solo/lib/python3.7/site-packages/mxnet/gluon/block.py:1517: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
        data: None
  input_sym_arg_type = in_param.infer_type()[0]
[17:23:24] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[(1, 256, 56, 56), (1, 512, 28, 28), (1, 1024, 14, 14), (1, 2048, 7, 7)]
malloc_consolidate(): invalid chunk size
[1]    87701 abort (core dumped)  python symbolblockbug.py

&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

import mxnet as mx
from mxnet import gluon
from mxnet.gluon import nn
import gluoncv as gcv
class NetEncoder(nn.SymbolBlock):
    def __init__(self, **kwargs):
        base_network = gcv.model_zoo.resnet50_v1(pretrained=False)
        outputs = ['stage1_activation2', 'stage2_activation3', 'stage3_activation5',
                            'stage4_activation2']

        inputs, outputs, params = gcv.nn.feature._parse_network(
            base_network, outputs, ['data'], pretrained=False, ctx=mx.cpu(), **kwargs)
        super(NetEncoder, self).__init__(outputs, inputs, params=params)
    
class Foo(nn.HybridBlock):
    def __init__(self):
        super(Foo, self).__init__()
        self.features = NetEncoder()

    def hybrid_forward(self, F, x):
        y = self.features(x)
        return y

a = mx.nd.random.uniform(shape=(1,3,224,224), ctx=mx.gpu(0))

f = Foo()
f.collect_params().initialize()
f.hybridize()
f.collect_params().reset_ctx(mx.gpu(0))
b = f(a)
print([x.shape for x in b])
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


mxnet_cu102-1.7.0b20200719-py2.py3-none-manylinux2014_x86_64
mxnet 2.0 master in April

	</description>
	<comments>
		<comment id='1' author='chinakook' date='2020-07-21T09:37:22Z'>
		Solved. Change the last row to print([x.asnumpy().shape for x in b]).
		</comment>
		<comment id='2' author='chinakook' date='2020-07-21T18:20:04Z'>
		&lt;denchmark-link:https://github.com/chinakook&gt;@chinakook&lt;/denchmark-link&gt;
 thanks for providing a workaround. I think it's still a bug
		</comment>
		<comment id='3' author='chinakook' date='2020-07-21T19:00:16Z'>
		Simpler reproducible example for latest master:
&lt;denchmark-code&gt;import mxnet as mx
from mxnet import gluon
from mxnet.gluon import nn

a = mx.nd.random.uniform(shape=(1,3,224,224))

backbone = gluon.model_zoo.vision.resnet18_v1()
backbone.initialize()
backbone.hybridize()

backbone(a)

# Alternative:
# backbone.reset_ctx(mx.gpu(0))
# b = backbone(a.as_in_context(mx.gpu(0)))
# print([x.shape for x in b])

sym_file, params_file = backbone.export('/tmp/model')

f = gluon.SymbolBlock.imports(sym_file, 'data', params_file)
f.reset_ctx(mx.gpu(0))
b = f(a.as_in_context(mx.gpu(0)))
print([x.shape for x in b])
&lt;/denchmark-code&gt;

It fails with
&lt;denchmark-code&gt;[18:59:34] ../src/storage/storage.cc:198: Using Pooled (Naive) StorageManager for CPU
/home/ubuntu/src/mxnet-master/python/mxnet/gluon/block.py:1723: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
        data: None
  input_sym_arg_type = in_param.infer_type()[0]
[18:59:37] ../src/storage/storage.cc:198: Using Pooled (Naive) StorageManager for GPU
[(1000,)]
[18:59:38] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)

Segmentation fault: 11

zsh: abort (core dumped)  python3 symbolblockbug.py
&lt;/denchmark-code&gt;

However, the following will work:
&lt;denchmark-code&gt;
import mxnet as mx
from mxnet import gluon
from mxnet.gluon import nn

a = mx.nd.random.uniform(shape=(1,3,224,224))

backbone = gluon.model_zoo.vision.resnet18_v1()
backbone.initialize()
backbone.hybridize()

# backbone(a)

# Alternative:
backbone.reset_ctx(mx.gpu(0))
b = backbone(a.as_in_context(mx.gpu(0)))
print([x.shape for x in b])

sym_file, params_file = backbone.export('/tmp/model')

f = gluon.SymbolBlock.imports(sym_file, 'data', params_file)
f.reset_ctx(mx.gpu(0))
b = f(a.as_in_context(mx.gpu(0)))
print([x.shape for x in b])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='chinakook' date='2020-07-21T21:55:15Z'>
		Backtrace
&lt;denchmark-code&gt;#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:51
#1  0x00007ffff70608b1 in __GI_abort () at abort.c:79
#2  0x00007ffff70a9907 in __libc_message (action=action@entry=do_abort, fmt=fmt@entry=0x7ffff71d6dfa "%s\n") at ../sysdeps/posix/libc_fatal.c:181
#3  0x00007ffff70b097a in malloc_printerr (str=str@entry=0x7ffff71d4fe8 "free(): invalid pointer") at malloc.c:5350
#4  0x00007ffff70b7e8c in _int_free (have_lock=0, p=0x7ffcc0a783d8, av=0x7ffff740bc40 &lt;main_arena&gt;) at malloc.c:4157
#5  __GI___libc_free (mem=0x7ffcc0a783e8) at malloc.c:3124
#6  0x00007fff461d3d46 in __gnu_cxx::new_allocator&lt;char&gt;::deallocate (this=0x7ffd81ffde10, __p=0x7ffcc0a783e8 "") at /usr/include/c++/7/ext/new_allocator.h:125
#7  0x00007fff461d2dc3 in std::allocator_traits&lt;std::allocator&lt;char&gt; &gt;::deallocate (__a=..., __p=0x7ffcc0a783e8 "", __n=305) at /usr/include/c++/7/bits/alloc_traits.h:462
#8  0x00007fff461d2178 in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_destroy (this=0x7ffd81ffde10, __size=304)
    at /usr/include/c++/7/bits/basic_string.h:226
#9  0x00007fff461d187a in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::_M_dispose (this=0x7ffd81ffde10)
    at /usr/include/c++/7/bits/basic_string.h:221
#10 0x00007fff461d0318 in std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::~basic_string (this=0x7ffd81ffde10, __in_chrg=&lt;optimized out&gt;)
    at /usr/include/c++/7/bits/basic_string.h:647
#11 0x00007fff5204c784 in mxnet::FusedOp::CompileCode (this=0x555559e922d0,
    code="using DType_output0 = float;\nstatic const int ndim_output0 = 4;\nstatic const int ndim_input_1 = 4;\nusing DType_input_1 = float;\nstatic const int ndim_input_0 = 4;\nusing DType_input_0 = float;\nstatic c"..., kernel_name="elemwise_add_Activation", dev_id=0) at ../src/operator/fusion/fused_op.cu:651
#12 0x00007fff5204df75 in mxnet::FusedOp::Forward&lt;mshadow::gpu&gt; (this=0x555559e922d0, attrs=..., ctx=..., inputs=std::vector of length 2, capacity 2 = {...},
    req=std::vector of length 1, capacity 1 = {...}, outputs=std::vector of length 1, capacity 1 = {...}) at ../src/operator/fusion/fused_op.cu:766
#13 0x00007fff5204eac1 in mxnet::FusedOpForwardGPU (attrs=..., ctx=..., inputs=std::vector of length 2, capacity 2 = {...}, req=std::vector of length 1, capacity 1 = {...},
    outputs=std::vector of length 1, capacity 1 = {...}) at ../src/operator/fusion/fused_op.cu:836
#14 0x00007fff466b3bfb in std::_Function_handler&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;), void (*)(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt;::_M_invoke(std::_Any_data const&amp;, nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;) (__functor=..., __args#0=..., __args#1=...,
    __args#2=std::vector of length 2, capacity 2 = {...}, __args#3=std::vector of length 1, capacity 1 = {...}, __args#4=std::vector of length 1, capacity 1 = {...})
    at /usr/include/c++/7/bits/std_function.h:316
#15 0x00007fff464f09b4 in std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt;::operator()(nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;) const (this=0x555559e6eb20, __args#0=..., __args#1=..., __args#2=std::vector of length 2, capacity 2 = {...}, __args#3=std::vector of length 1, capacity 1 = {...},
    __args#4=std::vector of length 1, capacity 1 = {...}) at /usr/include/c++/7/bits/std_function.h:706
#16 0x00007fff4656a8d6 in mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;)&gt; const&amp;, nnvm::Op const*, nnvm::NodeAttrs const&amp;, mxnet::Context const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}::operator()(mxnet::RunContext) const (__closure=0x555559e6ea90, rctx=...) at ../src/imperative/./imperative_utils.h:494
#17 0x00007fff46572f70 in std::_Function_handler&lt;void (mxnet::RunContext), mxnet::imperative::PushFCompute(std::function&lt;void (nnvm::NodeAttrs const&amp;, mxnet::OpContext const&amp;, std::vector&lt;mxnet::TBlob, std::allocator&lt;mxnet::TBlob&gt; &gt; const&amp;, std::vector&lt;mxnet::Op---Type &lt;return&gt; to continue, or q &lt;return&gt;
to quit---
:engine::Var*, std::allocator&lt;mxnet::engine::Var*&gt; &gt; const&amp;, std::vector&lt;mxnet::Resource, std::allocator&lt;mxnet::Resource&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;mxnet::NDArray*, std::allocator&lt;mxnet::NDArray*&gt; &gt; const&amp;, std::vector&lt;unsigned int, std::allocator&lt;unsigned int&gt; &gt; const&amp;, std::vector&lt;mxnet::OpReqType, std::allocator&lt;mxnet::OpReqType&gt; &gt; const&amp;)::{lambda(mxnet::RunContext)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;) (__functor=...,
    __args#0=...) at /usr/include/c++/7/bits/std_function.h:316
#18 0x00007fff464bd868 in std::function&lt;void (mxnet::RunContext)&gt;::operator()(mxnet::RunContext) const (this=0x555555edb1e0, __args#0=...) at /usr/include/c++/7/bits/std_function.h:706
#19 0x00007fff464c96f6 in mxnet::engine::ThreadedEngine::BulkFlush()::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)#1}::operator()(mxnet::RunContext, mxnet::engine::CallbackOnComplete) const (__closure=0x555559e374b0, ctx=..., on_complete=...)
    at ../src/engine/./threaded_engine.h:537
#20 0x00007fff464ce27b in std::_Function_handler&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete), mxnet::engine::ThreadedEngine::BulkFlush()::{lambda(mxnet::RunContext, mxnet::engine::CallbackOnComplete)#1}&gt;::_M_invoke(std::_Any_data const&amp;, mxnet::RunContext&amp;&amp;, mxnet::engine::CallbackOnComplete&amp;&amp;) (__functor=..., __args#0=..., __args#1=...) at /usr/include/c++/7/bits/std_function.h:316
#21 0x00007fff464be704 in std::function&lt;void (mxnet::RunContext, mxnet::engine::CallbackOnComplete)&gt;::operator()(mxnet::RunContext, mxnet::engine::CallbackOnComplete) const (this=0x555557eedc60, __args#0=..., __args#1=...)
    at /usr/include/c++/7/bits/std_function.h:706
#22 0x00007fff464d70e4 in mxnet::engine::ThreadedEngine::ExecuteOprBlock (this=0x555556fb6980, run_ctx=..., opr_block=0x5555580bd9b0) at ../src/engine/./threaded_engine.h:381
#23 0x00007fff464dcc57 in mxnet::engine::ThreadedEnginePerDevice::GPUWorker&lt;(dmlc::ConcurrentQueueType)0&gt; (this=0x555556fb6980, ctx=..., is_copy_worker=false, block=0x5555570b5b40,
    ready_event=std::shared_ptr&lt;dmlc::ManualEvent&gt; (use count 2, weak count 0) = {...}) at ../src/engine/threaded_engine_perdevice.cc:272
#24 0x00007fff464d8baa in mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}::operator()(dmlc::ManualEvent) const (__closure=0x5555580e8e20,
    ready_event=std::shared_ptr&lt;dmlc::ManualEvent&gt; (use count 2, weak count 0) = {...}) at ../src/engine/threaded_engine_perdevice.cc:186
#25 0x00007fff464dfc9d in std::_Function_handler&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;) (__functor=..., __args#0=...) at /usr/include/c++/7/bits/std_function.h:316
#26 0x00007fff464e088f in std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;::operator()(std::shared_ptr&lt;dmlc::ManualEvent&gt;) const (this=0x555558040268, __args#0=std::shared_ptr&lt;dmlc::ManualEvent&gt; (empty) = {...})
    at /usr/include/c++/7/bits/std_function.h:706
#27 0x00007fff464ddfbf in std::__invoke_impl&lt;void, std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt;(std::__invoke_other, std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;&amp;&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;) (__f=...) at /usr/include/c++/7/bits/invoke.h:60
#28 0x00007fff464d9b7d in std::__invoke&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt;(std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;&amp;&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;) (__fn=...)
    at /usr/include/c++/7/bits/invoke.h:95
#29 0x00007fff464e746b in std::thread::_Invoker&lt;std::tuple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt; &gt;::_M_invoke&lt;0ul, 1ul&gt;(std::_Index_tuple&lt;0ul, 1ul&gt;) (this=0x555558040258) at /usr/include/c++/7/thread:234
#30 0x00007fff464e73d3 in std::thread::_Invoker&lt;std::tuple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt; &gt;::operator()() (this=0x555558040258) at /usr/include/c++/7/thread:243
#31 0x00007fff464e7372 in std::thread::_State_impl&lt;std::thread::_Invoker&lt;std::tuple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt;, std::shared_ptr&lt;dmlc::ManualEvent&gt; &gt; &gt; &gt;::_M_run() (this=0x555558040250) at /usr/include/c++/7/thread:186
#32 0x00007ffff070a6df in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#33 0x00007ffff7bbd6db in start_thread (arg=0x7ffd81fff700) at pthread_create.c:463
#34 0x00007ffff7141a3f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/ptrendx&gt;@ptrendx&lt;/denchmark-link&gt;
 do you think this is a bug in fused op or in the engine?
		</comment>
		<comment id='5' author='chinakook' date='2020-07-21T23:52:51Z'>
		does adding mx.nd.waitall() help?
		</comment>
		<comment id='6' author='chinakook' date='2020-07-22T02:06:47Z'>
		&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 Yes, it does.
		</comment>
		<comment id='7' author='chinakook' date='2020-07-22T02:13:47Z'>
		As I've tested, &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/18768&gt;#18768&lt;/denchmark-link&gt;
 can solve this problem.
		</comment>
	</comments>
</bug>