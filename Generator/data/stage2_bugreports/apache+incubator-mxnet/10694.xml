<bug id='10694' author='lupesko' open_date='2018-04-26T02:03:40Z' closed_time='2018-09-21T23:57:36Z'>
	<summary>Importing an ONNX model (from model zoo) to MXNet errors out</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Importing an ONNX model to MXNet errors out.
Model: &lt;denchmark-link:https://github.com/onnx/models/tree/master/emotion_ferplus&gt;FER+ Emotion Recognition&lt;/denchmark-link&gt;

This may be an issue with the ONNX model itself, but it is on the ONNX model zoo so I assume it is tested regularly.
To reproduce:

Download the ONNX model listed above into the working directory, add signature.json and synset.txt
Use new MXNet ONNX contrib API to import ONNX model into MXNet

Expected result: emotion-detection sym and params are returned
Actual result: errors out
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;----------Python Info----------
Version      : 3.6.4
Compiler     : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)
Build        : ('default', 'Jan 16 2018 12:04:33')
Arch         : ('64bit', '')
------------Pip Info-----------
Version      : 10.0.1
Directory    : /Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/pip
----------MXNet Info-----------
Version      : 1.2.0
Directory    : /Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet
Commit Hash   : 7989782cca64db5469d31713e65d21c8e043bbc0
----------System Info----------
Platform     : Darwin-16.7.0-x86_64-i386-64bit
system       : Darwin
node         : 8c8590170440.ant.amazon.com
release      : 16.7.0
version      : Darwin Kernel Version 16.7.0: Tue Jan 30 11:27:06 PST 2018; root:xnu-3789.73.11~1/RELEASE_X86_64
----------Hardware Info----------
machine      : x86_64
processor    : i386
b'machdep.cpu.extfeatures: SYSCALL XD 1GBPAGE EM64T LAHF LZCNT PREFETCHW RDTSCP TSCI'
b'machdep.cpu.leaf7_features: SMEP ERMS RDWRFSGS TSC_THREAD_OFFSET BMI1 HLE AVX2 BMI2 INVPCID RTM SMAP RDSEED ADX IPT SGX FPU_CSDS MPX CLFSOPT'
b'machdep.cpu.features: FPU VME DE PSE TSC MSR PAE MCE CX8 APIC SEP MTRR PGE MCA CMOV PAT PSE36 CLFSH DS ACPI MMX FXSR SSE SSE2 SS HTT TM PBE SSE3 PCLMULQDQ DTES64 MON DSCPL VMX SMX EST TM2 SSSE3 FMA CX16 TPR PDCM SSE4.1 SSE4.2 x2APIC MOVBE POPCNT AES PCID XSAVE OSXSAVE SEGLIM64 TSCTMR AVX1.0 RDRAND F16C'
b'machdep.cpu.brand_string: Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz'
----------Network Test----------
Setting timeout: 10
Timing for MXNet: https://github.com/apache/incubator-mxnet, DNS: 0.0187 sec, LOAD: 0.6492 sec.
Timing for Gluon Tutorial(en): http://gluon.mxnet.io, DNS: 0.0438 sec, LOAD: 0.1820 sec.
Timing for Gluon Tutorial(cn): https://zh.gluon.ai, DNS: 0.0206 sec, LOAD: 1.0483 sec.
Timing for FashionMNIST: https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz, DNS: 0.0231 sec, LOAD: 0.1971 sec.
Timing for PYPI: https://pypi.python.org/pypi/pip, DNS: 0.0180 sec, LOAD: 0.3810 sec.
Timing for Conda: https://repo.continuum.io/pkgs/free/, DNS: 0.0190 sec, LOAD: 0.1072 sec.```
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;File "/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_model.py", line 53, in import_model
    sym, arg_params, aux_params = graph.from_onnx(model_proto.graph)
  File "/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py", line 114, in from_onnx
    mxnet_sym = self._convert_operator(node_name, op_name, onnx_attr, inputs)
  File "/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/import_onnx.py", line 58, in _convert_operator
    op_name, new_attrs, inputs = convert_map[op_name](attrs, inputs, self)
  File "/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/op_translations.py", line 216, in conv
    new_attrs = translation_utils._fix_channels('Convolution', new_attrs, inputs, cls)
  File "/Users/hag/anaconda/envs/mms-onnx-talk-3-6/lib/python3.6/site-packages/mxnet/contrib/onnx/_import/translation_utils.py", line 172, in _fix_channels
    raise ValueError("Unable to get channels/units attr from onnx graph.")
ValueError: Unable to get channels/units attr from onnx graph.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='lupesko' date='2018-04-26T02:07:07Z'>
		&lt;denchmark-link:https://github.com/anirudhacharya&gt;@anirudhacharya&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/spidyDev&gt;@spidyDev&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Roshrini&gt;@Roshrini&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='lupesko' date='2018-04-26T03:07:10Z'>
		These are the tests running on onnx CI with the latest master - &lt;denchmark-link:https://github.com/onnx/onnx/blob/master/onnx/backend/test/case/model/__init__.py#L39&gt;https://github.com/onnx/onnx/blob/master/onnx/backend/test/case/model/__init__.py#L39&lt;/denchmark-link&gt;
.
ONNX v1.1 which we are using for our tests has one less than the list. This error is occurring while translating the convolution operator, and it would seem the translator is unable to find the channel information in the ONNX graph. But have to take a closer look.
Following two models have been added since the v1.1 release -

emotion_ferplus
tiny yolo

		</comment>
		<comment id='3' author='lupesko' date='2018-04-26T06:00:59Z'>
		&lt;denchmark-link:https://github.com/onnx/models/tree/master/emotion_ferplus&gt;FER+ Emotion Recognition&lt;/denchmark-link&gt;
 is using legacy attribute for convolution , , which we do not support.
auto_pad : string
auto_pad must be either SAME_UPPER, SAME_LOWER or VALID. Where SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
		</comment>
		<comment id='4' author='lupesko' date='2018-04-27T05:48:32Z'>
		Thanks &lt;denchmark-link:https://github.com/spidyDev&gt;@spidyDev&lt;/denchmark-link&gt;
.
Closing.
		</comment>
		<comment id='5' author='lupesko' date='2018-04-27T21:39:55Z'>
		&lt;denchmark-link:https://github.com/spidyDev&gt;@spidyDev&lt;/denchmark-link&gt;
 can you create an issue &lt;denchmark-link:https://github.com/onnx/models/issues&gt;onnx-models repo&lt;/denchmark-link&gt;
 saying that the repo contains models with deprecated operators?
Because the repository README says that "any implementation of ONNX needs to support these models out of the box".
		</comment>
	</comments>
</bug>