<bug id='18373' author='sxjscience' open_date='2020-05-20T08:51:22Z' closed_time='2020-05-31T16:44:17Z'>
	<summary>[Numpy] The symbolic export of BatchNorm is wrong</summary>
	<description>
import mxnet as mx
import json
import pprint
mx.npx.set_np()
net = mx.gluon.nn.BatchNorm(epsilon=2E-5, axis=2)
net.hybridize()
net.initialize()
a = net(mx.np.ones((10, 3, 5, 5)))
net.export('bnorm', 0)
with open('bnorm-symbol.json') as f:
   dat = json.load(f)
   pprint.pprint(dat)
Output:
&lt;denchmark-code&gt;           {'attrs': {'__profiler_scope__': 'batchnorm0:',
                      'axis': '1',
                      'eps': '1e-05',
                      'fix_gamma': 'False',
                      'momentum': '0.9',
                      'use_global_stats': 'False'},
            'inputs': [[0, 0, 0], [1, 0, 0], [2, 0, 0], [3, 0, 1], [4, 0, 1]],
            'name': 'batchnorm0_fwd',
            'op': 'BatchNorm'}]}
&lt;/denchmark-code&gt;

We can find that eps and axis are not stored.
	</description>
	<comments>
		<comment id='1' author='sxjscience' date='2020-05-20T17:52:25Z'>
		I find that issue does not only happen in numpy but also exists in ndarray:
import mxnet as mx
import json
import pprint
#mx.npx.set_np()
net = mx.gluon.nn.BatchNorm(epsilon=2E-5, axis=2)
net.hybridize()
net.initialize()
a = net(mx.nd.ones((10, 3, 5, 5)))
net.export('bnorm', 0)
with open('bnorm-symbol.json') as f:
   dat = json.load(f)
   pprint.pprint(dat)
Output:
&lt;denchmark-code&gt;           {'attrs': {'__profiler_scope__': 'batchnorm0:',
                      'axis': '1',
                      'eps': '1e-05',
                      'fix_gamma': 'False',
                      'momentum': '0.9',
                      'use_global_stats': 'False'},
            'inputs': [[0, 0, 0], [1, 0, 0], [2, 0, 0], [3, 0, 1], [4, 0, 1]],
            'name': 'batchnorm0_fwd',
            'op': 'BatchNorm'}]}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='sxjscience' date='2020-06-05T00:01:45Z'>
		Hi &lt;denchmark-link:https://github.com/sxjscience&gt;@sxjscience&lt;/denchmark-link&gt;
 , is it available to delete the pre-built pip packages impacted by this issue?
BatchNorm is universally used, and this bug will not raise any exception. Users may install the previous version of MXNet with this bug, and find that the accuracy drops.
		</comment>
		<comment id='3' author='sxjscience' date='2020-06-05T00:05:17Z'>
		&lt;denchmark-link:https://github.com/wkcn&gt;@wkcn&lt;/denchmark-link&gt;
 Yes, this is a disaster for the users. However, deleting the pre-built pip packages is also not a good option because there are users that are not using BatchNorm. We will need to ensure that the official 1.7 release does not contain this bug.
		</comment>
		<comment id='4' author='sxjscience' date='2020-06-05T00:48:52Z'>
		cc &lt;denchmark-link:https://github.com/ciyongch&gt;@ciyongch&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='sxjscience' date='2020-06-05T02:11:43Z'>
		Hi &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
, v1.7.x doesn't include the PR &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/17679&gt;#17679&lt;/denchmark-link&gt;
 (it's a new feature after code freeze), so there's no such issue on this branch. While for v1.x branch, the fix were already cherry-picked.
I just check the latest commit of both v1.7.x and v1.x branches with the above reproducer, it works well. So no action is needed for this case.
&lt;denchmark-code&gt;           {'attrs': {'axis': '2',
                      'eps': '2e-05',
                      'fix_gamma': 'False',
                      'momentum': '0.9',
                      'use_global_stats': 'False'},
            'inputs': [[0, 0, 0], [1, 0, 0], [2, 0, 0], [3, 0, 1], [4, 0, 1]],
            'name': 'batchnorm0_fwd',
            'op': 'BatchNorm'}]}
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>