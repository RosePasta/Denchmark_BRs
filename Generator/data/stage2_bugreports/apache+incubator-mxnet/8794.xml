<bug id='8794' author='SumNeuron' open_date='2017-11-23T09:43:25Z' closed_time='2018-07-23T18:48:09Z'>
	<summary>GPU throws out of index error?</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

(Brief description of the problem in no more than 2 sentences.)
I have two files:

VAE.py which defines a variational auto encoder
vae_test.py which loads these classes and runs mnist on it

now when I set the context to cpu things run.
when I set the context to gpu things break (error and files pasted below).
I have previously used mxnet with gpus on this machine. So I am a bit confused...
&lt;denchmark-h:h1&gt;VAE.py&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import mxnet as mx
from mxnet import nd, gluon, autograd
from mxnet.gluon import nn, utils


def sample_gaussian(mu, lv, batch_size, latent_z):
    epsilon = nd.random_normal(0, 1, shape=(batch_size, latent_z))
    sigma = nd.sqrt(nd.exp(lv))
    z = mu + nd.multiply(sigma, epsilon)
    return z

class VAEEncoder(gluon.Block):
    def __init__(self, latent_z=100, **kwargs):
        super(VAEEncoder, self).__init__(**kwargs)
        with self.name_scope():
            self.enc = nn.Sequential()
            with self.enc.name_scope():
                self.enc.add(nn.Dense(28*28, activation='relu'))
                self.enc.add(nn.Dense(128, activation='relu'))
                self.enc.add(nn.Activation(activation='tanh'))

            self.mu = nn.Dense(latent_z) # mu = mean
            self.lv = nn.Dense(latent_z) # lv = log variance

    def forward(self, x):
        x = self.enc(x)
        mu = self.mu(x)
        lv = self.lv(x)
        return mu, lv

    def net_init(self, ctx):
        self.enc.initialize(ctx=ctx)


class VAEDecoder(gluon.Block):
    def __init__(self, latent_z=100, **kwargs):
        super(VAEDecoder, self).__init__(**kwargs)
        with self.name_scope():
            self.dec = nn.Sequential()
            self.dec.add(nn.Dense(128, in_units=latent_z, activation='relu'))
            self.dec.add(nn.Dense(28*28))
            self.dec.add(nn.Activation(activation='tanh'))


    def forward(self, x):
        x = self.dec(x)
        return x

    def net_init(self, ctx):
        self.dec.initialize(ctx=ctx)

class VAE(gluon.Block):
    def __init__(self, latent_z=100, batch_size=1,  **kwargs):
        super(VAE, self).__init__(**kwargs)
        with self.name_scope():
            self.enc = VAEEncoder(latent_z=latent_z)
            self.dec = VAEDecoder(latent_z=latent_z)
            self.latent_z = latent_z
            self.batch_size = batch_size

    def forward(self, x):
        mu, lv = self.enc(x)
        z = sample_gaussian(mu, lv, self.batch_size, self.latent_z)
        y = self.dec(z)
        return y, mu, lv


def vae_loss(x, y, mu, lv):
    l2 = gluon.loss.L2Loss()
    bce = l2(y, x) # MSE loss
    bce = nd.sum(bce)
    # loss = 0.5 sum(1-log(sigma^2)+mu^2+sigma^2)
    kld_el = (nd.power(mu, 2) + nd.exp(lv)) * -1 + 1 + lv
    kld = nd.sum(kld_el) * (-0.5)
    return bce + kld


&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;vae_test.py&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import mxnet as mx
from mxnet import nd, gluon, autograd
from mxnet.gluon import nn, utils

from VAE import VAE, vae_loss


use_gpu = False

latent_z = 100
batch_size = 128
learning_rate = 0.001
epochs = 20

ctx = mx.gpu() if use_gpu else mx.cpu()


mnist = mx.test_utils.get_mnist()
flattened_training_data = mnist["train_data"].reshape(60000, 28*28)
data_iter = mx.io.NDArrayIter(flattened_training_data, mnist['train_label'], batch_size=batch_size, shuffle=True)

vae = VAE(latent_z=latent_z)
vae.collect_params().initialize(ctx=ctx)

vae_trainer = gluon.Trainer(vae.collect_params(), 'adam', {'learning_rate': learning_rate})


for epoch in range(epochs):
    train_loss = 0
    data_iter.reset()
    for batch_index, batch in enumerate(data_iter):
        data = batch.data[0]
        with mx.autograd.record():
            y, mu, lv = vae(data)
            loss = vae_loss(data, y, mu, lv)
        loss.backward()
        train_loss += loss.asscalar()
        vae_trainer.step(batch_size)
        
        if batch_index % 100 == 0:
            print('Epoch {}\tBatch {}\tLoss {}'.format(epoch, batch_index, train_loss))
        
        
&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;Error when ctx=mx.gpu()&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-7-4d9d0712ffcd&gt; in &lt;module&gt;()
      5         data = batch.data[0]
      6         with mx.autograd.record():
----&gt; 7             y, mu, lv = vae(data)
      8             loss = vae_loss(data, y, mu, lv)
      9         loss.backward()

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in __call__(self, *args)
    288     def __call__(self, *args):
    289         """Calls forward. Only accepts positional arguments."""
--&gt; 290         return self.forward(*args)
    291 
    292     def forward(self, *args):

~/Programming/edge_repos/detexon/vaegan/VAE.py in forward(self, x)
     64 
     65     def forward(self, x):
---&gt; 66         mu, lv = self.enc(x)
     67         z = sample_gaussian(mu, lv, self.batch_size, self.latent_z)
     68         y = self.dec(z)

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in __call__(self, *args)
    288     def __call__(self, *args):
    289         """Calls forward. Only accepts positional arguments."""
--&gt; 290         return self.forward(*args)
    291 
    292     def forward(self, *args):

~/Programming/edge_repos/detexon/vaegan/VAE.py in forward(self, x)
     26 
     27     def forward(self, x):
---&gt; 28         x = self.enc(x)
     29         mu = self.mu(x)
     30         lv = self.lv(x)

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in __call__(self, *args)
    288     def __call__(self, *args):
    289         """Calls forward. Only accepts positional arguments."""
--&gt; 290         return self.forward(*args)
    291 
    292     def forward(self, *args):

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/nn/basic_layers.py in forward(self, x)
     48     def forward(self, x):
     49         for block in self._children:
---&gt; 50             x = block(x)
     51         return x
     52 

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in __call__(self, *args)
    288     def __call__(self, *args):
    289         """Calls forward. Only accepts positional arguments."""
--&gt; 290         return self.forward(*args)
    291 
    292     def forward(self, *args):

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in forward(self, x, *args)
    466                     return self._call_cached_op(x, *args)
    467                 try:
--&gt; 468                     params = {i: j.data(ctx) for i, j in self._reg_params.items()}
    469                 except DeferredInitializationError:
    470                     self.infer_shape(x, *args)

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in &lt;dictcomp&gt;(.0)
    466                     return self._call_cached_op(x, *args)
    467                 try:
--&gt; 468                     params = {i: j.data(ctx) for i, j in self._reg_params.items()}
    469                 except DeferredInitializationError:
    470                     self.infer_shape(x, *args)

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/parameter.py in data(self, ctx)
    359         NDArray on ctx
    360         """
--&gt; 361         return self._check_and_get(self._data, ctx)
    362 
    363     def list_data(self):

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/parameter.py in _check_and_get(self, arr_list, ctx)
    148                 else:
    149                     ctx = context.current_context()
--&gt; 150             idx = self._ctx_map[ctx.device_typeid][ctx.device_id]
    151             if idx is not None:
    152                 return arr_list[idx]

IndexError: list index out of range
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='SumNeuron' date='2017-11-23T13:56:01Z'>
		Please try data.as_in_context(ctx).
		</comment>
		<comment id='2' author='SumNeuron' date='2017-11-23T14:03:13Z'>
		doing just that results in:
&lt;denchmark-code&gt;MXNetError                                Traceback (most recent call last)
&lt;ipython-input-7-8070ef786604&gt; in &lt;module&gt;()
      5         data = batch.data[0].as_in_context(ctx)
      6         with mx.autograd.record():
----&gt; 7             y, mu, lv = vae(data)
      8             loss = vae_loss(data, y, mu, lv)
      9         loss.backward()

/usr/local/lib/python3.5/dist-packages/mxnet/gluon/block.py in __call__(self, *args)
    288     def __call__(self, *args):
    289         """Calls forward. Only accepts positional arguments."""
--&gt; 290         return self.forward(*args)
    291 
    292     def forward(self, *args):

~/Programming/edge_repos/detexon/vaegan/VAE.py in forward(self, x)
     63     def forward(self, x):
     64         mu, lv = self.enc(x)
---&gt; 65         z = sample_gaussian(mu, lv, self.batch_size, self.latent_z)
     66         y = self.dec(z)
     67         return y, mu, lv

~/Programming/edge_repos/detexon/vaegan/VAE.py in sample_gaussian(mu, lv, batch_size, latent_z, ctx)
      8     sigma = nd.sqrt(nd.exp(lv))
      9     # sigma = nd.exp(lv * 0.5)
---&gt; 10     z = mu + nd.multiply(sigma, epsilon)
     11     return z
     12 

/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py in multiply(lhs, rhs)
   2210         operator.mul,
   2211         _internal._mul_scalar,
-&gt; 2212         None)
   2213     # pylint: enable= no-member, protected-access
   2214 

/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/ndarray.py in _ufunc_helper(lhs, rhs, fn_array, fn_scalar, lfn_scalar, rfn_scalar)
   2023         return lfn_scalar(lhs, float(rhs))
   2024     elif isinstance(rhs, NDArray):
-&gt; 2025         return fn_array(lhs, rhs)
   2026     else:
   2027         raise TypeError('type %s not supported' % str(type(rhs)))

/usr/local/lib/python3.5/dist-packages/mxnet/ndarray/register.py in broadcast_mul(lhs, rhs, out, name, **kwargs)

/usr/local/lib/python3.5/dist-packages/mxnet/_ctypes/ndarray.py in _imperative_invoke(handle, ndargs, keys, vals, out)
     90         c_array(ctypes.c_char_p, [c_str(key) for key in keys]),
     91         c_array(ctypes.c_char_p, [c_str(str(val)) for val in vals]),
---&gt; 92         ctypes.byref(out_stypes)))
     93 
     94     if original_output is not None:

/usr/local/lib/python3.5/dist-packages/mxnet/base.py in check_call(ret)
    144     """
    145     if ret != 0:
--&gt; 146         raise MXNetError(py_str(_LIB.MXGetLastError()))
    147 
    148 if sys.version_info[0] &lt; 3:

MXNetError: [14:58:02] src/imperative/./imperative_utils.h:54: Check failed: inputs[i]-&gt;ctx().dev_mask() == ctx.dev_mask() (1 vs. 2) Operator broadcast_mul require all inputs live on the same context. But the first argument is on gpu(0) while the 2-th argument is on cpu(0)

Stack trace returned 10 entries:
[bt] (0) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x272f3c) [0x7f3aa60c6f3c]
[bt] (1) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x214b9dc) [0x7f3aa7f9f9dc]
[bt] (2) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x213e23e) [0x7f3aa7f9223e]
[bt] (3) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(+0x2094831) [0x7f3aa7ee8831]
[bt] (4) /usr/local/lib/python3.5/dist-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x63) [0x7f3aa7ee8bd3]
[bt] (5) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call_unix64+0x4c) [0x7f3af429de20]
[bt] (6) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(ffi_call+0x2eb) [0x7f3af429d88b]
[bt] (7) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(_ctypes_callproc+0x49a) [0x7f3af429801a]
[bt] (8) /usr/lib/python3.5/lib-dynload/_ctypes.cpython-35m-x86_64-linux-gnu.so(+0x9fcb) [0x7f3af428bfcb]
[bt] (9) /usr/bin/python3(PyObject_Call+0x47) [0x5b5da7]
&lt;/denchmark-code&gt;

HOWEVER going into VAE.py and passing the context to the function sample_gaussian solves the issue:
&lt;denchmark-code&gt;def sample_gaussian(mu, lv, batch_size, latent_z, ctx=mx.cpu()):
    epsilon = nd.random_normal(0, 1, shape=(batch_size, latent_z), ctx=ctx)
    sigma = nd.sqrt(nd.exp(lv))
    # sigma = nd.exp(lv * 0.5)
    z = mu + nd.multiply(sigma, epsilon)
    return z

class VAE(gluon.Block):
    def __init__(self, latent_z=100, batch_size=1, ctx=mx.cpu(),  **kwargs):
        super(VAE, self).__init__(**kwargs)
        with self.name_scope():
            self.enc = VAEEncoder(latent_z=latent_z)
            self.dec = VAEDecoder(latent_z=latent_z)
            self.latent_z = latent_z
            self.batch_size = batch_size
            self.ctx = ctx

    def forward(self, x):
        mu, lv = self.enc(x)
        z = sample_gaussian(mu, lv, self.batch_size, self.latent_z, self.ctx)
        y = self.dec(z)
        return y, mu, lv
&lt;/denchmark-code&gt;

thanks for pointing me in the right direction.
Why did this solve the issue?
Could the error thrown by mxnet include a warning about non equal contexts?
		</comment>
		<comment id='3' author='SumNeuron' date='2017-11-23T14:04:21Z'>
		to clarify, both fixes are needed
		</comment>
		<comment id='4' author='SumNeuron' date='2017-11-23T14:06:01Z'>
		Is there way to set the global context?
or for mxnet to auto switch to the greater of two contexts automatically (e.g. if I accidentally init something on the cpu and run something on 4 cpus, it automatically knows to move to a single gpu when needed?)
		</comment>
		<comment id='5' author='SumNeuron' date='2017-11-24T23:37:19Z'>
		try mx.gpu(0). mx.cpu doesn't needs index but gpu does.
		</comment>
		<comment id='6' author='SumNeuron' date='2017-11-27T16:04:39Z'>
		&lt;denchmark-link:https://github.com/Soonhwan-Kwon&gt;@Soonhwan-Kwon&lt;/denchmark-link&gt;
  I would like to postulate that mx.gpu() works fine. It is equivalent to mx.gpu(0).
The point is figuring out ways to handle non-conforming contexts (preferably internally)
		</comment>
		<comment id='7' author='SumNeuron' date='2018-03-09T23:53:34Z'>
		proposed labels: "Bug", "Python"
		</comment>
		<comment id='8' author='SumNeuron' date='2018-07-19T22:45:41Z'>
		&lt;denchmark-link:https://github.com/SumNeuron&gt;@SumNeuron&lt;/denchmark-link&gt;

Right now, context can be set within a block at max (&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/context.py&gt;https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/context.py&lt;/denchmark-link&gt;
).
with mx.Context(mx.gpu(2)): # Context changed in with block. 
There is no support for automatically switching between contexts yet. There is a request (&lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/6333&gt;#6333&lt;/denchmark-link&gt;
) for the same.
Can this issue be marked as closed? &lt;denchmark-link:https://github.com/SumNeuron&gt;@SumNeuron&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/sandeep-krishnamurthy&gt;@sandeep-krishnamurthy&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='SumNeuron' date='2018-07-23T18:48:09Z'>
		Closing in favor of &lt;denchmark-link:https://github.com/apache/incubator-mxnet/issues/6333&gt;#6333&lt;/denchmark-link&gt;
,  please feel free to reopen in case of issue.
		</comment>
	</comments>
</bug>