<bug id='10739' author='rwarnung' open_date='2018-04-28T18:14:43Z' closed_time='2018-05-13T15:06:57Z'>
	<summary>[MXNet-R] package crashes using mx.metric.logloss</summary>
	<description>
I have already discussed this issue with hetong07 in the &lt;denchmark-link:https://discuss.mxnet.io/t/logloss-in-the-recent-mxnet-rpackage/965/5&gt;forum&lt;/denchmark-link&gt;
. He told me to post it here. He guesses that  does not work and that causes a negative input for .
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

the mxnet R packages crahses when I use eval.metric = mx.metric.logloss in mx.mlp. The same problem works for eval.metric = mx.metric.accuracy.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

My sessionInfo is the following (I try to make it run on R 3.5) and downloaded via
install.packages("https://github.com/jeremiedb/mxnet_winbin/raw/master/mxnet.zip", repos = NULL)
I am using R 3.5 on Windows (session.info below)
For R user, please provide R sessionInfo():

R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows &gt;= 8 x64 (build 9200)
Matrix products: default
locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
[5] LC_TIME=English_United States.1252
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
other attached packages:
[1] mxnet_1.2.0
loaded via a namespace (and not attached):
[1] Rcpp_0.12.16       pillar_1.2.1       compiler_3.5.0     RColorBrewer_1.1-2 influenceR_0.1.0   plyr_1.8.4
[7] bindr_0.1.1        viridis_0.5.1      tools_3.5.0        digest_0.6.15      jsonlite_1.5       viridisLite_0.3.0
[13] tibble_1.4.2       gtable_0.2.0       rgexf_0.15.3       pkgconfig_2.0.1    rlang_0.2.0        igraph_1.2.1
[19] rstudioapi_0.7     yaml_2.1.18        bindrcpp_0.2.2     gridExtra_2.3      downloader_0.4     DiagrammeR_1.0.0
[25] dplyr_0.7.4        stringr_1.3.0      htmlwidgets_1.2    hms_0.4.2          grid_3.5.0         glue_1.2.0
[31] R6_2.2.2           Rook_1.1-1         XML_3.98-1.11      readr_1.1.1        purrr_0.2.4        tidyr_0.8.0
[37] ggplot2_2.2.1      magrittr_1.5       codetools_0.2-15   scales_0.5.0       htmltools_0.3.6    assertthat_0.2.0
[43] colorspace_1.3-2   brew_1.0-6         stringi_1.1.7      visNetwork_2.0.3   lazyeval_0.2.1     munsell_0.4.3

&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

No error message it just crashes and R needs to be restarted.
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;library(mxnet)

deep.model = mx.mlp(as.matrix(iris[,1:4]), ifelse(iris[,5] == "setosa",1,0),
                    eval.data          = list("data" = as.matrix(iris[,1:4]), "label" = ifelse(iris[,5] == "setosa",1,0)),
                    hidden_node        = c(3,3), 
                    out_node           = 2, 
                    out_activation     = "softmax",
                    num.round = 5, array.batch.size = 256, learning.rate = 0.01, momentum = 0.9, dropout = 0.8,
                    eval.metric = mx.metric.logloss, #mx.metric.logloss, mx.metric.accuracy
                    array.layout = "rowmajor",
                    activation = "relu", 
                    ctx = mx.ctx.default(),
                    initializer = mx.init.uniform(0.5),
                    epoch.end.callback = mx.callback.log.train.metric(period = 5)
)
&lt;/denchmark-code&gt;

Thank you!
	</description>
	<comments>
		<comment id='1' author='rwarnung' date='2018-05-10T21:55:59Z'>
		I think the issue was raised from changing the metric calculation to NDArrays instead than on the conversion to R arrays as it can be beneficial in certain circumstances to keep the eval metric calculation on the device.
You can look for instance at this logloss definition:
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/R-package/R/metric.R#L96&gt;https://github.com/apache/incubator-mxnet/blob/master/R-package/R/metric.R#L96&lt;/denchmark-link&gt;

If need to perform calculation on R arrays, then you would need to apply the conversion within the metric function, for example label &lt;- as.array(label)
		</comment>
		<comment id='2' author='rwarnung' date='2018-05-11T17:43:56Z'>
		&lt;denchmark-link:https://github.com/jeremiedb&gt;@jeremiedb&lt;/denchmark-link&gt;
 thank you for your comment. But I don't quite understand. If I just use the parameter  without redefining  does your comment apply in this case? Isn't this exactly the code as from
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/blob/master/R-package/R/metric.R#L96&gt;https://github.com/apache/incubator-mxnet/blob/master/R-package/R/metric.R#L96&lt;/denchmark-link&gt;

?
		</comment>
		<comment id='3' author='rwarnung' date='2018-05-11T20:15:35Z'>
		My bad, I think I get the issue now: the mx.metric.logloss has been defined for the LogisticRegressionOutput operator, which acts on 1-demsionnal vector of predictions and labels. However your model is framed as a multiclass model which outputs n-columns predictions.
A mlogloss metric would be needed to support those use case. I can make a PR soon for this.
		</comment>
		<comment id='4' author='rwarnung' date='2018-05-12T19:07:24Z'>
		&lt;denchmark-link:https://github.com/jeremiedb&gt;@jeremiedb&lt;/denchmark-link&gt;
 sorry if my example is not that clear but the line  gives two classes 1 for the species "setosa" and 0 for all others. The iris data set is quite standard in R it is about feature of plants and their species.  So it is a two class problem. Shouldn't  just work in this case? I am afraid the problem is qith the clipping or the logarithm ... can't that be? Can we test the basic building blocks of the measure? logloss is one of the standard measures in classification so it would be really good to have it in the R package for mxnet ... please tell me if I can provide anything to find a solution.
		</comment>
		<comment id='5' author='rwarnung' date='2018-05-12T23:54:27Z'>
		Could you try running your example with :
&lt;denchmark-code&gt;out_node           = 1, 
out_activation     = "logistic"
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='rwarnung' date='2018-05-13T05:54:24Z'>
		In the your example, out_node  = 2, which results in the last layer of the network to output a matrix of dim: 2 X batch_size. This last layer has an explicit representation of the score associated with each of the 2 levels, which is normalized into a probability by the softmax operator.
Under the logistic regression output operator, the logic is a little different: since the probability associated with the second level can be infered from the first level probability, the logistic regression output simply uses an prediction of dim 1 X batch_size. The mx.metric.logistic assumes this 1 column representation of the logistic regression, while the mx.metric.accuracy metric assumes the softmax where the predictions are sotred into a N levels X batch_size matrix.
The mx.metric.logistic_acc returns accuracy when the problem is formulated as a logistic regression rather than a multi-class classification.
To calculate the logloss on multi class problem, you can use the following metric:
&lt;denchmark-code&gt;mx.metric.mlogloss &lt;- mx.metric.custom("mlogloss", function(label, pred) {
  pred &lt;- mx.nd.pick(pred, index = label, axis = 1)
  pred &lt;- mx.nd.clip(pred, a_min = 1e-15, a_max = 1-1e-15)
  res &lt;- -mx.nd.mean(mx.nd.log(pred))
  return(as.array(res))
})

&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='rwarnung' date='2018-05-13T15:06:57Z'>
		&lt;denchmark-link:https://github.com/jeremiedb&gt;@jeremiedb&lt;/denchmark-link&gt;
 thank you! This is the solution! I was used to the activation but of course with two classes the approach that you propose makes perfect sense. I changed the input to
&lt;denchmark-code&gt;out_node           = 1, 
out_activation     = "logistic"

&lt;/denchmark-code&gt;

and it worked fine! Thank you! We can close this request!
		</comment>
	</comments>
</bug>