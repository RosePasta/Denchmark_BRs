<bug id='14864' author='araitats' open_date='2019-05-02T21:55:09Z' closed_time='2019-05-03T17:40:06Z'>
	<summary>[MXNet] - [BERT]</summary>
	<description>
&lt;denchmark-link:https://github.com/dmlc/gluon-nlp/issues/690&gt;dmlc/gluon-nlp#690&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

There is a problem with a custom BERT model training with the later version of MXNet 1.5.0 (observed with cu90).
mlm_loss stops around 7.3 and nsp_acc stopps around 54.
mxnet-cu90 version which is older than 1.5.0b20190425 does not have this issue.
1.5.0b20190426 onward has this issue.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

Amazon SageMaker Notebook (ml.p3.16xlarge)
CUDA version: 9.0
Package used (Python/R/Scala/Julia):
Python 3.6
	</description>
	<comments>
	</comments>
</bug>