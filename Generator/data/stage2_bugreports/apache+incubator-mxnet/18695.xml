<bug id='18695' author='JeanKossaifi' open_date='2020-07-11T23:30:50Z' closed_time='2020-07-16T17:25:03Z'>
	<summary>Transpose only supports up to 6 dimensions</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Transpose does not currently support tensors with more than 6 dimensions.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;E           mxnet.base.MXNetError: Traceback (most recent call last):
E             File "src/operator/tensor/./matrix_op-inl.h", line 459
E           MXNetError: Check failed: shp.ndim() &lt;= 6 (7 vs. 6) : Transpose support at most 6 dimensions
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Apply transpose to a higher-order tensor.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

Python 3.7.3
MXNet 2.0.0
	</description>
	<comments>
		<comment id='1' author='JeanKossaifi' date='2020-07-12T17:53:35Z'>
		Thanks for reporting, Jean. I confirm that this affects numpy operators too.
		</comment>
		<comment id='2' author='JeanKossaifi' date='2020-07-12T18:02:13Z'>
		Two changes will help immediately:

Collapse consecutive axes of the input array into a single axis here https://github.com/apache/incubator-mxnet/blob/master/src/operator/numpy/np_matrix_op-inl.h#L142-L149
Extend the implementation to support more https://github.com/apache/incubator-mxnet/blob/master/src/operator/tensor/matrix_op-inl.h#L362-L419

The root cause is really the limitation of template based programming in mshadow. Because of that choice, the axis is in template variable and thus needs to be expanded at compile time. We should move away from this approach and have a transpose implementation without mshadow instead.
Let's focus on only the immediate changes, and I will open a separate issue for the larger change.
		</comment>
		<comment id='3' author='JeanKossaifi' date='2020-07-13T22:29:59Z'>
		Hi &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
 , I am trying to fix it and select 'Collapse consecutive axes of the input array into a single axis here when axes.ndim() &gt; 2'.
&lt;denchmark-link:https://github.com/wkcn/incubator-mxnet/tree/support_transpose_dim_gt_6&gt;https://github.com/wkcn/incubator-mxnet/tree/support_transpose_dim_gt_6&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='JeanKossaifi' date='2020-07-14T02:50:13Z'>
		Hi &lt;denchmark-link:https://github.com/szha&gt;@szha&lt;/denchmark-link&gt;
 , I create a &lt;denchmark-link:https://github.com/wkcn/incubator-mxnet/blob/support_transpose_dim_gt_6/src/operator/tensor/matrix_op-inl.h#L324&gt;TransposeKernel&lt;/denchmark-link&gt;
 and need to copy the argument (namely ) into the target context. Is there any good way to copy it?
I try to call &lt;denchmark-link:https://github.com/wkcn/incubator-mxnet/blob/support_transpose_dim_gt_6/src/operator/tensor/matrix_op-inl.h#L429&gt;get_space_typed&lt;/denchmark-link&gt;
 to alloc a workspace, but it need to declare a temporary space in each operator which calls .
&lt;denchmark-h:h2&gt;Solution&lt;/denchmark-h&gt;

I will create a new function TransposeExImpl to support up to 6 dimensions, which needs to alloc extra workspace. The original TransposeImpl will not be modified.
		</comment>
	</comments>
</bug>