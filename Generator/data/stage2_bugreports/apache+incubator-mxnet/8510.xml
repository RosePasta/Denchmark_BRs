<bug id='8510' author='Luo-Liang' open_date='2017-11-01T20:28:20Z' closed_time='2018-11-30T06:01:26Z'>
	<summary>Minor differences in distributed training with GPU/without GPU.</summary>
	<description>
Note: Providing complete information in the most concise form is the best way to get help. This issue template serves as the checklist for essential information to most of the technical issues.
If the issue is non-technical, feel free to present the information in what you believe is the best form.
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

mnist accuracy differ slightly when training with local gpu and distributed training with GPU but accuracy is the same when training with CPU.
&lt;denchmark-h:h2&gt;Environment info (Required)&lt;/denchmark-h&gt;

CentOS 7
MxNet latest master
&lt;denchmark-code&gt;What to do:
1. Download the diagnosis script from https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/diagnose.py
2. Run the script using `python diagnose.py` and paste its output here.
&lt;/denchmark-code&gt;

Package used (Python/R/Scala/Julia):
(I'm using ...) Python!
For Scala user, please provide:

Java version: (java -version)
Maven version: (mvn -version)
Scala runtime if applicable: (scala -version)

For R user, please provide R sessionInfo():
&lt;denchmark-h:h2&gt;Build info (Required if built from source)&lt;/denchmark-h&gt;

train_mnist.py with data shuffle turned off so accuracy of each run is the same.
Compiler (gcc/clang/mingw/visual studio):
gcc 4.9
MXNet commit hash:
(Paste the output of  here.)
&lt;denchmark-link:https://github.com/apache/incubator-mxnet/commit/8592e1cd3b9f79cff740f29e599ba7788a454c54&gt;8592e1c&lt;/denchmark-link&gt;

Build config:
(Paste the content of config.mk, or the build command.)
USE_DISTRIBUTED_KVSTORE=1
USE_CUDNN=1
USE_CUDA=/usr/local/cuda
&lt;denchmark-h:h2&gt;Error Message:&lt;/denchmark-h&gt;

1 server 1 client training with train_mnist.py WITHOUT GPU
INFO:root:Epoch[0] Batch [100]  Speed: 3606.78 samples/sec      accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 3747.11 samples/sec      accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 3982.58 samples/sec      accuracy=0.912656
INFO:root:Epoch[0] Batch [400]  Speed: 3960.68 samples/sec      accuracy=0.928594
INFO:root:Epoch[0] Batch [500]  Speed: 5376.55 samples/sec      accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 4133.33 samples/sec      accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 5935.95 samples/sec      accuracy=0.944688
INFO:root:Epoch[0] Batch [800]  Speed: 3966.74 samples/sec      accuracy=0.940312
INFO:root:Epoch[0] Batch [900]  Speed: 3803.05 samples/sec      accuracy=0.953906
INFO:root:Epoch[0] Train-accuracy=0.966639
INFO:root:Epoch[0] Time cost=14.467
INFO:root:Epoch[0] Validation-accuracy=0.943670
1 server 1 client training with train_mnist.py WITH GPU
INFO:root:Epoch[0] Batch [100]  Speed: 13700.01 samples/sec     accuracy=0.807859
INFO:root:Epoch[0] Batch [200]  Speed: 27909.23 samples/sec     accuracy=0.895469
INFO:root:Epoch[0] Batch [300]  Speed: 23719.16 samples/sec     accuracy=0.910781
INFO:root:Epoch[0] Batch [400]  Speed: 30796.60 samples/sec     accuracy=0.925312
INFO:root:Epoch[0] Batch [500]  Speed: 26746.35 samples/sec     accuracy=0.933906
INFO:root:Epoch[0] Batch [600]  Speed: 29120.16 samples/sec     accuracy=0.943906
INFO:root:Epoch[0] Batch [700]  Speed: 30805.82 samples/sec     accuracy=0.944531
INFO:root:Epoch[0] Batch [800]  Speed: 22852.49 samples/sec     accuracy=0.937813
INFO:root:Epoch[0] Batch [900]  Speed: 28238.62 samples/sec     accuracy=0.952031
INFO:root:Epoch[0] Train-accuracy=0.969172
INFO:root:Epoch[0] Time cost=2.452
INFO:root:Epoch[0] Validation-accuracy=0.936505
&lt;denchmark-h:h2&gt;Minimum reproducible example&lt;/denchmark-h&gt;

(If you are using your own code, please provide a short script that reproduces the error. Otherwise, please provide link to the existing example.)
(pgrep python | xargs kill -9 &amp;&amp; rm ~/train/profile.json) &amp;&gt;/dev/null
(pgrep memcheck-amd64- | xargs kill -9) &amp;&gt; /dev/null
export DMLC_PS_ROOT_PORT=9091;
export DMLC_NUM_WORKER=1;
export DMLC_NUM_SERVER=1;
export DMLC_PS_ROOT_URI=127.0.0.1;
export DMLC_ROLE=scheduler;
python train_mnist.py &amp;
export DMLC_ROLE=server;
export DMLC_SERVER_ID=0
python train_mnist.py --kv-store dist_sync --gpus 0 &amp;
export DMLC_ROLE=worker;
export DMLC_WORKER_ID=0
python train_mnist.py --kv-store dist_sync --num-epochs 1 --gpus 0&amp;
&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

(Paste the commands you ran that produced the error.)

Run the example and toggle --gpus 0
Observe accuracy differences.

&lt;denchmark-h:h2&gt;What have you tried to solve it?&lt;/denchmark-h&gt;


The problem seems to be the initialization of params in GPU.
The first divergence of these two training is the first gradient sent out after the first batch.

	</description>
	<comments>
		<comment id='1' author='Luo-Liang' date='2018-02-01T00:26:29Z'>
		&lt;denchmark-link:https://github.com/orgs/apache/teams/mxnet-committers&gt;@apache/mxnet-committers&lt;/denchmark-link&gt;
: This issue has been inactive for the past 90 days. It has no label and needs triage.
For general "how-to" questions, our &lt;denchmark-link:https://discuss.mxnet.io/&gt;user forum&lt;/denchmark-link&gt;
 (and &lt;denchmark-link:https://discuss.gluon.ai/&gt;Chinese version&lt;/denchmark-link&gt;
) is a good place to get help.
		</comment>
		<comment id='2' author='Luo-Liang' date='2018-04-10T18:07:54Z'>
		have you tried to fix the seed for initialization?
		</comment>
		<comment id='3' author='Luo-Liang' date='2018-11-27T23:40:32Z'>
		&lt;denchmark-link:https://github.com/Luo-Liang&gt;@Luo-Liang&lt;/denchmark-link&gt;
 Have you tried fixed seed for initialization as per &lt;denchmark-link:https://github.com/ThomasDelteil&gt;@ThomasDelteil&lt;/denchmark-link&gt;
's suggestion? Requesting to close this issue, if the issue is resolved.
		</comment>
		<comment id='4' author='Luo-Liang' date='2018-11-30T06:01:24Z'>
		Yes. This is no longer a problem. I have confirmed it's due to initialization.
		</comment>
	</comments>
</bug>