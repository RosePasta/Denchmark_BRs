<bug id='17907' author='chinakook' open_date='2020-03-25T15:03:54Z' closed_time='2020-03-26T07:05:18Z'>
	<summary>Depthwise in windows is 10 times slower than linux on gpu</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Depthwise in windows is 10x slower than linux on gpu. On windows, mobilenet 1.0 is even much slower than resnet50.
&lt;denchmark-h:h3&gt;Error Message&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

mxnet 1.6.0 official
predict a mobienet1.0 model on gpu. windows take 5s while linux only takes 0.5s
import os
os.environ['MXNET_CUDNN_AUTOTUNE_DEFAULT'] = '0'
import time
import mxnet as mx
from mxnet import gluon
from mxnet.gluon import nn
from gluoncv.model_zoo import get_model

ctx = mx.gpu()
net = get_model('mobilenet1.0', norm_layer=gluon.nn.BatchNorm)
net.initialize()

net.collect_params().reset_ctx(ctx)

s = time.time()
for i in range(50):
    x = mx.nd.random.uniform(shape=(1,3,512,512), ctx=ctx)

    t = time.time()
    y = net(x)
    mx.nd.waitall()
    print(time.time() - t)

print('TOTAL TIME: ', time.time() - s)
linux profile:



CopyCPU2GPU 🔍
21.517 ms
21.517 ms
0.158 ms
136




DeleteVariable 🔍
28.710 ms
28.710 ms
0.004 ms
6948


ResourceParallelRandomSetSeed 🔍
1.744 ms
1.744 ms
0.436 ms
4


_zeros 🔍
8.958 ms
8.958 ms
0.109 ms
82


BatchNorm 🔍
69.947 ms
69.947 ms
0.052 ms
1350


Activation 🔍
50.415 ms
50.415 ms
0.037 ms
1350


Convolution 🔍
112.266 ms
112.266 ms
0.083 ms
1350


Pooling 🔍
1.520 ms
1.520 ms
0.030 ms
50


FullyConnected 🔍
2.286 ms
2.286 ms
0.046 ms
50


Flatten 🔍
1.535 ms
1.535 ms
0.031 ms
50


_random_uniform 🔍
6.177 ms
6.177 ms
0.124 ms
50


Totals
305.074 ms
305.074 ms
0.027 ms
11420



windows profile:



CopyCPU2GPU 🔍
30.645 ms
30.645 ms
0.225 ms
136




ResourceParallelRandomSetSeed 🔍
2.809 ms
2.809 ms
0.702 ms
4


_random_uniform 🔍
10.450 ms
10.450 ms
0.209 ms
50


Convolution 🔍
3,823.058 ms
3,823.058 ms
2.832 ms
1350


BatchNorm 🔍
132.901 ms
132.901 ms
0.098 ms
1350


DeleteVariable 🔍
16.054 ms
16.054 ms
0.002 ms
6948


_zeros 🔍
13.822 ms
13.822 ms
0.169 ms
82


Activation 🔍
125.978 ms
125.978 ms
0.093 ms
1350


Pooling 🔍
5.188 ms
5.188 ms
0.104 ms
50


FullyConnected 🔍
6.716 ms
6.716 ms
0.134 ms
50


Flatten 🔍
4.227 ms
4.227 ms
0.085 ms
50


Totals
4,171.848 ms
4,171.848 ms
0.365 ms
11420



	</description>
	<comments>
		<comment id='1' author='chinakook' date='2020-03-25T16:22:20Z'>
		There is another version in windows, pytorch takes 2.0s while mxnet takes 10.2s. I think this is a bug for a long time.
MXNET version:
import os
os.environ['MXNET_CUDNN_AUTOTUNE_DEFAULT'] = '0'
import time
import mxnet as mx
from mxnet import gluon
from mxnet.gluon import nn
from gluoncv.model_zoo import get_model

ctx = mx.gpu()
net = get_model('mobilenetv2_1.0', norm_layer=gluon.nn.BatchNorm)
net.initialize()

net.collect_params().reset_ctx(ctx)

s = time.time()
for i in range(50):
    x = mx.nd.random.uniform(shape=(1,3,512,512), ctx=ctx)

    t = time.time()
    y = net(x)
    mx.nd.waitall()
    print(time.time() - t)

print('TOTAL TIME: ', time.time() - s)
&lt;denchmark-code&gt;0.2889983654022217
0.15599989891052246
0.14120268821716309
0.1549980640411377
0.14800024032592773
0.1549973487854004
0.1419973373413086
0.16100192070007324
0.15399909019470215
0.14299798011779785
0.1490001678466797
0.17000079154968262
0.1530005931854248
0.14499974250793457
0.1569969654083252
0.15002942085266113
0.14699625968933105
0.14600133895874023
0.143998384475708
0.15400242805480957
0.1439976692199707
0.14451003074645996
0.16103625297546387
0.15851068496704102
0.15300440788269043
0.15399932861328125
0.15399956703186035
0.14400243759155273
0.15401935577392578
0.14500117301940918
0.14951753616333008
0.14799976348876953
0.14800000190734863
0.15600085258483887
0.1529989242553711
0.14699888229370117
0.14899921417236328
0.1512279510498047
0.1525120735168457
0.1549992561340332
0.16200017929077148
0.1529998779296875
0.1510009765625
0.14804387092590332
0.14800000190734863
0.15600061416625977
0.15230464935302734
0.15199899673461914
0.14699792861938477
0.1289997100830078
TOTAL TIME:  10.248228788375854
&lt;/denchmark-code&gt;

PYTORCH version:
import time
import torch
import torchvision

torch.backends.cudnn.benchmark=False

net = torchvision.models.mobilenet_v2()
net.cuda()
net.eval()

s = time.time()
for i in range(50):
    t = time.time()
    x = torch.rand([1,3,512,512]).cuda()
    y = net(x)
    print(time.time() - t)

print('TOTAL TIME: ', time.time() - s)
&lt;denchmark-code&gt;0.9051487445831299
0.04097485542297363
0.019997835159301758
0.018999099731445312
0.023026704788208008
0.021998167037963867
0.020003795623779297
0.0209958553314209
0.020031213760375977
0.020966291427612305
0.019999980926513672
0.022031784057617188
0.019968032836914062
0.023028850555419922
0.020004987716674805
0.01996612548828125
0.022998332977294922
0.020999431610107422
0.02000117301940918
0.019997119903564453
0.02300119400024414
0.02200031280517578
0.01899886131286621
0.01999974250793457
0.021999835968017578
0.02000284194946289
0.02000141143798828
0.02000117301940918
0.02099919319152832
0.020000457763671875
0.021001338958740234
0.020998477935791016
0.020000219345092773
0.020998477935791016
0.022002458572387695
0.02502727508544922
0.02000284194946289
0.021997690200805664
0.021001100540161133
0.024999141693115234
0.0299990177154541
0.02599787712097168
0.029999256134033203
0.029999256134033203
0.02700185775756836
0.02520275115966797
0.02800154685974121
0.032999277114868164
0.02400040626525879
0.02900218963623047
TOTAL TIME:  2.065340518951416
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='chinakook' date='2020-03-26T07:05:18Z'>
		It's relevant to the cudnn opitimization on windows with Pascal cards.
		</comment>
	</comments>
</bug>