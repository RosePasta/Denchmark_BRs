<bug id='14396' author='YutingZhang' open_date='2019-03-12T01:47:10Z' closed_time='2019-03-20T16:23:02Z'>
	<summary>mx.nd.Custom not working in subprocess</summary>
	<description>
mx.nd.Custom gets stuck at subprocess.
The following code to replicate the error is from &lt;denchmark-link:https://github.com/wkcn/MobulaOP/issues/40#issuecomment-471803878&gt;wkcn/MobulaOP#40 (comment)&lt;/denchmark-link&gt;

from concurrent import futures

import mxnet as mx
import sys

class AdditionOP(mx.operator.CustomOp):
    def __init__(self):
        super(AdditionOP, self).__init__()
    def forward(self, is_train, req, in_data, out_data, aux):
        out_data[0][:] = in_data[0] + in_data[1]
    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):
        in_grad[0][:] = out_grad[0]
        in_grad[1][:] = out_grad[0]

@mx.operator.register("AdditionOP")
class AdditionOPProp(mx.operator.CustomOpProp):
    def __init__(self):
        super(AdditionOPProp, self).__init__()
    def list_arguments(self):
        return ['a', 'b']
    def list_outputs(self):
        return ['output']
    def infer_shape(self, in_shape):
        return in_shape, [in_shape[0]]
    def create_operator(self, ctx, shapes, dtypes):
        return AdditionOP()

def foo():
    a = mx.nd.array([1, 2, 3])
    b = mx.nd.array([4, 5, 6])

    a.attach_grad()
    b.attach_grad()

    print("REC")
    with mx.autograd.record():
        c = mx.nd.Custom(a, b, op_type='AdditionOP')

    dc = mx.nd.array([7, 8, 9])
    c.backward(dc)

    print('Okay :-)')
    print('a + b = c \n {} + {} = {}'.format(a.asnumpy(), b.asnumpy(), c.asnumpy()))

def main():
    ex = futures.ProcessPoolExecutor(1)
    r = ex.submit(foo)
    r.result()

if __name__ == '__main__':
    main()
asnumpy gets stuck due to mx.nd.Custom
	</description>
	<comments>
		<comment id='1' author='YutingZhang' date='2019-03-12T01:47:12Z'>
		Hey, this is the MXNet Label Bot.
Thank you for submitting the issue! I will try and suggest some labels so that the appropriate MXNet community members can help resolve it.
Here are my recommended labels: Bug
		</comment>
		<comment id='2' author='YutingZhang' date='2019-03-12T02:12:42Z'>
		I found that the custom operator has been Engine::Get()-&gt;PushSync, but it couldn't be executed. (forward and backward).
		</comment>
		<comment id='3' author='YutingZhang' date='2019-03-12T11:24:47Z'>
		I rekon there's a limitation of custom op with requires a global lock when executing the python custom op, and it might cause dead lock when combined with subprocess.
&lt;denchmark-link:https://github.com/eric-haibin-lin&gt;@eric-haibin-lin&lt;/denchmark-link&gt;
 raising for expertise in engine part.
		</comment>
		<comment id='4' author='YutingZhang' date='2019-03-15T19:35:11Z'>
		Yes this is because of the dead lock in the subprocess. One way to fix this is to create a start and stop functions in CustomOperator, which should be called from pthread_atfork prepare and child handlers.
Using thread pool to manage CustomOperator threads would make the implementation cleaner. Anyone wants to try and create a PR for this ? &lt;denchmark-link:https://github.com/wkcn&gt;@wkcn&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/arcadiaphy&gt;@arcadiaphy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/YutingZhang&gt;@YutingZhang&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='5' author='YutingZhang' date='2019-03-16T19:26:49Z'>
		After &lt;denchmark-link:https://github.com/apache/incubator-mxnet/pull/14363&gt;#14363&lt;/denchmark-link&gt;
, the threads is created  when running custom operator, so custom operator needs also to be executed in main process to reproduce the bug:
&lt;denchmark-code&gt;from concurrent import futures

import mxnet as mx
import sys

class AdditionOP(mx.operator.CustomOp):
    def __init__(self):
        super(AdditionOP, self).__init__()
    def forward(self, is_train, req, in_data, out_data, aux):
        out_data[0][:] = in_data[0] + in_data[1]
    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):
        in_grad[0][:] = out_grad[0]
        in_grad[1][:] = out_grad[0]

@mx.operator.register("AdditionOP")
class AdditionOPProp(mx.operator.CustomOpProp):
    def __init__(self):
        super(AdditionOPProp, self).__init__()
    def list_arguments(self):
        return ['a', 'b']
    def list_outputs(self):
        return ['output']
    def infer_shape(self, in_shape):
        return in_shape, [in_shape[0]]
    def create_operator(self, ctx, shapes, dtypes):
        return AdditionOP()

def foo():
    a = mx.nd.array([1, 2, 3])
    b = mx.nd.array([4, 5, 6])

    a.attach_grad()
    b.attach_grad()

    print("REC")
    with mx.autograd.record():
        c = mx.nd.Custom(a, b, op_type='AdditionOP')

    dc = mx.nd.array([7, 8, 9])
    c.backward(dc)

    print('Okay :-)')
    print('a + b = c \n {} + {} = {}'.format(a.asnumpy(), b.asnumpy(), c.asnumpy()))

def main():
    foo()  # ensure custom threads created in main process
    ex = futures.ProcessPoolExecutor(1)
    r = ex.submit(foo)
    r.result()

if __name__ == '__main__':
    main()
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>