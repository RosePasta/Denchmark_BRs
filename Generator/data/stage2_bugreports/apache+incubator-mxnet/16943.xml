<bug id='16943' author='haojin2' open_date='2019-11-29T05:15:36Z' closed_time='2019-12-10T04:27:36Z'>
	<summary>Failing Test: test_contrib_amp.test_amp_conversion</summary>
	<description>
Happening multiple times across different platforms/PRs/builds:
&lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16870/9/pipeline/356&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16870/9/pipeline/356&lt;/denchmark-link&gt;

&lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fcentos-gpu/detail/PR-16788/20/pipeline/76&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Fcentos-gpu/detail/PR-16788/20/pipeline/76&lt;/denchmark-link&gt;

&lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16931/3/pipeline/356&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16931/3/pipeline/356&lt;/denchmark-link&gt;

&lt;denchmark-link:http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16931/3/pipeline/360&gt;http://jenkins.mxnet-ci.amazon-ml.com/blue/organizations/jenkins/mxnet-validation%2Funix-gpu/detail/PR-16931/3/pipeline/360&lt;/denchmark-link&gt;

Sample error log:
&lt;denchmark-code&gt;test_contrib_amp.test_amp_conversion ... [11:22:18] src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...

[11:22:18] src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!

[11:22:21] src/base.cc:80: cuDNN lib mismatch: linked-against version 7501 != compiled-against version 7600.  Set MXNET_CUDNN_LIB_CHECKING=0 to quiet this warning.

terminate called after throwing an instance of 'dmlc::Error'

  what():  [11:22:23] /work/mxnet/3rdparty/mshadow/mshadow/./stream_gpu-inl.h:107: Check failed: err == CUBLAS_STATUS_SUCCESS (7 vs. 0) : Destory cublas handle failed

Stack trace:

  [bt] (0) /work/mxnet/python/mxnet/../../lib/libmxnet.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7f724907dff2]

  [bt] (1) /work/mxnet/python/mxnet/../../lib/libmxnet.so(mshadow::Stream&lt;mshadow::gpu&gt;::DestroyBlasHandle()+0x10f) [0x7f724cafc8ff]

  [bt] (2) /work/mxnet/python/mxnet/../../lib/libmxnet.so(void mshadow::DeleteStream&lt;mshadow::gpu&gt;(mshadow::Stream&lt;mshadow::gpu&gt;*)+0xb7) [0x7f724cafd227]

  [bt] (3) /work/mxnet/python/mxnet/../../lib/libmxnet.so(mshadow::Stream&lt;mshadow::gpu&gt;* mshadow::NewStream&lt;mshadow::gpu&gt;(bool, bool, int)+0x313) [0x7f724cafd873]

  [bt] (4) /work/mxnet/python/mxnet/../../lib/libmxnet.so(void mxnet::engine::ThreadedEnginePerDevice::GPUWorker&lt;(dmlc::ConcurrentQueueType)0&gt;(mxnet::Context, bool, mxnet::engine::ThreadedEnginePerDevice::ThreadWorkerBlock&lt;(dmlc::ConcurrentQueueType)0&gt;*, std::shared_ptr&lt;dmlc::ManualEvent&gt; const&amp;)+0x18f) [0x7f724cb229df]

  [bt] (5) /work/mxnet/python/mxnet/../../lib/libmxnet.so(std::_Function_handler&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;), mxnet::engine::ThreadedEnginePerDevice::PushToExecute(mxnet::engine::OprBlock*, bool)::{lambda()#4}::operator()() const::{lambda(std::shared_ptr&lt;dmlc::ManualEvent&gt;)#1}&gt;::_M_invoke(std::_Any_data const&amp;, std::shared_ptr&lt;dmlc::ManualEvent&gt;&amp;&amp;)+0x4e) [0x7f724cb22c1e]

  [bt] (6) /work/mxnet/python/mxnet/../../lib/libmxnet.so(std::thread::_Impl&lt;std::_Bind_simple&lt;std::function&lt;void (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; (std::shared_ptr&lt;dmlc::ManualEvent&gt;)&gt; &gt;::_M_run()+0x4a) [0x7f724cb0848a]

  [bt] (7) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80) [0x7f72bbb44c80]

  [bt] (8) /lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba) [0x7f72c33fb6ba]

/work/runtime_functions.sh: line 1114:   146 Aborted                 (core dumped) nosetests-3.4 $NOSE_COVERAGE_ARGUMENTS $NOSE_TIMER_ARGUMENTS --with-xunit --xunit-file nosetests_gpu.xml --verbose tests/python/gpu
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/ptrendx&gt;@ptrendx&lt;/denchmark-link&gt;
 Any insights?
	</description>
	<comments>
		<comment id='1' author='haojin2' date='2019-12-02T20:59:39Z'>
		This failure  is not specific to that test, I believe it is a CI misconfiguration. Maybe it pulls in 10.2 version of cublas for 10.1 toolkit?
&lt;denchmark-link:https://github.com/samskalicky&gt;@samskalicky&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ChaiBapchya&gt;@ChaiBapchya&lt;/denchmark-link&gt;
 Could you comment on that?
		</comment>
		<comment id='2' author='haojin2' date='2019-12-03T00:10:55Z'>
		&lt;denchmark-link:https://github.com/apeforest&gt;@apeforest&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/roywei&gt;@roywei&lt;/denchmark-link&gt;
 are working on this. FYI &lt;denchmark-link:https://github.com/larroy&gt;@larroy&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='haojin2' date='2019-12-03T00:35:06Z'>
		&lt;denchmark-link:https://github.com/larroy&gt;@larroy&lt;/denchmark-link&gt;
 confirmed it's an issue of outdated Nvidia driver. He could not reproduce the error on an Ubuntu 18.04 instance. &lt;denchmark-link:https://github.com/larroy&gt;@larroy&lt;/denchmark-link&gt;
 is working to deploy an AMI from his successful EC2 instance.
		</comment>
		<comment id='4' author='haojin2' date='2019-12-10T04:27:36Z'>
		This issue is now resolved. It was a bug in nvidia/cuda docker images that pulled the wrong version of cublas.
		</comment>
	</comments>
</bug>