<bug id='18591' author='zhongqingyang' open_date='2020-06-19T03:10:40Z' closed_time='2020-07-21T08:04:14Z'>
	<summary>CPU memory leak when running inference on model with GPU</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

I used cpp to inference on model with GPU in childthread.
cpu Memory increase 0.1G after 72000 execution.
cpu Memory increase 0.14G after 100000 execution.
cpu Memory increase 0.236G after 163500 execution.
cpu Memory increase 0.437G after 163500 execution.
cpu Memory increase 2G after 643100 execution.
&lt;denchmark-h:h3&gt;Here is my test code&lt;/denchmark-h&gt;

`
#include 
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;mxnet-cpp/MxNetCpp.h&gt;
#include &lt;zconf.h&gt;
#include 
#include 
#include &lt;unistd.h&gt;
#include &lt;malloc.h&gt;
#define FILE_NAME_SIZE 255
#include "mxnet/c_predict_api.h"
using namespace mxnet::cpp;
using namespace std;
std::vector&lt;mx_uint&gt; batch_size = {1, 3, 512, 896};//设置模式
Context global_ctx = Context::gpu();//模型选择的运行设备cpu或gpu
map&lt;string, NDArray&gt; args_map;//框架内部保留的代码,初始化模型有用到
map&lt;string, NDArray&gt; aux_map;//框架内部保留的代码,初始化模型有用到
Symbol net;//网络对象
Executor *executor = nullptr;//执行器 用于网络前向传播
string model_type = "YOLO";
mutex mut;
void LoadParameters(string params) {
map&lt;string, NDArray&gt; parameters;
NDArray::Load(params, 0, &amp;parameters);
&lt;denchmark-code&gt;for (const auto&amp; pair : parameters) {
    string type = pair.first.substr(0, 4);
    string name = pair.first.substr(4);
    if (type == "arg:") {
        (args_map)[name] = pair.second.Copy(global_ctx);
    } else if (type == "aux:") {
        (aux_map)[name] = pair.second.Copy(global_ctx);
    }
}

NDArray::WaitAll();
&lt;/denchmark-code&gt;

}
NDArray YOLOSSDTransform(vectorcv::Mat ori_image_vec, int &amp;new_height, int &amp;new_width)
{
int pre_H = 0, pre_W = 0;
int maxLongSide = 1024;
int short_side = 512;
&lt;denchmark-code&gt;//判断是否有输入图片
if (ori_image_vec.empty())
{
    LG &lt;&lt; "输入图片为空";
    throw runtime_error("输入图片为空");
}
//判断输入尺寸是否一致
for (auto &amp; i : ori_image_vec)
{
    if (pre_H == 0)
    {
        pre_H = i.rows;
        pre_W = i.cols;
    }
    else
    {
        if (pre_H != i.rows || pre_W != i.cols)
        {
            LG &lt;&lt; "输入图片尺寸不一致";
            throw runtime_error("输入图片尺寸不一致!");
        }
        pre_H = i.rows;
        pre_W = i.cols;
    }
}

int H = ori_image_vec[0].rows;
int W = ori_image_vec[0].cols;
float times;
vector&lt;float&gt; array;
//std::vector&lt;uchar&gt; array;
if (H &gt; W)
{ //当高大于宽时
    if ((H * short_side) &gt; (maxLongSide * W))
    { //当图片过于狭长时,选用长边为固定边
        times = maxLongSide * 1.0 / H;
    }
    else
    { //当图片不狭长时,选用短边为固定边
        times = short_side * 1.0 / W;
    }
}
else
{ //当宽大于高时
    if ((W * short_side) &gt; (maxLongSide * H))
    { //当图片过于狭长时,选用长边为固定边
        times = maxLongSide * 1.0 / W;
    }
    else
    { //当图片不狭长时,选用短边为固定边
        times = short_side * 1.0 / H;
    }
}

if (model_type == "YOLO")
{
    new_height = int(times * H) / 32 * 32;
    new_width = int(times * W) / 32 * 32;
}
else if (model_type == "SSD")
{
    new_height = int(times * H);
    new_width = int(times * W);
}
else
{
    LG &lt;&lt; "no model type  match with " &lt;&lt; model_type &lt;&lt; " !" &lt;&lt; endl;
    throw runtime_error("wrong value with model type !");
}
//图片标准化
cv::Mat im;
int channels = 3;
int bach_size = ori_image_vec.size();
cv::resize(ori_image_vec[0], im, cv::Size(new_width, new_height));
int size = im.rows * im.cols * channels;
std::vector&lt;std::vector&lt;float&gt;&gt; files(bach_size);
files[0].resize(size);

float *image_data = files[0].data();
float *ptr_image_b = image_data;
float mean_b = 0.485;
float mean_g = 0.456;
float mean_r = 0.406;
float std_b = 0.229;
float std_g = 0.224;
float std_r = 0.225;

for (int i = 0; i &lt; im.rows; ++i)
{
    auto data = im.ptr&lt;uchar&gt;(i);
    for (int j = 0; j &lt; im.cols; j++)
    {
        *ptr_image_b++ = (static_cast&lt;float&gt;(*data++) / 255.0 - mean_b) / std_b;
        *ptr_image_b++ = (static_cast&lt;float&gt;(*data++) / 255.0 - mean_g) / std_g;
        *ptr_image_b++ = (static_cast&lt;float&gt;(*data++) / 255.0 - mean_r) / std_r;
    }
}

//transpose shape from (h,w,c) to (c,h,w)
for (int k = 0; k &lt; 1; k++)
{
    for (int c = 0; c &lt; 3; ++c)
    {
        for (int i = 0; i &lt; new_height; ++i)
        {
            for (int j = 0; j &lt; new_width; ++j)
            {
                array.push_back(static_cast&lt;float&gt;(image_data[(i * new_width + j) * 3 + c]));
            }
        }
    }
}

//expend shape from (c,h,w) to (1,c,h,w)
Shape image_shape = Shape(1, 3, new_height, new_width);
NDArray transformed_image = NDArray(image_shape, global_ctx, false);

transformed_image.SyncCopyFromCPU(array.data(), image_shape.Size());
NDArray::WaitAll();
return transformed_image;
&lt;/denchmark-code&gt;

}
//
void PredictFromMat(const NDArray&amp; normalized_images,const float &amp;height_plus, const float &amp;width_plus)
{
std::lock_guardstd::mutex _guard(mut);
&lt;denchmark-code&gt;normalized_images.CopyTo(&amp;(executor-&gt;arg_dict()["data"]));
NDArray::WaitAll();

// Run the forward pass.
executor-&gt;Forward(false);

// The output is available in executor-&gt;outputs.
auto ids = executor-&gt;outputs[0].Copy(Context(kCPU, 0));
auto scores = executor-&gt;outputs[1].Copy(Context(kCPU, 0));
auto bboxes = executor-&gt;outputs[2].Copy(Context(kCPU, 0));
NDArray::WaitAll();
malloc_trim(0);
&lt;/denchmark-code&gt;

}
int main() {
&lt;denchmark-code&gt;net = Symbol::Load("/home/enhance/workspace/json/walker-ssd-symbol.json");
LoadParameters("/home/enhance/workspace/params/walker-ssd.params");

//获取执行器
args_map["data"] = NDArray(Shape(batch_size), global_ctx);
executor = net.SimpleBind(global_ctx, args_map, map&lt;string, NDArray&gt;(),map&lt;string, OpReqType&gt;(),aux_map);

cv::Mat frame;
vector&lt;cv::Mat&gt;vframe;
frame = cv::imread("/home/enhance/png/0.jpg");
vframe.push_back(frame);
int w,h;
NDArray normalized_images = YOLOSSDTransform(vframe,h,w);
frame.release();
vframe.clear();

for (auto i = 0;i&lt;1000000;i++){
    cout&lt;&lt;i&lt;&lt;endl;
    auto fun = [&amp;normalized_images, h, w] { return PredictFromMat(normalized_images, h, w); };
    std::thread go(fun);
    go.join();
}
&lt;/denchmark-code&gt;

}
`
	</description>
	<comments>
		<comment id='1' author='zhongqingyang' date='2020-07-06T15:27:26Z'>
		This api may not support multi thread safety.
		</comment>
	</comments>
</bug>