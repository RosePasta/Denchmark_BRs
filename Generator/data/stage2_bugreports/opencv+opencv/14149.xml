<bug id='14149' author='JaosonMa' open_date='2019-03-26T03:00:08Z' closed_time='2019-03-27T13:42:59Z'>
	<summary>c++ opencv4.01 called  tensorflow inception-v4 model ,readNetFromTensorflow ERROR!</summary>
	<description>
train a tf flowers model with inception-v4,
after got the mode.ckpy , use the code to convert it:
echo "create model.pb over"
cd ..
CUDA_VISIBLE_DEVICES=1 python3 -u export_inference_graph.py 
--model_name=inception_v4 
--output_file=./data/flowers_5/models/infer/flowers.pb 
--dataset_name=flowers 
--dataset_dir=./data/flowers_5
echo "start create frzee pb"
CUDA_VISIBLE_DEVICES=1 python3 -u /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools/freeze_graph.py 
--input_graph=./data/flowers_5/models/infer/flowers.pb 
--input_checkpoint=./data/flowers_5/models/model.ckpt-10027 
--output_graph=./data/flowers_5/models/infer/my_freeze.pb 
--input_binary=True 
--output_node_name=InceptionV4/Logits/Predictions
i test the flowers.pb with  classify.sh (&lt;denchmark-link:https://github.com/isiosia/models/tree/lession/slim&gt;https://github.com/isiosia/models/tree/lession/slim&lt;/denchmark-link&gt;
)
it works well
id:[0] name:[daisy] (score = 0.80188)
id:[1] name:[dandelion] (score = 0.11308)
id:[3] name:[sunflowers] (score = 0.05036)
id:[4] name:[tulips] (score = 0.02128)
id:[2] name:[roses] (score = 0.01340)
then  i use it for vs2015+opencv4.01, with the code
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54968514-ef102b80-4fb5-11e9-8871-74955b2431ba.png&gt;&lt;/denchmark-link&gt;

then got the error
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54968526-00f1ce80-4fb6-11e9-8fbb-be9cd56edac0.png&gt;&lt;/denchmark-link&gt;

load models
OpenCV: terminate handler is called! The last OpenCV error is:
OpenCV(4.0.1) Error: Assertion failed (scaleMat.type() == CV_32FC1) in cv::dnn::dnn4_v20181221::`anonymous-namespace'::TFImporter::populateNet, file E:\product\opencv-4.0.1\modules\dnn\src\tensorflow\tf_importer.cpp, line 1377
so  i dont know where was wrong?
how can i make it work in c++ opoencv4.01?
&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='JaosonMa' date='2019-03-26T03:54:06Z'>
		Usage questions should go to Users OpenCV Q/A forum: &lt;denchmark-link:http://answers.opencv.org&gt;http://answers.opencv.org&lt;/denchmark-link&gt;

If you think this is a bug which should be fixed - provide complete reproducer including models.
		</comment>
		<comment id='2' author='JaosonMa' date='2019-03-26T04:05:55Z'>
		
Usage questions should go to Users OpenCV Q/A forum: http://answers.opencv.org
If you think this is a bug which should be fixed - provide complete reproducer including models.

i have done this, but there don have the A,
		</comment>
		<comment id='3' author='JaosonMa' date='2019-03-26T04:58:53Z'>
		We really don't have spare time to download datasets and try to train models using outdated instructions (you point on commits which are modified 2+ years ago).
Reproducer should have:

OpenCV C++ code
data/images processed by OpenCV code
no more external dependencies.

Ask for help on &lt;denchmark-link:http://answers.opencv.org&gt;http://answers.opencv.org&lt;/denchmark-link&gt;
 if you are not able to provide this.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Could you try add this before mentioned assertion?
+std::cout &lt;&lt; typeToString(scaleMat.type()) &lt;&lt; std::endl;
+scaleMat.convertTo(scaleMat, CV_32FC1);
 CV_Assert(scaleMat.type() == CV_32FC1);
		</comment>
		<comment id='4' author='JaosonMa' date='2019-03-26T05:36:29Z'>
		
std::cout &lt;&lt; typeToString(scaleMat.type()) &lt;&lt; std::endl;
+scaleMat.convertTo(scaleMat, CV_32FC1);

i tried the code ,
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54973516-33f28d00-4fcb-11e9-9e7d-1b5d2355b079.png&gt;&lt;/denchmark-link&gt;

here is the result before change and after change with debug
before change:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54973685-e0cd0a00-4fcb-11e9-91d7-97fff664a7d6.png&gt;&lt;/denchmark-link&gt;

after change:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54973571-72884780-4fcb-11e9-97fb-926b986f3eb6.png&gt;&lt;/denchmark-link&gt;

here is my pb.  baidu ，i don 't know can you download or not ,
链接：&lt;denchmark-link:https://pan.baidu.com/s/1d9nWjKV_NCLFuzReOP4WKQ&gt;https://pan.baidu.com/s/1d9nWjKV_NCLFuzReOP4WKQ&lt;/denchmark-link&gt;

提取码：94sx
c++ code
#include "pch.h"
#include &lt;opencv2/dnn.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
#include &lt;Windows.h&gt;
#include 
#include 
#include 
using namespace cv;
using namespace cv::dnn;
using namespace std;
//自己新建一个txt文件，写入分类的标签（一行写一个标签，例如二分类，第一行写good，第二行bad）
string labels_txt_file = R"(D:\downloads\googledownloads\labels.txt)";
string tf_pb_file = R"(D:\downloads\googledownloads\my_freeze.pb)";
vector  readClassNames();
void main()
{
Mat src = imread(R"(D:\downloads\googledownloads\437859108_173fb33c98.jpg)");
if (src.empty())	{
cout &lt;&lt; "error:no img" &lt;&lt; endl;
}
vector  labels = readClassNames();
Mat rgb;
int w = 299;
int h = 299;
resize(src, src, Size(w, h));
cvtColor(src, rgb, COLOR_BGR2RGB);
cout &lt;&lt; "load models" &lt;&lt; endl;
Net net = readNetFromTensorflow(tf_pb_file);
cout &lt;&lt; "load over" &lt;&lt; endl;
DWORD timestart = GetTickCount();
if (net.empty())
{
cout &lt;&lt; "error:no model" &lt;&lt; endl;
}
Mat inputBlob = blobFromImage(src, 0.00390625f, Size(w, h), Scalar(), true, false);
//inputBlob -= 117.0;
//执行图像分类
Mat prob;
net.setInput(inputBlob, "input");
prob = net.forward("output");
cout &lt;&lt; prob &lt;&lt; endl;
//prob=net.forward("softmax2");
//得到最大分类概率
Mat probMat = prob.reshape(1, 1);
Point classNumber;
double classProb;
minMaxLoc(probMat, NULL, &amp;classProb, NULL, &amp;classNumber);
DWORD timeend = GetTickCount();
int classidx = classNumber.x;
printf("\n current image classification : %s, possible : %.2f\n", labels.at(classidx).c_str(), classProb);
cout &lt;&lt; "用时(毫秒):" &lt;&lt; timeend - timestart &lt;&lt; endl;
// 显示文本
putText(src, labels.at(classidx), Point(20, 20), FONT_HERSHEY_SIMPLEX, 1.0, Scalar(0, 0, 255), 2, 8);
imshow("Image Classfication", src);
waitKey(0);
}
vector readClassNames()
{
vector classNames;
fstream fp(labels_txt_file);
if (!fp.is_open())
{
cout &lt;&lt; "does not open" &lt;&lt; endl;
exit(-1);
}
string name;
while (!fp.eof())
{
getline(fp, name);
if (name.length())
classNames.push_back(name);
}
fp.close();
return classNames;
}
		</comment>
		<comment id='5' author='JaosonMa' date='2019-03-26T06:45:43Z'>
		here is the layers in my_freeze.pb
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/54976755-39a1a000-4fd6-11e9-9f71-3ff9987015de.png&gt;&lt;/denchmark-link&gt;

input
DecodePng
eval_image/convert_image/Cast
eval_image/convert_image/y
eval_image/convert_image
eval_image/central_crop/Shape_1
eval_image/central_crop/strided_slice/stack
eval_image/central_crop/strided_slice/stack_1
eval_image/central_crop/strided_slice/stack_2
eval_image/central_crop/strided_slice
eval_image/central_crop/Shape_2
eval_image/central_crop/strided_slice_1/stack
eval_image/central_crop/strided_slice_1/stack_1
eval_image/central_crop/strided_slice_1/stack_2
eval_image/central_crop/strided_slice_1
eval_image/central_crop/ToDouble
eval_image/central_crop/mul/y
eval_image/central_crop/mul
eval_image/central_crop/sub
eval_image/central_crop/truediv/y
eval_image/central_crop/truediv
eval_image/central_crop/ToInt32
eval_image/central_crop/ToDouble_1
eval_image/central_crop/mul_1/y
eval_image/central_crop/mul_1
eval_image/central_crop/sub_1
eval_image/central_crop/truediv_1/y
eval_image/central_crop/truediv_1
eval_image/central_crop/ToInt32_1
eval_image/central_crop/mul_2/y
eval_image/central_crop/mul_2
eval_image/central_crop/sub_2
eval_image/central_crop/mul_3/y
eval_image/central_crop/mul_3
eval_image/central_crop/sub_3
eval_image/central_crop/stack/2
eval_image/central_crop/stack
eval_image/central_crop/stack_1/2
eval_image/central_crop/stack_1
eval_image/central_crop/Slice
eval_image/ExpandDims/dim
eval_image/ExpandDims
eval_image/ResizeBilinear/size
eval_image/ResizeBilinear
eval_image/Squeeze
eval_image/Sub/y
eval_image/Sub
eval_image/Mul/y
eval_image/Mul
ExpandDims/dim
ExpandDims
InceptionV4/Conv2d_1a_3x3/weights
InceptionV4/Conv2d_1a_3x3/weights/read
InceptionV4/InceptionV4/Conv2d_1a_3x3/Conv2D
InceptionV4/InceptionV4/Conv2d_1a_3x3/BatchNorm/Const
InceptionV4/Conv2d_1a_3x3/BatchNorm/beta
InceptionV4/Conv2d_1a_3x3/BatchNorm/beta/read
InceptionV4/Conv2d_1a_3x3/BatchNorm/moving_mean
InceptionV4/Conv2d_1a_3x3/BatchNorm/moving_mean/read
InceptionV4/Conv2d_1a_3x3/BatchNorm/moving_variance
InceptionV4/Conv2d_1a_3x3/BatchNorm/moving_variance/read
InceptionV4/InceptionV4/Conv2d_1a_3x3/BatchNorm/FusedBatchNorm
InceptionV4/InceptionV4/Conv2d_1a_3x3/Relu
InceptionV4/Conv2d_2a_3x3/weights
InceptionV4/Conv2d_2a_3x3/weights/read
InceptionV4/InceptionV4/Conv2d_2a_3x3/Conv2D
InceptionV4/InceptionV4/Conv2d_2a_3x3/BatchNorm/Const
InceptionV4/Conv2d_2a_3x3/BatchNorm/beta
InceptionV4/Conv2d_2a_3x3/BatchNorm/beta/read
InceptionV4/Conv2d_2a_3x3/BatchNorm/moving_mean
InceptionV4/Conv2d_2a_3x3/BatchNorm/mo
...
InceptionV4/Logits/PreLogitsFlatten/flatten/strided_slice/stack
InceptionV4/Logits/PreLogitsFlatten/flatten/strided_slice/stack_1
InceptionV4/Logits/PreLogitsFlatten/flatten/strided_slice/stack_2
InceptionV4/Logits/PreLogitsFlatten/flatten/strided_slice
InceptionV4/Logits/PreLogitsFlatten/flatten/Reshape/shape/1
InceptionV4/Logits/PreLogitsFlatten/flatten/Reshape/shape
InceptionV4/Logits/PreLogitsFlatten/flatten/Reshape
InceptionV4/Logits/Logits/weights
InceptionV4/Logits/Logits/weights/read
InceptionV4/Logits/Logits/biases
InceptionV4/Logits/Logits/biases/read
InceptionV4/Logits/Logits/MatMul
InceptionV4/Logits/Logits/BiasAdd
InceptionV4/Logits/Predictions
&lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='JaosonMa' date='2019-03-26T06:50:30Z'>
		here is my train.sh with tensorflow's slim API:
cd ..
CUDA_VISIBLE_DEVICES=1 python3 train_image_classifier.py 
--dataset_name=flowers 
--dataset_dir=./data/flowers_5 
--model_name=inception_v4 
--train_dir=./data/flowers_5/models 
--learning_rate=0.001 
--learning_rate_decay_factor=0.76 
--num_epochs_per_decay=50 
--moving_average_decay=0.9999 
--optimizer=adam 
--ignore_missing_vars=True 
--batch_size=32
		</comment>
		<comment id='7' author='JaosonMa' date='2019-03-26T07:37:16Z'>
		
i have done this, but there don have the A,

I can not find your question on answers.opencv.org? Please provide a link.
		</comment>
		<comment id='8' author='JaosonMa' date='2019-03-26T07:59:36Z'>
		

i have done this, but there don have the A,

I can not find your question on answers.opencv.org? Please provide a link.

sorry , i mean i don't find the A on answers.opencv.org? and  i can not sing in or create an username,
so i have not ask this Q on answers.opecn.org , so sorry
		</comment>
		<comment id='9' author='JaosonMa' date='2019-03-26T13:43:41Z'>
		OpenCV: terminate handler is called! The last OpenCV error is:
OpenCV(4.0.1) Error: Unspecified error (Input [eval_image/central_crop/stack] for node [eval_image/central_crop/Slice] not found) in cv::dnn::dnn4_v20181221::`anonymous-namespace'::TFImporter::getConstBlob, file E:\product\opencv-4.0.1\modules\dnn\src\tensorflow\tf_importer.cpp, line 535
		</comment>
		<comment id='10' author='JaosonMa' date='2019-03-27T09:23:21Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, Please follow issue's template and make it reproducible. Provide a reference to model so we can test it locally.
		</comment>
		<comment id='11' author='JaosonMa' date='2019-03-27T09:56:55Z'>
		&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; :4.01:
Operating System / Platform =&gt; win10 64bite
Compiler =&gt; :vs2017 x86:

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

i train a model with a tensorflow slim, inception-v4 with code like this
CUDA_VISIBLE_DEVICES=1 python3 train_image_classifier.py \ --dataset_name=flowers \ --dataset_dir=./data/flowers_5 \ --model_name=inception_v4 \ --train_dir=./data/flowers_5/models \ --learning_rate=0.001 \ --learning_rate_decay_factor=0.76 \ --num_epochs_per_decay=50 \ --moving_average_decay=0.9999 \ --optimizer=adam \ --ignore_missing_vars=True \ --batch_size=32
1&gt; i got a tf-model save as model.ckpt-xxx
2&gt; freeze the model to .pb file with the code like this
`echo "create model.pb start"
CUDA_VISIBLE_DEVICES=1 python3 -u export_inference_graph.py 
--model_name=inception_v4 
--output_file=./data/flowers_5/models/infer_isiosia/flowers.pb 
--dataset_name=flowers 
--dataset_dir=./data/flowers_5
echo "start create frzee pb"
CUDA_VISIBLE_DEVICES=1 python3 -u /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools/freeze_graph.py 
--input_graph=./data/flowers_5/models/infer_isiosia/flowers.pb 
--input_checkpoint=./data/flowers_5/models/model.ckpt-10027 
--output_graph=./data/flowers_5/models/infer_isiosia/my_freeze.pb 
--input_binary=True 
--output_node_name=InceptionV4/Logits/Predictions
`
3&gt; use the my_freeze.pb to opencv4.01 + vs2017 with code like this
first  i got the error , like this
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55066524-f2d8a680-50b8-11e9-9ac4-56ce48ceebc8.png&gt;&lt;/denchmark-link&gt;

then add some code  in openv-dnn module, as &lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
 say
&lt;denchmark-link:https://github.com/opencv/opencv/issues/14149#issuecomment-476475899&gt;#14149 (comment)&lt;/denchmark-link&gt;

then got the error like this
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55066664-392e0580-50b9-11e9-8879-5259a8200311.png&gt;&lt;/denchmark-link&gt;

OpenCV: terminate handler is called! The last OpenCV error is:
OpenCV(4.0.1) Error: Unspecified error (Input [eval_image/central_crop/stack] for node [eval_image/central_crop/Slice] not found) in cv::dnn::dnn4_v20181221::`anonymous-namespace'::TFImporter::getConstBlob, file E:\product\opencv-4.0.1\modules\dnn\src\tensorflow\tf_importer.cpp, line 535
&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

'
using namespace cv;
using namespace cv::dnn;
using namespace std;
string labels_txt_file = R"(D:\downloads\googledownloads\labels.txt)";
string tf_pb_file = R"(D:\downloads\googledownloads\my_freeze.pb)";
vector  readClassNames();
void main()
{
Mat src = imread(R"(D:\downloads\googledownloads\437859108_173fb33c98.jpg)");
if (src.empty())	{
cout &lt;&lt; "error:no img" &lt;&lt; endl;
}
vector  labels = readClassNames();
Mat rgb;
int w = 299;
int h = 299;
resize(src, src, Size(w, h));
cvtColor(src, rgb, COLOR_BGR2RGB);
cout &lt;&lt; "load models" &lt;&lt; endl;
Net net = readNetFromTensorflow(tf_pb_file);
cout &lt;&lt; "load over" &lt;&lt; endl;
DWORD timestart = GetTickCount();
if (net.empty())
...
}
'
pb.file
link: (&lt;denchmark-link:https://pan.baidu.com/s/14nIYO6yeHaPCDrRCXRsuGQ&gt;https://pan.baidu.com/s/14nIYO6yeHaPCDrRCXRsuGQ&lt;/denchmark-link&gt;
)
pwd:imzb
&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

forgive me for my bad english !!
		</comment>
		<comment id='12' author='JaosonMa' date='2019-03-27T10:01:44Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, please do not use Baidu for sharing. We just cannot download anything from there because it downloads  files! Please provide a direct link.
		</comment>
		<comment id='13' author='JaosonMa' date='2019-03-27T10:13:30Z'>
		
@JaosonMa, please do not use Baidu for sharing. We just cannot download anything from there because it downloads .exe files! Please provide a direct link.

sorry, i can not google , and i  can not find some good ways ,that can just provide a direct link ,  can you give me a email or some other ways... so sorry for thie
		</comment>
		<comment id='14' author='JaosonMa' date='2019-03-27T10:24:54Z'>
		

@JaosonMa, please do not use Baidu for sharing. We just cannot download anything from there because it downloads .exe files! Please provide a direct link.

sorry, i can not google , and i can not find some good ways ,that can just provide a direct link , can you give me a email or some other ways... so sorry for thie

can you tell me , my steps was right or not,
1&gt; use tensorflow - slim train a model ( &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/preprocessing_factory.py&gt;https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/preprocessing_factory.py&lt;/denchmark-link&gt;
 )saved as model.ckpt
2&gt;, use export_inference_graph.py export the model.pb file
3&gt;. use freeze_graph.py ceate the freeze.pb
does opencv 4.01 can load the the freeze.pb direct or not ?
did i miss some steps?
		</comment>
		<comment id='15' author='JaosonMa' date='2019-03-27T10:29:43Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, please try Dropbox at least.
		</comment>
		<comment id='16' author='JaosonMa' date='2019-03-27T10:34:40Z'>
		
@JaosonMa, please try Dropbox at least.
ok  ,i will give a shoot.
i also tried this mobilenet_v2_1.0_224

&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55069296-ab551900-50be-11e9-92c3-0fba550c13d0.png&gt;&lt;/denchmark-link&gt;

does the mobilenet_v2_1.4_224_frozen.pb can used by opencv4.01 direct?
		</comment>
		<comment id='17' author='JaosonMa' date='2019-03-27T11:14:52Z'>
		
@JaosonMa, please try Dropbox at least.

i faild , my internet can not use DropBox
		</comment>
		<comment id='18' author='JaosonMa' date='2019-03-27T12:16:01Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, Thanks for your issue! Please test the changes from PR &lt;denchmark-link:https://github.com/opencv/opencv/pull/14166&gt;#14166&lt;/denchmark-link&gt;
. It'll be merged into 3.4 and then ported to master branch.
		</comment>
		<comment id='19' author='JaosonMa' date='2019-03-27T13:42:48Z'>
		
@JaosonMa, Thanks for your issue! Please test the changes from PR #14166. It'll be merged into 3.4 and then ported to master branch.

i change these codes in my opencv4.01 source code
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55078051-2f65cb80-50d4-11e9-9ed9-0ce8521cc8e9.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55078094-473d4f80-50d4-11e9-806d-2b232a50d1a7.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55078110-52907b00-50d4-11e9-96f7-4fe9e211095a.png&gt;&lt;/denchmark-link&gt;

then rebuild the opencvdnn modules . try two times with diffient codes:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55078452-288b8880-50d5-11e9-855f-f0f0b9b2ebb3.png&gt;&lt;/denchmark-link&gt;

and  mobilenet_v2 SUCC!
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55079100-82408280-50d6-11e9-94c0-541dd0ad927b.png&gt;&lt;/denchmark-link&gt;

But  inceptionv-v4 Failed!
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55080449-2297a680-50d9-11e9-82ab-3c8ee56ac1cf.png&gt;&lt;/denchmark-link&gt;

i closed this , i think i must do something wrong with the inception-v4, i will keep trying....
		</comment>
		<comment id='20' author='JaosonMa' date='2019-04-09T06:18:53Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;

I tried many many times ,but always failed! ,so please help me again!
i ran the &lt;denchmark-link:https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz&gt;mobilenet_v2_1.0_224&lt;/denchmark-link&gt;
 sucess!
so i train the data again with mobilenet_v2_1.0_224 on my data,
after training, got the ckpt,
`cd ..
&lt;denchmark-h:h1&gt;Where the pre-trained MobilenetV1 checkpoint is saved to.&lt;/denchmark-h&gt;

PRETRAINED_CHECKPOINT_DIR=./data/flowers_2/models/all
&lt;denchmark-h:h1&gt;Where the training (fine-tuned) checkpoint and logs will be saved to.&lt;/denchmark-h&gt;

TRAIN_DIR=/tmp/flowers-models/mobilenet_v1_1.0_224
&lt;denchmark-h:h1&gt;Where the dataset is saved to.&lt;/denchmark-h&gt;

DATASET_DIR=./data/flowers_2
DATASET_NAME=flowers
INFER_DIR=./data/flowers_2/models/all/infer
MODEL_NAME=mobilenet_v2_140
echo "create model.pb start"
CUDA_VISIBLE_DEVICES=0 python3 -u export_inference_graph.py 
--model_name=${MODEL_NAME} 
--output_file=${INFER_DIR}/flowers.pb 
--dataset_name=${DATASET_NAME} 
--dataset_dir=${DATASET_DIR}
echo "start create frzee pb"
CUDA_VISIBLE_DEVICES=0 python3 -u /usr/local/lib/python3.5/dist-packages/tensorflow/python/tools/freeze_graph.py 
--input_graph=${INFER_DIR}/flowers.pb 
--input_checkpoint=${PRETRAINED_CHECKPOINT_DIR}/model.ckpt-44885 
--output_graph=${INFER_DIR}/my_freeze.pb 
--input_binary=True 
--output_node_name=MobilenetV2/Predictions/Reshape_1
`
&lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/slim/export_inference_graph.py&gt;export_inference_graph.pu&lt;/denchmark-link&gt;

then i got the &lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/flowers.pb&gt;flowers.pb&lt;/denchmark-link&gt;

and the &lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/my_freeze.pb&gt;my_freeze.pb&lt;/denchmark-link&gt;

the use the  same code ,the got error :
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55776601-e1879500-5acf-11e9-9f65-34c1bda09410.png&gt;&lt;/denchmark-link&gt;

it seems like that some layers was not found in opencv4.01,so i check the two pbfile(my_freeze.pb and mobilenet_v2_1.0_224_frozen.pb) with code like this:
`mobile_net = '../data/mobilenet_v2_1.4_224/mobilenet_v2_1.4_224_frozen.pb'
my_mobile_net = '../data/flowers_2/models/all/infer/my_freeze.pb'
def create_graph():
with tf.gfile.FastGFile(my_mobile_net, 'rb') as f:
graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())
tf.import_graph_def(graph_def, name='')
create_graph()
tensor_name_list_my = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]
print(len(tensor_name_list))
print(len(tensor_name_list_my))
for idx,tensor_name in enumerate(tensor_name_list_my):
if(idx&lt;len(tensor_name_list)):
print(idx+1,"--&gt;",tensor_name,idx+1,"--&gt;",tensor_name_list[idx],'\n')
else:
print(idx+1,"--&gt;",tensor_name,'\n')
`
the length is not same ,
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55777285-14328d00-5ad2-11e9-8fd2-cc32c41eb3eb.png&gt;&lt;/denchmark-link&gt;

...
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55777307-2280a900-5ad2-11e9-96a5-938c4a5abee2.png&gt;&lt;/denchmark-link&gt;

...
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55777323-2b717a80-5ad2-11e9-8c9b-ae41b0fa2276.png&gt;&lt;/denchmark-link&gt;

so i think some thing was wrong with my export_inference_graph.py, can you tell me how can i got the pb just as same as the tf's mobilenet_v1_1.0_224_.pb,
		</comment>
		<comment id='21' author='JaosonMa' date='2019-04-09T07:18:14Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, before the neural network this graph has a lot of support nodes (jpeg decoding, cropping, resizing). It's might be done out of the network (i.e. by blobFromImage). So you can remove these nodes:
before:
&lt;denchmark-link:https://user-images.githubusercontent.com/25801568/55780245-30253700-5ab0-11e9-9170-9949135cdbc9.png&gt;&lt;/denchmark-link&gt;

import tensorflow as tf
from tensorflow.tools.graph_transforms import TransformGraph

with tf.gfile.FastGFile('my_freeze.pb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

graph_def = TransformGraph(graph_def, ["ExpandDims"], ["MobilenetV2/Predictions/Reshape_1"], ["strip_unused_nodes"])
with tf.gfile.FastGFile("graph.pb", 'wb') as f:
    f.write(graph_def.SerializeToString())
after:
&lt;denchmark-link:https://user-images.githubusercontent.com/25801568/55780465-a2961700-5ab0-11e9-9003-4c1878b3a866.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='22' author='JaosonMa' date='2019-04-09T07:53:05Z'>
		first  thank you a lot!!!
i try the code you give me,  error like this :
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55782065-1f8bb580-5ade-11e9-9773-a3e569a17d2f.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55782077-231f3c80-5ade-11e9-831c-788381f7753e.png&gt;&lt;/denchmark-link&gt;

so i change from
 to 
then it run succ
got the &lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/frozen_graph.pb&gt;frozen_graph.pb&lt;/denchmark-link&gt;

use frozen_graph.pb in opencv4.01 ,got error:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55782538-16e7af00-5adf-11e9-8bd7-47d7926046eb.png&gt;&lt;/denchmark-link&gt;

so i print the nodes , like this:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55782610-44345d00-5adf-11e9-8ddc-acf61b3eb77d.png&gt;&lt;/denchmark-link&gt;

so which is the input?
`       Net net = readNetFromTensorflow(tf_pb_file);
Mat src = imread(R"(D:\downloads\googledownloads\dc165458a6955e67399f2186f90cccc9.jpg)");
&lt;denchmark-code&gt;Mat rgb;
int w = 224;
int h = 224;
resize(src, src, Size(w, h));
Mat inputBlob = blobFromImage(src, 0.00390625f, Size(w, h), Scalar(), true, false);
Mat prob;
net.setInput(inputBlob, "input");  // what should i put in there?
prob = net.forward("MobilenetV2/Predictions/Reshape_1");`
&lt;/denchmark-code&gt;

net.setInput(inputBlob, "input");   what should i put in there?
&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='JaosonMa' date='2019-04-09T07:56:50Z'>
		Mat prob; net.setInput(inputBlob, "ExpandDims"); prob = net.forward("MobilenetV2/Predictions/Reshape_1");
i put ExpandDims in ，it run succ!
i think it is right!
		</comment>
		<comment id='24' author='JaosonMa' date='2019-04-11T13:17:19Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
  So sorry to disturb you again.
I used the pb with input:ExpanDims run succ in opencv4.01,
but the acc is lower than the my_freeze.pb in tensorflow code ,
the acc when before TransformGraph:
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55959561-97540e80-5c9d-11e9-8525-7962e5c2e0a2.png&gt;&lt;/denchmark-link&gt;

my data only have two classes, They are somewhat similar. so acc=0.9 It's almost what I expected.
but used the pb after TranfromGraph , the acc is only 0.65, i don't know why, i check three  graphs in tensorboard ,1&gt; tensorflow's slim mobilenet_v2_1.4_224.pb 2&gt; my_freeze.pb 3&gt;frozen_graph.pb
the mobilenetV2 part is all the same
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55959948-6c1def00-5c9e-11e9-910b-e62d21fb403a.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55959967-73dd9380-5c9e-11e9-8241-73656072d9fe.png&gt;&lt;/denchmark-link&gt;

but  there input layer was diffient ,
1&gt; mobilenet_v2_1.4_224.pb
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55960169-d040b300-5c9e-11e9-8f76-793a8fb9a10c.png&gt;&lt;/denchmark-link&gt;

2&gt;my_freeze.pb
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55960304-0847f600-5c9f-11e9-9c7d-0f2af994b0c1.png&gt;&lt;/denchmark-link&gt;

3&gt;froze_graph.pb
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55960106-af785d80-5c9e-11e9-8d6f-0ca76f277ff2.png&gt;&lt;/denchmark-link&gt;

can i just got a pb , just like the mobilenet_v2_1.4_224.pb with the input "input",
Is it possible that this input caused the reduction?
		</comment>
		<comment id='25' author='JaosonMa' date='2019-04-11T13:36:27Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, Please provide two code snippets: how you run the model with TensorFlow and with OpenCV. Please make it as minimal as possible: remove dataset reading. Just a single image.
		</comment>
		<comment id='26' author='JaosonMa' date='2019-04-11T14:11:59Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

tensorflow:
classify code: &lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/classify.py&gt;classify.py&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/my_freeze.pb&gt;my_freeze.pb:&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/classify.sh&gt;class.sh:&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/labels.txt&gt;labels.txt:&lt;/denchmark-link&gt;

c++:
&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/edit/master/pch.cpp&gt;classfi.cpp:&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/frozen_graph.pb&gt;frozen_graph.pb:&lt;/denchmark-link&gt;

labels.txt: same as tenflow labels.txt
&lt;denchmark-link:https://github.com/JaosonMa/for-models-download/blob/master/2_1_25_3_1.jpg&gt;test_img:&lt;/denchmark-link&gt;

this image is one of the val data , its label is 'N'
in my computer :
tensorflow output is
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55964100-af7c5b80-5ca6-11e9-9ea5-d928c036c0c8.png&gt;&lt;/denchmark-link&gt;

C++ outPut is
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/55964159-cae76680-5ca6-11e9-964f-f7e9635f9584.png&gt;&lt;/denchmark-link&gt;

it is diffient!
		</comment>
		<comment id='27' author='JaosonMa' date='2019-04-12T04:56:37Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
  Is this enough for you to debug?What else do you need?I will certainly give it to you.
		</comment>
		<comment id='28' author='JaosonMa' date='2019-04-12T08:15:17Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 please help me , My project has been delayed for 10 days.
&lt;denchmark-link:https://user-images.githubusercontent.com/23551774/56022390-2284e100-5d3e-11e9-9b16-6ffab7e52e2c.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='29' author='JaosonMa' date='2019-04-12T08:20:52Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, please stop it. We already figured out that the problem might be fixed with current version of OpenCV. For now the question is to align TensorFlow and OpenCV usage. Actually, the problem in your code. So be patient please.
		</comment>
		<comment id='30' author='JaosonMa' date='2019-04-12T08:24:41Z'>
		got you , so sorry for what i have done , i will just wait .
		</comment>
		<comment id='31' author='JaosonMa' date='2019-04-13T15:05:20Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
, There are two nodes which impact on different predictions from OpenCV and TensorFlow:  and . The thing is that precision of Jpeg decoding is not similar even between different versions of decoding libraries. ResizeBilinear's interpolation strategy differs from OpenCV's one.
So to achieve similar outputs you need to pass similar inputs to the node after these ones:
import numpy as np
import cv2 as cv

import tensorflow as tf
from tensorflow.tools.graph_transforms import TransformGraph

image = cv.imread("2_1_25_3_1.jpg")
image = image[:,:,[2,1,0]]  # BGB 2 RGB
image = cv.resize(image, (224, 224))
paddedImage = cv.copyMakeBorder(image, 15, 15, 15, 15, cv.BORDER_CONSTANT)

#
# TensorFlow
#
with tf.gfile.FastGFile("my_freeze.pb", 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Session() as sess:
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='')

    tfOut = sess.run(sess.graph.get_tensor_by_name('MobilenetV2/Predictions/Reshape_1:0'),
                     feed_dict={'eval_image/convert_image/Cast:0': paddedImage})
    print tfOut

#
# OpenCV
#
net = cv.dnn.readNet("graph.pb")
net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)

blob = cv.dnn.blobFromImage(image, 1.0/127.5, (224, 224), [127.5, 127.5, 127.5])
net.setInput(blob)
cvOut = net.forward()

print cvOut
Central crop looks also a bit confusing (it crops by a 0.875 ratio). So I resized an image out of the graph and added zero paddings so both Central Crop and ResizeBilinear don't affect an accuracy:
&lt;denchmark-code&gt;TF
[[1.7407431e-01 8.2585084e-01 3.5822773e-05 3.9013106e-05]]
CV
[[1.7408027e-01 8.2584488e-01 3.5821628e-05 3.9013088e-05]]
&lt;/denchmark-code&gt;

To achieve better similarity, you man try to define  layer as a custom one (read a tutorial &lt;denchmark-link:https://docs.opencv.org/master/dc/db1/tutorial_dnn_custom_layers.html&gt;https://docs.opencv.org/master/dc/db1/tutorial_dnn_custom_layers.html&lt;/denchmark-link&gt;
) so  will be inside a graph.
Please use a forum for future usage questions: &lt;denchmark-link:http://answers.opencv.org&gt;http://answers.opencv.org&lt;/denchmark-link&gt;

		</comment>
		<comment id='32' author='JaosonMa' date='2019-05-21T14:15:17Z'>
		Hey &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
, can you clarify the reason to the 15 pixel padding?
		</comment>
		<comment id='33' author='JaosonMa' date='2019-05-21T17:42:35Z'>
		&lt;denchmark-link:https://github.com/bnascimento&gt;@bnascimento&lt;/denchmark-link&gt;
, I guess the same padding (which depends on image size) is done inside the TensorFlow graph (please visualize it with TensorBoard and show the nodes from the beginning up to .
		</comment>
		<comment id='34' author='JaosonMa' date='2019-11-21T01:07:47Z'>
		&lt;denchmark-link:https://github.com/JaosonMa&gt;@JaosonMa&lt;/denchmark-link&gt;
  hi brother, i also met this problem,Have you already  solve it?
		</comment>
	</comments>
</bug>