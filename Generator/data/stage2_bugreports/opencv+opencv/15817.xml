<bug id='15817' author='toborobot' open_date='2019-10-31T08:33:38Z' closed_time='2019-12-31T05:35:25Z'>
	<summary>pbtxt file from frozen tf trained graph cant work</summary>
	<description>
Situation:
I have trained own model with google colab (tensorflow 1.15). it works good.
Trying to prepare pbtxt file for opencv with this tutorial &lt;denchmark-link:https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API&gt;https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API&lt;/denchmark-link&gt;

Recieve file which is only 24Kb (last worked file prepared at June was 124Kb).
This pbtxt file with frozen model raise mistake (core dumped).
I have test saved previous own frozen graph model prepared before and generate good worked pbtxt file.
That means problem is in new tf 1.15 or with colab environments probably... somebody have this mistakes?
name of nodes is different in last and new pbtxt files.
	</description>
	<comments>
		<comment id='1' author='toborobot' date='2019-10-31T09:13:00Z'>
		We cannot help you without reproducer.
		</comment>
		<comment id='2' author='toborobot' date='2019-10-31T10:31:45Z'>
		how better prepare You reproducer? Colab notebook will be ok?
		</comment>
		<comment id='3' author='toborobot' date='2019-10-31T11:16:41Z'>
		&lt;denchmark-link:https://github.com/toborobot&gt;@toborobot&lt;/denchmark-link&gt;
,  model with  would be enough. Thanks.
		</comment>
		<comment id='4' author='toborobot' date='2019-10-31T12:01:05Z'>
		&lt;denchmark-link:https://github.com/opencv/opencv/files/3793626/fine_tuned_model.zip&gt;fine_tuned_model.zip&lt;/denchmark-link&gt;

this model prerared with colab standart tensorflow environment (tf1.15) (base model ssd_mobilenet_v2 (2019_03_29)

plus 2 hours
I have found that locally trained model with Tensorflow 1.13 reproduce good pbtxt file (~123Kb) and works good with Opencv dnn
plus 6 hours


train graph with tensorflow 1.15
make fine_tuned_model with tensorflow 1.14.1(from train_dir) (could be other version I have checked 1.14)
pbtxt prepared correct - inference with cv2.dnn.readNetFromTensorflow(frozen_graph, pbtxt) is ok.

problem is in between tensorflow 1.15 and tf_text_graph_ssd.py with high possibility... :)
addons:
tensorflow backward and forward compatibility policy - &lt;denchmark-link:https://www.tensorflow.org/guide/versions&gt;https://www.tensorflow.org/guide/versions&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='toborobot' date='2019-12-30T17:09:14Z'>
		&lt;denchmark-link:https://github.com/toborobot&gt;@toborobot&lt;/denchmark-link&gt;
, thanks for bug report!
Please try to run this script first to get opt_graph.pb:
import tensorflow as tf
from tensorflow.python.tools import optimize_for_inference_lib

with tf.gfile.FastGFile('frozen_inference_graph.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Session() as sess:
    # Restore session
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='')


inp_nodes = ['image_tensor']
out_nodes = ['num_detections', 'detection_scores', 'detection_boxes', 'detection_classes']

graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def, inp_nodes, out_nodes, tf.float32.as_datatype_enum)

with tf.gfile.FastGFile("opt_graph.pb", 'wb') as f:
    f.write(graph_def.SerializeToString())
Then using the changes from &lt;denchmark-link:https://github.com/opencv/opencv/pull/16263&gt;#16263&lt;/denchmark-link&gt;
 generate a  file:
python tf_text_graph_ssd.py --input opt_graph.pb --config pipeline.config --output graph.pbtxt
Please let us know if the accuracy won't match or add a sample image so we can check.
		</comment>
	</comments>
</bug>