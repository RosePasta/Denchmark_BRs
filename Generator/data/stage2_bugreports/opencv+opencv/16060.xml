<bug id='16060' author='balachandarsv' open_date='2019-12-04T14:43:53Z' closed_time='2019-12-09T20:29:45Z'>
	<summary>Opencv DNN Inference Engine FPGA Target</summary>
	<description>
Tried using the FPGA Target in Inference Engine using OPENCV Dnn. Getting the following error.
I tried setting the library path as LD_LIBRARY_PATH still the same error.
opencv-4.1.2/modules/dnn/src/op_inf_engine.cpp:704: error: (-215:Assertion failed) in function 'initPlugin'

Failed to initialize Inference Engine backend: Failed to create plugin /opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64/libdliaPlugin.so for device FPGA
Please, check your environment
Cannot load library '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/
]

The same model works on CPU Target.
How to solve this issue?
	</description>
	<comments>
		<comment id='1' author='balachandarsv' date='2019-12-04T15:02:40Z'>
		&lt;denchmark-link:https://github.com/balachandarsv&gt;@balachandarsv&lt;/denchmark-link&gt;
, Hi!
Do you use FPGA distribution of OpenVINO?
		</comment>
		<comment id='2' author='balachandarsv' date='2019-12-04T15:22:00Z'>
		Hi
		</comment>
		<comment id='3' author='balachandarsv' date='2019-12-04T21:09:23Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 Yes. I am using FPGA Distribution only. The required .so file libdliaPlugin.so is available at that location. But still I am getting the same error while calling net.forward()
		</comment>
		<comment id='4' author='balachandarsv' date='2019-12-05T15:22:58Z'>
		
Cannot load library

Running LD_DEBUG=libs &lt;your_app&gt; should help with investigation.
		</comment>
		<comment id='5' author='balachandarsv' date='2019-12-06T09:07:20Z'>
		I was able to solve this by keeping the libs in intel fpga sdk folder.
But while running the googlenet model (bvlc_googlenet.caffemodel) I am getting the following error.
How to activate heterogeneous plugin of InferenceEngine from opencv?   &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;

OpenCV(4.1.2) /opt/opencv-4.1.2/modules/dnn/src/op_inf_engine.cpp:704: error: (-215:Assertion failed) in function 'initPlugin'

Failed to initialize Inference Engine backend: Graph is not supported on FPGA plugin due to existance of layer (Name: pool1/norm1, Type: Norm)
in topology. Most likely you need to use heterogeneous plugin instead of FPGA plugin directly.
]

		</comment>
		<comment id='6' author='balachandarsv' date='2019-12-06T10:31:30Z'>
		&lt;denchmark-link:https://github.com/balachandarsv&gt;@balachandarsv&lt;/denchmark-link&gt;
, Please check the following code execution:



opencv/modules/dnn/src/op_inf_engine.cpp


        Lines 742 to 765
      in
      8108fb0






 #if INF_ENGINE_VER_MAJOR_LE(INF_ENGINE_RELEASE_2019R1) 



         plugin = InferenceEngine::InferencePlugin(enginePtr); 



         netExec = plugin.LoadNetwork(net, {}); 



 #else 



 bool isHetero = false; 



 if (device_name != "CPU") 



         { 



             isHetero = device_name == "FPGA"; 



 for (auto&amp; layer : net) 



             { 



 if (layer-&gt;type == kOpenCVLayersType) 



                 { 



                     layer-&gt;affinity = "CPU"; 



                     isHetero = true; 



                 } 



 else 



                     layer-&gt;affinity = device_name; 



             } 



         } 



 if (isHetero) 



             netExec = ie.LoadNetwork(net, "HETERO:" + device_name + ",CPU"); 



 else 



             netExec = ie.LoadNetwork(net, device_name); 



 #endif 





		</comment>
		<comment id='7' author='balachandarsv' date='2019-12-06T12:23:27Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 I tried the same with the above commit, still the same response.
Most likely you need to use heterogeneous plugin instead of FPGA plugin direct
Is there any variable that i should set in addition
		</comment>
		<comment id='8' author='balachandarsv' date='2019-12-06T12:44:32Z'>
		&lt;denchmark-link:https://github.com/balachandarsv&gt;@balachandarsv&lt;/denchmark-link&gt;
, I just wanted to ask, which code part is used (2019R1 or another one) and which device name is used there ("CPU" or "HETERO:FPGA,CPU"). Please check it by print.
		</comment>
		<comment id='9' author='balachandarsv' date='2019-12-06T13:05:10Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
  I am using opencv JAVA bindings.  I will try to use the c++ and update here.
I am having the device as FPGA
Failed to initialize Inference Engine backend (device = FPGA): Graph is not supported on FPGA plugin due to existance of layer (Name: MobilenetV2/Logits/Conv2d_1c_1x1/act_quant/FakeQuantWithMinMaxVars/Transpose, Type: Permute)

in topology. Most likely you need to use heterogeneous plugin instead of FPGA plugin direct
]

I even tried for mobilenet model too.
		</comment>
		<comment id='10' author='balachandarsv' date='2019-12-06T13:35:49Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 Device name : FPGA , ishetero : true . Its branching to the else part, not to 2019R1.
Device name is not changing to HETERO:FPGA,CPU.
It's still FPGA.
I printed these in the catch block in that function.
I am facing error in this line

netExec = ie.LoadNetwork(net, "HETERO:" + device_name + ",CPU");

		</comment>
		<comment id='11' author='balachandarsv' date='2019-12-06T13:51:49Z'>
		&lt;denchmark-link:https://github.com/balachandarsv&gt;@balachandarsv&lt;/denchmark-link&gt;
, thanks!
Can you please provide a model to reproduce it?
		</comment>
		<comment id='12' author='balachandarsv' date='2019-12-06T13:59:31Z'>
		Mobilenet Model :
&lt;denchmark-link:https://download.01.org/opencv/2019/open_model_zoo/R2/20190628_180000_models_bin/mobilenetv2-int8-tf-0001/FP16/&gt;https://download.01.org/opencv/2019/open_model_zoo/R2/20190628_180000_models_bin/mobilenetv2-int8-tf-0001/FP16/&lt;/denchmark-link&gt;

Googlenet Model : &lt;denchmark-link:https://github.com/intel/caffe/tree/master/models/bvlc_googlenet&gt;https://github.com/intel/caffe/tree/master/models/bvlc_googlenet&lt;/denchmark-link&gt;

You can use either of these models.
I just used model optimizer to convert the googlenet model to FP16 for bin and xml files so that i can run using IE.
&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 let me know if you need the googlenet bin and xml. I will attach them too.
		</comment>
		<comment id='13' author='balachandarsv' date='2019-12-06T15:14:16Z'>
		Could you please run LoadNetwork for HETERO:FPGA,CPU device with additional flags HETERO_CONFIG_KEY(DUMP_GRAPH_DOT) -&gt; YES?
It forces HETERO plugin to dump .dot files which shows how HETERO plugin splitted layers between CPU and FPGA devices.
		</comment>
		<comment id='14' author='balachandarsv' date='2019-12-06T15:16:41Z'>
		Please also try the following code to check that the problem inside OpenCV:
from openvino.inference_engine import IENetwork, IECore

net = IENetwork('mobilenetv2-int8-tf-0001.xml', 'mobilenetv2-int8-tf-0001.bin')

ie = IECore()
ie.add_extension('libcpu_extension_avx2.so', "CPU")
exec_net = ie.load_network(net, 'HETERO:FPGA,CPU')
		</comment>
		<comment id='15' author='balachandarsv' date='2019-12-06T16:23:41Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
  I am not getting any error while running the code you shared. It runs without any warning.
&lt;denchmark-link:https://user-images.githubusercontent.com/6115858/70338379-d65d5280-1872-11ea-8bce-7f69b4470297.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/ilya-lavrenov&gt;@ilya-lavrenov&lt;/denchmark-link&gt;
 I am not sure how to do that. Can you please let me know how to proceed ?
		</comment>
		<comment id='16' author='balachandarsv' date='2019-12-06T16:36:31Z'>
		&lt;denchmark-link:https://github.com/balachandarsv&gt;@balachandarsv&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/ilya-lavrenov&gt;@ilya-lavrenov&lt;/denchmark-link&gt;
, thanks for help!
It's a bug on OpenCV side. Here is a patch: &lt;denchmark-link:https://github.com/opencv/opencv/pull/16089&gt;#16089&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='balachandarsv' date='2019-12-07T05:49:13Z'>
		Thanks &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 Its working fine now.
Out of context, Is there any way to improve the execution speed in Hetero plugin?
When running on CPU Target, the image takes 20 ms
But on FPGA,CPU it takes around 600ms.
Any idea why this happens?
Is it because of too many CPU&lt;-&gt;FPGA layer switches?
		</comment>
		<comment id='18' author='balachandarsv' date='2019-12-07T06:55:29Z'>
		Please dump an affinity graph as &lt;denchmark-link:https://github.com/ilya-lavrenov&gt;@ilya-lavrenov&lt;/denchmark-link&gt;
 suggested. This way we can see the exact hardware utilisation.
		</comment>
	</comments>
</bug>