<bug id='17964' author='YashasSamaga' open_date='2020-07-28T05:59:22Z' closed_time='2020-10-09T22:10:49Z'>
	<summary>dnn(opencl, cuda): wrong weights are used after power fusion, eltwise power fusion is mathematically wrong</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 4.4.0, 3.4

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;




opencv/modules/dnn/src/layers/convolution_layer.cpp


        Lines 409 to 420
      in
      b698d0a






 if (!activ_power.empty()) 



 { 



 if (activ_power-&gt;scale != 1.f || activ_power-&gt;shift != 0.f) 



     { 



 const int outCh = blobs[0].size[0]; 



 fuseWeights(Mat(1, outCh, CV_32F, Scalar(activ_power-&gt;scale)), 



 Mat(1, outCh, CV_32F, Scalar(activ_power-&gt;shift))); 



     } 



 



     power = activ_power-&gt;power; 



     activType = OCL4DNN_CONV_FUSED_ACTIV_POWER; 



 } 





fusedWeights and fusedBias are not updated after fusion. Same with CUDA. Here is tryFuse for reference on how it should have been:



opencv/modules/dnn/src/layers/convolution_layer.cpp


        Lines 176 to 182
      in
      b698d0a






 if (!w.empty() || !b.empty()) 



 { 



 fuseWeights(w, b); 



     fusedWeights = fusedWeights || !w.empty(); 



     fusedBias = fusedBias || (hasBias() &amp;&amp; !w.empty()) || !b.empty(); 



 return true; 



 } 





&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

Disabled tests from &lt;denchmark-link:https://github.com/opencv/opencv/pull/17976&gt;#17976&lt;/denchmark-link&gt;
 can reproduce this bug. Relevant tests have  comment just before applying the skip test tag.
&lt;denchmark-h:h5&gt;Issue submission checklist&lt;/denchmark-h&gt;


 I report the issue, it's not a question


 I checked the problem with documentation, FAQ, open issues,
answers.opencv.org, Stack Overflow, etc and have not found solution


 I updated to latest OpenCV version and the issue is still there


 There is reproducer code and related data files: videos, images, onnx, etc



	</description>
	<comments>
		<comment id='1' author='YashasSamaga' date='2020-07-28T15:53:04Z'>
		There is still a bug after fixing the problem reported in the issue. The power fusion is mathematically incorrect:
after convolution layer: conv + bias
after eltwise layer: conv + bias + eltwise
after power layer: pow(a * (conv + bias + eltwise) + b, exponent)
So the representative mathematical expression is: pow(a * conv + a * bias + a * eltwise + b, exponent)
Now look at what OpenCL and CUDA backends are doing:
The scale a and shift b parameter of power layer is fused with convolution weights. So the convolution operation outputs (a * conv + a * bias + b).  The fused eltwise operation is then applied on this which gives a * conv + a * bias + b + eltwise. Note that the scale factor a is missing from the eltwise term.
So the scale parameter of the power activation cannot be directly fused into the weights and bias. It has to be saved instead of fusing with the weights and bias and instead applied after the eltwise step.
		</comment>
	</comments>
</bug>