<bug id='6562' author='jlguardi' open_date='2016-05-20T10:49:09Z' closed_time='2016-05-23T08:39:35Z'>
	<summary>ANN_MLP 'predict' function returns -nan/incorrect value for CV_64F</summary>
	<description>
&lt;denchmark-h:h3&gt;Please state the information for your system&lt;/denchmark-h&gt;


OpenCV version: 3.1 and also dev version
Host OS: Linux (Ubuntu 16.04-64 bits)
Compiler &amp; CMake: GCC 5.3.1 &amp; CMake 3.5.1

&lt;denchmark-h:h3&gt;In which part of the OpenCV library you got the issue?&lt;/denchmark-h&gt;


On ANN_MLP class ( machine learning module)
ANN_MLP predictions with CV_64F return +/-nan or different value  than CV_32F

Probably related with &lt;denchmark-link:https://github.com/opencv/opencv/issues/6394&gt;#6394&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Expected behaviour&lt;/denchmark-h&gt;

CV_32F and CV_64F should generate the "same" result.
&lt;denchmark-h:h3&gt;Actual behaviour&lt;/denchmark-h&gt;

If I train a ANN and test with CV_32F  and CV_64F data, I get different values
&lt;denchmark-h:h3&gt;Code example to reproduce the issue / Steps to reproduce the issue&lt;/denchmark-h&gt;

Please try to give a full example which will compile as is.
&lt;denchmark-code&gt;#include "opencv2/core/core.hpp"
#include "opencv2/ml/ml.hpp"


#include &lt;cstdio&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;

using namespace std;
using namespace cv;
using namespace cv::ml;

static void help(const string &amp; appname)
{
    clog &lt;&lt; "This is letter recognition sample." &lt;&lt; endl &lt;&lt; "The usage: " &lt;&lt; appname &lt;&lt; endl;
}

inline TermCriteria TC(int iters, double eps)
{
    return TermCriteria(TermCriteria::MAX_ITER + (eps &gt; 0 ? TermCriteria::EPS : 0), iters, eps);
}

int main( int argc, char *argv[] )
{
  cv::CommandLineParser parser(argc, argv, "{help h||}");
  if (parser.has("help"))
    {
      help(argv[0]);
      return 0;
    }


  Ptr&lt;ANN_MLP&gt; model;


  float dummy[4] = {1, 2, 3, 4};
  Mat train_data(1, (int)(sizeof(dummy)/sizeof(dummy[0])), CV_32F, dummy);
  float resp[4] = {1, 2, 3, 4};
  Mat train_responses(1, (int)(sizeof(resp)/sizeof(resp[0])), CV_32F, resp);
  // 2. train classifier
  int layer_sz[] = { train_data.cols, train_responses.cols };
  int nlayers = (int)(sizeof(layer_sz)/sizeof(layer_sz[0]));
  Mat layer_sizes( 1, nlayers, CV_32S, layer_sz );

  int method = ANN_MLP::BACKPROP;
  double method_param = 0.001;
  int max_iter = 100;

  Ptr&lt;TrainData&gt; tdata = TrainData::create(train_data, ROW_SAMPLE, train_responses);

  model = ANN_MLP::create();
  model-&gt;setLayerSizes(layer_sizes);
  model-&gt;setActivationFunction(ANN_MLP::SIGMOID_SYM);
  model-&gt;setTermCriteria(TC(max_iter,0));
  model-&gt;setTrainMethod(method, method_param);
  model-&gt;train(tdata/*, ANN_MLP::NO_OUTPUT_SCALE*/);

  float tdummy[4] = {129.6857147216797, 2, 3, 4};
  Mat test_data(1, (int)(sizeof(tdummy)/sizeof(tdummy[0])), CV_32F, tdummy);
  Mat out;

  // 32F test
  clog &lt;&lt; "In  32F: " &lt;&lt; test_data  &lt;&lt; endl;
  model-&gt;predict( test_data, out );
  clog &lt;&lt; "Out 32F: " &lt;&lt; out &lt;&lt; endl;

  // 64F test
  test_data.convertTo(test_data, CV_64F);
  clog &lt;&lt; "In  64F: " &lt;&lt; test_data  &lt;&lt; endl;
  model-&gt;predict( test_data, out );
  clog &lt;&lt; "Out 64F: " &lt;&lt; out &lt;&lt; endl;

  return 0;
}
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>