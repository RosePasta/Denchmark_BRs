<bug id='14683' author='vonchenplus' open_date='2019-05-31T09:10:35Z' closed_time='2019-07-04T08:28:59Z'>
	<summary>dnn miss many tensorflow layer type</summary>
	<description>
I'm using the readNetFromTensorflow to import a tensorflow pb frozen model. However, I get an error during forward:
Can't create layer "moments/StopGradient" of type "StopGradient"
and i found dnn miss many other tensorflow layer type,for example:
SquaredDifference
Power,
Pow,
RealDiv,
TanH
so, opencv have any plan to add these layers? Or how could I remove this as this is not used in the network any longer after training.
thanks.
	</description>
	<comments>
		<comment id='1' author='vonchenplus' date='2019-05-31T12:59:58Z'>
		StopGradient is not a deployment node - turn the model into testing phase.
Power, TanH - supported
Pow, SquaredDifference, RealDiv most likely are part of Batch Normalization subgraphs (we can fuse it automatically)
Please provide reproducer if it's a bug report.
		</comment>
		<comment id='2' author='vonchenplus' date='2019-06-03T01:48:30Z'>
		hello dkurt, thanks for your reply.
so, how can i fixed this problem?
I don't quite understand how opencv handles this situation.
I upload a pb file at google drive:
&lt;denchmark-link:https://drive.google.com/open?id=1KGTYKEhH0UZyQtMObAE5WVW8MZ7DFfoP&gt;https://drive.google.com/open?id=1KGTYKEhH0UZyQtMObAE5WVW8MZ7DFfoP&lt;/denchmark-link&gt;

Please help me to see this model when running with opencv.
thank you very much.
		</comment>
		<comment id='3' author='vonchenplus' date='2019-06-06T17:47:24Z'>
		&lt;denchmark-link:https://github.com/vonchenplus&gt;@vonchenplus&lt;/denchmark-link&gt;
, Thanks for report! Please try the changes from &lt;denchmark-link:https://github.com/opencv/opencv/pull/14747&gt;#14747&lt;/denchmark-link&gt;
. I tested your model in the following way:
import cv2 as cv
import numpy as np

import tensorflow as tf

np.random.seed(324)

cvNet = cv.dnn.readNet('la_muse.pb')
inp = np.random.standard_normal([1, 3, 256, 256]).astype(np.float32)
cvNet.setInput(inp)
cvOut = cvNet.forward()

print(cvOut.shape)

graph = 'la_muse.pb'
with tf.gfile.FastGFile(graph) as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Session() as sess:
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='')
    tfOut = sess.run(sess.graph.get_tensor_by_name('add_37:0'),
                     feed_dict={'ContentImage:0': inp.transpose(0, 2, 3, 1)})

print(np.max(np.abs(tfOut.transpose(0, 3, 1, 2) - cvOut)))
print(np.min(cvOut), np.max(cvOut))
It shows that maximal absolute difference is about 0.004. Output values range is (-22.5, 277.5) so I think that difference is OK (about 1.617432e-05 of entire range).
		</comment>
		<comment id='4' author='vonchenplus' date='2019-06-10T07:00:58Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
, Thanks for report!
This Patch work for me, thanks!
		</comment>
		<comment id='5' author='vonchenplus' date='2019-06-10T08:40:10Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 , I set preferable target to DNN_TARGET_OPENCL, it must be blocked at ocl.cpp:5056

follow the call stack:
igdrclneo64.dll!00007ffbbd784302()	Unknown igdrclneo64.dll!00007ffbbd7ee52e()	Unknown igdrclneo64.dll!00007ffbbd7b5e91()	Unknown igdrclneo64.dll!00007ffbbd7ea120()	Unknown igdrclneo64.dll!00007ffbbd869584()	Unknown igdrclneo64.dll!00007ffbbd86b08a()	Unknown igdrclneo64.dll!00007ffbbd772836()	Unknown OpenCL.DLL!00007ffbddbd361f()	Unknown cv::ocl::OpenCLAllocator::map(cv::UMatData * u, cv::AccessFlag accessFlags) Line 5056	C++ cv::UMat::getMat(cv::AccessFlag accessFlags) Line 825	C++ cv::UMat::setTo(const cv::debug_build_guard::_InputArray &amp; _value, const cv::debug_build_guard::_InputArray &amp; _mask) Line 1095	C++ cv::UMat::operator=(const cv::Scalar_&lt;double&gt; &amp; s) Line 1102	C++ cv::UMat::UMat(int _dims, const int * _sz, int _type, const cv::Scalar_&lt;double&gt; &amp; _s, cv::UMatUsageFlags _usageFlags) Line 3635	C++ cv::UMat::zeros(int ndims, const int * sz, int type) Line 1207	C++ cv::dnn::ocl4dnn::OCL4DNNConvSpatial&lt;float&gt;::verifyResult(const cv::UMat &amp; bottom, cv::UMat &amp; top, const cv::UMat &amp; weight, const cv::UMat &amp; bias, int numImages, cv::dnn::ocl4dnn::OCL4DNNConvSpatial&lt;float&gt;::kernelConfig * config, cv::UMat &amp; verifyTop) Line 1256	C++ 
And Some other window, for example:chrome, may be appears black screen.
I think this should be a resource leak.
This situation appears in windows and MacOS.
		</comment>
		<comment id='6' author='vonchenplus' date='2019-06-10T16:07:39Z'>
		
And Some other window, for example:chrome, may be appears black screen.

This can be caused by huge computation tasks - what is "CPU" inference time for your model?
GPU is busy, so it can't process other GPU tasks (drawing chrome windows).
Try to recompile OpenCV with &lt;denchmark-link:https://github.com/opencv/opencv/blob/3.4.6/modules/core/src/ocl.cpp#L68-L69&gt;OpenCL subsystem debugging&lt;/denchmark-link&gt;
 (set mentioned defines to "1")
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Please provide information about used OpenCL and versions:

output from clinfo or opencv_version --opencl

		</comment>
		<comment id='7' author='vonchenplus' date='2019-06-11T01:26:35Z'>
		&lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
,  thanks for your reply.
what is "CPU" inference time for your model?
"CPU" inference time about 2 second.
My OpenCL Version is 1.2,
Here is Opencv debug log:
&lt;denchmark-link:https://drive.google.com/open?id=1yDjvW9fBwkNNt7lllO2AQLqtiDAbAjWj&gt;https://drive.google.com/open?id=1yDjvW9fBwkNNt7lllO2AQLqtiDAbAjWj&lt;/denchmark-link&gt;

It muse be blocked this place.(see log, the last line).
		</comment>
		<comment id='8' author='vonchenplus' date='2019-06-12T16:52:26Z'>
		&lt;denchmark-link:https://github.com/vonchenplus&gt;@vonchenplus&lt;/denchmark-link&gt;
 Did you try to run OpenCV DNN tests? Do they freeze?
BTW, Your driver version is 23.20.16.4973. It has been released ~1 year ago.
Up-to-date Intel Graphics driver can be found &lt;denchmark-link:https://downloadcenter.intel.com/product/80939/Graphics-Drivers&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='9' author='vonchenplus' date='2019-06-13T00:58:43Z'>
		&lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
, I am update Intel Graphics driver yesterday and it's working properly now.
But, I found the Opencl mode(about 14s) slower than cpu mode(about 5s), Is this normal?
		</comment>
		<comment id='10' author='vonchenplus' date='2019-06-13T07:51:29Z'>
		Great!
Only subset of convolution modes has been properly optimized/&lt;denchmark-link:https://github.com/opencv/opencv/blob/3.4.6/modules/dnn/src/ocl4dnn/include/default_kernel_config.hpp&gt;configured&lt;/denchmark-link&gt;
 for OpenCL computations (they cover most cases of public models from OpenCV tests). All other cases are go via general "naive" implementation (and it is sometimes slower than CPU).
You can try to enable OpenCL tuning via environment variables (this mode has slow initialization at first time):

OPENCV_OCL4DNN_CONFIG_PATH=&lt;some_existed_emoty_directory&gt;
remove contents of that directory to rerun tuning phase again or use OPENCV_OCL4DNN_FORCE_AUTO_TUNING=1

Another important note - all layers should be run on OpenCL - switching between OpenCL/CPU increases computation time too.
You can check what is going with your model in VTune (&lt;denchmark-link:https://software.intel.com/en-us/vtune/choose-download&gt;it is free&lt;/denchmark-link&gt;
) - select &lt;denchmark-link:https://software.intel.com/en-us/vtune-amplifier-help-gpu-opencl-application-analysis-view&gt;GPU hotspots analysis&lt;/denchmark-link&gt;
 (ensure that your first "tuning" run is completed before VTune usage).
		</comment>
		<comment id='11' author='vonchenplus' date='2019-06-13T09:09:20Z'>
		hello &lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
 , OCL4DNN initialization too slow, i give up.
thanks for your reply.
		</comment>
		<comment id='12' author='vonchenplus' date='2019-06-19T08:29:46Z'>
		hello &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 , I test my new model and i found dnn unsupport these operation:
MirrorPad,
MaxPoolGrad(Very similar to MaxUnpoolLayer)
thinks.
		</comment>
		<comment id='13' author='vonchenplus' date='2019-06-19T11:31:43Z'>
		hello &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
, I Pull request to support MirrorPad at &lt;denchmark-link:https://github.com/opencv/opencv/pull/14845&gt;14845&lt;/denchmark-link&gt;
, please help me review it.
		</comment>
		<comment id='14' author='vonchenplus' date='2019-07-04T07:39:26Z'>
		&lt;denchmark-link:https://github.com/vonchenplus&gt;@vonchenplus&lt;/denchmark-link&gt;
, Can we close this issue due merged &lt;denchmark-link:https://github.com/opencv/opencv/pull/14860&gt;#14860&lt;/denchmark-link&gt;
?
		</comment>
	</comments>
</bug>