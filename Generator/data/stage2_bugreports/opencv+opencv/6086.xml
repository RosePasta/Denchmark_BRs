<bug id='6086' author='mbarnach' open_date='2016-02-08T10:25:37Z' closed_time='2016-07-13T15:13:56Z'>
	<summary>Cuda context initialization with multithreading.</summary>
	<description>
When multiple threads launch a cuda function in parallel, the behavior is undefined (wrong results or even SEGFAULT).
This could be proved with the followning code:
&lt;denchmark-code&gt;std::thread t[2];
for( int i = 0 ; i &lt; 2 ; ++i )
{
    t[i] = std::thread( cuda_function );
}
for( int i = 0 ; i &lt; 2 ; ++i )
{
    t[i].join();
}
&lt;/denchmark-code&gt;

Where cuda_function is any cuda OpenCV function.
Setting the device to the right one at the begining of the main thread and in each thread isn't enough, but calling any cuda OpenCV function (synchronously) from the main thread do the trick.
	</description>
	<comments>
		<comment id='1' author='mbarnach' date='2016-03-08T13:05:59Z'>
		When using CUDA Runtime API only (as OpenCV does i suppose), the context is initialized automatically the first time you call an API function.
Does each CPU thread use its "own" GPU ? That should work.
But if multiple CPU threads launch kernels on the same GPU in parallel, that generally is dangerous as most kernels are not CPU-thread-safe. This is due to usage of file-static "global" variables like texture references, constant memory etc. See &lt;denchmark-link:https://devtalk.nvidia.com/default/topic/711438/are-npp-routines-cpu-thread-safe-/&gt;https://devtalk.nvidia.com/default/topic/711438/are-npp-routines-cpu-thread-safe-/&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>