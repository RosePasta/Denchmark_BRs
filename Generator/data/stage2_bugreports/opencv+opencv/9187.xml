<bug id='9187' author='tomoaki0705' open_date='2017-07-19T09:57:28Z' closed_time='2017-07-20T12:26:52Z'>
	<summary>Calib3d_SolvePnP.accuracy is too unstable based on random seed</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; master (7733654, 20f603a)
Operating System / Platform =&gt; Windows 7 64 Bit Core i7 / Ubuntu 14.04
Compiler =&gt; Visual Studio 2013 / GCC 4.8

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;


The test Calib3d_SolvePnP.accuracy for method SOLVEPNP_P3P seems too strict for some input data
I found the error on Jetson TK1

&lt;denchmark-code&gt;[----------] 3 tests from Calib3d_SolvePnP
[ RUN      ] Calib3d_SolvePnP.accuracy
mode: 0, method: 0 -&gt; 98.4% (err &lt; 8.30464e-06)
mode: 0, method: 1 -&gt; 95.6% (err &lt; 1.34671e-05)
mode: 0, method: 2 -&gt; 5.3% (err &lt; 0.00592602)
mode: 0, method: 3 -&gt; 99.9% (err &lt; 0.000835733)
mode: 0, method: 4 -&gt; 100% (err &lt; 1.90072e-05)
mode: 0, method: 5 -&gt; 98.8% (err &lt; 0.00191663)
mode: 1, method: 0 -&gt; 98.4% (err &lt; 5.48124e+14)
mode: 1, method: 1 -&gt; 96.1% (err &lt; 0.352514)
mode: 1, method: 2 -&gt; 5.8% (err &lt; 0.00651514)
mode: 1, method: 3 -&gt; 99.8% (err &lt; 0.441405)
mode: 1, method: 4 -&gt; 99.5% (err &lt; 1.46951)
mode: 1, method: 5 -&gt; 99.1% (err &lt; 0.000364948)
/home/ubuntu/opencv-fork/modules/ts/src/ts.cpp:541: Failure
Failed

	failure reason: Bad accuracy
	test case #-1
	seed: ffffffffffffffff
-----------------------------------
	LOG:
Invalid accuracy for method 2, failed 947 tests from 1000, maximum error equals 0.005926, distortion mode equals 0
Invalid accuracy for method 2, failed 942 tests from 1000, maximum error equals 0.006515, distortion mode equals 1

-----------------------------------
[  FAILED  ] Calib3d_SolvePnP.accuracy (6192 ms)
[ RUN      ] Calib3d_SolvePnP.double_support
[       OK ] Calib3d_SolvePnP.double_support (2 ms)
[ RUN      ] Calib3d_SolvePnP.translation
[       OK ] Calib3d_SolvePnP.translation (4 ms)
[----------] 3 tests from Calib3d_SolvePnP (6208 ms total)
&lt;/denchmark-code&gt;


I thought this problem comes from difference of instruction set and/or compiler
Though during the investigation I realized that this doesn't happen even on exactly same platform/OS/program

For instance, when I pass --gtest_filter=Calib3d_SolvePnP* to gtest program to skip all the other tests, the test actually passes.



&lt;denchmark-code&gt;
[----------] 3 tests from Calib3d_SolvePnP
[ RUN      ] Calib3d_SolvePnP.accuracy
mode: 0, method: 0 -&gt; 98.6% (err &lt; 9.75961e-06)
mode: 0, method: 1 -&gt; 96.7% (err &lt; 1.63235e-05)
mode: 0, method: 2 -&gt; 89.6% (err &lt; 0.0124706)
mode: 0, method: 3 -&gt; 99.9% (err &lt; 0.000706929)
mode: 0, method: 4 -&gt; 100% (err &lt; 1.67126e-05)
mode: 0, method: 5 -&gt; 98.5% (err &lt; 0.00132396)
mode: 1, method: 0 -&gt; 98.2% (err &lt; 7779.09)
mode: 1, method: 1 -&gt; 96.3% (err &lt; 0.219446)
mode: 1, method: 2 -&gt; 88.7% (err &lt; 0.00896903)
mode: 1, method: 3 -&gt; 100% (err &lt; 1.72653e-05)
mode: 1, method: 4 -&gt; 99.4% (err &lt; 1.62516)
mode: 1, method: 5 -&gt; 98.8% (err &lt; 0.00115234)
[       OK ] Calib3d_SolvePnP.accuracy (6132 ms)
[ RUN      ] Calib3d_SolvePnP.double_support
[       OK ] Calib3d_SolvePnP.double_support (3 ms)
[ RUN      ] Calib3d_SolvePnP.translation
[       OK ] Calib3d_SolvePnP.translation (4 ms)
[----------] 3 tests from Calib3d_SolvePnP (6148 ms total)
&lt;/denchmark-code&gt;


I modified a bit and figured out that the error is based on input points, not the platforms
In another word, it could happen on other platforms based on the random seed
IMHO, this threshold  should be loosen to something like 3.0e-3

&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

&lt;denchmark-h:h6&gt;Visual Studio 2013&lt;/denchmark-h&gt;


I pushed a branch in my repository ( f76e226 ) and I added a test Calib3d_SolvePnP.verifyBehaviour in opencv_test_calib3d
I hard coded a value which reproduces bad accuracy failure, and the value is in the range of generated random data

&lt;denchmark-h:h6&gt;gcc (ARM)&lt;/denchmark-h&gt;


I confirmed on following platforms

Jetson TK1, Jetson TX1, Jetson TX2, ODROID-C2, ODROID-X2, PINE64,
As described above, it's not the problem of platform, it's the problem of run time.
For example, I used following cmake option for Jetson TK1


cmake option : -DCPU_BASELINE=FP16 -DNEON=ON
the execution order of the test is

cameraCalibrationTiltTest
Calib3d_UndistortPoints
Calib3d_InitUndistortRectifyMap
Calib3d_Undistort
Calib3d_StereoBM
Calib3d_StereoSGBM
Calib3d_StereoSGBM_HH4
Calib3d_POSIT
Calib3d_CalibrateCamera_CPP
Calib3d_SolveP3P
Calib3d_SolvePnPRansac
Calib3d_SolvePnP



	</description>
	<comments>
		<comment id='1' author='tomoaki0705' date='2017-07-19T10:14:45Z'>
		Input data is generated via RNG generator, but random numbers generator is not bit-exact (at least for floating point values).
Seed should be fixed, because there are no checks for input data validation/correctness (bad cases like, - all points on line or just single point). In other words,  (but we don't).
There is no actual instruction how to "select" RNG seed, so you need to specify some another value for failed test (&lt;denchmark-link:https://github.com/opencv/opencv/commit/e65c6270bf080ab3802c12fe024af9a4bde2ead6#diff-ad15c54e131bb5d8a9162570446e988a&gt;example&lt;/denchmark-link&gt;
).
BTW, RNG seed should be re-initialized to the same value between tests automatically (by "ts" module), so tests execution order should not impact test results.
		</comment>
		<comment id='2' author='tomoaki0705' date='2017-07-19T10:22:45Z'>
		I appreciate your comment and your suggestion is cleaner.
Speaking of input data, this test doesn't rely on RNG, but simple rand function. (in generate3DPointCloud)
Probably that should be fixed, too.
		</comment>
		<comment id='3' author='tomoaki0705' date='2017-07-19T11:32:12Z'>
		
simple rand

rand() should not be used at all. This is a bug. Using rand() is not acceptable because it is not thread-safe at least, so it is hard to receive reproducible test results.
It should be replaced to something like rng.uniform(0, 1.0f).
Nice catch!
		</comment>
		<comment id='4' author='tomoaki0705' date='2017-07-19T15:11:38Z'>
		Thanks! So, it sound a peace of cake, but the situation seems more harder than I expected.
As you suggest, I put new RNG which only generates random numbers for the input data.
I found a sweet spot for method == 2 which is SOLVEPNP_P3P and described above, but now test using SOLVEPNP_UPNP (4) keeps failing.
Hmm, I need to investigate more.
		</comment>
	</comments>
</bug>