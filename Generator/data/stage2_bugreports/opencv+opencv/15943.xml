<bug id='15943' author='Mowstyl' open_date='2019-11-18T22:57:39Z' closed_time='2020-01-03T11:15:00Z'>
	<summary>Python crash when calling readNetFromTensorflow</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 4.1.2
Operating System / Platform =&gt; Windows 7 64 bit
Compiler =&gt; Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 22:22:05) [MSC v.1916 64 bit (AMD64)] on win32

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

I've tuned a pre-trained tensorflow model using the object_detection API.
After freezing the model and using the "tf_text_graph_ssd.py" script (the pre-trained model I used was SSD_inception_v2_coco) I generated the graph.pbtxt file.
Each time I try to load the model with
cv.readNetFromTensorflow("frozen_inference_graph.pb", "graph.pbtxt")
Windows immediately says Python stopped working and crashes.
The same thing happens when I try to use it in C++.
&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import cv2 as cv
cv.readNetFromTensorflow("frozen_inference_graph.pb", "graph.pbtxt")
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://mega.nz/#!cEIDVIwS!P5hCTRA2MAAjkQLV6dfd0F4ZJf1ZbZBZkcVrQEfzmyg&gt;frozen_inference_graph.pb&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/opencv/opencv/files/3860944/graph_and_config.zip&gt;graph_and_config.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Mowstyl' date='2019-11-19T12:04:34Z'>
		&lt;denchmark-h:h5&gt;Also happens on&lt;/denchmark-h&gt;


OpenCV =&gt; 4.1.2-dev (just compiled from source)
Operating System / Platform =&gt; Ubuntu 19.10 64 bit
Compiler =&gt; Python 3.7.5rc1 (default, Oct  8 2019, 16:47:45)

It gives a segmentation fault (core dumped).
Using GDB to debug it, outputs the contents of &lt;denchmark-link:https://github.com/opencv/opencv/files/3863724/gdblog.txt&gt;gdblog.txt&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='Mowstyl' date='2019-11-20T12:58:44Z'>
		Having the same issue on a SSD MobileNet v2 network. Generating a new pbtxt from the original pretrained checkpoint &amp; pipeline.conf works. I also tried using my retrained network's pipeline.conf and the pretrained checkpoint and that also seems to work (no segfault in readNetFromTensorflow). The problem seems to be specific to using the new frozen_inference_graph.pb.
		</comment>
		<comment id='3' author='Mowstyl' date='2019-11-20T13:18:08Z'>
		I was about to post the same, I've tried to use the SSD MobileNet v2 COCO network and the same error appears.
I've also created two more frozen graphs by using the optimize_for_inference tool on the graph I posted, and another one by using the TransformGraph tool to do some cleaning.
The same error for both of them.
		</comment>
		<comment id='4' author='Mowstyl' date='2019-11-20T13:47:52Z'>
		Ok, I can confirm that the error seems to be related to the newly-generated frozen_inference_graph.pb.
To reproduce the error on the released SSD MobileNet V2 checkpoint (NOTE: I'm using the latest master version of the TF Object Detection API):

Generate a new frozen model, starting from the checkpoint in the Model Zoo:

python object_detection/export_inference_graph.py --pipeline_config_path path/to/ssd_mobilenet_v2_coco_2018_03_29/pipeline.config --trained_checkpoint_prefix path/to/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt --output_directory path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy


Follow the instructions from the OpenCV + TF Object Detection API guide:
python scripts/tf_text_graph_ssd.py --input path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy/frozen_inference_graph.pb --output path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy/opencv_graph.pbtxt --config path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy/pipeline.config


Attempt to load the combination path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy/frozen_inference_model.pb + path/to/ssd_mobilenet_v2_coco_2018_03_29/deploy/opencv_graph.pbtxt


This results in Segfault (from python, at least).
		</comment>
		<comment id='5' author='Mowstyl' date='2020-01-03T11:15:00Z'>
		Can reproduce the problem with the graph.pbtxt from issue's description. However with the latest state of OpenCV everything works fine. Please try to regenerate graph.pbtxt file. Thanks!
let me close it for now
		</comment>
		<comment id='6' author='Mowstyl' date='2020-01-13T11:09:25Z'>
		Hello, I can confirm that generating the file with the updated python scripts from the linked tutorial and loading them with a C++ build of OpenCV's master works. Thanks for looking into this!
		</comment>
		<comment id='7' author='Mowstyl' date='2020-01-30T13:58:43Z'>
		I need help with I have stuck with this issue 3 days now, if I can't solve it maybe I lose my job
		</comment>
		<comment id='8' author='Mowstyl' date='2020-01-30T14:19:21Z'>
		&lt;denchmark-link:https://github.com/GentBinaku&gt;@GentBinaku&lt;/denchmark-link&gt;
, Can you add more technical details instead? Can you share a model? Have you tried to regenerate a  file as mentioned in &lt;denchmark-link:https://github.com/opencv/opencv/issues/15943#issuecomment-570544454&gt;#15943 (comment)&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='9' author='Mowstyl' date='2020-01-30T14:28:43Z'>
		Ok I will write a complete setup.
I have been given a tensorFiles which should be read.
frozen_inference_graph.pb and pipeline.config( Can't share these files sorry).
First step sort the graph.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.tools.graph_transforms import TransformGraph

with tf.gfile.FastGFile('frozen_inference_graph.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    graph_def = TransformGraph(graph_def, ['image_tensor'], ['detection_boxes', 'detection_classes', 'detection_scores', 'num_detections'], ['sort_by_execution_order'])
    with tf.gfile.FastGFile('sorted_inference_graph.pb', 'wb') as f:
        f.write(graph_def.SerializeToString())
&lt;/denchmark-code&gt;

Which produces
sorted_inference_graph.pb
Then
sorted_inference_graph.pb
python3 tf_text_graph_ssd.py --input=sorted_inference_graph.pb --output=mygraph.pbtxt --config pipeline.config
Generate the pbtxt file, which we put through:
 net = cv::dnn::readNetFromTensorflow(tensorflowWeightFile,tensorflowConfigFile);
This produces a error
Program received signal SIGSEGV, Segmentation fault.
0x00007ffff6d493a7 in cv::dnn::dnn4_v20191202::(anonymous namespace)::TFImporter::populateNet(cv::dnn::dnn4_v20191202::Net) ()
from /usr/local/lib/libopencv_dnn.so.4.2
Checking the OpenCV branch to be sure it's master.
Branch Master
Version 4.2.0
&lt;denchmark-code&gt;root@gentbinaku:/opt/opencv_build/opencv# git remote show origin
* remote origin
  Fetch URL: https://github.com/opencv/opencv.git
  Push  URL: https://github.com/opencv/opencv.git
  HEAD branch: master
  Remote branches:
    2.4    tracked
    3.4    tracked
    master tracked
  Local branch configured for 'git pull':
    master merges with remote master
  Local ref configured for 'git push':
    master pushes to master (local out of date

&lt;/denchmark-code&gt;

TF Version
&lt;denchmark-code&gt;root@gentbinaku:/opt/opencv_build/opencv#  python3 -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
v1.15.0-rc3-22-g590d6ee 1.15.0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='Mowstyl' date='2020-01-30T14:41:58Z'>
		&lt;denchmark-link:https://github.com/GentBinaku&gt;@GentBinaku&lt;/denchmark-link&gt;
, can you use  from  master branch?

dnn4_v20191202

that means you source code can be 2 months old:



opencv/modules/dnn/include/opencv2/dnn/version.hpp


         Line 9
      in
      4b0132e






 #define OPENCV_DNN_API_VERSION 20191202 





		</comment>
		<comment id='11' author='Mowstyl' date='2020-01-30T14:54:58Z'>
		Yes I did that didn't work either
&lt;denchmark-code&gt;/// Use with major OpenCV version only.
#define OPENCV_DNN_API_VERSION 20200128
&lt;/denchmark-code&gt;

I uninstalled OpenCV, should I install it with the master branch
		</comment>
		<comment id='12' author='Mowstyl' date='2020-01-30T14:58:01Z'>
		&lt;denchmark-link:https://github.com/GentBinaku&gt;@GentBinaku&lt;/denchmark-link&gt;
, Maybe you can try to apply this patch &lt;denchmark-link:https://github.com/opencv/opencv/pull/16270&gt;#16270&lt;/denchmark-link&gt;
? Or even better to rebuild OpenCV from master or share resulting ?
		</comment>
		<comment id='13' author='Mowstyl' date='2020-01-30T15:46:37Z'>
		Still nothing, sorry but I am required from the NDA to not share the files.
Downloaded the latest branch  and still Seg Fault
		</comment>
		<comment id='14' author='Mowstyl' date='2020-01-30T16:07:19Z'>
		&lt;denchmark-link:https://github.com/GentBinaku&gt;@GentBinaku&lt;/denchmark-link&gt;
, try to create  using  from origin . Make sure you use the latest  script and OpenCV installation. Use them as well during import: .
There is no chance to debug it remotely unless you provide stacktrace or something useful.
		</comment>
		<comment id='15' author='Mowstyl' date='2020-01-31T08:29:54Z'>
		&lt;denchmark-code&gt; python3 tf_text_graph_ssd.py --input=frozen_inference_graph.pb --output=mygraph.pbtxt --config pipeline.config
Scale: [0.200000-0.950000]
Aspect ratios: [1.0, 2.0, 0.5, 3.0, 0.33329999]
Reduce boxes in the lowest layer: True
Number of classes: 5
Number of layers: 6
box predictor: convolutional
Input image size: 300x300
Traceback (most recent call last):
  File "tf_text_graph_ssd.py", line 399, in &lt;module&gt;
    createSSDGraph(args.input, args.config, args.output)
  File "tf_text_graph_ssd.py", line 236, in createSSDGraph
    assert(graph_def.node[0].op == 'Placeholder')
AssertionError
&lt;/denchmark-code&gt;

I get this error without sorting the graph
Commented that assertion  line and generated a file mygraph.pbtxt.
Stil same error
The stack error:
&lt;denchmark-code&gt;#0  0x00007ffff6d4529b in cv::dnn::dnn4_v20200128::(anonymous namespace)::TFImporter::populateNet(cv::dnn::dnn4_v20200128::Net) () from /usr/local/lib/libopencv_dnn.so.4.2
#1  0x00007ffff6d54d93 in cv::dnn::dnn4_v20200128::readNetFromTensorflow(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) () from /usr/local/lib/libopencv_dnn.so.4.2
#2  0x00007ffff6bffce9 in cv::dnn::dnn4_v20200128::readNet(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) () from /usr/local/lib/libopencv_dnn.so.4.2
#3  0x000055555555ba0e in Display::config() ()
#4  0x0000555555559789 in main ()
&lt;/denchmark-code&gt;

Judging from the dnn4_v20200128 I am using the latest version
DIsplaying the error with the following handler function:
&lt;denchmark-code&gt;inline void handler(int sig){
    void *array[100];
    size_t size;

    size = backtrace(array,100);
    fprintf(stderr,"Error: signal %d:\n",sig);
    backtrace_symbols_fd(array,size,STDERR_FILENO);
    exit(1);
}

&lt;/denchmark-code&gt;

Outputs the following:
&lt;denchmark-code&gt;
Error: signal 11:
./test_solaborate(_Z7handleri+0x34)[0x55a26f491c19]
/lib/x86_64-linux-gnu/libc.so.6(+0x3ef20)[0x7f776da94f20]
/usr/local/lib/libopencv_dnn.so.4.2(+0x29a29b)[0x7f777152229b]
/usr/local/lib/libopencv_dnn.so.4.2(_ZN2cv3dnn14dnn4_v2020012821readNetFromTensorflowERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEES9_+0xb3)[0x7f7771531d93]
./test_solaborate(_ZN7Display6configEv+0x47)[0x55a26f490be5]
./test_solaborate(main+0x9f)[0x55a26f48e979]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7)[0x7f776da77b97]
./test_solaborate(_start+0x2a)[0x55a26f48e7fa]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='16' author='Mowstyl' date='2020-02-03T13:06:25Z'>
		Hi!
I have encountered the same issue as &lt;denchmark-link:https://github.com/GentBinaku&gt;@GentBinaku&lt;/denchmark-link&gt;
. I also get the assertion error when running the tf_text_graph_ssd.py script so have to sort the graph. I have attached the resulting pbtxt file and the source frozen_graph.pb and config.
I compared the resulting pbtxt file with the &lt;denchmark-link:https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/ssd_mobilenet_v2_coco_2018_03_29.pbtxt&gt;ssd_mobilenet_v2_coco_2018_03_29.pbtxt&lt;/denchmark-link&gt;
, and noticed that all the Preprocessor and FeatureExtractor nodes are missing in my fine_tuned_graph.pbtxt file. I think that the segmentation fault occurs due to these missing nodes.
&lt;denchmark-link:https://github.com/opencv/opencv/files/4147997/graph_and_configs.zip&gt;graph_and_configs.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='Mowstyl' date='2020-02-03T13:33:46Z'>
		&lt;denchmark-link:https://github.com/mungaip&gt;@mungaip&lt;/denchmark-link&gt;
, your model consists of quantization nodes, . Just for interest, have you quantized it or this is new TensorFlow behavior?
&lt;denchmark-link:https://user-images.githubusercontent.com/25801568/73657204-d75c0600-46a2-11ea-866e-dbad1587e76e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='Mowstyl' date='2020-02-03T13:41:39Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 that's true sorry! I performed transfer learning on an already quantised model. I'll try again on the non-quant ssd_mobilenet_v2 and see if it makes a difference.
		</comment>
		<comment id='19' author='Mowstyl' date='2020-02-03T13:51:17Z'>
		&lt;denchmark-link:https://github.com/mungaip&gt;@mungaip&lt;/denchmark-link&gt;
, I think that this example would be also useful, thanks anyway!
		</comment>
		<comment id='20' author='Mowstyl' date='2020-02-04T12:31:15Z'>
		Hi &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
, I trained a normal ssd_mobilenet_v2 and the tf_text_graph_ssd.py script worked fine! The only issue I faced was that the readNetFromTensorflow dnn module couldn't recognise the types "FusedBatchNormV3" and "AddV2" when creating the layers. I worked around it by changing the strings to "FusedBatchNorm" and "Add" respectively in the pbtxt file. I'm using OpenCV 4.1.1. Is this something that is fixed in newer OpenCV versions?
		</comment>
		<comment id='21' author='Mowstyl' date='2020-02-04T14:07:26Z'>
		&lt;denchmark-link:https://github.com/mungaip&gt;@mungaip&lt;/denchmark-link&gt;
, yes, support of these layers has been added.
		</comment>
		<comment id='22' author='Mowstyl' date='2020-10-09T04:48:31Z'>
		Hi &lt;denchmark-link:https://github.com/mungaip&gt;@mungaip&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

I am facing the same issue. I trained a SSD MobileNet v2 from a pretrained model. and generated the pbtxt file from tf_text_graph_ssd.py script. I have performed this many times in my system and was able to run inference.
I used a different machine now. and stuck with this. please get me through.
Also let me know how to check if pre-trained model is already quantized. I am unaware how to find that. My SSD MobileNet V2 model is a 66mb file.



cv2.version
'4.4.0-openvino'



		</comment>
	</comments>
</bug>