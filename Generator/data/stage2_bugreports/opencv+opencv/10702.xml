<bug id='10702' author='philipp-fischer' open_date='2018-01-26T19:18:14Z' closed_time='2018-02-14T10:35:48Z'>
	<summary>DNN: Access violation in deconv2d layer</summary>
	<description>
&lt;denchmark-link:https://github.com/opencv/opencv/files/1668899/minimal_net.py.txt&gt;minimal_net.py.txt&lt;/denchmark-link&gt;

&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 3.4 (Master Branch)
Operating System / Platform =&gt; Windows 64 Bit
Compiler =&gt; Visual Studio 2015

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

Exception in deconvolution layer.
Easily reproducible with minimal example (see attachments)
Access violation happens im "convolution_layer.cpp" line 1089.
(in the two for loops "val +=...")
&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

Set up a minimal one-layer tensorflow network as in the attached file and export it.
Remove unneeded ops using the tf optimizer.
Load the protobuf into opencv with readNetFromTensorflow and do a forward pass.
It will crash.
&lt;denchmark-link:https://user-images.githubusercontent.com/12006597/35456341-61e96fa6-02d5-11e8-9a75-ad3f728a97f1.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/opencv/opencv/files/1668900/minimal_net.py.txt&gt;minimal_net.py.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/opencv/opencv/files/1668978/deconv.zip&gt;deconv.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='philipp-fischer' date='2018-01-27T12:09:09Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 I would like to work on this issue, can you give me some initial directions to get started?
		</comment>
		<comment id='2' author='philipp-fischer' date='2018-01-27T12:23:12Z'>
		Great. You can build upon this example:
&lt;denchmark-link:https://github.com/opencv/opencv/blob/master/samples/dnn/tf_inception.cpp&gt;https://github.com/opencv/opencv/blob/master/samples/dnn/tf_inception.cpp&lt;/denchmark-link&gt;

But you can really strip it down to
readNetFromTensorflow
SetInput and net.forward.
I attached a zip file that contains the optimized_model.pb you can load.
		</comment>
		<comment id='3' author='philipp-fischer' date='2018-01-27T14:42:03Z'>
		&lt;denchmark-link:https://github.com/akhandait&gt;@akhandait&lt;/denchmark-link&gt;
, as &lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
 said firstly we need to reproduce a error. Download attached graph, try to run it using OpenCV.
Then we need to find a problem. There is a &lt;denchmark-link:https://github.com/opencv/opencv_extra/blob/master/testdata/dnn/tensorflow/generate_tf_models.py&gt;generate_tf_models.py&lt;/denchmark-link&gt;
 script to generate test data using TensorFlow. We already have one test for  so we need to figure out what configuration leads the crush. I think you can start change strides and padding arguments then change the rest of parameters until you'll catch a bug.
		</comment>
		<comment id='4' author='philipp-fischer' date='2018-01-27T14:49:48Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
 Thanks, I will get on it now.
		</comment>
		<comment id='5' author='philipp-fischer' date='2018-01-27T15:48:58Z'>
		I had a look at the generate_tf_models.py script.
The conv2d_transpose layer there only uses strides of 1 and VALID padding.
Maybe you can already reproduce the error by changing this to stride 2 and SAME padding as a second test case.
		</comment>
		<comment id='6' author='philipp-fischer' date='2018-01-27T20:12:27Z'>
		I am also wondering why opencv doesn't seem to load the output_size from the TF graph. I think it is crucial for the layer to work.
		</comment>
		<comment id='7' author='philipp-fischer' date='2018-01-28T09:10:48Z'>
		I stripped tf_inception.cpp down to what we need.
Here it is:
#include &lt;opencv2/dnn.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
using namespace cv;
using namespace cv::dnn;

#include &lt;fstream&gt;
#include &lt;iostream&gt;
#include &lt;cstdlib&gt;
using namespace std;

const String keys =
        "{help h    || Sample app for loading Inception TensorFlow model. "
                       "The model and class names list can be downloaded here: "
                       "https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip }"
        "{model m   |tensorflow_inception_graph.pb| path to TensorFlow .pb model file }"
        "{image i   || path to image file }"
        "{i_blob    | input | input blob name) }"
        "{o_blob    | softmax2 | output blob name) }"
        "{result r  || path to save output blob (optional, binary format, NCHW order) }"
        ;

void getMaxClass(const Mat &amp;probBlob, int *classId, double *classProb);
std::vector&lt;String&gt; readClassNames(const char *filename);

int main(int argc, char **argv)
{
    cv::CommandLineParser parser(argc, argv, keys);

    if (parser.has("help"))
    {
        parser.printMessage();
        return 0;
    }

    String modelFile = parser.get&lt;String&gt;("model");
    String imageFile = parser.get&lt;String&gt;("image");
    String inBlobName = parser.get&lt;String&gt;("i_blob");
    String outBlobName = parser.get&lt;String&gt;("o_blob");

    if (!parser.check())
    {
        parser.printErrors();
        return 0;
    }

    String resultFile = parser.get&lt;String&gt;("result");

    //! [Initialize network]
    dnn::Net net = readNetFromTensorflow(modelFile);
    //! [Initialize network]

    if (net.empty())
    {
        std::cerr &lt;&lt; "Can't load network by using the mode file: " &lt;&lt; std::endl;
        std::cerr &lt;&lt; modelFile &lt;&lt; std::endl;
        exit(-1);
    }

    //! [Prepare blob]
    Mat img = imread(imageFile);
    if (img.empty())
    {
        std::cerr &lt;&lt; "Can't read image from the file: " &lt;&lt; imageFile &lt;&lt; std::endl;
        exit(-1);
    }

    Mat inputBlob = blobFromImage(img, 1.0f, Size(32, 32), Scalar(), true, false); 
    //Convert Mat to batch of images
    //! [Prepare blob]
    //! [Set input blob]
    net.setInput(inputBlob, inBlobName);        //set the network input
    //! [Set input blob]
    cv::TickMeter tm;
    tm.start();

    //! [Make forward pass]
    Mat result = net.forward(outBlobName);                          //compute output
    //! [Make forward pass]
    tm.stop();

    if (!resultFile.empty()) {
        CV_Assert(result.isContinuous());

        ofstream fout(resultFile.c_str(), ios::out | ios::binary);
        fout.write((char*)result.data, result.total() * sizeof(float));
        fout.close();
    }

    std::cout &lt;&lt; "Output blob shape " &lt;&lt; result.size[0] &lt;&lt; " x " &lt;&lt; result.size[1] &lt;&lt; " x " &lt;&lt; result.size[2] &lt;&lt; " x " &lt;&lt; result.size[3] &lt;&lt; std::endl;
    std::cout &lt;&lt; "Inference time, ms: " &lt;&lt; tm.getTimeMilli()  &lt;&lt; std::endl;
    
    return 0;
} 
But, I ran into a failed assertion and haven't been able to reproduce the bug. Can you help me out here a bit? I think it's about the wrong input blob size.
&lt;denchmark-code&gt;OpenCV Error: Assertion failed (blobs[0].size[0] == inpCn) in getMemoryShapes, file /home/atharva/Documents/opencv/modules/dnn/src/layers/convolution_layer.cpp, line 1070
terminate called after throwing an instance of 'cv::Exception'
  what():  /home/atharva/Documents/opencv/modules/dnn/src/layers/convolution_layer.cpp:1070: error: (-215) blobs[0].size[0] == inpCn in function getMemoryShapes

Aborted (core dumped)
&lt;/denchmark-code&gt;

I am using the optimized_model &lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
 uploaded.
		</comment>
		<comment id='8' author='philipp-fischer' date='2018-01-28T09:28:52Z'>
		
I am also wondering why opencv doesn't seem to load the output_size from the TF graph. I think it is crucial for the layer to work.

&lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
, you are right. It's the next problem but it's not critical for all cases. In example,
inp = tf.placeholder(tf.float32, [1, 31, 31, 1], 'input')
weights = tf.Variable(tf.random_normal([3, 3, 8, 1], dtype=tf.float32))
deconv = tf.nn.conv2d_transpose(value=inp, filter=weights,
                                output_shape=[1, 63, 63, 8], strides=[1, 2, 2, 1],
                                padding='VALID')
works fine because it's exactly inverse to convolution layer, . But if  we have to add some  padding (here it's 1x1). It's already implemented for &lt;denchmark-link:https://github.com/torch/nn/blob/master/doc/convolution.md#spatialfullconvolution&gt;Torch's deconvolution&lt;/denchmark-link&gt;
 and should be computed for TensorFlow from  as you noticed.
		</comment>
		<comment id='9' author='philipp-fischer' date='2018-01-28T09:36:52Z'>
		&lt;denchmark-link:https://github.com/akhandait&gt;@akhandait&lt;/denchmark-link&gt;
, we have more convenient way for tests. Take a look on &lt;denchmark-link:https://github.com/opencv/opencv/blob/master/modules/dnn/test/test_tf_importer.cpp&gt;test_tf_importer.cpp&lt;/denchmark-link&gt;
. There is a test
TEST(Test_TensorFlow, deconvolution)
{
    runTensorFlowNet("deconvolution");
}
that could be extended with one more test case. You need to generate input and output for network so TensorFlow should be installed first. Then save model, input and target output at opencv_extra/testdata/dnn and run a test by opencv_test_dnn --gtest_filter=Test_TensorFlow.deconvolution.
		</comment>
		<comment id='10' author='philipp-fischer' date='2018-01-30T20:42:00Z'>
		Had some quick tests today. So it seems to crash only if you use strides larger than 1.
VALID vs. SAME padding didn't cause a crash for me.
		</comment>
		<comment id='11' author='philipp-fischer' date='2018-01-31T11:48:28Z'>
		&lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
 In the generate_tf_models.py file, we have to provide an argument for the transform_graph tool, which file does it expect? I searched for it in my installed tensorflow but couldn't find it anywhere. How did you run it?
		</comment>
		<comment id='12' author='philipp-fischer' date='2018-01-31T11:50:47Z'>
		&lt;denchmark-link:https://github.com/akhandait&gt;@akhandait&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#using-the-graph-transform-tool&gt;Using the Graph Transform Tool&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='philipp-fischer' date='2018-02-04T06:47:26Z'>
		
Had some quick tests today. So it seems to crash only if you use strides larger than 1.
VALID vs. SAME padding didn't cause a crash for me.

&lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
, I think we could face a problem varying both strides or padding mode. In example, strides are 1 but  padding is crashed:
inp = tf.placeholder(tf.float32, [1, 64, 64, 1], 'input')
deconv_weights = tf.Variable(tf.random_normal([3, 3, 8, 1], dtype=tf.float32), name='deconv_weights')
deconv = tf.nn.conv2d_transpose(value=inp, filter=deconv_weights,
                                output_shape=[1, 64, 64, 8], strides=[1, 1, 1, 1],
                                padding='SAME')
but the following example works:
inp = tf.placeholder(tf.float32, [1, 64, 64, 1], 'input')
deconv_weights = tf.Variable(tf.random_normal([3, 3, 8, 1], dtype=tf.float32), name='deconv_weights')
deconv = tf.nn.conv2d_transpose(value=inp, filter=deconv_weights,
                                output_shape=[1, 66, 66, 8], strides=[1, 1, 1, 1],
                                padding='VALID')
		</comment>
		<comment id='14' author='philipp-fischer' date='2018-02-05T16:12:59Z'>
		I think I found it:
The problem is in class BaseConvolutionLayerImpl in void finalize(...).
This function is used for both conv and deconv layers when calling getConvPoolPaddings.
But for deconv, the order of input and output should be the other way around when computing the padding.
My current workaround is to override the finalize() function in DeConvolutionLayerImpl and change the getConvPoolPaddings call by swapping the first two arguments.
		</comment>
		<comment id='15' author='philipp-fischer' date='2018-02-12T17:12:21Z'>
		&lt;denchmark-link:https://github.com/philipp-fischer&gt;@philipp-fischer&lt;/denchmark-link&gt;
, May I ask you to test your model with changes from &lt;denchmark-link:https://github.com/opencv/opencv/pull/10850&gt;#10850&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='16' author='philipp-fischer' date='2018-02-13T11:28:39Z'>
		Thanks! We had a quick test and it seems to work now.
Great that you even fixed the shape problems with adj_w and adj_h
		</comment>
	</comments>
</bug>