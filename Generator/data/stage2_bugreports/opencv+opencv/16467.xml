<bug id='16467' author='ccqu' open_date='2020-01-30T14:58:22Z' closed_time='2020-02-24T18:22:20Z'>
	<summary>SSD 512 COCO model buggy detection on CUDA</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 4.2.0-dev 5265db8
Operating System / Platform =&gt; Windows 10 64 Bit
Compiler =&gt; Visual Studio 2015

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

Tried to do inference with the original &lt;denchmark-link:https://github.com/weiliu89/caffe/tree/ssd#models&gt;SSD512 COCO&lt;/denchmark-link&gt;
 model but got a lot of false detections (mostly "book") using CUDA ( ). Maybe &lt;denchmark-link:https://github.com/YashasSamaga&gt;@YashasSamaga&lt;/denchmark-link&gt;
 have an idea?

Input image: https://de.wikipedia.org/wiki/Oxford_Street#/media/Datei:Oxford.street.london.arp.jpg


Result



Result without category "book"



Result on CPU (`DNN_BACKEND_OPENCV` `DNN_TARGET_CPU`) is fine


&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

Code snippet:
&lt;denchmark-code&gt;cv::dnn::blobFromImage(img, blob, 1, cv::Size(512, 512), cv::Scalar(104, 117, 123), false/*swapRB*/, false/*crop*/);
net.setInput(blob, "data");
cv::Mat detection = net.forward("detection_out");
cv::Mat detectionMat(detection.size[2], detection.size[3], CV_32F, detection.ptr&lt;float&gt;());

// Postprocessing
// Detection format: [image_id, label, score, xmin, ymin, xmax, ymax]
for (size_t i = 0; i &lt; detectionMat.rows; ++i) {
    const std::vector&lt;float&gt;&amp; d = detectionMat.row(i);
    auto id = static_cast&lt;unsigned&gt;(round(d[1]));
    if (id &gt; 0) {
        bbox_t bb;
        bb.x = d[3] * img.cols;
        bb.y = d[4] * img.rows;
        bb.w = d[5] * img.cols - bb.x;
        bb.h = d[6] * img.rows - bb.y;
        bb.prob = d[2];
        bb.obj_id = id;
    }
}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ccqu' date='2020-01-31T08:33:36Z'>
		Other SSD512 models also show the same problem:
&lt;denchmark-link:https://user-images.githubusercontent.com/23058357/73524074-9e0a6880-440c-11ea-995a-cab48b1d4bea.png&gt;&lt;/denchmark-link&gt;

SSD300 models however work normally on CUDA.
		</comment>
		<comment id='2' author='ccqu' date='2020-01-31T14:14:03Z'>
		I tested it with 2080Ti with ocv 4.1.2 and 4.2.0 &lt;denchmark-link:https://github.com/opencv/opencv/commit/5265db82c7ed0880117634cc723ed1bc91333b1b&gt;5265db8&lt;/denchmark-link&gt;
 and i have the same issues
		</comment>
		<comment id='3' author='ccqu' date='2020-02-01T16:13:42Z'>
		CUDA-MEMCHECK reported truckload of illegal writes by concat kernels in the mbox_conf layer. This corrupts the data in the memory and hence leads to wrong outputs.
&lt;denchmark-link:https://github.com/tompollok&gt;@tompollok&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ccqu&gt;@ccqu&lt;/denchmark-link&gt;
 As a temporary solution, you can set the  environment variable to . The model should give the correct outputs without any significant loss in performance.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;




opencv/modules/dnn/src/op_cuda.hpp


        Lines 296 to 304
      in
      27edba4






 GenericCUDABackendWrapper(const Ptr&lt;BackendWrapper&gt;&amp; base_, const MatShape&amp; shape_) 



     : CUDABackendWrapper(TargetID) 



 { 



 const Ptr&lt;GenericCUDABackendWrapper&gt; base = base_.dynamicCast&lt;GenericCUDABackendWrapper&gt;(); 



 CV_Assert(base); 



 



     shape = shape_; 



     shared_block = base-&gt;shared_block; 



 } 





This constructor is called for a base buffer of size 65536 floats but the shape passed adds up to a total of 1989684 floats. Since the tensor is not resized to 1989684, attempts to use the tensor with the specified shape will lead to illegal memory accesses.
A fix would be to resize the tensor if it's not large enough to have the given shape but I am not sure if this is the correct fix as other backends (which I used as a reference) are also expecting the base buffer to be big enough to handle any reuse.



opencv/modules/dnn/src/op_vkcom.cpp


        Lines 95 to 107
      in
      27edba4






 VkComBackendWrapper::VkComBackendWrapper(const Ptr&lt;BackendWrapper&gt;&amp; baseBuffer, Mat&amp; m) 



     : BackendWrapper(DNN_BACKEND_VKCOM, DNN_TARGET_VULKAN) 



 { 



 Ptr&lt;VkComBackendWrapper&gt; base = baseBuffer.dynamicCast&lt;VkComBackendWrapper&gt;(); 



 CV_Assert(!base.empty()); 



 



     host = &amp;m; 



     tensor = base-&gt;tensor; 



 CV_Assert(tensor.count() &gt;= m.total()); 



     tensor.reshape(0, shape(m)); 



     hostDirty = false; 



     deviceDirty = false; 



 } 





Vulkan backend doesn't resize and in fact, has an assertion to ensure that a resize won't be required.



opencv/modules/dnn/src/op_halide.cpp


        Lines 115 to 134
      in
      27edba4






 HalideBackendWrapper::HalideBackendWrapper(const Ptr&lt;BackendWrapper&gt;&amp; base, 



 const MatShape&amp; shape) 



     : BackendWrapper(DNN_BACKEND_HALIDE, base-&gt;targetId) 



 { 



     managesDevMemory = false; 



     Halide::Buffer&lt;float&gt; baseBuffer = halideBuffer(base); 



     buffer = Halide::Buffer&lt;float&gt;((float*)baseBuffer.raw_buffer()-&gt;host, 



 getBufferShape(shape)); 



 if (baseBuffer.has_device_allocation()) 



     { 



         buffer.raw_buffer()-&gt;device = baseBuffer.raw_buffer()-&gt;device; 



         buffer.raw_buffer()-&gt;device_interface = baseBuffer.raw_buffer()-&gt;device_interface; 



         buffer.set_device_dirty(); 



     } 



 else 



     { 



         buffer.set_host_dirty();  // Indicate that data is on CPU. 



 CV_Assert(targetId == DNN_TARGET_CPU); 



     } 



 } 





I am not really sure about this but it looks like Buffer is wrapping an existing cv::Mat which I think is of size 65536.



opencv/modules/dnn/src/dnn.cpp


        Lines 922 to 928
      in
      27edba4






 if (unusedBlob.total() &gt;= targetTotal &amp;&amp; 



     unusedBlob.total() &lt; bestBlobTotal) 



 { 



     bestBlobPin = hostIt-&gt;first; 



     bestBlob = unusedBlob; 



     bestBlobTotal = unusedBlob.total(); 



 } 





Here it appears to ensure that the base buffer size is bigger than the required size but yet somehow CUDABackendWrapperFP32::create(base, shape) is called with a shape which has more elements than the base buffer.
		</comment>
		<comment id='4' author='ccqu' date='2020-02-03T09:45:08Z'>
		OPENCV_DNN_DISABLE_MEMORY_OPTIMIZATIONS needs to be set at compilation time, or can it be set at runtime?
		</comment>
		<comment id='5' author='ccqu' date='2020-02-03T09:53:11Z'>
		&lt;denchmark-link:https://github.com/tompollok&gt;@tompollok&lt;/denchmark-link&gt;
, at runtime. "export OPENCV_DNN_DISABLE_MEMORY_OPTIMIZATIONS=1" on Linux.
		</comment>
		<comment id='6' author='ccqu' date='2020-02-07T08:13:30Z'>
		Code used to print the log: &lt;denchmark-link:https://github.com/YashasSamaga/opencv/tree/hotfix-cuda4dnn-i16467&gt;https://github.com/YashasSamaga/opencv/tree/hotfix-cuda4dnn-i16467&lt;/denchmark-link&gt;


Log of creation of blobs and wrappers
wrap(Mat&amp; host): host.data = 0x559e6b331480, host.total() = 786432
CreateWrapper: m.data = 0x559e6b331480, m.total() = 786432
BeforeCreateHost: 0x559e6b331480 786432
AfterCreateHost: 0x559e6b331480 786432
wrap(Mat&amp; host): host.data = 0x559e6b331480, host.total() = 786432
ReuseWrapper: host.data = 0x559e6b331480, host.total() = 786432, required = 786432
BeforeCreateHost: 0 0
AfterCreateHost: 0x7f3b0c525040 16777216
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 16777216
CreateWrapper: m.data = 0x7f3b0c525040, m.total() = 16777216
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 16777216
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 16777216
BeforeCreateHost: 0 0
AfterCreateHost: 0x7f3b03fff040 16777216
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 16777216
CreateWrapper: m.data = 0x7f3b03fff040, m.total() = 16777216
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 16777216
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 16777216
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 8388608
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 8388608
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 8388608
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 8388608
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 8388608
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 8388608
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 8388608
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 8388608
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 4194304
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 4194304
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 1048576
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 1048576
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 524288
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 524288
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e47416d40 524288
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 524288
CreateWrapper: m.data = 0x559e47416d40, m.total() = 524288
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 524288
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 524288
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 524288
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 524288
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 524288
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 524288
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 524288
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 524288
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 524288
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 524288
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 524288
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 524288
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6b6314c0 1048576
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 1048576
CreateWrapper: m.data = 0x559e6b6314c0, m.total() = 1048576
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 1048576
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 1048576
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 1048576
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 1048576
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 1048576
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 1048576
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 262144
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 262144
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 262144
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 262144
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 131072
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 131072
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 131072
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 131072
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 32768
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 32768
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 32768
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 32768
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e483f2ec0 16384
wrap(Mat&amp; host): host.data = 0x559e483f2ec0, host.total() = 16384
CreateWrapper: m.data = 0x559e483f2ec0, m.total() = 16384
wrap(Mat&amp; host): host.data = 0x559e483f2ec0, host.total() = 16384
ReuseWrapper: host.data = 0x559e483f2ec0, host.total() = 16384, required = 16384
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 8192
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 8192
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 8192
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 8192
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e476bbf80 4096
wrap(Mat&amp; host): host.data = 0x559e476bbf80, host.total() = 4096
CreateWrapper: m.data = 0x559e476bbf80, m.total() = 4096
wrap(Mat&amp; host): host.data = 0x559e476bbf80, host.total() = 4096
ReuseWrapper: host.data = 0x559e476bbf80, host.total() = 4096, required = 4096
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 2048
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 2048
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 2048
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 2048
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e48402f00 1024
wrap(Mat&amp; host): host.data = 0x559e48402f00, host.total() = 1024
CreateWrapper: m.data = 0x559e48402f00, m.total() = 1024
wrap(Mat&amp; host): host.data = 0x559e48402f00, host.total() = 1024
ReuseWrapper: host.data = 0x559e48402f00, host.total() = 1024, required = 1024
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 512
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 512
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 512
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 512
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e46c535c0 256
wrap(Mat&amp; host): host.data = 0x559e46c535c0, host.total() = 256
CreateWrapper: m.data = 0x559e46c535c0, m.total() = 256
wrap(Mat&amp; host): host.data = 0x559e46c535c0, host.total() = 256
ReuseWrapper: host.data = 0x559e46c535c0, host.total() = 256, required = 256
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6ba31540 2097152
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 2097152
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 2097152
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 65536
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 65536
wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 65536
CreateWrapper: m.data = 0x559e6ba31540, m.total() = 65536
wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 65536
ReuseWrapper: host.data = 0x559e6ba31540, host.total() = 65536, required = 65536
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6c231580 1327104
wrap(Mat&amp; host): host.data = 0x559e6c231580, host.total() = 1327104
CreateWrapper: m.data = 0x559e6c231580, m.total() = 1327104
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6c7415c0 1327104
wrap(Mat&amp; host): host.data = 0x559e6c7415c0, host.total() = 1327104
CreateWrapper: m.data = 0x559e6c7415c0, m.total() = 1327104
wrap(Mat&amp; host): host.data = 0x559e6c7415c0, host.total() = 1327104
ReuseWrapper: host.data = 0x559e6c7415c0, host.total() = 1327104, required = 1327104
wrap(Mat&amp; host): host.data = 0x559e47416d40, host.total() = 131072
ReuseWrapper: host.data = 0x559e47416d40, host.total() = 524288, required = 131072
wrap(Mat&amp; host): host.data = 0x559e6c231580, host.total() = 24576
ReuseWrapper: host.data = 0x559e6c231580, host.total() = 1327104, required = 24576
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 24576
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 24576
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 24576
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 24576
wrap(Mat&amp; host): host.data = 0x559e6c231580, host.total() = 497664
ReuseWrapper: host.data = 0x559e6c231580, host.total() = 1327104, required = 497664
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6b031440 497664
wrap(Mat&amp; host): host.data = 0x559e6b031440, host.total() = 497664
CreateWrapper: m.data = 0x559e6b031440, m.total() = 497664
wrap(Mat&amp; host): host.data = 0x559e6b031440, host.total() = 497664
ReuseWrapper: host.data = 0x559e6b031440, host.total() = 497664, required = 497664
wrap(Mat&amp; host): host.data = 0x559e6c231580, host.total() = 49152
ReuseWrapper: host.data = 0x559e6c231580, host.total() = 1327104, required = 49152
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 6144
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 6144
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e476c0f40 6144
wrap(Mat&amp; host): host.data = 0x559e476c0f40, host.total() = 6144
CreateWrapper: m.data = 0x559e476c0f40, m.total() = 6144
wrap(Mat&amp; host): host.data = 0x559e476c0f40, host.total() = 6144
ReuseWrapper: host.data = 0x559e476c0f40, host.total() = 6144, required = 6144
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 124416
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 124416
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e47616d80 124416
wrap(Mat&amp; host): host.data = 0x559e47616d80, host.total() = 124416
CreateWrapper: m.data = 0x559e47616d80, m.total() = 124416
wrap(Mat&amp; host): host.data = 0x559e47616d80, host.total() = 124416
ReuseWrapper: host.data = 0x559e47616d80, host.total() = 124416, required = 124416
wrap(Mat&amp; host): host.data = 0x7f3b03fff040, host.total() = 12288
ReuseWrapper: host.data = 0x7f3b03fff040, host.total() = 16777216, required = 12288
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 1536
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 1536
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e476905c0 1536
wrap(Mat&amp; host): host.data = 0x559e476905c0, host.total() = 1536
CreateWrapper: m.data = 0x559e476905c0, m.total() = 1536
wrap(Mat&amp; host): host.data = 0x559e476905c0, host.total() = 1536
ReuseWrapper: host.data = 0x559e476905c0, host.total() = 1536, required = 1536
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 31104
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 31104
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e46c2e500 31104
wrap(Mat&amp; host): host.data = 0x559e46c2e500, host.total() = 31104
CreateWrapper: m.data = 0x559e46c2e500, m.total() = 31104
wrap(Mat&amp; host): host.data = 0x559e46c2e500, host.total() = 31104
ReuseWrapper: host.data = 0x559e46c2e500, host.total() = 31104, required = 31104
wrap(Mat&amp; host): host.data = 0x559e6b6314c0, host.total() = 3072
ReuseWrapper: host.data = 0x559e6b6314c0, host.total() = 1048576, required = 3072
wrap(Mat&amp; host): host.data = 0x559e483f2ec0, host.total() = 384
ReuseWrapper: host.data = 0x559e483f2ec0, host.total() = 16384, required = 384
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e47ec1c80 384
wrap(Mat&amp; host): host.data = 0x559e47ec1c80, host.total() = 384
CreateWrapper: m.data = 0x559e47ec1c80, m.total() = 384
wrap(Mat&amp; host): host.data = 0x559e47ec1c80, host.total() = 384
ReuseWrapper: host.data = 0x559e47ec1c80, host.total() = 384, required = 384
wrap(Mat&amp; host): host.data = 0x559e483f2ec0, host.total() = 7776
ReuseWrapper: host.data = 0x559e483f2ec0, host.total() = 16384, required = 7776
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e48495d40 7776
wrap(Mat&amp; host): host.data = 0x559e48495d40, host.total() = 7776
CreateWrapper: m.data = 0x559e48495d40, m.total() = 7776
wrap(Mat&amp; host): host.data = 0x559e48495d40, host.total() = 7776
ReuseWrapper: host.data = 0x559e48495d40, host.total() = 7776, required = 7776
wrap(Mat&amp; host): host.data = 0x559e483f2ec0, host.total() = 768
ReuseWrapper: host.data = 0x559e483f2ec0, host.total() = 16384, required = 768
wrap(Mat&amp; host): host.data = 0x559e476bbf80, host.total() = 64
ReuseWrapper: host.data = 0x559e476bbf80, host.total() = 4096, required = 64
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e476947c0 64
wrap(Mat&amp; host): host.data = 0x559e476947c0, host.total() = 64
CreateWrapper: m.data = 0x559e476947c0, m.total() = 64
wrap(Mat&amp; host): host.data = 0x559e476947c0, host.total() = 64
ReuseWrapper: host.data = 0x559e476947c0, host.total() = 64, required = 64
wrap(Mat&amp; host): host.data = 0x559e476bbf80, host.total() = 1296
ReuseWrapper: host.data = 0x559e476bbf80, host.total() = 4096, required = 1296
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e4849f640 1296
wrap(Mat&amp; host): host.data = 0x559e4849f640, host.total() = 1296
CreateWrapper: m.data = 0x559e4849f640, m.total() = 1296
wrap(Mat&amp; host): host.data = 0x559e4849f640, host.total() = 1296
ReuseWrapper: host.data = 0x559e4849f640, host.total() = 1296, required = 1296
wrap(Mat&amp; host): host.data = 0x559e476bbf80, host.total() = 128
ReuseWrapper: host.data = 0x559e476bbf80, host.total() = 4096, required = 128
wrap(Mat&amp; host): host.data = 0x559e48402f00, host.total() = 16
ReuseWrapper: host.data = 0x559e48402f00, host.total() = 1024, required = 16
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e484a2000 16
wrap(Mat&amp; host): host.data = 0x559e484a2000, host.total() = 16
CreateWrapper: m.data = 0x559e484a2000, m.total() = 16
wrap(Mat&amp; host): host.data = 0x559e484a2000, host.total() = 16
ReuseWrapper: host.data = 0x559e484a2000, host.total() = 16, required = 16
wrap(Mat&amp; host): host.data = 0x559e48402f00, host.total() = 324
ReuseWrapper: host.data = 0x559e48402f00, host.total() = 1024, required = 324
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e47ea2440 324
wrap(Mat&amp; host): host.data = 0x559e47ea2440, host.total() = 324
CreateWrapper: m.data = 0x559e47ea2440, m.total() = 324
wrap(Mat&amp; host): host.data = 0x559e47ea2440, host.total() = 324
ReuseWrapper: host.data = 0x559e47ea2440, host.total() = 324, required = 324
wrap(Mat&amp; host): host.data = 0x559e48402f00, host.total() = 32
ReuseWrapper: host.data = 0x559e48402f00, host.total() = 1024, required = 32
BeforeCreateHost: 0 0
AfterCreateHost: 0x559e46e813c0 98256
wrap(Mat&amp; host): host.data = 0x559e46e813c0, host.total() = 98256
CreateWrapper: m.data = 0x559e46e813c0, m.total() = 98256
wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 1989684
ReuseWrapper: host.data = 0x559e6ba31540, host.total() = 65536, required = 1989684
wrap(Mat&amp; host): host.data = 0x559e6b031440, host.total() = 196512
ReuseWrapper: host.data = 0x559e6b031440, host.total() = 497664, required = 196512
wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 1989684
ReuseWrapper: host.data = 0x559e6ba31540, host.total() = 65536, required = 1989684
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 1989684
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 1989684
wrap(Mat&amp; host): host.data = 0x7f3b0c525040, host.total() = 1989684
ReuseWrapper: host.data = 0x7f3b0c525040, host.total() = 16777216, required = 1989684
wrap(Mat&amp; host): host.data = 0x559e476905c0, host.total() = 1400
ReuseWrapper: host.data = 0x559e476905c0, host.total() = 1536, required = 1400


&lt;denchmark-h:h3&gt;What is causing memory corruption?&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 1989684
ReuseWrapper: host.data = 0x559e6ba31540, host.total() = 65536, required = 1989684
&lt;/denchmark-code&gt;

The CUDABackendWrapper that is being reused has capacity for just 65536 elements but it is being reused to hold 1989684 elements.
&lt;denchmark-h:h3&gt;What is causing this?&lt;/denchmark-h&gt;

The host blob of interest is allocated to have a capacity of 2097152 in allocateBlobsForLayer():
&lt;denchmark-code&gt;BeforeCreateHost: 0 0
AfterCreateHost: 0x559e6ba31540 2097152
&lt;/denchmark-code&gt;

The corresponding CUDABackendWrapper is created several steps later but a sub-mat of size 65536 is passed to the constructor. The host mat's actual capacity is 2097152 but it is passed to the constructor with a different shape which leads to a total of 65536 elements.
&lt;denchmark-code&gt;wrap(Mat&amp; host): host.data = 0x559e6ba31540, host.total() = 65536
CreateWrapper: m.data = 0x559e6ba31540, m.total() = 65536
&lt;/denchmark-code&gt;

Since the CUDABackendWrapper relies on the cv::Mat's shape that is passed to the constructor to compute the required memory size, it allocates device memory to hold 65536 elements instead of 2097152 elements.
The same logic is used by the Vulkan and Halide backends. I think they might also be affected but I don't have them to test.
&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
 I am not sure what's the correct way to fix this. I could simply resize the CUDA memory to be beig enough to be reused. But I think the actual problem is in the code which invokes the  constructors. While creating the wrapper, I think it should create a wrapper for the full host memory instead of passing a submatrix of the host mat.
		</comment>
	</comments>
</bug>