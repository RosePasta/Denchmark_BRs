<bug id='10718' author='akerimcapar' open_date='2018-01-29T11:23:26Z' closed_time='2018-02-01T13:22:25Z'>
	<summary>opencv dnn readNetFromCaffe error: "caffe.BatchNormParameter" has no field named "scale_filler"</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 3.3
Operating System / Platform =&gt; Windows 10 / 64 Bit
Compiler =&gt; Visual Studio 2015

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

I trained a custom caffe network with following batch normalization layer:
layer {
name: "bn1"
type: "BatchNorm"
bottom: "conv1"
top: "bn1"
param {
lr_mult: 1
decay_mult: 0
}
param {
lr_mult: 1
decay_mult: 0
}
batch_norm_param {
scale_filler {
type: "constant"
value: 1
}
bias_filler {
type: "constant"
value: 0
}
}
}
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

When I tried to load the caffe prototxt file with dnn::readNetFromCaffe function I get the following error:
[libprotobuf ERROR C:\opencv330\opencv\sources\3rdparty\protobuf\src\google\protobuf\text_format.cc:298] Error parsing text-format caffe.NetParameter: 63:18: Message type "caffe.BatchNormParameter" has no field named "scale_filler".
OpenCV Error: Unspecified error (FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: c:/deploy.prototxt) in cv::dnn::ReadNetParamsFromTextFileOrDie, file C:\opencv330\opencv\sources\modules\dnn\src\caffe\caffe_io.cpp, line 1137
Exception: C:\opencv330\opencv\sources\modules\dnn\src\caffe\caffe_io.cpp:1137: error: (-2) FAILED: ReadProtoFromTextFile(param_file, param). Failed to parse NetParameter file: c:/deploy.prototxt in function cv::dnn::ReadNetParamsFromTextFileOrDie
Can't load network by using the following files:
prototxt:   c:/deploy.prototxt
caffemodel: c://deploy.caffemodel
bvlc_googlenet.caffemodel can be downloaded here:
&lt;denchmark-link:http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel&gt;http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel&lt;/denchmark-link&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

I have to mention that readNetFromCaffe function works properly when I train the network without scale_filler and bias_filler parameters.
&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;


Train a caffe custom network with at least one batch normalization layer as in "Detailed description" part.
get the prototxt and caffemodel files and call the file paths as parameters of dnn::readNetFromCaffe function

	</description>
	<comments>
		<comment id='1' author='akerimcapar' date='2018-01-29T13:13:39Z'>
		&lt;denchmark-link:https://github.com/akerimcapar&gt;@akerimcapar&lt;/denchmark-link&gt;
, an origin Caffe framework has no  or  for . See &lt;denchmark-link:https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto&gt;https://github.com/BVLC/caffe/blob/master/src/caffe/proto/caffe.proto&lt;/denchmark-link&gt;
. Please specify what version of Caffe is used.
		</comment>
		<comment id='2' author='akerimcapar' date='2018-01-29T13:20:07Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

I am using NVIDIA Caffe 0.15.14 version on DIGITS 6.0.0-rc.2 platform
		</comment>
		<comment id='3' author='akerimcapar' date='2018-01-29T13:35:03Z'>
		&lt;denchmark-link:https://github.com/akerimcapar&gt;@akerimcapar&lt;/denchmark-link&gt;
, have you tried to comment all fillers and call  for it? Caffe uses it to initialize the weights before training. Your  contains trained parameters so deploy version of  can be without such kind of parameters like learning rate multipliers, fillers, etc.
If it is possible, check that Caffe and OpenCV produces similar results for similar inputs. See &lt;denchmark-link:https://github.com/opencv/opencv/issues/10653#issuecomment-359385765&gt;#10653 (comment)&lt;/denchmark-link&gt;
 for example.
		</comment>
		<comment id='4' author='akerimcapar' date='2018-01-30T09:37:50Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

Yes  function exception is solved when I comment out fillers as follows:
&lt;denchmark-code&gt;layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  #batch_norm_param {
    #scale_filler {
    #  type: "constant"
    #  value: 1.0
    #}
    #bias_filler {
    #  type: "constant"
    #  value: 0.0
    #}
  #}
}
&lt;/denchmark-code&gt;

But now it throws exception on net.forward function. Call stack is as follows:
concrt140.dll!Concurrency::details::SchedulingNode::GetFirstVirtualProcessor(int * pIdx) Line 107	C++
concrt140.dll!Concurrency::details::WorkSearchContext::StealLocalRunnable(Concurrency::details::WorkItem * pWorkItem, Concurrency::details::SchedulingNode * pNode, Concurrency::details::VirtualProcessor * pSkipVirtualProcessor) Line 254	C++
concrt140.dll!Concurrency::details::WorkSearchContext::SearchCacheLocal(Concurrency::details::WorkItem * pWorkItem, Concurrency::details::ScheduleGroupSegmentBase * pOriginSegment, bool fLastPass, unsigned long allowableTypes) Line 1449	C++
concrt140.dll!Concurrency::details::InternalContextBase::Dispatch(Concurrency::DispatchState * pDispatchState) Line 1697	C++
concrt140.dll!Concurrency::details::FreeThreadProxy::Dispatch() Line 203	C++
concrt140.dll!Concurrency::details::ThreadProxy::ThreadProxyMain(void * lpParameter) Line 177	C++
kernel32.dll!@BaseThreadInitThunk@12()	Unknown
ntdll.dll!__RtlUserThreadStart()	Unknown
ntdll.dll!__RtlUserThreadStart@8()	Unknown
I also checked to remove all parameters of batchnorm layer, but it did not work too:
&lt;denchmark-code&gt;layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='akerimcapar' date='2018-01-30T10:36:41Z'>
		&lt;denchmark-link:https://github.com/akerimcapar&gt;@akerimcapar&lt;/denchmark-link&gt;
 Is it possible to share a model? Or just a minimal working example with random weights that we can test locally.
		</comment>
		<comment id='6' author='akerimcapar' date='2018-01-30T12:19:27Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

I attached two zip files:

Caffe_model.zip: Caffe prototxt and binary weights file
SourceAndSampleImage.zip: C++ source code that i used to call opencv dnn functions and a sample input image

Thank you for your support
&lt;denchmark-link:https://github.com/opencv/opencv/files/1677582/Caffe_model.zip&gt;Caffe_model.zip&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/opencv/opencv/files/1677598/SourceAndSampleImage.zip&gt;SourceAndSampleImage.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='akerimcapar' date='2018-01-31T13:35:28Z'>
		&lt;denchmark-link:https://github.com/akerimcapar&gt;@akerimcapar&lt;/denchmark-link&gt;
, The problem is in deprecated order of Batch Normalization parameters.
see caffe-0.16: &lt;denchmark-link:https://github.com/NVIDIA/caffe/blob/3b49fb08fe49837a1ebc7d92b6ab1501bb4e2253/src/caffe/net.cpp#L1143&gt;https://github.com/NVIDIA/caffe/blob/3b49fb08fe49837a1ebc7d92b6ab1501bb4e2253/src/caffe/net.cpp#L1143&lt;/denchmark-link&gt;

We can use caffe-0.16 to update a model. However now caffe-0.16 can't load this model because bn3 layer can't manage 2D input from ip1 (a bug?).
So I suggest you a bit rude but workable solution.


Build and install NVIDIA caffe-0.15


Build OpenCV with a PR #10746


Create a separate .prototxt with no batch norm fillers but with scale_bias: 1 flag:


batch_norm_param {
  scale_bias: 1
  # scale_filler {
  #   type: "constant"
  #   value: 1.0
  # }
  # bias_filler {
  #   type: "constant"
  #   value: 0.0
  # }
}

Permute parameters manually and save a .caffemodel.

import cv2 as cv
import caffe
import numpy as np

proto = 'Caffe_model/deploy.prototxt'
weights = 'Caffe_model/deploy.caffemodel'

np.random.seed(223)
inp = np.random.standard_normal([1, 1, 56, 56]).astype(np.float32)

# Caffe
caffe_net = caffe.Net(proto, weights, caffe.TEST)
caffe_net.blobs['data'].data[:,:,:,:] = np.copy(inp)
caffe_net.forward()

# old format: 0 - scale , 1 - bias,  2 - mean , 3 - var, 4 - reserved
# new format: 0 - mean  , 1 - var,  2 - reserved , 3- scale, 4 - bias
bnLayers = ['bn1', 'bn2', 'bn3']
for name in bnLayers:
    caffe_net.params[name][0], caffe_net.params[name][2] = caffe_net.params[name][2], caffe_net.params[name][0]
    caffe_net.params[name][1], caffe_net.params[name][3] = caffe_net.params[name][3], caffe_net.params[name][1]
    caffe_net.params[name][2], caffe_net.params[name][4] = caffe_net.params[name][4], caffe_net.params[name][2]
    caffe_net.params[name][3], caffe_net.params[name][4] = caffe_net.params[name][4], caffe_net.params[name][3]

caffe_net.save('updated.caffemodel')

caffeOut = caffe_net.blobs['softmax'].data

# OpenCV
proto = 'Caffe_model/cv_deploy.prototxt'
net = cv.dnn.readNetFromCaffe(proto, 'updated.caffemodel')
net.setInput(inp)
cvOut = net.forward()

print np.max(np.abs(caffeOut - cvOut))
I got a 1.6298145e-09 difference.
		</comment>
		<comment id='8' author='akerimcapar' date='2018-02-01T06:44:13Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;

Thank you very much for your solution.


I am not familiar with python. Could you please send the updated caffemodel and prototxt files?


Is it possible to make this caffemodel update with opencv C++ code?


Can i solve the problem if i use caffe-0.16 without bn3 (which includes 2D input from an inner product layer ) layer to train the network. Any need to update opencv dnn codes?


		</comment>
		<comment id='9' author='akerimcapar' date='2018-02-01T07:57:07Z'>
		&lt;denchmark-link:https://github.com/akerimcapar&gt;@akerimcapar&lt;/denchmark-link&gt;
, I think it'd be nice if you can open an issue at &lt;denchmark-link:https://github.com/NVIDIA/caffe&gt;https://github.com/NVIDIA/caffe&lt;/denchmark-link&gt;
 attaching you model. Please try to build caffe-0.16, load the model and reproduce a error. Copy a error message to an issue. This way we can do all the steps easier using Caffe-0.16.
		</comment>
	</comments>
</bug>