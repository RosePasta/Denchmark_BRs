<bug id='9183' author='boulderZ' open_date='2017-07-18T18:24:48Z' closed_time='2017-07-24T16:45:50Z'>
	<summary>Global Patch Collider gpc_evaluate.cpp avg endpoint error calculation does not match test case</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; 3.2.0
Operating System / Platform =&gt;  Ubuntu 14.04
Compiler =&gt; gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;

Testing global patch collider code and found that I was seeing very large average endpoint error when trying to run the demo code gpc_evaluate.cpp. To investigate, I looked at the test case code in &lt;denchmark-link:https://github.com/opencv/opencv_contrib/blob/master/modules/optflow/test/test_OF_accuracy.cpp&gt;test accuracy&lt;/denchmark-link&gt;
. When I ran the test code with the test files the average endpoint error is 0.382. When running same files with gpc_evaluate.cpp, you get ~1e7. The difference is caused because the test case (test_OF_accuracy.cpp) rejects Nan and large numbers while the gpc_evaluate.cpp does not. It seems that the large numbers and or Nans are actually coming from the ground truth file which seemed strange.
Below is a snippet of gpc_evaluate.cpp showing where the error is calculated. If you compare this to the test code in test_OF_accuracy.cpp that follows, you will see that the test code calculates the same quantity except that it only updates the error after making sure the numbers are valid using .  I am not sure if the author's intent was to keep or reject the large numbers/NaNs, but since the test case rejects them, I believe they should also be rejected in the demo code. Also, if those values are rejected, then the line  should be inside the  brackets.
for ( size_t i = 0; i &lt; corr.size(); ++i )
  {
    const Point2f a = corr[i].first;
    const Point2f b = corr[i].second;
    const Point2f c = a + gt.at&lt; Point2f &gt;( corr[i].first.y, corr[i].first.x );
    error += normL2( b - c );
    circle( disp, a, 3, getFlowColor( b - a ), -1 );
    circle( dispErr, a, 3, getFlowColor( b - c, false, 32 ), -1 );
   }
error /= corr.size();
Code from test_OF_accuracy.cpp:
static float calcAvgEPE(vector&lt; pair&lt;Point2i, Point2i&gt; &gt; corr, Mat flow)
{
    double sum = 0;
    int counter = 0;

    for (size_t i = 0; i &lt; corr.size(); ++i)
    {
        Vec2f flow1_at_point = Point2f(corr[i].second - corr[i].first);
        Vec2f flow2_at_point = flow.at&lt;Vec2f&gt;(corr[i].first.y, corr[i].first.x);

        double u1 = (double)flow1_at_point[0];
        double v1 = (double)flow1_at_point[1];
        double u2 = (double)flow2_at_point[0];
        double v2 = (double)flow2_at_point[1];
        if (isFlowCorrect(u1) &amp;&amp; isFlowCorrect(u2) &amp;&amp; isFlowCorrect(v1) &amp;&amp; isFlowCorrect(v2))
        {
            sum += sqrt((u1 - u2) * (u1 - u2) + (v1 - v2) * (v1 - v2));
            counter++;
        }
    }
return (float)(sum / counter);
&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;

Compile and run gpc_evaluate.cpp and use the following input files RubberWhale*.* from &lt;denchmark-link:https://github.com/opencv/opencv_extra/tree/master/testdata/cv/optflow&gt;test data&lt;/denchmark-link&gt;
. Then go to &lt;denchmark-link:https://drive.google.com/open?id=0B7Hb8cfuzrIIZDFscXVYd0NBNFU&gt;trained model&lt;/denchmark-link&gt;
 to download the file forest_middlebury_QUALITY.yml.gz which contains one of the trained algorithms. Any one of the files at this site should work. Example of my command line to run after building is here

The -g flag is for using openCL which can be left off for testing if desired.
This should produce plots and terminal output that shows the average endpoint error to be on order of 1e7. If you then substitute in the code from calcAvgEPE(), you will get average endpoint error of 0.382.
	</description>
	<comments>
		<comment id='1' author='boulderZ' date='2017-07-24T14:47:26Z'>
		&lt;denchmark-link:https://github.com/VladX&gt;@VladX&lt;/denchmark-link&gt;
 , could you please comment on this?
		</comment>
		<comment id='2' author='boulderZ' date='2017-07-24T16:14:02Z'>
		&lt;denchmark-link:https://github.com/boulderZ&gt;@boulderZ&lt;/denchmark-link&gt;
 thank you very much for testing GPC code!
Middlebury groundtruth .flo files indeed contain some incorrect vectors in regions with motion discontinuities.
I fixed it in the pull request.
		</comment>
	</comments>
</bug>