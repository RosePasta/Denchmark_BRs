<bug id='15296' author='Julia702' open_date='2019-08-14T07:25:59Z' closed_time='2019-08-21T17:04:47Z'>
	<summary>Keras model included, Dense Layer MemoryShape error</summary>
	<description>

OpenCV &gt;= 4.1.0

I have a problem using dnn module.
I trained my model and generated a .pb file. I loaded the model wtih readNetFromTensorflow and all worked well.
Then, I tried to expand my model with the SE block of the sequeeze and excitation network. Same as before, I generated my .pb file successfully. I also load it with readNetFromTensorflow  again, but by run net.forward() some errors occurred.
error: OpenCV(4.1.0) /io/opencv/modules/dnn/src/layers/eltwise_layer.cpp:116: error: (-215:Assertion failed) inputs[0] == inputs[i] in function 'getMemoryShapes'
net = cv2.dnn.readNetFromTensorflow(modelPath) img = cv2.imread('image.bmp',0) img_blob = cv2.dnn.blobFromImage(img, size=(256, 256), swapRB=True, crop=False) net.setInput(img_blob) net.forward()
The problem seems to be in the keras dense layer / opencv eltwise layer. My Input is a 2-D Tensor with shape (None, 32).
Defined SE-Block:
`def squeeze_excite_block(input_x, ratio=16):
if K.image_data_format() == 'channels_first':
channel_axis = 1
dim_axis = -1
else:
channel_axis = -1
dim_axis = 1
filters = int(input_x.get_shape()[channel_axis])
dim = int(input_x.get_shape()[dim_axis])
&lt;denchmark-code&gt;    sequeeze = GlobalAveragePooling2D()(input_x)  
    excitation = tf.keras.layers.Dense(units=filters // ratio, activation='relu')(sequeeze)        
    excitation = tf.keras.layers.Dense(units=filters, activation='sigmoid')(excitation)  
    
    excitation = tf.keras.layers.Reshape((1,1,filters))(excitation)
    excitation = tf.keras.layers.UpSampling2D(size=(dim, dim))(excitation)

    if K.image_data_format() == 'channels_first':
        excitation = tf.keras.layers.Permute((3, 1, 2))(excitation)
    scale = tf.keras.layers.Multiply()([input_x, excitation])     
       
    return scale
`
&lt;/denchmark-code&gt;

Used model:
` def unet(pretrained_weights = None,input_size = (256,256,1)):
&lt;denchmark-code&gt;reduction_ratio = 16

inputs = Input(input_size, name='Input')

conv1 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
conv1 = Conv2D(16, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

conv2 = Conv2D(24, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
conv2 = Conv2D(24, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

conv4 = Conv2D(48, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
conv4 = Conv2D(48, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
drop4 = Dropout(0.5)(conv4)

up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop4))
#merge7 = concatenate([conv3,up7], axis = 3)
conv7 = Conv2D(32, 4, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(up7)
conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

up8 = Conv2D(24, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
merge8 = concatenate([conv2,up8], axis = 3)
conv8 = Conv2D(24, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
conv8 = Conv2D(24, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

up9 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
merge9 = concatenate([conv1,up9], axis = 3)
print(K.dtype(merge9))
merge9 = squeeze_excite_block_own(merge9, ratio=reduction_ratio)
print(K.dtype(merge9))
conv9 = Conv2D(12, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
conv9 = Conv2D(12, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv9 = Conv2D(6, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv10 = Conv2D(3, 1, activation = 'softmax', name='Output')(conv9)

model = Model(inputs,conv10)
model.compile(optimizer = Adam(lr = 1e-4), loss =dice_coef_multilabel, metrics = ['accuracy', my_iou_metric]) 

return model
&lt;/denchmark-code&gt;

`
I also tried an additional reshape or flatten layer before the dense layer, but the error still occurs.
Thanks for your help.
.pb file:
&lt;denchmark-link:https://github.com/opencv/opencv/files/3500235/unet_SE.zip&gt;unet_SE.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Julia702' date='2019-08-14T07:35:56Z'>
		
img = cv2.imread('image.bmp',0)

Just to be sure. Is it planned to use grayscale images as inputs?
		</comment>
		<comment id='2' author='Julia702' date='2019-08-14T07:49:31Z'>
		Yes, the input should be used as grayscale image
		</comment>
		<comment id='3' author='Julia702' date='2019-08-14T07:58:44Z'>
		Failed layer:
&lt;denchmark-code&gt;multiply_1_1/mul
input0 shape: [ 1 32 256 256 ]
input1 shape: [ 1 1 256 8192 ]
&lt;/denchmark-code&gt;

Can you please check the dimensions of
&lt;denchmark-code&gt;    scale = tf.keras.layers.Multiply()([input_x, excitation]) 
&lt;/denchmark-code&gt;

inputs?
		</comment>
		<comment id='4' author='Julia702' date='2019-08-14T08:08:45Z'>
		In my keras model I got the shapes:
input_x (None, 256, 256, 32)
excitation (None, 256, 256, 32)
scale (None, 256, 256, 32)
		</comment>
		<comment id='5' author='Julia702' date='2019-08-14T16:48:32Z'>
		&lt;denchmark-link:https://github.com/Julia702&gt;@Julia702&lt;/denchmark-link&gt;
, thanks for detailed report! Try this patch: &lt;denchmark-link:https://github.com/opencv/opencv/pull/15303&gt;#15303&lt;/denchmark-link&gt;

import cv2 as cv
import numpy as np
import tensorflow as tf

np.random.seed(324)
inp = np.random.standard_normal([1, 1, 256, 256]).astype(np.float32)

net = cv.dnn.readNet('unet_SE.pb')
net.setInput(inp)
cvOut = net.forward()
print(cvOut.shape)


with tf.gfile.FastGFile('unet_SE.pb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Session() as sess:
    # Restore session
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='')

    tfOut = sess.run(sess.graph.get_tensor_by_name('Output_2/truediv:0'),
                   feed_dict={'Input_2:0': inp.transpose(0, 2, 3, 1)})

print(tfOut.shape)

print(np.max(np.abs(cvOut - tfOut.transpose(0, 3, 1, 2))))
gives 8.34465e-07
		</comment>
		<comment id='6' author='Julia702' date='2019-08-16T09:25:48Z'>
		Thanks a lot! I can't test the patch right now, because I use OpenCV in Python and I don't know how to get the python wrapper to test the patch. Therefore I am looking forward to the next OpenCV version to test.
		</comment>
		<comment id='7' author='Julia702' date='2019-08-16T09:50:07Z'>
		&lt;denchmark-link:https://github.com/Julia702&gt;@Julia702&lt;/denchmark-link&gt;
, You may try
&lt;denchmark-code&gt;cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_LIST=dnn,python3 ..
make -j4
&lt;/denchmark-code&gt;

then
&lt;denchmark-code&gt;export PYTHONPATH=/path/to/opencv/build/lib/python3/:$PYTHONPATH
export LD_LIBRARY_PATH=/path/to/opencv/build/lib/:$LD_LIBRARY_PATH
&lt;/denchmark-code&gt;

then run the script above.
		</comment>
		<comment id='8' author='Julia702' date='2019-08-16T10:04:34Z'>
		
export ...

Just use ./setup_vars.sh python3 ... from bash after make.
		</comment>
	</comments>
</bug>