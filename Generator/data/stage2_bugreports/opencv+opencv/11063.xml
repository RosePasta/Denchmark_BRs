<bug id='11063' author='tomoaki0705' open_date='2018-03-13T14:18:55Z' closed_time='2018-03-23T13:04:52Z'>
	<summary>cudaarithm: async call to NPP fails</summary>
	<description>
&lt;denchmark-h:h5&gt;System information (version)&lt;/denchmark-h&gt;


OpenCV =&gt; master
Operating System / Platform =&gt; Windows 10 Pro 64bit / CUDA 8.0
Compiler =&gt; Visual Studio 2015 Win64
Operating System / Platform =&gt; Ubuntu 64bit  / Jetson TX1 / CUDA 8.0
Compiler =&gt; GCC 5.4.0

&lt;denchmark-h:h5&gt;Detailed description&lt;/denchmark-h&gt;


test from opencv_test_cudaarithm fails

&lt;denchmark-code&gt;[==========] 10629 tests from 65 test cases ran. (34990 ms total)
[  PASSED  ] 10625 tests.
[  FAILED  ] 4 tests, listed below:
[  FAILED  ] CUDA_Arithm/MeanStdDev.Async/0, where GetParam() = (NVIDIA Tegra X1, 128x128, whole matrix)
[  FAILED  ] CUDA_Arithm/MeanStdDev.Async/1, where GetParam() = (NVIDIA Tegra X1, 128x128, sub matrix)
[  FAILED  ] CUDA_Arithm/MeanStdDev.Async/2, where GetParam() = (NVIDIA Tegra X1, 113x113, whole matrix)
[  FAILED  ] CUDA_Arithm/MeanStdDev.Async/3, where GetParam() = (NVIDIA Tegra X1, 113x113, sub matrix)

 4 FAILED TESTS
&lt;/denchmark-code&gt;


Also confirmed with Jetson TX2, Geforce GTX 650M, Geforce GTX 1060
I cut out the minimum code from OpenCV and then the crash didn't reproduce.
I googled up with the message "Microsoft C++ exception: NppStatus at memory location" which appeared on Visual Studio, and found this post from a nVidia person


It seems that any time you issue a nppSetStream() call that in fact changes the underlying stream, you will need to issue a cudaDeviceSynchronize() call (first), before issuing the nppSetStream() call.


This is exactly what is happening inside OpenCV
I added a macro to call cudaStreamSynchronize before nppSetStream and this solved the issue
References

Same situation still happens on CUDA 8.0
Same explanation on NPP 9.1




For this reason it is recommended that cudaDeviceSynchronize (or at least cudaStreamSynchronize) be called before making an nppSetStream call to change to a new stream ID. This will insure that any internal function calls that have not yet occurred will be completed using the current stream ID before it changes to a new ID.



cudaStreamSynchronize


I'll send a PR later


&lt;denchmark-h:h5&gt;Steps to reproduce&lt;/denchmark-h&gt;


run opencv_test_cudaarithm --gtest_filter=*MeanStdDev*Async*

	</description>
	<comments>
		<comment id='1' author='tomoaki0705' date='2018-03-14T04:24:48Z'>
		I was also looking into this issue. In my case, using cudaStreamSynchronize nor cudaDeviceSynchronize solved the issue.
My testing environment is:

Operating System / Platform =&gt; Windows 10 Pro 64bit / CUDA 8.0, 9.1
Compiler =&gt; Visual Studio 2015
GPU =&gt; GTX1080 with driver version 388.19

The error message on my machine is:
&lt;denchmark-code&gt;unknown file: error: C++ exception with description "OpenCV(3.4.1-dev) C:\Users\lee.namgoo\Repos\opencv_dev\opencv\modules\cudaarithm\src\reductions.cpp:162: error: (-217) Gpu API call: NPP_RANGE_ERROR [Code = -7] in function cv::cuda::meanStdDev" thrown in the test body.
&lt;/denchmark-code&gt;

The error message is identical before and after adding the synchronizing API.
		</comment>
		<comment id='2' author='tomoaki0705' date='2018-03-14T09:40:34Z'>
		Thank you &lt;denchmark-link:https://github.com/nglee&gt;@nglee&lt;/denchmark-link&gt;
 , indeed, this issue still happens on my environment, too.
It passed once, and that made me believe that this fix works, but it's run time error happening inside, once was not enough.
Your feedback was very useful.  It encouraged me that I'm not the only one facing this issue.
I think I need to throw this issue to nvidia forum, and ask for feedback.
		</comment>
		<comment id='3' author='tomoaki0705' date='2018-03-15T01:45:26Z'>
		Thank you &lt;denchmark-link:https://github.com/tomoaki0705&gt;@tomoaki0705&lt;/denchmark-link&gt;
 for your comment.
In my case, after commenting out &lt;denchmark-link:https://github.com/opencv/opencv/blob/d68466bb6a855efd3b7540740bb89ea43be1aef4/modules/cudaarithm/src/reductions.cpp#L160&gt;this line&lt;/denchmark-link&gt;
, the  tests did not fail.
Could this be an indication that there's an internal issue in NPP?
About two weeks ago, I've opened a &lt;denchmark-link:https://devtalk.nvidia.com/default/topic/1030559/gpu-accelerated-libraries/using-nppimean_stddev_8u_c1r-after-setnppstream-returns-npp_range_error/&gt;topic&lt;/denchmark-link&gt;
 at nvidia forum, and someone else opend a &lt;denchmark-link:https://devtalk.nvidia.com/default/topic/1030832/gpu-accelerated-libraries/nppicountinrange-returns-npp_range_error-when-called-from-multiple-threads-cuda-9-1-/&gt;similar topic&lt;/denchmark-link&gt;
 recently. Both topic reports some NPP APIs returning  when  is used, and both reports that the error is gone when  is removed.
		</comment>
		<comment id='4' author='tomoaki0705' date='2018-03-15T09:51:16Z'>
		Thank you &lt;denchmark-link:https://github.com/nglee&gt;@nglee&lt;/denchmark-link&gt;
, following your suggestion, things are now moving forward.
Thank you for the report to nvidia !
Now, the situation is getting complicated.
&lt;denchmark-link:https://github.com/opencv/opencv/blob/d68466bb6a855efd3b7540740bb89ea43be1aef4/modules/cudaarithm/src/reductions.cpp#L160&gt;The line &lt;/denchmark-link&gt;
 that &lt;denchmark-link:https://github.com/nglee&gt;@nglee&lt;/denchmark-link&gt;
 pointed is calling .
Removing this call, it works but we have a  which is created but never passed to driver.
At the end function,  &lt;denchmark-link:https://github.com/opencv/opencv/blob/d68466bb6a855efd3b7540740bb89ea43be1aef4/modules/cudaarithm/src/reductions.cpp#L164&gt;there is syncOutput &lt;/denchmark-link&gt;
 which is passing a stream which never actually passed to driver to wait.
I'm bit afraid that there might be a data corruption at the end.
Still, getting back to the original goal "execute a npp function asynchronously" may be it's no problem to keep using default stream (=0), or may be removing nppSetStream is the correct way.
I just need more time to investigate
		</comment>
	</comments>
</bug>