<bug id='4595' author='opencv-pushbot' open_date='2015-07-27T09:48:41Z' closed_time='2016-10-13T14:27:37Z'>
	<summary>bug, race conditions in updateTrainingSet/fillPassedSamples/NegReader::get</summary>
	<description>
Transferred from &lt;denchmark-link:http://code.opencv.org/issues/3147&gt;http://code.opencv.org/issues/3147&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;|| Alex Leverington on 2013-07-09 18:19
|| Priority: Normal
|| Affected: 2.4.6 (latest release)
|| Category: objdetect
|| Tracker: Bug
|| Difficulty: Hard
|| PR: 
|| Platform: Any / Any
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;bug, race conditions in updateTrainingSet/fillPassedSamples/NegReader::get&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;There is a common (and major) symptom which is caused by the issues discussed below. Basically, the issues below causes the training process to take an excessive amount of time. The current strategy I've seen from SO posts and such is "well, training takes a long time, so just let it run for a week".

However after using the cascade trainer a lot, I've found there are indeed bugs, and I've found fixes for them!

I've described the issues in more (excruciating) detail below, but let's look at the math. Based on my analysis of the code surrounding these bugs, my changes are based on the math/logic below. I've personally validated that the training now runs much faster (read: O(1) time as compared to previous O(currStage*nStages*0.5)) and works properly.


Below is psuedo code of the workflow for train() and updateTrainingSet(). Is this accurate with regard to acceptanceRatio, requiredLeafRate, and reaching target FA rate?


requiredLeafRate = pow(maxFA, numStages) / maxDepth

updateTrainingSet(&amp;acceptanceRatio)
   posCount = fillPassedSamples(&amp;posConsumed) // fills from 0 .. numPos + rejectPosCount (until out of pos; if out, training fails)
   negCount = fillPassedSamples(&amp;negConsumed) // cycles through tiling/scaling every image in -bg parameter

   _curNumSamples = posCount + negCount;
   acceptanceRatio = negConsumed == 0 ? 0 : ( (double)negCount/(double)(int64)negConsumed );
   return

if acceptanceRatio &lt;= requiredLeafRate
  done: "Required leaf false alarm rate achieved."






Bug #1: infinite loop occurs if a given stage reaches a 0 FA rate (such as when no negatives are detected as FAs)
To reproduce
1) create positive image sample set with clear and consistent features
2) create negative image samples which contain no features (gradients/gauss blur will do this)
3) negative images have same size as positive images
4) negative images are square

The result of these conditions is that fillPassedSamples will endlessly loop pulling background images (until "rounds" integer overflows).


#2: if trained classifier cannot detect a given positive image, and there are no extra image within vector, training fails
To reproduce:
Creating some poor/blurred positives would yield this result. Although this can easily be discerned by reading current fillPassedSamples method. Quite simply, if there are 100 positive samples in a vector, numPos=100, and one of the positive images isn't detected within predix() of fillPassedSamples, the training will end with an error that there are no more images in the vector file.

Question:
How should this function?

It's quite possible that stage 1 could eliminate 75% of positives but then all remaining stages detect every positive. Moreover, as long as there at at least n=(positive - eliminated) "extra" negative images, there will still be enough samples for adaboost.

So there are two options. Either 1, recommend to users they provide a vector file which has numPos*numStages*0.5 samples. Or, option 2, allow positive image reader to return false if it reads all images and have fillPassedSamples determine whether there are not enough images. In the latter case

In either case, documentation or logic should be updated to correct this issue.


#3: (related to #1) If number of negative FA &lt; numNeg, fillPassedSamples will perform excessive FA detections.
This is really a math issue. So, either the "supporting" code around the current logic is flawed, or the current logic is flawed. (math is above)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;History&lt;/denchmark-h&gt;

&lt;denchmark-h:h5&gt;Nikita Manovich on 2013-07-11 12:36&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Alex,

Thank you for the bug report with a lot of details. If you have a fix for the problem please prepare a pull request. It will help us significantly. We will be glad to accept your contribution. On the page http://www.code.opencv.org/projects/opencv/wiki/How_to_contribute you will find information how to do that.
-   Description changed from There is a common (and major) symptom which
    is caused by the issues discusse... to There is a common (and major)
    symptom which is caused by the issues discussed... More
-   Assignee set to Alex Leverington
-   Status changed from New to Open
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='opencv-pushbot' date='2016-10-13T14:19:14Z'>
		&lt;denchmark-link:https://github.com/alalek&gt;@alalek&lt;/denchmark-link&gt;
 version 2.4.6 here. Again suggest to close down until actually something like this re-emerges.
		</comment>
	</comments>
</bug>