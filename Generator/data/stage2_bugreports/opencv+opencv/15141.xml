<bug id='15141' author='sangjoonhong' open_date='2019-07-25T05:23:35Z' closed_time='2019-08-26T12:55:51Z'>
	<summary>DNN, Keras model included Flatten() problem.</summary>
	<description>

OpenCV =&gt; 4.1.0
Operating System / Platform =&gt; Ubuntu 16.04

Hello,
I have a problem using dnn module.
I made binary classification model using Keras.
I used pre-trained mobilenet v2 (imagenet)
And this is part of my code:
&lt;denchmark-code&gt;conv_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))
model = models.Sequential()
model.add(conv_base) # mobilenetv2
model.add(layers.Reshape([3 * 3 * 1280])) # Flatten() -&gt; Reshape()
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(1, activation='sigmoid'))
&lt;/denchmark-code&gt;

Of course, Error is occur
OpenCV(4.1.0) C:\projects\opencv-python\opencv\modules\dnn\src\dnn.cpp:524: error: (-2:Unspecified error) Can't create layer "strided_slice" of type "StridedSlice" in function 'cv::dnn::dnn4_v20190122::LayerData::getLayerInstance'
I found many questions about same problem.
But, change the 'Flatten()' to 'Reshape()' is not working solution.
I changed but, same error is still occur.
I saw reshape is only working in Keras version 2.0.8
But I can't using that version because using pretrained mobilenetv2.
It is not exist in Keras version 2.0.8
Is there any other solution about this problem?
Thank you.
	</description>
	<comments>
		<comment id='1' author='sangjoonhong' date='2019-07-25T05:44:12Z'>
		Pleas follow issues template and make it easier to reproduce.
		</comment>
		<comment id='2' author='sangjoonhong' date='2019-07-28T19:22:57Z'>
		&lt;denchmark-link:https://answers.opencv.org/question/183682/opencv-dnn-import-dropout-layer-error-after-finetuning-keras-vgg16/&gt;https://answers.opencv.org/question/183682/opencv-dnn-import-dropout-layer-error-after-finetuning-keras-vgg16/&lt;/denchmark-link&gt;

I found similar question and answer.
But I don't know how apply to my problem.
My graph's nodes are little different from that article.
		</comment>
		<comment id='3' author='sangjoonhong' date='2019-07-28T19:34:06Z'>
		&lt;denchmark-link:https://github.com/sangjoonhong&gt;@sangjoonhong&lt;/denchmark-link&gt;
, Please provide at least a  model.
		</comment>
		<comment id='4' author='sangjoonhong' date='2019-07-29T00:34:29Z'>
		&lt;denchmark-link:https://drive.google.com/open?id=1qdkFFbL5WiA--o4o90oln-XnjhGSBX6n&gt;https://drive.google.com/open?id=1qdkFFbL5WiA--o4o90oln-XnjhGSBX6n&lt;/denchmark-link&gt;

This is my .pb model.
		</comment>
		<comment id='5' author='sangjoonhong' date='2019-08-07T02:49:56Z'>
		Is there any updates? :)
		</comment>
		<comment id='6' author='sangjoonhong' date='2019-08-24T20:17:04Z'>
		&lt;denchmark-link:https://github.com/sangjoonhong&gt;@sangjoonhong&lt;/denchmark-link&gt;
, Thanks for report! Please try the changes from &lt;denchmark-link:https://github.com/opencv/opencv/pull/15391&gt;#15391&lt;/denchmark-link&gt;
 (with Reshape model for now)
test code:
import tensorflow as tf
import cv2 as cv
import numpy as np

model = 'normal_and_abnormal_mnet_v2_96_96_Reshape.pb'

np.random.seed(324)
inp = np.random.uniform(0.0, 1.0, [1, 96, 96, 3]).astype(np.float32)

with tf.gfile.FastGFile(model, 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Session() as sess:
    sess.graph.as_default()
    tf.import_graph_def(graph_def, name='')

    tfOut = sess.run(sess.graph.get_tensor_by_name('dense_2/Sigmoid:0'),
                     feed_dict={'mobilenetv2_1.00_96_input:0': inp})

net = cv.dnn.readNet(model)
net.setInput(inp.transpose(0, 3, 1, 2))  # NHWC to NCHW
cvOut = net.forward()
print cvOut
print tfOut
print np.max(np.abs(cvOut - tfOut))
output:
&lt;denchmark-code&gt;[[ 0.64483404]]
[[ 0.6448338]]
2.38419e-07
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='sangjoonhong' date='2019-08-27T06:17:21Z'>
		&lt;denchmark-link:https://github.com/dkurt&gt;@dkurt&lt;/denchmark-link&gt;
 Thank you very much :)
		</comment>
	</comments>
</bug>