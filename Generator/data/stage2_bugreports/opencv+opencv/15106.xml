<bug id='15106' author='lubagov' open_date='2019-07-20T18:57:03Z' closed_time='2019-07-25T19:14:52Z'>
	<summary>Strange output size in last convolution DNN face detector</summary>
	<description>
in this commit, &lt;denchmark-link:https://github.com/opencv/opencv/commit/03850008b9901ebe177b8f12efc47657ceab4fc4&gt;0385000&lt;/denchmark-link&gt;
 by some reason, was changed padding in last convolution. After this, convolutions, conv8_2_h, conv9_2_h has output blob size 5x5. But, last detection levels should be 3x3 and 1x1, like in original SSD. When it detect big face 100 pixels side or more, i get strange effect:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61582874-fc3ec080-ab38-11e9-8e79-c2d4d1194e93.png&gt;&lt;/denchmark-link&gt;

When i remove this padding, and set to 0, it fine working:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61582875-fc3ec080-ab38-11e9-952d-f7b4224c4c04.png&gt;&lt;/denchmark-link&gt;

for what, was this commit made?
	</description>
	<comments>
		<comment id='1' author='lubagov' date='2019-07-20T19:54:20Z'>
		
Can you compare the model with and without padding with the same image (current issue description shows two different images)
There is a description of corresponding PR so you can understand the motivation: #10216

		</comment>
		<comment id='2' author='lubagov' date='2019-07-20T20:40:56Z'>
		I can see this description, but it is strange description.
Really, each level SSD should detect higher size image, if add this padding all 3 blocks dtect image with 300/5=60 pixels (for 300x300 input), because blob output size:
layer:  conv6_1_h shape: (1, 128, 19, 19)
layer:  conv6_2_h shape: (1, 256, 10, 10)
layer:  conv7_1_h shape: (1, 64, 10, 10)
layer:  conv7_2_h shape: (1, 128, 5, 5)
layer:  conv8_1_h shape: (1, 64, 5, 5)
layer:  conv8_2_h shape: (1, 128, 5, 5)
layer:  conv9_1_h shape: (1, 64, 5, 5)
layer:  conv9_2_h shape: (1, 128, 5, 5)
after i remove this padding back, shape sizes is:
layer:  conv7_1_h shape: (1, 64, 10, 10)
layer:  conv7_2_h shape: (1, 128, 5, 5)
layer:  conv8_1_h shape: (1, 64, 5, 5)
layer:  conv8_2_h shape: (1, 128, 3, 3)
layer:  conv9_1_h shape: (1, 64, 3, 3)
layer:  conv9_2_h shape: (1, 128, 1, 1)
Next image, received from Caffe samples, without OpenCV:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61583922-c8b76280-ab47-11e9-90da-67e8f697dc8e.jpg&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61583926-ce14ad00-ab47-11e9-897f-c991136153da.jpg&gt;&lt;/denchmark-link&gt;

Maybe i don't understand something?
		</comment>
		<comment id='3' author='lubagov' date='2019-07-20T20:49:29Z'>
		Can you please add an origin image without bounding boxes to reproduce the problem? Am I right that 300x300 input blob resolution is used?
		</comment>
		<comment id='4' author='lubagov' date='2019-07-20T20:50:57Z'>
		Any image, it is not matter. Yes, 300 pixels, and face should be more then 60 pixels side.
It is because, 8, 9 convolutions not working here. But yes, if input size less, 300x300, we should remove 8 and 9 level at all, and set padding to 1 in level 7. Other ways we not het 1x1 blob in last level.  But it is anomal.
		</comment>
		<comment id='5' author='lubagov' date='2019-07-20T20:59:26Z'>
		Cannot reproduce with the following image (face size: 102x191):
&lt;denchmark-link:https://user-images.githubusercontent.com/25801568/61584057-509e6c00-ab4a-11e9-882f-dc0c677f0f15.jpg&gt;&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://user-images.githubusercontent.com/25801568/61584063-5e53f180-ab4a-11e9-939c-2c08e5a1609e.jpg&gt;&lt;/denchmark-link&gt;

command:
&lt;denchmark-code&gt;python3 ~/opencv/samples/dnn/object_detection.py opencv_fd --input face_sample.jpg --backend 3
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='lubagov' date='2019-07-20T21:03:04Z'>
		102x191 it is not 300x300, in any case we should use only 300x300 blob size only. Otherways we should change network structure. Add advanced detection levels, at end of SSD network to incrase resolution, or remove part levels to decease. Because, we will get false positive detection with big face and not able to detect big faces, or blob less then 1x1!, if it is less 300px.
		</comment>
		<comment id='7' author='lubagov' date='2019-07-20T21:26:00Z'>
		python3 object_detection.py --input tstimg1.jpg --backend 3 --model ./face_detector/res10_300x300_ssd_iter_140000_fp16.caffemodel --config ./face_detector/deploy.prototxt
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61584351-d1f7fd80-ab4e-11e9-84c9-bc478caaf28f.jpg&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61584303-0cad6600-ab4e-11e9-9999-7716c503dbf1.jpg&gt;&lt;/denchmark-link&gt;

Original image:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61584288-c8ba6100-ab4d-11e9-9ba4-6292ca82cac4.jpg&gt;&lt;/denchmark-link&gt;

Fixed prototxt:
&lt;denchmark-link:https://github.com/opencv/opencv/files/3414007/deploy1.prototxt.txt&gt;deploy1.prototxt.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='lubagov' date='2019-07-20T21:57:40Z'>
		and yes i am sorry:
conv8_2_mbox_priorbox:
min_size: 213.0
max_size: 264.0
conv9_2_mbox_priorbox:
min_size: 264.0
max_size: 315.0
so, face should fit in this size to get effect.
		</comment>
		<comment id='9' author='lubagov' date='2019-07-21T16:57:44Z'>
		Can reproduce it now, thanks!
		</comment>
		<comment id='10' author='lubagov' date='2019-07-22T06:59:51Z'>
		&lt;denchmark-link:https://github.com/lubagov&gt;@lubagov&lt;/denchmark-link&gt;
, Need you help to resolve this issue.
With stride: 2 I could achieve both bug elimination and opportunity to run the model on lower resolution. Can you please check it on your data?
layer {
  name: "conv8_2_h"
  type: "Convolution"
  bottom: "conv8_1_h"
  top: "conv8_2_h"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
// ...
layer {
  name: "conv9_2_h"
  type: "Convolution"
  bottom: "conv9_1_h"
  top: "conv9_2_h"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
Open question is if we need to apply it to both convolutions of just to first one.
		</comment>
		<comment id='11' author='lubagov' date='2019-07-22T08:57:19Z'>
		Tested with FDDB dataset and &lt;denchmark-link:https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py&gt;https://github.com/opencv/opencv/blob/master/modules/dnn/misc/face_detector_accuracy.py&lt;/denchmark-link&gt;
:
origin network:
&lt;denchmark-code&gt; Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.408
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.251
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528
&lt;/denchmark-code&gt;

conv8_2_h with pad: 1 and stride: 2:
&lt;denchmark-code&gt; Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.885
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
&lt;/denchmark-code&gt;

conv8_2_h and conv9_2_h with pad: 1 and stride: 2:
&lt;denchmark-code&gt; Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.889
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.260
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.306
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='lubagov' date='2019-07-22T09:23:32Z'>
		&lt;denchmark-link:https://github.com/lubagov&gt;@lubagov&lt;/denchmark-link&gt;
, please check the changes from &lt;denchmark-link:https://github.com/opencv/opencv/pull/15118&gt;#15118&lt;/denchmark-link&gt;
. I've choosen the version with two  due it gives higher mAP.
		</comment>
		<comment id='13' author='lubagov' date='2019-07-22T16:28:41Z'>
		Look, if we make conv8_2_h and conv9_2_h with pad: 1 and stride: 2, then, convolution output will be:
layer:  conv6_1_h shape: (1, 128, 19, 19)
layer:  conv6_2_h shape: (1, 256, 10, 10)
layer:  conv7_1_h shape: (1, 64, 10, 10)
layer:  conv7_2_h shape: (1, 128, 5, 5)
layer:  conv8_1_h shape: (1, 64, 5, 5)
layer:  conv8_2_h shape: (1, 128, 3, 3)
layer:  conv9_1_h shape: (1, 64, 3, 3)
layer:  conv9_2_h shape: (1, 128, 2, 2)
And conv_9 is not working, right. And I notice that he does not find my face in the camera when the face is more than 300 pixels in height (min_size: 264.0 max_size: 315.0), i.e. when a face fragment is placed in an image.
Maybe has scene use conv8_2_h pad: 1 and stride: 2 and conv9_2_h with pad: 0 and stride: 2.
when we get normal blob sizes:
layer:  conv6_1_h shape: (1, 128, 19, 19)
layer:  conv6_2_h shape: (1, 256, 10, 10)
layer:  conv7_1_h shape: (1, 64, 10, 10)
layer:  conv7_2_h shape: (1, 128, 5, 5)
layer:  conv8_1_h shape: (1, 64, 5, 5)
layer:  conv8_2_h shape: (1, 128, 3, 3)
layer:  conv9_1_h shape: (1, 64, 3, 3)
layer:  conv9_2_h shape: (1, 128, 1, 1)
but when my face, look marked less boxing than it should:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61647555-3f726e00-acb6-11e9-9b6b-4fda51f1cfe6.png&gt;&lt;/denchmark-link&gt;

And yet, the ideal output, I have when we are not playing with the pad / stride and leave them as in the original network, from weiliu89.
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61647662-819baf80-acb6-11e9-8cd7-daa989c1c17e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='lubagov' date='2019-07-22T17:02:42Z'>
		red box, is ,  both convolution, blue box ,  on both:
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61649305-e7d60180-acb9-11e9-9d3a-5750f1bc1bdf.png&gt;&lt;/denchmark-link&gt;

red box, is ,  both convolution, blue box ,  on :
&lt;denchmark-link:https://user-images.githubusercontent.com/6134203/61650055-78f9a800-acbb-11e9-9bd8-7656abecaede.png&gt;&lt;/denchmark-link&gt;

Although in general I am not proficient in this, I am still trying. My goal now is to expand the network in order to find faces from any distance, with a higher resolution of the photo 1200x1200 example.
		</comment>
		<comment id='15' author='lubagov' date='2019-07-23T10:16:34Z'>
		&lt;denchmark-link:https://github.com/lubagov&gt;@lubagov&lt;/denchmark-link&gt;
, I experimented with the following configuration:
conv8_2_h and conv9_2_h have pad: 1 and stride: 1
But conv8_2_mbox_priorbox now with step: 64 instead of step: 100
and conv9_2_mbox_priorbox with step: 64 instead of step: 300
&lt;denchmark-code&gt; Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.890
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.476
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.305
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.481
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.189
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.527
&lt;/denchmark-code&gt;

May I kindly ask you to check it with your experiment?
&lt;denchmark-link:https://github.com/opencv/opencv/files/3421489/deploy.txt&gt;deploy.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='lubagov' date='2019-07-25T08:21:05Z'>
		&lt;denchmark-link:https://github.com/lubagov&gt;@lubagov&lt;/denchmark-link&gt;
, Thank you so much for close collaboration and pointing this bug. I've replaced paddings back to zeros (see &lt;denchmark-link:https://github.com/opencv/opencv/pull/15118&gt;#15118&lt;/denchmark-link&gt;
). For scenarios where we want to use lower resolution than 300x300 (like out JavaScript demo) added  with truncated SSD head.
		</comment>
		<comment id='17' author='lubagov' date='2019-07-27T09:34:24Z'>
		Please check, train.prototxt file also. Because it also has wrong padding, and wrong train network.
		</comment>
	</comments>
</bug>