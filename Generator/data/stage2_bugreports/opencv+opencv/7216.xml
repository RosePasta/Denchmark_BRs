<bug id='7216' author='nlgranger' open_date='2016-09-01T17:26:47Z' closed_time='2020-08-09T16:54:34Z'>
	<summary>(python) opencv and theano conflict</summary>
	<description>
When importing theano (a machine learning library that uses gpu for computation), opencv crashes in warpAffine:
import numpy as np
import cv2
import theano


def _rotate(img, pose):
    center = np.mean(pose, axis=0, dtype=int)
    angle = np.random.rand() * 20 - 10
    r = cv2.getRotationMatrix2D(tuple(center), angle, 1.0)
    print("tadaaaa")
    img = cv2.warpAffine(img, r, (img.shape[1], img.shape[0]))
    print("not tadaaa")
    pose = np.dot((pose - center[None, :]), np.transpose(r[:, :2])) + center
    return img, pose


def main():
    img = cv2.imread("picture.jpg")
    pose = np.array([[450, 250],
                     [350, 250],
                     [400, 350]])
    img2, pose2 = _rotate(img, pose)

    cv2.drawMarker(img, (int(pose[0, 0]), int(pose[0, 1])), (0, 0, 255))
    cv2.drawMarker(img, (int(pose[1, 0]), int(pose[1, 1])), (0, 0, 255))
    cv2.drawMarker(img2, (int(pose2[0, 0]), int(pose2[0, 1])), (0, 0, 255))
    cv2.drawMarker(img2, (int(pose2[1, 0]), int(pose2[1, 1])), (0, 0, 255))
    cv2.namedWindow('preview')
    cv2.imshow('preview', img)
    cv2.waitKey()
    cv2.imshow('preview', img2)
    cv2.waitKey()
    cv2.destroyAllWindows()


main()
&lt;denchmark-code&gt;python test.py
Using gpu device 0: GeForce GTX 980 Ti (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5005)
tadaaaa
zsh: segmentation fault (core dumped)  python test.py
&lt;/denchmark-code&gt;

I have OpenCV 3.1.0 (build script &lt;denchmark-link:https://git.archlinux.org/svntogit/packages.git/tree/trunk/PKGBUILD?h=packages/opencv&gt;here&lt;/denchmark-link&gt;
). I have strictly no idea how to debug this, but I can run some tests for you if tell me how.
	</description>
	<comments>
		<comment id='1' author='nlgranger' date='2016-09-02T06:42:21Z'>
		Possibly related bug: &lt;denchmark-link:https://github.com/Theano/Theano/issues/4740&gt;Theano/Theano#4740&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='nlgranger' date='2016-09-22T13:07:04Z'>
		I am experiencing exactly the same problem with OpenCV 3.1.0 and also 3.0.0. Code works fine on CPU, but fails when I send it to GPU. My debugging attempts so far included compiling OpenCV with the 'WITH_CUDA' option set to 'OFF', and changing the order in which the modules are loaded. Both didn't work.
Interestingly, I ran a sample script similar to the one above on a number of machines with identical GPUs, virtualenvs and cuda libraries and I could only reproduce the problem on one of them. However, I couldn't figure out where the setup differs.
The GPU model I am using is the Geforce GTX 1080 with CUDA version 8.0.27 and theano version  0.9.0dev2.dev-RELEASE.
		</comment>
		<comment id='3' author='nlgranger' date='2019-10-03T01:34:02Z'>
		I am also having a similar problem with cv2 using Keras-Tensorflow on a GPU. I used cv2 for face detection to crop the input image to only include the face. Then I feed the cropped image into a trained Keras classification model but get the error:
Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,
Have found no solution to date.
		</comment>
		<comment id='4' author='nlgranger' date='2020-08-09T16:54:34Z'>
		Theano is no longer developped, closing.
		</comment>
	</comments>
</bug>