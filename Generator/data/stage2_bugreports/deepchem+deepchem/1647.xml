<bug id='1647' author='sfrench007' open_date='2019-07-26T21:19:30Z' closed_time='2020-03-07T17:02:35Z'>
	<summary>Model Interpretability tutorial with Tox21 dataset seems like it has a broken Lime explainer</summary>
	<description>
Description:
Model Interpretability tutorial with Tox21 dataset seems like it has a broken Lime explainer

DeepChem Version: 2.1.1
Platform: Linux (conda)

The eval_model function returns an error when run with the LimeTabularExplainer.  Below is the code from the tutorial, but it returns these errors when running the explainer (ipython):
In [5]: # this returns an Lime Explainer class
...: # The explainer contains details for why the model behaved the way it di
...: d
...: exp = explainer.explain_instance(test_dataset.X[active_id], model_fn, nu
...: m_features=5, top_labels=1)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

ValueError                                Traceback (most recent call last)
 in ()
1 # this returns an Lime Explainer class
2 # The explainer contains details for why the model behaved the way it did
----&gt; 3 exp = explainer.explain_instance(test_dataset.X[active_id], model_fn, num_features=5, top_labels=1)
~/anaconda3/envs/deepchem/lib/python3.5/site-packages/lime/lime_tabular.py in explain_instance(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)
350         ).ravel()
351
--&gt; 352         yss = predict_fn(inverse)
353
354         # for classification, the model needs to provide a list of tuples - classes
 in eval_closure(x)
4         ds = dc.data.NumpyDataset(x, None, None, None)
5         # The 0th task is NR-AR
----&gt; 6         predictions = model.predict(ds)[:,0]
7         return predictions
8     return eval_closure
~/anaconda3/envs/deepchem/lib/python3.5/site-packages/deepchem/models/keras_model.py in predict(self, dataset, transformers, outputs)
674     generator = self.default_generator(
675         dataset, mode='predict', pad_batches=False)
--&gt; 676     return self.predict_on_generator(generator, transformers, outputs)
677
678   def predict_uncertainty(self, dataset, masks=50):
~/anaconda3/envs/deepchem/lib/python3.5/site-packages/deepchem/models/keras_model.py in predict_on_generator(self, generator, transformers, outputs)
597       if it produces multiple outputs
598     """
--&gt; 599     return self._predict(generator, transformers, outputs, False)
600
601   def predict_on_batch(self, X, transformers=[], outputs=None):
~/anaconda3/envs/deepchem/lib/python3.5/site-packages/deepchem/models/keras_model.py in _predict(self, generator, transformers, outputs, uncertainty)
507     if isinstance(outputs, tf.Tensor):
508       outputs = [outputs]
--&gt; 509     for batch in generator:
510       inputs, labels, weights = batch
511       self._create_inputs(inputs)
~/anaconda3/envs/deepchem/lib/python3.5/site-packages/deepchem/models/tensorgraph/fcnet.py in default_generator(self, dataset, epochs, mode, deterministic, pad_batches)
139         if y_b is not None:
140           y_b = to_one_hot(y_b.flatten(), self.n_classes).reshape(
--&gt; 141               -1, self.n_tasks, self.n_classes)
142         yield ([X_b], [y_b], [w_b])
143
ValueError: cannot reshape array of size 200 into shape (12,2)
&lt;denchmark-code&gt;# Imaging imports to get pictures in the notebook
from rdkit import Chem
from rdkit.Chem.Draw import IPythonConsole
from IPython.display import SVG
from rdkit.Chem import rdDepictor
from rdkit.Chem.Draw import rdMolDraw2D


import numpy as np
import deepchem as dc
from deepchem.molnet import load_tox21

# Only for debug!
np.random.seed(123)

# Load Tox21 dataset
n_features = 1024
tox21_tasks, tox21_datasets, transformers = load_tox21()
train_dataset, valid_dataset, test_dataset = tox21_datasets

# Fit models
metric = dc.metrics.Metric(
    dc.metrics.roc_auc_score, np.mean, mode="classification")

nb_epoch = 10
model = dc.models.tensorgraph.fcnet.MultitaskClassifier(
    len(tox21_tasks),
    train_dataset.get_data_shape()[0])

# Fit trained model
model.fit(train_dataset, nb_epoch=nb_epoch)
#model.save('test.h5')

train_scores = model.evaluate(train_dataset, [metric], transformers)
valid_scores = model.evaluate(valid_dataset, [metric], transformers)

from lime import lime_tabular
feature_names = ["fp_%s"  % x for x in range(1024)]
explainer = lime_tabular.LimeTabularExplainer(train_dataset.X,
                                              feature_names=feature_names,
                                              categorical_features=feature_names,
                                              class_names=['not toxic', 'toxic'],
                                              discretize_continuous=True)

# We need a function which takes a 2d numpy array (samples, features) and returns predictions (samples,)
def eval_model(my_model, transformers):
    def eval_closure(x):
        ds = dc.data.NumpyDataset(x, None, None, None)
        # The 0th task is NR-AR
        predictions = model.predict(ds)[:,0]
        return predictions
    return eval_closure
model_fn = eval_model(model, transformers)

# We want to investigate a toxic compound
active_id = np.where(test_dataset.y[:,0]==1)[0][0]

# this returns an Lime Explainer class
# The explainer contains details for why the model behaved the way it did
exp = explainer.explain_instance(test_dataset.X[active_id], model_fn, num_features=5, top_labels=0)

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='sfrench007' date='2019-07-29T10:50:22Z'>
		The error was actually in def eval_model(my_model, transformers). New definition below:
&lt;denchmark-code&gt;def eval_model(my_model, transformers):
    def eval_closure(x):
        ds = dc.data.NumpyDataset(x, None, None, None, n_tasks=len(tox21_tasks))
        # The 0th task is NR-AR
        predictions = model.predict(ds)[:,0]
        return predictions
    return eval_closure
&lt;/denchmark-code&gt;

Also, did you write this code yourself or was it taken from a DeepChem tutorial somewhere? - Just asking because the bug should be fixed if it is inside a DeepChem tutorial. Otherwise, dc.data.NumpyDataset creates an array of zeros if y is None. If n_tasks(default 1) is not correctly specified, the array shapes are wrong, which was the error.
		</comment>
		<comment id='2' author='sfrench007' date='2019-07-29T16:23:13Z'>
		Hi @VIGS25, thanks for the reply.  This is directly from the tutorial at &lt;denchmark-link:https://github.com/deepchem/deepchem/blob/master/examples/notebooks/Explaining_Tox21.ipynb&gt;https://github.com/deepchem/deepchem/blob/master/examples/notebooks/Explaining_Tox21.ipynb&lt;/denchmark-link&gt;

Your reply makes sense - I was wondering why the reshaping was erroring out.  Thanks so much again for your help here.
		</comment>
		<comment id='3' author='sfrench007' date='2019-08-01T18:02:38Z'>
		Can you close this issue?
		</comment>
		<comment id='4' author='sfrench007' date='2019-08-10T23:22:12Z'>
		The code in the Tutorial Part 5: Model Interpretability, [12] , still has this bug. &lt;denchmark-link:https://github.com/rbharath&gt;@rbharath&lt;/denchmark-link&gt;
 could you please fix this with the solution that @VIGS25  mentioned ?
		</comment>
		<comment id='5' author='sfrench007' date='2019-08-13T21:01:33Z'>
		Re-opening the issue and marking as open for a bugfix
		</comment>
		<comment id='6' author='sfrench007' date='2020-03-07T16:12:45Z'>
		Seems fixed in &lt;denchmark-link:https://github.com/deepchem/deepchem/pull/1763&gt;#1763&lt;/denchmark-link&gt;
 
		</comment>
	</comments>
</bug>