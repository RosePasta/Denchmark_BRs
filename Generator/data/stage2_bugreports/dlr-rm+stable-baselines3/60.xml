<bug id='60' author='siferati' open_date='2020-06-15T14:29:35Z' closed_time='2020-08-05T10:12:03Z'>
	<summary>Environment is reset twice per episode when evaluating policy on DummyVecEnv</summary>
	<description>
The evaluate_policy helper function reset the environment at the start of each episode:



stable-baselines3/stable_baselines3/common/evaluation.py


        Lines 33 to 34
      in
      494ebfd






 for _ in range(n_eval_episodes): 



 obs = env.reset() 





But DummyVecEnv automatically resets the environment when step returns done = true:



stable-baselines3/stable_baselines3/common/vec_env/dummy_vec_env.py


        Lines 45 to 48
      in
      494ebfd






 if self.buf_dones[env_idx]: 



 # save final observation where user can get it, then reset 



 self.buf_infos[env_idx]['terminal_observation'] = obs 



 obs = self.envs[env_idx].reset() 





This causes the environment to reset twice per episode when evaluating the policy.
	</description>
	<comments>
		<comment id='1' author='siferati' date='2020-06-15T14:38:16Z'>
		Good catch, indeed it is being reset twice. Looks like a simple solution would be to move the first reset outside the loop in evaluate_policy.
&lt;denchmark-link:https://github.com/araffin&gt;@araffin&lt;/denchmark-link&gt;
 Pinging you to give a comment on this, in case we missed something important.
		</comment>
		<comment id='2' author='siferati' date='2020-06-15T14:44:17Z'>
		&lt;denchmark-link:https://github.com/Miffyli&gt;@Miffyli&lt;/denchmark-link&gt;
 In my opinion, a better fix would be to remove the call to  from DummyVecEnv's  method. It doesn't seem very intuitive that  would automatically reset the environment - the user should be responsible for checking when  themselves and calling  when needed. Also, this results in even the simple examples from Gym also resetting the envs twice per episode. Example taken from &lt;denchmark-link:https://gym.openai.com/&gt;here&lt;/denchmark-link&gt;
:
import gym
from stable_baselines3.common.vec_env import DummyVecEnv

env = DummyVecEnv([lambda: gym.make("CartPole-v1")])
observation = env.reset()
for _ in range(1000):
  action = env.action_space.sample()
  observation, reward, done, info = env.step(action)

  if done[0]:
    observation = env.reset() # double reset, since it was already called by DummyVecEnv step
env.close()
		</comment>
		<comment id='3' author='siferati' date='2020-06-15T14:49:19Z'>
		This would make things more complicated when implementing algorithms and gathering samples from multiple envs, though. You would have to loop over dones, see what were True, specifically reset those envs, update obs and also update any masks/hidden states. By letting step do resets when necessary, this gets abstracted away and simplifies training process/code.
But indeed this leads to more complicated/confusing setup when evaluating and working on single environments. However both sb and sb3 algorithms assume vectorized environments (even in the case of single environment) to simplify the code-base by only covering one of these APIs.
		</comment>
		<comment id='4' author='siferati' date='2020-06-16T12:30:01Z'>
		
Pinging you to give a comment on this, in case we missed something important.

I had that issue for another project. I think a better solution would be to allow deactivating automatic reset but keep it True by default.
And even if we are using a VecEnv, we still need to call reset() the very first time.
Maybe adding a need_reset() method to the VecEnv would solve the issue?
		</comment>
		<comment id='5' author='siferati' date='2020-06-17T08:43:26Z'>
		
I had that issue for another project.

Was it this same evaluation mistake? In that case the error would be fixed by moving the reset outside the loop. I see the point behind adding argument for disabling automatic resets (and then we need the need_reset() function), but I do not see need for adding it if it is not going to be used.
		</comment>
		<comment id='6' author='siferati' date='2020-06-19T08:44:56Z'>
		
In that case the error would be fixed by moving the reset outside the loop.

This does not solve the complete problem (the environment will still be reset twice but at least not after every episode)

I see the point behind adding argument for disabling automatic resets (and then we need the need_reset() function), but I do not see need for adding it if it is not going to be used.

Good point. My main concern is that it is one of the less intuitive behavior that we have (we had several issues asking about where is the reset done).
So, in fact, to solve that issue, we just need the need_reset() method.
(On another project, where I was using teleoperation, I had to define a custom VecEnv that does not auto-reset in order to re-initialize manually the robot before resetting the env.)
		</comment>
		<comment id='7' author='siferati' date='2020-06-19T10:50:30Z'>
		Ok, I agree we at least need the need_reset() function (returns True if at least one environment requires reset?). To help clarifying how VecEnv works, we could add the reset_automatically=True parameter to step function. Seeing the parameter should already tell a little bit about how they work, and I would have enjoyed same feature back when I was confused with the "vectorized environments" :D
		</comment>
		<comment id='8' author='siferati' date='2020-06-22T08:47:59Z'>
		
To help clarifying how VecEnv works, we could add the reset_automatically=True parameter to step function.

I don't like changing the api of step() :/ (which should mimic the gym api) even though I understand your point.
		</comment>
		<comment id='9' author='siferati' date='2020-06-24T14:23:21Z'>
		Ah, right, good point. In that case it can be passed in init. In any case, the documentation should reflect the behaviour as precisely as possible (e.g. what needs to be done if it automatically does not reset). Also what should be the behaviour of reset()? Shall it reset all environments, or only reset the ones that need resetting? The former matches Gym API, but makes little sense, while latter makes things easier but breaks the behaviour. Should it be a new function reset_done_envs() which only resets environments which reached done=True, and then returns observations for all environments. The observations for non-resetted environments are the observations from previous step call.
		</comment>
		<comment id='10' author='siferati' date='2020-06-24T15:04:44Z'>
		
Shall it reset all environments, or only reset the ones that need resetting?

It shall reset all envs, you have the env_method() for something more granular.
We have to keep in mind that this feature will be used in special cases only and the current behavior work in most cases, so I would avoid overcomplicated things.
		</comment>
	</comments>
</bug>