<bug id='131' author='araffin' open_date='2020-07-30T16:00:08Z' closed_time='2020-07-30T18:48:31Z'>
	<summary>[Bug] Optimized Polyak update not equivalent for CnnPolicy</summary>
	<description>
The following code works for MlpPolicy but fail with CNN.
import torch as th

from stable_baselines3 import DQN
from stable_baselines3.common.cmd_util import make_atari_env
from stable_baselines3.common.utils import polyak_update

tau = 0.1

model = DQN('CnnPolicy', make_atari_env('BreakoutNoFrameskip-v4', 1), learning_starts=0,
      target_update_interval=250, verbose=1, seed=0,
      train_freq=100, buffer_size=1000)

model_2 = DQN('CnnPolicy', make_atari_env('BreakoutNoFrameskip-v4', 1), learning_starts=0,
      target_update_interval=250, verbose=1, seed=0,
      train_freq=100, buffer_size=1000)

polyak_update(model.q_net.parameters(), model.q_net_target.parameters(), tau)
with th.no_grad():
    for param, target_param in zip(model_2.q_net.parameters(), model_2.q_net_target.parameters()):
        target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)

for param, target_param in zip(model.q_net_target.parameters(), model_2.q_net_target.parameters()):
    assert th.allclose(param, target_param)
Introduced in &lt;denchmark-link:https://github.com/DLR-RM/stable-baselines3/pull/106&gt;#106&lt;/denchmark-link&gt;

Pinging &lt;denchmark-link:https://github.com/PartiallyTyped&gt;@PartiallyTyped&lt;/denchmark-link&gt;

EDIT: this optimization is maybe not needed anymore, see &lt;denchmark-link:https://github.com/DLR-RM/stable-baselines3/issues/122#issuecomment-666521802&gt;#122 (comment)&lt;/denchmark-link&gt;

	</description>
	<comments>
	</comments>
</bug>