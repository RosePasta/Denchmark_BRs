<bug id='38' author='ekourlit' open_date='2020-06-17T17:13:13Z' closed_time='2020-06-19T06:27:19Z'>
	<summary>DeepHyper on TensorFlow 2 &amp; GPUs</summary>
	<description>
Hi,
I have cloned DH from git and changed the setup.py to point it to TF2.2.0-GPU.
I 'm working on an HPS so I developed my model_run.py which when I test with a command like:
python model_run.py
I get the expected behavior, TF is using my machine GPU(s) to train the model. However, when I run my run() function with DH:
deephyper hps ambs --problem &lt;myProblem&gt; --run &lt;myRun&gt;
TF is not seeing the GPUs:
&lt;denchmark-code&gt;failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
&lt;/denchmark-code&gt;

and the training proceeds on my CPU.
Have you faced any similar issue before? Or DH makes a call to TF that prohibit it to see the GPUs?
Thanks in advance!
Vangelis
	</description>
	<comments>
		<comment id='1' author='ekourlit' date='2020-06-18T07:11:22Z'>
		Hi &lt;denchmark-link:https://github.com/ekourlit&gt;@ekourlit&lt;/denchmark-link&gt;
 ,
I never got into this issue but I have a few ideas about it...
&lt;denchmark-h:h3&gt;First solution&lt;/denchmark-h&gt;

In DeepHyper, we developed the  API (&lt;denchmark-link:https://github.com/deephyper/deephyper/tree/master/deephyper/evaluator&gt;link to code&lt;/denchmark-link&gt;
) to abstract how the work is distributed. By default, the  is used. It is probable that this backend needs a specific argument to recognize local GPUs (&lt;denchmark-link:https://docs.ray.io/en/master/using-ray-with-gpus.html?highlight=GPU&gt;GPU Support with Ray&lt;/denchmark-link&gt;
) and then you would probably need to modify &lt;denchmark-link:https://github.com/deephyper/deephyper/blob/master/deephyper/evaluator/ray_evaluator.py#L14&gt;this line&lt;/denchmark-link&gt;
 to  where  is the number of GPUs.
&lt;denchmark-h:h3&gt;Second solution&lt;/denchmark-h&gt;

Another solution that should directly work if you use DeepHyper on a single machine is ot use the Subprocess evaluator by giving the --evaluator subprocess argument to the command line.
Let me know how it goes and if you find a way to implement this option in a nice manner feel free to create a Pull Request!
		</comment>
		<comment id='2' author='ekourlit' date='2020-06-19T02:09:32Z'>
		Hi &lt;denchmark-link:https://github.com/Deathn0t&gt;@Deathn0t&lt;/denchmark-link&gt;
 ,
thanks for your reply! Your first solution worked well for me and after configuring Ray to see the GPUs I'm able to use use them for training the NNs of my HPS. The machine I'm using though it's quite of a custom setup (3 GPUs which only 2 of them I can use) so I had to correctly set the CUDA_VISIBLE_DEVICES environmental variable too, so unfortunately I don't have a general implementation of it.
I have another Ray question thoug: Could I use its technology to parallelize the HPS on a single machine? For example, if I switch back to the CPU usage, can the different Ray tasks run on the different cores or threads of my CPU in parallel? At the moment, Ray is creating 24 tasks (as many as my CPU threads) but only one is actually running, the rest are IDLE.
		</comment>
		<comment id='3' author='ekourlit' date='2020-06-19T06:27:19Z'>
		Glad to know it worked! In order to keep track of the different issues/questions, I will create a new thread for the Ray question.
		</comment>
	</comments>
</bug>