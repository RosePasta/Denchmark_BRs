<bug id='10' author='feribg' open_date='2019-10-17T20:37:51Z' closed_time='2019-10-23T15:37:56Z'>
	<summary>Very slow transmission speeds</summary>
	<description>
Describe the bug:
Not sure, what the root cause is or how to go about debugging but when running ml-workspace the cells return very slowly. htop shows the python process pinned at a 100 and ZMQ process also appears a lot.  I'm using this command:
&lt;denchmark-code&gt;docker run -d -p 8080:8080 --name "ml-workspace" -v "${PWD}:/workspace" --env AUTHENTICATE_VIA_JUPYTER=")*==&amp;11" --shm-size 512m --restart always mltooling/ml-workspace:latest
&lt;/denchmark-code&gt;

If I switch to using vanilla jupyter lab outside of docker everything is speedy again.
The time for cell execution is still accurate, it's in the order of ms, but the results arrive seconds later and the cell keeps being shown as busy with python process at a 100.
Expected behaviour:
Return values with  the same speed, vanilla jupyter lab does.
	</description>
	<comments>
		<comment id='1' author='feribg' date='2019-10-18T12:23:44Z'>
		&lt;denchmark-link:https://github.com/feribg&gt;@feribg&lt;/denchmark-link&gt;
 Thanks for reporting this issue. In our production deployments of the workspace, we generally do not see any significant delay with cell execution compared to vanilla Jupyter installations. So, I assume that there might be an issue with your Docker daemon, and we would be happy to help you figure this out.
The Docker daemon can have certain compute restrictions depending on the platform you are using it. For example, on Mac, you can configure the resources available to the Docker engine in the advanced section of the Docker preferences:
&lt;denchmark-link:https://user-images.githubusercontent.com/2852129/67093600-568c0380-f1b2-11e9-9f86-a38e08959534.png&gt;&lt;/denchmark-link&gt;

Only 1/2 CPUs or very limited amount of memory can cause certain issues within the workspace. On what platform have you deployed the workspace? Have you checked the compute restrictions of the Docker daemon? There might be also some errors within the container logs: docker logs ml-workspace which might be helpful for figuring this out.
		</comment>
		<comment id='2' author='feribg' date='2019-10-18T16:40:36Z'>
		Hey &lt;denchmark-link:https://github.com/LukasMasuch&gt;@LukasMasuch&lt;/denchmark-link&gt;
 I'm running this on Ubuntu 18.04, so docker has full access to system resources. I also thought shm might an issue and I tried running with shared host shm and it  was the same.
		</comment>
		<comment id='3' author='feribg' date='2019-10-23T15:37:56Z'>
		&lt;denchmark-link:https://github.com/LukasMasuch&gt;@LukasMasuch&lt;/denchmark-link&gt;
 Here's the culprit:
&lt;denchmark-link:https://github.com/jupyter/notebook/issues/3224#issuecomment-382300098&gt;jupyter/notebook#3224 (comment)&lt;/denchmark-link&gt;

VariableInspector extension should be disabled when doing any meaningful data science work. I loaded up a 1gb csv and the whole thing grinds to a halt.
However when I use the nbextensions tab, my settings are not persisted between container restarts?
		</comment>
		<comment id='4' author='feribg' date='2019-10-23T16:02:51Z'>
		&lt;denchmark-link:https://github.com/feribg&gt;@feribg&lt;/denchmark-link&gt;
 Thanks for figuring this out! I will disable the Variable Inspector for the next workspace version.
However when I use the nbextensions tab, my settings are not persisted between container restarts?
If the CONFIG_BACKUP_ENABLED is true (default), certain user settings, including the which extensions are activated, should be backuped to the /workspace and restored if the workspace is restarted. However, the backup is run via a cron-job every hour and doesn't cover all user settings.
		</comment>
	</comments>
</bug>