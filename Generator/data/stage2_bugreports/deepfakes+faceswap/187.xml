<bug id='187' author='Clorr' open_date='2018-02-12T17:47:20Z' closed_time='2018-03-01T11:23:47Z'>
	<summary>Landmarks not matching with CNN/MMOD detector</summary>
	<description>
From: &lt;denchmark-link:https://github.com/deepfakes/faceswap-playground/issues/43&gt;deepfakes/faceswap-playground#43&lt;/denchmark-link&gt;

Aligning faces does not work on some faces found with the cnn option. See below for the landmarks returned.
Can someone tell where the problem come from?
[Images Removed]
Code to reproduce (put in plugins/Extract_Align.py):
&lt;denchmark-code&gt;    def extract(self, image, face, size):
        if face.landmarks == None:
            print("Warning! landmarks not found. Switching to crop!")
            return cv2.resize(face.image, (size, size))

        # Draws landmarks for debug
        for (x, y) in face.landmarksAsXY():
            cv2.circle(image, (x, y), 1, (0, 0, 255), -1)

        alignment = get_align_mat( face )
        return self.transform( image, alignment, size, 48 )
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Clorr' date='2018-02-12T20:13:45Z'>
		why pictures zooming ?
cnn:
[Image Removed]
hog:
[Image Removed]
need mp4 file ?
		</comment>
		<comment id='2' author='Clorr' date='2018-02-12T20:42:19Z'>
		There is no specific picture zooming here, it is the extract as it is done by the code just now with the source you can find on the &lt;denchmark-link:https://github.com/deepfakes/faceswap-playground/issues/43&gt;original issue&lt;/denchmark-link&gt;

The question is to know why the landmarks are incorrect here, and also what we can do to correct this.
But as you say, there may be another problem which is that the face is framed too narrow. However, I don't think it is the origin of the landmarks defect as the landmarks are calculated on the original image (in lib/faces_detect.py)
		</comment>
		<comment id='3' author='Clorr' date='2018-02-12T23:51:37Z'>
		This is weird:
 return [pose_predictor(face_image, face_location) for face_location in face_locations]
The shape predictor receives as an argument the face box. According to dlib examples, it tries to get the landmark points inside that box, not the full image.

&lt;denchmark-link:http://dlib.net/face_landmark_detection.py.html&gt;http://dlib.net/face_landmark_detection.py.html&lt;/denchmark-link&gt;

That would explain why the landmarks are wrong if the cnn model extracts a zoomed-in image.
Passing the face box to the predictor outputs the expected(and wrong) result:
[Image Removed]
Not passing the box gets the landmarks right as expected:
[Image Removed]
But then the unexpected happened. Pass the hog face box to the predictor, it just ignores it.
[Image Removed]
		</comment>
		<comment id='4' author='Clorr' date='2018-02-13T04:16:18Z'>
		so how to fix problems?
		</comment>
		<comment id='5' author='Clorr' date='2018-02-13T05:03:21Z'>
		fakeapp align without zoom glitches:
[Image Removed]
		</comment>
		<comment id='6' author='Clorr' date='2018-02-13T06:35:46Z'>
		may be use &lt;denchmark-link:https://github.com/1adrianb/face-alignment&gt;https://github.com/1adrianb/face-alignment&lt;/denchmark-link&gt;
 as in fakeapp ?
ah no pytorch for windows ;(
		</comment>
		<comment id='7' author='Clorr' date='2018-02-13T07:50:27Z'>
		I think problem in landmarks detector, not face detector.
FaceSwap using ageitgey/face_recognition
fakeapp using 1adrianb/face-alignment
		</comment>
		<comment id='8' author='Clorr' date='2018-02-13T10:34:23Z'>
		Thank you &lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 for the awesome report!

The shape predictor receives as an argument the face box. According to dlib examples, it tries to get the landmark points inside that box, not the full image.


I think it is intended, because if you give an image with many faces the landmarks detector would be lost I presume.
From what you show, there is a slight difference between the box returned by hog and cnn, which I wasn't aware of. Maybe that explains also the "zooming" that @iperov reports?
My first option would be to try to enlarge the box returned by the cnn detector and see if it solves our problem. Also we can ask @ageitgey to have a look as it would be an enhancement for all face_recognition users.

		</comment>
		<comment id='9' author='Clorr' date='2018-02-13T10:56:23Z'>
		I have tried with 1adrianb/face-alignment and it seems to get the right landmarks, but I don't know why it is horribly slow even with CUDA.
		</comment>
		<comment id='10' author='Clorr' date='2018-02-13T11:02:33Z'>
		Have you an idea on the zooming effect noticed by &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
 ? Because the 1adrianb/face-alignment repo also uses &lt;denchmark-link:https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/api.py#L75&gt;mmod detector&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='Clorr' date='2018-02-13T11:25:43Z'>
		1adrianb also gets wrong the face box and for some reason it is a different box than the one in face_recognition. It also doesn't affect the landmarks.
Comparison of different face boxes:
Red: Extracted by face_recognition using cnn.
Green: Extracted by face-alignment using cnn.
White: Extracted with hog. Same result in both repos.
[Image Removed]
		</comment>
		<comment id='12' author='Clorr' date='2018-02-13T11:28:22Z'>
		yeah problem in face landmarks detector.
face-alignment better, but cant build it for windows :((
		</comment>
		<comment id='13' author='Clorr' date='2018-02-13T11:42:04Z'>
		Strange that the cnn detector returns a different box. Where did you get the values for the box? Also, there is a &lt;denchmark-link:https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/api.py#L171&gt;preprocessing of the recognized face done in 1adrianb repo&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;                center = torch.FloatTensor(
                    [d.right() - (d.right() - d.left()) / 2.0, d.bottom() -
                     (d.bottom() - d.top()) / 2.0])
                center[1] = center[1] - (d.bottom() - d.top()) * 0.12
                scale = (d.right() - d.left() + d.bottom() - d.top()) / 195.0

                inp = crop(image, center, scale)
                inp = torch.from_numpy(inp.transpose((2, 0, 1))).float().div(255.0).unsqueeze_(0)
&lt;/denchmark-code&gt;

However my skills are too low to understand what this does. Have you some idea?
		</comment>
		<comment id='14' author='Clorr' date='2018-02-13T11:56:11Z'>
		The face_location object is the box itself, it is a 4-tuple: (top,right,bottom,left)
face-alignment seems to be centering and resizing the face box before calculating landmarks, I will take a look at it.
Comparison of face-alignment and face_recognition landmarks:
face_recognition landmarks with cnn face box:
[Image Removed]
face_recognition landmarks with hog face box:
[Image Removed]
face-alignment landmarks with cnn face box:
[Image Removed]
face-alignment landmarks with hog face box:
[Image Removed]
		</comment>
		<comment id='15' author='Clorr' date='2018-02-13T12:04:56Z'>
		Yes, from what I understand it takes the center, but i don't understand the line with the 0.12. It moves the center a bit or something?
Then the scale is computed so that the box is 195 wide, doesn't it?
Then the &lt;denchmark-link:https://github.com/1adrianb/face-alignment/blob/fecdd1084df5d52246d26a9eb210e3404b4f6345/face_alignment/utils.py#L79&gt;crop method&lt;/denchmark-link&gt;
 returns a 256 wide image, so maybe it adds some margin around, which could explain that it gets the right landmarks as the face is not cropped too narrow?
I let you have a look when possible, no hurry ;-)
		</comment>
		<comment id='16' author='Clorr' date='2018-02-13T16:17:22Z'>
		I have just replaced the landmarks for the ones from face-alignment and it works a lot better, but it is also notably slower. I leave it here if someone wants to try it, don't forget to import face_alignment
face_detect.py
&lt;denchmark-code&gt;def detect_faces(frame, model="hog"):
    face_locations = face_recognition.face_locations(frame, model=model)

    if model=="cnn":
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=True,use_cnn_face_detector=True)
    else:
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=True,use_cnn_face_detector=False)

    raw_landmarks = fa.get_landmarks(frame,all_faces=True)
    landmarksXY = []
    if raw_landmarks is not None:
        for raw_landmark in raw_landmarks:
            landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

        for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
            yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='Clorr' date='2018-02-13T16:21:35Z'>
		&lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 thx, only need to build pytorch for me :D
		</comment>
		<comment id='18' author='Clorr' date='2018-02-13T16:43:17Z'>
		Take a look at this:
&lt;denchmark-link:https://github.com/peterjc123/pytorch-scripts&gt;https://github.com/peterjc123/pytorch-scripts&lt;/denchmark-link&gt;

		</comment>
		<comment id='19' author='Clorr' date='2018-02-13T16:49:26Z'>
		i dont want deal with conda, trying to build from python...
		</comment>
		<comment id='20' author='Clorr' date='2018-02-13T19:55:14Z'>
		I suggest open 2DFAN-4.pth.tar in torch, research network structure and tensors, and port it to keras.
:D
is this violates &lt;denchmark-link:https://github.com/1adrianb/face-alignment/blob/master/LICENSE&gt;https://github.com/1adrianb/face-alignment/blob/master/LICENSE&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='21' author='Clorr' date='2018-02-13T21:05:41Z'>
		&lt;denchmark-link:https://github.com/shaoanlu&gt;@shaoanlu&lt;/denchmark-link&gt;
 has added to his repo a new algorithm for face detection better than cnn.
&lt;denchmark-link:https://github.com/shaoanlu/faceswap-GAN&gt;https://github.com/shaoanlu/faceswap-GAN&lt;/denchmark-link&gt;

Comparison gif:
&lt;denchmark-link:https://user-images.githubusercontent.com/562386/36173639-fc9d0b74-1109-11e8-9a5b-3fb799670767.gif&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='22' author='Clorr' date='2018-02-13T21:20:01Z'>
		need test with 90deg rotated face
		</comment>
		<comment id='23' author='Clorr' date='2018-02-14T03:14:58Z'>
		&lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 I can confirm the suggested code finds the correct landmarks. Indeed it's slower, but a lot more precise.
As a side note. I had to tu user an older version of PyTorch (0.3.0) because 0.3.1 requires CUDA with compute capability &gt; 3.0.
Request a PR on that code. Also on the the bug flag for printing the dots on the images. It should be activated on demand by a --debug flag in the extract script. I can help.
		</comment>
		<comment id='24' author='Clorr' date='2018-02-14T06:41:55Z'>
		&lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 thx for code
I found prebuilt win64 python 3.5 torch 0.3.0 package.
and tested your code
Its works slow because you reinitialize face_alignment every frame
my temporary fix is
&lt;denchmark-code&gt;fa = None

def detect_faces(frame, model="hog"):
    face_locations = face_recognition.face_locations(frame, model=model)
    global fa
    
    if fa == None:
        if model=="cnn":
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=False,use_cnn_face_detector=True)
        else:
            fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=True,enable_cudnn=False,use_cnn_face_detector=False)

    raw_landmarks = fa.get_landmarks(frame,all_faces=True)
    landmarksXY = []
    if raw_landmarks is not None:
        for raw_landmark in raw_landmarks:
            landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

        for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
            yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)
        
&lt;/denchmark-code&gt;

I will use this face detector for my faceswap build :)
		</comment>
		<comment id='25' author='Clorr' date='2018-02-14T10:19:55Z'>
		that was my bad, flip_input must be False
now all fine !!
face_recognition dlib cnn suxx, face_alignment pytorch cnn rules.
face_alignment pytorch cnn VS face_recognition dlib cnn
in faceswap
[Image Removed]
&lt;denchmark-link:https://github.com/Clorr&gt;@Clorr&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gdunstone&gt;@gdunstone&lt;/denchmark-link&gt;
 will you adapt face_alignment to faceswap?
		</comment>
		<comment id='26' author='Clorr' date='2018-02-14T11:27:43Z'>
		So much improvement! &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
 How do I make pytorch work for windows?
		</comment>
		<comment id='27' author='Clorr' date='2018-02-14T11:49:51Z'>
		Maybe we could add face-alignment optional support for Linux and macOS users and leave pytorch out of the official requirements.
		</comment>
		<comment id='28' author='Clorr' date='2018-02-14T14:16:04Z'>
		&lt;denchmark-link:https://github.com/Deadfishzzway&gt;@Deadfishzzway&lt;/denchmark-link&gt;
  I downloaded package from there &lt;denchmark-link:https://anaconda.org/peterjc123/pytorch/files&gt;https://anaconda.org/peterjc123/pytorch/files&lt;/denchmark-link&gt;

and just copied lib to site-packages
		</comment>
		<comment id='29' author='Clorr' date='2018-02-14T15:34:03Z'>
		It is totally possible to add face-alignment as an option, however something still bothers me.
From what has been seen, landmarks detection seems to fail because of a too narrow crop which can be solved by adding some margin to the image before passed to the detector.
The other issue mentioned by &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
 is that we have a zooming effect that is not in . What bothers me here is that this zooming effect is not related to the landmarks, it is related to cnn detector that is the same in  and in . So I'm still wondering where this come from, and I strongly suspect the preprocessing done in  is the key
		</comment>
		<comment id='30' author='Clorr' date='2018-02-14T15:47:09Z'>
		&lt;denchmark-link:https://github.com/Clorr&gt;@Clorr&lt;/denchmark-link&gt;
 face detector same, but landmarks solver different
		</comment>
		<comment id='31' author='Clorr' date='2018-02-14T15:49:42Z'>
		The zooming effect is also present in face-alignment as you can see here (I have no clue why it is a different box though):
&lt;denchmark-link:https://github.com/deepfakes/faceswap/issues/187#issuecomment-365238963&gt;#187 (comment)&lt;/denchmark-link&gt;

I think face-alignment fixes it this way:

Gets face location box from the image with cnn algorithm.
Modifies center and size of the box.
Crops the face from the image using the new box.
Calculates landmarks inside that cropped image.

		</comment>
		<comment id='32' author='Clorr' date='2018-02-14T15:52:10Z'>
		That's what I think too, and it would be nice if we could include this "normalization" step in our code
		</comment>
		<comment id='33' author='Clorr' date='2018-02-14T19:20:30Z'>
		So, as it turned out the problem is the landmarks generator(aka shape predictor), maybe switching to face-alignment completely, as it also supports hog, would be a good idea.
		</comment>
		<comment id='34' author='Clorr' date='2018-02-14T19:32:35Z'>
		
What bothers me here is that this zooming effect is not related to the landmarks, it is related to cnn detector that is the same in face_recognition and in face-alignment

&lt;denchmark-link:https://github.com/Clorr&gt;@Clorr&lt;/denchmark-link&gt;
 i think the zooming is because of the wrong landmarks if you check the gif by &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;

[Image Removed]
only the ones with wrong landmarks are zoomed in
		</comment>
		<comment id='35' author='Clorr' date='2018-02-14T19:47:23Z'>
		&lt;denchmark-link:https://github.com/KMMR156&gt;@KMMR156&lt;/denchmark-link&gt;
 In the Extract_Align plugin, the final output is done with the help of the landmarks. And indeed, if the landmarks are wrong, the aligned output will be wrong.
&lt;denchmark-link:https://github.com/deepfakes/faceswap/blob/51f1993d93e0ffb581d44416f327f0cf731c34e8/lib/faces_detect.py#L7&gt;However, the landmarks are computed over the box returned by the face detector&lt;/denchmark-link&gt;
 and it seems to me that the failure of finding landmarks is due to the too narrow box returned by the face detector
		</comment>
		<comment id='36' author='Clorr' date='2018-02-14T19:53:43Z'>
		Also note that there is no dependency between face detector and landmarks detector outside the box delimiting the face, so if it works with hog and not with cnn, it means it is a problem of the box
		</comment>
		<comment id='37' author='Clorr' date='2018-02-14T20:14:44Z'>
		I checked problem picture directly in face_recognition/examples/find_facial_features_in_picture.py
result:
[Image Removed]
so... yes, no need face_alignment and pytorch, just need to fix existing code
		</comment>
		<comment id='38' author='Clorr' date='2018-02-14T20:34:07Z'>
		Yes, this is because the script you mention does not do a face_search before, and passes the full picture to the landmarks detector. That still adds to my conviction it is a problem of the box returned by the cnn detector
		</comment>
		<comment id='39' author='Clorr' date='2018-02-14T21:59:51Z'>
		So I played a bit with the box ;-) And it actually does not improve anything...
I could not reproduce &lt;denchmark-link:https://github.com/deepfakes/faceswap/issues/187#issuecomment-365103341&gt;@LordVulkan second example&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 could you call  without the box argument? Because I couldn't...
Also &lt;denchmark-link:https://github.com/deepfakes/faceswap/issues/187#issuecomment-365731325&gt;@iperov example&lt;/denchmark-link&gt;
 uses hog AFAIK
So face-alignment seems the way to go.
		</comment>
		<comment id='40' author='Clorr' date='2018-02-15T05:58:45Z'>
		Also @iperov example uses hog AFAIK

face_locations =  face_recognition.face_locations(image, 1, 'cnn')
face_landmarks_list = face_recognition.face_landmarks(image, face_locations)

same result
		</comment>
		<comment id='41' author='Clorr' date='2018-02-16T12:04:02Z'>
		Even with iperov fix hog detection is terribly slow not to mention cnn detection which was always very slow for me.
Detecting a face in single 1280x720 snapshot takes from 4-10 minutes. Is it normal? Perhaps problem with tf/cuda/pyhon config.
What time does it takes normally to process single picture in your case?
		</comment>
		<comment id='42' author='Clorr' date='2018-02-16T12:34:30Z'>
		&lt;denchmark-link:https://github.com/kcimit&gt;@kcimit&lt;/denchmark-link&gt;
 actually this is LordVulkan fix for use face_alignment in faceswap.
pytorch must be installed with cuda support, then speed is normal, ~1.3 images per sec
		</comment>
		<comment id='43' author='Clorr' date='2018-02-16T21:57:55Z'>
		thanks &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 but I think I miss something. Tried every method here for pytorch including building it under win10 - still same performance.
		</comment>
		<comment id='44' author='Clorr' date='2018-02-16T23:52:52Z'>
		I think CNN implementation can be improved. I use hd images for extract, if I use CNN with cuda support I get out of memory crash. If I use CNN without cuda it takes forever to complete.
There's an implementation &lt;denchmark-link:https://github.com/deepfakes/faceswap/issues/162&gt;here&lt;/denchmark-link&gt;
 I think pretty efficient. It first downsizes the image by four then use CNN with cuda to detect face then upsizes the image again and use hog to extract face. It works good but because it's not a part of the plugin system it doesn't output alignment.json file. Also It has the same zoomed in output problem.
		</comment>
		<comment id='45' author='Clorr' date='2018-02-17T08:44:44Z'>
		For the fix suggested by &lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/LordVulkan&gt;@LordVulkan&lt;/denchmark-link&gt;
 I wonder whether we need at all use face_recognition.
face_alignment when calculating landmarks already establish face location box. The question that it is impossible to get without changing get_landmarks
Provided that it returns bounding rect, the code in faces_detect could be.
`
def detect_faces(frame, model="hog"):
&lt;denchmark-code&gt;global fa
if fa == None:
    if model=="cnn":
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=False,enable_cudnn=False,use_cnn_face_detector=True)
    else:
        fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D,enable_cuda=False,enable_cudnn=False,use_cnn_face_detector=False)

raw_rects, raw_landmarks = fa.get_landmarks(frame,all_faces=False)
landmarksXY = []
face_locations =[]
if raw_landmarks is not None and raw_rects is not None:
    for raw_landmark in raw_landmarks:
        landmarksXY.append([(int(p[0]), int(p[1])) for p in raw_landmark])

    for raw_rect in raw_rects:
        face_locations.append((int(raw_rect.top()), int(raw_rect.right()), int(raw_rect.bottom()), int(raw_rect.left())))
        
    for ((y, right, bottom, x), landmarks) in zip(face_locations, landmarksXY):
        yield DetectedFace(frame[y: bottom, x: right], x, right - x, y, bottom - y, landmarks=landmarks,landmarksXY=landmarks)`
&lt;/denchmark-code&gt;

Kind of removes calculation overhead, which makes it a bit faster especially for cnn
		</comment>
		<comment id='46' author='Clorr' date='2018-02-23T07:04:18Z'>
		&lt;denchmark-link:https://github.com/kcimit&gt;@kcimit&lt;/denchmark-link&gt;
 do you have the above code with face_alignment-only working? Is there anything else required?
		</comment>
		<comment id='47' author='Clorr' date='2018-02-26T19:58:11Z'>
		Yes, I have it but it involves changing face_alignment
		</comment>
		<comment id='48' author='Clorr' date='2018-02-27T12:06:15Z'>
		almost ported face_alignment from PyTorch to Keras, output points 100% identical
		</comment>
		<comment id='49' author='Clorr' date='2018-03-01T07:32:03Z'>
		In my own testing, I found that face_recognition outperforms face-alignment (pytorch version) for speed, sensitivity, and errors in everything BUT the zooming stability issue. In particular, for dynamic scenes with complex backgrounds and lots of motion, face-alignment has a much higher error rate and also misses more faces. However, in "easy" scenes, face-alignment is probably better because of the more stable tracking.
Given the constraints of the whole faceswap package (want nice neat, slowly moving faces anyways), face-alignment is probably better for most use cases. Face_recognition is still handy to keep around for tough scenes pushing the limits, though.
		</comment>
		<comment id='50' author='Clorr' date='2018-03-01T07:35:37Z'>
		&lt;denchmark-link:https://github.com/deepfakesclub&gt;@deepfakesclub&lt;/denchmark-link&gt;
 I ported face-alignment to keras, speed same as face_recognition
		</comment>
		<comment id='51' author='Clorr' date='2018-03-01T11:23:46Z'>
		Closing this as &lt;denchmark-link:https://github.com/deepfakes/faceswap/pull/228&gt;#228&lt;/denchmark-link&gt;
 adresses this. Feel free to open new issue if there are still problems
		</comment>
	</comments>
</bug>