<bug id='4693' author='jacooba' open_date='2019-04-24T15:35:43Z' closed_time='2019-05-08T21:07:30Z'>
	<summary>Qmix Bug with Truncated Episodes or when max_seq_len is set</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04
Ray installed from (source or binary): source
Ray version:  0.6.2
Python version:  3.5.5
Exact command to reproduce: (running on custom env)

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Qmix is set up to add padded q-values of -9999999 to the end of every sequence. These q-values are not being correctly masked out. They are ignored in terminal states, due to line 108 in qmix_policy_graph.py, however they are being used in non-terminal states that happen to be at the end of a sequence. This is causing astronomical TD-errors on my custom env with 1 agent.
The issue is also a bit more complicated than just masking them out, as the code tries to do: There does need to be a next state (observation) to complete the bootstrapped return. If it is simply masked out, then certain states will never receive a back propagated loss.
I would suggest also passing in next_states to the loss function (new_obs in samples dictionary I believe). If terminal states are not recorded with a next observation, then one can be added as padding, since it will be 0-ed out by (1 - terminated) in line 108 anyway.
This issue can be verified by truncating episodes and noting that reward + self.gamma*-9999999 is contained in the variable masked_td_error.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='jacooba' date='2019-04-25T00:31:18Z'>
		To clarify, this only happens if batch mode is set to truncate episodes?
		</comment>
		<comment id='2' author='jacooba' date='2019-04-25T09:22:14Z'>
		I assume it would also be an issue with complete episodes but with a max_seq_len less than the length of the episode. It seems to be an issue if there is a non-terminal state at the end of a sequence.
		</comment>
		<comment id='3' author='jacooba' date='2019-04-25T09:41:29Z'>
		I have attached code that I believe reproduces the same bug. The commands are:
python3 twostep_game_no_bug.py --run QMIX
python3 twostep_game_bug.py --run QMIX
the variable masked_td_error seems to still contain the dummy constant in the bug version.
&lt;denchmark-link:https://github.com/ray-project/ray/files/3116258/Qmix.bug.zip&gt;Qmix bug.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='jacooba' date='2019-04-25T20:58:31Z'>
		Hm I see. The proposed fix makes sense to me, and it also seems ok to potentially ignore the last state when truncating. Do you want to make a patch?
		</comment>
		<comment id='5' author='jacooba' date='2019-04-26T08:46:20Z'>
		Sure. I can't do it this second, but should have some time next week.
		</comment>
	</comments>
</bug>