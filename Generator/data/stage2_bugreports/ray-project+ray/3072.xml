<bug id='3072' author='Rendok' open_date='2018-10-17T06:22:58Z' closed_time='2018-11-20T20:09:51Z'>
	<summary>'APEX_DDPG' doesn't work when there are less than 5 CPUs on a head node</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Deep Learning AMI (Ubuntu) Version 16.0
Ray installed from (source or binary): source
Ray version: 0.5.2
Python version: 3.6.5
Exact command to reproduce: None (freeze)

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I cannot start 'APEX_DDPG' via Tune on p2.xlarge (head) + m5.12xlarge (worker), but it works on g3.4xlarge (head) + m5.12xlarge (worker). Terminal just freezes. I think the problem is in initialization. That is, p2.xlarge has 4 CPUs, g3.4xlarge has 16 CPUs, though APEX requires at least 5 to start (and all have to be on a head node).
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

None
	</description>
	<comments>
		<comment id='1' author='Rendok' date='2018-10-17T08:09:36Z'>
		Thanks for reporting the hang, that's definitely not supposed to happen.
Note that you can lower the head node requirements by reducing the number of replay buffer shards: 


ray/python/ray/rllib/agents/ddpg/apex.py


         Line 16
      in
      a9e454f






 "num_replay_buffer_shards": 4, 





		</comment>
		<comment id='2' author='Rendok' date='2018-11-09T07:50:01Z'>
		I think this is actually fixed in master, where the resource request is now 1 CPU only. Can you try this out to confirm?
		</comment>
		<comment id='3' author='Rendok' date='2018-11-11T09:55:45Z'>
		Yes, it works in the last wheel. Thanks.
But
&lt;denchmark-code&gt;ray exec create-cluster.yaml 'tail -n 100 -f /tmp/raylogs/monitor-*'
&lt;/denchmark-code&gt;

doesn't work anymore though.
		</comment>
		<comment id='4' author='Rendok' date='2018-11-11T19:48:24Z'>
		/tmp/raylogs got renamed to /tmp/ray is the only thing I think.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sun, Nov 11, 2018, 1:55 AM Rendok ***@***.***&gt; wrote:
 Yes, it works in the last wheel. Thanks.

 But

 ray exec create-cluster.yaml 'tail -n 100 -f /tmp/raylogs/monitor-*'

 doesn't work anymore though.

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#3072 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAA6Shh3SUcyuFQSZVlBvWHvOgeFRa77ks5ut_QogaJpZM4XjNbl&gt;
 .



		</comment>
		<comment id='5' author='Rendok' date='2018-11-13T07:57:40Z'>
		Then you probably forgot to change the info in ray up *.yaml
		</comment>
		<comment id='6' author='Rendok' date='2018-11-20T20:09:51Z'>
		Ah, also ran into this recently and I think the issue is a version mismatch between the locally installed Ray and the one you are deploying via ray up.
		</comment>
	</comments>
</bug>