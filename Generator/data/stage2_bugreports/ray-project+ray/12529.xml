<bug id='12529' author='meechos' open_date='2020-12-01T11:09:17Z' closed_time='2020-12-09T17:11:54Z'>
	<summary>[tune] Issue with transferring weights between trials with schedulers/pbt.py</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Error during [exploit] of pbt scheduler when transferring weights between trials.
&lt;denchmark-code&gt;ray 1.0.1
torch 1.4.0
python 3
Cloudera CDSW environment
&lt;/denchmark-code&gt;

Error trace:
&lt;denchmark-code&gt;ERROR trial_runner.py:793 -- Trial _inner_82effdee: Error processing event.
Traceback (most recent call last):
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 755, in _process_trial
    self, trial, flat_result)
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/schedulers/pbt.py", line 387, in on_trial_result
    lower_quantile)
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/schedulers/pbt.py", line 479, in _perturb_trial
    self._exploit(trial_runner.trial_executor, trial, trial_to_clone)
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/schedulers/pbt.py", line 532, in _exploit
    new_config = self._get_new_config(trial, trial_to_clone)
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/schedulers/pbt.py", line 517, in _get_new_config
    self._resample_probability, self._custom_explore_fn)
  File "/home/cdsw/.local/lib/python3.6/site-packages/ray/tune/schedulers/pbt.py", line 81, in explore
    new_config[key] = int(new_config[key])
TypeError: int() argument must be a string, a bytes-like object or a number, not 'Apply'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

def tune_it(config,
            data_dir,
            vocab_dir,
           ):
    
    data = np.load(data_dir)
    model = Cronos(
        vocab_size,
        output_size,
        embedding_dim=config["embedding_dim"],
        latent_dim=config["latent_dim"],
        n_lstm=config["n_lstm"],
        bidirectional=config["bidirectional"],
        recurrent_dropout=config["recurrent_dropout"],
        dropout=config["dropout"],
        n_aux=config["n_aux"],
        n_fc=config["n_fc"],
        n_neurons=config["n_neurons"],
    )

    opt = torch.optim.Adam(model.parameters(), lr=config["lr"])
    model.train(
        data['train_seq'],
        data['train_aux'],
        data['val_seq'],
        data['val_aux'],
        data['train_y'],
        data['val_y'],
        optimizer=opt,
        shuffle_loader=False,
        lr=config["lr"],
        epochs=config["max_epochs"],
        criterion=loss_fn,
        clip=5,  # param_space['clip'],
        batch_size=config["batch_size"],
        validation_step=250,
        scoring="APS",
        early_stopping=200,
        tolerance=0.0001,
        tune_tracking=True,
        print_figure=False,
    )


param_space = dict(
    bidirectional=False,
    recurrent_dropout=0.3,
    dropout=0.3,
    n_aux=2,
    max_epochs=10,
    clip=5,
    batch_size=256,
)

search_space = dict(
    embedding_dim=hp.choice("embedding_dim", [64, 128, 256, 1024]),
    latent_dim=hp.choice("latent_dim", [64, 128, 256, 1024]),
    n_lstm=hp.choice("n_lstm", [1, 2, 4, 8]),
    n_fc=hp.choice("n_fc", [2, 4, 16, 32]),
    n_neurons=hp.choice("n_neurons", [64, 128, 256, 512]),
    lr=hp.choice("learning_rate", [0.001, 0.01, 0.1]),
)


hyperopt = HyperOptSearch(search_space, metric="model_score", mode="max")

pbt = PopulationBasedTraining(
    hyperparam_mutations=search_space,
    metric="model_score", mode="max", 
)


tune_result = tune.run(
    tune.with_parameters(tune_it,
                         data_dir=data_dir,
                         vocab_dir=vocab_path,
                        ),
    config=param_space,
    local_dir="tune_logs",
    verbose=0,
    resources_per_trial={"cpu": 16, "gpu": 1},
    search_alg=hyperopt,
    num_samples=20,
    scheduler=pbt,
    reuse_actors=False,
    resume=False,
)
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='meechos' date='2020-12-08T18:56:57Z'>
		&lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 it looks like an odd interaction of PBT with the hyperopt search perhaps. Not sure if that's allowed.
		</comment>
		<comment id='2' author='meechos' date='2020-12-08T20:57:50Z'>
		Hey &lt;denchmark-link:https://github.com/meechos&gt;@meechos&lt;/denchmark-link&gt;
, PBT isn't compatible with Hyperopt. Consider using PB2:
&lt;denchmark-link:https://docs.ray.io/en/master/tune/api_docs/schedulers.html#summary&gt;https://docs.ray.io/en/master/tune/api_docs/schedulers.html#summary&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>