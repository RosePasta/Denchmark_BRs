<bug id='2532' author='efang96' open_date='2018-08-01T00:17:24Z' closed_time='2018-08-01T22:29:26Z'>
	<summary>PPO num_gpus config does not work outside of Ray tune</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04
Ray installed from (source or binary):
Installed using pip install ray
Ray version:
0.5.0
Python version:
3.5.5
Exact command to reproduce:
trainer = ppo.PPOAgent(env="my_env", config={ "num_gpus":2, "tf_session_args": { "device_count": { "GPU": 2 } }

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

It depends on ray.get_gpu_ids() but this value returns [], which is misleading when GPUs are actually available.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='efang96' date='2018-08-01T01:27:37Z'>
		Did you set num_gpus in the PPO config? We won't try to request GPUs from ray unless that is set.
		</comment>
		<comment id='2' author='efang96' date='2018-08-01T17:23:47Z'>
		Yes, I also set:
"tf_session_args": { "device_count": { "GPU": 1 },
and also set CUDA_VISIBLE_DEVICES=0
		</comment>
		<comment id='3' author='efang96' date='2018-08-01T17:33:41Z'>
		What happens when you run the multi GPU tuned example?
		</comment>
		<comment id='4' author='efang96' date='2018-08-01T17:34:02Z'>
		You shouldn't need to set any of those variables except num GPUs.
		</comment>
		<comment id='5' author='efang96' date='2018-08-01T17:43:54Z'>
		I think it does end up using the GPU (according to nvidia-smi at least), but ray logs that I'm only using CPU.
		</comment>
		<comment id='6' author='efang96' date='2018-08-01T18:24:54Z'>
		Can you provide some output for reference? (and also fill out the issue)
		</comment>
		<comment id='7' author='efang96' date='2018-08-01T19:48:09Z'>
		Hi, can you try running this:
&lt;denchmark-code&gt;./train.py --run=PPO --env=CartPole-v0 --config='{"num_gpus": 2}'
&lt;/denchmark-code&gt;

When I run that, I get:
&lt;denchmark-code&gt;== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/32 CPUs, 2/2 GPUs
Result logdir: /home/ubuntu/ray_results/default
RUNNING trials:
 - PPO_CartPole-v0_0:	RUNNING [pid=19209], 21 s, 4047 ts, 22.8 rew
&lt;/denchmark-code&gt;

Which indicates two GPUs are being used. This is on master btw.
		</comment>
		<comment id='8' author='efang96' date='2018-08-01T20:14:41Z'>
		Seems like this is working, I pasted the output below:
&lt;denchmark-code&gt;== Status ==
Using FIFO scheduling algorithm.
Result logdir: /home/eecs/edward.fang/ray_results/default
PENDING trials:
 - PPO_CartPole-v0_0:	PENDING

Created LogSyncer for /home/eecs/edward.fang/ray_results/default/PPO_CartPole-v0_0_2018-08-01_13-13-29pux3ceu6 -&gt;
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/88 CPUs, 2/8 GPUs
Result logdir: /home/eecs/edward.fang/ray_results/default
RUNNING trials:
 - PPO_CartPole-v0_0:	RUNNING

/data/efang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
WARNING: lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
WARN: gym.spaces.Box autodetected dtype as &lt;class 'numpy.float32'&gt;. Please provide explicit dtype.
2018-08-01 13:13:39.309463: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
LocalMultiGPUOptimizer devices ['/gpu:0', '/gpu:1']
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='efang96' date='2018-08-01T20:28:47Z'>
		Oh, I see the problem, you're not running in Ray tune, so Ray doesn't assign the gpu ids properly without more manual work.
This PR &lt;denchmark-link:https://github.com/ray-project/ray/pull/2535&gt;#2535&lt;/denchmark-link&gt;
 should fix the issue. After that, you just need to set "num_gpus".
		</comment>
		<comment id='10' author='efang96' date='2018-08-01T22:29:26Z'>
		Great, thanks &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 !
		</comment>
	</comments>
</bug>