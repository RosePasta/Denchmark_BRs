<bug id='4913' author='rueberger' open_date='2019-05-31T16:53:04Z' closed_time='2020-10-12T03:58:03Z'>
	<summary>bug in remote function registration?</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution: ubuntu 16.04
Ray installed from (source or binary):  binary
Ray version: both 0.6.6 and 0.7 exhibit the same behavior
Python version:  3.5.2
Exact command to reproduce: forthcoming....

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When running an actor method that runs other remote tasks, ray throws "This worker was asked to execute a function that it does not have registered." for functions that it should have registered.
In particular, this breaks tune when training involves running remote tasks.
&lt;denchmark-h:h4&gt;background info&lt;/denchmark-h&gt;

As this problem spans a lot of code, it will take some time to make a minimal reproducible example. For the time being, I will describe the relevant bits as best I can.
The package structure looks like this:
foo:

experiment.py: entry point into running experiment
batch_gen.py: uses several remote methods
hypersweep.py: hyperparams search is launched from here

The trial actors launched for the hyperparam search look like this:
@ray.remote(num_gpus=1)
class RemoteTraining(object):
    def train(self):
        from foo.experiment import run_experiment
        run_experiment()
Note that   cannot  be a top-level import because in the real code, the equivalent of   is not serializable (it's a &lt;denchmark-link:https://github.com/IDSIA/sacred&gt;sacred&lt;/denchmark-link&gt;
  experiment).
experiment.py looks like this
from foo.batch_gen import batch_gen

def run_experiment():
     batch_generator =  batch_gen() # calls remote tasks to load data and initialize the batch gen
     # run experiment
      ...
batch_gen.py looks like this
import ray

@ray.remote
def load_data(args):
    data_urls = split_urls()
    # load data
    ...
    return data

def split_urls():
    ...

def batch_gen(): 
    data = load_data()
    # yield batches 
    ...
&lt;denchmark-h:h4&gt;the problem&lt;/denchmark-h&gt;

The following crashes:
import ray
ray.init()

from foo.hypersweep import RemoteTraining
training = RemoteTraining.remote()
training.train.remote() # ERROR: "This worker was asked to execute a function that it does not have registered."
On the other hand,  if I try the following we get an entirely different error:
import ray
ray.init()
from  foo.batch_gen import *

from foo.hypersweep import RemoteTraining
training = RemoteTraining.remote()
training.train.remote() # ERROR: "File:  batch_gen.py, in load_data, NameError: name 'split_urls' is not defined"
It was this point I became confident that this is a bug in ray, or at least bizarre and undesirable behavior.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Minimal reproducible example forthcoming...
	</description>
	<comments>
		<comment id='1' author='rueberger' date='2019-05-31T18:39:54Z'>
		OTOH, if I simply change the order of the imports:
import ray
from foo.batch_gen  import *
ray.init()

from foo.hypersweep import RemoteTraining
training = RemoteTraining.remote()
training.train.remote() # works!
everything works. Bizarre. Is this intended behavior?
		</comment>
		<comment id='2' author='rueberger' date='2019-06-05T10:20:01Z'>
		training.train() is intented? instead of training.train.remote()
		</comment>
		<comment id='3' author='rueberger' date='2019-06-05T15:49:19Z'>
		Thanks, fixed.
		</comment>
	</comments>
</bug>