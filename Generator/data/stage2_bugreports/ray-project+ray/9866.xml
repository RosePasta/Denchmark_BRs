<bug id='9866' author='snmhaines' open_date='2020-08-03T00:44:07Z' closed_time='2020-08-12T19:46:59Z'>
	<summary>EC2 Ray Cluster only using the head-node</summary>
	<description>
I have previously run Ray clusters which successfully employed a number of worker nodes in parallel.  Recently I updated to Ubuntu 18.04 (from 16.04) and the latest version of Ray, but now the same sort of configuration only seems to be scheduling tasks on the head node.  I tried both c4.8xlarge (which worked before), and c5.24xlarge instances, with the same results.  I am attaching the following files:-
ray_config.yaml  :  This has the recent non-hyperthreading commands commented out, but the same problem occurs either way.
Test.py  :  A simple test program containing the same approach that I am using for my simulation work.
ray-timeline*.json ; showing the result of running Test2
You can see that, despite my EC2 Console showing  showing two instances up and running, without any faults, Ray has only employed the 96 head-node CPUs - requiring serial execution on most in order to execute all 190 tasks.
&lt;denchmark-link:https://github.com/ray-project/ray/files/5013275/Files.zip&gt;Files.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='snmhaines' date='2020-08-07T21:08:58Z'>
		Are you sure you're using ray.init(address="auto")?
		</comment>
		<comment id='2' author='snmhaines' date='2020-08-07T23:22:45Z'>
		No - I was using the redis address from the host and adding the magic port number.  I just tried using "auto" instead, but the result was the same.
Note that for the "head_start_ray_commands:" (in the config) I am still using:-

ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-
config=~/ray_bootstrap_config.yaml

I also tried substituting "auto" in the "worker_start_ray_commands:" :-

ulimit -n 65536; ray start --redis-address="auto" --object-manager-port=8076

still no luck.
		</comment>
		<comment id='3' author='snmhaines' date='2020-08-11T23:39:26Z'>
		Hmm, the latest version of Ray I think doesn't support redis-port anymore? I think you need to do ray --port=6379.
Can you also run ray monitor {cluster.yaml}?
		</comment>
		<comment id='4' author='snmhaines' date='2020-08-12T06:27:52Z'>
		Well, I updated the ray start commands as follows:-
&lt;denchmark-code&gt;head_start_ray_commands:           # Command to start ray on the head node (don't change).
    - ray stop
    - ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

worker_start_ray_commands:         # Command to start ray on the workers (don't change).
    - ray stop
    - ulimit -n 65536; ray start --address="auto" --object-manager-port=8076
&lt;/denchmark-code&gt;

These start the cluster OK, but Ray is still not employing the worker.  I could not understand how to use that monitor, is there a more full instruction than this (&lt;denchmark-link:https://docs.ray.io/en/master/cluster/launcher.html#monitoring-cluster-status-ray-dashboard-monitor&gt;https://docs.ray.io/en/master/cluster/launcher.html#monitoring-cluster-status-ray-dashboard-monitor&lt;/denchmark-link&gt;
)?
		</comment>
		<comment id='5' author='snmhaines' date='2020-08-12T07:24:46Z'>
		Can you post the monitor output? I could help you decipher it.
		</comment>
		<comment id='6' author='snmhaines' date='2020-08-12T19:46:59Z'>
		I checked the latest version of example-full.yaml and followed that, i.e. using --address=$RAY_HEAD_IP:6379 in the worker ray start command.  This worked.
I would suggest that since the start command sections are not supposed to be configured by the user, but they do need updating for new releases, it would be safer if they were invisible.  In other words, not in the .yaml, but issued elsewhere, and updated automatically in new releases.
For the monitor, it is not clear whether it is a command issued instead of the "ray up" process or on the head node once logged on, and before or after the application run.  I tried a number of different ideas, mostly producing an error because the command was not understood ("cluster.yaml" isn't found).  Substituting the cluster name for "cluster" doesn't work, but substituting the configuration filename does, if the command is issued instead of "ray up"; though it is not obvious that it does much different from the latter.  I did find a large amount of log files on the head node at the location given in the instruction, including monitor.err: is this the same output that the ray monitor command extracts?
Thanks.
		</comment>
	</comments>
</bug>