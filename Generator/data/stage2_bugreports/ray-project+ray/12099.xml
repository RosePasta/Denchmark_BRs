<bug id='12099' author='LianShuaiLong' open_date='2020-11-18T05:34:41Z' closed_time='2020-11-18T05:54:02Z'>
	<summary>[Tune] Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

when i run tf_mnist_example.py with tensorflow-gpu, the following errors occur:
Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above
Ray version and other system information (Python version, TensorFlow version, OS):
ray:1.0.0
tensorflow:2.2.0
cuda:10.1
cudnn:7.6.5
python:3.6.12
os:centos7.4
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='LianShuaiLong' date='2020-11-18T05:35:22Z'>
		Can you post the full trace?
		</comment>
		<comment id='2' author='LianShuaiLong' date='2020-11-18T05:42:47Z'>
		
Can you post the full trace?

&lt;denchmark-code&gt;2020-11-18 13:35:43,658 INFO services.py:1166 -- View the Ray dashboard at http://127.0.0.1:8265
== Status ==
Memory usage on this node: 19.7/251.6 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None
Resources requested: 2/48 CPUs, 1/1 GPUs, 0.0/131.64 GiB heap, 0.0/41.65 GiB objects (0/1.0 accelerator_type:V100)
Result logdir: /data/home/lianshuailong/ray_results/MNISTTrainable
Number of trials: 3 (2 PENDING, 1 RUNNING)
+----------------------------+----------+-------+-----------+
| Trial name                 | status   | loc   |   hiddens |
|----------------------------+----------+-------+-----------|
| MNISTTrainable_e7955_00000 | RUNNING  |       |        32 |
| MNISTTrainable_e7955_00001 | PENDING  |       |        64 |
| MNISTTrainable_e7955_00002 | PENDING  |       |       128 |
+----------------------------+----------+-------+-----------+


(pid=103378) 2020-11-18 13:35:49.201166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
(pid=103378) 2020-11-18 13:35:49.223073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103378) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103378) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103378) 2020-11-18 13:35:49.226163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103378) 2020-11-18 13:35:49.233551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103378) 2020-11-18 13:35:49.238394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103378) 2020-11-18 13:35:49.241851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103378) 2020-11-18 13:35:49.248157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103378) 2020-11-18 13:35:49.252602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103378) 2020-11-18 13:35:49.261278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103378) 2020-11-18 13:35:49.265592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103378) 2020-11-18 13:35:49.266219: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
(pid=103378) 2020-11-18 13:35:49.304745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
(pid=103378) 2020-11-18 13:35:49.313822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556c36ec23b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=103378) 2020-11-18 13:35:49.313875: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=103378) 2020-11-18 13:35:49.448526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103378) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103378) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103378) 2020-11-18 13:35:49.448658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103378) 2020-11-18 13:35:49.448675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103378) 2020-11-18 13:35:49.448686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103378) 2020-11-18 13:35:49.448697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103378) 2020-11-18 13:35:49.448708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103378) 2020-11-18 13:35:49.448718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103378) 2020-11-18 13:35:49.448729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103378) 2020-11-18 13:35:49.451087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103378) 2020-11-18 13:35:49.451135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103378) 2020-11-18 13:35:49.829733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
(pid=103378) 2020-11-18 13:35:49.829804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
(pid=103378) 2020-11-18 13:35:49.829814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
(pid=103378) 2020-11-18 13:35:49.962568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory) -&gt; physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
(pid=103378) 2020-11-18 13:35:49.967506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556c37837480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
(pid=103378) 2020-11-18 13:35:49.967545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
(pid=103378) WARNING:tensorflow:AutoGraph could not transform &lt;function MNISTTrainable.setup.&lt;locals&gt;.train_step at 0x7f8cc241eae8&gt; and will run it as-is.
(pid=103378) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103378) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103378) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103378) WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.
(pid=103378)
(pid=103378) If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.
(pid=103378)
(pid=103378) To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
(pid=103378)
(pid=103378) WARNING:tensorflow:AutoGraph could not transform &lt;bound method MyModel.call of &lt;__main__.MyModel object at 0x7f8d1bb52438&gt;&gt; and will run it as-is.
(pid=103378) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103378) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103378) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103378) 2020-11-18 13:35:54.147202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103378) 2020-11-18 13:35:55.784789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103378) 2020-11-18 13:35:56.976668: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
(pid=103378) 2020-11-18 13:35:57.835636: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-11-18 13:35:57,918 ERROR trial_runner.py:567 -- Trial MNISTTrainable_e7955_00000: Error processing event.
Traceback (most recent call last):
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(UnknownError): ray::MNISTTrainable.train() (pid=103378, ip=10.28.72.248)
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trainable.py", line 336, in train
    result = self.step()
  File "train_esmm_tf.py", line 87, in step
    "--worker-type",
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node my_model/conv2d/Conv2D (defined at train_esmm_tf.py:24) ]] [Op:__inference_train_step_570]

Errors may have originated from an input operation.
Input Source operations connected to node my_model/conv2d/Conv2D:
 my_model/Cast (defined at train_esmm_tf.py:59)

Function call stack:
train_step
== Status ==
Memory usage on this node: 21.9/251.6 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None
Resources requested: 0/48 CPUs, 0/1 GPUs, 0.0/131.64 GiB heap, 0.0/41.65 GiB objects (0/1.0 accelerator_type:V100)
Result logdir: /data/home/lianshuailong/ray_results/MNISTTrainable
Number of trials: 3 (1 ERROR, 2 PENDING)
+----------------------------+----------+-------+-----------+
| Trial name                 | status   | loc   |   hiddens |
|----------------------------+----------+-------+-----------|
| MNISTTrainable_e7955_00000 | ERROR    |       |        32 |
| MNISTTrainable_e7955_00001 | PENDING  |       |        64 |
| MNISTTrainable_e7955_00002 | PENDING  |       |       128 |
+----------------------------+----------+-------+-----------+
Number of errored trials: 1
+----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+
| Trial name                 |   # failures | error file                                                                                                                |
|----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------|
| MNISTTrainable_e7955_00000 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00000_0_hiddens=32_2020-11-18_13-35-44/error.txt |
+----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+

(pid=103495) 2020-11-18 13:36:02.563292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
(pid=103495) 2020-11-18 13:36:02.630841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103495) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103495) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103495) 2020-11-18 13:36:02.631230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103495) 2020-11-18 13:36:02.632945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103495) 2020-11-18 13:36:02.634726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103495) 2020-11-18 13:36:02.635081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103495) 2020-11-18 13:36:02.637097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103495) 2020-11-18 13:36:02.638313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103495) 2020-11-18 13:36:02.644687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103495) 2020-11-18 13:36:02.647485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103495) 2020-11-18 13:36:02.648170: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
(pid=103495) 2020-11-18 13:36:02.669486: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
(pid=103495) 2020-11-18 13:36:02.675330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55834c02c2b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=103495) 2020-11-18 13:36:02.675389: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=103495) 2020-11-18 13:36:02.677082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103495) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103495) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103495) 2020-11-18 13:36:02.677204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103495) 2020-11-18 13:36:02.677224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103495) 2020-11-18 13:36:02.677238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103495) 2020-11-18 13:36:02.677251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103495) 2020-11-18 13:36:02.677264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103495) 2020-11-18 13:36:02.677276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103495) 2020-11-18 13:36:02.677290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103495) 2020-11-18 13:36:02.680677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103495) 2020-11-18 13:36:02.680753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103495) 2020-11-18 13:36:03.387324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
(pid=103495) 2020-11-18 13:36:03.387375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
(pid=103495) 2020-11-18 13:36:03.387384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
(pid=103495) 2020-11-18 13:36:03.389453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory) -&gt; physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
(pid=103495) 2020-11-18 13:36:03.391999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55834c9a12e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
(pid=103495) 2020-11-18 13:36:03.392028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
(pid=103495) WARNING:tensorflow:AutoGraph could not transform &lt;function MNISTTrainable.setup.&lt;locals&gt;.train_step at 0x7f5766c5cae8&gt; and will run it as-is.
(pid=103495) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103495) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103495) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103495) WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.
(pid=103495)
(pid=103495) If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.
(pid=103495)
(pid=103495) To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
(pid=103495)
(pid=103495) WARNING:tensorflow:AutoGraph could not transform &lt;bound method MyModel.call of &lt;__main__.MyModel object at 0x7f57c039e940&gt;&gt; and will run it as-is.
(pid=103495) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103495) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103495) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103495) 2020-11-18 13:36:07.184522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103495) 2020-11-18 13:36:08.902627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103495) 2020-11-18 13:36:11.361162: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
(pid=103495) 2020-11-18 13:36:11.367937: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-11-18 13:36:11,408 ERROR trial_runner.py:567 -- Trial MNISTTrainable_e7955_00001: Error processing event.
Traceback (most recent call last):
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(UnknownError): ray::MNISTTrainable.train() (pid=103495, ip=10.28.72.248)
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trainable.py", line 336, in train
    result = self.step()
  File "train_esmm_tf.py", line 87, in step
    "--worker-type",
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node my_model/conv2d/Conv2D (defined at train_esmm_tf.py:24) ]] [Op:__inference_train_step_570]

Errors may have originated from an input operation.
Input Source operations connected to node my_model/conv2d/Conv2D:
 my_model/Cast (defined at train_esmm_tf.py:59)

Function call stack:
train_step
== Status ==
Memory usage on this node: 21.8/251.6 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None
Resources requested: 0/48 CPUs, 0/1 GPUs, 0.0/131.64 GiB heap, 0.0/41.65 GiB objects (0/1.0 accelerator_type:V100)
Result logdir: /data/home/lianshuailong/ray_results/MNISTTrainable
Number of trials: 3 (2 ERROR, 1 PENDING)
+----------------------------+----------+-------+-----------+
| Trial name                 | status   | loc   |   hiddens |
|----------------------------+----------+-------+-----------|
| MNISTTrainable_e7955_00000 | ERROR    |       |        32 |
| MNISTTrainable_e7955_00001 | ERROR    |       |        64 |
| MNISTTrainable_e7955_00002 | PENDING  |       |       128 |
+----------------------------+----------+-------+-----------+
Number of errored trials: 2
+----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+
| Trial name                 |   # failures | error file                                                                                                                |
|----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------|
| MNISTTrainable_e7955_00000 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00000_0_hiddens=32_2020-11-18_13-35-44/error.txt |
| MNISTTrainable_e7955_00001 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00001_1_hiddens=64_2020-11-18_13-35-57/error.txt |
+----------------------------+--------------+---------------------------------------------------------------------------------------------------------------------------+

(pid=103479) 2020-11-18 13:36:15.544001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
(pid=103479) 2020-11-18 13:36:15.677568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103479) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103479) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103479) 2020-11-18 13:36:15.679766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103479) 2020-11-18 13:36:15.685263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103479) 2020-11-18 13:36:15.688702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103479) 2020-11-18 13:36:15.691506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103479) 2020-11-18 13:36:15.695247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103479) 2020-11-18 13:36:15.698229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103479) 2020-11-18 13:36:15.706542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103479) 2020-11-18 13:36:15.711721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103479) 2020-11-18 13:36:15.712531: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
(pid=103479) 2020-11-18 13:36:15.728628: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2100000000 Hz
(pid=103479) 2020-11-18 13:36:15.734341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605d9c6e2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
(pid=103479) 2020-11-18 13:36:15.734396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
(pid=103479) 2020-11-18 13:36:15.843194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
(pid=103479) pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0
(pid=103479) coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s
(pid=103479) 2020-11-18 13:36:15.843374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103479) 2020-11-18 13:36:15.843397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103479) 2020-11-18 13:36:15.843425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
(pid=103479) 2020-11-18 13:36:15.843443: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
(pid=103479) 2020-11-18 13:36:15.843460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
(pid=103479) 2020-11-18 13:36:15.843485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
(pid=103479) 2020-11-18 13:36:15.843505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103479) 2020-11-18 13:36:15.885127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
(pid=103479) 2020-11-18 13:36:15.885273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
(pid=103479) 2020-11-18 13:36:16.380413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
(pid=103479) 2020-11-18 13:36:16.380462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
(pid=103479) 2020-11-18 13:36:16.380470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
(pid=103479) 2020-11-18 13:36:16.425180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory) -&gt; physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0)
(pid=103479) 2020-11-18 13:36:16.428724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605da5e33a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
(pid=103479) 2020-11-18 13:36:16.428759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0
(pid=103479) WARNING:tensorflow:AutoGraph could not transform &lt;function MNISTTrainable.setup.&lt;locals&gt;.train_step at 0x7f64f3728ae8&gt; and will run it as-is.
(pid=103479) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103479) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103479) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103479) WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.
(pid=103479)
(pid=103479) If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.
(pid=103479)
(pid=103479) To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
(pid=103479)
(pid=103479) WARNING:tensorflow:AutoGraph could not transform &lt;bound method MyModel.call of &lt;__main__.MyModel object at 0x7f6550eba438&gt;&gt; and will run it as-is.
(pid=103479) Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
(pid=103479) Cause: 'NoneType' object has no attribute 'add_ordinary_node'
(pid=103479) To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
(pid=103479) 2020-11-18 13:36:21.348686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
(pid=103479) 2020-11-18 13:36:22.918051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
(pid=103479) 2020-11-18 13:36:23.982796: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
(pid=103479) 2020-11-18 13:36:23.999772: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-11-18 13:36:24,053 ERROR trial_runner.py:567 -- Trial MNISTTrainable_e7955_00002: Error processing event.
Traceback (most recent call last):
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(UnknownError): ray::MNISTTrainable.train() (pid=103479, ip=10.28.72.248)
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/trainable.py", line 336, in train
    result = self.step()
  File "train_esmm_tf.py", line 87, in step
    "--worker-type",
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node my_model/conv2d/Conv2D (defined at train_esmm_tf.py:24) ]] [Op:__inference_train_step_570]

Errors may have originated from an input operation.
Input Source operations connected to node my_model/conv2d/Conv2D:
 my_model/Cast (defined at train_esmm_tf.py:59)

Function call stack:
train_step
== Status ==
Memory usage on this node: 21.7/251.6 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None
Resources requested: 0/48 CPUs, 0/1 GPUs, 0.0/131.64 GiB heap, 0.0/41.65 GiB objects (0/1.0 accelerator_type:V100)
Result logdir: /data/home/lianshuailong/ray_results/MNISTTrainable
Number of trials: 3 (3 ERROR)
+----------------------------+----------+-------+-----------+
| Trial name                 | status   | loc   |   hiddens |
|----------------------------+----------+-------+-----------|
| MNISTTrainable_e7955_00000 | ERROR    |       |        32 |
| MNISTTrainable_e7955_00001 | ERROR    |       |        64 |
| MNISTTrainable_e7955_00002 | ERROR    |       |       128 |
+----------------------------+----------+-------+-----------+
Number of errored trials: 3
+----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------+
| Trial name                 |   # failures | error file                                                                                                                 |
|----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------|
| MNISTTrainable_e7955_00000 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00000_0_hiddens=32_2020-11-18_13-35-44/error.txt  |
| MNISTTrainable_e7955_00001 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00001_1_hiddens=64_2020-11-18_13-35-57/error.txt  |
| MNISTTrainable_e7955_00002 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00002_2_hiddens=128_2020-11-18_13-36-11/error.txt |
+----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------+

== Status ==
Memory usage on this node: 21.7/251.6 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None
Resources requested: 0/48 CPUs, 0/1 GPUs, 0.0/131.64 GiB heap, 0.0/41.65 GiB objects (0/1.0 accelerator_type:V100)
Result logdir: /data/home/lianshuailong/ray_results/MNISTTrainable
Number of trials: 3 (3 ERROR)
+----------------------------+----------+-------+-----------+
| Trial name                 | status   | loc   |   hiddens |
|----------------------------+----------+-------+-----------|
| MNISTTrainable_e7955_00000 | ERROR    |       |        32 |
| MNISTTrainable_e7955_00001 | ERROR    |       |        64 |
| MNISTTrainable_e7955_00002 | ERROR    |       |       128 |
+----------------------------+----------+-------+-----------+
Number of errored trials: 3
+----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------+
| Trial name                 |   # failures | error file                                                                                                                 |
|----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------|
| MNISTTrainable_e7955_00000 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00000_0_hiddens=32_2020-11-18_13-35-44/error.txt  |
| MNISTTrainable_e7955_00001 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00001_1_hiddens=64_2020-11-18_13-35-57/error.txt  |
| MNISTTrainable_e7955_00002 |            1 | /data/home/lianshuailong/ray_results/MNISTTrainable/MNISTTrainable_e7955_00002_2_hiddens=128_2020-11-18_13-36-11/error.txt |
+----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------+

Traceback (most recent call last):
  File "train_esmm_tf.py", line 126, in &lt;module&gt;
    resources_per_trial={'cpu':2,'gpu':int(args.cuda)}
  File "/data/home/lianshuailong/anaconda3/envs/tf-ray/lib/python3.6/site-packages/ray/tune/tune.py", line 427, in run
    raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [MNISTTrainable_e7955_00000, MNISTTrainable_e7955_00001, MNISTTrainable_e7955_00002])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='LianShuaiLong' date='2020-11-18T05:47:33Z'>
		Thanks!
1 tip: use 3 ticks (```)  to mark as code ^ see my edits in your response.
Also, it looks like you're seeing a tensorflow issue - &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/37144&gt;tensorflow/tensorflow#37144&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='LianShuaiLong' date='2020-11-18T05:54:02Z'>
		
Thanks!
1 tip: use 3 ticks (```) to mark as code ^ see my edits in your response.
Also, it looks like you're seeing a tensorflow issue - tensorflow/tensorflow#37144

thanks
		</comment>
	</comments>
</bug>