<bug id='9573' author='javadan' open_date='2020-07-19T19:39:42Z' closed_time='2020-07-19T20:58:33Z'>
	<summary>ARSTrainer freezing</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Running custom environment with ARSTrainer is freezing computer.
Ray Dashboard shows  two threads:
ARSTrainer.init() using 1.2% CPU and 4.1 MB RAM
ray.rllib.ars.ars.create_shared_noise() using 100.6% CPU and 1689MB RAM
Latest stable (0.8.6)
&lt;denchmark-h:h3&gt;Reproduction&lt;/denchmark-h&gt;

Attempting to run ARS algorithm on custom environment
I'll test on a standard gym env later, to see if it's my environment, when I'm ready to reboot my computer.  It does seem like the most likely case would be my environment, but if it is using that much memory in the shared noise method, that's suspicious.
Will update later.  Thanks. Great framework.
	</description>
	<comments>
		<comment id='1' author='javadan' date='2020-07-19T20:20:45Z'>
		Well after brief investigation, I see it's got to be this parameter 'noise_size': 250000000
I'm onto the next issue. Complaining about the observations, so maybe a mismatch between arrays and numpy arrays?
Anyone seen this bug?
&lt;denchmark-code&gt;2020-07-19 20:04:28,438	ERROR trial_runner.py:520 -- Trial ARS_TestEnv-v0_055a3_00000: Error processing event.
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/ray/tune/trial_runner.py", line 468, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/usr/local/lib/python3.6/dist-packages/ray/tune/ray_trial_executor.py", line 430, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/usr/local/lib/python3.6/dist-packages/ray/worker.py", line 1474, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TypeError): ray::ARSTrainer.train() (pid=6316, ip=192.168.101.127)
  File "python/ray/_raylet.pyx", line 446, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 400, in ray._raylet.execute_task.function_executor
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/trainer.py", line 497, in train
    raise e
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/trainer.py", line 486, in train
    result = Trainable.train(self)
  File "/usr/local/lib/python3.6/dist-packages/ray/tune/trainable.py", line 261, in train
    result = self._train()
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/ars/ars.py", line 231, in _train
    theta_id, config["num_rollouts"])
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/ars/ars.py", line 339, in _collect_results
    for result in ray.get(rollout_ids):
ray.exceptions.RayTaskError(TypeError): ray::Worker.do_rollouts() (pid=6314, ip=192.168.101.127)
  File "python/ray/_raylet.pyx", line 446, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 400, in ray._raylet.execute_task.function_executor
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/ars/ars.py", line 144, in do_rollouts
    rewards_pos, lengths_pos = self.rollout(timestep_limit)
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/ars/ars.py", line 116, in rollout
    offset=self.config["offset"])
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/es/es_tf_policy.py", line 49, in rollout
    observation, add_noise=add_noise, update=True)[0]
  File "/usr/local/lib/python3.6/dist-packages/ray/rllib/agents/ars/ars_tf_policy.py", line 59, in compute_actions
    observation = self.observation_filter(observation[None], update=update)
TypeError: list indices must be integers or slices, not NoneType
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='javadan' date='2020-07-19T20:58:33Z'>
		(possibly related error?: &lt;denchmark-link:https://groups.google.com/forum/#!topic/ray-dev/lrb_33SSlXk&gt;https://groups.google.com/forum/#!topic/ray-dev/lrb_33SSlXk&lt;/denchmark-link&gt;
 )
"  env was returning a list as opposed to a numpy array in the reset."
Well indeed mine is also returning a list.  np.array(...)  fixed it. Phew.
		</comment>
	</comments>
</bug>