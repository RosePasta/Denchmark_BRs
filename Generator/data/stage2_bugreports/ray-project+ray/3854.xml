<bug id='3854' author='dpad' open_date='2019-01-25T14:10:03Z' closed_time='2019-02-02T04:32:08Z'>
	<summary>on_train_result results do not get logged</summary>
	<description>
Mutating the info['results'] object inside a on_train_result callback function means that the mutated results do not get logged. This is because the Agent's train() method calls the superclass Trainable's train() method (which does the logging) prior to calling the callback. I'm not sure whether this is intended behaviour or not, but it means that custom metrics via this callback interface don't show up in Tensorboard.
	</description>
	<comments>
		<comment id='1' author='dpad' date='2019-01-25T14:31:26Z'>
		MWE:
import ray.rllib

def result_callback(info):
    info['result']['new_metric'] = 1234

ray.init()
trainer = ray.rllib.agents.ppo.PPOAgent(env="CartPole-v1", config={'callbacks': {'on_train_result': result_callback}})

result = trainer.train()
assert 'new_metric' in result and result['new_metric'] == 1234  # OK!
# Check result.json -- 'new_metric' was not written (so does not show up in Tensorboard).
Super quick hacky work around (I think this ends up duplicating some of the results so the logging is a bit off, but it's good enough for me for now):
result = trainer.train()
trainer._result_logger.on_result(result)  # Logged to result.json.
		</comment>
	</comments>
</bug>