<bug id='9821' author='snmhaines' open_date='2020-07-30T16:45:40Z' closed_time='2020-08-14T19:05:37Z'>
	<summary>Hyperthreading not disabled in Ray 0.8.6</summary>
	<description>
This relates to the pull request "Force OMP_NUM_THREADS=1 if unset &lt;denchmark-link:https://github.com/ray-project/ray/pull/6998&gt;#6998&lt;/denchmark-link&gt;
" from February (also "Always set OMP_NUM_THREADS even on low core machines &lt;denchmark-link:https://github.com/ray-project/ray/pull/7006&gt;#7006&lt;/denchmark-link&gt;
").  I left a comment on the former, but I am not sure that anyone will have been notified.  I also posted a question on Stackoverflow: "Disabling Hyperthreading on Nodes in an AWS EC2 Cluster through Ray Configuration".
I have updated to 0.8.6, but OMP_NUM_THREADS isn't defined on the head-node (c5.24xlarge).  If the change has not been made in the current version, then this is not a bug, and I just need advice on how to get the variable set through the config.
	</description>
	<comments>
		<comment id='1' author='snmhaines' date='2020-07-31T00:57:48Z'>
		P.S.  I have managed to set OMP_NUM_THREADS=1 on the head-node and workers, through the config file, but it is has made disappointingly little difference.
		</comment>
		<comment id='2' author='snmhaines' date='2020-07-31T21:05:50Z'>
		Can you provide a repro script? That'd help us better understand the problem!
		</comment>
		<comment id='3' author='snmhaines' date='2020-07-31T21:52:58Z'>
		I am attaching the configuration file that I have been using.  You can see that I have a line in the setup that sets OMP_NUM_THREADS=1.  The application that I want to run on this cluster is a rather large 1-D CFD simulation that is started by a Python3 script that initiates Ray to run 90 instances of this in parallel.  I have checked that each worker does get the environmental variable set with that ray_config.yaml, so the immediate problem should be reproducible by removing line 61 and spinning up the cluster, then logging into the head node to see whether OMP_NUM_THREADS exists.
Meanwhile, I am running some diagnostic tests that AWS suggested to try to positively identify the cause of my application bogging down with larger numbers of workers.  One theory, that I cannot yet completely eliminate, is that the way I am commanding HT to be switched off is not actually taking effect.
P.S.  Actually that seems to be the case - this is from the head-node:-
ubuntu@ip-172-31-48-161:$
ubuntu@ip-172-31-48-161:$ echo $OMP_NUM_THREADS
1
ubuntu@ip-172-31-48-161:~$ lscpu --extended
CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE
0   0    0      0    0:0:0:0       yes
1   0    0      1    1:1:1:0       yes
2   0    0      2    2:2:2:0       yes
3   0    0      3    3:3:3:0       yes
4   0    0      4    4:4:4:0       yes
5   0    0      5    5:5:5:0       yes
6   0    0      6    6:6:6:0       yes
7   0    0      7    7:7:7:0       yes
8   0    0      8    8:8:8:0       yes
9   0    0      9    9:9:9:0       yes
10  0    0      10   10:10:10:0    yes
11  0    0      11   11:11:11:0    yes
12  0    0      12   12:12:12:0    yes
13  0    0      13   13:13:13:0    yes
14  0    0      14   14:14:14:0    yes
15  0    0      15   15:15:15:0    yes
16  0    0      16   16:16:16:0    yes
17  0    0      17   17:17:17:0    yes
18  0    0      18   18:18:18:0    yes
19  0    0      19   19:19:19:0    yes
20  0    0      20   20:20:20:0    yes
21  0    0      21   21:21:21:0    yes
22  0    0      22   22:22:22:0    yes
23  0    0      23   23:23:23:0    yes
24  1    1      24   24:24:24:1    yes
25  1    1      25   25:25:25:1    yes
26  1    1      26   26:26:26:1    yes
27  1    1      27   27:27:27:1    yes
28  1    1      28   28:28:28:1    yes
29  1    1      29   29:29:29:1    yes
30  1    1      30   30:30:30:1    yes
31  1    1      31   31:31:31:1    yes
32  1    1      32   32:32:32:1    yes
33  1    1      33   33:33:33:1    yes
34  1    1      34   34:34:34:1    yes
35  1    1      35   35:35:35:1    yes
36  1    1      36   36:36:36:1    yes
37  1    1      37   37:37:37:1    yes
38  1    1      38   38:38:38:1    yes
39  1    1      39   39:39:39:1    yes
40  1    1      40   40:40:40:1    yes
41  1    1      41   41:41:41:1    yes
42  1    1      42   42:42:42:1    yes
43  1    1      43   43:43:43:1    yes
44  1    1      44   44:44:44:1    yes
45  1    1      45   45:45:45:1    yes
46  1    1      46   46:46:46:1    yes
47  1    1      47   47:47:47:1    yes
48  0    0      0    0:0:0:0       yes
49  0    0      1    1:1:1:0       yes
50  0    0      2    2:2:2:0       yes
51  0    0      3    3:3:3:0       yes
52  0    0      4    4:4:4:0       yes
53  0    0      5    5:5:5:0       yes
54  0    0      6    6:6:6:0       yes
55  0    0      7    7:7:7:0       yes
56  0    0      8    8:8:8:0       yes
57  0    0      9    9:9:9:0       yes
58  0    0      10   10:10:10:0    yes
59  0    0      11   11:11:11:0    yes
60  0    0      12   12:12:12:0    yes
61  0    0      13   13:13:13:0    yes
62  0    0      14   14:14:14:0    yes
63  0    0      15   15:15:15:0    yes
64  0    0      16   16:16:16:0    yes
65  0    0      17   17:17:17:0    yes
66  0    0      18   18:18:18:0    yes
67  0    0      19   19:19:19:0    yes
68  0    0      20   20:20:20:0    yes
69  0    0      21   21:21:21:0    yes
70  0    0      22   22:22:22:0    yes
71  0    0      23   23:23:23:0    yes
72  1    1      24   24:24:24:1    yes
73  1    1      25   25:25:25:1    yes
74  1    1      26   26:26:26:1    yes
75  1    1      27   27:27:27:1    yes
76  1    1      28   28:28:28:1    yes
77  1    1      29   29:29:29:1    yes
78  1    1      30   30:30:30:1    yes
79  1    1      31   31:31:31:1    yes
80  1    1      32   32:32:32:1    yes
81  1    1      33   33:33:33:1    yes
82  1    1      34   34:34:34:1    yes
83  1    1      35   35:35:35:1    yes
84  1    1      36   36:36:36:1    yes
85  1    1      37   37:37:37:1    yes
86  1    1      38   38:38:38:1    yes
87  1    1      39   39:39:39:1    yes
88  1    1      40   40:40:40:1    yes
89  1    1      41   41:41:41:1    yes
90  1    1      42   42:42:42:1    yes
91  1    1      43   43:43:43:1    yes
92  1    1      44   44:44:44:1    yes
93  1    1      45   45:45:45:1    yes
94  1    1      46   46:46:46:1    yes
95  1    1      47   47:47:47:1    yes
That is showing 95 CPUs on-line in the 48-CPU instance, so it is prepared for hyperthreading despite the value of OMP_NUM_THREADS.
Yours,
Steven Haines
&lt;denchmark-link:https://github.com/ray-project/ray/files/5009146/ray_conf.zip&gt;ray_conf.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='snmhaines' date='2020-08-01T00:27:10Z'>
		Success!  I used the suggestion from here: &lt;denchmark-link:https://aws.amazon.com/blogs/compute/disabling-intel-hyper-threading-technology-on-amazon-linux/&gt;https://aws.amazon.com/blogs/compute/disabling-intel-hyper-threading-technology-on-amazon-linux/&lt;/denchmark-link&gt;
, but also had to give the user permissions to overwrite all the cpu online flags:-
setup_commands:
- sudo chmod -R 777 /sys/devices/system/cpu/*
- for cpunum in $(cat /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | cut -s -d, -f2- | tr ',' '\n' | sort -un); do echo 0 &gt; /sys/devices/system/cpu/cpu$cpunum/online; done
My application now runs on 90 tasks as fast as one.  It seems that OMP_NUM_THREADS is ineffective.
Also, I would suggest that if you intend to simplify the disablement of hyperthreading, then it is implemented as an option in the config file (as in the Matlab Cloud Center cluster configuration), because the need to do it is application-specific, not a function of number of CPUs in the instance.  The problem of two CPUs fighting over one FPU arises, even on only one core, if the application's floating-point usage is heavy enough.
... Steven Haines
		</comment>
		<comment id='5' author='snmhaines' date='2020-08-07T21:15:12Z'>
		Any recommendation on what we should add to the documentation?
		</comment>
	</comments>
</bug>