<bug id='10372' author='ebilgin' open_date='2020-08-27T19:51:28Z' closed_time='2020-09-22T06:03:07Z'>
	<summary>KeyError: 'action_logp' while consuming offline data [rllib]</summary>
	<description>
I am trying to consume offline data using the example &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/examples/saving_experiences.py&gt;here&lt;/denchmark-link&gt;
. I have the following code:
&lt;denchmark-code&gt;from ray.tune.logger import pretty_print
from ray.rllib.agents.dqn.dqn import DEFAULT_CONFIG
from ray.rllib.agents.dqn.dqn import DQNTrainer
import numpy as np

config = DEFAULT_CONFIG.copy()
config["env"] = "CartPole-v0"
config["input"] = {"demo-out": 0.3, "sampler": 0.7}
config["explore"] = False
trainer = DQNTrainer(config=config)
best_eps_length_avg = np.PINF
while True:
    results = trainer.train()
    print(pretty_print(results))
&lt;/denchmark-code&gt;

I am getting the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/enes/ws/code/arl/mt/test/consume_experiences.py", line 16, in &lt;module&gt;
    results = trainer.train()
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 522, in train
    raise e
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 508, in train
    result = Trainable.train(self)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/tune/trainable.py", line 332, in train
    result = self.step()
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 110, in step
    res = next(self.train_exec_impl)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 758, in __next__
    return next(self.built_iterator)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 785, in apply_foreach
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 845, in apply_filter
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 845, in apply_filter
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 785, in apply_foreach
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 845, in apply_filter
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 1078, in build_union
    item = next(it)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 758, in __next__
    return next(self.built_iterator)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 785, in apply_foreach
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 785, in apply_foreach
    for item in it:
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/util/iter.py", line 785, in apply_foreach
    for item in it:
  [Previous line repeated 2 more times]
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/execution/replay_ops.py", line 89, in gen_replay
    item = local_buffer.replay()
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/execution/replay_buffer.py", line 331, in replay
    beta=self.prioritized_replay_beta)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/execution/replay_buffer.py", line 173, in sample
    batch = self._encode_sample(idxes)
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/execution/replay_buffer.py", line 64, in _encode_sample
    out = SampleBatch.concat_samples([self._storage[i] for i in idxes])
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/policy/sample_batch.py", line 93, in concat_samples
    out[k] = concat_aligned([s[k] for s in samples])
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/policy/sample_batch.py", line 93, in &lt;listcomp&gt;
    out[k] = concat_aligned([s[k] for s in samples])
  File "/home/enes/ws/envs/rlws/lib/python3.7/site-packages/ray/rllib/policy/sample_batch.py", line 294, in __getitem__
    return self.data[key]
KeyError: 'action_logp'
&lt;/denchmark-code&gt;

I am using ray 0.8.7 on Ubuntu 18.04 LTS. Tensorflow 2.3.0.
	</description>
	<comments>
		<comment id='1' author='ebilgin' date='2020-08-29T05:35:13Z'>
		It seems like somehow we're trying to read that key, though action_prob should be enough. As a workaround, you can try also writing action_logp (calling add_values(action_logp=np.log(action_prob))).
		</comment>
	</comments>
</bug>