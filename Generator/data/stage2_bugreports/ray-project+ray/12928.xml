<bug id='12928' author='EvanOman' open_date='2020-12-16T22:58:16Z' closed_time='2020-12-17T00:05:12Z'>
	<summary>[tune] tune.with_parameters Not Working with XGBoost</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Versions:
Ray: v1.0.1.post1
Python: 3.7.9
OS: Ubuntu 16.04
I am getting an error when I use tune.with_parameters to pass the NumPy training data to an XGBoost model.

Training Function

from typing import Any, Dict

import numpy as np
import ray
from ray import tune
from ray.tune.integration.xgboost import TuneReportCallback
from ray.tune.schedulers import FIFOScheduler
from xgboost import XGBRegressor

# Initialize Ray
ray.init(num_cpus=1)

def train(config: Dict[str, Any], feat_train: np.ndarray, feat_test:np.ndarray, tgt_train:np.ndarray, tgt_test:np.ndarray) -&gt; None:
    # Train the classifier, using the Tune callback
    xgr = XGBRegressor(**config)
    xgr.fit(feat_train, tgt_train,
        eval_set=[(feat_test, tgt_test)],
        eval_metric=["rmse", "mae"],
        callbacks=[TuneReportCallback({"rmse": "validation_0-rmse", "mae": "validation_0-mae"})],
        verbose=False
    )


Working Tune Function (w/ Currying):

def tune_works():
    # Generate the data
    feat_train = np.random.rand(80,4)
    feat_test = np.random.rand(20,4)
    tgt_train = np.random.rand(80,1)
    tgt_test = np.random.rand(20,1)

    # Use currying
    train_func = lambda config: train(config, feat_train, feat_test, tgt_train, tgt_test)

    # Run Tune
    analysis = tune.run(
        train_func,
        name="TEST",
        scheduler=FIFOScheduler(),
        num_samples=2,
        metric="rmse",
        mode="min",
        resources_per_trial={"cpu": 1},
        config={"max_depth": tune.randint(1,9)}
    )


Failing Tune Function (w/ with_params)

def tune_fails():
    # Generate the data
    feat_train = np.random.rand(80,4)
    feat_test = np.random.rand(20,4)
    tgt_train = np.random.rand(80,1)
    tgt_test = np.random.rand(20,1)

    # Run Tune
    analysis = tune.run(
        tune.with_parameters(train, feat_train=feat_train, feat_test=feat_test, tgt_train=tgt_train, tgt_test=tgt_test),
        name="TEST",
        scheduler=FIFOScheduler(),
        num_samples=2,
        metric="rmse",
        mode="min",
        resources_per_trial={"cpu": 1},
        config={"max_depth": tune.randint(1,9)}
    )



Error Message

(pid=22878) *** Aborted at 1608158301 (unix time) try "date -d @1608158301" if you are using GNU date ***
(pid=22878) PC: @                0x0 (unknown)
(pid=22878) *** SIGSEGV (@0x0) received by PID 22878 (TID 0x7f2583932700) from PID 0; stack trace: ***
(pid=22878)     @     0x7f297158c390 (unknown)
(pid=22878)     @     0x7f2583cc32da xgboost::MetaInfo::SetInfo()
(pid=22878)     @     0x7f2583c46a4c XGDMatrixSetDenseInfo
(pid=22878)     @     0x7f297077b9dd ffi_call_unix64
(pid=22878)     @     0x7f297077b067 ffi_call_int
(pid=22878)     @     0x7f29704c3517 _ctypes_callproc
(pid=22878)     @     0x7f29704c3f84 PyCFuncPtr_call
(pid=22878)     @     0x5622f9a5cccb _PyObject_FastCallKeywords
(pid=22878)     @     0x5622f9ac239e _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a54e7b _PyFunction_FastCallKeywords
(pid=22878)     @     0x5622f9abd4b6 _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a04829 _PyEval_EvalCodeWithName
(pid=22878)     @     0x5622f9a550a5 _PyFunction_FastCallKeywords
(pid=22878)     @     0x5622f9abd4b6 _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a54e7b _PyFunction_FastCallKeywords
(pid=22878)     @     0x5622f9abd740 _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a05160 _PyEval_EvalCodeWithName
(pid=22878)     @     0x5622f9a05b50 _PyFunction_FastCallDict
(pid=22878)     @     0x5622f9abeeea _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a05160 _PyEval_EvalCodeWithName
(pid=22878)     @     0x5622f9a55107 _PyFunction_FastCallKeywords
(pid=22878)     @     0x5622f9abe585 _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a04829 _PyEval_EvalCodeWithName
(pid=22878)     @     0x5622f9a05b50 _PyFunction_FastCallDict
(pid=22878)     @     0x5622f9a244d3 _PyObject_Call_Prepend
(pid=22878)     @     0x5622f9a5bd5a slot_tp_init
(pid=22878)     @     0x5622f9a5c968 _PyObject_FastCallKeywords
(pid=22878)     @     0x5622f9ac2688 _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a05160 _PyEval_EvalCodeWithName
(pid=22878)     @     0x5622f9a05b50 _PyFunction_FastCallDict
(pid=22878)     @     0x5622f9abeeea _PyEval_EvalFrameDefault
(pid=22878)     @     0x5622f9a05160 _PyEval_EvalCodeWithName
E1216 17:38:21.972815 22375 22645 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.tune.function_runner, class_name=ImplicitFunc, function_name=train, function_hash=}, task_id=6ab1468f8b13f54fbc38c54701000000, task_name=ImplicitFunc.train(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bc38c54701000000, actor_caller_id=ffffffffffffffffffffffff01000000, actor_counter=0}
2020-12-16 17:38:21,974 ERROR trial_runner.py:793 -- Trial _inner_65b02_00000: Error processing event.
Traceback (most recent call last):
  File "/home/oman/anaconda3/envs/payload/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 726, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/oman/anaconda3/envs/payload/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 489, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/oman/anaconda3/envs/payload/lib/python3.7/site-packages/ray/worker.py", line 1454, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
E1216 17:38:21.976387 22375 22645 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.tune.function_runner, class_name=ImplicitFunc, function_name=stop, function_hash=}, task_id=62536b5ffc3b339abc38c54701000000, task_name=ImplicitFunc.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bc38c54701000000, actor_caller_id=ffffffffffffffffffffffff01000000, actor_counter=1}
2020-12-16 17:38:21,980 WARNING worker.py:1091 -- A worker died or was killed while executing task ffffffffffffffffbc38c54701000000.



&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Run the code above.
	</description>
	<comments>
		<comment id='1' author='EvanOman' date='2020-12-16T23:03:29Z'>
		Thanks for posting this issue &lt;denchmark-link:https://github.com/EvanOman&gt;@EvanOman&lt;/denchmark-link&gt;
!
Also, thanks for nicely formatting this -- it's so incredibly clean and easy to parse.
A couple things:

Can you try using the nightly wheels to see if this is still an issue? We recently modified tune.with_parameters to better leverage the object store. The nightly wheels can be found here: https://docs.ray.io/en/master/installation.html#daily-releases-nightlies (use the pip install -U method)
If this is still an issue, can you try .copy() on your numpy arrays within your training function that you are wrapping with with_parameters? I suspect maybe xgboost doesn't play well with read-only numpy arrays.

		</comment>
		<comment id='2' author='EvanOman' date='2020-12-16T23:05:50Z'>
		On another side, maybe you can try tune-sklearn (&lt;denchmark-link:https://github.com/ray-project/tune-sklearn/blob/master/examples/xgbclassifier.py&gt;https://github.com/ray-project/tune-sklearn/blob/master/examples/xgbclassifier.py&lt;/denchmark-link&gt;
) which provides a scikit-learn interface for using Tune.
		</comment>
		<comment id='3' author='EvanOman' date='2020-12-16T23:15:19Z'>
		&lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
  Thank you for the quick response!

I updated to nightly and still got the same result.
I added a .copy() to each of the numpy array uses within the training function and that did the trick, no error!

		</comment>
		<comment id='4' author='EvanOman' date='2020-12-17T00:05:11Z'>
		Cool! I'll close this issue for now; feel free to open a new one if you have any questions.
		</comment>
	</comments>
</bug>