<bug id='7743' author='pengzhenghao' open_date='2020-03-25T12:54:39Z' closed_time='2020-04-13T07:49:29Z'>
	<summary>[rllib] PPO with pytorch model fails</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
Mac OS and Linux.
python=3.7
ray=0.8.2 (install by pip install ray (installed in Mar 25, 2020))
torch=1.4.0 (latest)
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
from ray import tune

tune.run(
    "PPO",
    config={
        "env": "BipedalWalker-v2",
        "use_pytorch": True,
    },
)
The error is:
&lt;denchmark-code&gt;ray.exceptions.RayTaskError(RuntimeError): ray::PPO.train() (pid=3435, ip=192.168.205.2)
  File "python/ray/_raylet.pyx", line 452, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 430, in ray._raylet.execute_task.function_executor
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 497, in train
    raise e
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 483, in train
    result = Trainable.train(self)
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/tune/trainable.py", line 254, in train
    result = self._train()
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 133, in _train
    fetches = self.optimizer.step()
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/optimizers/sync_samples_optimizer.py", line 71, in step
    self.standardize_fields)
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/utils/sgd.py", line 111, in do_minibatch_sgd
    }, minibatch.count)))[policy_id]
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 626, in learn_on_batch
    info_out[pid] = policy.learn_on_batch(batch)
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py", line 108, in learn_on_batch
    loss_out = self._loss(self, self.model, self.dist_class, train_batch)
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py", line 137, in ppo_surrogate_loss
    use_gae=policy.config["use_gae"],
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py", line 79, in __init__
    self.mean_kl = reduce_mean_valid(action_kl)
  File "/home/sunhao/anaconda3/envs/pzh/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo_torch_policy.py", line 72, in reduce_mean_valid
    return torch.mean(t * valid_mask)
RuntimeError: The size of tensor a (4) must match the size of tensor b (128) at non-singleton dimension 1
&lt;/denchmark-code&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='pengzhenghao' date='2020-03-25T16:06:14Z'>
		cc &lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='pengzhenghao' date='2020-03-29T16:08:28Z'>
		I have the exact same problem! how did you solve it? did you?
btw, the framework doesn't matter. it also happens with TF ):
		</comment>
		<comment id='3' author='pengzhenghao' date='2020-04-01T04:44:18Z'>
		
I have the exact same problem! how did you solve it? did you?
btw, the framework doesn't matter. it also happens with TF ):

Updating ray to 0.8.3 fixs the problem that PPO torch version can't run. I don't find PPO TF version has any problem in 0.8.1, 0.8.2, 0.8.3. How you get the error using TF PPO?
I feel that ray 0.8.2 introduce something that corrupt the basic functionality of rllib. See &lt;denchmark-link:https://github.com/ray-project/ray/issues/7843&gt;#7843&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='pengzhenghao' date='2020-04-13T07:49:29Z'>
		Issue is fixed in 0.8.4
		</comment>
	</comments>
</bug>