<bug id='12227' author='ericl' open_date='2020-11-21T07:29:58Z' closed_time='2020-12-03T21:39:05Z'>
	<summary>[tune] "Too many open files" with Tune sync after 4000 trials completed</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

After 4000 trials completed, the Tune job crashed with:
&lt;denchmark-code&gt;2020-11-21 02:02:05,077 ERROR syncer.py:190 -- Sync execution failed.
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/syncer.py", line 187, in sync_down
    self._local_dir)
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/sync_client.py", line 197, in sync_down
    return self._execute(self.sync_down_template, source, target)
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/sync_client.py", line 243, in _execute
    final_cmd, shell=True, stderr=subprocess.PIPE, stdout=self.logfile)
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/subprocess.py", line 729, in __init__
    restore_signals, start_new_session)
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/subprocess.py", line 1254, in _execute_child
    errpipe_read, errpipe_write = os.pipe()
OSError: [Errno 24] Too many open files
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/bin/rllib", line 8, in &lt;module&gt;
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/rllib/scripts.py", line 34, in cli
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/rllib/train.py", line 215, in run
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/tune.py", line 496, in run_experiments
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/tune.py", line 415, in run
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 361, in step
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/callback.py", line 180, in on_trial_start
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/logger.py", line 428, in on_trial_start
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ray/tune/logger.py", line 635, in log_trial_start
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorboardX/writer.py", line 275, in __init__
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorboardX/writer.py", line 327, in _get_file_writer
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorboardX/writer.py", line 95, in __init__
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorboardX/event_file_writer.py", line 105, in __init__
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/multiprocessing/context.py", line 102, in Queue
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/multiprocessing/queues.py", line 42, in __init__
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/multiprocessing/context.py", line 67, in Lock
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/multiprocessing/synchronize.py", line 162, in __init__
  File "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/multiprocessing/synchronize.py", line 59, in __init__
OSError: [Errno 24] Too many open files
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

rllib train --run=PPO --env=Pong-v0 --config='{"num_workers": 16, "num_sgd_iter": 1}' --num-samples=10000 --stop='{"timesteps_total": 1}' --ray-address=auto
cc &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='ericl' date='2020-11-21T21:00:15Z'>
		Thanks for the report; we should definitely add to the release tests when we have time (cc &lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='2' author='ericl' date='2020-11-25T04:42:35Z'>
		A simple run (200 trial, 200 iter) seems to suggest that this is not due to a tune file management issue but rather a gcs_server fd leak, as seen in &lt;denchmark-link:https://github.com/ray-project/ray/issues/11713&gt;#11713&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='ericl' date='2020-11-25T04:44:19Z'>
		This is P2 since &lt;denchmark-link:https://github.com/ray-project/ray/issues/11713&gt;#11713&lt;/denchmark-link&gt;
 is possibly the main culprit and is also P2.
		</comment>
		<comment id='4' author='ericl' date='2020-11-25T04:54:24Z'>
		&lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 are you sure this isn't due to file sync? That bug you linked triggers on high rate of actors created. However this job failed only after a long time, when the number of trials results got too large.
		</comment>
		<comment id='5' author='ericl' date='2020-11-25T07:30:23Z'>
		Hmmm, i ran a couple distributed workloads just now but file sync didn't show any growth of fds.
I just ran this rllib command you posted but i'm seeing a lot of:
&lt;denchmark-code&gt;(pid=raylet, ip=172.31.23.185) Error in atexit._run_exitfuncs:
(pid=raylet, ip=172.31.23.185) Traceback (most recent call last):
(pid=raylet, ip=172.31.23.185)   File "/root/anaconda3/lib/python3.7/logging/__init__.py", line 2037, in shutdown
(pid=raylet, ip=172.31.23.185)     h.close()
(pid=raylet, ip=172.31.23.185)   File "/root/anaconda3/lib/python3.7/site-packages/absl/logging/__init__.py", line 945, in close
(pid=raylet, ip=172.31.23.185)     self.stream.close()
(pid=raylet, ip=172.31.23.185) AttributeError: 'StandardStreamInterceptor' object has no attribute 'close'
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>