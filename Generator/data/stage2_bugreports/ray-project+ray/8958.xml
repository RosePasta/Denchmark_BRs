<bug id='8958' author='arunmk' open_date='2020-06-16T01:50:57Z' closed_time='2020-09-14T06:40:49Z'>
	<summary>Kubernetes: GPU Resource Detection is not correct</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray 0.8.0, 0.8.5
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

This is simple, use a kubernetes install wherein the pod CPU does not match the host CPU. In the pod, run a python shell (kubectl exec -it &lt;pod name&gt; -- python) and try:
ray.available_resources() ray.cluster_resources()
These will report the host resources and not the pod resources. The incorrect details are for CPU, memory and GPU.
	</description>
	<comments>
		<comment id='1' author='arunmk' date='2020-06-18T19:02:22Z'>
		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
 Probably related to the Docker issue that doesn't show the correct resources information?
		</comment>
		<comment id='2' author='arunmk' date='2020-06-19T21:16:51Z'>
		cc &lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='arunmk' date='2020-06-19T22:27:37Z'>
		I"m looking into this
		</comment>
		<comment id='4' author='arunmk' date='2020-06-19T22:34:44Z'>
		Btw this is somewhat strange, because we attempt to explicitly check for this. Maybe we just aren't doing it correctly? 


ray/python/ray/utils.py


         Line 406
      in
      2589309






 docker_limit = int(f.read()) 





		</comment>
		<comment id='5' author='arunmk' date='2020-06-19T23:09:02Z'>
		&lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
  That appears to work locally--in the sense that when Ray starts the correct amount is printed. The data for  and  comes from GCS.
		</comment>
		<comment id='6' author='arunmk' date='2020-06-20T00:05:05Z'>
		Actually, for what it's worth if I run ray.cluster_resources() on my computer (no container), I actually get incorrect information :/
^^This is because Memory is in 50MB increments, it is otherwise fine.
		</comment>
		<comment id='7' author='arunmk' date='2020-06-20T00:26:43Z'>
		Could be related: &lt;denchmark-link:https://github.com/ray-project/ray/issues/8983#issuecomment-646316576&gt;#8983 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/ray-project/ray/issues/8983#issuecomment-646450764&gt;#8983 (comment)&lt;/denchmark-link&gt;

Also, (I guess we already calculate this programmatically, but just in case)
&lt;denchmark-code&gt;Worker heap: memory used by your application (e.g., in Python code or TensorFlow), best measured as the resident set size (RSS) of your application minus its shared memory usage (SHR) in commands such as top. The reason you need to subtract SHR is that object store shared memory is reported by the OS as shared with each worker. Not subtracting SHR will result in double counting memory usage.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='arunmk' date='2020-06-20T01:36:57Z'>
		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
 to be clear, the issue is that the containers report resources of the host. I give 2 containers 2 cores each in the cluster but the API reports 24 instead of 4. My host has 24 cores.
		</comment>
		<comment id='9' author='arunmk' date='2020-06-20T03:58:56Z'>
		In kubernetes you might be putting resource requests and limits for 2 CPUs, but this is soft and not seen for real inside the pod, it just sees what the host has. If you want ray to respect the 2 CPU you would need ray to read what you set in the pod definition under resources or set that as an env variable that ray uses.
		</comment>
		<comment id='10' author='arunmk' date='2020-06-20T14:36:49Z'>
		&lt;denchmark-link:https://github.com/virtualluke&gt;@virtualluke&lt;/denchmark-link&gt;
 that is also done. For example, my worker spec is as follows:
&lt;denchmark-link:https://github.com/ray-project/ray/files/4808050/ray-worker-deployment.yaml.txt&gt;ray-worker-deployment.yaml.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='arunmk' date='2020-06-22T13:50:25Z'>
		in your example I believe what you would want is $MY_CPU_REQUEST matching what you have in your yaml under resources (where you have 2000m), except my guess is the behavior you want is for it to match not under resources-&gt;requests but resources-&gt;limits (which you don't have).
		</comment>
		<comment id='12' author='arunmk' date='2020-06-22T14:10:58Z'>
		&lt;denchmark-link:https://github.com/virtualluke&gt;@virtualluke&lt;/denchmark-link&gt;
 yes, exactly. In ray-head, I want the sum of all of the limits values of the workers joined into the cluster for cluster_resources().
		</comment>
		<comment id='13' author='arunmk' date='2020-06-22T16:45:29Z'>
		&lt;denchmark-link:https://github.com/arunmk&gt;@arunmk&lt;/denchmark-link&gt;
 can you show the full output from ?
		</comment>
		<comment id='14' author='arunmk' date='2020-06-22T18:34:15Z'>
		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
 this is what I get from prints from ray-head pod:
2020-06-16 01:52:25 INFO     Available ray resources: [{'CPU': 23.0, (pid=225)  'memory': 883.0, (pid=225)  'node:172.17.0.12': 1.0, (pid=225)  'object_store_memory': 304.0}]
 2020-06-16 01:52:25 INFO     Ray resources currently: [{'CPU': 24.0, (pid=225)  'memory': 883.0, (pid=225)  'node:172.17.0.12': 1.0, (pid=225)  'object_store_memory': 304.0}]
		</comment>
		<comment id='15' author='arunmk' date='2020-06-22T19:50:04Z'>
		Okay--thanks and what is your head spec?
		</comment>
		<comment id='16' author='arunmk' date='2020-06-23T16:23:15Z'>
		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
 attached.
&lt;denchmark-link:https://github.com/ray-project/ray/files/4820620/ray-head-deployment.yaml.txt&gt;ray-head-deployment.yaml.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/ray-project/ray/files/4820622/ray-worker-deployment.yaml.txt&gt;ray-worker-deployment.yaml.txt&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/ray-project/ray/files/4820623/start_ray_driver.sh.txt&gt;start_ray_driver.sh.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='arunmk' date='2020-06-23T17:56:29Z'>
		&lt;denchmark-link:https://github.com/arunmk&gt;@arunmk&lt;/denchmark-link&gt;
 when you're calling  are you calling  to connect to the running cluster? One reason you might be seeing all CPUs used is if you're just calling .
		</comment>
		<comment id='18' author='arunmk' date='2020-06-23T22:47:11Z'>
		&lt;denchmark-link:https://github.com/edoakes&gt;@edoakes&lt;/denchmark-link&gt;
 that did the trick! Thanks!
My fundamental issue was with getting the right number of GPUs. Will this API call provide accurate GPU numbers as well?
		</comment>
		<comment id='19' author='arunmk' date='2020-06-24T01:01:37Z'>
		&lt;denchmark-link:https://github.com/edoakes&gt;@edoakes&lt;/denchmark-link&gt;
 thanks, I can now see the GPUs as well, but the count is incorrect. I have a GCP node with 2 V100 GPUs connected to it. I have a small ray cluster which has one ray head and two workers. Each worker uses one GPU:
&lt;denchmark-code&gt;- args:
    - ray start --redis-password='password' --num-cpus=$MY_CPU_REQUEST --num-gpus=$MY_GPU_REQUEST
      --memory=8589934592 --object-store-memory=4294967296 --node-ip-address=$MY_POD_IP
      --address=${RAY_HEAD_SERVICE_HOST}:${RAY_HEAD_SERVICE_PORT_REDIS_PRIMARY} --object-manager-port=12345
      --node-manager-port=12346 --block
    command:
    - /bin/bash
    - -c
    - --
    env:
    - name: MY_POD_IP
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: status.podIP
    - name: MY_CPU_REQUEST
      valueFrom:
        resourceFieldRef:
          divisor: "0"
          resource: requests.cpu
    - name: MY_GPU_REQUEST
      value: "1"
    image: continual/engine
    imagePullPolicy: IfNotPresent
    name: ray-worker
    ports:
    - containerPort: 12345
      protocol: TCP
    - containerPort: 12346
      protocol: TCP
    resources:
      limits:
        nvidia.com/gpu: "1"
      requests:
        cpu: "2"
        memory: 10Gi
        nvidia.com/gpu: "1"

&lt;/denchmark-code&gt;

However the available and cluster resources shows 4 GPUs:
(pid=23, ip=172.17.0.8) 2020-06-24 00:54:58 INFO     Available ray resources: [{'CPU': 3.0, (pid=23, ip=172.17.0.8)  'GPU': 4.0, (pid=23, ip=172.17.0.8)  'memory': 1194.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.4': 1.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.6': 1.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.8': 1.0, (pid=23, ip=172.17.0.8)  'object_store_memory': 411.0}] (pid=23, ip=172.17.0.8) 2020-06-24 00:54:58 INFO     Ray resources currently: [{'CPU': 4.0, (pid=23, ip=172.17.0.8)  'GPU': 4.0, (pid=23, ip=172.17.0.8)  'memory': 1194.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.4': 1.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.6': 1.0, (pid=23, ip=172.17.0.8)  'node:172.17.0.8': 1.0, (pid=23, ip=172.17.0.8)  'object_store_memory': 411.0}]
Do you know what could be going on?
		</comment>
		<comment id='20' author='arunmk' date='2020-06-24T01:37:23Z'>
		&lt;denchmark-link:https://github.com/edoakes&gt;@edoakes&lt;/denchmark-link&gt;
 I tried without any GPUs mentioned in the kubernetes yamls. On a gpu enabled machine, I still see the GPUs of the host. (2GPUs):

Should this be passed through the ray-head alone (as per &lt;denchmark-link:https://docs.ray.io/en/ray-0.8.5/using-ray-with-gpus.html&gt;https://docs.ray.io/en/ray-0.8.5/using-ray-with-gpus.html&lt;/denchmark-link&gt;
)? I have a config where I have a very lightweight ray-head and only workers have GPUs. So it would be tough for the ray-head to compute the resources of a cluster. Also, the k8s cluster could be dynamic with nodes joining and leaving at any point, so having a static config as part of ray-head would not work. In the current case, there is no mention of GPUs in ray-head.
		</comment>
		<comment id='21' author='arunmk' date='2020-07-03T13:02:25Z'>
		May I ask a related question.
What is the unit for 'object_store_memory' in the output from ray.cluster_resource()? It seems not equal to the bytes in 'ray start' above. 'ray start --redis-password='password' --num-cpus=$MY_CPU_REQUEST --num-gpus=$MY_GPU_REQUEST --memory=8589934592 --object-store-memory=4294967296 ....'
		</comment>
		<comment id='22' author='arunmk' date='2020-07-06T18:26:26Z'>
		&lt;denchmark-link:https://github.com/YuejiYang&gt;@YuejiYang&lt;/denchmark-link&gt;
 it is in bytes I think. Is there some documentation on what it should be set to and how one goes about estimating these values?
		</comment>
		<comment id='23' author='arunmk' date='2020-07-07T01:21:36Z'>
		ray.cluster_resources() and ray.available_resources() will be in bytes/gigabytes soon.
		</comment>
		<comment id='24' author='arunmk' date='2020-07-07T01:21:49Z'>
		&lt;denchmark-link:https://github.com/arunmk&gt;@arunmk&lt;/denchmark-link&gt;
 After several testing, I found the ray.cluster_resource() returns object_store_memory in 100MB per unit and memory in 50MB per unit.  It is in bytes for "ray start --object-store-memory=.......".
I did not find any related documentation:(. So it is confusing. Could you please refer me to any documentation if you saw any. Thank you!
		</comment>
		<comment id='25' author='arunmk' date='2020-07-10T07:22:12Z'>
		&lt;denchmark-link:https://github.com/arunmk&gt;@arunmk&lt;/denchmark-link&gt;
 Hi there. I encountered the same problem that the number of GPUs is showed incorrectly. Do you fix it?
Concretely, when I specify ,  is always showing the whole GPUs in my host. However, if I specify , then  shows correct resources.
Is there any way to make  start correct resources?
		</comment>
		<comment id='26' author='arunmk' date='2020-07-15T03:39:44Z'>
		
@arunmk Hi there. I encountered the same problem that the number of GPUs is showed incorrectly. Do you fix it?
Concretely, when I specify ray start --num-gpus=x, ray.cluster_resources() is always showing the whole GPUs in my host. However, if I specify ray.init(num_gpus=x), then ray.cluster_resources() shows correct resources.
Is there any way to make ray start --num-gpus=x start correct resources?

I got the same issue, if I specify --num-cpus, --num-gpus(--num-gpus=0 is also import, if you do not specify, ray will read the gpu numbers from the host) and --memory the request resource/total resource seems correct.
		</comment>
		<comment id='27' author='arunmk' date='2020-07-26T06:32:33Z'>
		&lt;denchmark-link:https://github.com/barakmich&gt;@barakmich&lt;/denchmark-link&gt;
 I will assign it to you now since you asked last time!
		</comment>
	</comments>
</bug>