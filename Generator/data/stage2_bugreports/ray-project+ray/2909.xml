<bug id='2909' author='whikwon' open_date='2018-09-19T01:09:57Z' closed_time='2018-09-27T05:32:30Z'>
	<summary>[rllib] ARS optimizer differs from paper</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
Ray installed from (source or binary): source
Ray version: 0.5.2
Python version: 3.6.3
Exact command to reproduce:

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

In the ars.py code, the model use Adam optimizer for training. When I looked into the &lt;denchmark-link:https://arxiv.org/pdf/1803.07055.pdf&gt;paper&lt;/denchmark-link&gt;
, SGD was used for training.
Is there any reason or experimental result for using Adam rather than SGD?
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='whikwon' date='2018-09-19T04:37:07Z'>
		I believe this code is directly adapted from the reference implemention cc &lt;denchmark-link:https://github.com/eugenevinitsky&gt;@eugenevinitsky&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='whikwon' date='2018-09-19T04:43:42Z'>
		This is a mistake; thank you for catching it. The reference code used SGD as you pointed out, but Evolutionary Strategies used ADAM and that wound up getting copied over. I will push a fix shortly.
		</comment>
		<comment id='3' author='whikwon' date='2018-09-19T16:27:10Z'>
		&lt;denchmark-link:https://github.com/whikwon&gt;@whikwon&lt;/denchmark-link&gt;
 PR for this will be up shortly
		</comment>
	</comments>
</bug>