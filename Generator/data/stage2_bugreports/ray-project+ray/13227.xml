<bug id='13227' author='herunyu' open_date='2021-01-06T06:31:04Z' closed_time='2021-01-09T12:11:18Z'>
	<summary>PolicyServerInput with num_workers = 1 will have AttributeError</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

PolicyServerInput with num_workers = 1 will have AttributeError
Ray version and other system information (Python version, TensorFlow version, OS):

ray: 1.1.0
python: 3.8.5
tensorflow:  2.3.1
OS: macOS 11.1 or Ubuntu 20.04.1 LTS

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a short code snippet (less than 50 lines if possible) that can be copy-pasted to reproduce the issue. The snippet should have no external library dependencies (i.e., use fake or mock data / environments):
env = "CartPole-v0"
    connector_config = {
        # Use the connector server to generate experiences.
        "input": (
            lambda ioctx: PolicyServerInput(ioctx, SERVER_ADDRESS, SERVER_PORT)
        ),
        # Use a single worker process to run the server.
        "num_workers": 1,
        # Disable OPE, since the rollouts are coming from online clients.
        "input_evaluation": [],
    }

trainer = PPOTrainer(
            env=env,
            config=dict(
                connector_config, **{
                    "rollout_fragment_length": 1000,
                    "train_batch_size": 4000,
                    "framework": args.framework,
                }))

checkpoint_path = CHECKPOINT_FILE.format(args.run)

    # Attempt to restore from checkpoint if possible.
    if os.path.exists(checkpoint_path):
        checkpoint_path = open(checkpoint_path).read()
        print("Restoring from checkpoint path", checkpoint_path)
        trainer.restore(checkpoint_path)

    # Serving and training loop
    while True:
        print(pretty_print(trainer.train()))
        checkpoint = trainer.save()
        print("Last checkpoint", checkpoint)
        with open(checkpoint_path, "w") as f:
            f.write(checkpoint)
If the code snippet cannot be run by itself, the issue will be closed with "needs-repro-script".

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

When I set num_workers to 1 it will give an AttributeError as follow:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

WARNING:tensorflow:From /Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2021-01-06 14:09:10,810 INFO services.py:1171 -- View the Ray dashboard at &lt;denchmark-link:http://127.0.0.1:8265&gt;http://127.0.0.1:8265&lt;/denchmark-link&gt;

2021-01-06 14:09:12,882 INFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution
2021-01-06 14:09:12,883 INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
(pid=49831) WARNING:tensorflow:From /Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
(pid=49831) Instructions for updating:
(pid=49831) non-resource variables are not supported in the long term
(pid=49831) 2021-01-06 14:09:19,552     INFO policy_server_input.py:89 --
(pid=49831) 2021-01-06 14:09:19,552     INFO policy_server_input.py:90 -- Starting connector server at localhost:9900
(pid=49831) 2021-01-06 14:09:19,552     INFO policy_server_input.py:91 --
Traceback (most recent call last):
File "cartpole_server.py", line 54, in 
trainer = PPOTrainer(
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py", line 106, in 
Trainer.(self, config, env, logger_creator)
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/agents/trainer.py", line 465, in 
super().(config, logger_creator)
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/tune/trainable.py", line 96, in 
self.setup(copy.deepcopy(self.config))
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
self._init(self.config, self.env_creator)
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py", line 133, in _init
self.workers = self._make_workers(
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/agents/trainer.py", line 700, in _make_workers
return WorkerSet(
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py", line 87, in 
self._local_worker = self._make_worker(
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py", line 315, in _make_worker
worker = cls(
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py", line 607, in 
self.input_reader: InputReader = input_creator(self.io_context)
File "cartpole_server.py", line 34, in 
lambda ioctx: PolicyServerInput(ioctx, SERVER_ADDRESS, SERVER_PORT)
File "/Users/hyt/miniconda3/envs/ray/lib/python3.8/site-packages/ray/rllib/env/policy_server_input.py", line 84, in 
self.rollout_worker.sampler.get_metrics = get_metrics
AttributeError: 'NoneType' object has no attribute 'get_metrics'
	</description>
	<comments>
		<comment id='1' author='herunyu' date='2021-01-08T07:04:09Z'>
		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
 can you take a look?
		</comment>
		<comment id='2' author='herunyu' date='2021-01-09T12:11:18Z'>
		Thanks for filing this issue &lt;denchmark-link:https://github.com/herunyu&gt;@herunyu&lt;/denchmark-link&gt;
 ! I can reproduce this. However, I'm not sure what the purpose of rollout workers (num_workers &gt; 0), would be here. The server process is basically the learner (local_worker) and the client(s) are the rollout workers.
Sure, you could argue that you need a mixed setup with some rollout workers remote and others running on the server side.
Either way, you can fix this error by setting "create_env_on_driver": True in your Trainer's config. This will make sure that a Sampler object (with environment) is created either way on the local worker (driver) no matter whether you set num_workers &gt;0 or not.
		</comment>
		<comment id='3' author='herunyu' date='2021-01-10T08:31:17Z'>
		Oh I see. I thought that if I can make multiple servers I can utilize the power of ray to train the model in parallel. According to what you said, it doesn’t really matter if using 1 num workers or more than 1, am I right? Does that mean that I cannot use parallelism to train the model?

获取 Outlook for iOS&lt;&lt;denchmark-link:https://aka.ms/o0ukef&gt;https://aka.ms/o0ukef&lt;/denchmark-link&gt;
&gt;
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


________________________________
发件人: Sven Mika &lt;notifications@github.com&gt;
发送时间: Saturday, January 9, 2021 8:11:31 PM
收件人: ray-project/ray &lt;ray@noreply.github.com&gt;
抄送: Runyu He &lt;herunyu@berkeley.edu&gt;; Mention &lt;mention@noreply.github.com&gt;
主题: Re: [ray-project/ray] PolicyServerInput with num_workers = 1 will have AttributeError (#13227)


Thanks for filing this issue @herunyu&lt;https://github.com/herunyu&gt; ! I can reproduce this. However, I'm not sure what the purpose of rollout workers (num_workers &gt; 0), would be here. The server process is basically the learner (local_worker) and the client(s) are the rollout workers.
Sure, you could argue that you need a mixed setup with some rollout workers remote and others running on the server side.

Either way, you can fix this error by setting "create_env_on_driver": True in your Trainer's config. This will make sure that a Sampler object (with environment) is created either way on the local worker (driver) no matter whether you set num_workers &gt;0 or not.

―
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub&lt;#13227 (comment)&gt;, or unsubscribe&lt;https://github.com/notifications/unsubscribe-auth/ABGKQ2WS5O44YLRBCRTGMSTSZBBXHANCNFSM4VXBA3CA&gt;.

		</comment>
		<comment id='4' author='herunyu' date='2021-01-13T02:01:47Z'>
		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
 Would you mind taking a few minutes to take a look at my question？Really appreciated it!
		</comment>
	</comments>
</bug>