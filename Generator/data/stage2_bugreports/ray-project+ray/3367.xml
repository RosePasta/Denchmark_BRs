<bug id='3367' author='dwilson1988' open_date='2018-11-20T22:41:44Z' closed_time='2018-11-24T06:51:09Z'>
	<summary>Using LSTM model raises ValueError with custom model</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Ubuntu 16.04
Ray installed from source
Ray version 0.5.3
Python version 3.6.6

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Hello,
I'm running into an issue. I have an environment that has a Dict observation_space with multiple components that get processes by a custom model (built with tensorflow). I wanted to stack this model with an LSTM afterwards, but I'm getting an error. The last two layers of my custom model look like:
def _build_layers_v2(self,inputs, num_outputs, options):
        ...
        last_layer = slim.fully_connected(concatenated,256)
        output = slim.linear(last_layer,num_outputs)
        return output, last_layer
So you can see my last layer has a size of [?,256]. This seems to be causing trouble when the LSTM is added:
&lt;denchmark-code&gt;~/miniconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/agents/ppo/ppo_policy_graph.py in __init__(self, observation_space, action_space, config, existing_inputs)
    165             self.config["model"],
    166             state_in=existing_state_in,
--&gt; 167             seq_lens=existing_seq_lens)
    168 
    169         # KL Coefficient

~/miniconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/models/catalog.py in get_model(input_dict, obs_space, num_outputs, options, state_in, seq_lens)
    202             copy["obs"] = model.last_layer
    203             model = LSTM(copy, obs_space, num_outputs, options, state_in,
--&gt; 204                          seq_lens)
    205 
    206         logger.debug("Created model {}: ({} of {}, {}, {}) -&gt; {}, {}".format(

~/miniconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/models/model.py in __init__(self, input_dict, obs_space, num_outputs, options, state_in, seq_lens)
     69         try:
     70             self.outputs, self.last_layer = self._build_layers_v2(
---&gt; 71                 _restore_original_dimensions(input_dict, obs_space),
     72                 num_outputs, options)
     73         except NotImplementedError:

~/miniconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/models/model.py in _restore_original_dimensions(input_dict, obs_space)
    164         return dict(
    165             input_dict,
--&gt; 166             obs=_unpack_obs(input_dict["obs"], obs_space.original_space))
    167     return input_dict
    168 

~/miniconda3/envs/rl/lib/python3.6/site-packages/ray/rllib/models/model.py in _unpack_obs(obs, space)
    175             raise ValueError(
    176                 "Expected flattened obs shape of [None, {}], got {}".format(
--&gt; 177                     prep.shape[0], obs.shape))
    178         assert len(prep.preprocessors) == len(space.spaces), \
    179             (len(prep.preprocessors) == len(space.spaces))

ValueError: Expected flattened obs shape of [None, 589], got (?, 256)
&lt;/denchmark-code&gt;

I believe this is happening because it's trying to flatten the observation tensor, but obviously since this is the last layer of my custom model, it's not of the dimensions of the observation space. The dimensionality of my observation space is 589, so I'm guessing that's why it's expecting that shape.
&lt;denchmark-code&gt;config = {
    'model': {
        'custom_model': 'my_model',
        'use_lstm': True,
        'lstm_cell_size': 256    
    },
}
&lt;/denchmark-code&gt;

Am I doing something wrong or is a bug? I'm using the latest from the repo at the moment. Should I be using the latest wheel instead? I need support for Dict spaces and not sure when that was added.
	</description>
	<comments>
		<comment id='1' author='dwilson1988' date='2018-11-20T23:06:56Z'>
		Thanks for reporting this. &lt;denchmark-link:https://github.com/dwilson1988&gt;@dwilson1988&lt;/denchmark-link&gt;
 could you see if this fixes it? &lt;denchmark-link:https://github.com/ray-project/ray/pull/3368&gt;#3368&lt;/denchmark-link&gt;

Btw, the latest wheels are usually up-to-date with master.
		</comment>
		<comment id='2' author='dwilson1988' date='2018-11-20T23:24:59Z'>
		Thanks for the fast turn around! Tested and it appears to be working. I don't have everything fully functioning on my end, so I can't do an end to end test just yet, but that fixed my bug and I was able to create my agent.
Also looked at the code and the implementation definitely makes sense to me. Thanks!
		</comment>
	</comments>
</bug>