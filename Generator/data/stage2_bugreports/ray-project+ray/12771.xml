<bug id='12771' author='wuisawesome' open_date='2020-12-11T01:25:56Z' closed_time='2020-12-15T21:49:46Z'>
	<summary>[Autoscaler] Startup logs are missing</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Unsure when this happened, but autoscaler logs were originally written to monitor.out, but were moved to their own separate log files (per node). Now they don't seem to exist at all.
This seems to be easy to reproduce (pick your favorite yaml), mine is attached below.
&lt;denchmark-code&gt;# Experimental: an example of configuring a mixed-node-type cluster.
cluster_name: alex
min_workers: 2
max_workers: 40

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-1
    availability_zone: us-west-1a

# Tell the autoscaler the allowed node types and the resources they provide.
# The key is the name of the node type, which is just for debugging purposes.
# The node config specifies the launch config and physical instance type.
available_node_types:
    cpu_4_ondemand:
        node_config:
            InstanceType: m4.xlarge
        # For AWS instances, autoscaler will automatically add the available
        # CPUs/GPUs/accelerator_type ({"CPU": 4} for m4.xlarge) in "resources".
        resources: {"CPU": 4}
        min_workers: 2
        max_workers: 5
    custom1:
        node_config:
            InstanceType: m4.4xlarge
            InstanceMarketOptions:
                MarketType: spot
        resources: {"Custom1": 1}
        max_workers: 10
    custom2:
        node_config:
            InstanceType: m4.4xlarge
            InstanceMarketOptions:
                MarketType: spot
        resources: {"Custom2": 2}
        max_workers: 4

# Specify the node type of the head node (as configured above).
head_node_type: cpu_4_ondemand

# Specify the default type of the worker node (as configured above).
worker_default_node_type: cpu_4_ondemand

# The default settings for the head node. This will be merged with the per-node
# type configs given above.
head_node:
    ImageId: latest_dlami

# The default settings for worker nodes. This will be merged with the per-node
# type configs given above.
worker_nodes:
    ImageId: latest_dlami

setup_commands:
    - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl
    - git clone --branch autoscaler_formatted_report https://github.com/wuisawesome/ray.git || true
    - pushd ray; git reset --hard; popd;
    - ray/python/ray/setup-dev.py -y 
    - rm /home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/monitor.py
    - ln -s /home/ubuntu/ray/python/ray/monitor.py /home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/monitor.py


# Configure the cluster for very conservative auto-scaling otherwise.
target_utilization_fraction: 1.0
idle_timeout_minutes: 2

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
&lt;/denchmark-code&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a short code snippet (less than 50 lines if possible) that can be copy-pasted to reproduce the issue. The snippet should have no external library dependencies (i.e., use fake or mock data / environments):
If the code snippet cannot be run by itself, the issue will be closed with "needs-repro-script".

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='wuisawesome' date='2020-12-11T01:26:18Z'>
		cc &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 could this be related to cli logger changes?
cc &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='wuisawesome' date='2020-12-13T05:18:47Z'>
		&lt;denchmark-link:https://github.com/ray-project/ray/commit/f669830de6ae9f93ae4f81b921a667a33e53fc0d&gt;f669830&lt;/denchmark-link&gt;
 (dec 3) does not work
11:59
&lt;denchmark-link:https://github.com/ray-project/ray/commit/234df9091e57f2a4d7574e2ae53635bb5c862b9e&gt;234df90&lt;/denchmark-link&gt;
 (nov 30) works
12:03
&lt;denchmark-link:https://github.com/ray-project/ray/commit/da42bf29d07141c61948bd78cad936548fc47911&gt;da42bf2&lt;/denchmark-link&gt;
 (dec 1) does not work
Richard Liaw  3:38 PM
&lt;denchmark-link:https://github.com/ray-project/ray/commit/8223a33bff9b8d0e736571c9808b27dc2e2a74f5&gt;8223a33&lt;/denchmark-link&gt;
 is the source of error
		</comment>
		<comment id='3' author='wuisawesome' date='2020-12-13T05:25:40Z'>
		Have a couple questions for fix

what do you mean by log file per node? Isn’t autoscaler log supposed to be only at a head node?
also what do you mean by “its own log files”?

		</comment>
	</comments>
</bug>