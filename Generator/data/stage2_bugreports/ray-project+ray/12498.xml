<bug id='12498' author='PidgeyBE' open_date='2020-11-30T11:38:34Z' closed_time='2020-12-09T02:41:31Z'>
	<summary>[autoscaler] Request_resources and actual actors are counted double</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version and other system information (Python version, TensorFlow version, OS):

Ray nightly
k8s autoscaling

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

I have an autoscaling cluster with:
&lt;denchmark-code&gt;available_node_types:
    def_head:
        node_config: {}
        resources: {"CPU": 2}
        max_workers: 1
    def_worker:
        node_config: {}
        resources: {"CPU": 2, "GPU": 1,  "WORKER": 1}
        max_workers: 3
&lt;/denchmark-code&gt;

Then I run:
&lt;denchmark-code&gt;import os
import ray
from ray.autoscaler.sdk import request_resources

ray.init(address="auto")

@ray.remote(num_cpus=0.2, resources={"WORKER": 1.0})
class ActorA:
    def __init__(self):
        pass

# 1. Request resource bundle
request_resources(bundles=[{"CPU": 0.2, "WORKER": 1.0}])
&lt;/denchmark-code&gt;


Wait untill worker is online and then start actor

&lt;denchmark-code&gt;a = ActorA.remote()
&lt;/denchmark-code&gt;

-&gt; I see a second worker is scaled up, this is not needed, as the actor consumes exactly the same resources as requested before.

Request same resources again

&lt;denchmark-code&gt;request_resources(bundles=[{"CPU": 0.2, "WORKER": 1.0}])

&lt;/denchmark-code&gt;

-&gt; I see a third worker is scaled up. This should not happen. Edit: I could not reproduce this step, so possibly the third worker is a race condition
After some time 1 or 2 workers are scaled down and immediately an extra worker is scaled up again. This bouncing behavior keeps going.
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
	</comments>
</bug>