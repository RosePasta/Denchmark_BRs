<bug id='3190' author='robertnishihara' open_date='2018-11-01T22:08:13Z' closed_time='2019-10-24T20:13:42Z'>
	<summary>[autoscaler] Nodes other than the head node are not starting up.</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Launching from MacOS, but starting Ubuntu 16 (with deep learning AMI)
Ray installed from (source or binary): source
Ray version: current master
Python version: 3.6

My autoscaler config is
&lt;denchmark-code&gt;# An unique identifier for the head node and workers of this cluster.
cluster_name: default

min_workers: 200

max_workers: 200

docker:
    image: "" # e.g., tensorflow/tensorflow:1.5.0-py3
    container_name: "" # e.g. ray_docker

target_utilization_fraction: 0.8

idle_timeout_minutes: 5

provider:
    type: aws
    region: us-west-2
    availability_zone: us-west-2a,us-west-2b

auth:
    ssh_user: ubuntu

head_node:
    InstanceType: m5.2xlarge
    ImageId: ami-3b6bce43  # Amazon Deep Learning AMI (Ubuntu)

    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 50

worker_nodes:
    InstanceType: m5.large
    ImageId: ami-3b6bce43  # Amazon Deep Learning AMI (Ubuntu)

    InstanceMarketOptions:
        MarketType: spot

file_mounts: {}

setup_commands:
    - echo 'export PATH="$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH"' &gt;&gt; ~/.bashrc
    - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.5.3-cp36-cp36m-manylinux1_x86_64.whl

head_setup_commands:
    - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions

worker_setup_commands: []

head_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

worker_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076
&lt;/denchmark-code&gt;

The head node starts up fine. When I ssh to it and print the monitor logs, I see the following.
No nodes other than the head node start up.
&lt;denchmark-code&gt;ubuntu@ip-172-31-22-20:/tmp/ray/session_2018-11-01_22-01-45_16654/logs$ cat monitor.err
StandardAutoscaler: {'cluster_name': 'mastertest', 'min_workers': 200, 'max_workers': 200, 'docker': {'image': '', 'container_name': ''}, 'target_utilization_fraction': 0.8, 'idle_timeout_minutes': 5, 'provider': {'type': 'aws', 'region': 'us-west-2', 'availability_zone': 'us-west-2a,us-west-2b'}, 'auth': {'ssh_user': 'ubuntu', 'ssh_private_key': '~/ray_bootstrap_key.pem'}, 'head_node': {'InstanceType': 'm5.2xlarge', 'ImageId': 'ami-3b6bce43', 'BlockDeviceMappings': [{'DeviceName': '/dev/sda1', 'Ebs': {'VolumeSize': 50}}], 'IamInstanceProfile': {'Arn': 'arn:aws:iam::339530224232:instance-profile/ray-autoscaler-v1'}, 'KeyName': 'ray-autoscaler_us-west-2', 'SubnetIds': ['subnet-2154c944', 'subnet-4645f631'], 'SecurityGroupIds': ['sg-030b1764c1812e998']}, 'worker_nodes': {'InstanceType': 'm5.large', 'ImageId': 'ami-3b6bce43', 'InstanceMarketOptions': {'MarketType': 'spot'}, 'IamInstanceProfile': {'Arn': 'arn:aws:iam::339530224232:instance-profile/ray-autoscaler-v1'}, 'KeyName': 'ray-autoscaler_us-west-2', 'SubnetIds': ['subnet-2154c944', 'subnet-4645f631'], 'SecurityGroupIds': ['sg-030b1764c1812e998']}, 'file_mounts': {}, 'setup_commands': ['echo \'export PATH="$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH"\' &gt;&gt; ~/.bashrc'], 'head_setup_commands': ['pip install boto3==1.4.8'], 'worker_setup_commands': [], 'head_start_ray_commands': ['ray stop', 'ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml'], 'worker_start_ray_commands': ['ray stop', 'ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076'], 'no_restart': False}
StandardAutoscaler [2018-11-01 22:01:46.799401]: 0/200 target nodes (0 pending)
 - NodeIdleSeconds: Min=-1 Mean=-1 Max=-1
 - NumNodesConnected: 0
 - NumNodesUsed: 0.0
 - ResourceUsage: 
 - TimeSinceLastHeartbeat: Min=-1 Mean=-1 Max=-1
StandardAutoscaler: Launching 5 new nodes
StandardAutoscaler [2018-11-01 22:01:46.830794]: 0/200 target nodes (5 pending)
 - NodeIdleSeconds: Min=-1 Mean=-1 Max=-1
 - NumNodesConnected: 0
 - NumNodesUsed: 0.0
 - ResourceUsage: 
 - TimeSinceLastHeartbeat: Min=-1 Mean=-1 Max=-1
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py", line 251, in run
    self._launch_node(config, count)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py", line 242, in _launch_node
    }, count)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/aws/node_provider.py", line 163, in create_node
    self.ec2.create_instances(**conf)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/factory.py", line 520, in do_action
    response = action(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/action.py", line 83, in __call__
    response = getattr(parent.meta.client, operation_name)(**params)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py", line 314, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py", line 612, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (UnauthorizedOperation) when calling the RunInstances operation: You are not authorized to perform this operation. Encoded authorization failure message: JUmMphVKvdVLB83WorEP2n5lOkl7LJT5E1K6lCJAxAjpvkJzdk--3vcnRXFh0Yj6Ez-XjrAda9hU472FJ_o2JIzby0EqMD2WD_qg7SqlgmahgDWBSwxOu4uCn_Py-OV1Cwj6XqFy6xJ9QcqsIfttWB9DstSHNQR_8y6SZ0-KYgUzzP51lLcYbTm2CK-D5mghExYd30aoyIV1YQpZ_8JyudvA8JhOFGVNrAIsYK_fT0iqsJOalAeTJAu-TUQNFxzUW6NENFT6xfN3bov6MPB2z0UvnFkMzH9fyerYzUXblO0qzdoEgyfxhcvhnq-7Dd6OJIBlycL5QF2XnR8czqmiSE3aQ09USKgKj1Oaru04EonLCRr64oVKMqpR80jTIGET7TTKDy-qqra-_uS2oQajd0T21V_y__GB7197KlSMi6JPSFHni7H6pZxOp3YTOneNBCydPrHCEmf6OFrbBtD7US-xIo_mW-LWMfHygRINgdAlPTQxBNfCWNpd7Mo9TK_02i0uNQaxR2Eb4sHQgPjWRRyN1gtsEA

StandardAutoscaler [2018-11-01 22:01:51.687415]: 0/200 target nodes (0 pending)
 - NodeIdleSeconds: Min=4 Mean=4 Max=4
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 5 new nodes
StandardAutoscaler [2018-11-01 22:01:51.703377]: 0/200 target nodes (5 pending)
 - NodeIdleSeconds: Min=4 Mean=4 Max=4
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py", line 251, in run
    self._launch_node(config, count)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/autoscaler.py", line 242, in _launch_node
    }, count)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ray/autoscaler/aws/node_provider.py", line 163, in create_node
    self.ec2.create_instances(**conf)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/factory.py", line 520, in do_action
    response = action(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/boto3/resources/action.py", line 83, in __call__
    response = getattr(parent.meta.client, operation_name)(**params)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py", line 314, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/botocore/client.py", line 612, in _make_api_call
    raise error_class(parsed_response, operation_name)
botocore.exceptions.ClientError: An error occurred (UnauthorizedOperation) when calling the RunInstances operation: You are not authorized to perform this operation. Encoded authorization failure message: QOnTis6VbTYrt-07yg40sRrg8_SPtfkGI7lGq8R4bvzaISfzl48BMA5e6PeMiilTnDI40xDfLhJCVrCBIvvPoKljhdk-fssOX9yc174zfGLQRWZZGra1F8P3_bAEaAZn-KlWMZKbfh2XPeMw6U83Lbln2wuEWNaTxydbXyO4ADjz9PUsyXDijXopkp7VylGRBNcQy20718--eGZ5kIZlc5BJ40YTFU9JfaiMGLWTAV_hNcUrB5DOAtklZI4de4tYjxt88imIpp-slkiTbtJXcP4--bU1keOqIgbIP5vZMTrECvo95av4Tyq2BsydvK4PVviQSpqnZ9FlFUJi232jrxNYoH7-meIqGRsU9Xl715WOos2Yorgfqp5KyJn_aaxwWzwdPReN_aaIetpmQHJJtUj6c5R5jiJxtl9LxJNicT47JHvmPyJYb4iYNFHdAUMcrJryQCvZ6aNvz9IiG5ZVXyueSabABGskplcTZkpQ9wEib0kGbMyBncGR9kyAkmHrqOcauAjx1qpGawbrz16JXUED1FZJfQ

StandardAutoscaler [2018-11-01 22:01:56.744077]: 0/200 target nodes (0 pending)
 - NodeIdleSeconds: Min=9 Mean=9 Max=9
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 5 new nodes
StandardAutoscaler [2018-11-01 22:01:56.767962]: 0/200 target nodes (5 pending)
 - NodeIdleSeconds: Min=9 Mean=9 Max=9
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:01.814536]: 0/200 target nodes (5 pending)
 - NodeIdleSeconds: Min=14 Mean=14 Max=14
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 5 new nodes
StandardAutoscaler [2018-11-01 22:02:01.841278]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=14 Mean=14 Max=14
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:06.875743]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=19 Mean=19 Max=19
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:06.893544]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=19 Mean=19 Max=19
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:11.929128]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=24 Mean=24 Max=24
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:11.945196]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=25 Mean=25 Max=25
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:16.983206]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=30 Mean=30 Max=30
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:16.997781]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=30 Mean=30 Max=30
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:22.051389]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=35 Mean=35 Max=35
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:22.067704]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=35 Mean=35 Max=35
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:27.109345]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=40 Mean=40 Max=40
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:27.125878]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=40 Mean=40 Max=40
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler [2018-11-01 22:02:32.157747]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=45 Mean=45 Max=45
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
StandardAutoscaler: Launching 0 new nodes
StandardAutoscaler [2018-11-01 22:02:32.172933]: 0/200 target nodes (10 pending)
 - NodeIdleSeconds: Min=45 Mean=45 Max=45
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/8.0 b'CPU', 0.0/0.0 b'GPU'
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
&lt;/denchmark-code&gt;

For some reason, the non-head nodes are not starting up. Any ideas about this?
	</description>
	<comments>
		<comment id='1' author='robertnishihara' date='2018-11-01T22:09:23Z'>
		cc &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='robertnishihara' date='2018-11-01T22:41:23Z'>
		The error says Unauthorized... Can you check if this works in 0.5.3? I wonder if it's a Ray change or an AWS issue.
		</comment>
		<comment id='3' author='robertnishihara' date='2018-11-01T23:38:24Z'>
		It seems to work for 0.5.3.
EDIT: It also works when you call ray up using the current master, but pip install 0.5.3 on the cluster.
		</comment>
		<comment id='4' author='robertnishihara' date='2018-11-01T23:53:07Z'>
		Ok it might be &lt;denchmark-link:https://github.com/ray-project/ray/pull/3118&gt;#3118&lt;/denchmark-link&gt;

But I don't know why that would be the case.
		</comment>
		<comment id='5' author='robertnishihara' date='2018-11-01T23:53:46Z'>
		Oh, maybe the head doesn't have permission to grant the workers its own profile. We can probably just revert that PR then.
		</comment>
		<comment id='6' author='robertnishihara' date='2019-05-10T01:46:44Z'>
		Hello,
I seem to be hitting this problem. The cluster starts with two workers but doesn't start more even though the two workers are near-100% utilisation.
I'm using ray 0.7.0.dev2 and Python 3.6 on Ubuntu.
My yaml file:
&lt;denchmark-code&gt;# An unique identifier for the head node and workers of this cluster.
cluster_name: default

# The minimum number of workers nodes to launch in addition to the head
# node. This number should be &gt;= 0.
min_workers: 0

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers.
max_workers: 10

# The initial number of worker nodes to launch in addition to the head
# node. When the cluster is first brought up (or when it is refreshed with a
# subsequent `ray up`) this number of nodes will be started.
initial_workers: 2

# Whether or not to autoscale aggressively. If this is enabled, if at any point
#   we would start more workers, we start at least enough to bring us to
#   initial_workers.
# autoscaling_mode: default

# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled.
docker:
    image: "" # e.g., tensorflow/tensorflow:1.5.0-py3
    container_name: "" # e.g. ray_docker
    run_options: []  # Extra options to pass into "docker run"

    # Example of running a GPU head with CPU workers
    # head_image: "tensorflow/tensorflow:1.13.1-py3"
    # head_run_options:
    #     - --runtime=nvidia

    # worker_image: "ubuntu:18.04"
    # worker_run_options: []

# The autoscaler will scale up the cluster to this target fraction of resource
# usage. For example, if a cluster of 10 nodes is 100% busy and
# target_utilization is 0.8, it would resize the cluster to 13. This fraction
# can be decreased to increase the aggressiveness of upscaling.
# This value must be less than 1.0 for scaling to happen.
target_utilization_fraction: 0.8

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 5

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-2
    # Availability zone(s), comma-separated, that nodes may be launched in.
    # Nodes are currently spread between zones by a round-robin approach,
    # however this implementation detail should not be relied upon.
    availability_zone: us-west-2a,us-west-2b

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
# By default Ray creates a new private keypair, but you can also use your own.
# If you do so, make sure to also set "KeyName" in the head and worker node
# configurations below.
#    ssh_private_key: /path/to/your/key.pem

# Provider-specific config for the head node, e.g. instance type. By default
# Ray will auto-configure unspecified fields such as SubnetId and KeyName.
# For more documentation on available fields, see:
# http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
head_node:
    InstanceType: m5.2xlarge
    ImageId: ami-0b5a1e5a79033f015  # ray-cluster-template in us-west-2

    # You can provision additional disk space with a conf as follows
    # BlockDeviceMappings:
    #     - DeviceName: /dev/sda1
    #       Ebs:
    #           VolumeSize: 100

    # Additional options in the boto docs.

# Provider-specific config for worker nodes, e.g. instance type. By default
# Ray will auto-configure unspecified fields such as SubnetId and KeyName.
# For more documentation on available fields, see:
# http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
worker_nodes:
    InstanceType: m5.2xlarge
    ImageId: ami-0b5a1e5a79033f015  # ray-cluster-template in us-west-2

    # Run workers on spot by default. Comment this out to use on-demand.
    InstanceMarketOptions:
        MarketType: spot
        # Additional options can be found in the boto docs, e.g.
        #   SpotOptions:
        #       MaxPrice: MAX_HOURLY_PRICE

    # Additional options in the boto docs.

# Files or directories to copy to the head and worker nodes. The format is a
# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
file_mounts: {
   "/home/ubuntu/HeLa_20KInt-rt-4340-4580-denoised/HeLa_20KInt.sqlite": "/Users/darylwilding-mcbride/Downloads/HeLa_20KInt-rt-4340-4580-denoised/HeLa_20KInt.sqlite",
   "/home/ubuntu/denoised-HeLa_20KInt_2KIT_Slot1-46_01_1179.d/analysis.tdf": "/Users/darylwilding-mcbride/Downloads/denoised-HeLa_20KInt_2KIT_Slot1-46_01_1179.d/analysis.tdf",
   "/home/ubuntu/feature-extraction-from-PASEF-isolation-windows.py": "/Users/darylwilding-mcbride/Documents/otf-peak-detect/experiments/feature-extraction-from-PASEF-isolation-windows.py"
}

# List of commands that will be run before `setup_commands`. If docker is
# enabled, these commands will run outside the container and before docker
# is setup.
initialization_commands: []

# List of shell commands to run to set up nodes.
setup_commands:
    # Note: if you're developing Ray, you probably want to create an AMI that
    # has your Ray repo pre-cloned. Then, you can replace the pip installs
    # below with a git checkout &lt;your_sha&gt; (and possibly a recompile).
    - echo 'hello'
    # - echo 'export PATH="$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH"' &gt;&gt; ~/.bashrc
    # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp27-cp27mu-manylinux1_x86_64.whl
    # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp35-cp35m-manylinux1_x86_64.whl
    # - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.7.0.dev2-cp36-cp36m-manylinux1_x86_64.whl
    # Consider uncommenting these if you also want to run apt-get commands during setup
    # - sudo pkill -9 apt-get || true
    # - sudo pkill -9 dpkg || true
    # - sudo dpkg --configure -a

# Custom commands that will be run on the head node after common setup.
head_setup_commands:
    - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --head --redis-port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076

&lt;/denchmark-code&gt;

A monitor log fragment:
&lt;denchmark-code&gt;2019-05-10 01:27:12,573	INFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)
2019-05-10 01:27:12,573	INFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.17139339447021484, '172.31.40.64': 0.17134618759155273, '172.31.36.240': 0.17130565643310547}, NodeIdleSeconds=Min=14 Mean=151 Max=419, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0
2019-05-10 01:27:12,574	INFO autoscaler.py:456 -- Ending bringup phase
2019-05-10 01:27:17,578	INFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)
2019-05-10 01:27:17,579	INFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.17473340034484863, '172.31.40.64': 0.17469072341918945, '172.31.36.240': 0.174652099609375}, NodeIdleSeconds=Min=19 Mean=156 Max=424, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0
2019-05-10 01:27:17,579	INFO autoscaler.py:456 -- Ending bringup phase
2019-05-10 01:27:22,688	INFO autoscaler.py:630 -- StandardAutoscaler: 2/0 target nodes (0 pending)
2019-05-10 01:27:22,688	INFO autoscaler.py:631 -- LoadMetrics: MostDelayedHeartbeats={'172.31.41.98': 0.20582270622253418, '172.31.40.64': 0.2057802677154541, '172.31.36.240': 0.20574188232421875}, NodeIdleSeconds=Min=0 Mean=153 Max=429, NumNodesConnected=3, NumNodesUsed=0.0, ResourceUsage=, TimeSinceLastHeartbeat=Min=0 Mean=0 Max=0
2019-05-10 01:27:22,688	INFO autoscaler.py:456 -- Ending bringup phase

&lt;/denchmark-code&gt;

The worker node utilisation:
&lt;denchmark-link:https://user-images.githubusercontent.com/1016303/57496960-ef237b00-7318-11e9-90d8-d50c1a143654.png&gt;&lt;/denchmark-link&gt;

NumNodesUsed and ResourceUsage don't seem right when worker utilisation is well above 0.8 average.
		</comment>
	</comments>
</bug>