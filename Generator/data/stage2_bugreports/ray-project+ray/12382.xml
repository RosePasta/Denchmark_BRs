<bug id='12382' author='wuisawesome' open_date='2020-11-25T03:10:55Z' closed_time='2020-12-21T18:30:04Z'>
	<summary>[Autoscaler] Autoscaler counts head node in node specific max workers</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Given a config like this (with a program that needs 5 GPUs), 4 of them launch, and the final worker cannot launch because there are no remaining nodes which fulfill the resource demand.
&lt;denchmark-code&gt;min_workers: 4
max_workers: 4
initial_workers: 4
idle_timeout_minutes: 1000

docker: {}

provider:
    type: aws
    region: us-west-2
    availability_zone: us-west-2a, us-west-2b, us-west-2c

available_node_types:
    gpu_1_ondemand:
        max_worker: 4
        node_config:
            InstanceType: g4dn.16xlarge
            TagSpecifications:
              - ResourceType: "instance"
                Tags:
                  - Key: anyscale-user
                    Value: xmo@anyscale.com
                  - Key: anyscale-expiration
                    Value: "2020-11-30"

# Specify the node type of the head node (as configured above).
head_node_type: gpu_1_ondemand

# Specify the default type of the worker node (as configured above).
worker_default_node_type: gpu_1_ondemand

# The default settings for the head node. This will be merged with the per-node
# type configs given above.
head_node:
    ImageId: latest_dlami

# The default settings for worker nodes. This will be merged with the per-node
# type configs given above.
worker_nodes:
    ImageId: latest_dlami

file_mounts: {
  "/home/ubuntu/workspace": "."
}

rsync_filter:
    - .gitignore

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu

setup_commands:
  - pip install torch torchvision ray[all] pillow
  - pip install -U boto3 botocore
  # Download the pretrained model
  - python -c "from torchvision.models import resnet50; resnet50(pretrained=True)"
  - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-1.1.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl
&lt;/denchmark-code&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='wuisawesome' date='2020-12-08T22:39:57Z'>
		&lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
 do you mean that only three workers are launched, instead of 4?
		</comment>
		<comment id='2' author='wuisawesome' date='2020-12-08T22:41:13Z'>
		Yeah
		</comment>
		<comment id='3' author='wuisawesome' date='2020-12-09T00:16:20Z'>
		Can you just add +1 if it is a headnode here:



ray/python/ray/autoscaler/_private/resource_demand_scheduler.py


         Line 564
      in
      fd4e025






 node_type, 0) &gt;= node_types[node_type].get( 





?
		</comment>
	</comments>
</bug>