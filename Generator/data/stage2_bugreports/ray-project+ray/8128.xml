<bug id='8128' author='henrypfister' open_date='2020-04-22T05:43:48Z' closed_time='2020-05-04T11:58:18Z'>
	<summary>[rllib] Multiagent DQN Training Crashes</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Some of my multi-agent environment code that works in 0.7.1 - 0.8.2 no longer works in &gt;=0.8.3.  Rather than give you a big mess of code, I am providing a small example with RockPaperScissors that breaks in Ray 0.8.4.
Ray version and other system information (Python version, TensorFlow version, OS):
Ray 0.8.4
Python 3.6.9
Tensorflow 2.2.0-rc3
OS = Google Colaboratory
(also breaks on Mac OSX 10.13.16 with Ray 0.8.4, Python 3.7.6, and Tensorflow 2.1)
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
&lt;denchmark-link:https://github.com/ray-project/ray/files/4513997/issue.zip&gt;issue.zip&lt;/denchmark-link&gt;

This zip file contains a single python file that reproduces the result.

[Yes] I have verified my script runs in a clean environment and reproduces the issue.
[No] I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='henrypfister' date='2020-04-22T13:49:14Z'>
		I forgot to include this link to a Google Colaboratory notebook that also reproduces the issue:
&lt;denchmark-link:https://colab.research.google.com/github/henrypfister/rllib_examples/blob/master/multiagent_rock_scissors_paper.ipynb&gt;https://colab.research.google.com/github/henrypfister/rllib_examples/blob/master/multiagent_rock_scissors_paper.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='henrypfister' date='2020-04-23T01:53:36Z'>
		&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
 it seems to crash when  is set due to some bug in the piecewise schedule:
&lt;denchmark-code&gt;    for item in it:
  File "/home/eric/Desktop/ray/python/ray/rllib/execution/rollout_ops.py", line 63, in sampler
    yield workers.local_worker().sample()
  File "/home/eric/Desktop/ray/python/ray/rllib/evaluation/rollout_worker.py", line 510, in sample
    batches = [self.input_reader.next()]
  File "/home/eric/Desktop/ray/python/ray/rllib/evaluation/sampler.py", line 53, in next
    batches = [self.get_data()]
  File "/home/eric/Desktop/ray/python/ray/rllib/evaluation/sampler.py", line 97, in get_data
    item = next(self.rollout_provider)
  File "/home/eric/Desktop/ray/python/ray/rllib/evaluation/sampler.py", line 356, in _env_runner
    active_episodes)
  File "/home/eric/Desktop/ray/python/ray/rllib/evaluation/sampler.py", line 610, in _do_policy_eval
    eval_results[pid] = builder.get(v)
  File "/home/eric/Desktop/ray/python/ray/rllib/utils/tf_run_builder.py", line 48, in get
    raise e
  File "/home/eric/Desktop/ray/python/ray/rllib/utils/tf_run_builder.py", line 44, in get
    self.feed_dict, os.environ.get("TF_TIMELINE_DIR"))
  File "/home/eric/Desktop/ray/python/ray/rllib/utils/tf_run_builder.py", line 89, in run_timeline
    fetches = sess.run(ops, feed_dict=feed_dict)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 960, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1361, in _do_run
    run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: Cannot convert 19000.0 to EagerTensor of dtype int32
Traceback (most recent call last):

  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py", line 234, in __call__
    return func(device, token, args)

  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/script_ops.py", line 123, in __call__
    ret = self._func(*args)

  File "/home/eric/Desktop/ray/python/ray/rllib/utils/schedules/piecewise_schedule.py", line 46, in _value
    if l_t &lt;= t &lt; r_t:

  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_math_ops.py", line 4895, in less
    x, y)

TypeError: Cannot convert 19000.0 to EagerTensor of dtype int32


	 [[node dqn_policy1/EagerPyFunc (defined at /home/eric/Desktop/ray/python/ray/rllib/utils/schedules/schedule.py:44) ]]

Errors may have originated from an input operation.
Input Source operations connected to node dqn_policy1/EagerPyFunc:
 dqn_policy1/timestep (defined at /home/eric/Desktop/ray/python/ray/rllib/policy/dynamic_tf_policy.py:130)

&lt;/denchmark-code&gt;

Oddly, it seems to be trying to execute some ops in eager mode.
		</comment>
		<comment id='3' author='henrypfister' date='2020-05-04T09:41:42Z'>
		Thanks for filing this &lt;denchmark-link:https://github.com/henrypfister&gt;@henrypfister&lt;/denchmark-link&gt;
. Taking a look now ...
		</comment>
		<comment id='4' author='henrypfister' date='2020-05-04T11:58:18Z'>
		Hey &lt;denchmark-link:https://github.com/henrypfister&gt;@henrypfister&lt;/denchmark-link&gt;
 Got it. It's a weird py_function related problem.
We'll get rid of  in all our Schedules (which should also fix this related issue here &lt;denchmark-link:https://github.com/ray-project/ray/issues/8062&gt;#8062&lt;/denchmark-link&gt;
 ).
Here is a PR that fixes your script (tested right now):
&lt;denchmark-link:https://github.com/ray-project/ray/pull/8304&gt;#8304&lt;/denchmark-link&gt;

Closing this issue. Please feel free to re-open it should this solution not work for you.
		</comment>
	</comments>
</bug>