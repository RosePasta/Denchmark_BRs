<bug id='11733' author='RodgerLuo' open_date='2020-10-31T21:56:50Z' closed_time='2020-11-04T12:43:29Z'>
	<summary>[rllib] IMPALA returns Actions as Nan</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

OS: Ubuntu 16.04
Ray: 1.0.0
Python: 3.6
PyTorch: 1.4.0
IMPALA returns Actions as NaN during training, which results in the following error:
&lt;denchmark-code&gt;ray.exceptions.RayTaskError(ValueError): ray::RolloutWorker.par_iter_next_batch() (pid=13852, ip=10.55.144.214)
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/util/iter.py", line 1158, in par_iter_next_batch
    batch.append(self.par_iter_next())
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/util/iter.py", line 1152, in par_iter_next
    return next(self.local_it)
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 288, in gen_rollouts
    yield self.sample()
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 579, in sample
    batches = [self.input_reader.next()]
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py", line 93, in next
    batches = [self.get_data()]
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py", line 209, in get_data
    item = next(self.rollout_provider)
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py", line 648, in _env_runner
    base_env.send_actions(actions_to_send)
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/env/base_env.py", line 345, in send_actions
    self.vector_env.vector_step(action_vector)
  File "/home/ubuntu/anaconda3/envs/ray-1.0/lib/python3.6/site-packages/ray/rllib/env/vector_env.py", line 147, in vector_step
    "Actions={}.".format(r, type(r), actions[i]))
ValueError: Reward should be finite scalar, got nan (&lt;class 'numpy.float64'&gt;). Actions=[nan].
&lt;/denchmark-code&gt;

It happens in several gym environments and customized environments as well.
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
Training with the following yaml file would reproduce the error in a few iterations:
&lt;denchmark-code&gt;pendulum-impala:
    env: Pendulum-v0
    run: IMPALA
    stop:
        episode_reward_mean: -160
    config:
      framework: torch
&lt;/denchmark-code&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='RodgerLuo' date='2020-11-04T12:43:29Z'>
		Hmm, yeah, IMPALA does not really learn well (or at all) in continuous action spaces (such as Pendulum). We made it such that it does run, but I really wouldn't recommend it. You should use SAC, PPO, or DDPG for cont. action problems.
		</comment>
	</comments>
</bug>