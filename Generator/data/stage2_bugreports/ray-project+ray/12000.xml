<bug id='12000' author='richardrl' open_date='2020-11-13T08:00:20Z' closed_time='2020-12-16T10:37:42Z'>
	<summary>[Tune] Double printing</summary>
	<description>
All my print statements are double printing inside tune.run. I'm not sure what logs to post, but I can paste logs if I know where to look.
	</description>
	<comments>
		<comment id='1' author='richardrl' date='2020-11-13T08:01:59Z'>
		Is this a new issue? What version of Ray are you on?
Can you try disabling tune.run(log_to_file?
		</comment>
		<comment id='2' author='richardrl' date='2020-11-13T08:38:13Z'>
		I am using Ray 1.1 dev0.
Commenting out log_to_file fixed it. But, it's nice to have log_to_file for debugging.
		</comment>
		<comment id='3' author='richardrl' date='2020-11-13T08:56:32Z'>
		ah its a bug then - cc &lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='richardrl' date='2020-11-13T17:55:45Z'>
		Hi &lt;denchmark-link:https://github.com/richardrl&gt;@richardrl&lt;/denchmark-link&gt;
, can you provide a script for reproduction? I tried this:
&lt;denchmark-code&gt;from ray import tune


def train(config):
    print("Test")
    return 5


tune.run(
    train,
    log_to_file=True)
&lt;/denchmark-code&gt;

on the latest wheels and the output seems fine to me:
&lt;denchmark-code&gt;2020-11-13 18:54:30,413	INFO services.py:1160 -- View the Ray dashboard at http://127.0.0.1:8265
2020-11-13 18:54:32,467	WARNING function_runner.py:539 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.
== Status ==
Memory usage on this node: 10.3/16.0 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/16 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects
Result logdir: /Users/kai/ray_results/train_2020-11-13_18-54-32
Number of trials: 1/1 (1 RUNNING)
+-------------------+----------+-------+
| Trial name        | status   | loc   |
|-------------------+----------+-------|
| train_48d0b_00000 | RUNNING  |       |
+-------------------+----------+-------+


Result for train_48d0b_00000:
  _metric: 5
  date: 2020-11-13_18-54-32
  done: false
  experiment_id: 5c4ebf3e470d45739466a113411538f2
  experiment_tag: '0'
  hostname: Kais-MBP.fritz.box
  iterations_since_restore: 1
  node_ip: 192.168.0.28
  pid: 82007
  time_since_restore: 0.00014591217041015625
  time_this_iter_s: 0.00014591217041015625
  time_total_s: 0.00014591217041015625
  timestamp: 1605290072
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 48d0b_00000
  
== Status ==
Memory usage on this node: 10.1/16.0 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.32 GiB objects
Result logdir: /Users/kai/ray_results/train_2020-11-13_18-54-32
Number of trials: 1/1 (1 TERMINATED)
+-------------------+------------+-------+--------+------------------+-----------+
| Trial name        | status     | loc   |   iter |   total time (s) |   _metric |
|-------------------+------------+-------+--------+------------------+-----------|
| train_48d0b_00000 | TERMINATED |       |      1 |      0.000145912 |         5 |
+-------------------+------------+-------+--------+------------------+-----------+


2020-11-13 18:54:32,821	INFO tune.py:444 -- Total run time: 2.93 seconds (0.35 seconds for the tuning loop).
(pid=82007) Test

Process finished with exit code 0
&lt;/denchmark-code&gt;

Also:
&lt;denchmark-code&gt;&gt; cat /Users/kai/ray_results/train_2020-11-13_18-54-32/train_48d0b_00000_0_2020-11-13_18-54-32/stdout 
Test
&gt; cat /Users/kai/ray_results/train_2020-11-13_18-54-32/train_48d0b_00000_0_2020-11-13_18-54-32/stderr 
(empty)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='richardrl' date='2020-12-16T10:37:42Z'>
		Closing this because of inactivity, please reopen if the problem persists and can be reproduced.
		</comment>
	</comments>
</bug>