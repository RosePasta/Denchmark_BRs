<bug id='6930' author='cbalaf' open_date='2020-01-27T19:11:18Z' closed_time='2020-01-27T22:52:49Z'>
	<summary>[tune] `tune.run` hangs for "long-running" functions</summary>
	<description>
tune.run works fine for optimization functions that exit quickly but hangs for longer running functions.
The following script runs fine:
&lt;denchmark-code&gt;from time import sleep

import numpy as np
from ray import tune
from ray.tune import track
from ray.tune.schedulers import AsyncHyperBandScheduler

np.random.seed(123)
def dummy(config):
    duration = 20
    sleep(duration)
    mean_err = np.random.uniform()
    print('Simulated long task over')
    track.log(mean_err=mean_err)


if __name__ == '__main__':
    search_space = {'var1': tune.randint(2, 32),
                    'var2': tune.loguniform(1e-6, 1)}
    tune.run(dummy, num_samples=20, config=search_space,
             scheduler=AsyncHyperBandScheduler(metric="mean_err", mode="min"))
&lt;/denchmark-code&gt;

However, setting duration=40 will cause ray to hang after the first pass of concurrent trials and never moves forward or completes the progress.csv and result.json files for the trials that kicked off.
MacOS 10.13.6
Python 3.7.4
ray 0.8.0
Any advice on how to get ray to run for a trial that takes longer than 30-ish seconds?
	</description>
	<comments>
		<comment id='1' author='cbalaf' date='2020-01-27T21:52:56Z'>
		Hi &lt;denchmark-link:https://github.com/cbalaf&gt;@cbalaf&lt;/denchmark-link&gt;
, thanks for opening this issue!
One clarification, does it block forever?
Also, a followup - is it possible break up the "simulated long task" into chunks? i.e.,
&lt;denchmark-code&gt;from time import sleep

import numpy as np
from ray import tune
from ray.tune import track
from ray.tune.schedulers import AsyncHyperBandScheduler

np.random.seed(123)
def dummy(config):
    duration = 20
    sleep(5)
    print('Simulated small portion of task over')
    track.log(mean_err=np.random.uniform())
    sleep(5)
    print('Simulated small portion of task over')
    track.log(mean_err=np.random.uniform())
    sleep(5)
    print('Simulated small portion of task over')
    track.log(mean_err=np.random.uniform())
    sleep(5)
    print('Simulated small portion of task over')
    track.log(mean_err=np.random.uniform())


if __name__ == '__main__':
    search_space = {'var1': tune.randint(2, 32),
                    'var2': tune.loguniform(1e-6, 1)}
    tune.run(dummy, num_samples=20, config=search_space,
             scheduler=AsyncHyperBandScheduler(metric="mean_err", mode="min"))
&lt;/denchmark-code&gt;

Tune takes advantage of intermediate results, and without them, you'll get some blocked.
		</comment>
		<comment id='2' author='cbalaf' date='2020-01-27T22:06:54Z'>
		(BTW, setting duration to a higher duration in the above works for me fine)
		</comment>
		<comment id='3' author='cbalaf' date='2020-01-27T22:31:36Z'>
		&lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 thank you very much for your response!
Breaking the task down worked, though I can imagine situations where that is not possible or meaningful. Any advice there?
Also, out of curiosity, what system/environment did you use to get it to work with a higher duration?
EDIT: On the blocking part, "forever" is a strong word, but it hangs for at least 15-20 minutes before I run out of patience and kill the job
		</comment>
		<comment id='4' author='cbalaf' date='2020-01-27T22:48:01Z'>
		I'm using a latest snapshot of master (&lt;denchmark-link:https://ray.readthedocs.io/en/latest/installation.html&gt;https://ray.readthedocs.io/en/latest/installation.html&lt;/denchmark-link&gt;
) on a Mac 10.15 with py3.7.3.

Breaking the task down worked, though I can imagine situations where that is not possible or meaningful. Any advice there?

Agree, in theory, you should be able to use arbitrarily long duration tasks with Ray Tune.
		</comment>
		<comment id='5' author='cbalaf' date='2020-01-27T23:02:23Z'>
		&lt;denchmark-link:https://github.com/cbalaf&gt;@cbalaf&lt;/denchmark-link&gt;
 thanks for closing - do feel free to open if this becomes an issue later down the road.
		</comment>
	</comments>
</bug>