<bug id='9146' author='anqixu' open_date='2020-06-25T18:31:30Z' closed_time='2020-07-17T12:46:32Z'>
	<summary>[tune] resume=LOCAL possibly not working on 0.8.5/0.8.6</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Tune's resume feature used to work (I remember testing it with production code on ray 0.7.5 and 0.8.3). But now with 0.8.5/0.8.6, when passing resume="LOCAL" to tune.run_experiments(), it doesn't call Trainable._restore(), and instead starts training from self.iteration=0.
Ray version and other system information (Python version, TensorFlow version, OS):

ray[rllib]==0.8.5 (also tested on 0.8.6)
Python 3.6.9 (default, Apr 18 2020, 01:56:04)
Ubuntu 18.04 (both as native OS and via Windows 10 x64 WSL2)
Linux 5.3.0-59-generic #53~18.04.1-Ubuntu SMP Thu Jun 4 14:58:26 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
tensorflow-gpu==2.1.0 (not that it matters)


 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

&lt;denchmark-h:h3&gt;Steps to reproduce error (see error.txt)&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/ray-project/ray/files/4833167/test_tune.py.txt&gt;test_tune.py (remove .txt extension)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/ray-project/ray/files/4833168/error.txt&gt;error.txt&lt;/denchmark-link&gt;

deactivate
cd ~
python3 -m venv tune_test
source tune_test/bin/activate
pip install -U pip wheel
pip install requests ray[tune]==0.8.5
rm -rf /tmp/MyTrainable/
python test_tune.py 
# wait till Tune reports training iteration &gt; 2, then press CTRL-C to kill process
python test_tune.py
	</description>
	<comments>
		<comment id='1' author='anqixu' date='2020-07-17T12:20:27Z'>
		Updated test script: (minor flaw in _save() function and more robust _restore() function; not cause of issue)
&lt;denchmark-link:https://github.com/ray-project/ray/files/4937843/test_tune.py.txt&gt;test_tune.py.txt&lt;/denchmark-link&gt;

Found issue in trainable.py &gt; Trainable.restore_from_object(), which restores objects from pickle to tmpdir yet passes checkpoint_path=os.path.join(tmpdir, info["checkpoint_name"]) instead to restore().
Bugfix: when writing pickled files to filesystem, save under checkpoint_path rather than tmpdir
Alternative bugfix: checkpoint_path = os.path.join(tmpdir, "./") (adds trailing slash in system-agnostic manner)
Issue confirmed to be fixed on &lt;denchmark-link:https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl&gt;nightly wheel&lt;/denchmark-link&gt;
:  now contains  rather than previously .
		</comment>
	</comments>
</bug>