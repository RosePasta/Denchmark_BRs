<bug id='12441' author='PidgeyBE' open_date='2020-11-26T10:24:22Z' closed_time='2020-11-30T04:55:51Z'>
	<summary>[autoscaler] Actor resource demands are not cleared after actor is scheduled</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;


ray nightly

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Take the following steps:

start a k8s autoscaling cluster
Execute: (I did in in ipython in ray head container)

&lt;denchmark-code&gt;import os
import ray

ray.init(address="auto")

@ray.remote(num_cpus=0.2)
class ActorA:
    def __init__(self):
        pass

a = ActorA.remote()
b = ActorA.remote()

# wait untill deployed, then kill actors or exit ipython
ray.kill(a)
ray.kill(b)
&lt;/denchmark-code&gt;

-&gt; output of autoscaling monitor:
&lt;denchmark-code&gt;2020-11-26 10:23:43,710 INFO resource_demand_scheduler.py:193 -- Resource demands: [{'CPU': 0.2}, {'CPU': 0.2}]
&lt;/denchmark-code&gt;

-&gt; the actor resources stick, instead of getting cleaned up
I would expect the resources to be cleaned up...

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='PidgeyBE' date='2020-11-27T18:06:20Z'>
		I think this may be the same issue as &lt;denchmark-link:https://github.com/ray-project/ray/issues/12381&gt;#12381&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='PidgeyBE' date='2020-11-27T23:48:52Z'>
		&lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
 it looks like the actor demands aren't cleared after the actor is scheduled. The following unit test reproduces:
&lt;denchmark-code&gt;def test_actor_resource_demand(shutdown_only):
    cluster = ray.init(num_cpus=3)
    global_state_accessor = GlobalStateAccessor(
        cluster["redis_address"], ray.ray_constants.REDIS_DEFAULT_PASSWORD)
    global_state_accessor.connect()

    @ray.remote(num_cpus=2)
    class Actor:
        def foo(self):
            return "ok"

    a = Actor.remote()
    ray.get(a.foo.remote())
    time.sleep(2)

    message = global_state_accessor.get_all_heartbeat()
    heartbeat = ray.gcs_utils.HeartbeatBatchTableData.FromString(message)

    # The actor is scheduled so there should be no more demands left.
    print(heartbeat)
    assert len(heartbeat.resource_load_by_shape.resource_demands) == 0

    global_state_accessor.disconnect()
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>