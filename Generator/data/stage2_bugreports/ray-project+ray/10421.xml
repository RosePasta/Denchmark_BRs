<bug id='10421' author='Rockyyost' open_date='2020-08-29T15:16:55Z' closed_time='2020-09-07T20:29:27Z'>
	<summary>[autoscaler] Workers Never Start</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
Ray 0.8.7
Python 3.7
TensorFlow 1.14.0
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
I've been working with an autoscaling cluster in AWS, but only the head node starts. None of the worker nodes turn on.
I use this command to start the cluster: ray up example-full.yaml
Below is the example-full.yaml file:
&lt;denchmark-code&gt;# An unique identifier for the head node and workers of this cluster.
cluster_name: default

# The minimum number of workers nodes to launch in addition to the head
# node. This number should be &gt;= 0.
min_workers: 3

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers.
max_workers: 3

# The initial number of worker nodes to launch in addition to the head
# node. When the cluster is first brought up (or when it is refreshed with a
# subsequent `ray up`) this number of nodes will be started.
initial_workers: 3

# Whether or not to autoscale aggressively. If this is enabled, if at any point
#   we would start more workers, we start at least enough to bring us to
#   initial_workers.
autoscaling_mode: default

# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled.
docker:
    image: "" # e.g., rayproject/ray:0.8.7
    container_name: "" # e.g. ray_docker
    # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
    # if no cached version is present.
    pull_before_run: True
    run_options: []  # Extra options to pass into "docker run"

    # Example of running a GPU head with CPU workers
    # head_image: "rayproject/ray:0.8.7-gpu"
    # head_run_options:
    #     - --runtime=nvidia

    # worker_image: "rayproject/ray:0.8.7"
    # worker_run_options: []

# The autoscaler will scale up the cluster to this target fraction of resource
# usage. For example, if a cluster of 10 nodes is 100% busy and
# target_utilization is 0.8, it would resize the cluster to 13. This fraction
# can be decreased to increase the aggressiveness of upscaling.
# This value must be less than 1.0 for scaling to happen.
target_utilization_fraction: 0.8

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 5

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-2
    # Availability zone(s), comma-separated, that nodes may be launched in.
    # Nodes are currently spread between zones by a round-robin approach,
    # however this implementation detail should not be relied upon.
    availability_zone: us-west-2a,us-west-2b
    # Whether to allow node reuse. If set to False, nodes will be terminated
    # instead of stopped.
    cache_stopped_nodes: True # If not present, the default is True.

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
# By default Ray creates a new private keypair, but you can also use your own.
# If you do so, make sure to also set "KeyName" in the head and worker node
# configurations below.
#    ssh_private_key: /path/to/your/key.pem

# Provider-specific config for the head node, e.g. instance type. By default
# Ray will auto-configure unspecified fields such as SubnetId and KeyName.
# For more documentation on available fields, see:
# http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
head_node:
    InstanceType: m5.4xlarge
    ImageId: ami-0a2363a9cff180a64 # Deep Learning AMI (Ubuntu) Version 30

    # You can provision additional disk space with a conf as follows
    BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
              VolumeSize: 100

    # Additional options in the boto docs.

# Provider-specific config for worker nodes, e.g. instance type. By default
# Ray will auto-configure unspecified fields such as SubnetId and KeyName.
# For more documentation on available fields, see:
# http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
worker_nodes:
    InstanceType: m5.4xlarge
    ImageId: ami-0a2363a9cff180a64 # Deep Learning AMI (Ubuntu) Version 30

    # Run workers on spot by default. Comment this out to use on-demand.
    InstanceMarketOptions:
        MarketType: spot
        # Additional options can be found in the boto docs, e.g.
        #   SpotOptions:
        #       MaxPrice: MAX_HOURLY_PRICE

    # Additional options in the boto docs.

# Files or directories to copy to the head and worker nodes. The format is a
# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
file_mounts: {
    "/home/ubuntu": "./core",
#    "/path2/on/remote/machine": "/path2/on/local/machine",
}

# Files or directories to copy from the head node to the worker nodes. The format is a
# list of paths. The same path on the head node will be copied to the worker node.
# This behavior is a subset of the file_mounts behavior. In the vast majority of cases
# you should just use file_mounts. Only use this if you know what you're doing!
#cluster_synced_files: []

# Whether changes to directories in file_mounts or cluster_synced_files in the head node
# should sync to the worker node continuously
#file_mounts_sync_continuously: False

# List of commands that will be run before `setup_commands`. If docker is
# enabled, these commands will run outside the container and before docker
# is setup.
initialization_commands: []

# List of shell commands to run to set up nodes.
setup_commands:
    # Note: if you're developing Ray, you probably want to create an AMI that
    # has your Ray repo pre-cloned. Then, you can replace the pip installs
    # below with a git checkout &lt;your_sha&gt; (and possibly a recompile).
    - echo 'export PATH="$HOME/anaconda3/envs/tensorflow_p36/bin:$PATH"' &gt;&gt; ~/.bashrc
    - pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl
    - sudo apt-get install libpq-dev
    - pip install -U psycopg2 sklearn gym ta pendulum namesgenerator dm-tree tabulate lz4
    # Consider uncommenting these if you also want to run apt-get commands during setup
    # - sudo pkill -9 apt-get || true
    # - sudo pkill -9 dpkg || true
    # - sudo dpkg --configure -a

# Custom commands that will be run on the head node after common setup.
head_setup_commands:
    - pip install boto3==1.4.8  # 1.4.8 adds InstanceMarketOptions

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop
    - ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076

&lt;/denchmark-code&gt;

And here is the output that appears in the terminal while running the command:
&lt;denchmark-code&gt;2020-08-29 08:46:34,688	INFO commands.py:202 -- get_or_create_head_node: Launching new head node...
2020-08-29 08:46:34,869	INFO node_provider.py:208 -- AWSNodeProvider: reusing instances ['i-053897df137f724b4']. To disable reuse, set 'cache_stopped_nodes: False' in the provider config.
2020-08-29 08:46:36,664	INFO commands.py:222 -- get_or_create_head_node: Updating files on head node...
2020-08-29 08:46:36,666	INFO updater.py:337 -- NodeUpdater: i-053897df137f724b4: Updating to cb16a724be3b61dd4fe1cfa8bd4a08e88c877421
2020-08-29 08:46:36,666	INFO updater.py:379 -- NodeUpdater: i-053897df137f724b4: Waiting for remote shell...
2020-08-29 08:46:36,667	INFO updater.py:194 -- NodeUpdater: i-053897df137f724b4: Waiting for IP...
2020-08-29 08:46:37,050	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-node-type=head on ['i-053897df137f724b4'] [LogTimer=566ms]
2020-08-29 08:46:37,401	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-launch-config=d40f964afb50d7faaff84cbb800eb666c60d66a4 on ['i-053897df137f724b4'] [LogTimer=351ms]
2020-08-29 08:46:37,675	INFO log_timer.py:17 -- AWSNodeProvider: Set tag Name=ray-default-head on ['i-053897df137f724b4'] [LogTimer=274ms]
2020-08-29 08:46:42,916	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-node-status=waiting-for-ssh on ['i-053897df137f724b4'] [LogTimer=237ms]
2020-08-29 08:46:46,844	INFO updater.py:194 -- NodeUpdater: i-053897df137f724b4: Waiting for IP...
2020-08-29 08:46:47,093	INFO log_timer.py:17 -- NodeUpdater: i-053897df137f724b4: Got IP [LogTimer=10427ms]
2020-08-29 08:46:47,109	INFO updater.py:256 -- NodeUpdater: i-053897df137f724b4: Running uptime on 34.213.234.165...
ssh: connect to host 34.213.234.165 port 22: Operation timed out
2020-08-29 08:46:57,134	INFO updater.py:256 -- NodeUpdater: i-053897df137f724b4: Running uptime on 34.213.234.165...
Warning: Permanently added '34.213.234.165' (ECDSA) to the list of known hosts.
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
 12:46:59 up 0 min,  0 users,  load average: 0.27, 0.06, 0.02
2020-08-29 08:46:59,868	INFO log_timer.py:17 -- NodeUpdater: i-053897df137f724b4: Got remote shell [LogTimer=23202ms]
2020-08-29 08:46:59,869	INFO updater.py:414 -- NodeUpdater: i-053897df137f724b4: i-053897df137f724b4 already up-to-date, skip to ray start
2020-08-29 08:46:59,869	INFO updater.py:256 -- NodeUpdater: i-053897df137f724b4: Running ray stop on 34.213.234.165...
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
Did not find any active Ray processes.
2020-08-29 08:47:02,715	INFO updater.py:256 -- NodeUpdater: i-053897df137f724b4: Running ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml on 34.213.234.165...
bash: cannot set terminal process group (-1): Inappropriate ioctl for device
bash: no job control in this shell
bash: ulimit: open files: cannot modify limit: Operation not permitted
Local node IP: 172.31.36.254
Available RAM
  Workers: 4.39 GiB
  Objects: 2.2 GiB
  
  To adjust these values, use
    ray.init(memory=&lt;bytes&gt;, object_store_memory=&lt;bytes&gt;)
Dashboard URL: http://localhost:8265

--------------------
Ray runtime started.
--------------------

Next steps
  To connect to this Ray runtime from another node, run
    ray start --address='172.31.36.254:6379' --redis-password='5241590000000000'
  
  Alternatively, use the following Python code:
    import ray
    ray.init(address='auto', redis_password='5241590000000000')
  
  If connection fails, check your firewall settings other network configuration.
  
  To terminate the Ray runtime, run
    ray stop
2020-08-29 08:47:04,882	INFO log_timer.py:17 -- NodeUpdater: i-053897df137f724b4: Ray start commands completed [LogTimer=5012ms]
2020-08-29 08:47:04,882	INFO log_timer.py:17 -- NodeUpdater: i-053897df137f724b4: Applied config cb16a724be3b61dd4fe1cfa8bd4a08e88c877421 [LogTimer=28216ms]
2020-08-29 08:47:05,067	INFO commands.py:289 -- get_or_create_head_node: Head node up-to-date, IP address is: 34.213.234.165
To monitor auto-scaling activity, you can run:

  ray exec /Users/rockfordyost/Documents/stockbot/stockbot/example-full.yaml 'tail -n 100 -f /tmp/ray/session_*/logs/monitor*'

To open a console on the cluster:

  ray attach /Users/rockfordyost/Documents/stockbot/stockbot/example-full.yaml

To get a remote shell to the cluster manually, run:

  ssh -o IdentitiesOnly=yes -i /Users/rockfordyost/.ssh/ray-autoscaler_us-west-2.pem ubuntu@34.213.234.165


2020-08-29 08:47:05,092	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-node-status=up-to-date on ['i-053897df137f724b4'] [LogTimer=203ms]
2020-08-29 08:47:05,294	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-runtime-config=cb16a724be3b61dd4fe1cfa8bd4a08e88c877421 on ['i-053897df137f724b4'] [LogTimer=202ms]
(base) Rockfords-MBP:stockbot rockfordyost$ 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Rockyyost' date='2020-08-29T19:24:09Z'>
		Thanks, &lt;denchmark-link:https://github.com/Rockyyost&gt;@Rockyyost&lt;/denchmark-link&gt;
. This is another instance of &lt;denchmark-link:https://github.com/ray-project/ray/issues/10343&gt;#10343&lt;/denchmark-link&gt;
 - we're working hard to address it!
		</comment>
		<comment id='2' author='Rockyyost' date='2020-08-29T21:23:55Z'>
		As a workaround, you can try modifying the ray stop command in your cluster yaml to use ray stop --force instead.
		</comment>
		<comment id='3' author='Rockyyost' date='2020-08-30T18:13:05Z'>
		Thanks! I tried the workaround. I placed ray stop --force both under the head_start_ray_commands and worker_start_ray_commands attributes.
This time, I did notice this error: bash: ulimit: open files: cannot modify limit: Operation not permitted. This error appeared after the following output in the terminal:
2020-08-30 13:42:39,643	INFO cli_logger.py:388 -- NodeUpdater: i-044097a2adf8aa6a2: Running ssh -tt -i /Users/rockfordyost/.ssh/ray-autoscaler_us-west-2.pem -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_e24ba10ef7/777825838f/%C -o ControlPersist=10s -o ConnectTimeout=120s ubuntu@34.217.30.238 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml'
Thank you for your help!
		</comment>
		<comment id='4' author='Rockyyost' date='2020-08-30T19:20:02Z'>
		Hmm it should be harmless; is there any other output after that?
		</comment>
		<comment id='5' author='Rockyyost' date='2020-09-07T20:29:27Z'>
		Closing because &lt;denchmark-link:https://github.com/ray-project/ray/issues/10343&gt;#10343&lt;/denchmark-link&gt;
 was fixed.
		</comment>
	</comments>
</bug>