<bug id='11597' author='LucaCappelletti94' open_date='2020-10-24T19:39:45Z' closed_time='2020-11-05T22:12:40Z'>
	<summary>[Tune] Bayesian Optimization does not perform correctly</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Weird duplicated points are searched, even with complex loss functions and parameters.
&lt;denchmark-code&gt;from bayes_opt import BayesianOptimization
space = {"x": (-1, 20)}

# Bounded region of parameter space
def loss(x):
    return -x**2

optimizer = BayesianOptimization(
    f=loss,
    pbounds=space,
    # random_state=1,
)
&lt;/denchmark-code&gt;

Returns:
&lt;denchmark-code&gt;|  33       | -9.488e-1 |  3.08e-06 |
|  34       | -3.424e-1 |  5.851e-0 |
|  35       | -2.039e-1 |  1.428e-0 |
|  36       | -7.964e-1 |  8.924e-0 |
|  37       | -1.389e-1 |  3.726e-0 |
|  38       | -7.326e-0 |  8.559e-0 |
|  39       | -0.0      |  0.0      |
|  40       | -4.414e-1 |  6.644e-0 |
=====================================
&lt;/denchmark-code&gt;

While Ray does not.
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

I have prepared a &lt;denchmark-link:https://colab.research.google.com/drive/1a0Pe3-Q0QJjrwVZQjb1W6MzJGWFtup26?usp=sharing&gt;Google Colab&lt;/denchmark-link&gt;
 to reproduce the issue.
	</description>
	<comments>
		<comment id='1' author='LucaCappelletti94' date='2020-10-29T20:40:52Z'>
		I was able to make this close to standard performance by wrapping the BayesOptSearch object with a concurrency limiter:
from ray.tune.suggest import ConcurrencyLimiter
gp = ConcurrencyLimiter(gp, max_concurrent=1)
# if you want parallelism, this works too
gp = ConcurrencyLimiter(gp, max_concurrent=2, batch=True)
		</comment>
	</comments>
</bug>