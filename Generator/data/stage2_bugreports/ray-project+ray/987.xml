<bug id='987' author='robertnishihara' open_date='2017-09-15T08:00:35Z' closed_time='2018-10-27T02:16:59Z'>
	<summary>Plasma managers die when running stressful workloads on a large cluster.</summary>
	<description>
I've seen the following problem arise for stressful workloads on 200 nodes (m4.16xlarge).
From the logs, some plasma managers and some local schedulers kill themselves because they go long enough without sending a heartbeat. In the past this arose because a plasma manager could be blocked in a call to connect when trying to establish a TCP connection to ship an object to another plasma manager. When too many managers did this at once, some would retry and due to exponential backoff some would end up blocked for tens of seconds. I think the relevant line is the one below.



ray/src/plasma/plasma_manager.cc


         Line 822
      in
      6601bb5






 int fd = connect_inet_sock(ip_addr, port); 





This was addressed in &lt;denchmark-link:https://github.com/ray-project/ray/pull/661&gt;#661&lt;/denchmark-link&gt;
.
This time, it looks like the blocking call that is taking too long is the following.



ray/src/common/state/redis.cc


        Lines 612 to 613
      in
      6601bb5






 redisReply *reply = (redisReply *) redisCommand( 



     db-&gt;sync_context, "RAY.GET_CLIENT_ADDRESS %b", (char *) db_client_id.id, 





Now, each individual synchronous Redis command there isn't taking too long (the slowest ones according to my print statements took 300 or 400 milliseconds), but we're doing it in a loop at



ray/src/common/state/redis.cc


        Lines 710 to 713
      in
      6601bb5






 for (int i = 0; i &lt; manager_count; ++i) { 



   DBClientID manager_id = from_flatbuf(message-&gt;manager_ids()-&gt;Get(i)); 



 redis_get_cached_db_client(db, manager_id, &amp;manager_vector[i]); 



 } 





This is inside of object_table_redis_subscribe_to_notifications_callback, so if one manager is trying to fetch a particular object, and that object is present on 200 other nodes, and if the primary Redis shard happens to be somewhat overwhelmed (e.g., it is exporting tons of remote function definitions to tons and tons of workers), then that loop can take tens of seconds and kill the plasma manager.
	</description>
	<comments>
		<comment id='1' author='robertnishihara' date='2018-10-27T02:16:58Z'>
		No longer relevant.
		</comment>
	</comments>
</bug>