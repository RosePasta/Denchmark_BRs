<bug id='3684' author='marlonjan' open_date='2019-01-03T13:50:45Z' closed_time='2019-01-07T03:37:36Z'>
	<summary>[RLlib] PGAgent learns with lr=0.0</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS High Sierra
Ray installed from (source or binary): installed with pip
Ray version: 0.6.0
Python version: 3.6.7
Exact command to reproduce: See below

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

PGAgent successfully trains with learning rate 0.0, while all model weights should remain constant.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import ray
import ray.tune as tune
from ray.rllib.agents.pg import PGAgent
from ray.tune import Experiment

if __name__ == "__main__":
    ray.init()
    tune.run_experiments(
        Experiment(
            name="zero_lr_cart_pole",
            run=PGAgent,
            stop={"episode_reward_mean": 400.0},
            config={
                "env": "CartPole-v0", 
                "num_gpus": 0, 
                "num_workers": 1, 
                "lr": 0.0  # &lt;---------- zero
            },
        )
    )
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='marlonjan' date='2019-01-03T15:57:56Z'>
		My impression is that the learning rate parameter gets ignored also for non-zero values. This is CartPole-v0 for radically different learning rates:
&lt;denchmark-link:https://user-images.githubusercontent.com/9771046/50647354-a4fc4880-0f78-11e9-8b5d-c2ece330d386.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='marlonjan' date='2019-01-06T07:24:21Z'>
		Thanks for reporting -- should be fixed in &lt;denchmark-link:https://github.com/ray-project/ray/pull/3697&gt;#3697&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>