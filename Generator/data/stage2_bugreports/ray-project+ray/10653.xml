<bug id='10653' author='mvindiola1' open_date='2020-09-08T19:13:53Z' closed_time='2020-09-21T03:01:52Z'>
	<summary>[rllib] DDPG TWIN_Q LOSS ERROR</summary>
	<description>
The TD3 loss according to OpenAI Spinning up is:
&lt;denchmark-link:https://camo.githubusercontent.com/9c2dd76c2a0c8b8453802102917774b8c27a661cd14c0d7566fb4ec96da0bed5/68747470733a2f2f7370696e6e696e6775702e6f70656e61692e636f6d2f656e2f6c61746573742f5f696d616765732f6d6174682f376435633138663439613234326363336565633535346637313766653466336266633131396261622e737667&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://camo.githubusercontent.com/9223fea845a0dc6073fe1d17a13c68b8ccb94271f1e2026403656274af557355/68747470733a2f2f7370696e6e696e6775702e6f70656e61692e636f6d2f656e2f6c61746573742f5f696d616765732f6d6174682f636437333732366138613338343561646534363761656435373731343931326638363866366233362e737667&gt;&lt;/denchmark-link&gt;

They implement this as you would expect:
&lt;denchmark-code&gt;# MSE loss against Bellman backup
loss_q1 = ((q1 - backup)**2).mean()
loss_q2 = ((q2 - backup)**2).mean()
loss_q = loss_q1 + loss_q2
&lt;/denchmark-code&gt;

The rllib implementation is off and I ran into training issues when using it.
Tensorflow:



ray/rllib/agents/ddpg/ddpg_tf_policy.py


        Lines 174 to 184
      in
      39c598b






 if twin_q: 



 td_error = q_t_selected - q_t_selected_target 



 twin_td_error = twin_q_t_selected - q_t_selected_target 



 td_error = td_error + twin_td_error 



 if use_huber: 



 errors = huber_loss(td_error, huber_threshold) + \ 



 huber_loss(twin_td_error, huber_threshold) 



 else: 



 errors = 0.5 * tf.math.square(td_error) + \ 



 0.5 * tf.math.square(twin_td_error) 



 else: 





Pytorch:



ray/rllib/agents/ddpg/ddpg_torch_policy.py


        Lines 124 to 134
      in
      5851e89






 if twin_q: 



 td_error = q_t_selected - q_t_selected_target 



 twin_td_error = twin_q_t_selected - q_t_selected_target 



 td_error = td_error + twin_td_error 



 if use_huber: 



 errors = huber_loss(td_error, huber_threshold) \ 



 + huber_loss(twin_td_error, huber_threshold) 



 else: 



 errors = 0.5 * \ 



             (torch.pow(td_error, 2.0) + torch.pow(twin_td_error, 2.0)) 



 else: 





The error is on line 177 and 127 respectively where the td_error and twin_td_error are added together and then squared a couple lines later. Removing that line would bring the implementation in line with the spinningup reference implementation. This worked for me to improve training on my problem. They also do not multiply by the constant (0.5) but I would not expect that to make much of a difference either way.
	</description>
	<comments>
		<comment id='1' author='mvindiola1' date='2020-09-11T19:16:29Z'>
		Interesting, do you want to push a fix. Also cc &lt;denchmark-link:https://github.com/michaelzhiluo&gt;@michaelzhiluo&lt;/denchmark-link&gt;
 if you could take a look here.
		</comment>
	</comments>
</bug>