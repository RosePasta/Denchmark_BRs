<bug id='8830' author='richardrl' open_date='2020-06-08T05:22:21Z' closed_time='2020-06-12T23:38:39Z'>
	<summary>Docker + AWS hanging at "Set tag..." for autoscaler</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Using latest version of Ray (0.9.0.dev0)
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

If we take the example AWS configuration YAML, given &lt;denchmark-link:https://docs.ray.io/en/master/autoscaling.html?highlight=docker&gt;here&lt;/denchmark-link&gt;
 (under AWS header) and simply change line 26 and 27 to use an actual Docker image:
&lt;denchmark-link:https://github.com/ray-project/ray/files/4744002/example_full.zip&gt;example_full.zip&lt;/denchmark-link&gt;

Running any commands with the autoscaler hangs and eventually fails:
&lt;denchmark-code&gt;ray up config/example_full.yaml 
2020-06-08 01:13:10,526 INFO config.py:143 -- _configure_iam_role: Role not specified for head node, using arn:aws:iam::&lt;redacted&gt;:instance-profile/ray-autoscaler-v1
2020-06-08 01:13:11,089 INFO config.py:194 -- _configure_key_pair: KeyName not specified for nodes, using ray-autoscaler_us-west-2
2020-06-08 01:13:11,365 INFO config.py:235 -- _configure_subnet: SubnetIds not specified for head node, using [('subnet-&lt;redacted&gt;', 'us-west-2b'), ('subnet-&lt;redacted&gt;', 'us-west-2a')]
2020-06-08 01:13:11,366 INFO config.py:241 -- _configure_subnet: SubnetId not specified for workers, using [('subnet-&lt;redacted&gt;', 'us-west-2b'), ('subnet-&lt;redacted&gt;', 'us-west-2a')]
2020-06-08 01:13:11,725 INFO config.py:261 -- _configure_security_group: SecurityGroupIds not specified for head node, using ray-autoscaler-default (sg-&lt;redacted&gt;)
2020-06-08 01:13:11,725 INFO config.py:268 -- _configure_security_group: SecurityGroupIds not specified for workers, using ray-autoscaler-default (sg-&lt;redacted&gt;)
This will restart cluster services [y/N]: y
2020-06-08 01:13:15,214 INFO commands.py:238 -- get_or_create_head_node: Updating files on head node...
2020-06-08 01:13:15,215 INFO updater.py:379 -- NodeUpdater: i-&lt;redacted&gt;: Updating to &lt;redacted&gt;
2020-06-08 01:13:15,216 INFO updater.py:423 -- NodeUpdater: i-&lt;redacted&gt;: Waiting for remote shell...
2020-06-08 01:13:15,422 INFO log_timer.py:22 -- AWSNodeProvider: Set tag ray-node-status=waiting-for-ssh on ['i-&lt;redacted&gt;
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/usr/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/richard/improbable/ray/python/ray/autoscaler/updater.py", line 383, in run
    self.do_update()
  File "/home/richard/improbable/ray/python/ray/autoscaler/updater.py", line 450, in do_update
    self.wait_ready(deadline)
  File "/home/richard/improbable/ray/python/ray/autoscaler/updater.py", line 444, in wait_ready
    assert False, "Unable to connect to node"
AssertionError: Unable to connect to node

2020-06-08 01:11:59,679 ERROR commands.py:304 -- get_or_create_head_node: Updating &lt;redacted&gt; failed
2020-06-08 01:11:59,701 INFO log_timer.py:22 -- AWSNodeProvider: Set tag ray-node-status=update-failed on ['i-&lt;redacted&gt;']  [LogTimer=333ms]

&lt;/denchmark-code&gt;

If I remove the Docker image and name on line 26 and line 27, the YAML file succeeds for any ray up / attach / submit etc. command.
(Related, it would be nice if we piped out more verbose error messages about why errors like this occur when using the autoscaler.)

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='richardrl' date='2020-06-08T07:02:52Z'>
		After fixing the above issue by removing the "allocate_tty" flag, I am running into issues where the Docker container is not run with tty / not persistent.
Where is the code that first starts the Docker container when doing "ray up ..."?
I can manually add the run command in "initialization_commands: []" but I'm guessing the below error is a bug... If someone explains how Ray team wants the Docker setup to work (which file should contain run "docker run ...") I can do a PR.
&lt;denchmark-code&gt;(pb_venv) richard@richard-desktop:~/improbable/&lt;redacted&gt;$ ray submit --docker config/example_full.yaml &lt;redacted&gt;/torch/train_ray.py 
2020-06-08 02:03:06,388 INFO commands.py:54 -- Using cached config at /tmp/ray-config-e82fb02128a816538f2a0dc5e8abcfdf5dd594a5
2020-06-08 02:03:07,123 INFO updater.py:485 -- NodeUpdater: i-&lt;redacted&gt;: Syncing &lt;redacted&gt;/torch/train_ray.py to ~/train_ray.py...
2020-06-08 02:03:07,617 INFO updater.py:200 -- NodeUpdater: i-&lt;redacted&gt;: Waiting for IP...
2020-06-08 02:03:07,617 INFO log_timer.py:22 -- NodeUpdater: i-&lt;redacted&gt;: Got IP  [LogTimer=493ms]
sending incremental file list
train_ray.py

sent 2,525 bytes  received 35 bytes  1,024.00 bytes/sec
total size is 8,257  speedup is 3.23
2020-06-08 02:03:09,475 INFO updater.py:253 -- NodeUpdater: i-&lt;redacted&gt;: Running docker cp ~/train_ray.py ray_docker:`docker exec ray_docker env | grep HOME | cut -d'=' -f2`/train_ray.py on 34.208.67.2...
2020-06-08 02:03:09,476 INFO updater.py:254 -- Begin remote output from &lt;redacted&gt;
Error: No such container: ray_docker
Error: No such container:path: ray_docker:/
Shared connection to &lt;redacted&gt; closed.
Error: SSH command Failed. See above for the output from the failure.

&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='richardrl' date='2020-06-08T20:09:29Z'>
		Just to confirm, if you SSH into the node and run docker container ls it does not show anything?
		</comment>
		<comment id='3' author='richardrl' date='2020-06-09T05:00:27Z'>
		Commit &lt;denchmark-link:https://github.com/ray-project/ray/commit/daf1ee13da9da96d99fe112970ee01b1f372f360&gt;daf1ee1&lt;/denchmark-link&gt;
  does not solve the issue.
&lt;denchmark-code&gt;Shared connection to 127.0.0.1 closed.
2020-06-09 00:58:18,716 INFO updater.py:254 -- NodeUpdater: localhost: Running docker cp /home/richard/&lt;code&gt;:/home/richard/&lt;code&gt;/ on 127.0.0.1...
2020-06-09 00:58:18,716 INFO updater.py:255 -- Begin remote output from 127.0.0.1
Error: No such container:path: &lt;code&gt;:/home/richard

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='richardrl' date='2020-06-09T15:03:16Z'>
		What happens if you include the --start flag for ray submit.
		</comment>
		<comment id='5' author='richardrl' date='2020-06-29T21:32:34Z'>
		I realize that this issue is closed, but the thread is the most recent and relevant that I could find to the problem that I am having, so I am asking for help.
I was successfully running an EC2 cluster using Ray last year, and recently attempted to start one up again with the same configuration, but updated release.
Firstly, I encountered the redis_address deprecation warning, so I changed my ray.init argument to (address="auto"), and the head_ and worker_start_ray_commands to those in a recent version of the example-full.yaml config' (see attached).
Now, when trying to bring ray up, I am getting an error very similar to the one above:-
&lt;denchmark-code&gt;bash: no job control in this shell
Error: no such option: --port
2020-06-29 17:24:37,025	INFO log_timer.py:17 -- NodeUpdater: i-08ab35ed68fbb942a: Ray start commands completed [LogTimer=2355ms]
2020-06-29 17:24:37,026	INFO log_timer.py:17 -- NodeUpdater: i-08ab35ed68fbb942a: Applied config ebfab67c94259a0ba4df6381d5cf2410fa5ef49b [LogTimer=38656ms]
2020-06-29 17:24:37,026	ERROR updater.py:348 -- NodeUpdater: i-08ab35ed68fbb942a: Error updating (Exit Status 2) ssh -i /home/haines/.ssh/ray-key2_us-east-1.pem -o ConnectTimeout=120s -o StrictHostKeyChecking=no -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_98734ce2b6/2ebd7d2a8f/%C -o ControlPersist=10s -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 ubuntu@54.210.118.84 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; ulimit -n 65536; ray start --head --port=6379 --autoscaling-config=~/ray_bootstrap_config.yaml'
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/usr/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 351, in run
    raise e
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 341, in run
    self.do_update()
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 434, in do_update
    self.cmd_runner.run(cmd)
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 263, in run
    self.process_runner.check_call(final_cmd)
  File "/usr/lib/python3.6/subprocess.py", line 311, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '['ssh', '-i', '/home/haines/.ssh/ray-key2_us-east-1.pem', '-o', 'ConnectTimeout=120s', '-o', 'StrictHostKeyChecking=no', '-o', 'ControlMaster=auto', '-o', 'ControlPath=/tmp/ray_ssh_98734ce2b6/2ebd7d2a8f/%C', '-o', 'ControlPersist=10s', '-o', 'IdentitiesOnly=yes', '-o', 'ExitOnForwardFailure=yes', '-o', 'ServerAliveInterval=5', '-o', 'ServerAliveCountMax=3', 'ubuntu@54.210.118.84', 'bash', '--login', '-c', '-i', "'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; ulimit -n 65536; ray start --head --port=6379 --autoscaling-config=~/ray_bootstrap_config.yaml'"]' returned non-zero exit status 2.

2020-06-29 17:24:37,170	ERROR commands.py:285 -- get_or_create_head_node: Updating 54.210.118.84 failed
2020-06-29 17:24:37,184	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-node-status=update-failed on ['i-08ab35ed68fbb942a'] [LogTimer=157ms]
&lt;/denchmark-code&gt;

The head node starts OK, but not the worker.  Is there something else that needs changing in order to substitute the redis address?
&lt;denchmark-link:https://github.com/ray-project/ray/files/4848130/ray_conf.txt&gt;ray_conf.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='richardrl' date='2020-06-30T00:02:09Z'>
		&lt;denchmark-link:https://github.com/snmhaines&gt;@snmhaines&lt;/denchmark-link&gt;
 What if you try using  instead of ?
		</comment>
		<comment id='7' author='richardrl' date='2020-06-30T21:41:55Z'>
		Thanks for the quick reply Ian.  I reverted to my previous config, which has ulimit -n 65536; ray start --redis-address=$RAY_HEAD_IP:6379 --object-manager-port=8076 ... as the start_ray_commands, and the cluster started OK.
I was going to check whether ray.init(redis_address=+":6379") still produces a warning for initialization in Python, but have run into a new problem on getting ray up:-
&lt;denchmark-code&gt;Collecting py-spy&gt;=0.2.0 (from ray)
  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)
Collecting grpcio (from ray)
  Downloading https://files.pythonhosted.org/packages/5e/29/1bd649737e427a6bb850174293b4f2b72ab80dd49462142db9b81e1e5c7b/grpcio-1.30.0.tar.gz (19.7MB)
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):
      File "&lt;string&gt;", line 1, in &lt;module&gt;
      File "/tmp/pip-build-9x_z6x8v/grpcio/setup.py", line 196, in &lt;module&gt;
        if check_linker_need_libatomic():
      File "/tmp/pip-build-9x_z6x8v/grpcio/setup.py", line 156, in check_linker_need_libatomic
        stderr=PIPE)
      File "/home/ubuntu/anaconda3/lib/python3.6/subprocess.py", line 709, in __init__
        restore_signals, start_new_session)
      File "/home/ubuntu/anaconda3/lib/python3.6/subprocess.py", line 1344, in _execute_child
        raise child_exception_type(errno_num, err_msg, err_filename)
    FileNotFoundError: [Errno 2] No such file or directory: 'cc': 'cc'
    
    ----------------------------------------
Command "python setup.py egg_info" failed with error code 1 in /tmp/pip-build-9x_z6x8v/grpcio/
You are using pip version 9.0.1, however version 20.1.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
2020-06-30 16:52:10,251	INFO log_timer.py:17 -- NodeUpdater: i-0dcaa2c55fbf456bd: Setup commands completed [LogTimer=97821ms]
2020-06-30 16:52:10,251	INFO log_timer.py:17 -- NodeUpdater: i-0dcaa2c55fbf456bd: Applied config 3c0845120a75432975eabe3c3f52bc4599173c4f [LogTimer=166507ms]
2020-06-30 16:52:10,252	ERROR updater.py:348 -- NodeUpdater: i-0dcaa2c55fbf456bd: Error updating (Exit Status 1) ssh -i /home/haines/.ssh/ray-key2_us-east-1.pem -o ConnectTimeout=120s -o StrictHostKeyChecking=no -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_98734ce2b6/2ebd7d2a8f/%C -o ControlPersist=10s -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 ubuntu@34.229.85.7 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; pip install ray'
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/usr/lib/python3.6/threading.py", line 916, in _bootstrap_inner
    self.run()
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 351, in run
    raise e
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 341, in run
    self.do_update()
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 430, in do_update
    self.cmd_runner.run(cmd)
  File "/home/haines/Projects/VF83/Ray_Cloud/lib/python3.6/site-packages/ray/autoscaler/updater.py", line 263, in run
    self.process_runner.check_call(final_cmd)
  File "/usr/lib/python3.6/subprocess.py", line 311, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '['ssh', '-i', '/home/haines/.ssh/ray-key2_us-east-1.pem', '-o', 'ConnectTimeout=120s', '-o', 'StrictHostKeyChecking=no', '-o', 'ControlMaster=auto', '-o', 'ControlPath=/tmp/ray_ssh_98734ce2b6/2ebd7d2a8f/%C', '-o', 'ControlPersist=10s', '-o', 'IdentitiesOnly=yes', '-o', 'ExitOnForwardFailure=yes', '-o', 'ServerAliveInterval=5', '-o', 'ServerAliveCountMax=3', 'ubuntu@34.229.85.7', 'bash', '--login', '-c', '-i', "'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; pip install ray'"]' returned non-zero exit status 1.

2020-06-30 16:52:10,774	ERROR commands.py:285 -- get_or_create_head_node: Updating 34.229.85.7 failed
2020-06-30 16:52:10,797	INFO log_timer.py:17 -- AWSNodeProvider: Set tag ray-node-status=update-failed on ['i-0dcaa2c55fbf456bd'] [LogTimer=545ms]

&lt;/denchmark-code&gt;

The head node starts, but not the worker.  I can log into the former, but it seems that the Python3 installation isn't completing, and
subsequent setup_commands in the config are not being executed (eg. boto3 is not being loaded).  The difficult thing is that this was working this morning.  Any ideas?
		</comment>
		<comment id='8' author='richardrl' date='2020-07-01T15:23:43Z'>
		Try adding  pip install --upgrade pip to your setup commands before pip install ray. It just looks like the AMI you are using has an old version of pip and that is tripping up GRPC installation.
		</comment>
		<comment id='9' author='richardrl' date='2020-07-01T21:43:58Z'>
		Thanks again, that did the trick.  However, I am now back to the original problem of the redis-address deprecation.  If I use ray.init(address="auto"), the Ray cluster cannot be found:-
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "Big_Data_Gen.py", line 489, in &lt;module&gt;
    ray.init(address="auto")   #(redis_address=redadd+":6379")
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ray/worker.py", line 643, in init
    address, redis_address)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ray/services.py", line 273, in validate_redis_address
    address = find_redis_address_or_die()
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ray/services.py", line 165, in find_redis_address_or_die
    "Could not find any running Ray instance. "
ConnectionError: Could not find any running Ray instance. Please specify the one to connect to by setting `address`.
&lt;/denchmark-code&gt;

But if I use the redis address, then the warning halts execution as if it were an error:-
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "Big_Data_Gen.py", line 489, in &lt;module&gt;
    ray.init(redis_address=redadd+":6379")
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ray/worker.py", line 627, in init
    raise DeprecationWarning("The redis_address argument is deprecated. "
DeprecationWarning: The redis_address argument is deprecated. Please use address instead.
&lt;/denchmark-code&gt;

I know that this was discussed in &lt;denchmark-link:https://github.com/ray-project/ray/issues/7127&gt;#7127&lt;/denchmark-link&gt;
, but there doesn't seem to be a way of configuring without redis.
Yours,
Steven Haines
		</comment>
		<comment id='10' author='richardrl' date='2020-07-02T00:55:24Z'>
		What if you did:
ray.init(address=redadd+":6379")
		</comment>
		<comment id='11' author='richardrl' date='2020-07-02T19:10:45Z'>
		Thanks Richard; that worked.  It seems that I was over-thinking the implications of the change.
		</comment>
	</comments>
</bug>