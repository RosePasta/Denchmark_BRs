<bug id='11891' author='TommasoBendinelli' open_date='2020-11-09T13:32:45Z' closed_time='2020-11-11T11:31:07Z'>
	<summary>ray up, hangs indefinitely</summary>
	<description>
I have the following yaml file:
&lt;denchmark-code&gt;cluster_name:test
min_workers: 1
max_workers: 1

docker:
    image: ""
    container_name: ""

provider:
    type: local
    head_ip: localhost
    worker_ips: []
    # Optional when running automatic cluster management on prem. If you use a coordinator server,
    # then you can launch multiple autoscaling clusters on the same set of machines, and the coordinator
    # will assign individual nodes to clusters as needed.
    #    coordinator_address: "&lt;host&gt;:&lt;port&gt;"

auth:
    ssh_user: tommaso

initialization_commands: ["source /home/tommaso/repos/gemintelligence/env/bin/activate"]
setup_commands: [""]
head_setup_commands: [""]
worker_setup_commands: [""]
head_start_ray_commands:
    ["ray stop", "ray start --head --port=6379"]

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    ["ray stop", "ray start --address=$RAY_HEAD_IP:6379"]
&lt;/denchmark-code&gt;

when running ray up test.yaml, I get the following
&lt;denchmark-code&gt;(env) tommaso@tommaso-desktop:~/repos/gemintelligence$ ray up test.yaml
Cluster: test
2020-11-09 14:30:53,304 INFO node_provider.py:40 -- ClusterState: Loaded cluster state: ['localhost']
This will restart cluster services [y/N]: y
2020-11-09 14:30:54,462 INFO commands.py:617 -- get_or_create_head_node: Updating files on head node...
2020-11-09 14:30:54,462 WARNING commands.py:478 -- Ray start on the head node does not have the flag--autoscaling-config set. The head node will not launchworkers. Add --autoscaling-config=~/ray_bootstrap_config.yamlto ray start in the head_start_ray_commands section.
2020-11-09 14:30:54,463 INFO updater.py:97 -- NodeUpdater: localhost: Updating to 3f0ada4ff00d7ebf9cb62e85024ebaf84b31119d
2020-11-09 14:30:54,463 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['localhost']
2020-11-09 14:30:54,464 INFO updater.py:221 -- NodeUpdater: localhost: Waiting for remote shell...
2020-11-09 14:30:54,465 INFO log_timer.py:25 -- NodeUpdater: localhost: Got IP  [LogTimer=1ms]
2020-11-09 14:30:54,465 INFO command_runner.py:542 -- NodeUpdater: localhost: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@127.0.0.1 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (uptime)'
 14:30:54 up 6 min,  2 users,  load average: 0.00, 0.02, 0.00
Shared connection to tommaso-desktop closed.
2020-11-09 14:30:54,521 INFO log_timer.py:25 -- NodeUpdater: localhost: Got remote shell  [LogTimer=58ms]
2020-11-09 14:30:54,522 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['localhost']
2020-11-09 14:30:54,522 INFO command_runner.py:542 -- NodeUpdater: localhost: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@127.0.0.1 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (mkdir -p ~)'
Shared connection to tommaso-desktop closed.
2020-11-09 14:30:54,578 INFO updater.py:419 -- NodeUpdater: localhost: Syncing /tmp/ray-bootstrap-t41u621f to ~/ray_bootstrap_config.yaml...
sending incremental file list
ray-bootstrap-t41u621f

sent 457 bytes  received 47 bytes  1,008.00 bytes/sec
total size is 815  speedup is 1.62
2020-11-09 14:30:54,588 INFO log_timer.py:25 -- NodeUpdater: localhost: Synced /tmp/ray-bootstrap-t41u621f to ~/ray_bootstrap_config.yaml  [LogTimer=66ms]
2020-11-09 14:30:54,589 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['localhost']
2020-11-09 14:30:54,589 INFO command_runner.py:542 -- NodeUpdater: localhost: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@127.0.0.1 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (source /home/tommaso/repos/gemintelligence/env/bin/activate)'
Shared connection to tommaso-desktop closed.
2020-11-09 14:30:54,648 INFO log_timer.py:25 -- NodeUpdater: localhost: Initialization commands succeeded [LogTimer=59ms]
&lt;/denchmark-code&gt;

And then it is stuck forwever. Am I missing something?
	</description>
	<comments>
		<comment id='1' author='TommasoBendinelli' date='2020-11-09T18:53:59Z'>
		cc &lt;denchmark-link:https://github.com/AmeerHajAli&gt;@AmeerHajAli&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='TommasoBendinelli' date='2020-11-09T19:20:58Z'>
		Can you explain a bit more on where this is running?
What do you mean by min_workers: 1 when you did not provide any worker_ips?
Are you trying to run this on your laptop?
Which ray version is that?
		</comment>
		<comment id='3' author='TommasoBendinelli' date='2020-11-10T07:57:09Z'>
		Sorry, I should have provided more details. I am using ray 1.0.0.
I have tried multiple times with and without adding workers but result was not changing.
What I notice, that to me was I bit unclear in the documentation, is that the commands specify in initialization, setup, heat_setup and head_start are not stateful.
For instance I have a python enviroment with ray installed in on folder, and I perform "source /home/tommaso/repos/myray/env/bin/activate". The enviroment will not be anymore activated in the following command.
Hence, I have changed the code as follow. placing all the commands in a single string (altough I do not think is the proper way to go)
&lt;denchmark-code&gt;cluster_name: test
min_workers: 1
max_workers: 1

docker:
    image: ""
    container_name: ""

provider:
    type: local
    head_ip: 138.131.217.158
    worker_ips: [KUKA_Ubuntu]
    # Optional when running automatic cluster management on prem. If you use a coordinator server,
    # then you can launch multiple autoscaling clusters on the same set of machines, and the coordinator
    # will assign individual nodes to clusters as needed.
    #    coordinator_address: "&lt;host&gt;:&lt;port&gt;"

auth:
    ssh_user: tommaso

initialization_commands: []
setup_commands: []
    
head_setup_commands: []
#worker_setup_commands: []
head_start_ray_commands:
    - source /home/tommaso/repos/gemintelligence/env/bin/activate ray start --head --port=6379

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop"
    - ray start --address=$RAY_HEAD_IP:6379
&lt;/denchmark-code&gt;

Now I am getting this as a result:
&lt;denchmark-code&gt;(env) tommaso@tommaso-desktop:~/repos/gemintelligence$ ray up test.yaml
Cluster: test
2020-11-10 08:50:56,385 INFO node_provider.py:40 -- ClusterState: Loaded cluster state: ['138.131.217.158']
This will restart cluster services [y/N]: y
2020-11-10 08:50:57,512 INFO commands.py:617 -- get_or_create_head_node: Updating files on head node...
2020-11-10 08:50:57,512 WARNING commands.py:478 -- Ray start on the head node does not have the flag--autoscaling-config set. The head node will not launchworkers. Add --autoscaling-config=~/ray_bootstrap_config.yamlto ray start in the head_start_ray_commands section.
2020-11-10 08:50:57,513 INFO updater.py:97 -- NodeUpdater: 138.131.217.158: Updating to 5cd085d7c2d77f185072c0a7bb2c514a942df014
2020-11-10 08:50:57,513 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['138.131.217.158', 'KUKA_Ubuntu']
2020-11-10 08:50:57,514 INFO updater.py:221 -- NodeUpdater: 138.131.217.158: Waiting for remote shell...
2020-11-10 08:50:57,515 INFO log_timer.py:25 -- NodeUpdater: 138.131.217.158: Got IP  [LogTimer=1ms]
2020-11-10 08:50:57,515 INFO command_runner.py:542 -- NodeUpdater: 138.131.217.158: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@138.131.217.158 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (uptime)'
Warning: Permanently added '138.131.217.158' (ECDSA) to the list of known hosts.
tommaso@138.131.217.158's password: 
 08:51:01 up 15:32,  1 user,  load average: 0.80, 0.43, 0.16
Shared connection to 138.131.217.158 closed.
2020-11-10 08:51:01,735 INFO log_timer.py:25 -- NodeUpdater: 138.131.217.158: Got remote shell  [LogTimer=4221ms]
2020-11-10 08:51:01,736 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['138.131.217.158', 'KUKA_Ubuntu']
2020-11-10 08:51:01,736 INFO command_runner.py:542 -- NodeUpdater: 138.131.217.158: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@138.131.217.158 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (mkdir -p ~)'
Shared connection to 138.131.217.158 closed.
2020-11-10 08:51:01,780 INFO updater.py:419 -- NodeUpdater: 138.131.217.158: Syncing /tmp/ray-bootstrap-_e9evpqt to ~/ray_bootstrap_config.yaml...
sending incremental file list
ray-bootstrap-_e9evpqt

sent 484 bytes  received 47 bytes  1,062.00 bytes/sec
total size is 809  speedup is 1.52
2020-11-10 08:51:01,791 INFO log_timer.py:25 -- NodeUpdater: 138.131.217.158: Synced /tmp/ray-bootstrap-_e9evpqt to ~/ray_bootstrap_config.yaml  [LogTimer=55ms]
2020-11-10 08:51:01,791 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['138.131.217.158', 'KUKA_Ubuntu']
2020-11-10 08:51:01,792 INFO command_runner.py:542 -- NodeUpdater: 138.131.217.158: Running ssh -tt -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o IdentitiesOnly=yes -o ExitOnForwardFailure=yes -o ServerAliveInterval=5 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPath=/tmp/ray_ssh_029ee67de7/098f6bcd46/%C -o ControlPersist=10s -o ConnectTimeout=120s tommaso@138.131.217.158 bash --login -c -i 'true &amp;&amp; source ~/.bashrc &amp;&amp; export OMP_NUM_THREADS=1 PYTHONWARNINGS=ignore &amp;&amp; (source /home/tommaso/repos/gemintelligence/env/bin/activate ray start --head --port=6379)'
Shared connection to 138.131.217.158 closed.
2020-11-10 08:51:01,841 INFO log_timer.py:25 -- NodeUpdater: 138.131.217.158: Ray start commands succeeded [LogTimer=50ms]
2020-11-10 08:51:01,842 INFO log_timer.py:25 -- NodeUpdater: 138.131.217.158: Applied config 5cd085d7c2d77f185072c0a7bb2c514a942df014  [LogTimer=4329ms]
2020-11-10 08:51:01,842 INFO node_provider.py:91 -- ClusterState: Writing cluster state: ['138.131.217.158', 'KUKA_Ubuntu']
2020-11-10 08:51:01,843 INFO commands.py:704 -- get_or_create_head_node: Head node up-to-date, IP address is: 138.131.217.158
To monitor autoscaling activity, you can run:

  ray exec /home/tommaso/repos/gemintelligence/test.yaml 'tail -n 100 -f /tmp/ray/session_latest/logs/monitor*'

To open a console on the cluster:

  ray attach /home/tommaso/repos/gemintelligence/test.yaml

To get a remote shell to the cluster manually, run:

  ssh -o IdentitiesOnly=yes tommaso@138.131.217.158
&lt;/denchmark-code&gt;

Still, the cluster does not seem to be on. Indeed, if I do ray status I get an error saying that no ray instance are running
		</comment>
		<comment id='4' author='TommasoBendinelli' date='2020-11-11T11:31:06Z'>
		hi &lt;denchmark-link:https://github.com/AmeerHajAli&gt;@AmeerHajAli&lt;/denchmark-link&gt;
 , I looked into this.
can you try using latest yaml file: &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/local/example-full.yaml&gt;https://github.com/ray-project/ray/blob/master/python/ray/autoscaler/local/example-full.yaml&lt;/denchmark-link&gt;
 with the later ray version?
set the worker_ips to [] and the head_ip to 138.131.217.158.
you should also source the anaconda from bashrc not in setup commands.
I think the docker container will resolve this issue too.
It worked for me.
&lt;denchmark-code&gt;--------------------
Ray runtime started.
--------------------

Next steps
  To connect to this Ray runtime from another node, run
    ray start --address='123.XXX.49.48:6379' --redis-password='5241590000000000'
  
  Alternatively, use the following Python code:
    import ray
    ray.init(address='auto', _redis_password='5241590000000000')
  
  If connection fails, check your firewall settings and network configuration.
  
  To terminate the Ray runtime, run
    ray stop
Shared connection to 123.XXX.49.48 closed.
2020-11-11 03:26:46,147	INFO node_provider.py:93 -- ClusterState: Writing cluster state: ['123.XXX.49.48']
  New status: up-to-date

Useful commands
  Monitor autoscaling with
    ray exec /home/eecs/ameerh/tst.yaml 'tail -n 100 -f /tmp/ray/session_latest/logs/monitor*'
  Connect to a terminal on the cluster head:
    ray attach /home/eecs/ameerh/tst.yaml
  Get a remote shell to the cluster manually:
    ssh -tt -o IdentitiesOnly=yes ameerh@123.XXX.49.48 docker exec -it ray_container /bin/bash
(base) ameerh@a8:~$     ray attach /home/eecs/ameerh/tst.yaml

Loaded cached provider configuration
If you experience issues with the cloud provider, try re-running the command with --no-config-cache.
2020-11-11 03:26:49,927	INFO node_provider.py:41 -- ClusterState: Loaded cluster state: ['123.XXX.49.48']
Fetched IP: 123.XXX.49.48


(base) root@a8:/# 
(base) root@a8:/# ls
bin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
(base) root@a8:/# ray status
2020-11-11 11:26:55,056	INFO scripts.py:1355 -- Connecting to Ray instance at 123.XXX.49.48:6379.
2020-11-11 11:26:55,056	INFO worker.py:651 -- Connecting to existing Ray cluster at address: 123.XXX.49.48:6379
Cluster status: 0/0 target nodes (0 pending)
 - MostDelayedHeartbeats: {'123.XXX.49.48': 0.12530970573425293}
 - NodeIdleSeconds: Min=4 Mean=4 Max=4
 - NumNodesConnected: 1
 - NumNodesUsed: 0.0
 - ResourceUsage: 0.0/32.0 CPU, 0.0 GiB/179.2 GiB memory, 0.0 GiB/55.94 GiB object_store_memory
 - TimeSinceLastHeartbeat: Min=0 Mean=0 Max=0
Worker node types:
(base) root@a8:/# 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='TommasoBendinelli' date='2020-11-11T14:08:15Z'>
		Yeah, I think docker is the solution. What I would suggest is to make sure to specify in the documentation that the docker container is needed for running the cluster properly
		</comment>
		<comment id='6' author='TommasoBendinelli' date='2020-11-11T14:16:26Z'>
		&lt;denchmark-link:https://github.com/TommasoBendinelli&gt;@TommasoBendinelli&lt;/denchmark-link&gt;
 , thanks for pointing this out. I think that you can overcome this challenge in the setup commands by setting up the cluster with the necessary environments. We generally provide our example yaml with the docker image.
		</comment>
	</comments>
</bug>