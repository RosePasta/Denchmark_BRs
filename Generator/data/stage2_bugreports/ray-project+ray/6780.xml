<bug id='6780' author='thuijskens' open_date='2020-01-13T14:27:41Z' closed_time='2020-09-16T15:57:07Z'>
	<summary>[Tune] HyperBandScheduler throws TuneError for some max_t - reduction_factor pairs</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;


OS: Ubuntu
Ray version: 0.8.0 (installed through pip)

For certain combinations of the max_t and reduction_factor arguments in ray.tune.schedulers.HyperBandScheduler, I get the following error once no more Trials are in PENDING mode:
&lt;denchmark-code&gt;ray.tune.error.TuneError: There are paused trials, but no more pending trials with sufficient resources.
&lt;/denchmark-code&gt;

For some reason Tune is not continuing the Trials that are in PAUSED mode (which is what I expected to happen).
I've not been able to really find a pattern for which combinations of  and  cause this. I've included one example below (a simple adaptation of the &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/hyperband_example.py&gt;example&lt;/denchmark-link&gt;
 for , where the only thing I have changed is the value of ).
&lt;denchmark-h:h3&gt;Reproduction&lt;/denchmark-h&gt;

I've put the following in a script hb_test.py
#!/usr/bin/env python

import argparse
import json
import os
import random

import numpy as np

import ray
from ray.tune import Trainable, run, Experiment, sample_from
from ray.tune.schedulers import HyperBandScheduler


class MyTrainableClass(Trainable):
    """Example agent whose learning curve is a random sigmoid.
    The dummy hyperparameters "width" and "height" determine the slope and
    maximum reward value reached.
    """

    def _setup(self, config):
        self.timestep = 0

    def _train(self):
        self.timestep += 1
        v = np.tanh(float(self.timestep) / self.config.get("width", 1))
        v *= self.config.get("height", 1)

        # Here we use `episode_reward_mean`, but you can also report other
        # objectives such as loss or accuracy.
        return {"episode_reward_mean": v}

    def _save(self, checkpoint_dir):
        path = os.path.join(checkpoint_dir, "checkpoint")
        with open(path, "w") as f:
            f.write(json.dumps({"timestep": self.timestep}))
        return path

    def _restore(self, checkpoint_path):
        with open(checkpoint_path) as f:
            self.timestep = json.loads(f.read())["timestep"]


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--smoke-test", action="store_true", help="Finish quickly for testing")
    args, _ = parser.parse_known_args()
    ray.init()

    # Hyperband early stopping, configured with `episode_reward_mean` as the
    # objective and `training_iteration` as the time unit,
    # which is automatically filled by Tune.
    hyperband = HyperBandScheduler(
        time_attr="training_iteration",
        metric="episode_reward_mean",
        mode="max",
        max_t=100,
        #####################################
        # Change is located here
        #####################################
        reduction_factor=2, # this crashes for me, whereas setting reduction_factor = 3 works
    )

    exp = Experiment(
        name="hyperband_test",
        run=MyTrainableClass,
        num_samples=20,
        stop={"training_iteration": 1 if args.smoke_test else 99999},
        config={
            "width": sample_from(lambda spec: 10 + int(90 * random.random())),
            "height": sample_from(lambda spec: int(100 * random.random()))
        })

    run(exp, scheduler=hyperband, verbose=1)
and created a new conda environment
&lt;denchmark-code&gt;conda create --name ray-bug python=3.6
conda activate ray-bug
pip install ray tabulate requests psutil
python hb_test.py
&lt;/denchmark-code&gt;

which generates the error
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "hb_test.py", line 72, in &lt;module&gt;
    run(exp, scheduler=hyperband, verbose=1)
  File "/home/thomas/anaconda3/envs/ray-bug/lib/python3.6/site-packages/ray/tune/tune.py", line 304, in run
    runner.step()
  File "/home/thomas/anaconda3/envs/ray-bug/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 341, in step
    self.trial_executor.on_no_available_trials(self)
  File "/home/thomas/anaconda3/envs/ray-bug/lib/python3.6/site-packages/ray/tune/trial_executor.py", line 175, in on_no_available_trials
    raise TuneError("There are paused trials, but no more pending "
ray.tune.error.TuneError: There are paused trials, but no more pending trials with sufficient resources.
&lt;/denchmark-code&gt;

However, setting reduction_factor = 3 (like in the original example) makes the code work.
	</description>
	<comments>
		<comment id='1' author='thuijskens' date='2020-01-20T02:20:18Z'>
		Thanks for reporting this issue &lt;denchmark-link:https://github.com/thuijskens&gt;@thuijskens&lt;/denchmark-link&gt;
!
I'll try to fix this up over the next week. Is this a blocker for you? if so, I can prioritize it.
		</comment>
		<comment id='2' author='thuijskens' date='2020-01-22T09:12:56Z'>
		Hi &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
! Awesome that you are putting this on your backlog. It is a bit of a blocker but not one that needs to be solved immediately. For the moment I've switched from using BOHB to ASHA for my experiments
		</comment>
		<comment id='3' author='thuijskens' date='2020-01-22T09:23:03Z'>
		OK sounds good. BTW, you should be able to obtain some improvements similar
to BOHB by combining ASHA with Bayesian Optimization (ray.tune.suggest).
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Jan 22, 2020 at 1:12 AM Thomas Huijskens ***@***.***&gt; wrote:
 Hi @richardliaw &lt;https://github.com/richardliaw&gt;! Awesome that you are
 putting this on your backlog. It is a bit of a blocker but not one that
 needs to be solved immediately. For the moment I've switched from using
 BOHB to ASHA for my experiments

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#6780?email_source=notifications&amp;email_token=ABCRZZOZAWMCNVWGO5SMZ2TQ7AEZRA5CNFSM4KGDC7MKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJSZKZI#issuecomment-577082725&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ABCRZZMCORHXCZVGMOWBS33Q7AEZRANCNFSM4KGDC7MA&gt;
 .



		</comment>
		<comment id='4' author='thuijskens' date='2020-08-19T09:44:44Z'>
		Hello &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
,
I just wanted to follow up and see if there were any updates on this issue. Curious to hear your thoughts on what might induce this problem. I am facing a similar issue running BOHB.
		</comment>
		<comment id='5' author='thuijskens' date='2020-08-19T23:29:24Z'>
		&lt;denchmark-link:https://github.com/shaandesaiqb&gt;@shaandesaiqb&lt;/denchmark-link&gt;
 can you post your HyperBandScheduler code?
		</comment>
		<comment id='6' author='thuijskens' date='2020-08-26T10:09:50Z'>
		Hi &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
 I upgraded to Ray 0.8.7 and this issue appears to be resolved. I had a follow up: I noticed that in 0.8.7 the max_concurrency parameter for hyperopt is deprecated (in favor of concurrency_limiter) but in BOHB it isn't, is there a reason for this?
		</comment>
		<comment id='7' author='thuijskens' date='2020-08-27T04:03:47Z'>
		Could you open a new issue to track that? Thanks!
		</comment>
	</comments>
</bug>