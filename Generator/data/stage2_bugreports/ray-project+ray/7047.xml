<bug id='7047' author='sherylwang' open_date='2020-02-04T15:44:00Z' closed_time='2020-02-06T19:52:10Z'>
	<summary>[Tune] BrokenPipeError when setting torch.dataloaders num_workers &amp;gt; 0</summary>
	<description>
Hi，
I'm using tune PopulationBasedTraining with pytorch. I found when setting num_workers &gt; 0 in dataloader with num_sample &gt; 1, it will raise "BrokenPipeError: [Errno 32] Broken pipe" error.
When don't use ray or just running the ray model, the error won't appear.
My ray[tune] version is 0.8.0, installed with pip, pytorch version is 1.2.0 cuda10.
	</description>
	<comments>
		<comment id='1' author='sherylwang' date='2020-02-06T01:07:53Z'>
		Can you try deleting your custom dataloader? I think you can do this by putting del {DataLoader} in _stop.
If you are using reuse_actors, you'll have to do it in reset_config.
		</comment>
		<comment id='2' author='sherylwang' date='2020-02-06T02:43:32Z'>
		Hi richardliaw. Thanks for your advice. I'm using the pbt scheduler, so I tried to delete the dataloader in reset_config function. When setting num_workers = 1, the broken pipe error still occurs in the first epoch(before the reset_config function be performed).
		</comment>
		<comment id='3' author='sherylwang' date='2020-02-06T02:51:40Z'>
		Actually, I found even  just warpped my pytorch model in ray.tune.Trainable. Then call the _train function to simply train the model, the num_workers in torch.utils.data.DataLoader seem not work, the data fetching time significantly increased compared to the raw torch model and training.
		</comment>
		<comment id='4' author='sherylwang' date='2020-02-06T02:52:11Z'>
		Can you provide a stack trace and repro script?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Feb 5, 2020 at 6:43 PM Xiaqing Xu ***@***.***&gt; wrote:
 Hi richardliaw. Thanks for your advice. I'm using the pbt scheduler, so I
 tried to delete the dataloader in reset_config function. When setting
 num_workers = 1, the broken pipe error still occurs in the first
 epoch(before the reset_config function be performed).

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#7047?email_source=notifications&amp;email_token=ABCRZZJKRD7X5SB5FJHPOSLRBN2NLA5CNFSM4KPZFNQ2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEK5XGFA#issuecomment-582710036&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ABCRZZOH4ZSQ34TH44C5TUTRBN2NLANCNFSM4KPZFNQQ&gt;
 .



		</comment>
		<comment id='5' author='sherylwang' date='2020-02-06T03:01:43Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/10609885/73902670-81b97080-48d1-11ea-90b3-b46b9282e680.png&gt;&lt;/denchmark-link&gt;

This is the broken pipe error &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='sherylwang' date='2020-02-06T13:39:11Z'>
		I found the error  occurs due to improper data fetching method of torch's dataloader, the "next(iter(dataloader))" format actually makes the data fetching slow.
		</comment>
		<comment id='7' author='sherylwang' date='2020-02-06T13:40:26Z'>
		
Actually, I found even just warpped my pytorch model in ray.tune.Trainable. Then call the _train function to simply train the model, the num_workers in torch.utils.data.DataLoader seem not work, the data fetching time significantly increased compared to the raw torch model and training.

This is not caused by the Trainable wrapper, sorry. I've found the reason.
		</comment>
		<comment id='8' author='sherylwang' date='2020-02-06T19:52:10Z'>
		OK great; I'll close this issue then.
		</comment>
	</comments>
</bug>