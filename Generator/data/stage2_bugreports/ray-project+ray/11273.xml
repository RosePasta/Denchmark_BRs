<bug id='11273' author='mattearllongshot' open_date='2020-10-08T11:05:21Z' closed_time='2020-10-16T00:21:12Z'>
	<summary>[autoscaler] 120s timeout in uptime command causes delays when booting</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version: 1.0.0
Python version: 3.8.1
OS: Ubuntu 18.04
Hi all, I noticed a delay on some nodes when booting a cluster.  Specifically, the delay comes between system boot (as reported by psutil) and setup commands executing.  The issue appears to be fixed by changing the timeout parameter when running the uptime command:
&lt;denchmark-code&gt;diff --git a/python/ray/autoscaler/updater.py b/python/ray/autoscaler/updater.py
index 8040dbcbd..ccb0d1931 100644
--- a/python/ray/autoscaler/updater.py
+++ b/python/ray/autoscaler/updater.py
@@ -231,7 +231,7 @@ class NodeUpdater:
                                              self.log_prefix)
 
                         # Run outside of the container
-                        self.cmd_runner.run("uptime", run_env="host")
+                        self.cmd_runner.run("uptime", timeout=5, run_env="host")
                         cli_logger.old_debug(logger, "Uptime succeeded.")
                         cli_logger.success("Success.")
                         return True
&lt;/denchmark-code&gt;

Here's a histogram of the time to setup commands for 64 workers, both with and without the above change:
&lt;denchmark-link:https://user-images.githubusercontent.com/37295291/95451260-725a5d80-095f-11eb-8ef3-7dd83bd2dcbc.png&gt;&lt;/denchmark-link&gt;

As you can see, setting timeout=5 gets rid of the second mode around 60s.  I notice that historically the timeout used to be 5s but was reverted as part of this PR, but it's not clear why?  &lt;denchmark-link:https://github.com/ray-project/ray/pull/9322/files#diff-2691ece495b9e3385c14189d8a32b54eL113&gt;https://github.com/ray-project/ray/pull/9322/files#diff-2691ece495b9e3385c14189d8a32b54eL113&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Reproduction&lt;/denchmark-h&gt;

Boot a cluster with 64 c5.12xlarge instances, measure the time between the setup commands executing, and that reported by psutil.boot_time().
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='mattearllongshot' date='2020-10-08T18:15:50Z'>
		cc &lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='mattearllongshot' date='2020-10-08T18:30:01Z'>
		&lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;
  Any reason for this change in &lt;denchmark-link:https://github.com/ray-project/ray/pull/9322&gt;#9322&lt;/denchmark-link&gt;
?
&lt;denchmark-link:https://github.com/mattearllongshot&gt;@mattearllongshot&lt;/denchmark-link&gt;
 What does your cluster config look like?
		</comment>
		<comment id='3' author='mattearllongshot' date='2020-10-09T03:12:38Z'>
		&lt;denchmark-link:https://github.com/ijrsvt&gt;@ijrsvt&lt;/denchmark-link&gt;
 probably accidental, we should revert.
		</comment>
		<comment id='4' author='mattearllongshot' date='2020-10-09T04:11:01Z'>
		&lt;denchmark-link:https://github.com/mattearllongshot&gt;@mattearllongshot&lt;/denchmark-link&gt;
 would you like to contribute the fix =)
Thanks again for finding this!!
		</comment>
		<comment id='5' author='mattearllongshot' date='2020-10-09T07:53:58Z'>
		I've raised the PR &lt;denchmark-link:https://github.com/ray-project/ray/pull/11300&gt;#11300&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>