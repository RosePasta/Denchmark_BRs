<bug id='7271' author='waldroje' open_date='2020-02-22T17:23:50Z' closed_time='2020-03-03T18:49:51Z'>
	<summary>[autoscaler]Changes in ssh defaults in 0.8.2 break code</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Due to firewall restrictions and the required use of elastic ips, I've had to build a workaround to launch aws clusters... this has worked reliably for many releases... but I noticed in 0.8.2 there has been an update to get_default_ssh_options method in SSHCommandRunner, which now causes my scripts to break, as setting "ExitOnForwardFailure" to "yes" causes an exception which it doesn't recover from.  I know I can just remove that in my own version, but figured I'd mention, as I like to minimize my custom changes.
Ray version and other system information (Python version, TensorFlow version, OS):
Ray 0.8.2, Python 3.6.8, TF 2.1, RHEL 7.7
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='waldroje' date='2020-02-22T18:33:20Z'>
		cc &lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='waldroje' date='2020-02-26T22:35:40Z'>
		Sorry for the long turn around time on this. Does your workaround actually involve port forwarding?
I suppose we could only add the ExitOnForwardFailure flag if port forwarding is actually used, otherwise, we could more generally add a yaml option to manually change the ssh options
		</comment>
		<comment id='3' author='waldroje' date='2020-02-27T13:26:22Z'>
		Sorry for my slow response.... and I'll say right up front if I'm the only one complaining about this, just close the issue... I can easily comment that out in my version... but I figured I'd detail my process, and at the very least you might suggest a better way...
The issue is I generally want to be able to launch multiple aws clusters... so what I do is initially launch what I call a "monitor", which I can create as many of these as I want, which is a low cost, long running small instance which will simulate a local machine, only inside of aws, where I won't have any firewall issues... so my only issue becomes getting that "monitor" up and running, and having the right packages available on it, as I will ultimately ssh into that and launch my cluster from it... and this will require an elastic ip on the "monitor" due to my internal controls.. so I have a script where I create an instance using boto3 and a saved ami, and then assign an available elastic_ip to this instance... then what I do it hijack a bit of your code to configure the instance to update the "monitor" to whatever current packages I want to use both for ray as well as my own code... I do that by creating an instance of a NodeUpdater, and normally just call do_update() on that instance, having passed in all the various initialization commands... and this has saved me from having to construct all the ssh command updates myself, and allows me to just use existing configuration files that I will also use inside aws.
Normally everything works... I shortly have an instance available which I can ssh into and port forward anything I want to have access to locally, and it has all the right packages and cluster configuration files on it. I can immediately launch a cluster, but from inside aws, and all of the ray autoscaler functionality works because there are no firewall issues from there.  What is happening in 0.8.2 is the do_update() fails in this process... and thus I end up with a monitor without the proper installs... and in fact I just terminate it if any part of the process fails.
I'd be curious how others work around elastic ip/firewall requirements when launching clusters on aws from a local machine... but either way I want to have the ability to launch multiple aws clusters, which you cannot do locally, as it only allows a single initialization of ray as far as I can tell.
		</comment>
		<comment id='4' author='waldroje' date='2020-03-03T03:12:21Z'>
		Sorry, I'm not quite sure I understand your setup. I believe you can launch multiple aws clusters from the same local machine by using multiple config.yaml files (the cluster name needs to be unique).
Also, do you have a stack trace or error message for what's breaking? I don't believe ray should be port forwarding unless it's explicitly told to.
		</comment>
		<comment id='5' author='waldroje' date='2020-03-03T12:24:19Z'>
		ok, you're absolutely right... i was able to change my code and simply through a different naming convention get multiple clusters up.... so I think we can close this issue... the only thing I'd say is it would be great if we could supply an elastic_ip address... as right now I have to manually associate the elastic ip with the head... Ctrl-C out of the ray up, as it just hangs because my firewall won't let it connect to the original ip... and then restart the cluster, at which point it connects...
boto3 has a client.associate_address method, which it would be cool if we could supply an elastic_ip address in the configuration which the Updater would apply and make the process completely seamless...
		</comment>
		<comment id='6' author='waldroje' date='2020-03-03T18:40:55Z'>
		Awesome, I'll go ahead and close this issue. Do you want to make a new issue/feature request about elastic ip addresses?
		</comment>
	</comments>
</bug>