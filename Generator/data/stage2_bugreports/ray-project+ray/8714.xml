<bug id='8714' author='rpandya922' open_date='2020-06-01T22:16:55Z' closed_time='2020-06-14T19:05:02Z'>
	<summary>[rllib] QMix initialization error with Tuple observation space</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

When trying to run QMix on a multi-agent environment, the QMixTorchPolicy object throws an error upon initialization, saying
&lt;denchmark-code&gt;Failure # 1 (occurred at 2020-06-01_14-46-39)
Traceback (most recent call last):
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 467, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 430, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/worker.py", line 1522, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): �[36mray::QMIX.train()�[39m (pid=3884, ip=10.0.2.15)
  File "python/ray/_raylet.pyx", line 421, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 456, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 459, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 460, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 414, in ray._raylet.execute_task.function_executor
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 90, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 444, in __init__
    super().__init__(config, logger_creator)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/tune/trainable.py", line 174, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 613, in _setup
    self._init(self.config, self.env_creator)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 115, in _init
    self.config["num_workers"])
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 684, in _make_workers
    logdir=self.logdir)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 59, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 282, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 393, in __init__
    policy_dict, policy_config)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 932, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/home/ravi/dev/gym-rl/qmix/lib/python3.6/site-packages/ray/rllib/agents/qmix/qmix_policy.py", line 223, in __init__
    self.mixer = QMixer(self.n_agents, self.env_global_state_shape,
AttributeError: 'QMixTorchPolicy' object has no attribute 'env_global_state_shape'
&lt;/denchmark-code&gt;

I have done some digging in the QMix source code, and this error is caused because the variable 'env_global_state_shape' does not get set for the QMixTorchPolicy object if the observation space is not of type . This is found in the if statement on line 173 of &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/agents/qmix/qmix_policy.py#L173&gt;qmix_policy.py&lt;/denchmark-link&gt;

Then later in line 223, as the error suggests, there is a reference to self.env_global_state_shape with no check if the property exists first. This is the only code path taken when config["mixer"]  == "qmix", so this makes the error unavoidable if the observation space is not a dictionary.
The MultiAgentEnv specification makes no mention of the observation space needing to be a dictionary, and the QMixTorchPolicy does not throw an error if it is not either.
Ray version and other system information (Python version, TensorFlow version, OS): OS: Ubuntu 18.04.4 LTS, python==3.6.9, torch==1.5.0, ray==0.8.4 (also tested with latest wheels on June 1st, 2020), tensorflow==1.14.0
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
&lt;denchmark-code&gt;from gym.spaces import Tuple, Discrete, Box
import ray
from ray import tune
from ray.tune.registry import register_env
from ray.rllib.env.multi_agent_env import MultiAgentEnv
import numpy as np


class TestEnv(MultiAgentEnv):
    def __init__(self, config):
        self.n_agents = len(config["agents"])
        self.agents = config["agents"]
        self.observation_space = Box(low=np.array([0, 0]), high=np.array([1, 1]))
        self.obs_size = 2
        self.action_space = Discrete(3)

    def step(self):
        obs_n = {}
        reward_n = {}
        done_n = {}
        info_n = {}

        for agent in self.agents:
            obs_n[agent] = self.observation_space.sample()
            reward_n[agent] = np.random.rand()
            done_n[agent] = True
            info_n[agent] = {}

        done_n["__all__"] = True

    def reset(self):
        return {agent: np.zeros(self.obs_size) for agent in self.agents}


def env_creator(args):
    env = TestEnv(args)

    obs_space = env.observation_space
    act_space = env.action_space
    n_agents = len(args["agents"])
    obs_space = Tuple([obs_space for _ in range(n_agents)])
    act_space = Tuple([act_space for _ in range(n_agents)])
    grouping = {"group_1": [str(i) for i in range(n_agents)]}
    return env.with_agent_groups(grouping, obs_space=obs_space, act_space=act_space)


register_env("grouped_test", env_creator)

results = tune.run(
    "QMIX",
    stop={"timesteps_total": 5,},
    config={
        "mixer": "qmix",
        "env": "grouped_test",
        "env_config": {"agents": [0, 1, 2]},
        "num_workers": 0,
        "timesteps_per_iteration": 2,
    },
)
&lt;/denchmark-code&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='rpandya922' date='2020-06-14T19:05:02Z'>
		&lt;denchmark-link:https://github.com/rpandya922&gt;@rpandya922&lt;/denchmark-link&gt;
 Thanks for filing this issue!
The following PR fixes it:
&lt;denchmark-link:https://github.com/ray-project/ray/pull/8936&gt;#8936&lt;/denchmark-link&gt;

Closing this now. Please feel free to reopen should it still not work on your end.
		</comment>
		<comment id='2' author='rpandya922' date='2020-06-14T19:14:59Z'>
		Oh, I forgot! Also, your grouping is kind of wrong. You are defining the agents as strings: "1", "2", and "3", but in the env, they are returned as ints 1, 2, and, 3. This then leads to the grouped observations not being recognized properly. Just change the "tune.run" call to:
&lt;denchmark-code&gt;"env_config": {"agents": ["0", "1", "2"]},
&lt;/denchmark-code&gt;

and it should work.
		</comment>
	</comments>
</bug>