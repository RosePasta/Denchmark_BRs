<bug id='8041' author='Jungdam' open_date='2020-04-16T06:40:31Z' closed_time='2020-05-12T17:14:06Z'>
	<summary>[rllib] free_log_std does not support modelV2?</summary>
	<description>
&lt;denchmark-h:h3&gt;What is your question?&lt;/denchmark-h&gt;

Previously, free_log_std was supported and was implemented in "rllib/models/model.py".
Now, I was not able to find similar ones anywhere else in "rllib/models/modelv2.py" and its tf and torch extensions. I am curious whether free_log_std was deprecated or was just missing for some reason.
Thanks!
	</description>
	<comments>
		<comment id='1' author='Jungdam' date='2020-04-17T06:10:28Z'>
		This looks like an unintended omission. I'm not sure if this would affect performance much though, since the logstds will still end up learnable, but connected to more units.
		</comment>
		<comment id='2' author='Jungdam' date='2020-04-17T07:59:27Z'>
		Thank for the reply.
I'll assume our policy is a Gaussian policy.
In theory, there would be similar eventually, however, there are some environments that show differences in performance in practice. The environments affected by the free_log_std option are usually ones that require careful exploration such as physically-simulated agents or robot controls. If logstd depends on the state of agent, the sampled actions could be too aggressive because logstd could be really large at some (unknown) states, which easily gets off the safe action range for agents. So, some of literatures in physically-simulated agents or robot controls reported that using state-independent logstd (like free_log_std) or constant logstd showed better performances.
I currently implemented state-independent logstd and constant logstd myself, they showed better performances, and the convergences are more stable than state-dependent logstd.
It would be great if you guys consider that both state-indendent and constant logstd are included as default functionalities in the future.
		</comment>
		<comment id='3' author='Jungdam' date='2020-04-20T19:17:55Z'>
		That's a good point. &lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
 this could be relevant during benchmarking.
		</comment>
		<comment id='4' author='Jungdam' date='2020-04-21T01:45:35Z'>
		And also it would be good if users can assign the initial values for constant/learnable log_std.
The implementation existed in the previous version initializes log_std as 0.0, which means 1.0 std and covers approximately 1/4 range given a mean value. In my experience, some environments required more careful exploration by setting lower values than 1.0 std.
And, I guess that &lt;denchmark-link:https://github.com/ray-project/ray/issues/7923&gt;#7923&lt;/denchmark-link&gt;
 would be probably related to this problem. I also got NaN eventually in my environment when I run the experiment by using state_dependent log_std.
		</comment>
		<comment id='5' author='Jungdam' date='2020-05-01T08:35:45Z'>
		Did you implement this for rllib? If so, would you mind sharing how you did it?
Im also experiencing NaN problems which I suspect is caused by this.

I currently implemented state-independent logstd and constant logstd myself, they showed better performances, and the convergences are more stable than state-dependent logstd.

		</comment>
		<comment id='6' author='Jungdam' date='2020-05-05T18:58:04Z'>
		Just updating that changing to free_log_std solved this for me, having very similar issues as in &lt;denchmark-link:https://github.com/ray-project/ray/issues/7923&gt;#7923&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Jungdam' date='2020-05-09T03:10:24Z'>
		&lt;denchmark-link:https://github.com/ray-project/ray/pull/8380/files&gt;https://github.com/ray-project/ray/pull/8380/files&lt;/denchmark-link&gt;
 should fix this, please give it a try!
		</comment>
		<comment id='8' author='Jungdam' date='2020-05-12T19:47:05Z'>
		Sorry for the late reply. Thanks for adding this and I leave a comment in TF implementation part.
Thanks again!
		</comment>
	</comments>
</bug>