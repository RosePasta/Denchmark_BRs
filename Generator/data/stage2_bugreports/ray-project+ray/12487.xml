<bug id='12487' author='LianShuaiLong' open_date='2020-11-30T03:45:23Z' closed_time='2020-12-02T04:02:44Z'>
	<summary>[tune] How can i get 'metric' value currently of all trials while running Ray?</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

I want to get 'metric' best so far during running ray, and to help me decide whether to save model trained by current trial.
so what should i do?
Ray version and other system information (Python version, TensorFlow version, OS):
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='LianShuaiLong' date='2020-11-30T09:10:49Z'>
		Hi &lt;denchmark-link:https://github.com/LianShuaiLong&gt;@LianShuaiLong&lt;/denchmark-link&gt;
, could you give us a concrete example where in your code you'd want to implement such logic? Since  is a blocking call and waits until all trials are finished (or another stopping condition is reached) I think it must happen within a trial.
However, trial trainables currently do not receive any information about other trials. You will probably have to keep at least one checkpoint per trial, and can decide after the run which checkpoint to keep:
&lt;denchmark-code&gt;analysis = tune.run(....)
best_checkpoint_dir = analysis.best_trial.checkpoint.value
# ...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='LianShuaiLong' date='2020-11-30T11:45:51Z'>
		
Hi @LianShuaiLong, could you give us a concrete example where in your code you'd want to implement such logic? Since tune.run() is a blocking call and waits until all trials are finished (or another stopping condition is reached) I think it must happen within a trial.
However, trial trainables currently do not receive any information about other trials. You will probably have to keep at least one checkpoint per trial, and can decide after the run which checkpoint to keep:
analysis = tune.run(....)
best_checkpoint_dir = analysis.best_trial.checkpoint.value
# ...


Since it takes too long to finish all trials, i want to get the best model so far anytime during training.
		</comment>
		<comment id='3' author='LianShuaiLong' date='2020-11-30T11:50:49Z'>
		is there any way to get name of the trial during running ray?
		</comment>
		<comment id='4' author='LianShuaiLong' date='2020-12-02T04:02:44Z'>
		&lt;denchmark-link:https://github.com/ray-project/ray/issues/6796#issuecomment-736340082&gt;#6796 (comment)&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>