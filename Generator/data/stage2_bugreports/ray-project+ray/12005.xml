<bug id='12005' author='PidgeyBE' open_date='2020-11-13T09:28:03Z' closed_time='2020-12-14T20:11:12Z'>
	<summary>[autoscaler] Failed workers end up in broken state</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;


ray 1.0.1
kubernetes autoscaling

When an autoscaled worker failed to update, it ends up in a broken state:

The worker pod that was scaled and failed to update is not cleaned up. It keeps running and keeps using e.g. GPU resources.
The autoscaler algorithm takes resources of "failed workers" into account, while in fact no resources can be scheduled on these workers.

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

One way to force a worker to be in a "failed update" state is to set NODE_START_WAIT_S low enough.



ray/python/ray/autoscaler/_private/command_runner.py


         Line 36
      in
      3b56a1a






 NODE_START_WAIT_S = 300 





If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='PidgeyBE' date='2020-11-13T21:58:50Z'>
		cc &lt;denchmark-link:https://github.com/AmeerHajAli&gt;@AmeerHajAli&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='PidgeyBE' date='2020-11-13T22:01:11Z'>
		One option here is to retry on update failures, or to terminate the node if updates failed.
		</comment>
		<comment id='3' author='PidgeyBE' date='2020-11-14T08:35:36Z'>
		I think this should be handled by the autoscaler cleaner of idle nodes. The only concern is when the number of nodes is min_workers and then it might not be cleaned.
		</comment>
		<comment id='4' author='PidgeyBE' date='2020-11-17T16:56:58Z'>
		If we can detect failed nodes, we can easily skip the keep_min_workers call when the node is tagged as failed.
		</comment>
		<comment id='5' author='PidgeyBE' date='2020-11-17T17:13:46Z'>
		
terminate the node if updates failed.

IMO this seems like the best solution. Clean and cost effective.
One downside is that this would make it harder to debug setup failures, so we may want to consider putting it behind a flag.
		</comment>
		<comment id='6' author='PidgeyBE' date='2020-11-23T23:37:39Z'>
		&lt;denchmark-link:https://github.com/AmeerHajAli&gt;@AmeerHajAli&lt;/denchmark-link&gt;
 I think you mentioned running into this before. Do you want to take this issue?
We can probably do something like auto-terminate failed workers (or at least add an option to do so).
		</comment>
		<comment id='7' author='PidgeyBE' date='2020-11-24T14:29:07Z'>
		I am happy to take this bug into my queue.
		</comment>
		<comment id='8' author='PidgeyBE' date='2020-12-14T20:11:12Z'>
		Closed in &lt;denchmark-link:https://github.com/ray-project/ray/pull/12661&gt;#12661&lt;/denchmark-link&gt;
 for nodes that failed to update/init and  for getting nodes.
		</comment>
	</comments>
</bug>