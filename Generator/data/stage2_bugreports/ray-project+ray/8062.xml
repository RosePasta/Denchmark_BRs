<bug id='8062' author='5cp' open_date='2020-04-17T03:45:47Z' closed_time='2020-05-04T11:57:01Z'>
	<summary>[rllib] Exported Tensorflow models cannot be served by tensorflow-serving when using DQN with EpsilonGreedy</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

When training using DQN with EpsilonGreedy exploration, the resulting Tensorflow model fails to load in tensorflow-serving with the following error:
&lt;denchmark-code&gt;2020-04-16 21:25:36.137202: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: fail: Invalid argument: No OpKernel was registered to support Op 'PyFunc' used by {{node default_policy/PyFunc}}with these attrs: [Tout=[DT_DOUBLE], token="pyfunc_0", _output_shapes=[&lt;unknown&gt;], Tin=[DT_INT32]]
Registered devices: [CPU]
Registered kernels:
  &lt;no registered kernels&gt;

	 [[default_policy/PyFunc]]. Took 37487 microseconds.
&lt;/denchmark-code&gt;

Changing exploration_type to 'StochasticSampling' results in a Tensorflow model that successfully loads into tensorflow-serving:
&lt;denchmark-code&gt;2020-04-16 21:25:50.590837: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.
2020-04-16 21:25:50.625754: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 75142 microseconds.
&lt;/denchmark-code&gt;

The issue appears to be related to the use of  in &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/utils/schedules/schedule.py#L44&gt;Schedule.py&lt;/denchmark-link&gt;
. According to the &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/py_function&gt;Tensorflow docs for tf.py_function&lt;/denchmark-link&gt;
:

The body of the function (i.e. func) will not be serialized in a GraphDef. Therefore, you should not use this function if you need to serialize your model and restore it in a different environment.

Ray version and other system information (Python version, TensorFlow version, OS):
&lt;denchmark-code&gt;Ray 0.8.2 / Ray 0.8.4 / 0.9.0dev0
Python 3.6.6 :: Anaconda, Inc.
Tensorflow 2.1.0
TensorFlow ModelServer: 2.1.0-rc1+dev.sha.5029f06
Ubuntu 18.04.4 LTS
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
from ray import tune
from ray.rllib.agents.dqn import DQNTrainer, DEFAULT_CONFIG
import tempfile

config = DEFAULT_CONFIG.copy()
good_model_dir = tempfile.NamedTemporaryFile().name + "_good"
bad_model_dir = tempfile.NamedTemporaryFile().name + "_bad"

# Train and export 'bad' model with expected failure:
trainer = DQNTrainer(env="CartPole-v0", config=config)
for it in range(3):
    trainer.train()
trainer.get_policy().export_model(bad_model_dir + "/1")

# Train and export 'good' model with expected success:
config['exploration_config'] = { 'type': 'StochasticSampling' }
trainer = DQNTrainer(env="CartPole-v0", config=config)
for it in range(3):
    trainer.train()
trainer.get_policy().export_model(good_model_dir + "/1")

print("Good model: ", good_model_dir)
print("Bad model: ", bad_model_dir)

Install tensorflow-serving as per https://www.tensorflow.org/tfx/serving/setup
Run the above reproduction script
Try the 'good' model:
tensorflow2_model_server --model_base_path=PATH_TO_GOOD_MODEL
Try the 'bad' model:
tensorflow2_model_server --model_base_path=PATH_TO_BAD_MODEL

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the [latest wheels] &lt;- yes, but reproduction script currently fails because ray.rllib.execution appears to be missing from wheel

	</description>
	<comments>
		<comment id='1' author='5cp' date='2020-04-17T06:25:53Z'>
		I see. Sorry about that. We'll try to change this to not use tf.py_function in our Schedules.
		</comment>
		<comment id='2' author='5cp' date='2020-05-01T08:09:51Z'>
		I put this on my next sprint to be fixed, starting Monday.
		</comment>
		<comment id='3' author='5cp' date='2020-05-04T11:57:01Z'>
		Hey &lt;denchmark-link:https://github.com/5cp&gt;@5cp&lt;/denchmark-link&gt;
 Could you try it with this PR here?
&lt;denchmark-link:https://github.com/ray-project/ray/pull/8304&gt;#8304&lt;/denchmark-link&gt;

None of our Schedules uses py_function anymore, such that they should all be differentiable now.
Please let me know, if this doesn't fix your issue and feel free to re-open it.
		</comment>
	</comments>
</bug>