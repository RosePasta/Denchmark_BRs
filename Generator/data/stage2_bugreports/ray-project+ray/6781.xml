<bug id='6781' author='camcastera' open_date='2020-01-13T17:29:06Z' closed_time='2020-01-14T10:04:03Z'>
	<summary>Unable to schedule actor even with available resources</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Hi,
I cannot figure why i cannot use ray with any example such as the ones from &lt;denchmark-link:https://ray.readthedocs.io/en/latest/tune.html&gt;the main page of tune&lt;/denchmark-link&gt;
.
This seems related to &lt;denchmark-link:https://github.com/ray-project/ray/issues/6007&gt;#6007&lt;/denchmark-link&gt;
 but no workaround is provided.
Here is the type of error i get:
&lt;denchmark-code&gt;== Status ==
Memory usage on this node: 4.8/31.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 1/2 CPUs, 0/1 GPUs, 0.0/16.11 GiB heap, 0.0/5.57 GiB objects
Result logdir: /home/ccastera/ray_results/train_mnist
Number of trials: 3 (1 RUNNING, 2 PENDING)
+----------------------+----------+-------+------+
| Trial name           | status   | loc   | lr   |
|----------------------+----------+-------+------|
| train_mnist_3d3297d6 | RUNNING  |       |      |
| train_mnist_3d3297d7 | PENDING  |       |      |
| train_mnist_3d3297d8 | PENDING  |       |      |
+----------------------+----------+-------+------+


2020-01-13 18:15:09,447	WARNING worker.py:1062 -- The actor or task with ID ffffffffffffffff45b95b1c0100 is pending and cannot currently be scheduled. It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {node:172.22.225.108: 1.000000}, {CPU: 2.000000}, {memory: 16.113281 GiB}, {GPU: 1.000000}, {object_store_memory: 5.566406 GiB}. In total there are 0 pending tasks and 2 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.
&lt;/denchmark-code&gt;

python           3.6
ray                  0.9.0.dev0 (same behavior with 0.8.0)
torch               1.3.1
&lt;denchmark-h:h3&gt;Reproduction&lt;/denchmark-h&gt;

An example to reproduce the error is simply the example on MNIST:
import torch.optim as optim
from ray import tune
from ray.tune.examples.mnist_pytorch import get_data_loaders, ConvNet, train, test


def train_mnist(config):
    train_loader, test_loader = get_data_loaders()
    model = ConvNet()
    optimizer = optim.SGD(model.parameters(), lr=config["lr"])
    for i in range(10):
        train(model, optimizer, train_loader)
        acc = test(model, test_loader)
        tune.track.log(mean_accuracy=acc)


analysis = tune.run(
    train_mnist, config={"lr": tune.grid_search([0.001, 0.01, 0.1])})

print("Best config: ", analysis.get_best_config(metric="mean_accuracy"))

# Get a dataframe for analyzing trial results.
df = analysis.dataframe()
Thank you very much in advance.
	</description>
	<comments>
		<comment id='1' author='camcastera' date='2020-01-13T20:22:26Z'>
		This looks quite odd -- the resource string seems to suggest there are available resources.

It requires {CPU: 1.000000} for execution and {CPU: 1.000000} for placement, but this node only has remaining {node:172.22.225.108: 1.000000}, {CPU: 2.000000}, {memory: 16.113281 GiB}, {GPU: 1.000000}, {object_store_memory: 5.566406 GiB}

cc &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='camcastera' date='2020-01-14T10:04:02Z'>
		I found the solution.
The issues comes from the fact that I was installing ray inside a virtual environment, which worked as you can see below.
&lt;denchmark-code&gt;which ray
/home/Documents/PytorchEnv/bin/ray
&lt;/denchmark-code&gt;

but even with the environment activated, Ipython was referring to the one of the system.
&lt;denchmark-code&gt;which ipython
/usr/local/bin/ipython
&lt;/denchmark-code&gt;

Reinstalling Ipython inside the virtual environment fixed it for me.
Thanks for your help.
		</comment>
		<comment id='3' author='camcastera' date='2020-05-10T11:42:54Z'>
		&lt;denchmark-link:https://github.com/camcastera&gt;@camcastera&lt;/denchmark-link&gt;

The same issue &lt;denchmark-link:https://github.com/ray-project/ray/issues/8326#issuecomment-626314227&gt;#8326 (comment)&lt;/denchmark-link&gt;
, why reinstalling ipython can help? How to set the number of CPUs for execution and placement respectively?
		</comment>
		<comment id='4' author='camcastera' date='2020-05-10T12:37:14Z'>
		To be more specific, ray was installed inside a virtual environment, but ipython was not installed inside this environment. Thus, when activating the environment and using the command ipython it was actually launching the ipython from the system which was not the one ray was supposed to be working with. That is why installing ipython inside the environment solved it for me.
More generally if you have multiple versions of python and/or virtual environments installed, make sure you use the same python version as the one ray was installed with.
		</comment>
		<comment id='5' author='camcastera' date='2020-10-14T09:30:10Z'>
		How is this related to ipython? Are you running it from a notebook?
I have the same problem, but I'm not running RLlib from a notebook but calling it inside my code, which I run from command line.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Solved: It does seem to have sth to do with the virtual environment. I completely deleted my virtualenv and created a new one, installing everything a new, and it solved the problem.
Just uninstalling and reinstalling ray within the old virtualenv didn't help.
Not sure why.
		</comment>
	</comments>
</bug>