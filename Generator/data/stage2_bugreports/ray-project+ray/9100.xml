<bug id='9100' author='pengzhenghao' open_date='2020-06-23T07:21:44Z' closed_time='2020-07-15T17:42:13Z'>
	<summary>SAC-pytorch is not working with atari</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
SAC-pytorch is not working with atari! Seems related to bug in pytorch.
python 3.7
ray 0.8.5
torch 1.5.1
torch vision 0.6.1
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
rllib train --run SAC --env "Pong-v0" --config '{"use_pytorch": true}'
Error looks like:
&lt;denchmark-code&gt;2020-06-23 15:18:52,349 ERROR trial_runner.py:519 -- Trial SAC_Pong-v0_00000: Error processing event.
Traceback (most recent call last):
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 467, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 431, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/worker.py", line 1515, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ZeroDivisionError): ray::SAC.train() (pid=9305, ip=192.168.31.23)
  File "python/ray/_raylet.pyx", line 424, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 459, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 462, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 463, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 417, in ray._raylet.execute_task.function_executor
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 90, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 448, in __init__
    super().__init__(config, logger_creator)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/tune/trainable.py", line 174, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 591, in _setup
    self._init(self.config, self.env_creator)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 117, in _init
    self.config["num_workers"])
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 662, in _make_workers
    logdir=self.logdir)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 61, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 279, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 391, in __init__
    policy_dict, policy_config)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 861, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/policy/torch_policy_template.py", line 109, in __init__
    self, obs_space, action_space, config)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/sac/sac_torch_policy.py", line 23, in build_sac_model_and_action_dist
    model = build_sac_model(policy, obs_space, action_space, config)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/sac/sac_tf_policy.py", line 75, in build_sac_model
    target_entropy=config["target_entropy"])
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/models/catalog.py", line 355, in get_model_v2
    name, **model_kwargs)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/agents/sac/sac_torch_model.py", line 83, in __init__
    activation_fn=activation))
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/ray/rllib/models/torch/misc.py", line 98, in __init__
    linear = nn.Linear(in_size, out_size)
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 77, in __init__
    self.reset_parameters()
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 80, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/Users/pengzhenghao/opt/anaconda3/envs/selfplay/lib/python3.7/site-packages/torch/nn/init.py", line 324, in kaiming_uniform_
    std = gain / math.sqrt(fan)
ZeroDivisionError: float division by zero
&lt;/denchmark-code&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='pengzhenghao' date='2020-07-15T17:42:13Z'>
		Can you try with the latest ray release? It should be fine now. There is an SAC compilation test that proves this:
rllib/agents/sac/tests/test_sac.py::TestSAC::test_sac_compilation
It loops through all frameworks (pytorch included) and makes sure SAC runs on Atari envs as well.
Your command line also would change with the new release to:
rllib train --run SAC --env "Pong-v0" --config '{"framework": "torch"}'
		</comment>
		<comment id='2' author='pengzhenghao' date='2020-07-15T20:36:03Z'>
		&lt;denchmark-link:https://github.com/pengzhenghao&gt;@pengzhenghao&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='pengzhenghao' date='2020-07-16T03:15:37Z'>
		
Can you try with the latest ray release? It should be fine now. There is an SAC compilation test that proves this:
rllib/agents/sac/tests/test_sac.py::TestSAC::test_sac_compilation
It loops through all frameworks (pytorch included) and makes sure SAC runs on Atari envs as well.
Your command line also would change with the new release to:
rllib train --run SAC --env "Pong-v0" --config '{"framework": "torch"}'

&lt;denchmark-link:https://github.com/sven1977&gt;@sven1977&lt;/denchmark-link&gt;
  Great! Torch version SAC is working now (not sure if the performance match tf).
BTW, I found a strange error if there is no torch installed (It seems the policy falls back to TFPolicy if no pytorch installed? I am not sure):
&lt;denchmark-code&gt;(pid=11562) Traceback (most recent call last):
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1367, in _do_call
(pid=11562)     return fn(*args)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1352, in _run_fn
(pid=11562)     target_list, run_metadata)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1445, in _call_tf_sessionrun
(pid=11562)     run_metadata)
(pid=11562) tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [1,256], In[1]: [0,256]
(pid=11562) 	 [[{{node default_policy/sequential_6/action_1/Relu}}]]
(pid=11562)
(pid=11562) During handling of the above exception, another exception occurred:
(pid=11562)
(pid=11562) Traceback (most recent call last):
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py", line 44, in get
(pid=11562)     self.feed_dict, os.environ.get("TF_TIMELINE_DIR"))
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py", line 89, in run_timeline
(pid=11562)     fetches = sess.run(ops, feed_dict=feed_dict)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 960, in run
(pid=11562)     run_metadata_ptr)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1183, in _run
(pid=11562)     feed_dict_tensor, options, run_metadata)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1361, in _do_run
(pid=11562)     run_metadata)
(pid=11562)   File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1386, in _do_call
(pid=11562)     raise type(e)(node_def, op, message)
(pid=11562) tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [1,256], In[1]: [0,256]
(pid=11562) 	 [[node default_policy/sequential_6/action_1/Relu (defined at /ray/rllib/agents/sac/sac_tf_model.py:187) ]]
(pid=11562)
(pid=11562) Original stack trace for 'default_policy/sequential_6/action_1/Relu':
(pid=11562)   File "/ray/workers/default_worker.py", line 123, in &lt;module&gt;
(pid=11562)     ray.worker.global_worker.main_loop()
(pid=11562)   File "/ray/worker.py", line 374, in main_loop
(pid=11562)     self.core_worker.run_task_loop()
(pid=11562)   File "/ray/function_manager.py", line 559, in actor_method_executor
(pid=11562)     method_returns = method(actor, *args, **kwargs)
(pid=11562)   File "/ray/rllib/agents/trainer_template.py", line 90, in __init__
(pid=11562)     Trainer.__init__(self, config, env, logger_creator)
(pid=11562)   File "/ray/rllib/agents/trainer.py", line 450, in __init__
(pid=11562)     super().__init__(config, logger_creator)
(pid=11562)   File "/ray/tune/trainable.py", line 175, in __init__
(pid=11562)     self._setup(copy.deepcopy(self.config))
(pid=11562)   File "/ray/rllib/agents/trainer.py", line 623, in _setup
(pid=11562)     self._init(self.config, self.env_creator)
(pid=11562)   File "/ray/rllib/agents/trainer_template.py", line 115, in _init
(pid=11562)     self.config["num_workers"])
(pid=11562)   File "/ray/rllib/agents/trainer.py", line 696, in _make_workers
(pid=11562)     logdir=self.logdir)
(pid=11562)   File "/ray/rllib/evaluation/worker_set.py", line 59, in __init__
(pid=11562)     RolloutWorker, env_creator, policy, 0, self._local_config)
(pid=11562)   File "/ray/rllib/evaluation/worker_set.py", line 282, in _make_worker
(pid=11562)     extra_python_environs=extra_python_environs)
(pid=11562)   File "/ray/rllib/evaluation/rollout_worker.py", line 379, in __init__
(pid=11562)     self._build_policy_map(policy_dict, policy_config)
(pid=11562)   File "/ray/rllib/evaluation/rollout_worker.py", line 937, in _build_policy_map
(pid=11562)     policy_map[name] = cls(obs_space, act_space, merged_conf)
(pid=11562)   File "/ray/rllib/policy/tf_policy_template.py", line 143, in __init__
(pid=11562)     obs_include_prev_action_reward=obs_include_prev_action_reward)
(pid=11562)   File "/ray/rllib/policy/dynamic_tf_policy.py", line 208, in __init__
(pid=11562)     is_training=self._input_dict["is_training"])
(pid=11562)   File "/ray/rllib/agents/sac/sac_tf_policy.py", line 128, in get_distribution_inputs_and_class
(pid=11562)     distribution_inputs = model.get_policy_output(model_out)
(pid=11562)   File "/ray/rllib/agents/sac/sac_tf_model.py", line 187, in get_policy_output
(pid=11562)     return self.action_model(model_out)
(pid=11562)   File "/tensorflow_core/python/keras/engine/base_layer.py", line 778, in __call__
(pid=11562)     outputs = call_fn(cast_inputs, *args, **kwargs)
(pid=11562)   File "/tensorflow_core/python/keras/engine/sequential.py", line 281, in call
(pid=11562)     outputs = layer(inputs, **kwargs)
(pid=11562)   File "/tensorflow_core/python/keras/engine/base_layer.py", line 778, in __call__
(pid=11562)     outputs = call_fn(cast_inputs, *args, **kwargs)
(pid=11562)   File "/tensorflow_core/python/keras/layers/core.py", line 1146, in call
(pid=11562)     return self.activation(outputs)  # pylint: disable=not-callable
(pid=11562)   File "/tensorflow_core/python/ops/gen_nn_ops.py", line 10051, in relu
(pid=11562)     "Relu", features=features, name=name)
(pid=11562)   File "/tensorflow_core/python/framework/op_def_library.py", line 742, in _apply_op_helper
(pid=11562)     attrs=attr_protos, op_def=op_def)
(pid=11562)   File "/tensorflow_core/python/framework/ops.py", line 3322, in _create_op_internal
(pid=11562)     op_def=op_def)
(pid=11562)   File "/tensorflow_core/python/framework/ops.py", line 1756, in __init__
(pid=11562)     self._traceback = tf_stack.extract_stack()
(pid=11562)
2020-07-16 11:10:34,195	ERROR trial_runner.py:520 -- Trial SAC_Pong-v0_de946_00000: Error processing event.
Traceback (most recent call last):
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 468, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 430, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/worker.py", line 1474, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(InvalidArgumentError): ray::SAC.train() (pid=11562, ip=10.1.72.24)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1352, in _run_fn
    target_list, run_metadata)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1445, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [1,256], In[1]: [0,256]
	 [[{{node default_policy/sequential_6/action_1/Relu}}]]

During handling of the above exception, another exception occurred:

ray::SAC.train() (pid=11562, ip=10.1.72.24)
  File "python/ray/_raylet.pyx", line 442, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 446, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 400, in ray._raylet.execute_task.function_executor
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 500, in train
    raise e
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 486, in train
    result = Trainable.train(self)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/tune/trainable.py", line 261, in train
    result = self._train()
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 132, in _train
    return self._train_exec_impl()
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 170, in _train_exec_impl
    res = next(self.train_exec_impl)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 731, in __next__
    return next(self.built_iterator)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 744, in apply_foreach
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 814, in apply_filter
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 814, in apply_filter
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 744, in apply_foreach
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 814, in apply_filter
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 1047, in build_union
    item = next(it)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 731, in __next__
    return next(self.built_iterator)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 744, in apply_foreach
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 744, in apply_foreach
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/util/iter.py", line 744, in apply_foreach
    for item in it:
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/execution/rollout_ops.py", line 70, in sampler
    yield workers.local_worker().sample()
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 528, in sample
    batches = [self.input_reader.next()]
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 59, in next
    batches = [self.get_data()]
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 164, in get_data
    item = next(self.rollout_provider)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 500, in _env_runner
    tf_sess=tf_sess)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/evaluation/sampler.py", line 830, in _do_policy_eval
    eval_results[pid] = builder.get(v)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py", line 48, in get
    raise e
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py", line 44, in get
    self.feed_dict, os.environ.get("TF_TIMELINE_DIR"))
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/ray/rllib/utils/tf_run_builder.py", line 89, in run_timeline
    fetches = sess.run(ops, feed_dict=feed_dict)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 960, in run
    run_metadata_ptr)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1361, in _do_run
    run_metadata)
  File "/home/zhpeng/anaconda3/envs/dice/lib/python3.7/site-packages/tensorflow_core/python/client/session.py", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Matrix size-incompatible: In[0]: [1,256], In[1]: [0,256]
	 [[node default_policy/sequential_6/action_1/Relu (defined at /ray/rllib/agents/sac/sac_tf_model.py:187) ]]
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>