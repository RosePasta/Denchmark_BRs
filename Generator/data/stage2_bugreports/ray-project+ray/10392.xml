<bug id='10392' author='yangw1234' open_date='2020-08-28T07:49:20Z' closed_time='2020-10-19T02:30:29Z'>
	<summary>Console output got relipated n times if there are n ray nodes on the same machine</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Ray version: 0.8.7
Python version:  3.6.7
Problem:
If multiple ray nodes (say n ray nodes) are started on the same machine, then one ray nodes' console output will got replicated n times on driver.
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
Step 1: start two ray nodes on the same machine
ray start --head
ray start --address='the address printed' --redis-password='the password printed'
Step 2: run the following script
import ray
def print_hello():
    print("hello")
    return 0

remote_print = ray.remote(print_hello)
ray.get(remote_print.remote())
Then "hello" will be printed twice on the driver.
&lt;denchmark-link:https://user-images.githubusercontent.com/10561966/91535616-ff180180-e945-11ea-8e64-14d469897824.png&gt;&lt;/denchmark-link&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='yangw1234' date='2020-08-28T07:51:48Z'>
		It is not recommended to run multiple ray nodes in the same machine. Is it reproducible when it is running in multiple machines?
		</comment>
		<comment id='2' author='yangw1234' date='2020-08-28T07:52:10Z'>
		Also, if you need to run multiple nodes in a single machine, would you mind sharing your use case?
		</comment>
		<comment id='3' author='yangw1234' date='2020-08-28T08:02:11Z'>
		Hi &lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
, I only observe this when running multiple ray nodes in the same machine.
We are actually running on a multi-sockets machine and we want to bind ray processes to different numa nodes to achieve best performance.
Is there a way to do this without starting multiple ray nodes?
		</comment>
		<comment id='4' author='yangw1234' date='2020-08-28T08:09:42Z'>
		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
 it seems all ray nodes shard the same log directory on the same machine, and all ray nodes have a log_monitor monitoring the same log directory. As a result, when one worker prints something, all log_monitor will see it and forward it to the driver.
		</comment>
		<comment id='5' author='yangw1234' date='2020-08-28T08:14:46Z'>
		Is there a way to set this logging directory manually?
		</comment>
		<comment id='6' author='yangw1234' date='2020-08-28T21:11:59Z'>
		Yes I think you can use this command arg &lt;denchmark-link:https://docs.ray.io/en/latest/package-ref.html#cmdoption-ray-start-temp-dir&gt;https://docs.ray.io/en/latest/package-ref.html#cmdoption-ray-start-temp-dir&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='yangw1234' date='2020-08-31T06:21:06Z'>
		&lt;denchmark-link:https://github.com/rkooo567&gt;@rkooo567&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/python/ray/node.py#L233&gt;https://github.com/ray-project/ray/blob/master/python/ray/node.py#L233&lt;/denchmark-link&gt;
, seems non-head ray process just read the "temp_dir" set to head node, and each ray node cannot be assigned to different log dir.
I worked around this issue by manually killing the redundant log_monitor processes. However, I think it would be nice to support it in ray. E.g. separating each ray nodes' log dir to "/tmp/ray/session-xx/0/logs", "/tmp/ray/session-xxx/1/logs", .etc
		</comment>
		<comment id='8' author='yangw1234' date='2020-10-16T17:18:50Z'>
		I am seeing this on latest 1.0.0 , worker stdout / stderr is duplicated to all of the workers. It *was fixed in 0.9.0  and I have had to pin to this release: &lt;denchmark-link:https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp35-cp35m-manylinux1_x86_64.whl&gt;https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp35-cp35m-manylinux1_x86_64.whl&lt;/denchmark-link&gt;

I am trying to find the original issue where this was addressed. Anyone know why this has Resurfaced in 1.0.0?
I am running multiple worker procs under supervisor to process messages from a an AMQP queue.  Each pid is replicating the stdout of each-other where as in 0.9.0 the logs are correctly only logged by the respective process and not duplicated.
		</comment>
		<comment id='9' author='yangw1234' date='2020-10-17T05:09:19Z'>
		Hmm interesting. cc &lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
 Doesn't this mean our log_monitor per job is broken?
		</comment>
		<comment id='10' author='yangw1234' date='2020-10-17T05:09:34Z'>
		&lt;denchmark-link:https://github.com/byoung0589&gt;@byoung0589&lt;/denchmark-link&gt;
 Can you give us a simple script to reproduce this? We can probably find a quick fix.
		</comment>
		<comment id='11' author='yangw1234' date='2020-10-17T05:09:46Z'>
		Also please open an new issue! So that we won't lose the track of it.
		</comment>
		<comment id='12' author='yangw1234' date='2020-10-17T22:47:37Z'>
		Sure , thanks. Our setup is kind of complex I will write something simple to demonstrate the issue and create a seperate issue here for it.
		</comment>
		<comment id='13' author='yangw1234' date='2020-10-19T02:30:29Z'>
		I'll close this issue for now since you will open a new issue with the repro
		</comment>
	</comments>
</bug>