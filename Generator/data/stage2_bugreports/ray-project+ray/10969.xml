<bug id='10969' author='bentzinir' open_date='2020-09-23T05:33:42Z' closed_time='2020-10-16T21:37:59Z'>
	<summary>[rllib] sample_batch_builder: pre batch is passed "by reference" (and not copied) to postprocessing function</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

function postprocess_batch_so_far sends the batches to postprocessing. The batches from other agents are copied before sent (other_batches = pre_batches.copy()), while the "self" batch, i.e. the own batch of the agent is sent without being copied and is edited in place.
As a result, after iterating the first agent, the second agent will receive the post-processed batch of the first agent and not the pre-batch.
Ray version and other system information (Python version, TensorFlow version, OS):
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='bentzinir' date='2020-09-24T18:56:34Z'>
		Hmm, I realized that we never in fact deep copy the batches, only the dictionary containing them. If we were to add a copy, this could add a significant amount of overhead.
I assume you're running into this issue since your postprocessing is mutating the batch? Is it possible to add new fields instead of updating existing ones?
		</comment>
		<comment id='2' author='bentzinir' date='2020-09-25T08:26:50Z'>
		Yes, it's possible.
Do you want to restrict postprocessing to allow addition and prohibit mutation?
		</comment>
		<comment id='3' author='bentzinir' date='2020-10-08T19:27:32Z'>
		
We should not copy just for the sake of having the exact pre-batch data available.
postprocessing is allowed to a) mutate and b) create new columns. Both are supported.

		</comment>
		<comment id='4' author='bentzinir' date='2020-10-10T17:47:41Z'>
		To my understanding mutation is not possible.
Say for example I want to average the rewards of two agents: {r_0: 0, r_1:10}.
When the batch of agent_0 is postprocessed, the reward field is edited in place to r_0=5.
When the batch of agent_1 is postprocessed, it will see r_0=5 and not r_0=0 as it should be.
		</comment>
		<comment id='5' author='bentzinir' date='2020-10-10T18:05:57Z'>
		In that case, how about defining a new avg_reward field and use that in the
policy loss instead of the original?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sat, Oct 10, 2020, 10:47 AM bentzinir ***@***.***&gt; wrote:
 To my understanding mutation is not possible.
 Say for example I want to average the rewards of two agents: {r_0: 0,
 r_1:10}.
 When the batch of agent_0 is postprocessed, the reward field is edited *in
 place* to r_0=5.
 When the batch of agent_1 is postprocessed, it will see r_0=5 and not
 r_0=0 as it should be.

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub
 &lt;#10969 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AAADUSRKMSQ7VUCMMQZVFULSKCM4VANCNFSM4RWSZQWA&gt;
 .



		</comment>
		<comment id='6' author='bentzinir' date='2020-10-10T18:30:44Z'>
		Of course. If the overhead of mutation is too expensive I'll go with that.
		</comment>
		<comment id='7' author='bentzinir' date='2020-10-16T21:37:59Z'>
		Closing this, since I think the copy is too expensive to support by default and there is a workaround.
		</comment>
	</comments>
</bug>