<bug id='10338' author='janblumenkamp' open_date='2020-08-26T10:55:01Z' closed_time='2020-08-26T16:55:58Z'>
	<summary>[rllib] Weights &amp; Biases integration doesn't work for RLlib</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

If I try to integrate Weights &amp; Biases according to the &lt;denchmark-link:https://docs.ray.io/en/releases-0.8.7/tune/tutorials/tune-wandb.html&gt;relevant tune docs page&lt;/denchmark-link&gt;
 with RLlib, it crashes saying "Unknown config parameter ".
&lt;denchmark-code&gt;2020-08-26 11:31:51,029 ERROR trial_runner.py:523 -- Trial PPO_CartPole-v0_58d06_00000: Error processing event.
Traceback (most recent call last):           
  File "[...]/ray/tune/trial_runner.py", line 471, in _process_trial
    result = self.trial_executor.fetch_result(trial)             
  File "[...]/ray/tune/ray_trial_executor.py", line 430, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)                
  File "[...]/ray/worker.py", line 1538, in get
    raise value.as_instanceof_cause()                                     
ray.exceptions.RayTaskError: ray::PPO.train() (pid=32088, ip=128.232.69.20)
  File "python/ray/_raylet.pyx", line 439, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 474, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 478, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 432, in ray._raylet.execute_task.function_executor
  File "[...]/ray/rllib/agents/trainer_template.py", line 88, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "[...]/ray/rllib/agents/trainer.py", line 479, in __init__
    super().__init__(config, logger_creator)
  File "[...]/ray/tune/trainable.py", line 245, in __init__
    self.setup(copy.deepcopy(self.config))
  File "[...]/ray/rllib/agents/trainer.py", line 580, in setup
    config)
  File "[...]/ray/rllib/agents/trainer.py", line 1067, in merge_trainer_configs
    cls._override_all_subkeys_if_type_changes)
  File "[...]/ray/tune/utils/util.py", line 181, in deep_update
    raise Exception("Unknown config parameter `{}` ".format(k))
Exception: Unknown config parameter `wandb`
&lt;/denchmark-code&gt;


Ray 0.8.7
Ubuntu 18.04
Python 3.7

&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
&lt;denchmark-code&gt;from ray import tune
from ray.rllib.agents.ppo import PPOTrainer
from ray.tune.logger import DEFAULT_LOGGERS
from ray.tune.integration.wandb import WandbLogger

tune.run(
    PPOTrainer,
    checkpoint_freq=1,
    config={
        "framework": "torch",
        "num_workers": 8,
        "num_gpus": 1,
        "env": "CartPole-v0",
        "wandb": {
            "project": "test",
            "api_key_file": "./wandb_api_key_file",
        }
    },
    stop={
        "training_iteration":1
    },
    loggers=DEFAULT_LOGGERS + (WandbLogger, )
)
&lt;/denchmark-code&gt;

If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='janblumenkamp' date='2020-08-26T16:45:50Z'>
		cc &lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/richardliaw&gt;@richardliaw&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='janblumenkamp' date='2020-08-26T16:52:15Z'>
		Hi &lt;denchmark-link:https://github.com/janblumenkamp&gt;@janblumenkamp&lt;/denchmark-link&gt;
, we addressed this issue recently in &lt;denchmark-link:https://github.com/ray-project/ray/pull/10252&gt;#10252&lt;/denchmark-link&gt;

Basically, you'll have to wrap the wandb config in a logger_config key:
&lt;denchmark-code&gt;tune.run(
    PPOTrainer,
    checkpoint_freq=1,
    config={
        "framework": "torch",
        "num_workers": 8,
        "num_gpus": 1,
        "env": "CartPole-v0",
        "logger_config" : {
            "wandb": {
                "project": "test",
                "api_key_file": "./wandb_api_key_file",
            }
        }
    },
    stop={
        "training_iteration":1
    },
    loggers=DEFAULT_LOGGERS + (WandbLogger, )
)
&lt;/denchmark-code&gt;

We'll make sure to add documentation for this integration soon.
		</comment>
		<comment id='3' author='janblumenkamp' date='2020-08-26T16:55:58Z'>
		Addendum: It is actually documented &lt;denchmark-link:https://docs.ray.io/en/master/tune/tutorials/tune-wandb.html&gt;here in the latest master docs&lt;/denchmark-link&gt;
. You'll have to install &lt;denchmark-link:https://docs.ray.io/en/latest/installation.html#latest-snapshots-nightlies&gt;Ray nightly&lt;/denchmark-link&gt;
 to make it work.
Let me know if you have further questions.
		</comment>
		<comment id='4' author='janblumenkamp' date='2020-08-26T16:59:06Z'>
		Ah, thanks a lot, I overlooked it in the master docs!
		</comment>
		<comment id='5' author='janblumenkamp' date='2020-12-07T00:18:13Z'>
		Hi &lt;denchmark-link:https://github.com/krfricke&gt;@krfricke&lt;/denchmark-link&gt;
,
I followed your instruction (&lt;denchmark-link:https://github.com/ray-project/ray/issues/10338#issuecomment-680999888&gt;#10338 (comment)&lt;/denchmark-link&gt;
) to wrap the wandb config in a logger_config key and now I get this:
&lt;denchmark-code&gt;til.py", line 181, in deep_update
    raise Exception("Unknown config parameter `{}` ".format(k))
Exception: Unknown config parameter `logger_config`

&lt;/denchmark-code&gt;

What I'm missing?
		</comment>
		<comment id='6' author='janblumenkamp' date='2020-12-07T17:19:51Z'>
		Hi &lt;denchmark-link:https://github.com/hnekoeiq&gt;@hnekoeiq&lt;/denchmark-link&gt;

the example above does work for me - which version are you on?
Anyway, in the latest master we refactored the loggers. You can now pass fully configured callbacks to tune.run();
&lt;denchmark-link:https://docs.ray.io/en/master/tune/api_docs/integration.html#weights-and-biases-tune-integration-wandb&gt;Here are the docs for the wandb logger.&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;from ray.tune.integration.wandb import WandbLoggerCallback

tune.run(
    PPOTrainer,
    checkpoint_freq=1,
    config={
        "framework": "torch",
        "num_workers": 8,
        "num_gpus": 1,
        "env": "CartPole-v0"
    },
    stop={
        "training_iteration":1
    },
    callbacks=[WandbLoggerCallback(project="test", api_key_file="~/.wandb_api+key")]
)

&lt;/denchmark-code&gt;

Please notice that this only works on the current master (or the nightly wheels) but not in the latest release. It will be included in the next release (1.2.0).
		</comment>
		<comment id='7' author='janblumenkamp' date='2020-12-17T07:04:34Z'>
		Just spent 30-40 mins on this too before I found this issue. Would be nice to put something in the docs saying this doesn't work right now...
Any eta on when 1.2.0 comes?
		</comment>
	</comments>
</bug>