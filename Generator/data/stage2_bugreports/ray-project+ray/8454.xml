<bug id='8454' author='RaedShabbir' open_date='2020-05-15T04:03:49Z' closed_time='2020-05-15T05:50:30Z'>
	<summary>[ray][tune] Ray Autoscalar FileNotFoundError with CustomEnv</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

When using auto scaling distributed training with a custom environment, the environment creation process fails due to a FileNotFoundError: [Errno 2] .
Some steps I've taken to ensure the file exists and should be read properly:


The cluster.yaml file transfers a folder with the relevant files upon running ray up


I have verified that the file does exist on the cluster head at the exact path described in the error


I have verified that the file also exists on a single spot instance child node that was spawned by autoscalar from ray submit


The error seems to persist even if ray submit doesn't spawn any child nodes


The error does not persist if instead of ray submit I run with my custom env after sshing into the cluster (so likely comes from the autoscaler?)


Ray version and other system information (Python version, TensorFlow version, OS):
Tried with
ray                    0.8.5
torch                  1.5.0
tensorflow             2.2.0
Python 3.7.6
Running on WSL2 VERSION="18.04.4 LTS (Bionic Beaver)"
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

I have attached the stack trace that go with this process, can create a script to replicate this if still required.
Possible Source of Error:
Despite seeing that the files have been correctly transfered via ssh, I see the following error from the NodeUpdater between every file update.
Running mkdir -p ~ on &lt;IP&gt; bash: cannot set terminal process group (-1): Inappropriate ioctl for device bash: no job control in this shell
Error Traceback from PPO:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 467, in _process_trial
    result = self.trial_executor.fetch_result(trial)

  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 431, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/worker.py", line 1515, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(FileNotFoundError): ray::PPO.train() (pid=3818, ip=&lt;IP&gt;)
  
File "python/ray/_raylet.pyx", line 424, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 459, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 462, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 463, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 417, in ray._raylet.execute_task.function_executor
 
 File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 90, in __init__
    Trainer.__init__(self, config, env, logger_creator)
 
 File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 448, in __init__
    super().__init__(config, logger_creator)
 
 File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/tune/trainable.py", line 174, in __init__
    self._setup(copy.deepcopy(self.config))
 
 File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 591, in _setup
    self._init(self.config, self.env_creator)
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 117, in _init
    self.config["num_workers"])
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 662, in _make_workers
    logdir=self.logdir)
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 61, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 279, in _make_worker
    extra_python_environs=extra_python_environs)
  
File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 303, in __init__
    self.env = _validate_env(env_creator(env_context))
&lt;/denchmark-code&gt;

Which then leads to a file not found error

 I have verified my script runs in a clean environment and reproduces the issue.
[ X] I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='RaedShabbir' date='2020-05-15T05:50:14Z'>
		Issue was resolved by updating to ray == 0.9.0.dev0.
		</comment>
	</comments>
</bug>