<bug id='4626' author='opherlieber' open_date='2019-04-14T12:43:03Z' closed_time='2020-03-07T07:27:43Z'>
	<summary>[rllib] wrong target discount in DQN in case of truncated n_step</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
Ray installed from (source or binary): source
Ray version: master branch
Python version: 3.6
Exact command to reproduce:

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

In DQN, when using 'truncate_episodes' batch_mode, it looks like the last &lt;n_step-1&gt; samples in each sample batch get a truncated n_step. In particular the last sample will get an n_step of 1 and it's target/NEXT_OBS will be the actual next observation.
In the loss calculation though all samples get the full n_step discount (gamma**n_step) for the target value, even if they are truncated.
I don't know how critical if at all this is, I assume not so much for small n_step and/or large sample_batch_size, but for n_step of 10/20 the discount difference can be large.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='opherlieber' date='2019-04-14T20:48:06Z'>
		Yeah, I think you are right, the target calculation should also take into account the truncated n_step. Though as you point out for small n the error is trivial.
cc &lt;denchmark-link:https://github.com/joneswong&gt;@joneswong&lt;/denchmark-link&gt;
 what do you think?
		</comment>
		<comment id='2' author='opherlieber' date='2019-04-15T02:40:54Z'>
		yes, this is a problem. I am afraid that taking this into consideration by the TF computation graph is costly. How about post-processing batch_size + n each samples each time to generate batch_size ones for training, and then we continue interaction with the last n samples reserved.
		</comment>
		<comment id='3' author='opherlieber' date='2019-04-15T02:44:39Z'>
		Hm, that was the old strategy but it has bad behaviour around rollout boundaries.
Is it expensive to take the n into account? We could feed an array of the actual n step value used for each transition.
		</comment>
		<comment id='4' author='opherlieber' date='2019-04-15T03:25:02Z'>
		I forgot the assert not any(dones[:-1]), "Unexpected done in middle of trajectory" assertion in the _adjust_nstep method. It seems that each postprocessed trajectory has only one done mask at the end. In this case, the last n-1 samples have done=True and thus gamma ** n would not introduce any bias.
		</comment>
		<comment id='5' author='opherlieber' date='2019-04-15T12:10:59Z'>
		
I forgot the assert not any(dones[:-1]), "Unexpected done in middle of trajectory" assertion in the _adjust_nstep method. It seems that each postprocessed trajectory has only one done mask at the end. In this case, the last n-1 samples have done=True and thus gamma ** n would not introduce any bias.

It only validates that the trajectories don't have a 'done' in the middle (i.e. only allows 'done' at the end, but doesn't require it), but the trajectories can still have no 'done' at all if they are from the middle of an episode (when using 'truncate_episodes'), this is usually the case for long episodes.
		</comment>
		<comment id='6' author='opherlieber' date='2019-04-15T14:13:13Z'>
		my fault...so we cannot depend on that the last n-1 samples do not need the estimated target q values. Besides, as the correct discount factor changes according to the done_masks of the last n-1 samples, it is not viable to prepare a fixed array of discount factors. Thus, I think we'd better change Sampler to enable the old strategy.
		</comment>
		<comment id='7' author='opherlieber' date='2019-04-15T16:09:10Z'>
		We can compute a dynamic array of discounts and feed that in right? For example vtrace does this, though we feed in a constant array.
		</comment>
		<comment id='8' author='opherlieber' date='2019-04-16T03:02:36Z'>
		
We can compute a dynamic array of discounts and feed that in right? For example vtrace does this, though we feed in a constant array.

I guess that [gamma**n, ..., gamma**n, gamma**(n-1), ..., gamma**1] is always viable, since we have correctly propagated the done_mask which enables transitions with done_mask==True to ignore the correct/incorrect discounts.
		</comment>
		<comment id='9' author='opherlieber' date='2019-04-17T05:34:36Z'>
		&lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
 Hi Eric, Am I wrong? or you will prepare a dynamic array?


We can compute a dynamic array of discounts and feed that in right? For example vtrace does this, though we feed in a constant array.

I guess that [gamman, ..., gamman, gamma**(n-1), ..., gamma**1] is always viable, since we have correctly propagated the done_mask which enables transitions with done_mask==True to ignore the correct/incorrect discounts.

		</comment>
		<comment id='10' author='opherlieber' date='2019-04-17T16:16:20Z'>
		That sounds like a reasonable solution to me, and also this idea of passing in the discounts separately per step seems pretty common in RL algorithms.
		</comment>
		<comment id='11' author='opherlieber' date='2019-04-18T03:25:07Z'>
		&lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
  very sorry for my mistakes. I considered again. The problem is, for each (s, a, r, done, s') sampled from replay buffer, how could we know that the actual . For those whose , any  makes no difference. As for those whose , we should have assigned appropriate  but currently we harshly give a fixed one. Without changing to the old strategy of sampling, we need the actual TD distance  to be in the training data. Otherwise, how could you feed the dynamic array of discount factors?
		</comment>
		<comment id='12' author='opherlieber' date='2019-04-18T19:27:42Z'>
		Could we store it in the replay buffer as well?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Apr 17, 2019, 8:25 PM Jones Wong ***@***.***&gt; wrote:
 @ericl &lt;https://github.com/ericl&gt; very sorry for my mistakes. I
 considered again. The problem is, for each (s, a, r, done, s') sampled from
 replay buffer, how could we know that the actual n. For those whose
 done==True, any n makes no difference. As for those whose done==False, we
 should have assigned appropriate n but currently we harshly give a fixed
 one. Without changing to the old strategy of sampling, we need the actual
 TD distance n to be in the training data. Otherwise, how could you feed
 the dynamic array of discount factors?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#4626 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAADUSUAGOA2MRYCXD3F57TPQ7S2JANCNFSM4HF2MDRA&gt;
 .



		</comment>
		<comment id='13' author='opherlieber' date='2019-04-19T02:05:55Z'>
		&lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;
 definitely yes, but my concern is that most transitions are just corresponding to gamma ** n. If we add a field in replay buffer to store the discount factors, the developers may feel redundant and cumbersome.
		</comment>
		<comment id='14' author='opherlieber' date='2020-03-07T07:27:43Z'>
		Won't fix.
		</comment>
	</comments>
</bug>