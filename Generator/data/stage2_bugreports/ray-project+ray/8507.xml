<bug id='8507' author='waldroje' open_date='2020-05-19T20:27:13Z' closed_time='2020-06-25T13:07:35Z'>
	<summary>[rllib] Pytorch missing custom loss</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

Running rllib/examples/custom_loss.py example, the tensorflow implementation displays the custom loss, but Pytorch does not.  During the process, I had to update the rllib/examples/models/custom_loss_model.py models method name from custom_stats to metrics.
Ray version and other system information (Python version, TensorFlow version, OS):
Ray version: latest wheel
Python: 3.6.8
TF: 2.1
OS: RHEL 7.7
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
Use existing example script in Rllib
If we cannot run your script, we cannot fix your issue.

[x ] I have verified my script runs in a clean environment and reproduces the issue.
[x ] I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='waldroje' date='2020-05-20T19:53:59Z'>
		&lt;denchmark-link:https://github.com/ray-project/ray/issues/8193&gt;#8193&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='waldroje' date='2020-05-21T10:34:41Z'>
		Sorry, this may have slipped through the cracks. I'll take a look and provide the missing example.
		</comment>
		<comment id='3' author='waldroje' date='2020-05-21T10:53:15Z'>
		Got it, ModelV2.custom_loss() is not supported for PyTorch yet at all (ignored). Will fix this.
Yes, metrics is the new name (ModelV2) for the old custom_stats (Model(V1)).
		</comment>
		<comment id='4' author='waldroje' date='2020-05-23T12:35:00Z'>
		I'm looking closer at the current tf policies, and I'm actually struggling to see where model.custom_loss has been implemented in tf IMPALA either... Can you highlight the part of the code where this is done for my benefit? In the case of IMPALA, I know it calls the model.custom_loss method, as I can see the custom loss metrics I've produced, but what is not clear is that it is actually making it into the gradient calculations... build_vtrace_loss seems to just call  the class VTraceLoss, where I don't see any references to the output of model.custom_loss. and dynamic_tf_policy seems to just return the output of this loss function... so I'm struggling to see where it comes into play.
		</comment>
		<comment id='5' author='waldroje' date='2020-05-28T20:50:01Z'>
		Looks like it is only used once &lt;denchmark-link:https://github.com/ray-project/ray/blob/master/rllib/policy/tf_policy.py#L215&gt;here&lt;/denchmark-link&gt;
 and from there on it's accessed through .
		</comment>
		<comment id='6' author='waldroje' date='2020-05-28T23:44:11Z'>
		Thanks for that, not sure how that eluded me… it looks like on further review my issue on the TF side was using 1.x style tf.losses.get_regularization_loss rather than model.losses … once I switched everything is working for TF models.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On May 28, 2020, at 4:50 PM, Jan Blumenkamp ***@***.***&gt; wrote:

 Looks like it is only used once here and from there on it's accessed through self._loss.

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub, or unsubscribe.



		</comment>
		<comment id='7' author='waldroje' date='2020-06-22T10:26:11Z'>
		
Got it, ModelV2.custom_loss() is not supported for PyTorch yet at all (ignored). Will fix this.
Yes, metrics is the new name (ModelV2) for the old custom_stats (Model(V1)).

Hi! Is there any update on this? If update is not expected soon, I might give it a shot with tensorflow side. Many thanks.
		</comment>
		<comment id='8' author='waldroje' date='2020-06-25T12:23:07Z'>
		Hey, &lt;denchmark-link:https://github.com/cedros23&gt;@cedros23&lt;/denchmark-link&gt;
 . Taking another look right now.
		</comment>
		<comment id='9' author='waldroje' date='2020-06-25T13:07:35Z'>
		This PR (hopefully) fixes this issue: &lt;denchmark-link:https://github.com/ray-project/ray/pull/9142&gt;#9142&lt;/denchmark-link&gt;

I did confirm via our now-working example script: .
Note that you need to:
a) return an altered list of policy-losses (same length) from the custom_loss function (no extra custom-loss optimizer; custom_loss gets e.g. added to policy loss(es)).
b) return a list that has the policy losses as well as the custom loss(es) in it (list must have same length as there are optimizers in the torch policy).
See the: rllib/examples/models/custom_loss_model.py::TorchCustomLossModel for an example for both these cases.
Closing this issue. Feel free to re-open should this not solve the problem on your end.
		</comment>
		<comment id='10' author='waldroje' date='2020-06-25T13:07:50Z'>
		&lt;denchmark-link:https://github.com/janblumenkamp&gt;@janblumenkamp&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='waldroje' date='2020-06-25T13:08:05Z'>
		&lt;denchmark-link:https://github.com/cedros23&gt;@cedros23&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='waldroje' date='2020-06-27T06:10:21Z'>
		Hello again,
I try to test and expand the example file -&gt; rllib/examples/models/custom_loss_model.py (I build ray from source - master)
I confirm it works in the standard cartpole example with --torch flag. However, if I change PG method to the DQN it gives the following error: (This error is particular to the torch, Tensorflow works fine with DQN)
&lt;denchmark-code&gt;File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/trainer_template.py", line 97, in __init__
   Trainer.__init__(self, config, env, logger_creator)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/trainer.py", line 469, in __init__
   super().__init__(config, logger_creator)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/tune/trainable.py", line 231, in __init__
   self._setup(copy.deepcopy(self.config))
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/trainer.py", line 643, in _setup
   self._init(self.config, self.env_creator)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/trainer_template.py", line 122, in _init
   self.config["num_workers"])
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/trainer.py", line 713, in _make_workers
   logdir=self.logdir)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/evaluation/worker_set.py", line 67, in __init__
   RolloutWorker, env_creator, policy, 0, self._local_config)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/evaluation/worker_set.py", line 296, in _make_worker
   extra_python_environs=extra_python_environs)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/evaluation/rollout_worker.py", line 416, in __init__
   policy_dict, policy_config)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/evaluation/rollout_worker.py", line 971, in _build_policy_map
   policy_map[name] = cls(obs_space, act_space, merged_conf)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/policy/torch_policy_template.py", line 118, in __init__
   self, obs_space, action_space, config)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/dqn/dqn_torch_policy.py", line 112, in build_q_model_and_distribution
   add_layer_norm=add_layer_norm)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/models/catalog.py", line 364, in get_model_v2
   model_config, name, **model_kwargs)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/rllib/agents/dqn/dqn_torch_model.py", line 51, in __init__
   num_outputs, model_config, name)
TypeError: __init__() missing 1 required positional argument: 'input_files'
Traceback (most recent call last):
 File "/home/eatron/Sources/GymStar/ray_source/ray/rllib/examples/custom_loss.py", line 67, in &lt;module&gt;
   tune.run("DQN", config=config, stop=stop)
 File "/home/eatron/Sources/GymStar/ray_source/ray/python/ray/tune/tune.py", line 356, in run
   raise TuneError("Trials did not complete", incomplete_trials)
ray.tune.error.TuneError: ('Trials did not complete', [DQN_CartPole-v0_82195_00000])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='waldroje' date='2020-06-27T06:49:41Z'>
		Quick update, I have compared the custom_loss models of TF and Torch. It appears that the error raised above is due the fact that pytorch custom model gets the input file as an argument during object creation whereas, tensorflow reads it via model config dictionary.
If I copy the style of TF to the torch as follows and remove the input_files arg in the Init, custom_loss example start works with DQN:
        self.reader = JsonReader(self.model_config["custom_model_config"]["input_files"])
I will further test if this leads to new problems. I would appreciate your opinions.
Thanks &amp; Regards
		</comment>
		<comment id='14' author='waldroje' date='2020-07-17T18:22:12Z'>
		Yeah, that makes perfect sense. We'll fix this as well.
Thanks so much for your investigation into this! &lt;denchmark-link:https://github.com/cedros23&gt;@cedros23&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>