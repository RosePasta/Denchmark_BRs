<bug id='4839' author='nathanlct' open_date='2019-05-23T02:32:13Z' closed_time='2019-05-25T10:47:44Z'>
	<summary>[rllib] pi.update_kl(fetches[pi_id]["kl"]) KeyError: 'kl'</summary>
	<description>
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I have been trying to do multi-agent training using the PPOTrainer class.
I got the following error:
2019-05-22 19:22:33,151	ERROR trial_runner.py:497 -- Error processing event.
Traceback (most recent call last):
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 446, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 316, in fetch_result
    result = ray.get(trial_future[0])
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py", line 2197, in get
    raise value
ray.exceptions.RayTaskError: ray_PPOTrainer:train() (pid=98952, host=Nathans-MBP)
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 354, in train
    raise e
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 340, in train
    result = Trainable.train(self)
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/trainable.py", line 151, in train
    result = self._train()
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo.py", line 133, in _train
    self.local_evaluator.foreach_trainable_policy(update)
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/policy_evaluator.py", line 638, in foreach_trainable_policy
    func(policy, pid) for pid, policy in self.policy_map.items()
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/evaluation/policy_evaluator.py", line 639, in &lt;listcomp&gt;
    if pid in self.policies_to_train
  File "/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/ppo/ppo.py", line 127, in update
    pi.update_kl(fetches[pi_id]["kl"])
KeyError: 'kl'
Going into the problematic file
        if "kl" in fetches:
            # single-agent
            self.local_evaluator.for_policy(
                lambda pi: pi.update_kl(fetches["kl"]))
        else:

            def update(pi, pi_id):
                if pi_id in fetches:
                    pi.update_kl(fetches[pi_id]["kl"])  # key error here
                else:
                    logger.debug(
                        "No data for {}, not updating kl".format(pi_id))
I printed fetches and got the following:
(pid=98952) {'adversary': {'learner_stats': {'cur_kl_coeff': 0.2,
(pid=98952)                                  'cur_lr': 4.999999873689376e-05,
(pid=98952)                                  'entropy': 1.4204963,
(pid=98952)                                  'kl': 2.2946597e-05,
(pid=98952)                                  'model': {},
(pid=98952)                                  'policy_loss': 2.1760285,
(pid=98952)                                  'total_loss': 7.3781013,
(pid=98952)                                  'vf_explained_var': -2.2411346e-05,
(pid=98952)                                  'vf_loss': 5.2020683}},
(pid=98952)  'av': {'learner_stats': {'cur_kl_coeff': 0.2,
(pid=98952)                           'cur_lr': 4.999999873689376e-05,
(pid=98952)                           'entropy': 1.4173344,
(pid=98952)                           'kl': 2.3267268e-05,
(pid=98952)                           'model': {},
(pid=98952)                           'policy_loss': -2.187273,
(pid=98952)                           'total_loss': 3.0322573,
(pid=98952)                           'vf_explained_var': -0.00042819977,
(pid=98952)                           'vf_loss': 5.219526}}}
Shouldn't the function get_learner_stats inside metrics.py be called on fetches in order to remove the middle 'learner_stats' layer? Doing this made the code work for me, but I might have missed something.
Looking into the issues, I saw a solved one mentioning KeyError: 'kl' but I still have the error (and I think it was for single agent anyway). I installed ray using pip install -U ray.
Any insights? Thanks!
	</description>
	<comments>
		<comment id='1' author='nathanlct' date='2019-05-24T00:16:29Z'>
		Do you see this on latest master? When I run multiagent_cartpole.py the fetches look like this:
 {'policy_0': {'total_loss': 629.03076, 'cur_kl_coeff': 0.025, 'cur_lr': 4.999999873689376e-05, 'vf_loss': 629.0366, 'kl': 0.009583184, 'policy_loss': -0.0061244722, 'entropy': 0.55311847, 'vf_explained_var': 0.10275469}, 'policy_1': {'total_loss': 585.98285, 'cur_kl_coeff': 0.0031249998, 'cur_lr': 4.999999873689376e-05, 'vf_loss': 585.98944, 'kl': 0.013653709, 'policy_loss': -0.0067283926, 'entropy': 0.5508158, 'vf_explained_var': 0.27053756}}
		</comment>
		<comment id='2' author='nathanlct' date='2019-05-24T00:31:45Z'>
		Ok, I'm able to reproduce this now with "simple_optimizer": True.
		</comment>
		<comment id='3' author='nathanlct' date='2019-05-24T00:37:27Z'>
		Yeah the code on latest master is different from the code I get when installing ray via pip install -U ray.
Indeed I have simple_optimizer to True. Lmk if you want all the config I'm running my code with.
		</comment>
		<comment id='4' author='nathanlct' date='2019-05-24T00:45:32Z'>
		Thanks, could you try this out? &lt;denchmark-link:https://github.com/ray-project/ray/pull/4849&gt;#4849&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='nathanlct' date='2019-05-24T00:51:19Z'>
		That works for me, thanks!
		</comment>
	</comments>
</bug>