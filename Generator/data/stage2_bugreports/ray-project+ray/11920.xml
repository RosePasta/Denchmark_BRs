<bug id='11920' author='DmitriGekhtman' open_date='2020-11-10T20:33:36Z' closed_time='2020-11-10T21:24:44Z'>
	<summary>[autoscaler] ResourceDemandScheduler legacy yaml logic</summary>
	<description>
&lt;denchmark-h:h3&gt;What is the problem?&lt;/denchmark-h&gt;

The two blocks of logic in ResourceDemandScheduler._infer_legacy_node_resources_if_needed() look like they are intended to be executed once per monitoring/autoscaling session. However, the ResourceDemandScheduler is reinstantiated in StandardAutoscaler.reset(), which is called during each autoscaler update. As a result, the logic is repeated during each update when launching with a legacy-style yaml. This leads to an AssertionError at some point after the autoscaler starts a worker node.
Here's the relevant part of the output from  /tmp/ray/session_latest/logs/monitor.err on the head node.
&lt;denchmark-code&gt;Worker node types:
 - ray-legacy-worker-node-type: 1
2020-11-10 19:57:25,083 ERROR autoscaler.py:130 -- StandardAutoscaler: Error during autoscaling.
Traceback (most recent call last):
  File "/root/anaconda3/lib/python3.7/site-packages/ray/autoscaler/_private/autoscaler.py", line 128, in update
    self._update()
  File "/root/anaconda3/lib/python3.7/site-packages/ray/autoscaler/_private/autoscaler.py", line 219, in _update
    ensure_min_cluster_size=self.resource_demand_vector)
  File "/root/anaconda3/lib/python3.7/site-packages/ray/autoscaler/_private/resource_demand_scheduler.py", line 108, in get_nodes_to_launch
    self._infer_legacy_node_resources_if_needed(max_resources_by_ip)
  File "/root/anaconda3/lib/python3.7/site-packages/ray/autoscaler/_private/resource_demand_scheduler.py", line 213, in _infer_legacy_node_resources_if_needed
    assert len(max_resources_by_ip) == 1  # Only the head node.
AssertionError
&lt;/denchmark-code&gt;

Ray version and other system information (Python version, TensorFlow version, OS):
Current master
&lt;denchmark-h:h3&gt;Reproduction (REQUIRED)&lt;/denchmark-h&gt;

Please provide a script that can be run to reproduce the issue. The script should have no external library dependencies (i.e., use fake or mock data / environments):
I get this error when running ray up python/ray/autoscaler/kubernetes/example-full.yaml on a minikube cluster with the following modifications to the legacy-style python/ray/autoscaler/kubernetes/example-full.yaml:
head and worker container image fields set to rayproject/ray:nightly
min_workers set to 1.
If we cannot run your script, we cannot fix your issue.

 I have verified my script runs in a clean environment and reproduces the issue.
 I have verified the issue also occurs with the latest wheels.

	</description>
	<comments>
		<comment id='1' author='DmitriGekhtman' date='2020-11-10T20:34:24Z'>
		cc &lt;denchmark-link:https://github.com/wuisawesome&gt;@wuisawesome&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ericl&gt;@ericl&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='DmitriGekhtman' date='2020-11-10T20:38:15Z'>
		Should be closed with &lt;denchmark-link:https://github.com/ray-project/ray/pull/11802&gt;#11802&lt;/denchmark-link&gt;
 .
		</comment>
		<comment id='3' author='DmitriGekhtman' date='2020-11-10T21:52:54Z'>
		The PR looks like a big PR. Can you push some hotfix so we can still use autoscaler master in the meantime?
		</comment>
	</comments>
</bug>