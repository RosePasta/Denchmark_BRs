<bug id='497' author='psyhtest' open_date='2020-05-22T12:06:47Z' closed_time='2020-12-23T03:05:52Z'>
	<summary>PyTorch: Loading 10 GB model fails</summary>
	<description>
Loading the &lt;denchmark-link:https://dlrm.s3-us-west-1.amazonaws.com/models/tb0875_10M.pt&gt;~10 GB DLRM model&lt;/denchmark-link&gt;
 from &lt;denchmark-link:https://github.com/mlperf/inference/tree/db0b7eb368f009adf703d073765aa212d1f3a026/v0.5/recommendation&gt;MLPerf Inference&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/mlperf/inference/issues/608#issue-623152831&gt;failed&lt;/denchmark-link&gt;
 on an Ubuntu 18.04 machine with 32 GB RAM:

from the browser: File read error '0'.
from the command line: Error loading model. Unsupported file content for extension '.pt' in 'tb0875_10M.pt'. (memory usage shoot up to 27 GB)

I would completely understand if the same thing happened with the ~100 GB model :), but maybe the ~10 GB one could be supported still?
P.S. Netron is a beautiful and useful tool - thank you so much for it &lt;denchmark-link:https://github.com/lutzroeder&gt;@lutzroeder&lt;/denchmark-link&gt;
!
	</description>
	<comments>
		<comment id='1' author='psyhtest' date='2020-12-13T16:55:00Z'>
		&lt;denchmark-link:https://console.cloud.google.com/storage/browser/vit_models/imagenet21k&gt;https://console.cloud.google.com/storage/browser/vit_models/imagenet21k&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='psyhtest' date='2020-12-23T03:05:52Z'>
		The desktop app now supports this. The Web and Python versions are constrained by the 2 GB browser limit.
		</comment>
	</comments>
</bug>