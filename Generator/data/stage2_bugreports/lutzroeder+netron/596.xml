<bug id='596' author='palakurthir' open_date='2020-09-14T14:12:40Z' closed_time='2020-09-14T15:04:29Z'>
	<summary>Error loading model. Unsupported file content (00ff0000ff007bff00ff0000ff00ff00) for extension '.tflite' in 'quantized_model.tflite'.</summary>
	<description>

Netron app and version: 
OS and browser version: 

Steps to Reproduce:

From my tensor flow script it generated expected_result_tflite.dat when Iam trying to open using netron model viewer it didn't recognize that model
2.I copied expected_result_tflite.dat into quantized_sim.tflite then it could recognize the model, but its giving the
Unsupported file content (00ff0000ff007bff00ff0000ff00ff00) for extension '.tflite' in 'quantized_model.tflite'.

Please attach or link model files to reproduce the issue if necessary.
	</description>
	<comments>
		<comment id='1' author='palakurthir' date='2020-09-14T15:02:07Z'>
		Can you share the model file and the script to reproduce the issue?
		</comment>
		<comment id='2' author='palakurthir' date='2020-09-14T15:15:11Z'>
		import numpy as np
import tempfile
import sys
import os
#import pygraphviz
# Add the src path to python
sys.path.append("../../src2")
NZOO_ROOT = os.environ.get("NZOO_ROOT", None)

if NZOO_ROOT:
    sys.path.append(os.path.join(NZOO_ROOT, "tools/kmb_test_generation/"))
else:
    raise ValueError("Please clone migNetworkZoo and create and environment variable #NZOO_ROOT to that repo")

# Suppress useless warning
from Models.System.StartUp import suppress_warnings
suppress_warnings()  # noqa

from Controllers.CompositionAPI import CompositionAPI
from Controllers.Arguments.CompilationArgs import CompilationArgs
from Controllers.OptimizationPasses.PassManager import PassManager
from Controllers.Parsers.APIHook import APIParser

from hex_converter import convert_to_numpy
def compile_network(layers: list, debug=False, image=None, outputs_location=None, device="OYB", **args):
    """Compile the networks from a list of layers
    Arguments:
        layers {list} -- List of layers in the compiler IR format. Input and Output node must be present
    Keyword Arguments:
        debug bool -- Enable debug info (default: False)
    """
    # Generate random output folder
    if outputs_location is None:
        tempdir = tempfile.TemporaryDirectory()
        outputs_location = tempdir.name
    else:
        if not os.path.exists(outputs_location):
            os.mkdir(outputs_location)

    # Generate compiler options
    arguments = CompilationArgs(outputs_location=outputs_location,
                                target_file=f"../../targets/{device}.yaml",
                                **args)

    arguments.processed_input_data = image

    # Generate a pass manager with default passes
    pm = PassManager("../../src2/Controllers/OptimizationPasses/pass_order.yaml")
    # Compile
    pm.run_passes(layers, arguments, debug=debug)

    # Compiler
    return pm.getIR()
def generate_test(image, weights, zero_point=128, output_scale=1.0):

    ca = CompositionAPI()

    weight_quantization = ca.QuantizationInfo(scale=[1], zero_point=[zero_point])
    input_quantization = ca.QuantizationInfo(scale=[1], zero_point=[zero_point])
    output_quantization = ca.QuantizationInfo(scale=[output_scale], zero_point=[zero_point])
    bias_data = 128*np.ones((1,256,1,1)).astype(np.uint8)
    bias_quantization = ca.QuantizationInfo(scale=[1], zero_point=0)
    weights_tensor = ca.Tensor(weights, name="Weights", quantization=weight_quantization, dtype=np.dtype(weights.dtype).name)
    bias = ca.Tensor(bias_data, name="Bias", quantization=bias_quantization, dtype=np.uint8)
    ## Assuming padding == SAME
    output_shape = (1, weights.shape[0], image.shape[2], image.shape[3])

    # Activation dtype
    t1 = ca.Tensor(image.shape,
                   name="Input Tensor",
                   quantization=input_quantization,
                   dtype=np.uint8)
    t2 = ca.Tensor(output_shape,
                   name="Output Tensor",
                   quantization=output_quantization,
                   dtype=np.uint8)

    # Network Input
    in_layer = ca.Layer("Input", [], t1, name="Input")
    # Convolution
    convA = ca.Layer("Convolution", [t1], [t2],
                     weights=weights_tensor,
                     kernel_width=weights.shape[2],
                     kernel_height=weights.shape[3],
                     kernel_stride_height=1,
                     kernel_stride_width=1,
                     bias=bias,
                     name="convA")

    out_layer = ca.Layer("Output", t2, [], name="Output")

    # Compile the CA graph
    ca_graph = ca.compile(in_layer, out_layer)

    # Generate the IR layers
    return APIParser(ca_graph).parse(arguments=None)
# Transpose to conver from TFLite to compiler canonical representation
weights = convert_to_numpy(os.path.join("/nfs/iir/disks/vpu2p6_phy_user_disk002/rcpalaku/wa2/nxn/MTL/", "cmx_wt_data.bin")).transpose((2, 3, 0, 1))
image = convert_to_numpy(os.path.join("/nfs/iir/disks/vpu2p6_phy_user_disk002/rcpalaku/wa2/nxn/MTL/", "cmx_se_data.bin")).transpose((0, 3, 1, 2))
# Generate layers and show some info
layers = generate_test(image, weights,zero_point=128, output_scale=1.0)

print("================")
for layer in layers:
    print(f"Name: {layer.name}, class: {layer.className()}")

conv = layers[1]


print("---- Input tensors ----")
for t in conv.getInputTensors():
    print(f"name: {t.name}, shape: {t.shape}, dtype: {t.dtype.nptype}")

print("---- Output tensors ----")
for t in conv.getOutputTensors():
    print(f"name: {t.name}, shape: {t.shape}, dtype: {t.dtype.nptype}")

print("================")
#from Views.IRVisualize import drawGraphFromLayers
#drawGraphFromLayers(layers, path="layers.png")
#print("================")

#from IPython.display import Image
#Image(filename="layers.png")
#os.remove("layers.png")


IR = compile_network(layers,
                     image=image,
                     outputs_location="outputmtlnxn",
                     device="MTL",
                     nDPU=1,
                     nClusters=2,
                     emulator=True,
                     duplicate=3)
    # Output layer
&lt;denchmark-link:#&gt;â€¦&lt;/denchmark-link&gt;


--------------------------------------------------------------
Intel Research and Development Ireland Limited
Registered in Ireland
Registered Office: Collinstown Industrial Park, Leixlip, County Kildare
Registered Number: 308263


This e-mail and any attachments may contain confidential material for the sole
use of the intended recipient(s). Any review or distribution by others is
strictly prohibited. If you are not the intended recipient, please contact the
sender and delete all copies.

		</comment>
	</comments>
</bug>