<bug id='547' author='lutzroeder' open_date='2020-07-24T01:32:51Z' closed_time='2020-08-27T02:07:07Z'>
	<summary>PyTorch: Unsupported uninitialized argument</summary>
	<description>
Please provide steps or model files to reproduce this issue.
	</description>
	<comments>
		<comment id='1' author='lutzroeder' date='2020-08-25T05:50:31Z'>
		&lt;denchmark-link:https://github.com/lutzroeder/netron/files/5121555/model_test.zip&gt;model_test.zip&lt;/denchmark-link&gt;

you can rename the above file to model_test.pt and try to load it. I think it fails because there is no model/data.pkl .  the model_test.zip was created from torch c++.
It fails with Error loading PyTorch model. Cannot read property '1' of undefined in 'model_test.pt'.
		</comment>
		<comment id='2' author='lutzroeder' date='2020-08-27T02:07:06Z'>
		&lt;denchmark-link:https://github.com/powderluv&gt;@powderluv&lt;/denchmark-link&gt;
 the  expects additional parameters. The model would have to be evaluated guessing defaults for those parameters. In particular  will fail unless  contains .
		</comment>
		<comment id='3' author='lutzroeder' date='2020-08-27T15:39:30Z'>
		&lt;denchmark-link:https://github.com/lutzroeder/netron/files/5137393/netron_issue_547_1.zip&gt;netron_issue_547_1.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='lutzroeder' date='2020-10-20T12:23:00Z'>
		&lt;denchmark-link:https://drive.google.com/file/d/1-oLvAC6iVCMJ2HtQlbAspdBERf-atPC8/view?usp=sharing&gt;https://drive.google.com/file/d/1-oLvAC6iVCMJ2HtQlbAspdBERf-atPC8/view?usp=sharing&lt;/denchmark-link&gt;

Includes both the torchscript file (.pt) and the python file that generated it
		</comment>
		<comment id='5' author='lutzroeder' date='2020-10-20T12:26:07Z'>
		Another, simpler example (both torchscript and python generator):
&lt;denchmark-link:https://drive.google.com/file/d/1ZG0QYEJt9aVs964YiJIoa81fzcufyc-N/view?usp=sharing&gt;https://drive.google.com/file/d/1ZG0QYEJt9aVs964YiJIoa81fzcufyc-N/view?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='lutzroeder' date='2020-10-20T12:36:04Z'>
		Ok, I got a minimal repro:
&lt;denchmark-code&gt;import torch
import torch.nn as nn

class UpModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        
        
    def forward(self, x):
        x = self.upsample(x)        
        return x

_model=UpModel()
_scriptmodule = torch.jit.script(_model)
_scriptmodule.save("UpModel.pt")
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/lutzroeder/netron/files/5408656/upsample.zip&gt;upsample.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='lutzroeder' date='2020-10-26T17:08:32Z'>
		I see that you made a commit but now when trying to load the upsample example in Netron 4.5.9 it says Error Loading PyTorch model: Exception in UpModel.pt.
		</comment>
		<comment id='8' author='lutzroeder' date='2020-11-28T19:59:29Z'>
		&lt;denchmark-link:https://github.com/divideconcept&gt;@divideconcept&lt;/denchmark-link&gt;
  does not include input tensor size information so it is not always possible to run the code and extract the graph without user interaction (see &lt;denchmark-link:https://github.com/lutzroeder/netron/issues/630&gt;#630&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/lutzroeder/netron/issues/636&gt;#636&lt;/denchmark-link&gt;
). Saving a traced model should work around the issue.
&lt;denchmark-code&gt;import torch
import torch.nn as nn

class UpModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

    def forward(self, x):
        x = self.upsample(x)
        return x

model = UpModel()
traced_model = torch.jit.trace(model, torch.rand([ 1, 3, 224, 224 ]))
torch.jit.save(traced_model, "UpModel.pt")
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='lutzroeder' date='2020-11-28T20:10:26Z'>
		Indeed, traced models works much better than scripted model.
		</comment>
	</comments>
</bug>