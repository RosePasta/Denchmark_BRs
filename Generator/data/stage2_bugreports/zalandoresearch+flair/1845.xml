<bug id='1845' author='dabasmoti' open_date='2020-09-02T21:18:19Z' closed_time='2020-09-08T08:46:18Z'>
	<summary>Shared memory error</summary>
	<description>
Hi,
I am trying to train Emsbeddings on my corpus(8GB),
After few epochs i got this error:
ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).
&lt;denchmark-code&gt;------ Messages Limits --------
max queues system wide = 32000
max size of message (bytes) = 8192
default max size of queue (bytes) = 16384

------ Shared Memory Limits --------
max number of segments = 4096
max seg size (kbytes) = 18014398509465599
max total shared memory (kbytes) = 18014398442373116
min seg size (bytes) = 1

------ Semaphore Limits --------
max number of arrays = 32000
max semaphores per array = 32000
max semaphores system wide = 1024000000
max ops per semop call = 500
semaphore max value = 32767
&lt;/denchmark-code&gt;

Running on 16cpu 60gb Nvidia p100
pytorch 1.4
I found this [https://github.com/&lt;denchmark-link:https://github.com/flairNLP/flair/issues/1109&gt;/issues/1109&lt;/denchmark-link&gt;
]
but i am not running on docker, i am using conda as it come with the instance image.
How can i solve it?
	</description>
	<comments>
	</comments>
</bug>