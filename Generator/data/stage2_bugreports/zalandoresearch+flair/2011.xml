<bug id='2011' author='Rasmitha23' open_date='2020-12-07T15:55:58Z' closed_time='2020-12-17T14:02:30Z'>
	<summary>'NoneType' object has no attribute 'encode'</summary>
	<description>
I am fine-tuning the available sentiment analysis model() on my data with 5 epochs, After completing 5 epochs, it tries to evaluate the performance on the test set and then I am getting the 'NoneType' object has no attribute 'encode' error
Below is the code I used
import flair
model = flair.models.TextClassifier.load('en-sentiment')
corpus: Corpus = CSVClassificationCorpus(data_folder,column_name_map,skip_header=True)
trainer: ModelTrainer = ModelTrainer(model, corpus)
trainer.train('./results',learning_rate=0.00001,
mini_batch_size=32,
max_epochs=5)
screenshot of the error.
&lt;denchmark-link:https://user-images.githubusercontent.com/12725119/101372850-5416cc80-38d2-11eb-99eb-ad5b0fadf150.png&gt;&lt;/denchmark-link&gt;

Environment (please complete the following information):

OS - Linux:
Versions


flair-0.7
torch - 1.6.0+cu101
Python- 3.6

	</description>
	<comments>
		<comment id='1' author='Rasmitha23' date='2020-12-07T18:06:28Z'>
		If your test set is None, you probably haven't defined one. Please provide some infos on your data_folder - you'll probably haven't formatted your .csv files in a test, train and dev file but it is hard to tell since we don't have any clue how the files in your data_folder are.
		</comment>
		<comment id='2' author='Rasmitha23' date='2020-12-08T02:24:44Z'>
		&lt;denchmark-link:https://github.com/whoisjones&gt;@whoisjones&lt;/denchmark-link&gt;
 My data has a test set. My data folder has train.csv , dev.csv and test.csv files. test.csv has 47 samples. Below is an example of such sample from corpus.test
corpus.test[0] = Sentence: "Thank you"   [− Tokens: 2  − Sentence-Labels: {'class': [POSITIVE (1.0)]}]
len(corpus.test) = 47
corpus.obtain_statistics provides this:
Dictionary with 2 tags: POSITIVE, NEGATIVE
{
"TRAIN": {
"dataset": "TRAIN",
"total_number_of_documents": 141,
"number_of_documents_per_class": {
"POSITIVE": 68,
"NEGATIVE": 73
},
"number_of_tokens_per_tag": {},
"number_of_tokens": {
"total": 6069,
"min": 1,
"max": 337,
"avg": 43.04255319148936
}
},
"TEST": {
"dataset": "TEST",
"total_number_of_documents": 47,
"number_of_documents_per_class": {
"POSITIVE": 18,
"NEGATIVE": 29
},
"number_of_tokens_per_tag": {},
"number_of_tokens": {
"total": 1828,
"min": 2,
"max": 369,
"avg": 38.8936170212766
}
},
"DEV": {
"dataset": "DEV",
"total_number_of_documents": 47,
"number_of_documents_per_class": {
"POSITIVE": 20,
"NEGATIVE": 27
},
"number_of_tokens_per_tag": {},
"number_of_tokens": {
"total": 1518,
"min": 1,
"max": 238,
"avg": 32.297872340425535
}
}
}
To further debug, I loaded the model which is saved as ./results/best-model.pt (the above trained model) and used it to predict on the sentence "Thank you". I am getting the same error.
Below is the code and Error screenshot:
code
from flair.data import Sentence
sentence = Sentence('Thank you')
model1 =  TextClassifier.load('./results/best-model.pt')
model1.predict(sentence)

&lt;denchmark-link:https://user-images.githubusercontent.com/12725119/101430096-615fa580-392a-11eb-91b7-4053285d98f6.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Rasmitha23' date='2020-12-08T16:02:48Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;
 can you please provide the files you are using for training? your code is actually working fine.
		</comment>
		<comment id='4' author='Rasmitha23' date='2020-12-09T13:42:15Z'>
		Hi &lt;denchmark-link:https://github.com/whoisjones&gt;@whoisjones&lt;/denchmark-link&gt;

You can find the data here (data.tar) . I am getting the same error on this data.
&lt;denchmark-link:https://github.com/Rasmitha23/data_share/tree/main&gt;https://github.com/Rasmitha23/data_share/tree/main&lt;/denchmark-link&gt;

The Notebook I am running this code on is on a virtual machine where I do not have access to the internet. Would that cause this issue?
Also, when I import flair, I get this warning -
/home/username/.local/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: scipy.sparse.sparsetools is deprecated!
scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.
_deprecated()
I am not sure if this has to do with the error. Thanks!
		</comment>
		<comment id='5' author='Rasmitha23' date='2020-12-09T13:55:28Z'>
		Hi &lt;denchmark-link:https://github.com/whoisjones&gt;@whoisjones&lt;/denchmark-link&gt;
 ,
I notice that the same code is working correctly or as expected without any error on a machine where i have access to the internet. Is there any workaround to make it work on a machine which does not have internet access?
		</comment>
		<comment id='6' author='Rasmitha23' date='2020-12-11T10:17:45Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;
 just tried your code with your data again, everything works fine. You question regarding scipy - flair never explicitly uses scipy, please check that you set up your environment correctly. Also internet connection should not be the issue. I would suggest that you go once again through our documentation where everything is explained in detail, seems to that you config's are causing your issue and not flair itself.
from training:
&lt;denchmark-code&gt;2020-12-11 11:07:42,945 ----------------------------------------------------------------------------------------------------
2020-12-11 11:07:59,072 epoch 5 - iter 1/4 - loss 0.01960632 - samples/sec: 3.21 - lr: 0.000010
2020-12-11 11:08:09,160 epoch 5 - iter 2/4 - loss 0.02977333 - samples/sec: 3.17 - lr: 0.000010
2020-12-11 11:08:19,182 epoch 5 - iter 3/4 - loss 0.08699056 - samples/sec: 3.19 - lr: 0.000010
2020-12-11 11:08:20,702 epoch 5 - iter 4/4 - loss 0.17913381 - samples/sec: 21.05 - lr: 0.000010
2020-12-11 11:08:21,300 ----------------------------------------------------------------------------------------------------
2020-12-11 11:08:21,301 EPOCH 5 done: loss 0.1791 - lr 0.0000100
2020-12-11 11:08:32,142 DEV : loss 0.13376662135124207 - score 0.94
2020-12-11 11:08:32,208 BAD EPOCHS (no improvement): 0
saving best model
2020-12-11 11:08:33,165 ----------------------------------------------------------------------------------------------------
2020-12-11 11:08:33,166 Testing using best model ...
2020-12-11 11:08:33,167 loading file results/best-model.pt
2020-12-11 11:08:45,790 	0.96
2020-12-11 11:08:45,790 
&lt;/denchmark-code&gt;

from predicting:
&lt;denchmark-code&gt;&gt;&gt;&gt;model = TextClassifier.load("results/best-model.pt")
&gt;&gt;&gt;2020-12-11 11:10:13,683 loading file results/best-model.pt
&gt;&gt;&gt;from flair.data import Sentence
&gt;&gt;&gt;sentence = Sentence("Thank you")
&gt;&gt;&gt;model.predict(sentence)
&gt;&gt;&gt;print(sentence)
&gt;&gt;&gt;Sentence: "Thank you"   [− Tokens: 2  − Sentence-Labels: {'label': [POSITIVE (0.9188)]}]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='Rasmitha23' date='2020-12-12T05:13:09Z'>
		&lt;denchmark-link:https://github.com/whoisjones&gt;@whoisjones&lt;/denchmark-link&gt;
 thanks for replying. Is it possible to check which configuration is raising this issue. One of the things i notice is that, the model doesn't have tokenizer class when loaded back, is there a way to explicitly provide this. Or is there a explicit way to store the best model so that it gets stored correctly. Any log that can be enabled while storing the model
Is there a work-around for this?
Is it possible to fine-tune a flair model using huggingface?
		</comment>
		<comment id='8' author='Rasmitha23' date='2020-12-17T14:02:30Z'>
		It seems like tokenizer is not getting loaded without internet access. For the fix, I edited the flair code to save the tokenizer whenever it saves the model and load the tokenizer and assign in model.document_embeddings.tokenizer whenever the model is loaded
		</comment>
		<comment id='9' author='Rasmitha23' date='2020-12-18T11:55:38Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;
 thanks for reporting this. We actually changed this because there were problems with the serialization of some tokenizers. We have an update to transformers 4 planned, so maybe the serialization issues are sorted out and we can take this out again.
		</comment>
	</comments>
</bug>