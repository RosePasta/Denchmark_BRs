<bug id='854' author='yliu2018' open_date='2019-07-01T20:49:09Z' closed_time='2020-05-07T00:41:21Z'>
	<summary>OpenAIGPTEmbeddings() initialization failure</summary>
	<description>
Describe the bug
When initializing OpenAIGPTEmbeddings() through
embeddings = OpenAIGPTEmbeddings()
,it failed with the following error message:
OSError: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.
To Reproduce
Steps to reproduce the behavior (e.g. which model did you train? what parameters did you use? etc.).
embeddings = OpenAIGPTEmbeddings()
Expected behavior
It should return the embeddings.
Screenshots
If applicable, add screenshots to help explain your problem.
Environment (please complete the following information):

Version : flair-0.4.2

&lt;denchmark-h:h2&gt;Full errors:
OSError: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.&lt;/denchmark-h&gt;

OSError                                   Traceback (most recent call last)
 in ()
----&gt; 1 embeddings = get_embeddings(embedding_type)
2 if document_level_embedding_type == "pooling":
3   document_embeddings = DocumentPoolEmbeddings(embeddings)
 in get_embeddings(embedding_option)
17     'flair_glove': [FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast'), WordEmbeddings('glove')],
18     'transformer_xl':[TransformerXLEmbeddings()],
---&gt; 19     'gpt':[OpenAIGPTEmbeddings()],
20     }.get(embedding_option, [FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')])
/databricks/python/lib/python3.6/site-packages/flair/embeddings.py in init(self, model, pooling_operation)
762             raise ValueError("Provided OpenAI GPT model is not available.")
763
--&gt; 764         self.tokenizer = OpenAIGPTTokenizer.from_pretrained(model)
765         self.model = OpenAIGPTModel.from_pretrained(model)
766         self.name = model
/databricks/python/lib/python3.6/site-packages/pytorch_pretrained_bert/tokenization_openai.py in from_pretrained(cls, pretrained_model_name_or_path, cache_dir, *inputs, **kwargs)
	</description>
	<comments>
		<comment id='1' author='yliu2018' date='2019-07-01T23:10:33Z'>
		This seems to be a spacy related problem. One question: did you install spacy + downloaded the en model? I did that a few days ago, but the error did not go away.
		</comment>
		<comment id='2' author='yliu2018' date='2019-07-01T23:11:27Z'>
		I'm planing to revise several embeddings, because the upcoming 0.7 release of pytorch_pretrained_bert will have a unified api for all models :)
		</comment>
		<comment id='3' author='yliu2018' date='2019-07-02T19:21:17Z'>
		
This seems to be a spacy related problem. One question: did you install spacy + downloaded the en &gt; model? I did that a few days ago, but the error did not go away.

Thanks for the hint. After I imported spacy and downloaded 'en' model, this error went away.
But if you still have this error even after this, then probably we should keep this bug open?
		</comment>
		<comment id='4' author='yliu2018' date='2020-04-30T00:10:51Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>