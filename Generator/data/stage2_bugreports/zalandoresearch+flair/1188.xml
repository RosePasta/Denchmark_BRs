<bug id='1188' author='dhanachandran-ezdi' open_date='2019-10-07T07:02:12Z' closed_time='2019-10-20T14:32:15Z'>
	<summary>Error while loading BertEmbeddings with pooling_operation = "mean"</summary>
	<description>
word_embeddings = [BertEmbeddings('bert-base-uncased', pooling_operation = 'mean')]
[80         if not everything_embedded or not self.static_embeddings:
---&gt; 81             self._add_embeddings_internal(sentences)
82
83         return sentences
2141                             embedding.unsqueeze(0) for embedding in embeddings
2142                         ]
-&gt; 2143                         mean = torch.mean(torch.cat(embeddings, dim=0), dim=0)
2144                         token.set_embedding(self.name, mean)
2145
RuntimeError: expected a non-empty list of Tensors]
BUT there is no error if pooling_operation = "first"
	</description>
	<comments>
		<comment id='1' author='dhanachandran-ezdi' date='2019-10-10T02:51:49Z'>
		Hello &lt;denchmark-link:https://github.com/dhanachandran-ezdi&gt;@dhanachandran-ezdi&lt;/denchmark-link&gt;
 , which flair version do you use?
In my test, it works fine.
Can you share code snippets and data to reproduce this problem?
		</comment>
		<comment id='2' author='dhanachandran-ezdi' date='2019-10-10T06:10:40Z'>
		Flair version 0.4.3
Dataset source: [https://competitions.codalab.org/competitions/20900]
`from flair.data import Corpus
from flair.datasets import CSVClassificationCorpus
data_folder = 'data_folder'
column_name_map = {0: "text", 1: "label_topic"}
corpus: Corpus = CSVClassificationCorpus(data_folder,
column_name_map,
skip_header=False,
delimiter='\t',    # tab-separated files
)
label_dict = corpus.make_label_dictionary()`
`from flair.data import Corpus
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.trainers import ModelTrainer
from flair.models import TextClassifier
from flair.embeddings import BertEmbeddings
word_embeddings = [
BertEmbeddings('bert-base-uncased', pooling_operation = 'mean')#(pooling_operation = 'mean')
]
document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,
hidden_size=512,
reproject_words=True,
reproject_words_dimension=256,
)
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)
trainer = ModelTrainer(classifier, corpus)
trainer.train('resources/bert_emb',
learning_rate=0.1,
mini_batch_size=32,
anneal_factor=0.5,
patience=5,
max_epochs=150)
ERROR:
2019-10-10 05:58:49,048 epoch 1 - iter 0/521 - loss 0.64399666 - samples/sec: 404.00
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

RuntimeError                              Traceback (most recent call last)
 in 
33               anneal_factor=0.5,
34               patience=5,
---&gt; 35               max_epochs=150)
36
37 # 8. plot weight traces (optional)
~/Dhana/semeval_2020/deft_eval_2020/trainer.py in train(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, anneal_factor, patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, batch_growth_annealing, shuffle, param_selection_mode, num_workers, sampler, use_amp, amp_opt_level, **kwargs)
309
310                         # forward pass
--&gt; 311                         loss = self.model.forward_loss(batch_step)
312
313                         # Backward
~/Dhana/semeval_2020/deft_eval_2020/text_classification_model.py in forward_loss(self, data_points)
132     ) -&gt; torch.tensor:
133
--&gt; 134         scores = self.forward(data_points)
135         return self._calculate_loss(scores, data_points)
136
~/Dhana/semeval_2020/deft_eval_2020/text_classification_model.py in forward(self, sentences)
97     def forward(self, sentences) -&gt; List[List[float]]:
98
---&gt; 99         self.document_embeddings.embed(sentences)
100
101         text_embedding_list = [
~/anaconda3/envs/tensorflow_37_vatsal/lib/python3.7/site-packages/flair/embeddings.py in embed(self, sentences)
2697         sentences = [sentences[i] for i in sort_perm]
2698
-&gt; 2699         self.embeddings.embed(sentences)
2700
2701         longest_token_sequence_in_batch: int = len(sentences[0])
~/anaconda3/envs/tensorflow_37_vatsal/lib/python3.7/site-packages/flair/embeddings.py in embed(self, sentences, static_embeddings)
147
148         for embedding in self.embeddings:
--&gt; 149             embedding.embed(sentences)
150
151     &lt;denchmark-link:https://github.com/Property&gt;@Property&lt;/denchmark-link&gt;

~/anaconda3/envs/tensorflow_37_vatsal/lib/python3.7/site-packages/flair/embeddings.py in embed(self, sentences)
79
80         if not everything_embedded or not self.static_embeddings:
---&gt; 81             self._add_embeddings_internal(sentences)
82
83         return sentences
~/anaconda3/envs/tensorflow_37_vatsal/lib/python3.7/site-packages/flair/embeddings.py in _add_embeddings_internal(self, sentences)
2141                             embedding.unsqueeze(0) for embedding in embeddings
2142                         ]
-&gt; 2143                         mean = torch.mean(torch.cat(embeddings, dim=0), dim=0)
2144                         token.set_embedding(self.name, mean)
2145
RuntimeError: expected a non-empty list of Tensors
		</comment>
		<comment id='3' author='dhanachandran-ezdi' date='2019-10-14T12:52:25Z'>
		Hello &lt;denchmark-link:https://github.com/dhanachandran-ezdi&gt;@dhanachandran-ezdi&lt;/denchmark-link&gt;
 , sorry, I can't find where to download the dataset.
I think you can try the code snippet below, maybe it can run well.
from flair.data import space_tokenizer

corpus: Corpus = CSVClassificationCorpus(
    data_folder,
    column_name_map,
    skip_header=False,
    delimiter='\t',  # tab-separated files
    tokenizer=space_tokenizer)
		</comment>
		<comment id='4' author='dhanachandran-ezdi' date='2019-10-15T06:02:35Z'>
		Link to the dataset: &lt;denchmark-link:https://github.com/Dhanachandra/deft_eval&gt;deft_eval&lt;/denchmark-link&gt;

There is error in your code snippet. Please check it
&gt;&gt;&gt; import flair
&gt;&gt;&gt; flair.__version__
'0.4.3'
&gt;&gt;&gt; from flair.data import space_tokenizer
Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ImportError: cannot import name 'space_tokenizer'
		</comment>
		<comment id='5' author='dhanachandran-ezdi' date='2019-10-19T10:11:16Z'>
		Hi &lt;denchmark-link:https://github.com/Dhanachandra&gt;@Dhanachandra&lt;/denchmark-link&gt;
 , I see the data.
This problem is wrong tokenization result with segtok tokenizer, like "did n't" -&gt; "did", "", "n't".
You can try using the latest version in github and use my code snippet.
If you want to use version 0.4.3, you should add  parameter like below.
corpus: Corpus = CSVClassificationCorpus(
    data_folder,
    column_name_map,
    skip_header=False,
    delimiter='\t',
    use_tokenizer=False)
		</comment>
	</comments>
</bug>