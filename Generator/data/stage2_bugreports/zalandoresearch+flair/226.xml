<bug id='226' author='jfilter' open_date='2018-11-19T13:26:20Z' closed_time='2018-11-26T15:51:48Z'>
	<summary>Non-whitespaced tokenized text results into an infinite loop</summary>
	<description>
I though my text was whitespace-tokenized, but it actually wasn't. I run into an infinite loop here:
&lt;denchmark-link:https://github.com/zalandoresearch/flair/blob/86485ec920e30b787c43b6b3ff094fbc4fa0c253/flair/data.py#L539-L541&gt;https://github.com/zalandoresearch/flair/blob/86485ec920e30b787c43b6b3ff094fbc4fa0c253/flair/data.py#L539-L541&lt;/denchmark-link&gt;

A safeguard would have been helpful and I am about to send a PR to add one.
	</description>
	<comments>
		<comment id='1' author='jfilter' date='2018-11-19T19:01:35Z'>
		Hi &lt;denchmark-link:https://github.com/jfilter&gt;@jfilter&lt;/denchmark-link&gt;
 cool thanks for pointing this out!
I am trying to reproduce the error with a string that is not whitespace tokenized but not getting this error. Could you post a code snippet that causes the error?
		</comment>
		<comment id='2' author='jfilter' date='2018-11-20T14:41:19Z'>
		Okay, I investigated it a little bit more. It only happens in certain constellations. For instance here:
from flair.models import SequenceTagger
from flair.data import Sentence

tagger = SequenceTagger.load('ner-ontonotes')

text = 'It all boils down to a simple question:    If you are happy with the globalism that has infected our nation on countless levels with New World Order establishment favorites like HW Bush, Bill, W Bush and Obama the past 24 years and want to further erode America, choose Hillary, Ted Cruz or John Kasich who are all more of the same controlled puppets of the elite banks and world power players who only care about making more money and gaining more power for themselves. '

tagger.predict(Sentence(text))[0].to_dict(tag_type='ner')
The four spaces after to a simple question: break it. If you remove one space, it works fine.
		</comment>
		<comment id='3' author='jfilter' date='2018-11-20T22:18:52Z'>
		Wow very interesting. It seems the error only occurs in the predict method - I'll take a closer look! Thanks for spotting this!!
		</comment>
		<comment id='4' author='jfilter' date='2018-11-21T18:05:28Z'>
		Thanks again for spotting this. The minimum example to reproduce the error is:
from flair.data import Sentence

text = ':    nation on '
sentence = Sentence(text)
print(sentence.to_original_text())
The error already happens as you noted already during creating the Sentence without a tokenizer. While PR &lt;denchmark-link:https://github.com/flairNLP/flair/pull/227&gt;#227&lt;/denchmark-link&gt;
 would fix the error, it would prevent people from using the class with text where multiple whitespaces occur (which some might want to do).
There's a solution in which the indexes get correctly determined even with multiple whitespaces, namely in the Sentence constructor, instead of:
                for word in text.split(' '):
                    if word:
                        try:
                            word_offset = text.index(word, offset)
                        except:
                            word_offset = offset

                        token = Token(word, start_position=word_offset)
                        self.add_token(token)
                        offset += len(word) + 1
use this to determine offsets:
# add each word in tokenized string as Token object to Sentence
                word = ''
                for index, char in enumerate(text):
                    if char == ' ':
                        if len(word) &gt; 0:
                            token = Token(word, start_position=index-len(word))
                            self.add_token(token)

                        word = ''
                    else:
                        word += char
I'll test a bit - if it works, we can do a PR.
		</comment>
		<comment id='5' author='jfilter' date='2018-11-22T18:20:54Z'>
		Okay, cool! As long it's fixed I am happy. ;)
		</comment>
	</comments>
</bug>