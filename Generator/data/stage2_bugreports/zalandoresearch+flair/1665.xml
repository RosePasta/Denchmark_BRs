<bug id='1665' author='neonet1' open_date='2020-06-04T23:12:02Z' closed_time='2020-10-22T02:56:30Z'>
	<summary>Anomaly when attempting to train Text Classifier (RuntimeError)</summary>
	<description>
Describe the bug
Cannot train Text Classifier models, as the script fails when computing label dictionary. Both own CSV dataset model and TREC_6 example dataset model given in tutorial 7 fail with the same error.
RAN SCRIPT:
`from flair.data import Corpus
from flair.datasets import TREC_6
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer
corpus: Corpus = TREC_6()
label_dict = corpus.make_label_dictionary()
word_embeddings = [WordEmbeddings('glove')]
document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)
trainer = ModelTrainer(classifier, corpus)
trainer.train('resources/taggers/trec',
learning_rate=0.1,
mini_batch_size=32,
anneal_factor=0.5,
patience=5,
max_epochs=150)`
SCRIPT RUNNING AND ERROR:
`(env) C:\Users\Me\Documents\Blog\AIKame\deep&gt;python tc_sample.py
2020-06-04 18:56:14,309 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-04 18:56:14,309 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-04 18:56:14,309 Dev: None
2020-06-04 18:56:14,309 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-04 18:56:14,394 Computing label dictionary. Progress:
2020-06-04 18:56:16,935 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-04 18:56:16,935 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-04 18:56:16,935 Dev: None
2020-06-04 18:56:16,935 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-04 18:56:17,019 Computing label dictionary. Progress:
Traceback (most recent call last):
File "", line 1, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 116, in spawn_main
exitcode = _main(fd, parent_sentinel)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 125, in _main
prepare(preparation_data)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 236, in prepare
_fixup_main_from_path(data['init_main_from_path'])
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 287, in _fixup_main_from_path
main_content = runpy.run_path(main_path,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 265, in run_path
return _run_module_code(code, init_globals, run_name,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 97, in _run_module_code
_run_code(code, mod_globals, init_globals,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 87, in _run_code
exec(code, run_globals)
File "C:\Users\Me\Documents\Blog\AIKame\deep\tc_sample.py", line 12, in 
label_dict = corpus.make_label_dictionary()
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
for batch in Tqdm.tqdm(iter(loader)):
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
return _MultiProcessingDataLoaderIter(self)
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
w.start()
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\process.py", line 121, in start
self._popen = self._Popen(self)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\context.py", line 224, in _Popen
return _default_context.get_context().Process._Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\context.py", line 326, in _Popen
return Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\popen_spawn_win32.py", line 45, in init
prep_data = spawn.get_preparation_data(process_obj._name)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 154, in get_preparation_data
_check_not_importing_main()
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 134, in _check_not_importing_main
raise RuntimeError('''
RuntimeError:
An attempt has been made to start a new process before the
current process has finished its bootstrapping phase.
&lt;denchmark-code&gt;    This probably means that you are not using fork to start your
    child processes and you have forgotten to use the proper idiom
    in the main module:

        if __name__ == '__main__':
            freeze_support()
            ...

    The "freeze_support()" line can be omitted if the program
    is not going to be frozen to produce an executable.
&lt;/denchmark-code&gt;

`
To Reproduce
I ran the script as provided. I made a virtualenv and installed flair on it to test if it was some weird conflict, but the error persisted.
Expected behavior
I expected the model to train correctly. The fact that Text Classifier models wont train is odd, since Sequence Labeling models like the example UD_ENGLISH in Tutorial 7 did run successfully.
Environment (please complete the following information):

OS [Windows 10 64-bit]:
Version [flair-0.5]:

	</description>
	<comments>
		<comment id='1' author='neonet1' date='2020-06-08T15:44:16Z'>
		That is strange - the script is running on my setups so I cannot reproduce the error. It looks like it has something to do with multiprocessing. Could you try setting the workers to 1, i.e.:
trainer.train('resources/taggers/trec',
    learning_rate=0.1,
    mini_batch_size=32,
    anneal_factor=0.5,
    patience=5,
    max_epochs=150, 
    num_workers=1, # set number of workers to 1
)
		</comment>
		<comment id='2' author='neonet1' date='2020-06-10T22:02:37Z'>
		&lt;denchmark-h:h3&gt;Thanks for the suggestion, but the error persists:&lt;/denchmark-h&gt;

SCRIPT
from flair.data import Corpus
from flair.datasets import TREC_6
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer
corpus: Corpus = TREC_6()
label_dict = corpus.make_label_dictionary()
word_embeddings = [WordEmbeddings('glove')]
document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)
trainer = ModelTrainer(classifier, corpus)
trainer.train('resources/taggers/trec',
learning_rate=0.1,
mini_batch_size=32,
anneal_factor=0.5,
patience=5,
max_epochs=15,
num_workers=1, # set number of workers to 1
)
SCRIPT ATTEMPT
(env) C:\Users\Me\Documents\Blog\AIKame\deep&gt;python tc_sample.py
2020-06-10 17:59:31,765 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-10 17:59:31,765 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-10 17:59:31,765 Dev: None
2020-06-10 17:59:31,765 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-10 17:59:31,846 Computing label dictionary. Progress:
2020-06-10 17:59:34,729 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-10 17:59:34,729 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-10 17:59:34,729 Dev: None
2020-06-10 17:59:34,729 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-10 17:59:34,813 Computing label dictionary. Progress:
Traceback (most recent call last):
File "", line 1, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 116, in spawn_main
exitcode = _main(fd, parent_sentinel)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 125, in _main
prepare(preparation_data)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 236, in prepare
_fixup_main_from_path(data['init_main_from_path'])
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 287, in _fixup_main_from_path
main_content = runpy.run_path(main_path,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 265, in run_path
return _run_module_code(code, init_globals, run_name,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 97, in _run_module_code
_run_code(code, mod_globals, init_globals,
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\runpy.py", line 87, in _run_code
exec(code, run_globals)
File "C:\Users\Me\Documents\Blog\AIKame\deep\tc_sample.py", line 9, in 
label_dict = corpus.make_label_dictionary()
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
for batch in Tqdm.tqdm(iter(loader)):
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
return _MultiProcessingDataLoaderIter(self)
File "C:\Users\Me\Documents\Blog\AIKame\deep\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
w.start()
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\process.py", line 121, in start
self._popen = self._Popen(self)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\context.py", line 224, in _Popen
return _default_context.get_context().Process._Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\context.py", line 326, in _Popen
return Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\popen_spawn_win32.py", line 45, in init
prep_data = spawn.get_preparation_data(process_obj._name)
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 154, in get_preparation_data
_check_not_importing_main()
File "C:\Users\Me\AppData\Local\Programs\Python\Python38\lib\multiprocessing\spawn.py", line 134, in _check_not_importing_main
raise RuntimeError('''
RuntimeError:
An attempt has been made to start a new process before the
current process has finished its bootstrapping phase.
&lt;denchmark-code&gt;    This probably means that you are not using fork to start your
    child processes and you have forgotten to use the proper idiom
    in the main module:

        if __name__ == '__main__':
            freeze_support()
            ...

    The "freeze_support()" line can be omitted if the program
    is not going to be frozen to produce an executable.
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;I have obtained additional information that may be relevant:&lt;/denchmark-h&gt;

PYTHON VERSION
Python 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)] on win32
INSTALLED PYTHON PACKAGES (virtualenv)
(env) C:\Users\Me\Documents\Blog\AIKame\deep&gt;pip list
Package         Version
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

atomicwrites    1.4.0
attrs           19.3.0
boto            2.49.0
boto3           1.13.23
botocore        1.16.23
bpemb           0.3.0
certifi         2020.4.5.1
chardet         3.0.4
click           7.1.2
cloudpickle     1.4.1
colorama        0.4.3
cycler          0.10.0
Cython          0.29.14
decorator       4.4.2
Deprecated      1.2.10
docutils        0.15.2
filelock        3.0.12
flair           0.5
future          0.18.2
gensim          3.8.3
hyperopt        0.2.4
idna            2.9
jmespath        0.10.0
joblib          0.15.1
kiwisolver      1.2.0
langdetect      1.0.8
matplotlib      3.2.1
more-itertools  8.3.0
mpld3           0.3
networkx        2.4
numpy           1.18.5
packaging       20.4
Pillow          7.1.2
pip             19.2.3
pluggy          0.13.1
py              1.8.1
pyparsing       2.4.7
pytest          5.4.3
python-dateutil 2.8.1
regex           2020.5.14
requests        2.23.0
s3transfer      0.3.3
sacremoses      0.0.43
scikit-learn    0.23.1
scipy           1.4.1
segtok          1.5.10
sentencepiece   0.1.91
setuptools      41.2.0
six             1.15.0
smart-open      2.0.0
sqlitedict      1.6.0
tabulate        0.8.7
threadpoolctl   2.1.0
tokenizers      0.7.0
torch           1.5.0
torchvision     0.6.0
tqdm            4.46.1
transformers    2.11.0
urllib3         1.25.9
wcwidth         0.2.3
wrapt           1.12.1
WARNING: You are using pip version 19.2.3, however version 20.1.1 is available.
You should consider upgrading via the 'python -m pip install --upgrade pip' command.

I use a Dell G7 15 gaming laptop.
&lt;denchmark-link:https://user-images.githubusercontent.com/38730172/84322999-f7fe0600-ab43-11ea-8374-30aa40c968da.png&gt;&lt;/denchmark-link&gt;

I hope the issue can be addressed with current information. Thanks in advance.
		</comment>
		<comment id='3' author='neonet1' date='2020-06-11T16:16:50Z'>
		Hm not sure where this error comes from. Maybe you could install in a fresh virtual environment?
		</comment>
		<comment id='4' author='neonet1' date='2020-06-16T08:15:32Z'>
		I installed flair on a new virtual environment and the same error resulted when trying to run the same script. I only have a couple of ideas:
&lt;denchmark-h:h3&gt;1) Setup.py&lt;/denchmark-h&gt;

When installing flair, pip warned that since wheel was not installed, setup.py was used to install the packages. Would this affect anything realistically?
&lt;denchmark-h:h3&gt;2) PyTorch 1.5.0&lt;/denchmark-h&gt;

When installing flair through pip, the torch package always failed to download. This is apparently an issue with PyTorch itself, so I downloaded PyTorch 1.5.0 manually. Is this version causing issues?
&lt;denchmark-h:h3&gt;3) Python 3.8.3&lt;/denchmark-h&gt;

Could it be that Python 3.8.3 is causing some incompatibilities?
&lt;denchmark-h:h3&gt;4) CUDA&lt;/denchmark-h&gt;

My computer does not have CUDA currently installed. Is this necessary to run the Text Classifier example? If so, what other programs should I install?
I just want to get flair working, so any information on these potential causes (or any others) would be greatly appreciated. Thanks in advance!
		</comment>
		<comment id='5' author='neonet1' date='2020-06-16T14:38:57Z'>
		That is strange, but I think we can exclude CUDA since Flair does not need a GPU to run. I am not sure about Python 3.8.3 but if this were causing problems we would probably see a lot of such bug reports, so I am thinking this is more likely to be something specific to your setup. Perhaps the problem is the manual install of PyTorch? Have you tried pip installing pytorch==1.4.0 to get an earlier version?
		</comment>
		<comment id='6' author='neonet1' date='2020-06-17T01:55:40Z'>
		made a virtualenv on Python 3.7.6 and installed flair along with torch 1.4.0, the script still failed.
&lt;denchmark-h:h3&gt;Script&lt;/denchmark-h&gt;

from flair.data import Corpus
from flair.datasets import TREC_6
from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer
corpus: Corpus = TREC_6()
label_dict = corpus.make_label_dictionary()
word_embeddings = [WordEmbeddings('glove')]
document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=256)
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)
trainer = ModelTrainer(classifier, corpus)
trainer.train('resources/taggers/trec',
learning_rate=0.1,
mini_batch_size=32,
anneal_factor=0.5,
patience=5,
max_epochs=40)
&lt;denchmark-h:h3&gt;Command Line process&lt;/denchmark-h&gt;

Microsoft Windows [Version 10.0.18362.900]
(c) 2019 Microsoft Corporation. All rights reserved.
C:\Users\Me&gt;cd C:\Users\Me\Documents\flair-experiments\3-7-virtual
C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;.\Scripts\activate
The system cannot find the path specified.
C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;.\env\Scripts\activate
(env) C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;pip list
Package            Version
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

atomicwrites       1.4.0
attrs              19.3.0
boto               2.49.0
boto3              1.14.4
botocore           1.17.4
bpemb              0.3.0
certifi            2020.4.5.2
chardet            3.0.4
click              7.1.2
cloudpickle        1.4.1
colorama           0.4.3
cycler             0.10.0
Cython             0.29.14
decorator          4.4.2
Deprecated         1.2.10
docutils           0.15.2
filelock           3.0.12
flair              0.5
future             0.18.2
gensim             3.8.3
hyperopt           0.2.4
idna               2.9
importlib-metadata 1.6.1
jmespath           0.10.0
joblib             0.15.1
kiwisolver         1.2.0
langdetect         1.0.8
matplotlib         3.2.1
more-itertools     8.4.0
mpld3              0.3
networkx           2.4
numpy              1.18.5
packaging          20.4
Pillow             7.1.2
pip                20.1.1
pluggy             0.13.1
py                 1.8.2
pyparsing          2.4.7
pytest             5.4.3
python-dateutil    2.8.1
regex              2020.6.8
requests           2.23.0
s3transfer         0.3.3
sacremoses         0.0.43
scikit-learn       0.23.1
scipy              1.4.1
segtok             1.5.10
sentencepiece      0.1.91
setuptools         41.2.0
six                1.15.0
smart-open         2.0.0
sqlitedict         1.6.0
tabulate           0.8.7
threadpoolctl      2.1.0
tokenizers         0.7.0
torch              1.4.0
torchvision        0.6.0
tqdm               4.46.1
transformers       2.11.0
urllib3            1.25.9
wcwidth            0.2.4
wrapt              1.12.1
zipp               3.1.0
(env) C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;python text-test.py
2020-06-16 21:32:05,928 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-16 21:32:05,928 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-16 21:32:05,928 Dev: None
2020-06-16 21:32:05,928 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-16 21:32:06,039 Computing label dictionary. Progress:
2020-06-16 21:32:08,454 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-16 21:32:08,455 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-16 21:32:08,455 Dev: None
2020-06-16 21:32:08,455 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-16 21:32:08,564 Computing label dictionary. Progress:
Traceback (most recent call last):
File "", line 1, in 
Traceback (most recent call last):
File "text-test.py", line 12, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
exitcode = _main(fd)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
label_dict = corpus.make_label_dictionary()
prepare(preparation_data)  File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
for batch in Tqdm.tqdm(iter(loader)):_fixup_main_from_path(data['init_main_from_path'])
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
return _MultiProcessingDataLoaderIter(self)run_name="mp_main")
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
pkg_name=pkg_name, script_name=fname)w.start()
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
mod_name, mod_spec, pkg_name, script_name)self._popen = self._Popen(self)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 85, in _run_code
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
exec(code, run_globals)return _default_context.get_context().Process._Popen(process_obj)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\text-test.py", line 12, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
label_dict = corpus.make_label_dictionary()return Popen(process_obj)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in init
reduction.dump(process_obj, to_child)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
for batch in Tqdm.tqdm(iter(loader)):
ForkingPickler(file, protocol).dump(obj)  File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
&lt;denchmark-code&gt;BrokenPipeErrorreturn _MultiProcessingDataLoaderIter(self):
&lt;/denchmark-code&gt;

[Errno 32] Broken pipe  File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
&lt;denchmark-code&gt;w.start()
&lt;/denchmark-code&gt;

File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
self._popen = self._Popen(self)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
return _default_context.get_context().Process._Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
return Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in init
prep_data = spawn.get_preparation_data(process_obj._name)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 143, in get_preparation_data
_check_not_importing_main()
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
is not going to be frozen to produce an executable.''')
RuntimeError:
An attempt has been made to start a new process before the
current process has finished its bootstrapping phase.
&lt;denchmark-code&gt;    This probably means that you are not using fork to start your
    child processes and you have forgotten to use the proper idiom
    in the main module:

        if __name__ == '__main__':
            freeze_support()
            ...

    The "freeze_support()" line can be omitted if the program
    is not going to be frozen to produce an executable.
&lt;/denchmark-code&gt;

(env) C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;
I also ran a script with the worker number parameter you suggested, no dice.
&lt;denchmark-h:h3&gt;?&lt;/denchmark-h&gt;

I'm at a loss, I have no idea what the issue could be. Is there something about the pytorch version and installing it? When installing pytorch, the official tutorial gives a pip command that downloads both torch===1.5.0 and torchvision===0.6.0. Is torchvision causing some incompatibilities? I don't know, but I hope this can be resolved.
		</comment>
		<comment id='7' author='neonet1' date='2020-06-17T02:00:11Z'>
		&lt;denchmark-h:h3&gt;This was the command line process for the script with num_workers=1&lt;/denchmark-h&gt;

Microsoft Windows [Version 10.0.18362.900]
(c) 2019 Microsoft Corporation. All rights reserved.
C:\Users\Me&gt;cd Documents\flair-experiments\3-7-virtual
C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;.\env\Scripts\activate
(env) C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;python text-test.py
2020-06-16 21:58:38,213 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-16 21:58:38,213 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-16 21:58:38,214 Dev: None
2020-06-16 21:58:38,214 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-16 21:58:38,325 Computing label dictionary. Progress:
2020-06-16 21:58:40,795 Reading data from C:\Users\Me.flair\datasets\trec_6
2020-06-16 21:58:40,795 Train: C:\Users\Me.flair\datasets\trec_6\train.txt
2020-06-16 21:58:40,795 Dev: None
2020-06-16 21:58:40,795 Test: C:\Users\Me.flair\datasets\trec_6\test.txt
2020-06-16 21:58:40,911 Computing label dictionary. Progress:
Traceback (most recent call last):
File "", line 1, in 
Traceback (most recent call last):
File "text-test.py", line 12, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 105, in spawn_main
exitcode = _main(fd)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 114, in _main
label_dict = corpus.make_label_dictionary()
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
prepare(preparation_data)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 225, in prepare
_fixup_main_from_path(data['init_main_from_path'])for batch in Tqdm.tqdm(iter(loader)):
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 277, in _fixup_main_from_path
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
run_name="mp_main")
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 263, in run_path
return _MultiProcessingDataLoaderIter(self)pkg_name=pkg_name, script_name=fname)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 96, in _run_module_code
mod_name, mod_spec, pkg_name, script_name)w.start()
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\runpy.py", line 85, in _run_code
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
exec(code, run_globals)self._popen = self._Popen(self)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\text-test.py", line 12, in 
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
label_dict = corpus.make_label_dictionary()
return _default_context.get_context().Process._Popen(process_obj)  File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\flair\data.py", line 1124, in make_label_dictionary
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
for batch in Tqdm.tqdm(iter(loader)):return Popen(process_obj)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 279, in iter
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 89, in init
return _MultiProcessingDataLoaderIter(self)reduction.dump(process_obj, to_child)
File "C:\Users\Me\Documents\flair-experiments\3-7-virtual\env\lib\site-packages\torch\utils\data\dataloader.py", line 719, in init
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py", line 60, in dump
ForkingPickler(file, protocol).dump(obj)w.start()
BrokenPipeError  File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py", line 112, in start
:     [Errno 32] Broken pipeself._popen = self._Popen(self)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 223, in _Popen
return _default_context.get_context().Process._Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py", line 322, in _Popen
return Popen(process_obj)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py", line 46, in init
prep_data = spawn.get_preparation_data(process_obj._name)
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 143, in get_preparation_data
_check_not_importing_main()
File "C:\Users\Me\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py", line 136, in _check_not_importing_main
is not going to be frozen to produce an executable.''')
RuntimeError:
An attempt has been made to start a new process before the
current process has finished its bootstrapping phase.
&lt;denchmark-code&gt;    This probably means that you are not using fork to start your
    child processes and you have forgotten to use the proper idiom
    in the main module:

        if __name__ == '__main__':
            freeze_support()
            ...

    The "freeze_support()" line can be omitted if the program
    is not going to be frozen to produce an executable.
&lt;/denchmark-code&gt;

(env) C:\Users\Me\Documents\flair-experiments\3-7-virtual&gt;
		</comment>
		<comment id='8' author='neonet1' date='2020-10-15T02:29:28Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>