<bug id='83' author='ducalpha' open_date='2018-08-21T02:26:17Z' closed_time='2018-08-21T14:41:27Z'>
	<summary>ValueError when input has double spaces and flair does not use tokenizer</summary>
	<description>
I found that flair will crash when using Sentence() with use_tokenizer=False (its default value) and the sentence string has a double-space, which causes an empty token and the following error on PyTorch:
(To reproduce the following, I changed the input text in predict.py to have a double-space.)
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "predict.py", line 8, in &lt;module&gt;
    tagger.predict(sentence)
  File "/home/projects/ner/flair/flair/models/sequence_tagger_model.py", line 371, in predict
    score, tag_seq = self._predict_scores_batch(batch)
  File "/home/projects/ner/flair/flair/models/sequence_tagger_model.py", line 386, in _predict_scores_batch
    all_feats, tags = self.forward(sentences)
  File "/home/projects/ner/flair/flair/models/sequence_tagger_model.py", line 157, in forward
    self.embeddings.embed(sentences)
  File "/home/projects/ner/flair/flair/embeddings.py", line 115, in embed
    embedding.embed(sentences)
  File "/home/projects/ner/flair/flair/embeddings.py", line 48, in embed
    self._add_embeddings_internal(sentences)
  File "/home/projects/ner/flair/flair/embeddings.py", line 268, in _add_embeddings_internal
    tokens_sorted_by_length = sorted(tokens_char_indices, key=lambda p: len(p), reverse=True)
  File "/home/miniconda3/lib/python3.6/site-packages/torch/onnx/__init__.py", line 68, in wrapper
    return fn(*args, **kwargs)
  File "/home/miniconda3/lib/python3.6/site-packages/torch/nn/utils/rnn.py", line 141, in pack_padded_sequence
    data, batch_sizes = PackPadded.apply(input, lengths, batch_first)
  File "/home/miniconda3/lib/python3.6/site-packages/torch/nn/_functions/packing.py", line 12, in forward
    raise ValueError("Length of all samples has to be greater than 0, "
ValueError: Length of all samples has to be greater than 0, but found an element in 'lengths' that is &lt;= 0
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ducalpha' date='2018-08-21T07:17:20Z'>
		Thanks for reporting this. I'm going to fix it.
		</comment>
	</comments>
</bug>