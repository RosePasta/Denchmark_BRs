<bug id='23' author='akshaykhatri639' open_date='2018-07-31T02:08:22Z' closed_time='2018-11-07T16:47:15Z'>
	<summary>tagger = SequenceTagger.load('ner-ontonotes') does not work</summary>
	<description>
Trying to use the ner-ontonotes model on a Mac. Installed flair via pip.
&lt;denchmark-code&gt;from flair.tagging_model import SequenceTagger
tagger = SequenceTagger.load('ner-ontonotes')
&lt;/denchmark-code&gt;

Here's the traceback:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
&lt;ipython-input-4-4d86fef1ef40&gt; in &lt;module&gt;()
----&gt; 1 tagger = SequenceTagger.load('ner-ontonotes')

~/.virtualenvs/py36/lib/python3.6/site-packages/flair/tagging_model.py in load(model)
    459 
    460         if model_file is not None:
--&gt; 461             tagger: SequenceTagger = SequenceTagger.load_from_file(model_file)
    462             return tagger
    463 

~/.virtualenvs/py36/lib/python3.6/site-packages/flair/tagging_model.py in load_from_file(cls, model_file)
    123         # serialization of torch objects
    124         warnings.filterwarnings("ignore")
--&gt; 125         state = torch.load(model_file, map_location={'cuda:0': 'cpu'})
    126         warnings.filterwarnings("default")
    127 

~/.virtualenvs/py36/lib/python3.6/site-packages/torch/serialization.py in load(f, map_location, pickle_module)
    301         f = open(f, 'rb')
    302     try:
--&gt; 303         return _load(f, map_location, pickle_module)
    304     finally:
    305         if new_fd:

~/.virtualenvs/py36/lib/python3.6/site-packages/torch/serialization.py in _load(f, map_location, pickle_module)
    467     unpickler = pickle_module.Unpickler(f)
    468     unpickler.persistent_load = persistent_load
--&gt; 469     result = unpickler.load()
    470 
    471     deserialized_storage_keys = pickle_module.load(f)

OSError: [Errno 22] Invalid argument
&lt;/denchmark-code&gt;

Note: tagger = SequenceTagger.load('ner') works fine
	</description>
	<comments>
		<comment id='1' author='akshaykhatri639' date='2018-07-31T07:24:36Z'>
		Hi Akshay, thanks for your interest! Could you also try some of the other models?
tagger = SequenceTagger.load('chunk')
tagger = SequenceTagger.load('pos')
tagger = SequenceTagger.load('frame')
		</comment>
		<comment id='2' author='akshaykhatri639' date='2018-08-02T19:56:01Z'>
		Hey Alan, all of these models work fine
		</comment>
		<comment id='3' author='akshaykhatri639' date='2018-08-03T16:51:35Z'>
		Release 0.2 fixes this bug. git pull or pip install flair --upgrade to get the newest version!
		</comment>
		<comment id='4' author='akshaykhatri639' date='2018-08-14T21:37:34Z'>
		The error still persists in version 0.2.1
		</comment>
		<comment id='5' author='akshaykhatri639' date='2018-08-14T22:20:30Z'>
		&lt;denchmark-link:https://github.com/akshaykhatri639&gt;@akshaykhatri639&lt;/denchmark-link&gt;
 Could you please check the checksum of the  model?
Just go to the ~/.flair/models folder and execute sha256sum en-ner-ontonotes-v0.2.pt:
$ sha256sum en-ner-ontonotes-v0.2.pt 
34044e832903456139d942ea6b346dafbbcbb922c0df93684a6412951984cdc5  en-ner-ontonotes-v0.2.pt
If that command outputs another checksum, then I guess something went wrong during the download of the model. In that case just delete the model and download it again using tagger = SequenceTagger.load('ner-ontonotes') :)
		</comment>
		<comment id='6' author='akshaykhatri639' date='2018-08-15T19:52:32Z'>
		&lt;denchmark-link:https://github.com/stefan-it&gt;@stefan-it&lt;/denchmark-link&gt;
 Thanks for the quick response but the checksum is correct.
		</comment>
		<comment id='7' author='akshaykhatri639' date='2018-08-16T07:09:06Z'>
		Hm very strange - could you try deleting the model ~/.flair/models/en-ner-ontonotes-v0.2.pt and try again?
		</comment>
		<comment id='8' author='akshaykhatri639' date='2018-08-16T21:24:26Z'>
		No luck
		</comment>
		<comment id='9' author='akshaykhatri639' date='2018-08-20T23:12:09Z'>
		Same problem here.
		</comment>
		<comment id='10' author='akshaykhatri639' date='2018-08-21T00:03:30Z'>
		But all the other models work? including 'ner-ontonotes-fast'?
One thing that is different amout the 'ner-ontonotes' model is that it is the largest model we've trained. Could it somehow be a memory issue? Could you monitor memory as you load the model?
		</comment>
		<comment id='11' author='akshaykhatri639' date='2018-08-21T08:44:29Z'>
		Hi,
using:
from flair.models import SequenceTagger

tagger = SequenceTagger.load('ner-ontonotes')
Outputs:
stefan@stefan-power-workstation:/tmp$ \time -v python ontonotes.py 
	Command being timed: "python ontonotes.py"
	User time (seconds): 6.21
	System time (seconds): 2.62
	Percent of CPU this job got: 112%
	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:07.89
	Average shared text size (kbytes): 0
	Average unshared data size (kbytes): 0
	Average stack size (kbytes): 0
	Average total size (kbytes): 0
	Maximum resident set size (kbytes): 6037476
	Average resident set size (kbytes): 0
	Major (requiring I/O) page faults: 0
	Minor (reclaiming a frame) page faults: 1641289
	Voluntary context switches: 157
	Involuntary context switches: 75
	Swaps: 0
	File system inputs: 0
	File system outputs: 0
	Socket messages sent: 0
	Socket messages received: 0
	Signals delivered: 0
	Page size (bytes): 4096
	Exit status: 0
So max. resident size was 6037476 kb = ~ 6GB of RAM.
		</comment>
		<comment id='12' author='akshaykhatri639' date='2018-08-21T18:43:11Z'>
		Yes  fails too. I reran the code and monitored the memory usage using  and it did not get anywhere close to full.  Is this stackoverflow post related? &lt;denchmark-link:https://stackoverflow.com/questions/11662960/ioerror-errno-22-invalid-argument-when-reading-writing-large-bytestring&gt;https://stackoverflow.com/questions/11662960/ioerror-errno-22-invalid-argument-when-reading-writing-large-bytestring&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='akshaykhatri639' date='2018-08-21T19:18:08Z'>
		&lt;denchmark-link:https://github.com/pwichmann&gt;@pwichmann&lt;/denchmark-link&gt;
 Do you also use you a MAC?
		</comment>
		<comment id='14' author='akshaykhatri639' date='2018-08-21T19:22:27Z'>
		&lt;denchmark-link:https://github.com/akshaykhatri639&gt;@akshaykhatri639&lt;/denchmark-link&gt;
 thanks for testing this. This kind of supports the theory that this may have something to do with model size and that large models fail to load on some setups.
Since we cannot reproduce the error ourselves, could we ask you to try loading each of the 13 pre-trained models listed &lt;denchmark-link:https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_TAGGING.md&gt;here&lt;/denchmark-link&gt;
 and tell us which ones work and which ones fail? If all the large ones fail, we get closer to diagnosing the problem.
(After the test, you can delete the models again in ~/.flair/models/ so as not to run up your hard drive with a bunch of models :))
		</comment>
		<comment id='15' author='akshaykhatri639' date='2018-08-21T19:28:09Z'>
		&lt;denchmark-link:https://github.com/stefan-it&gt;@stefan-it&lt;/denchmark-link&gt;
 Yes, I used a Mac.
		</comment>
		<comment id='16' author='akshaykhatri639' date='2018-08-29T20:31:39Z'>
		&lt;denchmark-link:https://github.com/akshaykhatri639&gt;@akshaykhatri639&lt;/denchmark-link&gt;
 Did you manage to solve the problem?
		</comment>
		<comment id='17' author='akshaykhatri639' date='2018-08-29T20:39:59Z'>
		No, I moved to a linux environment ðŸ˜…
		</comment>
		<comment id='18' author='akshaykhatri639' date='2018-08-29T20:57:14Z'>
		So, it is a Mac problem? That's weird...
		</comment>
		<comment id='19' author='akshaykhatri639' date='2018-11-07T16:47:15Z'>
		Fixed in master branch, will be part of next version release!
		</comment>
	</comments>
</bug>