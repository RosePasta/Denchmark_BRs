<bug id='1827' author='lucaventurini' open_date='2020-08-21T13:07:34Z' closed_time='2021-01-02T11:17:17Z'>
	<summary>Error when loading trained model</summary>
	<description>
When I load a model trained (on a different machine) with TransformerDocumentEmbeddings, the script fails with the following error:
Not found: "/root/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed": No such file or directory Error #2 
Apparently, it's looking for some file in cache from transformers, even if I expected the model to contain everything needed for the prediction.
The workaround is to call again, before the loading,
_ = TransformerDocumentEmbeddings('xlm-roberta-base')
but you need to know which pre-trained model was used in the training, in this case 'xlm-roberta-base'.
	</description>
	<comments>
		<comment id='1' author='lucaventurini' date='2020-08-28T08:11:39Z'>
		I think the problem is that it serializes a path specific to the machine it was trained on. I am seeing a similar error. What transformers version are you running? I think it might work with the current transformers.
		</comment>
		<comment id='2' author='lucaventurini' date='2020-08-28T09:31:11Z'>
		Correction: I think the error persists even with the most current version.
		</comment>
		<comment id='3' author='lucaventurini' date='2020-12-26T10:54:00Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>