<bug id='478' author='Santosh-Gupta' open_date='2019-02-10T01:11:16Z' closed_time='2019-02-10T21:22:45Z'>
	<summary>NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03), file not found</summary>
	<description>
Describe the bug
A clear and concise description of what the bug is.
I am trying to follow this tutorial &lt;denchmark-link:https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md&gt;https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md&lt;/denchmark-link&gt;

and I am getting a file File not found for . Similar issue to
&lt;denchmark-link:https://github.com/flairNLP/flair/issues/371&gt;#371&lt;/denchmark-link&gt;

To Reproduce
Steps to reproduce the behavior (e.g. which model did you train? what parameters did you use? etc.).
&lt;denchmark-code&gt;from flair.data import TaggedCorpus
from flair.data_fetcher import NLPTaskDataFetcher, NLPTask
from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings
from typing import List

corpus: TaggedCorpus = NLPTaskDataFetcher.load_corpus(NLPTask.CONLL_03).downsample(0.1)
&lt;/denchmark-code&gt;

Expected behavior
A clear and concise description of what you expected to happen.
No error should appear, and files should be downloaded
Screenshots
If applicable, add screenshots to help explain your problem.
Environment (please complete the following information):

OS [e.g. iOS, Linux]:
Version [e.g. flair-0.3.2]:

Google colab
Additional context
Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='Santosh-Gupta' date='2019-02-10T09:17:52Z'>
		Hi,
one problem with this dataset is, that both German and English training data cannot be directly obtained from the shared tasks site: &lt;denchmark-link:https://www.clips.uantwerpen.be/conll2003/ner/&gt;https://www.clips.uantwerpen.be/conll2003/ner/&lt;/denchmark-link&gt;


The English data is a collection of news wire articles from the Reuters Corpus. The annotation has been done by people of the University of Antwerp. Because of copyright reasons we only make available the annotations. In order to build the complete data sets you will need access to the Reuters Corpus. It can be obtained for research purposes without any charge from NIST.

The shared task site only provides scripts to transform the annotations and the Reuters Corpus into a "real" dataset.
But in some repositories on GitHub you can find the complete training, dev and test dataset (for English). But I'm not sure if we're allowed to integrate them into flair ðŸ¤”
		</comment>
		<comment id='2' author='Santosh-Gupta' date='2019-10-03T07:22:28Z'>
		
The shared task site only provides scripts to transform the annotations and the Reuters Corpus into a "real" dataset.
But in some repositories on GitHub you can find the complete training, dev and test dataset (for English). But I'm not sure if we're allowed to integrate them into flair ðŸ¤”

I tried to use these: &lt;denchmark-link:https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003&gt;https://github.com/synalp/NER/tree/master/corpus/CoNLL-2003&lt;/denchmark-link&gt;

but it's failing to work. Getting this exception: Getting 'Exception: Invalid IOB format!'.
		</comment>
		<comment id='3' author='Santosh-Gupta' date='2019-10-04T08:03:24Z'>
		Try only using the standard files, not the OpenNLP ones.
		</comment>
	</comments>
</bug>