<bug id='1905' author='abhipn' open_date='2020-10-10T19:46:48Z' closed_time='2020-10-10T20:13:35Z'>
	<summary>AttributeError: 'NoneType' object has no attribute 'tokenize'</summary>
	<description>
I have trained a model on another machine but when I try to load the trained model onto google colab I am getting,
It took almost 24 hours to train the model, is there any way I can fix this issue? I'm sure it is related to some dependency version mismatch but I just can't figure out which one?
Here's my training  code,
&lt;denchmark-code&gt;embedding_types = [
    TransformerWordEmbeddings('distilbert-base-cased', allow_long_sentences=True, fine_tune=True, batch_size=8),
    FlairEmbeddings('news-forward-fast', fine_tune=True)
]

embeddings : StackedEmbeddings = StackedEmbeddings(
                             embeddings=embedding_types)

trainer : ModelTrainer = ModelTrainer(tagger, corpus, torch.optim.Adam)
trainer.train('/taggers/flair-ner',
              learning_rate=0.0001,
              mini_batch_size=8,
              max_epochs=100,
              num_workers=4,
              min_learning_rate=0.00001) 
&lt;/denchmark-code&gt;

Here's the error,
 tagger = SequenceTagger.load('models/flair/best-model.pt')
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-9-0fa565b989ff&gt; in &lt;module&gt;
----&gt; 1 tagger.predict(Sentence(content))

~/env/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py in predict(self, sentences, mini_batch_size, all_tag_prob, verbose, label_name, return_loss, embedding_storage_mode)
    367                     continue
    368 
--&gt; 369                 feature = self.forward(batch)
    370 
    371                 if return_loss:

~/env/lib/python3.8/site-packages/flair/models/sequence_tagger_model.py in forward(self, sentences)
    606     def forward(self, sentences: List[Sentence]):
    607 
--&gt; 608         self.embeddings.embed(sentences)
    609 
    610         names = self.embeddings.get_names()

~/env/lib/python3.8/site-packages/flair/embeddings/token.py in embed(self, sentences, static_embeddings)
     69 
     70         for embedding in self.embeddings:
---&gt; 71             embedding.embed(sentences)
     72 
     73     @property

~/env/lib/python3.8/site-packages/flair/embeddings/base.py in embed(self, sentences)
     58 
     59         if not everything_embedded or not self.static_embeddings:
---&gt; 60             self._add_embeddings_internal(sentences)
     61 
     62         return sentences

~/env/lib/python3.8/site-packages/flair/embeddings/token.py in _add_embeddings_internal(self, sentences)
    857         # embed each micro-batch
    858         for batch in sentence_batches:
--&gt; 859             self._add_embeddings_to_sentences(batch)
    860 
    861         return sentences

~/env/lib/python3.8/site-packages/flair/embeddings/token.py in _add_embeddings_to_sentences(self, sentences)
    906             # method 2:
    907             # transformer specific tokenization
--&gt; 908             subtokenized_sentence = self.tokenizer.tokenize(tokenized_string)
    909             if len(subtokenized_sentence) == 0:
    910                 empty_sentences.append(sentence)

AttributeError: 'NoneType' object has no attribute 'tokenize'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='abhipn' date='2020-11-05T14:48:41Z'>
		Hi &lt;denchmark-link:https://github.com/abhipn&gt;@abhipn&lt;/denchmark-link&gt;
, I have the exact same error.
Have you solved this ?
thanks
		</comment>
		<comment id='2' author='abhipn' date='2020-11-05T18:00:20Z'>
		
Hi @abhipn, I have the exact same error.
Have you solved this ?
thanks

I can't recall on how I solved it, but I know the issue is related to incorrect dependencies problem. I think using torch 1.5.1 solved the issue for me.
		</comment>
		<comment id='3' author='abhipn' date='2020-12-07T14:22:11Z'>
		Hi &lt;denchmark-link:https://github.com/abhipn&gt;@abhipn&lt;/denchmark-link&gt;
,
I am getting this error and I have torch version 1.6.0. Should I change torch version to 1.5.1?
Hi &lt;denchmark-link:https://github.com/aneuraz&gt;@aneuraz&lt;/denchmark-link&gt;
 ,
How did you solve this issue?
		</comment>
		<comment id='4' author='abhipn' date='2020-12-07T14:24:33Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;
 I think after changing the torch version, it worked. Do try it out.
		</comment>
		<comment id='5' author='abhipn' date='2020-12-07T14:29:56Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;
 During the training of the model, I would define the path to the langage model using an absolute path. Then, when I tried to use the model on another machine, the language model could not be found anymore. To solve it, I used relative path when defining the model and then put the language model in the exact same relative path on the inference machine. Not a completely satisfying solution but it does the trick
		</comment>
		<comment id='6' author='abhipn' date='2020-12-07T15:45:21Z'>
		&lt;denchmark-link:https://github.com/abhipn&gt;@abhipn&lt;/denchmark-link&gt;
 thanks for replying, I tried that but still getting the same error
&lt;denchmark-link:https://github.com/aneuraz&gt;@aneuraz&lt;/denchmark-link&gt;
 thanks for replying.
		</comment>
		<comment id='7' author='abhipn' date='2020-12-15T15:35:20Z'>
		&lt;denchmark-link:https://github.com/Rasmitha23&gt;@Rasmitha23&lt;/denchmark-link&gt;

For me this issue was caused by the transformers library (silently) not being able to download some files (a config.json and a vocab.txt) to a .cache directory. This was because it did not have write permission there.
Setting the  env variable to a directory with enough permissions fixed the issue for me.
Perhaps this is also the cause of &lt;denchmark-link:https://github.com/flairNLP/flair/issues/2011&gt;#2011&lt;/denchmark-link&gt;
?
		</comment>
	</comments>
</bug>