<bug id='1823' author='ForLittleBeauty' open_date='2020-08-19T09:05:10Z' closed_time='2020-08-21T07:38:09Z'>
	<summary>Change batch_size but the usage of GPU remains the same.</summary>
	<description>
Describe the bug
When I use GPU to fine-tuning my BERT model,  I use nvidia-smi to check the usage of my GPU,  however, when I double the mini_batch_size, it seems that the usage of GPU remains the same as before smaller mini_batch_size, I am confused, is this a bug or something wrong to me?
To Reproduce
&lt;denchmark-code&gt;trainer.train('resources/taggers/trec',
            learning_rate=3e-5, # use very small learning rate
            mini_batch_size=512,
            mini_batch_chunk_size=32, # optionally set this if transformer is too much for your machine
            max_epochs=50, # terminate after 5 epochs
	embeddings_storage_mode='gpu'
            )
&lt;/denchmark-code&gt;

Expected behavior
I change mini_batch_size from 16 to 512, the usages of GPU are nearly the same. And I use V100 with 32GB so I do not think the batch_sizes of 16,32,64 will be too large.
Environment (please complete the following information):

Centos :
flair 0.6:

Additional context
Besides, I do not quite understand the usefulness of mini_batch_chunk_size
	</description>
	<comments>
		<comment id='1' author='ForLittleBeauty' date='2020-08-19T09:27:47Z'>
		You have to decrease mini_batch_chunk_size. mini_batch_size is achieved by gradient accumulation.
		</comment>
		<comment id='2' author='ForLittleBeauty' date='2020-08-20T02:38:48Z'>
		this seems to not work for me.
When I keep mini_batch_size = 2
if mini_batch_chunk_size = 1. the GPU Memory Usage = 2876MB
if mini_batch_chunk_size = 2. the GPU Memory Usage = 3273MB
if mini_batch_chunk_size = 4. the GPU Memory Usage = 3277MB
		</comment>
		<comment id='3' author='ForLittleBeauty' date='2020-08-20T07:10:30Z'>
		mini_batch_size is sum of all mini_batch_chunk_size, so e.g. mini_batch_size = 32, mini_batch_chunk_size = 8
		</comment>
		<comment id='4' author='ForLittleBeauty' date='2020-08-20T07:31:42Z'>
		you mean that each time the number of mini_batch_chunk_size's samples will be calculated and when these add up to the number of mini_batch_size samples, it will do the backpropagation?
Anyway, no matter what hyperparameters I set, I can still not double the GPU Memory Usage, can you give me some code to show me how to use more GPU Memory?
		</comment>
		<comment id='5' author='ForLittleBeauty' date='2020-08-20T07:38:44Z'>
		Yes, mini_batch_chunk_size&lt;=mini_batch_size. Set both to e.g. 128 to increase memory.
		</comment>
		<comment id='6' author='ForLittleBeauty' date='2020-08-21T07:38:09Z'>
		Thank you, my problem is solved
		</comment>
	</comments>
</bug>