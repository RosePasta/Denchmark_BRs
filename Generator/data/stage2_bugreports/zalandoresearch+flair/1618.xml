<bug id='1618' author='nstylia' open_date='2020-05-20T08:30:59Z' closed_time='2020-06-13T10:25:18Z'>
	<summary>Using ElmoEmbeddings crashes at the first save attempt.</summary>
	<description>
Using stacked flair embeddings with elmo (or even standalone elmo I assume), results in an error while saving the model due to the lambda function in the elmo embeddings. As a result, the pickler in pytorch cannot save the model and crashes after the first epoch, while trying to save the model. The same code snippet works without the elmo embeddings (omitted parameters in SequenceTagger and train).
embedding_types: List[TokenEmbeddings] = [ PooledFlairEmbeddings('pubmed-forward'), PooledFlairEmbeddings('pubmed-backward'), ELMoEmbeddings('pubmed'), ]
embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)
tagger: SequenceTagger = SequenceTagger(...)
trainer: ModelTrainer = ModelTrainer(tagger, corpus)
trainer.train(...)
The error message:

Traceback (most recent call last):
File "flair_main.py", line 43, in 
max_epochs=100)
File "/home/ns/envs/mldev/lib/python3.6/site-packages/flair/trainers/trainer.py", line 552, in train
self.model.save(base_path / "best-model.pt")
File "/home/ns/envs/mldev/lib/python3.6/site-packages/flair/nn.py", line 70, in save
torch.save(model_state, str(model_file), pickle_protocol=4)
File "/home/ns/envs/mldev/lib/python3.6/site-packages/torch/serialization.py", line 328, in save
_legacy_save(obj, opened_file, pickle_module, pickle_protocol)
File "/home/ns/envs/mldev/lib/python3.6/site-packages/torch/serialization.py", line 401, in _legacy_save
pickler.dump(obj)
AttributeError: Can't pickle local object 'ELMoEmbeddings.__init__.&lt;locals&gt;.&lt;lambda&gt; '

Environment information:
Ubuntu 16.04
torch-1.4.0+cu101
flair-0.4.5
Is there any work around ? Am I doing something wrong? I don't think this is expected behavior. Also, I assume that pickle would be able to handle lambda functions.
	</description>
	<comments>
		<comment id='1' author='nstylia' date='2020-05-31T23:27:11Z'>
		Same error here with using the ELMo embeddings only. I tried to train a NER model with pretty much the old code (except I wanted to choose 'average' as the embedding mode for ELMo, since this is the new feature in Release 0.5) I used for Release 0.45, which worked well in the past. My code is as follows:
&lt;denchmark-code&gt;from flair.data import Corpus
from flair.datasets import ColumnCorpus
from flair.models import SequenceTagger
from flair.trainers import ModelTrainer
from flair.embeddings import ELMoEmbeddings
from knockknock import slack_sender

webhook_url = "https://hooks.slack.com/services/TES***"

#from flair.embeddings import TokenEmbeddings,FlairEmbeddings,StackedEmbeddings

# define columns
columns = {0: 'text', 1: 'ner'}

# this is the folder in which train, test and dev files reside
data_folder = '../data/name_parsing_mix/'

# init a corpus using column format, data folder and the names of the train, dev and test files
corpus: Corpus = ColumnCorpus(data_folder, columns,
                              train_file='train.txt',
                              test_file='test.txt',
                              dev_file='dev.txt',
                              column_delimiter='\t',
                              in_memory=True)

#%%
#print (len(corpus.train))
#print(corpus.train[554].to_tagged_string('ner'))
#%%
@slack_sender(webhook_url=webhook_url,channel='	Yue')
def start_train_elmo_noncrf(corpus,crf=False):
    tag_type = 'ner'
    tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)
    #print(tag_dictionary)
    tagger: SequenceTagger = SequenceTagger(hidden_size=128,
                                            embeddings=ELMoEmbeddings(model='original',
                                                                      embedding_mode='average'),
                                            tag_dictionary=tag_dictionary,
                                            tag_type=tag_type,
                                            use_crf=crf)
    
    trainer: ModelTrainer = ModelTrainer(tagger, corpus)
    
    trainer.train('../model/name_parser_elmo_noncrf',
                  learning_rate=0.1,
                  mini_batch_size=128,
                  max_epochs=3,
                  embeddings_storage_mode='none',
                  checkpoint=False)

    return ('model crf='+str(crf)+' is complete.')

#%%
start_train_elmo_noncrf(corpus,crf=False)

&lt;/denchmark-code&gt;

The setup is shown as:
&lt;denchmark-code&gt;2020-05-31 11:11:50,530 Model: "SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-original-average)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=1024, out_features=1024, bias=True)
  (rnn): LSTM(1024, 128, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=256, out_features=15, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-05-31 11:11:50,534 ----------------------------------------------------------------------------------------------------
2020-05-31 11:11:50,534 Corpus: "Corpus: 2414463 train + 689839 dev + 344939 test sentences"
2020-05-31 11:11:50,534 ----------------------------------------------------------------------------------------------------
2020-05-31 11:11:50,534 Parameters:
2020-05-31 11:11:50,534  - learning_rate: "0.1"
2020-05-31 11:11:50,534  - mini_batch_size: "128"
2020-05-31 11:11:50,534  - patience: "3"
2020-05-31 11:11:50,534  - anneal_factor: "0.5"
2020-05-31 11:11:50,534  - max_epochs: "3"
2020-05-31 11:11:50,534  - shuffle: "True"
2020-05-31 11:11:50,535  - train_with_dev: "False"
2020-05-31 11:11:50,535  - batch_growth_annealing: "False"
2020-05-31 11:11:50,535 ----------------------------------------------------------------------------------------------------
2020-05-31 11:11:50,535 Model training base path: "../model/name_parser_elmo_noncrf"
2020-05-31 11:11:50,535 ----------------------------------------------------------------------------------------------------
2020-05-31 11:11:50,535 Device: cuda:0
2020-05-31 11:11:50,535 ----------------------------------------------------------------------------------------------------
2020-05-31 11:11:50,535 Embeddings storage mode: none

&lt;/denchmark-code&gt;

As soon as the model is getting saved after the first epoch, I ran into the following error:
&lt;denchmark-code&gt;2020-05-31 11:23:49,567 epoch 1 - iter 1886/18863 - loss 0.34166095 - samples/sec: 336.07
2020-05-31 11:36:13,568 epoch 1 - iter 3772/18863 - loss 0.26286673 - samples/sec: 324.97
2020-05-31 11:48:16,641 epoch 1 - iter 5658/18863 - loss 0.22865570 - samples/sec: 334.16
2020-05-31 12:00:18,113 epoch 1 - iter 7544/18863 - loss 0.20833792 - samples/sec: 334.89
2020-05-31 12:12:22,932 epoch 1 - iter 9430/18863 - loss 0.19446842 - samples/sec: 333.33
2020-05-31 12:24:24,954 epoch 1 - iter 11316/18863 - loss 0.18426253 - samples/sec: 334.61
2020-05-31 12:36:27,148 epoch 1 - iter 13202/18863 - loss 0.17635040 - samples/sec: 334.53
2020-05-31 12:48:26,543 epoch 1 - iter 15088/18863 - loss 0.17007715 - samples/sec: 335.83
2020-05-31 13:00:26,932 epoch 1 - iter 16974/18863 - loss 0.16472568 - samples/sec: 335.37
2020-05-31 13:12:27,473 epoch 1 - iter 18860/18863 - loss 0.16004452 - samples/sec: 335.30
2020-05-31 13:12:28,663 ----------------------------------------------------------------------------------------------------
2020-05-31 13:12:28,663 EPOCH 1 done: loss 0.1600 - lr 0.1000000
2020-05-31 13:45:39,259 DEV : loss 0.0749698281288147 - score 0.9788
2020-05-31 13:45:41,464 BAD EPOCHS (no improvement): 0
saving best model
Traceback (most recent call last):
  File "train_elmo_noncrf.py", line 63, in &lt;module&gt;
    start_train_elmo_noncrf(corpus,crf=False)
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/knockknock/slack_sender.py", line 105, in wrapper_sender
    raise ex
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/knockknock/slack_sender.py", line 63, in wrapper_sender
    value = func(*args, **kwargs)
  File "train_elmo_noncrf.py", line 58, in start_train_elmo_noncrf
    checkpoint=False)
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/flair/trainers/trainer.py", line 557, in train
    self.model.save(base_path / "best-model.pt")
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/flair/nn.py", line 70, in save
    torch.save(model_state, str(model_file), pickle_protocol=4)
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/serialization.py", line 224, in save
    return _with_file_like(f, "wb", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/serialization.py", line 149, in _with_file_like
    return body(f)
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/serialization.py", line 224, in &lt;lambda&gt;
    return _with_file_like(f, "wb", lambda f: _save(obj, f, pickle_module, pickle_protocol))
  File "/scratch/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/serialization.py", line 296, in _save
    pickler.dump(obj)
AttributeError: Can't pickle local object 'ELMoEmbeddings.__init__.&lt;locals&gt;.&lt;lambda&gt;'
&lt;/denchmark-code&gt;

I have never run into this error in previous releases. I looked into the lines in "trainer.py" and "nn.py" in flair where the model is saved. They seem the same compared to Release 0.45. So then is this error caused by incompatibility with some changes made on Allennlp side or the pytorch side?
I have the following version:
allennlp=0.9.0
torch=1.2.0
		</comment>
		<comment id='2' author='nstylia' date='2020-06-08T18:53:18Z'>
		Did you solve? I had the same problem...
		</comment>
		<comment id='3' author='nstylia' date='2020-06-09T08:00:51Z'>
		As far as I can tell, without being certain, the problem does not stem from flair. Nevertheless I have not found a satisfying solution, but I have found the following workaround in case you absolutely have to do it.
You can locate the trainer.py script from flair and bypass all the save/load methods called, by commenting them out. This will affect all projects that use flair! You can then train and evaluate a model this way, but it has to be done in 1 go and it will not be saved.
Keep in mind that this is a very bad way to approach this. If you are to pursuit this approach, I would also recommend using a new virtual environment to avoid any unwanted side-effects.
		</comment>
		<comment id='4' author='nstylia' date='2020-06-10T08:33:51Z'>
		The issue is caused by the use of lambda function in ELMoEmbeddings class introduced in Release 0.5. When the model is getting saved with Pickle in serialization.py, the lambda functions cannot be pickled and cause the error.  See this &lt;denchmark-link:https://gist.github.com/betatim/ae42c092827d2f8e9d6e4f7219a8cadd&gt;snippet&lt;/denchmark-link&gt;
 for a demonstration.
To choose the combinations of layers of the ELMo embeddings (a &lt;denchmark-link:https://github.com/flairNLP/flair/pull/1547&gt;new feature&lt;/denchmark-link&gt;
 in Release 0.5), line 1543 - 1548 of &lt;denchmark-link:https://github.com/flairNLP/flair/blob/v0.5/flair/embeddings/token.py&gt;token.py&lt;/denchmark-link&gt;
 define three lambda functions,
&lt;denchmark-code&gt;if embedding_mode == "all":
    self.embedding_mode_fn = lambda x: torch.cat(x, 0)
elif embedding_mode == "top":
    self.embedding_mode_fn = lambda x: x[-1]
elif embedding_mode == "average":
    self.embedding_mode_fn = lambda x: torch.mean(torch.stack(x), 0)
&lt;/denchmark-code&gt;

These are the exact lines that caused the problem. In my forked Release 0.5, I commented out these lines while replacing line 1594,
&lt;denchmark-code&gt;word_embedding = self.embedding_mode_fn(elmo_embedding_layers)
&lt;/denchmark-code&gt;

with
&lt;denchmark-code&gt;word_embedding = torch.cat(elmo_embedding_layers, 0)
&lt;/denchmark-code&gt;

which is equivalent to choosing "all" for the embedding mode. After these changes, the training ran through and the model was able to be saved. If you want to choose other embedding mode, maybe try doing the same thing, but just convert the corresponding lambda function. Also, I found that commenting out line 1543 - 1548 is required. Otherwise, the lambda functions are still part of the ELMoEmbeddings class and the same pickle error may occur.
		</comment>
		<comment id='5' author='nstylia' date='2020-06-11T10:23:00Z'>
		&lt;denchmark-link:https://github.com/yzhaoinuw&gt;@yzhaoinuw&lt;/denchmark-link&gt;
 could you do a PR for this? The fix would be useful for lots of people :)
		</comment>
		<comment id='6' author='nstylia' date='2020-06-11T20:14:24Z'>
		&lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
 Ceratainly! Maybe I can also include my fix for &lt;denchmark-link:https://github.com/flairNLP/flair/issues/1634&gt;#1634&lt;/denchmark-link&gt;
 in one go since both issues are caused by the changes in the ELMoEmbeddings class in Release 0.5.
		</comment>
		<comment id='7' author='nstylia' date='2020-06-12T10:52:35Z'>
		Yes that would be great!
		</comment>
		<comment id='8' author='nstylia' date='2020-06-13T10:25:18Z'>
		PR just merged that fixes this! Thanks &lt;denchmark-link:https://github.com/yzhaoinuw&gt;@yzhaoinuw&lt;/denchmark-link&gt;
!
		</comment>
	</comments>
</bug>