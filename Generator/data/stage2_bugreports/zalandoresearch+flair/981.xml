<bug id='981' author='juand-r' open_date='2019-08-08T18:10:41Z' closed_time='2019-08-12T12:16:29Z'>
	<summary>Truncating sentences with max_tokens_per_doc when in_memory=False</summary>
	<description>
It appears that argument max_tokens_per_doc has no effect when creating a ClassificationCorpus if in_memory=False (which is the default for ClassificationCorpus).
Looking at ClassificationDataset in datasets.py, I see that max_tokens_per_doc is not used when self.in_memory is False.
I also get an error due to long lines with the following code:
from pathlib import Path 
from flair.datasets import ClassificationCorpus
from flair.embeddings import DocumentRNNEmbeddings, BertEmbeddings
from flair.models import TextClassifier
from flair.trainers import ModelTrainer

data_folder = Path('data_fasttext_format') # some of the sentences have long lines
corpus: ClassificationCorpus = ClassificationCorpus(data_folder,train_file='train.txt',dev_file='val.txt',test_file='val.txt', max_tokens_per_doc=20)
label_dict = corpus.make_label_dictionary()                                     
embs = [BertEmbeddings()]
document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(embs, rnn_type='LSTM')
classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, multi_label=False)
trainer = ModelTrainer(classifier, corpus) 
trainer.train('data_fasttext_format')
This results in error RuntimeError: index out of range at /pytorch/aten/src/TH/generic/THTensorEvenMoreMath.cpp:191. However, when I use in_memory=True when creating the ClassificationDataset, the sentences are truncated as expected and there are no errors.
Enviroment:

Linux
Python 3.6.2
flair-0.4.2

	</description>
	<comments>
		<comment id='1' author='juand-r' date='2019-08-12T07:26:38Z'>
		Thanks for reporting this - looks like an error. I'll put in a PR to fix this!
		</comment>
	</comments>
</bug>