<bug id='407' author='stefan-it' open_date='2019-01-21T01:06:28Z' closed_time='2019-02-02T14:47:25Z'>
	<summary>Error when training a model on CUDA</summary>
	<description>
Hi,
I think this is a regression bug that was introduced after merging the CUDA semantics pull request &lt;denchmark-link:https://github.com/flairNLP/flair/pull/402&gt;#402&lt;/denchmark-link&gt;
.
Here's an error message that comes from the test_model_integration.py  integration test:
&gt;               tag_tensor = torch.LongTensor(sentence_tags)
E               TypeError: expected torch.LongTensor (got torch.cuda.LongTensor)
I got a similar error message when I tried to test my recent ELMo transformer embeddings on GPU.
To replicate the error just run the integration tests (pytest --runintegration) on a machine with GPU/CUDA support :)
	</description>
	<comments>
		<comment id='1' author='stefan-it' date='2019-02-06T09:05:23Z'>
		Thanks, it is working now :)
		</comment>
	</comments>
</bug>