<bug id='2995' author='Lisicong9203' open_date='2020-09-03T10:42:48Z' closed_time='2020-09-07T05:09:06Z'>
	<summary>Version converter 9--&amp;gt;10 fails with 'Input conv_first.weight is undefined!'</summary>
	<description>
&lt;denchmark-h:h1&gt;Bug Report&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Describe the bug&lt;/denchmark-h&gt;

The version converter fails on the attached model
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g. Linux Ubuntu 16.04):  Ubuntu 18.04.4 LTS
ONNX version (e.g. 1.7):  1.7.0
Python version: Python 3.6.9
GCC/Compiler version (if compiling from source):
CMake version:
Protobuf version:
Visual Studio version (if applicable):

&lt;denchmark-h:h3&gt;Reproduction instructions&lt;/denchmark-h&gt;


Describe the code to reproduce the behavior.

&lt;denchmark-code&gt;import onnx
from onnx import version_converter, helper
model_path = 'deart_model_fp16.onnx'
original_model = onnx.load(model_path)

converted_model = version_converter.convert_version(original_model, 10)

print('The model after conversion:\n{}'.format(converted_model))

&lt;/denchmark-code&gt;

error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-8-4409d2eda4ac&gt; in &lt;module&gt;
      6 # https://github.com/onnx/onnx/blob/master/onnx/version_converter.py#L21
      7 # Apply the version conversion on the original model
----&gt; 8 converted_model = version_converter.convert_version(original_model, 10)
      9
     10 print('The model after conversion:\n{}'.format(converted_model))

~/tf.t130/lib/python3.6/site-packages/onnx/version_converter.py in convert_version(model, target_version)
    164         raise ValueError('VersionConverter only accepts int as target_version, incorrect type: {}'.format(type(target_version)))
    165     model_str = model.SerializeToString()
--&gt; 166     converted_model_str = C.convert_version(model_str, target_version)
    167     return onnx.load_from_string(converted_model_str)

IndexError: Input conv_first.weight is undefined!
&lt;/denchmark-code&gt;

Onnx model:
&lt;denchmark-link:https://drive.google.com/open?id=1tO3P9ZxxqCZqi-4RoWQxxGYv2c2i4yrI&gt;deart_model_fp16.onnx&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Lisicong9203' date='2020-09-03T15:44:19Z'>
		Hi &lt;denchmark-link:https://github.com/Lisicong9203&gt;@Lisicong9203&lt;/denchmark-link&gt;
,
It seems that you provide a wrong file (). Could you upload the onnx model again? Thanks.
		</comment>
		<comment id='2' author='Lisicong9203' date='2020-09-04T03:27:01Z'>
		&lt;denchmark-link:https://github.com/jcwchen&gt;@jcwchen&lt;/denchmark-link&gt;
  I'm so sorry about that , i have update the onnx file.
		</comment>
		<comment id='3' author='Lisicong9203' date='2020-09-04T14:52:41Z'>
		&lt;denchmark-link:https://github.com/Lisicong9203&gt;@Lisicong9203&lt;/denchmark-link&gt;
 No worries. But it needs access right now...
		</comment>
		<comment id='4' author='Lisicong9203' date='2020-09-04T17:34:42Z'>
		&lt;denchmark-link:https://github.com/jcwchen&gt;@jcwchen&lt;/denchmark-link&gt;
 Because it is not convenient to access Google in China, I got it wrong. I updated this link the file named deart_model.onnx  is the file I used when converting. I first converted this file to fp 16  (deart_model_fp16.onnx I will update this file tomorrow ) like this: &lt;denchmark-link:https://github.com/onnx/onnx-docker/blob/master/onnx-ecosystem/converter_scripts/float32_float16_onnx.ipynb&gt;tutorial&lt;/denchmark-link&gt;
  . then when i convert deart_model_fp16.onnx from onnx 9 to onnx 10  I encountered this error.
		</comment>
		<comment id='5' author='Lisicong9203' date='2020-09-04T22:09:32Z'>
		No problem. Thank you for providing the onnx model!
I believe it is a known IR issue like &lt;denchmark-link:https://github.com/onnx/onnx/issues/2873&gt;#2873&lt;/denchmark-link&gt;
. The old version_converter expects initializers also be added as graph inputs. A quick workaround would be including all the initializers into the graph inputs. There will be a PR for fixing this.
		</comment>
		<comment id='6' author='Lisicong9203' date='2020-09-05T07:16:49Z'>
		&lt;denchmark-link:https://github.com/jcwchen&gt;@jcwchen&lt;/denchmark-link&gt;

I am not particularly familiar with onnx .   . What exactly does initializers here mean? Is it the code we often write in the code model   ?
What should I do if I want to add this 'initializers'  part to onnx model ?
In addition, if I donâ€™t have the original model code, only the onnx file, can I have other ways to fix this problem?
		</comment>
		<comment id='7' author='Lisicong9203' date='2020-09-05T16:22:52Z'>
		You can use something like this to add input from initializer:
&lt;denchmark-code&gt;def add_input_from_initializer(model : onnx.ModelProto):
    """
    Currently onnx.shape_inference doesn't use the shape of initializers, so add
    that info explicitly as ValueInfoProtos.
    Mutates the model.
    Args:
        model: The ModelProto to update.
    """
    # All (top-level) constants will have ValueInfos before IRv4 as they are all inputs
    if model.ir_version &lt; 4:
        return

    def add_const_value_infos_to_graph(graph : onnx.GraphProto):
        inputs = {i.name for i in graph.input}
        existing_info = {vi.name: vi for vi in graph.input}
        for init in graph.initializer:
            # Check it really is a constant, not an input
            if init.name in inputs:
                continue

            # The details we want to add
            elem_type = init.data_type
            shape = init.dims

            # Get existing or create new value info for this constant
            vi = existing_info.get(init.name)
            if vi is None:
                vi = graph.input.add()
                vi.name = init.name

            # Even though it would be weird, we will not overwrite info even if it doesn't match
            tt = vi.type.tensor_type
            if tt.elem_type == onnx.TensorProto.UNDEFINED:
                tt.elem_type = elem_type
            if not tt.HasField("shape"):
                # Ensure we set an empty list if the const is scalar (zero dims)
                tt.shape.dim.extend([])
                for dim in shape:
                    tt.shape.dim.add().dim_value = dim

        # Handle subgraphs
        for node in graph.node:
            for attr in node.attribute:
                # Ref attrs refer to other attrs, so we don't need to do anything
                if attr.ref_attr_name != "":
                    continue

                if attr.type == onnx.AttributeProto.GRAPH:
                    add_const_value_infos_to_graph(attr.g)
                if attr.type == onnx.AttributeProto.GRAPHS:
                    for g in attr.graphs:
                        add_const_value_infos_to_graph(g)


    return add_const_value_infos_to_graph(model.graph)
add_input_from_initializer(original_model)
&lt;/denchmark-code&gt;

Even though it can fix the error you are facing, it will bump into another one after applying this fix:
&lt;denchmark-code&gt;BaseConverter.h:64: adapter_lookup: Assertion `false` failed: No Adapter For Slice
&lt;/denchmark-code&gt;

For those supported operators for version_converter, you can check this &lt;denchmark-link:https://github.com/onnx/onnx/blob/master/onnx/version_converter/convert.h&gt;file&lt;/denchmark-link&gt;
. Sorry that currently the  operator is unsupported.
		</comment>
		<comment id='8' author='Lisicong9203' date='2020-09-07T05:09:03Z'>
		OK,I will try some other methods. Thanks
		</comment>
	</comments>
</bug>