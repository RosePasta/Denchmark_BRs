<bug id='1040' author='michaelbzhu' open_date='2020-12-04T06:39:51Z' closed_time='2020-12-06T19:52:51Z'>
	<summary>Hyperopt: Category feature preprocessing in hyperopt raising Attribute Error</summary>
	<description>
So I'm running hyperopt() with the following arguments
&lt;denchmark-code&gt;hyperopt(
    config=config,
    training_set=train_data,
    validation_set=validation_data,
    test_set=test_data,
    skip_save_progress=True,
    skip_save_model=True,
    skip_save_processed_input=True
)
&lt;/denchmark-code&gt;

and I'm getting a AttributeError: 'int' object has no attribute 'strip' during the data preprocessing step
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-13-c2e6c8f1ae7c&gt; in &lt;module&gt;()
     10     skip_save_progress=True,
     11     skip_save_model=False,
---&gt; 12     skip_save_processed_input=True
     13 )
/usr/local/lib/python3.6/dist-packages/ludwig/hyperopt/run.py in hyperopt(config, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, experiment_name, model_name, skip_save_training_description, skip_save_training_statistics, skip_save_model, skip_save_progress, skip_save_log, skip_save_processed_input, skip_save_unprocessed_output, skip_save_predictions, skip_save_eval_stats, skip_save_hyperopt_statistics, output_directory, gpus, gpu_memory_limit, allow_parallel_threads, use_horovod, random_seed, debug, **kwargs)
    289         random_seed=random_seed,
    290         debug=debug,
--&gt; 291         **kwargs
    292     )
    293 
/usr/local/lib/python3.6/dist-packages/ludwig/hyperopt/execution.py in execute(self, config, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, experiment_name, model_name, skip_save_training_description, skip_save_training_statistics, skip_save_model, skip_save_progress, skip_save_log, skip_save_processed_input, skip_save_unprocessed_output, skip_save_predictions, skip_save_eval_stats, output_directory, gpus, gpu_memory_limit, allow_parallel_threads, use_horovod, random_seed, debug, **kwargs)
    149                     skip_collect_overall_stats=False,
    150                     random_seed=random_seed,
--&gt; 151                     debug=debug,
    152                 )
    153                 metric_score = self.get_metric_score(eval_stats)
/usr/local/lib/python3.6/dist-packages/ludwig/api.py in experiment(self, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, experiment_name, model_name, model_load_path, model_resume_path, eval_split, skip_save_training_description, skip_save_training_statistics, skip_save_model, skip_save_progress, skip_save_log, skip_save_processed_input, skip_save_unprocessed_output, skip_save_predictions, skip_save_eval_stats, skip_collect_predictions, skip_collect_overall_stats, output_directory, random_seed, debug, **kwargs)
   1054             output_directory=output_directory,
   1055             random_seed=random_seed,
-&gt; 1056             debug=debug,
   1057         )
   1058 
/usr/local/lib/python3.6/dist-packages/ludwig/api.py in train(self, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, experiment_name, model_name, model_resume_path, skip_save_training_description, skip_save_training_statistics, skip_save_model, skip_save_progress, skip_save_log, skip_save_processed_input, output_directory, random_seed, debug, **kwargs)
    415                     random_seed=random_seed,
    416                     devbug=debug,
--&gt; 417                     **kwargs,
    418                 )
    419                 (training_set,
/usr/local/lib/python3.6/dist-packages/ludwig/api.py in preprocess(self, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, skip_save_processed_input, random_seed, debug, **kwargs)
   1261             preprocessing_params=self.config[PREPROCESSING],
   1262             backend=self.backend,
-&gt; 1263             random_seed=random_seed
   1264         )
   1265 
/usr/local/lib/python3.6/dist-packages/ludwig/data/preprocessing.py in preprocess_for_training(config, dataset, training_set, validation_set, test_set, training_set_metadata, data_format, skip_save_processed_input, preprocessing_params, backend, random_seed)
   1395         preprocessing_params=preprocessing_params,
   1396         backend=backend,
-&gt; 1397         random_seed=random_seed
   1398     )
   1399     training_set, test_set, validation_set, training_set_metadata = processed
/usr/local/lib/python3.6/dist-packages/ludwig/data/preprocessing.py in preprocess_for_training(features, dataset, training_set, validation_set, test_set, training_set_metadata, skip_save_processed_input, preprocessing_params, backend, random_seed)
    183             preprocessing_params=preprocessing_params,
    184             backend=backend,
--&gt; 185             random_seed=random_seed
    186         )
    187 
/usr/local/lib/python3.6/dist-packages/ludwig/data/preprocessing.py in _preprocess_df_for_training(features, dataset, training_set, validation_set, test_set, training_set_metadata, preprocessing_params, backend, random_seed)
   1645         metadata=training_set_metadata,
   1646         random_seed=random_seed,
-&gt; 1647         backend=backend
   1648     )
   1649 
/usr/local/lib/python3.6/dist-packages/ludwig/data/preprocessing.py in build_dataset(dataset_df, features, global_preprocessing_parameters, metadata, backend, random_seed)
   1013             features,
   1014             global_preprocessing_parameters,
-&gt; 1015             backend
   1016         )
   1017 
/usr/local/lib/python3.6/dist-packages/ludwig/data/preprocessing.py in build_metadata(dataset_df, features, global_preprocessing_parameters, backend)
   1122                 column,
   1123                 preprocessing_parameters,
-&gt; 1124                 backend
   1125             )
   1126 
/usr/local/lib/python3.6/dist-packages/ludwig/features/category_feature.py in get_feature_meta(column, preprocessing_parameters, backend)
     65             lowercase=preprocessing_parameters['lowercase'],
     66             add_padding=False,
---&gt; 67             processor=backend.df_engine
     68         )
     69         return {
/usr/local/lib/python3.6/dist-packages/ludwig/utils/strings_utils.py in create_vocabulary(data, tokenizer_type, add_unknown, add_padding, lowercase, num_most_frequent, vocab_file, unknown_symbol, padding_symbol, pretrained_model_name_or_path, processor)
    139         vocab = load_vocabulary(vocab_file)
    140 
--&gt; 141     processed_lines = data.map(lambda line: tokenizer(line.lower() if lowercase else line))
    142     processed_counts = processed_lines.explode().value_counts(sort=False)
    143     processed_counts = processor.compute(processed_counts)
/usr/local/lib/python3.6/dist-packages/pandas/core/series.py in map(self, arg, na_action)
   3980         dtype: object
   3981         """
-&gt; 3982         new_values = super()._map_values(arg, na_action=na_action)
   3983         return self._constructor(new_values, index=self.index).__finalize__(
   3984             self, method="map"
/usr/local/lib/python3.6/dist-packages/pandas/core/base.py in _map_values(self, mapper, na_action)
   1158 
   1159         # mapper is a function
-&gt; 1160         new_values = map_f(values, mapper)
   1161 
   1162         return new_values
pandas/_libs/lib.pyx in pandas._libs.lib.map_infer()
/usr/local/lib/python3.6/dist-packages/ludwig/utils/strings_utils.py in &lt;lambda&gt;(line)
    139         vocab = load_vocabulary(vocab_file)
    140 
--&gt; 141     processed_lines = data.map(lambda line: tokenizer(line.lower() if lowercase else line))
    142     processed_counts = processed_lines.explode().value_counts(sort=False)
    143     processed_counts = processor.compute(processed_counts)
/usr/local/lib/python3.6/dist-packages/ludwig/utils/strings_utils.py in __call__(self, text)
    305 class StrippedStringToListTokenizer(BaseTokenizer):
    306     def __call__(self, text):
--&gt; 307         return [text.strip()]
    308 
    309 
AttributeError: 'int' object has no attribute 'strip'
&lt;/denchmark-code&gt;

Environment :

Run on Google Colab
Python version: 3.6
Ludwig version: Using ludwig from github repo up to commit fcb01e3

Seems like this is related to the recent commits (on Dec 3, 2020) as this bug hasn't happened before
	</description>
	<comments>
		<comment id='1' author='michaelbzhu' date='2020-12-05T06:54:47Z'>
		This is probably related to a change made in &lt;denchmark-link:https://github.com/ludwig-ai/ludwig/pull/1038&gt;#1038&lt;/denchmark-link&gt;
 that changes the data type casting during preprocessing.  I'll take a look.
		</comment>
		<comment id='2' author='michaelbzhu' date='2020-12-05T17:38:45Z'>
		Hey &lt;denchmark-link:https://github.com/michaelbzhu&gt;@michaelbzhu&lt;/denchmark-link&gt;
, can you try &lt;denchmark-link:https://github.com/ludwig-ai/ludwig/pull/1042&gt;#1042&lt;/denchmark-link&gt;
 and let me know if it solves your issue?
		</comment>
		<comment id='3' author='michaelbzhu' date='2020-12-06T03:18:45Z'>
		&lt;denchmark-link:https://github.com/tgaddair&gt;@tgaddair&lt;/denchmark-link&gt;
 yeah it's working now when I use &lt;denchmark-link:https://github.com/ludwig-ai/ludwig/pull/1042&gt;#1042&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='michaelbzhu' date='2020-12-06T19:53:23Z'>
		Merged ;)
		</comment>
	</comments>
</bug>