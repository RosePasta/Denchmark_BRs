<bug id='616' author='JaiKotia' open_date='2020-01-19T12:20:23Z' closed_time='2020-01-23T22:33:12Z'>
	<summary>Running the One Shot Siamese Network produces ValueError: Trying to share variable image_path_1/fc_0/weights, but specified shape (46656, 128) and found shape (3136, 128)</summary>
	<description>
Describe the bug
This is the error traceback log:

Traceback (most recent call last):
File "/home/jai/anaconda3/bin/ludwig", line 10, in 
sys.exit(main())
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/cli.py", line 108, in main
CLI()
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/cli.py", line 64, in init
getattr(self, args.command)()
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/cli.py", line 69, in experiment
experiment.cli(sys.argv[2:])
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/experiment.py", line 529, in cli
experiment(**vars(args))
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/experiment.py", line 219, in experiment
**kwargs
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/train.py", line 336, in full_train
debug=debug
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/train.py", line 483, in train
debug=debug
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/model.py", line 113, in init
**kwargs
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/model.py", line 163, in __build
is_training=self.is_training
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/inputs.py", line 42, in build_inputs
**kwargs)
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/inputs.py", line 69, in build_single_input
**kwargs)
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/features/image_feature.py", line 378, in build_input
is_training,
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/modules/image_encoders.py", line 89, in call
is_training=is_training
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/modules/fully_connected_modules.py", line 136, in call
'regularize'] else None
File "/home/jai/anaconda3/lib/python3.6/site-packages/ludwig/models/modules/fully_connected_modules.py", line 50, in fc_layer
initializer=initializer
File "/home/jai/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 1496, in get_variable
aggregation=aggregation)
File "/home/jai/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 1239, in get_variable
aggregation=aggregation)
File "/home/jai/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 562, in get_variable
aggregation=aggregation)
File "/home/jai/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 514, in _true_getter
aggregation=aggregation)
File "/home/jai/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py", line 869, in _get_single_variable
(name, shape, found_var.get_shape()))
ValueError: Trying to share variable image_path_1/fc_0/weights, but specified shape (46656, 128) and found shape (3136, 128).


I tried to reproduce the example given in the documentation:
&lt;denchmark-link:https://uber.github.io/ludwig/examples/#one-shot-learning-with-siamese-networks&gt;https://uber.github.io/ludwig/examples/#one-shot-learning-with-siamese-networks&lt;/denchmark-link&gt;

Used exactly the same model_definition.yaml and omniglot data. Ran the following command:
&lt;denchmark-code&gt;ludwig experiment \
--data_csv balinese_characters.csv \
  --model_definition_file model_definition.yaml

&lt;/denchmark-code&gt;

Environment

OS: Ubuntu
Version: 18.04
Python version: 3.6.6
Ludwig version: 0.16.0

	</description>
	<comments>
		<comment id='1' author='JaiKotia' date='2020-01-21T19:46:17Z'>
		Can you please share your model definition? This issue is due to the image size mismatches somewhere.
Are all the images in your dataset of the same shape?
		</comment>
		<comment id='2' author='JaiKotia' date='2020-01-22T21:57:19Z'>
		No Sai, the error is due to sharing the parameters between the two branches of the siamese networks. He probably defined some fully connected weights in one branch and not in the other. Parameters of both the branches that are tied should be identical.
&lt;denchmark-link:https://github.com/JaiKotia&gt;@JaiKotia&lt;/denchmark-link&gt;
  please share your model definition so that we can confirm but I'm pretty confident that's the cause.
		</comment>
		<comment id='3' author='JaiKotia' date='2020-01-23T06:38:29Z'>
		Hey &lt;denchmark-link:https://github.com/msaisumanth&gt;@msaisumanth&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/w4nderlust&gt;@w4nderlust&lt;/denchmark-link&gt;
 thanks for the reply. This is the model definition. I didn't make any changes to it from the documentation example:
&lt;denchmark-code&gt;input_features:
    -
        name: image_path_1
        type: image
        encoder: stacked_cnn
        preprocessing:
          width: 28
          height: 28
          resize_image: true
    -
        name: image_path_2
        type: image
        encoder: stacked_cnn
        resize_image: true
        width: 28
        height: 28
        tied_weights: image_path_1

combiner:
    type: concat
    num_fc_layers: 2
    fc_size: 256

output_features:
    -
        name: similarity
        type: binary
&lt;/denchmark-code&gt;

Yes the images are of the same shape, they are both from the omniglot data set.
		</comment>
		<comment id='4' author='JaiKotia' date='2020-01-23T21:43:35Z'>
		Could you try rewriting the width and height parameters for image_path_2 just like for image_path_1?
I think that's the issue.
		</comment>
		<comment id='5' author='JaiKotia' date='2020-01-23T22:35:40Z'>
		So the error in the docs was fixed. Can you please confirm that with the correct preprocessing now the example forks? In case it doesn't we can reopen the issue.
		</comment>
		<comment id='6' author='JaiKotia' date='2020-01-24T10:25:07Z'>
		&lt;denchmark-link:https://github.com/w4nderlust&gt;@w4nderlust&lt;/denchmark-link&gt;
 works fine now, thanks! 
		</comment>
	</comments>
</bug>