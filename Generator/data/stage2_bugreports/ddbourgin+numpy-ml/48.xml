<bug id='48' author='Z-zhe' open_date='2020-04-08T09:15:23Z' closed_time='2020-04-19T02:10:07Z'>
	<summary>A little bugÔºÅ</summary>
	<description>
Hi, I think there is a little bug at numpy-ml/numpy_ml/neural_nets/activations/activations.py  Line 64.
your code
&lt;denchmark-code&gt;fn_x = self.fn_x
&lt;/denchmark-code&gt;

but
self.fn_x Never defined
	</description>
	<comments>
		<comment id='1' author='Z-zhe' date='2020-04-09T07:23:52Z'>
		And numpy-ml/numpy_ml/neural_nets/wrappers/wrappers.py Line 207:
your code
&lt;denchmark-code&gt;def backward(self, dLdy, retain_grads):
"""
retain_grads: Default is True
"""
&lt;/denchmark-code&gt;

Your code is missing the default value, resulting in an error at  numpy-ml/numpy_ml/neural_nets/layers/layers.py Line 332.
		</comment>
		<comment id='2' author='Z-zhe' date='2020-04-09T09:06:04Z'>
		And numpy-ml/numpy_ml/neural_nets/layers/layers.py Line 2116:
your code
&lt;denchmark-code&gt;def backward(self, dLdy):
"""
retain_grads: Default is True
"""
&lt;/denchmark-code&gt;

The function in your code is missing an argument retain_grads, resulting in an error at numpy-ml/numpy_ml/neural_nets/wrappers/wrappers.py Line 227.
		</comment>
		<comment id='3' author='Z-zhe' date='2020-04-09T09:16:46Z'>
		Maybe I should fork and create pull request üòÉ
		</comment>
		<comment id='4' author='Z-zhe' date='2020-04-09T12:18:33Z'>
		And numpy-ml/numpy_ml/neural_nets/tests/tests.py line 510:
your code
&lt;denchmark-code&gt;from ..activations import Softmax
&lt;/denchmark-code&gt;

but
Softmax is not implemented in ..activations, but in ..layers.
right code

line 510:

&lt;denchmark-code&gt;from ..layers import Softmax
&lt;/denchmark-code&gt;



line 527:

&lt;denchmark-code&gt;y_pred = sm.forward(z)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='Z-zhe' date='2020-04-09T12:35:22Z'>
		And numpy-ml/numpy_ml/neural_nets/tests/tests.py line 771:
your code
&lt;denchmark-code&gt;from ..activations import SoftSign
&lt;/denchmark-code&gt;

but SoftSign is not implemented in ..activations.
maybe you should delete function test_softsign_grad and test_softsign_activation.
		</comment>
		<comment id='6' author='Z-zhe' date='2020-04-09T15:11:55Z'>
		&lt;denchmark-link:https://github.com/Z-zhe&gt;@Z-zhe&lt;/denchmark-link&gt;
 - Wow, thanks so much for all these! I haven't had a chance to take a look yet, but should have some time this weekend. In the meantime if you feel like submitting a PR with fixes I'd be happy to review it, otherwise I can try to address these shortly.
		</comment>
		<comment id='7' author='Z-zhe' date='2020-04-10T09:05:15Z'>
		PR is complicated, it is easier for you to modify. üòÉ
		</comment>
		<comment id='8' author='Z-zhe' date='2020-04-17T09:30:04Z'>
		numpy-ml/numpy_ml/neural_nets/layers/layers.py line 2341:
your code
&lt;denchmark-code&gt;dX = dZ @ W.T
&lt;/denchmark-code&gt;

I don't think it should be W it should be W_sparse. So I think right code should be:
&lt;denchmark-code&gt;dX = dZ @ W_sparse.T
&lt;/denchmark-code&gt;

Please reconsiderÔºåthanks.
		</comment>
	</comments>
</bug>