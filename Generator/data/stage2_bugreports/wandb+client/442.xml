<bug id='442' author='eugeneware' open_date='2019-07-22T08:46:31Z' closed_time='2019-07-25T02:35:47Z'>
	<summary>fastai: wandb not logging fastai validation loss with default args</summary>
	<description>
wandb --version &amp;&amp; python --version &amp;&amp; uname

Weights and Biases version: 0.8.5
Python version: 3.7.3
Operating System: Linux
fast.ai version: 1.0.55

&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

When you use the fastai callback WandbCallback with the default arguments you get some errors and the validation loss is not logged.
&lt;denchmark-h:h3&gt;What I Did&lt;/denchmark-h&gt;


Run the following code in a jupyter notebook

&lt;denchmark-code&gt;import wandb
import fastai
from wandb.fastai import WandbCallback
from fastai.vision import *
from functools import partial
print(f'wandb version: {wandb.__version__}, fastai version: {fastai.__version__}')
wandb.init(project="fastai-test")
path = untar_data(URLs.MNIST_SAMPLE)
data = ImageDataBunch.from_folder(path)
learn = cnn_learner(data, models.resnet18, metrics=accuracy, callback_fns=WandbCallback)
learn.fit_one_cycle(1, 1e-2)
&lt;/denchmark-code&gt;


You'll get the following error:

&lt;denchmark-link:https://user-images.githubusercontent.com/38154/61618701-b7d63080-acb0-11e9-9eb1-9de4addaa9cd.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;/home/fastai/anaconda3/envs/wandbtest/lib/python3.7/site-packages/fastai/callbacks/tracker.py:50: UserWarning: &lt;class 'wandb.fastai.WandbCallback'&gt; conditioned on metric `val_loss` which is not available. Available metrics are: train_loss, valid_loss, accuracy
  warn(f'{self.__class__} conditioned on metric `{self.monitor}` which is not available. Available metrics are: {", ".join(map(str, self.learn.recorder.names[1:-1]))}')
&lt;/denchmark-code&gt;


To fix it you can tell it to monitor valid_loss by changing the callback to be:

learn = cnn_learner(data, models.resnet18, metrics=accuracy, callback_fns=partial(WandbCallback, monitor='valid_loss'))
I'm guessing that the name of the loss changed with fast.ai at some point.
	</description>
	<comments>
		<comment id='1' author='eugeneware' date='2019-07-22T08:46:34Z'>
		Issue-Label Bot is automatically applying the label bug to this issue, with a confidence of 0.73. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/wandb/client&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='eugeneware' date='2019-07-22T17:25:46Z'>
		We'll take a look this week
		</comment>
		<comment id='3' author='eugeneware' date='2019-07-24T04:59:38Z'>
		This is correct, the default "monitor" value was changed from "val_loss" to "valid_loss".
The callback will be updated to reflect that change.
		</comment>
		<comment id='4' author='eugeneware' date='2019-07-25T04:45:18Z'>
		Thanks &lt;denchmark-link:https://github.com/borisdayma&gt;@borisdayma&lt;/denchmark-link&gt;
 !
		</comment>
		<comment id='5' author='eugeneware' date='2019-09-03T19:31:02Z'>
		WandbCallback callback also seems not compatible with SaveModelCallback and learn.load(best_model_name). It throws the error:

Can't pickle local object 'TorchGraph.hook_torch_modules..backward_hook'

		</comment>
		<comment id='6' author='eugeneware' date='2019-09-03T22:12:28Z'>
		I've not seen this before, do you have a way for me to reproduce it?
Actually by default save_model=True in the callback, which means that it saves the model and load the best one (in wandb/RUN_ID folder) at the end of training.
		</comment>
		<comment id='7' author='eugeneware' date='2019-09-04T01:01:33Z'>
		Ah, so apparently I should have turned off SaveModelCallback and allowed it to save/load the best weights on its own. That works, thanks.
(running through a custom ECR image + sagemaker, so would take quite a while to get a minimum reproducible example)
		</comment>
	</comments>
</bug>