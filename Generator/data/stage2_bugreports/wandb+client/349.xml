<bug id='349' author='bask0' open_date='2019-05-22T17:39:51Z' closed_time='2019-06-20T23:34:20Z'>
	<summary>wandb / PyTorch: RecursionError: maximum recursion depth exceeded</summary>
	<description>

Weights and Biases version: 0.8.0
Python version: 3.6
Operating System: Ubuntu 16.04.6

&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

When I use wandb.watch(...) to monitor my PyTorch model, an error occurs. wandb.log(...) still works perfectly and wandb.watch(...) also used to work fine with other models.
I cannot paste my entire code here but below, I added the model summary. The model is highly nested as it has two layers of independent branches for multi-task learning and multiple parameter prediction per task, in case you are wondering.
&lt;denchmark-h:h3&gt;What I Did&lt;/denchmark-h&gt;


wandb.watch(self.model)
wandb.init(project='myproject', dir='/workspace/myproject/')
Start model training.
The error occurs instantly.

I also changed the recursion limit sys.setrecursionlimit(50000), but this did not resolve the issue.
I appreciate any hints!
Model summary
&lt;denchmark-code&gt;MultiTaskModel(
  (shared): LSTM(
    (lstm): LSTM(3, 32, num_layers=2)
    (linear): MultilinearLayer(
      (model): Sequential(
        (0): Linear(in_features=32, out_features=32, bias=True)
        (1): Dropout(p=0.0)
        (2): Sigmoid()
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): Dropout(p=0.0)
        (5): Sigmoid()
      )
    )
  )
  (branches): MultilayerBranches(
    (branches): ModuleDict(
      (shared_out): ModuleDict(
        (et): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=32, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
        (lwe): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=32, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
        (swe): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=32, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
      )
    )
  )
  (hetbranches): MultilayerBranches(
    (branches): ModuleDict(
      (et): ModuleDict(
        (mu): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=1, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
      )
      (lwe): ModuleDict(
        (mu): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=1, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
      )
      (swe): ModuleDict(
        (mu): MultilinearLayer(
          (model): Sequential(
            (0): Linear(in_features=32, out_features=32, bias=True)
            (1): Dropout(p=0.0)
            (2): Sigmoid()
            (3): Linear(in_features=32, out_features=1, bias=True)
            (4): Dropout(p=0.0)
            (5): Sigmoid()
          )
        )
      )
    )
  )
)
&lt;/denchmark-code&gt;

Traceback
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RecursionError                            Traceback (most recent call last)
&lt;ipython-input-18-1247abacf757&gt; in &lt;module&gt;
----&gt; 1 TS.train(30)

&lt;ipython-input-7-fbf3c6a61cfa&gt; in train(self, batch_size, max_epochs)
    322                 features, target = self.batch_to_device(batch)
    323 
--&gt; 324                 output = self.model(features)
    325                 output_red = self.bin_reduce(output, 'train')
    326 

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    489             result = self._slow_forward(*input, **kwargs)
    490         else:
--&gt; 491             result = self.forward(*input, **kwargs)
    492         for hook in self._forward_hooks.values():
    493             hook_result = hook(self, input, result)

&lt;ipython-input-5-c0a77e4126cb&gt; in forward(self, x)
    545         """
    546         out = self.shared(x)
--&gt; 547         out = self.branches(out)
    548         out = self.hetbranches(out)
    549 

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self.forward(*input, **kwargs)
    492         for hook in self._forward_hooks.values():
--&gt; 493             hook_result = hook(self, input, result)
    494             if hook_result is not None:
    495                 raise RuntimeError(

/opt/conda/lib/python3.6/site-packages/wandb/wandb_torch.py in after_forward_hook(module, input, output)
    241                 name=name,
    242                 class_name=str(module),
--&gt; 243                 output_shape=nested_shape(output),
    244                 parameters=parameters,
    245                 num_parameters=[reduce(mul, size)

/opt/conda/lib/python3.6/site-packages/wandb/wandb_torch.py in nested_shape(array_or_tuple)
     37     try:
     38         # treat object as iterable
---&gt; 39         return [nested_shape(item) for item in list(array_or_tuple)]
     40     except TypeError:
     41         # object is not actually iterable

/opt/conda/lib/python3.6/site-packages/wandb/wandb_torch.py in &lt;listcomp&gt;(.0)
     37     try:
     38         # treat object as iterable
---&gt; 39         return [nested_shape(item) for item in list(array_or_tuple)]
     40     except TypeError:
     41         # object is not actually iterable

... last 2 frames repeated, from the frame below ...

/opt/conda/lib/python3.6/site-packages/wandb/wandb_torch.py in nested_shape(array_or_tuple)
     37     try:
     38         # treat object as iterable
---&gt; 39         return [nested_shape(item) for item in list(array_or_tuple)]
     40     except TypeError:
     41         # object is not actually iterable

RecursionError: maximum recursion depth exceeded while calling a Python object
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='bask0' date='2019-05-22T18:59:19Z'>
		Issue-Label Bot is automatically applying the label bug to this issue, with a confidence of 0.65. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/wandb/client&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='bask0' date='2019-05-22T19:01:53Z'>
		Two questions:

Which version of pytorch are you using?
Could you paste the code that generates the model?  I'd like to try to replicate the issue.

		</comment>
		<comment id='3' author='bask0' date='2019-05-22T23:40:20Z'>
		Hey &lt;denchmark-link:https://github.com/bask0&gt;@bask0&lt;/denchmark-link&gt;
 we just pushed what we believe is a fix.  You can try it by running  .  Let us know if you're still seeing the issue, we can push a new official release this week.
		</comment>
		<comment id='4' author='bask0' date='2019-05-23T08:00:35Z'>
		
Two questions:
Which version of pytorch are you using?
Could you paste the code that generates the model? I'd like to try to replicate the issue.

Thanks &lt;denchmark-link:https://github.com/lukas&gt;@lukas&lt;/denchmark-link&gt;
, I use pytorch version 1.1.0. My model pipeline is rather complex, I would prefer solving the issue without pasting my code here. If the bug cannot be fixed without, I try to figure out a MWE.

Hey @bask0 we just pushed what we believe is a fix. You can try it by running pip install --upgrade git+git://github.com/wandb/client.git@fix/pytorch_graph_recursion#egg=wandb . Let us know if you're still seeing the issue, we can push a new official release this week.

Hey &lt;denchmark-link:https://github.com/vanpelt&gt;@vanpelt&lt;/denchmark-link&gt;
, I installed wandb as you said, now I get a different error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-15-72011ae6b94f&gt; in &lt;module&gt;
----&gt; 1 TS.train(40)

&lt;ipython-input-10-58f135e52aa3&gt; in train(self, batch_size, max_epochs)
    319                 features, target = self.batch_to_device(batch)
    320 
--&gt; 321                 output = self.model(features)
    322                 output_red = self.bin_reduce(output, 'train')
    323 

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    489             result = self._slow_forward(*input, **kwargs)
    490         else:
--&gt; 491             result = self.forward(*input, **kwargs)
    492         for hook in self._forward_hooks.values():
    493             hook_result = hook(self, input, result)

&lt;ipython-input-8-c0a77e4126cb&gt; in forward(self, x)
    545         """
    546         out = self.shared(x)
--&gt; 547         out = self.branches(out)
    548         out = self.hetbranches(out)
    549 

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self.forward(*input, **kwargs)
    492         for hook in self._forward_hooks.values():
--&gt; 493             hook_result = hook(self, input, result)
    494             if hook_result is not None:
    495                 raise RuntimeError(

/opt/conda/lib/python3.6/site-packages/wandb/wandb_torch.py in after_forward_hook(module, input, output)
    254             graph.add_node(node)
    255             if not graph.criterion_passed:
--&gt; 256                 graph.criterion = output[0].grad_fn
    257         return after_forward_hook
    258 

AttributeError: 'dict' object has no attribute 'grad_fn'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='bask0' date='2019-05-23T19:49:16Z'>
		&lt;denchmark-link:https://github.com/bask0&gt;@bask0&lt;/denchmark-link&gt;
: We were able to reproduce the failure you saw with a similar structured model.
To verify the fix please pull a build from the same branch:
&lt;denchmark-code&gt;pip install --upgrade git+git://github.com/wandb/client.git@fix/pytorch_graph_recursion#egg=wandb
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='bask0' date='2019-05-23T20:45:35Z'>
		
@bask0: We were able to reproduce the failure you saw with a similar structured model.
To verify the fix please pull a build from the same branch:
pip install --upgrade git+git://github.com/wandb/client.git@fix/pytorch_graph_recursion#egg=wandb


&lt;denchmark-link:https://github.com/raubitsj&gt;@raubitsj&lt;/denchmark-link&gt;
 - I get a new error now:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
StopIteration                             Traceback (most recent call last)
&lt;ipython-input-13-72011ae6b94f&gt; in &lt;module&gt;
----&gt; 1 TS.train(40)

&lt;ipython-input-7-35efb0e213c4&gt; in train(self, batch_size, max_epochs)
    357                 features, target = self.batch_to_device(batch)
    358 
--&gt; 359                 output = self.model(features)
    360                 output_red = self.bin_reduce(output, 'train')
    361 

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    489             result = self._slow_forward(*input, **kwargs)
    490         else:
--&gt; 491             result = self.forward(*input, **kwargs)
    492         for hook in self._forward_hooks.values():
    493             hook_result = hook(self, input, result)

&lt;ipython-input-5-673f49459fe7&gt; in forward(self, x)
    564         out = self.shared(x)
    565         out = self.branches(out)
--&gt; 566         out = self.hetbranches(out)
    567 
    568         return out

/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    500             while not isinstance(var, torch.Tensor):
    501                 if isinstance(var, dict):
--&gt; 502                     var = next((v for v in var.values() if isinstance(v, torch.Tensor)))
    503                 else:
    504                     var = var[0]

StopIteration: 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='bask0' date='2019-05-24T18:41:23Z'>
		&lt;denchmark-link:https://github.com/bask0&gt;@bask0&lt;/denchmark-link&gt;
, Thanks for trying the experimental branch.
We have pushed a new release (0.8.1) which has the fixes for the first two errors you experienced.
The third issue will be harder to isolate without the model.  I have a couple of ideas I am still exploring to attempt to create a test case which might be more similar to your model.  I will keep you updated on the progress.
		</comment>
		<comment id='8' author='bask0' date='2019-05-25T10:08:42Z'>
		&lt;denchmark-link:https://github.com/raubitsj&gt;@raubitsj&lt;/denchmark-link&gt;
 - Thank you very much for investigating this issue. To be clear: The error only occurs if I use wandb.watch(...).
		</comment>
		<comment id='9' author='bask0' date='2019-06-20T23:34:20Z'>
		This is fixed in 0.8.2
		</comment>
	</comments>
</bug>