<bug id='1085' author='parmarsuraj99' open_date='2020-06-05T09:36:59Z' closed_time='2020-06-05T19:21:35Z'>
	<summary>Error in continuing training with HuggingFace Trainer on TPU</summary>
	<description>
wandb --version &amp;&amp; python --version &amp;&amp; uname

Weights and Biases version: 0.8.36
Python version: 3.6.9
Operating System: Linux

&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

While training Model using HuggingFace Trainer on Colab with TPU, Once an epoch is complete and  a run finishes successfully. When started training again from checkpoints it gives this error.
&lt;denchmark-h:h3&gt;What I Did&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;
Exception in device=TPU:0: cannot create weak reference to 'dict' object
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py", line 231, in _start_fn
    fn(gindex, *args)
  File "/content/transformers/examples/language-modeling/run_language_modeling.py", line 278, in _mp_fn
    main()
  File "/content/transformers/examples/language-modeling/run_language_modeling.py", line 236, in main
    prediction_loss_only=True,
  File "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py", line 211, in __init__
    self._setup_wandb()
  File "/usr/local/lib/python3.6/dist-packages/transformers/trainer.py", line 344, in _setup_wandb
    self.model, log=os.getenv("WANDB_WATCH", "gradients"), log_freq=max(100, self.args.logging_steps)
  File "/usr/local/lib/python3.6/dist-packages/wandb/__init__.py", line 166, in watch
    model, criterion, graph_idx=global_idx)
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_torch.py", line 291, in hook_torch
    graph.hook_torch_modules(model, criterion, graph_idx=graph_idx)
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_torch.py", line 394, in hook_torch_modules
    sub_module.register_forward_hook(self.create_forward_hook(name, modules)))
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 543, in register_forward_hook
    handle = hooks.RemovableHandle(self._forward_hooks)
  File "/usr/local/lib/python3.6/dist-packages/torch/utils/hooks.py", line 13, in __init__
    self.hooks_dict_ref = weakref.ref(hooks_dict)
TypeError: cannot create weak reference to 'dict' object 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='parmarsuraj99' date='2020-06-05T09:37:02Z'>
		Issue-Label Bot is automatically applying the label bug to this issue, with a confidence of 0.98. Please mark this comment with üëç or üëé to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/wandb/client&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='parmarsuraj99' date='2020-06-05T17:38:36Z'>
		Good to know.  A quick fix is to set os.environ["WANDB_WATCH"] = "false" we'll look into the root cause.
		</comment>
		<comment id='3' author='parmarsuraj99' date='2020-06-05T17:57:52Z'>
		&lt;denchmark-link:https://github.com/parmarsuraj99&gt;@parmarsuraj99&lt;/denchmark-link&gt;
 do you have a colab to share to ensure we propose a good fix?
		</comment>
		<comment id='4' author='parmarsuraj99' date='2020-06-05T19:21:18Z'>
		os.environ["WANDB_WATCH"] = "false"  this worked.
I think it's a problem with pytorch-xla or Transformers with TPU. Logging while training seems to freeze everything.
		</comment>
	</comments>
</bug>