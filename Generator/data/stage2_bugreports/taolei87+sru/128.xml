<bug id='128' author='bratao' open_date='2020-09-16T19:30:16Z' closed_time='2020-09-19T23:02:15Z'>
	<summary>Error unpacking PackedSequence on latest version</summary>
	<description>
Hello &lt;denchmark-link:https://github.com/taolei87&gt;@taolei87&lt;/denchmark-link&gt;
 ,
After updating to the latest version, my code broke. It works great on the previous 2.3.5 version and with nn.LSTM.
&lt;denchmark-code&gt;File "C:\xxx\lib\site-packages\torch\nn\modules\module.py", line 722, in _call_impl
  result = self.forward(*input, **kwargs)
File "C:\xxx\lib\site-packages\sru\modules.py", line 576, in forward
  mask_pad = (mask_pad &gt;= batch_sizes.view(length, 1)).contiguous()
RuntimeError: shape '[393, 1]' is invalid for input of size 384
&lt;/denchmark-code&gt;

I can see that in the previous version the unpacking code on forward was different:
&lt;denchmark-code&gt;        input_packed = isinstance(input, nn.utils.rnn.PackedSequence)
        if input_packed:
            input, lengths = nn.utils.rnn.pad_packed_sequence(input)
            max_length = lengths.max().item()
            mask_pad = torch.ByteTensor([[0] * l + [1] * (max_length - l) for l in lengths.tolist()])
            mask_pad = mask_pad.to(input.device).transpose(0, 1).contiguous()
&lt;/denchmark-code&gt;

Now is:
&lt;denchmark-code&gt;
        orig_input = input
        if isinstance(orig_input, PackedSequence):
            input, batch_sizes, sorted_indices, unsorted_indices = input
            length = input.size(0)
            batch_size = input.size(1)
            mask_pad = torch.arange(batch_size,
                                    device=batch_sizes.device).expand(length, batch_size)
            mask_pad = (mask_pad &gt;= batch_sizes.view(length, 1)).contiguous()
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='bratao' date='2020-09-16T19:57:10Z'>
		hi &lt;denchmark-link:https://github.com/bratao&gt;@bratao&lt;/denchmark-link&gt;
 i can take a look into this.
Would you mind sharing the pytorch version and a toy example of inputs to SRU for me to reproduce the error?
		</comment>
		<comment id='2' author='bratao' date='2020-09-16T20:41:17Z'>
		Thank you &lt;denchmark-link:https://github.com/taolei87&gt;@taolei87&lt;/denchmark-link&gt;

I´m doing a regular training using AllenNLP, but using SRU in place of a LSTM.
I attached an example. Sorry for the laziness, but I torch.saved the mask and input.
I´m in Windows 10 x64, Python 3.8 and Pytorch 1.6
&lt;denchmark-link:https://github.com/asappresearch/sru/files/5234815/test_sru.zip&gt;test_sru.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='bratao' date='2020-09-18T14:33:55Z'>
		&lt;denchmark-link:https://github.com/taolei87&gt;@taolei87&lt;/denchmark-link&gt;
 that example I sent in the last post is enough to you? If you prefer I can try to do without using serialized tensors.
		</comment>
		<comment id='4' author='bratao' date='2020-09-18T18:43:57Z'>
		&lt;denchmark-link:https://github.com/bratao&gt;@bratao&lt;/denchmark-link&gt;
 I revert this piece of code back to that of vesrion &lt; 2.3.5.
&lt;denchmark-link:https://github.com/asappresearch/sru/pull/130&gt;#130&lt;/denchmark-link&gt;

can you check if this PR works now?
		</comment>
		<comment id='5' author='bratao' date='2020-09-18T21:28:45Z'>
		&lt;denchmark-link:https://github.com/taolei87&gt;@taolei87&lt;/denchmark-link&gt;
 yes, I can confirm. Everything is working great!! Thanks
		</comment>
		<comment id='6' author='bratao' date='2020-09-21T02:28:57Z'>
		&lt;denchmark-link:https://github.com/taolei87&gt;@taolei87&lt;/denchmark-link&gt;
 please remember to release 2.4.2 in pypi! 
		</comment>
		<comment id='7' author='bratao' date='2020-09-21T23:34:51Z'>
		Same here
		</comment>
		<comment id='8' author='bratao' date='2020-09-22T01:11:05Z'>
		Just made a new release.
		</comment>
	</comments>
</bug>