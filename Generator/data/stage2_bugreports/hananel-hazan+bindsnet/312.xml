<bug id='312' author='dee0512' open_date='2019-09-18T15:06:27Z' closed_time='2020-10-25T15:51:21Z'>
	<summary>Reorganize Examples</summary>
	<description>
Examples to be removed:

 space_invaders/et_space_invaders.py
 space_invaders/minimal_space_invaders.py
 space_invaders/random_baseline.py
 asteroids/random_network_baseline.py
 datasets/davis.py
 datasets/spoken_mnist.py
 mnist/batch_conv_mnist.py
 mnist/minimal_mnist.py
 mnist/minimal_resevoir.py
 mnist/minimal_supervised_mnist.py
 cifar10/*
 notebooks/LIFNodes\ vs.\ CurrentLIFNodes.ipynb

Examples to be added:

 breakout/random_baseline.py
 breakout/random_network_baseline.py

Examples to be moved:

 datasets/conv.py -&gt; tensorboard/tensorboard.py
 benchmark -&gt; separate repo

	</description>
	<comments>
		<comment id='1' author='dee0512' date='2019-09-18T15:09:31Z'>
		&lt;denchmark-link:https://github.com/djsaunde&gt;@djsaunde&lt;/denchmark-link&gt;
 can we move notebooks to bindsnet examples? We are planning to keep only examples that are required to help you understand Bindsnet. This would also reduce our workload when updating BindsNET.
		</comment>
		<comment id='2' author='dee0512' date='2019-09-18T15:12:04Z'>
		Yes, I think that's for the best. We've been talking for a while about removing a bunch of examples, since they're out of date / not super informative.
		</comment>
		<comment id='3' author='dee0512' date='2019-09-18T15:17:17Z'>
		I think we should move BindsNET to an organization repo and move the benchmark stuff to a separate repo under this organization.
		</comment>
		<comment id='4' author='dee0512' date='2019-09-18T15:42:12Z'>
		Yup, I'm in the process of convincing Robert to let us move BindsNET to a BINDS GitHub organization
		</comment>
		<comment id='5' author='dee0512' date='2019-09-18T18:38:08Z'>
		This is not relevant to this thread nor to public forum.
There is a plan to move to an organization, that plan involve lots of moving parts. Currently, BindsNET is in the right place to take advantage of that plan.
		</comment>
		<comment id='6' author='dee0512' date='2019-09-18T21:05:28Z'>
		So what do we do with the benchmarking examples? They require brian, ANNarchy, etc. which are not part of Bindsnet and are not relevant to normal users.
		</comment>
		<comment id='7' author='dee0512' date='2019-09-18T21:12:35Z'>
		Also, can everyone react to this comment to confirm all the examples to be removed? We tried to remove redundant and non-useful examples. Objections are welcome.
&lt;denchmark-link:https://github.com/Hananel-Hazan&gt;@Hananel-Hazan&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/djsaunde&gt;@djsaunde&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/sharath&gt;@sharath&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/coopersigrist&gt;@coopersigrist&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='dee0512' date='2019-09-18T21:20:52Z'>
		The ideal situation is that on every big feature that we have, there is example that show how it works. But we cannot maintain so many examples.
So,  I think:

benchmark can be in docs and not in examples.  This script is needed to reproduce the figure in the BindsNET paper
All the examples in the BindsNET paper need to stay.
Minimal and not minimal need to be combine to one example (if any)
Unless it necessary, one example from the ATARI can explain how to use the framework to all other ATARI game. No need for multiple ATARI examples.

I also think that there is need to show some aspects of BindsNET.

Core examples for BindsNET - different architecture, different neurons, maybe different learning rules
Data-set examples - show how to connect and fetch data
RL examples - how to work with feedback

Open to suggestions
		</comment>
		<comment id='9' author='dee0512' date='2019-09-19T14:05:24Z'>
		I agree with Hananel on most of the points. But:
The examples in the Bindsnet paper might not be relevant anymore. For eg. Pipeline.
People can learn how to use datasets from the Docs. Same goes for neurons, architectures and learning rules. One Atari example should be enough to show how to work with rewards in RL.
So, I would suggest that instead of writing and maintaining an example for every major update, we update the documentation.
		</comment>
		<comment id='10' author='dee0512' date='2019-09-19T16:21:35Z'>
		Yes, you right, pipeline and datasets can be in the documents. But, although the examples from the paper are less relevant today, they are the first that going to be use by people that been introduce to the framework by reading the paper (quite a lots of people if you look on frontier page counter).
Still some example need to be maintain, not all people read the doc first, some clone and run the examples first before diving to the documents to see what else the framework can do.
Therefore we need to choose top highly relevant examples for the novel user.
What would be the relevant examples?
RL, RNN (reservoir), CNN, SOM, batch learning?
Anything else, anything less?
		</comment>
		<comment id='11' author='dee0512' date='2019-09-24T16:22:47Z'>
		mnist/reservoir is functional (I update &lt;denchmark-link:https://github.com/sharath&gt;@sharath&lt;/denchmark-link&gt;
 project)
cifar10/cifar10_reservoir.py is next
		</comment>
		<comment id='12' author='dee0512' date='2019-09-25T15:24:03Z'>
		We planned on removing cifar10 examples.
		</comment>
		<comment id='13' author='dee0512' date='2020-02-03T13:34:24Z'>
		maybe a related issue &lt;denchmark-link:https://github.com/BindsNET/bindsnet/issues/350&gt;#350&lt;/denchmark-link&gt;
 ?
		</comment>
	</comments>
</bug>