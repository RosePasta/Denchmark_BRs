<bug id='690' author='dxjjhm' open_date='2021-01-18T07:38:19Z' closed_time='2021-01-18T11:18:40Z'>
	<summary>[🐛BUG] case_study.py 中， 输入的用户id只有一个时， full_sort_topk 报错</summary>
	<description>
代码
import torch
import pandas as pd

from recbole.model.general_recommender.bpr import BPR
from recbole.config import Config
from recbole.data import create_dataset, data_preparation
from recbole.utils.case_study import full_sort_topk

param_dict = {
    'use_gpu': False
}

# 加载 BPR 模型
bpr_model_path = "D:\\source\\recbole-0.2.0\\app\\ex\\saved\\BPR-Jan-18-2021_14-03-52.pth"
bpr_config = Config(model='BPR',
                    dataset='ml-100k',
                    config_dict=param_dict)
dataset = create_dataset(bpr_config)
train_data, valid_data, test_data = data_preparation(bpr_config, dataset)

bpr_model = BPR(bpr_config, train_data)
checkpoint = torch.load(bpr_model_path)
bpr_model.load_state_dict(checkpoint['state_dict'])
bpr_model.eval()

uid_series = dataset.token2id(dataset.uid_field, ['200'])  # 原始数据集中的用户id，变换为训练内部使用的索引id

full_sort_topk(uid_series, bpr_model, test_data, 10)
报错信息
Traceback (most recent call last):
File "D:/source/recbole-0.2.0/app/ex/bpr_predict_ml100k.py", line 33, in 
full_sort_topk(uid_series, bpr_model, test_data, 10)
File "D:\source\recbole-0.2.0\recbole\utils\case_study.py", line 87, in full_sort_topk
scores = full_sort_scores(uid_series, model, test_data)
File "D:\Anaconda3\envs\pytorch\lib\site-packages\torch\autograd\grad_mode.py", line 26, in decorate_context
return func(*args, **kwargs)
File "D:\source\recbole-0.2.0\recbole\utils\case_study.py", line 45, in full_sort_scores
history_row = torch.cat([torch.full_like(hist_iid, i) for i, hist_iid in enumerate(history_item)])
RuntimeError: zero-dimensional tensor (at position 0) cannot be concatenated
	</description>
	<comments>
		<comment id='1' author='dxjjhm' date='2021-01-18T08:07:48Z'>
		感谢，我们在 &lt;denchmark-link:https://github.com/RUCAIBox/RecBole/pull/692&gt;#692&lt;/denchmark-link&gt;
 解决了这个问题。
这个问题主要是由于  使用长度为1的  下标引发的，你可以改一下源代码来解决它。
		</comment>
	</comments>
</bug>