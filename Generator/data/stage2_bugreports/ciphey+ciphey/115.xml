<bug id='115' author='bee-san' open_date='2020-06-10T23:36:04Z' closed_time='2020-06-29T18:04:34Z'>
	<summary>PyPi version is incredibly slow</summary>
	<description>
&lt;denchmark-code&gt;➜ ciphey -t "NBSWY3DPEBUSAYLNEBQSA2DVNVQW4IDBNZSCA2JANRUWWZJAMNQXI==="
┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Name of Cipher ┃ Probability ┃
┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ Caesar         │      58.03% │
│ Plaintext      │      39.72% │
│ Base           │       2.25% │
└────────────────┴─────────────┘
hello i am a human and i like cat

~/Documents via 𝗥 v1.43.1 via test8 took 10s
➜ c

Ciphey on  master [⇣!] via ciphey via 🐍 system
➜ python3 ciphey -t "NBSWY3DPEBUSAYLNEBQSA2DVNVQW4IDBNZSCA2JANRUWWZJAMNQXI==="
┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓
┃ Name of Cipher ┃ Probability ┃
┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩
│ Caesar         │      58.03% │
│ Plaintext      │      39.72% │
│ Base           │       2.25% │
└────────────────┴─────────────┘
hello i am a human and i like cat
&lt;/denchmark-code&gt;

PyPi vs local
	</description>
	<comments>
		<comment id='1' author='bee-san' date='2020-06-11T00:23:25Z'>
		&lt;denchmark-link:https://i.imgur.com/Koo9Rti.gifv&gt;https://i.imgur.com/Koo9Rti.gifv&lt;/denchmark-link&gt;

from &lt;denchmark-link:https://github.com/michalani&gt;@michalani&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='bee-san' date='2020-06-11T10:26:48Z'>
		For my example in the original issue, it look 10 seconds to decode that base string, whereas locally it took &lt; 3 seconds.
		</comment>
		<comment id='3' author='bee-san' date='2020-06-11T10:29:40Z'>
		Here's a better show case using the time module:
&lt;denchmark-code&gt;hello i am a human and i like cat
ciphey -t "NBSWY3DPEBUSAYLNEBQSA2DVNVQW4IDBNZSCA2JANRUWWZJAMNQXI==="  8.64s user 1.43s system 91% cpu 11.000 total
&lt;/denchmark-code&gt;

^^ PyPi version
&lt;denchmark-code&gt;python3 ciphey -t "NBSWY3DPEBUSAYLNEBQSA2DVNVQW4IDBNZSCA2JANRUWWZJAMNQXI==="  1.80s user 0.54s system 75% cpu 3.099 total
&lt;/denchmark-code&gt;

11 seconds for PyPi, vs 3.099 seconds for git clone.
It can't be tensorflow because the prob table prints so physically fast, if you try to re-create it you'll notice the prob table prints after 1 - 2 seconds, while the program still takes 9 - 10 seconds to run.
		</comment>
		<comment id='4' author='bee-san' date='2020-06-11T10:44:17Z'>
		Possibly, this may be caused by Pip installed apps having a limit on the number of threads? maybe? It's the only thing I can think of
		</comment>
		<comment id='5' author='bee-san' date='2020-06-11T12:20:54Z'>
		I have an AMD threadripper, so you would think that multithreading would give me more benefit that most. However, I actually see performance degradation when I use the threads. I do not believe it is that.
It could be something to do with the manylinux2014 image I am forced to build on. I would like to statically compile it with the latest libs, but unfortunately it complains when I do that (if anyone knows how to get around that, please file it!)
I cannot repro this slowness everyone is talking about, so can people check they have the latest version 4.2.0? I'm going to add a python3 -m pip show ciphey cipheycore cipheydists' to the template!
		</comment>
		<comment id='6' author='bee-san' date='2020-06-11T13:12:33Z'>
		On checking your output, you are definitely using an old version. This is most likely due to the borked versioning in &lt;denchmark-link:https://github.com/Ciphey/Ciphey/issues/117&gt;#117&lt;/denchmark-link&gt;
. I'm going to mark this as "invalid" until it is shown in ciphey 4.2.0 using the latest cipheycore
		</comment>
	</comments>
</bug>