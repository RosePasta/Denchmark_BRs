<bug id='143' author='bee-san' open_date='2020-07-03T13:05:16Z' closed_time='2020-07-11T15:07:29Z'>
	<summary>Strings that can be decoded / cracked in 2 crackers / decoders</summary>
	<description>
&lt;denchmark-code&gt;ciphey -t "IkknbSBnb2luZyB0byBtdXJkZXIgdW5jbGUgYm9iIGF0IDZwbSB0b21vcnJvdw=="â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Name of Cipher â”ƒ Probability â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Base           â”‚      99.99% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
&lt;/denchmark-code&gt;

This is a base 64 string, but it returns as SHA256.
&lt;denchmark-code&gt;Returning {'lc': None, 'IsPlaintext?': True, 'Plaintext': 'CODE ERREUR : 005', 'Cipher': 'sha256', 'Extra Information': None}
&lt;/denchmark-code&gt;

This is because:

The string is the exact right size for SHA256
It just so happens, on one of our hash APIs, that the string has been calculated to be that.

	</description>
	<comments>
		<comment id='1' author='bee-san' date='2020-07-03T13:05:18Z'>
		Issue-Label Bot is automatically applying the label bug to this issue, with a confidence of 0.89. Please mark this comment with ğŸ‘ or ğŸ‘ to give our bot feedback!
Links: &lt;denchmark-link:https://github.com/marketplace/issue-label-bot&gt;app homepage&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://mlbot.net/data/Ciphey/Ciphey&gt;dashboard&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/hamelsmu/MLapp&gt;code&lt;/denchmark-link&gt;
 for this bot.
		</comment>
		<comment id='2' author='bee-san' date='2020-07-04T07:50:48Z'>
		This is a difficult situation.
Luckily, there are some things we can do with the (almost finished) cipher-iface branch!
Since a hash is binary data, AuSearch will decode the base64, and first check for further decodings. The chance of a SHA256 hash successfully decoding as UTF-8 is roughly 1 in 2^32 (4 billion). Even if someone really is that unlucky, that just means that we will waste time with that string, before cracking the hash.
Conversely, if it really is a UTF-8 string, any reasonably accurate AuSearch heuristic will leave the intensive sha256 cracking until later in the search.
One suggestion would be to add a tag system for the crackers, so that a user could disable/single out hash cracking, without having to rewrite large portions of the code base.
I would be interested to see people's feedback after Orwell is released, so that we can see whether this is worth implementing.
		</comment>
		<comment id='3' author='bee-san' date='2020-07-04T21:28:44Z'>
		SHA256 is not cracked, it is searched up in an API - thus it is much faster than everything apart from the decoders. ğŸ˜
I'm hoping this fixes it:

Since a hash is binary data, AuSearch will decode the base64, and first check for further decodings. The chance of a SHA256 hash successfully decoding as UTF-8 is roughly 1 in 2^32 (4 billion). Even if someone really is that unlucky, that just means that we will waste time with that string, before cracking the hash.

		</comment>
		<comment id='4' author='bee-san' date='2020-07-11T15:07:29Z'>
		Ausearch is now reasonably accurate, so this should not be a problem anymore
		</comment>
	</comments>
</bug>