<bug id='460' author='andraugust' open_date='2020-02-24T23:29:08Z' closed_time='2020-04-18T08:17:54Z'>
	<summary>[BUG] Inconsistent batch size output</summary>
	<description>
Thanks for the great package.  The output of kornia.augmentation.RandomRotation has an inconsistent batch size when the input batch size is 1:
import torch
from kornia.augmentation import RandomRotation  # version 0.2.0

rotation = RandomRotation((-90.,90.))

x = torch.rand(1,3,10,10)
print(rotation(x).shape)   # torch.Size([3, 10, 10])  // expecting torch.Size([1, 3, 10, 10])

x = torch.rand(2,3,10,10)
print(rotation(x).shape)   # torch.Size([2, 3, 10, 10]) // fine

x = torch.rand(6,3,10,10)
print(rotation(x).shape)   # torch.Size([6, 3, 10, 10]) // fine
Is this desired behavior?
	</description>
	<comments>
		<comment id='1' author='andraugust' date='2020-02-25T08:49:56Z'>
		The same behavior occurs not only with RandomRotation, but also with RandomHorizontalFlip, but not with RandomVerticalFlip.
Given this, this behavior seems to be inconsistent.
In the case of RandomRotation, the shape of the tensor changes around here:



kornia/kornia/augmentation/functional.py


        Lines 487 to 488
      in
      cb9373b






 input = input.unsqueeze(0) 



 input = input.view((-1, (*input.shape[-3:]))) 





If this is unexpected behavior, we need to change the implementation.
		</comment>
		<comment id='2' author='andraugust' date='2020-03-11T00:09:25Z'>
		&lt;denchmark-link:https://github.com/skmatz&gt;@skmatz&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/andraugust&gt;@andraugust&lt;/denchmark-link&gt;
 thanks for reporting. Could you try to send a PR fixing ?
		</comment>
		<comment id='3' author='andraugust' date='2020-03-14T05:40:29Z'>
		&lt;denchmark-link:https://github.com/edgarriba&gt;@edgarriba&lt;/denchmark-link&gt;

Yup, but first let's discuss (tell me) input/output shape.



#
input shape
output shape




1
(1, 3, 10, 10)
(1, 3, 10, 10) or (3, 10, 10)


2
(2, 3, 10, 10)
(2, 3, 10, 10)


3
(1, 1, 10, 10)
(1, 1, 10, 10) or (1, 10, 10) or (10, 10)


4
(2, 1, 10, 10)
(2, 1, 10, 10) or (2, 10, 10)


5
(1, 10, 10)
(1, 1, 10, 10) or (1, 10, 10) or (10, 10)


6
(3, 10, 10)
(1, 3, 10, 10) or (3, 10, 10)



I would also like to discuss the shape of acceptable input.
Whether to allow grayscale images (#_3, #_4) and non-batch images (#_5, #_6).
I don't think it is necessary to allow input non-batch images (#_5, #_6).
By allowing only (B, C, H, W) input shape, the output shape can be uniquely unified to (B, C, H, W).
What do you think?
		</comment>
		<comment id='4' author='andraugust' date='2020-03-14T06:44:16Z'>
		
By allowing only (B, C, H, W) input shape, the output shape can be uniquely unified to (B, C, H, W).

I agree. I think input and output shape should always be (B, C, H, W), even when B=1 and/or C=1.
		</comment>
		<comment id='5' author='andraugust' date='2020-03-15T14:21:52Z'>
		I think that keeping (B, C, H, W) even for B=1 and/or C=1 is good convention to enforce.
		</comment>
		<comment id='6' author='andraugust' date='2020-03-15T14:24:23Z'>
		&lt;denchmark-link:https://github.com/skmatz&gt;@skmatz&lt;/denchmark-link&gt;
 if you can proceed with some test and fixes for shape it's fine
		</comment>
		<comment id='7' author='andraugust' date='2020-04-12T12:07:51Z'>
		It should be all fixed in &lt;denchmark-link:https://github.com/kornia/kornia/pull/514&gt;#514&lt;/denchmark-link&gt;
, all the input will be transformed into BCHW and output BCHW only:
def _transform_input(input: torch.Tensor) -&gt; torch.Tensor:
    r"""Reshape an input tensor to be (*, C, H, W). Accept either (H, W), (C, H, W) or (*, C, H, W).
    Args:
        input: torch.Tensor

    Returns:
        torch.Tensor
    """
    if not torch.is_tensor(input):
        raise TypeError(f"Input type is not a torch.Tensor. Got {type(input)}")

    if len(input.shape) not in [2, 3, 4]:
        raise ValueError(
            f"Input size must have a shape of either (H, W), (C, H, W) or (*, C, H, W). Got {input.shape}")

    if len(input.shape) == 2:
        input = input.unsqueeze(0)

    if len(input.shape) == 3:
        input = input.unsqueeze(0)

    return input
		</comment>
	</comments>
</bug>