<bug id='45' author='loiccordone' open_date='2019-04-17T12:15:15Z' closed_time='2019-04-26T17:24:44Z'>
	<summary>Can't set num_steps to None in Trainer component</summary>
	<description>
Hello,
In my Airflow pipeline, I can't set num_steps in TrainArgs to None. According to the doc of TrainSpec, max_steps can be set to None (useful for training exactly one epoch)

max_steps: Int. Positive number of total steps for which to train model. If None, train forever.

trainer = Trainer(module_file=_module_file,  transformed_examples=transform.outputs.transformed_examples, schema=infer_schema.outputs.output, transform_output=transform.outputs.transform_output, train_args=trainer_pb2.TrainArgs(num_steps=None), eval_args=trainer_pb2.EvalArgs(num_steps=None))
At execution I get "'ERROR - Must specify max_steps &gt; 0, given: 0".
In my utils.py, the trainer_fn takes hparams in parameter, sent by TrainArgs and EvalArgs above, but inside trainer_fn hparams.train_steps is set to 0, not None.
The problem seems to come from tfx/proto/trainer_pb2.py :
_TRAINARGS = _descriptor.Descriptor( name='TrainArgs', ... has_default_value=False, default_value=0, ...
However, changing the default_value to None didn't seem to help my case. I hard-codded None in my trainer_fn for the moment. Can you allow us to pass None ?
I'm using TFX 0.12 and TF 1.12.0
Thanks
	</description>
	<comments>
		<comment id='1' author='loiccordone' date='2019-04-17T19:00:56Z'>
		That's a bug.  I'll work on a fix (second in my queue).
		</comment>
		<comment id='2' author='loiccordone' date='2019-04-18T20:15:49Z'>
		Hi Loic -- what are you using as the stop condition for your estimator?  I'm curious how a "runs forever" Trainer configuration behaves in airflow/kubeflow.  If you're raising an error after n passes through the data, the error should abort the remainder of the pipeline execution as well.
		</comment>
		<comment id='3' author='loiccordone' date='2019-04-18T20:36:04Z'>
		Well I'm not raising an error, I'm simply defining the num_epoch in my inputs with the Estimator API (I can add precisions tomorrow), and the training stops exactly after num_epoch epochs.
		</comment>
		<comment id='4' author='loiccordone' date='2019-04-19T01:49:35Z'>
		To confirm, your TrainSpec looks something like
&lt;denchmark-code&gt;  train_spec = tf.estimator.TrainSpec( 
      train_input_fn,
      # max_steps=hparams.train_steps,
      max_steps=None,
      num_epochs=1)
&lt;/denchmark-code&gt;

?
		</comment>
		<comment id='5' author='loiccordone' date='2019-04-19T05:54:02Z'>
		The configuration is done in the input_fn, not in the TrainSpec:
train_input_fn = lambda: utils.input_fn(hparams.train_files, hparams.transform_output, batch_size=train_batch_size, num_epochs=1)
And this call to read_batch_features in my utils.input_fn:
tf.contrib.learn.io.read_batch_features(filenames, batch_size, transformed_feature_spec, reader=_gzip_reader_fn, num_epochs=num_epochs)
A deprecated function, but it is used in the Taxi example.
		</comment>
	</comments>
</bug>