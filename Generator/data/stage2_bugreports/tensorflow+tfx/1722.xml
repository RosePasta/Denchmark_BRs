<bug id='1722' author='luischinchillagarcia' open_date='2020-05-01T22:11:44Z' closed_time='2020-05-08T23:52:50Z'>
	<summary>Error Using Accumulators in TFT with Pipeline</summary>
	<description>
When using a combiner function like , it successfully runs using TFT_beam (&lt;denchmark-link:https://colab.research.google.com/drive/17LPB6b1D6ojnJbzs-t_M2qzhuZfin7Wx&gt;shown in this Colab&lt;/denchmark-link&gt;
) or TFX Interactive Context (&lt;denchmark-link:https://colab.research.google.com/drive/1g-GPCcxPmBqbQyOTZHcL_FkPYB0HHlJZ&gt;shown in this Colab&lt;/denchmark-link&gt;
).
However, using the  code using  fails with a Runtime Error pointing to dill and pickling. &lt;denchmark-link:https://colab.research.google.com/drive/1SDsCZhdeFBG8HMBRoV_lJdFDRJCZJIqa&gt;Here is the Colab replicating the issue.&lt;/denchmark-link&gt;

The preprocessing function that TFT is calling looks like this:
class ConcatCombiner(tft.analyzer_nodes.Combiner):
    def __init__(self):
        pass
    def create_accumulator(self):
        return []

    def add_input(self, accumulator, batch_values):
        return accumulator + batch_values

    def _concatenate_accumulators(self, accumulators):
        result = []
        for lst in accumulators:
            result.extend(lst)
        return result

    def merge_accumulators(self, accumulators):
        return self._concatenate_accumulators(accumulators)

    def extract_output(self, accumulator):
        return accumulator

    def output_tensor_infos(self):
        return [analyzer_nodes.TensorInfo(tf.string, [], False)]

def _compute_user_id_vocabulary(key, value):
    combiner = ConcatCombiner()
    vocab_file = tft.analyzers._apply_cacheable_combiner_per_key_large( 
        combiner, 'user_id_to_item_id_vocab', key, value)
    return vocab_file

def preprocessing_fn(inputs):

    outputs = {}

    uid = inputs['user_id']
    iid = inputs['item_id']
    label = inputs['label']

    uid_transf = tft.compute_and_apply_vocabulary(_fill_in_missing(uid))
    iid_transf = tft.compute_and_apply_vocabulary(_fill_in_missing(iid))

    outputs.update({_transformed_name('item_id'): iid_transf,
                    _transformed_name('user_id'): uid_transf,
                    'label': _fill_in_missing(label)
                    })


    user_id_to_item_id_vocab = _compute_user_id_vocabulary(uid_transf, iid_transf)
    initializer = tf.lookup.TextFileInitializer(user_id_to_item_id_vocab,
                                                key_dtype=tf.string,
                                                key_index=1,
                                                value_dtype=tf.string,
                                                value_index=0,
                                                delimiter=' ')
    table = tf.lookup.StaticHashTable(initializer, default_value='')
    outputs['item_id_grouped'] = table.lookup(tf.strings.as_string(uid_transf))


    return outputs
	</description>
	<comments>
		<comment id='1' author='luischinchillagarcia' date='2020-05-05T00:11:17Z'>
		Just confirm, are they using the same input data with the same format, and in same env (e.g., tft version)?
		</comment>
		<comment id='2' author='luischinchillagarcia' date='2020-05-05T00:12:14Z'>
		Yes, everything is exactly the same.
		</comment>
		<comment id='3' author='luischinchillagarcia' date='2020-05-05T00:13:52Z'>
		Sorry I take a look at your colab, the error is about "user_module" setup, not in TFT
		</comment>
		<comment id='4' author='luischinchillagarcia' date='2020-05-05T00:16:09Z'>
		It seems the error "user_module" setup is isolated to appear only in the TFT part of the TFX Pipeline.
		</comment>
		<comment id='5' author='luischinchillagarcia' date='2020-05-05T00:18:07Z'>
		Is there a possibility to have a fix in the same way you can do it using Interactive Context? There, you can have a line in the imports as:
import sys
import tensorflow_transform as user_module
sys.modules['user_module'] = user_module
		</comment>
		<comment id='6' author='luischinchillagarcia' date='2020-05-05T01:06:18Z'>
		what's this sys.modules['user_module'] for?
here is an &lt;denchmark-link:https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#transform&gt;example&lt;/denchmark-link&gt;
  about how to use module_file in colab
Is that what's your user_module for?
		</comment>
		<comment id='7' author='luischinchillagarcia' date='2020-05-05T01:10:49Z'>
		Without the sys.modules['user_module'], I get an error of the form as seen below. The TFT step in my example works under Interactive Context, just not in Pipeline.
I'm also using TFT exactly as intended as given in that example.
If you remove the sys.modules['user_module'] from the Interactive Context, you get once again the error below:
&lt;denchmark-link:https://user-images.githubusercontent.com/50338632/81027338-47a92d80-8e32-11ea-90ad-7940f5a8e4f0.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='luischinchillagarcia' date='2020-05-05T01:23:39Z'>
		The main part of the issue is:
This code works perfectly with TFT_beam. It works with TFX Interactive Context ONLY if you include the sys.modules['user_module'] fix. But it completely fails on TFX Pipeline with or without the sys.modules['user_module'].
Why does this inconsistency happen and is there a possible solution?
		</comment>
		<comment id='9' author='luischinchillagarcia' date='2020-05-05T02:22:21Z'>
		I'm not sure if I understand how the "sys.modules['user_module']" fix works.
This Interactive Context &lt;denchmark-link:https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#transform&gt;example&lt;/denchmark-link&gt;
 works without "sys.modules['user_module']"
Note that if you want to play with the pipeline instead of detailed components, this iris pipeline &lt;denchmark-link:https://github.com/tensorflow/tfx/blob/master/tfx/examples/iris/README.md&gt;example&lt;/denchmark-link&gt;
 might be simpler
		</comment>
		<comment id='10' author='luischinchillagarcia' date='2020-05-05T02:34:52Z'>
		So that is part of the issue: why does my code produce this 'Key Error: user_module' to begin with?
If this code works in with TFT_beam, why doesn't it work in a TFX Pipeline?
		</comment>
		<comment id='11' author='luischinchillagarcia' date='2020-05-05T03:02:53Z'>
		This Interactive Context &lt;denchmark-link:https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#transform&gt;example&lt;/denchmark-link&gt;
 works  "sys.modules['user_module']", while in your code you have this "sys.modules['user_module']" and it seems causing issues. could you try remove it and follow that example?
		</comment>
		<comment id='12' author='luischinchillagarcia' date='2020-05-05T04:36:12Z'>
		So it seems without it, it doesn't work.
		</comment>
		<comment id='13' author='luischinchillagarcia' date='2020-05-05T05:04:24Z'>
		Hi,
I tried the Interactive Context &lt;denchmark-link:https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#transform&gt;example&lt;/denchmark-link&gt;
 again and it works fine, so it might be some missing steps in your Colab, e.g., I can't find "context = InteractiveContext()"
I never tried the entire pipeline in Colab before, if you want to run the entire pipeline instead of playing with each components, try this iris pipeline &lt;denchmark-link:https://github.com/tensorflow/tfx/blob/master/tfx/examples/iris/README.md&gt;example&lt;/denchmark-link&gt;
 locally, it might be simpler (without InteractiveContext too)
		</comment>
		<comment id='14' author='luischinchillagarcia' date='2020-05-05T05:05:33Z'>
		Charles, do you know if we can run the entire pipeline in Colab?
		</comment>
		<comment id='15' author='luischinchillagarcia' date='2020-05-05T05:10:33Z'>
		Thanks for taking the time to check these over once again.
It might be that you were looking in the incorrect one. So &lt;denchmark-link:https://colab.research.google.com/drive/1g-GPCcxPmBqbQyOTZHcL_FkPYB0HHlJZ#scrollTo=h-Kh7SFB_Hc9&gt;this Colab&lt;/denchmark-link&gt;
 contains the Interactive Context run, &lt;denchmark-link:https://colab.research.google.com/drive/17LPB6b1D6ojnJbzs-t_M2qzhuZfin7Wx#scrollTo=tFcdSuXTidhH&gt;this one&lt;/denchmark-link&gt;
 contains the TFT_Beam, and &lt;denchmark-link:https://colab.research.google.com/drive/1SDsCZhdeFBG8HMBRoV_lJdFDRJCZJIqa&gt;this one&lt;/denchmark-link&gt;
 contains the TFX Pipeline.

I also just re-ran them to be sure everything was consistent with our discussion, and they were good to go

		</comment>
		<comment id='16' author='luischinchillagarcia' date='2020-05-05T05:21:03Z'>
		I tried your &lt;denchmark-link:https://colab.sandbox.google.com/drive/1g-GPCcxPmBqbQyOTZHcL_FkPYB0HHlJZ#scrollTo=h-Kh7SFB_Hc9&gt;colab&lt;/denchmark-link&gt;
 that contains InteractiveContext,
I replaced the the first section (Restart after installing tfx...) to "" and it works fine. (copied from &lt;denchmark-link:https://www.tensorflow.org/tfx/tutorials/tfx/components_keras#install_tfx&gt;here&lt;/denchmark-link&gt;
, removing the rest part will cause some compatible issue but it's still working)
iiuc, our Colab needs InteractiveContext to run, so pipeline example in Colab might not work (Charles might know detailed reason).
For pipeline, you could try the iris local example mentioned above.
		</comment>
		<comment id='17' author='luischinchillagarcia' date='2020-05-05T05:43:38Z'>
		So thankfully, the Interactive Context Colab works with these versions! (edited Colab version of the Interactive Context implementation &lt;denchmark-link:https://colab.research.google.com/drive/13JgIsPHYefc3VNjTf6vFmNZp2jM8pRvX&gt;here&lt;/denchmark-link&gt;
)
However, this  doesn't work on the Pipeline (). It's the same error. Why does this work with Interactive Context but not Pipeline? (Here an edited version with these updated package versions using : &lt;denchmark-link:%60tfx.orchestration.pipeline%60&gt;link here&lt;/denchmark-link&gt;
  )
		</comment>
		<comment id='18' author='luischinchillagarcia' date='2020-05-07T19:19:59Z'>
		I tried your pipeline Colab:
I replaced the the first section (Restart after installing tfx...) to "!pip install "tfx&gt;=0.21.1,&lt;0.22"" and set direct_num_workers=1 (or beam_pipeline_args=[]), it works. Notebook has some issue with Beam multiprocessing I guess
		</comment>
		<comment id='19' author='luischinchillagarcia' date='2020-05-07T19:22:19Z'>
		Perfect, thanks!
a natural next question is: would this issue persist while using Dataflow or this is purely an error caused in a notebook environment?
		</comment>
		<comment id='20' author='luischinchillagarcia' date='2020-05-07T21:11:14Z'>
		it should work in Dataflow, if not, it might be a beam side issue or tfx set up beam incorrectly
		</comment>
		<comment id='21' author='luischinchillagarcia' date='2020-05-08T23:52:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfx/issues/1722&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfx/issues/1722&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='22' author='luischinchillagarcia' date='2020-06-03T01:09:34Z'>
		Quick update that although this works perfectly with locally using Pipeline and Interactive Context, it fails with Dataflow under the error "no module named tfx".  Would this then be a Beam issue?
		</comment>
	</comments>
</bug>