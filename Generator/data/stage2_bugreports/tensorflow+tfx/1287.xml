<bug id='1287' author='valeriano-manassero' open_date='2020-02-14T16:19:59Z' closed_time='2020-10-09T11:25:23Z'>
	<summary>Kubeflow 1.0RC4 metadata config fails</summary>
	<description>
Kubernetes: 1.15
Kubeflow: 1.0RC4
TFX: 0.21.0
While testing
&lt;denchmark-code&gt;taxi_pipeline_kubeflow_local.py
&lt;/denchmark-code&gt;

I got:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py", line 371, in &lt;module&gt;
    main()
  File "/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py", line 345, in main
    _get_metadata_connection_config(kubeflow_metadata_config))
  File "/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py", line 93, in _get_metadata_connection_config
    kubeflow_metadata_config.grpc_config)
  File "/tfx-src/tfx/orchestration/kubeflow/container_entrypoint.py", line 110, in _get_grpc_metadata_connection_config
    kubeflow_metadata_config.grpc_service_host)
TypeError: None has type NoneType, but expected one of: bytes, unicode
&lt;/denchmark-code&gt;

While in the past TFX versions I had issues described in &lt;denchmark-link:https://github.com/tensorflow/tfx/issues/1002&gt;#1002&lt;/denchmark-link&gt;
 , now TFX is getting metadata config via grpc but it's not getting the configs expected (maybe Kubeflow new version is also involved).
	</description>
	<comments>
		<comment id='1' author='valeriano-manassero' date='2020-02-14T19:10:16Z'>
		Unfortunately that's a known issue. Kubeflow full-fledge deployment does not have the right MLMD config to use gRPC as in TFX 0.21.0. There are two solution to this issue:


Can you try a standalone KFP deployment (this is the only thing you need to run TFX pipeline, if you do not use Kubeflow notebook, katib and so on) with version &gt;= 0.2.1? You can find deploy instruction here


We can work out a kubeflow_metadata_config that works with full fledge kubeflow deployment, might take 1 or 2 days.


		</comment>
		<comment id='2' author='valeriano-manassero' date='2020-02-14T19:27:24Z'>
		Hi &lt;denchmark-link:https://github.com/numerology&gt;@numerology&lt;/denchmark-link&gt;
 and ty for answer.
Unfortunately Katib is a requirement for this testing deployment so I can't avoid it. Atm I'm not sure I have enough time to deep dive into code to issue a PR. Will try if you will not have an implementation before.
		</comment>
		<comment id='3' author='valeriano-manassero' date='2020-03-04T14:51:20Z'>
		Does this block the use of tfx with Kubeflow Pipelines only on local clusters, or also on GCP etc.?
Could you guys perhaps give an indication on the priority of this issue? It would certainly help with decisions going forward on the use of tfx with kubeflow and considering possible alternatives.
Many thanks!
		</comment>
		<comment id='4' author='valeriano-manassero' date='2020-03-08T21:05:04Z'>
		To solve the issue, you should change the configuration:
&lt;denchmark-code&gt;metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()
metadata_config.mysql_db_service_host.value = 'mysql.kubeflow'
metadata_config.mysql_db_service_port.value = "3306"
metadata_config.mysql_db_name.value = "metadb"
metadata_config.mysql_db_user.value = "root"
metadata_config.mysql_db_password.value = ""
metadata_config.grpc_config.grpc_service_host.value ='metadata-grpc-service'
metadata_config.grpc_config.grpc_service_port.value ='8080'

runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(
    kubeflow_metadata_config=metadata_config
)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='valeriano-manassero' date='2020-03-09T08:50:10Z'>
		
To solve the issue, you should change the configuration:
metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()
metadata_config.mysql_db_service_host.value = 'mysql.kubeflow'
metadata_config.mysql_db_service_port.value = "3306"
metadata_config.mysql_db_name.value = "metadb"
metadata_config.mysql_db_user.value = "root"
metadata_config.mysql_db_password.value = ""
metadata_config.grpc_config.grpc_service_host.value ='metadata-grpc-service'
metadata_config.grpc_config.grpc_service_port.value ='8080'

runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(
    kubeflow_metadata_config=metadata_config
)


I can confirm this workaround is good for Kubeflow 1.0 on premise. ty!
		</comment>
		<comment id='6' author='valeriano-manassero' date='2020-03-13T11:50:52Z'>
		After some testing I see grpc config should be enough, at least I didn't notice any issues with this:
&lt;denchmark-code&gt;metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()
metadata_config.grpc_config.grpc_service_host.value ='metadata-grpc-service'
metadata_config.grpc_config.grpc_service_port.value ='8080'

runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(
    kubeflow_metadata_config=metadata_config
)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='valeriano-manassero' date='2020-09-17T19:23:47Z'>
		I'd like to add that if your pod is running in a different namespace, you need to append the namespace of the grpc backend to the grpc host name:
metadata_config = kubeflow_dag_runner.get_default_kubeflow_metadata_config()
metadata_config.grpc_config.grpc_service_host.value ='metadata-grpc-service.kubeflow'
metadata_config.grpc_config.grpc_service_port.value ='8080'
runner_config = kubeflow_dag_runner.KubeflowDagRunnerConfig(
kubeflow_metadata_config=metadata_config
)
For instance.
		</comment>
		<comment id='8' author='valeriano-manassero' date='2020-10-09T11:25:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tfx/issues/1287&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tfx/issues/1287&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>