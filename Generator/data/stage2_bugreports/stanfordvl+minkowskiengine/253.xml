<bug id='253' author='fangwei123456' open_date='2020-10-31T05:23:52Z' closed_time='2020-12-26T11:45:30Z'>
	<summary>Problems about converting a 1d sparse tensor to a dense tensor</summary>
	<description>
&lt;denchmark-code&gt;def to_sparse_coo(data):
    # An intuitive way to extract coordinates and features
    coords, feats = [], []
    for i, val in enumerate(data):
        if val != 0:
            coords.append([i])
            feats.append([val])
    return torch.IntTensor(coords), torch.FloatTensor(feats)

M = 8
data0 = torch.randint(0, 2, [M]).float()
data1 = torch.randint(0, 2, [M]).float()
print(data0, data1)

coords0, feats0 = to_sparse_coo(data0)
coords1, feats1 = to_sparse_coo(data1)
coords, feats = ME.utils.sparse_collate(
    coords=[coords0, coords1], feats=[feats0, feats1])
print(coords, feats)

x = ME.SparseTensor(coords=coords, feats=feats)
x_d = x.dense(torch.IntTensor([0]), torch.IntTensor([M - 1]))[0]
print(x_d)
&lt;/denchmark-code&gt;

When I run this code, the output is
&lt;denchmark-code&gt;tensor([0., 0., 0., 1., 1., 1., 1., 1.]) tensor([0., 0., 1., 1., 0., 1., 0., 0.])
tensor([[0, 3],
        [0, 4],
        [0, 5],
        [0, 6],
        [0, 7],
        [1, 2],
        [1, 3],
        [1, 5]], dtype=torch.int32) tensor([[1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.]])

Traceback (most recent call last):
  File "/home/wfang/sp_test/test2.py", line 55, in &lt;module&gt;
    x_d = x.dense(torch.IntTensor([0]), torch.IntTensor([M - 1]))[0]
  File "/home/wfang/anaconda3/envs/pytorch-env/lib/python3.8/site-packages/MinkowskiEngine-0.4.3-py3.8-linux-x86_64.egg/MinkowskiEngine/SparseTensor.py", line 915, in dense
    size = torch.Size([max_batch + 1, nchannels, *size])
  File "/home/wfang/anaconda3/envs/pytorch-env/lib/python3.8/site-packages/torch/tensor.py", line 450, in __iter__
    raise TypeError('iteration over a 0-d tensor')
TypeError: iteration over a 0-d tensor
&lt;/denchmark-code&gt;

I don't know why this code doesn't work.
How can I convert a 1d sparse tensor to a dense tensor?
	</description>
	<comments>
		<comment id='1' author='fangwei123456' date='2020-10-31T05:27:52Z'>
		Here is an example for converting a 2d sparse tensor to a dense tensor. This code works well for 2d converting.
&lt;denchmark-code&gt;def to_sparse_coo(data):
    # An intuitive way to extract coordinates and features
    coords, feats = [], []
    for i, row in enumerate(data):
        for j, val in enumerate(row):
            if val != 0:
                coords.append([i, j])
                feats.append([val])
    return torch.IntTensor(coords), torch.FloatTensor(feats)


M = 3
N = 4
data0 = torch.randint(0, 2, [M, N]).float()
data1 = torch.randint(0, 2, [M, N]).float()
print(data0, data1)

coords0, feats0 = to_sparse_coo(data0)
coords1, feats1 = to_sparse_coo(data1)
coords, feats = ME.utils.sparse_collate(
    coords=[coords0, coords1], feats=[feats0, feats1])
print(coords, feats)

x = ME.SparseTensor(coords=coords, feats=feats)
x_d = x.dense(torch.IntTensor([0, 0]), torch.IntTensor([M - 1, N - 1]))[0]
print(x_d)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;tensor([[0., 1., 1., 0., 1., 0., 0.],
        [1., 1., 0., 1., 0., 1., 0.]]) tensor([[1., 0., 1., 0., 0., 1., 1.],
        [0., 1., 1., 0., 0., 0., 1.]])
tensor([[0, 0, 1],
        [0, 0, 2],
        [0, 0, 4],
        [0, 1, 0],
        [0, 1, 1],
        [0, 1, 3],
        [0, 1, 5],
        [1, 0, 0],
        [1, 0, 2],
        [1, 0, 5],
        [1, 0, 6],
        [1, 1, 1],
        [1, 1, 2],
        [1, 1, 6]], dtype=torch.int32) tensor([[1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.],
        [1.]])
tensor([[[[0., 1., 1., 0., 1., 0., 0.],
          [1., 1., 0., 1., 0., 1., 0.]]],


        [[[1., 0., 1., 0., 0., 1., 1.],
          [0., 1., 1., 0., 0., 0., 1.]]]])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='fangwei123456' date='2020-12-26T11:45:30Z'>
		The issue has been resolved in v0.5
		</comment>
	</comments>
</bug>