<bug id='300' author='torrmal' open_date='2019-09-05T17:58:36Z' closed_time='2019-09-18T16:19:20Z'>
	<summary>accuracy per bucket seems to be offw</summary>
	<description>
Accuracy per bucket seems to be off from inuition, please revise tha this is being calcualted accurately,
&lt;denchmark-link:https://user-images.githubusercontent.com/5898506/64366924-da13db80-cfdc-11e9-896e-0d144d2a2650.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='torrmal' date='2019-09-09T03:50:30Z'>
		So, I've investigated this a bit and I can't find anything wrong. But I see what you mean, I'd totally expect more examples to lead to better accuracy.
I guess the one thing that could be happening here, to som extent, is that the model has a range of error that's more obvious in the middle bucket,s but, I don't know. Rest assured that I'm on it, but this is not exactly a "bug" as far as I see, so finding a "fix" might be a bit difficult.
		</comment>
		<comment id='2' author='torrmal' date='2019-09-09T06:32:36Z'>
		Ok, figured it out, it was rather silly:
The histogram doesn't show the accuracy per bucket of the real value, it shows accuracy per bucket of the predicted value.
Hence why a lot of the buckets with a lot of occurrences have very high accuracies (since that's where a lot of predictions fall by default, and they are usually wrong).
Now, there's two other possible issues:

The "x" axis is the bucket index, not the bucket value, that'd be easy enough to change if so desired (at least from my end, but I'd require plotting changes on the frontend)
The accuracy being displayed is the model's accuracy, not the probabilistic validator's accuracy, and by default we now give users the prediction of the probabilistic validator.

Both of those can be changed, the former is easy the later would be a bit tricker to get working, but not that problematic.
		</comment>
		<comment id='3' author='torrmal' date='2019-09-09T06:58:53Z'>
		This is how the histogram looks using the buckets of the real values (so it's accuracy when the real value is "x" rather than accuracy when the model predicts "x")
&lt;denchmark-link:https://user-images.githubusercontent.com/23587658/64509370-168e5280-d2cf-11e9-8c29-a442c802e1d3.png&gt;&lt;/denchmark-link&gt;

... Not sure why the "-1" appears in your though, that's a bug I can't replicate.
		</comment>
		<comment id='4' author='torrmal' date='2019-09-18T16:19:20Z'>
		The latest PR should have fixed this, it boiled down to a plotting error where the incorrect buckets where sometimes being plotted, since the buckets were used for accuracy and the histogram was used for plotting the data distribution. These were not necessarily the same for numerical values, and some buckets could have had no accuracy associated.
In the latest PR, if a bucket has no accuracy we associate the average accuracy with it and we use the histogram's x axis for the value buckets.
		</comment>
	</comments>
</bug>