<bug id='367' author='surendra1472' open_date='2020-01-05T06:32:48Z' closed_time='2020-05-07T13:24:36Z'>
	<summary>Loading time series model in GUI and finding column importance is giving error</summary>
	<description>
Your Environment

Python environment used (e.g. venv, conda): 1.9.2

Describe the bug
Loading time series model in GUI and finding column importance is giving error. Find the attached screen shot.
To Reproduce
Steps to reproduce the behavior, for example:

Train a time series model using Group by in local machine and export it
Upload the model via GUI(point the GUI to local server, for this we need to run the server locally)
Try to see the column importances

Expected behavior
It should show me the column importances.

&lt;denchmark-link:https://user-images.githubusercontent.com/27191684/71776189-2daa2c00-2fb3-11ea-8ac2-b616ff81a616.PNG&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='surendra1472' date='2020-01-07T22:45:53Z'>
		&lt;denchmark-link:https://github.com/surendra1472&gt;@surendra1472&lt;/denchmark-link&gt;
 please provide a copy of the data and code you used to train the model.
		</comment>
		<comment id='2' author='surendra1472' date='2020-01-08T16:11:48Z'>
		&lt;denchmark-link:https://github.com/George3d6&gt;@George3d6&lt;/denchmark-link&gt;
 Please find the code. After running the python file model will be exported. Try to import the model to GUI.
folder
&lt;denchmark-link:https://github.com/mindsdb/mindsdb/files/4036179/Model_Import_code.zip&gt;Model_Import_code.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='surendra1472' date='2020-02-21T09:48:25Z'>
		It seems like this is caused by the lightwood backend predicting everything as nan and column confidence computation might consequentially screwed over by that, thus the UI is unable to visualize them.
Which... I mean, it's a bug I guess, but if the model can't learn anything at all, that's not an edge case we want to spare too much time patching up or thinking about.
Running some extra check to make sure this is the case.
		</comment>
		<comment id='4' author='surendra1472' date='2020-02-21T18:41:59Z'>
		Trying to run this dataset with ludwig as the backend also yield errors:
&lt;denchmark-code&gt;ERROR:mindsdb-logger-core-logger:libs/controllers/transaction.py:126 - Could not load module ModelInterface

ERROR:mindsdb-logger-core-logger:libs/controllers/transaction.py:127 - Traceback (most recent call last):
  File "/home/george/mindsdb/mindsdb/libs/controllers/transaction.py", line 123, in _call_phase_module
    return module(self.session, self)(**kwargs)
  File "/home/george/mindsdb/mindsdb/libs/phases/base_module.py", line 54, in __call__
    ret = self.run(**kwargs)
  File "/home/george/mindsdb/mindsdb/libs/phases/model_interface/model_interface.py", line 35, in run
    self.transaction.hmd['predictions'] = self.transaction.model_backend.predict()
  File "/home/george/mindsdb/mindsdb/libs/backends/ludwig.py", line 445, in predict
    predict_dataframe, model_definition, timeseries_cols, has_heavy_data, _ = self._create_ludwig_dataframe(mode)
  File "/home/george/mindsdb/mindsdb/libs/backends/ludwig.py", line 255, in _create_ludwig_dataframe
    date = parse_datetime(row[col])
  File "/usr/lib/python3/dist-packages/dateutil/parser/_parser.py", line 1356, in parse
    return DEFAULTPARSER.parse(timestr, **kwargs)
  File "/usr/lib/python3/dist-packages/dateutil/parser/_parser.py", line 645, in parse
    res, skipped_tokens = self._parse(timestr, **kwargs)
  File "/usr/lib/python3/dist-packages/dateutil/parser/_parser.py", line 721, in _parse
    l = _timelex.split(timestr)         # Splits the timestr into tokens
  File "/usr/lib/python3/dist-packages/dateutil/parser/_parser.py", line 207, in split
    return list(cls(s))
  File "/usr/lib/python3/dist-packages/dateutil/parser/_parser.py", line 76, in __init__
    '{itype}'.format(itype=instream.__class__.__name__))
TypeError: Parser must be a string or character stream, not NoneType
&lt;/denchmark-code&gt;

Strange... maybe there's some weirdly malformed data somewhere in there leading to all of this... I'll try to look into it a bit more, if I find something new I'll most an update.
		</comment>
		<comment id='5' author='surendra1472' date='2020-05-07T13:24:36Z'>
		This was fixed by the text transformation &amp; ts transformation changes, closing.
		</comment>
	</comments>
</bug>