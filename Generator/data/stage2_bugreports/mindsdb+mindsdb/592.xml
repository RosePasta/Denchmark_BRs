<bug id='592' author='ZoranPandovski' open_date='2020-07-14T16:44:31Z' closed_time='2020-07-14T16:54:05Z'>
	<summary>DB timeouts when training takes more time</summary>
	<description>
Using the join_learn_process flag will throw a timeout error if the training takes longer. It looks like ClickHouse throws this error if data for INSERT queries are not sent for more then 300 seconds.
Insert statement using &lt;denchmark-link:https://github.com/mindsdb/mindsdb-examples/tree/master/others/air_pollution_seoul&gt;air_pollution_data&lt;/denchmark-link&gt;

&lt;denchmark-code&gt; INSERT INTO predictors (name, predict_cols, select_data_query, training_options) VALUES ('airq_predictorz', 'SO2', 'SELECT * FROM pollution_measurementz LIMIT 10000',  '{"join_learn_process": true}');

&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;Exception on client:
Code: 209. DB::NetException: Timeout exceeded while reading from socket (127.0.0.1:9000): while receiving packet from localhost:9000
&lt;/denchmark-code&gt;

Note that in the end the Predictor will be created, just the timeout issue is returned to the user. Maybe send some parameters as send_timeout but we can never be sure when the training will finish?
	</description>
	<comments>
		<comment id='1' author='ZoranPandovski' date='2020-07-14T16:54:05Z'>
		After a talk with &lt;denchmark-link:https://github.com/StpMax&gt;@StpMax&lt;/denchmark-link&gt;
, we agreed that join_learn_process shall be used only for testing purposes and users shall use select status in mindsdb.predictors.
		</comment>
	</comments>
</bug>