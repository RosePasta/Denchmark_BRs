<bug id='454' author='andreabat' open_date='2020-06-01T11:01:41Z' closed_time='2020-06-25T15:29:43Z'>
	<summary>Problem when training with date time from csv file</summary>
	<description>
Your Environment

Python version: Python 3.6.9
Pip version: 9.0.1
Operating system:Ubuntu 18-04
Mindsdb version you tried to install: installed from pip ( guess latest)

Describe the bug
Trying to import a csv with a column that is date time in this format "YYYY-MM-DD HH:mm:ss"
I recieve this warning
Failed to parser numerical value with error chain:
could not convert string to float: '2015-11-20 11:55:49' -&gt; name 'parse_datetime' is not defined
	</description>
	<comments>
		<comment id='1' author='andreabat' date='2020-06-01T12:24:48Z'>
		&lt;denchmark-link:https://github.com/andreabat&gt;@andreabat&lt;/denchmark-link&gt;
 If it's not private, can you please share the dataset that you are using so we can try to reproduce the issue?
		</comment>
		<comment id='2' author='andreabat' date='2020-06-02T05:38:41Z'>
		This is worrying parse_datetime looks like some dependency missing, let me look into it.
		</comment>
		<comment id='3' author='andreabat' date='2020-06-02T05:58:04Z'>
		Alright, &lt;denchmark-link:https://github.com/andreabat&gt;@andreabat&lt;/denchmark-link&gt;
 I just pushed a hotfix that should take care of this, should be on pypi in 20 minutes from now.
Try installing it via pip install mindsdb=1.18.1 and please tell us if you still have the issue.
Thanks a lot for finding this :)
		</comment>
		<comment id='4' author='andreabat' date='2020-06-02T13:07:46Z'>
		Ok, Will try it tomorrow (today is bank holiday in Italy). Will check if another issue I encountered with null fields using the postgresdb data source is still happening and will let you know.
Cannot share dataset easily since it contains pii.
		</comment>
		<comment id='5' author='andreabat' date='2020-06-06T08:17:10Z'>
		&lt;denchmark-link:https://github.com/andreabat&gt;@andreabat&lt;/denchmark-link&gt;
 any updates on this ?
		</comment>
		<comment id='6' author='andreabat' date='2020-06-08T07:55:29Z'>
		Sorrry , no luck. I am now anonymizing the csv file  and will share right away with error stack.
		</comment>
		<comment id='7' author='andreabat' date='2020-06-08T08:46:57Z'>
		Ok, I am a bit confused.
Transformed my dataset with faker. Turns out that it doesn't show that error anymore.  My first thoughts are that empty fields, cause an exception. Is that possible ?
The faker procedure generates a value for all fields. The original dataset has occasionally missing values.
Not sharing the faked dataset, since it is working and it would be pointless.
Just to clarify (:-) ) things:
If I load complete original dataset: I get this exception
KeyError: 'Timestamp'
( I do not have a field "Timestamp" in my csv file )
This is the csv header
"blacklist","GiornoSettimana","Ora","Minuto","IDCanale","Email","Telefono","Cellulare","DataScontrino","OraScontrino","Scontrino","ImportoScontrino","Nome","Cognome","Indirizzo","Comune","CAP","Prov","Username"
Once I anonymize data  I get:
KeyError: 'Cellulare'
Cellulare is in the headers field, but it is always empty. When faking the data, the resulting csv is empty, while the original file has double quotes.
If I add fake data to the Cellulare field, it works.
BTW should I update to version 1.2 ?
		</comment>
		<comment id='8' author='andreabat' date='2020-06-08T09:10:50Z'>
		Hmh, do try upgrading to 1.20.0, but I doubt that will fix it.
Can you add the full stack trace for the exception you are getting on the original dataset?
Can you also try trining with the original data and removing Cellulare (since you're saying it's empty anyway)? And seeing what error that generates.
		</comment>
		<comment id='9' author='andreabat' date='2020-06-25T15:29:43Z'>
		No update so closing this for now, feel free to repon in the mindsdb_native repository.
		</comment>
	</comments>
</bug>