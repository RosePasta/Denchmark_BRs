<bug id='2764' author='weiqiangshen' open_date='2020-08-04T04:05:13Z' closed_time='2020-12-07T14:35:28Z'>
	<summary>when run auto_pruners_torch.py with save file flag, the log print out "Layer: conv1  Sparsity: 0.0000",  infact the sparsity is 0.3</summary>
	<description>
Environment:ubuntu 18.04

NNI version: 1.7
NNI mode (local|remote|pai): local
Client OS: ubuntu 18.04
Server OS (for remote mode only):
Python version: 3.6
PyTorch/TensorFlow version:1.5.1+cu101
Is conda/virtualenv/venv used?: no
Is running in Docker?: no

Log message:
Evaluation result (masked model): 0.9833
[08/04/2020, 12:00:00 PM] INFO (nni.compression.torch.compressor) Layer: conv1  Sparsity: 0.0000
[08/04/2020, 12:00:00 PM] INFO (nni.compression.torch.compressor) Layer: conv2  Sparsity: 0.0000
[08/04/2020, 12:00:00 PM] INFO (nni.compression.torch.compressor) Model state_dict saved to ./model_masked.pth
[08/04/2020, 12:00:00 PM] INFO (nni.compression.torch.compressor) Mask dict saved to ./mask.pth

nnimanager.log:
dispatcher.log:
nnictl stdout and stderr:

What issue meet, what's expected?:
How to reproduce it?:
python3 auto_pruners_torch.py
Additional information:
	</description>
	<comments>
		<comment id='1' author='weiqiangshen' date='2020-08-05T03:58:00Z'>
		This issue should have already been fixed in PR &lt;denchmark-link:https://github.com/microsoft/nni/pull/2736&gt;#2736&lt;/denchmark-link&gt;
.
Thanks for your comments &lt;denchmark-link:https://github.com/weiqiangshen&gt;@weiqiangshen&lt;/denchmark-link&gt;
 , please fetch the latest code from the master branch and check it again.
		</comment>
		<comment id='2' author='weiqiangshen' date='2020-08-06T06:35:45Z'>
		&lt;denchmark-link:https://github.com/weiqiangshen&gt;@weiqiangshen&lt;/denchmark-link&gt;
 - as a reference, this fix will be released on the upcoming release: &lt;denchmark-link:https://github.com/microsoft/nni/issues/2608&gt;#2608&lt;/denchmark-link&gt;
 (current target release date is Aug 17).
		</comment>
		<comment id='3' author='weiqiangshen' date='2020-12-07T14:35:28Z'>
		Iâ€™m closing this issue as we have fixed the problem you raised, please feel free to reopen if you are still seeing it an active issue.
		</comment>
	</comments>
</bug>