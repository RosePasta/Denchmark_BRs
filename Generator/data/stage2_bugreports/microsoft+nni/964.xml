<bug id='964' author='Crysple' open_date='2019-04-09T02:19:05Z' closed_time='2019-10-28T03:25:43Z'>
	<summary>'PAI Training service: Submit trial trial_id to PAI Cluster failed</summary>
	<description>
Short summary about the issue/question:
Run a lot of jobs(maybe dozens of) and suddenly NNI failed because training services fail to copy one trial's files.
Brief what process you are following:
How to reproduce it:
submit a lot of jobs to PAI, and there's a certain probability of occurrence of the failure
nni Environment:

nni version: master/0.6
nni mode(local|pai|remote): pai
OS: Ubuntu
python version: 3.6.1
is conda or virtualenv used?:  conda
is running in docker?: no

Anything else we need to know:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Log information:

WebUI:

&lt;denchmark-link:https://user-images.githubusercontent.com/20517842/55768624-2d2a4680-5ab0-11e9-9f03-90d13add4b7f.png&gt;&lt;/denchmark-link&gt;


nnictl log stderr:

&lt;denchmark-code&gt;(node:25377) ExperimentalWarning: The fs.promises API is experimental
{ [Job management error: Job management error: undefined]
  name: 'Job management error',
  cause: 'Submit trial failed, http code: 502' }
&lt;/denchmark-code&gt;


NNI manager's log:

&lt;denchmark-code&gt;[2019-04-08T20:29:46.362Z] ERROR [ 'PAI Training service: Submit trial flQmh to PAI Cluster failed!' ]
[2019-04-08T20:29:46.363Z] INFO [ 'Change NNIManager status from: RUNNING to: ERROR' ]
[2019-04-08T20:29:48.329Z] INFO [ 'POST: /stdout/c3cW0dUX/SbdkR: body:\n{\n    "msg": "Eval at 1500",\n    "stdOutputType": "Stdout",\n    "tag": "trial"\n}' ]
[2019-04-08T20:29:48.613Z] INFO [ 'POST: /stdout/c3cW0dUX/SbdkR: body:\n{\n    "msg": "test_accuracy: 0.5752",\n    "stdOutputType": "Stdout",\n    "tag": "trial"\n}' ]
[2019-04-08T20:29:48.889Z] INFO [ 'POST: /stdout/c3cW0dUX/SbdkR: body:\n{\n    "msg": "NNISDK_MEb\'{\\"parameter_id\\": 181, \\"sequence\\": 2, \\"type\\": \\"PERIODICAL\\", \\"trial_job_id\\": \\"SbdkR\\", \\"value\\": 0.5752}\'",\n    "stdOutputType": "Stdout",\n    "tag": "trial"\n}' ]
[2019-04-08T20:29:55.520Z] INFO [ 'POST: /stdout/c3cW0dUX/Xs17p: body:\n{\n    "msg": "Eval at 1500",\n    "tag": "trial",\n    "stdOutputType": "Stdout"\n}' ]
[2019-04-08T20:29:55.797Z] INFO [ 'POST: /stdout/c3cW0dUX/Xs17p: body:\n{\n    "msg": "test_accuracy: 0.5740",\n    "tag": "trial",\n    "stdOutputType": "Stdout"\n}' ]
[2019-04-08T20:29:56.072Z] INFO [ 'POST: /stdout/c3cW0dUX/Xs17p: body:\n{\n    "msg": "NNISDK_MEb\'{\\"parameter_id\\": 180, \\"trial_job_id\\": \\"Xs17p\\", \\"value\\": 0.574, \\"sequence\\": 2, \\"type\\": \\"PERIODICAL\\"}\'",\n    "tag": "trial",\n    "stdOutputType": "Stdout"\n}' ]
[2019-04-08T20:30:02.566Z] INFO [ 'POST: /stdout/c3cW0dUX/qJxEI: body:\n{\n    "stdOutputType": "Stdout",\n    "msg": "[2019-04-08 20:30:28.492050] ERROR Copy hdfs file /quzha/nni/experiments/c3cW0dUX/codeDir/src/common_ops.py to /root/qJxEI/src/common_ops.py error: Expected JSON. Is WebHDFS enabled? Got \'&lt;html&gt;\\\\r\\\\n&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;\\\\r\\\\n&lt;body bgcolor=\\"white\\"&gt;\\\\r\\\\n&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;\\\\r\\\\n&lt;hr&gt;&lt;center&gt;nginx/1.13.8&lt;/center&gt;\\\\r\\\\n&lt;/body&gt;\\\\r\\\\n&lt;/html&gt;\\\\r\\\\n\'",\n    "tag": "trial_keeper"\n}' ]
[2019-04-08T20:30:02.841Z] INFO [ 'POST: /stdout/c3cW0dUX/qJxEI: body:\n{\n    "stdOutputType": "Stdout",\n    "msg": "[2019-04-08 20:30:28.767049] ERROR Exit trial keeper with code 1 because Exception: Expected JSON. Is WebHDFS enabled? Got \'&lt;html&gt;\\\\r\\\\n&lt;head&gt;&lt;title&gt;502 Bad Gateway&lt;/title&gt;&lt;/head&gt;\\\\r\\\\n&lt;body bgcolor=\\"white\\"&gt;\\\\r\\\\n&lt;center&gt;&lt;h1&gt;502 Bad Gateway&lt;/h1&gt;&lt;/center&gt;\\\\r\\\\n&lt;hr&gt;&lt;center&gt;nginx/1.13.8&lt;/center&gt;\\\\r\\\\n&lt;/body&gt;\\\\r\\\\n&lt;/html&gt;\\\\r\\\\n\' is catched",\n    "tag": "trial_keeper"\n}' ]
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Possible Reason:
In paiTrainingService.ts (line 261-289), when it fails to copy file in hdfs, it logs the err information and reject directly, which causes the whole experiment fail. (maybe it could still log the failure but then mark this trial as failure so NNI can re-schedule another one to try again, rather than directly reject and terminal the experiment?
&lt;denchmark-code&gt;// Step 2. Upload code files in codeDir onto HDFS
try {
    await HDFSClientUtility.copyDirectoryToHdfs(trialLocalTempFolder, hdfsCodeDir, this.hdfsClient);
} catch (error) {
    this.log.error(`PAI Training service: copy ${this.paiTrialConfig.codeDir} to HDFS ${hdfsCodeDir} failed, error is ${error}`);
    throw new Error(error.message);
}

// Step 3. Submit PAI job via Rest call
// Refer https://github.com/Microsoft/pai/blob/master/docs/rest-server/API.md for more detail about PAI Rest API
const submitJobRequest: request.Options = {
    uri: `http://${this.paiClusterConfig.host}/rest-server/api/v1/user/${this.paiClusterConfig.userName}/jobs`,
    method: 'POST',
    json: true,
    body: paiJobConfig,
    headers: {
        "Content-Type": "application/json",
        "Authorization": 'Bearer ' + this.paiToken
    }
};
request(submitJobRequest, (error: Error, response: request.Response, body: any) =&gt; {
    if (error || response.statusCode &gt;= 400) {
        this.log.error(`PAI Training service: Submit trial ${trialJobId} to PAI Cluster failed!`);
        trialJobDetail.status = 'FAILED';
        deferred.reject(error ? error.message : 'Submit trial failed, http code: ' + response.statusCode);                
    } else {
        trialJobDetail.submitTime = Date.now();
        deferred.resolve(trialJobDetail);
    }
});
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Crysple' date='2019-04-09T03:22:33Z'>
		I also met this problem before and don't know how to get rid of it.
		</comment>
		<comment id='2' author='Crysple' date='2019-04-10T07:23:10Z'>
		Another similar problem happened when updating PAI token.
It is at the middle of the experiment, when there are already a lot of succeeded trials. Suddenly (maybe due to the network or PAI) it fails to get PAI token
&lt;denchmark-code&gt;-----------------------------------------------------------------------
                Experiment start time 2019-04-10 04:41:41
-----------------------------------------------------------------------
2019-04-10 04:42:00.469781: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-10 04:42:00.477402: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294680000 Hz
2019-04-10 04:42:00.479514: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x8829540 executing computations on platform Host. Devices:
2019-04-10 04:42:00.479551: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
(node:26289) ExperimentalWarning: The fs.promises API is experimental
{ Error: Get PAI token timeout. Please check your PAI cluster.
    at Timeout.setTimeout (/datadisk/v-zejlin/venv/nni/training_service/pai/paiTrainingService.js:347:49)
    at ontimeout (timers.js:436:11)
    at tryOnTimeout (timers.js:300:5)
    at listOnTimeout (timers.js:263:5)
    at Timer.processTimers (timers.js:223:10)
  name: 'Training service error',
  cause:
   Error: Get PAI token timeout. Please check your PAI cluster.
       at Timeout.setTimeout (/datadisk/v-zejlin/venv/nni/training_service/pai/paiTrainingService.js:347:49)
       at ontimeout (timers.js:436:11)
       at tryOnTimeout (timers.js:300:5)
       at listOnTimeout (timers.js:263:5)
       at Timer.processTimers (timers.js:223:10) }
&lt;/denchmark-code&gt;

NNI manager:
&lt;denchmark-code&gt;[2019-04-10T06:41:51.342Z] ERROR [ 'Error: Get PAI token timeout. Please check your PAI cluster.\n    at Timeout.setTimeout (/datadisk/v-zejlin/venv/nni/training_service/pai/paiTrainingService.js:347:49)\n    at ontimeout (timers.js:436:11)\n    at tryOnTimeout (timers.js:300:5)\n    at listOnTimeout (timers.js:263:5)\n    at Timer.processTimers (timers.js:223:10)' ]
[2019-04-10T06:41:51.342Z] INFO [ 'Change NNIManager status from: TUNER_NO_MORE_TRIAL to: ERROR' ]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='Crysple' date='2019-04-23T09:12:33Z'>
		we will add retry logic.
		</comment>
		<comment id='4' author='Crysple' date='2019-10-20T05:54:27Z'>
		Hi all. Is this problem fixed or still reproducible?
		</comment>
		<comment id='5' author='Crysple' date='2019-10-25T09:37:30Z'>
		Fixed.
		</comment>
	</comments>
</bug>