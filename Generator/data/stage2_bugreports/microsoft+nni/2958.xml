<bug id='2958' author='HeekangPark' open_date='2020-10-14T09:40:04Z' closed_time='2020-10-30T08:41:25Z'>
	<summary>SPOS Example Fails to Run</summary>
	<description>
Environment:

NNI version: 1.8
NNI mode (local|remote|pai): local
Client OS: Ubuntu 18.04
Server OS (for remote mode only):
Python version: v3.7
PyTorch/TensorFlow version: Pytorch v1.6.0
Is conda/virtualenv/venv used?: conda used
Is running in Docker?: no

Log message:

nnimanager.log:
dispatcher.log:
nnictl stdout and stderr:

What issue meet, what's expected?:
Currently, in examples/nas/spos/supernet.py, line 55, the argument of flops_func is set as model.module.get_candidate_flops.
However, when I run python supernet.py, it fails to run due to that line.
I think the argument of flops_func should be model.get_candidate_flops, not model.module.get_candidate_flops.
How to reproduce it?:
Clone the repo, and just run python supernet.py in examples/nas/spos/.
Additional information:
I'm new to this field, so the issue I found might be due to my ignorance. Thank you in advance.
	</description>
	<comments>
		<comment id='1' author='HeekangPark' date='2020-10-14T10:31:27Z'>
		I find out the problem.
supernet.py runs in parallel only when the number of available gpu is bigger than 1.
I used only 1 gpu to run the code, so nn.DataParallel() was not executed, which makes model.module.get_candidate_flops as wrong code.
Well, of course it is not a wise idea to run NAS with only 1 gpu, , but for those who run code with 1 gpu like me, I suggest to add a line of code right below line 47(model = ShuffleNetV2OneShot()) like this.
&lt;denchmark-code&gt;model = ShuffleNetV2OneShot()  # line 47
flops_func = model.get_candidate_flops
if args.load_checkpoint:
    if not args.spos_preprocessing:
        logger.warning("You might want to use SPOS preprocessing if you are loading their checkpoints.")
    model.load_state_dict(load_and_parse_state_dict())
model.cuda()
if torch.cuda.device_count() &gt; 1:  # exclude last gpu, saving for data preprocessing on gpu
    model = nn.DataParallel(model, device_ids=list(range(0, torch.cuda.device_count() - 1)))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='HeekangPark' date='2020-10-15T01:41:23Z'>
		Hi. Seems that you've identified the problem and would you kindly submit a pull request? We would be happy to have you as one of our contributor. :)
		</comment>
	</comments>
</bug>