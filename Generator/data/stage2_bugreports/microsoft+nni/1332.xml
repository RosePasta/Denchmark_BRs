<bug id='1332' author='ultmaster' open_date='2019-07-18T09:44:48Z' closed_time='2019-07-26T03:13:16Z'>
	<summary>Hyper-parameter page broken</summary>
	<description>
Short summary about the issue/question:
I'm trying to use NNI to train my network, and what the first few trials show "SUCCEEDED", I can no longer visit the hyper-parameter page in training details.
Then I press F12 to see what's going on. It seems like some "undefined" bug.
&lt;denchmark-code&gt;DOMException: Failed to execute 'addColorStop' on 'CanvasGradient': The value provided ('undefined') could not be parsed as a color.
    at o.getGradient (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:852514)
    at t.brush (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:86745)
    at g._doPaintEl (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2283310)
    at g._doPaintList (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2282292)
    at g._paintList (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2281297)
    at g.refresh (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2280095)
    at p.refreshImmediately (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:451438)
    at p.flush (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:451567)
    at W.B.setOption (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:8912)
    at t.n.renderEchartDom (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2707289)
ha @ react-dom.production.min.js:198
n.callback @ react-dom.production.min.js:210
ia @ react-dom.production.min.js:193
na @ react-dom.production.min.js:193
ja @ react-dom.production.min.js:217
Ba @ react-dom.production.min.js:220
(anonymous) @ react-dom.production.min.js:250
t.unstable_runWithPriority @ scheduler.production.min.js:18
Is @ react-dom.production.min.js:250
Ts @ react-dom.production.min.js:249
Os @ react-dom.production.min.js:248
Ds @ react-dom.production.min.js:251
On @ react-dom.production.min.js:85
react-dom.production.min.js:248 Uncaught DOMException: Failed to execute 'addColorStop' on 'CanvasGradient': The value provided ('undefined') could not be parsed as a color.
    at o.getGradient (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:852514)
    at t.brush (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:86745)
    at g._doPaintEl (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2283310)
    at g._doPaintList (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2282292)
    at g._paintList (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2281297)
    at g.refresh (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2280095)
    at p.refreshImmediately (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:451438)
    at p.flush (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:451567)
    at W.B.setOption (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:8912)
    at t.n.renderEchartDom (http://10.150.144.124:20718/static/js/main.565fbd70.js:1:2707289)
&lt;/denchmark-code&gt;

Brief what process you are following:
How to reproduce it:
My tuner is as follows:
&lt;denchmark-code&gt;from nni.gridsearch_tuner.gridsearch_tuner import GridSearchTuner


class FixedProductTuner(GridSearchTuner):

    def __init__(self, product):
        super().__init__()
        self.product = product

    def expand_parameters(self, para):
        para = super().expand_parameters(para)
        if all([key in para[0] for key in ["alpha", "beta", "gamma"]]):
            ret_para = []
            for p in para:
                prod = p["alpha"] * (p["beta"] ** 2) * (p["gamma"] ** 2)
                if abs(prod - self.product) &lt; 0.05:
                    ret_para.append(p)
            return ret_para
        return para
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;import tensorflow as tf


class NNIExporter(tf.estimator.Exporter):
    def export(self, estimator, export_path, checkpoint_path, eval_result,
               is_the_final_export):
        import nni
        result = eval_result["top_1_accuracy"]
        if is_the_final_export:
            nni.report_intermediate_result(result)
        else:
            nni.report_intermediate_result(result)

    @property
    def name(self):
        return "nni_exporter"
&lt;/denchmark-code&gt;

Here is my config file and search space:
&lt;denchmark-code&gt;authorName: xxx
experimentName: example_efficient_net
trialConcurrency: 4
maxExecDuration: 1h
maxTrialNum: 20
trainingServicePlatform: local
searchSpacePath: search.json
useAnnotation: false
tuner:
  codeDir: .
  classFileName: tuner.py
  className: FixedProductTuner
  classArgs:
    product: 2
trial:
  codeDir: .
  command: python trainer.py --batch-size 24 --request-from-nni
  gpuNum: 1
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;{
  "alpha": {
    "_type": "quniform",
    "_value": [1.0, 2.0, 10]
  },
  "beta": {
    "_type": "quniform",
    "_value": [1.0, 1.5, 10]
  },
  "gamma": {
    "_type": "quniform",
    "_value": [1.0, 1.5, 10]
  }
}
&lt;/denchmark-code&gt;

nni Environment:

nni version: 0.9.1.1
nni mode(local|pai|remote): local
OS: ubuntu 16.04
python version: python 3.6
is conda or virtualenv used?: conda
is running in docker?: no

need to update document(yes/no): no
Anything else we need to know:
	</description>
	<comments>
		<comment id='1' author='ultmaster' date='2019-07-19T08:36:57Z'>
		I did some digging and figured that I didn't sent FINAL result (all results are INTERMEDIATE). Could that be the cause?
BTW, don't you think it's more reasonable to make the last result automatically FINAL, in case the user forgets to send one?
		</comment>
	</comments>
</bug>