<bug id='288' author='leftluoyi' open_date='2018-01-24T05:34:19Z' closed_time='2019-05-13T15:24:13Z'>
	<summary>predict np.vstack problem when batch_size if no factor of test dataset size</summary>
	<description>
Have a trained network. The test set includes 28000 rows. If I set the batch_size to 256, i.e.,
prediction = tl.utils.predict(sess, network, test_X, X, y_op, batch_size=256) 
the following exception is thrown:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "D:/Project/Python/kaggle/mnist/run.py", line 136, in &lt;module&gt;
    prediction = tl.utils.predict(sess, network, test_X, X, y_op, batch_size=256)
  File "D:\Anaconda3\lib\site-packages\tensorlayer\utils.py", line 296, in predict
    result = np.vstack((result, result_a))
  File "D:\Anaconda3\lib\site-packages\numpy\core\shape_base.py", line 234, in vstack
    return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
&lt;/denchmark-code&gt;

If set the batch_size to a factor of 28000, like 400. the problem goes away.
Looking into the utils.py, the exception is caused by the fact that tl.utils.predict tries to vstack the results from each batch. In my case, predict tries to divide the 28000 results into groups of 256, which left 96 extra results. When stacking the 96 results which has shape [1,96] with the other results with shape `[109,256]', the issue happens.
I think this issue this is important because some time the number test set is prime number.
	</description>
	<comments>
		<comment id='1' author='leftluoyi' date='2018-03-19T01:20:00Z'>
		the bug have been fixed
		</comment>
		<comment id='2' author='leftluoyi' date='2018-05-13T12:32:49Z'>
		&lt;denchmark-link:https://github.com/luomai&gt;@luomai&lt;/denchmark-link&gt;
 I think this issue hasn't solved yet. Now,  works only if  is equal to  or  is . When  is not  and is just equal to ,  that is not a multiple of  raises an error.
If we provide the argument  continuously, this function should be modified to account for the issue.
		</comment>
		<comment id='3' author='leftluoyi' date='2019-05-13T15:24:13Z'>
		feel free to reopen if you want to discuss
		</comment>
	</comments>
</bug>