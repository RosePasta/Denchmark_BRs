<bug id='641' author='ywangeq' open_date='2018-05-20T11:40:35Z' closed_time='2021-01-06T01:44:31Z'>
	<summary>Problem in the Deformable conv speed</summary>
	<description>
I am not sure, but i think the implement of the deformable conv is slower than offical version when i use it in the network
	</description>
	<comments>
		<comment id='1' author='ywangeq' date='2018-05-20T15:57:12Z'>
		Can you give some reproducible code?
It is hardly possible to do anything with your statement.
		</comment>
		<comment id='2' author='ywangeq' date='2018-05-23T06:50:24Z'>
		I don't find a good implement based on tensorflow. And I check the speed in the MXnet(the offical version). It is similar to the speed which is told in the paper. But when i use the deformable conv in the tensorlayer with my current work. My speed decrease from 11ms to 1s. Now i cannot give my code which related some works.
I am quite sorry. If i found some good implement, i will remind you!
Thank for you work
		</comment>
		<comment id='3' author='ywangeq' date='2018-05-23T08:54:54Z'>
		Im sorry, we can't fix an issue if you are not able to provide a simple dummy example.
The issue may be in the TF lib, now t necesseraly in TL.
I'm closing this issue.
		</comment>
		<comment id='4' author='ywangeq' date='2018-05-23T11:28:19Z'>
		If you are able to provide a simple example without any business logic &lt;denchmark-link:https://github.com/ywangeq&gt;@ywangeq&lt;/denchmark-link&gt;
 just a few layers and dummy random input, I'll be glad to give it a look &lt;denchmark-link:https://github.com/ywangeq&gt;@ywangeq&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ywangeq' date='2018-07-17T11:49:02Z'>
		&lt;denchmark-link:https://github.com/DEKHTIARJonathan&gt;@DEKHTIARJonathan&lt;/denchmark-link&gt;

I confirm that Deformable conv, for example:
offset1 = Conv2d(conv5, 18, (3, 3), (1, 1), act=None, padding='SAME'')
conv5 = DeformableConv2d(conv5, offset1, int(512 * filter_size_scale), (3, 3), act=tf.nn.leaky_relu, W_init=w_init, b_init=None'
is about 3+ times slower than simple conv:
conv5 = Conv2d(pool4, 512 * filter_size_scale, (3, 3), act=tf.nn.leaky_relu, W_init=w_init)
		</comment>
		<comment id='6' author='ywangeq' date='2018-07-17T12:11:51Z'>
		&lt;denchmark-link:https://github.com/UndeadBlow&gt;@UndeadBlow&lt;/denchmark-link&gt;
 I reopen the issue. Please provide a simple working example to show your point.
Just a 1 layer network and make it comparable with a non deformable conv. I can't test your assumption with your code.
&lt;denchmark-link:https://github.com/zsdonghao&gt;@zsdonghao&lt;/denchmark-link&gt;
 and me, we'll have a look at this as soon as you provide some working example showing your point.
		</comment>
		<comment id='7' author='ywangeq' date='2018-07-18T15:04:14Z'>
		&lt;denchmark-link:https://github.com/DEKHTIARJonathan&gt;@DEKHTIARJonathan&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorlayer/tensorlayer/files/2206276/arch.py.zip&gt;arch.py.zip&lt;/denchmark-link&gt;

No problem, here is not 1 layer, but simple Unet  - 1 layer in the end of encoder are conv and deform conv respectively (conv5 layer). Just one layer!
I got such results with that code:


It's about 20 times slower.
Original paper states that there should be not very significant slowdown. Definitely not in 20 times.
It's very critical, but for now I can't understand why it is so slow.
		</comment>
		<comment id='8' author='ywangeq' date='2018-09-14T02:21:02Z'>
		Any News?
		</comment>
		<comment id='9' author='ywangeq' date='2018-09-17T10:49:20Z'>
		&lt;denchmark-link:https://github.com/zsdonghao&gt;@zsdonghao&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/lgarithm&gt;@lgarithm&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='ywangeq' date='2018-09-17T10:51:54Z'>
		Hi, I don't have time to work on this issue at the moment, any contributions could be welcome.
		</comment>
		<comment id='11' author='ywangeq' date='2018-09-20T05:40:26Z'>
		import tensorflow as tf
import tensorlayer as tl
import time
import os
os.environ['CUDA_VISIBLE_DEVICES']='1'
slim=tf.contrib.slim
&lt;denchmark-code&gt;/users2/ml/jlong.yuan/config/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters


WARNING:tensorflow:From /users2/ml/jlong.yuan/config/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
&lt;/denchmark-code&gt;

a = tf.ones([1,10,10,1])
with tf.name_scope('standard'):
    b = slim.conv2d(a, num_outputs=2, kernel_size=[3,3], stride=1, scope='conv/test', weights_initializer=tf.ones_initializer(), activation_fn=None)

with tf.name_scope('temsorlayer'):
    c = tl.layers.InputLayer(a, name='input')
    offset1 = tl.layers.Conv2d(c, 18, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', name='offset1')
    c = tl.layers.DeformableConv2d(c, offset1, n_filter=2, filter_size=(3,3), W_init=tf.ones_initializer(), b_init=None)
&lt;denchmark-code&gt;[TL] InputLayer  input: (1, 10, 10, 1)
[TL] Conv2d offset1: n_filter: 18 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu
[TL] DeformableConv2d deformable_conv_2d: n_filter: 2, filter_size: (3, 3) act: No Activation
&lt;/denchmark-code&gt;

op1=tf.train.MomentumOptimizer(0.1, momentum=0.9)
op2=tf.train.MomentumOptimizer(0.1, momentum=0.9)
loss1= b - tf.zeros([1,10,10,2])
loss2= c.outputs - tf.to_float(tf.zeros([1,10,10,2]))
for i in tf.trainable_variables():
    print(i)
&lt;denchmark-code&gt;&lt;tf.Variable 'conv/test/weights:0' shape=(3, 3, 1, 2) dtype=float32_ref&gt;
&lt;tf.Variable 'conv/test/biases:0' shape=(2,) dtype=float32_ref&gt;
&lt;tf.Variable 'offset1/kernel:0' shape=(3, 3, 1, 18) dtype=float32_ref&gt;
&lt;tf.Variable 'offset1/bias:0' shape=(18,) dtype=float32_ref&gt;
&lt;tf.Variable 'deformable_conv_2d/W_deformableconv2d:0' shape=(1, 1, 9, 1, 2) dtype=float32_ref&gt;
&lt;/denchmark-code&gt;

grad1 = tf.gradients(loss1, tf.trainable_variables()[0])
grad2 = tf.gradients(loss2, tf.trainable_variables()[0:])
train_op1 =op1.apply_gradients(zip(grad1, [tf.trainable_variables()[0]]))
train_op2 =op2.apply_gradients(zip(grad2, tf.trainable_variables()[0:]))
sess=tf.Session()
sess.run(tf.global_variables_initializer())
s=time.time()

sess.run([train_op1])

e=time.time()
print(e-s)
&lt;denchmark-code&gt;0.11040878295898438
&lt;/denchmark-code&gt;

s=time.time()

sess.run([train_op2])

e=time.time()
print(e-s)
&lt;denchmark-code&gt;1.5291271209716797
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='ywangeq' date='2018-09-20T05:41:42Z'>
		&lt;denchmark-link:https://github.com/DEKHTIARJonathan&gt;@DEKHTIARJonathan&lt;/denchmark-link&gt;
 Hi, i just write a simple code to get this problems, so can you help me?
		</comment>
		<comment id='13' author='ywangeq' date='2018-09-20T05:50:46Z'>
		&lt;denchmark-link:https://github.com/jianlong-yuan&gt;@jianlong-yuan&lt;/denchmark-link&gt;

Im really sorry, I have no time to investigate the issue as &lt;denchmark-link:https://github.com/zsdonghao&gt;@zsdonghao&lt;/denchmark-link&gt;
...
If you ever find the issue, feel free to open a PR, we will happily merge your work ðŸ˜Š
		</comment>
	</comments>
</bug>