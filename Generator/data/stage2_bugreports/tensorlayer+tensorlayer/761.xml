<bug id='761' author='Lisupy' open_date='2018-07-31T03:46:46Z' closed_time='2019-05-13T15:30:23Z'>
	<summary>Tensor name Not found when restore tf slim pretrain model</summary>
	<description>
&lt;denchmark-h:h3&gt;New Issue Checklist&lt;/denchmark-h&gt;


 I have read the Contribution Guidelines
 I searched for existing GitHub issues

&lt;denchmark-h:h3&gt;Issue Description&lt;/denchmark-h&gt;

I encounted an Tensor not found error when running  example code.
It seems that the  use the layer name as an outter variable scope to the variable in slim models.
I down load the InceptionV3 model from &lt;denchmark-link:https://github.com/tensorflow/models/tree/master/research/slim&gt;https://github.com/tensorflow/models/tree/master/research/slim&lt;/denchmark-link&gt;
.
I have searched the previous version of   in  Tensorlayer such as  and I found that the previous version didn't add a that variable scope.
I also try another mothod by using var_list in tf.train.Saver(). Unfortunately, same exception raise again.
However, when I commented the code that introduce new variable_scope in SlimNetsLayer, I can successfully restore the slim pretrain model.
Is this a bug or there have another way to restore the slim model.
Best.
&lt;denchmark-h:h3&gt;Reproducible Code&lt;/denchmark-h&gt;


Ubunt 16.04
Tensorlayer 1.9.0
Python 3.6.4

code copy from &lt;denchmark-link:https://github.com/tensorlayer/tensorlayer/blob/master/example/tutorial_inceptionV3_tfslim.py&gt;tutorial_inceptionV3_tfslim.py&lt;/denchmark-link&gt;

import tensorflow as tf
import tensorflow.contrib.slim as slim
import tensorlayer as tl
from tensorflow.contrib.slim.python.slim.nets.inception_v3 import (inception_v3,
                                                                   inception_v3_base,
                                                                   inception_v3_arg_scope)
tf.logging.set_verbosity(tf.logging.DEBUG)
tl.logging.set_verbosity(tl.logging.DEBUG)

MODEL_PATH = os.path.join('models', 'inception_v3.ckpt')
with slim.arg_scope(inception_v3_arg_scope()):
    ## Alternatively, you should implement inception_v3 without TensorLayer as follow.
    # logits, end_points = inception_v3(X, num_classes=1001,
    #                                   is_training=False)
    network = tl.layers.SlimNetsLayer(
        prev_layer=net_in,
        slim_layer=inception_v3_base,
        slim_args={}
        name='InceptionV3'  # &lt;-- the name should be the same with the ckpt model
    )

sess = tf.InteractiveSession()
network.print_params(False)

saver = tf.train.Saver()
saver.restore(sess, MODEL_PATH)
print("Model Restored")

error:
NotFoundError (see above for traceback): Tensor name "InceptionV3/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta" not found in checkpoint files /models/inception_v3.ckpt

code using var_list
imports ...

# ... import SlimNetsLayer, same as prev code

sess = tf.InteractiveSession()

variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='InceptionV3')
var_map = {}
for item in variables:
    var_name = item.name
    key = var_name.split('/', 1)[-1]
    var_map[key] = item

saver = tf.train.Saver(var_map)
saver.restore(sess, MODEL_PATH)

error
NotFoundError (see above for traceback): Tensor name "InceptionV3/Conv2d_1a_3x3/BatchNorm/beta:0" not found in checkpoint files /models/inception_v3.ckpt

inspect of ckpt file

In [11]:  chkp.print_tensors_in_checkpoint_file("inception_v3.ckpt", tensor_name='', all_tensor_names=True, all_tensors=False)
tensor_name:  InceptionV3/AuxLogits/Conv2d_1b_1x1/BatchNorm/beta
tensor_name:  InceptionV3/AuxLogits/Conv2d_1b_1x1/BatchNorm/moving_mean
tensor_name:  InceptionV3/AuxLogits/Conv2d_1b_1x1/BatchNorm/moving_variance
tensor_name:  InceptionV3/AuxLogits/Conv2d_1b_1x1/weights
tensor_name:  InceptionV3/AuxLogits/Conv2d_2a_5x5/BatchNorm/beta
tensor_name:  InceptionV3/AuxLogits/Conv2d_2a_5x5/BatchNorm/moving_mean
...

	</description>
	<comments>
		<comment id='1' author='Lisupy' date='2018-11-24T11:11:19Z'>
		I encounter the problem just now, because I am learning how to use tensorlayer to combine tfslim. ðŸ˜ž .
		</comment>
		<comment id='2' author='Lisupy' date='2018-11-28T06:05:40Z'>
		&lt;denchmark-link:https://github.com/duohappy&gt;@duohappy&lt;/denchmark-link&gt;
  Try to describe your problem. I hope I can help you to find out the reason.
		</comment>
		<comment id='3' author='Lisupy' date='2019-05-13T15:30:23Z'>
		TF slim is removed by TF team, and we just release TL 2.0.0.
enjoy coding
		</comment>
	</comments>
</bug>