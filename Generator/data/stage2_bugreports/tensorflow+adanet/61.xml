<bug id='61' author='zjost' open_date='2019-01-23T21:06:32Z' closed_time='2019-08-22T15:50:41Z'>
	<summary>Training takes &amp;gt; 1 day on Boston Housing example using 8 GPU machine</summary>
	<description>
Using tf 1.9.0 and running example notebook.  I think the problem is in the &lt;denchmark-link:https://github.com/tensorflow/adanet/blob/master/adanet/examples/tutorials/adanet_objective.ipynb&gt;eval spec definition&lt;/denchmark-link&gt;
 which has this code section:
&lt;denchmark-code&gt;eval_spec = tf.estimator.EvalSpec(
      input_fn=input_fn("test", training=False, batch_size=BATCH_SIZE),
      steps=None,
      start_delay_secs=1,
      throttle_secs=1,
  )
&lt;/denchmark-code&gt;

This seems to cause evaluation every 1 second, and lead to a ginormous tf.events file (&gt;20 GB).
	</description>
	<comments>
		<comment id='1' author='zjost' date='2019-01-23T23:16:29Z'>
		Evaluation should only occur whenever a checkpoint gets written. However, if one of those causes a checkpoint to be written every second, then you will have the reported issue. Do you have any suggestions for resolving this? Perhaps adding a comment to the notebook? A PR is welcome.
		</comment>
		<comment id='2' author='zjost' date='2019-01-24T15:31:18Z'>
		When I changed throttle_secs to something like 30, that fixed the issue and allowed training to happen fairly quickly.  However, it seems from your notebook that the same problem didn't exist.  I wonder if something has changed with the TF versions that alters the behavior.
I'll also note that my training data curves had much less data too, not just the eval curves.  It's unclear to me how to separately control the tensorboard write frequency of training information vs eval information.
I'm happy to make a PR to change throttle_secs, but I'm not sure that's the right approach since the behavior seems different between TF versions.  What do you think?
		</comment>
		<comment id='3' author='zjost' date='2019-01-28T07:56:25Z'>
		I agree, there are many knobs you can tune. RunConfig.save_summary_steps controls the frequency of saving summaries (training information). The above fields in conjunction with save_checkpoints_steps control evaluation frequency, because an evaluation only occurs when a new checkpoint is created. And last but not least, RunConfig.log_step_count_steps controls the frequency of writing the global_steps/sec metric for TensorBoard.
If you think you have a fix, feel free to send a PR, and I'll have a look.
		</comment>
		<comment id='4' author='zjost' date='2019-01-29T15:09:13Z'>
		Cool, let me dig into it a bit and see if there's a sensible approach that works across versions (within reason).
		</comment>
		<comment id='5' author='zjost' date='2019-04-12T17:37:28Z'>
		I think root cause is explained in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17650&gt;this Issue&lt;/denchmark-link&gt;
.  Relevant quote related to changes to  between TF versions 1.9 and 1.10:

My understanding is it now runs evaluation via a tf.train.CheckpointSaverListener. As such, the evaluation frequency is determined by the saving frequency. You can see the new functionality here: https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/estimator/training.py#L667

When I run the example, the logs say:

INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 1 secs (eval_spec.throttle_secs) or training is finished.

Whereas the example notebook says:

INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5000 or save_checkpoints_secs None.

It seems TF versions &gt;= 1.10 use a different mechanism for deciding when to evaluate that's based on checkpoint writing rather than time.  Here are relevant code blocks for &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/estimator/training.py#L667&gt;1.10&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/estimator/training.py#L634&gt;1.9&lt;/denchmark-link&gt;

The same linked issue gives a work-around related to making the training input_fn finite, which will trigger the eval.  It doesn't seem worth the effort to implement this.  I recommend just changing the throttle_secs to something more sensible than 1 sec, such as 30 secs.  This shouldn't impact TF versions &gt;= 1.10 unless training of 5000 steps occurs faster than whatever the new value is, since evaluation would only occur if both a new checkpoint were available and the last evaluation occurred more than throttle_secs ago.
Would you support this change?
		</comment>
		<comment id='6' author='zjost' date='2019-04-12T20:50:00Z'>
		&lt;denchmark-link:https://github.com/zjost&gt;@zjost&lt;/denchmark-link&gt;
: If you have a fix for v1.9/1.10, feel free to send a PR. The team will have a look. Is this still an issue with adanet v0.6.1?
		</comment>
	</comments>
</bug>