<bug id='73' author='Chen94yue' open_date='2020-04-28T10:50:16Z' closed_time='2020-05-03T12:18:13Z'>
	<summary>Got &amp;lt;class 'NoneType'&amp;gt;, but numpy array, torch tensor, or caffe2 blob name are expected.</summary>
	<description>
Hi,
This error occurs when testing after one epoch.
Traceback (most recent call last):
File "main.py", line 116, in 
main(cfg)
File "main.py", line 96, in main
trainer.train(num_epochs=cfg.SOLVER.EPOCH)
File "/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/trainers/base_trainer.py", line 88, in train
if self.end_of_epoch_hook(self) is False:
File "/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/logging_presets.py", line 51, in actual_hook
best_epoch = self.save_models_and_eval(trainer, dataset_dict, model_folder, test_interval, tester, test_collate_fn)
File "/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/logging_presets.py", line 96, in save_models_and_eval
tester.test(dataset_dict, epoch, trainer.models["trunk"], trainer.models["embedder"], list(dataset_dict.keys()), collate_fn)
File "/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/testers/base_tester.py", line 205, in test
self.end_of_testing_hook(self) if self.end_of_testing_hook else logging.info(self.all_accuracies)
File "/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/logging_presets.py", line 64, in end_of_testing_hook
self.record_keeper.update_records(best, epoch, input_group_name_for_non_objects=self.record_group_name(tester, split_name))
File "/opt/conda/lib/python3.6/site-packages/record_keeper/record_keeper.py", line 39, in update_records
self.append_data(group_name, name_in_dict, input_obj, global_iteration)
File "/opt/conda/lib/python3.6/site-packages/record_keeper/record_keeper.py", line 29, in append_data
self.tensorboard_writer.add_scalar(tag_name, value, iteration)
File "/opt/conda/lib/python3.6/site-packages/torch/utils/tensorboard/writer.py", line 295, in add_scalar
scalar(tag, scalar_value), global_step, walltime)
File "/opt/conda/lib/python3.6/site-packages/torch/utils/tensorboard/summary.py", line 91, in scalar
scalar = make_np(scalar)
File "/opt/conda/lib/python3.6/site-packages/torch/utils/tensorboard/_convert_np.py", line 32, in make_np
'Got {}, but numpy array, torch tensor, or caffe2 blob name are expected.'.format(type(x)))
NotImplementedError: Got &lt;class 'NoneType'&gt;, but numpy array, torch tensor, or caffe2 blob name are expected.
My code is:
&lt;denchmark-link:https://user-images.githubusercontent.com/34304578/80479081-12f42c80-8981-11ea-8c11-4f5bb909d3d5.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Chen94yue' date='2020-04-28T10:58:07Z'>
		&lt;denchmark-link:https://github.com/Chen94yue&gt;@Chen94yue&lt;/denchmark-link&gt;
 Can you let me know which version of pytorch-metric-learning and record-keeper you're using?
		</comment>
		<comment id='2' author='Chen94yue' date='2020-04-28T14:19:01Z'>
		faiss-gpu                 1.6.3
pytorch                   1.2.0
pytorch-metric-learning   0.9.84
torchvision               0.4.0
record-keeper             0.9.24
		</comment>
		<comment id='3' author='Chen94yue' date='2020-04-28T14:23:17Z'>
		&lt;denchmark-link:https://github.com/Chen94yue&gt;@Chen94yue&lt;/denchmark-link&gt;
 Thanks, I think I know what the bug is. I'll try to work on this later today and upload a new version to pip.
		</comment>
		<comment id='4' author='Chen94yue' date='2020-04-28T22:28:02Z'>
		&lt;denchmark-link:https://github.com/Chen94yue&gt;@Chen94yue&lt;/denchmark-link&gt;
 Can you try  and let me know if the same bug occurs.
		</comment>
		<comment id='5' author='Chen94yue' date='2020-04-29T02:08:49Z'>
		thx, my bug fixed.
		</comment>
		<comment id='6' author='Chen94yue' date='2020-04-29T08:23:35Z'>
		Is this training result right? Why some value is nan:
epoch,AMI_level0,NMI_level0,mean_average_precision_at_r_level0,precision_at_1_level0,r_precision_level0,best_epoch,best_accuracy
1,0.03571634389980823,0.9380670339206018,nan,0.05411392405063291,nan,1,nan
2,0.04971500775107919,0.9391037759803879,nan,0.07361550632911393,nan,2,nan
3,0.05644224460528958,0.9395244619237163,nan,0.08536392405063291,nan,3,nan
4,0.06051057625383018,0.9398136875135318,nan,0.0939873417721519,nan,4,nan
5,0.06405937464798545,0.9400855015944669,nan,0.1002373417721519,nan,5,nan
The training log for one epoch is:
INFO:root:TRAINING EPOCH 4
total_loss=0.39131: 100%|#############################################################################################################################################################################| 4532/4532 [1:01:33&lt;00:00,  1.32it/s]
INFO:root:Evaluating epoch 4
INFO:root:Getting embeddings for the val split
100%|#####################################################################################################################################################################################################| 790/790 [04:09&lt;00:00,  3.77it/s]
INFO:root:Running UMAP on the val set
INFO:root:Finished UMAP
INFO:root:UMAP plot for the val split and label set UMAP_level0
INFO:root:Computing accuracy for the val split
INFO:root:running k-nn with k=2
INFO:root:embedding dimensionality is 512
INFO:root:running k-means clustering with k=15060
INFO:root:embedding dimensionality is 512
WARNING clustering 25280 points to 15060 centroids: please provide at least 587340 training points
/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/accuracy_calculator.py:33: RuntimeWarning: divide by zero encountered in true_divide
return np.mean(summed_precision_per_row / max_possible_matches_per_row)
/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/accuracy_calculator.py:33: RuntimeWarning: invalid value encountered in true_divide
return np.mean(summed_precision_per_row / max_possible_matches_per_row)
/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/accuracy_calculator.py:22: RuntimeWarning: divide by zero encountered in true_divide
return np.mean(matches_per_row / max_possible_matches_per_row)
/opt/conda/lib/python3.6/site-packages/pytorch_metric_learning/utils/accuracy_calculator.py:22: RuntimeWarning: invalid value encountered in true_divide
return np.mean(matches_per_row / max_possible_matches_per_row)
INFO:root:New best accuracy!
		</comment>
		<comment id='7' author='Chen94yue' date='2020-04-29T08:29:52Z'>
		This is occurring because mean_average_precision_at_r and r_precision are expecting each sample to have at least 1 other sample of the same class in the dataset. If there are 0 other samples of the same class, then a division by 0 occurs. In other words, when there are classes with just 1 sample, these metrics will return nan. In contrast, precision_at_1 will just give those samples a score of 0.
I think the best solution is to make mean_average_precision_at_r and r_precision ignore samples that are the only one of their kind. I'll make a separate issue to fix this.
		</comment>
		<comment id='8' author='Chen94yue' date='2020-04-29T08:35:37Z'>
		In the meantime (before I fix this issue), you can try using one of the other metrics as the "primary metric" for keeping track of the best model.
hooks = logging_presets.get_hook_container(record_keeper, primary_metric="AMI")
		</comment>
		<comment id='9' author='Chen94yue' date='2020-04-29T08:53:34Z'>
		By the way, if you want to load models to resume training, you can try using &lt;denchmark-link:https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/src/pytorch_metric_learning/utils/logging_presets.py#L77&gt;this function&lt;/denchmark-link&gt;
 like this:
# Put this code after the trainer initialization.
# Also I think your models have to not be wrapped in dataparallel for the loading to work.
start_epoch = hooks.load_latest_saved_models(trainer, model_folder, device)

# set to dataparallel
for k, v in models.items():
    models[k] = torch.nn.DataParallel(v)

trainer.train(start_epoch, num_epochs)
However, I think the  calculation will be thrown off by the existing NaNs in the logs.db file, so if you have &lt;denchmark-link:https://sqlitebrowser.org/&gt;DB Browser&lt;/denchmark-link&gt;
 (open source software), you can open that db file and get rid of the NaNs.
Obviously this is hacky, I'm just mentioning it because I noticed in your post that 1 epoch took 1 hour, so I figure you might not want to restart training from scratch.
		</comment>
		<comment id='10' author='Chen94yue' date='2020-04-30T06:22:27Z'>
		Thanks! ðŸ˜Š
		</comment>
		<comment id='11' author='Chen94yue' date='2020-05-03T12:18:13Z'>
		The latest version (0.9.85) fixes the NaN bug.
		</comment>
	</comments>
</bug>