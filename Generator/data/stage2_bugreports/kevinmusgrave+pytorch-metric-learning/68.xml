<bug id='68' author='wconnell' open_date='2020-04-21T19:22:49Z' closed_time='2020-05-01T18:00:31Z'>
	<summary>hierarchical labels training / testing</summary>
	<description>
For label_hierarchy_level parameter use in trainer and tester, should passed dataset __getitem__ return a 2D array, with column indices representing labels?
I am doing this and passing trainer(label_hierarchy_level=0) and encountering a RunTimeError about mismatched tensor sizes (2) and (64) [batch size] in get_all_triplets_indices(labels, ref_labels). Can't figure out if I am mispreprsenting data labels or if there is a bug.
	</description>
	<comments>
		<comment id='1' author='wconnell' date='2020-04-21T20:06:55Z'>
		Something like this works for __getitem___:
def __getitem___(self, index):
    return img, np.array([label1, label2])
So it's actually a 1d array, but it becomes 2d when batched by the dataloader. Also, returning a list  doesn't work right now because the &lt;denchmark-link:https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/src/pytorch_metric_learning/utils/common_functions.py#L64&gt;label processing function&lt;/denchmark-link&gt;
 is expecting a numpy array. (Actually this should be easy to fix. I think the &lt;denchmark-link:https://github.com/KevinMusgrave/pytorch-metric-learning/blob/master/src/pytorch_metric_learning/utils/common_functions.py#L34&gt;to_numpy&lt;/denchmark-link&gt;
 function just needs to catch list types in addition to tuples.)
Note that you can also set label_hierarchy_level to "all" or to a list of integers which will be used to slice the columns of each batch of labels. However, none of the existing trainers are compatible with these settings (i.e. you'd have to write a custom trainer that has a method for calculating the loss based on multiple labels etc.)
But the testers should work with the "all" and list options. Edit: just found out that the list option breaks the HookContainer database write due to having a bracket in the sqlite table name, so I'll need to fix that....
		</comment>
		<comment id='2' author='wconnell' date='2020-05-01T16:43:04Z'>
		If labels are hierarchical, GlobalEmbeddingSpaceTester does the same as WithSameParentLabelTester? Is there redundancy here?
		</comment>
		<comment id='3' author='wconnell' date='2020-05-01T17:56:41Z'>
		These fucking spam bots are driving me crazy!
&lt;denchmark-link:https://github.com/wconnell&gt;@wconnell&lt;/denchmark-link&gt;
 WithSameParentLabelTester is supposed to do something different. &lt;denchmark-link:https://kevinmusgrave.github.io/pytorch-metric-learning/testers/#withsameparentlabeltester&gt;The example in the documentation&lt;/denchmark-link&gt;
 basically explains it.
As a more specific example, consider a dataset with 1000 samples divided as follows:

400 dogs (animal)
300 cats (animal)
200 cars (vehicle)
100 trucks (vehicle)

GlobalEmbeddingSpaceTester:

The "level 0" accuracy for a "dog" datapoint will be computed by considering all 999 other samples, using the {dog, cat, cars, trucks} labels.
The "level 1" accuracy will also consider all 999 other samples, but using the {animal, vehicle} labels.

WithSameParentLabelTester:

The "level 0" accuracy for a "dog" datapoint will be computed by considering only the 699 other samples that are "animals".
There is no "level 1" accuracy, because level 1 has no parent labels (i.e. there's no level 2)

I haven't used WithSameParentLabelTester in a long time, and there isn't a test for it at the moment, so I can't guarantee that it works.
		</comment>
		<comment id='4' author='wconnell' date='2020-05-01T18:00:31Z'>
		Let's close this and duplicate in a new issue, I dont know why this is getting spammed.
I see, each sample does not require a hierarchical label in WithSameParentLabelTester.
Ok I'll follow up later, I think it's broken.
		</comment>
		<comment id='5' author='wconnell' date='2020-05-02T03:01:32Z'>
		&lt;denchmark-link:https://github.com/wconnell&gt;@wconnell&lt;/denchmark-link&gt;
 In v0.9.85.dev2 I fixed the bugs I mentioned above. I also fixed some other label hierarchy bugs, and WithSameParentLabelTester should at least run now.
		</comment>
	</comments>
</bug>