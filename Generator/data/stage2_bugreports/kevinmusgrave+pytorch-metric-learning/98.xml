<bug id='98' author='jac99' open_date='2020-05-14T15:58:25Z' closed_time='2020-05-15T19:04:55Z'>
	<summary>MarginLoss produces very large loss if there are no active pairs</summary>
	<description>
It may happen, that late in the training process both positive and negative distances in all triplets in some batch fall below thresholds. In such case MarginLoss produces very large loss (like 997187911680.0).  This breaks computation of batch statistics, such as a mean loss per batch, which I use in my code.
I looked into MarginLoss code and this is because when pair_count (number of active pairs) becomes zero,  total loss is equal to beta_reg_loss divided by 1e-16. Which produces a very large number. This is done by below piece of code:
&lt;denchmark-code&gt;        pair_count = self.num_pos_pairs + self.num_neg_pairs 

        return (torch.sum(pos_loss + neg_loss) + beta_reg_loss) / (pair_count + 1e-16)
&lt;/denchmark-code&gt;

When pair_count is zero, I think it's more logical to return loss equal to zero. Not some very large number. Maybe MarginLoss code could be amended to something like:
&lt;denchmark-code&gt;        return (torch.sum(pos_loss + neg_loss) + beta_reg_loss) / (max(pair_count,1))
&lt;/denchmark-code&gt;

This would prevent returning very large loss, when pair_count is zero. Or maybe more appropriate would be:
&lt;denchmark-code&gt;        if pair_count &gt;= 1:
              return (torch.sum(pos_loss + neg_loss) + beta_reg_loss) / pair_count
       else:
              return ...grad enabled tensor set to zero (or something that doesn't break loss.backward()...
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jac99' date='2020-05-14T16:25:41Z'>
		The if/else looks good. We can just return 0 in the else statement, because the base class takes care of the loss.backward problem you mentioned.
		</comment>
		<comment id='2' author='jac99' date='2020-05-14T19:11:46Z'>
		&lt;denchmark-link:https://github.com/jac99&gt;@jac99&lt;/denchmark-link&gt;
 I made the changes you suggested, plus a couple others. See &lt;denchmark-link:https://github.com/KevinMusgrave/pytorch-metric-learning/commit/2dd61bb34c3da8b13c6ce974a5a67cae0c788483&gt;this commit&lt;/denchmark-link&gt;
 to view the changes.
The changes are available in v0.9.86.dev3:
&lt;denchmark-code&gt;pip install pytorch-metric-learning==0.9.86.dev3
&lt;/denchmark-code&gt;

Let me know if it works
		</comment>
		<comment id='3' author='jac99' date='2020-05-15T13:35:46Z'>
		Hi Kevin, thanks for quick answer. The changes look good and I've re-run the code. Good idea to add margin_loss and beta_reg_loss to recordable attributes. This allows observing individual loss components.
However when pair_count &gt;= 1, margin_loss and beta_reg_loss recordable attributes are one-element tensors. But when pair_count=0, margin_loss and beta_reg_loss recordable attributes are numbers (not tensors). This break my code to calculate per-batch statistics.
I added a simple fix in my code to handle both cases correctly and re-run the training loop. I'll let you known if everything finishes successfully.
Maybe it's worth to consider data type od recordable attributes? My feeling is, that these attributes are used for monitoring of the training process or displaying statistics about dynamics of the training process. So they should be all numbers not tensors. Currently, some recordable attributes are numbers (like num_zero_triplets in TripletMarginLoss) and some are grad-enabled tensors. I'm not sure if this is not causing some extra-memory consumption or other performance issues to keep track of computation graphs for each of these attributes.
		</comment>
		<comment id='4' author='jac99' date='2020-05-15T15:32:12Z'>
		In my logging code I &lt;denchmark-link:https://github.com/KevinMusgrave/record-keeper/blob/master/record_keeper/utils.py#L39&gt;detach if necessary&lt;/denchmark-link&gt;
. I suppose we could move some of that logic into the "recordable attributes" part of this library, though right now, "recordable attributes" just refers to a list of strings that correspond to object attributes.
		</comment>
		<comment id='5' author='jac99' date='2020-05-15T19:04:54Z'>
		Closing this issue as its now in the latest version 0.9.86. I made a &lt;denchmark-link:https://github.com/KevinMusgrave/pytorch-metric-learning/issues/101&gt;separate issue&lt;/denchmark-link&gt;
 for the data types of recordable attributes, so we can continue the discussion there.
		</comment>
	</comments>
</bug>