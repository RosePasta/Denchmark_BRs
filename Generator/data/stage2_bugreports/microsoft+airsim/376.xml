<bug id='376' author='Mayankm96' open_date='2017-07-26T17:01:35Z' closed_time='2017-10-05T19:13:06Z'>
	<summary>Quantization in the processing of depth images from the simulator?</summary>
	<description>
Hey!
So I have been trying to write my own ros wrapper to communicate with the AirSim (a bit of help from &lt;denchmark-link:https://github.com/marcelinomalmeidan/publishAirsimImgs&gt;here&lt;/denchmark-link&gt;
). While I am processing the depth image using opencv and viewing the output using image_view, I am seeing quantization occurring over the image. Is it due to conversion of float to uchar in the ?
A snippet of the code for processing the depth (similar to the function &lt;denchmark-link:https://github.com/Microsoft/AirSim/blob/master/Examples/StereoImageGenerator.hpp&gt;convertToPlanDepth&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;cv::Mat convertToPlaneDepth(const cv::Mat&amp; input, float scale, float f = 320){
    int width = input.cols;
    int height = input.rows;

    float center_i = width / 2.0f - 1;
    float center_j = height / 2.0f - 1;

    cv::Mat output = cv::Mat(height, width, CV_32FC1);
    cv::Mat depth_float;
    input.convertTo(depth_float, CV_32FC1, scale);

    for (int i = 0; i &lt; width; ++i) {
        for (int j = 0; j &lt; height; ++j) {
            float dist = std::sqrt((i - center_i)*(i - center_i) + (j - center_j)*(j - center_j));
            float denom = (dist / f);
            denom *= denom;
            denom = std::sqrt(1 + denom);
            output.at&lt;float&gt;(j, i) = input.at&lt;float&gt;(j, i) / denom;
        }
    }
    return output;
}
&lt;/denchmark-code&gt;

where input = cv::imdecode(response.at(2).image_data, CV_LOAD_IMAGE_GRAYSCALE).
&lt;denchmark-link:https://user-images.githubusercontent.com/12863862/28633614-ba96024a-7234-11e7-9a48-5060b36558c3.jpg&gt;&lt;/denchmark-link&gt;
.
Also for creating point clouds, do the camera parameters change if you are taking a 720p form the depth, and rgb rendered targets because I tried creating a point cloud from this depth image and it looked different.
Thanks for your help!
	</description>
	<comments>
		<comment id='1' author='Mayankm96' date='2017-07-27T05:54:33Z'>
		Unreal generates the ground truth perspective depth image. The value of each pixel is a depth value from 0 to 2^24-1. However as this range is too large, the depth map would end up looking like all white. So we clip the depth at 10,000 cm and then normalize it from 0.0 to 1.0 by dividing it by 10000. I'm not sure if this is the best way to handle this so please feel free to let us know better alternatives.
I think what you need is depth from the plan. To get the planner depth you need to do additional processing. One attempt to do this  can be &lt;denchmark-link:https://github.com/Microsoft/AirSim/blob/master/Examples/StereoImageGenerator.hpp#L200&gt;found here&lt;/denchmark-link&gt;
). However I am not sure if its right. Especially I don't know how parameter f was calculated. If you know correct way to convert to planner depth given FOV and resolution of image, let us know.
		</comment>
		<comment id='2' author='Mayankm96' date='2017-07-29T19:59:23Z'>
		Well the image I shared above is the one from the convertToPlanDepth() function. I published both the raw (from the airsim) and the one after this processing to see the difference between the two. I am now confused on the way the processed one always look bright at the center and becomes darker as we proceed towards the boundary while the one from the simulator looks "more accurate".
At the same time, I might be confusing the meaning of a depth image with the real depth/distance of the objects from the camera.
The unprocessed depth image (from simulator):
&lt;denchmark-link:https://user-images.githubusercontent.com/12863862/28747853-076df610-74a9-11e7-84c6-81666dd01eb5.jpg&gt;&lt;/denchmark-link&gt;

The processed depth image (after processing from the ):
&lt;denchmark-link:https://user-images.githubusercontent.com/12863862/28747856-24a3eaf0-74a9-11e7-8fe9-eb6adccc9f8b.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Mayankm96' date='2017-07-31T09:21:39Z'>
		I was going over convertToPlanDepth() implementation with one of my colleague and I think current one is wrong. We have derived new equation that looks more right and I'll probably re-check that and implement it around end of week. Meanwhile, if you are familiar with computer vision algos for how to convert perspective projection to planner projection given FOV and resolution, let us know your suggestions as well!
		</comment>
		<comment id='4' author='Mayankm96' date='2017-10-05T19:13:06Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 I guess this issue is resolved now due to recent changes in the code. I'll be closing it now.
		</comment>
	</comments>
</bug>