<bug id='491' author='hngenc' open_date='2017-09-27T21:35:43Z' closed_time='2017-12-16T05:21:14Z'>
	<summary>Images from simGetImages have low color range</summary>
	<description>
Images obtained using the simGetImages function show much less color range than they do in the Unreal Editor. Here's an example below:


This is how the DepthVis image appears in the Unreal Editor:



This is how the same image appears when saved with simGetImages:



I've been trying to find the cause of this effect. It appears that the raw pixel values that AirSim gets from Unreal in the RenderRequest.cpp file show this restricted color range. So this would seem to be an Unreal issue rather than an AirSim issue, but previous versions of AirSim did not have this problem, so I assume that something must have changed on AirSim's end to cause this.
	</description>
	<comments>
		<comment id='1' author='hngenc' date='2017-09-28T09:21:57Z'>
		I think this is because how scene capture parameters are set. I've seen this previously as well when gamma was set to low. You might want to play with capture settings:&lt;denchmark-link:https://github.com/Microsoft/AirSim/blob/master/docs/settings.md#image-capture-settings&gt;https://github.com/Microsoft/AirSim/blob/master/docs/settings.md#image-capture-settings&lt;/denchmark-link&gt;

However you are correct that we need to figure out a way to do this automatically.
		</comment>
		<comment id='2' author='hngenc' date='2017-09-28T09:58:51Z'>
		Concerning this, can anyone tell me why &lt;denchmark-link:https://github.com/Microsoft/AirSim/issues/478&gt;I am just seeing the initial 180°?&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='hngenc' date='2017-09-28T19:37:59Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 Do you know if gamma values affect the DepthMeters images as well?
&lt;denchmark-link:https://github.com/Kjell-K&gt;@Kjell-K&lt;/denchmark-link&gt;
 I've also noticed the issue you described. Any solution would be hugely appreciated.
		</comment>
		<comment id='4' author='hngenc' date='2017-09-28T19:49:31Z'>
		&lt;denchmark-link:https://github.com/hngenc&gt;@hngenc&lt;/denchmark-link&gt;
 I have your issue as well by the way. I use it as gray image decoded but the low range in data is occurring as well.
And no my issue post remains uncommented. As work around I rotated the entire map in Unreal Editor by an angle, so that I have the 180° with DepthVis in the direction of interest. Very unsatisfying though.
		</comment>
		<comment id='5' author='hngenc' date='2017-09-28T20:05:11Z'>
		I can confirm that this low pixel range also occurs for DepthMeters images. For example, in the image below, both regions marked red show the exact same distance (17m) when they should show slightly different distances because of the angle at which the drone is facing them:
&lt;denchmark-link:https://user-images.githubusercontent.com/13737642/30987877-16fda62c-a45e-11e7-840b-cc04772c24ed.png&gt;&lt;/denchmark-link&gt;

This makes it impossible for me to create point-clouds from depth images whereas I was able to do so in previous versions of AirSim.
Edit:
Also, &lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
, none of the capture settings, including Target Gamma, seem to have any effect on the color output of DepthVis or DepthMeters.
		</comment>
		<comment id='6' author='hngenc' date='2017-09-28T22:13:15Z'>
		&lt;denchmark-link:https://github.com/hngenc&gt;@hngenc&lt;/denchmark-link&gt;
 DepthMeters should not be effected by gamma. Its direct float values (not descretized pixel value). How are you looking at DepthMeters image? If you are converting to RGB first then you won't get accurate result. Generally, you might want to save DepthMeters as just float matrix in binary format and then read out the value of cells.
		</comment>
		<comment id='7' author='hngenc' date='2017-09-28T22:41:59Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 I get DepthMeters as direct float values. For the post above, I converted the float values to a grayscale image to help visualize the problem. But when creating point clouds, I only use the float values.
However, the float values simply aren't correct. Their range is broken. Let me use the image below to illustrate:
&lt;denchmark-link:https://user-images.githubusercontent.com/13737642/30987877-16fda62c-a45e-11e7-840b-cc04772c24ed.png&gt;&lt;/denchmark-link&gt;

On AirSim's current version, the difference in depth between the two red regions is . But when I revert to commit &lt;denchmark-link:https://github.com/microsoft/AirSim/commit/8820a7fdd811d86aba5f7c9ded3d8eb9f93b6f16&gt;8820a7f&lt;/denchmark-link&gt;
, the difference in depth between the two red regions is , as it should be.
		</comment>
		<comment id='8' author='hngenc' date='2017-09-29T00:55:15Z'>
		I've found a solution to the problem of depth images not being accurate. Navigate to the HUDAssets folder and replace either  or  with the following asset file:  &lt;denchmark-link:https://github.com/Microsoft/AirSim/files/1342742/DepthMapMaterial.zip&gt;DepthMapMaterial.zip&lt;/denchmark-link&gt;
. Every pixel in your new depth images will be a float representing the depth of the pixel in meters.
&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 I can close the issue now, but I think it would be better to wait until the broken material assets in the main branch are replaced before the issue is closed.
		</comment>
		<comment id='9' author='hngenc' date='2017-09-29T08:07:25Z'>
		Unreal can't import .uasset file by itself. You will have to zip AirSim folder and attach it. Alternatively, could you please post screenshot of asset? May be short description?
One thing I do want to point out is that the depth in meters is in camera plan. This means that depth you get is same for all points in a plan that is parallel to camera. This is unlike perspective projection (i.e. shoot ray from camera to point and get distance). This is done intentionally because this is what stereo matching algorithms would generate. If you get depth in perspective projection and try to feed it to ROS for reconstruction then you would get distortion.
		</comment>
		<comment id='10' author='hngenc' date='2017-09-29T08:29:06Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/hngenc&gt;@hngenc&lt;/denchmark-link&gt;
 Does this solve &lt;denchmark-link:https://github.com/Microsoft/AirSim/issues/478&gt;#478&lt;/denchmark-link&gt;
 as well?
Cause otherwise you yaw and have the extreme issue of zero data range again.
		</comment>
		<comment id='11' author='hngenc' date='2017-09-29T19:14:43Z'>
		I also thought that the DepthMeters image's color range is too low for lower values (i.e., near), which is important for purposes such as autonomous navigation. For example, the following is what I got as-is, where it is nearly impossible to tell what's right in front of the car:
&lt;denchmark-link:https://user-images.githubusercontent.com/13685803/31031707-706c82ae-a527-11e7-9a91-ed3f2376da19.png&gt;&lt;/denchmark-link&gt;

My work-around is to do a log transformation of the depth information received, so as to stretch low-value depths, so that I can get better depth resolution for those that are near. The following shows that I am now able to see much of the frontend of the car.
&lt;denchmark-link:https://user-images.githubusercontent.com/13685803/31031808-c53b73ee-a527-11e7-95bf-be9514bae587.png&gt;&lt;/denchmark-link&gt;

The log transformation does help, but nonetheless it would be nice if the raw depth information could have more range at low values, so that I have more depth resolution to work with for dealing with something like collision avoidance, etc.
		</comment>
		<comment id='12' author='hngenc' date='2017-09-29T21:32:34Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;
 Unreal may not be able to explicitly import the assets, but when I manually copied the asset to the HUDAssets folder using Windows File Explorer, the Unreal Editor detected it. In any case, here's a screenshot:
&lt;denchmark-link:https://user-images.githubusercontent.com/13737642/31036537-4b745958-a532-11e7-80d2-abde46b66d15.png&gt;&lt;/denchmark-link&gt;

You may notice that the .uasset is nearly identical to the old one in commit  &lt;denchmark-link:https://github.com/microsoft/AirSim/commit/8820a7fdd811d86aba5f7c9ded3d8eb9f93b6f16&gt;8820a7f&lt;/denchmark-link&gt;
. The only difference is that I multiply the final value by 100 to obtain the depth in meters. One drawback of the .uasset is that pixel depths are capped at a maximum of 100 m.
I believe the code I posted (or rather copied) does  provide depth in the camera plane. However, I use a ROS package called &lt;denchmark-link:http://wiki.ros.org/depth_image_proc&gt;depth_image_proc&lt;/denchmark-link&gt;
 to generate point-clouds and they appear perfect as far as I can see. Perhaps depth_image_proc corrects for camera distortions on its own.
&lt;denchmark-link:https://github.com/Kjell-K&gt;@Kjell-K&lt;/denchmark-link&gt;
 I can confirm that this solves the  &gt;180 degree yaw issue. But you shouldn't use the code I posted if you absolutely  planar depth images, as discussed above.
&lt;denchmark-link:https://github.com/kaihuchen&gt;@kaihuchen&lt;/denchmark-link&gt;
 The log transformation is a great idea! I wish I had thought of it.
		</comment>
		<comment id='13' author='hngenc' date='2017-09-30T09:31:27Z'>
		ok... given your feedback I have done some refactoring (code is updated in master branch):

Rename current DepthMeters to DepthPlanner.
Add DepthPerspective mode.
Use black-white gradient in depth visualization.

The DepthPerspective mode is bit different than your above version. The above version uses scene depth  which gives depth as a number between 0 to 2^24 but not well documented units. There is another way to get perspective depth that gives depth in meters. So I've used that way for DepthPerspective mode. Here's &lt;denchmark-link:https://github.com/Microsoft/AirSim/blob/master/Unreal/Plugins/AirSim/Content/HUDAssets/DepthPerspectiveMaterial.uasset&gt;the asset&lt;/denchmark-link&gt;
 for this.
One other thing is that you don't need clamp - it actually causes all depth to max out after 100m. If you use image API and get depth as float then clamp is not needed. But if you do depth visualization on screen then clamping is useful.
Anyway, it would be great if you can try out new DepthPerspective mode in new version and see if works as expected in your scenario. I've updated &lt;denchmark-link:https://github.com/Microsoft/AirSim/blob/master/docs/image_apis.md#depth-image&gt;doc here&lt;/denchmark-link&gt;
 as well.
		</comment>
		<comment id='14' author='hngenc' date='2017-09-30T18:57:10Z'>
		&lt;denchmark-link:https://github.com/sytelus&gt;@sytelus&lt;/denchmark-link&gt;

Tested DepthPerspective, and it seems to work just fine. I have found another depth problem but it does not seem to be specific to DepthPerspective, so I will report it separately.
		</comment>
		<comment id='15' author='hngenc' date='2017-10-03T11:42:03Z'>
		With the fix of &lt;denchmark-link:https://github.com/microsoft/AirSim/issues/500&gt;#500&lt;/denchmark-link&gt;
 I am back to the problem of low color range and in this case black and white values.
&lt;denchmark-link:https://user-images.githubusercontent.com/29546195/31123519-90308902-a840-11e7-83ed-ad39a8c70996.PNG&gt;&lt;/denchmark-link&gt;

I extract the image by following the example navigate.py
		</comment>
		<comment id='16' author='hngenc' date='2017-12-11T11:08:54Z'>
		Anyone knows how can I save a depth image with the same result as seen in Unreal?
		</comment>
		<comment id='17' author='hngenc' date='2017-12-11T13:17:43Z'>
		The bug is fixed but you have to increase the intensity. I also invert the range so that dark is near and white is far (As in Unreal window).
With this function, you will get the DepthImage as displayed in the Unreal window (just a bit bitter even).
&lt;denchmark-code&gt;    def getScreenDepthVis(self):

        responses = self.simGetImages([ImageRequest(0, AirSimImageType.DepthPerspective, True, False)])
        img1d = np.array(responses[0].image_data_float, dtype=np.float)
        img1d = 255/np.maximum(np.ones(img1d.size), img1d)
        img2d = np.reshape(img1d, (responses[0].height, responses[0].width))
        
        image = np.invert(np.array(Image.fromarray(img2d.astype(np.uint8), mode='L')))
        
        factor = 10
        maxIntensity = 255.0 # depends on dtype of image data
        
        # Decrease intensity such that dark pixels become much darker, bright pixels become slightly dark 
        newImage1 = (maxIntensity)*(image/maxIntensity)**factor
        newImage1 = array(newImage1,dtype=uint8)
        
        #cv2.imshow("Test", newImage1)
        #cv2.waitKey(0)
        
        return newImage1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='18' author='hngenc' date='2017-12-12T10:53:56Z'>
		Thanks. I think this issue is solved and recommend this issue to be closed. :)
		</comment>
	</comments>
</bug>