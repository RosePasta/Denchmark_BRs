<bug id='121' author='isaacmg' open_date='2020-08-19T15:41:11Z' closed_time='2020-10-06T18:25:24Z'>
	<summary>DA-RNN still does not work on GPU</summary>
	<description>
The DA-RNN model currently encounters an error when it runs on the GPU devices (at least on Colab) This is currently blocking work on several things. The goal is to fix the model so it no longer fails. When this all said and done this &lt;denchmark-link:https://colab.research.google.com/drive/1mbn777MigWa-Q6WbUnhZ0OxVTHcO7lee&gt;notebook&lt;/denchmark-link&gt;
 should be able to run.
	</description>
	<comments>
		<comment id='1' author='isaacmg' date='2020-09-10T02:51:03Z'>
		I'll take this on.
		</comment>
		<comment id='2' author='isaacmg' date='2020-09-14T17:55:03Z'>
		This actually seems to be working now. I don't know why.
		</comment>
		<comment id='3' author='isaacmg' date='2020-09-14T21:12:20Z'>
		NVM hit the error
&lt;denchmark-code&gt;wandb: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.
Process Process-4:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_agent.py", line 62, in _start
    function()
  File "&lt;ipython-input-10-e5b868f37696&gt;", line 37, in &lt;lambda&gt;
    wandb.agent(sweep_full, lambda:train_function("PyTorch", make_config_file(file_path_name, gage_id, station_id, correct_file, prev_config["pretrained_rivers"])))
  File "/content/flow-forecast/flood_forecast/trainer.py", line 45, in train_function
    {})
  File "/content/flow-forecast/flood_forecast/evaluator.py", line 119, in evaluate_model
    model, test_data, inference_params["datetime_start"]
  File "/content/flow-forecast/flood_forecast/explain_model_output.py", line 72, in deep_explain_model_summary_plot
    shap_values = deep_explainer.shap_values(background_tensor)
  File "/usr/local/lib/python3.6/dist-packages/shap/explainers/deep/__init__.py", line 119, in shap_values
    return self.explainer.shap_values(X, ranked_outputs, output_rank_order, check_additivity=check_additivity)
  File "/usr/local/lib/python3.6/dist-packages/shap/explainers/deep/deep_pytorch.py", line 184, in shap_values
    sample_phis = self.gradient(feature_ind, joint_x)
  File "/usr/local/lib/python3.6/dist-packages/shap/explainers/deep/deep_pytorch.py", line 122, in gradient
    allow_unused=True)[0]
  File "/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py", line 192, in grad
    inputs, allow_unused)
RuntimeError: cudnn RNN backward can only be called in training mode
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/slundberg/shap/issues/1057&gt;slundberg/shap#1057&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='isaacmg' date='2020-09-16T02:14:21Z'>
		The solution to this for now, a temporary work-around, is to just not plot anything with shap.
		</comment>
	</comments>
</bug>