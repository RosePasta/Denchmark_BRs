<bug id='145' author='isaacmg' open_date='2020-09-09T21:10:20Z' closed_time='2020-09-10T02:47:56Z'>
	<summary>Weird size mismatch</summary>
	<description>
So I got this error while running a sweep.
&lt;denchmark-code&gt;    wandb.agent(sweep_id, lambda:train_function("PyTorch", make_config()))
  File "/kaggle/working/flow-forecast/flood_forecast/trainer.py", line 37, in train_function
    train_transformer_style(trained_model, params["training_params"], params["forward_params"])
  File "/kaggle/working/flow-forecast/flood_forecast/pytorch_training.py", line 92, in train_transformer_style
    forward_params)
  File "/kaggle/working/flow-forecast/flood_forecast/pytorch_training.py", line 166, in torch_single_train
    output = model.model(src, **forward_params)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/kaggle/working/flow-forecast/flood_forecast/transformer_xl/transformer_basic.py", line 122, in forward
    x = self.out_length_lay(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py", line 1612, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [10 x 5], m2: [10 x 1] at /opt/conda/conda-bld/pytorch_1591914794252/work/aten/src/TH/generic/THTensorMath.cpp:41
&lt;/denchmark-code&gt;

coNFI G sweep
&lt;denchmark-code&gt;andb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.9.5
    framework: torch
    is_jupyter_run: true
    is_kaggle_kernel: true
    python_version: 3.7.6
batch_size:
  desc: null
  value: 10
dropout:
  desc: null
  value: 0.1
forecast_history:
  desc: null
  value: 10
lr:
  desc: null
  value: 0.001
meta_data:
  desc: null
  value: true
number_encoder_layers:
  desc: null
  value: 1
out_seq_length:
  desc: null
  value: 1
use_mask:
  desc: null
  value: true

interpolate should be below
Now loading and scaling ma_test_data.csv
interpolate should be below
Now loading and scaling ma_test_data.csv
interpolate should be below
Now loading and scaling ma_test_data.csv
Using Wandb config:
wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.9.5
    framework: torch
    is_jupyter_run: true
    is_kaggle_kernel: true
    python_version: 3.7.6
batch_size:
  desc: null
  value: 10
dropout:
  desc: null
  value: 0.1
forecast_history:
  desc: null
  value: 10
lr:
  desc: null
  value: 0.001
meta_data:
  desc: null
  value: true
number_encoder_layers:
  desc: null
  value: 1
out_seq_length:
  desc: null
  value: 1
use_mask:
  desc: null
  value: true

Torch is using cpu
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='isaacmg' date='2020-09-10T02:47:55Z'>
		Nevermind this was related to a problem with the sweep config. If anyone has the same issue seq_length ==  "forecast_history . Therefore wandb_config["forecast_history"] should be used in all the relevant places in the documents and so forth.
&lt;denchmark-code&gt;def make_config(weight_path=None):
    run = wandb.init(project="covid_forecast", entity="covid")
    print(wandb.config)
    wandb_config = wandb.config
    full_config = {                 
    "model_name": "CustomTransformerDecoder",
    "model_type": "PyTorch",
    "model_params": {
      "n_time_series":9,
      "seq_length":wandb_config["forecast_history"],
      "output_seq_length": wandb_config["out_seq_length"], 
      "n_layers_encoder": wandb_config["number_encoder_layers"],
      "dropout": wandb_config["dropout"],
      "meta_data": {
          "embedding_size":128,
          "output_size":10
      }
     }, 
      "metadata":{
        "path":"meta_config.json",
        "column_id": "full_county",
        "uuid": "Middlesex County_Massachusetts",
        "use": wandb_config["meta_data"]

    }
            
    ,
    "dataset_params":
    {  "class": "default",
       "training_path": "ma_test_data.csv",
       "validation_path": "ma_test_data.csv",
       "test_path": "ma_test_data.csv",
       "batch_size":4,
       "forecast_history":5, &lt;----
       "forecast_length":1,
       "train_end": 100,
       "valid_start":101,
       "valid_end": 126,
       "test_start":101,
       "target_col": ["rolling_7"],
       "relevant_cols": ["rolling_7", "month", "weekday", "mobility_retail_recreation", "mobility_grocery_pharmacy", "mobility_parks", "mobility_transit_stations", "mobility_workplaces", "mobility_residential"],
       "scaler": "StandardScaler", 
       "interpolate": False
    },
    "training_params":
    {
       "criterion":"RMSE",
       "optimizer": "Adam",
       "optim_params":
       {

       },
       "lr": wandb_config["lr"],
       "epochs": 10,
       "batch_size":wandb_config["batch_size"]

    },
    "GCS": False,
    "sweep":True,
    "wandb":False,
    "forward_params":{},
    "metrics":["MSE"],
    "inference_params":
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>