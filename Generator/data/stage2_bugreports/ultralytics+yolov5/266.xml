<bug id='266' author='wanghaoyang0106' open_date='2020-07-02T10:37:31Z' closed_time='2020-08-05T19:53:57Z'>
	<summary>Incorrect image shape order in utils/datasets.letterbox</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

In line 680-683 of utils/datasets.py, function letterbox, new_shape is regarded as with an order [width, height].
&lt;denchmark-code&gt;elif scaleFill:  # stretch
        dw, dh = 0.0, 0.0
        new_unpad = new_shape
        ratio = new_shape[0] / shape[1], new_shape[1] / shape[0]  # width, height ratios
&lt;/denchmark-code&gt;

However in other context of this function, it's with an order [height, width], e.g.:
&lt;denchmark-code&gt;r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding
&lt;/denchmark-code&gt;

scaleFill may hardly be set and images are usually in square shapes, but this might be a potential risk.
	</description>
	<comments>
		<comment id='1' author='wanghaoyang0106' date='2020-07-02T10:38:07Z'>
		Hello &lt;denchmark-link:https://github.com/wanghaoyang0106&gt;@wanghaoyang0106&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;Jupyter Notebook&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov5&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart&gt;Google Cloud Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='wanghaoyang0106' date='2020-07-02T16:22:31Z'>
		&lt;denchmark-link:https://github.com/wanghaoyang0106&gt;@wanghaoyang0106&lt;/denchmark-link&gt;
 oh thanks for discovering this! Can you submit a PR with your proposed fix please? Thank you!
		</comment>
		<comment id='3' author='wanghaoyang0106' date='2020-07-03T05:37:19Z'>
		Hello! I made the PR of bug &lt;denchmark-link:https://github.com/ultralytics/yolov5/issues/266&gt;#266&lt;/denchmark-link&gt;

I also noticed that, in , the  calculation is quite confusing.
&lt;denchmark-code&gt;gain = max(img1_shape) / max(img0_shape)  # gain  = old / new
&lt;/denchmark-code&gt;

It might be incorrect if the image to the model img1 is in rectangular shape but the original image img0 is in squre, or img1 is larger in width but img0 is larger in height.
Actually gain and pad here should be exactly idendity to the r and (dw, dh) in utils/datasets.letterbox, since it's just the reverse operation. So I also modified this part.
But still, there are several round operations in utils/datasets.letterbox, but the reverse operation of utils/utils.scale_coords uses exact float number, which may cause some slight error. So if possible, I hope to change to use ratio_pad in utils/utils.scale_coords to directly set the ratio and pad from utils/datasets.letterbox.
And actually in my own application, I will use some images with very large width/height ratio, and that's why I am focusing on this width/height process. But currently train.py only do preprocess to resize and pad the raw image to square. This is acceptable but not preferrable. If possible, I hope to have the feature of allowing rectangular shaped images for training.
		</comment>
		<comment id='4' author='wanghaoyang0106' date='2020-07-12T03:54:14Z'>
		&lt;denchmark-link:https://github.com/wanghaoyang0106&gt;@wanghaoyang0106&lt;/denchmark-link&gt;
 was just reviewing this issue and read your message again. Rectangular training is designed into the system, your training command would be this below, but in this case we do not use the mosaic dataloader, we only train with 1 image at a time.
python trian.py --rect
Also, rectangular inference is the default setting with test.py and detect.py, and also in our iOS app iDetection. For obvious reasons its very advantageous at inference time.
		</comment>
		<comment id='5' author='wanghaoyang0106' date='2020-07-12T07:12:01Z'>
		Thank you! Got it. I will read the source code for the usage.
		</comment>
		<comment id='6' author='wanghaoyang0106' date='2020-07-22T18:47:16Z'>
		&lt;denchmark-link:https://github.com/supergbl&gt;@supergbl&lt;/denchmark-link&gt;
 --rect (and all other train.py arguments) are compatible with any batch size.
		</comment>
		<comment id='7' author='wanghaoyang0106' date='2020-08-05T19:53:50Z'>
		Removing TODO as issue appears resolved.
		</comment>
	</comments>
</bug>