<bug id='1272' author='laomaup' open_date='2020-11-03T09:48:02Z' closed_time='2020-11-20T10:23:37Z'>
	<summary>RuntimeError: No such operator torchvision::nms</summary>
	<description>
Before submitting a bug report, please be aware that your issue must be reproducible with all of the following, otherwise it is non-actionable, and we can not help you:

Current repo: run git fetch &amp;&amp; git status -uno to check and git pull to update repo
Common dataset: coco.yaml or coco128.yaml
Common environment: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov5#environments

If this is a custom dataset/training question you must include your train*.jpg, test*.jpg and results.png figures, or we can not help you. You can generate these with utils.plot_results().
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

A clear and concise description of what the bug is.
Starting training for 30 epochs...
&lt;denchmark-code&gt; Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0/29    0.799G   0.07891   0.03296   0.06775    0.1796         2       640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 218/218 [00:51&lt;00:00,  4.22it/s]
           Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0%|                   | 0/19 [00:00&lt;?, ?it/s]
&lt;/denchmark-code&gt;

Traceback (most recent call last):
File "train.py", line 482, in 
train(hyp, opt, device, tb_writer, wandb)
File "train.py", line 318, in train
results, maps, times = test.test(opt.data,
File "/workspace/yolov5/test.py", line 125, in test
output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)
File "/workspace/yolov5/utils/general.py", line 661, in non_max_suppression
i = torch.ops.torchvision.nms(boxes, scores, iou_thres)
File "/root/anaconda3/envs/yolo5/lib/python3.8/site-packages/torch/_ops.py", line 61, in getattr
op = torch._C._jit_get_operation(qualified_op_name)
RuntimeError: No such operator torchvision::nms
&lt;denchmark-h:h2&gt;To Reproduce (REQUIRED)&lt;/denchmark-h&gt;

Input:
&lt;denchmark-code&gt;python train.py --img 640 --batch 8 --epochs 30 --data ./data/handpose.yaml --cfg ./models/yolov5s.yaml --weights '' --device 0,1
Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11177MB)
           device1 _CudaDeviceProperties(name='GeForce GTX 1080 Ti', total_memory=11178MB)

Namespace(adam=False, batch_size=8, bucket='', cache_images=False, cfg='./models/yolov5s.yaml', data='./data/handpose.yaml', device='0,1', epochs=30, evolve=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_imgs=10, logdir='runs/', multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, sync_bn=False, total_batch_size=8, weights='', workers=8, world_size=1)
Start Tensorboard with "tensorboard --logdir runs/", view at http://localhost:6006/
Install Weights &amp; Biases for experiment logging via 'pip install wandb' (recommended)
Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}
Overriding model.yaml nc=80 with nc=13

                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        
  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          
 24      [17, 20, 23]  1     48546  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model Summary: 191 layers, 7.28746e+06 parameters, 7.28746e+06 gradients

Optimizer groups: 62 .bias, 70 conv.weight, 59 other
Scanning images:   0%|                                                                                              | 0/1738 [00:00&lt;?, ?it/s]WARNING: Ignoring corrupted image and/or label /workspace/yolov5/data/images/chen_7.jpg: setting an array element with a sequence.
Scanning images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1738/1738 [00:00&lt;00:00, 6555.56it/s]
Scanning labels /workspace/yolov5/data/labels.cache (1071 found, 0 missing, 0 empty, 0 duplicate, for 1737 images): 1071it [00:00, 10703.55itScanning labels /workspace/yolov5/data/labels.cache (1737 found, 0 missing, 0 empty, 0 duplicate, for 1737 images): 1737it [00:00, 10807.05it/s]
Scanning images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 145/145 [00:00&lt;00:00, 5554.81it/s]
Scanning labels /workspace/yolov5/data/labels.cache (145 found, 0 missing, 0 empty, 0 duplicate, for 145 images): 145it [00:00, 8856.99it/s]

Analyzing anchors... anchors/target = 5.27, Best Possible Recall (BPR) = 1.0000
Image sizes 640 train, 640 test
Using 8 dataloader workers

&lt;/denchmark-code&gt;

Output:
Starting training for 30 epochs...
&lt;denchmark-code&gt; Epoch   gpu_mem       box       obj       cls     total   targets  img_size
  0/29    0.799G   0.07891   0.03296   0.06775    0.1796         2       640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 218/218 [00:51&lt;00:00,  4.22it/s]
           Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0%|                   | 0/19 [00:00&lt;?, ?it/s]
&lt;/denchmark-code&gt;

Traceback (most recent call last):
File "train.py", line 482, in 
train(hyp, opt, device, tb_writer, wandb)
File "train.py", line 318, in train
results, maps, times = test.test(opt.data,
File "/workspace/yolov5/test.py", line 125, in test
output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres)
File "/workspace/yolov5/utils/general.py", line 661, in non_max_suppression
i = torch.ops.torchvision.nms(boxes, scores, iou_thres)
File "/root/anaconda3/envs/yolo5/lib/python3.8/site-packages/torch/_ops.py", line 61, in getattr
op = torch._C._jit_get_operation(qualified_op_name)
RuntimeError: No such operator torchvision::nms
&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

A clear and concise description of what you expected to happen.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

If applicable, add screenshots to help explain your problem.

OS: [e.g. Ubuntu18.04]
GPU [e.g. 1080 Ti]
CUDA [e.g. 10.1]
python[e.g 3.8]

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

my conda Environment
_libgcc_mutex             0.1                        main    defaults
absl-py                   0.11.0                    
ca-certificates           2020.10.14                    0    defaults
cachetools                4.1.1                     
certifi                   2020.6.20          pyhd3eb1b0_3    defaults
chardet                   3.0.4                     
cycler                    0.10.0                    
Cython                    0.29.21                   
dataclasses               0.6                       
future                    0.18.2                    
google-auth               1.23.0                    
google-auth-oauthlib      0.4.2                     
grpcio                    1.33.2                    
idna                      2.10                      
kiwisolver                1.3.1                     
ld_impl_linux-64          2.33.1               h53a641e_7    defaults
libedit                   3.1.20191231         h14c3975_1    defaults
libffi                    3.3                  he6710b0_2    defaults
libgcc-ng                 9.1.0                hdf63c60_0    defaults
libstdcxx-ng              9.1.0                hdf63c60_0    defaults
Markdown                  3.3.3                     
matplotlib                3.3.2                     
ncurses                   6.2                  he6710b0_1    defaults
numpy                     1.19.4                    
oauthlib                  3.1.0                     
opencv-python             4.4.0.46                  
openssl                   1.1.1h               h7b6447c_0    defaults
Pillow                    8.0.1                     
pip                       20.2.4                   py38_0    defaults
protobuf                  3.13.0                    
pyasn1                    0.4.8                     
pyasn1-modules            0.2.8                     
pyparsing                 2.4.7                     
python                    3.8.5                h7579374_1    defaults
python-dateutil           2.8.1                     
PyYAML                    5.3.1                     
readline                  8.0                  h7b6447c_0    defaults
requests                  2.24.0                    
requests-oauthlib         1.3.0                     
rsa                       4.6                       
scipy                     1.5.3                     
setuptools                50.3.0           py38hb0f4dca_1    defaults
six                       1.15.0                    
sqlite                    3.33.0               h62c20be_0    defaults
tensorboard               2.3.0                     
tensorboard-plugin-wit    1.7.0                     
tk                        8.6.10               hbc83047_0    defaults
torch                     1.7.0+cu101               
torchvision               0.8.1                     
tqdm                      4.51.0                    
typing-extensions         3.7.4.3                   
urllib3                   1.25.11                   
Werkzeug                  1.0.1                     
wheel                     0.35.1                     py_0    defaults
xz                        5.2.5                h7b6447c_0    defaults
zlib                      1.2.11               h7b6447c_3    defaults
	</description>
	<comments>
		<comment id='1' author='laomaup' date='2020-11-03T09:48:48Z'>
		Hello &lt;denchmark-link:https://github.com/laomaup&gt;@laomaup&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;Jupyter Notebook&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov5&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart&gt;Google Cloud Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='laomaup' date='2020-11-03T11:49:37Z'>
		It appears you may have environment problems. Please ensure you meet all dependency requirements if you are attempting to run YOLOv5 locally.  If in doubt, create a new virtual Python 3.8 environment, clone the latest repo (code changes daily), and pip install -r requirements.txt again. We also highly recommend using one of our verified environments below.
&lt;denchmark-h:h2&gt;Requirements&lt;/denchmark-h&gt;

 or later with all &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/requirements.txt&gt;requirements.txt&lt;/denchmark-link&gt;
 dependencies installed, including . To install run:
$ pip install -r requirements.txt
&lt;denchmark-h:h2&gt;Environments&lt;/denchmark-h&gt;

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including &lt;denchmark-link:https://developer.nvidia.com/cuda&gt;CUDA&lt;/denchmark-link&gt;
/&lt;denchmark-link:https://developer.nvidia.com/cudnn&gt;CUDNN&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://www.python.org/&gt;Python&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://pytorch.org/&gt;PyTorch&lt;/denchmark-link&gt;
 preinstalled):

Google Colab Notebook with free GPU: 
Kaggle Notebook with free GPU: https://www.kaggle.com/ultralytics/yolov5
Google Cloud Deep Learning VM. See GCP Quickstart Guide
Docker Image https://hub.docker.com/r/ultralytics/yolov5. See Docker Quickstart Guide 

&lt;denchmark-h:h2&gt;Status&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg&gt;&lt;/denchmark-link&gt;

If this badge is green, all &lt;denchmark-link:https://github.com/ultralytics/yolov5/actions&gt;YOLOv5 GitHub Actions&lt;/denchmark-link&gt;
 Continuous Integration (CI) tests are passing. These tests evaluate proper operation of basic YOLOv5 functionality, including training (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/train.py&gt;train.py&lt;/denchmark-link&gt;
), testing (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/test.py&gt;test.py&lt;/denchmark-link&gt;
), inference (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/detect.py&gt;detect.py&lt;/denchmark-link&gt;
) and export (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/models/export.py&gt;export.py&lt;/denchmark-link&gt;
) on MacOS, Windows, and Ubuntu.
		</comment>
		<comment id='3' author='laomaup' date='2020-11-03T11:54:19Z'>
		&lt;denchmark-link:https://github.com/laomaup&gt;@laomaup&lt;/denchmark-link&gt;
 all seems fine according to your pip list, not sure what the problem may be. Perhaps start from a clean venv and try again. You might also try the Docker image failing that.
		</comment>
		<comment id='4' author='laomaup' date='2020-11-04T01:25:21Z'>
		ok, i will try,think you.
		</comment>
		<comment id='5' author='laomaup' date='2020-11-20T09:41:24Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 I just came across this issue from &lt;denchmark-link:https://github.com/pytorch/vision/issues/1405#issuecomment-731056137&gt;pytorch/vision#1405 (comment)&lt;/denchmark-link&gt;

I would strongly recommend replacing 


yolov5/utils/general.py


         Line 326
      in
      199c9c7






 i = torch.ops.torchvision.nms(boxes, scores, iou_thres) 




 with
torchvision.ops.nms, as in order for torch.ops.torchvision to be available, one first need to import torchvision to register NMS.
		</comment>
		<comment id='6' author='laomaup' date='2020-11-20T09:52:02Z'>
		&lt;denchmark-link:https://github.com/fmassa&gt;@fmassa&lt;/denchmark-link&gt;
 ah I see. Thanks for the advice, I will create a PR for this!
		</comment>
		<comment id='7' author='laomaup' date='2020-11-20T10:25:23Z'>
		&lt;denchmark-link:https://github.com/laomaup&gt;@laomaup&lt;/denchmark-link&gt;
 I've pushed a PR per &lt;denchmark-link:https://github.com/fmassa&gt;@fmassa&lt;/denchmark-link&gt;
 recommendations. Please  and see if the problem is fixed.
		</comment>
		<comment id='8' author='laomaup' date='2020-11-24T10:14:08Z'>
		it is work nowÔºåthink you.



At 2020-11-20 17:41:40, "Francisco Massa" &lt;notifications@github.com&gt; wrote:

&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 I just came across this issue from &lt;denchmark-link:https://github.com/pytorch/vision/issues/1405&gt;pytorch/vision#1405&lt;/denchmark-link&gt;
 (comment)

I would strongly recommend replacing &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/199c9c787427ece5723d5309e1c7c524a99bc59d/utils/general.py#L326&gt;https://github.com/ultralytics/yolov5/blob/199c9c787427ece5723d5309e1c7c524a99bc59d/utils/general.py#L326&lt;/denchmark-link&gt;
 with
torchvision.ops.nms, as in order for torch.ops.torchvision to be available, one first need to import torchvision to register NMS.

‚Äî
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub, or unsubscribe.
		</comment>
		<comment id='9' author='laomaup' date='2020-11-24T10:24:27Z'>
		&lt;denchmark-link:https://github.com/laomaup&gt;@laomaup&lt;/denchmark-link&gt;
 great, glad to hear its working!
		</comment>
	</comments>
</bug>