<bug id='868' author='NanoCode012' open_date='2020-08-28T17:43:46Z' closed_time='2020-08-30T06:09:17Z'>
	<summary>Dataset download failure on Windows</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Windows does not support unzip.



yolov5/utils/general.py


         Line 153
      in
      9776e70






 r = os.system('unzip -q %s -d ../ &amp;&amp; rm %s' % (f, f))  # unzip 





&lt;denchmark-h:h2&gt;To Reproduce (REQUIRED)&lt;/denchmark-h&gt;

Input:
python test.py
Output:
Download file success
&lt;denchmark-link:https://user-images.githubusercontent.com/9899957/91599417-74102900-e990-11ea-8149-3ed154c3fd54.png&gt;&lt;/denchmark-link&gt;

but, does not unzip and remove it
&lt;denchmark-code&gt;WARNING: Dataset not found, nonexistant paths: ['coco128\\images\\train2017']    
Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.1M/21.1M [00:48&lt;00:00, 452kB/s] 
'unzip' is not recognized as an internal or external command,
operable program or batch file.
Dataset autodownload failure

Traceback (most recent call last):
  File "yolov5\utils\datasets.py", line 309, in __init__
    raise Exception('%s does not exist' % p)
Exception: ..\coco128\images\train2017 does not exist
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

Unzip and remove
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


OS: Windows 10
Env: Conda py37
Shell: cmd

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

I looked around for solutions on Windows. The closest one is &lt;denchmark-link:https://stackoverflow.com/a/12886818/8293176&gt;this link on SO&lt;/denchmark-link&gt;
 , but a new function has to be added which I understand is not a clean solution. I was hoping others would have a solution
	</description>
	<comments>
		<comment id='1' author='NanoCode012' date='2020-08-28T20:07:32Z'>
		&lt;denchmark-link:https://github.com/NanoCode012&gt;@NanoCode012&lt;/denchmark-link&gt;
 thanks for spotting this! I don't have access to a windows machine, so I'll modify the CI checks in a new PR to see what's going on there. The current checks force a dataset download before everything else, but this also uses the unzip command. Perhaps a simple  would fix this?
		</comment>
		<comment id='2' author='NanoCode012' date='2020-08-28T20:08:31Z'>
		Current manual download step in CI checks:



yolov5/.github/workflows/ci-testing.yml


        Lines 54 to 59
      in
      9776e70






       - name: Download data 



 run: | 



           curl -L -o temp.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip 



           unzip -q temp.zip -d ../ 



           rm temp.zip 



  





		</comment>
		<comment id='3' author='NanoCode012' date='2020-08-29T01:06:40Z'>
		Hi &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , I thought  was a Unix package only!
I've tried,
 : got error due to dependency uses py &lt; 3. See here for open Issue &lt;denchmark-link:https://github.com/kdheepak/zip/issues/3#issue-462598301&gt;kdheepak/zip#3 (comment)&lt;/denchmark-link&gt;

pip install unzip: does not exist
: looking at &lt;denchmark-link:https://anaconda.org/conda-forge/unzip&gt;site&lt;/denchmark-link&gt;
, it only supports unix (PackageNotFound Error)
python test.py (on Anaconda shell): same error
However, I know using git bash (MinGW) could use unzip because it uses unix commands. Maybe it is what the CI checks uses? (Fyi, my conda does not seem to play well with it)
		</comment>
		<comment id='4' author='NanoCode012' date='2020-08-29T01:16:27Z'>
		&lt;denchmark-link:https://github.com/NanoCode012&gt;@NanoCode012&lt;/denchmark-link&gt;
 I'm not sure exactly, not too familiar with windows. I see that the Windows autodownload process did succeed though:
&lt;denchmark-link:https://github.com/ultralytics/yolov5/pull/869/checks?check_run_id=1043171610&gt;https://github.com/ultralytics/yolov5/pull/869/checks?check_run_id=1043171610&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/91625228-6770de00-e95a-11ea-81c7-7cb724d158dd.png&gt;&lt;/denchmark-link&gt;

The CI environment must then have a zip utility installed as part of its dependencies.
		</comment>
		<comment id='5' author='NanoCode012' date='2020-08-29T01:32:21Z'>
		Hi &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , Yes, I saw that too.. I‚Äôm actually surprised no one else got this issue as V3 has been out for a while.. I was using Unix this entire time, so I did not notice till yesterday.
Could you try to add ls as one of the commands? It is not a recognized function in Windows. We can see whether it‚Äôs using windows cmd or Unix..
Also, a system call, unzip file could not be a python file/lib..
Edit: This isn‚Äôt a breaking problem as a user could just extract it themselves using Windows built in zip. But it would be nice to be given a warning or message.
		</comment>
		<comment id='6' author='NanoCode012' date='2020-08-29T02:18:03Z'>
		Hi &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , some findings:
It uses Windows Powershell
&lt;denchmark-link:https://user-images.githubusercontent.com/9899957/91626129-99278a80-e9d6-11ea-8ed6-8be23a35ae6c.png&gt;&lt;/denchmark-link&gt;

Test ls follows same output format as my powershell.
&lt;denchmark-link:https://user-images.githubusercontent.com/9899957/91626144-ad6b8780-e9d6-11ea-8752-c6a0863959b9.png&gt;&lt;/denchmark-link&gt;

I don't use Powershell because I had to add conda to PATH, which I don't want, but maybe the below could help others.
Test unzip on Powershell:
&gt; unzip coco128.zip
unzip : The term 'unzip' is not recognized as the name of a cmdlet, function, script file, or operable program. Check
the spelling of the name, or if a path was included, verify that the path is correct and try again.
At line:1 char:1
+ unzip coco128.zip
+ ~~~~~
    + CategoryInfo          : ObjectNotFound: (unzip:String) [], CommandNotFoundException
    + FullyQualifiedErrorId : CommandNotFoundException
After some digging on Powershell, the below worked for me
Expand-Archive -LiteralPath coco128.zip -DestinationPath ..
Really  inconvenient üòÜ
		</comment>
		<comment id='7' author='NanoCode012' date='2020-08-29T06:59:48Z'>
		&lt;denchmark-link:https://github.com/NanoCode012&gt;@NanoCode012&lt;/denchmark-link&gt;
 strange! Hey I have a random question. I was experimenting with DDP and found that 4x T4 GPUs are now faster than 1 V100, at about 2/3 the price on GCP (yay!). When I run DDP though I see a warning msg saying something like OMP_THREAD_NUMBER set to 1 to keep system from being overloaded.
Do you think this means that each node then only has 1 cpu worker available to it?
		</comment>
		<comment id='8' author='NanoCode012' date='2020-08-29T07:09:32Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , Wow! That's great! More performance with less cost! I recall that you had a breakdown of the costs on GCP but can't find it anymore..
Regarding OMP, I'm not sure how it's related to number of cpu workers. I referred to a few threads and chose to keep it to its default value because it has different effects on different systems. For ex,
&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/22451#issuecomment-507887210&gt;pytorch/pytorch#22451 (comment)&lt;/denchmark-link&gt;

Edit: Maybe I will test diff values of that env variable and will post my results. But right now, I'm testing diff batch sizes for 5m on coco and testing 1 fine tuning of 5s.
		</comment>
		<comment id='9' author='NanoCode012' date='2020-08-29T08:20:33Z'>
		&lt;denchmark-link:https://github.com/NanoCode012&gt;@NanoCode012&lt;/denchmark-link&gt;
 hmm ok! I would think if the worker count were restricted it would show up in the logging statement, i.e. 'Using 8 dataloader workers...' is what we see for single GPU. I can't check right now either as my multi-gpu vm is evolving finetuning hyps. The evolution is a huge success, it's raised YOLOv5m VOC mAP from 86.5 to 89.1 now after about 100 generations. I'm assuming this means that the larger models will produce VOC mAPs over 0.90, which I think is pretty good.
		</comment>
	</comments>
</bug>