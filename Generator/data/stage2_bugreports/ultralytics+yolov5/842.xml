<bug id='842' author='zhayanli' open_date='2020-08-25T15:44:34Z' closed_time='2020-10-06T00:43:11Z'>
	<summary>Rectangular training got bug</summary>
	<description>
I'm so happy to use your YOLOv5 and think you for the good work.
When i run "CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node 4 train.py --batch-size 80 --data coco.yaml --cfg yolov5x.yaml --weights yolov5x.pt --img-size 800--rect"，i got the error report as:
Traceback (most recent call last):
File "train.py", line 486, in 
train(hyp, opt, device, tb_writer)
File "train.py", line 280, in train
for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 363, in next
data = self._next_data()
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
return self._process_data(data)
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
data.reraise()
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
data = fetcher.fetch(index)
File "/home/zhayanli/anaconda3/envs/onestage/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
return self.collate_fn(data)
File "/home/zhayanli/yolov5-master/utils/datasets.py", line 564, in collate_fn
return torch.stack(img, 0), torch.cat(label, 0), path, shapes
RuntimeError: stack expects each tensor to be equal size, but got [3, 384, 800] at entry 0 and [3, 672, 800] at entry 1
Please help me!!!
	</description>
	<comments>
		<comment id='1' author='zhayanli' date='2020-08-25T15:45:16Z'>
		Hello &lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;Jupyter Notebook&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov5&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart&gt;Google Cloud Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='zhayanli' date='2020-08-25T18:12:50Z'>
		&lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 I'll paste you our default bug reply here. Mainly you should check whether this occurs in a new git clone of the repo, whether it occurs on single-gpu in a verified environment before we would try to reproduce.
Hello, thank you for your interest in our work! This issue seems to lack the minimum requirements for a proper response, or is insufficiently detailed for us to help you. Please note that most technical problems are due to:

Your changes to the default repository. If your issue is not reproducible in a new git clone version of this repository we can not debug it. Before going further run this code and ensure your issue persists:

sudo rm -rf yolov5  # remove existing
git clone https://github.com/ultralytics/yolov5 &amp;&amp; cd yolov5 # clone latest
python detect.py  # verify detection
# CODE TO REPRODUCE YOUR ISSUE HERE


Your custom data. If your issue is not reproducible with COCO or COCO128 data we can not debug it. Visit our Custom Training Tutorial for guidelines on training your custom data. Examine train_batch0.jpg and test_batch0.jpg for a sanity check of training and testing data.


Your environment. If your issue is not reproducible in one of the verified environments below we can not debug it. If you are running YOLOv5 locally, ensure your environment meets all of the requirements.txt dependencies specified below.


If none of these apply to you, we suggest you close this issue and raise a new one using the Bug Report template, providing screenshots and minimum viable code to reproduce your issue. Thank you!
&lt;denchmark-h:h2&gt;Requirements&lt;/denchmark-h&gt;

Python 3.8 or later with all &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/requirements.txt&gt;requirements.txt&lt;/denchmark-link&gt;
 dependencies installed, including . To install run:
$ pip install -r requirements.txt
&lt;denchmark-h:h2&gt;Environments&lt;/denchmark-h&gt;

YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including &lt;denchmark-link:https://developer.nvidia.com/cuda&gt;CUDA&lt;/denchmark-link&gt;
/&lt;denchmark-link:https://developer.nvidia.com/cudnn&gt;CUDNN&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://www.python.org/&gt;Python&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://pytorch.org/&gt;PyTorch&lt;/denchmark-link&gt;
 preinstalled):

Google Colab Notebook with free GPU: 
Kaggle Notebook with free GPU: https://www.kaggle.com/ultralytics/yolov5
Google Cloud Deep Learning VM. See GCP Quickstart Guide
Docker Image https://hub.docker.com/r/ultralytics/yolov5. See Docker Quickstart Guide 

&lt;denchmark-h:h2&gt;Status&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg&gt;&lt;/denchmark-link&gt;

If this badge is green, all &lt;denchmark-link:https://github.com/ultralytics/yolov5/actions&gt;YOLOv5 GitHub Actions&lt;/denchmark-link&gt;
 Continuous Integration (CI) tests are passing. These tests evaluate proper operation of basic YOLOv5 functionality, including training (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/train.py&gt;train.py&lt;/denchmark-link&gt;
), testing (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/test.py&gt;test.py&lt;/denchmark-link&gt;
), inference (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/detect.py&gt;detect.py&lt;/denchmark-link&gt;
) and export (&lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/models/export.py&gt;export.py&lt;/denchmark-link&gt;
) on MacOS, Windows, and Ubuntu.
		</comment>
		<comment id='3' author='zhayanli' date='2020-08-28T15:57:27Z'>
		Thank you for your attention on my question. I reload the last clone just now.
sudo rm -rf yolov5  # remove existing
git clone &lt;denchmark-link:https://github.com/ultralytics/yolov5&gt;https://github.com/ultralytics/yolov5&lt;/denchmark-link&gt;
 &amp;&amp; cd yolov5 # clone latest
python detect.py  # verify detection
My data was according to the guidelines in your our Custom Training Tutorial.My environment is in the picture below.
&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587212-09a7ba80-e989-11ea-95c2-a896723adb9d.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587290-2217d500-e989-11ea-9108-5b4270e3698c.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587336-3360e180-e989-11ea-82ec-e327066368ba.png&gt;&lt;/denchmark-link&gt;

and i run the command below
&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587583-8c307a00-e989-11ea-8244-dc3418e260b1.png&gt;&lt;/denchmark-link&gt;

then got the error report below
&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587880-f47f5b80-e989-11ea-9e51-a7b9d71113ab.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91587971-111b9380-e98a-11ea-9c70-c1c5660a02fd.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91588064-301a2580-e98a-11ea-96c6-d5c80227060e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='zhayanli' date='2020-08-28T18:46:18Z'>
		&lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 conda is not recommended. I would simply make a 3.8 venv, install requirements and run.
But in any case, without a reproducible example there's nothing for us to debug. A reproducible example would use a public dataset like coco128, in one of our verified environments.
		</comment>
		<comment id='5' author='zhayanli' date='2020-08-29T00:13:44Z'>
		Thank you.  I train several expX perfectly without '--rect'. I want to train with '--rect' to see the difference but got the error.
		</comment>
		<comment id='6' author='zhayanli' date='2020-08-29T01:17:58Z'>
		&lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 sure. If you can create steps for us to reproduce this in one of our verified environments (docker image, colab notebook) with coco128 we can take a look, otherwise there's nothing for us to do.
		</comment>
		<comment id='7' author='zhayanli' date='2020-08-30T07:29:09Z'>
		Hello, i run on the coco128 got the same error.
&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91653677-75973980-ead5-11ea-9816-3d57d325fe94.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/40348284/91653692-89db3680-ead5-11ea-87af-a6b5a5aab09b.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='zhayanli' date='2020-08-31T13:35:35Z'>
		Hello, the (rectangular training is only for single-gpu training?
		</comment>
		<comment id='9' author='zhayanli' date='2020-08-31T22:56:44Z'>
		&lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 I don't know, I have not tried rectangular training with multigpu. Recommend using default settings.
		</comment>
		<comment id='10' author='zhayanli' date='2020-10-01T00:43:06Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='11' author='zhayanli' date='2020-10-25T04:12:33Z'>
		&lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 I also have some question, can you tell me how to solve it ? Thanks
		</comment>
		<comment id='12' author='zhayanli' date='2020-11-10T01:37:44Z'>
		same error.
It is a bug.
		</comment>
		<comment id='13' author='zhayanli' date='2020-11-10T11:19:20Z'>
		&lt;denchmark-link:https://github.com/JiefuYuan&gt;@JiefuYuan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Pluto1314&gt;@Pluto1314&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/zhayanli&gt;@zhayanli&lt;/denchmark-link&gt;
 I tested multi-gpu rectangular training and everything works fine. See example below:
INPUT
$ python train.py --device 0,1 --epochs 3 --rect
OUTPUT
Using torch 1.7.0+cu101 CUDA:0 (Tesla T4, 15079MB)
                        CUDA:1 (Tesla T4, 15079MB)

Namespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='', data='data/coco128.yaml', device='0,1', epochs=3, evolve=False, global_rank=-1, hyp='data/hyp.scratch.yaml',  image_weights=False, img_size=[640, 640], local_rank=-1, log_imgs=10, logdir='runs/train', multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=True, resume=False, single_cls=False, sync_bn=False, total_batch_size=16, weights='yolov5s.pt', workers=8, world_size=1)

Start Tensorboard with "tensorboard --logdir runs/train", view at http://localhost:6006/
Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_
pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear'
: 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}

                 from  n    params  module                                  arguments
  0                -1  1      3520  models.common.Focus                     [3, 32, 3]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]
  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 6]  1         0  models.common.Concat                    [1]
 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16           [-1, 4]  1         0  models.common.Concat                    [1]
 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]
 19          [-1, 14]  1         0  models.common.Concat                    [1]
 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]
 22          [-1, 10]  1         0  models.common.Concat                    [1]
 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]
 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
Model Summary: 191 layers, 7.46816e+06 parameters, 7.46816e+06 gradients

Transferred 370/370 items from yolov5s.pt
Optimizer groups: 62 .bias, 70 conv.weight, 59 other
wandb: Offline run mode, not syncing to the cloud.
wandb: W&amp;B is disabled in this directory.  Run `wandb on` to enable cloud syncing.
Scanning labels ../coco128/labels/train2017.cache (126 found, 0 missing, 2 empty, 0 duplicate, for 128 images): 128it [00:00, 16174.71it/s]
Scanning labels ../coco128/labels/train2017.cache (126 found, 0 missing, 2 empty, 0 duplicate, for 128 images): 128it [00:00, 9873.31it/s]
NumExpr defaulting to 8 threads.

Analyzing anchors... anchors/target = 4.28, Best Possible Recall (BPR) = 0.9946
Image sizes 640 train, 640 test
Using 8 dataloader workers
Logging results to runs/train/exp2

Starting training for 3 epochs...
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
       0/2     2.57G   0.04574    0.0503   0.02272    0.1188        81       480: 100%|██████████| 8/8 [00:18&lt;00:00,  2.35s/it]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 8/8 [00:09&lt;00:00,  1.21s/it]
                 all         128         929       0.392       0.769       0.694       0.435
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
       1/2      7.2G   0.04586   0.04771   0.01985    0.1134        84       480: 100%|██████████| 8/8 [00:01&lt;00:00,  4.82it/s]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 8/8 [00:02&lt;00:00,  3.88it/s]
                 all         128         929       0.383       0.775       0.692        0.44
     Epoch   gpu_mem       box       obj       cls     total   targets  img_size
       2/2      7.2G   0.04536   0.04729    0.0187    0.1114        83       480: 100%|██████████| 8/8 [00:01&lt;00:00,  5.10it/s]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100%|██████████| 8/8 [00:03&lt;00:00,  2.21it/s]
                 all         128         929       0.367       0.771       0.685       0.437
Optimizer stripped from runs/train/exp2/weights/last.pt, 15.2MB
Optimizer stripped from runs/train/exp2/weights/best.pt, 15.2MB
3 epochs completed in 0.011 hours.
		</comment>
		<comment id='14' author='zhayanli' date='2020-11-10T11:24:11Z'>
		If I run the torch.distributed.launch I get an error as well, so for multi-gpu --rect use the syntax below and everything will work correctly:
$ python train.py --device 0,1,2,3 --epochs 3 --rect
		</comment>
	</comments>
</bug>