<bug id='94' author='zidanexu' open_date='2020-06-16T11:47:53Z' closed_time='2020-06-25T05:22:20Z'>
	<summary>model.names bug</summary>
	<description>
hi, I running  this command  python detect.py --source ./inference/images/ --weights best.pt --conf 0.4
get the error
&lt;denchmark-link:https://user-images.githubusercontent.com/54395639/84770497-3e52d980-b00a-11ea-92c3-b7f3e9729b6f.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='zidanexu' date='2020-06-16T16:54:59Z'>
		&lt;denchmark-link:https://github.com/zidanexu&gt;@zidanexu&lt;/denchmark-link&gt;
 every model needs a name list to run inference. Your custom model is lacking this, so you would need to create and attach it:
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/84804036-6533f000-afb7-11ea-9777-20167cb2d3ef.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='zidanexu' date='2020-06-16T17:49:34Z'>
		&lt;denchmark-link:https://github.com/zidanexu&gt;@zidanexu&lt;/denchmark-link&gt;
 was this model trained with multi-gpu?
I've run unit tests in colab on all 3 main components of the repo with all 4 models, but I don't have unit tests set up for multi-gpu.
		</comment>
		<comment id='3' author='zidanexu' date='2020-06-17T02:19:17Z'>
		yes, I used multi-gpu  Tesla P40.  it is done when I use default mode yolov5s.ptã€‚But I used best.pt It's also a model trained by default
		</comment>
		<comment id='4' author='zidanexu' date='2020-06-18T10:11:21Z'>
		I hv found GPU stay 100% Utlization after press 'q' to exit.
My system detail.
Ubuntu 18.04
Python 3.7.7
GTX1060 with NVDIA-SMI 440.64.00
		</comment>
		<comment id='5' author='zidanexu' date='2020-06-18T17:25:39Z'>
		&lt;denchmark-link:https://github.com/theerawatramchuen&gt;@theerawatramchuen&lt;/denchmark-link&gt;
 just use ctrl+c then
		</comment>
		<comment id='6' author='zidanexu' date='2020-06-19T03:06:23Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 I also meet the same problem when I test my own weights, is there wrong with the training code? Should I add the names manually?
		</comment>
		<comment id='7' author='zidanexu' date='2020-06-19T04:10:17Z'>
		&lt;denchmark-link:https://github.com/gaogg&gt;@gaogg&lt;/denchmark-link&gt;
 if you are referring to the names problem, this may be resolved in the latest code, please git pull and try again. You can train 1-2 epochs and then use last.pt to detect to verify quickly.
		</comment>
		<comment id='8' author='zidanexu' date='2020-06-19T07:36:42Z'>
		
@gaogg if you are referring to the names problem, this may be resolved in the latest code, please git pull and try again. You can train 1-2 epochs and then use last.pt to detect to verify quickly.

I pull the latest code and train coco128 for 2 epochs and inference by the last.pt.
The model.names error still there.
		</comment>
		<comment id='9' author='zidanexu' date='2020-06-19T13:14:14Z'>
		
@gaogg if you are referring to the names problem, this may be resolved in the latest code, please git pull and try again. You can train 1-2 epochs and then use last.pt to detect to verify quickly.

error still exists
		</comment>
		<comment id='10' author='zidanexu' date='2020-06-19T16:44:13Z'>
		&lt;denchmark-link:https://github.com/gaogg&gt;@gaogg&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/XinyuDu&gt;@XinyuDu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/AItechnology&gt;@AItechnology&lt;/denchmark-link&gt;
 we designed a set of unit tests which include this exact use case, and they are all passing in our colab notebook with no errors on the latest repository. If you can't run these successfully on your system, then you are using old/modified code, or your environment is a problem.
# Unit tests
%%shell
git pull
python3 -c "from utils.google_utils import *; gdrive_download('1n_oKgR81BJtqk75b00eAjdv03qVCQn2f', 'coco128.zip')" &amp;&amp; mv ./coco128 ../
for d in 0 # device
do
  for x in yolov5s #yolov5m yolov5l yolov5x # models
  do
    python train.py --weights $x.pt --cfg $x.yaml --epochs 3 --img 320 --device $d --name test
    python detect.py --weights weights/last_test.pt --device $d
    python detect.py --weights weights/best_test.pt --device $d
  done
done
Output:
Already up to date.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   408    0   408    0     0    137      0 --:--:--  0:00:02 --:--:--   137
  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0
100 21.0M    0 21.0M    0     0  4699k      0 --:--:--  0:00:04 --:--:--  237M
Downloading https://drive.google.com/uc?export=download&amp;id=1n_oKgR81BJtqk75b00eAjdv03qVCQn2f as coco128.zip... unzipping... Done (8.7s)
Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex
{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}
Namespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='./models/yolov5s.yaml', data='data/coco128.yaml', device='0', epochs=3, evolve=False, img_size=[320], multi_scale=False, name='test', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='yolov5s.pt')
Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)

2020-06-19 16:38:28.749236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
Start Tensorboard with "tensorboard --logdir=runs", view at http://localhost:6006/

              from  n    params  module                                  arguments                     
  0             -1  1      3520  models.common.Focus                     [3, 32, 3]                    
  1             -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2             -1  1     20672  models.common.Bottleneck                [64, 64]                      
  3             -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4             -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 
  5             -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6             -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 
  7             -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8             -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        
  9             -1  1   1905152  models.common.BottleneckCSP             [512, 512, 2]                 
 10             -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          
 11             -1  1    130815  torch.nn.modules.conv.Conv2d            [512, 255, 1, 1]              
 12             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 13        [-1, 6]  1         0  models.common.Concat                    [1]                           
 14             -1  1    197120  models.common.Conv                      [768, 256, 1, 1]              
 15             -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          
 16             -1  1     65535  torch.nn.modules.conv.Conv2d            [256, 255, 1, 1]              
 17             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 18        [-1, 4]  1         0  models.common.Concat                    [1]                           
 19             -1  1     49408  models.common.Conv                      [384, 128, 1, 1]              
 20             -1  1     78720  models.common.BottleneckCSP             [128, 128, 1, False]          
 21             -1  1     32895  torch.nn.modules.conv.Conv2d            [128, 255, 1, 1]              
 22   [-1, 16, 11]  1         0  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]
Model Summary: 165 layers, 7.07417e+06 parameters, 7.07417e+06 gradients

Optimizer groups: 54 .bias, 60 conv.weight, 51 other
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   408    0   408    0     0    447      0 --:--:-- --:--:-- --:--:--   446
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
100 13.6M    0 13.6M    0     0  7962k      0 --:--:--  0:00:01 --:--:-- 7962k
Downloading https://drive.google.com/uc?export=download&amp;id=1R5T6rIyy3lLwgFXNms8whc-387H0tMQO as yolov5s.pt... Done (3.7s)
Reading image shapes: 100% 128/128 [00:00&lt;00:00, 4405.17it/s]
Caching labels ../coco128/labels/train2017 (126 found, 0 missing, 2 empty, 0 duplicate, for 128 images): 100% 128/128 [00:00&lt;00:00, 7694.21it/s]
Caching labels ../coco128/labels/train2017 (126 found, 0 missing, 2 empty, 0 duplicate, for 128 images): 100% 128/128 [00:00&lt;00:00, 10106.76it/s]

Analyzing anchors... Best Possible Recall (BPR) = 0.9623. Attempting to generate improved anchors, please wait...
WARNING: Extremely small objects found. 84 of 929 labels are &lt; 4 pixels in width or height.
Running kmeans for 9 anchors on 916 points...
thr=0.25: 0.9645 best possible recall, 3.74 anchors past thr
n=9, img_size=320, metric_all=0.261/0.653-mean/best, past_thr=0.472-mean: 9,12,  32,19,  27,48,  74,43,  54,92,  77,161,  161,107,  174,237,  299,195
Evolving anchors with Genetic Algorithm: fitness = 0.6670: 100% 1000/1000 [00:00&lt;00:00, 1604.71it/s]
thr=0.25: 0.9849 best possible recall, 3.79 anchors past thr
n=9, img_size=320, metric_all=0.263/0.663-mean/best, past_thr=0.471-mean: 8,10,  23,12,  23,33,  58,37,  48,89,  68,145,  145,110,  181,199,  310,221
New anchors saved to model. Update model *.yaml to use these anchors in the future.

Image sizes 320 train, 320 test
Using 2 dataloader workers
Starting training for 3 epochs...

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
       0/2     2.31G   0.07842    0.1905   0.03977    0.3087       177       320: 100% 8/8 [00:04&lt;00:00,  1.84it/s]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:03&lt;00:00,  2.28it/s]
                 all         128         929       0.172       0.609       0.408        0.24

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
       1/2     2.31G   0.06492    0.1971   0.04188    0.3039       140       320: 100% 8/8 [00:03&lt;00:00,  2.29it/s]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:02&lt;00:00,  3.25it/s]
                 all         128         929       0.174       0.646       0.464       0.275

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
       2/2     2.32G   0.06308    0.1993   0.03756       0.3       191       320: 100% 8/8 [00:03&lt;00:00,  2.34it/s]
               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:02&lt;00:00,  3.24it/s]
                 all         128         929       0.149       0.658       0.494       0.305
Optimizer stripped from weights/last_test.pt
Optimizer stripped from weights/best_test.pt
3 epochs completed in 0.006 hours.

Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='0', fourcc='mp4v', img_size=640, iou_thres=0.5, output='inference/output', save_txt=False, source='inference/images', view_img=False, weights='weights/last_test.pt')
Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)

image 1/2 inference/images/bus.jpg: 640x512 5 persons, 1 buss, 2 skateboards, Done. (0.010s)
image 2/2 inference/images/zidane.jpg: 384x640 3 persons, 2 ties, Done. (0.011s)
Results saved to /content/yolov5/inference/output
Done. (0.123s)
Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='0', fourcc='mp4v', img_size=640, iou_thres=0.5, output='inference/output', save_txt=False, source='inference/images', view_img=False, weights='weights/best_test.pt')
Using CUDA device0 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', total_memory=16280MB)

image 1/2 inference/images/bus.jpg: 640x512 4 persons, 1 buss, 2 skateboards, Done. (0.010s)
image 2/2 inference/images/zidane.jpg: 384x640 2 persons, 2 ties, Done. (0.010s)
Results saved to /content/yolov5/inference/output
Done. (0.104s)
		</comment>
		<comment id='11' author='zidanexu' date='2020-06-20T01:31:31Z'>
		Dears

It is my mistake report. Pls ignore its.
Your code working very fine with my machine. Sorry about that.

Good work.
Best regards.
Theerawat

à¹ƒà¸™à¸§à¸±à¸™à¸—à¸µà¹ˆ à¸¨. 19 à¸¡à¸´.à¸¢. 2020 00:25 Glenn Jocher &lt;notifications@github.com&gt;
à¹€à¸‚à¸µà¸¢à¸™à¸§à¹ˆà¸²:
&lt;denchmark-link:#&gt;â€¦&lt;/denchmark-link&gt;


 @theerawatramchuen &lt;https://github.com/theerawatramchuen&gt; just use ctrl+c
 then

 â€”
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#94 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ADY7CCF5LCKC5JD262EI3OLRXJE2FANCNFSM4N7RGHPA&gt;
 .



		</comment>
		<comment id='12' author='zidanexu' date='2020-06-24T09:01:23Z'>
		&lt;denchmark-link:https://github.com/gaogg&gt;@gaogg&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/XinyuDu&gt;@XinyuDu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/AItechnology&gt;@AItechnology&lt;/denchmark-link&gt;

i just move the  in train.py line194 to line 81 then solve the problem.
guess only need to before the code 
also, if you use  as i did
in utils/torch_utils.py line 188

should change to:

&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 am i right ?
		</comment>
		<comment id='13' author='zidanexu' date='2020-06-24T09:40:15Z'>
		
@gaogg @XinyuDu @AItechnology
i just move the model.names = data_dict['names'] in train.py line194 to line 81 then solve the problem.
guess only need to before the code model = torch.nn.parallel.DistributedDataParallel(model)
also, if you use model = torch.nn.DataParallel(model) as i did
in utils/torch_utils.py line 188
if type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel):
should change to:
 if type(model) in (nn.DataParallel, nn.parallel.DistributedDataParallel):
@glenn-jocher am i right ?

thanks, but I have solved this bug by modifying names manually
		</comment>
		<comment id='14' author='zidanexu' date='2020-06-24T10:35:58Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

maybe a more stable way is to replicate the parameter in #save

i try and it work for single and mutl gpu
i am not familiar with the distribution training of pytorch, maybe can save the ema.ema all the way ignore muti or single gpu?
		</comment>
		<comment id='15' author='zidanexu' date='2020-06-24T18:08:39Z'>
		&lt;denchmark-link:https://github.com/yxNONG&gt;@yxNONG&lt;/denchmark-link&gt;
 thanks for the ideas! Can you test your changes in single and multi gpu, and then submit a PR for the proposed changes?
		</comment>
		<comment id='16' author='zidanexu' date='2020-06-24T18:40:37Z'>
		Multiple people have cited this same issue now, so I've added a TODO here as it's becoming a priority to fix. I will test the recommendations here and update the code today hopefully.
		</comment>
		<comment id='17' author='zidanexu' date='2020-06-25T05:23:56Z'>
		&lt;denchmark-link:https://github.com/zidanexu&gt;@zidanexu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yxNONG&gt;@yxNONG&lt;/denchmark-link&gt;
 bug has been fixed, however fix only applies to newly trained models. Please git pull, train again, and everything should work fine.
Thanks for catching this bug also. It shows that we really need more automated unit tests across all the different use cases. I'm not sure the best way to accomplish this unfortunately.
		</comment>
		<comment id='18' author='zidanexu' date='2020-07-07T02:58:24Z'>
		Removing TODO label as issue resolved.
		</comment>
	</comments>
</bug>