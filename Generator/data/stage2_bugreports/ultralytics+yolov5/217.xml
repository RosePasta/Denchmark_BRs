<bug id='217' author='ChenYingpeng' open_date='2020-06-28T08:02:09Z' closed_time='2020-08-05T00:30:14Z'>
	<summary>ERROR: Unexpected segmentation fault encountered in worker.</summary>
	<description>
`
&lt;denchmark-code&gt;python train.py --data data/voc.yaml --cfg models/yolov5s.yaml --batch-size 64 --resume
Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex
{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 
'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}
Namespace(adam=False, batch_size=64, bucket='', cache_images=False, cfg='models/yolov5s.yaml', data='data/voc.yaml', 
device='', epochs=300, evolve=False, img_size=[640, 640], multi_scale=False, name='', noautoanchor=False, nosave=False, 
notest=False, rect=False, resume=True, single_cls=False, weights='weights/last.pt')
Using CUDA device0 _CudaDeviceProperties(name='TITAN Xp COLLECTORS EDITION', total_memory=12195MB)
       device1 _CudaDeviceProperties(name='TITAN Xp COLLECTORS EDITION', total_memory=12196MB)

Start Tensorboard with "tensorboard --logdir=runs", view at http://localhost:6006/

          from  n    params  module                                  arguments                     
  0             -1  1      3520  models.common.Focus                     [3, 32, 3]                    
  1             -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2             -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   
  3             -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4             -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 
  5             -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6             -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 
  7             -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8             -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        
  9             -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          
 10             -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11             -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12        [-1, 6]  1         0  models.common.Concat                    [1]                           
 13             -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          
 14             -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 15             -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16        [-1, 4]  1         0  models.common.Concat                    [1]                           
 17             -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          
 18             -1  1      9675  torch.nn.modules.conv.Conv2d            [128, 75, 1, 1]               
 19             -2  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 20       [-1, 14]  1         0  models.common.Concat                    [1]                           
 21             -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          
 22             -1  1     19275  torch.nn.modules.conv.Conv2d            [256, 75, 1, 1]               
 23             -2  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 24       [-1, 10]  1         0  models.common.Concat                    [1]                           
 25             -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          
 26             -1  1     38475  torch.nn.modules.conv.Conv2d            [512, 75, 1, 1]               
 27   [-1, 22, 18]  1         0  models.yolo.Detect                      [20, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]
Model Summary: 191 layers, 7.30634e+06 parameters, 7.30634e+06 gradients

Optimizer groups: 62 .bias, 70 conv.weight, 59 other
Caching labels /home/ss/data/VOCdevkit/VOC2007/labels.npy (16551 found, 0 missing, 0 empty, 0 duplicate, for 16551 i
Saving labels to /home/ss/data/VOCdevkit/VOC2007/labels.npy for faster future loading
Caching labels /home/ss/data/VOCdevkit/VOC2007/labels.npy (4952 found, 0 missing, 0 empty, 0 duplicate, for 4952 ima
Saving labels to /home/ss/data/VOCdevkit/VOC2007/labels.npy for faster future loading

Analyzing anchors... Best Possible Recall (BPR) = 0.9998
Image sizes 640 train, 640 test
Using 8 dataloader workers
Starting training for 300 epochs...

 Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
  0%|                                                                                       | 0/259 [00:00&lt;?, ?it/s]ERROR: Unexpected segmentation fault 
  encountered in worker.
  0%|                                                                                       | 0/259 [00:02&lt;?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 387, in &lt;module&gt;
    train(hyp)
  File "train.py", line 241, in train
    pred = model(imgs)
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
result = self.forward(*input, **kwargs)
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 449, in forward
outputs = self.parallel_apply(self._module_copies[:len(inputs)], inputs, kwargs)
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 474, in parallel_apply
return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 77, in parallel_apply
thread.join()
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/threading.py", line 1032, in join
self._wait_for_tstate_lock()
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/threading.py", line 1048, in _wait_for_tstate_lock
elif lock.acquire(block, timeout):
  File "/home/ss/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
_error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 12367) is killed by signal: Segmentation fault. `
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


OS: [Ubuntu16.04]
GPU [2*Titan-Xp]
Pytorch==1.4.0
Python==3.7

How to solve the bug? Thank you in advance.
	</description>
	<comments>
		<comment id='1' author='ChenYingpeng' date='2020-06-28T08:02:53Z'>
		Hello &lt;denchmark-link:https://github.com/ChenYingpeng&gt;@ChenYingpeng&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;Jupyter Notebook&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb&gt;&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov5&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart&gt;Google Cloud Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='ChenYingpeng' date='2020-07-31T00:30:10Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>