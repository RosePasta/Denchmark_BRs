<bug id='589' author='zifeishan' open_date='2016-10-28T19:50:49Z' closed_time='2016-11-01T13:49:25Z'>
	<summary>OverflowError: Python int too large to convert to C long</summary>
	<description>
With latest master branch (&lt;denchmark-link:https://github.com/explosion/spaCy/commit/d563f1eadb965de5dc09536cc8c6263277b864fe&gt;d563f1e&lt;/denchmark-link&gt;
) I am getting following error:
&lt;denchmark-code&gt;  File ".../spaCy/spacy/language.py", line 304, in __call__
    doc = self.make_doc(text)
  File ".../spaCy/spacy/language.py", line 279, in &lt;lambda&gt;
    self.make_doc = lambda text: self.tokenizer(text)
  File "spacy/tokenizer.pyx", line 155, in spacy.tokenizer.Tokenizer.__call__ (spacy/tokenizer.cpp:5527)
  File "spacy/tokenizer.pyx", line 196, in spacy.tokenizer.Tokenizer._tokenize (spacy/tokenizer.cpp:6272)
  File "spacy/tokenizer.pyx", line 259, in spacy.tokenizer.Tokenizer._attach_tokens (spacy/tokenizer.cpp:7144)
  File "spacy/vocab.pyx", line 201, in spacy.vocab.Vocab.get (spacy/vocab.cpp:6492)
  File "spacy/vocab.pyx", line 222, in spacy.vocab.Vocab._new_lexeme (spacy/vocab.cpp:6747)
OverflowError: Python int too large to convert to C long
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='zifeishan' date='2016-10-28T19:54:09Z'>
		Thanks! Steps to reproduce appreciated if you have time.
		</comment>
		<comment id='2' author='zifeishan' date='2016-10-28T19:54:50Z'>
		A minimal example to reproduce this:
(related: &lt;denchmark-link:https://github.com/explosion/spaCy/issues/285&gt;#285&lt;/denchmark-link&gt;
)
&lt;denchmark-code&gt;import spacy
nlp = spacy.en.English()
# this is the motivation I am using latest master.. to try out the fix suggested by #285
nlp.vocab.strings.set_frozen(True)
&lt;/denchmark-code&gt;

Then parse some random stuff:
&lt;denchmark-code&gt;&gt;&gt;&gt; nlp('Whata')  # a new lexeme
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File ".../spaCy/spacy/language.py", line 304, in __call__
    doc = self.make_doc(text)
  File ".../spaCy/spacy/language.py", line 279, in &lt;lambda&gt;
    self.make_doc = lambda text: self.tokenizer(text)
  File "spacy/tokenizer.pyx", line 169, in spacy.tokenizer.Tokenizer.__call__ (spacy/tokenizer.cpp:5698)
  File "spacy/tokenizer.pyx", line 196, in spacy.tokenizer.Tokenizer._tokenize (spacy/tokenizer.cpp:6272)
  File "spacy/tokenizer.pyx", line 259, in spacy.tokenizer.Tokenizer._attach_tokens (spacy/tokenizer.cpp:7144)
  File "spacy/vocab.pyx", line 201, in spacy.vocab.Vocab.get (spacy/vocab.cpp:6492)
  File "spacy/vocab.pyx", line 222, in spacy.vocab.Vocab._new_lexeme (spacy/vocab.cpp:6747)
OverflowError: value too large to convert to int32_t
&gt;&gt;&gt; nlp('Aba Aba Aba Aba')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File ".../spaCy/spacy/language.py", line 304, in __call__
    doc = self.make_doc(text)
  File ".../spaCy/spacy/language.py", line 279, in &lt;lambda&gt;
    self.make_doc = lambda text: self.tokenizer(text)
  File "spacy/tokenizer.pyx", line 155, in spacy.tokenizer.Tokenizer.__call__ (spacy/tokenizer.cpp:5527)
  File "spacy/tokenizer.pyx", line 196, in spacy.tokenizer.Tokenizer._tokenize (spacy/tokenizer.cpp:6272)
  File "spacy/tokenizer.pyx", line 259, in spacy.tokenizer.Tokenizer._attach_tokens (spacy/tokenizer.cpp:7144)
  File "spacy/vocab.pyx", line 201, in spacy.vocab.Vocab.get (spacy/vocab.cpp:6492)
  File "spacy/vocab.pyx", line 222, in spacy.vocab.Vocab._new_lexeme (spacy/vocab.cpp:6747)
OverflowError: Python int too large to convert to C long

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='zifeishan' date='2016-11-01T13:49:25Z'>
		Fixed. The fix isn't wonderful, though â€” we end up with only a 32 bit hash for the OOV words. If the store isn't flushed regularly, we'll get clashes quite often. Something to consider when designing the rest of the solution here.
		</comment>
		<comment id='4' author='zifeishan' date='2017-06-14T19:06:39Z'>
		This issue is still there. Was the fix pushed to the released version?
&lt;denchmark-code&gt;~/my_dir $ pip show spacy
Name: spacy
Version: 1.8.2
Summary: Industrial-strength Natural Language Processing (NLP) with Python and Cython
Home-page: https://spacy.io
Author: Matthew Honnibal
Author-email: matt@explosion.ai
License: MIT
Location: /usr/lib/python2.7/site-packages
Requires: numpy, murmurhash, cymem, preshed, thinc, plac, six, pathlib, ujson, dill, requests, regex, ftfy
~/my_dir $ python
Python 2.7.13 (default, Dec 22 2016, 09:22:15) 
[GCC 6.2.1 20160822] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import spacy
&gt;&gt;&gt; nlp = spacy.en.English()
&gt;&gt;&gt; nlp.vocab.strings.set_frozen(True)
&gt;&gt;&gt; nlp(u'Whataasdfsdaf')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/lib/python2.7/site-packages/spacy/language.py", line 320, in __call__
    doc = self.make_doc(text)
  File "/usr/lib/python2.7/site-packages/spacy/language.py", line 293, in &lt;lambda&gt;
    self.make_doc = lambda text: self.tokenizer(text)
  File "spacy/tokenizer.pyx", line 165, in spacy.tokenizer.Tokenizer.__call__ (spacy/tokenizer.cpp:5486)
  File "spacy/tokenizer.pyx", line 205, in spacy.tokenizer.Tokenizer._tokenize (spacy/tokenizer.cpp:6060)
  File "spacy/tokenizer.pyx", line 279, in spacy.tokenizer.Tokenizer._attach_tokens (spacy/tokenizer.cpp:7129)
  File "spacy/vocab.pyx", line 246, in spacy.vocab.Vocab.get (spacy/vocab.cpp:6986)
  File "spacy/vocab.pyx", line 269, in spacy.vocab.Vocab._new_lexeme (spacy/vocab.cpp:7249)
OverflowError: value too large to convert to int32_t

&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='zifeishan' date='2017-06-15T10:59:40Z'>
		Having same problem here following instructions from &lt;denchmark-link:https://github.com/explosion/spaCy/issues/285&gt;#285&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='6' author='zifeishan' date='2017-07-22T16:02:36Z'>
		&lt;denchmark-link:https://github.com/honnibal&gt;@honnibal&lt;/denchmark-link&gt;
. We need your help to reopen the issue and see if there is way to solve this.
		</comment>
		<comment id='7' author='zifeishan' date='2018-05-08T18:28:05Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>