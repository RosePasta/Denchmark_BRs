<bug id='5440' author='resuls' open_date='2020-05-15T07:01:08Z' closed_time='2020-05-18T15:03:23Z'>
	<summary>Spacy can't finish NER for one (very) long word.</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behavior&lt;/denchmark-h&gt;

I have a string consisting of just one repeated character 'a' (300.000 times). The problem is that when I try to find NER in this string spacy just hangs and never finishes the process. I also tried the same string at &lt;denchmark-link:https://explosion.ai/demos/displacy-ent&gt;https://explosion.ai/demos/displacy-ent&lt;/denchmark-link&gt;
 with spacy version 2.2 and the result is the same.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Operating System: Ubuntu 18.04
Python Version Used: 3.6
spaCy Version Used: 2.1.9

	</description>
	<comments>
		<comment id='1' author='resuls' date='2020-05-15T07:24:01Z'>
		This is a problem with the regex used to detect URLs (see &lt;denchmark-link:https://github.com/explosion/spaCy/issues/4362&gt;#4362&lt;/denchmark-link&gt;
). It should be improved in spacy v2.2.2-v2.2.4.
If you're not concerned about identifying URLs as tokens, you can just remove the URL regex from the tokenizer. For most languages, you can just set token_match to None:
&lt;denchmark-code&gt;nlp.tokenizer.token_match = None
&lt;/denchmark-code&gt;

A few languages use token_match to do more complicated tokenization (French, Hungarian), so you'd want to examine the token_match definition to remove the URL pattern without removing the other patterns.
		</comment>
		<comment id='2' author='resuls' date='2020-05-15T21:35:55Z'>
		That solved my issue for now.
		</comment>
		<comment id='3' author='resuls' date='2020-05-18T15:03:23Z'>
		As there is an acceptable work-around, and this should be fixed in newer versions of spaCy, I guess this issue can be closed Adriane? Feel free to reopen if you feel like there is still some action point on our side.
		</comment>
	</comments>
</bug>