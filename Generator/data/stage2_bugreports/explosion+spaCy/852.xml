<bug id='852' author='aniruddha-adhikary' open_date='2017-02-21T02:59:08Z' closed_time='2017-03-18T14:46:18Z'>
	<summary>Resource file not copied during install</summary>
	<description>
When installing spaCy by executing python setup.py install, the file spacy/fr/resources/tokenizer_exceptions is not copied over because the file has no extensions. The setup.py file only copies non-python files with extensions: '*.pyx', '*.pxd', '*.txt', '*.tokens'
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;


Operating System: OS X Yosemite
Python Version Used: 3.5.2
spaCy Version Used: 1.6.0

	</description>
	<comments>
		<comment id='1' author='aniruddha-adhikary' date='2017-02-21T10:20:47Z'>
		Thanks for pointing this out ‚Äì when I merged the French PR,¬†I thought that file was just there for reference and didn't notice it was actually read in as a data file.
We definitely prefer storing this kind of data in Python files instead of plain text ‚Äì this prevents installation and file reading errors, especially across platforms, and makes it easier to modify the data at runtime. So I'll fix this! üëç
cc: &lt;denchmark-link:https://github.com/raphael0202&gt;@raphael0202&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='aniruddha-adhikary' date='2017-02-21T10:35:34Z'>
		&lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
 Yes the file is read during tokenizer exceptions loading, sorry if it wasn't clear.
The file is quite large, that is why I included it as a text file.
		</comment>
		<comment id='3' author='aniruddha-adhikary' date='2017-02-26T18:30:55Z'>
		Hit by the same issue as well on Linux.
It prevents me from import spacy
---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
&lt;ipython-input-1-6baab52e507a&gt; in &lt;module&gt;()
----&gt; 1 import spacy
      2 import pandas as pd
      3 import numpy as np
      4 from collections import Counter
      5 from glob import glob

/usr/lib/python3.6/site-packages/spacy/__init__.py in &lt;module&gt;()
     10 from . import it
     11 from . import hu
---&gt; 12 from . import fr
     13 from . import pt
     14 from . import nl

/usr/lib/python3.6/site-packages/spacy/fr/__init__.py in &lt;module&gt;()
      5 from ..attrs import LANG
      6 
----&gt; 7 from .language_data import *
      8 from .punctuation import TOKENIZER_INFIXES, TOKENIZER_SUFFIXES
      9 

/usr/lib/python3.6/site-packages/spacy/fr/language_data.py in &lt;module&gt;()
      3 
      4 from .stop_words import STOP_WORDS
----&gt; 5 from .tokenizer_exceptions import TOKENIZER_EXCEPTIONS, TOKEN_MATCH
      6 
      7 

/usr/lib/python3.6/site-packages/spacy/fr/tokenizer_exceptions.py in &lt;module&gt;()
    215 TOKEN_MATCH = re.compile('|'.join('(?:{})'.format(m) for m in REGULAR_EXP), re.IGNORECASE).match
    216 
--&gt; 217 TOKENIZER_EXCEPTIONS = get_tokenizer_exceptions()
    218 
    219 __all__ = ["TOKENIZER_EXCEPTIONS", "TOKEN_MATCH"]

/usr/lib/python3.6/site-packages/spacy/fr/tokenizer_exceptions.py in get_tokenizer_exceptions()
    143     HYPHEN = ['-', '‚Äê']
    144 
--&gt; 145     base_exceptions = list(iter_exceptions())
    146     infixes_exceptions = []
    147 

/usr/lib/python3.6/site-packages/spacy/fr/tokenizer_exceptions.py in iter_exceptions()
     19 def iter_exceptions():
     20     with io.open(os.path.join(os.path.dirname(__file__), 'resources/tokenizer_exceptions'),
---&gt; 21                  'rt', encoding='utf8') as f:
     22         for line in f:
     23             yield line.strip('\n')

FileNotFoundError: [Errno 2] No such file or directory: '/usr/lib/python3.6/site-packages/spacy/fr/resources/tokenizer_exceptions'
		</comment>
		<comment id='4' author='aniruddha-adhikary' date='2017-03-18T14:46:18Z'>
		Fixed on master, so closing this issue!
		</comment>
		<comment id='5' author='aniruddha-adhikary' date='2018-05-09T01:39:15Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>