<bug id='1073' author='michaelcapizzi' open_date='2017-05-18T16:20:06Z' closed_time='2017-05-26T17:18:36Z'>
	<summary>remnants of default vectors when loading custom vectors</summary>
	<description>
I have a small set (only 1000) word vectors in .txt format as an example.
&lt;denchmark-code&gt;vectors_loaded = []
with open("../data/sample_w2v_no_header.txt", "r") as f:
    for line in f:
        vectors_loaded.append(line.split()[0])
len(vectors_loaded)
&gt;&gt;&gt; 999
"apples" in vectors_loaded
&gt;&gt;&gt; False
"to" in vectors_loaded
&gt;&gt;&gt; True
&lt;/denchmark-code&gt;

I can successfully load them.
&lt;denchmark-code&gt;f = open("../data/sample_w2v_no_header.txt", "r")
pr_custom_vectors = spacy.load("en_core_web_md")
pr_custom_vectors.vocab.load_vectors(f)
f.close()
to_custom_vectors = pr_custom_vectors("to")[0]
to_custom_vectors.vector.shape
&gt;&gt;&gt; 200
&lt;/denchmark-code&gt;

However, there is still a vector for apple:
&lt;denchmark-code&gt;apple_custom_vectors = pr_custom_vectors("apple")[0]
apple_custom_vectors.vector.shape
&gt;&gt;&gt; 200
&lt;/denchmark-code&gt;

And as I suspected, it looks like it's simply the first 200 dimensions of the original, default vectors.
&lt;denchmark-code&gt;pr = spacy.load("en_core_web_md")
apple = pr("apple")[0]
apple.vector.shape
&gt;&gt;&gt; 300
import numpy as np
apple.vector[0:200] == apple_custom_vectors.vector
&gt;&gt;&gt; array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True], dtype=bool)
&lt;/denchmark-code&gt;

Not surprisingly then, the cosine similarity calculation of Vectors that are "remnants" of the default, are now incorrect:
&lt;denchmark-code&gt;to_custom_vectors.similarity(to_custom_vectors)
&gt;&gt;&gt; 1.0000000636394395
apple_custom_vectors.similarity(apple_custom_vectors)
&gt;&gt;&gt; 0.73650105644500141
&lt;/denchmark-code&gt;

This is presumably because the vector_norm value is based on the original 300-dimensional vector.
I can confirm, however, that cosine similarity of successfully loaded Vectors is correct:
&lt;denchmark-code&gt;to_custom_vectors.similarity(to_custom_vectors)
&gt;&gt;&gt; 1.0000000636394395
&lt;/denchmark-code&gt;

I'm assuming this issue will not be an issue if I had loaded 300-dimensional vectors, but many of my use cases will be with smaller-dimension vectors.
So I need a way to remove all default vectors before loading my own vectors.  So if I don't load a vector for a particular word (essentially then, it's oov), then I want an empty vector (all zeros) returned, or even None.
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


Platform: Linux-4.4.0-72-generic-x86_64-with-debian-stretch-sid
Python version: 3.5.2
spaCy version: 1.7.0
Installed models: cache, pycache, en_glove_cc_300_1m_vectors-1.0.0, en-1.1.0, en

	</description>
	<comments>
		<comment id='1' author='michaelcapizzi' date='2017-05-21T20:17:37Z'>
		Thanks -- there's definitely a gap in the API here. I think the best workaround at the moment is to iterate over the vocab and assign each lex.vector to an empty vector.
		</comment>
		<comment id='2' author='michaelcapizzi' date='2017-05-22T19:33:03Z'>
		Thank you, &lt;denchmark-link:https://github.com/honnibal&gt;@honnibal&lt;/denchmark-link&gt;
 for your suggestion.
If anyone is interested, here is the code snippet to do what he suggests:
&lt;denchmark-code&gt;en_nlp = spacy.load("en")
# resize existing vectors
en_nlp.vocab.resize_vectors(size)
# clear existing vectors
for k in en_nlp.vocab:
    k.vector = np.zeros(size, dtype='float32')
# load new vectors
with open(path_to_vectors_file, "r") as f:
    return en_nlp.vocab.load_vectors(f)
&lt;/denchmark-code&gt;

This will ensure that any words for which you did not load a vector, will instead return a vector of zeros.
		</comment>
		<comment id='3' author='michaelcapizzi' date='2018-05-08T20:39:09Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>