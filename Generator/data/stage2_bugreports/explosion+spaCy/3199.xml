<bug id='3199' author='sotnyk' open_date='2019-01-26T10:20:10Z' closed_time='2019-02-08T17:33:33Z'>
	<summary>TypeError for sentences' noun_chunks if "it_core_news_sm" is used</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import spacy
from spacy.lang.it.examples import sentences as sents_it
from spacy.lang.fr.examples import sentences as sents_fr

fr_nlp = spacy.load('fr_core_news_sm')
fr_doc = fr_nlp(sents_fr[0])

it_nlp = spacy.load('it_core_news_sm')
it_doc = it_nlp(sents_it[0])

print(list(list(fr_doc.sents)[0].noun_chunks))
print(list(list(it_doc.sents)[0].noun_chunks))
&lt;/denchmark-code&gt;

For French (also have been checked small English and German vocabularies) we get:

[de dollard]

For Italian:
&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-5-03cc3443c5ec&gt; in &lt;module&gt;
----&gt; 1 list(list(it_doc.sents)[0].noun_chunks)

span.pyx in __get__()

TypeError: 'NoneType' object is not callable
&lt;/denchmark-code&gt;

Additional issue:
it_doc.noun_chunks simple returns empty list without any elements. But one or more noun chunks is expected.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.0.16
Platform: Windows-10-10.0.17763-SP0
Python version: 3.6.8

	</description>
	<comments>
		<comment id='1' author='sotnyk' date='2019-01-26T13:01:04Z'>
		Thanks for the report â€“ I really thought we had this fixed in the nightly, but I was able to reproduce the error there as well.
The problem is that Italian doesn't have a noun chunk iterator and spaCy doesn't fail gracefully here. For Doc objects, I think we already fixed this â€“ but the sentences in doc.sents are Span objects, and it seems like Span.noun_chunks still defaults to None for the noun chunks iterator (instead of just returning no noun chunks).
		</comment>
		<comment id='2' author='sotnyk' date='2019-01-27T17:45:11Z'>
		&lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
 , Thank you for explanation.
So, I should implement noun chunks recognition in Italian texts "by hand", using POS tagging feature.
		</comment>
		<comment id='3' author='sotnyk' date='2019-01-30T21:37:42Z'>
		If you do end up implementing Italian noun chunks, that'd be really cool and we'd definitely appreciate a pull request ðŸ™‚ (Maybe you can take inspiration from one of the other languages, like Spanish?)
In the meantime, fixing Span.noun_chunks like Doc.noun_chunks (if no noun chunks are available) should also solve this and prevent spaCy from raising an error.
		</comment>
		<comment id='4' author='sotnyk' date='2019-03-10T17:43:35Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>