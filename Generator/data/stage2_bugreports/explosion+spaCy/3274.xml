<bug id='3274' author='chbrown' open_date='2019-02-13T21:19:17Z' closed_time='2019-02-27T09:53:06Z'>
	<summary>Token.sent (via Span.sent) relies on dependency parse</summary>
	<description>
The &lt;denchmark-link:https://spacy.io/api/token&gt;docs&lt;/denchmark-link&gt;
 say  is a property returning "The sentence span that this token is a part of." But, surprisingly, when disabling the parser and using a custom sentence boundary detector, like &lt;denchmark-link:https://spacy.io/usage/processing-pipelines#component-example1&gt;the one in the docs&lt;/denchmark-link&gt;
 (which produces proper s when calling ),  always returns a singleton  containing  that token.
This is because &lt;denchmark-link:https://github.com/explosion/spaCy/blob/v2.0.18/spacy/tokens/token.pyx#L366&gt;Token.sent&lt;/denchmark-link&gt;
 hands off to &lt;denchmark-link:https://github.com/explosion/spaCy/blob/v2.0.18/spacy/tokens/span.pyx#L297-L303&gt;Span.sent&lt;/denchmark-link&gt;
, which depends on a full dependency parse, because it follows the dependency tree upward until . This is a problem, because with the parser disabled, every token is effectively already at the root of its tree. Thus the singleton s.
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

# this is all straight from the example in the docs except for the disable=[...] setting 
# and deleting the add_pipe(..., before='parser') placement
import spacy
def sbd_component(doc):
    for i, token in enumerate(doc[:-2]):
        if token.text == '.' and doc[i+1].is_title:
            doc[i+1].sent_start = True
    return doc
nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner']) # disable parser and ner for speed
nlp.add_pipe(sbd_component) # order in pipeline defaults to last
doc = nlp('This is a sentence. This is another sentence.')
Let's give it a shot:
sent0 = next(doc.sents)
assert sent0.text == 'This is a sentence.'  # checks out :)
That's all well and good, but then:
assert doc[0].sent == sent0 # nope - raises AssertionError :(
&lt;denchmark-h:h2&gt;Workaround/fix&lt;/denchmark-h&gt;

The following helpers rely on Token.is_sent_start and produce the expected output, but I'm not sure if this is the optimal way.
def Span__sent(span):
    # look left for nearest sent start
    l_edge = span.start
    while l_edge &gt; 0 and not span.doc[l_edge].is_sent_start:
        l_edge -= 1
    # look right for next sent start
    r_boundary = span.end
    while r_boundary &lt; len(span.doc) and not span.doc[r_boundary].is_sent_start:
        r_boundary += 1
    return span.doc[l_edge:r_boundary]
        
def Token__sent(token):
    return Span__sent(token.doc[token.i : token.i+1])

assert Token__sent(doc[0]) == sent0  # yay!
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


spaCy version: 2.0.18
Platform: Darwin-18.2.0-x86_64-i386-64bit
Python version: 3.7.2
Models: en_core_web_sm

	</description>
	<comments>
		<comment id='1' author='chbrown' date='2019-02-17T11:48:15Z'>
		Thanks for the nice analysis! I think you're definitely correct that there's a mismatch here.
More generally, we do allow custom hooks for sentences, which could be calculated using other heuristics. If you have a look at the doc.sents implementation, you'll see that it might delegate to a custom handler.
It's a tricky problem though, because it means we'd be calling into this handler on every token for the full doc, as there's no way to cache the output.
		</comment>
		<comment id='2' author='chbrown' date='2019-02-27T09:53:06Z'>
		Wait, scratch that...This shouldn't be tricky at all. I misread this; I think it's just a bug and should have a straight-forward fix.
...And in fact it seems to be fixed on develop! If you try spacy-nightly, I think you'll find this is resolved. Thanks again for the report.
		</comment>
		<comment id='3' author='chbrown' date='2019-03-29T10:42:45Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>