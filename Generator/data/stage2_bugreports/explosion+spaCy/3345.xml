<bug id='3345' author='kormilitzin' open_date='2019-02-27T23:18:11Z' closed_time='2019-03-10T14:08:31Z'>
	<summary>Bus Error 10 / Segmentation fault 11 with for loop with EntityRuler (spaCy-nightly)</summary>
	<description>
I'm using EntityRuler in my pipeline, so far so good. However, when I iterated over a collection of documents, after a while (5-10 docs) I get either 'Bus Error: 10' or 'Segmentation fault: 11' (Mac OS Mojave).
My pipeline:
I have a list of predefined 5 categories of named entities which I upload from a disk in a json format. In my pipeline, I'm adding EntityRuler before 'ner' and it works nicely. My data set is a collection of 300 documents and when I'm looping over them, I get either set fault or bus error. However (very odd!), when I'm trying to iterate over documents manually, all works fine, but when I'm using 'for' loop, I'm getting these errors.
** If I replace EntityRuler from the pipeline, I do not get any errors.

$ python test_1.py
5%|██████▌                                                                                                                                      | 14/303 [01:02&lt;18:07,  3.76s/it]
Segmentation fault: 11


$ python test_1.py
10%|██████████████▌                                                                                                                              | 29/281 [01:54&lt;14:50,  3.53s/it]
Bus error: 10

Here is my example:
&lt;denchmark-code&gt;
test_1.py:


import numpy as np
import pandas as pd
import spacy
import os, glob, re
import itertools
import pickle
from tqdm import tqdm
from spacy.pipeline import EntityRuler


nlp = spacy.load('en')
ruler = EntityRuler(nlp).from_disk('drug_patterns.jsonl')
nlp.add_pipe(ruler, before='ner')


def text_to_iob_scheme(text_i, nlp):
    doc_i = nlp(text_i)
    
    # get a list of named entities from the file
    labels = nlp_i.pipeline[2][1].labels
    
    df_tmp = pd.DataFrame([(e.text, e.ent_iob_, e.ent_type_) for e in doc_i])
    df_tmp['bio_tags'] = 'O'
    df_tmp.loc[df_tmp[1] != 'O', 'bio_tags'] = df_tmp.loc[df_tmp[1] != 'O', 1] + '-' + df_tmp.loc[df_tmp[1] != 'O', 2]
    
    # remove all IOB tags apart from those mentioned in EntityRuler 
    df_tmp.loc[~df_tmp.bio_tags.str.contains('|'.join(list(labels))), 'bio_tags'] = 'O'
    
    return df_tmp[[0, 'bio_tags']]


def main():
    
    df_texts = pd.read_csv('df_texts.csv')

    tmp_var = []

    for idx in tqdm(df_texts.doc_id.unique()):
         tmp_var.append(text_to_iob_scheme(df_texts_low.loc[df_texts.doc_id == idx, 'text'].iloc[0], nlp))
 
    output_var = pd.concat(tmp_var)
    output_var.to_csv('annotated_texts.tsv', header=False, index=False, sep='\t')
        
    
if __name__ == "__main__":

    main()


&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Operating System: Mac OSX Mojave
Python Version Used: Anaconda 3.6.7
spaCy Version Used: spaCy-nightly 2.1.0a16
Environment Information:

	</description>
	<comments>
		<comment id='1' author='kormilitzin' date='2019-02-28T08:59:02Z'>
		Thanks for the report! This sounds similar to &lt;denchmark-link:https://github.com/explosion/spaCy/issues/3338&gt;#3338&lt;/denchmark-link&gt;
.
I suspect the underlying problem might be a bug in the entity recognizer and how it deals with existing entities that were set previously in the pipeline. It should just accept them, move on and "predict around them", but in some specific cases, it seems to get confused.
If you're able to somehow narrow it down to a small set of patterns and examples and you can share those, that would be super helpful. Maybe you can print the texts before you process them and see if you can find one it always fails on?
(C-level errors like this sometimes lead to peculiar behaviour that's difficult to make sense of. At some point, a bit of arbitrary memory might have been modified, but it only leads to an issue if it's accessed later on. And this may happen in some scenarios – like when you loop over all texts – and not in others.)
		</comment>
		<comment id='2' author='kormilitzin' date='2019-02-28T09:06:00Z'>
		Hi &lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
, I can't agree more, that C-level errors are tricky to catch. I'm reading similar threads here and will experiment with your suggestions. I will keep you posted.
New alpha docs are great!
		</comment>
		<comment id='3' author='kormilitzin' date='2019-03-10T11:17:05Z'>
		Okay, I think I was able to reproduce this (or at least a segmentation fault in combination with the entity ruler). At the moment, the entity recognizer tries to prevent adding entities across sentence boundaries – but the entity ruler doesn't care.
So if the parser predicts a sentence boundary between one of the entities matched by the entity ruler, adding the entity works fine. But when the entity recognizer comes across this state of the Doc afterwards, it gets confused.
import spacy
from spacy.pipeline import EntityRuler

nlp = spacy.load("en_core_web_sm")
patterns = [{"label": "GPE", "pattern": "New York"}]
ruler = EntityRuler(nlp, patterns=patterns)

def sent_start_hack(doc):
    # Hard-code sentence boundaries because they need to
    # be set in the pipeline before the parser
    doc[4].is_sent_start = True
    return doc

nlp.add_pipe(sent_start_hack, before="parser")
nlp.add_pipe(ruler, before="ner")
doc = nlp("I live in New York")
		</comment>
		<comment id='4' author='kormilitzin' date='2019-04-09T14:38:11Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>