<bug id='2111' author='dkarmon' open_date='2018-03-18T08:16:35Z' closed_time='2018-05-21T00:26:13Z'>
	<summary>"'s" not lemmatized correctly</summary>
	<description>
I followed the rule base matcher tutorial from &lt;denchmark-link:https://spacy.io/usage/linguistic-features#example1&gt;here&lt;/denchmark-link&gt;
 and created the same rule as mentioned there:

The rule should have located sentences such as "Facebook's annoying" (as it stated in the link), but in reality, it missed that sentence.
&lt;denchmark-code&gt;matched_sents = [] # collect data of matched sentences to be visualized

def collect_sents(matcher, doc, i, matches):
    match_id, start, end = matches[i]
    span = doc[start : end] # matched span
    sent = span.sent # sentence containing matched span
    # append mock entity for match in displaCy style to matched_sents
    # get the match span by ofsetting the start and end of the span with the
    # start and end of the sentence in the doc
    match_ents = [{'start': span.start_char - sent.start_char,
                   'end': span.end_char - sent.start_char,
                   'label': 'MATCH'}]
    matched_sents.append({'text': sent.text, 'ents': match_ents })

pattern = [{'LOWER': 'facebook'}, {'LEMMA': 'be'}, {'POS': 'ADV', 'OP': '*'},
           {'POS': 'ADJ'}]
matcher.add('FacebookIs', collect_sents, pattern) # add pattern
doc = nlp("Facebook's annoying. facebook is good. facebook is very good")
matches = matcher(text) # match on your text

&lt;/denchmark-code&gt;

The output:
&lt;denchmark-link:https://user-images.githubusercontent.com/669552/37563951-d66fef4e-2a94-11e8-9592-fd3cd215e9ba.png&gt;&lt;/denchmark-link&gt;

I printed the flags and POS of the sentences and it seems that the "'s" token was successfully identified as a VERB (lemma be)
&lt;denchmark-link:https://user-images.githubusercontent.com/669552/37563965-32d76e6a-2a95-11e8-80f3-bfe88f2e6cda.png&gt;&lt;/denchmark-link&gt;

Model used: en
	</description>
	<comments>
		<comment id='1' author='dkarmon' date='2018-03-27T19:55:16Z'>
		Thanks for the report – it looks like there's actually a problem with the lemmatization of "'s". Even though the tag is correct, the lemma isn't overwritten based on the context, so the rule doesn't match. Will look into this, thanks!
		</comment>
		<comment id='2' author='dkarmon' date='2018-05-21T00:26:13Z'>
		Just tested the example again with the latest version on master and it now works as expected – I'm getting the following matches:
&lt;denchmark-code&gt;Facebook's annoying
Facebook's annoying
facebook is good
facebook is good
facebook is very good
facebook is very good
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://explosion.ai/demos/matcher?text=Facebook%27s%20annoying.%20facebook%20is%20good.%20facebook%20is%20very%20good&amp;model=en_core_web_sm&amp;pattern=%5B%7B%22id%22%3A0%2C%22attrs%22%3A%5B%7B%22name%22%3A%22LOWER%22%2C%22value%22%3A%22facebook%22%7D%5D%7D%2C%7B%22id%22%3A1%2C%22attrs%22%3A%5B%7B%22name%22%3A%22LEMMA%22%2C%22value%22%3A%22be%22%7D%5D%7D%2C%7B%22id%22%3A2%2C%22attrs%22%3A%5B%7B%22name%22%3A%22POS%22%2C%22value%22%3A%22ADV%22%7D%2C%7B%22name%22%3A%22OP%22%2C%22value%22%3A%22*%22%7D%5D%7D%2C%7B%22id%22%3A3%2C%22attrs%22%3A%5B%7B%22name%22%3A%22POS%22%2C%22value%22%3A%22ADJ%22%7D%5D%7D%5D&gt;Here's the example&lt;/denchmark-link&gt;
 in our new  visualizer 
		</comment>
		<comment id='3' author='dkarmon' date='2018-06-20T00:45:57Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>