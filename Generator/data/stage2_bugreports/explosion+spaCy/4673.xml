<bug id='4673' author='mmaybeno' open_date='2019-11-19T21:43:50Z' closed_time='2019-12-10T08:48:47Z'>
	<summary>vector_norm throws error for unusual text in sentence with more than one word.</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

I found this bug that I'm not sure if it resides in spacy or cupy. It only appears on GPU instances and when you try to get vectors from a multiple word document containing non standard words. Any help tracking it down with a potential fix would be fantastic.
&lt;denchmark-code&gt;import en_core_web_md
import spacy
spacy.prefer_gpu()
nlp = en_core_web_md.load()

doc = nlp("somerandomword")
doc.vector_norm
# works

doc = nlp("somerandomword.")
doc.vector_norm
# throws type error

doc = nlp("The somerandomword")
doc.vector_norm
# throws type error
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-96-d19c7b8f8943&gt; in &lt;module&gt;()
----&gt; 1 doc.vector_norm
doc.pyx in spacy.tokens.doc.Doc.vector_norm.__get__()
doc.pyx in __iter__()
cupy/core/core.pyx in cupy.core.core.ndarray.__add__()
cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__()
cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args()
TypeError: Unsupported type &lt;class 'numpy.ndarray'&gt;
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Operating System: Ubuntu 18.04.3
Python Version Used: 3.6.8
spaCy Version Used: 2.2.2
Environment Information: Running on Google Colab but also experienced it on other GPU instances.

&lt;denchmark-code&gt;+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |
| N/A   34C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;!pip install spacy==2.2.2
!pip install chainer
!pip install thinc_gpu_ops thinc
!python -m spacy download en_core_web_md 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mmaybeno' date='2019-11-19T21:48:19Z'>
		For context. I found this  PR that was merged recently and thought that would fix it, but building from source didn't appear to fix this issue.
&lt;denchmark-link:https://github.com/cupy/cupy/pull/2611&gt;cupy/cupy#2611&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='mmaybeno' date='2019-11-19T22:33:58Z'>
		I think it has to do with this part specifically.

&lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/tokens/doc.pyx#L439&gt;https://github.com/explosion/spaCy/blob/master/spacy/tokens/doc.pyx#L439&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='mmaybeno' date='2019-11-19T22:38:18Z'>
		Found it. There is a case where a token will have an empty numpy.ndarray instead of a cupy.core.core.ndarray, which makes incompatible types when you try and sum them.
&lt;denchmark-code&gt;[type(t.vector) for t in nlp("somerandomword.")]
# [numpy.ndarray, cupy.core.core.ndarray]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='mmaybeno' date='2019-11-19T22:59:27Z'>
		Vocab's  defaults to a numpy array, so if the word does not exist it will stay a zero numpy array. I think this is the bug. &lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/vocab.pyx#L364&gt;https://github.com/explosion/spaCy/blob/master/spacy/vocab.pyx#L364&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='mmaybeno' date='2019-11-20T06:26:03Z'>
		Attempting to create a PR for this fix but unsure on how to test it since it's cupy related.
		</comment>
		<comment id='6' author='mmaybeno' date='2019-12-10T08:48:47Z'>
		Fixed by &lt;denchmark-link:https://github.com/explosion/spaCy/pull/4680&gt;#4680&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='mmaybeno' date='2019-12-10T17:08:13Z'>
		Awesome!
		</comment>
		<comment id='8' author='mmaybeno' date='2020-01-09T18:01:55Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>