<bug id='3093' author='jarib' open_date='2018-12-25T15:33:46Z' closed_time='2018-12-27T18:56:23Z'>
	<summary>pretrained_vectors meta written inconsistently by CLI</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

I would like to build a new model more or less from scratch, using word vectors trained elsewhere:
&lt;denchmark-code&gt;spacy init-model nb path/to/model-with-vectors --vectors-loc input-vectors.txt  [...]
spacy train --vectors path/to/model-with-vectors [...]
&lt;/denchmark-code&gt;

This works well. But when I try to spacy.load() a trained model, it fails with:
OSError: [E050] Can't find model 'nb_model.vectors'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory. 
If I manually remove "pretrained_vectors": "nb_model.vectors" from {ner,tagger,parser}/cfg, the model appears to work as expected.

Full stack trace
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/__init__.py", line 21, in load
    return util.load_model(name, **overrides)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/util.py", line 116, in load_model
    return load_model_from_path(Path(name), **overrides)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/util.py", line 156, in load_model_from_path
    return nlp.from_disk(model_path)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/language.py", line 647, in from_disk
    util.from_disk(path, deserializers, exclude)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/util.py", line 511, in from_disk
    reader(path / key)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/language.py", line 643, in &lt;lambda&gt;
    deserializers[name] = lambda p, proc=proc: proc.from_disk(p, vocab=False)
  File "pipeline.pyx", line 643, in spacy.pipeline.Tagger.from_disk
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/util.py", line 511, in from_disk
    reader(path / key)
  File "pipeline.pyx", line 625, in spacy.pipeline.Tagger.from_disk.load_model
  File "pipeline.pyx", line 535, in spacy.pipeline.Tagger.Model
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/_ml.py", line 447, in build_tagger_model
    pretrained_vectors=pretrained_vectors)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/_ml.py", line 278, in Tok2Vec
    glove = StaticVectors(pretrained_vectors, width, column=cols.index(ID))
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/thinc/neural/_classes/static_vectors.py", line 41, in __init__
    vectors = self.get_vectors()
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/thinc/neural/_classes/static_vectors.py", line 52, in get_vectors
    return get_vectors(self.ops, self.lang)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/thinc/extra/load_nlp.py", line 19, in get_vectors
    nlp = get_spacy(lang)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/thinc/extra/load_nlp.py", line 11, in get_spacy
    SPACY_MODELS[lang] = spacy.load(lang, **kwargs)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/__init__.py", line 21, in load
    return util.load_model(name, **overrides)
  File "/home/ubuntu/src/spacy-nb/.venv/lib/python3.6/site-packages/spacy/util.py", line 119, in load_model
    raise IOError(Errors.E050.format(name=name))
OSError: [E050] Can't find model 'nb_model.vectors'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.


&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.1.0a4
Platform: Darwin-18.2.0-x86_64-i386-64bit
Python version: 3.6.1
Models: de, fr

	</description>
	<comments>
		<comment id='1' author='jarib' date='2018-12-25T16:13:28Z'>
		
It appears to only be a problem with non-final models (including model-best)
It can also be fixed by setting vectors.name to "nb_model.vectors" in the top-level meta.json (which is why it works in model-final).

		</comment>
		<comment id='2' author='jarib' date='2018-12-27T13:40:52Z'>
		&lt;denchmark-link:https://github.com/jarib&gt;@jarib&lt;/denchmark-link&gt;
 Thanks for the report. I think we should be able to patch this by adjusting the meta in . Would you be able to make a pull request?
		</comment>
		<comment id='3' author='jarib' date='2018-12-27T13:54:14Z'>
		Looks like the same problem occurs in , see &lt;denchmark-link:https://github.com/explosion/spaCy/issues/3067&gt;#3067&lt;/denchmark-link&gt;
:

First reported on the Prodigy forum:

You were right, that was caused by wrong meta.json, which was generated after spacy package ... --create-meta, without vector names: "vectors":{ "width":XYZ, "vectors":XYZ, "keys":XYZ} . I compared that with meta.json automatically generated from prodigy textcat.batch-train ... en_core_web_md  where vector info is stored in following format: "vectors":{... , "name":"en_core_web_md.vectors"} 
I just copied automatically generated meta.json, changed model name to my unique and was able to load my custom model with vectors inside prodigy commands :)

This caused the following error:

OSError: [E050] Can’t find model 'en_core_web_lg.vectors'. It doesn’t seem to be a shortcut link, a Python package or a valid path to a data directory.



I'll merge those issues, since this should ideally be part of the same fix!
		</comment>
		<comment id='4' author='jarib' date='2019-01-26T19:50:25Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>