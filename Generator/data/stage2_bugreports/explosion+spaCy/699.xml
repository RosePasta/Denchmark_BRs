<bug id='699' author='petterhh' open_date='2016-12-21T08:13:52Z' closed_time='2017-01-09T17:47:29Z'>
	<summary>Very poor PoS tagging after v1.4</summary>
	<description>
After updating to the new version 1.4 (via pulling the repo), the PoS tagging is pretty much ruined. Using the same model as before, having done no changes whatsoever, the tagging gives completely wrong results. For instance, it tags '.' as , similar to the errors seen in &lt;denchmark-link:https://github.com/explosion/spaCy/issues/575&gt;#575&lt;/denchmark-link&gt;
. Also, re-running the  script, as done in &lt;denchmark-link:https://github.com/explosion/spaCy/issues/579&gt;#579&lt;/denchmark-link&gt;
, I'm getting a tag accuracy of 84%, down from 96%. However, the parsing accuracy scores are the same as before. I can't find any big changes to the PoS tagging in the source code, so I'm really lost here - what might have gone wrong?
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Operating System: macOS
Python Version Used: 3.5.2
spaCy Version Used: 1.4

	</description>
	<comments>
		<comment id='1' author='petterhh' date='2016-12-21T09:39:35Z'>
		Hmm. Thanks for the report, sounds like something went very wrong!
Are the .tag_ values correct? Unfortunately I'm travelling today so can't easily test this.
		</comment>
		<comment id='2' author='petterhh' date='2016-12-21T09:50:35Z'>
		I'm sticking to the UD tag set, so tag_ and pos_ are identical. See example below.
doc = nlp(sent)
for token in doc:
    print(token.i, token.text, token.tag_, token.pos_, token.dep_, token.head.i)
Input sentence: "Jeg så John i parken" (eng. "I saw John in the park")
Output:
&lt;denchmark-code&gt;0 Jeg PRON PRON neg 1
1 så SYM SYM nmod 3
2 John PROPN PROPN nsubj 3
3 i VERB VERB ROOT 3
4 parken PROPN PROPN dobj 3
&lt;/denchmark-code&gt;

It correctly tags 'jeg' as PRON and 'John' as PROPN, but the other ones are completely off.
Edit:
And with punctuation, the output is even more puzzling.
&lt;denchmark-code&gt;0 Jeg PRON PRON neg 1
1 så SYM SYM nmod 3
2 John PROPN PROPN nsubj 3
3 i VERB VERB ROOT 3
4 parken PROPN PROPN nsubj 3
5 . ADP ADP case||nmod 3
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='petterhh' date='2016-12-21T10:10:36Z'>
		Also worth noting that the parsing (of course) suffers, e.g., 'i' (eng. 'in') is ROOT and 'Jeg' (eng. 'I') is neg - but the train_ud.py script still gives UAS of 87.55% and LAS of 84.08%! How do they relate?
		</comment>
		<comment id='4' author='petterhh' date='2016-12-22T10:21:43Z'>
		I experience a similar problem. After upgrading to 1.4, using the train_ud script, the tagger accuracy went down from 92% to 47%. The parser accuracy decreased a bit but not much (2-3%).
		</comment>
		<comment id='5' author='petterhh' date='2017-01-03T08:44:39Z'>
		Have you had a chance to look at it, &lt;denchmark-link:https://github.com/honnibal&gt;@honnibal&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='6' author='petterhh' date='2017-01-09T17:47:29Z'>
		Just pushed:
&lt;denchmark-code&gt;commit 95a52005dff1713b467b021338462560069c858b
Author: Matthew Honnibal &lt;honnibal@gmail.com&gt;
Date:   Mon Jan 9 09:55:55 2017 -0600

    Revert "Fix Issue #683: Add 'SP' to tag_map, if it's not there already, within the Morphology class."

    This reverts commit 40e71586d607626cf7b144e39c2e049916933fa7.
&lt;/denchmark-code&gt;

Still don't really understand the root cause, but this should be fixed on master now. Closing this and reopening &lt;denchmark-link:https://github.com/explosion/spaCy/issues/683&gt;#683&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='petterhh' date='2018-05-09T04:39:15Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>