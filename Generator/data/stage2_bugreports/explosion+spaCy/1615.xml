<bug id='1615' author='pokey' open_date='2017-11-20T11:28:25Z' closed_time='2018-01-16T12:40:55Z'>
	<summary>SpaCy hangs after fork</summary>
	<description>
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.0.3
Platform: Darwin-16.6.0-x86_64-i386-64bit
Python version: 3.6.0
Models: en_core_web_sm-2.0.0

&lt;denchmark-h:h2&gt;The problem&lt;/denchmark-h&gt;

SpaCy now hangs if I try to run it after forking a process on MacOS.  This worked prior to SpaCy 2.0.0.  Here's code to reproduce the issue:
import multiprocessing

import spacy


nlp = None

text_list = [
    'I love SpaCy.'
]


def process_text(text):
    return list(nlp(text))


def init_globals(_nlp):
    # These are attrs that subprocesses need copies of.  Note that we are
    # relying on Unix fork semantics to ensure that children can access these
    # variables
    global nlp

    nlp = _nlp


def run():
    nlp = spacy.load('en')
    init_globals(nlp)
    with multiprocessing.Pool(1) as pool:
        for out in pool.imap(process_text, text_list):
            print(out)


run()
	</description>
	<comments>
		<comment id='1' author='pokey' date='2017-11-23T11:40:35Z'>
		I think this is the problem: &lt;denchmark-link:https://github.com/numpy/numpy/issues/5752&gt;numpy/numpy#5752&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='pokey' date='2017-11-24T13:47:08Z'>
		Interesting.  Any idea why that would have become a problem in 2.0.0?  Using numpy differently I guess?
		</comment>
		<comment id='3' author='pokey' date='2018-01-16T12:40:55Z'>
		Yes, 1.x didn't use numpy at all during calls to the nlp pipeline.
Merging this with &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1572&gt;#1572&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='pokey' date='2018-05-08T02:55:09Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>