<bug id='4308' author='adrianeboyd' open_date='2019-09-19T08:35:19Z' closed_time='2019-09-27T14:22:35Z'>
	<summary>PhraseMatcher starts missing matches if lots of new vocab has been added</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

You need this keywords file: &lt;denchmark-link:https://github.com/mpuig/spacy-lookup/blob/master/data/keywords.txt&gt;https://github.com/mpuig/spacy-lookup/blob/master/data/keywords.txt&lt;/denchmark-link&gt;

If you process the sample keywords before doing all the extra processing, the match is found. You can also process the sample keywords again after all the extra processing and the match is still found.
If you load the sample keywords after doing all the extra processing (as below) and keyword_limit is at least 10067, the match is not found. Any lower, the match is found.
I think it's probably something related to the Vocab and not PhraseMatcher itself, but I really don't know?
&lt;denchmark-code&gt;import spacy
from spacy.matcher import PhraseMatcher
from spacy.matcher import Matcher

def run_matching(matcher, docs):
    matches = []
    for doc in docs:
        matches.extend([match for match in matcher(doc)])

    return (len(matches), matches)

def run(with_extra_keyword_processing=False):
    print("\n\nRunning test", "*with*" if with_extra_keyword_processing else "*without*", "extra document processing")

    keyword_limit = 10067

    nlp = spacy.load('en')

    if with_extra_keyword_processing:
        print("Processing a lot of keywords, then discarding...")
        unused_keywords = []
        count = 0
        with open("keywords.txt") as fileh:
            for line in fileh:
                unused_keywords.append(line.strip())
                if count &gt; keyword_limit:
                    break
                count += 1
        unused_keywords = [nlp.make_doc(keyword) for keyword in unused_keywords]

    keywords = sample_keywords()
    keywords = [nlp.make_doc(keyword) for keyword in keywords]
    print("Loaded sample keywords")
    print("Keywords:", keywords)
    print("# Keywords:", len(keywords))

    texts = sample_texts()
    docs = list(nlp.tokenizer.pipe(texts))
    print("Loaded sample docs")
    print("# Docs:", len(docs))

    smatcher = Matcher(nlp.vocab)
    pmatcher = PhraseMatcher(nlp.vocab)

    for keyword in keywords:
        smatcher.add(keyword.text, None, [{"ORTH": token.text} for token in keyword])
        pmatcher.add(keyword.text, None, keyword)

    for matcher in [smatcher, pmatcher]:
        print("\nMatcher type:", type(matcher))
        (len_matches, matches) = run_matching(matcher, docs)
        print("# Matches", len_matches)
        print("Matches:", matches)

def sample_keywords():
    return ["Hanif Kureishi"]

def sample_texts():
    return [
"""
A real triumph for Roger Michell and Hanif Kureishi, and the rest of the team. A must see for serious film lovers.
""",
]

if __name__ == "__main__":
    run()
    run(with_extra_keyword_processing=True)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;Running test *without* extra document processing
Loaded sample keywords
Keywords: [Hanif Kureishi]
# Keywords: 1
Loaded sample docs
# Docs: 1

Matcher type: &lt;class 'spacy.matcher.matcher.Matcher'&gt;
# Matches 1
Matches: [(4725172808025326492, 8, 10)]

Matcher type: &lt;class 'spacy.matcher.phrasematcher.PhraseMatcher'&gt;
# Matches 1
Matches: [(4725172808025326492, 8, 10)]


Running test *with* extra document processing
Processing a lot of keywords, then discarding...
Loaded sample keywords
Keywords: [Hanif Kureishi]
# Keywords: 1
Loaded sample docs
# Docs: 1

Matcher type: &lt;class 'spacy.matcher.matcher.Matcher'&gt;
# Matches 1
Matches: [(4725172808025326492, 8, 10)]

Matcher type: &lt;class 'spacy.matcher.phrasematcher.PhraseMatcher'&gt;
# Matches 0
Matches: []
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


spaCy version: 2.1.8
Platform: Linux-4.19.0-5-amd64-x86_64-with-debian-10.0
Python version: 3.7.3

	</description>
	<comments>
		<comment id='1' author='adrianeboyd' date='2019-10-27T14:43:57Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>