<bug id='3611' author='svlandeg' open_date='2019-04-17T19:18:58Z' closed_time='2019-07-12T08:02:03Z'>
	<summary>Textcat with setting ngram parameter</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

For a specific (confidential) dataset, I ran the textcat pipeline succesfully with the default setting ngram_size set to 1, then I set it specifically to 1 which works equally well (obviously), but then it crashes when setting this to 2 while keeping all other parameters the same:
&lt;denchmark-code&gt;textcat = nlp.create_pipe(
        "textcat",
        config={
            "exclusive_classes": False,
            "architecture": "ensemble",
            "ngram_size": 2,
        }
    )
&lt;/denchmark-code&gt;

I'm guessing that perhaps I have texts in there too short to get 2-grams from? The thinc error is a little cryptic...
Any idea what happens here?
&lt;denchmark-code&gt;Traceback (most recent call last):
  ...
  File "...\spacy_model.py", line 79, in train_model
    nlp.update(docs=texts, golds=annotations, sgd=optimizer, drop=setting.DROP_OUT, losses=losses)   
  File "C:\...\lib\site-packages\spacy\language.py", line 452, in update
    proc.update(docs, golds, sgd=get_grads, losses=losses, **kwargs)
  File "pipes.pyx", line 931, in spacy.pipeline.pipes.TextCategorizer.update
  File "C:\...\lib\site-packages\thinc\neural\_classes\feed_forward.py", line 46, in begin_update
    X, inc_layer_grad = layer.begin_update(X, drop=drop)
  File "C:\...\lib\site-packages\thinc\api.py", line 132, in begin_update
    values = [fwd(X, *a, **k) for fwd in forward]
  File "C:\...\lib\site-packages\thinc\api.py", line 132, in &lt;listcomp&gt;
    values = [fwd(X, *a, **k) for fwd in forward]
  File "C:\...\lib\site-packages\thinc\api.py", line 225, in wrap
    output = func(*args, **kwargs)
  File "C:\...\lib\site-packages\thinc\neural\_classes\feed_forward.py", line 46, in begin_update
    X, inc_layer_grad = layer.begin_update(X, drop=drop)
  File "C:\...\lib\site-packages\spacy\_ml.py", line 137, in begin_update
    ngrams.append(self.ops.ngrams(n, unigrams))
  File "ops.pyx", line 727, in thinc.neural.ops.NumpyOps.ngrams
  File "ops.pyx", line 398, in thinc.neural.ops.NumpyOps.allocate
ValueError: negative dimensions are not allowed
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


spaCy version: 2.1.3
Platform: Windows-10-10.0.17134-SP0
Python version: 3.6.8

	</description>
	<comments>
		<comment id='1' author='svlandeg' date='2019-04-19T08:59:32Z'>
		Yeah there's probably a one-word sentence in there that's messing things up. Could you print [len(doc) for doc in batch] for the failing batch? I'm guessing there'll be a 1 or a 0 in there.
		</comment>
		<comment id='2' author='svlandeg' date='2019-05-03T13:13:17Z'>
		This issue has been automatically closed because there has been no response to a request for more information from the original author. With only the information that is currently in the issue, there's not enough information to take action. If you're the original author, feel free to reopen the issue if you have or find the answers needed to investigate further.
		</comment>
		<comment id='3' author='svlandeg' date='2019-05-03T16:38:51Z'>
		&lt;denchmark-link:https://github.com/honnibal&gt;@honnibal&lt;/denchmark-link&gt;
 : Sorry for the delay.
I created a minimal unit test that exhibits this behaviour: &lt;denchmark-link:https://github.com/svlandeg/spaCy/commit/ac30d6311002aeb64a7793b2ac8578465033b6c2&gt;svlandeg@ac30d63&lt;/denchmark-link&gt;
 (I can put it in a PR if you like).
This test crashes with the same error as quoted above:

ValueError: negative dimensions are not allowed
ops.pyx:398: ValueError

If you change ngram_size to 1, or if you edit the 3rd training text to contain more than 1 word, the error goes away and the training works.
		</comment>
		<comment id='4' author='svlandeg' date='2019-05-11T14:21:41Z'>
		Thanks! Definitely a bug.
		</comment>
		<comment id='5' author='svlandeg' date='2019-06-11T09:56:43Z'>
		&lt;denchmark-link:https://github.com/svlandeg&gt;@svlandeg&lt;/denchmark-link&gt;
  - Did you have a workaround for ngram_size&gt;1 in the the meantime?
		</comment>
		<comment id='6' author='svlandeg' date='2019-06-11T09:59:46Z'>
		&lt;denchmark-link:https://github.com/tomstelk&gt;@tomstelk&lt;/denchmark-link&gt;
 : yep, if you want to use  long n-grams, you'll have to make sure that each input text has at least  tokens. So for now you'll have to "manually" pre-filter
		</comment>
		<comment id='7' author='svlandeg' date='2019-06-11T12:27:29Z'>
		Thanks &lt;denchmark-link:https://github.com/svlandeg&gt;@svlandeg&lt;/denchmark-link&gt;
 - was hoping there might be some quick hack in thinc somewhere to handle text with less than  tokens, oh well
		</comment>
		<comment id='8' author='svlandeg' date='2019-07-11T14:47:51Z'>
		&lt;denchmark-link:https://github.com/tomstelk&gt;@tomstelk&lt;/denchmark-link&gt;
 : we found the issue - should be fixed in the next version
		</comment>
		<comment id='9' author='svlandeg' date='2019-08-11T08:42:27Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>