<bug id='5458' author='Fourthought' open_date='2020-05-19T13:53:34Z' closed_time='2020-05-19T14:25:58Z'>
	<summary>Merge_noun_chunk trying to merge disjoint spans</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

` There appears to be a problem where overlapping noun_chunks are being created for a particular text. This seems to be a bug within in-built functionality. Reproduction of the problem as follows:
&lt;denchmark-code&gt;nlp = spacy.load("en_core_web_md")
nlp2 =  spacy.load("en_core_web_md"

merge_nps = nlp.create_pipe("merge_noun_chunks")
nlp.add_pipe(merge_nps)
  
merge_ents = nlp.create_pipe("merge_entities")
nlp.add_pipe(merge_ents)

text taken from: 
https://www.americanrhetoric.com/speeches/gwbushcubaindependence100th.htm
 
doc = nlp(text)

error message: ValueError: [E102] Can't merge non-disjoint spans. 'markets' is already part of 
tokens to merge. If you want to find the longest non-overlapping spans, you can use the 
util.filter_spans helper: https://spacy.io/api/top-level#util.filter_spans

for chunk in nlp(text).noun_chunks:
    if str(chunk).find("markets") != -1:
        print(chunk.start, '|', chunk)

Output: 
1232 | markets      # &lt;= the start of this chunk overlaps with the next
1231 | where markets have brought prosperity`
&lt;/denchmark-code&gt;

I should be able to temporarily resolve the problem by creating a custom add-on using  filterspans, but thought you would want to know this.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;

spaCy version: 2.2.4
Platform: Windows-10-10.0.18362-SP0
Python version: 3.7.6
	</description>
	<comments>
		<comment id='1' author='Fourthought' date='2020-05-19T14:25:58Z'>
		I think this is more or less a duplicate of &lt;denchmark-link:https://github.com/explosion/spaCy/issues/5393&gt;#5393&lt;/denchmark-link&gt;
. Thanks for the additional example!
		</comment>
	</comments>
</bug>