<bug id='2153' author='justinkreft' open_date='2018-03-28T12:34:20Z' closed_time='2019-03-10T16:21:51Z'>
	<summary>len(nlp.vocab) is unexpectedly different when using different load methods</summary>
	<description>
When loading a model from disk, the  does not appear to remain consistent. Discovered this when messing around with loading/saving models (&lt;denchmark-link:https://github.com/explosion/spaCy/issues/2083&gt;#2083&lt;/denchmark-link&gt;
), and although I discovered that the final method of loading  (  ) is not appropriate from &lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
, it is still surprising that the length of the vocab differs on loading.  At her request, I'm opening this issue.
Specifically 1) why does a base 'en' model have less vocab before it is sent to_disk and 2) although it is incorrect way of loading, why does the vocab length double when using spacy.load('en').from_disk(cwd + '/spacy_model').
See code to reproduce below. Thanks :)
&lt;denchmark-code&gt;import spacy
from spacy.language import Language
import os
cwd = os.getcwd()

###load nlp1 which is just spacy 'en'
nlp1 = spacy.load('en')
#persist model to_disk
nlp1.to_disk(cwd + '/spacy_model')
#persist model to_bytes
nlp1_bytes = nlp1.to_bytes()

print((
    len(spacy.load('en').vocab), #vocab len 57852
    len(spacy.load(cwd + '/spacy_model').vocab),  #vocab len 57864
    len(spacy.load('en').from_disk(cwd + '/spacy_model').vocab) #vocab len 115240
     ))
# &gt;&gt;&gt; (57852, 57864, 115240)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

python3 -m spacy info
&lt;denchmark-code&gt;Info about spaCy

Python version     3.4.3
Models             en
Location           /usr/local/lib/python3.4/dist-packages/spacy
Platform           Linux-3.13.0-107-generic-x86_64-with-Ubuntu-14.04-trusty
spaCy version      2.0.8
&lt;/denchmark-code&gt;

python3 -m spacy validate
&lt;denchmark-code&gt;Installed models (spaCy v2.0.8)
/usr/local/lib/python3.4/dist-packages/spacy

TYPE        NAME                  MODEL                 VERSION             
package     en-core-web-sm        en_core_web_sm        2.0.0
link        en                    en_core_web_sm        2.0.0
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='justinkreft' date='2018-11-13T20:40:14Z'>
		I can reproduce &lt;denchmark-link:https://github.com/justinkreft&gt;@justinkreft&lt;/denchmark-link&gt;
 results. There seem some hidden terms in the vocabulary. I extracted terms in each vocabulary and the sizes are the same. In addition, the three vocabulary sets are identical. According to &lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
 and spaCy documentation, "In spaCy v2.x, this isn't such a problem anymore, since the StringStore now uses hash values that are consistent across models. See here for more background and examples.", the difference between vocabularies might not affect the model outcomes.
nlp2 = spacy.load('en')
nlp3 = spacy.load(cwd + '/spacy_model')
nlp4 = spacy.load('en').from_disk(cwd + '/spacy_model')
print(len(nlp2.vocab), len(nlp3.vocab), len(nlp4.vocab))
&lt;denchmark-h:h1&gt;57852 57864 115240&lt;/denchmark-h&gt;

vocab2 = [tok.text for tok in nlp2.vocab]
vocab3 = [tok.text for tok in nlp3.vocab]
vocab4 = [tok.text for tok in nlp4.vocab]
print(len(vocab2), len(vocab3), len(vocab4))
&lt;denchmark-h:h1&gt;57388 57388 57388&lt;/denchmark-h&gt;

assert set(vocab2)==set(vocab3)
assert set(vocab2)==set(vocab4)
		</comment>
		<comment id='2' author='justinkreft' date='2019-03-10T15:40:43Z'>
		Thanks for the report, sorry it took me a while to get to this.
When deserializing, the vocab did not check whether a lexeme already existed for the data it was loading back in. We'd just save the lexeme into the hash. The vocab wouldn't actually store a duplicate entry, as the key would be there --- but we'd increment the length counter. We'd also allocate a new Lexeme object, so if you kept doing this, you'd waste a bit of memory.
		</comment>
		<comment id='3' author='justinkreft' date='2019-04-09T17:08:56Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>