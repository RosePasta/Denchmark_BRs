<bug id='2792' author='honnibal' open_date='2018-09-24T08:44:33Z' closed_time='2018-12-08T11:27:57Z'>
	<summary>ðŸ’« spaCy does not obey a consistent memory budget</summary>
	<description>
I've been concerned about this problem for a while but realised I didn't have it on the tracker. It's a high priority problem, so it definitely deserves an issue.
Currently spaCy uses a variable amount of memory, depending on the batch size and document length. If you pass in a batch with excessively long documents, memory usage can spike, which can bring down a service process. This sucks, and needs to change.
Here are the things we need to do on this:

Models need to advertise their base memory requirements
Models need to advertise their required working space per token
nlp.pipe() needs to choose batches that have a limited number of words.
If a document is too long to be processed in the memory budget, we need to either error out, or (preferable), determine split points so that we can divide the document into chunks, parse the chunks, and then reassemble into a single Doc object.

I've labelled the issue "bug" rather than enhancement because the API promises "send text, get Doc". It doesn't say "unless your texts are some unspecified combination of too-long lengths, in which case you get an OOM error or a segfault", which is how the library (sometimes) currently behaves.
	</description>
	<comments>
		<comment id='1' author='honnibal' date='2018-09-25T14:34:01Z'>
		Does dropout also affect this crash?  In my current experiment, everything was working with a certain batch_size and then I added dropout and it began to crash
		</comment>
		<comment id='2' author='honnibal' date='2018-09-25T15:30:04Z'>
		For those of us working around this issue, is there a good test so we can filter out the text that makes it crash?
		</comment>
		<comment id='3' author='honnibal' date='2018-09-27T11:28:39Z'>
		Length should be sufficient I'd think? The memory requirement should be linear in the total number of words in the batch.
I'm surprised to hear dropout makes it crash. I would've thought dropout would increase the memory usage, but not by so much? That's worth looking into, thanks.
		</comment>
		<comment id='4' author='honnibal' date='2018-12-08T11:27:57Z'>
		Resolved in v2.1.0!
		</comment>
		<comment id='5' author='honnibal' date='2019-01-07T11:28:01Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>