<bug id='191' author='chrisjbryant' open_date='2015-11-26T02:19:15Z' closed_time='2016-10-22T13:00:05Z'>
	<summary>Universal PRON tag.</summary>
	<description>
Hiya,
I was just wondering if there was any reason you deviated from the Universal Tagset by changing PRP and other pronoun tags to NOUN rather than PRON.
In fact I noticed some other changes that are different from Petrov et al.'s original proposal in lang_data/en/tag_map.json too.
Is this intended?
Thanks,
Chris
	</description>
	<comments>
		<comment id='1' author='chrisjbryant' date='2015-11-27T09:39:53Z'>
		Hey,
I first used the Google Universal Tags, and then updated to the Stanford Universal ones. I guess this slipped through, I didn't notice this tag was written differently. I'll fix it, thanks.
		</comment>
		<comment id='2' author='chrisjbryant' date='2015-11-27T14:58:16Z'>
		Ok np.
I'd not looked at the Stanford one before, but read it's no longer just a 1:1 mapping from old to new POS tags, but rather relies on additional syntactic context: (&lt;denchmark-link:https://mailman.stanford.edu/pipermail/java-nlp-user/2014-September/006335.html&gt;https://mailman.stanford.edu/pipermail/java-nlp-user/2014-September/006335.html&lt;/denchmark-link&gt;
). There also seem to be some new classes compared to Petrov's: e.g. AUX and SCONJ.
Currently I am just using your POS-tagger, but does this mean I need to parse too to get the syntactic information for the more accurate POS tags?
I see you also put some of the Universal Features in the tag_map.json too. Is there any way to access these for a particular token?
Thanks again and keep up the good work!
Chris
		</comment>
		<comment id='3' author='chrisjbryant' date='2015-11-27T16:41:59Z'>
		Bear in mind that you can always use the PTB tags, via the token.tag and token.tag_ attribute.
The lack of 1-to-1 mapping is sort of troubling =/. The thing is, the tagger should really be trained to predict fine-grained, language-specific tags. They can be leaned more accurately and they make better features for downstream tasks. I like the idea of supporting the coarse-grained representation. But I don't want to learn a model just to do that.
		</comment>
		<comment id='4' author='chrisjbryant' date='2015-11-27T18:25:20Z'>
		Yup, I have been using the PTB tags as well; e.g. to catch pronouns.
I also like the idea of the coarse-grained tags (and in fact that was one of the reasons I chose spaCy!) but it does seem like a lot of extra effort to get the Stanford Universal tags. Unfortunately, I'm now noticing quite a lot of differences between your current Stanford mapping file and the one on their website (&lt;denchmark-link:https://universaldependencies.github.io/docs/tagset-conversion/en-penn-uposf.html&gt;https://universaldependencies.github.io/docs/tagset-conversion/en-penn-uposf.html&lt;/denchmark-link&gt;
) which it also warns is "only an approximation".
Tbh, I'd probably just prefer the simpler 1:1 Google Universal tags, even if they aren't quite as good as the Stanford ones.
Chris
		</comment>
		<comment id='5' author='chrisjbryant' date='2015-11-28T21:22:20Z'>
		Would prefer the Stanford ones. They're regularly maintained and updated.
		</comment>
		<comment id='6' author='chrisjbryant' date='2015-11-28T23:00:35Z'>
		So would I if they were easy to implement.
As it is however, there are problems with the v0.97 Stanford Universal Tags which might not be easy to fix. So we have a choice between the older but more consistent Google tags or the newer but more complicated Stanford tags.
Ultimately, I don't know how much difference it'll make, but missing a universal PRON tag in the current Stanford version (amongst other things) seemed like a big deal...
		</comment>
		<comment id='7' author='chrisjbryant' date='2015-11-30T21:35:58Z'>
		It seems PRON tag exists in v1.2? I think most people just use PTB but if one crosses over to multi-lingual parsing I personally like much the fact that UD is regularly released though the data is not much yet.
		</comment>
		<comment id='8' author='chrisjbryant' date='2015-12-09T20:50:53Z'>
		On (I think) a related note, would you consider also adding the PROPN (proper noun) universal tag? I know that corresponds to NNP or NNPS in PTB, but for other languages and general convenience, it would be great to have in the .pos and .pos_ attributes.
		</comment>
		<comment id='9' author='chrisjbryant' date='2016-04-14T10:49:27Z'>
		Finally fixed this. Sorry about letting this slip through the cracks for so long!
		</comment>
		<comment id='10' author='chrisjbryant' date='2016-04-14T13:03:35Z'>
		Sorry to rain on your parade, but the tag_map.json still doesn't look like the one on the Stanford website, although you fixed a couple of them:
&lt;denchmark-link:http://universaldependencies.org/tagset-conversion/en-penn-uposf.html&gt;http://universaldependencies.org/tagset-conversion/en-penn-uposf.html&lt;/denchmark-link&gt;


You have an extra pos "", maybe by design
"""": {"pos": "punct", "puncttype": "quot", "punctside": "fin"},
NIL doesn't go to anything in spacy
"NIL": {"pos": ""},
It goes to X in Stanford.
PDT goes to ADJ in spacy, but DET in Stanford.
PRP$ goes to ADJ in spacy, but DET in Stanford.
WDT goes to ADJ in spacy, but DET in Stanford.
WP goes to NOUN in spacy, but PRON in Stanford.
WP$ goes to ADJ in spacy, but DET in Stanford.
AFX is mentioned twice in spacy - once going to ADJ, then going to X
HYPH is mentioned twice in spacy - both going to PUNCT, but the first has extra detail.
There are several other tags on the end of the file not in the Stanford list; SP, ADD, NFP, GW, XX, BES and HVS.

If you make these changes, I'll definitely start using the coarse tags in spacy, but until then, I still feel forced to define the mapping myself.
Also, when you change this file, are they immediately updated in spacy? I know I'll probably have to do more general update, but will that be immediate or do I have to wait for the next release?
		</comment>
		<comment id='11' author='chrisjbryant' date='2016-04-14T13:37:06Z'>
		Thanks. I keep getting confused here, because the names of these things are very similar and the contents overlap so much. I also keep sliding between talking about what spaCy is doing currently, and discussing what we should be doing.
Let's set focus on what we should do. Here are some things I think we want:

We want to learn fine-grained tags in the statistical model
We want coarse grained tags available in the API
We want the coarse tags to follow a standard. We don't want half a standard.

Here are some smaller considerations:

We'd like to produce the coarse tags from a deterministic mapping (not a model)
The Stanford set has better adoption by others.
The Stanford tags are a bit more complete/useful

As much as I'd like to support the Stanford scheme, I think it's a higher priority to have a simple mapping. So I propose that the policy is we're using the Google scheme. At some point in future I'd like to switch to full universal dependencies support, but for now I think it's better to be clear about the tag mapping.
If we follow this policy, we'll revert the change I just made to the tag map, and avoid using the PROPN tag. It's easy to fix the lemmatizer in another way.
Thoughts? &lt;denchmark-link:https://github.com/wbwseeker&gt;@wbwseeker&lt;/denchmark-link&gt;
 , I know you're advocating for eventual adoption of UD. What are your thoughts on how we should do the coarse grained mapping at the moment? Is the Google Universal Tag Set okay for German?
		</comment>
		<comment id='12' author='chrisjbryant' date='2016-04-14T13:57:18Z'>
		Why don't we just adopt the tag set defined by UD?: &lt;denchmark-link:http://universaldependencies.org/u/pos/index.html&gt;http://universaldependencies.org/u/pos/index.html&lt;/denchmark-link&gt;

It is based on the Google Tag Set but was improved and people work on it. I don't understand why the Google Tags are supposed to be simpler than UPOS. It is just less of them, and noone actively works on it anymore because it was superseded by UPOS.
Looking at &lt;denchmark-link:http://universaldependencies.org/tagset-conversion/en-penn-uposf.html&gt;http://universaldependencies.org/tagset-conversion/en-penn-uposf.html&lt;/denchmark-link&gt;
, it just defines a mapping from Penn Treebank Tags to UPOS. I would advocate for using this mapping. (I can understand if we want to wait to adopt the syntactic annotation, because this is still changing. But this isn't the case for the POS tags)
For German, I already use UPOS in the tagmap.json.
We will have to add some tags to deal with stuff that UD doesn't annotate. Like space tokens. But as long as we just add and don't change, this won't matter.
		</comment>
		<comment id='13' author='chrisjbryant' date='2016-04-14T14:07:52Z'>
		I think the issue is that the real UD mapping is not 1:1 and requires additional information, e.g. lemmas.
That said, I do prefer some of the mappings in the approximated UPOS scheme over the Google one, so am now leaning more towards that. Also, I wouldn't think of the approximation as a half standard, but rather a simplified version of a full standard. By the very fact that it's available, there must be some demand for it, right?
Edit: Whatever you decide, it would be good if you could mention whichever scheme you use on the docs!
		</comment>
		<comment id='14' author='chrisjbryant' date='2016-04-17T13:46:51Z'>
		Okay. UD it is. We'll use the suggested mapping.
&lt;denchmark-link:https://github.com/wbwseeker&gt;@wbwseeker&lt;/denchmark-link&gt;
 , would you be able to take care of this? I think we need the following:

Fix the English tag_map.json
Fix the data in spacy/attrs.pyx, spacy/attrs.pxd, spacy/symbols.pyx, spacy/symbols.pxd
Fix the docs for Token.pos
Fix the explanation in the annotation specs

Additionally if you have a clever idea to make the mapping to the POS attribute more accurate by using the lemmas, then feel free to suggest it (or just implement it, if that's easier than explaining). Otherwise, I'm happy to use the suggested partially lossy mapping.
		</comment>
		<comment id='15' author='chrisjbryant' date='2016-04-17T14:02:32Z'>
		sure, no problem.

Am 17.04.2016 um 15:46 schrieb Matthew Honnibal notifications@github.com:
Okay. UD it is. We'll use the suggested mapping.
@wbwseeker https://github.com/wbwseeker , would you be able to take care of this? I think we need the following:
Fix the English tag_map.json
Fix the data in spacy/attrs.pyx, spacy/attrs.pxd, spacy/symbols.pyx, spacy/symbols.pxd
Fix the docs for Token.pos
Fix the explanation in the annotation specs
—
You are receiving this because you were mentioned.
Reply to this email directly or view it on GitHub #191 (comment)

		</comment>
		<comment id='16' author='chrisjbryant' date='2018-05-09T09:11:59Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>