<bug id='2201' author='winobes' open_date='2018-04-10T14:33:59Z' closed_time='2018-04-10T19:10:49Z'>
	<summary>Keyerror related to `Language.pipe` after loading `Doc` with the same `Vocab`</summary>
	<description>
&lt;denchmark-code&gt;import spacy

def annotate():
    nlp = spacy.load('en')

    raw_texts = [u'So Crazy when they play my @SantanaRxcks song', u'This is a test.']
    # raw_texts = [raw_texts[0]]

    docs = []
    for doc in nlp.pipe(raw_texts, batch_size=10000, n_threads=1):
        docs.append(doc)
    # docs = [nlp(text) for text in raw_texts]

    return docs[0].to_bytes()

def load_doc(doc_bytes):
    nlp = spacy.load('en')
    doc = spacy.tokens.Doc(nlp.vocab).from_bytes(doc_bytes)
    for token in doc:
        print(u"{} {} {}".format(token, token.lemma_, token.pos_))

if __name__ == '__main__':
    print("Annotating...")
    doc_bytes = annotate()
    print("Loading...")
    load_doc(doc_bytes)

&lt;/denchmark-code&gt;

Running this code I get the following error:
&lt;denchmark-code&gt;  File "/home/me/bug.py", line 23, in load_doc
    print(u"{} {} {}".format(token, token.lemma_, token.pos_))
  File "token.pyx", line 746, in spacy.tokens.token.Token.lemma_.__get__
  File "strings.pyx", line 118, in spacy.strings.StringStore.__getitem__
KeyError: 15434898665801592255L
&lt;/denchmark-code&gt;

In addition to not finding this lemma, the re-loaded Doc object doesn't have any pos_.
Curiously, the error doesn't occur if the first sentence is the only document (i.e. the first comment) or if the documents are created with nlp.__call__ (i.e. the second comment).
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


Python version: 2.7.12
Platform: Linux-4.10.0-38-generic-x86_64-with-Ubuntu-16.04-xenial
spaCy version: 2.0.10
Models: en, en_core_web_md

	</description>
	<comments>
		<comment id='1' author='winobes' date='2018-04-10T19:10:37Z'>
		First: We actually  came across a bug in  that would set  to incorrectly and was likely the cause of the tags not being set correctly. It's already fixed – see &lt;denchmark-link:https://github.com/explosion/spaCy/commit/5ecb274764b085bd6fe49fcc573618e430051259&gt;5ecb274&lt;/denchmark-link&gt;
.
About the : I think the problem here is that you are using the "same" vocab – but not actually the same instance. The hash values in spaCy v2.x are nice because the same words will always receive the same hashes – but they're not reversible, and since your second  has never seen some of the lexemes you're processing, the  doesn't have an entry for  (see the last example &lt;denchmark-link:https://spacy.io/usage/spacy-101#vocab&gt;in this docs section&lt;/denchmark-link&gt;
 for more details).
Here's a working proof of concept:
nlp = spacy.load('en')
raw_texts = [u'So Crazy when they play my @SantanaRxcks song', u'This is a test.']
docs = nlp.pipe(raw_texts)
doc = list(docs)[0]
doc_bytes = doc.to_bytes()
new_doc = spacy.tokens.Doc(nlp.vocab).from_bytes(doc_bytes)
print([t.lemma_ for t in new_doc])
# ['so', 'crazy', 'when', '-PRON-', 'play', '-PRON-', '@santanarxck', 'song']
		</comment>
		<comment id='2' author='winobes' date='2018-05-10T19:57:51Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>