<bug id='4054' author='svlandeg' open_date='2019-07-31T19:01:28Z' closed_time='2019-08-01T15:14:01Z'>
	<summary>No valid 'lang' when creating blank model with vocab from file</summary>
	<description>
&lt;denchmark-h:h2&gt;How to reproduce the behaviour&lt;/denchmark-h&gt;

Previously, I saved en_core_web_lg to file, creating a vocab subdirectory, and its meta.json which reads (among other things)

"lang":"en",
"name":"core_web_lg"

Now, I'm attempting to use the vocab subdir as source for a blank model:
&lt;denchmark-code&gt;vocab = Vocab().from_disk(vocab_dir)
nlp = spacy.blank("en", vocab=vocab)
print(nlp("This is a test sentence"))
nlp.to_disk(output_dir)
nlp2 = spacy.load(output_dir)
print(nlp2("This is another test sentence"))
&lt;/denchmark-code&gt;

Which fails, giving the error ValueError: [E054] No valid 'lang' setting found in model meta.json.
And indeed, the meta.json of the new nlp object reads

"lang":""

Is this expected behaviour? When I run this in a unit test and replace the second line with
&lt;denchmark-code&gt;nlp = spacy.blank("en", vocab=en_vocab)
&lt;/denchmark-code&gt;

it does work correctly.
&lt;denchmark-h:h2&gt;Your Environment&lt;/denchmark-h&gt;


spaCy version: 2.1.6
Platform: Windows-10-10.0.17763-SP0
Python version: 3.6.7

	</description>
	<comments>
		<comment id='1' author='svlandeg' date='2019-07-31T19:34:02Z'>
		I think the problem might be related to this:



spaCy/spacy/language.py


        Lines 175 to 176
      in
      23ec07d






 def meta(self): 



 self._meta.setdefault("lang", self.vocab.lang) 





When you call , it loads in the data, but it does that all on top of a  . The language-specific  is created via the &lt;denchmark-link:https://github.com/explosion/spaCy/blob/23ec07debdd568f09c7c83b10564850f9fa67ad4/spacy/language.py#L44&gt;create_vocab&lt;/denchmark-link&gt;
 classmethod of the given  defaults. The blank  model has that, but it's then overwritten by the vocab you pass in.
I do agree that this is slightly confusing, and I'm not immediately sure what the solution should be. In general, for a use case like this, the recommended best practice would probably be to remove all the pipeline components you don't want, which will give you the desired result: a base model with the vocab.
		</comment>
		<comment id='2' author='svlandeg' date='2019-07-31T20:45:57Z'>
		Ok, that makes sense. Thanks for the detailed explanation :-)
I was testing this in the context of serializing the KnowledgeBase for the entity linking functionality. To read the KB back in, you need at least the original vocab object, or otherwise the corresponding nlp object you used to create the KB with.
Because you have the option of loading the KB back in with the vocab only, you can then also create a blank English model with this vocab and create a new entity_linking pipe and have a functional pipeline, at least for demonstration purposes (in practice you'd need ner too, ofcourse).
See here: &lt;denchmark-link:https://github.com/svlandeg/spaCy/blob/feature/el-docs/examples/training/train_entity_linker.py&gt;https://github.com/svlandeg/spaCy/blob/feature/el-docs/examples/training/train_entity_linker.py&lt;/denchmark-link&gt;

This works, but the IO doesn't because of the reasons described above.
But if you think that use-case is not relevant, we can just assume we always have access to the original nlp object with the right vocab...
		</comment>
		<comment id='3' author='svlandeg' date='2019-08-31T15:42:33Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>