<bug id='3839' author='honnibal' open_date='2019-06-12T11:25:04Z' closed_time='2019-07-11T11:25:19Z'>
	<summary>Matcher returns incorrect match ID when optional tokens exhaust the sentence</summary>
	<description>
This feels very similar to a previous matcher bug. The minimal example is:
import spacy
from spacy.matcher import Matcher
nlp = spacy.blank("en")
doc = nlp("terrific group of people")

# Works
matcher = Matcher(nlp.vocab)
pat1 = [{'LOWER' : "terrific"}, {"OP": "?"}, {'LOWER' : "group"}]
matcher.add('PAT', None, pat1)
matches = matcher(doc)
assert matches[0][0] == nlp.vocab.strings["PAT"]
# Fails
matcher = Matcher(nlp.vocab)
matcher.add('PAT', None, pat2)
pat2 = [{'LOWER' : "terrific"}, {"OP": "?"}, {"OP": "?"}, {'LOWER' : "group"}]
matcher.add('PAT', None, pat2)
matches = matcher(doc)
assert matches[0][0] == nlp.vocab.strings["PAT"]
	</description>
	<comments>
		<comment id='1' author='honnibal' date='2019-06-12T11:26:25Z'>
		&lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
 I'm having trouble finding the previous issue. If you happen to remember it, it'd be useful to cross-reference it here.
		</comment>
		<comment id='2' author='honnibal' date='2019-06-12T11:28:21Z'>
		&lt;denchmark-link:https://github.com/honnibal&gt;@honnibal&lt;/denchmark-link&gt;
 I think you mean the "ghost match" issue (see &lt;denchmark-link:https://github.com/explosion/spaCy/issues/3291&gt;#3291&lt;/denchmark-link&gt;
)? The matcher would produce "ghost matches" with match IDs that weren't in the string store.
Since the IDs vary on each invocation, it's possible that this is a memory issue and the same issue that causes some very random and confusing test failures we've observed and a segmentation fault that was reported when using the matcher.
		</comment>
		<comment id='3' author='honnibal' date='2019-06-13T17:25:46Z'>
		I was going to submit an issue a while ago about this multiple "OP":"?", finally have time to do it, and found this issues.
I will add my test case that I typed up early here for reference:
pattern = [{"LOWER":"start"},{"OP":"?"},{"OP":"?"},{"OP":"?"},{"LOWER":"end"}]
matcher = Matcher(nlp.vocab)
matcher.add("OP_3", None, pattern)
problem4 = matcher(nlp("padding start 1 2 3 4 end padding"))
problem3 = matcher(nlp("padding start 1 2 3 end padding"))
problem2 = matcher(nlp("padding start 1 2 end padding"))
problem1 = matcher(nlp("padding start 1 end padding"))
problem0 = matcher(nlp("padding start end padding"))

print(problem4) # No match; Expected
print(nlp.vocab.strings[problem3[0][0]]) # Match; Expected
print(nlp.vocab.strings[problem2[0][0]]) # Match; Expected
print(nlp.vocab.strings[problem1[0][0]]) # Match; KeyError: "[E018] Can't retrieve string for hash
print(nlp.vocab.strings[problem0[0][0]]) # Match; Wrong key problem0[0][0]=0
		</comment>
		<comment id='4' author='honnibal' date='2019-08-10T11:42:33Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>