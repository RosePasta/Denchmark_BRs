<bug id='1336' author='jaju' open_date='2017-09-19T15:41:47Z' closed_time='2017-09-21T18:17:27Z'>
	<summary>Entity recognition is inconsistent across runs</summary>
	<description>
I'm attempting some entity recognition, and the results keep changing for the same sentence when I reload the same model.
Sample run snapshot (verbatim)
&lt;denchmark-code&gt;&gt;&gt;&gt; import spacy
&gt;&gt;&gt; nlp = spacy.load('en_core_web_sm')
&gt;&gt;&gt; d = nlp('The company that IBM bought had rejected Apple and Google bids')
&gt;&gt;&gt; d.ents
()
&gt;&gt;&gt; nlp = spacy.load('en_core_web_sm')
&gt;&gt;&gt; d = nlp('The company that IBM bought had rejected Apple and Google bids')
&gt;&gt;&gt; d.ents
()
&gt;&gt;&gt; nlp = spacy.load('en_core_web_sm')
&gt;&gt;&gt; d = nlp('The company that IBM bought had rejected Apple and Google bids')
&gt;&gt;&gt; d.ents
(IBM,)
&gt;&gt;&gt; nlp = spacy.load('en_core_web_sm')
&gt;&gt;&gt; d = nlp('The company that IBM bought had rejected Apple and Google bids')
&gt;&gt;&gt; d.ents
(IBM,)
&gt;&gt;&gt; nlp = spacy.load('en_core_web_sm')
&gt;&gt;&gt; d = nlp('The company that IBM bought had rejected Apple and Google bids')
&gt;&gt;&gt; d.ents
(IBM, Apple)
&lt;/denchmark-code&gt;

I'm not sure, but this is unexpected given nothing really changes.
Output of spacy info --markdown
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.0.0a13
Platform: Darwin-16.7.0-x86_64-i386-64bit
Python version: 3.6.2
Models: en, en_core_web_sm, en_vectors_web_lg

	</description>
	<comments>
		<comment id='1' author='jaju' date='2017-09-19T15:58:09Z'>
		Thanks for the report -- definitely something wrong here.
		</comment>
		<comment id='2' author='jaju' date='2017-09-19T16:13:46Z'>
		Please let me know if I can provide any more information, or run additional tests.
Thanks!
		</comment>
		<comment id='3' author='jaju' date='2017-09-19T16:51:50Z'>
		I have it reproduced now, so it shouldn't be long to get the fix sorted :)
		</comment>
		<comment id='4' author='jaju' date='2017-09-19T18:19:45Z'>
		Something similar -
&lt;denchmark-code&gt;&gt;&gt;&gt; doc = nlp(u"She Was among first investors to get approval for Biotech Fund.")
&gt;&gt;&gt; doc.ents
(first, Biotech Fund)
&gt;&gt;&gt; doc = nlp(u"She Was among the first investors to get approval for Biotech Fund.")
&gt;&gt;&gt; doc.ents
()
&gt;&gt;&gt; doc = nlp(u"I Was among first investors to get approval for Biotech Fund.")
&gt;&gt;&gt; doc.ents
(Biotech Fund,)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='jaju' date='2017-09-19T19:54:11Z'>
		The current version on develop seems to have this fixed already. Hopefully I can get it pushed to spacy-nightly tonight. (The new model also has better parse accuracy, which is nice...)
There are two possible explanations for the inconsistency:


Some model preserves its random initialization even after loading (e.g. the model adds the loaded weights, instead of replacing them)


Somewhere there's an out-of-bounds read. The eventual calculations would then depend on values from neighbouring memory locations, which would vary between runs.


I think 2) is probably more likely. The good news is that the instability occurs also in the tensor values, not just in the parser or tagger. This means there's only a few places to look. It's probably the maxout or convolution functions.
		</comment>
		<comment id='6' author='jaju' date='2017-09-20T04:58:15Z'>
		I updated to the latest nightly build, and the issue has disappeared.
Thanks a lot! That's admirably quick! :)
		</comment>
		<comment id='7' author='jaju' date='2017-09-21T18:17:27Z'>
		No worries!
		</comment>
		<comment id='8' author='jaju' date='2018-05-08T16:27:51Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>