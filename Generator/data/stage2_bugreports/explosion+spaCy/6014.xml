<bug id='6014' author='chopeen' open_date='2020-09-02T11:11:34Z' closed_time='2020-09-02T13:15:46Z'>
	<summary>Off-by-one error when reporting best iteration of `spacy train`</summary>
	<description>
I am running spacy train to train a NER model, the output is:
&lt;denchmark-code&gt;Training pipeline: ['ner']
Starting with base model 'en_core_web_lg'
Replacing component from base model 'ner'
Counting training words (limit=0)

Itn  NER Loss   NER P   NER R   NER F   Token %  CPU WPS
---  ---------  ------  ------  ------  -------  -------
  1  62234.469  62.796  41.864  50.237  100.000    23189                        
  2  19664.287  65.930  51.817  58.027  100.000    27767                        
  3  15704.214  63.482  53.002  57.770  100.000    29516                        
  4  16203.358  65.178  56.477  60.516  100.000    27201                        
  5  12726.774  65.704  59.321  62.350  100.000    29252                        
  6  12014.974  66.430  59.084  62.542  100.000    27897                        
  7  11054.259  66.725  60.190  63.289  100.000    28087                        
  8  10016.129  65.371  58.452  61.718  100.000    26646                        
Early stopping, best iteration is: 6
Best score = 63.40121792913442; Final iteration score = 62.57056616419042
&lt;/denchmark-code&gt;

The message says "best iteration is: 6" even though the F-score for iteration 7 is higher. Is it a bug or am I reading this output wrong?
This issue appears consistently for different models I have been training today.
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.3.2
Platform: Linux-4.15.0-112-generic-x86_64-with-glibc2.10
Python version: 3.8.5

	</description>
	<comments>
		<comment id='1' author='chopeen' date='2020-09-02T11:23:27Z'>
		The calculation is implemented in &lt;denchmark-link:https://github.com/explosion/spaCy/blob/597bcc629e173dfd87422188dc76a2f1053a9bba/spacy/cli/train.py#L559&gt;train.py&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;if iter_since_best &gt;= n_early_stopping:
    msg.text(
        "Early stopping, best iteration "
        "is: {}".format(i - iter_since_best)
    )
&lt;/denchmark-code&gt;

i starts from zero and the iterations are numbered from 1 (column Itn), so I think the calculation should be (i + 1) - iter_since_best. If my reasoning I correct, I am happy to submit a PR.
		</comment>
		<comment id='2' author='chopeen' date='2020-09-02T11:31:41Z'>
		Sure, a PR would be welcome! I think we updated the console output to start counting the iterations from 1 at some point, but missed this section in the output. I'm pretty sure it's still correctly selecting/saving the best model in the saved output, right?
		</comment>
		<comment id='3' author='chopeen' date='2020-09-02T12:12:09Z'>
		model-best == model6 and model directories are numbered from 0, so it is correct.
		</comment>
	</comments>
</bug>