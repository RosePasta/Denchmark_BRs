<bug id='4616' author='Branislava' open_date='2019-11-09T14:50:51Z' closed_time='2019-11-11T08:52:33Z'>
	<summary>Missing AttributeError: 'spacy.tokens.token.Token' object has no attribute 'check_morph'</summary>
	<description>
This is my configuration

spaCy version    2.2.2
Location         /usr/local/lib/python3.6/dist-packages/spacy
Platform         Linux-4.15.0-66-generic-x86_64-with-debian-buster-sid
Python version   3.6.5

The script
&lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/bin/ud/ud_run_test.py&gt;https://github.com/explosion/spaCy/blob/master/bin/ud/ud_run_test.py&lt;/denchmark-link&gt;

e.g. in line 139 invokes
token.check_morph(Fused_begin)
but when I type
import spacy; print(dir(spacy.tokens.token.Token))
I get the following output
['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_extension', 'has_vector', 'head', 'i', 'idx', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'shape', 'shape_', 'similarity', 'string', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']
i.e. there is no method check_morph() and this script gives me the message
AttributeError: 'spacy.tokens.token.Token' object has no attribute 'check_morph'
Is this method perhaps hidden in some older version, or am I making a mistake somewhere?
	</description>
	<comments>
		<comment id='1' author='Branislava' date='2019-11-09T15:53:17Z'>
		This is an older script and I don't know for sure, but I suspect this was a developmental feature that wasn't added to the library in the end.
If you want to see how to run spacy on all the UD languages that spacy supports, check out run_eval.py instead. It has been updated and tested recently.
(Since the script will stop when it fails to initialize a language, you might have to comment out some of the languages that use external tokenizers if you don't have all the requirements installed, typically: ja, ko, vi, zh. And even with the external tokenizers installed, vi and zh will probably have errors during the evaluation, so don't be surprised if they're not working yet.)
		</comment>
		<comment id='2' author='Branislava' date='2019-11-09T16:50:35Z'>
		Wait, some recent changes have caused bugs. I know that the version of these scripts (, , and ) was working at &lt;denchmark-link:https://github.com/explosion/spaCy/commit/d844030fd880165f08bf88f4fd386ef878e63360&gt;d844030&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='Branislava' date='2019-11-11T07:44:28Z'>
		
This is an older script and I don't know for sure, but I suspect this was a developmental feature that wasn't added to the library in the end.
If you want to see how to run spacy on all the UD languages that spacy supports, check out run_eval.py instead. It has been updated and tested recently.
(Since the script will stop when it fails to initialize a language, you might have to comment out some of the languages that use external tokenizers if you don't have all the requirements installed, typically: ja, ko, vi, zh. And even with the external tokenizers installed, vi and zh will probably have errors during the evaluation, so don't be surprised if they're not working yet.)

Thank you, that works perfectly!
		</comment>
		<comment id='4' author='Branislava' date='2019-11-11T08:52:33Z'>
		Good to hear, thanks!
		</comment>
		<comment id='5' author='Branislava' date='2019-12-11T10:00:52Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>