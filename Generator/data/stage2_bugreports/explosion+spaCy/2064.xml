<bug id='2064' author='kevinrosenberg21' open_date='2018-03-06T16:34:26Z' closed_time='2018-12-10T15:14:52Z'>
	<summary>Python kernel dies and restarts when parsing with multiple pipeline components</summary>
	<description>
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.0.5
Python version: 3.5.2
Models: en, es
Platform: Linux-4.13.0-36-generic-x86_64-with-debian-stretch-sid

Hi everyone,
I'm trying to train a model that recognizes entities and then finds the relationships between them through a dependency parser.
The code I'm using for training is:
&lt;denchmark-code&gt;nlp = spacy.blank('es')
def custom_tokenizer(nlp):
    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,
                                suffix_search=nlp.tokenizer.suffix_search,
                                infix_finditer=compile_infix_regex().finditer,
                                token_match=nlp.tokenizer.token_match)

from gensim.models import Word2Vec
word_to_vec = Word2Vec.load(w2v_dir)
nlp.vocab.reset_vectors(width=128)

for word in word_to_vec.wv.vocab:
    nlp.vocab.set_vector(word, word_to_vec.wv[word])
    
nlp.tokenizer = custom_tokenizer(nlp)

import copy
TRAIN_DATA_FULL = copy.deepcopy(TRAIN_DATA)
ner = nlp.create_pipe('ner')
nlp.add_pipe(ner, first=True)
def merge_entities(doc):
    for ent in doc.ents:
        ent.merge()
    return doc
def custom_sbd(doc):
    doc[0].sent_start = True
    for i in range(1, len(doc)):
        doc[i].sent_start = False
    return doc

nlp.add_pipe(merge_entities, after='ner')
nlp.add_pipe(custom_sbd, after='merge_entities')
parser = nlp.create_pipe('parser')
nlp.add_pipe(parser, last=True)

    for dep in annotations.get('deps', []):
        parser.add_label(dep)
    for ent in annotations.get('entities', []):
        ner.add_label(ent[2])

nlp_make_ner = spacy.blank('es')
nlp_make_ner.vocab = nlp.vocab
nlp_make_ner.tokenizer = custom_tokenizer(nlp_make_ner)

for i,data in enumerate(TRAIN_DATA_FULL):
    doc = make_doc_from_ner_train_data(data,nlp_make_ner)
    doc = merge_entities(doc)
    TRAIN_DATA_FULL[i] = add_token_heads(data, doc)
    TRAIN_DATA_FULL[i] = add_heads_and_deps(data, doc)
    TRAIN_DATA_FULL[i][1].pop('entities_idx')
    TRAIN_DATA_FULL[i][1].pop('entities_token_idx')
    TRAIN_DATA_FULL[i][1].pop('relations')
    TRAIN_DATA_FULL[i][1].pop('relation_to')
    TRAIN_DATA_FULL[i][1].pop('main_entity_idx')

TRAIN_DATA_NER = copy.deepcopy(TRAIN_DATA_FULL)
for data in TRAIN_DATA_NER:
    data[1].pop('heads')
    data[1].pop('deps')
optimizer = nlp.begin_training()
optimizer2 = copy.deepcopy(optimizer)
for i in range(20):
    random.shuffle(TRAIN_DATA_NER)
    for data in TRAIN_DATA_NER:
        text = data[0]
        annotations = data[1]
        gold = annotations
        nlp.update([text], [gold], sgd=optimizer)
TRAIN_DATA_PARSER = copy.deepcopy(TRAIN_DATA_FULL)
for data in TRAIN_DATA_NER:
    data[1].pop('entities')

for i in range(20):
    random.shuffle(TRAIN_DATA_PARSER)
    for data in TRAIN_DATA_PARSER:
        text = data[0]
        annotations = data[1]
        from spacy.gold import GoldParse
        doc = make_doc_from_ner_train_data(data, nlp_make_ner)
        gold = GoldParse(doc, annotations)
        nlp.update([text], [gold], sgd=optimizer2)

print("The models were trained successfully.")
&lt;/denchmark-code&gt;

This runs. I can't tell how well because when I actually try to execute it on a text the python kernel dies and restarts three times, even with the custom pipeline components disabled.
&lt;denchmark-code&gt;txt = u"""Can't post text for privacy reasons"""

doc1 = nlp(txt,['merge_entities','custom_sbd'])

from spacy import displacy
displacy.serve([doc1],style="dep")
&lt;/denchmark-code&gt;

What I get in the console is:

Kernel died, restarting
Kernel died, restarting
Kernel died, restarting
Kernel died, restarting
Kernel died, restarting

Is this a bug?
	</description>
	<comments>
		<comment id='1' author='kevinrosenberg21' date='2018-03-06T17:23:43Z'>
		UPDATE:
I ran the code without the usage part (i.e. just training) and nothing failed, but after trying nlp even on a much shorter text than the ones in my domain it also kills and restarts the kernel repeatedly.
		</comment>
		<comment id='2' author='kevinrosenberg21' date='2018-03-06T20:34:49Z'>
		UPDATE:
I ran the code from the terminal and got a segmentation fault (core dumped) error which, according to &lt;denchmark-link:https://stackoverflow.com/questions/13654449/error-segmentation-fault-core-dumped&gt;this&lt;/denchmark-link&gt;
 presents itself most commonly for issues with the C code, so I don't think there's much I can do about it.
		</comment>
		<comment id='3' author='kevinrosenberg21' date='2018-12-10T15:14:52Z'>
		I think this should be fixed now --- in v2.0.18 we released a fix to an out-of-bounds access in the NER training, which I think is what was causing the problem.
		</comment>
		<comment id='4' author='kevinrosenberg21' date='2019-01-09T16:12:51Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>