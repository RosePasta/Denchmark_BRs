<bug id='717' author='kootenpv' open_date='2017-01-02T08:22:18Z' closed_time='2017-03-18T15:17:43Z'>
	<summary>Contractions do not have the correct lemma</summary>
	<description>
I made a &lt;denchmark-link:https://github.com/kootenpv/contractions&gt;pip package called contractions&lt;/denchmark-link&gt;
 to solve contractions, but it is rather slow (even though I tried to optimise for speed). I did that before working with spacy :)
&lt;denchmark-code&gt;# seetree is my function that wraps contractions and spacy.nlp
seetree("yall don't want nothin' to do with it")

 Input: You all do not want nothing to do with it

 want	(VERB,	ROOT)
---- You	(PRON,	nsubj)
-------- all	(DET,	appos)
---- do	(VERB,	aux)
---- not	(ADV,	neg)
---- nothing	(NOUN,	dobj)
-------- do	(VERB,	relcl)
------------ to	(PART,	aux)
------------ with	(ADP,	prep)
---------------- it	(PRON,	pobj)

&lt;/denchmark-code&gt;

I'm mostly wondering why you handle it like this:
&lt;denchmark-code&gt;In [268]: list(nlp("You're happy"))[1].lemma_
Out[268]: "'re"

In [269]: list(nlp("You are happy"))[1].lemma_
Out[269]: 'be'
&lt;/denchmark-code&gt;

Why not replace 're with are so that the lemma would be correct?
	</description>
	<comments>
		<comment id='1' author='kootenpv' date='2017-01-02T08:28:41Z'>
		I looked it up in the code, it does seem like the lemma mentioned is there:
&lt;denchmark-link:https://github.com/explosion/spaCy/blob/master/spacy/en/tokenizer_exceptions.py#L896&gt;https://github.com/explosion/spaCy/blob/master/spacy/en/tokenizer_exceptions.py#L896&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;In [271]: list(nlp("You're happy"))[1].lemma
Out[271]: 536

In [272]: list(nlp("You are happy"))[1].lemma
Out[272]: 488
&lt;/denchmark-code&gt;

Strange, seems like a bug?
		</comment>
		<comment id='2' author='kootenpv' date='2017-01-02T09:04:51Z'>
		Thanks for the report. The data definitely looks correct, so this seems like a bug.
I'm travelling today so can't easily check, so just to confirm: are you on the most recent version (1.5)?
		</comment>
		<comment id='3' author='kootenpv' date='2017-01-02T09:07:47Z'>
		Yes (same session :-)):
&lt;denchmark-code&gt;In [327]: spacy.__version__
Out[327]: '1.5.0'
&lt;/denchmark-code&gt;

It is not a problem with all contractions strangely.
&lt;denchmark-code&gt;In [328]: list(nlp("You have happiness"))[1].lemma
Out[328]: 484

In [329]: list(nlp("You've happiness"))[1].lemma
Out[329]: 484
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='kootenpv' date='2017-01-02T09:19:30Z'>
		I wonder whether the new exception data is being loaded for English...I think it might be preferring to load the exceptions in the model, using the (deprecated) text file.
If so, least know the tokenizer is in sync with the existing trained weights.
		</comment>
		<comment id='5' author='kootenpv' date='2017-01-02T09:47:15Z'>
		
seetree("yall don't want nothin' to do with it")

On a slightly unrelated note, I just realised that both yall and nothin' (and similar spellings) aren't yet covered in the tokenizer exceptions. I'll be adding those now, so they'll be available as soon as this issue is fixed.
		</comment>
		<comment id='6' author='kootenpv' date='2017-01-02T10:38:35Z'>
		&lt;denchmark-link:https://github.com/ines&gt;@ines&lt;/denchmark-link&gt;
 Feel free to have a look at &lt;denchmark-link:https://github.com/kootenpv/contractions/blob/master/contractions/__init__.py&gt;https://github.com/kootenpv/contractions/blob/master/contractions/__init__.py&lt;/denchmark-link&gt;
 and see if there is anything else you'd like to add.
		</comment>
		<comment id='7' author='kootenpv' date='2017-01-02T10:45:09Z'>
		&lt;denchmark-link:https://github.com/kootenpv&gt;@kootenpv&lt;/denchmark-link&gt;
 Ah, this is perfect, thanks!  There are definitely a few that we haven't covered.
		</comment>
		<comment id='8' author='kootenpv' date='2018-05-09T01:39:09Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>