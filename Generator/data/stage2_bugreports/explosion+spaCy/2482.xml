<bug id='2482' author='wpm' open_date='2018-06-26T21:48:28Z' closed_time='2018-09-28T13:19:58Z'>
	<summary>Error when saving new untrained model: 'bool' object is not subscriptable</summary>
	<description>
Following the example in &lt;denchmark-link:https://spacy.io/usage/training#example-train-ner&gt;Updating the Named Entity Recognizer&lt;/denchmark-link&gt;
, I created a blank model and added an named entity recognizer to the pipeline.
&lt;denchmark-code&gt;import spacy
nlp = spacy.blank('en')
ner = nlp.create_pipe('ner')
nlp.add_pipe(ner, last=True)
nlp.to_disk('model')
&lt;/denchmark-code&gt;

I then tried to save the model and got an error.
&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-5-a56721e00b6b&gt; in &lt;module&gt;()
----&gt; 1 nlp.to_disk('model')

/anaconda3/envs/keras-spacy/lib/python3.6/site-packages/spacy/language.py in to_disk(self, path, disable)
    619             serializers[name] = lambda p, proc=proc: proc.to_disk(p, vocab=False)
    620         serializers['vocab'] = lambda p: self.vocab.to_disk(p)
--&gt; 621         util.to_disk(path, serializers, {p: False for p in disable})
    622 
    623     def from_disk(self, path, disable=tuple()):

/anaconda3/envs/keras-spacy/lib/python3.6/site-packages/spacy/util.py in to_disk(path, writers, exclude)
    501     for key, writer in writers.items():
    502         if key not in exclude:
--&gt; 503             writer(path / key)
    504     return path
    505 

/anaconda3/envs/keras-spacy/lib/python3.6/site-packages/spacy/language.py in &lt;lambda&gt;(p, proc)
    617             if not hasattr(proc, 'to_disk'):
    618                 continue
--&gt; 619             serializers[name] = lambda p, proc=proc: proc.to_disk(p, vocab=False)
    620         serializers['vocab'] = lambda p: self.vocab.to_disk(p)
    621         util.to_disk(path, serializers, {p: False for p in disable})

nn_parser.pyx in spacy.syntax.nn_parser.Parser.to_disk()

/anaconda3/envs/keras-spacy/lib/python3.6/site-packages/spacy/util.py in to_disk(path, writers, exclude)
    501     for key, writer in writers.items():
    502         if key not in exclude:
--&gt; 503             writer(path / key)
    504     return path
    505 

nn_parser.pyx in spacy.syntax.nn_parser.Parser.to_disk.lambda3()

TypeError: 'bool' object is not subscriptable
&lt;/denchmark-code&gt;

If I run update on the model I can save it to disk. Even with an empty training batch like so.
&lt;denchmark-code&gt;optimizer = self.nlp.begin_training()
nlp.update([], [], sgd=self.nlp.begin_training())
&lt;/denchmark-code&gt;

(If I don't add the sgd argument I get the warning "Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))".)
Is this the correct behavior? I would expect that I would be able to save an empty model.
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 2.0.11
Platform: Darwin-17.6.0-x86_64-i386-64bit
Python version: 3.6.5
Models: en_core_web_lg, en

	</description>
	<comments>
		<comment id='1' author='wpm' date='2018-07-05T20:44:21Z'>
		Thanks, yes this is a bug. Before calling begin_training() and without loading a model, spaCy doesn't immediately initialize one. I hadn't tested saving the model in this condition, and it seems we're missing a check.
		</comment>
		<comment id='2' author='wpm' date='2018-07-20T04:53:49Z'>
		I don't understand why sometimes when i run train_ner.py under examples, the loss function minimizes, but then it reaches a point then the shell restarts. it is almost like a global minimum couldn't be reached and so the trainer gives up.
Some other details:
I successfully saved to folder before using the same code, but I wanted to update the model with new examples. I figured i didn't have that many so I trained from a new model.
		</comment>
		<comment id='3' author='wpm' date='2018-09-28T13:19:58Z'>
		@enmatics That sounds like a completely different problem; perhaps related to memory usage?
&lt;denchmark-link:https://github.com/wpm&gt;@wpm&lt;/denchmark-link&gt;
 Thanks -- fixed on develop now.
		</comment>
		<comment id='4' author='wpm' date='2018-10-28T13:34:54Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>