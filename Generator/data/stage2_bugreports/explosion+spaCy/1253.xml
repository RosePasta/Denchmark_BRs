<bug id='1253' author='leighhopcroft' open_date='2017-08-10T19:11:31Z' closed_time='2017-10-20T14:29:41Z'>
	<summary>RuntimeError: Array bounds exceeded while searching for root word. This likely means the parse tree is in an invalid state.</summary>
	<description>
I'm trying to merge any multi-token entities found in a text in to a single token with the following code adapted from &lt;denchmark-link:https://explosion.ai/blog/sense2vec-with-spacy&gt;https://explosion.ai/blog/sense2vec-with-spacy&lt;/denchmark-link&gt;

My code within a function that processes a generator of texts:
&lt;denchmark-code&gt;for doc in nlp.pipe(texts, batch_size=batch_size, n_threads=n_threads):
    # Iterate over named entities
        for ent in doc.ents:
            if len(ent) &gt; 1:
                # Merge them into single tokens
                ent.merge(ent.root.tag_, ent.text, ent.label_)
&lt;/denchmark-code&gt;

I get the following error on one entity when trying to perform the merge:
&lt;denchmark-code&gt;File "spacy/tokens/span.pyx", line 307, in spacy.tokens.span.Span.root.__get__ (spacy/tokens/span.cpp:7562)
  File "spacy/tokens/span.pyx", line 415, in spacy.tokens.span._count_words_to_root (spacy/tokens/span.cpp:10330)
RuntimeError: Array bounds exceeded while searching for root word. This likely means the parse tree is in an invalid state. Please report this issue here: http://github.com/explosion/spaCy/issues
&lt;/denchmark-code&gt;

The particular entity in question is "Â£32 million" and the error seems to occur when trying to access the ent.root.tag_ attribute.
I'm using a Python 3.6.2 Conda environment:
'3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 13:14:59) \n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]'
&lt;denchmark-h:h2&gt;Info about spaCy&lt;/denchmark-h&gt;


spaCy version: 1.9.0
Platform: Darwin-16.7.0-x86_64-i386-64bit
Python version: 3.6.2
Installed models: en

	</description>
	<comments>
		<comment id='1' author='leighhopcroft' date='2017-09-08T19:35:59Z'>
		I've encountered a similar error.
I'm using en_core_web_sm and it seems that running its parser on (some type of tokenized text that has been tagged) more than once, corrupts the state of the parse tree, causing exception in _count_words_to_root.
Repro Step:
&lt;denchmark-code&gt;import en_core_web_sm
SPACY_EN_CORE_WEB_SM = en_core_web_sm.load()

def ss(tt):
...   for i in range(len(tt)-1):
...     for j in range(i+1, len(tt)):
...       tt[i:j].root

t_t = SPACY_EN_CORE_WEB_SM.tokenizer("Highly rated - I'll definitely")
SPACY_EN_CORE_WEB_SM.tagger(t_t)
SPACY_EN_CORE_WEB_SM.parser(t_t)
SPACY_EN_CORE_WEB_SM.parser(t_t)
ss(t_t)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 4, in ss
  File "spacy/tokens/span.pyx", line 307, in spacy.tokens.span.Span.root.__get__ (spacy/tokens/span.cpp:7562)
  File "spacy/tokens/span.pyx", line 415, in spacy.tokens.span._count_words_to_root (spacy/tokens/span.cpp:10330)
RuntimeError: Array bounds exceeded while searching for root word. This likely means the parse tree is in an invalid state. Please report this issue here: http://github.com/explosion/spaCy/issues

&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='leighhopcroft' date='2017-09-09T21:07:09Z'>
		&lt;denchmark-link:https://github.com/carolingfish&gt;@carolingfish&lt;/denchmark-link&gt;
 Thanks for the clues! That makes things a fair bit easier.
&lt;denchmark-link:https://github.com/leighhopcroft&gt;@leighhopcroft&lt;/denchmark-link&gt;
 Until the error is fixed, you might be able to work around this by gathering the entities first, and then merging them together. I think the problem at the moment is that the document is changing tokenization after the  property produces the spans. This usually works, but it seems the call to  is throwing it off. If you get a list of the entities and their tags in one step, and then merge them in the next step, it might work around the bug.
		</comment>
		<comment id='3' author='leighhopcroft' date='2018-05-08T13:27:53Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>