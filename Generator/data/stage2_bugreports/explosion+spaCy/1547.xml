<bug id='1547' author='Manslow' open_date='2017-11-10T18:51:13Z' closed_time='2018-01-16T12:33:16Z'>
	<summary>spacy.tokens.doc.Doc.ents.__get__  AssertionError</summary>
	<description>
Using Spacy 2.0, Python 3.6.3 on MacOS 10.11.6  I'm getting:

Traceback (most recent call last):
File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1599, in 
globals = debugger.run(setup['file'], None, None, is_module)
File "/Applications/PyCharm.app/Contents/helpers/pydev/pydevd.py", line 1026, in run
pydev_imports.execfile(file, globals, locals)  # execute the script
File "/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
exec(compile(contents+"\n", file, 'exec'), glob, loc)
File "myuserpath/tokenize.py", line 54, in 
pipeline_args=pipe_line_arguments))
File "myuserpath/text_processing_pipeline.py", line 385, in text_pipeline
doc = pipeline(doc, token_pipeline_funcs, nlp, pipeline_args)
File "myuserpath/text_processing_pipeline.py", line 409, in pipeline
doc = pipeline_function(doc, nlp, pipeline_args)
File "myuserpath/text_processing_pipeline.py", line 203, in chunk_named_entities
for ent in doc.ents:
File "doc.pyx", line 412, in spacy.tokens.doc.Doc.ents.get
AssertionError

when merging entity spans after merging noun chunk spans but not vice versa.
I have a list of texts I'm creating document objects from that are used for merging spans and it fails on the same text each time. However, when just trying it on that single text it works fine so I haven't been able to replicate a self contained example here. Also, this happens with small, medium and large Engish models but the error is raised on a different text input in the sequence by each model but the same one each time.
Finally if I look at the debugger in PyCharm to see what ents is assigned to when the assertion is thrown, it is a string with the traceback call pasted above.
	</description>
	<comments>
		<comment id='1' author='Manslow' date='2017-11-10T21:18:31Z'>
		Ok, I've managed to come up with a 'minimal' example. I just hacked away at a long piece of text while trying to keep the error. The previous hunch that a sequence was important doesn't seem to matter:
&lt;denchmark-code&gt;import spacy

text = """
worda.
wordb - Biosphere 2 -  
"""

model = spacy.load('en_core_web_sm')
doc = model(text)

for chunk in doc.noun_chunks:
    chunk.merge()

for ent in doc.ents:
    ent.merge()
&lt;/denchmark-code&gt;

This results in:

Traceback (most recent call last):
File "path_to_script/example.py", line 14, in 
for ent in doc.ents:
File "doc.pyx", line 412, in spacy.tokens.doc.Doc.ents.get
AssertionError

		</comment>
		<comment id='2' author='Manslow' date='2017-11-10T22:21:37Z'>
		Thanks for the detailed report and the example!
To get a better idea for what's going on, I slightly reformatted the input text to make the whitespace visible and printed the  ent_iob values. It looks like the noun chunks and entities are overlapping and after merging the start token of the entity ("Biosphere") with the preceding token, the second token inside the entity ("-"), which is set to I, causes the assertion error here:



spaCy/spacy/tokens/doc.pyx


        Lines 409 to 412
      in
      35653be






 for i in range(self.length): 



     token = &amp;self.c[i] 



 if token.ent_iob == 1: 



 assert start != -1 





So basically, spaCy complains, because the document contains an isolated entity token that's supposed to be inside an entity â€“ but it's invalid, because it's not actually following a token that's inside an entity (I) or the beginning of an entity (B):
doc = nlp('\nworda.\nwordb - Biosphere 2 -  \n')

[(t.text, t.ent_iob, t.ent_iob_) for t in doc]
# [('\n', 3, 'B'), ('worda', 2, 'O'), ('.', 2, 'O'), ('\n', 3, 'B'), ('wordb', 2, 'O'), 
#  ('-', 2, 'O'), ('Biosphere', 3, 'B'), ('2', 1, 'I'), ('-', 2, 'O'), (' \n', 2, 'O')]

for chunk in doc.noun_chunks:
    chunk.merge()

[chunk.text for chunk in doc.noun_chunks]
# ['wordb', '- Biosphere']

[(t.text, t.ent_iob, t.ent_iob_) for t in doc]
# [('\n', 3, 'B'), ('worda', 2, 'O'), ('.', 2, 'O'), ('\n', 3, 'B'), ('wordb', 2, 'O'), 
#  ('- Biosphere', 2, 'O'), ('2', 1, 'I'), ('-', 2, 'O'), (' \n', 2, 'O')]

[ent.text for ent in doc.ents]
# AssertionError
Edit: The isolated version without the model etc. (will add this as a regression test later):
from spacy.vocab import Vocab
from spacy.tokens import Doc, Span

doc = Doc(Vocab(), words=['\n', 'worda', '.', '\n', 'wordb', '-', 'Biosphere', '2', '-', ' \n'])
doc.ents = [Span(doc, 6, 8, label=doc.vocab.strings['PRODUCT'])]
doc[5:7].merge()
doc.ents
Related issues: &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1487&gt;#1487&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1474&gt;#1474&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Manslow' date='2018-01-16T12:33:16Z'>
		Merging discussion to &lt;denchmark-link:https://github.com/explosion/spaCy/issues/1474&gt;#1474&lt;/denchmark-link&gt;
 , as the underlying problem is the same.
		</comment>
		<comment id='4' author='Manslow' date='2018-05-08T02:55:15Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>