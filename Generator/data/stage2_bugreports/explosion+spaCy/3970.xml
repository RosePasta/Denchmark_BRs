<bug id='3970' author='gorqkop' open_date='2019-07-16T09:16:00Z' closed_time='2019-10-15T11:15:29Z'>
	<summary>小/小++  free(): invalid next size (fast)</summary>
	<description>
Spacy 2.1.1 - 2.1.6
Python 3.6
Ubuntu 18.04.1 LTS
In Spacy since 2.1 randomly occurs memory errors from 小/小++ like "free(): invalid next size (fast)" no any additional information are provided in logs. Has anybody meet the same problems?
	</description>
	<comments>
		<comment id='1' author='gorqkop' date='2019-07-16T16:00:36Z'>
		Do you have any more specifics about what text it fails on, what model is being used, and what pipeline components are in it?
		</comment>
		<comment id='2' author='gorqkop' date='2019-07-17T06:14:21Z'>
		Because I cann't give any logs, I'm trying to prepare code to share, which reproduce the problem.
		</comment>
		<comment id='3' author='gorqkop' date='2019-07-17T12:13:58Z'>
		After tests I realized that one of the way to see this problem working with 2 instances of Spacy. For example with custom lemmatizer based on Spacy instance:
&lt;denchmark-code&gt;class CustomLemmatizer(object):
    def __init__(self, nlp):
        self.nlp = nlp

    def lemmatize(self, token):
        """
        Here described lemmatization rules
        :param token: Spacy.Token
        :return: str
        """
        if ' ' in token.text:
            return token.lemma_.lower()
        if token.is_lower:
            return token.lemma_
        right_context = get_nbor(token, 'token', 1)
        right_context = right_context.text if right_context else ''
        new_token = self.nlp(' '.join([token.lower_, right_context]))[0]
        return new_token.lemma_

    def __call__(self, doc):
        """
        On call
        :param doc: Spacy.doc
        :return: Spacy.doc
        """
        for token in doc:
            token._.clemma = self.lemmatize(token)
        return doc
&lt;/denchmark-code&gt;

Than use it via custom attribute:
&lt;denchmark-code&gt;    """
    Initialising and manipulating with SpaCy language model
    """
    __NM = None

    @classmethod
    def load(cls):
        """Use it to load nlp model from memory."""
        if not cls.__NM:
            cls.__NM = cls()
        return cls.__NM

    def __init__(self):
        self.parser = spacy.load('en_core_web_lg')
        tmp_parser = spacy.load('en_core_web_lg')
        clemmatizer = CustomLemmatizer(tmp_parser)
        if not Token.get_extension('clemma'):
            Token.set_extension('clemma', getter=lambda token: clemmatizer.lemmatize(token))
        self.parser.max_length = 2000000
&lt;/denchmark-code&gt;

So if use NlpModel.parser Sapcy can occasionally raise errors like:
corrupted double-linked list
python3.6: malloc.c:4023: _int_malloc: Assertion `(unsigned long) (size) &gt;= (unsigned long) (nb)' failed.
free(): invalid next size (fast)
		</comment>
		<comment id='4' author='gorqkop' date='2019-07-17T12:15:03Z'>
		Sorry for bad code quotation, but git marks nicely only part of code in quotes
		</comment>
		<comment id='5' author='gorqkop' date='2019-10-15T11:15:29Z'>
		Fixed since Spacy 2.1.8
		</comment>
		<comment id='6' author='gorqkop' date='2019-10-15T11:59:12Z'>
		Happy to hear it, thanks for following up!
		</comment>
		<comment id='7' author='gorqkop' date='2019-11-14T12:54:31Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>