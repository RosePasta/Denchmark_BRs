<bug id='786' author='schlichtanders' open_date='2017-01-29T18:19:35Z' closed_time='2017-03-31T10:07:04Z'>
	<summary>MemoryError: Error allocating memory for feature</summary>
	<description>
Dear spaCy Team,
I tried to further train the default spacy entity recognizer, however I immediately run into a Memory Error.
&lt;denchmark-code&gt;import spacy
nlp = spacy.load("de")
nlp.entity.model.resume_training()
&lt;/denchmark-code&gt;

throws
&lt;denchmark-code&gt;MemoryError                               Traceback (most recent call last)
&lt;ipython-input-29-6298edf1c0b7&gt; in &lt;module&gt;()
----&gt; 1 nlp.entity.model.resume_training()

C:\tools\Anaconda3\lib\site-packages\thinc\linear\avgtron.pyx in thinc.linear.avgtron.AveragedPerceptron.resume_training (thinc/linear/avgtron.cpp:4177)()

MemoryError: Error allocating memory for feature: 13665621275175813120
&lt;/denchmark-code&gt;

Have you ever encountered such things? Any suggestions how to proceed?
&lt;denchmark-h:h3&gt;My Environment&lt;/denchmark-h&gt;


Operating System: Windows 10
Python Version Used: 3.5
spaCy Version Used: 1.6.0
Environment Information: 32GB RAM

	</description>
	<comments>
		<comment id='1' author='schlichtanders' date='2017-01-29T22:51:31Z'>
		Hi,
Labelling this bug, because no matter the root cause that shouldn't be the expected behaviour.
Do you have the data installed?
Matt
		</comment>
		<comment id='2' author='schlichtanders' date='2017-01-30T08:53:38Z'>
		thank you very much for your fast response
I already had run long ago python -m spacy.de.download all and tried to redownload it using --force, however this behaviour is currently broken in spacy 1.6 (on master it is already fixed), hence I might have an older download from spacy 1.2
I executed python -m spacy.en.download all and downloaded all english data.
Still the same error. (also with the english equivalent code)
		</comment>
		<comment id='3' author='schlichtanders' date='2017-02-13T14:28:38Z'>
		I tried it again with the new thinc master adapted for &lt;denchmark-link:https://github.com/explosion/spaCy/issues/799&gt;#799&lt;/denchmark-link&gt;
 however this memory allocation error is unfortunately still there.
		</comment>
		<comment id='4' author='schlichtanders' date='2017-03-06T17:37:32Z'>
		I am encountering similar issues now - upgrading to thinc-6.4.0 solved my memory issues, however now I am unable to save the models I update. Traceback below:
&lt;denchmark-code&gt;
  File "/mnt/alex/NER/train_general_model.py", line 277, in &lt;module&gt;

    train_client_brand_model(output_path, td)

  File "/mnt/alex/NER/train_general_model.py", line 211, in train_client_brand_model

    ner.model.dump(str(model_dir / 'model'))

  File "thinc/linear/avgtron.pyx", line 81, in thinc.linear.avgtron.AveragedPerceptron.dump 
(thinc/linear/avgtron.cpp:2852)

AttributeError: 'preshed.maps.PreshMap' object has no attribute 'capacity' ```
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='schlichtanders' date='2017-03-06T18:46:24Z'>
		Actually, looks like an upgrade of preshed to 1.0.0 solves the issue I was seeing.
		</comment>
		<comment id='6' author='schlichtanders' date='2017-03-31T10:07:04Z'>
		This should be fixed now -- see &lt;denchmark-link:https://github.com/explosion/spaCy/issues/910&gt;#910&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='schlichtanders' date='2018-05-09T00:39:15Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>