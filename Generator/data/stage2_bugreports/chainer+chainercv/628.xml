<bug id='628' author='1292765944' open_date='2018-05-29T08:30:31Z' closed_time='2018-09-10T07:01:40Z'>
	<summary>The host shuts down in training</summary>
	<description>
I use two gpus for SSD300 training, and find that the host always shuts down after one validation evaluation (e.g. at 10000th iteration) and couldn't switch over training and validation. What may be the problem for this?
	</description>
	<comments>
		<comment id='1' author='1292765944' date='2018-05-29T14:14:10Z'>
		Please try following settings.

use single GPU (train.py)
multi GPU without saving snapshot

		</comment>
		<comment id='2' author='1292765944' date='2018-05-30T02:57:36Z'>
		&lt;denchmark-link:https://github.com/Hakuyume&gt;@Hakuyume&lt;/denchmark-link&gt;
 using single GPU is ok but is too slow.
In multi GPU training, saving snapshot do not lead to this problem, and validation evaluation does.
		</comment>
		<comment id='3' author='1292765944' date='2018-05-30T04:45:55Z'>
		How about decreasing batchsize and test-batchsize in train_multi.py ?
		</comment>
		<comment id='4' author='1292765944' date='2018-09-08T16:28:14Z'>
		can we close this issue?
		</comment>
	</comments>
</bug>