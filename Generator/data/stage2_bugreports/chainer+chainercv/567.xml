<bug id='567' author='leewaymay' open_date='2018-04-13T05:26:12Z' closed_time='2018-09-08T22:50:00Z'>
	<summary>Training on SSD terminated due to 'thrust::system::system_error'</summary>
	<description>
I encountered an issue when I was using my own dataset to train SSD. And I have the following error after I trained the first 20 iterations.
terminate called after throwing an instance of 'thrust::system::system_error'
what():  merge_sort: failed to synchronize: an illegal memory access was encountered
I used the same dataset to train Faster-rCNN and it has no problem.
I trained with the VOC dataset and the training code works.
I checked the cupy.sort() method, and I can successfully call this method.
asd = np.array([1, 23, 343, 3424, 134]) asd = cupy.array(asd) cupy.sort(asd) 
The output is
array([   1,   23,  134,  343, 3424])
I don't know what cause this issue. Could anyone help me?
	</description>
	<comments>
		<comment id='1' author='leewaymay' date='2018-05-06T14:07:23Z'>
		Do you succeed to train SSD by chainercv/examples/ssd/train.py with VOCDataset?
And do you use multi GPU?
If yes, you also had better to confirm whether train_multi.py works or not.
		</comment>
		<comment id='2' author='leewaymay' date='2018-05-18T07:51:59Z'>
		Please try train.py with Pascal VOC, first.
		</comment>
		<comment id='3' author='leewaymay' date='2018-05-28T00:29:41Z'>
		I have encountered same problem.
I could train with VOCDataset, but I got  'thrust::system::system_error'  when I use my own dataset.
Is there any possible cause?
Best regards.
		</comment>
		<comment id='4' author='leewaymay' date='2018-05-28T03:42:54Z'>
		Please check the number of instances per image.
		</comment>
		<comment id='5' author='leewaymay' date='2018-05-29T01:29:09Z'>
		Do you mean that if the number of instances is 0, the error occur?
I have checked that there is no image that doesn't have instances.
		</comment>
		<comment id='6' author='leewaymay' date='2018-05-29T01:40:01Z'>
		
I have checked that there is no image that doesn't have instances.

I see. Could you report this issue to CuPy repository?
		</comment>
		<comment id='7' author='leewaymay' date='2018-06-09T06:16:53Z'>
		&lt;denchmark-link:https://github.com/fukatani&gt;@fukatani&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Hakuyume&gt;@Hakuyume&lt;/denchmark-link&gt;

I successed with the VOC dataset and I only have one GPU so I didn't try train_multi.py code.
I haven't tried the SSD after this issue occured. But I suspect that the reason might be there can be no instance in one of the training images in my dataset. Thought all images in my dataset have at least one instance, after transform in the training script, the cropped images might contain no instance.
		</comment>
		<comment id='8' author='leewaymay' date='2018-09-08T16:32:36Z'>
		can we close this issue?
		</comment>
		<comment id='9' author='leewaymay' date='2019-07-05T06:43:45Z'>
		Same problems, since I have a lot of images without instance in it, will the error may resulted by this, and why?
So how can I train SSD with images with no instance?
Looking forward for help.
		</comment>
		<comment id='10' author='leewaymay' date='2019-07-17T03:17:11Z'>
		
Please check the number of instances per image.

Could you please tell me the reason why no instance images will lead to this error?
		</comment>
		<comment id='11' author='leewaymay' date='2019-07-17T06:30:10Z'>
		Since I couldn't reproduce that error in my environment, I don't know the actual reason. Even if I removed all instances from the training dataset, the train script worked. This is just a guess.
		</comment>
	</comments>
</bug>