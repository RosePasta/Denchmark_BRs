<bug id='194' author='haarburger' open_date='2019-08-31T19:39:24Z' closed_time='2019-10-06T12:07:57Z'>
	<summary>[Bug] Poor augmentation performance when not in debug mode</summary>
	<description>
Description
When training using n_process=4 the performance is worse than when using delira debug mode. This also happens when setting n_process=1.
In my example I get ~1.3s/batch with n_process=4 and 2 batch/s in debug mode. With multithreading working properly I would expect something like 4 batch/s at least.
The problem occurs with batchgenerators versions 0.19.3. I also tested against 0.18.2, which resulted in the same problem.
Environment

OS: Ubuntu 18.04
Python version: 3.7
delira version: master
How did you install delira? source


The script needed for reproduction is in my private repo, but &lt;denchmark-link:https://github.com/mibaumgartner&gt;@mibaumgartner&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/justusschock&gt;@justusschock&lt;/denchmark-link&gt;
 have access.
git checkout https://github.com/haarburger/multi-scale-curriculum-prototype
cd multi-scale-curriculum
pip install -e . # delira is the only dependency
python experiments/mri/exec_wic.py -cp experiments/mri/config_debug_wic.yml # depends on files at LfB filesrv
	</description>
	<comments>
		<comment id='1' author='haarburger' date='2019-09-01T07:57:48Z'>
		This is a known issue, and we already started working on it (see PR &lt;denchmark-link:https://github.com/delira-dev/delira/pull/154&gt;#154&lt;/denchmark-link&gt;
 ). The issue lies within the fact, that we had to hack batchgenerators a bit for our sampling and the mentioned PR resolves this issue. It is almost good to go, only one sampler is not yet working the way it is expected to.
		</comment>
	</comments>
</bug>