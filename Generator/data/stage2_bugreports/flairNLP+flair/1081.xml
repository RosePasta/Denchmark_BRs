<bug id='1081' author='tombburnell' open_date='2019-09-10T13:28:26Z' closed_time='2020-05-06T22:33:07Z'>
	<summary>Not all relevant labels are being predicted</summary>
	<description>
Describe the bug
I have a trained an LM model via a text corpus with multiple labels per document.
When I ask it to predict labels for a new document, it often (but not always) only predicts the most relevant label. Why does it not always give all labels that have a relevance. How does it decide which labels to give?
For example:


Harry Kane died in a plane crash  =&gt; [death 0.8319]      expected - only one relevant


Harry Kane the Tottenham striker died in a plane crash =&gt; [sport 0.73]    not-expected. should give [death too]


Harry Kane the footballer died in a plane crash =&gt; [sport 0.73] [ death 0.63] expected - gives sport and death.


Why would the 2nd one not give death and sport when the indicators for death label are strong and the 3rd one does?
	</description>
	<comments>
		<comment id='1' author='tombburnell' date='2019-09-12T14:03:16Z'>
		Hi &lt;denchmark-link:https://github.com/tombburnell&gt;@tombburnell&lt;/denchmark-link&gt;
,
could you try to pass all_tag_prob=True to your .predict() function? This should return all probabilities for your classes.
		</comment>
		<comment id='2' author='tombburnell' date='2020-04-29T21:11:06Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>