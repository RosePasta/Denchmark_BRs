<bug id='1340' author='Otavio-Parraga' open_date='2020-01-09T19:32:54Z' closed_time='2020-09-28T13:43:18Z'>
	<summary>Tutorial 8 not working with Flair 0.4.4 on Google Colab</summary>
	<description>
Describe the bug
So, I was running Flair tutorials on a google colab notebook and in the 8th tutorial i discovered a bug. When i run the command param_selector.optimize(search_space, max_evals=100) the train stops after the first run with the error: RuntimeError: shape '[x,y,z]' is invalid for input of size "some_number"
*The x,y,z are numbers, usually 8,21 and 300, but they change sometimes, and some_number is a big number like 240000
I could only finish the tutorial on Google Colab after change Flair version to 0.4.3
To Reproduce
Run the following lines of code, from the 8 Tutorial on a Google Colab notebook with Flair in the 0.4.4 version.
&lt;denchmark-code&gt;from flair.datasets import TREC_6
from flair.embeddings import FlairEmbeddings, WordEmbeddings
from hyperopt import hp
from flair.hyperparameter.param_selection import SearchSpace, Parameter, TextClassifierParamSelector, OptimizationValue

corpus = TREC_6()

search_space = SearchSpace()
search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[
    [ WordEmbeddings('en') ]
])

search_space.add(Parameter.HIDDEN_SIZE, hp.choice, options=[32, 64, 128])
search_space.add(Parameter.RNN_LAYERS, hp.choice, options=[1, 2])
search_space.add(Parameter.DROPOUT, hp.uniform, low=0.0, high=0.5)
search_space.add(Parameter.LEARNING_RATE, hp.choice, options=[0.05, 0.1, 0.15, 0.2])
search_space.add(Parameter.MINI_BATCH_SIZE, hp.choice, options=[8, 16, 32])

param_selector = TextClassifierParamSelector(
    corpus, 
    False, 
    'resources/results', 
    'lstm',
    max_epochs=10, 
    training_runs=3,
    optimization_value=OptimizationValue.DEV_SCORE
)

param_selector.optimize(search_space, max_evals=100)
&lt;/denchmark-code&gt;

The only thing I've changed was the search_space.add(Parameter.EMBEDDINGS, hp.choice, options=[ [ WordEmbeddings('en') ] ]) that I only used WordEmbeddings instead WordEmbeddings and both FlairEmbeddings as well. But that doesn't change the bug, i've tested.
Expected behavior
After the first training run, something like this problem will appear: RuntimeError: shape '[32, 14, 300]' is invalid for input of size 223500
&lt;denchmark-code&gt;2020-01-09 19:18:11,548 Training run: 2
2020-01-09 19:18:11,557 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,558 Model: "TextClassifier(
  (document_embeddings): DocumentRNNEmbeddings(
    (embeddings): StackedEmbeddings(
      (list_embedding_0): WordEmbeddings('en')
    )
    (word_reprojection_map): Linear(in_features=300, out_features=300, bias=True)
    (rnn): GRU(300, 128, num_layers=2, batch_first=True)
    (dropout): Dropout(p=0.30408081538769743, inplace=False)
  )
  (decoder): Linear(in_features=128, out_features=6, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2020-01-09 19:18:11,559 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,561 Corpus: "Corpus: 4907 train + 545 dev + 500 test sentences"
2020-01-09 19:18:11,562 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,563 Parameters:
2020-01-09 19:18:11,564  - learning_rate: "0.1"
2020-01-09 19:18:11,566  - mini_batch_size: "32"
2020-01-09 19:18:11,567  - patience: "3"
2020-01-09 19:18:11,569  - anneal_factor: "0.5"
2020-01-09 19:18:11,570  - max_epochs: "10"
2020-01-09 19:18:11,571  - shuffle: "True"
2020-01-09 19:18:11,572  - train_with_dev: "False"
2020-01-09 19:18:11,573  - batch_growth_annealing: "False"
2020-01-09 19:18:11,574 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,575 Model training base path: "resources/results"
2020-01-09 19:18:11,577 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,578 Device: cpu
2020-01-09 19:18:11,579 ----------------------------------------------------------------------------------------------------
2020-01-09 19:18:11,580 Embeddings storage mode: cpu
2020-01-09 19:18:11,582 ----------------------------------------------------------------------------------------------------

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-8-baa23c9082a4&gt; in &lt;module&gt;()
     25 )
     26 
---&gt; 27 param_selector.optimize(search_space, max_evals=100)

11 frames
/usr/local/lib/python3.6/dist-packages/flair/hyperparameter/param_selection.py in optimize(self, space, max_evals)
    160         search_space = space.search_space
    161         best = fmin(
--&gt; 162             self._objective, search_space, algo=tpe.suggest, max_evals=max_evals
    163         )
    164 

/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py in fmin(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)
    405                     show_progressbar=show_progressbar)
    406     rval.catch_eval_exceptions = catch_eval_exceptions
--&gt; 407     rval.exhaust()
    408     if return_argmin:
    409         return trials.argmin

/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py in exhaust(self)
    260     def exhaust(self):
    261         n_done = len(self.trials)
--&gt; 262         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
    263         self.trials.refresh()
    264         return self

/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py in run(self, N, block_until_done)
    225                     else:
    226                         # -- loop over trials and do the jobs directly
--&gt; 227                         self.serial_evaluate()
    228 
    229                     try:

/usr/local/lib/python3.6/dist-packages/hyperopt/fmin.py in serial_evaluate(self, N)
    139                 ctrl = base.Ctrl(self.trials, current_trial=trial)
    140                 try:
--&gt; 141                     result = self.domain.evaluate(spec, ctrl)
    142                 except Exception as e:
    143                     logger.info('job exception: %s' % str(e))

/usr/local/lib/python3.6/dist-packages/hyperopt/base.py in evaluate(self, config, ctrl, attach_attachments)
    842                 memo=memo,
    843                 print_node_on_error=self.rec_eval_print_node_on_error)
--&gt; 844             rval = self.fn(pyll_rval)
    845 
    846         if isinstance(rval, (float, int, np.number)):

/usr/local/lib/python3.6/dist-packages/flair/hyperparameter/param_selection.py in _objective(self, params)
    110                 max_epochs=self.max_epochs,
    111                 param_selection_mode=True,
--&gt; 112                 **training_params,
    113             )
    114 

/usr/local/lib/python3.6/dist-packages/flair/trainers/trainer.py in train(self, base_path, learning_rate, mini_batch_size, mini_batch_chunk_size, max_epochs, anneal_factor, patience, min_learning_rate, train_with_dev, monitor_train, monitor_test, embeddings_storage_mode, checkpoint, save_final_model, anneal_with_restarts, batch_growth_annealing, shuffle, param_selection_mode, num_workers, sampler, use_amp, amp_opt_level, eval_on_train_fraction, eval_on_train_shuffle, **kwargs)
    316 
    317                         # forward pass
--&gt; 318                         loss = self.model.forward_loss(batch_step)
    319 
    320                         # Backward

/usr/local/lib/python3.6/dist-packages/flair/models/text_classification_model.py in forward_loss(self, data_points)
    115     ) -&gt; torch.tensor:
    116 
--&gt; 117         scores = self.forward(data_points)
    118         return self._calculate_loss(scores, data_points)
    119 

/usr/local/lib/python3.6/dist-packages/flair/models/text_classification_model.py in forward(self, sentences)
     80     def forward(self, sentences) -&gt; List[List[float]]:
     81 
---&gt; 82         self.document_embeddings.embed(sentences)
     83 
     84         text_embedding_list = [

/usr/local/lib/python3.6/dist-packages/flair/embeddings.py in embed(self, sentences)
     88 
     89         if not everything_embedded or not self.static_embeddings:
---&gt; 90             self._add_embeddings_internal(sentences)
     91 
     92         return sentences

/usr/local/lib/python3.6/dist-packages/flair/embeddings.py in _add_embeddings_internal(self, sentences)
   2753                 len(sentences),
   2754                 longest_token_sequence_in_batch,
-&gt; 2755                 self.embeddings.embedding_length,
   2756             ]
   2757         )

RuntimeError: shape '[32, 14, 300]' is invalid for input of size 223500
&lt;/denchmark-code&gt;

Environment (please complete the following information):

OS [e.g. iOS, Linux]: A normal runtime from Google Colab
Version [e.g. flair-0.3.2]: flair-0.4.4

Additional context
This only happens on Google Colab, when i use my machine everything goes normally.
Thanks!
	</description>
	<comments>
		<comment id='1' author='Otavio-Parraga' date='2020-01-13T21:07:38Z'>
		&lt;denchmark-link:https://github.com/Otavio-Parraga&gt;@Otavio-Parraga&lt;/denchmark-link&gt;
 I'm seeing the same error on Colab - thanks for reporting this!
		</comment>
		<comment id='2' author='Otavio-Parraga' date='2020-01-28T15:44:14Z'>
		Any updates on this issue? I'm running into the same error on my desktop
Environment:
OS: Ubuntu 18.04
Version: flair 0.4.4
IDE: pycharm
Thanks
		</comment>
		<comment id='3' author='Otavio-Parraga' date='2020-09-21T13:26:12Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='4' author='Otavio-Parraga' date='2020-10-06T19:45:13Z'>
		i am  getting same error in colab
		</comment>
	</comments>
</bug>