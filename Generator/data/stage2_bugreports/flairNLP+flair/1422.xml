<bug id='1422' author='CatarinaPC' open_date='2020-02-08T18:17:58Z' closed_time='2020-05-24T13:14:21Z'>
	<summary>Using model trained with camembert gives error</summary>
	<description>
Describe the bug
When using a model trained with camembert embeddings to predict sentences, I get the following error: UnboundLocalError: local variable 'tokenizer' referenced before assignment
The error occurs during SequenceTagger.load().
To Reproduce
I trained  model with all default parameters and camembert embeddings. Then I try to give it sentences to predict, as in the following code excerpt:
&lt;denchmark-code&gt;from flair.models import SequenceTagger

# load model
model = SequenceTagger.load("../../models/trained/flair/camembert/best-model.pt")

# by default whitespace based tokenizer is used
model.predict("testing sentence 1")
&lt;/denchmark-code&gt;

Error
&lt;denchmark-code&gt;2020-02-08 18:11:54,184 loading file ../../models/trained/flair/camembert/best-model.pt
Traceback (most recent call last):
  File "/home/catarinapc/cl-extraction-models_new/src/models/testing.py", line 4, in &lt;module&gt;
    model = SequenceTagger.load("../../models/trained/flair/camembert/best-model.pt")
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/nn.py", line 86, in load
    state = torch.load(f, map_location=flair.device)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 426, in load
    return _load(f, map_location, pickle_module, **pickle_load_args)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 613, in _load
    result = unpickler.load()
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/embeddings.py", line 1621, in __setstate__
    "-".join(self.name.split("-")[1:])
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 302, in from_pretrained
    return cls._from_pretrained(*inputs, **kwargs)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 444, in _from_pretrained
    tokenizer.init_inputs = init_inputs
UnboundLocalError: local variable 'tokenizer' referenced before assignment
&lt;/denchmark-code&gt;

Environment:
OS: Ubuntu 18.04.3 LTS
Version: 0.4.4 (I think I'm using the version on the master branch)
Python version: 3.6.8
Thanks for the help!
&lt;denchmark-h:h3&gt;UPDATE&lt;/denchmark-h&gt;

Just uninstalled and installed both flair (was using master branch), transformers library, and torch (one version bellow current) and now I get the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/catarinapc/cl-extraction-models_new/src/models/testing.py", line 4, in &lt;module&gt;
    model = SequenceTagger.load("../../models/trained/flair/camembert/best-model.pt")
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/nn.py", line 86, in load
    state = torch.load(f, map_location=flair.device)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 702, in _legacy_load
    result = unpickler.load()
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/embeddings.py", line 1621, in __setstate__
    "-".join(self.name.split("-")[1:])
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 309, in from_pretrained
    return cls._from_pretrained(*inputs, **kwargs)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 410, in _from_pretrained
    list(cls.vocab_files_names.values()),
OSError: Model name 'base' was not found in tokenizers model name list (camembert-base). We assumed 'base' was a path, a model identifier, or url to a directory containing vocabulary files named ['sentencepiece.bpe.model'] but couldn't find such vocabulary files at this path or url.

&lt;/denchmark-code&gt;

and when using xml roberta:
&lt;denchmark-code&gt;2020-02-08 18:52:33,804 loading file ../../models/trained/flair/xlm-roberta-base/best-model.pt
Traceback (most recent call last):
  File "/home/catarinapc/cl-extraction-models_new/src/models/predict_model.py", line 34, in &lt;module&gt;
    run()
  File "/home/catarinapc/cl-extraction-models_new/src/models/predict_model.py", line 30, in run
    predict_flair_trained_models()
  File "/home/catarinapc/cl-extraction-models_new/src/models/predict_model.py", line 22, in predict_flair_trained_models
    df_copy["pred"] = flair_model_handler.predict(model_dir_path+"/best-model.pt", sentences_text_flair)
  File "/home/catarinapc/cl-extraction-models_new/src/models/flair_model.py", line 75, in predict
    model = SequenceTagger.load(model_path)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/nn.py", line 86, in load
    state = torch.load(f, map_location=flair.device)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 426, in load
    return _load(f, map_location, pickle_module, **pickle_load_args)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 613, in _load
    result = unpickler.load()
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/embeddings.py", line 1693, in __setstate__
    "-".join(self.name.split("-")[1:])
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 309, in from_pretrained
    return cls._from_pretrained(*inputs, **kwargs)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/transformers/tokenization_utils.py", line 410, in _from_pretrained
    list(cls.vocab_files_names.values()),
OSError: Model name 'roberta-base' was not found in tokenizers model name list (xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german). We assumed 'roberta-base' was a path, a model identifier, or url to a directory containing vocabulary files named ['sentencepiece.bpe.model'] but couldn't find such vocabulary files at this path or url.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='CatarinaPC' date='2020-03-16T15:33:54Z'>
		Hi &lt;denchmark-link:https://github.com/CatarinaPC&gt;@CatarinaPC&lt;/denchmark-link&gt;
 ,
does this error still occurs when you use the latest Flair version?
		</comment>
		<comment id='2' author='CatarinaPC' date='2020-03-16T15:52:47Z'>
		I think so. I checked and I'm using flair==0.4.5, which I think is the latest version (correct me if I'm wrong).
I had to change the Flair code on both the Camembert and the XLM Roberta models in the __setstate__ function in embeddings.py:
I replaced "-".join(self.name.split("-")[1:]), which converted the tokenizer name to just 'base' (for example for camembert), to self.name
&lt;denchmark-code&gt;def __setstate__(self, d):
    self.__dict__ = d

    # 1-camembert-base -&gt; camembert-base
    self.tokenizer = self.tokenizer = CamembertTokenizer.from_pretrained(
        #"-".join(self.name.split("-")[1:])
        self.name
    )
&lt;/denchmark-code&gt;

It is possible other models might get this error. more specifically the ones that use the transformers library.
		</comment>
		<comment id='3' author='CatarinaPC' date='2020-03-16T16:51:48Z'>
		Another thing related to this. I trained a new camembert model on another machine. And when I try to load the model using SequenceTagger.load() function, I get a different error:
&lt;denchmark-code&gt;2020-03-16 16:50:25,313 loading file /models/trained/flair/camembert-dev-150/best-model.pt
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/nn.py", line 85, in load
    f = file_utils.load_big_file(str(model_file))
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/file_utils.py", line 32, in load_big_file
    with open(f, "rb") as f_in:
FileNotFoundError: [Errno 2] No such file or directory: '/models/trained/flair/camembert-dev-150/best-model.pt'
&gt;&gt;&gt; model = SequenceTagger.load("./models/trained/flair/camembert-dev-150/best-model.pt")
2020-03-16 16:50:30,682 loading file ./models/trained/flair/camembert-dev-150/best-model.pt
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/catarinapc/.local/lib/python3.6/site-packages/flair/nn.py", line 86, in load
    state = torch.load(f, map_location=flair.device)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 426, in load
    return _load(f, map_location, pickle_module, **pickle_load_args)
  File "/home/catarinapc/.local/lib/python3.6/site-packages/torch/serialization.py", line 613, in _load
    result = unpickler.load()
ModuleNotFoundError: No module named 'transformers.activations'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='CatarinaPC' date='2020-05-24T13:14:21Z'>
		We've just released Flair 0.5 that contains the above bugfix and new transformer classes. Load like this:
from flair.embeddings import TransformerWordEmbeddings

# init embedding
embedding = TransformerWordEmbeddings('camambert-base')

# create a sentence
sentence = Sentence('The grass is green .')

# embed words in sentence
embedding.embed(sentence)
This should fix the issue. If not, feel free to reopen!
		</comment>
	</comments>
</bug>