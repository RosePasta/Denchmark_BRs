<bug id='697' author='Green-li' open_date='2019-04-28T07:34:13Z' closed_time='2019-06-17T03:16:49Z'>
	<summary>Can't load the Chinese BERT Embeddings from file</summary>
	<description>
Describe the bug
As mentioned in the title, when I load the BERT embeddings from file, it reports an UnicodeDecodeErrorã€‚
To Reproduce
The code is as follows:
&lt;denchmark-code&gt;from flair.embeddings import BertEmbeddings
from flair.data import Sentence

# init embedding
embedding = BertEmbeddings("./pretrained_models/pytorch_model.bin", layers='-1,-2,-3,-4', pooling_operation='mean')
&lt;/denchmark-code&gt;

The errors are as follows:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;stdin&gt;", line 2, in &lt;module&gt;
  File "/home/myuser/venv/lib/python3.6/site-packages/flair/embeddings.py", line 1070, in __init__
    self.tokenizer = BertTokenizer.from_pretrained(bert_model_or_path)
  File "/home/myuser/venv/lib/python3.6/site-packages/pytorch_pretrained_bert/tokenization.py", line 153, in from_pretrained
    tokenizer = cls(resolved_vocab_file, *inputs, **kwargs)
  File "/home/myuser/venv/lib/python3.6/site-packages/pytorch_pretrained_bert/tokenization.py", line 83, in __init__
    self.vocab = load_vocab(vocab_file)
  File "/home/myuser/venv/lib/python3.6/site-packages/pytorch_pretrained_bert/tokenization.py", line 56, in load_vocab
    token = reader.readline()
  File "/home/myuser/venv/lib64/python3.6/codecs.py", line 321, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte
&lt;/denchmark-code&gt;

Environment (please complete the following information):

centos 7
python 3.6.6
flair 0.4.1
pytorch 1.0.0

	</description>
	<comments>
		<comment id='1' author='Green-li' date='2019-05-21T09:47:33Z'>
		Hello &lt;denchmark-link:https://github.com/Green-li&gt;@Green-li&lt;/denchmark-link&gt;
 please excuse the late reply. Have you managed to resolve the error? If not, could you share the  that you are using so we can try to reproduce?
		</comment>
		<comment id='2' author='Green-li' date='2019-05-21T23:09:16Z'>
		&lt;denchmark-link:https://github.com/Green-li&gt;@Green-li&lt;/denchmark-link&gt;
 For Chinese you could  use  model that is natively supported in  :)
Just use:
&lt;denchmark-code&gt;from flair.embeddings import BertEmbeddings
embedding = BertEmbeddings("bert-base-chinese")
&lt;/denchmark-code&gt;

The Chinese model (incl. vocab) will be downloaded automatically.
But if you want to use your own trained or fine-tuned model, you just need to pass the path name (not the model filename pytorch_model.bin!), e.g.:
&lt;denchmark-code&gt;from flair.embeddings import BertEmbeddings
embedding = BertEmbeddings("/tmp/chinese")
&lt;/denchmark-code&gt;

Then the following files must be located under /tmp/chinese:

bert_config.json - this file includes all BERT model specific information
pytorch_model.bin - the BERT model file that was converted to PyTorch (the original TensorFlow model file model.ckpt could also be used instead)
vocab.txt - this file includes all BPE vocab

I tried the import of own pretrained BERT models (converted to PyTorch models with pytorch_pretrained_bert) and it is definitely working with flair :)
		</comment>
		<comment id='3' author='Green-li' date='2019-06-17T03:16:36Z'>
		&lt;denchmark-link:https://github.com/stefan-it&gt;@stefan-it&lt;/denchmark-link&gt;
  THANKS!!! GET IT!
		</comment>
	</comments>
</bug>