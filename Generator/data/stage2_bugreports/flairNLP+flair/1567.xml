<bug id='1567' author='junhua' open_date='2020-05-02T09:12:30Z' closed_time='2020-05-06T22:22:46Z'>
	<summary>TransformerDocuementEmbedding does not take flair.device</summary>
	<description>
By setting flair.device = torch.device('cuda:0;), it throws an error saying expected device cpu  but got device cuda:0. I have to explicitly set TextClassifier(...).to(torch.device('cuda:0') to make it happen
	</description>
	<comments>
		<comment id='1' author='junhua' date='2020-05-02T09:28:06Z'>
		Hm that should not happen since the TextClassifier moves itself to flair.device when calling the constructor. Can you post a full code example to reproduce?
		</comment>
		<comment id='2' author='junhua' date='2020-05-02T09:50:14Z'>
		There:
&lt;denchmark-code&gt;import torch
from torch.optim.adam import Adam

from flair.datasets import CSVClassificationCorpus, ClassificationCorpus
from flair.data import Corpus
from flair.embeddings import (WordEmbeddings, FlairEmbeddings, TransformerDocumentEmbeddings )
from flair.models import TextClassifier
from flair.trainers import ModelTrainer

flair.device = torch.device('cuda:0')
flair.cache_root = './cache'

document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', use_scalar_mix=True)

corpus: Corpus = ClassificationCorpus(data_folder,
                                          test_file='test.txt',
                                          dev_file='val.txt',
                                          train_file='train.txt')

label_dict = corpus.make_label_dictionary()

classifier = TextClassifier(document_embeddings, 
                                label_dictionary=label_dict, 
                                multi_label=False))

trainer = ModelTrainer(classifier, corpus, optimizer=Adam, use_tensorboard=True)

trainer.train(result_folder,
                  max_epochs=200, 
                  embeddings_storage_mode='gpu',
                  learning_rate = 1e-3,
                  mini_batch_size = 32,
    )
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='junhua' date='2020-05-02T13:04:13Z'>
		Thanks! Can you also verify that your GPU is visible?
Does the following print out True?
import torch
print(torch.cuda.is_available())
		</comment>
		<comment id='4' author='junhua' date='2020-05-02T19:18:45Z'>
		Yes - I've been training using Flair's document embedding and text classification for multiple tasks..
&lt;denchmark-link:https://user-images.githubusercontent.com/3516360/80873789-e3c91c80-8cec-11ea-91bc-c1d79395a9f6.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='junhua' date='2020-05-05T00:29:34Z'>
		Hello &lt;denchmark-link:https://github.com/junhua&gt;@junhua&lt;/denchmark-link&gt;
 thanks for sharing the script - the error comes from setting . This option should only be used if not fine-tuning document transformer embeddings. But since you are fine-tuning, you should use .
Still, we have to change this so that this error does not occur. I'll investigate and do a PR.
		</comment>
	</comments>
</bug>