<bug id='1831' author='cibeah' open_date='2020-08-27T15:20:17Z' closed_time='2020-09-03T19:27:59Z'>
	<summary>Error when creating embeddings - HEAD request to S3 bucket returns 404</summary>
	<description>
Hello, I have a problem loading Word/FlairEmbeddings for English and German languages located at the urls: "&lt;denchmark-link:https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/xxxxxxxxx.pt&gt;https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/xxxxxxxxx.pt&lt;/denchmark-link&gt;
".
When following &lt;denchmark-link:https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md&gt;Tutorial 3&lt;/denchmark-link&gt;
, trying to create these embeddings gives the following error:
OSError: HEAD request failed for url https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy with status code 404
Making a simple HEAD request to that url outside of flair returns 404, so it looks like the embeddings are not located there anymore ?
To Reproduce
from flair.embeddings import WordEmbeddings
glove_embedding = WordEmbeddings('glove')
I would  appreciate your help,
Thank you !
	</description>
	<comments>
		<comment id='1' author='cibeah' date='2020-08-27T16:07:29Z'>
		Seeing the same behaviour for the Flair forward and backward news embeddings ('news-forward' and 'news-backward'):

HEAD request failed for url https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt with status code 404.

		</comment>
		<comment id='2' author='cibeah' date='2020-08-27T18:43:56Z'>
		Hm, it looks like the AWS bucket is down. I have to check what's going on!
		</comment>
		<comment id='3' author='cibeah' date='2020-08-28T01:11:04Z'>
		Thanks &lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
... I think we are all blocked by this, those of us who are using this on different machines / CI where we need this stuff to work. Your help is much appreciated!!
		</comment>
		<comment id='4' author='cibeah' date='2020-08-28T06:28:49Z'>
		Quick update: Unfortunately the entire AWS account was deleted yesterday by an internal process since I no longer work at Zalando (I'm now at university). That means that most models are currently not accessible. To fix this, I have to set up another file hosting solution and do a hotfix of Flair.
If anybody knows a good way to host a large amount of large files (with high amounts of download traffic by a big community of users), please let me know!
		</comment>
		<comment id='5' author='cibeah' date='2020-08-28T08:57:54Z'>
		
If anybody knows a good way to host a large amount of large files (with high amounts of download traffic by a big community of users), please let me know!

S3 is still your best bet.
		</comment>
		<comment id='6' author='cibeah' date='2020-08-28T09:25:53Z'>
		Is it resolved? We are blocked with this.
		</comment>
		<comment id='7' author='cibeah' date='2020-08-28T10:21:38Z'>
		&lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
 is this repo still being supported by Zalando ‚Äì financially or otherwise? My startup uses this package we could see if we can help with the hosting.
		</comment>
		<comment id='8' author='cibeah' date='2020-08-28T10:31:54Z'>
		Folks, I just nabbed the alan-nlp bucket name while it's available, to prevent any bad actors taking it. I'll happily release it back to the project when you have an AWS account. üëç
		</comment>
		<comment id='9' author='cibeah' date='2020-08-28T10:36:33Z'>
		There is currently no financial support - the project is maintained only through code contributions by open source community and members of my group. We're now tentatively thinking of setting up a system for donations to cover costs (and maybe even to hire people to maintain the code).
		</comment>
		<comment id='10' author='cibeah' date='2020-08-28T10:47:19Z'>
		If a developer on my team ran our app locally &lt;20 hours ago, will the files from alan-nlp/* be cached locally anywhere? Is there any chance we could extract those files from their hard drive and put them into our deployment pipeline?
Thanks for any guidance!
		</comment>
		<comment id='11' author='cibeah' date='2020-08-28T10:51:32Z'>
		Folks, to clarify &lt;denchmark-link:https://github.com/flairNLP/flair/issues/1831#issuecomment-682453133&gt;#1831 (comment)&lt;/denchmark-link&gt;
: I've reserved the bucket name but I . The emails are flooding in, and I can't help you.
		</comment>
		<comment id='12' author='cibeah' date='2020-08-28T10:51:52Z'>
		Yes all files are cached in the .flair folder in your home folder.
		</comment>
		<comment id='13' author='cibeah' date='2020-08-28T11:51:12Z'>
		Quick update: we are working on a fix. Will keep you posted.
		</comment>
		<comment id='14' author='cibeah' date='2020-08-28T12:14:20Z'>
		What about &lt;denchmark-link:https://zenodo.org/&gt;Zenodo&lt;/denchmark-link&gt;
 as hoster? You also get a DOI for each model which would make it easier to cite models in papers.
You can download models from Zenodo e.g. like this:
import requests
import wget

def download(doi, filepath):
    url = f"https://doi.org/{doi}"
    r = requests.get(url)
    record = r.url.split("/")[-1].strip()
    url = f"https://zenodo.org/api/records/{record}"
    r = requests.get(url)
    if r.ok:
        print("Downloading model from Zenodo...")
        print(f"Target directory: {filepath}")
        response = r.json()
        files = response["files"]
        total = sum(file["size"] for file in files)
        for file in files:
            link = file["links"]["self"]
            size = file["size"] / 2 ** 20
            print(f"Total size: {size:.1f} MB")
            fname = file["key"]
            checksum = file["checksum"]
            filename = wget.download(link, filepath)
            return filename
    else:
        raise Excpetion("Unable to download model from Zenodo.")
		</comment>
		<comment id='15' author='cibeah' date='2020-08-29T13:39:42Z'>
		i need en-ner-conll03-v0.4.pt  file . its stored in .flair/ directory default .
		</comment>
		<comment id='16' author='cibeah' date='2020-08-29T22:19:04Z'>
		What's the approximate costs / month or year for hosting? We and a few others rely heavily on this project so can discuss with our investors make a meaningful donation.
		</comment>
		<comment id='17' author='cibeah' date='2020-08-30T12:58:30Z'>
		&lt;denchmark-link:https://github.com/RXminuS&gt;@RXminuS&lt;/denchmark-link&gt;
 that would be great and very much appredicated! I am currently looking into options for hosting and donation models!
&lt;denchmark-link:https://github.com/severinsimmler&gt;@severinsimmler&lt;/denchmark-link&gt;
 thanks for the pointer to Zenodo. Looks interesting - do you have experience wrt download speeds? Some of the models are pretty big and there is a good amount of traffic.
As a first fix, I've moved all models to our university server. Download speeds are slower than before and I worry that the server will have problems with the traffic (so please don't all try at the same time ;)), but at least everything should run again. Will be merged and released soon.
		</comment>
		<comment id='18' author='cibeah' date='2020-08-30T13:05:30Z'>
		
at least everything should run again. Will be merged

Thank you &lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
 so how to use it. as i am getting the below error
OSError                                   Traceback (most recent call last)
 in ()
58     BertEmbeddings(bert_model_or_path = data_folder),
59     #flair fast embedding
---&gt; 60     WordEmbeddings('ar'),
61
62
2 frames
/usr/local/lib/python3.6/dist-packages/flair/file_utils.py in get_from_cache(url, cache_dir)
216     if response.status_code != 200:
217         raise IOError(
--&gt; 218             f"HEAD request failed for url {url} with status code {response.status_code}."
219         )
220
OSError: HEAD request failed for url &lt;denchmark-link:https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/ar-wiki-fasttext-300d-1M.vectors.npy&gt;https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/ar-wiki-fasttext-300d-1M.vectors.npy&lt;/denchmark-link&gt;
 with status code 301.
		</comment>
		<comment id='19' author='cibeah' date='2020-08-30T13:28:20Z'>
		The fix is merged to master and can be used by installing Flair with:
&lt;denchmark-code&gt;pip install --upgrade git+https://github.com/flairNLP/flair.git
&lt;/denchmark-code&gt;

I'll also push this to pip later, but first let's test if this works.
		</comment>
		<comment id='20' author='cibeah' date='2020-08-30T13:33:02Z'>
		Thanks a bunch, &lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
. My stack uses Flair 0.4.2. How do I install that specific version?
		</comment>
		<comment id='21' author='cibeah' date='2020-08-30T13:39:41Z'>
		&lt;denchmark-link:https://github.com/Masum06&gt;@Masum06&lt;/denchmark-link&gt;
 I'm afraid the model download in older versions will remain broken. If updating is not possible you could use the new version to download the models manually and then run the old version.
		</comment>
		<comment id='22' author='cibeah' date='2020-08-30T16:31:50Z'>
		Just wanted to say fantastic work &lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
. Not just for the library but keeping your cool during a situation like this. And your dedication to finding a way around so quickly. I have the deepest respect for open-source maintainers like yourself 
		</comment>
		<comment id='23' author='cibeah' date='2020-08-30T17:12:44Z'>
		&lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
  You are the best! Thank you very much!
		</comment>
		<comment id='24' author='cibeah' date='2020-08-30T19:18:46Z'>
		&lt;denchmark-link:https://github.com/RXminuS&gt;@RXminuS&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/VigneshBaskar&gt;@VigneshBaskar&lt;/denchmark-link&gt;
 Thanks a lot!
We just pushed the new version to pip so you can do a regular update with:
&lt;denchmark-code&gt;pip install --upgrade flair 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='25' author='cibeah' date='2020-08-31T08:11:28Z'>
		Thank you so much for your reactivity &lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
 ! It all works fine for us.
		</comment>
		<comment id='26' author='cibeah' date='2020-09-21T14:12:38Z'>
		&lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
  in  does not work.
		</comment>
		<comment id='27' author='cibeah' date='2020-09-21T15:56:31Z'>
		&lt;denchmark-link:https://github.com/djstrong&gt;@djstrong&lt;/denchmark-link&gt;
 can you try again? Should work now
		</comment>
		<comment id='28' author='cibeah' date='2020-09-21T17:22:02Z'>
		Thank you. It works.
		</comment>
		<comment id='29' author='cibeah' date='2020-10-07T20:22:36Z'>
		Hello,
I am working with  wordembeddings  using Glove and encounter the below error:
**HEAD request failed for url https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy with status code 301**
I also ran the upgrade flair command that was mentioned in earlier posts.
&lt;denchmark-h:h1&gt;code to reproduce the error&lt;/denchmark-h&gt;

from flair.embeddings import WordEmbeddings, FlairEmbeddings
word_embeddings = [
WordEmbeddings('glove')]
		</comment>
		<comment id='30' author='cibeah' date='2020-10-16T08:03:35Z'>
		&lt;denchmark-link:https://github.com/truptikirve26&gt;@truptikirve26&lt;/denchmark-link&gt;
 - I was able to solve the issue with v0.61. Looks like the older version is still cached in your IDE/venv.
		</comment>
	</comments>
</bug>