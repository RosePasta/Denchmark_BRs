<bug id='1222' author='0x01h' open_date='2019-10-18T10:01:50Z' closed_time='2019-10-22T10:22:36Z'>
	<summary>Model name 'distilbert-base-uncased' was not found in model name list.</summary>
	<description>
Describe the bug
DistilBERT embedding throws error even though it can be used in transformers library successfully.
To Reproduce
from flair.embeddings import BertEmbeddings

BertEmbeddings('distilbert-base-uncased')
Expected behavior
Model name 'distilbert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). We assumed 'distilbert-base-uncased' was a path or url but couldn't find tokenizer filesat this path or url.

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-b92101fc623e&gt; in &lt;module&gt;
      5 #bp_embedding = BytePairEmbeddings('multi')
      6 #c_embedding = CharacterEmbeddings()
----&gt; 7 b_e = BertEmbeddings('distilbert-base-uncased')
      8 #embedding = ELMoEmbeddings('small')
      9 #flair_embedding_forward = FlairEmbeddings('news-forward')

~/miniconda3/lib/python3.6/site-packages/flair/embeddings.py in __init__(self, bert_model_or_path, layers, pooling_operation, use_scalar_mix)
   1979         self.tokenizer = BertTokenizer.from_pretrained(bert_model_or_path)
   1980         self.model = BertModel.from_pretrained(
-&gt; 1981             pretrained_model_name_or_path=bert_model_or_path, output_hidden_states=True
   1982         )
   1983         self.layer_indexes = [int(x) for x in layers.split(",")]

~/miniconda3/lib/python3.6/site-packages/pytorch_transformers/modeling_utils.py in from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)
    428                 pretrained_model_name_or_path, *model_args,
    429                 cache_dir=cache_dir, return_unused_kwargs=True,
--&gt; 430                 **kwargs
    431             )
    432         else:

TypeError: 'NoneType' object is not iterable
Environment (please complete the following information):

OS [e.g. iOS, Linux]: Linux, Ubuntu 18.04
Version [e.g. flair-0.3.2]: flair latest version.

Additional context
I've already upgraded flair and transformers, also installed them from git.
	</description>
	<comments>
		<comment id='1' author='0x01h' date='2019-10-21T17:53:44Z'>
		&lt;denchmark-link:https://github.com/0x01h&gt;@0x01h&lt;/denchmark-link&gt;
 we just released Flair 0.4.4 - could you try again? This code works for me locally and on CoLab.
		</comment>
		<comment id='2' author='0x01h' date='2019-10-22T10:22:36Z'>
		&lt;denchmark-link:https://github.com/alanakbik&gt;@alanakbik&lt;/denchmark-link&gt;
 It works like a charm, thank you!
		</comment>
	</comments>
</bug>