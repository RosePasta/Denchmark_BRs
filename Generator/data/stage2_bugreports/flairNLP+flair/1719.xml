<bug id='1719' author='olanag1' open_date='2020-06-25T13:56:52Z' closed_time='2020-11-26T16:58:11Z'>
	<summary>TransformerDocumentEmbeddings memory leak</summary>
	<description>
Hello,
I'm trying to pass a list of documents and obtain document embeddings from pre-trained model "bert-base-uncased".
To debug I measure memory consumption in for loop and I observe that on each new document the memory is leaked.
ubuntu 18.04
flair 0.5
torch 1.5.0


&lt;denchmark-code&gt;document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased')\n
res = []
i = 0
for sent in sentences.tolist() :
    document_embeddings.embed(sent)
    res.append(pd.DataFrame(sent.embedding.detach().numpy(), columns= ['vector']) )
    print('embed doc : ', i, len(sent.tokens))
    i=i+1
    %memit  
&lt;/denchmark-code&gt;

On the 10th document the memory is off:


&lt;denchmark-code&gt;embed doc :  0 5534
peak memory: 2872.60 MiB, increment: 0.00 MiB
embed doc :  1 5704
peak memory: 3546.12 MiB, increment: 0.00 MiB
embed doc :  2 13580
peak memory: 4219.87 MiB, increment: 0.00 MiB
embed doc :  3 17829
peak memory: 4893.87 MiB, increment: 0.00 MiB
embed doc :  4 10832
peak memory: 5567.14 MiB, increment: 0.00 MiB
embed doc :  5 15897
peak memory: 6240.81 MiB, increment: 0.00 MiB
embed doc :  6 3981
peak memory: 6914.24 MiB, increment: 0.00 MiB
embed doc :  7 11573
peak memory: 7587.70 MiB, increment: -0.25 MiB
embed doc :  8 6334
peak memory: 8261.38 MiB, increment: 0.00 MiB
embed doc :  9 5746
peak memory: 8934.84 MiB, increment: 0.00 MiB
embed doc :  10 7951`
&lt;/denchmark-code&gt;

I didn't find any parameter that would allow to free the memory once the computation is finished for one document. Maybe I missed something?
	</description>
	<comments>
		<comment id='1' author='olanag1' date='2020-07-21T12:21:21Z'>
		Hi everyone,
first of all thanks for making this library available, it really is fun to use!
I just ran into the same problem as OP. Any advice would be greatly appreciated.
Best
Jan
		</comment>
		<comment id='2' author='olanag1' date='2020-07-21T12:56:22Z'>
		Thanks for reporting this! &lt;denchmark-link:https://github.com/whoisjones&gt;@whoisjones&lt;/denchmark-link&gt;
 can you take a look?
		</comment>
		<comment id='3' author='olanag1' date='2020-07-21T13:11:48Z'>
		Hi,
after doing some research in the issues I found this thread which solved the problem for me: &lt;denchmark-link:https://github.com/flairNLP/flair/issues/1638&gt;#1638&lt;/denchmark-link&gt;

Basically, set the fine_tune flag to false when loading the model.
Thanks for the quick reply!
		</comment>
		<comment id='4' author='olanag1' date='2020-07-22T15:45:17Z'>
		Thanks &lt;denchmark-link:https://github.com/buenalaune&gt;@buenalaune&lt;/denchmark-link&gt;
,
Setting fine_tune=False also helped in my case.  So, the memory problem is mostly linked to the finetune option.
		</comment>
		<comment id='5' author='olanag1' date='2020-11-19T16:45:24Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>