<bug id='1366' author='trokhymovych' open_date='2020-01-20T14:46:00Z' closed_time='2020-05-24T12:38:16Z'>
	<summary>document_embeddings gives an unexpected error using RoBERTa model</summary>
	<description>
document_embeddings gives an error "IndexError: index 0 is out of bounds for dimension 0 with size 0" for some sentences using RoBERTa model.
It appears using both DocumentRNNEmbeddings and DocumentPoolEmbeddings
To Reproduce
&lt;denchmark-code&gt;from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence, DocumentRNNEmbeddings
from flair.embeddings import RoBERTaEmbeddings
embedding = RoBERTaEmbeddings(pooling_operation="mean")
document_embeddings_roberta = DocumentRNNEmbeddings([embedding]) #, fine_tune_mode='nonlinear')
s = 'negative reconnaissance it' 
sentence = Sentence(s)
document_embeddings_roberta.embed(sentence)
vector = sentence.get_embedding()
vector
&lt;/denchmark-code&gt;

Expected behavior
I expect to get a vector of embedding in the form of Tensor.

&lt;denchmark-link:https://user-images.githubusercontent.com/33522867/72734118-d22a9180-3ba1-11ea-8495-939103636637.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/33522867/72735254-1dde3a80-3ba4-11ea-9c55-905756d5d052.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;However...&lt;/denchmark-h&gt;

If I add a "." at the end of the sentence - it is starting to perform as expected.
&lt;denchmark-link:https://user-images.githubusercontent.com/33522867/72734383-38171900-3ba2-11ea-96e5-89fd9411584d.png&gt;&lt;/denchmark-link&gt;

code:
&lt;denchmark-code&gt;from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence,DocumentRNNEmbeddings
from flair.embeddings import RoBERTaEmbeddings
embedding = RoBERTaEmbeddings(pooling_operation="mean")
document_embeddings_roberta = DocumentRNNEmbeddings([embedding]) #, fine_tune_mode='nonlinear')
s = 'negative reconnaissance it.' 
sentence = Sentence(s)
document_embeddings_roberta.embed(sentence)
vector = sentence.get_embedding()
vector
&lt;/denchmark-code&gt;


Ubuntu
&lt;denchmark-link:https://user-images.githubusercontent.com/33522867/72735009-a7413d00-3ba3-11ea-9320-c6befc904f1f.png&gt;&lt;/denchmark-link&gt;

Additional context
What is interesting that there is no such behavior using the BERT model.
	</description>
	<comments>
		<comment id='1' author='trokhymovych' date='2020-01-20T14:48:10Z'>
		Hi &lt;denchmark-link:https://github.com/trokhymovych&gt;@trokhymovych&lt;/denchmark-link&gt;
 ,
could you try use the latest master version of Flair? I did some tokenization fixes for the GPT2-based models :)
		</comment>
		<comment id='2' author='trokhymovych' date='2020-01-20T14:58:00Z'>
		Thank you, &lt;denchmark-link:https://github.com/stefan-it&gt;@stefan-it&lt;/denchmark-link&gt;

It is working with latest 
		</comment>
		<comment id='3' author='trokhymovych' date='2020-05-19T15:40:00Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
		<comment id='4' author='trokhymovych' date='2020-05-24T12:38:07Z'>
		We've just released Flair 0.5, where you can get document embeddings directly out of the transformer:
from flair.embeddings import TransformerDocumentEmbeddings

# init embedding
embedding = TransformerDocumentEmbeddings('roberta-base')

# create a sentence
sentence = Sentence('The grass is green .')

# embed the sentence
embedding.embed(sentence)
		</comment>
	</comments>
</bug>