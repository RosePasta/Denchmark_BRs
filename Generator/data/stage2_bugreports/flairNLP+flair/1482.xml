<bug id='1482' author='prakashwarbler' open_date='2020-03-20T07:27:55Z' closed_time='2020-07-25T08:22:58Z'>
	<summary>free gpu cache to do prediction for multiple time</summary>
	<description>
this is the code i have tried to run the prediction on text file.
from flair.data import Sentence
from flair.models import SequenceTagger
tagger: SequenceTagger = SequenceTagger.load('models_file_aws/best_model-elmo-flair-11-24-19-3-2020.pt')
with open("flairdata/cust_test.txt","r",encoding="utf-8") as cust:
for line in cust:
sentence: Sentence = Sentence(line)
tagger.predict(sentence)
print("Analysing %s" % sentence)
[print(entity) for entity in sentence.get_spans('ner')]
&lt;denchmark-h:h2&gt;when try for more than once I get cuda out of memory: error given below
2020-03-20 12:32:45,903 loading file models_file_aws/best_model-elmo-flair-11-24-19-3-2020.pt&lt;/denchmark-h&gt;

RuntimeError                              Traceback (most recent call last)
 in 
3 import torch
4 torch.cuda.empty_cache()
----&gt; 5 tagger: SequenceTagger = SequenceTagger.load('models_file_aws/best_model-elmo-flair-11-24-19-3-2020.pt')
6 with open("flairdata/cust_test.txt","r",encoding="utf-8") as cust:
7     for line in cust:
~\Anaconda3\envs\flair\lib\site-packages\flair\nn.py in load(cls, model)
84             # see &lt;denchmark-link:https://github.com/flairNLP/flair/issues/351&gt;#351&lt;/denchmark-link&gt;

85             f = file_utils.load_big_file(str(model_file))
---&gt; 86             state = torch.load(f, map_location=flair.device)
87
88         model = cls._init_model_with_state_dict(state)
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
527             with _open_zipfile_reader(f) as opened_zipfile:
528                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
--&gt; 529         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
530
531
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in _legacy_load(f, map_location, pickle_module, **pickle_load_args)
700     unpickler = pickle_module.Unpickler(f, **pickle_load_args)
701     unpickler.persistent_load = persistent_load
--&gt; 702     result = unpickler.load()
703
704     deserialized_storage_keys = pickle_module.load(f, **pickle_load_args)
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in persistent_load(saved_id)
663                 obj = data_type(size)
664                 obj._torch_load_uninitialized = True
--&gt; 665                 deserialized_objects[root_key] = restore_location(obj, location)
666             storage = deserialized_objects[root_key]
667             if view_metadata is not None:
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in restore_location(storage, location)
738     elif isinstance(map_location, torch.device):
739         def restore_location(storage, location):
--&gt; 740             return default_restore_location(storage, str(map_location))
741     else:
742         def restore_location(storage, location):
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in default_restore_location(storage, location)
154 def default_restore_location(storage, location):
155     for _, _, fn in _package_registry:
--&gt; 156         result = fn(storage, location)
157         if result is not None:
158             return result
~\Anaconda3\envs\flair\lib\site-packages\torch\serialization.py in _cuda_deserialize(obj, location)
134             storage_type = getattr(torch.cuda, type(obj).name)
135             with torch.cuda.device(device):
--&gt; 136                 return storage_type(obj.size())
137         else:
138             return obj.cuda(device)
~\Anaconda3\envs\flair\lib\site-packages\torch\cuda_init_.py in _lazy_new(cls, *args, **kwargs)
478     # We may need to call lazy init again if we are a forked child
479     # del _CudaBase.new
--&gt; 480     return super(_CudaBase, cls).new(cls, *args, **kwargs)
481
482
RuntimeError: CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 4.00 GiB total capacity; 2.67 GiB already allocated; 10.20 MiB free; 2.68 GiB reserved in total by PyTorch)
I have tried torch.cuda.empty_cache() to clear the cache.
but no use of it. only if i restart the kernal in jupyter notebook or jupyter notebook  cuda memory has been cleared and allowed to run one prediction.
how to solve this bug issue. model size is 900+ mb (ELMO+FLAIR embedding).
and is there any way to reduce the size of the model. is pytorch has  post - training optimisation process like quantization process in tensorflow?? if so please let me know how to do it. or you can give us guide to approach this issue.
if you could respond asap that will really grateful.
thanks for your support and guidance.
	</description>
	<comments>
		<comment id='1' author='prakashwarbler' date='2020-07-18T08:18:38Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>