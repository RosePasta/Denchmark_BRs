<bug id='143' author='jiaxiangxu' open_date='2018-12-13T06:35:45Z' closed_time='2018-12-17T01:17:48Z'>
	<summary>Endless loop of discrimination-aware channel pruning, MobileNetV2 at Cifar10</summary>
	<description>
log:
Python script: ./nets/mobilenet_at_cifar10_run.py
# of GPUs: 1
extra arguments: --mobilenet_version 2 --mobilenet_depth_mult 1.0 --learner dis-chn-pruned --dcp_prune_ratio 0.75 --batch_size_eval 128 --model_http_url &lt;denchmark-link:https://api.ai.tencent.com/pocketflow&gt;https://api.ai.tencent.com/pocketflow&lt;/denchmark-link&gt;
 --data_dir_local /workspace/dataset/cifar10_data/cifar-10-batches-bin
'./nets/mobilenet_at_cifar10_run.py' -&gt; 'main.py'
multi-GPU training disabled
INFO:tensorflow:FLAGS:
INFO:tensorflow:data_disk: local
INFO:tensorflow:data_hdfs_host: None
INFO:tensorflow:data_dir_local: /workspace/dataset/cifar10_data/cifar-10-batches-bin
INFO:tensorflow:data_dir_hdfs: None
INFO:tensorflow:cycle_length: 4
INFO:tensorflow:nb_threads: 8
INFO:tensorflow:buffer_size: 1024
INFO:tensorflow:prefetch_size: 8
INFO:tensorflow:nb_classes: 10
INFO:tensorflow:nb_smpls_train: 50000
INFO:tensorflow:nb_smpls_val: 5000
INFO:tensorflow:nb_smpls_eval: 10000
INFO:tensorflow:batch_size: 128
INFO:tensorflow:batch_size_eval: 128
INFO:tensorflow:mobilenet_version: 2
INFO:tensorflow:mobilenet_depth_mult: 1.0
INFO:tensorflow:nb_epochs_rat: 1.0
INFO:tensorflow:lrn_rate_init: 0.045
INFO:tensorflow:batch_size_norm: 96.0
INFO:tensorflow:momentum: 0.9
INFO:tensorflow:loss_w_dcy: 4e-05
INFO:tensorflow:model_http_url: &lt;denchmark-link:https://api.ai.tencent.com/pocketflow&gt;https://api.ai.tencent.com/pocketflow&lt;/denchmark-link&gt;

INFO:tensorflow:summ_step: 100
INFO:tensorflow:save_step: 10000
INFO:tensorflow:save_path: ./models/model.ckpt
INFO:tensorflow:save_path_eval: ./models_eval/model.ckpt
INFO:tensorflow:enbl_dst: False
INFO:tensorflow:enbl_warm_start: False
INFO:tensorflow:loss_w_dst: 4.0
INFO:tensorflow:tempr_dst: 4.0
INFO:tensorflow:save_path_dst: ./models_dst/model.ckpt
INFO:tensorflow:ddpg_actor_depth: 2
INFO:tensorflow:ddpg_actor_width: 64
INFO:tensorflow:ddpg_critic_depth: 2
INFO:tensorflow:ddpg_critic_width: 64
INFO:tensorflow:ddpg_noise_type: param
INFO:tensorflow:ddpg_noise_prtl: tdecy
INFO:tensorflow:ddpg_noise_std_init: 1.0
INFO:tensorflow:ddpg_noise_dst_finl: 0.01
INFO:tensorflow:ddpg_noise_adpt_rat: 1.03
INFO:tensorflow:ddpg_noise_std_finl: 1e-05
INFO:tensorflow:ddpg_rms_eps: 0.0001
INFO:tensorflow:ddpg_tau: 0.01
INFO:tensorflow:ddpg_gamma: 0.9
INFO:tensorflow:ddpg_lrn_rate: 0.001
INFO:tensorflow:ddpg_loss_w_dcy: 0.0
INFO:tensorflow:ddpg_record_step: 1
INFO:tensorflow:ddpg_batch_size: 64
INFO:tensorflow:ddpg_enbl_bsln_func: True
INFO:tensorflow:ddpg_bsln_decy_rate: 0.95
INFO:tensorflow:ws_save_path: ./models_ws/model.ckpt
INFO:tensorflow:ws_prune_ratio: 0.75
INFO:tensorflow:ws_prune_ratio_prtl: optimal
INFO:tensorflow:ws_nb_rlouts: 200
INFO:tensorflow:ws_nb_rlouts_min: 50
INFO:tensorflow:ws_reward_type: single-obj
INFO:tensorflow:ws_lrn_rate_rg: 0.03
INFO:tensorflow:ws_nb_iters_rg: 20
INFO:tensorflow:ws_lrn_rate_ft: 0.0003
INFO:tensorflow:ws_nb_iters_ft: 400
INFO:tensorflow:ws_nb_iters_feval: 25
INFO:tensorflow:ws_prune_ratio_exp: 3.0
INFO:tensorflow:ws_iter_ratio_beg: 0.1
INFO:tensorflow:ws_iter_ratio_end: 0.5
INFO:tensorflow:ws_mask_update_step: 500.0
INFO:tensorflow:cp_lasso: True
INFO:tensorflow:cp_quadruple: False
INFO:tensorflow:cp_reward_policy: accuracy
INFO:tensorflow:cp_nb_points_per_layer: 10
INFO:tensorflow:cp_nb_batches: 30
INFO:tensorflow:cp_prune_option: auto
INFO:tensorflow:cp_prune_list_file: ratio.list
INFO:tensorflow:cp_channel_pruned_path: ./models/pruned_model.ckpt
INFO:tensorflow:cp_best_path: ./models/best_model.ckpt
INFO:tensorflow:cp_original_path: ./models/original_model.ckpt
INFO:tensorflow:cp_preserve_ratio: 0.5
INFO:tensorflow:cp_uniform_preserve_ratio: 0.6
INFO:tensorflow:cp_noise_tolerance: 0.15
INFO:tensorflow:cp_lrn_rate_ft: 0.0001
INFO:tensorflow:cp_nb_iters_ft_ratio: 0.2
INFO:tensorflow:cp_finetune: False
INFO:tensorflow:cp_retrain: False
INFO:tensorflow:cp_list_group: 1000
INFO:tensorflow:cp_nb_rlouts: 200
INFO:tensorflow:cp_nb_rlouts_min: 50
INFO:tensorflow:cpg_save_path: ./models_cpg/model.ckpt
INFO:tensorflow:cpg_save_path_eval: ./models_cpg_eval/model.ckpt
INFO:tensorflow:cpg_prune_ratio_type: uniform
INFO:tensorflow:cpg_prune_ratio: 0.5
INFO:tensorflow:cpg_skip_ht_layers: True
INFO:tensorflow:cpg_prune_ratio_file: None
INFO:tensorflow:cpg_lrn_rate_pgd_init: 1e-10
INFO:tensorflow:cpg_lrn_rate_pgd_incr: 1.4
INFO:tensorflow:cpg_lrn_rate_pgd_decr: 0.7
INFO:tensorflow:cpg_lrn_rate_adam: 0.01
INFO:tensorflow:cpg_nb_iters_layer: 1000
INFO:tensorflow:dcp_save_path: ./models_dcp/model.ckpt
INFO:tensorflow:dcp_save_path_eval: ./models_dcp_eval/model.ckpt
INFO:tensorflow:dcp_prune_ratio: 0.75
INFO:tensorflow:dcp_nb_stages: 3
INFO:tensorflow:dcp_lrn_rate_adam: 0.001
INFO:tensorflow:dcp_nb_iters_block: 10000
INFO:tensorflow:dcp_nb_iters_layer: 500
INFO:tensorflow:uql_equivalent_bits: 4
INFO:tensorflow:uql_nb_rlouts: 200
INFO:tensorflow:uql_w_bit_min: 2
INFO:tensorflow:uql_w_bit_max: 8
INFO:tensorflow:uql_tune_layerwise_steps: 100
INFO:tensorflow:uql_tune_global_steps: 2000
INFO:tensorflow:uql_tune_save_path: ./rl_tune_models/model.ckpt
INFO:tensorflow:uql_tune_disp_steps: 300
INFO:tensorflow:uql_enbl_random_layers: True
INFO:tensorflow:uql_enbl_rl_agent: False
INFO:tensorflow:uql_enbl_rl_global_tune: True
INFO:tensorflow:uql_enbl_rl_layerwise_tune: False
INFO:tensorflow:uql_weight_bits: 4
INFO:tensorflow:uql_activation_bits: 32
INFO:tensorflow:uql_use_buckets: False
INFO:tensorflow:uql_bucket_size: 256
INFO:tensorflow:uql_quant_epochs: 60
INFO:tensorflow:uql_save_quant_model_path: ./uql_quant_models/uql_quant_model.ckpt
INFO:tensorflow:uql_quantize_all_layers: False
INFO:tensorflow:uql_bucket_type: channel
INFO:tensorflow:uqtf_save_path: ./models_uqtf/model.ckpt
INFO:tensorflow:uqtf_save_path_eval: ./models_uqtf_eval/model.ckpt
INFO:tensorflow:uqtf_weight_bits: 8
INFO:tensorflow:uqtf_activation_bits: 8
INFO:tensorflow:uqtf_quant_delay: 0
INFO:tensorflow:uqtf_freeze_bn_delay: None
INFO:tensorflow:uqtf_lrn_rate_dcy: 0.01
INFO:tensorflow:nuql_equivalent_bits: 4
INFO:tensorflow:nuql_nb_rlouts: 200
INFO:tensorflow:nuql_w_bit_min: 2
INFO:tensorflow:nuql_w_bit_max: 8
INFO:tensorflow:nuql_tune_layerwise_steps: 100
INFO:tensorflow:nuql_tune_global_steps: 2101
INFO:tensorflow:nuql_tune_save_path: ./rl_tune_models/model.ckpt
INFO:tensorflow:nuql_tune_disp_steps: 300
INFO:tensorflow:nuql_enbl_random_layers: True
INFO:tensorflow:nuql_enbl_rl_agent: False
INFO:tensorflow:nuql_enbl_rl_global_tune: True
INFO:tensorflow:nuql_enbl_rl_layerwise_tune: False
INFO:tensorflow:nuql_init_style: quantile
INFO:tensorflow:nuql_opt_mode: weights
INFO:tensorflow:nuql_weight_bits: 4
INFO:tensorflow:nuql_activation_bits: 32
INFO:tensorflow:nuql_use_buckets: False
INFO:tensorflow:nuql_bucket_size: 256
INFO:tensorflow:nuql_quant_epochs: 60
INFO:tensorflow:nuql_save_quant_model_path: ./nuql_quant_models/model.ckpt
INFO:tensorflow:nuql_quantize_all_layers: False
INFO:tensorflow:nuql_bucket_type: split
INFO:tensorflow:log_dir: ./logs
INFO:tensorflow:enbl_multi_gpu: False
INFO:tensorflow:learner: dis-chn-pruned
INFO:tensorflow:exec_mode: train
INFO:tensorflow:debug: False
INFO:tensorflow:h: False
INFO:tensorflow:help: False
INFO:tensorflow:helpfull: False
INFO:tensorflow:helpshort: False
...
INFO:tensorflow:adding channel #0 to the non-pruned set
INFO:tensorflow:layer &lt;denchmark-link:https://github.com/Tencent/PocketFlow/issues/29&gt;#29&lt;/denchmark-link&gt;
: prune_ratio = 0.8719
INFO:tensorflow:adding channel #0 to the non-pruned set
INFO:tensorflow:layer &lt;denchmark-link:https://github.com/Tencent/PocketFlow/issues/29&gt;#29&lt;/denchmark-link&gt;
: prune_ratio = 0.8719
INFO:tensorflow:adding channel #0 to the non-pruned set
INFO:tensorflow:layer &lt;denchmark-link:https://github.com/Tencent/PocketFlow/issues/29&gt;#29&lt;/denchmark-link&gt;
: prune_ratio = 0.8719
	</description>
	<comments>
		<comment id='1' author='jiaxiangxu' date='2018-12-13T11:23:14Z'>
		Same problem, I run mobilenetV1  discrimination-aware channel pruning ratio 0.4 and inceptionv4 discrimination-aware channel pruning ratio 0.8 at the same time, they stuck at for long time (more than 12 hours)
INFO:tensorflow:adding channel #0 to the non-pruned set
		</comment>
		<comment id='2' author='jiaxiangxu' date='2018-12-13T13:27:57Z'>
		Seems like a bug. We are looking into it. &lt;denchmark-link:https://github.com/jiaxiangxu&gt;@jiaxiangxu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ginger0106&gt;@ginger0106&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='jiaxiangxu' date='2018-12-14T01:36:56Z'>
		&lt;denchmark-link:https://github.com/jiaxiangxu&gt;@jiaxiangxu&lt;/denchmark-link&gt;

Since you are using the self-defined model (MobileNet at CIFAR-10), can you post these two files, so that we can reproduce your issue?

mobilenet_at_cifar10.py
mobilenet_at_cifar10_run.py

		</comment>
		<comment id='4' author='jiaxiangxu' date='2018-12-14T07:42:32Z'>
		Actually, I used  mobilenetV1 at imagenet, it is a default model in pocketflow.
		</comment>
		<comment id='5' author='jiaxiangxu' date='2018-12-14T08:01:46Z'>
		&lt;denchmark-link:https://github.com/ginger0106&gt;@ginger0106&lt;/denchmark-link&gt;
 Understood. It should be some bugs with , instead of specific (model, dataset) combination. We are working on this.
		</comment>
		<comment id='6' author='jiaxiangxu' date='2018-12-14T08:28:59Z'>
		
@jiaxiangxu
Since you are using the self-defined model (MobileNet at CIFAR-10), can you post these two files, so that we can reproduce your issue?

mobilenet_at_cifar10.py
mobilenet_at_cifar10_run.py


Per &lt;denchmark-link:https://github.com/ginger0106&gt;@ginger0106&lt;/denchmark-link&gt;
 comment "Actually, I used mobilenetV1 at imagenet, it is a default model in pocketflow.", I omit to post these two files and thank you.
		</comment>
		<comment id='7' author='jiaxiangxu' date='2018-12-14T08:33:03Z'>
		&lt;denchmark-link:https://github.com/jiaxiangxu&gt;@jiaxiangxu&lt;/denchmark-link&gt;
 If interested, you can add a pull request for these two files to add support for MobileNet models at CIFAR-10, to enrich the model library in PocketFlow. Your contribution is highly welcomed and appreciated.
		</comment>
		<comment id='8' author='jiaxiangxu' date='2018-12-16T06:14:10Z'>
		&lt;denchmark-link:https://github.com/jiaxiang-wu&gt;@jiaxiang-wu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ginger0106&gt;@ginger0106&lt;/denchmark-link&gt;

We have provided a hotfix in PR &lt;denchmark-link:https://github.com/Tencent/PocketFlow/pull/147&gt;#147&lt;/denchmark-link&gt;
. Please verify whether the latest code has resolved your issues.
		</comment>
		<comment id='9' author='jiaxiangxu' date='2018-12-17T01:17:48Z'>
		Closing. Please reopen it if the bug still exists.
		</comment>
	</comments>
</bug>