<bug id='124' author='ananyahjha93' open_date='2020-07-22T07:21:01Z' closed_time='2020-07-24T10:05:33Z'>
	<summary>GPUs are not utilized in any self_supervised models without the --gpus flag</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Running something like CUDA_VISIBLE_DEVICES=0 python simclr_module.py allocates memory on the GPU but doesn't put any batches or forward/backward passes on it. Reported specifically for SimCLR in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning-bolts/issues/35&gt;#35&lt;/denchmark-link&gt;
.
This issue also percolates to the current tests in 'tests/models/test_self_supervised.py' where tests are passed without ever running the model on GPUs. Test fix expected in &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning-bolts/pull/122&gt;#122&lt;/denchmark-link&gt;
.
&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

python simclr_module.py

'simclr_module.py' can be replaced by amdim/cpc etc.
&lt;denchmark-link:https://user-images.githubusercontent.com/7491256/88146746-40d8be00-cbca-11ea-9acb-04b0734090d5.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/7491256/88146773-47673580-cbca-11ea-94d3-7c0e995f6453.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

The default params should put the model on the GPU and if --gpus flag is not set, Lightning trainer should not report GPU used as True.
Might well be a lightning bug and not a bolts bug.
	</description>
	<comments>
		<comment id='1' author='ananyahjha93' date='2020-07-22T20:30:12Z'>
		Fixed in PR: &lt;denchmark-link:https://github.com/PyTorchLightning/pytorch-lightning/pull/2674&gt;PyTorchLightning/pytorch-lightning#2674&lt;/denchmark-link&gt;
 of Lightning
		</comment>
	</comments>
</bug>