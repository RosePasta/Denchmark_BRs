<bug id='1340' author='andreasmarxer' open_date='2019-11-22T13:09:27Z' closed_time='2019-11-26T00:49:43Z'>
	<summary>RGBD_integration pose format in trajectory.log file</summary>
	<description>
I currently started working with the rgbd_integration for generating a colored 3D mesh.
I did work with the example code and adapt it to my own dataset. At the point of generating the trajectory.log file with including the poses I got confussed.
In the documentation (&lt;denchmark-link:http://redwood-data.org/indoor/fileformat.html&gt;http://redwood-data.org/indoor/fileformat.html&lt;/denchmark-link&gt;
) it is written that the transform should be from the camera to the world frame, the transform is: 
But when doing so I got very bad results. Could it be that there is a fault in the documentation and on should use the inverse transfo from world to camera frame?
Because when doing so, I get better, but still not a really good 3d representation.
I read also about another user posting about this in the Discord chat, but no answers were provided.
&lt;denchmark-link:https://user-images.githubusercontent.com/45263298/69428498-a0c44f80-0d31-11ea-882f-ef38ef6920c1.png&gt;&lt;/denchmark-link&gt;

Another question regarding the example pose format:
&lt;denchmark-link:https://user-images.githubusercontent.com/45263298/69428685-1e885b00-0d32-11ea-926e-21f666c3e76f.png&gt;&lt;/denchmark-link&gt;

Where is the origin of the world frame in the generated 3d mesh located?
It would make sense that it is at the first frame, therefore the first transform should have identity for rotation and no translation.But only the first rotation is identity, not the first translation.
So where is the origion of the world frame located in the example?
	</description>
	<comments>
		<comment id='1' author='andreasmarxer' date='2019-11-22T16:24:17Z'>
		&lt;denchmark-link:https://github.com/syncle&gt;@syncle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/qianyizh&gt;@qianyizh&lt;/denchmark-link&gt;
 any ideas?
		</comment>
		<comment id='2' author='andreasmarxer' date='2019-11-22T16:30:08Z'>
		If you have bad results either way then there might be problems within other configurations. Can you please verify if the adaptation works for the official datasets such as stanford/lounge?
		</comment>
		<comment id='3' author='andreasmarxer' date='2019-11-22T17:05:03Z'>
		I will verify tomorrow that it works with the official datasets. Although also the dataset I recorded with ROS looks fine when visualized as DepthCloud in Rviz with a decay time of 10 frames.
What I already did is testing it with the 5 example images of the chair, there it worked perfectly fine!
And further, I don't have bad results either way. I have bad and not really satisfying results.
Interesting is that when I integrate 20 images, as mentioned it's not satisfying:
&lt;denchmark-link:https://user-images.githubusercontent.com/45263298/69444903-974adf80-0d51-11ea-88b5-479c66f26334.png&gt;&lt;/denchmark-link&gt;

When I do pack them in 4 groups of 6 (with overlapping), then the integration looks fine as shown for two examples:
&lt;denchmark-link:https://user-images.githubusercontent.com/45263298/69445366-759e2800-0d52-11ea-96b8-c1b8a5b75c97.png&gt;&lt;/denchmark-link&gt;

Isn't this weird? What could be the issue for this?
		</comment>
		<comment id='4' author='andreasmarxer' date='2019-11-25T06:49:25Z'>
		
If you have bad results either way then there might be problems within other configurations. Can you please verify if the adaptation works for the official datasets such as stanford/lounge?

Do you mean this dataset? &lt;denchmark-link:http://buildingparser.stanford.edu/dataset.html&gt;http://buildingparser.stanford.edu/dataset.html&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/theNded&gt;@theNded&lt;/denchmark-link&gt;

The term adaption may have been somewhat misleading. I only adapted the RGB and Depth data paths and the Intrinsics, as opposed to the Example code!
		</comment>
		<comment id='5' author='andreasmarxer' date='2019-11-25T15:10:53Z'>
		Sorry for the confusion, this is not what I've mentioned.
The dataset can be downloaded with &lt;denchmark-link:https://github.com/intel-isl/Open3D/blob/master/examples/Python/ReconstructionSystem/scripts/download_stanford.sh&gt;this script&lt;/denchmark-link&gt;
 shipped with Open3D.
		</comment>
		<comment id='6' author='andreasmarxer' date='2019-11-25T17:02:14Z'>
		Thank you. In the meantime, I managed to solve the problem.
Indeed it was a problem within the poses I used.
Thank you very much for the help!
		</comment>
		<comment id='7' author='andreasmarxer' date='2019-11-26T00:49:43Z'>
		Cool, good luck!
		</comment>
	</comments>
</bug>