<bug id='916' author='abuzaina' open_date='2019-04-17T23:15:14Z' closed_time='2019-05-14T20:00:26Z'>
	<summary>Color map optimisation not working properly</summary>
	<description>
I am using the color_map_optimization.py example for texturing. I am able to generate a point cloud from rgbd image.  The point cloud fits perfectly to the mesh after applying the transformation. Please see image below.
&lt;denchmark-link:https://user-images.githubusercontent.com/6253920/56326580-6eaf9700-612b-11e9-8a0e-1f7d3b720b6a.png&gt;&lt;/denchmark-link&gt;

However when I use the same transformation matrix in color_map_optimization to do texturing  I get this result.
&lt;denchmark-link:https://user-images.githubusercontent.com/6253920/56326627-a4ed1680-612b-11e9-9e5d-998f92e35725.png&gt;&lt;/denchmark-link&gt;

Which is totally off. It does not make any sense to me. Any ideas ?
	</description>
	<comments>
		<comment id='1' author='abuzaina' date='2019-04-19T04:19:37Z'>
		Could you provide more information?

Did you get the expected outputs by running the color map optimization example?
"I am able to generate a point cloud from rgbd image.": how did you generate the point cloud?
"The point cloud fits perfectly to the mesh after applying the transformation.": how is the mesh generated and what's the relation among the "mesh", the "point cloud" and "rgbd image"?
"However when I use the same transformation matrix in color_map_optimization to do texturing I get this result.": How did you use color_map_optimization and how did you apply transformation?
As a sanity check, the color_map_optimization.py creates the default color mapping with 0 iterations, this, in theory, should produce blurry but roughly aligned results, what are the results with 0 iteration in your dataset?

		</comment>
		<comment id='2' author='abuzaina' date='2019-04-19T22:26:15Z'>
		hi &lt;denchmark-link:https://github.com/yxlao&gt;@yxlao&lt;/denchmark-link&gt;
 ,

Yes I get the expected outputs by running the color map optimization example on the fountain dataset.
I've generated the point cloud using first create_rgbd_image_from_color_and_depth, then create_point_cloud_from_rgbd_image, exactly like color map optimization example.
The mesh generated by a custom code. I've tested it with other texturing algorithms with the same image and camera geometries and it gave the expected results. So there is no error in the mesh or the image or in the camera parameters.
I used it exactly like the example, I just edited the example to put my data. The only difference is that the depth map I have is in raw format and has a scale of 10000, which is accounted for in the code.
I am aware of the iterations, here are the results of 0 iterations and 300 iterations respectively.
-- I attach the data and my code so please try to re-generate.
anas.zip

&lt;denchmark-link:https://user-images.githubusercontent.com/6253920/56446134-bfeb9200-62b5-11e9-99af-123d563f9f5a.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/6253920/56446202-1953c100-62b6-11e9-9f0d-ac71b54c6358.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='abuzaina' date='2019-05-10T22:05:28Z'>
		&lt;denchmark-link:https://github.com/yxlao&gt;@yxlao&lt;/denchmark-link&gt;
 any luck with running it on my data ?
		</comment>
		<comment id='4' author='abuzaina' date='2019-05-14T20:00:26Z'>
		I figured out the issue, needed to edit camera.parameters[i].intrinsic.intrinsic_matrix
		</comment>
	</comments>
</bug>