<bug id='874' author='mike239x' open_date='2019-03-20T17:57:21Z' closed_time='2019-09-16T15:32:23Z'>
	<summary>ICP point to plane has wrong RMSE</summary>
	<description>
In &lt;denchmark-link:https://github.com/IntelVCL/Open3D/blob/master/src/Open3D/Registration/Registration.cpp&gt;Registration.cpp&lt;/denchmark-link&gt;
 the for-loop calls  which in turn computes RMSE as if it is a point to point ICP.
As a side effect the  returned by  has wrong RMSE.
Also, in &lt;denchmark-link:https://github.com/IntelVCL/Open3D/blob/master/src/Open3D/Registration/TransformationEstimation.cpp&gt;TransformationEstimation.cpp&lt;/denchmark-link&gt;
 you have the correct code for the RMSE calculation, namely , but it is NEVER used. I &lt;denchmark-link:https://github.com/IntelVCL/Open3D/search?q=ComputeRMSE&amp;unscoped_q=ComputeRMS&gt;checked&lt;/denchmark-link&gt;
.
The easiest fix I see is to pass const TransformationEstimation &amp;estimation into  GetRegistrationResultAndCorrespondences and then inside just call estimation.ComputeRMSE(...).
It would be also nice to pass   into  the  function in &lt;denchmark-link:https://github.com/IntelVCL/Open3D/blob/master/src/Open3D/Registration/Registration.cpp&gt;Registration.cpp&lt;/denchmark-link&gt;
, so that one can choose between  and . I can make a separate issue for that if you want.
	</description>
	<comments>
		<comment id='1' author='mike239x' date='2019-03-20T18:00:15Z'>
		I can fix that and make a PR out of it but I got no idea how to change python bindings...
		</comment>
		<comment id='2' author='mike239x' date='2019-03-26T17:00:10Z'>
		Yes you are right. But I think I intentionally made this design. The reason is that I treat the result of GetRegistrationResultAndCorrespondences as a report of the registration. It contains two parts, one is the correspondence set, the other is the rmse of inlier correspondences in the 3D Euclidean space.
There are a couple of benefits to use this instead of the true RMSE in the optimization equation (which is implemented in TransformationEstimation::ComputeRMSE).
First, it has a specific geometric meaning (a physical distance in 3D Euclidean space) no matter which registration algorithm you use. You have an intuitive understanding of the results by just looking at the numbers. On the contrary, taking ColoredICP as an example, it is hard to interpret the meaning of the result produced by TransformationEstimationForColoredICP::ComputeRMSE.
Second, I think most ICP variants use 3D Euclidean distance of inliers as a criteria (together with the inlier ratio) to check if a registration result is better and how much it is better (to check convergence). I think the point-to-plane ICP in PCL and the original ColoredICP followed this. I also made some tests when I implemented this and it turns out using TransformationEstimation::ComputeRMSE is less robust than using the 3D Euclidean RMSE in my experiments. So I implemented TransformationEstimation::ComputeRMSE but eventually did not use them in the registration algorithms.
Having said that, everything above was based on my anecdotal experience. I may be wrong. We should probably run an extensive test again to compare the Euclidean RMSE and the true RMSE, and pick the one that is more robust. Also, I should definitely give them different names. They are confusing right now.
		</comment>
		<comment id='3' author='mike239x' date='2019-03-26T19:10:58Z'>
		&lt;denchmark-link:https://github.com/qianyizh&gt;@qianyizh&lt;/denchmark-link&gt;
 Well, from my personal experience the difference between the two becomes clear then the down-sampling is done with some really high voxel size.
I wanted to prove my point with a small script, but for whatever reason I got strange behavior of normals estimation... I'll leave it here for now:
import numpy as np
import open3d
from copy import deepcopy

X,Y = np.mgrid[0:1:0.001,0:1:0.001]
X = X.flatten()
Y = Y.flatten()

bot = np.zeros((3, X.size))
bot[0] = X
bot[1] = Y

left = np.zeros((3, X.size))
left[1] = X
left[2] = Y

front = np.zeros((3, X.size))
front[0] = X
front[2] = Y

pts = np.concatenate((bot, front, left), axis = 1)

noise = np.random.rand(*pts.shape) / 10000000
pts += noise

shape  = open3d.PointCloud()
shape.points = open3d.utility.Vector3dVector(pts.T)
ds1 = open3d.voxel_down_sample(shape, voxel_size = 0.1)
ds1.paint_uniform_color([1, 0.706, 0]) # yellow

# add 1 more point to shift the grid of down-sampling:
p = np.array([[-0.05],[-0.05],[-0.05]])
pts = np.concatenate((pts, p), axis = 1)

shape.points = open3d.utility.Vector3dVector(pts.T)
ds2 = open3d.voxel_down_sample(shape, voxel_size = 0.1)
ds2.paint_uniform_color([0, 0.651, 0.929]) # blue

open3d.estimate_normals(ds1, open3d.KDTreeSearchParamHybrid(radius = 0.5, max_nn = 30))
open3d.estimate_normals(ds2, open3d.KDTreeSearchParamHybrid(radius = 0.5, max_nn = 30))

# show the scene at the start
open3d.draw_geometries([ds1, ds2])

tr = np.identity(4)

# point to point ICP:
icp = open3d.registration_icp(ds1, ds2, 0.5,  tr, open3d.TransformationEstimationPointToPoint())
ds1.transform(icp.transformation)
# ICP point to point returns wrong results
open3d.draw_geometries([ds1, ds2])

# point to plane ICP
icp = open3d.registration_icp(ds1, ds2, 0.5,  tr, open3d.TransformationEstimationPointToPlane())
ds1.transform(icp.transformation)
# ICP point to plane does not fix it (because RMSE is wrong)
open3d.draw_geometries([ds1, ds2])
^^^ update: the script works now, but sadly doesn't prove my point...
		</comment>
	</comments>
</bug>