<bug id='398' author='vfdev-5' open_date='2017-08-30T19:10:06Z' closed_time='2017-08-30T19:28:14Z'>
	<summary>Issue with k-folds training (cross-validation)</summary>
	<description>
Hi,
I try to train k models on k-folded data. Code is &lt;denchmark-link:https://gist.github.com/vfdev-5/05648eaf8ffb71a6f2dd0ee932e22dea&gt;here&lt;/denchmark-link&gt;
. Training on the 1st fold runs correctly and on the next fold I have the following error:
&lt;denchmark-code&gt;ValueError: Tensor("input:0", shape=(?, 30, 30, 3), dtype=float32) must be from the same graph as Tensor("QueueInput/input_queue:0", shape=(), dtype=resource).
&lt;/denchmark-code&gt;

Could you suggest how to do such k-folds training within your frame work (probably, I would have a similar graph problem with pure TF).
Thank you
	</description>
	<comments>
		<comment id='1' author='vfdev-5' date='2017-08-30T19:11:57Z'>
		I think you need to clear the graph with tf.reset_default_graph() before starting a new training.
		</comment>
		<comment id='2' author='vfdev-5' date='2017-08-30T19:13:35Z'>
		Yes, I do this &lt;denchmark-link:https://gist.github.com/vfdev-5/05648eaf8ffb71a6f2dd0ee932e22dea#file-cifar-convnet-cross-validation-py-L186&gt;here&lt;/denchmark-link&gt;
. However, it is not enough
		</comment>
		<comment id='3' author='vfdev-5' date='2017-08-30T19:28:47Z'>
		Should be fixed now. BTW, because you created a new graph each time, you probably don't need a reset.
		</comment>
		<comment id='4' author='vfdev-5' date='2017-08-30T19:30:17Z'>
		Okay, I see. Thank you !
		</comment>
		<comment id='5' author='vfdev-5' date='2017-08-30T21:54:11Z'>
		I rerun my code with the latest tensorpack and the bug disappeared üëç
However, at the end there is an IndexError that is thrown after the messge Train is finished!. Here is the traceback:
&lt;denchmark-code&gt;[0830 21:45:55 @base.py:242] Training has finished!
Traceback (most recent call last):
  File "cifar-convnet-cross-validation.py", line 190, in &lt;module&gt;
    trainer.train()
  File "/usr/lib/python3.5/contextlib.py", line 66, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 3815, in get_controller
    if self.stack[-1] is not default:
IndexError: list index out of range
[0830 21:45:55 @prefetch.py:174] [Prefetch Master] Context terminated.
Prefetch process exited.
[0830 21:45:55 @input_source.py:203] EnqueueThread QueueInput/input_queue Exited.
Prefetch process exited.
Prefetch process exited.
Prefetch process exited.
Prefetch process exited.
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/ppwwyyxx&gt;@ppwwyyxx&lt;/denchmark-link&gt;
  could you hint how to fix this? Thanks
		</comment>
		<comment id='6' author='vfdev-5' date='2017-08-30T22:04:17Z'>
		Using reset_default_graph under tf.Graph() is already forbidden in latest TensorFlow (I'm using nightly).
Using this and it will be fine:
for val_fold_index in range(n_folds):
    with tf.Graph().as_default():
      # no reset
Or this:
for val_fold_index in range(n_folds):
    # no new graph
    tf.reset_default_graph()
		</comment>
		<comment id='7' author='vfdev-5' date='2019-04-13T15:22:34Z'>
		Hi yx,
My question is similar and I'm using examples/FasterRCNN with my own dataset (600 images).
The model easily overfitting at around 50 epoch (100 steps per epoch).
&lt;denchmark-link:https://user-images.githubusercontent.com/12379916/56081626-fce10000-5e41-11e9-9cb7-1ab7e7ee7e00.png&gt;&lt;/denchmark-link&gt;

And frcnn loss keep going down.
&lt;denchmark-link:https://user-images.githubusercontent.com/12379916/56081712-f30bcc80-5e42-11e9-9aec-8d4778628c47.png&gt;&lt;/denchmark-link&gt;

I'm wondering if we got any solutions like cross validation/drop out/early stop in tensorpack for FRCNN?
Can I assume that we don't need those methods for large dataset like COCO?
		</comment>
		<comment id='8' author='vfdev-5' date='2019-04-13T17:40:30Z'>
		You can implement early stop with tensorpack callbacks.
		</comment>
	</comments>
</bug>