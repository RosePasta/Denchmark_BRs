<bug id='966' author='maciejjaskowski' open_date='2018-11-05T08:54:49Z' closed_time='2018-11-05T10:48:06Z'>
	<summary>MinSaver saves wrong model without warning</summary>
	<description>
If you're asking about an unexpected problem you met, use this template.
PLEASE DO NOT DELETE THIS TEMPLATE, FILL IT:
&lt;denchmark-h:h3&gt;1. What you did:&lt;/denchmark-h&gt;

(1) 
Run mnist example &lt;denchmark-link:https://github.com/tensorpack/tensorpack/blob/master/examples/basics/mnist-convnet.py&gt;https://github.com/tensorpack/tensorpack/blob/master/examples/basics/mnist-convnet.py&lt;/denchmark-link&gt;

(2) If you're using examples, have you made any changes to the examples? Paste them here:
No changes.
&lt;denchmark-h:h3&gt;2. What you observed:&lt;/denchmark-h&gt;

(1) Include the ENTIRE logs here:
The model saved with MaxSaver is a model from epoch N+1 instead from the epoch N, as expected. Logs show no problem.
(2) Other observations, if any:
N/A
&lt;denchmark-h:h3&gt;3. What you expected, if not obvious.&lt;/denchmark-h&gt;

There are two problems:

the example is wrong, it should read:

&lt;denchmark-code&gt;callbacks=[
            ModelSaver(),   # save the model after every epoch
            InferenceRunner(    # run inference(for validation) after every epoch
                dataset_test,   # the DataFlow instance used for validation
                ScalarStats(['cross_entropy_loss', 'accuracy'])),
            MaxSaver('validation_accuracy'),  # save the model with highest accuracy (prefix 'validation_')
           
        ],
&lt;/denchmark-code&gt;

Note, the order in callbacks. If InferenceRunner is run last, as originally in the example, MaxSaver will read _get_stat after epoch N but will save model after epoch N+1.

There is no safeguard against the original version.

In my case, _need_save() could be changed to something like
&lt;denchmark-code&gt;    def _need_save(self):
        v = self._get_stat()
        assert v, "No InferenceRunner was run before executing MinSaver"
        return v &gt; self.min if self.reverse else v &lt; self.min
&lt;/denchmark-code&gt;

But I am not sure if it does not have some implications, I don't see.

I didn't find a piece of documentation suggesting that MaxSaver must be after InferenceRunner in callbacks.

&lt;denchmark-h:h3&gt;4. Your environment:&lt;/denchmark-h&gt;

N/A
I'll be happy to fix this either way once we settle on a solution.
	</description>
	<comments>
		<comment id='1' author='maciejjaskowski' date='2018-11-05T10:14:32Z'>
		Nice catch. This should be conveyed more clearly in the docs, and detected automatically.
		</comment>
		<comment id='2' author='maciejjaskowski' date='2018-11-05T12:17:57Z'>
		Probably not a big deal if your model's performance does not variate too much epoch to epoch :-)
		</comment>
	</comments>
</bug>