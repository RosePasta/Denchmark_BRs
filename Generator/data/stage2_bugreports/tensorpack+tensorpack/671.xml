<bug id='671' author='anthony123' open_date='2018-02-25T07:02:46Z' closed_time='2018-02-26T04:32:34Z'>
	<summary>problem encountered when I conduct distributed training</summary>
	<description>
I encountered a problem when  i run my distributed training code, the  error traces are as follows:
&lt;denchmark-link:https://user-images.githubusercontent.com/4050099/36638940-cee8895c-1a3b-11e8-801d-dafa56cb3390.png&gt;&lt;/denchmark-link&gt;

my code is &lt;denchmark-link:https://github.com/anthony123/learnit/blob/master/cifar10-sparse-densenet-bc-exp.py&gt;here&lt;/denchmark-link&gt;

I launch my code as:
python cifar10-sparse-densenet-bc-exp.py --gpu=0,1,2,3 --job worker --task 0
when I use trainer
&lt;denchmark-code&gt;trainer = SyncMultiGPUTrainerParameterServer(len(args.gpu.split(',')))
launch_train_with_config(config, trainer)
&lt;/denchmark-code&gt;

there will be no problem
Any suggestion is appreciated.
	</description>
	<comments>
		<comment id='1' author='anthony123' date='2018-02-25T15:50:28Z'>
		
You're using a very old tensorpack. Please upgrade and try again.
Tensorflow does not have a native fast distributed trainer. Only horovod trainer can get a reasonable speedup.

		</comment>
		<comment id='2' author='anthony123' date='2018-02-26T02:18:05Z'>
		When i upgrade tensorpack to 0.8.1, there is another error has appeared. the error traces are as follows:
&lt;denchmark-link:https://user-images.githubusercontent.com/4050099/36650334-d77a5c06-1add-11e8-9c74-6d3339ee5040.png&gt;&lt;/denchmark-link&gt;

Next i will try horovod trainer ,see if it can give me a reasonable speedup
		</comment>
		<comment id='3' author='anthony123' date='2018-02-26T04:33:39Z'>
		The above commit should fix the problem. Another way to fix the problem is to upgrade your tensorflow to 1.5
		</comment>
	</comments>
</bug>