<bug id='194' author='chingyaoc' open_date='2017-03-18T07:51:58Z' closed_time='2017-03-19T06:22:19Z'>
	<summary>[DQN] Attempt to free invalid pointer</summary>
	<description>
Hi,
Thanks for sharing such a powerful library.
However, error occurs when I attempt to run &lt;denchmark-link:https://github.com/ppwwyyxx/tensorpack/tree/master/examples/DeepQNetwork&gt;DeepQNetwork&lt;/denchmark-link&gt;
 with .
&lt;denchmark-code&gt;[0318 15:48:49 @logger.py:69] Argv: ./DQN.py --rom breakout.bin
Warning: couldn't load settings file: ./ale.cfg
[0318 15:48:49 @expreplay.py:144] Number of Legal actions: 4
tcmalloc: large alloc 7056007168 bytes == 0x46ce000 @
[0318 15:48:50 @gpu.py:32] Loading local devices by TensorFlow ...
src/tcmalloc.cc:277] Attempt to free invalid pointer 0x7f9c1e6f34e8
Aborted (core dumped)
&lt;/denchmark-code&gt;

It seems that the program try to release invalid memory area. Any ideas?
	</description>
	<comments>
		<comment id='1' author='chingyaoc' date='2017-03-18T07:54:24Z'>
		how much RAM you have ?
		</comment>
		<comment id='2' author='chingyaoc' date='2017-03-18T08:07:12Z'>
		I type htop in terminal and it shows 64373mb.
		</comment>
		<comment id='3' author='chingyaoc' date='2017-03-18T14:57:14Z'>
		Could you try without tcmalloc?
TensorFlow now builds with jemalloc together, so maybe there is a problem mixing the two.
		</comment>
		<comment id='4' author='chingyaoc' date='2017-03-18T17:12:07Z'>
		Thanks! Disable tcmalloc solve the problem above.
However I encountered another problem.
&lt;denchmark-code&gt;[0319 01:09:44 @base.py:187] Building predictor graph towerp0 on gpu=0 ...
[0319 01:09:44 @base.py:120] Finalize the graph, create the session ...
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
Traceback (most recent call last):
  File "./DQN.py", line 243, in &lt;module&gt;
    QueueInputTrainer(config).train()
  File "/home/james847286/anaconda2/envs/tf/lib/python2.7/site-packages/tensorpack/train/base.py", line 91, in train
    self.setup()
  File "/home/james847286/anaconda2/envs/tf/lib/python2.7/site-packages/tensorpack/train/base.py", line 123, in setup
    self.sess = self._monitored_sess._tf_sess()  # expose the underlying session also
AttributeError: 'MonitoredSession' object has no attribute '_tf_sess'
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

It seems that we do not define _tf_sess() for self._monitored_sess.
		</comment>
		<comment id='5' author='chingyaoc' date='2017-03-18T18:17:38Z'>
		I was using a private TF API which may be different between TF versions.
I will push a fix soon.
		</comment>
		<comment id='6' author='chingyaoc' date='2017-03-18T23:19:29Z'>
		That private API still exists in latest TF.
But the above fix should solve the issue for earlier versions.
I'll also update the doc to not mention tcmalloc anymore, since jemalloc seems better.
		</comment>
		<comment id='7' author='chingyaoc' date='2017-03-19T06:22:16Z'>
		Thanks, The fixes solve the problem!
		</comment>
		<comment id='8' author='chingyaoc' date='2017-03-20T12:39:40Z'>
		Hi,

Thanks for solving the problem!
May I ask another personal question that what’s the purpose for constructing “tower” since it occurs in several examples?
Does it relate to multi-thread training or something else?

Best,
James
		</comment>
		<comment id='9' author='chingyaoc' date='2017-03-20T15:37:42Z'>
		That's the term TF guys use for data-parallel training: &lt;denchmark-link:https://github.com/tensorflow/models/tree/master/inception#how-to-train-from-scratch&gt;https://github.com/tensorflow/models/tree/master/inception#how-to-train-from-scratch&lt;/denchmark-link&gt;

Here I extend the concept to use in inference as well.
		</comment>
		<comment id='10' author='chingyaoc' date='2017-03-20T16:19:36Z'>
		Thanks for replying.
Btw Tensorpack is the best tensorflow repo I’ve ever seen, great job!
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 On 20 Mar 2017, at 11:37 PM, Yuxin Wu ***@***.***&gt; wrote:

 That's the term TF guys use for data-parallel training: https://github.com/tensorflow/models/tree/master/inception#how-to-train-from-scratch &lt;https://github.com/tensorflow/models/tree/master/inception#how-to-train-from-scratch&gt;
 Here I extend the concept to use in inference as well.

 —
 You are receiving this because you modified the open/close state.
 Reply to this email directly, view it on GitHub &lt;#194 (comment)&gt;, or mute the thread &lt;https://github.com/notifications/unsubscribe-auth/ANoVprhLuidXsFvgMvacjOBqyLswJ_UTks5rnp1JgaJpZM4MhU4i&gt;.



		</comment>
		<comment id='11' author='chingyaoc' date='2017-03-20T21:05:03Z'>
		Thanks!
		</comment>
		<comment id='12' author='chingyaoc' date='2017-03-21T06:27:26Z'>
		This might be the last bug of DQN.
Callback will set learning rate in designate epoch like this.
&lt;denchmark-code&gt;ScheduledHyperParamSetter('learning_rate',
                          [(150, 4e-4), (250, 1e-4), (350, 5e-5)])
&lt;/denchmark-code&gt;

However when it attempt to update the value, the following error occurs
&lt;denchmark-code&gt;[0321 14:18:27 @param.py:144] learning_rate at epoch 151 will change to 0.00040000
W tensorflow/core/kernels/queue_base.cc:294] _0_input_queue: Skipping cancelled enqueue attempt with queue not closed
Traceback (most recent call last):
[0321 14:18:27 @input_data.py:124] EnqueueThread Exited.
  File "./DQN.py", line 250, in &lt;module&gt;
    DQN_Trainer(config).train()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/train/dqn_trainer.py", line 97, in train
    self.main_loop()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/train/dqn_trainer.py", line 171, in main_loop
    self._callbacks.trigger_epoch()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/base.py", line 121, in trigger_epoch
    self._trigger_epoch()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/group.py", line 104, in _trigger_epoch
    cb.trigger_epoch()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/base.py", line 121, in trigger_epoch
    self._trigger_epoch()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/base.py", line 181, in _trigger_epoch
    self.trigger()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/base.py", line 168, in trigger
    self._trigger()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/param.py", line 160, in _trigger
    self._set_param()
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/param.py", line 168, in _set_param
    self.param.set_value(v)
  File "/home/james847286/Work/RL/DeepQNetwork/tensorpack/callbacks/param.py", line 79, in set_value
    self.var.load(v)
AttributeError: 'Variable' object has no attribute 'load'
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='chingyaoc' date='2017-03-21T07:08:40Z'>
		Your tensorflow version seems too old.
		</comment>
	</comments>
</bug>