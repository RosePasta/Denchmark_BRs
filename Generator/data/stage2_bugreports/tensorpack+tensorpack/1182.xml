<bug id='1182' author='dps42' open_date='2019-05-10T19:15:28Z' closed_time='2019-05-10T19:22:42Z'>
	<summary>Keras example crashing on single gpu training</summary>
	<description>
If you're asking about an unexpected problem which you do not know the root cause,
use this template. PLEASE DO NOT DELETE THIS TEMPLATE, FILL IT:
If you already know the root cause to your problem,
feel free to delete everything in this template.
&lt;denchmark-h:h3&gt;1. What you did:&lt;/denchmark-h&gt;

(1) If you're using examples, what's the command you run:
&lt;denchmark-code&gt;  python mnist-keras.py
&lt;/denchmark-code&gt;

(2) If you're using examples, have you made any changes to the examples? Paste git status; git diff here:
Delete line 101: if get_num_gpu() &lt;= 1:, and the else statement.
Sorry git was not used at the time..
(3) If not using examples, tell us what you did:
I just wanted to compare the speedup between single GPU training and multiple GPU training on the keras example. Just deleted the if else statement at line 101 to run the single GPU example.
# single GPU:
launch_train_with_config(cfg, QueueInputTrainer())
It crashed with the error message described in section 3.
But  the multi-GPU code worked fine.
launch_train_with_config(cfg, SyncMultiGPUTrainerParameterServer(2))
It's always better to copy-paste what you did than to describe them.
Please try to provide enough information to let other reproduce your issues.
Without reproducing the issue, we may not be able to investigate it.
&lt;denchmark-h:h3&gt;2. What you observed:&lt;/denchmark-h&gt;

(1) Include the ENTIRE logs here:
�[32m[0510 15:05:05 @logger.py:90]�[0m Argv: mnist-keras.py
�[32m[0510 15:05:05 @fs.py:101]�[0m �[5m�[31mWRN�[0m Env var $TENSORPACK_DATASET not set, using C:\Users\dps42\tensorpack_data for datasets.
�[32m[0510 15:05:05 @interface.py:31]�[0m Automatically applying QueueInput on the DataFlow.
�[32m[0510 15:05:05 @input_source.py:223]�[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
�[32m[0510 15:05:05 @trainers.py:47]�[0m Building graph for a single training tower ...
It's always better to copy-paste what you observed instead of describing them.
It's always better to paste as much as possible, although sometimes a partial log is OK.
Tensorpack typically saves stdout to its training log.
If stderr is relevant, you can run a command with CMD 2&gt;&amp;1 | tee logs.txt
to save both stdout and stderr to one file.
(2) Other observations, if any:
For example, CPU/GPU utilization, output images, tensorboard curves, if relevant to your issue.
&lt;denchmark-h:h3&gt;3. What you expected, if not obvious.&lt;/denchmark-h&gt;

I had the following error message:
(dps42_dev) C:\Users\dps42\Desktop\dps42\tensorpack\examples\keras&gt;python mnist-keras.py
[0510 14:42:45 @logger.py:125] WRN Log directory train_log\mnist-keras exists! Use 'd' to delete it.
[0510 14:42:45 @logger.py:128] WRN If you're resuming from a previous run, you can choose to keep it.
Press any other key to exit.
Select Action: k (keep) / d (delete) / q (quit):d
[0510 14:42:49 @logger.py:90] Argv: mnist-keras.py
[0510 14:42:49 @fs.py:101] WRN Env var $TENSORPACK_DATASET not set, using C:\Users\dps42\tensorpack_data for datasets.
[0510 14:42:49 @interface.py:31] Automatically applying QueueInput on the DataFlow.
[0510 14:42:49 @input_source.py:223] Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...
[0510 14:42:49 @trainers.py:47] Building graph for a single training tower ...
Traceback (most recent call last):
File "mnist-keras.py", line 100, in 
launch_train_with_config(cfg, QueueInputTrainer())
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\interface.py", line 91, in launch_train_with_config
model.build_graph, model.get_optimizer)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\utils\argtools.py", line 176, in wrapper
return func(*args, **kwargs)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\tower.py", line 224, in setup_graph
train_callbacks = self._setup_graph(input, get_cost_fn, get_opt_fn)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\trainers.py", line 71, in _setup_graph
return super(QueueInputTrainer, self)._setup_graph(input, get_cost_fn, get_opt_fn)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\trainers.py", line 49, in _setup_graph
grads = self._make_get_grad_fn(input, get_cost_fn, get_opt_fn)()
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\tower.py", line 280, in get_grad_fn
return compute_grad_from_inputs(*inputs)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\train\tower.py", line 255, in compute_grad_from_inputs
cost = get_cost_fn(*inputs)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorpack\tfutils\tower.py", line 290, in call
output = self._tower_fn(*args)
File "mnist-keras.py", line 52, in build_graph
M = get_keras_model()
File "mnist-keras.py", line 29, in get_keras_model
with tf.name_scope('/'):
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorflow\python\framework\ops.py", line 5775, in enter
return self._name_scope.enter()
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\contextlib.py", line 59, in enter
return next(self.gen)
File "C:\Users\dps42\AppData\Local\Continuum\miniconda3\envs\dps42_dev\lib\site-packages\tensorflow\python\framework\ops.py", line 3851, in name_scope
raise ValueError("'%s' is not a valid scope name" % name)
ValueError: '/' is not a valid scope name
If you expect higher speed, please read
&lt;denchmark-link:http://tensorpack.readthedocs.io/tutorial/performance-tuning.html&gt;http://tensorpack.readthedocs.io/tutorial/performance-tuning.html&lt;/denchmark-link&gt;

before posting.
If you expect certain accuracy, only in one of the two conditions can we help with it:
(1) You're unable to reproduce the accuracy documented in tensorpack examples.
(2) It appears to be a tensorpack bug.
Otherwise, how to train a model to certain accuracy is a machine learning question.
We do not answer machine learning questions and it is your responsibility to
figure out how to make your models more accurate.
&lt;denchmark-h:h3&gt;4. Your environment:&lt;/denchmark-h&gt;


Paste the output of this command: python3 -c 'import tensorpack.tfutils as u; print(u.collect_env_info())'
If this command failed, tell us your version of Python/TF/tensorpack.
You can install Tensorpack master by pip install -U git+https://github.com/ppwwyyxx/tensorpack.git
and see if your issue is already solved.
If you're not using tensorpack under a normal command line shell (e.g.,
using an IDE or jupyter notebook), please retry under a normal command line shell.
Include relevant hardware information, e.g. number of GPUs used for training, amount of RAM.

sys.platform          win32
Python                3.5.2 | packaged by conda-forge | (default, Jan 19 2017, 15:41:23) [MSC v.1900 64 bit (AMD64)]
Tensorpack            v0.9.4-50-g6926d22a-dirty
Numpy                 1.13.3
TensorFlow            1.10.0/b'unknown'
TF Compiler Version   MSVC 190024215
TF CUDA support       True
TF MKL support        False
Nvidia Driver
CUDA
CUDNN
NCCL
CUDA_VISIBLE_DEVICES  None
GPU                   Not found with NVML
Free RAM              121.50/127.67 GB
CPU Count             20
cv2                   4.1.0
msgpack               0.5.6
python-prctl          False
I have 4 NVIDIA RTX 2080 Ti GPUs, but I set a single gpu training mode.
I also have another single GPU desktop (Quadro P5000), but when I ran the same code it produced the same error message.  Both on Windows 10, CUDA 9.0
You may often want to provide extra information related to your issue, but
at the minimum please try to provide the above information accurately to save effort in the investigation.
	</description>
	<comments>
		<comment id='1' author='dps42' date='2019-05-10T19:25:34Z'>
		This was introduced yesterday in &lt;denchmark-link:https://github.com/tensorpack/tensorpack/commit/6926d22a88547899e390ebe709913c38382ff361&gt;6926d22&lt;/denchmark-link&gt;
 and is now fixed.
Please note that &lt;denchmark-link:https://github.com/tensorpack/tensorpack/tree/master/examples/keras#note&gt;Keras support in tensorpack is experimental&lt;/denchmark-link&gt;
 and there is no guarantee that your custom Keras model still works.
If your purpose is to benchmark, also note that using Keras inside tensorpack will not utilize full optimization in tensorpack.
		</comment>
		<comment id='2' author='dps42' date='2019-05-10T19:38:37Z'>
		Thank you for the quick response.
I updated tensorpack, downloaded the example codes, and ran the code again but had another error:
C:\Users\dps42\Desktop\dps42\tensorpack\examples\keras&gt;python mnist-keras.py
Traceback (most recent call last):
File "mnist-keras.py", line 29, in 
@contextmanager
NameError: name 'contextmanager' is not defined
		</comment>
		<comment id='3' author='dps42' date='2019-05-10T19:50:23Z'>
		Sorry. You need from contextlib import contextmanager as well.
		</comment>
		<comment id='4' author='dps42' date='2019-05-10T20:01:01Z'>
		Thanks! The code with single gpu training is now working fine. But I have a concern. I haven't measured it super precisely, but from running the provided mnist example code on my 4 RTX 2080 Ti GPU station, the single gpu code seems to be a lot faster than the multi-gpu code.
Except for the first epoch, the single gpu code runs at around 1.3s per epoch, but the multi gpu code runs at around 3s per epoch.
Do you think using a Horovod trainer with Tensorpack can mitigate this problem?? I think Tensorpack provides a wrapper for Horovod, but I haven't found good documentation directly from Horovod.
		</comment>
		<comment id='5' author='dps42' date='2019-05-10T20:13:29Z'>
		Like I said above, this example does not fully utilise tensorpack trainers to have good performance. To benchmark performance please use a native tensorpack example, or our official benchmark &lt;denchmark-link:https://github.com/tensorpack/benchmarks/tree/master/other-wrappers&gt;https://github.com/tensorpack/benchmarks/tree/master/other-wrappers&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='dps42' date='2019-05-10T20:17:11Z'>
		Your number does look strange, I'll take a look at that later. The keras ResNet example does have a good speedup last time I run.
		</comment>
		<comment id='7' author='dps42' date='2019-05-10T20:33:05Z'>
		The number from my runs is a bit better: 1.3s for 1 GPU and 1.9s for 2 GPU, which means a 70% scaling efficiency (2GPU will train 2x more batch size).
Also note that using this model (no matter it is written in tensorpack or Keras) for benchmarking is not reasonable at all since it's way too small and the time to compute the training is totally not worth the time to communicate it.
		</comment>
		<comment id='8' author='dps42' date='2019-05-10T20:46:56Z'>
		Sorry. I'm completely new in this multi-gpu training area. I'm trying to train a custom Keras object detection model on a very large dataset. But the training is taking too much time on a single gpu, so I'm trying to see if I can speedup the training with multiple gpus and tensorpack.
But from the MNIST example, it takes longer time overall with the multiple GPU training.
So since you mentioned that 2GPU will train 2x more batch size, given that I have 4 GPUs, can I just reduce the batch size / 4 per GPU in this case to get the comparable accuracy and reduce the overall training time??
I'm quite confused since I'm not sure where but from FasterRCNN example only batch size of 1 per GPU is available for tensorpack.
		</comment>
		<comment id='9' author='dps42' date='2019-05-10T20:50:25Z'>
		
So since you mentioned that 2GPU will train 2x more batch size, given that I have 4 GPUs, can I just reduce the batch size / 4 per GPU in this case to get the comparable accuracy and reduce the overall training time??

That's correct for large enough models, and depends on how you define your batch size in code. Not for this mnist example.

I'm not sure where but from FasterRCNN example only batch size of 1 per GPU is available for tensorpack.

The FasterRCNN example in tensorpack only supports batch size 1. That does not mean Tensorpack only supports batch size 1.
		</comment>
		<comment id='10' author='dps42' date='2019-05-10T20:56:17Z'>
		Thank you so much for the clarification
		</comment>
	</comments>
</bug>