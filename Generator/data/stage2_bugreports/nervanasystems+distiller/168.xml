<bug id='168' author='zeyu-liu' open_date='2019-02-21T16:45:46Z' closed_time='2020-04-16T11:53:39Z'>
	<summary>Can not get the correct tensor input/output shape when use DynamicType</summary>
	<description>
I used slice / reshape ops in my networks and as it shown in &lt;denchmark-link:https://github.com/pytorch/pytorch/blob/94a95a0c7f3c38530a9cbc79932ea89ce092d1c2/torch/onnx/symbolic.py#L41&gt;https://github.com/pytorch/pytorch/blob/94a95a0c7f3c38530a9cbc79932ea89ce092d1c2/torch/onnx/symbolic.py#L41&lt;/denchmark-link&gt;
 we can not get the actual properties of this tensor. This will be a problem to calculate MACs. As &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/apputils/model_summaries.py#L190&gt;https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/apputils/model_summaries.py#L190&lt;/denchmark-link&gt;
 treats these tensor as empty tensor (shape is (0, )), it may cause exception when calculating the MACs and may mislead the pruning procedure.
	</description>
	<comments>
		<comment id='1' author='zeyu-liu' date='2019-02-21T16:50:26Z'>
		Some Exceptions occurred when applying pruning on this model:
&lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/apputils/model_summaries.py#L212&gt;https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/apputils/model_summaries.py#L212&lt;/denchmark-link&gt;

and
&lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/examples/automated_deep_compression/ADC.py#L807&gt;https://github.com/NervanaSystems/distiller/blob/ee1d160f75bd171d8f9b8afd17a65bcb0327a623/examples/automated_deep_compression/ADC.py#L807&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='zeyu-liu' date='2019-02-21T20:50:18Z'>
		Hi &lt;denchmark-link:https://github.com/zeyu-liu&gt;@zeyu-liu&lt;/denchmark-link&gt;
,
Can you provide a minimal example of a model which has these slice/reshape operations which cause the problem?  I would like to recreate it and see when the tensor shape == 0.
Thanks
Neta
		</comment>
		<comment id='3' author='zeyu-liu' date='2019-02-22T02:57:08Z'>
		
Hi @zeyu-liu,
Can you provide a minimal example of a model which has these slice/reshape operations which cause the problem? I would like to recreate it and see when the tensor shape == 0.
Thanks
Neta

&lt;denchmark-link:https://github.com/nzmora&gt;@nzmora&lt;/denchmark-link&gt;

I used an implementation of ShuffleNet from &lt;denchmark-link:https://github.com/ericsun99/Shufflenet-v2-Pytorch&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='zeyu-liu' date='2019-02-28T11:37:21Z'>
		
Hi @zeyu-liu,
Can you provide a minimal example of a model which has these slice/reshape operations which cause the problem? I would like to recreate it and see when the tensor shape == 0.
Thanks
Neta

Hi &lt;denchmark-link:https://github.com/nzmora&gt;@nzmora&lt;/denchmark-link&gt;
 ,
Any updates?
		</comment>
		<comment id='5' author='zeyu-liu' date='2019-03-02T22:49:58Z'>
		Hi &lt;denchmark-link:https://github.com/zeyu-liu&gt;@zeyu-liu&lt;/denchmark-link&gt;
,
Sorry for the delay and thanks for the details - I've recreated the issue.  In Distiller there are two ways to compute the MACs
of convolutional layers:

By traversing an ONNX representation of the model and using the sizes of Convolution operation inputs and outputs, which are extracted from the ONNX IR;
By performing a forward pass on the PyTorch model and extracting the input/output sizes from the forward callback (code)

As you pointed out (1) is broken when the model uses certain slice/reshape operations that translate to a tensor with an unknown size.
Therefore, (1) should be removed and (2) should be integrated into &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/d556ac51d0c8a349097c5a7ed1f5c5eb32681405/distiller/summary_graph.py#L52&gt;SummaryGraph&lt;/denchmark-link&gt;
.
I'll add this to the project issues, but I don't know when we will get to fixing this.
Cheers
Neta
		</comment>
	</comments>
</bug>