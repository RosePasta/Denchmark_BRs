<bug id='818' author='myungjoo' open_date='2018-11-13T01:10:26Z' closed_time='2018-11-28T07:35:13Z'>
	<summary>Caps negotiation power of tensor_converter is limited.</summary>
	<description>
In the following pipeline:
&lt;denchmark-code&gt;v4l2src (cam_src) --&gt; videoscale --&gt; videoconvert --&gt; tensor_converter --&gt; tensor_filter --&gt; ...
&lt;/denchmark-code&gt;

where tensor_filter is using tensorflow-lite model using static input dimension, 3:224:224:1 (image recognition), videoscale / videoconvert MUST automatically convert any video/x-raw stream into RGB 224x224 stream.
However, without capsfilter specifying 224x224 before tensor_converter, it does not work. (tested in pipeviz)
tensor_converter and tensor_filter MUST be able to enforce such.
&lt;denchmark-code&gt;v4l2src --&gt; videoconvert --&gt; videoscale --&gt; tee --&gt; queue --&gt; t_c --&gt; t_f
&lt;/denchmark-code&gt;

as well.
Therefore, I presume that the cap-nego-power is limited to downstream (media-&gt;tensor) and upstream cap-nego is not working as expected (srcpad (tensor) --&gt; sink pad (media) cap negotiation is not working as expected)
	</description>
	<comments>
		<comment id='1' author='myungjoo' date='2018-11-13T01:10:28Z'>
		 : Thank you for posting issue &lt;denchmark-link:https://github.com/nnstreamer/nnstreamer/issues/818&gt;#818&lt;/denchmark-link&gt;
. The person in charge will reply soon.
		</comment>
		<comment id='2' author='myungjoo' date='2018-11-13T02:04:29Z'>
		I'll add a test case where such negotiation power is required.
		</comment>
		<comment id='3' author='myungjoo' date='2018-11-21T04:50:34Z'>
		launch pipeline
&lt;denchmark-code&gt;GST_DEBUG=tensor_converter:6 gst-launch-1.0 v4l2src ! videoscale ! tensor_converter silent=false ! tensor_filter framework=tensorflow-lite model=./tflite_model/mobilenet_v1_1.0_224_quant.tflite ! tensor_sink
&lt;/denchmark-code&gt;

In tensor-converter gst_tensor_converter_query_caps(), if pad is sinkpad,
&lt;denchmark-code&gt;/* get possible caps from downstream element */
peer_caps = gst_pad_peer_query_caps (self-&gt;srcpad, NULL);

if (peer_caps) {
  /* convert peer caps to possible media caps */
  structure = gst_caps_get_structure (peer_caps, 0);
  gst_tensor_config_from_structure (&amp;config, structure);

  media_caps = gst_caps_new_empty ();

  /* video caps */
  tmp = gst_caps_from_string (GST_TENSOR_VIDEO_CAPS_STR);
  gst_caps_set_simple (tmp, "format", G_TYPE_STRING, format, NULL);
  gst_caps_set_simple (tmp, "width", G_TYPE_INT, width, NULL);
  gst_caps_set_simple (tmp, "height", G_TYPE_INT, height, NULL);
  gst_caps_append (media_caps, tmp);

  /* audio caps */
  tmp = gst_caps_from_string (GST_TENSOR_AUDIO_CAPS_STR);
  gst_caps_set_simple (tmp, "format", G_TYPE_STRING, format, NULL);
  gst_caps_append (media_caps, tmp);

  tmp = gst_caps_intersect_full (caps, media_caps, GST_CAPS_INTERSECT_FIRST);
  gst_caps_unref (caps);
  caps = tmp;

  gst_caps_unref (peer_caps);
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='myungjoo' date='2018-11-28T07:35:13Z'>
		PR merged, close this issue.
		</comment>
	</comments>
</bug>