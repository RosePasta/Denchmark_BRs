<bug id='1966' author='myungjoo' open_date='2019-12-18T05:43:31Z' closed_time='2020-06-15T08:04:10Z'>
	<summary>Test Request: nnstreamer-edgetpu @ Tizen board.</summary>
	<description>
Already tested:

nnstreamer-edgetpu / Ubuntu 18.04 x64 PC + Real USB Edge-TPU
nnstreamer-edgetpu / Tizen GBS on x64 PC + dummy Edge-TPU runtime-library (no TPU H/W)

To be tested:

nnstreamer-edgetpu / Tizen RPI3/RPI4/Odroid/or-what-so-ever + Tizen 6.0 + Real USB Edge-TPU
Please post the test results.

	</description>
	<comments>
		<comment id='1' author='myungjoo' date='2019-12-18T05:43:33Z'>
		 : Thank you for posting issue &lt;denchmark-link:https://github.com/nnstreamer/nnstreamer/issues/1966&gt;#1966&lt;/denchmark-link&gt;
. The person in charge will reply soon.
		</comment>
		<comment id='2' author='myungjoo' date='2020-05-11T09:39:49Z'>
		Now, we have a client who wants to use this with Tizen 6.0 M2.
		</comment>
		<comment id='3' author='myungjoo' date='2020-06-04T05:36:03Z'>
		&lt;denchmark-link:https://github.com/wooksong&gt;@wooksong&lt;/denchmark-link&gt;
 A few days ago, you've mentioned that you found a bug in this feature and are working on it. Please share related info here if you want.
		</comment>
		<comment id='4' author='myungjoo' date='2020-06-05T02:31:49Z'>
		&lt;denchmark-link:https://github.com/myungjoo&gt;@myungjoo&lt;/denchmark-link&gt;
 I will create another issue that contains the current status and action items to resolve this issue. How about that?
		</comment>
		<comment id='5' author='myungjoo' date='2020-06-05T04:24:04Z'>
		
@myungjoo I will create another issue that contains the current status and action items to resolve this issue. How about that?

It's ok to proceed. Close this and create another, then.
		</comment>
		<comment id='6' author='myungjoo' date='2020-06-05T08:10:37Z'>
		

@myungjoo I will create another issue that contains the current status and action items to resolve this issue. How about that?

It's ok to proceed. Close this and create another, then.

Before addressing this as another issue, I've tested several basic pipelines on Tizen-aarch64 board.
&lt;denchmark-h:h4&gt;Environment&lt;/denchmark-h&gt;


Target: RPI3
Kernel: 4.19.49-arm64-rpi3-v8 (tizen-unified_20200528.2_iot-boot-arm64-rpi3.tar.gz)
Platform: rootfs and system-data are extracted from t(izen-6.0-da-unified_20200528.142056_DA-M64-HEADLESS-WW-AD-DEBUG.tar.gz)
edgeTPU runtime:

libedgetpu-dev-12.1-1.1.aarch64.rpm for Tizen-aarch64
For compiler for x66_64, 12.1-1 (14237f65ba07b7b1d8287e9f60dd20c88562871a)



&lt;denchmark-h:h4&gt;1. Plain MobiNet V1 (mobilenet_v1_1.0_224_quant.tflite)&lt;/denchmark-h&gt;

gst-launch-1.0 filesrc location=/orange.png ! pngdec ! videoscale ! \
imagefreeze ! videoconvert ! video/x-raw,format=RGB,framerate=0/1 ! \
tensor_converter ! \
tensor_filter framework=edgetpu model=mobilenet_v1_1.0_224_quant.tflite ! \ 
filesink location=tensorfilter_edgetpu.out.log

This pipeline worked fine with the edgeTPU. (without the device, it is failed to launch this pipeline.)

&lt;denchmark-h:h4&gt;2. Compiled MobiNet V1 (mobilenet_v1_1.0_224_quant_edgetpu.tflite)&lt;/denchmark-h&gt;


Failed to compile mobilenet_v1_1.0_224_quant.tflite on x86_64

$ ./edgetpu_compiler mobilenet_v1_1.0_224_quant.tflite 
Edge TPU Compiler version 2.0.267685300

Internal compiler error. Aborting! 
&lt;denchmark-h:h4&gt;3. Plain MobiNet V2 (mobilenet_v2_1.0_224_quant.tflite)&lt;/denchmark-h&gt;

gst-launch-1.0 filesrc location=/orange.png ! pngdec ! videoscale ! \
imagefreeze ! videoconvert ! video/x-raw,format=RGB,framerate=0/1 ! \
tensor_converter ! \
tensor_filter framework=edgetpu model=mobilenet_v2_1.0_224_quant.tflite ! \ 
filesink location=tensorfilter_edgetpu.out.log

This pipeline also worked fine with the edgeTPU. (without the device, it is failed to launch this pipeline.)

&lt;denchmark-h:h4&gt;4. Compiled MobiNet V2 (mobilenet_v2_1.0_224_quant_edgetpu.tflite)&lt;/denchmark-h&gt;


Failed to launch the pipeline

# ./runTest_edgetpu_mobinetV2_compiled.sh 
Null custom op data.
Node number 0 (edgetpu-custom-op) failed to prepare.

Failed to allocate tensors.
Setting pipeline to PAUSED ...
Pipeline is PREROLLING ...
Invoke called on model that is not ready.
Failed to invoke tensorflow-lite + edge-tpu.
ERROR: from element /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0: Internal data stream error.
Additional debug info:
gstimagefreeze.c(924): gst_image_freeze_src_loop (): /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0:
streaming stopped, reason error (-5)
ERROR: pipeline doesn't want to preroll.
Setting pipeline to NULL ...

(gst-launch-1.0:1700): GStreamer-CRITICAL **: 11:04:59.338: gst_mini_object_unref: assertion '(g_atomic_int_get (&amp;mini_object-&gt;lockstate) &amp; LOCK_MASK) &lt; 4' failed
Freeing pipeline ...
&lt;denchmark-h:h4&gt;5. Running Compiled MobiNet V2 (mobilenet_v2_1.0_224_quant_edgetpu.tflite) using hand-written c++ application&lt;/denchmark-h&gt;


Worked.

root@localhost:/media/USBDriveA# ./a.out 
model file = resource/mobilenet_v2_1.0_224_quant_edgetpu.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Replacing 1 node(s) with delegate (EdgeTpuDelegateForCustomOp) node, yielding 1 partitions.
Input num = 1
    tensor[0]-&gt;dims-&gt;size[0]: 1
    tensor[0]-&gt;dims-&gt;size[1]: 224
    tensor[0]-&gt;dims-&gt;size[2]: 224
    tensor[0]-&gt;dims-&gt;size[3]: 3
    tensor[0]-&gt;type: quantized
    tensor[0]-&gt;params.outputZeroPoint, scale: 128, 0.007812
Output num = 1
    tensor[0]-&gt;dims-&gt;size[0]: 1
    tensor[0]-&gt;dims-&gt;size[1]: 1001
    tensor[0]-&gt;type: quantized
    tensor[0]-&gt;params.outputZeroPoint, scale: 0, 0.003906
  89  macaw (0.996)

		</comment>
		<comment id='7' author='myungjoo' date='2020-06-08T13:06:38Z'>
		Nicely done. As you've mentioned earlier today, we will need a edgetpu-compiled-binary-compatible filter; the current version uses delegation.
However, the priority depends on whether the client really need it right now or not.
		</comment>
		<comment id='8' author='myungjoo' date='2020-06-09T09:12:26Z'>
		&lt;denchmark-link:https://github.com/myungjoo&gt;@myungjoo&lt;/denchmark-link&gt;
 Here is the update on the compiled model with nnstreamer-edgeTPU (Note that mobilenet_v2_1.0_224_quant_edgetpu.tflite is used for this verification).

The pipeline used for testing is as follows:

&lt;denchmark-code&gt;gst-launch-1.0 filesrc location=/orange.png ! pngdec ! videoscale ! \
imagefreeze ! videoconvert ! video/x-raw,format=RGB,framerate=0/1 ! \
tensor_converter ! \
tensor_filter framework=edgetpu model=mobilenet_v2_1.0_224_quant_edgetpu.tflite ! \ 
filesink location=tensorfilter_edgetpu.out.log
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Tizen-aarch64&lt;/denchmark-h&gt;


With TFLite 1.15.2,

Worked fine.


With TFLite 1.13.1,

Failed to allocate tensors and invoke the framework
IMO, in this case, TFLite 1.13.1 does not support the model.
Possible solution: Release nnstreamer-edgetpu linked with tflite 1.15.2 via
http://10.113.136.201/project/show/devel:Tizen:6.0:AI



      # ./run.sh                                      
      Null custom op data.
      Node number 0 (edgetpu-custom-op) failed to prepare.

      Failed to allocate tensors.
      Setting pipeline to PAUSED ...
      Pipeline is PREROLLING ...
      Invoke called on model that is not ready.
      Failed to invoke tensorflow-lite + edge-tpu.
      ERROR: from element /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0: Internal data stream error.
      Additional debug info:
      gstimagefreeze.c(924): gst_image_freeze_src_loop (): /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0:
      streaming stopped, reason error (-5)
      ERROR: pipeline doesn't want to preroll.
      Setting pipeline to NULL ...

      (gst-launch-1.0:3022): GStreamer-CRITICAL **: 09:59:40.526: gst_mini_object_unref: assertion '(g_atomic_int_get (&amp;mini_object-&gt;lockstate) &amp; LOCK_MASK) &lt; 4' failed
      Freeing pipeline ...
&lt;denchmark-h:h3&gt;Ubuntu-x86_64&lt;/denchmark-h&gt;


With TFLite 1.15.2,

Case 1-F: ninja -C build install (since we do not release nnstreamer-edgetpu for ubuntu yet)



      INFO: Initialized TensorFlow Lite runtime.
      Setting pipeline to PAUSED ...
      Pipeline is PREROLLING ...
      ERROR: Node number 0 (edgetpu-custom-op) failed to invoke.

      Failed to invoke tensorflow-lite + edge-tpu.

       ** (gst-launch-1.0:26980): CRITICAL **: 17:50:27.295: Tensor-filter invoke failed (error code = -22).

      ERROR: from element /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0: Internal data stream error.
      Additional debug info:
      gstimagefreeze.c(851): gst_image_freeze_src_loop (): /GstPipeline:pipeline0/GstImageFreeze:imagefreeze0:
      streaming stopped, reason error (-5)
      ERROR: pipeline doesn't want to preroll.
      Setting pipeline to NULL ...
      Freeing pipeline ...
&lt;denchmark-code&gt;-  Case 1: After remove rpath of /usr/lib/nnstreamer/filters/
   libnnstreamer_filter_edgetpu.so, worked fine.
&lt;/denchmark-code&gt;

      $ sudo chrpath /usr/lib/nnstreamer/filters/libnnstreamer_filter_edgetpu.so 
      /usr/lib/nnstreamer/filters/libnnstreamer_filter_edgetpu.so: RUNPATH=$ORIGIN/../../../gst/nnstreamer:/home/wook/Work/NNS/nnstreamer/build/tests/nnstreamer_filter_edgetpu
      $ sudo chrpath /usr/lib/nnstreamer/filters/libnnstreamer_filter_edgetpu.so -d

With TFLite 1.13.1,

Regardless of the rpath, failed to run the pipeline.



     Null custom op data.
     Node number 0 (edgetpu-custom-op) failed to prepare.
     ...omission...
     Invoke called on model that is not ready.
     Failed to invoke tensorflow-lite + edge-tpu.
     ...omission...
		</comment>
		<comment id='9' author='myungjoo' date='2020-06-10T04:11:53Z'>
		Would it be possible to let users know that they need to upgrade tf-lite in case it's failed due to 1.13 vs 1.15+ issue?
If it is entirely impossible, with unknown errors at the invocation of tf-lite, (or edge-tpu delegation), we need to emit additional info that the user may need to retry with different tf-lite versions.
		</comment>
	</comments>
</bug>