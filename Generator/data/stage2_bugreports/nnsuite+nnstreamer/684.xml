<bug id='684' author='again4you' open_date='2018-10-23T01:27:17Z' closed_time='2018-11-14T06:27:22Z'>
	<summary>[Tensorflow] `armhf` Build failure on launchpad.net</summary>
	<description>
After applying some hotfixes to sandbox/sangjung/launchpad_bugfix branch in platform/upstream/tensorflow, Current status is as below.
&lt;denchmark-h:h2&gt;Completed&lt;/denchmark-h&gt;


PPA: https://launchpad.net/~nnstreamer/+archive/ubuntu/ppa/+packages
amd64 Xenial (16.04)
amd64 Bionic (18.04)
aarch64 Xenial (16.04)
aarch64 Bionic (18.04)

&lt;denchmark-h:h2&gt;Failed&lt;/denchmark-h&gt;


armhf Xenial (16.04): buildlog
armhf Bionic (18.04): buildlog

&lt;denchmark-h:h2&gt;Compile option for armhf&lt;/denchmark-h&gt;


CFLSGS: -Wno-sign-compare -Wno-unused-but-set-variable -Wno-format-security -Wno-format -fPIC --std=c++11 -DARM_NON_MOBILE -mfpu=neon-vfpv4 -std=gnu11 --ftree-vectorize -fomit-frame-pointer
CPPFLAGS: -Wno-sign-compare -Wno-unused-but-set-variable -Wno-format-security -Wno-format -fPIC --std=c++11 -DARM_NON_MOBILE -mfpu=neon-vfpv4 -std=gnu11 -ftree-vectorize -fomit-frame-pointer

&lt;denchmark-h:h2&gt;Detailed failure reasons&lt;/denchmark-h&gt;


Too long link time

[ 99%] Building CXX object CMakeFiles/pywrap_tensorflow_internal.dir/pywrap_tensorflow_internal.cc.o
c++: warning: /&lt;&lt;PKGBUILDDIR&gt;&gt;/tensorflow/tf_version_script.lds: linker input file unused because linking not done
[ 99%] Linking CXX shared library libpywrap_tensorflow_internal.so
make[3]: *** Deleting file 'libpywrap_tensorflow_internal.so'
debian/rules:46: recipe for target 'build' failed
make: *** [build] Terminated
E: Caught signal ‘Terminated’: terminating immediately
CMakeFiles/pywrap_tensorflow_internal.dir/build.make:2833: recipe for target 'libpywrap_tensorflow_internal.so' failed
make[3]: *** [libpywrap_tensorflow_internal.so] Terminated
CMakeFiles/Makefile2:127: recipe for target 'CMakeFiles/pywrap_tensorflow_internal.dir/all' failed
make[2]: *** [CMakeFiles/pywrap_tensorflow_internal.dir/all] Terminated
Makefile:129: recipe for target 'all' failed
make[1]: *** [all] Terminated
Build killed with signal TERM after 150 minutes of inactivity

undefined reference to void tensorflow::ConcatCPU

Related issue: Add ARM_NON_MOBILE or RASPBERRY_PI in CPP/CFLAGS (Link)



[ 99%] Linking CXX executable summarize_graph
CMakeFiles/tf_core_kernels.dir/&lt;&lt;PKGBUILDDIR&gt;&gt;/tensorflow/core/kernels/list_kernels.cc.o: In function `tensorflow::TensorListStack&lt;Eigen::ThreadPoolDevice, tensorflow::bfloat16&gt;::Compute(tensorflow::OpKernelContext*)':
list_kernels.cc:(.text._ZN10tensorflow15TensorListStackIN5Eigen16ThreadPoolDeviceENS_8bfloat16EE7ComputeEPNS_15OpKernelContextE[_ZN10tensorflow15TensorListStackIN5Eigen16ThreadPoolDeviceENS_8bfloat16EE7ComputeEPNS_15OpKernelContextE]+0x500): undefined reference to `void tensorflow::ConcatCPU&lt;tensorflow::bfloat16&gt;(tensorflow::DeviceBase*, std::vector&lt;std::unique_ptr&lt;tensorflow::TTypes&lt;tensorflow::bfloat16, 2, int&gt;::ConstMatrix, std::default_delete&lt;tensorflow::TTypes&lt;tensorflow::bfloat16, 2, int&gt;::ConstMatrix&gt; &gt;, std::allocator&lt;std::unique_ptr&lt;tensorflow::TTypes&lt;tensorflow::bfloat16, 2, int&gt;::ConstMatrix, std::default_delete&lt;tensorflow::TTypes&lt;tensorflow::bfloat16, 2, int&gt;::ConstMatrix&gt; &gt; &gt; &gt; const&amp;, tensorflow::TTypes&lt;tensorflow::bfloat16, 2, int&gt;::Matrix*)'
collect2: error: ld returned 1 exit status
	</description>
	<comments>
		<comment id='1' author='again4you' date='2018-10-23T01:27:19Z'>
		 : Thank you for posting issue &lt;denchmark-link:https://github.com/nnstreamer/nnstreamer/issues/684&gt;#684&lt;/denchmark-link&gt;
. The person in charge will reply soon.
		</comment>
		<comment id='2' author='again4you' date='2018-10-23T02:02:16Z'>
		
Related issue: Add ARM_NON_MOBILE or RASPBERRY_PI in CPP/CFLAGS (Link)

It's reasonable to me at least. In my case, I have used --copt=-DRASPBERRY_PI  option in order to build  the Tensorflow source code directly using bazel on my own Raspberry Pi3 board at home. At that time, the build time  (From my experience, the estimated time was +16 hours.) is problem to me.

https://github.com/samjabrahams/tensorflow-on-raspberry-pi
https://www.tensorflow.org/install/  (Google has supported Ubuntu and Rasbian officially Since 4 Aug 2018.)

		</comment>
		<comment id='3' author='again4you' date='2018-10-23T02:48:05Z'>
		

Too long link time
make[1]: *** [all] Terminated
Build killed with signal TERM after 150 minutes of inactivity


&lt;denchmark-link:https://github.com/again4you&gt;@again4you&lt;/denchmark-link&gt;
 , I suggest that you try to use  a   option to avoid a memory issue while linking object files. From my experience, if the launchpad server requires a few memory space, this option will be helpful to fix this issue.

--no-keep-memory (https://sourceware.org/binutils/docs/ld/Options.html)
ld normally optimizes for speed over memory usage by caching the symbol tables of input files in memory. This option tells ld to instead optimize for memory usage, by rereading the symbol tables as necessary. This may be required if ld runs out of memory space while linking a large executable.

		</comment>
		<comment id='4' author='again4you' date='2018-11-14T06:27:22Z'>
		Let's not invest too much time on this. As talked a few minutes ago,
aarch64/x86_64: tf-lite &amp; tf
armv7l/x86_32: tf-lite only (no tf build)
		</comment>
		<comment id='5' author='again4you' date='2018-11-19T07:49:27Z'>
		build still failed for "undefined reference to void tensorflow::ConcatCPU".
Why it is closed? or what is the solution? The new tf cannot be built on armv7l? only tf-lite can be built from source?
Then how does "TensorFlow 1.9 Officially Supports the Raspberry Pi" work?
		</comment>
		<comment id='6' author='again4you' date='2018-11-19T08:03:36Z'>
		
build still failed for "undefined reference to void tensorflow::ConcatCPU".
Why it is closed? or what is the solution?

@flyhorseli In our PPA and OBS, we are abandoning tensorflow build for armv7 and x86_32. We will disable tensorflow-filter in nnstreamer for armv7 and x86_32 as well. However, we will keep support tensorflow-lite for these 32bit systems.
		</comment>
	</comments>
</bug>