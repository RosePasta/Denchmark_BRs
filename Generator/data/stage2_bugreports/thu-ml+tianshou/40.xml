<bug id='40' author='nicoguertler' open_date='2020-04-28T15:00:34Z' closed_time='2020-06-13T09:06:27Z'>
	<summary>Missing sum over log_prob in SAC</summary>
	<description>

 I have marked all applicable categories:

 exception-raising bug
 RL algorithm bug
 documentation request (i.e. "X is missing from the documentation.")
 new feature request


 I have visited the [source website], and in particular read the [known issues]
  I have searched through the [issue categories] for duplicates
 I have mentioned version numbers, operating system and environment, where applicable:
import tianshou, torch, sys
print(tianshou.__version__, torch.__version__, sys.version, sys.platform)


yields
&lt;denchmark-code&gt;0.2.2 1.5.0 3.7.5 (default, Nov 20 2019, 09:21:52) 
[GCC 9.2.1 20191008] linux
&lt;/denchmark-code&gt;

When running halfcheetahBullet_v0_sac.py I get the pytorch warning:
&lt;denchmark-code&gt;tianshou/tianshou/policy/modelfree/sac.py:111: UserWarning: Using a target size (torch.Size([128, 6])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
&lt;/denchmark-code&gt;

This is caused by target_q having the wrong shape which in turn stems from log_prob. In order to fix this, log_prob should be summed over dimension 1 in the forward method:
log_prob = dist.log_prob(x) - torch.log(
            self._action_scale * (1 - y.pow(2)) + self.__eps)
log_prob = torch.unsqueeze(torch.sum(log_prob, 1), 1)
This should be correct because dist.log_prob(x) gives log_prob for a univariate Gaussian for each action dimension. As the covariance matrix is diagonal, the probability density factorizes and the log of the multivariate Gaussian is the sum of the individual log_probs.
Code as it is now:



tianshou/tianshou/policy/modelfree/sac.py


        Lines 80 to 92
      in
      959955f






 def forward(self, batch, state=None, input='obs', **kwargs): 



 obs = getattr(batch, input) 



 logits, h = self.actor(obs, state=state, info=batch.info) 



 assert isinstance(logits, tuple) 



 dist = torch.distributions.Normal(*logits) 



 x = dist.rsample() 



 y = torch.tanh(x) 



 act = y * self._action_scale + self._action_bias 



 log_prob = dist.log_prob(x) - torch.log( 



 self._action_scale * (1 - y.pow(2)) + self.__eps) 



 act = act.clamp(self._range[0], self._range[1]) 



 return Batch( 



 logits=logits, act=act, state=h, dist=dist, log_prob=log_prob) 





Let me know if you agree and if I should make a pull request.
By the way, I really like the modularity of Tianshou! Thank you for your work.
	</description>
	<comments>
		<comment id='1' author='nicoguertler' date='2020-04-28T15:12:59Z'>
		Yes, PR is quite welcome!!!
		</comment>
		<comment id='2' author='nicoguertler' date='2020-04-28T15:53:59Z'>
		Thank you for your quick reaction!
		</comment>
		<comment id='3' author='nicoguertler' date='2020-06-10T11:21:55Z'>
		Why this PR haven't been merged to the master branch?
		</comment>
		<comment id='4' author='nicoguertler' date='2020-06-10T11:34:32Z'>
		
Why this PR haven't been merged to the master branch?

This is merged a month ago. I don't know what you mean.
&lt;denchmark-link:https://user-images.githubusercontent.com/8189182/84263015-4bc31c00-ab51-11ea-9354-3b3ac50fdf50.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='nicoguertler' date='2020-06-13T08:56:54Z'>
		

Why this PR haven't been merged to the master branch?

This is merged a month ago. I don't know what you mean.


No, &lt;denchmark-link:https://github.com/thu-ml/tianshou/pull/49&gt;#49&lt;/denchmark-link&gt;
 added a new bug. Now it misses sum over log_prob in




tianshou/tianshou/policy/modelfree/sac.py


        Lines 103 to 104
      in
      3774258






 log_prob = dist.log_prob(x) - torch.log( 



 self._action_scale * (1 - y.pow(2)) + self.__eps) 






which should be
        log_prob = dist.log_prob(x) - torch.log( self._action_scale * (1 - y.pow(2)) + self.__eps).sum(-1, keepdim=True)
See that, dist.log_prob(x) has already summed over log_prob in DiagGaussian, so only the latter part misses summing.
		</comment>
		<comment id='6' author='nicoguertler' date='2020-06-13T09:02:07Z'>
		&lt;denchmark-link:https://github.com/imoneoi&gt;@imoneoi&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='nicoguertler' date='2020-06-13T09:07:21Z'>
		&lt;denchmark-link:https://github.com/danagi&gt;@danagi&lt;/denchmark-link&gt;
 fixed and many thanks for pointing out!
		</comment>
	</comments>
</bug>