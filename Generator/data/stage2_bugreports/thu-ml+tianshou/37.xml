<bug id='37' author='Trinkle23897' open_date='2020-04-23T14:39:44Z' closed_time='2020-04-26T03:05:00Z'>
	<summary>compatible with torch 1.5.0</summary>
	<description>
Fail in SACPolicy with torch==1.5.0
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "test/continuous/test_sac_with_il.py", line 145, in &lt;module&gt;
    test_sac_with_il()
  File "test/continuous/test_sac_with_il.py", line 106, in test_sac_with_il
    args.batch_size, stop_fn=stop_fn, save_fn=save_fn, writer=writer)
  File "/home/trinkle/github/tianshou-new/tianshou/trainer/offpolicy.py", line 87, in offpolicy_trainer
    losses = policy.learn(train_collector.sample(batch_size))
  File "/home/trinkle/github/tianshou-new/tianshou/policy/modelfree/sac.py", line 131, in learn
    actor_loss.backward()
  File "/home/trinkle/.local/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/trinkle/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [128, 1]], which is output 0 of TBackward, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
&lt;/denchmark-code&gt;

	</description>
	<comments>
	</comments>
</bug>