<bug id='23' author='ygk09' open_date='2018-12-25T09:57:35Z' closed_time='2020-05-18T00:04:32Z'>
	<summary>val_loss is too high while training loss is small in intent extraction</summary>
	<description>
&lt;denchmark-h:h4&gt;Target objective:&lt;/denchmark-h&gt;

When I am using the file [train_mlt_model.py] for intent extraction, the val_loss is very high wheras the training loss is relatively small. However, the conll eval results are all very good.
&lt;denchmark-h:h4&gt;Steps to objective:&lt;/denchmark-h&gt;


Download the Dataset [nlu-benchmark] and run the file [train_mlt_model.py] with command:
python train_mlt_model.py --dataset_path nlu-benchmark/2017-06-custom-intent-engines -b 100 -e 5
After 5 epochs, the console shows:
13784/13784 [==============================] - 11s 817us/step - loss: 3.1504 - intent_classifier_output_loss: 0.0971 - intent_slot_crf_loss: 3.0533 - intent_classifier_output_categorical_accuracy: 0.9710 - intent_slot_crf_accuracy: 0.9671 - val_loss: 95.6078 - val_intent_classifier_output_loss: 0.0791 - val_intent_slot_crf_loss: 95.5287 - val_intent_classifier_output_categorical_accuracy: 0.9771 - val_intent_slot_crf_accuracy: 0.9740
Here, the val_loss is 95.6 whears the training loss is only 3.15.

&lt;denchmark-h:h4&gt;Pull-Request related:&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='ygk09' date='2018-12-26T12:21:43Z'>
		Hi &lt;denchmark-link:https://github.com/ygk09&gt;@ygk09&lt;/denchmark-link&gt;
, we'll look into it. Currently our example and other models are converging and showing good results, it is an issue of the printed loss value.
Thanks
		</comment>
		<comment id='2' author='ygk09' date='2020-05-18T00:04:31Z'>
		Issue marked as stale, closing.
		</comment>
	</comments>
</bug>