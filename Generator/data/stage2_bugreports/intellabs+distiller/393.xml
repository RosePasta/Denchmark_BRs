<bug id='393' author='barrh' open_date='2019-09-24T13:29:20Z' closed_time='2019-12-02T11:08:41Z'>
	<summary>Activation collection fails with resnext50</summary>
	<description>
Resnext50 32x4d has been introduces recently via torchvision 0.3.
When collecting activation stats on the model, RuntimeError is raised.
Instruction: python3 examples/classifier_compression/compres_classifier.py --arch=resnext50_32x4d --pretrained IMAGENET --evaluate --act-stats=test --vs=0
Error: RuntimeError: The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 0
	</description>
	<comments>
		<comment id='1' author='barrh' date='2019-09-24T19:08:58Z'>
		Hi &lt;denchmark-link:https://github.com/barrh&gt;@barrh&lt;/denchmark-link&gt;

The source of the problem is explained here: &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/data_loggers/collector.py#L165-L171&gt;https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/data_loggers/collector.py#L165-L171&lt;/denchmark-link&gt;

You don't see this explanation printed because this  statement returns ;
&lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/data_loggers/collector.py#L164&gt;https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/data_loggers/collector.py#L164&lt;/denchmark-link&gt;

Specifically, the problem is in self.relu of the Bottleneck layer: as you can see the same instance of ReLU is used twice.
&lt;denchmark-code&gt;class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,
                 base_width=64, dilation=1, norm_layer=None):
        super(Bottleneck, self).__init__()
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        width = int(planes * (base_width / 64.)) * groups
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out
&lt;/denchmark-code&gt;

When I handled this issue for ResNet50 way back when, I did it by copying TorchVision's resnet.py into Distiller and made the changes to ReLU in that file (&lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/master/distiller/models/imagenet/resnet.py&gt;https://github.com/NervanaSystems/distiller/blob/master/distiller/models/imagenet/resnet.py&lt;/denchmark-link&gt;
).
Today I would suggest a more surgical approach, such as this patch to Mobilenet: &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/models/__init__.py#L61-L71&gt;https://github.com/NervanaSystems/distiller/blob/7bc2890efa436f02e9cc1ef6939f277b2f0a5e95/distiller/models/__init__.py#L61-L71&lt;/denchmark-link&gt;

I'm not sure when we'll get to fixing this - we are happy to get some help ;-)
Thanks!
Neta
		</comment>
		<comment id='2' author='barrh' date='2019-11-28T13:13:08Z'>
		This was fixed in: &lt;denchmark-link:https://github.com/IntelLabs/distiller/pull/414&gt;#414&lt;/denchmark-link&gt;

However, I get another error from collector.py on Resnext101_32x8d.
Perhaps we should add tests?
Edit2:
This is the error I've been getting running: python3 examples/classifier_compression/compres_classifier.py --arch=resnext101_32x8d --pretrained IMAGENET --evaluate --act-stats=test --vs=0
&lt;denchmark-code&gt;=&gt; created a pretrained resnext101_32x8d model with the imagenet dataset
Dataset sizes:
        training=1281167
        validation=50000
        test=50000
--- test ---------------------
50000 samples (256 per mini-batch)
distiller/distiller/data_loggers/collector.py:192: RuntimeWarning: invalid value encountered in sqrt
  self.std = np.sqrt(self.m_s / (self.n + n - 1.0))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='barrh' date='2019-12-02T11:08:41Z'>
		This was fixed in: &lt;denchmark-link:https://github.com/IntelLabs/distiller/pull/414&gt;#414&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>