<bug id='249' author='bdhammel' open_date='2019-05-10T19:46:54Z' closed_time='2019-05-19T09:23:31Z'>
	<summary>Setting clip value in `PostTrainLinearQuantizer` raises TypeError</summary>
	<description>
I'm trying to clip by specifying the number to standard deviations in PostTrainLinearQuantizer
&lt;denchmark-code&gt;    quantizer = quantization.PostTrainLinearQuantizer(
        model,
        bits_activations=8, bits_parameters=8, bits_accum=32,
        mode=quantization.LinearQuantMode.SYMMETRIC,
        clip_acts=quantization.ClipMode.N_STD,
        no_clip_layers=None, clip_n_stds=3
    )
    quantizer.prepare_model()
&lt;/denchmark-code&gt;

However, this throws the error:
&lt;denchmark-code&gt;TypeError: get_tensor_mean_n_stds_max_abs() got multiple values for argument 'n_stds'
&lt;/denchmark-code&gt;

It looks like the  is taking two values:
&lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/range_linear.py#L97&gt;https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/range_linear.py#L97&lt;/denchmark-link&gt;

One is the tensor and one is the dimension to be used with ; the standard deviation is attached as a partial: &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/range_linear.py#L76&gt;https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/range_linear.py#L76&lt;/denchmark-link&gt;

However,  only accepts the tensor and the std. &lt;denchmark-link:https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/q_utils.py#L149&gt;https://github.com/NervanaSystems/distiller/blob/master/distiller/quantization/q_utils.py#L149&lt;/denchmark-link&gt;

modifying the source fixed this:
&lt;denchmark-code&gt;def get_tensor_mean_n_stds_min_max(t, _, n_stds=1):
    if n_stds &lt;= 0:
        raise ValueError('n_stds must be &gt; 0, got {}'.format(n_stds))
    mean = t.mean()
    std = t.std()
    min_val, max_val = get_tensor_min_max(t)
    min_val = torch.max(min_val, mean - n_stds * std)
    max_val = torch.min(max_val, mean + n_stds * std)
    return min_val, max_val


def get_tensor_mean_n_stds_max_abs(t, _, n_stds=1):
    min_val, max_val = get_tensor_mean_n_stds_min_max(t, _, n_stds)
    return torch.max(min_val.abs_(), max_val.abs_())
&lt;/denchmark-code&gt;

Distiller version: 0.4.0-pre
Pytorch version: 1.0.1
Python version: 3.6.8
	</description>
	<comments>
		<comment id='1' author='bdhammel' date='2019-05-19T09:23:31Z'>
		&lt;denchmark-link:https://github.com/bdhammel&gt;@bdhammel&lt;/denchmark-link&gt;
 Sorry for the late response, and thanks for catching this! Fixed in &lt;denchmark-link:https://github.com/IntelLabs/distiller/commit/9af786b6599fe41fc95593e77d4631f0150b24d1&gt;9af786b&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>