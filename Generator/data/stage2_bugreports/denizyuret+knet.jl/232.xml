<bug id='232' author='ilkerkesen' open_date='2017-12-17T19:41:45Z' closed_time='2017-12-21T10:25:48Z'>
	<summary>Deconvolution Issues</summary>
	<description>
I highly suspect the correctness of deconvolution operations in Knet. I just want to have the following operation,

input: [24,24,20,100]
output: [28,28,1,100]

I couldn't have made it yet. I tried it on v0.8.6 and switched back to v0.8.5 (just in case, maybe something has broken in optimized cudnn algo stuff).
julia&gt; w0 = KnetArray(randn(Float32, 5, 5, 1, 20));

julia&gt; x0 = KnetArray(rand(Float32, 24, 24, 20, 100));

julia&gt; size(deconv4(w0,x0)) # this output does not make it sense, it should give what I want
(28, 28, 20, 100)

julia&gt; size(deconv4(Array(w0),Array(x0))) # it gives error on CPU
ERROR: AssertionError: Cx == C1 &amp;&amp; (Cy == C2 &amp;&amp; Ny == Nx)
Stacktrace:
 [1] #conv4x#332(::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:451
 [2] conv4x(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:446
 [3] #deconv4#261(::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
 [4] deconv4(::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177

julia&gt; w1 = KnetArray(randn(Float32, 5, 5, 20,20));

julia&gt; size(deconv4(w1,x0))
(28, 28, 20, 100)

julia&gt; size(deconv4(Array(w1),Array(x0)))
(28, 28, 20, 100)

julia&gt; w2 = KnetArray(randn(Float32, 5, 5, 20, 1));

julia&gt; size(deconv4(w2,x0))
ERROR: cudnn.cudnnConvolutionBackwardData error 3
Stacktrace:
 [1] macro expansion at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/gpu.jl:13 [inlined]
 [2] #conv4x#208(::Ptr{Void}, ::Int64, ::Int64, ::Ptr{Void}, ::Int64, ::Array{Any,1}, ::Function, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:52
 [3] #deconv4#261(::Array{Any,1}, ::Function, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
 [4] deconv4(::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177

julia&gt; size(deconv4(Array(w2),Array(x0)))
ERROR: AssertionError: Cx == C1 &amp;&amp; (Cy == C2 &amp;&amp; Ny == Nx)
Stacktrace:
 [1] #conv4x#332(::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:451
 [2] conv4x(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:446
 [3] #deconv4#261(::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
 [4] deconv4(::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177
I'll investigate the problem, but a discussion will be useful for me.
	</description>
	<comments>
		<comment id='1' author='ilkerkesen' date='2017-12-18T03:54:53Z'>
		deconv has a one line implementation. There are multiple deconv operations
used in practice, not sure which one Emre Yurdakul implemented.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sun, Dec 17, 2017 at 22:41 İlker Kesen ***@***.***&gt; wrote:
 I highly suspect the correctness of deconvolution operations in Knet. I
 just want to have the following operation,

    - input: [24,24,20,100]
    - output: [28,28,1,100]

 I couldn't have made it yet. I tried it on v0.8.6 and switched back to
 v0.8.5 (just in case, maybe something has broken in optimized cudnn algo
 stuff).

 julia&gt; w0 = KnetArray(randn(Float32, 5, 5, 1, 20));

 julia&gt; x0 = KnetArray(rand(Float32, 24, 24, 20, 100));

 julia&gt; size(deconv4(w0,x0)) # this output does not make it sense, it should give what I want
 (28, 28, 20, 100)

 julia&gt; size(deconv4(Array(w0),Array(x0))) # it gives error on CPU
 ERROR: AssertionError: Cx == C1 &amp;&amp; (Cy == C2 &amp;&amp; Ny == Nx)
 Stacktrace:
  [1] #conv4x#332(::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:451
  [2] conv4x(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:446
  [3] #deconv4#261(::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
  [4] deconv4(::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177

 julia&gt; w1 = KnetArray(randn(Float32, 5, 5, 20,20));

 julia&gt; size(deconv4(w1,x0))
 (28, 28, 20, 100)

 julia&gt; size(deconv4(Array(w1),Array(x0)))
 (28, 28, 20, 100)

 julia&gt; w2 = KnetArray(randn(Float32, 5, 5, 20, 1));

 julia&gt; size(deconv4(w2,x0))
 ERROR: cudnn.cudnnConvolutionBackwardData error 3
 Stacktrace:
  [1] macro expansion at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/gpu.jl:13 [inlined]
  [2] #conv4x#208(::Ptr{Void}, ::Int64, ::Int64, ::Ptr{Void}, ::Int64, ::Array{Any,1}, ::Function, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:52
  [3] #deconv4#261(::Array{Any,1}, ::Function, ::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
  [4] deconv4(::Knet.KnetArray{Float32,4}, ::Knet.KnetArray{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177

 julia&gt; size(deconv4(Array(w2),Array(x0)))
 ERROR: AssertionError: Cx == C1 &amp;&amp; (Cy == C2 &amp;&amp; Ny == Nx)
 Stacktrace:
  [1] #conv4x#332(::Int64, ::Int64, ::Int64, ::Int64, ::Int64, ::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:451
  [2] conv4x(::Array{Float32,4}, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:446
  [3] #deconv4#261(::Array{Any,1}, ::Function, ::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:178
  [4] deconv4(::Array{Float32,4}, ::Array{Float32,4}) at /KUFS/scratch/ikesen16/.julia/lnode/v0.6/Knet/src/conv.jl:177

 I'll investigate the problem, but a discussion will be useful for me.

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;#232&gt;, or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABvNpvHTEq5XYsaT7ImMysZ0h5ndlTVVks5tBW55gaJpZM4RExOy&gt;
 .



		</comment>
		<comment id='2' author='ilkerkesen' date='2017-12-18T10:18:43Z'>
		I've fixed the issue. I'll be sure our implementation is same with an another popular framework. I'll add extra documentation about what kind of deconvolution Knet implements, input and output sizes, references etc.
		</comment>
		<comment id='3' author='ilkerkesen' date='2017-12-18T10:55:33Z'>
		Does it include all deconvolution arithmetics as animated here &lt;denchmark-link:https://github.com/vdumoulin/conv_arithmetic#convolution-animations&gt;https://github.com/vdumoulin/conv_arithmetic#convolution-animations&lt;/denchmark-link&gt;
? I am also interested in using deconvolutions for image/text generation. So this support would be really helpful.
		</comment>
		<comment id='4' author='ilkerkesen' date='2017-12-18T11:01:38Z'>
		&lt;denchmark-link:https://github.com/ngphuoc&gt;@ngphuoc&lt;/denchmark-link&gt;
 not so sure. Currently deconv4 operation with default parameters corresponds to  in that table.
		</comment>
		<comment id='5' author='ilkerkesen' date='2017-12-19T08:33:55Z'>
		I'm able to perform the following operations in &lt;denchmark-link:https://github.com/vdumoulin/conv_arithmetic#convolution-animations&gt;this table&lt;/denchmark-link&gt;
,

No padding, no strides, transposed
Arbitrary padding, no strides, transposed
Half padding, no strides, transposed
Full padding, no strides, transposed
No padding, strides, transposed
Padding, strides, transposed

Not checked them by manually (I'll do it and be sure), just compared with PyTorch. People usually don't use unpool operation in deconvolutional neural networks (for instance, DCGAN model doesn't have pooling/unpooling operation). TensorFlow don't have unpool operation in core framework, PyTorch has one max-unpool operation, but it keeps track of indices. Since, unpool is not used in deconv networks generally, I won't do anything about unpooling.
		</comment>
		<comment id='6' author='ilkerkesen' date='2017-12-19T08:57:37Z'>
		&lt;denchmark-link:https://github.com/ilkerkesen&gt;@ilkerkesen&lt;/denchmark-link&gt;
 Discussing this on a PR thread might be better.
		</comment>
	</comments>
</bug>