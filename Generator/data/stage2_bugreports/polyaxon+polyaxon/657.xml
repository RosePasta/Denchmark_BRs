<bug id='657' author='hollowgalaxy' open_date='2020-01-16T01:16:42Z' closed_time='2020-05-02T21:09:05Z'>
	<summary>Distributed experiments unstable in succeeding to run.</summary>
	<description>
&lt;denchmark-h:h3&gt;Describe the bug&lt;/denchmark-h&gt;

Running exact same code, causes some experiments to fail, (althought sometimes succeeds). These experiments will work after certain number of restarts using the restart button on the web cli meaning that this issue is not code specific.
&lt;denchmark-h:h2&gt;Error type 1:&lt;/denchmark-h&gt;

This is the entire log
&lt;denchmark-code&gt;2020-01-15 23:00:50 UTC master.0 -- --------------------------------------------------------------------------

2020-01-15 23:00:50 UTC master.0 -- ORTE was unable to reliably start one or more daemons.

2020-01-15 23:00:50 UTC master.0 -- This usually is caused by:

2020-01-15 23:00:50 UTC master.0 -- 

2020-01-15 23:00:50 UTC master.0 -- * not finding the required libraries and/or binaries on

2020-01-15 23:00:50 UTC master.0 --   one or more nodes. Please check your PATH and LD_LIBRARY_PATH

2020-01-15 23:00:50 UTC master.0 --   settings, or configure OMPI with --enable-orterun-prefix-by-default

2020-01-15 23:00:50 UTC master.0 -- 

2020-01-15 23:00:50 UTC master.0 -- * lack of authority to execute on one or more specified nodes.

2020-01-15 23:00:50 UTC master.0 --   Please verify your allocation and authorities.

2020-01-15 23:00:50 UTC master.0 -- 

2020-01-15 23:00:50 UTC master.0 -- * the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).

2020-01-15 23:00:50 UTC master.0 --   Please check with your sys admin to determine the correct location to use.

2020-01-15 23:00:50 UTC master.0 -- 

2020-01-15 23:00:50 UTC master.0 -- *  compilation of the orted with dynamic libraries when static are required

2020-01-15 23:00:50 UTC master.0 --   (e.g., on Cray). Please check your configure cmd line and consider using

2020-01-15 23:00:50 UTC master.0 --   one of the contrib/platform definitions for your system type.

2020-01-15 23:00:50 UTC master.0 -- 

2020-01-15 23:00:50 UTC master.0 -- * an inability to create a connection back to mpirun due to a

2020-01-15 23:00:50 UTC master.0 --   lack of common network interfaces and/or no route found between

2020-01-15 23:00:50 UTC master.0 --   them. Please check network connectivity (including firewalls

2020-01-15 23:00:50 UTC master.0 --   and network routing requirements).

2020-01-15 23:00:50 UTC master.0 -- --------------------------------------------------------------------------
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Error type 2&lt;/denchmark-h&gt;

This is the entire log
&lt;denchmark-code&gt;2020-01-15 23:00:54 UTC master.0 -- --------------------------------------------------------------------------

2020-01-15 23:00:54 UTC master.0 -- ORTE was unable to reliably start one or more daemons.

2020-01-15 23:00:54 UTC master.0 -- This usually is caused by:

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- * not finding the required libraries and/or binaries on

2020-01-15 23:00:54 UTC master.0 --   one or more nodes. Please check your PATH and LD_LIBRARY_PATH

2020-01-15 23:00:54 UTC master.0 --   settings, or configure OMPI with --enable-orterun-prefix-by-default

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- * lack of authority to execute on one or more specified nodes.

2020-01-15 23:00:54 UTC master.0 --   Please verify your allocation and authorities.

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- * the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base).

2020-01-15 23:00:54 UTC master.0 --   Please check with your sys admin to determine the correct location to use.

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- *  compilation of the orted with dynamic libraries when static are required

2020-01-15 23:00:54 UTC master.0 --   (e.g., on Cray). Please check your configure cmd line and consider using

2020-01-15 23:00:54 UTC master.0 --   one of the contrib/platform definitions for your system type.

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- * an inability to create a connection back to mpirun due to a

2020-01-15 23:00:54 UTC master.0 --   lack of common network interfaces and/or no route found between

2020-01-15 23:00:54 UTC master.0 --   them. Please check network connectivity (including firewalls

2020-01-15 23:00:54 UTC master.0 --   and network routing requirements).

2020-01-15 23:00:54 UTC master.0 -- --------------------------------------------------------------------------

2020-01-15 23:00:54 UTC master.0 -- --------------------------------------------------------------------------

2020-01-15 23:00:54 UTC master.0 -- ORTE does not know how to route a message to the specified daemon

2020-01-15 23:00:54 UTC master.0 -- located on the indicated node:

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 --   my node:   plx-e102f64fb97c40c28dea46c129978a96-master-0

2020-01-15 23:00:54 UTC master.0 --   target node:  plx-e102f64fb97c40c28dea46c129978a96-worker-1

2020-01-15 23:00:54 UTC master.0 -- 

2020-01-15 23:00:54 UTC master.0 -- This is usually an internal programming error that should be

2020-01-15 23:00:54 UTC master.0 -- reported to the developers. In the meantime, a workaround may

2020-01-15 23:00:54 UTC master.0 -- be to set the MCA param routed=direct on the command line or

2020-01-15 23:00:54 UTC master.0 -- in your environment. We apologize for the problem.

2020-01-15 23:00:54 UTC master.0 -- --------------------------------------------------------------------------

2020-01-15 23:00:54 UTC master.0 -- [plx-somerandomnums-master-0:00009] 1 more process has sent help message help-errmgr-base.txt / no-path

2020-01-15 23:00:54 UTC master.0 -- [plx-somerandomnums-master-0:00009] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Error Type 3&lt;/denchmark-h&gt;

Stalled rank. Happens in code. At the start of training (when calling model.fit())
This is part of the logs. It loops infinitely with the last error.
&lt;denchmark-code&gt;
2020-01-15 22:41:16 UTC master.0 -- [1,0]&lt;stdout&gt;:Saving model every epoch steps.

2020-01-15 22:41:16 UTC master.0 -- [1,0]&lt;stdout&gt;:Training Model GPU_ID=0

2020-01-15 22:41:16 UTC master.0 -- [1,1]&lt;stdout&gt;:Setup Logs and Checkpoints GPU_ID=1

2020-01-15 22:41:16 UTC master.0 -- [1,1]&lt;stdout&gt;:Training Model GPU_ID=1

2020-01-15 22:41:16 UTC master.0 -- [1,3]&lt;stdout&gt;:Setup Logs and Checkpoints GPU_ID=3

2020-01-15 22:41:16 UTC master.0 -- [1,3]&lt;stdout&gt;:Training Model GPU_ID=3

2020-01-15 22:41:16 UTC master.0 -- [1,0]&lt;stdout&gt;:Epoch 1/100

2020-01-15 22:41:16 UTC master.0 -- [1,0]&lt;stderr&gt;:2020-01-15 22:41:16.757664: I tensorflow_io/core/kernels/ffmpeg_kernels_deprecated.cc:57] FFmpeg log level: error

2020-01-15 22:41:16 UTC master.0 -- [1,1]&lt;stdout&gt;:Epoch 1/100

2020-01-15 22:41:16 UTC master.0 -- [1,1]&lt;stderr&gt;:2020-01-15 22:41:16.808739: I tensorflow_io/core/kernels/ffmpeg_kernels_deprecated.cc:57] FFmpeg log level: error

2020-01-15 22:41:16 UTC master.0 -- [1,3]&lt;stdout&gt;:Epoch 1/100

2020-01-15 22:41:16 UTC master.0 -- [1,3]&lt;stderr&gt;:2020-01-15 22:41:16.888191: I tensorflow_io/core/kernels/ffmpeg_kernels_deprecated.cc:57] FFmpeg log level: error

2020-01-15 22:41:17 UTC master.0 -- [1,2]&lt;stdout&gt;:Setup Logs and Checkpoints GPU_ID=2

2020-01-15 22:41:17 UTC master.0 -- [1,2]&lt;stdout&gt;:Training Model GPU_ID=2

2020-01-15 22:41:17 UTC master.0 -- [1,2]&lt;stdout&gt;:Epoch 1/100

2020-01-15 22:41:17 UTC master.0 -- [1,2]&lt;stderr&gt;:2020-01-15 22:41:17.636133: I tensorflow_io/core/kernels/ffmpeg_kernels_deprecated.cc:57] FFmpeg log level: error

2020-01-15 22:42:01 UTC master.0 -- [1,0]&lt;stderr&gt;:2020-01-15 22:42:01.224880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7

2020-01-15 22:42:01 UTC master.0 -- [1,1]&lt;stderr&gt;:2020-01-15 22:42:01.972334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7

2020-01-15 22:42:02 UTC master.0 -- [1,0]&lt;stderr&gt;:2020-01-15 22:42:02.549070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0

2020-01-15 22:42:03 UTC master.0 -- [1,1]&lt;stderr&gt;:2020-01-15 22:42:03.291248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0

2020-01-15 22:42:03 UTC master.0 -- [1,3]&lt;stderr&gt;:2020-01-15 22:42:03.928426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7

2020-01-15 22:42:04 UTC master.0 -- [1,2]&lt;stderr&gt;:2020-01-15 22:42:04.365046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7

2020-01-15 22:42:05 UTC master.0 -- [1,3]&lt;stderr&gt;:2020-01-15 22:42:05.270845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0

2020-01-15 22:42:05 UTC master.0 -- [1,2]&lt;stderr&gt;:2020-01-15 22:42:05.726808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO NET/Socket : Using [0]eth0:10.20.16.7&lt;0&gt;

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO NET/IB : No device found.

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:NCCL version 2.4.7+cuda10.0

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO NET/Socket : Using [0]eth0:10.20.14.4&lt;0&gt;

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO NET/Socket : Using [0]eth0:10.20.8.7&lt;0&gt;

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO NET/IB : No device found.

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO NET/IB : No device found.

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO NET/Socket : Using [0]eth0:10.20.1.4&lt;0&gt;

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Setting affinity for GPU 0 to 0f

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO Setting affinity for GPU 0 to 0f

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO Setting affinity for GPU 0 to 0f

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO NET/IB : No device found.

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO Setting affinity for GPU 0 to 0f

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO CUDA Dev 0[0], Socket NIC distance :  SYS

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Channel 00 :    0   1   2   3

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO Could not find real path of /sys/class/net/eth0/device

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO include/net.h:24 -&gt; 2

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO Ring 00 : 0 -&gt; 1 [receive] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO Ring 00 : 2 -&gt; 3 [receive] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO Ring 00 : 1 -&gt; 2 [receive] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Ring 00 : 3 -&gt; 0 [receive] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO Ring 00 : 1 -&gt; 2 [send] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO Ring 00 : 3 -&gt; 0 [send] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Ring 00 : 0 -&gt; 1 [send] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO comm 0x7f463431fad0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO Ring 00 : 2 -&gt; 3 [send] via NET/Socket/0

2020-01-15 22:42:07 UTC master.0 -- [1,1]&lt;stdout&gt;:plx-somenumberid-worker-0:28:36 [0] NCCL INFO comm 0x7f34b42feb80 rank 1 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE

2020-01-15 22:42:07 UTC master.0 -- [1,2]&lt;stdout&gt;:plx-somenumberid-worker-1:25:33 [0] NCCL INFO comm 0x7eff642fe960 rank 2 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE

2020-01-15 22:42:07 UTC master.0 -- [1,3]&lt;stdout&gt;:plx-somenumberid-worker-2:25:33 [0] NCCL INFO comm 0x7f1e582fb4e0 rank 3 nranks 4 cudaDev 0 nvmlDev 0 - Init COMPLETE

2020-01-15 22:42:07 UTC master.0 -- [1,0]&lt;stdout&gt;:plx-somenumberid-master-0:22:30 [0] NCCL INFO Launch mode Parallel

2020-01-15 22:42:13 UTC master.0 -- [1,1]&lt;stderr&gt;:WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.361966). Check your callbacks.

2020-01-15 22:42:13 UTC master.0 -- [1,2]&lt;stderr&gt;:WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.362755). Check your callbacks.

2020-01-15 22:42:13 UTC master.0 -- [1,0]&lt;stderr&gt;:WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.361898). Check your callbacks.

2020-01-15 22:42:13 UTC master.0 -- [1,3]&lt;stderr&gt;:WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.363472). Check your callbacks.

2020-01-15 22:44:33 UTC master.0 -- [1,0]&lt;stderr&gt;:[[1,0]&lt;stderr&gt;:2020-01-15 22:44:33[1,0]&lt;stderr&gt;:.[1,0]&lt;stderr&gt;:214399[1,0]&lt;stderr&gt;:: [1,0]&lt;stderr&gt;:W[1,0]&lt;stderr&gt;: [1,0]&lt;stderr&gt;:horovod/common/stall_inspector.cc[1,0]&lt;stderr&gt;::[1,0]&lt;stderr&gt;:105[1,0]&lt;stderr&gt;:] [1,0]&lt;stderr&gt;:One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock.

2020-01-15 22:44:33 UTC master.0 -- [1,0]&lt;stderr&gt;:Stalled ranks:

2020-01-15 22:44:33 UTC master.0 -- [1,0]&lt;stderr&gt;:0: [HorovodAllreduce][1,0]&lt;stderr&gt;:

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:[[1,0]&lt;stderr&gt;:2020-01-15 22:45:33[1,0]&lt;stderr&gt;:.[1,0]&lt;stderr&gt;:219918[1,0]&lt;stderr&gt;:: [1,0]&lt;stderr&gt;:W[1,0]&lt;stderr&gt;: [1,0]&lt;stderr&gt;:horovod/common/stall_inspector.cc[1,0]&lt;stderr&gt;::[1,0]&lt;stderr&gt;:105[1,0]&lt;stderr&gt;:] [1,0]&lt;stderr&gt;:One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock.

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:Stalled ranks:

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:0: [HorovodAllreduce]

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:1: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_11_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_12_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_13_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_19_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_1_0 ...]

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:2: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_11_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_12_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_13_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_19_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_1_0 ...]

2020-01-15 22:45:33 UTC master.0 -- [1,0]&lt;stderr&gt;:3: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_11_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_12_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_13_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_19_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_1_0 ...][1,0]&lt;stderr&gt;:

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:[[1,0]&lt;stderr&gt;:2020-01-15 22:46:33[1,0]&lt;stderr&gt;:.224349: W[1,0]&lt;stderr&gt;: horovod/common/stall_inspector.cc:105] [1,0]&lt;stderr&gt;:One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock.

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:Stalled ranks:

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:0: [HorovodAllreduce]

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:1: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_105_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_106_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_107_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_108_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_114_0 ...]

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:2: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_105_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_106_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_107_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_108_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_114_0 ...]

2020-01-15 22:46:33 UTC master.0 -- [1,0]&lt;stderr&gt;:3: [training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_105_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_106_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_107_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_108_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_10_0, training/SGD_Allreduce/HorovodAllreduce_training_SGD_gradients_gradients_AddN_114_0 ...]

2020-01-15 22:47:33 UTC master.0 -- [1,0]&lt;stderr&gt;:[[1,0]&lt;stderr&gt;:2020-01-15 22:47:33[1,0]&lt;stderr&gt;:.[1,0]&lt;stderr&gt;:226365[1,0]&lt;stderr&gt;:: [1,0]&lt;stderr&gt;:W[1,0]&lt;stderr&gt;: [1,0]&lt;stderr&gt;:horovod/common/stall_inspector.cc[1,0]&lt;stderr&gt;::[1,0]&lt;stderr&gt;:105[1,0]&lt;stderr&gt;:] [1,0]&lt;stderr&gt;:One or more tensors were submitted to be reduced, gathered or broadcasted by subset of ranks and are waiting for remainder of ranks for more than 60 seconds. This may indicate that different ranks are trying to submit different tensors or that only subset of ranks is submitting tensors, which will cause deadlock
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;To Reproduce&lt;/denchmark-h&gt;

Running an experiment group has been the quickest way to reproduce but I don't have a 1 for 1 method.
&lt;denchmark-h:h3&gt;Expected behavior&lt;/denchmark-h&gt;

All experiments work.
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

Experiment group I was using, but this issue occurs with solo experiments as well.
&lt;denchmark-code&gt;---
version: 1

kind: group
framework: horovod

inputs:
  - {name: region, type: str, is_optional: true, default: None}
  - {name: bucket, type: str, is_optional: true, default: None}
  - {name: batch_size, type: int, is_optional: true, default: 8}
  - {name: max_epochs, type: int, is_optional: true, default: 100}
  - {name: learning_policy, type: str, is_optional: true, default: reduce}
  - {name: min_learning_rate, type: float, is_optional: true, default: 0.00001}


environment:
  resources:
    gpu:
      requests: 1
      limits: 1
  replicas:
    n_workers: 3
    default_worker:
      resources:
        gpu:
          requests: 1
          limits: 1

hptuning:
  concurrency: 4
  bo:
    n_iterations: 16
    n_initial_trials: 8
    metric:
      name: loss_func
      optimization: maximize
    utility_function:
      acquisition_function: ucb
      kappa: 2.576
      gaussian_process:
        kernel: matern
        length_scale: 1.0
        nu: 1.9
        n_restarts_optimizer: 0

  matrix:
      max_learning_rate:
        linspace: '0.001:0.03:5'
      momentum:
        range: '0.85:0.96:0.05'
      weight_decay:
        linspace: '0.00001:0.001:4'
      patience:
        values: [3, 5, 7]
      factor:
        values: [0.1, 0.25, 0.5]

build:
  dockerfile: polyaxon/Dockerfile

run:
  cmd: -x REGION={{ region }} \
    -x BUCKET={{ bucket }} \
    python polyaxon/i3d_train.py \
    --batch_size=8 \
    --max_learning_rate={{ max_learning_rate }} \
    --momentum={{ momentum }} \
    --weight_decay={{ weight_decay }} \
    --patience={{ patience }} \
    --factor={{ factor }} \
    --max_epochs=100
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hollowgalaxy' date='2020-01-16T01:25:53Z'>
		Hypothesis. Both try to spawn workers at the same time causing a partially spawned experiment. I have a limit on how many gpus I can use in the cluster. And if both experiments run together, they would exceed the number of gpus I can have.
		</comment>
		<comment id='2' author='hollowgalaxy' date='2020-01-16T01:28:48Z'>
		This is a known bug, a fix is a better integration with mpi operator.
		</comment>
		<comment id='3' author='hollowgalaxy' date='2020-01-16T01:40:27Z'>
		Is that for all 3 errors or just the orte errors?
		</comment>
		<comment id='4' author='hollowgalaxy' date='2020-01-16T01:41:43Z'>
		I would like to mention that for error 3, I am able to communicate with mpi4py even though horovod fails.
		</comment>
		<comment id='5' author='hollowgalaxy' date='2020-05-02T21:09:05Z'>
		Similar answer to &lt;denchmark-link:https://github.com/polyaxon/polyaxon/issues/453&gt;#453&lt;/denchmark-link&gt;
, we expose the full spec for MPI Operator in v1, so you can have full control over what's happening.
		</comment>
	</comments>
</bug>