<bug id='1503' author='Scharfsinnig' open_date='2020-09-25T07:59:55Z' closed_time='2020-12-16T00:33:52Z'>
	<summary>CUDA out of memory. Tried to allocate 50.00 MiB</summary>
	<description>
Before submitting a bug report, please be aware that your issue must be reproducible with all of the following, otherwise it is non-actionable, and we can not help you:

Current repo: run git fetch &amp;&amp; git status -uno to check and git pull to update repo
Common dataset: coco2017.data or coco64.data
Common environment: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov3#reproduce-our-environment

If this is a custom dataset/training question you must include your train*.jpg, test*.jpg and results.png figures, or we can not help you. You can generate these with utils.plot_results().
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.73 GiB total capacity; 13.62 GiB already allocated; 49.88 MiB free; 13.80 GiB reserved in total by PyTorch)
&lt;denchmark-h:h2&gt;To Reproduce (REQUIRED)&lt;/denchmark-h&gt;

When I tried to train my dataset by CUDA_VISIBLE_DEVICES=1 python train.py --weights '' --data coco/coco.data --cfg coco/yolov3.cfg --batch-size 16, I got CUDA OOM after a while. I have tried to set batch to 1, howerer, the error was still happened.
I got some message to add torch.no_grad(), but I don't konw where to set?
Input:
&lt;denchmark-code&gt;CUDA_VISIBLE_DEVICES=1 python train.py --weights '' --data coco/coco.data --cfg coco/yolov3.cfg --batch-size 16
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
    15/299     13.2G      5.98      5.37      2.13      13.5         9       512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08&lt;00:00,  4.10s/it]
               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04&lt;00:00,  4.95s/it]
                 all         5        15         0         0   0.00582         0

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
    16/299     13.2G      4.08      4.82      1.71      10.6         8       608: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:08&lt;00:00,  4.11s/it]
               Class    Images   Targets         P         R   mAP@0.5        F1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04&lt;00:00,  4.59s/it]
                 all         5        15         0         0   0.00446         0

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
  0%|                                                                                                                                                                          | 0/2 [00:09&lt;?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 436, in &lt;module&gt;
    train(hyp)  # train normally
  File "train.py", line 282, in train
    pred = model(imgs)
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/usr/src/app/models.py", line 244, in forward
    return self.forward_once(x)
  File "/usr/src/app/models.py", line 298, in forward_once
    x = module(x)
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py", line 131, in forward
    return F.batch_norm(
  File "/home/ultron/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py", line 2014, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.73 GiB total capacity; 13.62 GiB already allocated; 49.88 MiB free; 13.80 GiB reserved in total by PyTorch)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

If applicable, add screenshots to help explain your problem.

OS: CentOS7
GPU Tesla T4
CUDA: V10.1.243
CUDNN: 7.6.5
PyTorch: 1.6.0+cu101

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Add any other context about the problem here.
&lt;denchmark-link:https://user-images.githubusercontent.com/9099493/94242025-08e25400-ff48-11ea-8327-f308f05493fb.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/9099493/94242070-17c90680-ff48-11ea-88dd-b8ff72c283bd.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Scharfsinnig' date='2020-09-25T08:00:39Z'>
		Hello &lt;denchmark-link:https://github.com/Scharfsinnig&gt;@Scharfsinnig&lt;/denchmark-link&gt;
, thank you for your interest in our work! Ultralytics has open-sourced YOLOv5 at &lt;denchmark-link:https://github.com/ultralytics/yolov5&gt;https://github.com/ultralytics/yolov5&lt;/denchmark-link&gt;
, featuring faster, lighter and more accurate object detection. YOLOv5 is recommended for all new projects.




&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/90187293-6773ba00-dd6e-11ea-8f90-cd94afc0427f.png&gt;&lt;/denchmark-link&gt;

To continue with this repo, please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov3/blob/master/tutorial.ipynb&gt;Google Colab Notebook&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov3&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart&gt;GCP Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='Scharfsinnig' date='2020-09-25T08:02:37Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Could u help me to solve this problem?
		</comment>
		<comment id='3' author='Scharfsinnig' date='2020-09-28T18:15:44Z'>
		Observed similar issue on Amd Vega20 Gpus.
error:
RuntimeError: HIP out of memory. Tried to allocate 46.00 MiB (GPU 0; 7.98 GiB total capacity; 6.67 GiB already allocated; 1.17 GiB free; 6.81 GiB reserved in total by PyTorch)
[1]+  Exit 1                  nohup python3.6 train.py --data ./cfg/MaskIdentifier.data --weights ./weights/darknet53.conv.74 --batch-size 8 --cfg yolov3.cfg
		</comment>
		<comment id='4' author='Scharfsinnig' date='2020-10-26T01:46:17Z'>
		--batch-size 16Ôºåyou have to change a lower batch-size
		</comment>
		<comment id='5' author='Scharfsinnig' date='2020-11-04T07:32:16Z'>
		
--batch-size 16Ôºåyou have to change a lower batch-size

Already tried. I set to 1, the error still occurred.
		</comment>
		<comment id='6' author='Scharfsinnig' date='2020-11-05T02:42:15Z'>
		

--batch-size 16Ôºåyou have to change a lower batch-size

Already tried. I set to 1, the error still occurred.

try to change a lower epoch
		</comment>
		<comment id='7' author='Scharfsinnig' date='2020-11-09T07:46:09Z'>
		


--batch-size 16Ôºåyou have to change a lower batch-size

Already tried. I set to 1, the error still occurred.

try to change a lower epoch

I have already tried. I even set epoch to 1, the error still occurred.
		</comment>
		<comment id='8' author='Scharfsinnig' date='2020-12-10T00:33:07Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.
		</comment>
	</comments>
</bug>