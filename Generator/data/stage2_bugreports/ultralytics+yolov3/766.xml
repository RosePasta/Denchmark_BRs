<bug id='766' author='cbing88' open_date='2020-01-09T08:55:06Z' closed_time='2020-01-16T19:19:00Z'>
	<summary>Convert onnx successfully but has TracerWarnings</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I pulled docker image "ultralytics/yolov3:v196" and trained a yolov3 model "best.pt", and got many TracerWarnings when I convert to onnx.
Do you have any code available that does the conversion?
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:
below is Convert Code:
&lt;denchmark-code&gt;import os
import torch
import models

def main():
    cur_path = os.path.dirname(os.path.abspath(__file__))
    torch_model_path = os.path.join(cur_path, 'weights/best.pt')
    onnx_model_path = os.path.join(cur_path, 'weights/yolov3.onnx')
    cfg_path = os.path.join(cur_path, 'cfg/yolov3.cfg')

    dummy_input = torch.randn(1, 3, 416, 416)
    model = models.Darknet(cfg_path)
    model.load_state_dict(torch.load(torch_model_path, map_location='cpu')['model'], False)
    torch.onnx.export(model, dummy_input, onnx_model_path, opset_version=10)


if __name__ == '__main__':
    main()
&lt;/denchmark-code&gt;

I got the following warnings:
&lt;denchmark-code&gt;/usr/src/app/models.py:168: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (self.nx, self.ny) != (nx, ny):
/usr/src/app/models.py:299: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  self.img_size = max(img_size)
/usr/src/app/models.py:300: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  self.stride = self.img_size / max(ng)
/usr/src/app/models.py:309: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.
  self.ng = torch.Tensor(ng).to(device)
/usr/src/app/models.py:309: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  self.ng = torch.Tensor(ng).to(device)
/usr/src/app/models.py:205: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :2] = torch.sigmoid(io[..., :2]) + self.grid_xy  # xy
/usr/src/app/models.py:206: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method
/usr/src/app/models.py:208: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator mul_. This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :4] *= self.stride
/usr/src/app/models.py:208: TracerWarning: There are 4 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :4] *= self.stride
/usr/src/app/models.py:211: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator sigmoid_. This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  torch.sigmoid_(io[..., 4])
/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_helper.py:246: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.
ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).
We recommend using opset 11 and above for models using this operator. 
  "" + str(_export_onnx_opset_version) + ". "
&lt;/denchmark-code&gt;

I could still export onnx model, I'm wondering if I cloud ignore these warnings?
&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

No warnings or errors.
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

docker image: ultralytics/yolov3:v196
	</description>
	<comments>
		<comment id='1' author='cbing88' date='2020-01-09T18:06:28Z'>
		&lt;denchmark-link:https://github.com/cbing88&gt;@cbing88&lt;/denchmark-link&gt;
 if you pull a docker image you should use v0, the other versions are only for testing purposes (sorry for the confusion).
There are a few different ONNX export issues open, have you looked at these? In general,  if there are no errors you are good to go.
		</comment>
		<comment id='2' author='cbing88' date='2020-01-10T03:34:02Z'>
		Yes, I read all related issues and their situation is different from mine. I checked the onnx model and pytorch model, Here is my code:
&lt;denchmark-code&gt;import cv2
import torch
import onnxruntime
import numpy as np
from PIL import Image
from models import Darknet

device = 'cpu'
cfg = 'cfg/yolov3.cfg'
weights = 'weights/yolov3.pt'
img_size = (416, 416)
onnx_model_name = 'yolov3.onnx'
test_img_name = 'data/samples/bus.jpg'

def test(): 
    model = Darknet(cfg, img_size)
    model.load_state_dict(torch.load(weights, map_location=device)['model'])
    model.to(device).eval()

    img0 = Image.open(test_img_name)
    img = np.array(img0)
    img = cv2.resize(img, img_size)
    img = img.transpose(2, 0, 1)
    img = img.astype(np.float32)
    img /= 255.0  
    img = img.reshape((1, ) + img.shape)

    with torch.no_grad():
        img = torch.from_numpy(img)
        xout = model(img)[0]
    print('xout: ', xout.size())

    torch.onnx.export(model,                 # model being run
                  img,                       # model input (or a tuple for multiple inputs)
                  onnx_model_name,           # where to save the model (can be a file or file-like object)
                  export_params=True,        # store the trained parameter weights inside the model file
                  opset_version=10,          # the ONNX version to export the model to
                  do_constant_folding=True,  # wether to execute constant folding for optimization
                  input_names = ['input'],   # the model's input names
                  output_names = ['output'], # the model's output names
                  )
    model = onnxruntime.InferenceSession(onnx_model_name)
    ort_inputs = {model.get_inputs()[0].name: img.numpy()}
    ort_outs = model.run(None, ort_inputs)
    out = ort_outs[0]
    print(out.shape)

    np.testing.assert_allclose(xout.numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)

if __name__ == '__main__':
    test()
&lt;/denchmark-code&gt;

The output:
&lt;denchmark-code&gt;/usr/src/app/models.py:168: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if (self.nx, self.ny) != (nx, ny):
/usr/src/app/models.py:205: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :2] = torch.sigmoid(io[..., :2]) + self.grid_xy  # xy
/usr/src/app/models.py:206: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method
/usr/src/app/models.py:208: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator mul_. This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :4] *= self.stride
/usr/src/app/models.py:208: TracerWarning: There are 4 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  io[..., :4] *= self.stride
/usr/src/app/models.py:211: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator sigmoid_. This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.
  torch.sigmoid_(io[..., 4])
/opt/conda/lib/python3.6/site-packages/torch/onnx/symbolic_helper.py:246: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.
ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).
We recommend using opset 11 and above for models using this operator. 
  "" + str(_export_onnx_opset_version) + ". "
xout:  torch.Size([1, 10647, 85])
(1, 10647, 85)
Traceback (most recent call last):
  File "check_onnx.py", line 51, in &lt;module&gt;
    test()
  File "check_onnx.py", line 48, in test
    np.testing.assert_allclose(xout.numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)
  File "/opt/conda/lib/python3.6/site-packages/numpy/testing/_private/utils.py", line 1515, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File "/opt/conda/lib/python3.6/site-packages/numpy/testing/_private/utils.py", line 841, in assert_array_compare
    raise AssertionError(msg)
AssertionError: 
Not equal to tolerance rtol=0.001, atol=1e-05

Mismatch: 5.88%
Max absolute difference:       432.9
Max relative difference:  4.0996e+06
 x: array([[[     12.804,       19.88,      171.81, ...,     -3.0344,      -5.527,     -5.7068],
        [     53.229,      25.402,      129.65, ...,     -4.3247,     -5.9211,      -6.877],
        [     79.754,      24.647,      169.55, ...,     -5.2756,     -5.9931,      -6.717],...
 y: array([[[   -0.40492,     0.49487,     0.39278, ...,     -3.0344,      -5.527,     -5.7068],
        [    0.67855,      1.3482,     0.11123, ...,     -4.3247,     -5.9211,      -6.877],
        [  -0.030793,      1.2095,     0.37958, ...,     -5.2756,     -5.9931,      -6.717],...
&lt;/denchmark-code&gt;

That means the conversion of the onnx model failedÔºü
Anyway I'll try ultralytics/yolov3:v0 later, thank you for your reply!
		</comment>
		<comment id='3' author='cbing88' date='2020-01-10T17:59:55Z'>
		&lt;denchmark-link:https://github.com/cbing88&gt;@cbing88&lt;/denchmark-link&gt;
 ah interesting. Yes I don't see any reason why these two should not produce identical output. Can you plot the STS or MSE differences along the 85-vector? i.e. can you show something like this:

This should help show if the differences is in certain outputs or not.
		</comment>
		<comment id='4' author='cbing88' date='2020-01-12T15:00:55Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Here is STD and MSE of onnx output and  pytorch output in above code:
&lt;denchmark-code&gt;STD is:  [     120.03      119.95      53.645      47.542      4.0035  5.2154e-06  4.5532e-06  5.3168e-06  4.3002e-06  4.6089e-06  4.2678e-06  4.0211e-06  4.4537e-06  4.3412e-06  5.5698e-06  4.0521e-06  4.2781e-06  4.4175e-06  4.5388e-06  4.7046e-06  3.6611e-06  3.8398e-06  4.4299e-06  5.2582e-06  4.9454e-06  4.1343e-06  
  3.8336e-06   4.395e-06  4.1681e-06  4.1329e-06  4.0446e-06  4.4432e-06  4.2373e-06  4.4265e-06   4.362e-06   4.239e-06   4.095e-06  4.0204e-06  4.5069e-06  4.0431e-06  4.1058e-06  4.7981e-06  4.7566e-06  4.2987e-06   4.761e-06  4.6019e-06  4.3493e-06  4.1165e-06  4.1716e-06  3.8888e-06  4.1847e-06  4.5437e-06  
  4.6101e-06  3.8616e-06  4.4767e-06  4.6208e-06  4.8431e-06  4.1934e-06  4.0661e-06  4.8263e-06  4.1903e-06  5.2399e-06  3.4894e-06  4.8697e-06   3.356e-06  4.3399e-06  3.8515e-06    4.25e-06  4.0608e-06  4.0505e-06  4.5244e-06  3.6828e-06  4.6097e-06  3.6972e-06  3.6215e-06   3.673e-06  3.8156e-06  3.5598e-06  
  4.8788e-06  4.3523e-06  4.2446e-06   3.937e-06  4.1787e-06  3.7329e-06  4.1784e-06]

MSE is:  [      57682       57665      4468.8      3757.1      224.51  2.7344e-11  2.1882e-11  2.8302e-11  1.8742e-11  2.2121e-11  1.8245e-11   1.629e-11  1.9854e-11  1.8846e-11  3.1173e-11  1.6467e-11  1.8452e-11  1.9521e-11  2.0606e-11  2.2607e-11  1.3576e-11  1.4772e-11   1.964e-11  2.7694e-11   2.471e-11  1.7223e-11  
  1.5059e-11  1.9342e-11  1.7603e-11  1.7479e-11  1.6632e-11  2.0705e-11  1.7996e-11  1.9676e-11  1.9029e-11  1.7971e-11  1.6884e-11  1.6189e-11  2.0318e-11  1.6348e-11  1.6892e-11  2.3144e-11  2.2699e-11  1.8989e-11  2.2683e-11  2.1199e-11  1.8933e-11  1.7389e-11  1.7756e-11  1.5373e-11  1.7547e-11  2.0839e-11  
  2.1522e-11  1.5243e-11  2.0074e-11  2.1549e-11  2.3898e-11  1.7752e-11  1.6682e-11    2.39e-11  1.7732e-11  2.7623e-11   1.224e-11  2.3925e-11  1.1371e-11  1.8843e-11  1.4838e-11  1.8267e-11  1.6684e-11  1.7029e-11  2.0712e-11  1.3704e-11  2.1514e-11  1.3843e-11  1.3119e-11  1.3524e-11  1.4637e-11   1.274e-11   
  2.4208e-11  1.8974e-11  1.8027e-11  1.5537e-11  1.7483e-11  1.4015e-11  1.7752e-11]
&lt;/denchmark-code&gt;

By the way, ultralytics/yolov3:v0 is the same with v196.
		</comment>
		<comment id='5' author='cbing88' date='2020-01-12T20:01:10Z'>
		&lt;denchmark-link:https://github.com/cbing88&gt;@cbing88&lt;/denchmark-link&gt;
 ah interesting, so the difference is in the boxes and the confidence. Well these are modified in the YOLO module in PyTorch which is executed during inference, so it looks like the ONNX export is not copying these operations.


		</comment>
		<comment id='6' author='cbing88' date='2020-01-16T19:19:00Z'>
		I'll close this issue for now as the original issue appears to have been resolved, and/or no activity has been seen for some time. Feel free to comment if this is not the case.
		</comment>
		<comment id='7' author='cbing88' date='2020-08-03T14:58:56Z'>
		&lt;denchmark-link:https://github.com/cbing88&gt;@cbing88&lt;/denchmark-link&gt;
 hi,did you solver this problem, i also meet that problem?,conver onnx raise warings and no fault and check onnx alse have no errors, but when test an image the results is clearly wrong
		</comment>
		<comment id='8' author='cbing88' date='2020-08-13T07:41:52Z'>
		&lt;denchmark-link:https://github.com/cbing88&gt;@cbing88&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
  How did u solve this?
Even i got the same warnings
		</comment>
	</comments>
</bug>