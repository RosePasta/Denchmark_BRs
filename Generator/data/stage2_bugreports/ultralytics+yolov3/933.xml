<bug id='933' author='limingcv' open_date='2020-03-16T14:40:13Z' closed_time='2020-03-17T08:22:50Z'>
	<summary>KeyError: "param 'initial_lr' is not specified in param_groups[0] when resuming an optimizer"</summary>
	<description>
Thank you very much for your contribution so that we can use this amazing repo, but I had some problems while training my own dataset, and the results didn't look very good. All parameter settings are default. Could you give me some advice for better results? Thanks a lot again O(∩_∩)O
There are results:
&lt;denchmark-link:https://user-images.githubusercontent.com/48321730/76768690-554d1a00-67d6-11ea-8f88-7fbfb9ee8fbc.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/48321730/76768719-6138dc00-67d6-11ea-9a63-b17afc36e3b3.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='limingcv' date='2020-03-16T14:41:03Z'>
		Hello &lt;denchmark-link:https://github.com/limingcv&gt;@limingcv&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://colab.research.google.com/drive/1G8T-VFxQkjDe4idzN8F-hbIBqkkkQnxw&gt;Google Colab Notebook&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov3&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart&gt;GCP Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
		</comment>
		<comment id='2' author='limingcv' date='2020-03-16T18:14:44Z'>
		&lt;denchmark-link:https://github.com/limingcv&gt;@limingcv&lt;/denchmark-link&gt;
 looks pretty good! What seems to be the problem?
		</comment>
		<comment id='3' author='limingcv' date='2020-03-17T02:48:48Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

Thank you for replying to me, I tried to fine-tine the yesterday's model, so I ran the following code
&lt;denchmark-code&gt;python train.py --batch-size 64 --accumulate 1 --data data/ocean.data --multi-scale --cache-images --epochs 80 --name 'anchor cluster multi-scale' --weights weights/best.pt
&lt;/denchmark-code&gt;

but it gave an error
&lt;denchmark-code&gt;KeyError: "param 'initial_lr' is not specified in param_groups[0] when resuming an optimizer"
&lt;/denchmark-code&gt;

This error happened in file "train.py", line 162, in training process. what should I do for this problem?
		</comment>
		<comment id='4' author='limingcv' date='2020-03-17T03:25:43Z'>
		&lt;denchmark-link:https://github.com/limingcv&gt;@limingcv&lt;/denchmark-link&gt;
 I'm able to recreate this error with the following:
python3 train.py --epochs 3 --data coco16.data --weights ''
python3 train.py --epochs 6 --data coco16.data --weights weights/last.pt
It seems to be related to the order of optimizer instantiation. I don't have time to address this at the moment, so I would simply train for full epochs in the meantime.
&lt;denchmark-link:https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822&gt;https://discuss.pytorch.org/t/a-problem-occured-when-resuming-an-optimizer/28822&lt;/denchmark-link&gt;

A temporary, less preferable solution is to convert last.pt into a backbone first, which strips the optimizer and resets last_epoch to -1 to avoid the problem, though you will also lose the optimizer gradient and LR schedule:
Python code:
from utils.utils import *; create_backbone('weights/last.pt')
And then train (bash code):
python3 train.py --weights weights/backbone.pt
		</comment>
		<comment id='5' author='limingcv' date='2020-03-17T08:22:50Z'>
		Thanks a lot,  I will try it !
		</comment>
		<comment id='6' author='limingcv' date='2020-12-25T03:50:26Z'>
		It works with the code below that you mention, thanks
&lt;denchmark-code&gt;from utils.utils import *; create_backbone('weights/last.pt')
python3 train.py --weights weights/backbone.pt
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>