<bug id='592' author='myounus96' open_date='2019-11-06T13:06:39Z' closed_time='2019-11-06T16:39:30Z'>
	<summary>gpu is not utilized during training on windows</summary>
	<description>
Describe the bug
how to utilize gpu for training

here is the command I running
python train.py --data custom_obj/custom.data --cfg cfg/yolov3-spp-custom.cfg --weights weights/yolov3-spp.weights --transfer --epochs 55 --batch 8 --accumulate  4 --device 0

also tried --device 1,and got error of not founding gpu device at 1 like that
Desktop (please complete the following information):

OS: Windows
Version 10

	</description>
	<comments>
		<comment id='1' author='myounus96' date='2019-11-06T16:39:24Z'>
		Hello, thank you for your interest in our work! This is an automated response. Please note that most technical problems are due to:

Your changes to the default repository. If your issue is not reproducible in a fresh git clone version of this repository we can not debug it. Before going further run this code and ensure your issue persists:

sudo rm -rf yolov3  # remove exising repo
git clone https://github.com/ultralytics/yolov3 &amp;&amp; cd yolov3 # git clone latest
python3 detect.py  # verify detection
python3 train.py  # verify training (a few batches only)
# CODE TO REPRODUCE YOUR ISSUE HERE

Your custom data. If your issue is not reproducible with COCO data we can not debug it. Visit our Custom Training Tutorial for exact details on how to format your custom data. Examine train_batch0.jpg and test_batch0.jpg for a sanity check of training and testing data.
Your environment. If your issue is not reproducible in a GCP Quickstart Guide VM we can not debug it. Ensure you meet the requirements specified in the README: Unix, MacOS, or Windows with Python &gt;= 3.7, Pytorch &gt;= 1.1, etc. You can also use our Google Colab Notebook to test your code in working environment.

If none of these apply to you, we suggest you close this issue and raise a new one using the Bug Report template, providing screenshots and minimum viable code to reproduce your issue. Thank you!
		</comment>
		<comment id='2' author='myounus96' date='2019-11-07T06:58:09Z'>
		Currently I have python 3.6 let me try it with 3.7.
		</comment>
		<comment id='3' author='myounus96' date='2019-11-07T08:19:04Z'>
		still issue with python 3.7 :(.
		</comment>
		<comment id='4' author='myounus96' date='2019-11-07T17:58:52Z'>
		&lt;denchmark-link:https://github.com/m-younus&gt;@m-younus&lt;/denchmark-link&gt;
 a single GPU should work with windows, I think multiple GPUs no. In any case, windows is a bad environment for ML development work, you should try Google Colab for a free unix backend with GPU.
		</comment>
		<comment id='5' author='myounus96' date='2019-11-08T04:18:10Z'>
		I have single GPU(nvidia gtx 1050) :( .
		</comment>
		<comment id='6' author='myounus96' date='2019-11-08T04:18:58Z'>
		And it works fine with darknet with gpu,but I check your repo have higher mAP so I just wanna used your implementation.
		</comment>
		<comment id='7' author='myounus96' date='2019-11-09T18:44:03Z'>
		&lt;denchmark-link:https://github.com/m-younus&gt;@m-younus&lt;/denchmark-link&gt;
 GTX1050 maybe slower than the free K80 GPU you get with Colab. As I said already, try to use a Colab instance.
&lt;denchmark-link:https://colab.research.google.com/drive/1G8T-VFxQkjDe4idzN8F-hbIBqkkkQnxw&gt;https://colab.research.google.com/drive/1G8T-VFxQkjDe4idzN8F-hbIBqkkkQnxw&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>