<bug id='789' author='cloudrivers' open_date='2020-01-18T06:21:12Z' closed_time='2020-01-19T05:37:05Z'>
	<summary>Node has input size 4 not in range [min=2, max=2]</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

Hi, When I follow the advise to save a onnx model. But onnx.checker.check_model(model)  faild.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

Set ONNX_EXPORT to True
have torch.onnx.export(model, img, 'weights/michael_export.onnx', verbose=True, opset_version=11)
run detect.py

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

pytorch : 1.3.1
onnx: 1.5.0
python: 3.6.6
&lt;denchmark-h:h2&gt;Error info&lt;/denchmark-h&gt;

Traceback (most recent call last):
File "detect.py", line 178, in 
detect()
File "detect.py", line 52, in detect
onnx.checker.check_model(model)  # Check that the IR is well formed
File "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/onnx/checker.py", line 86, in check_model
C.check_model(model.SerializeToString())
onnx.onnx_cpp2py_export.checker.ValidationError: Node () has input size 4 not in range [min=2, max=2].
==&gt; Context: Bad node spec: input: "675" input: "698" input: "698" input: "697" output: "699" op_type: "Resize" attribute { name: "coordinate_transformation_mode" s: "asymmetric" type: STRING } attribute { name: "cubic_coeff_a" f: -0.75 type: FLOAT } attribute { name: "mode" s: "nearest" type: STRING } attribute { name: "nearest_mode" s: "floor" type: STRING }
	</description>
	<comments>
		<comment id='1' author='cloudrivers' date='2020-01-18T07:33:22Z'>
		&lt;denchmark-link:https://github.com/cloudrivers&gt;@cloudrivers&lt;/denchmark-link&gt;
 upgrading to onnx 1.6.0 should fix this.
		</comment>
		<comment id='2' author='cloudrivers' date='2020-01-18T08:00:16Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

After pip install onnx=1.6.0, a new error occurred.
Segmentation fault (core dumped)
		</comment>
		<comment id='3' author='cloudrivers' date='2020-01-18T12:20:31Z'>
		I have upgrade  pytorch to 1.4.0 and onnx to 1.6.0. it is still not work.
Namespace(agnostic_nms=False, cfg='cfg/yolov3.cfg', classes=None, conf_thres=0.3, device='', fourcc='mp4v', half=False, img_size=416, iou_thres=0.5, names='data/myclass.names', output='output', save_txt=False, source='data/samples', view_img=False, weights='weights/best.pt')
Using CPU
Segmentation fault (core dumped)
		</comment>
		<comment id='4' author='cloudrivers' date='2020-01-18T14:39:26Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Hi, I use onnxruntime to print the input &amp; output. I think there may something wrong when converting the onnx.
import onnxruntime
import numpy as np
import os
sess = onnxruntime.InferenceSession('./weights/best.onnx', None)
input_name = sess.get_inputs()[0].name
print("Input name  :", input_name)
input_shape = sess.get_inputs()[0].shape
print("Input shape :", input_shape)
input_type = sess.get_inputs()[0].type
print("Input type  :", input_type)
output_name = sess.get_outputs()[0].name
print("Output name  :", output_name)
output_shape = sess.get_outputs()[0].shape
print("Output shape :", output_shape)
output_type = sess.get_outputs()[0].type
print("Output type  :", output_type)
output_name = sess.get_outputs()[1].name
print("Output name  :", output_name)
output_shape = sess.get_outputs()[1].shape
print("Output shape :", output_shape)
output_type = sess.get_outputs()[1].type
print("Output type  :", output_type)
x = np.random.random(input_shape)
x = x.astype(np.float32)
result = sess.run([output_name], {input_name: x})
Input name  : input.1
Input shape : [1, 3, 320, 192]
Input type  : tensor(float)
Output name  : 839
Output shape : [3780, 1]
Output type  : tensor(float)
Output name  : 842
Output shape : [3780, 4]
Output type  : tensor(float)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Fail                                      Traceback (most recent call last)
 in ()
68 x = x.astype(np.float32)
69
---&gt; 70 result = sess.run([output_name], {input_name: x})
71
72 #print(result)
~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/onnxruntime/capi/session.py in run(self, output_names, input_feed, run_options)
140             output_names = [output.name for output in self._outputs_meta]
141         try:
--&gt; 142             return self._sess.run(output_names, input_feed, run_options)
143         except C.EPFail as err:
144             if self._enable_fallback:
Fail: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running Conv node. Name:'' Status Message: Input channels C is not equal to kernel channels * group. C: 513 kernel channels: 768 group: 1
		</comment>
		<comment id='5' author='cloudrivers' date='2020-01-18T19:48:29Z'>
		&lt;denchmark-link:https://github.com/cloudrivers&gt;@cloudrivers&lt;/denchmark-link&gt;
 note that in a conda environment on MacOS and Linux (such as we use), we had to install onnx using &lt;denchmark-link:https://github.com/onnx/onnx#linux-and-macos&gt;https://github.com/onnx/onnx#linux-and-macos&lt;/denchmark-link&gt;
:
conda install -c conda-forge protobuf numpy
pip install onnx
rather than directly with conda:
conda install -c conda-forge onnx
		</comment>
		<comment id='6' author='cloudrivers' date='2020-01-19T01:46:50Z'>
		Hi &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , I have finished a transfer learning with yolov3.weights for 1 classes. The mAP is even near 0.98. Both of the train and inference is done very well. Yeah your repo is wonderful !
However, I feel the onnx export for 1 classes with yolov3.weigthts may not function. because the official convert sample works well on curret onnx==1.6.0. But our code will Segmentation fault (core dumped). Bellow is the minimal test case, and it works in my env.
&lt;denchmark-h:h1&gt;Build a Mock Model in PyTorch with a convolution and a reduceMean layer&lt;/denchmark-h&gt;

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
import torch.onnx as torch_onnx
class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=1, padding=0, bias=False)
    def forward(self, inputs):
        x = self.conv(inputs)
        #x = x.view(x.size()[0], x.size()[1], -1)
        return torch.mean(x, dim=2)
input_shape = (3, 100, 100)
model_onnx_path = "torch_model.onnx"
model = Model()
model.train(False)
dummy_input = Variable(torch.randn(1, *input_shape))
output = torch_onnx.export(model, 
                          dummy_input, 
                          model_onnx_path, 
                          verbose=False)
print("Export of torch_model.onnx complete!")
		</comment>
		<comment id='7' author='cloudrivers' date='2020-01-19T05:37:05Z'>
		&lt;denchmark-link:https://github.com/cloudrivers&gt;@cloudrivers&lt;/denchmark-link&gt;
 for onnx bug issues, post your question on the onnx repo, for pytorch bug isses, post your question on the pytorch repo. This repo is not a catch-all to answer pytorch and onnx bugs.
		</comment>
		<comment id='8' author='cloudrivers' date='2020-01-19T10:29:38Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Hi, I think this is not a onnx or pytorch issue. It is convertion code has something wrong.
		</comment>
		<comment id='9' author='cloudrivers' date='2020-01-19T18:31:49Z'>
		&lt;denchmark-link:https://github.com/cloudrivers&gt;@cloudrivers&lt;/denchmark-link&gt;
 but your code to reproduce here &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/789#issuecomment-575956814&gt;#789 (comment)&lt;/denchmark-link&gt;
 contains no code from this repo. So if this code is causing problems, you must raise it on the relevant repo, not this one.
		</comment>
		<comment id='10' author='cloudrivers' date='2020-03-05T11:09:20Z'>
		&lt;denchmark-link:https://github.com/cloudrivers&gt;@cloudrivers&lt;/denchmark-link&gt;
  Have you solved your problem?
		</comment>
		<comment id='11' author='cloudrivers' date='2020-03-18T00:19:42Z'>
		
@glenn-jocher
After pip install onnx=1.6.0, a new error occurred.
Segmentation fault (core dumped)

So, after digging a bit into this issue, which affected me as well, I have found this &lt;denchmark-link:https://github.com/onnx/onnx/issues/2394#issuecomment-581638840&gt;onnx/onnx#2394 (comment)&lt;/denchmark-link&gt;
 solution. For me it worked. To summarize: apparently there's a dynamic loader issue, so you should import onnx in the first lines of your code, before a import torch is called. Just edit detect.py accordingly. Hope this helps.
		</comment>
		<comment id='12' author='cloudrivers' date='2020-03-25T23:32:27Z'>
		

@glenn-jocher
After pip install onnx=1.6.0, a new error occurred.
Segmentation fault (core dumped)

So, after digging a bit into this issue, which affected me as well, I have found this onnx/onnx#2394 (comment) solution. For me it worked. To summarize: apparently there's a dynamic loader issue, so you should import onnx in the first lines of your code, before a import torch is called. Just edit detect.py accordingly. Hope this helps.



@glenn-jocher
After pip install onnx=1.6.0, a new error occurred.
Segmentation fault (core dumped)

So, after digging a bit into this issue, which affected me as well, I have found this onnx/onnx#2394 (comment) solution. For me it worked. To summarize: apparently there's a dynamic loader issue, so you should import onnx in the first lines of your code, before a import torch is called. Just edit detect.py accordingly. Hope this helps.

This works on my end. Thanks BrunoVox, you saved my day.
		</comment>
	</comments>
</bug>