<bug id='222' author='fereenwong' open_date='2019-04-18T09:40:30Z' closed_time='2019-04-27T12:32:55Z'>
	<summary>mAP Code in test.py</summary>
	<description>
Thanks for sharing.
For the code in line 125 in test.py,  it seems to be a mistake as a correct prediction requires both correct classification and accuracy localization. In my view, the code below:
iou, bi = bbox_iou(pbox, tbox).max(0)
should be changed as:
iou, bi = bbox_iou(pbox, tbox[tcls == pcls]).max(0)
I am not sure if I am right, so feel free to correct me if I am wrong.
	</description>
	<comments>
		<comment id='1' author='fereenwong' date='2019-04-18T12:37:19Z'>
		&lt;denchmark-link:https://github.com/fereenwong&gt;@fereenwong&lt;/denchmark-link&gt;
 can you test against COCO to see what the effect of your change is on mAP?
		</comment>
		<comment id='2' author='fereenwong' date='2019-04-18T14:19:48Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 mAP drops to 23.7
		</comment>
		<comment id='3' author='fereenwong' date='2019-04-18T14:23:51Z'>
		&lt;denchmark-link:https://github.com/fereenwong&gt;@fereenwong&lt;/denchmark-link&gt;
 the mAP produced by this repo has been validated against pycocotools to within 1%:
&lt;denchmark-link:https://github.com/ultralytics/yolov3#map&gt;https://github.com/ultralytics/yolov3#map&lt;/denchmark-link&gt;

You can see at 416 pixels, we report 0.57 mAP, and pycocotools analysis of our JSON returns 0.565. At 608 pixels we report 0.611 mAP vs pycocotools 0.608.
If your proposed change causes our mAP to deviate substantially from pycocotools, we naturally can not accept it.
		</comment>
		<comment id='4' author='fereenwong' date='2019-04-19T08:04:27Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

I made a mistake since the index bi is changed when I modify the code:
iou, bi = bbox_iou(pbox, tbox).max(0)
as below:
iou, bi = bbox_iou(pbox, tbox[tcls == pcls]).max(0)
And I found that something changed in line 128 in test.py:
if iou &gt; iou_thres and bi not in detected:  # and pcls == tcls[bi]: correct[i] = 1 detected.append(bi)
Then, I did a test with the commented condition as below:
if iou &gt; iou_thres and bi not in detected and pcls == tcls[bi]: correct[i] = 1 detected.append(bi)
The mAP drops to 53.3
		</comment>
		<comment id='5' author='fereenwong' date='2019-04-19T10:31:19Z'>
		&lt;denchmark-link:https://github.com/fereenwong&gt;@fereenwong&lt;/denchmark-link&gt;
 yes I tried this change, but like you said the mAP drops (from 0.570 to 0.546) compared to the pycocotools mAP (0.565), so the alignment is closer without the update. I'm not sure of the cause.
		</comment>
		<comment id='6' author='fereenwong' date='2019-04-27T12:32:51Z'>
		&lt;denchmark-link:https://github.com/fereenwong&gt;@fereenwong&lt;/denchmark-link&gt;
 this should be fixed now in commit &lt;denchmark-link:https://github.com/ultralytics/yolov3/commit/e1850bf2342934ad85d129c26bf8023215c4aa03&gt;e1850bf&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='fereenwong' date='2019-10-01T14:45:12Z'>
		mAP bug is resolved with commit &lt;denchmark-link:https://github.com/ultralytics/yolov3/commit/84f0df6c34dbfcd6431f78db9e736fc558f6396f&gt;84f0df6&lt;/denchmark-link&gt;
. Problem was continuous integral vs 101-point interpolated integral (COCO method).
UPDATE: mAP only matches at 0.001 conf-thres, but computes much higher at 0.1 conf-thres. Problem remains.
		</comment>
	</comments>
</bug>