<bug id='674' author='Gaondong' open_date='2019-12-01T11:34:25Z' closed_time='2019-12-02T17:28:41Z'>
	<summary>default weight</summary>
	<description>
I saw there are many weights in hyp(train.py) , and I trained two class, and there is imbalance of labels in the dataset, eg(60000car and 6000 person), how could I change the hyp or loss function to get better performance .
I used FOCAL LOSS in objectness and classification loss to decay the imbalance but it don't work(GIOU LOSS is very high).
THE AP OF 2 CLASSES IS 0.78 and 0.49 by conf_thres=0.01 iou_thres= 0.5.
&lt;denchmark-link:https://user-images.githubusercontent.com/43692998/69913561-120fab00-1474-11ea-8cf5-41008376038f.png&gt;&lt;/denchmark-link&gt;

BEST WISHS.
	</description>
	<comments>
		<comment id='1' author='Gaondong' date='2019-12-02T01:19:57Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/43692998/69924134-baf5ee80-14e4-11ea-99fd-f77686d6b484.jpg&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/43692998/69924135-bb8e8500-14e4-11ea-8be2-d17f947a2e1f.png&gt;&lt;/denchmark-link&gt;

USE this  hyp ,without Focal loss and got the above result.
		</comment>
		<comment id='2' author='Gaondong' date='2019-12-02T01:51:04Z'>
		&lt;denchmark-link:https://github.com/Gaondong&gt;@Gaondong&lt;/denchmark-link&gt;
 this tuning work is something you will have to do by hand if you are not happy with your current results. You should start with the default hyps, and only adjust them manually if your 3 loss components are greatly different in magnitude.
Also, note that your first example validation obj loss is decreasing well, while in your second example is starts overfitting after 100 epochs (bad).
In both cases your validation classification loss is showing extreme overfitting, which is very bad.
I would not use focal loss, as it tends to cause overfitting.
You can also try starting from no weights using --weights ''.
		</comment>
		<comment id='3' author='Gaondong' date='2019-12-02T01:53:25Z'>
		In any case, 0.60 mAP is not a bad result at all. You probably want to simply start with all default settings and lower cls hyp to reduce the severe overfitting showing up (val classification).
		</comment>
		<comment id='4' author='Gaondong' date='2019-12-02T02:02:19Z'>
		
In any case, 0.60 mAP is not a bad result at all. You probably want to simply start with all default settings and lower cls hyp to reduce the severe overfitting showing up (val classification).

Thanks for your reply,  and what could I do about imbalances in the dataset labels. 60000car and 6000 person in 9000 pictures, the 0.6map(AP_car 0.75, AP_person 0.43),I want to improve the personâ€˜s AP performance
		</comment>
		<comment id='5' author='Gaondong' date='2019-12-02T02:07:01Z'>
		&lt;denchmark-link:https://github.com/Gaondong&gt;@Gaondong&lt;/denchmark-link&gt;
 you can collect more data, or evolve your hyperparameters &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/392&gt;#392&lt;/denchmark-link&gt;
.
You can also try Swish() activation functions or CIoU box loss. For swish create a cfg with activation=swish instead of activation=leaky.
For CIoU=True instead of GIoU=True here:



yolov3/utils/utils.py


         Line 362
      in
      3d91731






 giou = bbox_iou(pbox.t(), tbox[i], x1y1x2y2=False, GIoU=True)  # giou computation 





		</comment>
		<comment id='6' author='Gaondong' date='2019-12-02T02:11:23Z'>
		
@Gaondong you can collect more data, or evolve your hyperparameters #392.
You can also try Swish() activation functions or CIoU box loss. For swish create a cfg with activation=swish instead of activation=leaky.
For CIoU=True instead of GIoU=True here:



yolov3/utils/utils.py


         Line 362
      in
      3d91731






 giou = bbox_iou(pbox.t(), tbox[i], x1y1x2y2=False, GIoU=True)  # giou computation 






I am trying evolve the hyp, Thanks for your good advice.
		</comment>
		<comment id='7' author='Gaondong' date='2019-12-02T05:18:53Z'>
		
@Gaondong you can collect more data, or evolve your hyperparameters #392.
You can also try Swish() activation functions or CIoU box loss. For swish create a cfg with activation=swish instead of activation=leaky.
For CIoU=True instead of GIoU=True here:



yolov3/utils/utils.py


         Line 362
      in
      3d91731






 giou = bbox_iou(pbox.t(), tbox[i], x1y1x2y2=False, GIoU=True)  # giou computation 






&lt;denchmark-link:https://user-images.githubusercontent.com/43692998/69932378-dae9da00-1505-11ea-844c-1142c4d848e1.png&gt;&lt;/denchmark-link&gt;

After 50 epoch evolve I got the result  above.
Should I use the following code for 100 times at least , it seems need 2700 epoches!!
while true
do
python3 train.py --weights '' --prebias --img-size 512 --batch-size 16 --accumulate 4 --evolve --epochs 27 --device 4
done
		</comment>
		<comment id='8' author='Gaondong' date='2019-12-02T07:23:55Z'>
		&lt;denchmark-link:https://github.com/Gaondong&gt;@Gaondong&lt;/denchmark-link&gt;
 the hyps in evolve.txt start on column 8. Columns 1-7 are fitness metrics. The more you evolve the better (obviously).
		</comment>
		<comment id='9' author='Gaondong' date='2019-12-02T07:31:40Z'>
		
@Gaondong the hyps in evolve.txt start on column 8. Columns 1-7 are fitness metrics. The more you evolve the better (obviously).

I know this. I only have one GPU, so I can't train at 2700 epoch. Can I train 2-3 epochs per generation by 100 times?
		</comment>
		<comment id='10' author='Gaondong' date='2019-12-02T17:28:41Z'>
		Run your own experiments.
		</comment>
	</comments>
</bug>