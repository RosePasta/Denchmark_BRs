<bug id='864' author='BBuf' open_date='2020-02-22T12:56:16Z' closed_time='2020-02-25T01:32:25Z'>
	<summary>Why I can't get good result in my own datasets?</summary>
	<description>
&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
  Hello, I recently trained two of my private detection datasets using AlexeyAB DarkNet and your project, one of which is two categories and one of which is a category, and my target sizes are all regular. Then I can achieve mAP values of 99.5 +% and 96% + respectively on AlexeyAB DarkNet, but using your project can only reach mAP values of 80% + and 70% +, respectively. I also use GIOU Loss in the AlexeyAB code, and all use the default parameters in your project. In addition, I use YOLOV3-Tiny network. I wonder if there might be some problems with this code?
	</description>
	<comments>
		<comment id='1' author='BBuf' date='2020-02-22T17:49:54Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 this repo trains yolov3-spp.cfg on COCO to the highest mAP of any reported results we know. See &lt;denchmark-link:https://github.com/ultralytics/yolov3#map&gt;https://github.com/ultralytics/yolov3#map&lt;/denchmark-link&gt;

You may want to tune your hyperparameters &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/392&gt;#392&lt;/denchmark-link&gt;
 or switch from tiny to yolov3-spp.cfg. Other than that general guidance, we don't offer free support or feedback on training custom datasets. I'll leave the issue open for community feedback.
		</comment>
		<comment id='2' author='BBuf' date='2020-02-22T20:07:49Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 two other thoughts are that you may want to try better tiny derivatives like &lt;denchmark-link:https://github.com/ultralytics/yolov3/blob/master/cfg/yolov3-tiny3.cfg&gt;https://github.com/ultralytics/yolov3/blob/master/cfg/yolov3-tiny3.cfg&lt;/denchmark-link&gt;
, and that you should also try to test your darknet-trained models here to get an apples to apples mAP comparison:
&lt;denchmark-code&gt;python3 test.py --data ... --weights ... --cfg ...
&lt;/denchmark-code&gt;

And lastly, you need to look at your results.png for training feedback.
		</comment>
		<comment id='3' author='BBuf' date='2020-02-23T10:21:19Z'>
		OK, now I adjusted the batch_size of both projects to be the same, and then retrained YOLOV3-Tiny, the results are as follows:
In AlexeyAB DarkNet:
Train Loss And Map：
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75110278-39d37100-5667-11ea-97e9-d74e95a87fe8.png&gt;&lt;/denchmark-link&gt;

Use your code to test on the best weights model：
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75110417-f37f1180-5668-11ea-8247-33680e46e223.png&gt;&lt;/denchmark-link&gt;

In your project：
result.png
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75110316-a189bc00-5667-11ea-9695-bd707ea5f15b.png&gt;&lt;/denchmark-link&gt;

Use your code to test on the best pt model：
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75110431-14476700-5669-11ea-9486-7ef6cfdda5e9.png&gt;&lt;/denchmark-link&gt;

Apparently, the mAP and F1 scores of the AlexeyAB version of the model are higher than your project. I want to know why? In addition, when I tested, the conf-thres was set to 0.1
		</comment>
		<comment id='4' author='BBuf' date='2020-02-23T20:55:22Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 ah ok, this is a lot more info now. Yes, the darknet training is working better for you. The biggest problem I see with the ultralytics results are that the classification loss is about 10X larger compared to the GIoU and Objectness losses. The 3 should all be roughly in balance, so you probably want to reduce your  by up to 5X or 10X to bring it in line:


This is probably because the hyperparameters are tuned to an 80-class dataset, and you have a 2 class dataset. This is very interesting, maybe there's a way to automate this balancing in the future, perhaps using the mean losses after the first x epochs to adjust the hyps.
I would also cut the training time here down by half, as it looks like after 100 epochs you've already reached a steady state solution. Can you retrain with those two changes and see if it helps?
		</comment>
		<comment id='5' author='BBuf' date='2020-02-23T20:58:37Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 about the batch size, I recommend  if possible, or if you run out of CUDA memory then you can reduce this down, i.e.
python3 train.py --batch-size 64 --accum 1
python3 train.py --batch-size 32 --accum 2
python3 train.py --batch-size 16 --accum 4
are all roughly similar, but use less memory as you go down. --accum is the number of gradient accumulations before an optimizer update.
		</comment>
		<comment id='6' author='BBuf' date='2020-02-24T00:53:50Z'>
		Ok, I will try it, thank you。
		</comment>
		<comment id='7' author='BBuf' date='2020-02-24T03:15:24Z'>
		I changed 'cls': 37.4 to cls: 5.0 and got the following result：
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75126803-92058400-56f6-11ea-9cca-78b3f8f2380f.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75126848-c7aa6d00-56f6-11ea-8cf3-9178f878f0b8.png&gt;&lt;/denchmark-link&gt;

Looks like this hasn't improved significantly
		</comment>
		<comment id='8' author='BBuf' date='2020-02-24T04:36:44Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 yes, the losses are much better balanced now. You should reduce cls by half again to about 2.5, and depending on your dataset, you may also want to train with , which turns on multi-scale training. This is how we train COCO, and I think darknet has it on by default as well.
The other thing is you are training too long. As you can see, all of your results are already done by  epoch 100, so you should use --epochs 100:
python3 train.py --epochs 100 --multi ...
One last thing you could try is to apply a cosine LR scheduler, which shows improvement in COCO training. See &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/238#issuecomment-590027408&gt;#238 (comment)&lt;/denchmark-link&gt;
. You do this by commenting the current scheduler and uncommenting L139-140:



yolov3/train.py


        Lines 139 to 142
      in
      a3671bd






 # lf = lambda x: 0.5 * (1 + math.cos(x * math.pi / epochs))  # cosine https://arxiv.org/pdf/1812.01187.pdf 



 # scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf) 



 # scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=range(59, 70, 1), gamma=0.8)  # gradual fall to 0.1*lr0 



 scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[round(epochs * x) for x in [0.8, 0.9]], gamma=0.1) 





		</comment>
		<comment id='9' author='BBuf' date='2020-02-24T13:00:40Z'>
		I used all the improvements you mentioned above and got the following results:
&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75154384-8fcc1580-5748-11ea-9663-46abff8f8a2d.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/35585791/75154468-a7a39980-5748-11ea-9b96-238f2b294ac7.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='BBuf' date='2020-02-24T23:03:52Z'>
		&lt;denchmark-link:https://github.com/BBuf&gt;@BBuf&lt;/denchmark-link&gt;
 then you are all up to date with this repo. Class 2 exceeds darknet mAP, class 1 does not, overall mAP does not. I'd use the darknet trained results for your custom dataset.
		</comment>
		<comment id='11' author='BBuf' date='2020-02-25T01:32:20Z'>
		OK, thank you for your patience, then I will use the results of AlexeyAB DarkNet as the result of my custom data set.
		</comment>
		<comment id='12' author='BBuf' date='2020-09-07T09:46:37Z'>
		
@glenn-jocher Hello, I recently trained two of my private detection datasets using AlexeyAB DarkNet and your project, one of which is two categories and one of which is a category, and my target sizes are all regular. Then I can achieve mAP values of 99.5 +% and 96% + respectively on AlexeyAB DarkNet, but using your project can only reach mAP values of 80% + and 70% +, respectively. I also use GIOU Loss in the AlexeyAB code, and all use the default parameters in your project. In addition, I use YOLOV3-Tiny network. I wonder if there might be some problems with this code?

which repo do you use? yolov3 _darknet or yolov4 darknet repo? .....
		</comment>
	</comments>
</bug>