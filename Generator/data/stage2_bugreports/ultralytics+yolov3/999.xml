<bug id='999' author='tinothy22' open_date='2020-04-02T11:50:00Z' closed_time='2020-06-03T00:15:10Z'>
	<summary>my val classification is a bit abnormal</summary>
	<description>
&lt;denchmark-link:https://user-images.githubusercontent.com/53636618/78244972-327e6d80-7519-11ea-9a0c-d4ffd8d573f7.png&gt;&lt;/denchmark-link&gt;

my val classification looks different,Is it related to the default values of GIOU and cls? I lowered it to 1.2 and 3.5 respectively.
In addition, I change the values of GIOU and cls. The model MAP has not improved. What other methods can I use to improve my MAP?I think only 88% of the two classes classification are a bit too low
	</description>
	<comments>
		<comment id='1' author='tinothy22' date='2020-04-02T18:16:03Z'>
		&lt;denchmark-link:https://github.com/tinothy22&gt;@tinothy22&lt;/denchmark-link&gt;
 yes your val classification is overtraining fairly early on. We've seen this before when using pretrained weights, I'm not exactly sure why.
You could start from a backbone instead of fully pretrained weights, this might help:
--weights darknet53.conv.74
Also, you should train to at least 300 epochs. 50 will never produce optimal results.
		</comment>
		<comment id='2' author='tinothy22' date='2020-04-02T18:18:24Z'>
		&lt;denchmark-link:https://github.com/tinothy22&gt;@tinothy22&lt;/denchmark-link&gt;
 you could also play around with class label smoothing, by varying  from 0.01 to 0.10 perhaps. This is intended to prevent classification overfitting.



yolov3/utils/utils.py


        Lines 386 to 388
      in
      4ac6001






 # class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3 



 cp, cn = smooth_BCE(eps=0.0) 



 





		</comment>
		<comment id='3' author='tinothy22' date='2020-04-02T23:57:37Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 thank you for your guidence
		</comment>
		<comment id='4' author='tinothy22' date='2020-04-09T11:01:23Z'>
		I reused yolov3-tiny for training results and still overfit!
&lt;denchmark-link:https://user-images.githubusercontent.com/53636618/78888390-19833880-7a94-11ea-8988-e2fd3ecc3cb9.png&gt;&lt;/denchmark-link&gt;

I use eps=0.1 and it didn't get the effect.
&lt;denchmark-link:https://user-images.githubusercontent.com/53636618/78887922-4f73ed00-7a93-11ea-8aaf-7bc149f5a8ad.png&gt;&lt;/denchmark-link&gt;

I use yolov3-tiny.conv.15 and it still didn't work
&lt;denchmark-link:https://user-images.githubusercontent.com/53636618/78888051-8cd87a80-7a93-11ea-89ba-6f9b5a01e7af.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='tinothy22' date='2020-04-09T11:06:31Z'>
		I am puzzled, I also tried the adam optimizer, multi-scale, etc. have no effect, is there something wrong with my dataset?My data set has only two classes, a total of 7959 pictures, and a training set of 6737 pictures
		</comment>
		<comment id='6' author='tinothy22' date='2020-04-09T18:26:26Z'>
		&lt;denchmark-link:https://github.com/tinothy22&gt;@tinothy22&lt;/denchmark-link&gt;
 it looks like everything is working fine. If you are looking for better mAP I'd recommend switching to yolov3-spp.cfg and training from scratch --weights '', or training using the default pretrained --weights yolov3-spp-ultralytics.pt.
		</comment>
		<comment id='7' author='tinothy22' date='2020-04-09T18:27:19Z'>
		One thing I've noticed is that overtraining starts earlier when using pretrained weights, so if the val classification is increasing you should try instead training from scratch --weights ''.
		</comment>
		<comment id='8' author='tinothy22' date='2020-04-10T05:02:13Z'>
		I use yolov3-tiny.cfg train from scatch:
&lt;denchmark-link:https://user-images.githubusercontent.com/53636618/78963856-65cd8780-7b2b-11ea-844d-346cd9d02c79.png&gt;&lt;/denchmark-link&gt;

From the figure, it seems that there is a little overfitting, but from the data, it seems that it is still seriously overfitting?Below is the data of my last 5 epochs:
94/99     4.56G      1.12     0.855      1.06      3.04       115       576     0.843     0.836     0.848     0.839      1.31     0.835      1.41
95/99     4.56G      1.12     0.845      1.09      3.05        93       576     0.843     0.836     0.848     0.839      1.31     0.835      1.41
96/99     4.56G      1.11      0.87      1.07      3.05        79       576     0.843     0.836     0.848     0.839      1.31     0.835      1.41
97/99     4.56G      1.11     0.853      1.07      3.04        64       576     0.843     0.836     0.848      0.84      1.31     0.836      1.41
98/99     4.56G      1.11     0.862      1.06      3.03       147       576     0.843     0.836     0.848     0.839      1.31     0.836      1.41
99/99     4.56G       1.1     0.852      1.07      3.03        78       576     0.844     0.836     0.851      0.84      1.31     0.836      1.41
		</comment>
		<comment id='9' author='tinothy22' date='2020-04-17T03:01:06Z'>
		&lt;denchmark-link:https://github.com/tinothy22&gt;@tinothy22&lt;/denchmark-link&gt;
 your validation losses are not increasing in your results.png, there is no overfitting.
		</comment>
		<comment id='10' author='tinothy22' date='2020-04-17T13:47:57Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/37015371/79575759-d3ae1c00-80f4-11ea-8a13-54ce0f1156b8.png&gt;&lt;/denchmark-link&gt;

but mine is gone....
		</comment>
		<comment id='11' author='tinothy22' date='2020-04-17T19:28:06Z'>
		&lt;denchmark-link:https://github.com/PointCloudNiphon&gt;@PointCloudNiphon&lt;/denchmark-link&gt;
 you probably have nan values, check your results.txt.
		</comment>
		<comment id='12' author='tinothy22' date='2020-04-28T03:43:21Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Hello! My val losses are all very high during training. Is that normal? Maybe my test dataset is too small?(6557 images for train, 1311 images for test, my data are all chosen from coco 2017)
The following results use pretrained yolov3.pt.
&lt;denchmark-link:https://user-images.githubusercontent.com/41316711/80444483-6c8a3600-8944-11ea-9668-5e51d1ae030f.png&gt;&lt;/denchmark-link&gt;

The following results are trained from scratch.
&lt;denchmark-link:https://user-images.githubusercontent.com/41316711/80444858-58930400-8945-11ea-909a-08646b275dec.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='tinothy22' date='2020-04-28T03:54:20Z'>
		&lt;denchmark-link:https://github.com/tyb197&gt;@tyb197&lt;/denchmark-link&gt;
 see &lt;denchmark-link:https://github.com/ultralytics/yolov3#reproduce-our-results&gt;https://github.com/ultralytics/yolov3#reproduce-our-results&lt;/denchmark-link&gt;

I don't have a magic genie ball to declare your results either way, especially on a custom dataset I've never seen.
		</comment>
		<comment id='14' author='tinothy22' date='2020-05-29T00:14:47Z'>
		This issue is stale because it has been open 30 days with no activity. Remove Stale label or comment or this will be closed in 5 days.
		</comment>
	</comments>
</bug>