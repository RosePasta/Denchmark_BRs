<bug id='283' author='auniquesun' open_date='2019-05-16T08:15:50Z' closed_time='2019-05-20T02:23:05Z'>
	<summary>ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).</summary>
	<description>
I start training process on my Red Hat Enterprise Linux Server 7.4, after hundreds of iterations, the error always occurred: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm). What should I do to solve this problem? I need help.
	</description>
	<comments>
		<comment id='1' author='auniquesun' date='2019-05-18T09:52:00Z'>
		Hello, thank you for your interest in our work! This is an automated response. Please note that most technical problems are due to:

Your changes to the default repository. If your issue is not reproducible in a fresh git clone version of this repository we can not debug it. Before going further run this code and ensure your issue persists:

sudo rm -rf yolov3  # remove exising repo
git clone https://github.com/ultralytics/yolov3 &amp;&amp; cd yolov3 # git clone latest
python3 detect.py  # verify detection
python3 train.py  # verify training (a few batches only)
# CODE TO REPRODUCE YOUR ISSUE HERE

Your custom data. If your issue is not reproducible with COCO data we can not debug it. Visit our Custom Training Tutorial for exact details on how to format your custom data. Examine train_batch0.jpg and test_batch0.jpg for a sanity check of training and testing data.
Your environment. If your issue is not reproducible in a GCP Quickstart Guide VM we can not debug it. Ensure you meet the requirements specified in the README: Unix, MacOS, or Windows with Python &gt;= 3.7, Pytorch &gt;= 1.0, etc.

If none of these apply to you, we suggest you close this issue and raise a new one using the Bug Report template, providing screenshots and minimum viable code to reproduce your issue. Thank you!
		</comment>
		<comment id='2' author='auniquesun' date='2019-05-20T02:22:47Z'>
		hello &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 , I have solved this error by set "--num-workers 0" guided by the doc of PyTorch torch.utils.data DataLoader, thanks
		</comment>
		<comment id='3' author='auniquesun' date='2019-11-12T07:53:02Z'>
		"--num-workers 0"  will slow down training.
I fixed it by adding "--ipc=host" in my docker container configuration.
		</comment>
		<comment id='4' author='auniquesun' date='2019-11-12T22:24:05Z'>
		&lt;denchmark-link:https://github.com/mozpp&gt;@mozpp&lt;/denchmark-link&gt;
 yes, this is already the default usage in the dockerfile examples:
&lt;denchmark-link:https://github.com/ultralytics/yolov3/blob/master/Dockerfile&gt;https://github.com/ultralytics/yolov3/blob/master/Dockerfile&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='auniquesun' date='2020-02-02T14:48:37Z'>
		I fixed it by following this comment
&lt;denchmark-link:https://stackoverflow.com/a/59029085&gt;https://stackoverflow.com/a/59029085&lt;/denchmark-link&gt;

Hope it help!
		</comment>
		<comment id='6' author='auniquesun' date='2020-05-28T02:54:45Z'>
		&lt;denchmark-link:https://github.com/mozpp&gt;@mozpp&lt;/denchmark-link&gt;


"--num-workers 0" will slow down training.
I fixed it by adding "--ipc=host" in my docker container configuration.

How do you add this to a Docker file?
		</comment>
		<comment id='7' author='auniquesun' date='2020-05-28T03:58:19Z'>
		&lt;denchmark-link:https://github.com/mdanb&gt;@mdanb&lt;/denchmark-link&gt;
 see &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Docker-Quickstart&gt;https://github.com/ultralytics/yolov3/wiki/Docker-Quickstart&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>