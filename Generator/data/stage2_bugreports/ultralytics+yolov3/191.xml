<bug id='191' author='Niculuse' open_date='2019-04-05T13:37:22Z' closed_time='2019-04-06T12:36:43Z'>
	<summary>one class training</summary>
	<description>
When one class training is performed, the classification loss is always 0, because any N1 matrix is going to become a N1 matrix with all elements 1 after softmax operation in nn.CrossEntropyLoss(). Dose it matter? Do we need to modify codes to change it into a 2-class classificaiton problem, that's, we need to use background as another class?
Thanks!
	</description>
	<comments>
		<comment id='1' author='Niculuse' date='2019-04-05T14:34:43Z'>
		&lt;denchmark-link:https://github.com/Niculuse&gt;@Niculuse&lt;/denchmark-link&gt;
 the classification output neuron is clearly superfluous (not required) when training on only a single class. Leaving it in doesn't hurt though, it simply learns to always output the single class. If you want you can detach it from the loss function, or reconfigure your architecture to remove it entirely.
		</comment>
	</comments>
</bug>