<bug id='231' author='WannaSeaU' open_date='2019-04-22T12:50:37Z' closed_time='2019-04-23T14:01:25Z'>
	<summary>Dataloader BUG ValueError: sampler option is mutually exclusive with shuffle</summary>
	<description>
Describe the bug
ValueError: sampler option is mutually exclusive with shuffle
To Reproduce
`python  train.py
Additional context
I think the following codes in train.py lines 120-135 cause this error:
# Initialize distributed training
    if torch.cuda.device_count() &gt; 1:
        dist.init_process_group(backend=opt.backend, init_method=opt.dist_url, world_size=opt.world_size, rank=opt.rank)
        model = torch.nn.parallel.DistributedDataParallel(model)
        sampler = torch.utils.data.distributed.DistributedSampler(dataset)
    else:
        sampler = None

# Dataloader
    dataloader = DataLoader(dataset,
                            batch_size=batch_size,
                            num_workers=opt.num_workers,
                            shuffle=True,
                            pin_memory=True,
                            collate_fn=dataset.collate_fn,
                            sampler=sampler)
If there are multi-gpu available, sampler is not None, and parameter shuffer in dataloader is True, which leads to an error according to pytorch docs.
&lt;denchmark-link:url&gt;https://pytorch.org/docs/stable/_modules/torch/utils/data/dataloader.html&lt;/denchmark-link&gt;

class DataLoader(object):

    *******************

    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None,
                 num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False,
                 timeout=0, worker_init_fn=None):

        *******************

        if sampler is not None and shuffle:
            raise ValueError('sampler option is mutually exclusive with '
                             'shuffle')
	</description>
	<comments>
		<comment id='1' author='WannaSeaU' date='2019-04-22T13:57:31Z'>
		I'm wondering that is torch.utils.data.distributed.DistributedSampler necessary, or we can use default sampler with shuffle=True, in multi-gpu situations.
		</comment>
		<comment id='2' author='WannaSeaU' date='2019-04-22T20:41:36Z'>
		&lt;denchmark-link:https://github.com/WannaSeaU&gt;@WannaSeaU&lt;/denchmark-link&gt;
 thanks for the bug report! We  able to reproduce this issue. We may simply need to set shuffle=False.
		</comment>
		<comment id='3' author='WannaSeaU' date='2019-04-22T20:50:00Z'>
		&lt;denchmark-link:https://github.com/WannaSeaU&gt;@WannaSeaU&lt;/denchmark-link&gt;
 perhaps sampler=None is a better solution, both of the options seem to time with the same speed on GCP with 2 GPUs.
		</comment>
		<comment id='4' author='WannaSeaU' date='2019-04-22T21:29:41Z'>
		&lt;denchmark-link:https://github.com/WannaSeaU&gt;@WannaSeaU&lt;/denchmark-link&gt;
 Ok, I've removed the  argument from the Dataloader, so now it defaults to . This doesn't seem to have any ill effects.
		</comment>
		<comment id='5' author='WannaSeaU' date='2019-04-23T14:01:25Z'>
		Closing as I believe problem is now resolved.
		</comment>
	</comments>
</bug>