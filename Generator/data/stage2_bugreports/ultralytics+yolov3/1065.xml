<bug id='1065' author='huang475' open_date='2020-04-17T09:37:19Z' closed_time='2020-04-29T07:20:55Z'>
	<summary>need help, train on custom data get very bad results</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I am testing on my custom data, and get very bad results, need some helps on the things I should look for.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

create custom data config
train
observe bad result

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

Should be great?
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

If applicable, add screenshots to help explain your problem.
here's my results
&lt;denchmark-link:https://user-images.githubusercontent.com/5912803/79554995-7bb1ee00-80d1-11ea-9a48-6703a34fd54b.png&gt;&lt;/denchmark-link&gt;

some sample and annotation
&lt;denchmark-link:https://user-images.githubusercontent.com/5912803/79555160-b3209a80-80d1-11ea-8815-321c575393fa.png&gt;&lt;/denchmark-link&gt;

here's my hyper parameters
&lt;denchmark-code&gt;hyp = {'giou': 0.54,  # giou loss gain
       'cls': 3.4,  # cls loss gain
       'cls_pw': 1.0,  # cls BCELoss positive_weight
       'obj': 4.3,  # obj loss gain (*=img_size/320 if img_size != 320)
       'obj_pw': 1.0,  # obj BCELoss positive_weight
       'iou_t': 0.225,  # iou training threshold
       'lr0': 0.01,  # initial learning rate (SGD=5E-3, Adam=5E-4)
       'lrf': 0.0005,  # final learning rate (with cos scheduler)
       'momentum': 0.937,  # SGD momentum
       'weight_decay': 0.000484,  # optimizer weight decay
       'fl_gamma': 0.0,  # focal loss gamma (efficientDet default is gamma=1.5)
       'hsv_h': 0.0238,  # image HSV-Hue augmentation (fraction)
       'hsv_s': 0.778,  # image HSV-Saturation augmentation (fraction)
       'hsv_v': 0.46,  # image HSV-Value augmentation (fraction)
       'degrees': 1.98 * 0,  # image rotation (+/- deg)
       'translate': 0.05 * 0,  # image translation (+/- fraction)
       'scale': 0.05 * 0,  # image scale (+/- gain)
       'shear': 0.641 * 5}  # image shear (+/- deg)
&lt;/denchmark-code&gt;

here's my anchor settings:
anchors = 137,105, 328,581, 132,309, 66,111, 374,318, 72,162, 79,232, 483,363, 143,511, 564,576, 311,487, 258,229, 179,388, 124,189
image size is 512,  model config: yolov3.cfg ,  pretrained weights: darknet53.conv.74
Desktop (please complete the following information):

OS: [e.g. iOS] ubuntu
Version [e.g. 22] 19.04

Smartphone (please complete the following information):

Device: [e.g. iPhoneXS]
OS: [e.g. iOS8.1]
Version [e.g. 22]

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Add any other context about the problem here.
	</description>
	<comments>
		<comment id='1' author='huang475' date='2020-04-17T09:37:59Z'>
		Hello &lt;denchmark-link:https://github.com/huang475&gt;@huang475&lt;/denchmark-link&gt;
, thank you for your interest in our work! Please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov3/blob/master/tutorial.ipynb&gt;Google Colab Notebook&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov3&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart&gt;GCP Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
		</comment>
		<comment id='2' author='huang475' date='2020-04-17T19:34:25Z'>
		&lt;denchmark-link:https://github.com/huang475&gt;@huang475&lt;/denchmark-link&gt;
 your anchors are likely far too large. Also your hyperparameters are non standard. Recommend you train with all default settings, hyperparameters and anchors first. Also,  to get the latest updates.
		</comment>
		<comment id='3' author='huang475' date='2020-04-28T03:10:26Z'>
		I think initial learning rate lr0 is too big for 0.01. Reduce it to 0.001 usually helps!
		</comment>
	</comments>
</bug>