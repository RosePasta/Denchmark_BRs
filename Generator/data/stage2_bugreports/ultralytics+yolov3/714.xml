<bug id='714' author='Ronales' open_date='2019-12-13T13:19:09Z' closed_time='2020-01-16T19:16:46Z'>
	<summary>COCO Label Errors (duplicates/triplicate class 0 FPs)</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

A clear and concise description of what the bug is.
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

In augment,When i display the test_batch0.jpg.I find this error in final augment result,I think the bbox label encounter some problems when data augment.Some big boundingbox contain small boundingbox,but big box not true object.How to solve this augment problemÔºü

Thanks very muchÔºÅ
I use coco2017 detection dataset„ÄÇand using class is person and cellphone
&lt;denchmark-link:https://user-images.githubusercontent.com/20239826/70802787-62c8c180-1ded-11ea-9ece-cc4ff1cc3e18.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/20239826/70802926-c3f09500-1ded-11ea-9746-a3d613dccb59.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/20239826/70803227-8809ff80-1dee-11ea-8413-fcb785d053eb.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Ronales' date='2019-12-13T18:38:19Z'>
		&lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 oh thats very interesting, thank you for the bug report!
Do you get this on default COCO or is it something your changes produced (for person and cellphone only?)
Is there a set of reproducible code you could supply which produces the error?
		</comment>
		<comment id='2' author='Ronales' date='2019-12-13T18:42:46Z'>
		What is the image size that you trained on?
		</comment>
		<comment id='3' author='Ronales' date='2019-12-13T19:10:30Z'>
		&lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/FranciscoReveriano&gt;@FranciscoReveriano&lt;/denchmark-link&gt;
 I am able to reproduce this using the following images in test.py:
&lt;denchmark-code&gt;../coco/images/val2014/COCO_val2014_000000000357.jpg
../coco/images/train2014/COCO_train2014_000000419904.jpg
../coco/images/val2014/COCO_val2014_000000353148.jpg
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70825162-a34a2000-1d98-11ea-92ed-992f0e86759f.jpg&gt;&lt;/denchmark-link&gt;

I see them also if I use the same images to train. The next step is to see if the boxes are in the COCO labels text files themselves, or whether this repo is generating them accidentally.
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70825337-09cf3e00-1d99-11ea-9aed-8c7ba1bed2d0.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Ronales' date='2019-12-13T19:22:00Z'>
		The labels are below. The issue seems to originate in the official COCO labels themselves, so there is nothing we can do about this short of modifying the actual labels.
We could introduce error checking logic that eliminates duplicates alltogethor (or leaves 1 at most, which may help since it seems a fraction of these occurrences are labelled multiple times.
The large box on the baseball field seems to be a class 0 (person) box. It's also duplicated (not sure if this is coincidence or not).
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70825669-cf19d580-1d99-11ea-9c2e-98e4b3e894c3.png&gt;&lt;/denchmark-link&gt;

In the motorcycle image, there is again a class 0 label with a width of 0.95 causing the problem. This time it's triplicated.
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70825839-3899e400-1d9a-11ea-877c-e010086f4f51.png&gt;&lt;/denchmark-link&gt;

On the beach the only wide object I see is a class 0 (person again) in the last row, this time the label is by itself.
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70825956-87e01480-1d9a-11ea-81ef-bcd85b49aaee.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='Ronales' date='2019-12-13T20:11:22Z'>
		&lt;denchmark-link:https://github.com/joehoeller&gt;@joehoeller&lt;/denchmark-link&gt;
 could you try and see if these duplicated labels are present in the COCO json files? The most egregious one is the  motorcycle photo. The last 3 labels that we have (in *.txt format) show a nonexistant class zero person with a width of the 0.95 of the image in triplicate.
The duplicate labels seem pervasive in our *.txt labels, I'm trying to figure out if perhaps something about the JSON to txt file export process created them by accident.
		</comment>
		<comment id='6' author='Ronales' date='2019-12-13T20:14:19Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 sure no prob, are you using Dark Chocolate to convert, or....?
		</comment>
		<comment id='7' author='Ronales' date='2019-12-13T20:22:16Z'>
		&lt;denchmark-link:https://github.com/joehoeller&gt;@joehoeller&lt;/denchmark-link&gt;
 well that's the weird thing, I've never actually converted any COCO jsons to darknet *.txt.
The COCO labels can currently be downloaded with:

bash yolov3/data/get_coco_dataset.sh
bash yolov3/data/get_coco_dataset_gdrive.sh

The first one is a copy of the darknet download bash file which takes zips directly from pjreddie's server (the original yolo author). The second one is a cleanup I did of the first one (there was 1 corrupted image), which I uploaded as a single zip to Google Drive:
&lt;denchmark-link:https://drive.google.com/uc?export=download&amp;id=1WQT6SOktSe8Uw6r10-2JhbEhMY5DJaph&gt;https://drive.google.com/uc?export=download&amp;id=1WQT6SOktSe8Uw6r10-2JhbEhMY5DJaph&lt;/denchmark-link&gt;

So in all this time I've never actually exported the JSONs to darknet. This duplicate label issue is present in the Google Drive labels, which probably means its present in the pjreddie labels, but I don't know if the official COCO JSONs also show it.
Can you check if Dark Chocolate is making the same problem with COCO_val2014_000000353148?
		</comment>
		<comment id='8' author='Ronales' date='2019-12-13T20:32:10Z'>
		&lt;denchmark-link:https://github.com/joehoeller&gt;@joehoeller&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 the coco website doesn't show boxes anymore, only outlines, but there is no sign of an error there.
I also checked the original darknet labels just now (bash yolov3/data/get_coco_dataset.sh), and the FP duplicates are there as well.
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70830087-46ecfd80-1da4-11ea-8b0c-31772b20d88b.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='Ronales' date='2019-12-13T20:33:26Z'>
		No sir, I just generated all of those and tested. I will also denote I use FP (Functional Programming) code design patterns, so I dont have any loops or mutations, and my functions maintain state/referential transparency to avoid bugs like this.
&lt;denchmark-link:https://user-images.githubusercontent.com/5199900/70830082-077add00-1db5-11ea-828b-ed11e39f0e24.png&gt;&lt;/denchmark-link&gt;

Sample  .txt files in Darknet from DarkChocolate:
&lt;denchmark-link:https://user-images.githubusercontent.com/5199900/70830493-e8307f80-1db5-11ea-8a9b-31b4d302cf42.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/5199900/70830494-e8307f80-1db5-11ea-973e-f37b286f1dcf.png&gt;&lt;/denchmark-link&gt;

This is the JSON output where one can validate via darkchocolate key, with values above it to check the math in the event of any changes to COCO or Darknet:
&lt;denchmark-code&gt;[  
   {  
      'id':10,
      'image_id':10,
      'coco_class':'1',
      'x':32,
      'y':229,
      'bbox_width':22,
      'bbox_height':55,
      'img_width':640,
      'img_height':512,
      'output':'FLIR_00010.txt',
      'darkchocolate':[  
         0,
         0.0671875,
         0.5009765625,
         0.034375,
         0.107421875
      ]
   },
   {  
      'id':10,
      'image_id':10,
      'coco_class':'3',
      'x':174,
      'y':225,
      'bbox_width':39,
      'bbox_height':30,
      'img_width':640,
      'img_height':512,
      'output':'FLIR_00010.txt',
      'darkchocolate':[  
         2,
         0.30234375,
         0.46875,
         0.0609375,
         0.05859375
 ...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='Ronales' date='2019-12-13T20:38:28Z'>
		In reference to the above, do a cntrl+f to do a find for 00002, and you'll see the JSON matches the screenshots for the output of Darknet format from Dark Chocolate.
		</comment>
		<comment id='11' author='Ronales' date='2019-12-14T00:13:47Z'>
		&lt;denchmark-link:https://github.com/joehoeller&gt;@joehoeller&lt;/denchmark-link&gt;
 ok thanks buddy
&lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 I found out the problem was caused by COCO annotations with  dictionary values. I tried to reparse the COCO dataset ignoring entries where this value was , and now the issue seems resolved.
I've re-uploaded a new COCO dataset with the corrections that you can download using  or going to &lt;denchmark-link:https://drive.google.com/open?id=1WQT6SOktSe8Uw6r10-2JhbEhMY5DJaph&gt;https://drive.google.com/open?id=1WQT6SOktSe8Uw6r10-2JhbEhMY5DJaph&lt;/denchmark-link&gt;
 (same URL and same bash file, nothing has change there).
The new dataset has a simplified directory structure which created a breaking change for the tutorial datasets, so if you are using those please git pull or reclone and try everything again.
Again thanks for spotting this &lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
! In total I saw almost 5000 affected images, so this should have a positive impact on  COCO training results going forward :)
&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/70839758-254f3e80-1dc3-11ea-92ee-f3493abfa4bb.jpg&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='Ronales' date='2019-12-14T01:14:02Z'>
		Nice catch guys!
&lt;denchmark-link:#&gt;‚Ä¶&lt;/denchmark-link&gt;


On Fri, Dec 13, 2019 at 6:13 PM Glenn Jocher ***@***.***&gt; wrote:
 @joehoeller &lt;https://github.com/joehoeller&gt; ok thanks buddy

 @Ronales &lt;https://github.com/Ronales&gt; I found out the problem was caused
 by COCO annotations with 'iscrowd' dictionary keys. I tried to reparse the
 COCO dataset ignoring entries where this key was True, and now the issue
 seems resolved.

 I've re-uploaded a new COCO dataset with the corrections that you can
 download using bash yolov3/data/get_coco_dataset_gdrive.sh or going to
 https://drive.google.com/open?id=1WQT6SOktSe8Uw6r10-2JhbEhMY5DJaph

 The new dataset has a simplified directory structure which created a
 breaking change for the tutorial datasets, so if you are using those please
 git pull or reclone and try everything again.

 Again thanks for spotting this @Ronales &lt;https://github.com/Ronales&gt;! In
 total I saw almost 5000 affected images, so this should have a positive
 impact on COCO training results going forward :)

 [image: test_batch0]
 &lt;https://user-images.githubusercontent.com/26833433/70839758-254f3e80-1dc3-11ea-92ee-f3493abfa4bb.jpg&gt;

 ‚Äî
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#714?email_source=notifications&amp;email_token=ABHVQHES22CRZ3OBUUFK4WDQYQQLZA5CNFSM4J2M5MO2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEG3T4GI#issuecomment-565657113&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ABHVQHFUHSK2JKK7XVQTOQTQYQQLZANCNFSM4J2M5MOQ&gt;
 .



		</comment>
		<comment id='13' author='Ronales' date='2019-12-14T02:17:58Z'>
		&lt;denchmark-link:https://github.com/joehoeller&gt;@joehoeller&lt;/denchmark-link&gt;

Thanks for your reply!if I choose to download new coco dataset you support,May be the time cost is high,so I notice this is original  COCO annotations problems,Can you share ture annotations to me?
Or what should I do to close the COCO annotations 'iscrowd' = True means "iscrowd": 1 ? If i just modify the  'iscrowd' = True to 'iscrowd' = 0? meanwhile,I don't do anything to other files such as images .Can I solve this problem?
&lt;denchmark-link:https://user-images.githubusercontent.com/20239826/70842321-19b05600-1e5d-11ea-89aa-641f5f772a61.png&gt;&lt;/denchmark-link&gt;

Thanks!
		</comment>
		<comment id='14' author='Ronales' date='2019-12-14T02:32:16Z'>
		In my previous train or test experiment,I have notice this coco label errors,but I just think this is an accidental error until I find a great deal of labels bug.
If we provide a good method,That's a nice thing!
		</comment>
		<comment id='15' author='Ronales' date='2019-12-14T22:25:56Z'>
		&lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 I've updated the repo and the data now, so all you need to do is  a fresh copy and run again. I corrected the mistakes in the COCO2014 dataset, and I also added COCO2017 (new default).
You can use bash yolov3/data/coco2014.sh or bash yolov3/data/coco2017.sh:
rm -rf yolov3  # remove
git clone https://github.com/ultralytics/yolov3
bash yolov3/data/get_coco2017.sh
cd yolov3
python3 train.py --data coco.data  # 2017 default, or --data coco2014.data
		</comment>
		<comment id='16' author='Ronales' date='2019-12-16T02:46:12Z'>
		Dear authorÔºåI have download new default coco2017 from you,but how can I only choose centain class to train rather than all classes?
Can I create thresholdto filter coverted label txt to fix above mentioned overlap problems?or other solve method to acheive no overlap label.
Thanks forv your reply.
		</comment>
		<comment id='17' author='Ronales' date='2019-12-17T00:33:18Z'>
		&lt;denchmark-link:https://github.com/Ronales&gt;@Ronales&lt;/denchmark-link&gt;
 to only train certain classes you'd have to modify your label files by deleting the rows you are not interested in, or modify the dataset function to ignore these classes:


		</comment>
		<comment id='18' author='Ronales' date='2019-12-17T02:49:24Z'>
		I get it! Thanks for your reply.
		</comment>
		<comment id='19' author='Ronales' date='2020-01-16T19:16:46Z'>
		I'll close this issue for now as the original issue appears to have been resolved, and/or no activity has been seen for some time. Feel free to comment if this is not the case.
		</comment>
		<comment id='20' author='Ronales' date='2020-05-27T01:30:41Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Hi,
Did you reject only labels iscrowd=1, or whole images with iscrowd=1?
		</comment>
		<comment id='21' author='Ronales' date='2020-05-27T02:23:51Z'>
		Only labels.
		</comment>
		<comment id='22' author='Ronales' date='2020-07-13T21:13:16Z'>
		Is it a regular practice to ignore iscrowd annotations? Are SOTA measured on val/test sets with or without the iscrowd annotation? I don't see much information on this subject, maybe best algorithms can't really be compared if they train or evaluate on different labels
edit: solved my own question after searching for more informations AlexeyAB/darknet#5567 (comment)
		</comment>
	</comments>
</bug>