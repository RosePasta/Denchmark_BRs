<bug id='609' author='Pari-singh' open_date='2019-11-13T02:10:11Z' closed_time='2019-11-13T02:56:36Z'>
	<summary>Training error for custom data using transfer learning</summary>
	<description>
Hi, I created the dataset as mentioned in the custom data training and everything seems good. But when I run the training command, I get this error:
0%|          | 0/659 [00:00&lt;?, ?it/s]Traceback (most recent call last):
File "train.py", line 438, in 
train()  # train normally
File "train.py", line 237, in train
for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
File "/my_project/lib/python3.5/site-packages/tqdm/std.py", line 1091, in iter
for obj in iterable:
File "/my_project/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 819, in next
return self._process_data(data)
File "i/my_project/lib/python3.5/site-packages/torch/utils/data/dataloader.py", line 846, in _process_data
data.reraise()
File "/my_project/lib/python3.5/site-packages/torch/_utils.py", line 385, in reraise
raise self.exc_type(msg)
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
File "my_project/lib/python3.5/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
data = fetcher.fetch(index)
File "my_project/lib/python3.5/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
data = [self.dataset[idx] for idx in possibly_batched_index]
File "/my_project/lib/python3.5/site-packages/torch/utils/data/_utils/fetch.py", line 44, in 
data = [self.dataset[idx] for idx in possibly_batched_index]
File "yolov3/utils/datasets.py", line 416, in getitem
img, labels = load_mosaic(self, index)
File "yolov3/utils/datasets.py", line 593, in load_mosaic
labels4 = np.concatenate(labels4, 0)
File "&lt;array_function internals&gt;", line 6, in concatenate
ValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 2 has 1 dimension(s)
I am not sure why is this creating a trouble and how to fix this. I am following the steps mentioned and have done it previously successfully as well on different dataset. Any guidance will be appreciated.
Thanks
	</description>
	<comments>
		<comment id='1' author='Pari-singh' date='2019-11-13T02:56:24Z'>
		&lt;denchmark-link:https://github.com/Pari-singh&gt;@Pari-singh&lt;/denchmark-link&gt;
 well I'd say the culprit is clearly your custom cfg. You need to start from a working cfg like yolov3-spp.cfg and incrementally make your changes without breaking the parser.
		</comment>
		<comment id='2' author='Pari-singh' date='2019-11-13T02:58:37Z'>
		Also, the code to reproduce is available here. Start from there to verify your environment works and then start applying your changes incrementally.  When it stops working you'll know exactly why.
&lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data#reproduce-our-results&gt;https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data#reproduce-our-results&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Pari-singh' date='2019-11-13T13:13:22Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Thanks for the reply. I realised in train.py, there is a comment near the lines:
elif len(weights) &gt; 0:  # darknet format
# possible weights are 'yolov3.weights', 'yolov3-tiny.conv.15',  'darknet53.conv.74' etc.
cutoff = load_darknet_weights(model, weights)
which says possible weights can be from those? I am giving yolov3-spp.weights as an argument, I hope that is not an issue?
		</comment>
		<comment id='4' author='Pari-singh' date='2019-11-13T18:21:24Z'>
		&lt;denchmark-link:https://github.com/Pari-singh&gt;@Pari-singh&lt;/denchmark-link&gt;
 any darkest weights are fine.
		</comment>
	</comments>
</bug>