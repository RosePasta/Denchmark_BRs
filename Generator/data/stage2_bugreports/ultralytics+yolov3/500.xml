<bug id='500' author='souvik3333' open_date='2019-09-15T12:15:17Z' closed_time='2019-09-15T12:22:29Z'>
	<summary>Error when using last.pt for object detection after custom training</summary>
	<description>
I trained as mentioned in  &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/192&gt;#192&lt;/denchmark-link&gt;
 on data/coco_16img.data file. After training is done when I am trying to detect object on last.pt it's giving following error.
Also I have tried using backupX.pt files in weight folder. They are giving same error. Only yolov3.weights is working without any error.
Namespace(cfg='cfg/yolov3.cfg', conf_thres=0.3, data='data/coco.data', device='', fourcc='mp4v', half=False, img_size=416, nms_thres=0.5, output='output', source='beauty-3428550_1280.jpg', weights='weights/last.pt')
Using CUDA device0 _CudaDeviceProperties(name='Tesla K80', total_memory=11441MB)
Traceback (most recent call last):
File "detect.py", line 149, in 
detect()
File "detect.py", line 26, in detect
model.load_state_dict(torch.load(weights, map_location=device)['model'])
File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 777, in load_state_dict
self.class.name, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for Darknet:
Missing key(s) in state_dict: "module_list.78.Conv2d.weight", "module_list.78.BatchNorm2d.weight", "module_list.78.BatchNorm2d.bias", "module_list.78.BatchNorm2d.running_mean", "module_list.78.BatchNorm2d.running_var", "module_list.79.Conv2d.weight", "module_list.79.BatchNorm2d.weight", "module_list.79.BatchNorm2d.bias", "module_list.79.BatchNorm2d.running_mean", "module_list.79.BatchNorm2d.running_var", "module_list.80.Conv2d.weight", "module_list.80.BatchNorm2d.weight", "module_list.80.BatchNorm2d.bias", "module_list.80.BatchNorm2d.running_mean", "module_list.80.BatchNorm2d.running_var", "module_list.81.Conv2d.weight", "module_list.81.Conv2d.bias", "module_list.88.BatchNorm2d.weight", "module_list.88.BatchNorm2d.bias", "module_list.88.BatchNorm2d.running_mean", "module_list.88.BatchNorm2d.running_var", "module_list.89.Conv2d.weight", "module_list.89.BatchNorm2d.weight", "module_list.89.BatchNorm2d.bias", "module_list.89.BatchNorm2d.running_mean", "module_list.89.BatchNorm2d.running_var", "module_list.90.Conv2d.weight", "module_list.90.BatchNorm2d.weight", "module_list.90.BatchNorm2d.bias", "module_list.90.BatchNorm2d.running_mean", "module_list.90.BatchNorm2d.running_var", "module_list.92.Conv2d.weight", "module_list.92.BatchNorm2d.weight", "module_list.92.BatchNorm2d.bias", "module_list.92.BatchNorm2d.running_mean", "module_list.92.BatchNorm2d.running_var", "module_list.93.Conv2d.weight", "module_list.93.Conv2d.bias", "module_list.100.BatchNorm2d.weight", "module_list.100.BatchNorm2d.bias", "module_list.100.BatchNorm2d.running_mean", "module_list.100.BatchNorm2d.running_var", "module_list.101.Conv2d.weight", "module_list.101.BatchNorm2d.weight", "module_list.101.BatchNorm2d.bias", "module_list.101.BatchNorm2d.running_mean", "module_list.101.BatchNorm2d.running_var", "module_list.102.Conv2d.weight", "module_list.102.BatchNorm2d.weight", "module_list.102.BatchNorm2d.bias", "module_list.102.BatchNorm2d.running_mean", "module_list.102.BatchNorm2d.running_var", "module_list.104.Conv2d.weight", "module_list.104.BatchNorm2d.weight", "module_list.104.BatchNorm2d.bias", "module_list.104.BatchNorm2d.running_mean", "module_list.104.BatchNorm2d.running_var", "module_list.105.Conv2d.weight", "module_list.105.Conv2d.bias".
Unexpected key(s) in state_dict: "module_list.107.Conv2d.weight", "module_list.107.BatchNorm2d.weight", "module_list.107.BatchNorm2d.bias", "module_list.107.BatchNorm2d.running_mean", "module_list.107.BatchNorm2d.running_var", "module_list.107.BatchNorm2d.num_batches_tracked", "module_list.108.Conv2d.weight", "module_list.108.BatchNorm2d.weight", "module_list.108.BatchNorm2d.bias", "module_list.108.BatchNorm2d.running_mean", "module_list.108.BatchNorm2d.running_var", "module_list.108.BatchNorm2d.num_batches_tracked", "module_list.109.Conv2d.weight", "module_list.109.BatchNorm2d.weight", "module_list.109.BatchNorm2d.bias", "module_list.109.BatchNorm2d.running_mean", "module_list.109.BatchNorm2d.running_var", "module_list.109.BatchNorm2d.num_batches_tracked", "module_list.110.Conv2d.weight", "module_list.110.BatchNorm2d.weight", "module_list.110.BatchNorm2d.bias", "module_list.110.BatchNorm2d.running_mean", "module_list.110.BatchNorm2d.running_var", "module_list.110.BatchNorm2d.num_batches_tracked", "module_list.111.Conv2d.weight", "module_list.111.BatchNorm2d.weight", "module_list.111.BatchNorm2d.bias", "module_list.111.BatchNorm2d.running_mean", "module_list.111.BatchNorm2d.running_var", "module_list.111.BatchNorm2d.num_batches_tracked", "module_list.112.Conv2d.weight", "module_list.112.Conv2d.bias", "module_list.85.Conv2d.weight", "module_list.85.BatchNorm2d.weight", "module_list.85.BatchNorm2d.bias", "module_list.85.BatchNorm2d.running_mean", "module_list.85.BatchNorm2d.running_var", "module_list.85.BatchNorm2d.num_batches_tracked", "module_list.86.Conv2d.weight", "module_list.86.BatchNorm2d.weight", "module_list.86.BatchNorm2d.bias", "module_list.86.BatchNorm2d.running_mean", "module_list.86.BatchNorm2d.running_var", "module_list.86.BatchNorm2d.num_batches_tracked", "module_list.88.Conv2d.bias", "module_list.94.Conv2d.weight", "module_list.94.BatchNorm2d.weight", "module_list.94.BatchNorm2d.bias", "module_list.94.BatchNorm2d.running_mean", "module_list.94.BatchNorm2d.running_var", "module_list.94.BatchNorm2d.num_batches_tracked", "module_list.95.Conv2d.weight", "module_list.95.BatchNorm2d.weight", "module_list.95.BatchNorm2d.bias", "module_list.95.BatchNorm2d.running_mean", "module_list.95.BatchNorm2d.running_var", "module_list.95.BatchNorm2d.num_batches_tracked", "module_list.97.Conv2d.weight", "module_list.97.BatchNorm2d.weight", "module_list.97.BatchNorm2d.bias", "module_list.97.BatchNorm2d.running_mean", "module_list.97.BatchNorm2d.running_var", "module_list.97.BatchNorm2d.num_batches_tracked", "module_list.98.Conv2d.weight", "module_list.98.BatchNorm2d.weight", "module_list.98.BatchNorm2d.bias", "module_list.98.BatchNorm2d.running_mean", "module_list.98.BatchNorm2d.running_var", "module_list.98.BatchNorm2d.num_batches_tracked", "module_list.100.Conv2d.bias", "module_list.106.Conv2d.weight", "module_list.106.BatchNorm2d.weight", "module_list.106.BatchNorm2d.bias", "module_list.106.BatchNorm2d.running_mean", "module_list.106.BatchNorm2d.running_var", "module_list.106.BatchNorm2d.num_batches_tracked".
size mismatch for module_list.84.Conv2d.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).
size mismatch for module_list.84.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.84.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.84.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.84.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.87.Conv2d.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 768, 1, 1]).
size mismatch for module_list.87.BatchNorm2d.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.87.BatchNorm2d.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.87.BatchNorm2d.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.87.BatchNorm2d.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([256]).
size mismatch for module_list.88.Conv2d.weight: copying a param with shape torch.Size([255, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).
size mismatch for module_list.96.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).
size mismatch for module_list.96.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.96.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.96.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.96.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.99.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 384, 1, 1]).
size mismatch for module_list.99.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.99.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.99.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.99.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128]).
size mismatch for module_list.100.Conv2d.weight: copying a param with shape torch.Size([255, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).
To Reproduce:
Used commands:
python3 train.py --data data/coco_16img.data
python3 detect.py --cfg cfg/yolov3.cfg --weights weights/last.pt --source test.jpg
	</description>
	<comments>
		<comment id='1' author='souvik3333' date='2019-09-15T12:22:29Z'>
		Ok, got the error. I have to convert .pt to .weight format.
		</comment>
		<comment id='2' author='souvik3333' date='2019-09-16T11:56:28Z'>
		You trained yolov3-spp.cfg but then tried to run inference with yolov3.cfg, causing the error.
		</comment>
		<comment id='3' author='souvik3333' date='2019-11-25T21:05:13Z'>
		See &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/657&gt;#657&lt;/denchmark-link&gt;

This error is caused by a user supplying incompatible --weights and --cfg arguments. To solve this you must specify no weights (i.e. random initialization of the model) using --weights '' and any --cfg, or use a --cfg that is compatible with your --weights. If none are specified, the defaults are --weights ultralytics49.pt and --cfg cfg/yolov3-spp.cfg.
Examples of compatible combinations are:
python3 train.py --weights yolov3.pt --cfg cfg/yolov3.cfg
python3 train.py --weights yolov3.weights --cfg cfg/yolov3.cfg
python3 train.py --weights yolov3-spp.pt --cfg cfg/yolov3-spp.cfg
python3 train.py --weights ultralytics49.pt --cfg cfg/yolov3-spp.cfg
python3 train.py --weights '' --cfg cfg/*.cfg  # any cfg will work here
 is currently the highest performing YOLOv3 model (trained from scratch using this repo) available at the default  of 416 (see &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/310&gt;#310&lt;/denchmark-link&gt;
), which is the reason it is used as the default backbone.
		</comment>
	</comments>
</bug>