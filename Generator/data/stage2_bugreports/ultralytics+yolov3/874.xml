<bug id='874' author='Lornatang' open_date='2020-02-27T08:31:56Z' closed_time='2020-02-27T19:30:07Z'>
	<summary>A warning that could lead to incorrect test results</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

I noticed that you defined iou= 0.5 when initializing the test function, but you changed the size to iou=0.6 during the actual call„ÄÇ
&lt;denchmark-h:h2&gt;To Reproduce&lt;/denchmark-h&gt;

Steps to reproduce the behavior:

This problem in test.py 17 line.

&lt;denchmark-code&gt;def test(cfg,
         data,
         weights=None,
         batch_size=16,
         img_size=416,
         conf_thres=0.001,
--&gt;      iou_thres=0.5,  # for nms
         save_json=False,
         single_cls=False,
         model=None,
         dataloader=None):
&lt;/denchmark-code&gt;


But you're in the middle of the actual invocation

&lt;denchmark-code&gt;parser.add_argument('--iou-thres', type=float, default=0.6, help='IOU threshold for NMS')
...
    if opt.task == 'test':  # task = 'test', 'study', 'benchmark'
        # Test
        test(opt.cfg,
             opt.data,
             opt.weights,
             opt.batch_size,
             opt.img_size, 
             opt.conf_thres,
             opt.iou_thres,  # 0.6 not 0.5 for NMS
             opt.save_json,
             opt.single_cls)

&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected behavior&lt;/denchmark-h&gt;

The performance results of the test may vary somewhat
&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

Python==3.8.2
PyTorch==1.4.0
CUDA==10.1
CUDNN==7.4
Desktop (please complete the following information):

OS: [Ubuntu]
Version [18.04]

Smartphone (please complete the following information):

Device: [iPhoneX]
OS: [iOS]
Version [13]

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Good luck it.
	</description>
	<comments>
		<comment id='1' author='Lornatang' date='2020-02-27T19:29:10Z'>
		&lt;denchmark-link:https://github.com/Lornatang&gt;@Lornatang&lt;/denchmark-link&gt;
 yes this is true. iou_thres=0.5 is generally best for mAP@0.5, while mAP at 0.5...0.95 peaks at about iou_thres=0.7, so we've used iou_thres=0.6 as the best middle ground between both metrics. I'll update your line to iou_thres=0.6 to keep things consistent.
		</comment>
		<comment id='2' author='Lornatang' date='2020-02-27T19:30:06Z'>
		All done in &lt;denchmark-link:https://github.com/ultralytics/yolov3/commit/e7f85bcfb9c6040db919187cf3b26b56aa9d0146&gt;e7f85bc&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>