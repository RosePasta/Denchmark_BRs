<bug id='1337' author='Al-Razi-KR' open_date='2020-06-24T10:34:35Z' closed_time='2020-06-24T15:05:05Z'>
	<summary>AssertionError: Image Not Found ../dataset/images/train/4501.jpeg</summary>
	<description>
Input:
&lt;denchmark-code&gt;python3 train.py --img 640 --batch 16 --epochs 5 --data ./data/dataset.yaml --cfg ./models/yolov5s.yaml --weights weights/yolov5s.pt
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(train.py:19670): Gdk-CRITICAL **: 18:33:23.890: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex
{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}
Your branch is behind 'origin/master' by 1 commit, and can be fast-forwarded.
  (use "git pull" to update your local branch)

Namespace(adam=False, batch_size=16, bucket='', cache_images=False, cfg='./models/yolov5s.yaml', data='./data/dataset.yaml', device='', epochs=5, evolve=False, img_size=[640], multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/yolov5s.pt')
Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2080 Ti', total_memory=11019MB)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Start Tensorboard with "tensorboard --logdir=runs", view at http://localhost:6006/

              from  n    params  module                                  arguments
  0             -1  1      3520  models.common.Focus                     [3, 32, 3]
  1             -1  1     18560  models.common.Conv                      [32, 64, 3, 2]
  2             -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]
  3             -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  4             -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]
  5             -1  1    295424  models.common.Conv                      [128, 256, 3, 2]
  6             -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]
  7             -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]
  8             -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]
  9             -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]
 10             -1  1    131584  models.common.Conv                      [512, 256, 1, 1]
 11             -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12        [-1, 6]  1         0  models.common.Concat                    [1]
 13             -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]
 14             -1  1     33024  models.common.Conv                      [256, 128, 1, 1]
 15             -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 16        [-1, 4]  1         0  models.common.Concat                    [1]
 17             -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]
 18             -1  1      3483  torch.nn.modules.conv.Conv2d            [128, 27, 1, 1]
 19             -2  1    147712  models.common.Conv                      [128, 128, 3, 2]
 20       [-1, 14]  1         0  models.common.Concat                    [1]
 21             -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]
 22             -1  1      6939  torch.nn.modules.conv.Conv2d            [256, 27, 1, 1]
 23             -2  1    590336  models.common.Conv                      [256, 256, 3, 2]
 24       [-1, 10]  1         0  models.common.Concat                    [1]
 25             -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]
 26             -1  1     13851  torch.nn.modules.conv.Conv2d            [512, 27, 1, 1]
 27   [-1, 22, 18]  1         0  models.yolo.Detect                      [4, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]
Model Summary: 191 layers, 7.26318e+06 parameters, 7.26318e+06 gradients

Optimizer groups: 62 .bias, 70 conv.weight, 59 other
Caching labels ../dataset/labels/train.npy (8582 found, 0 missing, 0 empty, 674 duplicate, for 8582 images): 100%|████| 8582/8582 [00:00&lt;00:00, 24748.73it/s]
Caching labels ../dataset/labels/val.npy (1958 found, 0 missing, 0 empty, 135 duplicate, for 1958 images): 100%|██████| 1958/1958 [00:00&lt;00:00, 25395.42it/s]

Analyzing anchors... Best Possible Recall (BPR) = 0.9977
Image sizes 640 train, 640 test
Using 1 dataloader workers
Starting training for 5 epochs...

     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
       0/4     4.72G    0.1325   0.03671   0.05608    0.2252        60       640:   2%|▊                                    | 12/537 [00:07&lt;03:35,  2.44it/s]Traceback (most recent call last):
  File "train.py", line 407, in &lt;module&gt;
    train(hyp)
  File "train.py", line 237, in train
    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
  File "/usr/local/lib/python3.6/dist-packages/tqdm/std.py", line 1081, in __iter__
    for obj in iterable:
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
AssertionError: Caught AssertionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/fyp2020s1/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py", line 44, in &lt;listcomp&gt;
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/fyp2020s1/YoLo_v5/yolov5/utils/datasets.py", line 446, in __getitem__
    img, labels = load_mosaic(self, index)
  File "/home/fyp2020s1/YoLo_v5/yolov5/utils/datasets.py", line 573, in load_mosaic
    img, _, (h, w) = load_image(self, index)
  File "/home/fyp2020s1/YoLo_v5/yolov5/utils/datasets.py", line 534, in load_image
    assert img is not None, 'Image Not Found ' + path
AssertionError: Image Not Found ../dataset/images/train/4501.jpeg

       0/4     4.72G    0.1325   0.03671   0.05608    0.2252        60       640:   2%|▊ 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Al-Razi-KR' date='2020-06-24T10:35:15Z'>
		Hello &lt;denchmark-link:https://github.com/Al-Razi-KR&gt;@Al-Razi-KR&lt;/denchmark-link&gt;
, thank you for your interest in our work! Ultralytics has open-sourced YOLOv5 at &lt;denchmark-link:https://github.com/ultralytics/yolov5&gt;https://github.com/ultralytics/yolov5&lt;/denchmark-link&gt;
, featuring faster, lighter and more accurate object detection. YOLOv5 is recommended for all new projects.


&lt;denchmark-link:https://user-images.githubusercontent.com/26833433/85340570-30360a80-b49b-11ea-87cf-bdf33d53ae15.png&gt;&lt;/denchmark-link&gt;

To continue with this repo, please visit our &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data&gt;Custom Training Tutorial&lt;/denchmark-link&gt;
 to get started, and see our &lt;denchmark-link:https://github.com/ultralytics/yolov3/blob/master/tutorial.ipynb&gt;Google Colab Notebook&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://hub.docker.com/r/ultralytics/yolov3&gt;Docker Image&lt;/denchmark-link&gt;
, and &lt;denchmark-link:https://github.com/ultralytics/yolov3/wiki/GCP-Quickstart&gt;GCP Quickstart Guide&lt;/denchmark-link&gt;
 for example environments.
If this is a bug report, please provide screenshots and minimum viable code to reproduce your issue, otherwise we can not help you.
If this is a custom model or data training question, please note that Ultralytics does not provide free personal support. As a leader in vision ML and AI, we do offer professional consulting, from simple expert advice up to delivery of fully customized, end-to-end production solutions for our clients, such as:

Cloud-based AI systems operating on hundreds of HD video streams in realtime.
Edge AI integrated into custom iOS and Android apps for realtime 30 FPS video inference.
Custom data training, hyperparameter evolution, and model exportation to any destination.

For more information please visit &lt;denchmark-link:https://www.ultralytics.com&gt;https://www.ultralytics.com&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='Al-Razi-KR' date='2020-06-24T15:05:00Z'>
		Sorry, sent to the wrong repository. I thought YoLov5
		</comment>
	</comments>
</bug>