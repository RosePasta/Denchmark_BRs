<bug id='567' author='MichaelCong' open_date='2019-10-20T06:10:01Z' closed_time='2019-10-25T17:16:29Z'>
	<summary>The size of tensor a (128) must match the size of tensor b (16) at non-singleton dimension 1</summary>
	<description>
&lt;denchmark-code&gt; Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size
&lt;/denchmark-code&gt;

0%|                                                                                                          | 0/3665 [00:00&lt;?, ?it/s]Traceback (most recent call last):
File "train.py", line 432, in 
train()  # train normally
File "train.py", line 268, in train
pred = model(imgs)
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in call
result = self.forward(*input, **kwargs)
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 358, in forward
outputs = self.parallel_apply(self._module_copies[:len(inputs)], inputs, kwargs)
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 365, in parallel_apply
return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 83, in parallel_apply
raise output
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py", line 59, in _worker
output = module(*input, **kwargs)
File "/home/rencong/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 489, in call
result = self.forward(*input, **kwargs)
File "/home/rencong/yolov3/models.py", line 238, in forward
x = x + layer_outputs[int(mdef['from'])]
RuntimeError: The size of tensor a (128) must match the size of tensor b (16) at non-singleton dimension 1
	</description>
	<comments>
		<comment id='1' author='MichaelCong' date='2019-10-21T12:19:25Z'>
		same problem.
		</comment>
		<comment id='2' author='MichaelCong' date='2019-10-25T17:16:29Z'>
		Hello, thank you for your interest in our work! This is an automated response. Please note that most technical problems are due to:

Your changes to the default repository. If your issue is not reproducible in a fresh git clone version of this repository we can not debug it. Before going further run this code and ensure your issue persists:

sudo rm -rf yolov3  # remove exising repo
git clone https://github.com/ultralytics/yolov3 &amp;&amp; cd yolov3 # git clone latest
python3 detect.py  # verify detection
python3 train.py  # verify training (a few batches only)
# CODE TO REPRODUCE YOUR ISSUE HERE

Your custom data. If your issue is not reproducible with COCO data we can not debug it. Visit our Custom Training Tutorial for exact details on how to format your custom data. Examine train_batch0.jpg and test_batch0.jpg for a sanity check of training and testing data.
Your environment. If your issue is not reproducible in a GCP Quickstart Guide VM we can not debug it. Ensure you meet the requirements specified in the README: Unix, MacOS, or Windows with Python &gt;= 3.7, Pytorch &gt;= 1.1, etc. You can also use our Google Colab Notebook to test your code in working environment.

If none of these apply to you, we suggest you close this issue and raise a new one using the Bug Report template, providing screenshots and minimum viable code to reproduce your issue. Thank you!
		</comment>
		<comment id='3' author='MichaelCong' date='2020-02-10T00:47:39Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 thanks for your great work :) I really like it.
Today I had a similar problem as &lt;denchmark-link:https://github.com/MichaelCong&gt;@MichaelCong&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/ChenCong7375&gt;@ChenCong7375&lt;/denchmark-link&gt;
. I'm training the yolov3-spp on the COCO Dataset with a 2080 Ti with batch size 16 and accumulate factor 4 (as given in the repo), just for the person class. After some epochs, I copied the weight-file to my laptop (it has only 4GB VRAM, but good enough for training with batch size 1 or 2).
As I started finetuning on my laptop the error:

occurred. After playing around with the batch size and acc-factor, I was very confused. The error message differs from (128-256) up to (512-32) and it depends on the order of my choice of batch size and acc-factor.
However, after some hours I found the problem. If I take the best.pt or last.pt checkpoints and try to load this, then the above error occurred. After I converted the checkpoints to *.weight it works.
I hope that helps someone.
		</comment>
		<comment id='4' author='MichaelCong' date='2020-02-10T01:37:50Z'>
		&lt;denchmark-link:https://github.com/Deep-Learner&gt;@Deep-Learner&lt;/denchmark-link&gt;
 you might want to check the cfg you are using, as this error typically stems from a —weights —cfg mismatch
		</comment>
		<comment id='5' author='MichaelCong' date='2020-02-10T14:01:49Z'>
		Thanks for your replay. I already copied the cfg (which I used for training the first time) for finetuning on my Laptop. So, I think that should not be the problem. However, as long as the conversion does the job, I'm happy. :)
		</comment>
		<comment id='6' author='MichaelCong' date='2020-02-10T19:38:30Z'>
		Ok!
		</comment>
		<comment id='7' author='MichaelCong' date='2020-05-21T07:50:47Z'>
		
@glenn-jocher thanks for your great work :) I really like it.
Today I had a similar problem as @MichaelCong and @ChenCong7375. I'm training the yolov3-spp on the COCO Dataset with a 2080 Ti with batch size 16 and accumulate factor 4 (as given in the repo), just for the person class. After some epochs, I copied the weight-file to my laptop (it has only 4GB VRAM, but good enough for training with batch size 1 or 2).
As I started finetuning on my laptop the error:
The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 0
occurred. After playing around with the batch size and acc-factor, I was very confused. The error message differs from (128-256) up to (512-32) and it depends on the order of my choice of batch size and acc-factor.
However, after some hours I found the problem. If I take the best.pt or last.pt checkpoints and try to load this, then the above error occurred. After I converted the checkpoints to *.weight it works.
I hope that helps someone.

hello, can i ask you how to conver .pt to .weights?
thanks!
		</comment>
	</comments>
</bug>