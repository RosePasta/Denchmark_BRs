<bug id='750' author='gillmac13' open_date='2019-12-30T10:56:27Z' closed_time='2020-01-16T19:20:36Z'>
	<summary>Question concerning exporting to ONNX</summary>
	<description>
&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

I have been using your repo time and again with excellent results for 1-class detection with yolov3-spp. I am now working on different ways to deploy some models which need a .onnx format.
However, when applying the suggested conversion method to the letter, I get an unexpected output ...
For example, if I download a yolov3-spp.weights model (80 classes) from &lt;denchmark-link:url&gt; https://pjreddie.com/darknet/yolo/ &lt;/denchmark-link&gt;
, and:

change to ONNX_EXPORT = True in models.py
run the command: python3 detect.py --cfg cfg/yolov3-spp.cfg --weights weights/yolov3-spp.weights

I get an export.onnx file in return with no warning or error.
Now if I inspect this export.onnx with netron, I find that the output of the model is 2 tensors, 1 of shape 10647x80 and 1 of shape 10647x1. I was under the impression that an 80-class model would produce 85 columns, not 84.
Using the code snippet:
model_onnx = onnxruntime.InferenceSession("weights/export.onnx")  ort_inputs = {model_onnx.get_inputs()[0].name: img_t.numpy()}    ort_outs = model_onnx.run(None, ort_inputs)  x_out = ort_outs[0]  print(x_out.shape)
confirms what I get in terms of output format.
And applying this procedure to my 1-class models, I get 4+1 columns instead of the expected 6, such as in the "pred" variable in "detect.py".
My questions are simple: is what I get in terms of output normal, in which case how should I interpret the results, or is something wrong?
	</description>
	<comments>
		<comment id='1' author='gillmac13' date='2019-12-30T12:40:51Z'>
		Correction from above, I meant 1 tensor of shape 10647x80 et 1 of shape 10647x4
&lt;denchmark-link:https://user-images.githubusercontent.com/46053569/71582316-f1d21b00-2b09-11ea-82a4-d7ebdf37bb49.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='gillmac13' date='2019-12-30T20:11:58Z'>
		&lt;denchmark-link:https://github.com/gillmac13&gt;@gillmac13&lt;/denchmark-link&gt;
 yes this ONNX output is correct. These are the 4 box coordinates and the 80 class confidences, which have been multiplied by the objectness confidence.
See &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/653#issue-527705915&gt;#653 (comment)&lt;/denchmark-link&gt;
 for a stricter conversion which retains the 85 outputs, though be aware that the export pipeline is prone to failure on many pytorch-onnx version combinations.
		</comment>
		<comment id='3' author='gillmac13' date='2019-12-31T11:09:03Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

Thanks for your prompt reply.
And that clears up the format aspect of things.
Now if I dig up the code, I see that in order to perform NMS on the model output, the 2 confidences are needed. With them merged, is there another way to compute NMS ?
		</comment>
		<comment id='4' author='gillmac13' date='2020-01-16T19:20:36Z'>
		&lt;denchmark-link:https://github.com/gillmac13&gt;@gillmac13&lt;/denchmark-link&gt;
 NMS is not supplied in the ONNX model, nor in the PyTorch nor darknet models. NMS operations are executed after the model runs inference.
		</comment>
	</comments>
</bug>