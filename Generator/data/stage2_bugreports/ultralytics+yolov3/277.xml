<bug id='277' author='yanfei96' open_date='2019-05-14T16:40:09Z' closed_time='2019-05-14T16:47:21Z'>
	<summary>Parameter mismatch during the training</summary>
	<description>
There is something wrong as follows when I trained 40000 pictures but the program is running well when I trained 6 pictures. Could you give some advice? Thank you very much.
&lt;denchmark-code&gt;python3 train.py --cfg cfg/yolov3.cfg --batch-size 25
Namespace(accumulate=1, backend='nccl', batch_size=25, cfg='cfg/yolov3.cfg', data_cfg='data/coco.data', dist_url='tcp://127.0.0.1:9999', epochs=273, evolve=False, img_size=416, multi_scale=False, nosave=False, notest=False, num_workers=4, rank=0, resume=False, transfer=False, var=0, world_size=1)
Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX TITAN X', total_memory=12212MB)

Reading labels: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29379/29379 [00:01&lt;00:00, 21934.37it/s]
Traceback (most recent call last):
  File "train.py", line 340, in &lt;module&gt;
    multi_scale=opt.multi_scale,
  File "train.py", line 170, in train
    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights
  File "/home/ubuntu/yolo_v3/utils/utils.py", line 56, in labels_to_class_weights
    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO
ValueError: all the input arrays must have same number of dimensions
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='yanfei96' date='2019-05-14T16:42:27Z'>
		By the way, why labels.shape = (866643, 5) for COCO? Thanks.
		</comment>
		<comment id='2' author='yanfei96' date='2019-05-14T16:47:21Z'>
		&lt;denchmark-link:https://github.com/yanfei96&gt;@yanfei96&lt;/denchmark-link&gt;
 try to git pull, this may be related to an issue with a recent commit we fixed.
There are 866643 labels in the COCO training set.
		</comment>
		<comment id='3' author='yanfei96' date='2019-05-14T16:59:11Z'>
		Thank you very much, I will try it.
		</comment>
		<comment id='4' author='yanfei96' date='2019-05-15T08:52:21Z'>
		facing the same issue after git pull
		</comment>
		<comment id='5' author='yanfei96' date='2019-05-15T10:22:23Z'>
		
facing the same issue after git pull

&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='yanfei96' date='2019-05-15T14:11:11Z'>
		Hello, thank you for your interest in our work! This is an automated response. Please note that most technical problems are due to:

Your changes to the default repository. If your issue is not reproducible in a fresh git clone version of this repository we can not debug it. Before going further run this code and ensure your issue persists:

sudo rm -rf yolov3  # remove exising repo
git clone https://github.com/ultralytics/yolov3 &amp;&amp; cd yolov3 # git clone latest
python3 detect.py  # verify detection
python3 train.py  # verify training (a few batches only)
# CODE TO REPRODUCE YOUR ISSUE HERE

Your custom data. If your issue is not reproducible with COCO data we can not debug it. Visit our Custom Training Tutorial for exact details on how to format your custom data. Examine train_batch0.jpg and test_batch0.jpg for a sanity check of training and testing data.
Your environment. If your issue is not reproducible in a GCP Quickstart Guide VM we can not debug it. Ensure you meet the requirements specified in the README: Unix, MacOS, or Windows with Python &gt;= 3.7, Pytorch &gt;= 1.0, etc.

If none of these apply to you, we suggest you close this issue and raise a new one using the Bug Report template, providing screenshots and minimum viable code to reproduce your issue. Thank you!
		</comment>
		<comment id='7' author='yanfei96' date='2019-05-15T17:52:52Z'>
		I'm facing the same issue on a custom single class training. I used the default repository and got the same error
		</comment>
		<comment id='8' author='yanfei96' date='2019-05-15T18:09:07Z'>
		&lt;denchmark-link:https://github.com/lp55&gt;@lp55&lt;/denchmark-link&gt;
 can you supply reproducible example code?
		</comment>
		<comment id='9' author='yanfei96' date='2019-05-16T02:47:53Z'>
		managed to fix the error training on multi class custom data by changing to test branch, seems to be a problem with master, code was virtually unchanged other than changes to configuration and data files
		</comment>
		<comment id='10' author='yanfei96' date='2019-05-16T10:00:29Z'>
		
@lp55 can you supply reproducible example code?

I'm just using a single class tiny yolo config (filters set to 18). The rest is untouched. I didn't change the code. It used to work.
		</comment>
		<comment id='11' author='yanfei96' date='2019-05-16T16:43:10Z'>
		Changing to test branch simply changed the error for me:
File "train.py", line 303, in 
multi_scale=opt.multi_scale,
File "train.py", line 161, in train
for i, (imgs, targets, _, _) in enumerate(dataloader):
File "/home/dock/.conda/envs/tennisapp_py/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 615, in next
batch = self.collate_fn([self.dataset[i] for i in indices])
File "/home/dock/.conda/envs/tennisapp_py/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 615, in 
batch = self.collate_fn([self.dataset[i] for i in indices])
File "/home/dock/tennisapp/yolov3/utils/datasets.py", line 234, in getitem
labels_out[:, 1:] = torch.from_numpy(labels)
RuntimeError: The expanded size of the tensor (5) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [1, 5].  Tensor sizes: [10]
I seems to work on datasets with more than one class
		</comment>
		<comment id='12' author='yanfei96' date='2019-05-16T16:44:59Z'>
		I have several negative samples as well (empty txt files)
		</comment>
		<comment id='13' author='yanfei96' date='2019-05-17T11:01:54Z'>
		And the same dataset trains just fine on Darknet. I tested with release v6 to see if it would work, but got the same error after a couple of iterations.
		</comment>
		<comment id='14' author='yanfei96' date='2019-05-20T11:51:55Z'>
		Found out what the problem was. I had a few files where the endline was remove (duo to a cleanup script) and this caused and issue on the
self.labels[i] = np.array([x.strip().split() for x in f.read().splitlines()], dtype=np.float32)
line on the LoadImagesAndLabels function (from datasets.py). Might be a good idea to warn the user if the array has more than five columns (which means a bad labels file) and skip that to prevent an error.
		</comment>
		<comment id='15' author='yanfei96' date='2019-05-20T12:53:59Z'>
		&lt;denchmark-link:https://github.com/lp55&gt;@lp55&lt;/denchmark-link&gt;
 I see. I've added additional assertions and warnings in the case of not 5 columns or missing labels to increase awareness of label issues:



yolov3/utils/datasets.py


        Lines 191 to 201
      in
      8eced53






 # Preload labels (required for weighted CE training) 



 self.labels = [np.zeros((0, 5))] * n 



 iter = tqdm(self.label_files, desc='Reading labels') if n &gt; 1000 else self.label_files 



 for i, file in enumerate(iter): 



 try: 



 with open(file, 'r') as f: 



 self.labels[i] = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32) 



 assert self.labels[i].shape[1] == 5, 'corrupted labels file: %s' % file 



 except: 



 print('Warning: missing labels for %s' % self.img_files[i]) 



 pass # missing label file 





		</comment>
		<comment id='16' author='yanfei96' date='2019-05-20T13:55:12Z'>
		Hi,
I suggest adding this:
if os.stat(file).st_size != 0:
&lt;denchmark-code&gt;Before the with open(file, 'r') as f:  line, as you can have empty txt files (negative samples).
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='yanfei96' date='2019-05-21T12:03:56Z'>
		&lt;denchmark-link:https://github.com/lp55&gt;@lp55&lt;/denchmark-link&gt;
 yes you are correct! Thanks for the suggestion. I've updated this section to make it robust to empty files, and to add additional error checking.



yolov3/utils/datasets.py


        Lines 192 to 205
      in
      0effcd0






 self.labels = [np.zeros((0, 5))] * n 



 iter = tqdm(self.label_files, desc='Reading labels') if n &gt; 1000 else self.label_files 



 for i, file in enumerate(iter): 



 try: 



 with open(file, 'r') as f: 



 l = np.array([x.split() for x in f.read().splitlines()], dtype=np.float32) 



 if l.shape[0]: 



 assert l.shape[1] == 5, '&gt; 5 label columns: %s' % file 



 assert (l &gt;= 0).all(), 'negative labels: %s' % file 



 assert (l[:, 1:] &lt;= 1).all(), 'non-normalized or out of bounds coordinate labels: %s' % file 



 self.labels[i] = l 



 except: 



 print('Warning: missing labels for %s' % self.img_files[i])  # missing label file 



 assert len(np.concatenate(self.labels, 0)) &gt; 0, 'No labels found. Incorrect label paths provided.' 





		</comment>
	</comments>
</bug>