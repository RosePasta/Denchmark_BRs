<bug id='1266' author='Miracle2333' open_date='2020-06-02T03:45:56Z' closed_time='2020-07-09T00:20:34Z'>
	<summary>GPU memory of spp v3 during inference is relatively high compared to other repos</summary>
	<description>
I am done with training yolov3-spp and got the desired results in terms of mAp and FPS. Nevertheless, the model weights increased twice compared with the pre-trained one (from 241mb to 478mb). The gpu memory taken for inference is almost 2500mb. (see gpu 2 in the figure)
&lt;denchmark-link:https://user-images.githubusercontent.com/27708595/83477668-64369500-a4c6-11ea-96bb-8b6145125b99.png&gt;&lt;/denchmark-link&gt;

I used other repos of yolov3 (&lt;denchmark-link:https://github.com/eriklindernoren/PyTorch-YOLOv3&gt;https://github.com/eriklindernoren/PyTorch-YOLOv3&lt;/denchmark-link&gt;
) before. The gpu memory is only 900mb around. Any reason for the higher GPU memory and bigger weights? Is it only because of the spp part of the model?
	</description>
	<comments>
		<comment id='1' author='Miracle2333' date='2020-06-02T04:10:06Z'>
		&lt;denchmark-link:https://github.com/Miracle2333&gt;@Miracle2333&lt;/denchmark-link&gt;
 to strip the optimizer from your checkpoint and reduce it's size:


Inference memory is not a metric we track.
		</comment>
		<comment id='2' author='Miracle2333' date='2020-06-02T08:51:07Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 Thanks for the tips. It works well for reduce the size of weights.
About the inference memoryï¼ŒI will carry out some experiments and hope something can be figured out.
		</comment>
		<comment id='3' author='Miracle2333' date='2020-07-03T00:20:27Z'>
		This issue is stale because it has been open 30 days with no activity. Remove Stale label or comment or this will be closed in 5 days.
		</comment>
	</comments>
</bug>