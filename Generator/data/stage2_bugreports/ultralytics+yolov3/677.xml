<bug id='677' author='inspire-lts' open_date='2019-12-02T14:14:57Z' closed_time='2019-12-11T01:25:46Z'>
	<summary>Distributed Training on Windows</summary>
	<description>
I installed accroding "conda install pytorch torchvision cudatoolkit=10.1 -c pytorch'', but i found this question in my windows10 system:
AttributeError: module 'torch.distributed' has no attribute 'is_initialized'
and dir(torch.distributed) returns:
['_builtins_','cached','doc','file','loader','name','package','path''spec','absolute_imort','division', 'is_available','print_function','sys','torch','unicode_literals']
I hava one GPU. Why this happend, who can help?many thanks
	</description>
	<comments>
		<comment id='1' author='inspire-lts' date='2019-12-02T14:19:45Z'>
		Can you please check if Cuda was properly installed?
		</comment>
		<comment id='2' author='inspire-lts' date='2019-12-02T14:36:47Z'>
		&lt;denchmark-link:https://github.com/FranciscoReveriano&gt;@FranciscoReveriano&lt;/denchmark-link&gt;
  thank you.   return true
		</comment>
		<comment id='3' author='inspire-lts' date='2019-12-02T19:34:04Z'>
		&lt;denchmark-link:https://github.com/inspire-lts&gt;@inspire-lts&lt;/denchmark-link&gt;
 Windows functionality should technically work, but I highly recommend a unix environment. PyTorch has many known Windows issues.
To access an up-to-date working unix environment (with all dependencies including CUDA/CUDNN, python, PyTorch etc. preinstalled), consider one of our:

GCP Deep Learning VM with $300 free credit offer: See our GCP Quickstart Guide
Google Colab Notebook with 12 hours of free GPU time: Google Colab Notebook
Docker Image from https://hub.docker.com/r/ultralytics/yolov3. See Docker Quickstart Guide

		</comment>
		<comment id='4' author='inspire-lts' date='2019-12-02T20:14:31Z'>
		You most likely have 2 GPU cards without knowing it. (one built in and one you added probably)
Try: torch.cuda.device_count()
If it returns something over 1, then you must change this line in train.py to make sure it doesn't try to do distributed training:
if device.type != 'cpu' and torch.cuda.device_count() &gt; 1:
to something like
if device.type != 'cpu' and torch.cuda.device_count() &gt; 999:
or you can start your training with the option --device # where "#" is the number of the GPU you wish to use
Pytorch doesn't support distributed training on Windows and this repo defaults to distributed training if you have more then one GPU and you do not specify anything regarding GPUs.
		</comment>
		<comment id='5' author='inspire-lts' date='2019-12-03T05:25:09Z'>
		&lt;denchmark-link:https://github.com/Ownmarc&gt;@Ownmarc&lt;/denchmark-link&gt;
  thank you, sir. It does not work. It is weird and I really hava one GPU.
		</comment>
		<comment id='6' author='inspire-lts' date='2019-12-03T05:44:19Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
  thank you. Mybe I should change my environment to unix.
		</comment>
		<comment id='7' author='inspire-lts' date='2019-12-11T01:25:46Z'>
		I'll close this issue for now as the original issue appears to have been resolved, and/or no activity has been seen for some time. Feel free to comment if this is not the case.
		</comment>
	</comments>
</bug>