<bug id='812' author='MengtianLee' open_date='2020-01-29T06:23:49Z' closed_time='2020-01-31T19:20:04Z'>
	<summary>I have three questions about training.Please help me.</summary>
	<description>
&lt;denchmark-h:h2&gt;üêõ Bug&lt;/denchmark-h&gt;

1.The first question is that why the precision is always dramatically decrease on the last epoch?I find that is not an occasional  phenomena.
2.The second question is that during the training whether the mAP is calculated by the partial data from train_path or by the data from test_path? I know is an easy question, but i spend so many time on it without any results.
3.The last question is that it is reasonable that the mAP on test dataset preform better than valid dataset? BTW, the gap of both is narrow.
Thanks a lot.I really need you answer.
	</description>
	<comments>
		<comment id='1' author='MengtianLee' date='2020-01-31T06:01:51Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/42642078/73515609-e3409180-4430-11ea-9778-76b583455a99.png&gt;&lt;/denchmark-link&gt;

I don't know why my val_classification is increasing. And somehow is converged to 1. Is it so odd??
		</comment>
		<comment id='2' author='MengtianLee' date='2020-01-31T06:51:28Z'>
		

I don't know why my val_classification is increasing. And somehow is converged to 1. Is it so odd??

I know why, i add APs of every class in the results.txt. So I plotted AP instead of val_loss. That's a stupid mistake.
		</comment>
		<comment id='3' author='MengtianLee' date='2020-01-31T19:20:04Z'>
		&lt;denchmark-link:https://github.com/MengtianLee&gt;@MengtianLee&lt;/denchmark-link&gt;


Precision is measured at the --conf used. The last epoch measures mAP at a lower conf-thres to produce a higher mAP.
Testing is run on your test set defined in your *.data file.  See the custom training tutorial.
They should be generally similar.

		</comment>
	</comments>
</bug>