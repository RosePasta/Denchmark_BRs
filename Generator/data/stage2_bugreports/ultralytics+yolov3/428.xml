<bug id='428' author='AndresOsp' open_date='2019-08-06T13:54:15Z' closed_time='2019-08-10T17:19:53Z'>
	<summary>RuntimeError: Failed to export an ONNX attribute</summary>
	<description>
The bug
I am trying to export my model to ONNX. However, I have the error:
TypeError: 'YOLOLayer' object does not support indexing
Steps to reproduce the behavior:

Set: ONNX_EXPORT = True
run: python detect.py

Thanks for your work and help
	</description>
	<comments>
		<comment id='1' author='AndresOsp' date='2019-08-06T14:59:01Z'>
		I can reproduce this error. We recently rearranged the model architecture a bit, so the yolo layers are no longer nested inside sequential modules, so there's no longer a need to index [0] to get to the yolo layer.
We've just committed a fix. Can you git pull and try again?
		</comment>
		<comment id='2' author='AndresOsp' date='2019-08-06T15:24:27Z'>
		I just pull the new version.
One thing, I add the following code:
&lt;denchmark-code&gt;if ONNX_EXPORT:
    device = "cpu"
else:
    device = torch_utils.select_device()
&lt;/denchmark-code&gt;

Because without it I have the error:
&lt;denchmark-code&gt;RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same
&lt;/denchmark-code&gt;

After this, i still have an error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "detect.py", line 159, in &lt;module&gt;
    output=opt.output)
  File "detect.py", line 55, in detect
    torch.onnx.export(model, img, 'weights/export.onnx', verbose=True)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/__init__.py", line 25, in export
    return utils.export(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 131, in export
    strip_doc_string=strip_doc_string)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 363, in _export
    _retain_param_name, do_constant_folding)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 278, in _model_to_graph
    _disable_torch_constant_prop=_disable_torch_constant_prop)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 188, in _optimize_graph
    graph = torch._C._jit_pass_onnx(graph, operator_export_type)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/__init__.py", line 50, in _run_symbolic_function
    return utils._run_symbolic_function(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/utils.py", line 589, in _run_symbolic_function
    return fn(g, *inputs, **attrs)
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/symbolic.py", line 130, in wrapper
    args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/symbolic.py", line 130, in &lt;listcomp&gt;
    args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]
  File "/usr/local/lib/python3.5/dist-packages/torch/onnx/symbolic.py", line 90, in _parse_arg
    raise RuntimeError("Failed to export an ONNX attribute, "
RuntimeError: Failed to export an ONNX attribute, since it's not constant, please try to make things (e.g., kernel size) static if possible
&lt;/denchmark-code&gt;

Thanks for quick answer
		</comment>
		<comment id='3' author='AndresOsp' date='2019-08-06T15:48:32Z'>
		&lt;denchmark-link:https://github.com/AndresOsp&gt;@AndresOsp&lt;/denchmark-link&gt;
 ah, yes, I've seen that before. I just pushed a fix for the cpu issue.
This last message is the current state of affairs for ONNX export. I think there is a PyTorch issue open on this:
&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/19374&gt;pytorch/pytorch#19374&lt;/denchmark-link&gt;

They say it may be fixed in the latest pytorch nightly, though not in the latest stable (1.1). So you could try your luck with nightly. Or you could try this:
&lt;denchmark-link:https://github.com/onnx/tutorials/issues/137&gt;onnx/tutorials#137&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='AndresOsp' date='2019-08-06T17:36:54Z'>
		See &lt;denchmark-link:https://github.com/ultralytics/yolov3/issues/325&gt;#325&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='AndresOsp' date='2019-08-10T17:19:52Z'>
		&lt;denchmark-link:https://github.com/AndresOsp&gt;@AndresOsp&lt;/denchmark-link&gt;
 this should be resolved now in PyTorch 1.2.
		</comment>
		<comment id='6' author='AndresOsp' date='2020-06-01T10:36:53Z'>
		Hi &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
  I am using pytorch 1.2 but I am facing the issue.
Failed to export an ONNX attribute, since it's not constant, please try to make things (e.g., kernel size) static if possible.
Any suggestion?
Thanks
		</comment>
		<comment id='7' author='AndresOsp' date='2020-06-01T19:02:33Z'>
		&lt;denchmark-link:https://github.com/Akshaysharma29&gt;@Akshaysharma29&lt;/denchmark-link&gt;
 you already know the answer to this. Upgrade your pytorch.
		</comment>
		<comment id='8' author='AndresOsp' date='2020-06-02T06:41:51Z'>
		Hi, &lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;
 thanks for the response.
By the way, the question is not regarding yolov3 and I have tried 1.5,1.4,1.3 but the error almost remains the same.
Failed to export an ONNX attribute 'onnx::Gather', since it's not constant, please try to make things (e.g., kernel size) static if possible.
Wrong place to ask this question so I have open this issue here.
&lt;denchmark-link:https://github.com/onnx/onnx/issues/2807#issue-628940240&gt;onnx/onnx#2807 (comment)&lt;/denchmark-link&gt;

Thanks
		</comment>
	</comments>
</bug>