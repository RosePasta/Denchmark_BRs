<bug id='807' author='LinCoce' open_date='2020-01-26T03:32:12Z' closed_time='2020-01-31T19:20:43Z'>
	<summary>fuse_conv_and_bn</summary>
	<description>
&lt;denchmark-h:h3&gt;File "torch_utils.py", line 44, fuse_conv_and_bn() funtion&lt;/denchmark-h&gt;

This function is from &lt;denchmark-link:https://tehnokv.com/posts/fusing-batchnorm-and-conv/&gt;https://tehnokv.com/posts/fusing-batchnorm-and-conv/&lt;/denchmark-link&gt;
, but i think the original implementation is flawed. The fuse formula is
&lt;denchmark-link:https://user-images.githubusercontent.com/16974482/73130188-86a73600-402e-11ea-93fc-afdf86dc29f4.png&gt;&lt;/denchmark-link&gt;
, but the code for fusedconv.bias calculation is: . I think  has been forgot.
The test result is still right cause when BN is used, the bias in conv is usually canceled. So the inference calculation is not affected. But I think the code is till not rigorous enough.
	</description>
	<comments>
		<comment id='1' author='LinCoce' date='2020-01-27T17:59:49Z'>
		&lt;denchmark-link:https://github.com/LinCoce&gt;@LinCoce&lt;/denchmark-link&gt;
 this is very interesting, I did not realize this. Can you try to implement your proposed fix and compare outputs?
I believe when I implemented this originally I compared output values from fused and unfused and received nearly identical results, but I could be wrong.
		</comment>
		<comment id='2' author='LinCoce' date='2020-01-27T18:13:10Z'>
		&lt;denchmark-link:https://github.com/LinCoce&gt;@LinCoce&lt;/denchmark-link&gt;
 as a quick test if I run detect.py with default settings:
        # Get detections
        img = torch.from_numpy(img).to(device)
        if img.ndimension() == 3:
            img = img.unsqueeze(0)
        pred = model(img)[0]

        torch_utils.model_info(model, report='summary')  # 'full' or 'summary'
        print(pred[0])
Model Summary: 225 layers, 6.29987e+07 parameters, 6.29987e+07 gradients

tensor([[1.39544e+01, 1.49381e+01, 1.57842e+02,  ..., 1.65460e-02, 6.70419e-03, 3.36679e-03],
        [5.27974e+01, 2.14898e+01, 1.32991e+02,  ..., 1.52713e-02, 6.06968e-03, 3.10304e-03],
        [8.22322e+01, 1.97613e+01, 1.85406e+02,  ..., 1.17630e-02, 4.69894e-03, 2.74525e-03],
        ...,
        [2.99128e+02, 4.13183e+02, 9.45507e+01,  ..., 5.09370e-03, 2.40942e-03, 6.71110e-03],
        [3.06646e+02, 4.13326e+02, 8.40165e+01,  ..., 5.85396e-03, 2.03835e-03, 4.50750e-03],
        [3.16871e+02, 4.12817e+02, 8.86255e+01,  ..., 4.85221e-03, 2.79183e-03, 3.80355e-03]])
And if I use model.fuse():
Model Summary: 152 layers, 6.29719e+07 parameters, 6.29719e+07 gradients

tensor([[1.39544e+01, 1.49381e+01, 1.57842e+02,  ..., 1.65461e-02, 6.70421e-03, 3.36681e-03],
        [5.27974e+01, 2.14898e+01, 1.32991e+02,  ..., 1.52714e-02, 6.06968e-03, 3.10305e-03],
        [8.22322e+01, 1.97613e+01, 1.85405e+02,  ..., 1.17630e-02, 4.69893e-03, 2.74525e-03],
        ...,
        [2.99128e+02, 4.13183e+02, 9.45507e+01,  ..., 5.09367e-03, 2.40942e-03, 6.71111e-03],
        [3.06646e+02, 4.13326e+02, 8.40166e+01,  ..., 5.85390e-03, 2.03834e-03, 4.50747e-03],
        [3.16871e+02, 4.12817e+02, 8.86256e+01,  ..., 4.85219e-03, 2.79182e-03, 3.80353e-03]])
The differences all seem to be in the 1E-6 range, which I think it consistent with single precision (FP32) from here for example &lt;denchmark-link:https://en.wikipedia.org/wiki/Machine_epsilon&gt;https://en.wikipedia.org/wiki/Machine_epsilon&lt;/denchmark-link&gt;

That's strange that the gradients are appearing turned on though...
		</comment>
		<comment id='3' author='LinCoce' date='2020-01-28T12:06:59Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

I reproduced your detect.py test, with 
Detect.py was modifed for conv-with-bias checking:
&lt;denchmark-code&gt;...
def check_bias_in_conv(self, is_print=True):
    # check Conv2d + BatchNorm2d layers or fuseConv layers
    conv_with_bias_before_bn, conv_with_bias_no_bn, conv_no_bias_before_bn, conv_no_bias_no_bn = 0, 0, 0, 0
    for a in list(self.children())[0]:
        if isinstance(a, nn.Sequential):
            for i, b in enumerate(a):
                if isinstance(b, nn.modules.conv.Conv2d):
                    try:
                        bn = a[i+1]
                        if isinstance(bn, nn.modules.batchnorm.BatchNorm2d):
                            if b.bias is not None: conv_with_bias_before_bn += 1
                            else: conv_no_bias_before_bn += 1
                        else:
                            if b.bias is not None: conv_with_bias_no_bn += 1
                            else: conv_no_bias_no_bn += 1
                    except IndexError:
                        if b.bias is not None: conv_with_bias_no_bn += 1
                        else: conv_no_bias_no_bn += 1
                        continue
    print('If followed by bn, there are %d conv has bias and %d NOT' % (conv_with_bias_before_bn, conv_no_bias_before_bn))
    print('If NOT followed by bn, there are %d conv has bias and %d NOT' % (conv_with_bias_no_bn, conv_no_bias_no_bn))
...
def detect(save_txt=False, save_img=False):
...
        # Get detections
        img = torch.from_numpy(img).to(device)
        if img.ndimension() == 3:
            img = img.unsqueeze(0)
        pred = model(img)[0]

        # ########## fuse conv and bn test ##########
        torch_utils.model_info(model, report='summary')  # 'full' or 'summary'
        print(pred[0])
        check_bias_in_conv(model, is_print=False)

        model.fuse()
        pred_fuse = model(img.cpu())[0]
        torch_utils.model_info(model, report='summary')  # 'full' or 'summary'
        print(pred_fuse[0])
        check_bias_in_conv(model, is_print=False)

        d = (pred[0] - pred_fuse[0]).norm().div(pred[0].norm()).item()
        print("Error: %.8f" % d)

        # ########## End ##########
...
&lt;/denchmark-code&gt;

And the results are:
&lt;denchmark-code&gt;Model Summary: 37 layers, 8.85237e+06 parameters, 8.85237e+06 gradients
tensor([[2.40001e+01, 2.08713e+01, 8.70725e+01,  ..., 1.83841e-02, 4.68162e-04, 1.49674e-04],
        [4.90474e+01, 2.08060e+01, 1.20938e+02,  ..., 2.79196e-02, 9.30916e-04, 1.17514e-04],
        [8.19246e+01, 1.86440e+01, 1.62108e+02,  ..., 3.81493e-02, 1.59860e-03, 4.53681e-04],
        ...,
        [2.79226e+02, 4.06461e+02, 4.92743e+01,  ..., 1.04082e-03, 3.57477e-04, 4.14086e-04],
        [2.93216e+02, 4.07816e+02, 4.28459e+01,  ..., 8.41400e-04, 4.19613e-04, 4.04124e-04],
        [3.11913e+02, 4.09623e+02, 4.62420e+01,  ..., 1.51729e-03, 6.55530e-04, 6.08192e-04]])
If followed by bn, there are 0 conv has bias and 11 NOT
If NOT followed by bn, there are 2 conv has bias and 0 NOT
Model Summary: 26 layers, 8.84918e+06 parameters, 8.84918e+06 gradients
tensor([[2.40001e+01, 2.08713e+01, 8.70725e+01,  ..., 1.83841e-02, 4.68161e-04, 1.49674e-04],
        [4.90474e+01, 2.08060e+01, 1.20938e+02,  ..., 2.79196e-02, 9.30916e-04, 1.17514e-04],
        [8.19246e+01, 1.86440e+01, 1.62108e+02,  ..., 3.81494e-02, 1.59860e-03, 4.53681e-04],
        ...,
        [2.79226e+02, 4.06461e+02, 4.92743e+01,  ..., 1.04082e-03, 3.57477e-04, 4.14087e-04],
        [2.93216e+02, 4.07816e+02, 4.28459e+01,  ..., 8.41400e-04, 4.19613e-04, 4.04126e-04],
        [3.11913e+02, 4.09623e+02, 4.62420e+01,  ..., 1.51729e-03, 6.55529e-04, 6.08189e-04]])
If followed by bn, there are 0 conv has bias and 0 NOT
If NOT followed by bn, there are 13 conv has bias and 0 NOT
Error: 0.00000008
&lt;/denchmark-code&gt;

I got the same results. Fused and unfused convs receive nearly identical results.
But this is because when BN is used, the bias in conv is usually canceled, like in models.py:
&lt;denchmark-code&gt;            modules.add_module('Conv2d', nn.Conv2d(in_channels=output_filters[-1],
                                                   out_channels=filters,
                                                   kernel_size=size,
                                                   stride=stride,
                                                   padding=pad,
                                                   groups=int(mdef['groups']) if 'groups' in mdef else 1,
                                                   bias=not bn))
            if bn:
                modules.add_module('BatchNorm2d', nn.BatchNorm2d(filters, momentum=0.1))
&lt;/denchmark-code&gt;

The fuse code only fail when conv_with_bias_before_bn, which normally can be avoided. So I just think the code is not rigorous enough.
There are the errors in purpose. Insert random bias in model's first conv:
&lt;denchmark-code&gt;...
        # Get detections
        img = torch.from_numpy(img).to(device)
        if img.ndimension() == 3:
            img = img.unsqueeze(0)

        # ########## insert conv_with_bias_before_bn ##########
        target = list(model.children())[0][0][0]
        modified = torch.nn.Conv2d(target.in_channels,
                                   target.out_channels,
                                   kernel_size=target.kernel_size,
                                   stride=target.stride,
                                   padding=target.padding,
                                   bias=True)
        modified.weight.copy_(target.weight)
        list(model.children())[0][0][0] = modified
        # ########## End ##########
        pred = model(img)[0]
...
&lt;/denchmark-code&gt;

and the results:
&lt;denchmark-code&gt;Model Summary: 38 layers, 8.85238e+06 parameters, 8.85238e+06 gradients
tensor([[2.40035e+01, 2.01134e+01, 8.97949e+01,  ..., 5.17192e-02, 4.99909e-04, 3.00301e-04],
        [5.01554e+01, 2.19869e+01, 1.14426e+02,  ..., 8.63517e-02, 1.17998e-03, 2.65839e-04],
        [8.16482e+01, 2.06688e+01, 1.53743e+02,  ..., 6.54906e-02, 1.63738e-03, 4.91107e-04],
        ...,
        [2.79235e+02, 4.06116e+02, 5.00214e+01,  ..., 1.12911e-03, 2.80363e-04, 2.76489e-04],
        [2.93324e+02, 4.07370e+02, 4.42561e+01,  ..., 5.48370e-04, 2.99978e-04, 3.80757e-04],
        [3.11824e+02, 4.09439e+02, 4.67531e+01,  ..., 1.55280e-03, 5.35421e-04, 6.56669e-04]])
If followed by bn, there are 1 conv has bias and 10 NOT
If NOT followed by bn, there are 2 conv has bias and 0 NOT
Model Summary: 26 layers, 8.84918e+06 parameters, 8.84918e+06 gradients
tensor([[2.40331e+01, 2.07188e+01, 8.80087e+01,  ..., 2.36877e-02, 4.53512e-04, 1.77438e-04],
        [4.93723e+01, 2.12234e+01, 1.19377e+02,  ..., 3.68400e-02, 9.47023e-04, 1.40918e-04],
        [8.16568e+01, 1.92198e+01, 1.59739e+02,  ..., 4.37197e-02, 1.53967e-03, 4.77384e-04],
        ...,
        [2.79245e+02, 4.06299e+02, 4.89226e+01,  ..., 1.02152e-03, 3.31561e-04, 3.56736e-04],
        [2.93202e+02, 4.07689e+02, 4.28357e+01,  ..., 7.43237e-04, 3.77242e-04, 3.69071e-04],
        [3.11930e+02, 4.09628e+02, 4.64648e+01,  ..., 1.47649e-03, 6.05659e-04, 5.74691e-04]])
If followed by bn, there are 0 conv has bias and 0 NOT
If NOT followed by bn, there are 13 conv has bias and 0 NOT
Error: 0.01386723
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='LinCoce' date='2020-01-29T19:05:31Z'>
		&lt;denchmark-link:https://github.com/LinCoce&gt;@LinCoce&lt;/denchmark-link&gt;
 ah yes I understand now. The Conv2d() layers always have  since they are all followed by batchnorm layers. So we want to change this line


to this?
fusedconv.bias.copy_(torch.mm(w_bn, b_conv) + b_bn)
Does this change pass your test code?
		</comment>
		<comment id='5' author='LinCoce' date='2020-01-30T07:46:13Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

Yeah, in my test,  behave correctly in any conv-bias-bn situation.
		</comment>
		<comment id='6' author='LinCoce' date='2020-01-30T18:02:12Z'>
		&lt;denchmark-link:https://github.com/LinCoce&gt;@LinCoce&lt;/denchmark-link&gt;
 perfect. Do you want to submit a PR so you can be added to the repo authorlist or should I just make the change myself?
		</comment>
		<comment id='7' author='LinCoce' date='2020-01-31T04:07:42Z'>
		&lt;denchmark-link:https://github.com/glenn-jocher&gt;@glenn-jocher&lt;/denchmark-link&gt;

Thanks. I have submitted a PR for you.
		</comment>
		<comment id='8' author='LinCoce' date='2020-01-31T19:20:43Z'>
		&lt;denchmark-link:https://github.com/LinCoce&gt;@LinCoce&lt;/denchmark-link&gt;
 great, it's all done! Thanks for spotting the bug. I'll close the issue now.
		</comment>
	</comments>
</bug>