<bug id='88' author='caprone' open_date='2018-10-28T17:46:46Z' closed_time='2018-11-01T20:50:47Z'>
	<summary>hyperparameter space issue</summary>
	<description>
HI
ther's a problem when You try to rerun the optimizer with 'exactly' the same
hyperparameters's range of values;
for example, if I declare:
'max_depth'=Integer(2, 15)
and any other Real hyperpar., for ex.:
'min_split_loss'=(...)
the  hyper_space_size will be: np.inf;
then it make sense to rerun optimizer  also with high interations(in the same space);
but if I try to do that, the following Uncaught exception occur:
"Traceback (most recent call last):
File "D:/MachinLrn/Esperiments_Prjct/scripts/one.py", line 135, in 
execute()
File "D:/MachinLrn/Esperiments_Prjct/scripts/one.py", line 109, in execute
optimizer.go()  # Now, we go
File "D:\software\Anaconda3\envs\RBM\lib\site-packages\hyperparameter_hunter\optimization.py", line 87, in go
super().go()
File "D:\software\Anaconda3\envs\RBM\lib\site-packages\hyperparameter_hunter\optimization_core.py", line 340, in go
self._optimization_loop()
File "D:\software\Anaconda3\envs\RBM\lib\site-packages\hyperparameter_hunter\optimization_core.py", line 364, in _optimization_loop
if len(self.similar_experiments) + len(self.tested_keys) &gt;= self.search_space_size:
File "D:\software\Anaconda3\envs\RBM\lib\site-packages\hyperparameter_hunter\optimization_core.py", line 802, in search_space_size
self._search_space_size = len(self.hyperparameter_space)
TypeError: 'float' object cannot be interpreted as an integer
then if I change the max_depth range , like (2, 14) and rerun optimizer, all works well, again...
	</description>
	<comments>
		<comment id='1' author='caprone' date='2018-10-29T20:20:11Z'>
		&lt;denchmark-link:https://github.com/caprone&gt;@caprone&lt;/denchmark-link&gt;
, thank you for bringing this up. I'm sorry but I'm having some trouble understanding what exactly the problem is. Can you supply a minimal code example to recreate the bug, please? Also, using the markdown code block formatting with triple backticks (```) would be very helpful!
&lt;denchmark-code&gt;&lt;here's some code&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='caprone' date='2018-10-29T21:28:57Z'>
		&lt;denchmark-link:https://github.com/HunterMcGushion&gt;@HunterMcGushion&lt;/denchmark-link&gt;

Sorry for my bad english!!
Ok, below there"s a full reproducible example in which I can choose to run again (in a second moment) the Experiments with exactly --- the same search boundaries  ---
`
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
from hyperparameter_hunter import Environment, Integer, Real, GradientBoostedRegressionTreeOptimization
from xgboost import XGBRegressor
from sklearn.datasets.samples_generator import make_blobs
from pandas import DataFrame
x, y = make_blobs(n_samples=100, centers=3, n_features=2)
x_train = DataFrame(dict(x=x[:, 0], y=x[:, 1], target=y))
hunter_path = '../HyperparameterHunterAssets'
def execute():
"""This is going to be a very simple example to illustrate what exactly HyperparameterHunter does,
and how it revolutionizes hyperparameter optimization."""
&lt;denchmark-code&gt;env = Environment(
    train_dataset=x_train,
    target_column='target',
    root_results_path=hunter_path,
    metrics_map=['mean_squared_error'],
    cross_validation_type='KFold',
    cross_validation_params=dict(n_splits=5,  shuffle=True, random_state=32),
    runs=1
)

optimizer = GradientBoostedRegressionTreeOptimization(verbose=1, iterations=2,
                                                      acquisition_optimizer_kwargs=dict(n_points=10000,
                                                                                        # n_restarts_optimizer=5,
                                                                                        n_jobs=4),
                                                      base_estimator_kwargs=dict())

optimizer.set_experiment_guidelines(
    model_initializer=XGBRegressor,

    model_init_params=dict(
        objective='reg:linear',
        subsample=0.8,
        eval_metric='rmse',
        n_estimators=1000,
        nthread=8,
        # tunable param
        max_depth=Integer(2, 20),
        learning_rate=Real(0.01, 0.2),
        min_child_weight=Integer(1, 7)
        # min_split_loss=Real(0, 0.3)
    ),


    model_extra_params=dict(
        fit=dict(
            eval_set=[(env.train_input, env.train_target),
                      (env.validation_input, env.validation_target)],
            early_stopping_rounds=5)

    )
)

print("run optimizer for the first time...")
optimizer.go()

print("tryng run optimizer again...")
print("=====&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;")
try:
    optimizer.go()
except TypeError as te:
    print("the following uncaught TypeError exception occurred:  ", "&lt;&lt;&lt;&lt;&lt;&lt;&lt; ", te, " &gt;&gt;&gt;&gt;&gt;&gt;&gt;")
&lt;/denchmark-code&gt;

if name == 'main':
execute()
`
		</comment>
		<comment id='3' author='caprone' date='2018-10-30T22:28:06Z'>
		No apology necessary! Your english is quite good - just a little bit of misunderstanding! I've started looking into this, and I was able to reproduce the error on my end, but I haven't quite found the problem yet. I'll update you when I have more news. Thank you for bringing this issue up!
		</comment>
		<comment id='4' author='caprone' date='2018-10-30T22:58:30Z'>
		I found what was causing the problem. It seems that when the dataset sentinels are used in model_extra_params, experiments aren't matched properly.
I'll start working on a fix for the dataset sentinels. Meanwhile, this version of your code that comments out the model_extra_params["fit"] sent to optimizer.set_experiment_guidelines works fine:
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'
from hyperparameter_hunter import Environment, Integer, Real, GradientBoostedRegressionTreeOptimization
from xgboost import XGBRegressor
from sklearn.datasets.samples_generator import make_blobs
from pandas import DataFrame

x, y = make_blobs(n_samples=100, centers=3, n_features=2)
x_train = DataFrame(dict(x=x[:, 0], y=x[:, 1], target=y))

hunter_path = '../HyperparameterHunterAssets'


def execute():
    env = Environment(
        train_dataset=x_train,
        target_column='target',
        root_results_path=hunter_path,
        metrics_map=['mean_squared_error'],
        cross_validation_type='KFold',
        cross_validation_params=dict(n_splits=5, shuffle=True, random_state=32),
        runs=1,
    )

    optimizer = GradientBoostedRegressionTreeOptimization(
        verbose=1,
        iterations=2,
        acquisition_optimizer_kwargs=dict(
            n_points=10000,
            n_jobs=4,
        ),
        base_estimator_kwargs=dict(),
    )

    optimizer.set_experiment_guidelines(
        model_initializer=XGBRegressor,
        model_init_params=dict(
            objective='reg:linear',
            subsample=0.8,
            eval_metric='rmse',
            n_estimators=1000,
            nthread=8,
            max_depth=Integer(2, 20),
            learning_rate=Real(0.01, 0.2),
            min_child_weight=Integer(1, 7),
        ),
        model_extra_params=dict(
            # fit=dict(
            #     eval_set=[
            #         (env.train_input, env.train_target),
            #         (env.validation_input, env.validation_target)
            #     ],
            #     early_stopping_rounds=5,
            # ),
        ),
    )

    print("run optimizer for the first time...")
    optimizer.go()

    print("trying run optimizer again...")
    print("=====&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;")
    try:
        optimizer.go()
    except TypeError as te:
        print("the following uncaught TypeError exception occurred:  ", "&lt;&lt;&lt;&lt;&lt;&lt;&lt; ", te, " &gt;&gt;&gt;&gt;&gt;&gt;&gt;")
        raise te


if __name__ == '__main__':
    execute()
Just a reminder that, as &lt;denchmark-link:https://github.com/caprone&gt;@caprone&lt;/denchmark-link&gt;
 brought up in &lt;denchmark-link:https://github.com/HunterMcGushion/hyperparameter_hunter/issues/87&gt;#87&lt;/denchmark-link&gt;
 and as is noted in &lt;denchmark-link:https://github.com/HunterMcGushion/hyperparameter_hunter/issues/34&gt;#34&lt;/denchmark-link&gt;
, using error or loss metrics currently moves in the wrong direction when being optimized, which explains the optimizer's behavior in the working example.
		</comment>
	</comments>
</bug>