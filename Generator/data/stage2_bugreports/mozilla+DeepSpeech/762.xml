<bug id='762' author='istojan' open_date='2017-08-09T13:14:26Z' closed_time='2019-01-25T12:54:00Z'>
	<summary>Same sentence appearing twice when printing a report</summary>
	<description>
Hi guys,
While I was running some tests, I noticed that when printing reports sometimes the same sentence appears twice. I have noticed this happening in all types of reports (training, valid or test).
Example:
I Validation of Epoch 30 - WER: 0.667405, loss: 127.267698288, mean edit distance: 0.318987
I --------------------------------------------------------------------------------
I WER: 0.230769, loss: 68.335030, mean edit distance: 0.218750
I  - src: "then thou also shalt die with them by the sword of the assyrians"
I  - res: "then saw also shalt die bathe them by the sword of the aseyrincs"
I --------------------------------------------------------------------------------
I WER: 0.461538, loss: 71.804466, mean edit distance: 0.296875
I  - src: "then thou also shalt die with them by the sword of the assyrians"
I  - res: "then saw also shalt buy with them both sour of the asceyryiancs"
I --------------------------------------------------------------------------------
I WER: 0.600000, loss: 78.445549, mean edit distance: 0.231707
I  - src: "and they caused the little children to lie prostrate before the temple of the lord"
I  - res: "and the cause latte chilpent to my prostate before the temple of tailored"
I --------------------------------------------------------------------------------
I WER: 0.615385, loss: 75.957489, mean edit distance: 0.328358
I  - src: "for if any one complained it was immediately said he had the plague"
I  - res: "fore if any one company at wisofbeaatly say had plague"
I --------------------------------------------------------------------------------
I WER: 0.666667, loss: 16.149897, mean edit distance: 0.315789
I  - src: "judith chapter four"								&lt;-----------------------
I  - res: "judith chacpterfore"
I --------------------------------------------------------------------------------
I WER: 0.777778, loss: 71.201004, mean edit distance: 0.340909
I  - src: "know ye that the lord will hear your prayers"				&lt;-----------------------
I  - res: "no he tat the normal year ra prayers"
I --------------------------------------------------------------------------------
I WER: 0.777778, loss: 77.050140, mean edit distance: 0.340909
I  - src: "know ye that the lord will hear your prayers"				&lt;-----------------------
I  - res: "to eee tat the morale mary at prayers"
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 16.028034, mean edit distance: 0.315789
I  - src: "judith chapter four"								&lt;-----------------------
I  - res: "hurt it chapterfor"
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 58.811226, mean edit distance: 0.437500
I  - src: "and stayed there for thirty days"						&lt;-----------------------
I  - res: "an stay tirfriathry does"
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 62.440716, mean edit distance: 0.500000
I  - src: "and stayed there for thirty days"						&lt;-----------------------
I  - res: "an stay their fishery mates"
I --------------------------------------------------------------------------------
Now I checked and the sentences appear only once in the csv files. As far as I can notice, no sentence appears more than 2 times. Any idea why this is happening? Could it be something connected with me using 2 gpu's for training?
	</description>
	<comments>
		<comment id='1' author='istojan' date='2017-08-09T16:46:16Z'>
		Thanks for the report!
Do you have some more info on the data set your training from?
		</comment>
		<comment id='2' author='istojan' date='2017-08-09T16:59:06Z'>
		&lt;denchmark-link:https://github.com/istojan&gt;@istojan&lt;/denchmark-link&gt;
 What batch size, corpus and limits were used in this case?
		</comment>
		<comment id='3' author='istojan' date='2017-08-10T11:16:59Z'>
		I ran into this problem a few times before, so I used a small data set(226 wavs training, 28 valid and 31 for test to be exact) extracted from the librivox data set to confirm this. Batch size i used was 2, didn't have limits specified and the rest of the settings were the defaults.
Like I said, the same problem happened to me with a different data set of mine where the only thing that was in common between the 2 tests was that I used batch size 2 and used the 2 gpu's on my system.
I am running the same example at the moment with batch size 8 and I still had duplicate sentences in the validation and test reports.
Additionally, something else i noticed is that for batch size 8 in the reports for validation and test it only printed 16 sentences. Later I added 2 more sentences to the test set  to make it 33 and after testing again it printed 32 sentences in the test report (1 duplicate).  I don't know if this is expected behavior for the number of sentences in the report to be divisible by the batch size (or by the batch_size*num_used_gpus in this case) or its some bug.
		</comment>
		<comment id='4' author='istojan' date='2017-08-10T12:13:06Z'>
		&lt;denchmark-link:https://github.com/istojan&gt;@istojan&lt;/denchmark-link&gt;
 Thanks for your description. I think I know what is going wrong here: Our batch system is based on continuing at the first sample, if there were not enough samples for a full batch. This produces duplicates in reports. There are two ways to avoid this: Either by making the reports unique in regards to the sample, or by changing the batch building process. The latter is already solved as part of my current code-refactoring that will introduce dynamic batch sizes.
For the moment &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/blob/master/DeepSpeech.py#L711-L719&gt;this code&lt;/denchmark-link&gt;
 could be changed to skip duplicates of  (using an additional set object for the labels).
Would you want to contribute this?
		</comment>
		<comment id='5' author='istojan' date='2017-08-10T13:56:32Z'>
		From what I understand, you want to have a set with labels that should be cleared at the start of every new epoch? Looks good, but this will also remove 'valid' duplicate sentences (sentences with the same label, but different audio). In normal circumstances this shouldn't happen, but it might in some cases.
Is this considered a temporary fix until you introduce dynamic batch sizes?
		</comment>
		<comment id='6' author='istojan' date='2017-08-10T14:08:44Z'>
		Yes.
		</comment>
		<comment id='7' author='istojan' date='2017-11-30T08:17:38Z'>
		&lt;denchmark-link:https://github.com/reuben&gt;@reuben&lt;/denchmark-link&gt;
 Is this covered and/or affected by your "duplicate samples" fix?
		</comment>
		<comment id='8' author='istojan' date='2017-11-30T11:22:51Z'>
		Yes, but I still have to find a proper fix for the training code. The way I fixed it in the test script is a hack.
		</comment>
		<comment id='9' author='istojan' date='2019-01-25T12:54:00Z'>
		This was eventually fixed in evaluate.py by simply sticking to a single tower/GPU model since the cost of test epochs is completely dominated by the decoding step.
		</comment>
		<comment id='10' author='istojan' date='2019-02-24T13:15:35Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>