<bug id='1423' author='Franck-Dernoncourt' open_date='2018-06-30T18:37:38Z' closed_time='2018-07-02T17:54:55Z'>
	<summary>Common Voice's cv-other-train.csv contains empty transcripts, which cause the training to crash (Labels length is zero in batch 0)</summary>
	<description>
Issue: Common Voice's cv-other-train.csv contains 2 empty transcripts. which cause the training on cv-other-train.csv to crash:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: Labels length is zero in batch 0
         [[Node: tower_1/CTCLoss = CTCLoss[ctc_merge_repeated=true, ignore_longer_outputs_than_inputs=false, preprocess_collapse_repeated=false, _device="/job:localhost/replica:0/task:0/device:CPU:0"](tower_1/logits/_1879, tower_1/ToInt64/_1881, tower_1/Gather, tower_1/Gather_1_DequeueMany:1)]]
&lt;/denchmark-code&gt;

However, in the current &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/blob/28b07e45fd9a10741f2f31b4ed2d8242dba377f2/README.md&gt;README.md&lt;/denchmark-link&gt;
, it says that one can train DeepSpeech with Common Voice on :
&lt;denchmark-code&gt;./DeepSpeech.py --train_files ../data/CV/cv-valid-train.csv,../data/CV/cv-other-train.csv --dev_files ../data/CV/cv-valid-dev.csv --test_files ../data/CV/cv-valid-test.csv
&lt;/denchmark-code&gt;

It's not user-friendly for people going through the README.md.
Suggestions:

Remove ../data/CV/cv-other-train.csv from the command given in README.md
Amend import_cv.py to remove empty transcripts from cv-other-train.csv
Ignore empty transcripts in DeepSpeech.py

	</description>
	<comments>
		<comment id='1' author='Franck-Dernoncourt' date='2018-07-01T18:31:43Z'>
		Thanks for that, I guess the best fix would be:

fix the common voice dataset, I don't know ho we should handle this, but @mikehenrty might be of help
fix the import_cv script

		</comment>
		<comment id='2' author='Franck-Dernoncourt' date='2018-07-02T10:49:58Z'>
		
fix the common voice dataset, I don't know ho we should handle this, but @mikehenrty might be of help

other is our dataset that is not yet validated. there will always get bad data in there, even if we manually removed the ones in question here. users of the website will eventually move those to invalid once users try to listen to them (probably already have). so Common Voice is working as expected here, so I think the issue is only on the importer script.
		</comment>
		<comment id='3' author='Franck-Dernoncourt' date='2018-07-02T14:59:22Z'>
		&lt;denchmark-link:https://github.com/mikehenrty&gt;@mikehenrty&lt;/denchmark-link&gt;
 I missed the fact that this was with other. I guess we should also update the doc with some warning on that point.
		</comment>
		<comment id='4' author='Franck-Dernoncourt' date='2019-01-02T23:52:41Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>