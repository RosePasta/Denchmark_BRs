<bug id='3089' author='DanBmh' open_date='2020-06-18T20:50:38Z' closed_time='2020-06-19T10:22:40Z'>
	<summary>Overlay augmentation hangs after first epoch</summary>
	<description>
Using overlay augmentation is not stable, it does work for the first train and val epoch, but then it stops working at epoch 1 step 0. No error message, it just not continuing to step 1.
Flag used: --augment overlay[p=0.5,source=/DeepSpeech/data_prepared/noise/train.csv,layers=2:1,snr=50:20~6]
I dont use the --feature_cache flag.
I think may be related to the number of noise files, because if i use my normal train.csv instead the noise/train.csv everything works fine and i can train until early stop. The noise/train.csv has about 3600 files and the train.csv ~16k.
I'm using the up to date master, with the augmentation refactoring already merged. Running in the docker container.
&lt;denchmark-link:https://github.com/tilmankamp&gt;@tilmankamp&lt;/denchmark-link&gt;
 , any idea on this?
	</description>
	<comments>
		<comment id='1' author='DanBmh' date='2020-06-19T07:33:38Z'>
		&lt;denchmark-link:https://github.com/DanBmh&gt;@DanBmh&lt;/denchmark-link&gt;
 This sounds like a problem similar to the one I am currently debugging. Up until now I thought this would be related to the (new) caching logic. But your hint on the overlay augmentation is a highly appreciated data point. Will look into it now.
A question: Is this happening only in case of the overlay augmentation?
		</comment>
		<comment id='2' author='DanBmh' date='2020-06-19T09:00:32Z'>
		The full command I use is:
&lt;denchmark-code&gt;Running training with arguments: --train_files /DeepSpeech/data_prepared/voxforge/train_azce.csv --dev_files /DeepSpeech/data_prepared/voxforge/dev_azce.csv --test_files /DeepSpeech/data_prepared/voxforge/test_azce.csv --scorer /DeepSpeech/data_prepared/lm/kenlm_az.scorer --alphabet_config_path /DeepSpeech/deepspeech-german/data/alphabet_az.txt --test_batch_size 32 --train_batch_size 32 --dev_batch_size 32 --epochs 100 --early_stop True --es_epochs 7 --reduce_lr_on_plateau True --plateau_epochs 3 --force_initialize_learning_rate True --learning_rate 0.0001 --dropout_rate 0.25 --use_allow_growth --drop_source_layers 0 --train_cudnn --export_dir /DeepSpeech/checkpoints/voxforge/ --checkpoint_dir /DeepSpeech/checkpoints/voxforge/ --summary_dir /DeepSpeech/checkpoints/voxforge/ --max_to_keep 3 --augment volume[p=0.1,dbfs=-10:-40] --augment pitch[p=0.1,pitch=1.1~0.9] --augment tempo[p=0.1,factor=1.25~0.75] --augment dropout[p=0.1,rate=0.05] --augment add[p=0.1,domain=signal,stddev=0~0.5] --augment multiply[p=0.1,domain=features,stddev=0~0.5] --augment frequency_mask[p=0.1,n=1:3,size=1:5] --augment time_mask[p=0.1,domain=signal,n=3:10~2,size=50:100~40] --augment reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0] --augment resample[p=0.1,rate=12000:8000~4000] --augment codec[p=0.1,bitrate=48000:16000] --augment overlay[p=0.3,source=/DeepSpeech/data_prepared/voxforge/train_azce.csv,layers=10:1,snr=50:20~9]

&lt;/denchmark-code&gt;

I think this is related to the overlay augmentation. Yesterday i did forget the -- in the --augment overlay flag of my cocktailparty augmentation (it seems it left out this augmentation), I did test it again now (with the correct flag) and I have now the same problem with the speech files instead of the noise files too. In both cases it stops after the first epoch.
		</comment>
	</comments>
</bug>