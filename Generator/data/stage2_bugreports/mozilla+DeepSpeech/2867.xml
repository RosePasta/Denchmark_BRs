<bug id='2867' author='cnair-83' open_date='2020-03-31T06:20:17Z' closed_time='2020-04-17T19:03:12Z'>
	<summary>DeepSpeech 0.6.1 - start_time for the first word always zero</summary>
	<description>
DeepSpeech native-client output for the same audio file for 0.5.1 and 0.6.1
&lt;denchmark-h:h2&gt;0.5.1&lt;/denchmark-h&gt;

2019-11-06 17:58:30.581 [  1] I sdkVersion: 1.13.0.
TensorFlow: v1.13.1-13-g174b4760eb.
DeepSpeech: v0.5.1-3-g42c3de0.
Samples count : 145280.
Result : {"metadata":{"confidence":0},"words":[{"word":"visteon","time":1.06,"duration":1.36},{"word":"coupon","time":2.48,"duration":0.72},{"word":"me","time":3.26,"duration":0.24},{"word":"in","time":3.42,"duration":0.0800002},{"word":"the","time":3.52,"duration":0.16},{"word":"direction","time":3.7,"duration":0.4},{"word":"of","time":4.14,"duration":0.16},{"word":"the","time":4.34,"duration":0.1},{"word":"nearest","time":4.46,"duration":0.54},{"word":"shopping","time":5.04,"duration":0.34},{"word":"more","time":5.46,"duration":0.16}]}.
&lt;denchmark-h:h2&gt;0.6.1.&lt;/denchmark-h&gt;

2019-11-06 17:37:46.509 [  1] I sdkVersion: 1.13.0.
TensorFlow: v1.14.0-21-ge77504ac6b.
DeepSpeech: v0.6.1-51-g18403f0.
INFO: Initialized TensorFlow Lite runtime.
Samples count : 145280.
Result : {"metadata":{"confidence":-60.7535},"words":[{"word":"visteon","time":0,"duration":2.4},{"word":"code","time":2.4,"duration":0.3},{"word":"point","time":2.94,"duration":0.26},{"word":"me","time":3.26,"duration":0.12},{"word":"in","time":3.38,"duration":0.1},{"word":"the","time":3.52,"duration":0.0999999},{"word":"direction","time":3.66,"duration":0.38},{"word":"of","time":4.12,"duration":0.0599999},{"word":"the","time":4.22,"duration":0.18},{"word":"nearest","time":4.42,"duration":0.36},{"word":"shopping","time":4.94,"duration":0.36},{"word":"mall","time":5.42,"duration":0.14}]}.
For the first word "visteon" in 0.5.1 client, time shows as 1.06, but in 0.6.1 it is 0.  I even tried the patch &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/pull/2674&gt;#2674&lt;/denchmark-link&gt;
, but still it's giving the time for first word as zero.
&lt;denchmark-link:https://github.com/mozilla/DeepSpeech/files/4407084/samples.zip&gt;samples.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='cnair-83' date='2020-03-31T07:49:01Z'>
		
DeepSpeech native-client output for the same audio file for 0.5.1 and 0.6.1

Do you repro on 0.7.0a3 ?
		</comment>
		<comment id='2' author='cnair-83' date='2020-03-31T08:02:29Z'>
		Currently I don't have a checkpoint for 0.7.0a3, so I could not validate it.
		</comment>
		<comment id='3' author='cnair-83' date='2020-03-31T08:59:07Z'>
		
Currently I don't have a checkpoint for 0.7.0a3, so I could not validate it.

Re-exporting 0.6.1 checkpoint works. I can reproduce the issue :'(.
		</comment>
		<comment id='4' author='cnair-83' date='2020-03-31T09:06:11Z'>
		Turns out, it's not a new issue see &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/issues/2294&gt;#2294&lt;/denchmark-link&gt;
 which seems to have introduced that.
		</comment>
		<comment id='5' author='cnair-83' date='2020-03-31T09:12:25Z'>
		Any  tentative time frame for a fix ?
		</comment>
		<comment id='6' author='cnair-83' date='2020-03-31T09:17:08Z'>
		
Any tentative time frame for a fix ?

This requires to be able to investigate the issue, and we don't have enough bandwidth to do so.
		</comment>
		<comment id='7' author='cnair-83' date='2020-04-10T12:23:00Z'>
		Weird behavior:
&lt;denchmark-code&gt;text: r
start_time: 0 =&gt; out[i].timesteps[j]=0 * 0.02
text: e
start_time: 0.02 =&gt; out[i].timesteps[j]=1 * 0.02
text: s
start_time: 1.12 =&gt; out[i].timesteps[j]=56 * 0.02
&lt;/denchmark-code&gt;

indeed the first two characters have inconsistent timestep with the rest of the word
		</comment>
		<comment id='8' author='cnair-83' date='2020-04-12T10:47:40Z'>
		As far as I can tell this problem happens because we start expanding the trie with all characters in the alphabet on timestep=0 (without logit pruning), and the prefixes created in the first steps are maintained until the later timesteps when characters with high probability from the acoustic model are seen.
The &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/blob/0f71bd2493843168f3ba5d6f4f0206651380f50c/native_client/ctcdecode/path_trie.cpp#L42-L50&gt;heuristic to "push timesteps forward"&lt;/denchmark-link&gt;
 is meant to fix this problem, but the way it's currently implemented, it only pushes forward leaf nodes, which doesn't cover every case. If we relax the condition to:
      if (child-&gt;second-&gt;log_prob_c &lt; cur_log_prob_c &amp;&amp;
          child-&gt;second-&gt;timestep &lt; new_timestep) {
It does fix the early character problem in my tests, but it introduces a new problem: in words with repeated letters (as in "soot", "all") where the second repeated letter has a higher probability than the first one, both repeated letters get assigned the same timestep, breaking monotonicity. This is because in e.g. the "soot" case, when the second "o" is expanded, both the "s" and "so" prefixes still exist. When the "s" prefix is seen, the heuristic gets applied to the child representing the first "o", setting its timestep to be equal to the second "o", which is then also added as a child to the "so" prefix. I don't know how to fix this without even hackier heuristics.
Using &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/blob/0f71bd2493843168f3ba5d6f4f0206651380f50c/native_client/deepspeech.cc#L386&gt;cutoff probability pruning&lt;/denchmark-link&gt;
 also fixes this (without breaking monotonicity) in cases I tested for because on the early (silent) timesteps, the blank label will contain most of the probability mass, and so the "r" and "re" beams will not be created until later, when they're seen with higher probability by the acoustic model. The downside is that it degrades accuracy (although it gives a huge performance boost) and it becomes a new hyperparameter to tune.
Maybe an easier solution is to apply a type of "early pruning", or "late expansion start" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.
		</comment>
		<comment id='9' author='cnair-83' date='2020-04-12T11:04:49Z'>
		
Maybe an easier solution is to apply a type of "early pruning", or "late expansion start" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.

This is what I mean: &lt;denchmark-link:https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f&gt;https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='cnair-83' date='2020-04-14T09:37:10Z'>
		

Maybe an easier solution is to apply a type of "early pruning", or "late expansion start" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.

This is what I mean: https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f

It looks like this is working. We should really have better regressions coverage on that :/
		</comment>
		<comment id='11' author='cnair-83' date='2020-04-14T09:48:01Z'>
		


Maybe an easier solution is to apply a type of "early pruning", or "late expansion start" heuristic, where we only start expanding characters once the blank probability gets lower than some threshold, but after that point we expand all characters. This could be a good compromise between transcription accuracy, high quality timings, and no complicated heuristics.

This is what I mean: https://gist.github.com/reuben/70fdb0bb81b5155aeda3864fbf97766f

It looks like this is working. We should really have better regressions coverage on that :/

As much as I can re-test, this change does fix the present issue and does not regress issue &lt;denchmark-link:https://github.com/mozilla/DeepSpeech/issues/2489&gt;#2489&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/reuben&gt;@reuben&lt;/denchmark-link&gt;
 Do you want to finalize landing this ?
		</comment>
		<comment id='12' author='cnair-83' date='2020-04-17T08:12:24Z'>
		I tried the above patch , and it looks like it solved the start_time issue, but now the duration is not correct always.  Please find below example
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-52-g8431251
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{"metadata":{"confidence":-4.8416},"words":[{"word":"visteon","time":0.24,"duration":0.36}]}
Please find attached test wav file
&lt;denchmark-link:https://drive.google.com/file/d/1_vlqyDldadvWZkLEN23b51cF0Z68Jh4m/view?usp=sharing&gt;https://drive.google.com/file/d/1_vlqyDldadvWZkLEN23b51cF0Z68Jh4m/view?usp=sharing&lt;/denchmark-link&gt;

In this example, it shows incorrect duration value
		</comment>
		<comment id='13' author='cnair-83' date='2020-04-17T08:34:31Z'>
		
In this example, it shows incorrect duration value

What should be the correct value ?
Duration is computed from start_time value.
		</comment>
		<comment id='14' author='cnair-83' date='2020-04-17T08:39:23Z'>
		Yes, duration is computed from start_value. In this case it should be around 0.48 instead of 0.36. The word visteon ends approximately at 0.72 (0.24 + 0.48).
		</comment>
		<comment id='15' author='cnair-83' date='2020-04-17T08:45:25Z'>
		
DeepSpeech: v0.6.1-52-g8431251

This is not 0.6.1

"word":"visteon",

How close is this from the reality? At this point, this is really important, because it will change those values.
		</comment>
		<comment id='16' author='cnair-83' date='2020-04-17T08:47:24Z'>
		I don't even have a 8431251. And I can't really process your WAV file because it's very short, and given we don't yet have a 0.7 model, the 0.6.1 re-exported one cannot get me accuraet result at all:
&lt;denchmark-code&gt;{
  "metadata": {
    "confidence": -11.5804
  },
  "words": [
    {
      "word": "which",
      "time": 0.3,
      "duration": 0.16
    },
    {
      "word": "to",
      "time": 0.5,
      "duration": 0.12
    },
    {
      "word": "do",
      "time": 0.66,
      "duration": 0.02
    }
  ],
  "alternatives": [
    {
      "metadata": {
        "confidence": -9.68734
      },
      "words": [
        {
          "word": "wish",
          "time": 0.3,
          "duration": 0.16
        },
        {
          "word": "to",
          "time": 0.52,
          "duration": 0.12
        },
        {
          "word": "do",
          "time": 0.66,
          "duration": 0.04
        }
      ]
    },
    {
      "metadata": {
        "confidence": -20.0236
      },
      "words": [
        {
          "word": "which",
          "time": 0.3,
          "duration": 0.16
        },
        {
          "word": "to",
          "time": 0.5,
          "duration": 0.12
        },
        {
          "word": "don",
          "time": 0.66,
          "duration": 0.16
        }
      ]
    }
  ]
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='cnair-83' date='2020-04-17T08:48:51Z'>
		The recognition is of word "visteon" is correct. I noticed this issue mainly when the audio is small(single word).
		</comment>
		<comment id='18' author='cnair-83' date='2020-04-17T08:55:33Z'>
		we are using this model for wakeword detection, where the audio sample is samll(one or two words only)
		</comment>
		<comment id='19' author='cnair-83' date='2020-04-17T08:57:44Z'>
		Are you saying the word end time was correct before this patch but is now incorrect?
		</comment>
		<comment id='20' author='cnair-83' date='2020-04-17T09:05:19Z'>
		Please find the result of the same file before applying the patch.
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{"metadata":{"confidence":-4.83948},"words":[{"word":"visteon","time":0,"duration":0.6}]}
This (0.60) seems to be the correct value.
		</comment>
		<comment id='21' author='cnair-83' date='2020-04-17T09:06:38Z'>
		
Please find the result of the same file before applying the patch.
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=38400
{"metadata":{"confidence":-4.83948},"words":[{"word":"visteon","time":0,"duration":0.6}]}
This (0.60) seems to be the correct value.

Is this with or without using a LM ?
		</comment>
		<comment id='22' author='cnair-83' date='2020-04-17T09:10:58Z'>
		These results are with lm. If I try the deepspeech native-client without lm option, I amgetting following error
./deepspeech --model /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/ww/output_graph.tflite --audio /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
Error on stat: 2
Unexpected type for /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav: 0
		</comment>
		<comment id='23' author='cnair-83' date='2020-04-17T09:13:27Z'>
		This is a separate issue, the end time did not change with the patch.
		</comment>
		<comment id='24' author='cnair-83' date='2020-04-17T09:14:55Z'>
		But for the same audio file, the duration value is different before and after the patch.
		</comment>
		<comment id='25' author='cnair-83' date='2020-04-17T09:15:39Z'>
		Because the start time changed, which is the goal of the patch.
		</comment>
		<comment id='26' author='cnair-83' date='2020-04-17T09:16:39Z'>
		Yes, got it,. Should we file a new issue for this.
		</comment>
		<comment id='27' author='cnair-83' date='2020-04-17T09:17:06Z'>
		Sure.
		</comment>
		<comment id='28' author='cnair-83' date='2020-04-17T09:50:10Z'>
		
These results are with lm. If I try the deepspeech native-client without lm option, I amgetting following error
./deepspeech --model /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/ww/output_graph.tflite --audio /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav
TensorFlow: v1.14.0-21-ge77504ac6b
DeepSpeech: v0.6.1-51-g18403f0
INFO: Initialized TensorFlow Lite runtime.
Error on stat: 2
Unexpected type for /storage/emulated/0/Android/data/com.visteon.sns.app/files/sns/pcm/ww/ww_record_1587110146675.wav: 0

Please run on desktop, the c++ native client on Android is very very limited as documented.
		</comment>
		<comment id='29' author='cnair-83' date='2020-05-20T19:52:13Z'>
		This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.
		</comment>
	</comments>
</bug>