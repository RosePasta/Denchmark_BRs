<bug id='2631' author='sanvenDev' open_date='2019-09-27T10:45:27Z' closed_time='2020-05-08T01:26:04Z'>
	<summary>MPC not working with more than or equal to 3 workers</summary>
	<description>
I tried training a model using MPC, using 2 workers was successful. (A minor issue I noticed when using refresh() in computing loss, the loss values are good, otherwise it's computes big large values, which is not interpretable, any clue why this happens can be great to my research.)
Anyways but when using 3 or more workers, I'm facing errors.
First I got error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-7-902fb9b77716&gt; in &lt;module&gt;
     12 x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
     13 m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
---&gt; 14 o=m(x)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--&gt; 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)
     90     @weak_script_method
     91     def forward(self, input):
---&gt; 92         return F.linear(input, self.weight, self.bias)
     93 
     94     def extra_repr(self):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py in overloaded_func(*args, **kwargs)
    745                 handle_func_command = TorchTensor.handle_func_command
    746 
--&gt; 747             response = handle_func_command(command)
    748 
    749             return response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py in handle_func_command(cls, command)
    310             new_command = (cmd, None, new_args, new_kwargs)
    311             # Send it to the appropriate class and get the response
--&gt; 312             response = new_type.handle_func_command(new_command)
    313             # Put back the wrappers where needed
    314             response = syft.frameworks.torch.hook_args.hook_response(

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in handle_func_command(cls, command)
    236             # Try to get recursively the attributes in cmd = "&lt;attr1&gt;.&lt;attr2&gt;.&lt;attr3&gt;..."
    237             cmd = cls.rgetattr(cls, cmd)
--&gt; 238             return cmd(*args, **kwargs)
    239         except AttributeError:
    240             pass

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in linear(*args)
    201                     Un-hook the function to have its detailed behaviour
    202                     """
--&gt; 203                     return torch.nn.functional.native_linear(*args)
    204 
    205                 module.linear = linear

/usr/local/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)
   1406         ret = torch.addmm(bias, input, weight.t())
   1407     else:
-&gt; 1408         output = input.matmul(weight.t())
   1409         if bias is not None:
   1410             output += bias

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/autograd.py in method_with_grad(*args, **kwargs)
    138                 )
    139 
--&gt; 140                 result = getattr(new_self, name)(*new_args, **new_kwargs)
    141 
    142                 # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/precision.py in matmul(self, *args, **kwargs)
    414 
    415         # Send it to the appropriate class and get the response
--&gt; 416         response = getattr(new_self, "matmul")(*new_args, **new_kwargs)
    417 
    418         # Put back SyftTensor on the tensors found in the response

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in matmul(self, other)
    515             return self._public_mul(other, "matmul")
    516 
--&gt; 517         return self._private_mul(other, "matmul")
    518 
    519     def mm(self, *args, **kwargs):

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/additive_shared.py in _private_mul(self, other, equation)
    413             raise AttributeError("For multiplication a crypto_provider must be passed.")
    414 
--&gt; 415         shares = spdz.spdz_mul(cmd, self, other, self.crypto_provider, self.field)
    416 
    417         return shares

/usr/local/lib/python3.7/site-packages/syft/frameworks/torch/crypto/spdz.py in spdz_mul(cmd, x_sh, y_sh, crypto_provider, field)
     43         j = sy.MultiPointerTensor(children=[j1, j0])
     44     else:
---&gt; 45         j = sy.MultiPointerTensor(children=[j1] + j0.child.values())
     46 
     47     delta_b = cmd(delta, b)

TypeError: can only concatenate list (not "dict_values") to list
&lt;/denchmark-code&gt;

I tried cloning the repo, fixing this issue by passing  j0.child.values() to list constructor. Then I faced another error:
&lt;denchmark-code&gt;
Traceback (most recent call last):
   &lt;ipython-input-7-902fb9b77716&gt; in &lt;module&gt;
     o=m(x)
   File "/Users/sandeep/syft/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 493, in __call__
     result = self.forward(*input, **kwargs)
   File "a3.py", line 31, in forward
     x=F.relu(self.fc1(x))
   File "/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py", line 413, in overloaded_func
     response = handle_func_command(command)
   File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/native.py", line 297, in handle_func_command
     response = new_type.handle_func_command(new_command)
   File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py", line 237, in handle_func_command
     return cmd(*args, **kwargs)
  File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py", line 207, in relu
     return tensor.relu()
   File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py", line 141, in method_with_grad
     result = getattr(new_self, name)(*new_args, **new_kwargs)
   File "/Users/sandeep/syft/PySyft/syft/generic/frameworks/hook/hook.py", line 306, in overloaded_syft_method
     response = getattr(new_self, attr)(*new_args, **new_kwargs)
   File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/tensors/interpreters/additive_shared.py", line 793, in relu
     return securenn.relu(self)
   File "/Users/sandeep/syft/PySyft/syft/frameworks/torch/crypto/securenn.py", line 427, in relu
     alice, bob = a_sh.locations
ValueError: too many values to unpack (expected 2)
&lt;/denchmark-code&gt;

To Reproduce
Run this to reproduce:
&lt;denchmark-code&gt;def connect_to_workers(n_workers):
    return [
        sy.VirtualWorker(hook, id=f"worker{i+1}")
        for i in range(n_workers)
    ]
def connect_to_crypto_provider():
    return sy.VirtualWorker(hook, id="crypto_provider")

workers = connect_to_workers(n_workers=3)
sw = connect_to_crypto_provider()

x = th.tensor([1.1,2.0,3.2,4.0]).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
m=th.nn.Linear(4, 1).fix_precision().share(*workers, crypto_provider=sw, requires_grad=True)
o=m(x)
&lt;/denchmark-code&gt;

Desktop (please complete the following information):

OS: MacOS
Version 10.14.6

	</description>
	<comments>
		<comment id='1' author='sanvenDev' date='2019-12-04T16:37:23Z'>
		I'm having the same issue. I know this is a bit old but have you found a solution for this? (Not necessarily using PySyft, but on any Federated Learning solution)
		</comment>
	</comments>
</bug>