<bug id='3207' author='sachin-101' open_date='2020-03-17T05:58:10Z' closed_time='2020-05-22T00:04:56Z'>
	<summary>Inconsistency in remote_send and remote_get operations</summary>
	<description>

The remote pointer operations, remote_get and remote_send work fine together, but break when used in a sequence. Found this issue while working on &lt;denchmark-link:https://github.com/OpenMined/PySyft/issues/2864&gt;#2864&lt;/denchmark-link&gt;

To Reproduce
&lt;denchmark-code&gt;import syft as sy
hook = sy.TorchHook(torch)

def print_config():
    print('-'*10)
    print('   me:',  me._objects)
    print('  bob:', bob._objects)
    print('alice:',alice._objects)
    print('-'*10)

def check_remote_get():
    print("Checking remote_get")
    # me (pointer) -&gt; alice (pointer)-&gt; bob (tensor)
    p2p2x = torch.tensor([1,2,3,4]).send(alice).send(bob)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -&gt; alice (tensor)
    p2x = p2p2x.remote_get()
    print('p2x:', p2x)
    print_config()
    print('***remote_get() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_send():
    print("Checking remote_send")
    # me (pointer) -&gt; bob (tensor)
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -&gt; bob (pointer) -&gt; alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()
    print('***remote_send() works fine***')
    print('\n', '*'*10, '\n')

def check_remote_operations_sequence():
    # me (pointer) -&gt; bob (tensor)
    print("Checking remote_send and remote_get sequence")
    p2x = torch.tensor([1,2,3,4]).send(bob)
    print('p2x:', p2x)
    print_config()

    # after calling remote_send on p2x
    # me (pointer) -&gt; bob (pointer) -&gt; alice (tensor)
    p2p2x = p2x.remote_send(alice)
    print('p2p2x:', p2p2x)
    print_config()

    # after calling remote_get on p2p2x
    # me (pointer) -&gt; bob (tensor)
    p2x_ = p2p2x.remote_get()
    print('p2x_:', p2x_)
    print_config()

    # Throws ObjectNotFoundError
    z = p2x_ + p2x_

def clear_objects():
    bob.clear_objects()
    alice.clear_objects()
    
if __name__ == "__main__":
    me = sy.local_worker
    bob = sy.VirtualWorker(hook, id='bob')
    alice = sy.VirtualWorker(hook, id='alice')
    clear_objects()
    
    check_remote_get()
    clear_objects()

    check_remote_send()
    clear_objects()
    
    check_remote_operations_sequence()
    clear_objects()
&lt;/denchmark-code&gt;

Output
&lt;denchmark-code&gt;p2p2x: (Wrapper)&gt;[PointerTensor | me:89240781371 -&gt; bob:20411805653]
----------
   me: {}
  bob: {20411805653: (Wrapper)&gt;[PointerTensor | bob:20411805653 -&gt; alice:69485423954]}
alice: {69485423954: tensor([1, 2, 3, 4])}
----------
p2x: (Wrapper)&gt;[PointerTensor | me:89240781371 -&gt; bob:20411805653]
----------
   me: {}
  bob: {20411805653: tensor([1, 2, 3, 4])}
alice: {}
----------
***remote_get() works fine***

 ********** 

Checking remote_send
p2x: (Wrapper)&gt;[PointerTensor | me:9842172577 -&gt; bob:52458556840]
----------
   me: {}
  bob: {52458556840: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)&gt;[PointerTensor | me:9842172577 -&gt; bob:52458556840]
----------
   me: {}
  bob: {52458556840: (Wrapper)&gt;[PointerTensor | bob:87311029150 -&gt; alice:52458556840]}
alice: {52458556840: tensor([1, 2, 3, 4])}
----------
***remote_send() works fine***

 ********** 

Checking remote_send and remote_get sequence
p2x: (Wrapper)&gt;[PointerTensor | me:76396849905 -&gt; bob:80366686695]
----------
   me: {}
  bob: {80366686695: tensor([1, 2, 3, 4])}
alice: {}
----------
p2p2x: (Wrapper)&gt;[PointerTensor | me:76396849905 -&gt; bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)&gt;[PointerTensor | bob:43416594800 -&gt; alice:80366686695]}
alice: {80366686695: tensor([1, 2, 3, 4])}
----------
p2x_: (Wrapper)&gt;[PointerTensor | me:76396849905 -&gt; bob:80366686695]
----------
   me: {}
  bob: {80366686695: (Wrapper)&gt;[PointerTensor | bob:43416594800 -&gt; alice:80366686695], 43416594800: tensor([1, 2, 3, 4])}
alice: {}
----------

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/Desktop/GSoC/OpenMined/PySyft/syft/generic/object_storage.py in get_obj(self, obj_id)
     68         try:
---&gt; 69             obj = self._objects[obj_id]
     70         except KeyError as e:

KeyError: 80366686695

During handling of the above exception, another exception occurred:

ObjectNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-2-ca8d557e9987&gt; in &lt;module&gt;
     78     clear_objects()
     79 
---&gt; 80     check_remote_operations_sequence()
     81     clear_objects()

&lt;ipython-input-2-ca8d557e9987&gt; in check_remote_operations_sequence()
     60 
     61     # Throws Error
---&gt; 62     z = p2x_ + p2x_
     63 
     64 def clear_objects():
.
.
.

ObjectNotFoundError: Object "80366686695" not found on worker!!! You just tried to interact with an object ID:80366686695 on &lt;VirtualWorker id:alice #objects:0&gt; which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines. If you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!
&lt;/denchmark-code&gt;

Expected behavior
The remote_get and remote_send operations are Pointer Chain Operations and intuitively should


remote_get: call .get() on the last pointer in chain, move tensor from last worker to its predecessor worker in the pointer chain. Method call should return a PointerTensor, which is at the beginning of chain of pointers which ends at the tensor object.


remote_send: call .send(new_worker) on the tensor at the end of pointer chain, move tensor from last worker to new_worker in the pointer chain. Method call should return a PointerTensor at the beginning of the chain of pointers which ends at the tensor object on new_worker's machine.
I guess the fault is with remote_send method.


	</description>
	<comments>
		<comment id='1' author='sachin-101' date='2020-05-22T00:04:55Z'>
		This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the stale label to unmark it. Otherwise, this will be closed in 7 days.
		</comment>
	</comments>
</bug>