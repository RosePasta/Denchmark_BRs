<bug id='1817' author='robert-wagner' open_date='2019-01-14T22:23:09Z' closed_time='2019-02-05T14:41:31Z'>
	<summary>Constructor of torch.Tensor is broken in the torch_1 branch</summary>
	<description>
Currently in the torch_1 branch we are unable to construct tensors which require gradients (formerly known as variables). The proper way to do this is  torch.Tensor(&lt;list&gt;, requires_grad=True) On the current version this returns the error of
&lt;denchmark-code&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-28-35439c5a0d54&gt; in &lt;module&gt;
----&gt; 1 x = torch.Tensor([1,2,3,4,5], requires_grad=True).send(bob)
      2 y = torch.Tensor([1,1,1,1,1], requires_grad=True).send(bob)

TypeError: new() received an invalid combination of arguments - got (list, requires_grad=bool), but expected one of:
 * (torch.device device)
 * (torch.Storage storage)
 * (Tensor other)
 * (tuple of ints size, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
 * (object data, torch.device device)
      didn't match because some of the keywords were incorrect: requires_grad
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='robert-wagner' date='2019-01-14T22:23:42Z'>
		&lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/iamtrask&gt;@iamtrask&lt;/denchmark-link&gt;
 if you had any insight on this issue that would be appreciated
		</comment>
		<comment id='2' author='robert-wagner' date='2019-01-15T15:31:41Z'>
		trask [3:30 PM]
x = torch.tensor([1.,2,3,45], requires_grad=True)
Théo Ryffel [3:30 PM]
`x = torch.tensor([1.,2,3,4,5], requires_grad=True)``
trask [3:30 PM]
☝️ that works
x = torch.Tensor([1.,2,3,45], requires_grad=True)
		</comment>
		<comment id='3' author='robert-wagner' date='2019-01-20T21:44:09Z'>
		I am reopening this because we are unable to call send on torch.tensor which means either we need to hook torch.tensor or get pytorch to fix this issue upstream (ideally both) cc &lt;denchmark-link:https://github.com/iamtrask&gt;@iamtrask&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='robert-wagner' date='2019-01-25T12:54:37Z'>
		Note that hooking torch.tensor is not trivial since you can't add any attributes, if you try you get:
AttributeError: 'builtin_function_or_method' object has no attribute 'my_attr'
		</comment>
		<comment id='5' author='robert-wagner' date='2019-01-25T13:01:54Z'>
		One work around for owners could be adding owner as a property:
&lt;denchmark-code&gt;@property
        def owner(self):
            if not hasattr(self, "_owner"):
                self._owner = hook_self.local_worker
            return self._owner

        @owner.setter
        def owner(self, new_owner):
            self._owner = new_owner
            return self

        tensor_type.owner = owner
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='robert-wagner' date='2019-02-05T14:41:31Z'>
		Got this to work by just doing initialization normally then adding the attributes after
		</comment>
	</comments>
</bug>