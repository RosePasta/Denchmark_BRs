<bug id='4062' author='abogaziah' open_date='2020-08-21T20:32:58Z' closed_time='2020-08-31T19:59:14Z'>
	<summary>FixedPrecisionTensor: modular operations is broken (again)</summary>
	<description>
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

modules operator produces the wrong answer,
(torch.Tensor([-30]).fix_prec()%2**5).float_prec().
this evaluates to -30 instead of 2
apparently, when you calculate (mod a+1) it make the arithmetic in the field ]-a, a[ instead of [0, a]
for example, any operation mod 10 should produce a number in the range [0, 1, 2, ... 8, 9] but in this class, it produces a number in the range[-9, -8, ... 8, 9]
&lt;denchmark-h:h2&gt;How to Reproduce&lt;/denchmark-h&gt;


run (torch.Tensor([-30]).fix_prec()%2**5).float_prec()

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

(torch.Tensor([-30]).fix_prec()%2**5).float_prec() = 2
	</description>
	<comments>
	</comments>
</bug>