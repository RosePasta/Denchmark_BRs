<bug id='3261' author='AlanAboudib' open_date='2020-03-27T13:48:18Z' closed_time='2020-03-31T19:44:14Z'>
	<summary>fix_precision() is inplace when applied to a pointer tensor.</summary>
	<description>
Description of the bug
The method fix_precision() applied on pointers is 'inplace'. This should not be the case
In the following code:
&lt;denchmark-code&gt;a = torch.Tensor([2., 3.]).send(bob)
a.fix_precision()
a = a.get()
print(type(a))
&lt;/denchmark-code&gt;

The variable  a after calling get() is a fixed precision tensor which is a bug, because the original variable a defined as torch.Tensor([2., 3.]) is not a fixed precision tensor.
However, this bug is not existing in case when  a is not a pointer:
&lt;denchmark-code&gt;a = torch.Tensor([2., 3.])
a.fix_precision()
print(type(a))
&lt;/denchmark-code&gt;

a here is not a fixed precision tensor. which is the desired behavior.
Desktop:

OS: Archlinux
Version 0.3.2

	</description>
	<comments>
		<comment id='1' author='AlanAboudib' date='2020-03-27T14:05:30Z'>
		I can take this!!
		</comment>
		<comment id='2' author='AlanAboudib' date='2020-03-28T06:50:10Z'>
		Hey &lt;denchmark-link:https://github.com/AlanAboudib&gt;@AlanAboudib&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/karlhigley&gt;@karlhigley&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
 ,
so if I understand this correctly,
x = th.Tensor([1.,2.,3.]).send(bob)
x_fx = x.fix_precision()
x = x_fx.get()
x_fx is a PointerTensor and expected behavior is to be a FixedPrecisionTensor with PointerTensor as child?
Moreover when we .get() the x_fx, it returns FixedPrecisionTensor, which I think is a correct behavior, as we haven't called float_precision yet.
		</comment>
		<comment id='3' author='AlanAboudib' date='2020-03-28T12:32:45Z'>
		not exactly, fix_precision() should be applied anyway on the remote value when called on a pointer (and it works fine)
the issue is that currently we have this for pointers:
&lt;denchmark-code&gt;a = torch.Tensor([2., 3.]).send(bob)
a_fp = a.fix_precision()
# a_fp is a pointer to a fixed precision, but a is too!
&lt;/denchmark-code&gt;

while for non pointers:
&lt;denchmark-code&gt;a = torch.Tensor([2., 3.])
a_fp = a.fix_precision()
# a_fp is a wrapper onto a fixed precision, but a is not!
&lt;/denchmark-code&gt;

So for pointers, fix_precision behaves as fix_precision_ while it shouldn't
		</comment>
	</comments>
</bug>