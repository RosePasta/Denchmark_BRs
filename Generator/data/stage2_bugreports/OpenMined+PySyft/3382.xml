<bug id='3382' author='Nilanshrajput' open_date='2020-04-21T13:55:20Z' closed_time='2020-07-05T00:08:50Z'>
	<summary>PySyft Tensor shape and size() call returns different values</summary>
	<description>
Describe the bug
After sending tensor to a worker the size() call returns torch.Size([0]) while .shape returns correct value.
To Reproduce
Steps to reproduce the behavior:
1.
data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)
bobs_data = data.send(bob)
print(bobs_data.shape) -&gt; torch.Size([4, 2])
print(bobs_data.size()) -&gt; torch.Size([0])
Expected behavior
size() method call should return correct value
Screenshots
If applicable, add screenshots to help explain your problem.
Desktop (please complete the following information):

OS: [Ubuntu]
Version [18]

Additional context
This is very important as Pytorch essentially uses size() for getting shape/size of attribute, shape attribute is only to give some similarity with numpy.
And in most of pre-defined Pytorch models size() is used. So it won't  be possible to use most pre-defined Pytorch models with PySyft
	</description>
	<comments>
		<comment id='1' author='Nilanshrajput' date='2020-04-21T19:57:42Z'>
		Hey, this is a known issue: it is not possible to hook the size like we did for the shape because the size is used by the print function, which for Pointers wrapped into an empty torch tensor needs to be applied on this wrapper and not on the remote value.
		</comment>
		<comment id='2' author='Nilanshrajput' date='2020-04-21T19:58:08Z'>
		Well maybe there is a way to fix this, but this is why we didn't manage to get it working :)
		</comment>
		<comment id='3' author='Nilanshrajput' date='2020-05-14T19:27:46Z'>
		&lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/16415585/81976943-45e02680-95f7-11ea-948f-6d919d58ee7b.png&gt;&lt;/denchmark-link&gt;

If I am not mistaken now we are getting the size of the (empty) torch tensor, How does this happen differently when it comes to Size method only?
		</comment>
		<comment id='4' author='Nilanshrajput' date='2020-06-28T00:07:25Z'>
		This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the stale label to unmark it. Otherwise, this will be closed in 7 days.
		</comment>
		<comment id='5' author='Nilanshrajput' date='2020-09-24T12:14:45Z'>
		Hi &lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
, any news about this issue?
The (big) problem related to this is that models cannot be executed on private tensors :(
		</comment>
		<comment id='6' author='Nilanshrajput' date='2020-09-24T15:49:31Z'>
		Hey &lt;denchmark-link:https://github.com/xanderwallace85&gt;@xanderwallace85&lt;/denchmark-link&gt;
!
This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?
		</comment>
		<comment id='7' author='Nilanshrajput' date='2020-09-24T18:11:17Z'>
		
Hey @xanderwallace85!
This issue won't be solved shortly I think... why exactly do you need size and shape won't do the job?

Hi &lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
 ! Apparently, even simple CNN models do not work when using private tensors. I believe this is due to the size function :(  For instance, a model like the one below won't work as the function size is required (by the nn.Linear?).
&lt;denchmark-code&gt;class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
&lt;/denchmark-code&gt;

Is there an alternative to private tensors? As I am looking for a solution to hide the data in the nodes (so not allowing the .get(), for example).
Would be a pity to not be able to fully exploit private tensors though :(
		</comment>
	</comments>
</bug>