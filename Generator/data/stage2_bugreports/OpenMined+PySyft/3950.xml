<bug id='3950' author='abogaziah' open_date='2020-08-05T20:13:02Z' closed_time='2020-12-08T00:12:01Z'>
	<summary>Fixed precision tensor: linear operations with torch tensor are broken</summary>
	<description>
fixed precision tensor is supposed to work correctly given an int or float to be subtracted from or added to, just like a torch tensor.
for example:
torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
this should be the correct behavior of FPT:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
but instead we get:
(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)
multiplication also is broken.
any fix should be tested against all arithmetic operations (add, sub, mul, div, ..etc)
	</description>
	<comments>
		<comment id='1' author='abogaziah' date='2020-08-10T21:36:02Z'>
		I'd like to take this on :)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Formatting the exit condition and setup for easier checking
&lt;denchmark-code&gt;torch.tensor(5) + 5 = tensor(10)
torch.tensor(5) - 5 = tensor(0)
&lt;/denchmark-code&gt;

this should be the correct behavior of FPT:
&lt;denchmark-code&gt;(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = tensor(0)
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(10)
&lt;/denchmark-code&gt;

but instead we get:
&lt;denchmark-code&gt;(torch.tensor(5).fix_prec() - torch.tensor(5)).float_prec() = PureFrameworkTensorFoundError
(torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='abogaziah' date='2020-08-19T11:19:59Z'>
		&lt;denchmark-link:https://github.com/IanQS&gt;@IanQS&lt;/denchmark-link&gt;
 how it goes with this issue. Did you start work on it?
		</comment>
		<comment id='3' author='abogaziah' date='2020-08-19T15:43:50Z'>
		Heya &lt;denchmark-link:https://github.com/gmuraru&gt;@gmuraru&lt;/denchmark-link&gt;
 !
I've started working on it but I'm running into roadblocks. I've solved the
torch.tensor(5) + torch.tensor(5).fix_prec()).float_prec() = tensor(5.0050) but admittedly my solution isn't pretty and I've not run tests to make sure that my changes don't break anything.
I'm not too sure about how to solve the first issue (PureFrameworkTensorFoundError) I'd love some guidance if you've got any insight into it
		</comment>
		<comment id='4' author='abogaziah' date='2020-08-20T01:49:32Z'>
		&lt;denchmark-link:https://github.com/gmuraru&gt;@gmuraru&lt;/denchmark-link&gt;

I've linked my PR to this. Let me know if you think I'm going down the wrong path. I'd love to get feedback as I go along. I'm still trying to figure out how to address the PureFrameworkTensorFoundError
		</comment>
		<comment id='5' author='abogaziah' date='2020-08-20T13:24:05Z'>
		&lt;denchmark-link:https://github.com/IanQS&gt;@IanQS&lt;/denchmark-link&gt;
 you'd wanna look at the operations of the native tensor, since torch.Tensor+FPT calls the  method of the native tensor (torch.Tensor)
		</comment>
		<comment id='6' author='abogaziah' date='2020-08-20T22:34:35Z'>
		Got it! I'll look into syft.frameworks.torch.tensor.interpreters.Tensor specifically the add! I'll get to it this weekend and will try my best to have something up by Monday.
		</comment>
		<comment id='7' author='abogaziah' date='2020-08-21T12:22:59Z'>
		&lt;denchmark-link:https://github.com/IanQS&gt;@IanQS&lt;/denchmark-link&gt;
 let's review and merge the first fix and make the second one in a separate PR
		</comment>
		<comment id='8' author='abogaziah' date='2020-09-01T18:26:52Z'>
		Hey &lt;denchmark-link:https://github.com/abogaziah&gt;@abogaziah&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gmuraru&gt;@gmuraru&lt;/denchmark-link&gt;

I think it might be better for me to unassign myself. I'm really not sure how to fix the issue or where to put the fixes so it might be better for someone else to try and take it on. I'll close out the PR but leave a reference to it
		</comment>
		<comment id='9' author='abogaziah' date='2020-09-11T05:16:46Z'>
		Hi &lt;denchmark-link:https://github.com/abogaziah&gt;@abogaziah&lt;/denchmark-link&gt;
 I would like to attempt this if still available
		</comment>
		<comment id='10' author='abogaziah' date='2020-09-11T11:39:42Z'>
		&lt;denchmark-link:https://github.com/duggalsu&gt;@duggalsu&lt;/denchmark-link&gt;
 sure, go-ahead
		</comment>
		<comment id='11' author='abogaziah' date='2020-10-29T09:36:50Z'>
		I would like to fix this if still available
		</comment>
		<comment id='12' author='abogaziah' date='2020-10-29T10:11:25Z'>
		Hi &lt;denchmark-link:https://github.com/xutongye&gt;@xutongye&lt;/denchmark-link&gt;
 , I've started to work on this now. Will need a few days. I'll let you know if I cannot finish it.
		</comment>
		<comment id='13' author='abogaziah' date='2020-10-30T08:21:51Z'>
		&lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
 I know we discussed yesterday about this behavior.
We throw an exception if:

float_tensor (+|-|*|/) fix_prec_tensor
fix_prec_tensor (+|-|*|/) float_tensor

This was the conclusion, right?
		</comment>
		<comment id='14' author='abogaziah' date='2020-11-30T00:11:47Z'>
		This issue has been marked stale because it has been open 30 days with no activity. Leave a comment or remove the stale label to unmark it. Otherwise, this will be closed in 7 days.
		</comment>
	</comments>
</bug>