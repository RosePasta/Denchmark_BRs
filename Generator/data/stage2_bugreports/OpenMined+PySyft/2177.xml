<bug id='2177' author='LaRiffle' open_date='2019-05-29T10:47:52Z' closed_time='2019-11-15T09:17:53Z'>
	<summary>Fix ambiguous_functions in hook_args</summary>
	<description>
in hook_args if you want to add function to ambiguous_functions like stack you need to add torch.stack and stack while only should be needed torch.stack
This is due to an error in overload_torch.py where we don't retrieve the module of functions correctly
	</description>
	<comments>
		<comment id='1' author='LaRiffle' date='2019-06-06T20:33:09Z'>
		&lt;denchmark-link:https://github.com/LaRiffle&gt;@LaRiffle&lt;/denchmark-link&gt;
 could you clarify where the module of functions should be be retrieved in this file? There does not appear to be anything which explicitly checks to see if they are in the exclude_functions list
		</comment>
		<comment id='2' author='LaRiffle' date='2019-06-09T15:54:46Z'>
		At l.50 we do
&lt;denchmark-code&gt;# Replace all syft tensor with their child attribute
            new_args, new_kwargs, new_type = syft.frameworks.torch.hook_args.hook_function_args(
                attr.__name__, args, kwargs
            )
&lt;/denchmark-code&gt;

But ideally we should be replace attr.__name__ with smthg like attr.__module__+'.'+attr.__name__
However hooked functions have a module which is changed and we would like to keep the original module. Note the hooked functions are in hook.py and with @overload.module and @overload.function decorator in tensor definition files.
I'd like to underline that this is not a trivial issue
		</comment>
	</comments>
</bug>