<bug id='600' author='Punchwes' open_date='2019-01-30T02:47:59Z' closed_time='2019-01-30T04:24:57Z'>
	<summary>Embedding dimension not match?</summary>
	<description>
The loading embedding matrix process in the DRMM tutorial seems to have problem. The embedding input dimension is set to be the vocabulary size (which is the length of term_index), but the result of your build_matrix function gives incompatible input dimension which raises error when calling the load_embedding_matrix function.
Is there anything wrong with it? I try to make some modifications to the source code to make compatible dimension but the final result has large gap between your DRMM tutorial, and the training loss does not decrease.
	</description>
	<comments>
		<comment id='1' author='Punchwes' date='2019-01-30T03:28:43Z'>
		Did you figure it out?
		</comment>
		<comment id='2' author='Punchwes' date='2019-01-30T04:24:57Z'>
		Actually no, I just thought the bug label might not be appropriate..... So I closed this and opened another question-tagged issue.
		</comment>
	</comments>
</bug>