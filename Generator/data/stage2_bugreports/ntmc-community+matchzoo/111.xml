<bug id='111' author='ymzx' open_date='2018-05-23T13:43:59Z' closed_time='2018-06-04T13:39:14Z'>
	<summary>FileNotFoundError: [Errno 2] No such file or directory: './data/QuoraQP/embed_glove_d300_norm'</summary>
	<description>
where I  try the 'python matchzoo/main.py --phase train --model_file examples/QuoraQP/config/matchpyramid_quoraqp.config'  which you recommended, but it have some things error,such as 'No such file or directory: './data/QuoraQP/embed_glove_d300_norm', I knowe this file is needed but you have not put in, I think you can finshed it, thanks!
	</description>
	<comments>
		<comment id='1' author='ymzx' date='2018-05-23T20:34:00Z'>
		&lt;denchmark-link:https://github.com/ymzx&gt;@ymzx&lt;/denchmark-link&gt;

Sorry for the inconvenience, but there should be a  under QuoraQP directory as described in MatchZoo Readme.
However, for unknown reasons, it disappeared ... &lt;denchmark-link:https://github.com/yangliuy&gt;@yangliuy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/faneshion&gt;@faneshion&lt;/denchmark-link&gt;

But this is what you're looking for:
#!/bin/bash
# download the quora train dataset
wget http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv

:&lt;&lt;!EOF!
# you can also download the quora train dataset from kaggle
#Attentionï¼›You need to  register the Kaggle account to download the dataset
wget --keep-session-cookies --save-cookies cookies.txt --post-data "username=username&amp;password=password" "https://www.kaggle.com/account/login?isModal=true&amp;returnUrl=/"
wget --load-cookies=cookies.txt  "https://www.kaggle.com/c/quora-question-pairs/download/train.csv.zip"
unzip train.csv.zip
#download the quora test dataset
wget --load-cookies=cookies.txt "https://www.kaggle.com/c/quora-question-pairs/download/test.csv.zip"
unzip test.csv.zip
!EOF!

# You can also download and unzip it manually on the official web, and save it to the current directory

# download the glove vectors
wget http://nlp.stanford.edu/data/glove.840B.300d.zip
unzip glove.840B.300d.zip
wget http://nlp.stanford.edu/data/glove.6B.zip
unzip glove.6B.zip

# generate the mz-datasets
python prepare_mz_data.py

# generate word embedding
GLOVE='.'
python gen_w2v.py  $GLOVE/glove.840B.300d.txt word_dict.txt embed_glove_d300
python norm_embed.py embed_glove_d300 embed_glove_d300_norm
python gen_w2v.py  $GLOVE/glove.6B.50d.txt word_dict.txt embed_glove_d50
python norm_embed.py embed_glove_d50 embed_glove_d50_norm

# generate idf file
cat word_stats.txt | cut -d ' ' -f 1,4 &gt; embed.idf

# generate data histograms for drmm model
python gen_hist4drmm.py 60

# generate data bin sums for anmm model
python gen_binsum4anmm.py 20 # the default number of bin is 20

echo "Done ..."
Create run_data.sh under MatchZoo/examples/QuoraQP/run_data.sh, then run it.
		</comment>
		<comment id='2' author='ymzx' date='2018-06-04T13:39:14Z'>
		I'll close this issue for now, if you have further questions please feel free to re-open it or create a new issue. Best!
		</comment>
	</comments>
</bug>