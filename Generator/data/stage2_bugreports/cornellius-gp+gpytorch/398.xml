<bug id='398' author='jacobrgardner' open_date='2018-11-26T22:13:58Z' closed_time='2018-11-29T19:45:19Z'>
	<summary>Size mismatch in batch mode GaussianLikelihood</summary>
	<description>
&lt;denchmark-link:https://github.com/Balandat&gt;@Balandat&lt;/denchmark-link&gt;
 just ran in to an issue that I tracked back to this line:


Should this be:
shape = mean.shape
Haven't we been letting batch means be b x n, meaning shape would be [b] and then as written noise_covar will be b x b x b instead of b x n x n?
	</description>
	<comments>
		<comment id='1' author='jacobrgardner' date='2018-11-26T22:27:29Z'>
		Yeah so this is kind of tricky in general because you can have batched single-output GPs or non-batched multi-task GPs. On top of that you can do batch training and point evaluation or vice versa.  See discussion here: 


gpytorch/gpytorch/likelihoods/noise_models.py


        Lines 34 to 49
      in
      00ddfc8






 def forward(self, *params, shape=None): 



 """In the homoskedastic case, the parameters are only used to infer the required shape. 



         Here are the possible scenarios: 



         - non-batched noise, non-batched input, non-MT -&gt; noise_diag shape is `n` 



         - non-batched noise, non-batched input, MT -&gt; noise_diag shape is `nt` 



         - non-batched noise, batched input, non-MT -&gt; noise_diag shape is `b x n` with b' the broadcasted batch shape 



         - non-batched noise, batched input, MT -&gt; noise_diag shape is `b x nt` 



         - batched noise, non-batched input, non-MT -&gt; noise_diag shape is `b x n` 



         - batched noise, non-batched input, MT -&gt; noise_diag shape is `b x nt` 



         - batched noise, batched input, non-MT -&gt; noise_diag shape is `b' x n` 



         - batched noise, batched input, MT -&gt; noise_diag shape is `b' x nt` 



         where `n` is the number of evaluation points and `t` is the number of tasks (i.e. `num_tasks` of self.noise). 



         So bascially the shape is always `b' x nt`, with `b'` appropriately broadcast from the noise parameter and 



         input batch shapes. `n` and the input batch shape are determined either from the shape arg or from the params 



         input. For this it is sufficient to take in a single `shape` arg, with the convention that shape[:-1] is the 



         batch shape of the input, and shape[-1] is `n`. 





Maybe the correct thing to do here is to explicitly check whether the input is a MultitaskMultivariateNormal.
		</comment>
		<comment id='2' author='jacobrgardner' date='2018-11-26T22:37:46Z'>
		I see what you're saying. Yeah, I think checking the type of the input makes sense or maybe a shape property. Either way I think it's broken on master for batch mode non Multitask GPs
		</comment>
		<comment id='3' author='jacobrgardner' date='2018-11-26T22:38:50Z'>
		As an addendum, I'm surprised the batch mode unit test passed...
		</comment>
		<comment id='4' author='jacobrgardner' date='2018-11-29T19:45:19Z'>
		This is fixed via &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/400&gt;#400&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>