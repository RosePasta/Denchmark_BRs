<bug id='1254' author='dialuser' open_date='2020-08-18T19:26:42Z' closed_time='2020-08-18T20:23:09Z'>
	<summary>[Bug]</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

Tensor object has no attribute 'ndim'
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

Run the multioutput example, from &lt;denchmark-link:https://docs.gpytorch.ai/en/latest/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html&gt;https://docs.gpytorch.ai/en/latest/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html&lt;/denchmark-link&gt;

** Code snippet to reproduce **
# Your code goes here
# Please make sure it does not require any external dependencies (other than PyTorch!)
# (We much prefer small snippets rather than links to existing libraries!)
** Stack trace/error message **
File "/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py", line 107, in backward
torch.autograd.backward(self, gradient, retain_graph, create_graph)
File "/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/init.py", line 93, in backward
allow_unreachable=True)  # allow_unreachable flag
File "/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/function.py", line 77, in apply
return self._forward_cls.backward(self, *args)
File "/opt/anaconda3/lib/python3.7/site-packages/gpytorch/functions/_matmul.py", line 46, in backward
arg_grads = ctx.representation_tree(*matrix_args)._quad_form_derivative(grad_output_matrix, rhs)
File "/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/block_lazy_tensor.py", line 114, in _quad_form_derivative
if left_vecs.ndim == 1:
AttributeError: 'Tensor' object has no attribute 'ndim'
// Paste the bad output here!
&lt;denchmark-code&gt;
## Expected Behavior

&lt;!-- A clear and concise description of what you expected to happen. --&gt;

## System information

**Please complete the following information:**
- &lt;!-- GPyTorch Version (run `print(gpytorch.__version__)` --&gt;
- &lt;!-- PyTorch Version (run `print(torch.__version__)` --&gt;
- &lt;!-- Computer OS --&gt;

## Additional context
Add any other context about the problem here.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='dialuser' date='2020-08-18T19:57:40Z'>
		Are you using an old version of pytorch? See &lt;denchmark-link:https://github.com/huggingface/transformers/issues/5593&gt;huggingface/transformers#5593&lt;/denchmark-link&gt;
 for example
		</comment>
		<comment id='2' author='dialuser' date='2020-08-18T20:23:09Z'>
		Yes. I'm using pytorch 1.1. I'm in the process of updating. Thanks.
		</comment>
	</comments>
</bug>