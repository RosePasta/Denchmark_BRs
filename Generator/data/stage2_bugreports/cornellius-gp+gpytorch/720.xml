<bug id='720' author='stevenstetzler' open_date='2019-06-05T05:18:49Z' closed_time='2019-07-29T16:19:56Z'>
	<summary>[Bug] Product kernel produces error when obtaining diagonal for predictive variance</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

In some cases when producing predictive variance, I get an error RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([500]). Got size torch.Size([1, 500]), where size here refers to the size of data passed to model(data). I've checked the sizes of my inputs, and they are all in order. The issue also appears to go away when I decrease the size of the data set.
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

Code snippet to reproduce
Please see attached data file to use the same data. This appears to be a number of data points issue and/or a product kernel issue, so maybe it can be reproduced otherwise.
import torch
import gpytorch
from matplotlib import pyplot as plt
import numpy as np

# Define GP model
class PeriodicGP(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super(PeriodicGP, self).__init__(train_x, train_y, likelihood)

        self.mean_module = gpytorch.means.ConstantMean()
        
        covar_prod = gpytorch.kernels.RBFKernel() * gpytorch.kernels.PeriodicKernel()
        self.covar_module = gpytorch.kernels.ScaleKernel(covar_prod)

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

data = np.loadtxt("broken_data.txt", dtype=float)
train_x = torch.tensor(data[:, 0], dtype=torch.float)
train_y = torch.tensor(data[:, 1], dtype=torch.float)
train_y_err = torch.tensor(data[:, 2], dtype=torch.float)

# Show the data
plt.errorbar(train_x.detach().numpy(), train_y.detach().numpy(), train_y_err.detach().numpy(), fmt='o')
plt.show()

# Define likelihood and model
likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)
model = PeriodicGP(train_x, train_y, likelihood)

# Plot results
model.eval(), likelihood.eval()
with torch.no_grad(), gpytorch.settings.fast_pred_var():
    test_x = train_x
    test_y_err = train_y_err
    
    result = model(test_x)
    
    observed_pred = likelihood(result, noise=test_y_err)
    lower, upper = observed_pred.confidence_region()
    
    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color="blue")
    plt.scatter(train_x, train_y, color="k")
    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color="C0")
    plt.show()
Stack trace/error message
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-34-2ec9df0172e9&gt; in &lt;module&gt;
      7 
      8     observed_pred = likelihood(result, noise=test_y_err)
----&gt; 9     lower, upper = observed_pred.confidence_region()
     10 
     11     plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color="blue")

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py in confidence_region(self)
     77 
     78         """
---&gt; 79         std2 = self.stddev.mul_(2)
     80         mean = self.mean
     81         return mean.sub(std2), mean.add(std2)

~/.conda/envs/mypy/lib/python3.6/site-packages/torch/distributions/distribution.py in stddev(self)
    109         Returns the standard deviation of the distribution.
    110         """
--&gt; 111         return self.variance.sqrt()
    112 
    113     def sample(self, sample_shape=torch.Size()):

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/distributions/multivariate_normal.py in variance(self)
    181         if self.islazy:
    182             # overwrite this since torch MVN uses unbroadcasted_scale_tril for this
--&gt; 183             diag = self.lazy_covariance_matrix.diag()
    184             diag = diag.view(diag.shape[:-1] + self._event_shape)
    185             return diag.expand(self._batch_shape + self._event_shape)

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in diag(self)
     78 
     79     def diag(self):
---&gt; 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]
     81         size = diags[0].size()
     82         res = sum(diag.view(-1) for diag in diags)

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in &lt;listcomp&gt;(.0)
     78 
     79     def diag(self):
---&gt; 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]
     81         size = diags[0].size()
     82         res = sum(diag.view(-1) for diag in diags)

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in diag(self)
     78 
     79     def diag(self):
---&gt; 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]
     81         size = diags[0].size()
     82         res = sum(diag.view(-1) for diag in diags)

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/sum_lazy_tensor.py in &lt;listcomp&gt;(.0)
     78 
     79     def diag(self):
---&gt; 80         diags = [lazy_tensor.diag().contiguous() for lazy_tensor in self.lazy_tensors]
     81         size = diags[0].size()
     82         res = sum(diag.view(-1) for diag in diags)

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)
     32         cache_name = name if name is not None else method
     33         if not is_in_cache(self, cache_name):
---&gt; 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))
     35         return get_from_cache(self, cache_name)
     36 

~/.conda/envs/mypy/lib/python3.6/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py in diag(self)
    248                 raise RuntimeError(
    249                     "The kernel {} is not equipped to handle and diag. Expected size {}. "
--&gt; 250                     "Got size {}".format(self.__class__.__name__, expected_shape, res.shape)
    251                 )
    252 

RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([500]). Got size torch.Size([1, 500])
&lt;/denchmark-code&gt;

I can resolve this by removing data:
# take first 10 data points
train_x = torch.tensor(data[:, 0], dtype=torch.float)[:10]
train_y = torch.tensor(data[:, 1], dtype=torch.float)[:10]
train_y_err = torch.tensor(data[:, 2], dtype=torch.float)[:10]

likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)
model = PeriodicGP(train_x, train_y, likelihood)
model.eval(), likelihood.eval()
with torch.no_grad(), gpytorch.settings.fast_pred_var():
    test_x = train_x
    test_y_err = train_y_err
    
    result = model(test_x)
    
    observed_pred = likelihood(result, noise=test_y_err)
    lower, upper = observed_pred.confidence_region()
    
    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color="blue")
    plt.scatter(train_x, train_y, color="k")
    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color="C0")
    plt.show()
This produces the expected result, although I'd expect that the confidence region should be much smaller based on the errors in the data:
&lt;denchmark-link:https://user-images.githubusercontent.com/11035971/58931476-ae026900-8714-11e9-99ee-417677377642.png&gt;&lt;/denchmark-link&gt;

I can also resolve this by removing the product nature of the kernel:
class PeriodicGP(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super(PeriodicGP, self).__init__(train_x, train_y, likelihood)

        self.mean_module = gpytorch.means.ConstantMean()
        
        covar_prod = gpytorch.kernels.RBFKernel()
        self.covar_module = gpytorch.kernels.ScaleKernel(covar_prod)

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

train_x = torch.tensor(data[:, 0], dtype=torch.float)
train_y = torch.tensor(data[:, 1], dtype=torch.float)
train_y_err = torch.tensor(data[:, 2], dtype=torch.float)

plt.errorbar(train_x.detach().numpy(), train_y.detach().numpy(), train_y_err.detach().numpy(), fmt='o')
plt.show()

likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_y_err, learn_additional_noise=False)
model = PeriodicGP(train_x, train_y, likelihood)

model.eval(), likelihood.eval()
with torch.no_grad(), gpytorch.settings.fast_pred_var():
    test_x = train_x
    test_y_err = train_y_err
    
    result = model(test_x)
    
    observed_pred = likelihood(result, noise=test_y_err)
    lower, upper = observed_pred.confidence_region()
    
    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color="blue")
    plt.scatter(train_x, train_y, color="k")
    plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color="C0")
    plt.show()
produces expected results. Again, I'd expect that the confidence region should be much smaller based on the errors in the data.
&lt;denchmark-link:https://user-images.githubusercontent.com/11035971/58931570-02a5e400-8715-11e9-8a39-5ce3aae1a206.png&gt;&lt;/denchmark-link&gt;

Finally note that I can still produce the predictive mean, it is just the variance that is breaking:
# using the original kernel and all data
model.eval(), likelihood.eval()
with torch.no_grad(), gpytorch.settings.fast_pred_var():
    test_x = train_x
    test_y_err = train_y_err
    
    result = model(test_x)
    
    observed_pred = likelihood(result, noise=test_y_err)
#     lower, upper = observed_pred.confidence_region()
    
    plt.plot(test_x.detach().numpy(), observed_pred.mean.detach().numpy(), color="blue")
    plt.scatter(train_x, train_y, color="k")
#     plt.fill_between(test_x, lower.detach().numpy(), upper.detach().numpy(), alpha=0.5, color="C0")
    plt.show()
produces the expected result:
&lt;denchmark-link:https://user-images.githubusercontent.com/11035971/58931625-354fdc80-8715-11e9-9866-348a9e98d9b2.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

I expected the variance to be computed correctly, as is done in many other cases with the same data.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

GPyTorch Version (run print(gpytorch.__version__))
0.3.2
PyTorch Version (run print(torch.__version__))
1.1.0
Computer OS
CentOS Linux release 7.6.1810

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

Data:
&lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/files/3255597/broken_data.txt&gt;broken_data.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='stevenstetzler' date='2019-07-29T16:19:46Z'>
		This seems to run fine for me now. Are you on the latest version?
&lt;denchmark-link:https://user-images.githubusercontent.com/11478740/62064552-19d7ee00-b1fb-11e9-8204-78600d5ada08.png&gt;&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>