<bug id='749' author='MichaelDoron' open_date='2019-06-23T13:10:22Z' closed_time='2019-06-27T19:05:08Z'>
	<summary>[Bug] PeriodicKernel returns error with BernoulliLikelihood</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

When running the simple GPClassificationModel example (as in &lt;denchmark-link:https://gpytorch.readthedocs.io/en/latest/examples/02_Simple_GP_Classification/Simple_GP_Classification.html&gt;https://gpytorch.readthedocs.io/en/latest/examples/02_Simple_GP_Classification/Simple_GP_Classification.html&lt;/denchmark-link&gt;
), and changing the RBFKernel to a PeriodicKernel, the  line returns a RuntimeError:
RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([101]). Got size torch.Size([1, 101])
This error does not occur when changing the RBFKernel to a LinearKernel, or when changing the BernoulliLikelihood to GaussianLikelihood.
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import math
import torch
import gpytorch
from matplotlib import pyplot as plt

train_x = torch.linspace(0, 1, 10)
train_y = torch.sign(torch.cos(train_x * (4 * math.pi))).add(1).div(2)

from gpytorch.models import AbstractVariationalGP
from gpytorch.variational import CholeskyVariationalDistribution
from gpytorch.variational import VariationalStrategy

class GPClassificationModel(AbstractVariationalGP):
    def __init__(self, train_x):
        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))
        variational_strategy = VariationalStrategy(self, train_x, variational_distribution)
        super(GPClassificationModel, self).__init__(variational_strategy)
        self.mean_module = gpytorch.means.ConstantMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel())

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)
        return latent_pred


model = GPClassificationModel(train_x)
likelihood = gpytorch.likelihoods.BernoulliLikelihood()

from gpytorch.mlls.variational_elbo import VariationalELBO

model.train()
likelihood.train()

optimizer = torch.optim.Adam(model.parameters(), lr=0.1)

mll = VariationalELBO(likelihood, model, train_y.numel())

training_iter = 50
for i in range(training_iter):
    optimizer.zero_grad()
    output = model(train_x)
    loss = -mll(output, train_y)
    loss.backward()
    optimizer.step()

model.eval()
likelihood.eval()

with torch.no_grad():
    test_x = torch.linspace(0, 1, 101)
    observed_pred = likelihood(model(test_x))

print('Reached the end of the script, successfully calculated likelihood')
&lt;/denchmark-code&gt;

** Stack trace/error message **
&lt;denchmark-code&gt;RuntimeError: The kernel LazyEvaluatedKernelTensor is not equipped to handle and diag. Expected size torch.Size([101]). Got size torch.Size([1, 101])
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The expected behavior is that the model will run with PeriodicKernel, and not only RBFKernel or LinearKernel.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:


0.3.2


1.1.0


macOS


	</description>
	<comments>
		<comment id='1' author='MichaelDoron' date='2019-06-23T17:14:21Z'>
		Thanks for reporting this, I'll look in to this tomorrow morning.
		</comment>
		<comment id='2' author='MichaelDoron' date='2019-06-26T11:47:16Z'>
		Update:
The issue occurs in regression with GaussianLikelihood as well, with sine wave as input.
Notice that the error doesn't occur when we reduce the input size from 300 to 200  samples.
&lt;denchmark-code&gt;import gpytorch
import math
import torch
from time import time
import copy

data_samples = 300 
# data_samples = 200 # Lowering the size of the input vector removes the problem
training_iterations = 100

class GPRegressionModel(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)
        self.mean_module = gpytorch.means.ConstantMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.PeriodicKernel())

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_module = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_module)

train_x = torch.linspace(0, 0.5, data_samples)
train_y = torch.sin(train_x * 100.0)

likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = GPRegressionModel(train_x, train_y, likelihood)
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)
optimizer = torch.optim.Adam([{'params': model.parameters()}], lr=0.1)
model.train()
likelihood.train()

optimizer.zero_grad()
output = model(train_x)
loss = -mll(output, train_y)
loss.backward()
optimizer.step()    
for i in range(training_iterations):
    optimizer.zero_grad()
    output = model(train_x)
    loss = -mll(output, train_y)
    loss.backward()
    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))
    optimizer.step()

model.eval()
likelihood.eval()

with torch.no_grad():
    test_x = torch.linspace(0, train_x[-1] * 1, len(train_x) * 1)
    prediction = likelihood(model(test_x))
    mean = prediction.mean
    lower, upper = prediction.confidence_region()

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='MichaelDoron' date='2019-06-27T18:58:18Z'>
		This is fixed in &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/761&gt;#761&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='MichaelDoron' date='2019-06-27T19:05:07Z'>
		Thank you!
		</comment>
	</comments>
</bug>