<bug id='811' author='fonnesbeck' open_date='2019-07-29T20:57:28Z' closed_time='2019-11-12T20:16:26Z'>
	<summary>[Bug] RuntimeError when predicting from a model with updated parameter values</summary>
	<description>
I am trying to use 10-fold crossvalidation to select hyperparameters for my model, but hit a RuntimeError when calling the likelihood.
The error arises in this call:
observed_pred = likelihood(model(torch.Tensor(Z).contiguous().cuda()))
where Z is a grid of values, and the model and likelihood are for a single GP model. The hyperparameters of this model have been updated by averaging the parameters of the folds of a cross-validated model, run in batch mode. I have ensured that the parameters are of the same type and shape:
&lt;denchmark-h:h3&gt;Original parameters&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;likelihood.noise_covar.raw_noise tensor([-4.9271], device='cuda:0')
covar_module.raw_outputscale tensor(-5.0590, device='cuda:0')
covar_module.base_kernel.kernels.0.raw_variance tensor([[-5.0590]], device='cuda:0')
covar_module.base_kernel.kernels.1.raw_lengthscale tensor([[-0.1901, -0.5527]], device='cuda:0')
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;New parameters&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;likelihood.noise_covar.raw_noise tensor([-4.9184], device='cuda:0')
covar_module.raw_outputscale tensor(-5.4085, device='cuda:0')
covar_module.base_kernel.kernels.0.raw_variance tensor([[-5.4085]], device='cuda:0')
covar_module.base_kernel.kernels.1.raw_lengthscale tensor([[-4.3704, -4.3507]], device='cuda:0')
&lt;/denchmark-code&gt;

But the following occurs:
&lt;denchmark-code&gt;~/spatial_pitch_effectiveness/notebooks/plotting.py in plot_heatmaps(model, X, y, cov_val, week, vmin, vmax, size_scale, name, cmap, lengthscale)
     92 
     93     with torch.no_grad(), gpytorch.settings.fast_pred_var():
---&gt; 94         observed_pred = likelihood(model(torch.Tensor(Z).contiguous().cuda()))
     95         pred_labels = observed_pred.mean.view(nd, nd)
     96         pred_var = observed_pred.variance.view(nd, nd)

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_gp.py in __call__(self, *args, **kwargs)
    263             # Make the prediction
    264             with settings._use_eval_tolerance():
--&gt; 265                 predictive_mean, predictive_covar = self.prediction_strategy.exact_prediction(full_mean, full_covar)
    266 
    267             # Reshape predictive mean to match the appropriate event shape

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_prediction(self, joint_mean, joint_covar)
    263         return (
    264             self.exact_predictive_mean(test_mean, test_train_covar),
--&gt; 265             self.exact_predictive_covar(test_test_covar, test_train_covar),
    266         )
    267 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in exact_predictive_covar(self, test_test_covar, test_train_covar)
    328                 return test_test_covar + MatmulLazyTensor(test_train_covar, covar_correction_rhs.mul(-1))
    329 
--&gt; 330         precomputed_cache = self.covar_cache
    331         covar_inv_quad_form_root = self._exact_predictive_covar_inv_quad_form_root(precomputed_cache,
    332                                                                                    test_train_covar)

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)
     32         cache_name = name if name is not None else method
     33         if not is_in_cache(self, cache_name):
---&gt; 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))
     35         return get_from_cache(self, cache_name)
     36 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/models/exact_prediction_strategies.py in covar_cache(self)
    224     def covar_cache(self):
    225         train_train_covar = self.lik_train_train_covar
--&gt; 226         train_train_covar_inv_root = delazify(train_train_covar.root_inv_decomposition().root)
    227         return self._exact_predictive_covar_inv_quad_form_cache(train_train_covar_inv_root, self._last_test_train_covar)
    228 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/memoize.py in g(self, *args, **kwargs)
     32         cache_name = name if name is not None else method
     33         if not is_in_cache(self, cache_name):
---&gt; 34             add_to_cache(self, cache_name, method(self, *args, **kwargs))
     35         return get_from_cache(self, cache_name)
     36 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in root_inv_decomposition(self, initial_vectors, test_vectors)
   1375                 )
   1376 
-&gt; 1377         inv_roots = self._root_inv_decomposition(initial_vectors)
   1378 
   1379         # Choose the best of the inv_roots, if there were more than one initial vectors

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/lazy_tensor.py in _root_inv_decomposition(self, initial_vectors)
    612             inverse=True,
    613             initial_vectors=initial_vectors,
--&gt; 614         )(*self.representation())
    615 
    616         if initial_vectors is not None and initial_vectors.size(-1) &gt; 1:

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/functions/_root_decomposition.py in forward(self, *matrix_args)
     51             matrix_shape=self.matrix_shape,
     52             batch_shape=self.batch_shape,
---&gt; 53             init_vecs=self.initial_vectors,
     54         )
     55 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/utils/lanczos.py in lanczos_tridiag(matmul_closure, max_iter, dtype, device, matrix_shape, batch_shape, init_vecs, num_init_vecs, tol)
     71 
     72     # Initial alpha value: alpha_0
---&gt; 73     r_vec = matmul_closure(q_0_vec)
     74     alpha_0 = q_0_vec.mul(r_vec).sum(dim_dimension)
     75 

/opt/anaconda3/lib/python3.7/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py in _matmul(self, rhs)
     38 
     39     def _matmul(self, rhs):
---&gt; 40         return torch.addcmul(self._lazy_tensor._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)
     41 
     42     def add_diag(self, added_diag):

RuntimeError: Expected object of backend CUDA but got backend CPU for argument #3 'tensor1'
&lt;/denchmark-code&gt;

I'm confused by the backend error, because everything is CUDA here--all I have done is swap out values, with the reassigned values being CUDA. I can confirm that the call runs without error with the original parameter values.
Running GPyTorch 0.3.2 and Torch 1.1.0.
	</description>
	<comments>
		<comment id='1' author='fonnesbeck' date='2019-07-30T18:46:19Z'>
		&lt;denchmark-link:https://github.com/fonnesbeck&gt;@fonnesbeck&lt;/denchmark-link&gt;
 I'm not able to reproduce this in the simple GP notebook (e.g., just training + testing, modifying the hypers, and then testing again).
Do you have a snippet of code that reproduces this? I suspect what might be happening based on the error is you are testing the model on CPU data before updating the parameters or something.
		</comment>
		<comment id='2' author='fonnesbeck' date='2019-11-12T20:16:26Z'>
		Closing this issue for now - reopen if this still an issue!
		</comment>
	</comments>
</bug>