<bug id='635' author='danielrjiang' open_date='2019-04-10T21:24:20Z' closed_time='2019-04-12T18:43:43Z'>
	<summary>[Bug] Negative variances when using fast_pred_var()</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

Seeing negative variances when using fast_pred_var(). Seems to be related to cache-ing: goes away when caches are cleared by using .train().eval(). In addition, when evaluating the variance at some set of points test_x and the evaluating again at a single point in test_x, they may not match.
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

See attached notebook and the comments there.
** Stack trace/error message **
&lt;denchmark-code&gt;tensor([ 1.0139e+00,  8.5046e-02,  8.5050e-02,  5.4592e-01,  8.5045e-02,
         1.1338e+00,  2.0938e+00,  2.3304e+00,  2.3283e+00,  9.9273e-01,
         9.6964e-01, -2.7103e+00, -1.7627e+02, -4.9231e+01, -9.5254e-01,
         6.7344e-01,  1.1548e+00,  8.4972e-02,  1.1811e+00,  2.1131e+00])
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

Variances that are positive and match when evaluated in different ways.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

gpytorch 0.2.1
PyTorch 1.0.0a0
Linux release 7.5.1804

cc: &lt;denchmark-link:https://github.com/Balandat&gt;@Balandat&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/files/3065928/negative_variance.ipynb.txt&gt;negative_variance.ipynb.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='danielrjiang' date='2019-04-10T21:26:13Z'>
		Was this actually on 0.2.1, as you say? If so, I'd like to see this reproduced on master, because we've fixed a lot of these issues in even the past few weeks, nevermind since December.
		</comment>
		<comment id='2' author='danielrjiang' date='2019-04-10T21:31:09Z'>
		Pretty sure &lt;denchmark-link:https://github.com/danielrjiang&gt;@danielrjiang&lt;/denchmark-link&gt;
 was testing this on gpytorch master. Either way, I was able to repro this on gpytorch master.
		</comment>
		<comment id='3' author='danielrjiang' date='2019-04-10T21:40:17Z'>
		Yes, it was on gpytorch master.
		</comment>
		<comment id='4' author='danielrjiang' date='2019-04-12T18:20:25Z'>
		Tested this again on the multi-batch PR and the issue has disappeared!
		</comment>
		<comment id='5' author='danielrjiang' date='2019-04-12T18:43:43Z'>
		Great. Must have been some weird caching thing that got solved inadvertently...
		</comment>
	</comments>
</bug>