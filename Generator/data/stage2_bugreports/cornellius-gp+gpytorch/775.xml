<bug id='775' author='anh-tong' open_date='2019-07-06T15:31:28Z' closed_time='2019-07-06T18:34:10Z'>
	<summary>More stable inverse softplus</summary>
	<description>
Hi,
I found that the current inverse softplus is unstable for high-value inputs.
def inv_softplus(x):
    return torch.log(torch.exp(x) - 1)
Probably, the more stable version would be
def inv_softplus(x):
    return x + torch.log(1 - torch.exp(-x)) 
	</description>
	<comments>
		<comment id='1' author='anh-tong' date='2019-07-06T17:24:31Z'>
		Wouldn't this also be bad if x is small? Maybe we could have something like
def inv_softplus(x):
    return x + torch.log(-torch.expm1(-x))
		</comment>
	</comments>
</bug>