<bug id='727' author='tmpethick' open_date='2019-06-06T07:36:56Z' closed_time='2019-06-06T15:24:36Z'>
	<summary>[Bug] Noise-free setting causes CG termination during prediction</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

I am trying to fit f(x) = sin(60 x‚Å¥) with a gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel()) kernel. The maximum likelihood optimization with Adam seems to run correctly but at prediction time CG terminates because of too large norm.
Crucially this is a noisefree setting. If we were to add N(0,0.1) noise there would be no problem. However, GPy can handle the noisefree setting. Can we configure GPyTorch somehow to do the same?
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

import math
import torch
import gpytorch
import numpy as np
from matplotlib import pyplot as plt
%matplotlib inline

bounds = np.array([[0,1]])
train_x = torch.linspace(bounds[0,0], bounds[0,1], 200)
train_y = np.sin(60 * train_x ** 4)

# We will use the simplest form of GP model, exact inference
class ExactGPModel(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)
        self.mean_module = gpytorch.means.ZeroMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

# initialize likelihood and model
likelihood = gpytorch.likelihoods.GaussianLikelihood()
# likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=torch.ones(1) * 0.0001)
model = ExactGPModel(train_x, train_y, likelihood)

model.initialize(**{
    'likelihood.noise': 0.5,
    'covar_module.base_kernel.lengthscale': 2.5,
    'covar_module.outputscale': 1.5
})
print("Initialized with: lengthscale=%.3f variance=%.3f noise=%.5f" % (model.covar_module.base_kernel.lengthscale.item(),
        model.covar_module.outputscale.item(),
        model.likelihood.noise.item()))

# Find optimal model hyperparameters
model.train()
likelihood.train()

# Use the adam optimizer
optimizer = torch.optim.Adam([
    {'params': model.parameters()}, 
], lr=0.1)

# "Loss" for GPs - the marginal log likelihood
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)

training_iter = 500
for i in range(training_iter):
    # Zero gradients from previous iteration
    optimizer.zero_grad()
    # Output from model
    output = model(train_x)
    # Calc loss and backprop gradients
    loss = -mll(output, train_y)
    loss.backward()
    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f, variance: %.3f,   noise: %.5f' % (
        i + 1, training_iter, loss.item(),
        model.covar_module.base_kernel.lengthscale.item(),
        model.covar_module.outputscale.item(),
        model.likelihood.noise.item()
    ))
    optimizer.step()

# Prediction
# Get into evaluation (predictive posterior) mode
model.eval()
likelihood.eval()

# Test points are regularly spaced along [0,1]
# Make predictions by feeding model through likelihood
with torch.no_grad():
    test_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)
    observed_pred = likelihood(model(test_x))

    # Initialize plot
    f, ax = plt.subplots(1, 1, figsize=(10, 10))

    # Get upper and lower confidence bounds
    lower, upper = observed_pred.confidence_region()
    # Plot training data as black stars
    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')
    # Plot predictive means as blue line
    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')
    # Shade between the lower and upper confidence bounds
    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)
    ax.set_ylim([-3, 3])
    ax.legend(['Observed Data', 'Mean', 'Confidence'])
** Stack trace/error message **
&lt;denchmark-code&gt; .../gpytorch/utils/linear_cg.py:295: UserWarning:CG terminated in 1000 iterations with average residual norm 13342.345703125 which is larger than the tolerance of 0.01 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.
.../gpytorch/utils/linear_cg.py:295: UserWarning:CG terminated in 1000 iterations with average residual norm 191.66046142578125 which is larger than the tolerance of 0.01 specified by gpytorch.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a gpytorch.settings.max_cg_iterations(value) context.
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/544312/59015021-48120080-883e-11e9-80f6-a8f964786acf.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/544312/59015057-58c27680-883e-11e9-94c6-fbf78838741b.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

GPyTorch Version: 0.3.2
PyTorch Version: 1.0.1.post2
Computer OS: MacOS 10.14
&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

GPy manage to plot it even for N=1000.
%matplotlib inline

import math
import numpy as np
import torch
import gpytorch
from matplotlib import pyplot as plt
import GPy

bounds = np.array([[0,1]])
train_x = torch.linspace(bounds[0,0], bounds[0,1], 1000)
train_y = np.sin(60 * train_x ** 4)

kernel = GPy.kern.RBF(1, ARD=False)
model = GPy.models.GPRegression(train_x.numpy()[:,None], train_y.numpy()[:,None], kernel=kernel)
model.Gaussian_noise = 0.5
model.kern.lengthscale = 2.5
model.kern.variance = 1.5

model.optimize()

test_x = np.linspace(bounds[0,0], bounds[0,1], 1000)
mean, var = model.predict(test_x[:, None])
mean = mean[:,0]
var = var[:,0]

f, ax = plt.subplots(1, 1, figsize=(10, 10))

# Get upper and lower confidence bounds
lower, upper = mean - 2 * np.sqrt(var), mean + 2 * np.sqrt(var)
# Plot training data as black stars
ax.plot(train_x.numpy(), train_y.numpy(), 'k*')
# Plot predictive means as blue line
ax.plot(test_x, mean, 'b')
# Shade between the lower and upper confidence bounds
ax.fill_between(test_x, lower, upper, alpha=0.5)
ax.legend(['Observed Data', 'Mean', 'Confidence'])
	</description>
	<comments>
		<comment id='1' author='tmpethick' date='2019-06-06T07:56:57Z'>
		I was a little too quick. I believe it is the same problem as &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/issues/703&gt;#703&lt;/denchmark-link&gt;
. Double precision fixes it but as you write: it is slow. The alternative of adding noise however requires me to add a wooping . Do you think one can somehow automate the detection of the required noise-level?
		</comment>
		<comment id='2' author='tmpethick' date='2019-06-06T15:24:36Z'>
		Since they deal with the same function, I'm going to address this issue over in &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/issues/728&gt;#728&lt;/denchmark-link&gt;
 if that's alright.
		</comment>
	</comments>
</bug>