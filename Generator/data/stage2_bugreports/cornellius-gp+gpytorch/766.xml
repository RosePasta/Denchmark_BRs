<bug id='766' author='sdaulton' open_date='2019-06-28T21:31:11Z' closed_time='2019-06-28T22:07:22Z'>
	<summary>[Bug] Incorrect gradients for kernels using torch.cdist</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

Auto-differientiating torch.cdist on the GPU is broken (&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/22353&gt;pytorch/pytorch#22353&lt;/denchmark-link&gt;
). This means kernels using torch.cdist have incorrect gradients on the GPU
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/files/3340948/cdist_issue_gpytorch.ipynb.txt&gt;cdist_issue_gpytorch.ipynb.txt&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

Numerical and analytic gradients match
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:
GPyTorch Version: master
PyTorch Version (e.g., 1.0): master
OS (e.g., Linux): CentOS Linux 7 (Core)
CUDA/cuDNN version:CUDA Version 9.2.88
Tesla M40
	</description>
	<comments>
		<comment id='1' author='sdaulton' date='2019-06-28T21:31:40Z'>
		cc &lt;denchmark-link:https://github.com/Balandat&gt;@Balandat&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/danielrjiang&gt;@danielrjiang&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='sdaulton' date='2019-06-28T21:35:51Z'>
		It seems that the straightforward solution to this is to add a check that the tensors not be cuda tensors here: &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/kernels/kernel.py#L25&gt;https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/kernels/kernel.py#L25&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='sdaulton' date='2019-06-28T21:36:37Z'>
		And to make sure this gets fixed upstream before pytorch 1.2.
		</comment>
		<comment id='4' author='sdaulton' date='2019-06-28T22:01:47Z'>
		The newest non cdist version of the distance computation is pretty darn fast even in low data settings. Let's either just disable cdist for GPU tensors as max suggests or disable cdist entirely for now.
&lt;denchmark-link:https://github.com/Balandat&gt;@Balandat&lt;/denchmark-link&gt;
 do we need to release 0.3.4 as a result of this?
		</comment>
		<comment id='5' author='sdaulton' date='2019-06-28T22:13:05Z'>
		
@Balandat do we need to release 0.3.4 as a result of this?

That would be great. Let's make sure we understand the implications of using either the custom or cdist implementation first though, in particular regarding batch mode (see my comment on the PR).
		</comment>
		<comment id='6' author='sdaulton' date='2019-07-08T22:21:20Z'>
		&lt;denchmark-link:https://github.com/jacobrgardner&gt;@jacobrgardner&lt;/denchmark-link&gt;
 I didn't get to look into this much further (not sure I will anytime soon). Do you mind putting out a 0.3.4 at this point while we're waiting for cdist to get implemented properly on the pytorch end?
		</comment>
		<comment id='7' author='sdaulton' date='2019-07-08T23:11:06Z'>
		&lt;denchmark-link:https://github.com/Balandat&gt;@Balandat&lt;/denchmark-link&gt;
 Sure thing, I'll put out 0.3.4 first thing tomorrow.
		</comment>
		<comment id='8' author='sdaulton' date='2019-07-08T23:17:33Z'>
		Great, thanks. I checked about prioritizing fixing up cdist (both gradients and perf) with the pytorch folks, let's see what they say.
		</comment>
		<comment id='9' author='sdaulton' date='2019-08-27T01:11:01Z'>
		&lt;denchmark-link:https://github.com/pytorch/pytorch/issues/22353&gt;pytorch/pytorch#22353&lt;/denchmark-link&gt;
 was resolved, but perf is still better using the gpytorch implementation :/ (for batched tensors and cuda tensors), so I don't see a reason to use  at the moment.
&lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/files/3543800/perf_test_cdist.ipynb.txt&gt;perf_test_cdist.ipynb.txt&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>