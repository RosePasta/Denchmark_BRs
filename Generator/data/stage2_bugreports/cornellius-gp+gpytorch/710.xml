<bug id='710' author='mshvartsman' open_date='2019-05-29T19:27:50Z' closed_time='2019-05-29T21:44:18Z'>
	<summary>[Bug] TypeError when calling `backward` on `gpytorch.functions.logdet`</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

I think there's a missing  in &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/_inv_quad_log_det.py#L221&gt;https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/functions/_inv_quad_log_det.py#L221&lt;/denchmark-link&gt;
. I'm not super familiar with gpytorch internals so hopefully this is correct -- if so, happy to contribute the one-liner fix.
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

** Code snippet to reproduce **
### works (I'm guessing something dispatches elsewhere for small matrices?)
import torch
from torch.autograd import backward
import gpytorch
from gpytorch.functions import logdet, inv_matmul
n = 100
inp = torch.arange(n, dtype=torch.float)
kern = gpytorch.kernels.RBFKernel()(inp)
ld = logdet(kern)
backward(ld)

### doesn't work
import torch
from torch.autograd import backward
import gpytorch
from gpytorch.functions import logdet, inv_matmul
n = 1000
inp = torch.arange(n, dtype=torch.float)
kern = gpytorch.kernels.RBFKernel()(inp)
ld = logdet(kern)
backward(ld)
** Stack trace/error message **
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-46-593fbced29ac&gt; in &lt;module&gt;()
      3 kern = gpytorch.kernels.RBFKernel()(inp)
      4 ld = logdet(kern)
----&gt; 5 backward(ld)

&lt;PATH SNIPPED&gt;/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     91     Variable._execution_engine.run_backward(
     92         tensors, grad_tensors, retain_graph, create_graph,
---&gt; 93         allow_unreachable=True)  # allow_unreachable flag
     94 
     95 

&lt;PATH SNIPPED&gt;/lib/python3.7/site-packages/torch/autograd/function.py in apply(self, *args)
     75 
     76     def apply(self, *args):
---&gt; 77         return self._forward_cls.backward(self, *args)
     78 
     79 

&lt;PATH SNIPPED&gt;lib/python3.7/site-packages/gpytorch/functions/_inv_quad_log_det.py in backward(ctx, inv_quad_grad_output, logdet_grad_output)
    221             res = matrix_arg_grads
    222 
--&gt; 223         return tuple([None] * 9 + res)

TypeError: can only concatenate list (not "tuple") to list
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

No error.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

GPyTorch version: 0.3.2 
pytorch version 1.1.0.
Mac OSX.

	</description>
	<comments>
		<comment id='1' author='mshvartsman' date='2019-05-29T20:24:11Z'>
		Ah you‚Äôre totally right! Good catch. A one-line fix would be great!
		</comment>
	</comments>
</bug>