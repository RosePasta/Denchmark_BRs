<bug id='267' author='samuelstanton' open_date='2018-09-12T22:04:43Z' closed_time='2018-10-02T01:56:41Z'>
	<summary>Batch-mode not properly supported by priors</summary>
	<description>
Suppose you create FooGP, a subclass of gpytorch.models.ExactGP and have an instance foo_gp. We specify
&lt;denchmark-code&gt;foo_gp.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=D, log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3), batch_size=B)
&lt;/denchmark-code&gt;

Calling foo_gp.foward() results in the following error (here B=5, D=6)
&lt;denchmark-code&gt;~/Code/gpytorch/gpytorch/module.py in __call__(self, *inputs, **kwargs)
    160 
    161     def __call__(self, *inputs, **kwargs):
--&gt; 162         outputs = self.forward(*inputs, **kwargs)
    163         if torch.is_tensor(outputs) or isinstance(outputs, RandomVariable) or isinstance(outputs, LazyVariable):
    164             return outputs

~/Code/gpytorch/gpytorch/mlls/exact_marginal_log_likelihood.py in forward(self, output, target)
     62         # Add log probs of priors on the parameters
     63         for _, param, prior in self.named_parameter_priors():
---&gt; 64             res.add_(prior.log_prob(param).sum())
     65         for _, prior, params, transform in self.named_derived_priors():
     66             res.add_(prior.log_prob(transform(*params)).sum())

~/Code/gpytorch/gpytorch/priors/prior.py in log_prob(self, parameter)
     48     def log_prob(self, parameter):
     49         """Returns the log-probability of the parameter value under the prior."""
---&gt; 50         return self._log_prob(parameter.exp() if self.log_transform else parameter)
     51 
     52     def _initialize_distributions(self):

~/Code/gpytorch/gpytorch/priors/smoothed_box_prior.py in _log_prob(self, parameter)
     65     def _log_prob(self, parameter):
     66         # x = "distances from box`"
---&gt; 67         X = ((parameter.view(self.a.shape) - self._c).abs_() - self._r).clamp(min=0)
     68         return sum(p.log_prob(x) for p, x in zip(self._tails, X)) - self._M.sum()
     69 

RuntimeError: invalid argument 2: size '[1]' is invalid for input with 5 elements at /opt/conda/conda-bld/pytorch_1533672544752/work/aten/src/TH/THStorage.cpp:84 
&lt;/denchmark-code&gt;

However, if we say
&lt;denchmark-code&gt;foo_gp.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=D, log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3, size=(B, D)), batch_size=B)
&lt;/denchmark-code&gt;

We get this error
&lt;denchmark-code&gt;----&gt; 4 test_gp = ExactRBFGP(test_inputs, test_targets, likelihood)

&lt;ipython-input-49-10157c928ca4&gt; in __init__(self, train_inputs, train_targets, likelihood)
     11         lengthscale_size = (self.batch_size, self.input_dim)
     12         self.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=self.input_dim,
---&gt; 13                                                        log_lengthscale_prior=gpytorch.priors.SmoothedBoxPrior(-3, 3, size=lengthscale_size),
     14                                                        batch_size=self.batch_size)
     15         outputscale_size = (self.batch_size, 1, 1)

~/Code/gpytorch/gpytorch/priors/smoothed_box_prior.py in __init__(self, a, b, sigma, log_transform, size)
     26     def __init__(self, a, b, sigma=0.01, log_transform=False, size=None):
     27         if isinstance(a, Number) and isinstance(b, Number):
---&gt; 28             a = torch.full((size or 1,), float(a))
     29             b = torch.full((size or 1,), float(b))
     30         elif not (torch.is_tensor(a) and torch.is_tensor(b)):

TypeError: 'tuple' object cannot be interpreted as an integer 
&lt;/denchmark-code&gt;

This suggests that batch mode is not properly supported by some (all?) priors.
	</description>
	<comments>
		<comment id='1' author='samuelstanton' date='2018-09-12T22:18:50Z'>
		Hmm, batch mode isn't very thoroughly tested in conjunction with priors, so there may well be a bug. Can you provide the code for a minimal reproducible example so I can take a look?
On a higher level, in light &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/issues/126&gt;#126&lt;/denchmark-link&gt;
 of we should rethink whether priors should be derived from torch.distribution.Distribution as well, so as to inherit proper batch-evaluation natively and also to have the new and convenient  method to larger sizes (&lt;denchmark-link:https://github.com/pytorch/pytorch/pull/11341&gt;pytorch/pytorch#11341&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='2' author='samuelstanton' date='2018-09-13T12:43:03Z'>
		Yeah we probably to have priors inheret from torch distributions. I'll open an issue if one doesn't exist.
For the time being, I'll work on a quick fix to this issue.
		</comment>
		<comment id='3' author='samuelstanton' date='2018-09-25T15:53:20Z'>
		This should be fixed on the beta branch. &lt;denchmark-link:https://github.com/samuelstanton&gt;@samuelstanton&lt;/denchmark-link&gt;
 can you check?
		</comment>
		<comment id='4' author='samuelstanton' date='2018-10-02T01:56:41Z'>
		Closing this for now - should be fixed by &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/issues/284&gt;#284&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>