<bug id='905' author='activatedgeek' open_date='2019-10-16T18:49:08Z' closed_time='2019-11-11T16:21:52Z'>
	<summary>[Bug] add_jitter fails with AttributeError: other must be a LazyTensor at eval time</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

Using add_jitter with the covariance module fails at eval time.
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

** Code snippet to reproduce **


Start from the example https://github.com/cornellius-gp/gpytorch/blob/master/examples/05_Scalable_GP_Regression_Multidimensional/SVGP_Regression_CUDA.ipynb


Optionally, replace WhitenedVariationalStrategy with VariationalStrategy in GPModel.__init__


Replace self.covar_module(x) with self.covar_module(x).add_jitter(1e-6) in GPModel.forward


** Stack trace/error message **
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-6-c955f39ee560&gt; in &lt;module&gt;
      4 with torch.no_grad():
      5     for x_batch, y_batch in test_loader:
----&gt; 6         preds = model(x_batch)
      7         means = torch.cat([means, preds.mean.cpu()])
      8 means = means[1:]

~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/models/abstract_variational_gp.py in __call__(self, inputs, **kwargs)
     20             inputs = inputs.unsqueeze(-1)
     21 
---&gt; 22         return self.variational_strategy(inputs)

~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in __call__(self, x)
    228                 self._memoize_cache = dict()
    229 
--&gt; 230         return super(VariationalStrategy, self).__call__(x)

~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/module.py in __call__(self, *inputs, **kwargs)
     20 
     21     def __call__(self, *inputs, **kwargs):
---&gt; 22         outputs = self.forward(*inputs, **kwargs)
     23         if isinstance(outputs, list):
     24             return [_validate_module_outputs(output) for output in outputs]

~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/variational/variational_strategy.py in forward(self, x)
    214                     induc_induc_covar.inv_matmul(induc_data_covar)
    215                 )
--&gt; 216                 data_covariance = data_data_covar + neg_induc_data_data_covar
    217             predictive_covar = PsdSumLazyTensor(predictive_covar, data_covariance)
    218 

~/miniconda3/envs/mbrl/lib/python3.7/site-packages/gpytorch/lazy/sum_lazy_tensor.py in __add__(self, other)
     75             return SumLazyTensor(*(list(self.lazy_tensors) + [other]))
     76         else:
---&gt; 77             raise AttributeError("other must be a LazyTensor")
     78 
     79     def diag(self):

AttributeError: other must be a LazyTensor
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The model to return outputs like always.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

GPyTorch Version: 0.3.6
PyTorch Version: 1.2.0
OS Version: Ubuntu 18.04.3 LTS

	</description>
	<comments>
		<comment id='1' author='activatedgeek' date='2019-10-17T20:14:43Z'>
		Hi &lt;denchmark-link:https://github.com/activatedgeek&gt;@activatedgeek&lt;/denchmark-link&gt;
 - I believe this is going to be fixed as part of &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/pull/903&gt;#903&lt;/denchmark-link&gt;
 . It might take a bit before that PR is in though.
Is there a reason that you want to add jitter to the covariance matrix as part of the forward function?
		</comment>
		<comment id='2' author='activatedgeek' date='2019-10-17T23:52:34Z'>
		Well, all my numerical instability issues have been resolved, so this isn't high priority for me. I just found this behavior and thought should report it anyways.
		</comment>
	</comments>
</bug>