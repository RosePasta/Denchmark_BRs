<bug id='1200' author='amisaw' open_date='2020-07-07T14:54:38Z' closed_time='2020-07-07T23:58:51Z'>
	<summary>[Question]</summary>
	<description>
Hello - I am new to GPytorch and I trying to implement DKL Regression using a modified version of the example code here &lt;denchmark-link:https://docs.gpytorch.ai/en/v1.1.1/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html&gt;https://docs.gpytorch.ai/en/v1.1.1/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html&lt;/denchmark-link&gt;
.
However, after I've trained the model on dummy training data and switch to eval() mode and try to predict using test data, I'm finding that the forward method still uses the training data (rather than the test data I'm giving it). Any suggestions as to why this is happening?
class GPRegressionModel(gpytorch.models.ExactGP):
def init(self, train_x, train_y, likelihood):
super(GPRegressionModel, self).init(train_x, train_y, likelihood)
self.mean_module = gpytorch.means.ZeroMean()
length_scale_initial = 20
signal_var_initial = 10
self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())
&lt;denchmark-code&gt;    # initialize lengthscale and outputscale hyperparams
    self.covar_module.base_kernel.lengthscale = length_scale_initial
    self.covar_module.outputscale = signal_var_initial
  
    # NN feature extractor
    self.embedd_extractor = embedd_extractor 

def forward(self, x):
    projected_x = self.embedd_extractor.forward_image(x, relu_on_emb=True)        
    mean_x = self.mean_module(projected_x)
    covar_x = self.covar_module(projected_x)        
    return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)
&lt;/denchmark-code&gt;

def train(num_epochs):
for epoch in range(num_epochs):
optimizer.zero_grad()
output = model(train_x)
loss = -mll(output, train_y)
loss.backward()
optimizer.step()
if name == "main":
# load NN embedding model from checkpoint - note - code for this is not posted here
emb_trainer = create_voxel_trainer_with_checkpoint(checkpoint_path, cuda = 1)
embedd_extractor = emb_trainer.model
&lt;denchmark-code&gt;train_x = np.zeros((10, 3, 50, 50, 50)) # dummy data for now
train_x = torch.from_numpy(train_x)
train_x = train_x.float()
train_y = torch.from_numpy(np.repeat(2,10)) # dummy data for now

# define likelihood function and model
likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = GPRegressionModel(train_x, train_y, likelihood) 

# train the model    
model.train()
likelihood.train()

# Use the adam optimizer
optimizer = torch.optim.Adam([
    {'params': model.embedd_extractor.parameters()},
    {'params': model.covar_module.parameters()},
    {'params': model.mean_module.parameters()},
    {'params': model.likelihood.parameters()},
], lr=0.01)

# "Loss" for GPs - the marginal log likelihood
mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)

# train model
train(num_epochs = 2)

# evaluate model
test_x =  torch.from_numpy(np.ones((1, 3, 50, 50, 50)))
test_x = test_x.float()  

#evaluate_model(test_x)
model.eval()
likelihood.eval()
print('evaluating model')
with torch.no_grad(), gpytorch.settings.use_toeplitz(False):  
    preds = model(test_x)
&lt;/denchmark-code&gt;

Expected behavior:
During evaluation of the model, when preds = model(test_x) is called, I would expect it to use the trained model to predict with test_x data. But when I step into the forward method of the GPRegressionModel class after this line, it is using the train_x data not the test_x data as expected. I assume there's a bug in my code, but I'm not sure where it's occurring.
Any help would be much appreciated!
System information:
GPytorch version: 1.1.1
PyTorch version: 1.5.0
Ubuntu 16.04
	</description>
	<comments>
		<comment id='1' author='amisaw' date='2020-07-07T15:26:48Z'>
		Are you sure it's only using the train data? GP prediction on test points is based on both the train points and test points.
		</comment>
		<comment id='2' author='amisaw' date='2020-07-07T15:32:50Z'>
		I believe so, because the size of train_x is [10, 3, 50, 50, 50] and test_x is [1, 3, 50, 50, 50]. After preds = model(test_x) is called and I step into the forward method, the size of x is [10, 3, 50, 50, 50] and it seems to be just the train data.
		</comment>
		<comment id='3' author='amisaw' date='2020-07-07T15:34:35Z'>
		Can you provide code that fully runs without errors?
		</comment>
		<comment id='4' author='amisaw' date='2020-07-07T15:40:39Z'>
		Also just to be clear, the first time you call forward after model.eval() will always be on the training data since it needs to compute the prediction caches.
		</comment>
		<comment id='5' author='amisaw' date='2020-07-07T16:01:34Z'>
		unfortunately I don't currently have standalone code to load the NN feature extractor model (embedd_extractor in the code above) so i don't have standalone code that I can provide at the moment. but that is good to know that the first time model.eval() is called it is just on the training data. it seems like the next time forward is called it is concatenating the training data and test data along the wrong axis, which might be causing the issue. the  [10, 3, 50, 50, 50]  tensor becomes [10, 3, 50, 100, 50]. is there an easy way to modify how it concatenates the train and test data when calling model.eval() on test data?
		</comment>
		<comment id='6' author='amisaw' date='2020-07-07T16:05:02Z'>
		also, if i want to train in an online-type manner where i'm collecting new training samples online and want to train/update the model hyperparams each time i get new training data, what is the best way to do this given that the model object is created with a fixed training data set?
does the get_fantasy_model() method do this (i.e. update the model hyperparameters given new training data)?
		</comment>
		<comment id='7' author='amisaw' date='2020-07-07T16:52:23Z'>
		Prediction with an exact GP in posterior mode can be found here: &lt;denchmark-link:https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/models/exact_gp.py#L314&gt;https://github.com/cornellius-gp/gpytorch/blob/master/gpytorch/models/exact_gp.py#L314&lt;/denchmark-link&gt;

If you really want to change how train and test are concatenated, you could modify how the concatenation is done prior to computing the joint distribution.
But before doing that, could you just reshape the data to be B x N x D for the model and then reshape back when needed? That would be the easiest way.
Regarding online updates:
get_fantasy_model will update the predictive caches to reflect the updated training dataset but won't update the hyperparameters. You would have to update the parameters, say by taking a gradient step in .train() mode and then recomputing the predictive caches. Alternatively, you could do set_train_data to update the attribute train_inputs without computing the predictive caches. This would be slightly faster since you aren't updating the caches.
In general, exact GP inference is not particularly well suited for online tasks since recomputing the caches at each step is slow. You could try looking into approximate methods designed specifically for online GPs.
		</comment>
		<comment id='8' author='amisaw' date='2020-07-07T17:12:25Z'>
		ok that is helpful, thank you!
in regards to the reshaping the data: in my current use case, my training dataset has multiple samples and then at test time i only have 1 sample that i want to make a prediction on. so reshaping the test_data to be the same size as the train data (B x N x D) doesn't really seem feasible since i want to predict using only a single test sample.
regarding the online updates, that makes sense, thank you. I will try using get_fantasy_model or set_train_data and then running through the train optimization loop to update the model hyperparameters.
		</comment>
		<comment id='9' author='amisaw' date='2020-07-07T17:39:43Z'>
		What I meant with reshaping is that you can reshape your train data. For example reshape a train_x from 5x4x3x2 to 20x3x2, assuming the true data is 2 dimensional. You can do also undo the reshape prior to the feature extractor if it expects some structure, like convolutions. At test time, if you have a data point that's 2D, then you would just reshape that to 1x1x2.
It might help if you could tell me what the dimensions of your data are
		</comment>
		<comment id='10' author='amisaw' date='2020-07-07T20:14:57Z'>
		So my train data dimensions are nx3x50x50x50 (i.e. a 5D tensor that the feature extractor is expecting as input). n, i.e. number of samples, varies each time I get new training data and update the model.
During prediction time I'll have a single sample, of size 1x3x50x50x50.
Also, just to clarify with the set_train_data method, the train_inputs I give it should include the original training data and the new training data (not just the new training data), correct?
		</comment>
		<comment id='11' author='amisaw' date='2020-07-07T22:52:35Z'>
		Yes it should include the original data.
Why don't you make the data NxD and then in the forward function right before calling the extractor, reshape it to be Nx3x50x50x50? Or, insert a reshape layer as the first layer of the extractor? Then you won't have to change anything and everything will just work.
		</comment>
		<comment id='12' author='amisaw' date='2020-07-07T23:57:57Z'>
		sounds good, thank you so much for your help and prompt responses! much appreciated.
		</comment>
	</comments>
</bug>