<bug id='884' author='yeahrmek' open_date='2019-09-27T13:13:19Z' closed_time='2019-09-27T16:42:35Z'>
	<summary>[Bug] MaternKernel works incorrectly</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

When I try to calculate gradient of some function, that depends on GP, w.r.t. one input point I obtain different results in different runs though the input is the same.
Looks like the problem with the MaternKernel, because when I switch to RBFKernel everything works correctly. Also, when I calculate the gradient w.r.t. to several input points (not one) it works correctly as well with MaternKernel
&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

import torch
import gpytorch

class ExactGPModel(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood):
        super().__init__(train_x, train_y, likelihood)
        self.mean_module = gpytorch.means.ConstantMean()
        self.covar_module = gpytorch.kernels.ScaleKernel(
            gpytorch.kernels.MaternKernel()
        )
    
    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)


X = torch.randn(10, 2)
y = X.sum(dim=1)**2

likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = ExactGPModel(X, y, likelihood)

x_test = torch.randn(1, 2)
x_test.requires_grad_(True)

model.eval()

# Calculate gradient w.r.t. to the same input point 10 times
for _ in range(10):
    loss = model(x_test).mean.sum()
    loss.backward()

    print(x_test.grad)
    x_test = x_test.detach()
    x_test.requires_grad_(True)
The output looks like this
&lt;denchmark-code&gt;tensor([[-9.0657e+31,  6.2069e+31]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.1179,  0.0331]])
tensor([[-0.0790, -0.0018]])
tensor([[ 0.1508, -0.3041]])
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

The same output at each iteration
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

GPyTorch==0.3.5
PyTorch==1.2.0
OS: Ubuntu 19.04

	</description>
	<comments>
		<comment id='1' author='yeahrmek' date='2019-09-27T15:22:08Z'>
		Could you try again on master -- this was a bug in torch.cdist that we fixed by not using it
		</comment>
		<comment id='2' author='yeahrmek' date='2019-09-27T16:42:34Z'>
		On master it works correctly. Thank you!
		</comment>
	</comments>
</bug>