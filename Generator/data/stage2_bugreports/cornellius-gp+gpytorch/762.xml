<bug id='762' author='junliu0' open_date='2019-06-27T21:57:39Z' closed_time='2019-06-27T22:09:09Z'>
	<summary>[Bug] when 'test_x=train_x', it stops responding for a long time and then gives an error.</summary>
	<description>
&lt;denchmark-h:h1&gt;üêõ Bug&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;To reproduce&lt;/denchmark-h&gt;

** Code snippet to reproduce **
&lt;denchmark-code&gt;import gpytorch
import torch
import math

grid_bounds = [(0, 1), (0, 2)]
grid_size = 100
grid = torch.zeros(grid_size, len(grid_bounds))
for i in range(len(grid_bounds)):
    grid_diff = float(grid_bounds[i][1] - grid_bounds[i][0]) / (grid_size - 2)
    grid[:, i] = torch.linspace(grid_bounds[i][0] - grid_diff, grid_bounds[i][1] + grid_diff, grid_size)

train_x = gpytorch.utils.grid.create_data_from_grid(grid)
train_y = torch.sin((train_x[:, 0] + train_x[:, 1]) * (2 * math.pi)) + torch.randn_like(train_x[:, 0]).mul(0.01)

class GridGPRegressionModel(gpytorch.models.ExactGP):
    def __init__(self, grid, train_x, train_y, likelihood):
        super(GridGPRegressionModel, self).__init__(train_x, train_y, likelihood)
        num_dims = train_x.size(-1)
        self.mean_module = gpytorch.means.ConstantMean()
        self.covar_module = gpytorch.kernels.GridKernel(gpytorch.kernels.RBFKernel(), grid=grid)

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)

likelihood = gpytorch.likelihoods.GaussianLikelihood()
model = GridGPRegressionModel(grid, train_x, train_y, likelihood)


model.train()
likelihood.train()

optimizer = torch.optim.Adam([
    {'params': model.parameters()},  # Includes GaussianLikelihood parameters
], lr=0.1)

mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)

training_iter = 5
for i in range(training_iter):
    optimizer.zero_grad()
    output = model(train_x)
    loss = -mll(output, train_y.view(1,-1))
    loss.backward()
    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (
        i + 1, training_iter, loss.item(),
        model.covar_module.base_kernel.lengthscale.item(),
        model.likelihood.noise.item()
    ))
    optimizer.step()

model.eval()
likelihood.eval()
n = 20
test_x = torch.zeros(int(pow(n, 2)), 2)
for i in range(n):
    for j in range(n):
        test_x[i * n + j][0] = float(i) / (n-1)
        test_x[i * n + j][1] = float(j) / (n-1)

with torch.no_grad(), gpytorch.settings.fast_pred_var():
    observed_pred = likelihood(model(train_x))
&lt;/denchmark-code&gt;

** Stack trace/error message **
&lt;denchmark-code&gt;C:\Users\Anaconda3\envs\default\lib\site-packages\gpytorch\models\exact_gp.py:247: UserWarning: The input matches the stored training data. Did you forget to call model.train()?
  "The input matches the stored training data. Did you forget to call model.train()?", UserWarning
Traceback (most recent call last):

  File "&lt;ipython-input-1-b4aadbcf139b&gt;", line 1, in &lt;module&gt;
    runfile('C:/Users/Desktop/spyder/gp_regression.py', wdir='C:/Users/Jun/Desktop/spyder')

  File "C:\Users\Anaconda3\envs\default\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 827, in runfile
    execfile(filename, namespace)

  File "C:\Users\Anaconda3\envs\default\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 110, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File "C:/Users/Desktop/spyder/gp_regression.py", line 68, in &lt;module&gt;
    pred_labels = observed_pred.mean.view(n, n)

RuntimeError: shape '[20, 20]' is invalid for input of size 10000
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Expected Behavior&lt;/denchmark-h&gt;

It should give a result instead of not responding and then showing an error.
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;

Please complete the following information:

GPytorch 0.3.2
pytorch 1.1.0
win10

&lt;denchmark-h:h2&gt;Additional context&lt;/denchmark-h&gt;

The weird thing is that this error doesn't appear when I use a 1d example from the tutorial page.
	</description>
	<comments>
	</comments>
</bug>