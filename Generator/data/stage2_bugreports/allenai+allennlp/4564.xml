<bug id='4564' author='eladsegal' open_date='2020-08-16T00:23:56Z' closed_time='2020-08-19T21:52:54Z'>
	<summary>Wrong metrics calculations when running in distributed mode</summary>
	<description>
&lt;denchmark-h:h2&gt;Version&lt;/denchmark-h&gt;

v1.1.0rc3
&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

BooleanAccuracy and CategoricalAccuracy (and possibly other metrics) are not calculated correctly when running in distributed mode, causing them to return nan.
It is caused by repeated addition of an accumulated variable with itself with each call to update the metric, resulting in an exponential growth until it gets to a value of  (and when  is divided by  the result is ).
&lt;denchmark-link:https://github.com/allenai/allennlp/blob/v1.1.0rc3/allennlp/training/metrics/categorical_accuracy.py#L102-L108&gt;https://github.com/allenai/allennlp/blob/v1.1.0rc3/allennlp/training/metrics/categorical_accuracy.py#L102-L108&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

I've encountered the issue when I used BooleanAccuracy and CategoricalAccuracy, but from quickly looking at the code of other metrics it is possible it can occur for some of them as well.
Clone &lt;denchmark-link:https://github.com/allenai/allennlp-models&gt;allennlp-models&lt;/denchmark-link&gt;
, switch to tag  and run the following from it:

After less than 200 training steps the metrics start_acc, end_acc (CategoricalAccuracy) and span_acc (BooleanAccuracy) will be nan.
&lt;denchmark-h:h2&gt;Fix&lt;/denchmark-h&gt;

A fix for  and  is &lt;denchmark-link:https://github.com/eladsegal/allennlp/commit/564fbb727b8a7d7b9959fa2ebe9d3f64dbc3e808&gt;here&lt;/denchmark-link&gt;
.
I currently don't have time to verify and fix other metrics, so let me know if you'd like me to create a pull request just for these two.
	</description>
	<comments>
		<comment id='1' author='eladsegal' date='2020-08-17T15:30:51Z'>
		&lt;denchmark-link:https://github.com/eladsegal&gt;@eladsegal&lt;/denchmark-link&gt;
 Thank you for bringing this to our attention. I know what other metrics may have a similar problem, and can work on fixing those. Please feel free to go ahead and submit a PR for these two.
		</comment>
		<comment id='2' author='eladsegal' date='2020-08-17T20:26:34Z'>
		Reopening issue to keep track of adding tests and fixes to remaining metrics that will break.
		</comment>
	</comments>
</bug>