<bug id='4357' author='12seetharaman' open_date='2020-06-15T00:26:20Z' closed_time='2020-07-13T20:54:55Z'>
	<summary>Bug on calculating "argmax_predictions". It increases the false positive count for last label.</summary>
	<description>
File: &lt;denchmark-link:https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py&gt;https://github.com/allenai/allennlp/blob/master/allennlp/training/metrics/fbeta_measure.py&lt;/denchmark-link&gt;

Line no: 132
Prediction tensor is all zero "[0, 0, 0, 0, 0, 0]", when a record is not classified to any of the labels.
argmax_predictions = predictions.max(dim=-1)[1].float()
Here, we are calculating argmax predictions by a max value index.
In the case of all zeros tensor, we will get the index of the last label. It increases the false positive count of the last label and affects the F1 score.
&lt;denchmark-code&gt;&gt;&gt;&gt; prediction =  torch.zeros(6)
&gt;&gt;&gt; prediction
tensor([0., 0., 0., 0., 0., 0.])
&gt;&gt;&gt; prediction.max(dim=-1)
(tensor(0.), tensor(5))
&gt;&gt;&gt; prediction.max(dim=-1)[1]
tensor(5)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='12seetharaman' date='2020-06-19T16:24:04Z'>
		This is definitely a bug. Could you submit a PR to fix it?
		</comment>
	</comments>
</bug>