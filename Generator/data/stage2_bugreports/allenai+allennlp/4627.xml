<bug id='4627' author='juliahane' open_date='2020-09-05T14:03:21Z' closed_time='2020-09-11T21:16:53Z'>
	<summary>No module named allennlp.run</summary>
	<description>
Hi
I installed allennlp 1.0.0, and then I want to use it to run this repo:
&lt;denchmark-link:https://github.com/mrqa/MRQA-Shared-Task-2019/tree/master/baseline&gt;https://github.com/mrqa/MRQA-Shared-Task-2019/tree/master/baseline&lt;/denchmark-link&gt;

I write this command to run bert-base on some QA datasets:
python -m allennlp.run train &lt;denchmark-link:https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&gt;https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&lt;/denchmark-link&gt;
 -s Models/SQuAD -o "{'train_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'validation_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'trainer': {'cuda_device': -1, 'num_epochs': 2, 'optimizer': {'type': 'bert_adam', 'lr': 3e-05, 'warmup': 0.1, 't_total': 29000}}}" --include-package mrqa_allennlp
but then it says
No module named allennlp.run
thanks for your help
	</description>
	<comments>
		<comment id='1' author='juliahane' date='2020-09-08T15:48:36Z'>
		Hi &lt;denchmark-link:https://github.com/juliahane&gt;@juliahane&lt;/denchmark-link&gt;
, could you please provide a complete stack trace?
		</comment>
		<comment id='2' author='juliahane' date='2020-09-10T17:53:31Z'>
		Hi
The full stack trace is only this error:
(qa) julia@vgnh006:/user/julia/dev/MRQA-Shared-Task-2019$ python -m allennlp.run train &lt;denchmark-link:https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&gt;https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&lt;/denchmark-link&gt;
 -s Models/SQuAD -o "{'train_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'validation_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'trainer': {'cuda_device': -1, 'num_epochs': 2, 'optimizer': {'type': 'bert_adam', 'lr': 3e-05, 'warmup': 0.1, 't_total': 29000}}}" --include-package mrqa_allennlp
/user/julia/libs/anaconda3/envs/qa/bin/python: No module named allennlp.run
		</comment>
		<comment id='3' author='juliahane' date='2020-09-10T18:46:37Z'>
		Hi
I am not sure what is the correct way to train models with allennlp bu if the command is "allennlp train" then I got the following errors:
allennlp train &lt;denchmark-link:https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&gt;https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&lt;/denchmark-link&gt;
 -s Models/SQuAD -o "{'train_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'validation_data_path': '&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
', 'trainer': {'cuda_device': 0, 'num_epochs': 2, 'optimizer': {'type': 'bert_adam', 'lr': 3e-05, 'warmup': 0.1, 't_total': 29000}}}" --include-package mrqa_allennlp
2020-09-10 20:43:34,248 - INFO - transformers.file_utils - PyTorch version 1.5.1 available.
Traceback (most recent call last):
File "user/julia/libs/anaconda3/envs/qa/bin/allennlp", line 8, in 
sys.exit(run())
File "user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/.py", line 19, in run
main(prog="allennlp")
File "/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/commands/.py", line 91, in main
import_module_and_submodules(package_name)
File "/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/common/util.py", line 340, in import_module_and_submodules
module = importlib.import_module(package_name)
File "/user/julia/libs/anaconda3/envs/qa/lib/python3.7/importlib/.py", line 127, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
File "", line 1006, in _gcd_import
File "", line 983, in _find_and_load
File "", line 967, in _find_and_load_unlocked
File "", line 677, in _load_unlocked
File "", line 728, in exec_module
File "", line 219, in _call_with_frames_removed
File "/user/julia/dev/MRQA-Shared-Task-2019/baseline/mrqa_allennlp/.py", line 2, in 
from mrqa_allennlp.BERT_QA import *
File "/user/julia/dev/MRQA-Shared-Task-2019/baseline/mrqa_allennlp/BERT_QA.py", line 17, in 
from allennlp.tools import squad_eval
ImportError: cannot import name 'squad_eval' from 'allennlp.tools' (/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/tools/.py)
		</comment>
		<comment id='4' author='juliahane' date='2020-09-10T18:47:35Z'>
		Hi
I greatly appreciate if you could check this repo:
&lt;denchmark-link:https://github.com/mrqa/MRQA-Shared-Task-2019/tree/master/baseline&gt;https://github.com/mrqa/MRQA-Shared-Task-2019/tree/master/baseline&lt;/denchmark-link&gt;

and just run the BERT base command, and let me know how I can use allennlp
thanks.
		</comment>
		<comment id='5' author='juliahane' date='2020-09-10T23:28:45Z'>
		Please tell me what operating system you are using, and also paste the output of pip freeze.
		</comment>
		<comment id='6' author='juliahane' date='2020-09-11T00:31:23Z'>
		I am pretty sure the problem is that MRQA-Shared-Task-2019 depends on allennlp&lt;1.0, but it just specifies allennlp.
&lt;denchmark-link:https://github.com/juliahane&gt;@juliahane&lt;/denchmark-link&gt;
, can you run , and check if that works?
		</comment>
		<comment id='7' author='juliahane' date='2020-09-11T08:28:32Z'>
		Hi
thanks a lot, indeed with allennlp &lt;1 it does not go to that issue, but now
this does not recognize the GPU, I tried with multiple gpus, and with all
it does not recognize it, I provide the command below and the error stack,
here is also the versions I used

allennlp                  0.9.0                     &lt;pip&gt;
pytorch-pretrained-bert   0.6.2                     &lt;pip&gt;
pytorch-transformers      1.1.0                     &lt;pip&gt;
torch                     1.6.0                     &lt;pip&gt;
python                    3.7.9                h7579374_0
python-dateutil           2.8.1                     &lt;pip&gt;

thanks.

Kind regards
Julia

(qa) julia@vgnd007:/user/julia/dev/MRQA-Shared-Task-2019/baseline$ python
-m allennlp.run train
&lt;denchmark-link:https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&gt;https://multiqa.s3.amazonaws.com/config/MRQA_BERTbase.json&lt;/denchmark-link&gt;
 -s
/user/julia/MRQASharedTask/Models/SQuAD -o "{'train_data_path': '
&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/train/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
',
'validation_data_path': '
&lt;denchmark-link:https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&gt;https://mrqa.s3.us-east-2.amazonaws.com/data/dev/SQuAD.jsonl.gz&lt;/denchmark-link&gt;
',
'trainer': {'cuda_device': 0, 'num_epochs': 2, 'optimizer': {'type':
'bert_adam', 'lr': 3e-05, 'warmup': 0.1, 't_total': 29000}}}"
--include-package mrqa_allennlp
2020-09-11 10:23:37,759 - INFO - pytorch_pretrained_bert.modeling - Better
speed can be achieved with apex installed from
&lt;denchmark-link:https://www.github.com/nvidia/apex&gt;https://www.github.com/nvidia/apex&lt;/denchmark-link&gt;
 .
2020-09-11 10:23:39,521 - INFO - pytorch_transformers.modeling_bert -
Better speed can be achieved with apex installed from
&lt;denchmark-link:https://www.github.com/nvidia/apex&gt;https://www.github.com/nvidia/apex&lt;/denchmark-link&gt;
 .
2020-09-11 10:23:39,532 - INFO - pytorch_transformers.modeling_xlnet -
Better speed can be achieved with apex installed from
&lt;denchmark-link:https://www.github.com/nvidia/apex&gt;https://www.github.com/nvidia/apex&lt;/denchmark-link&gt;
 .
2020-09-11 10:23:40,487 - INFO - allennlp.common.registrable -
instantiating registered subclass relu of &lt;class
'allennlp.nn.activations.Activation'&gt;
2020-09-11 10:23:40,490 - INFO - allennlp.common.registrable -
instantiating registered subclass relu of &lt;class
'allennlp.nn.activations.Activation'&gt;
2020-09-11 10:23:40,493 - INFO - allennlp.common.registrable -
instantiating registered subclass relu of &lt;class
'allennlp.nn.activations.Activation'&gt;
2020-09-11 10:23:40,496 - INFO - allennlp.common.registrable -
instantiating registered subclass relu of &lt;class
'allennlp.nn.activations.Activation'&gt;
2020-09-11 10:23:41,501 - INFO - allennlp.common.params - random_seed =
13370
2020-09-11 10:23:41,501 - INFO - allennlp.common.params - numpy_seed = 1337
2020-09-11 10:23:41,501 - INFO - allennlp.common.params - pytorch_seed = 133
2020-09-11 10:23:41,539 - INFO - allennlp.common.checks - Pytorch version:
1.6.0
Traceback (most recent call last):
  File "/user/julia/libs/anaconda3/envs/qa/lib/python3.7/runpy.py", line
193, in _run_module_as_main
    "__main__", mod_spec)
  File "/user/julia/libs/anaconda3/envs/qa/lib/python3.7/runpy.py", line
85, in _run_code
    exec(code, run_globals)
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/run.py",
line 21, in &lt;module&gt;
    run()
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/run.py",
line 18, in run
    main(prog="allennlp")
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/commands/__init__.py",
line 102, in main
    args.func(args)
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/commands/train.py",
line 124, in train_model_from_args
    args.cache_prefix)
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/commands/train.py",
line 168, in train_model_from_file
    cache_directory, cache_prefix)
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/commands/train.py",
line 212, in train_model
    check_for_gpu(cuda_device)
  File
"/user/julia/libs/anaconda3/envs/qa/lib/python3.7/site-packages/allennlp/common/checks.py",
line 81, in check_for_gpu
    raise ConfigurationError("Experiment specified a GPU but none is
available;"
allennlp.common.checks.ConfigurationError: "Experiment specified a GPU but
none is available; if you want to run on CPU use the override
'trainer.cuda_device=-1' in the json config file."
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Sep 11, 2020 at 2:31 AM Dirk Groeneveld ***@***.***&gt; wrote:
 I am pretty sure the problem is that MRQA-Shared-Task-2019 depends on
 allennlp&lt;1.0, but it just specifies allennlp.

 @juliahane &lt;https://github.com/juliahane&gt;, can you run pip install
 "allennlp&lt;1.0", and check if that works?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#4627 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AM3GZM5HNMFAIWSTLHQGWZ3SFFVWTANCNFSM4Q26AMHQ&gt;
 .



		</comment>
		<comment id='8' author='juliahane' date='2020-09-11T16:19:44Z'>
		It looks like your config is specifying a GPU, but you don't have one. Just switch cuda_device: 0 out for cuda_device: -1 in the config file!
		</comment>
		<comment id='9' author='juliahane' date='2020-09-11T20:25:54Z'>
		Sorry, I did not read your message carefully enough. AllenNLP relies on torch for the GPUs. If torch sees the GPU, so do we. I suspect what happened is that it automatically installed an older version of pytorch, but one that doesn't have CUDA support.
		</comment>
		<comment id='10' author='juliahane' date='2020-09-11T21:05:31Z'>
		Hi
I realized that the issue was that allennlp install pytorch by itself,
installing pytorch from pip is buggy, then I installed it with conda and it
worked.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Sep 11, 2020 at 10:26 PM Dirk Groeneveld ***@***.***&gt; wrote:
 Sorry, I did not read your message carefully enough. AllenNLP relies on
 torch for the GPUs. If torch sees the GPU, so do we. I suspect what
 happened is that it automatically installed an older version of pytorch,
 but one that doesn't have CUDA support.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#4627 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AM3GZM2TWCNN2BJSBFISR4DSFKBWFANCNFSM4Q26AMHQ&gt;
 .



		</comment>
		<comment id='11' author='juliahane' date='2020-09-11T21:16:53Z'>
		Cool! Let us know if you have more problems with it.
		</comment>
	</comments>
</bug>