<bug id='4855' author='frcnt' open_date='2020-12-09T14:16:36Z' closed_time='2020-12-10T20:30:06Z'>
	<summary>Models: missing None check in PrecoReader's text_to_instance method.</summary>
	<description>
&lt;denchmark-h:h2&gt;Checklist&lt;/denchmark-h&gt;


 I have verified that the issue exists against the master branch of AllenNLP.
 I have read the relevant section in the contribution guide on reporting bugs.
 I have checked the issues list for similar or identical bug reports.
 I have checked the pull requests list for existing proposed fixes.
 I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.
 I have included in the "Description" section below a traceback from any exceptions related to this bug.
 I have included in the "Related issues or possible duplicates" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).
 I have included in the "Environment" section below the name of the operating system and Python version that I was using when I discovered this bug.
 I have included in the "Environment" section below the output of pip freeze.
 I have included in the "Steps to reproduce" section below a minimally reproducible example.

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Hi,
I think a  check is missing at that &lt;denchmark-link:https://github.com/allenai/allennlp-models/blob/ea1f71c79c329db1b66d9db79f0eaa39d2fd2857/allennlp_models/coref/dataset_readers/preco.py#L94&gt;line&lt;/denchmark-link&gt;
 in .
According to the function argument list, and the subsequent call to ,  should be allowed to be .
A typical use-case would be e.g. inference where we don't have any info about the clusters.

Python traceback: 


Traceback (most recent call last):
  File "/home/fco/coreference/bug.py", line 15, in &lt;module&gt;
    instance = reader.text_to_instance(sentences)
  File "/home/fco/anaconda3/envs/coref/lib/python3.8/site-packages/allennlp_models/coref/dataset_readers/preco.py", line 94, in text_to_instance
    for cluster in gold_clusters:
TypeError: 'NoneType' object is not iterable



&lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;


None

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

OS: Ubuntu 18.04.3 LTS
Python version: 3.8.5

Output of pip freeze:

absl-py==0.11.0
allennlp==1.2.0
allennlp-models==1.2.0
attrs==20.3.0
blis==0.4.1
boto3==1.16.14
botocore==1.19.14
cachetools==4.1.1
catalogue==1.0.0
certifi==2020.6.20
chardet==3.0.4
click==7.1.2
conllu==4.2.1
cymem==2.0.4
en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz
filelock==3.0.12
ftfy==5.8
future==0.18.2
google-auth==1.23.0
google-auth-oauthlib==0.4.2
grpcio==1.33.2
h5py==3.1.0
idna==2.10
importlib-metadata==2.0.0
iniconfig==1.1.1
jmespath==0.10.0
joblib==0.17.0
jsonnet==0.16.0
jsonpickle==1.4.1
Markdown==3.3.3
murmurhash==1.0.4
nltk==3.5
numpy==1.19.4
oauthlib==3.1.0
overrides==3.1.0
packaging==20.4
pandas==1.1.4
plac==1.1.3
pluggy==0.13.1
preshed==3.0.4
protobuf==3.13.0
py==1.9.0
py-rouge==1.1
pyasn1==0.4.8
pyasn1-modules==0.2.8
pyconll==2.3.3
pyparsing==2.4.7
PySocks==1.7.1
pytest==6.1.2
python-dateutil==2.8.1
pytz==2020.4
regex==2020.10.28
requests==2.24.0
requests-oauthlib==1.3.0
rsa==4.6
s3transfer==0.3.3
sacremoses==0.0.43
scikit-learn==0.23.2
scipy==1.5.4
sentencepiece==0.1.94
six==1.15.0
spacy==2.3.2
srsly==1.0.3
tensorboard==2.4.0
tensorboard-plugin-wit==1.7.0
tensorboardX==2.1
thinc==7.4.1
threadpoolctl==2.1.0
tokenizers==0.9.2
toml==0.10.2
torch==1.7.0
tqdm==4.51.0
transformers==3.4.0
tweepy==3.9.0
typing==3.7.4.3
typing-extensions==3.7.4.3
urllib3==1.25.11
wasabi==0.8.0
wcwidth==0.2.5
Werkzeug==1.0.1
word2number==1.1
zipp==3.4.0



&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;


Example source:

import spacy
from allennlp.data.token_indexers import SingleIdTokenIndexer, TokenCharactersIndexer
from allennlp_models.coref import PrecoReader

my_text = "Night you. Subdue creepeth cattle creeping living lesser."

sp = spacy.load("en_core_web_sm")
doc = sp(my_text)
sentences = [[token.text for token in sent] for sent in doc.sents]

reader = PrecoReader(max_span_width=10, token_indexers={"tokens": SingleIdTokenIndexer(),
                                                        "token_characters": TokenCharactersIndexer()})
instance = reader.text_to_instance(sentences)


	</description>
	<comments>
	</comments>
</bug>