<bug id='4480' author='sukeshlaghate' open_date='2020-07-15T14:48:37Z' closed_time='2020-07-20T10:43:59Z'>
	<summary>Inconsistency in answers generated by ELMo-Bidaf( trained on SQuAD) Demo and downloaded</summary>
	<description>
Describe the bug
Inconsistent answers generated by bidaf-elmo-model-2020.03.19.tar.gz model when run in Allennlp demo website and when run on local machine after downloading the model.
Steps to reproduce the behavior
I followed instructions given in the usage section of online demo for reading comprehension

conda create --name allennlp python=3.7
conda activate allennlp
conda install -c conda-forge jsonnet
pip install allennlp==1.0.0 allennlp-models==1.0.0
download bidaf-elmo model and store in folder
5a. download from https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz
5b. move it to python notebook location ~/sandbox/python/

Used following python code as given in Usage section of allennlp demo website
&lt;denchmark-code&gt; 
from allennlp.predictors.predictor import Predictor
import allennlp_models.rc

model_path = r"~/sandbox/python/rc_model"
predictor = Predictor.from_path(model_path)

text ="Becuase Pepsodent is a trusted brand. it has 130% germ attack power."

what_benefit = 'What is the benefit?'
why_use = 'Why use?'


why_answer = predictor.predict_json({
    "passage": text,
    "question": why_use
})

print(f"Answer for why should I use :{why_answer['best_span_str']}")
# Expected answer is Pepsodent is trusted brand.

what_answer = predictor.predict(
  passage=text,
  question=what_benefit
)

print(f"Answer for what is the benefit: {what_answer['best_span_str']}")
# Expected answer is 130% germ attack power

&lt;/denchmark-code&gt;

Expected behavior
For why question expected answer is  "Pepsodent is trusted brand."
For what question expected answer is "130% germ attack power"
Actual answer for both cases is "130% germ attack power" refer  screen shot below
&lt;denchmark-link:https://user-images.githubusercontent.com/25061957/87558881-3b193f00-c6d7-11ea-8786-7be8b8dd0d55.jpg&gt;&lt;/denchmark-link&gt;

However when same passage and questions are fed into online demo, the model generates expected responses  please refer to the screen shots
Response for what is the benefit question
&lt;denchmark-link:https://user-images.githubusercontent.com/25061957/87558621-f1c8ef80-c6d6-11ea-92f9-d65317da9532.jpg&gt;&lt;/denchmark-link&gt;

Response for why use question
&lt;denchmark-link:https://user-images.githubusercontent.com/25061957/87558920-47050100-c6d7-11ea-9f56-7ff5b8654b1c.jpg&gt;&lt;/denchmark-link&gt;

System
&lt;denchmark-code&gt;OS: [ubuntu 20.0.4]
Python version: [3.7.6]
AllenNLP version: [ v1.0.0]
&lt;/denchmark-code&gt;

Request you to help in resolving this inconsistency.
Any pointers/ insights/ solutions are much appreciated.
	</description>
	<comments>
		<comment id='1' author='sukeshlaghate' date='2020-07-17T10:25:24Z'>
		The ELMo model you are using does not guarantee the same results every time. That's a known characteristic of ELMo. Have you tried it with the TransformerQA model that's also there?
		</comment>
		<comment id='2' author='sukeshlaghate' date='2020-07-17T10:30:32Z'>
		&lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 Thanks for your response.
Point duly noted.
However I have an observation; On the demo website it consistently returns correct answers not only for the passage given in example above but even for variety of other passages too. So you can understand why I was confused with the responses that were generated by downloaded model.
I will try out TransformerQA Model as suggested.
		</comment>
		<comment id='3' author='sukeshlaghate' date='2020-07-17T10:41:38Z'>
		&lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 Also noticed that there is NMN model but demo site does not provide information on its usage. Could you please provide example along with instructions on how to download and run NMN(drop) trained model. Thank you in advance for your help
		</comment>
		<comment id='4' author='sukeshlaghate' date='2020-07-17T12:13:42Z'>
		Unfortunately I don't know too much about the NMN models. I think they live at &lt;denchmark-link:https://github.com/allenai/allennlp-semparse&gt;https://github.com/allenai/allennlp-semparse&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/matt-gardner&gt;@matt-gardner&lt;/denchmark-link&gt;
, do you know more?
		</comment>
		<comment id='5' author='sukeshlaghate' date='2020-07-17T15:21:02Z'>
		The DROP NMN lives here: &lt;denchmark-link:https://github.com/nitishgupta/nmn-drop&gt;https://github.com/nitishgupta/nmn-drop&lt;/denchmark-link&gt;
.  It's based on the semparse repo, but it's not in that repo.
		</comment>
	</comments>
</bug>