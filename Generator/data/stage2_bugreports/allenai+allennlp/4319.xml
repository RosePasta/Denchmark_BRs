<bug id='4319' author='ud2195' open_date='2020-06-04T12:59:48Z' closed_time='2020-06-08T16:24:10Z'>
	<summary>Predictor.from_path not loading my trained model</summary>
	<description>
Hi , After training my Textual entailment model successfully using roBERTa, I am unable to load the same:-
Traceback:-
&lt;denchmark-code&gt;---------------------------------------------------------------------------
---------------------------------------------------------------------------
ConfigurationError                        Traceback (most recent call last)
&lt;ipython-input-56-91de5da48e5e&gt; in &lt;module&gt;()
     10 from allennlp.predictors.predictor import Predictor
     11 get_ipython().system('pip install swifter')
---&gt; 12 predictor = Predictor.from_path("/content/allenepi/model.tar.gz")
     13 labels_dict = predictor._model.vocab.get_index_to_token_vocabulary('labels')
     14 
3 frames
/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py
 in from_path(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen)
    257             predictor_name,
    258             dataset_reader_to_load=dataset_reader_to_load,
--&gt; 259             frozen=frozen,
    260         )
    261 
/usr/local/lib/python3.6/dist-packages/allennlp/predictors/predictor.py in from_archive(cls, archive, predictor_name, dataset_reader_to_load, frozen)
    292         else:
    293             dataset_reader_params = config["dataset_reader"]
--&gt; 294         dataset_reader = DatasetReader.from_params(dataset_reader_params)
    295 
    296         model = archive.model
/usr/local/lib/python3.6/dist-packages/allennlp/common/from_params.py in from_params(cls, params, constructor_to_call, constructor_to_inspect, **extras)
    558                 "type",
    559                 choices=as_registrable.list_available(),
--&gt; 560                 default_to_first_choice=default_to_first_choice,
    561             )
    562             subclass, constructor_name = as_registrable.resolve_class_name(choice)
/usr/local/lib/python3.6/dist-packages/allennlp/common/params.py in pop_choice(self, key, choices, default_to_first_choice, allow_class_names)
    349                 """{"model": "my_module.models.MyModel"} to have it imported automatically."""
    350             )
--&gt; 351             raise ConfigurationError(message)
    352         return value
    353 
ConfigurationError: snli not in acceptable choices for dataset_reader.type: ['conll2003', 'interleaving', 'sequence_tagging', 'sharded', 'babi', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {"model": "my_module.models.MyModel"} to have it imported automatically.```



&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;my config.jsonnet:-
local transformer_model = "roberta-large";
local transformer_dim = 1024;
local cls_is_last_token = false;

{
  "dataset_reader":{
    "type": "snli",
    "tokenizer": {
      "type": "pretrained_transformer",
      "model_name": transformer_model,
      "add_special_tokens": false
    },
    "token_indexers": {
      "tokens": {
        "type": "pretrained_transformer",
        "model_name": transformer_model,
        "max_length": 40
      }
    }
  },
  "train_data_path": "/content/cnli_train_5L.jsonl",
  "validation_data_path": "/content/cnli_val_5L.jsonl",
  
  "model": {
    "type": "basic_classifier",
    "text_field_embedder": {
      "token_embedders": {
        "tokens": {
          "type": "pretrained_transformer",
          "model_name": transformer_model,
          "max_length": 40
        }
      }
    },
    "seq2vec_encoder": {
       "type": "cls_pooler",
       "embedding_dim": transformer_dim,
       "cls_is_last_token": cls_is_last_token
    },
    "feedforward": {
      "input_dim": transformer_dim,
      "num_layers": 1,
      "hidden_dims": transformer_dim,
      "activations": "tanh"
    },
    "dropout": 0.1,
    "namespace": "tags"
  },
  "data_loader": {
    "batch_sampler": {
      "type": "bucket",
      "batch_size" : 4
    }
  },
  "trainer": {
    "num_epochs": 10,
    "cuda_device" : 0,
    "validation_metric": "+accuracy",
    "learning_rate_scheduler": {
      "type": "slanted_triangular",
      "cut_frac": 0.06
    },
    "optimizer": {
      "type": "huggingface_adamw",
      "lr": 2e-5,
      "weight_decay": 0.1,
    }
  }
}

&lt;/denchmark-code&gt;

code :-
&lt;denchmark-code&gt;from allennlp.predictors.predictor import Predictor 
predictor = Predictor.from_path("/content/allenepi/model.tar.gz")
&lt;/denchmark-code&gt;

allennlp and allennlp-model version is 1.0.0rc5
will really appreciate some help on the same, Thank you
	</description>
	<comments>
		<comment id='1' author='ud2195' date='2020-06-04T16:44:35Z'>
		This looks like a duplicate of &lt;denchmark-link:https://github.com/allenai/allennlp/issues/4104&gt;#4104&lt;/denchmark-link&gt;
, which I thought we already fixed.  You're not supposed to need to do any imports or anything to get the  models and dataset readers registered.  &lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
, any idea why this isn't working in rc5?  Is it because we're not importing everything in ?
&lt;denchmark-link:https://github.com/ud2195&gt;@ud2195&lt;/denchmark-link&gt;
, a simple workaround is to run  before your other lines.
		</comment>
		<comment id='2' author='ud2195' date='2020-06-04T17:48:17Z'>
		&lt;denchmark-link:https://github.com/matt-gardner&gt;@matt-gardner&lt;/denchmark-link&gt;
 Thanks for replying matt. Model loaded successfully but when running the below function on my dataset i get 
function-
&lt;denchmark-code&gt;def get_labels(hypothesis, premise):
    pred = predictor.predict(
      hypothesis=hypothesis,
      premise=premise
    )
    
    label = labels_dict[np.argmax(pred['label_probs'])]
    return label

&lt;/denchmark-code&gt;

traceback:-
Traceback (most recent call last):
&lt;denchmark-code&gt;
  File "&lt;ipython-input-23-558217224d8c&gt;", line 10, in &lt;module&gt;
    testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/swifter/swifter.py", line 343, in apply
    timed = timeit.timeit(wrapped, number=N_REPEATS)

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/timeit.py", line 233, in timeit
    return Timer(stmt, setup, timer, globals).timeit(number)

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/timeit.py", line 178, in timeit
    timing = self.inner(it, self.timer)

  File "&lt;timeit-src&gt;", line 6, in inner

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/swifter/swifter.py", line 271, in wrapped
    func, axis=axis, raw=raw, result_type=result_type, args=args, **kwds

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py", line 6878, in apply
    return op.get_result()

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py", line 186, in get_result
    return self.apply_standard()

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/apply.py", line 296, in apply_standard
    values, self.f, axis=self.axis, dummy=dummy, labels=labels

  File "pandas/_libs/reduction.pyx", line 618, in pandas._libs.reduction.compute_reduction

  File "pandas/_libs/reduction.pyx", line 128, in pandas._libs.reduction.Reducer.get_result

  File "&lt;ipython-input-23-558217224d8c&gt;", line 10, in &lt;lambda&gt;
    testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/series.py", line 871, in __getitem__
    result = self.index.get_value(self, key)

  File "/home/episourcein.episource.com/espm1854/miniconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py", line 4405, in get_value
    return self._engine.get_value(s, k, tz=getattr(series.dtype, "tz", None))

  File "pandas/_libs/index.pyx", line 80, in pandas._libs.index.IndexEngine.get_value

  File "pandas/_libs/index.pyx", line 90, in pandas._libs.index.IndexEngine.get_value

  File "pandas/_libs/index.pyx", line 135, in pandas._libs.index.IndexEngine.get_loc

  File "pandas/_libs/index_class_helper.pxi", line 109, in pandas._libs.index.Int64Engine._check_type

KeyError: 'hypothesis'
&lt;/denchmark-code&gt;

code:-
&lt;denchmark-code&gt;import swifter
testdata['predicted']=testdata.swifter.apply(lambda x:get_labels(x['hypothesis'],x['sent']))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='ud2195' date='2020-06-04T18:04:08Z'>
		For that model you have to specify a separate predictor:
predictor = Predictor.from_path(
    "/content/allenepi/model.tar.gz",
    predictor_name="textual-entailment"
)
		</comment>
		<comment id='4' author='ud2195' date='2020-06-04T18:45:01Z'>
		&lt;denchmark-link:https://github.com/matt-gardner&gt;@matt-gardner&lt;/denchmark-link&gt;
 thank you so much, really appreciate your prompt replies and the work that you guys do to build such packages :)
		</comment>
		<comment id='5' author='ud2195' date='2020-06-05T22:39:06Z'>
		From issue review: A simple solution is to just import default plugins in allennlp.__init__.  That has potential speed and memory implications that we want to measure before doing it.  Another solution is to do it when importing Predictor, because that's where this issue keeps coming up.
		</comment>
		<comment id='6' author='ud2195' date='2020-06-05T23:24:45Z'>
		I think importing plugins in  could potentially result in some circular import issues. Anyway, here's a one potential solution: &lt;denchmark-link:https://github.com/allenai/allennlp/pull/4333&gt;#4333&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>