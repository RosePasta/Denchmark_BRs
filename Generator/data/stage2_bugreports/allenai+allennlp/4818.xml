<bug id='4818' author='KTRosenberg' open_date='2020-11-25T01:41:20Z' closed_time='2020-12-09T18:38:32Z'>
	<summary>SRL bert-base-srl predictor basic to be “is” verb examples return no results</summary>
	<description>
&lt;denchmark-h:h2&gt;Checklist&lt;/denchmark-h&gt;


 I have verified that the issue exists against the master branch of AllenNLP.
 I have read the relevant section in the contribution guide on reporting bugs.
 I have checked the issues list for similar or identical bug reports.
 I have checked the pull requests list for existing proposed fixes.
 I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.
 I have included in the "Description" section below a traceback from any exceptions related to this bug.
 I have included in the "Related issues or possible duplicates" section below all related issues and possible duplicate issues (If there are none, check this box anyway).
 I have included in the "Environment" section below the name of the operating system and Python version that I was using when I discovered this bug.
 I have included in the "Environment" section below the output of pip freeze.
 I have included in the "Steps to reproduce" section below a minimally reproducible example.

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Simple sentences involving the verb, "is" return no results for semantic role labeling, either via the demo page or by using AllenNLP in Python3.8 with the latest November Bert base model.
For example, "I am here." returns nothing.
In short:

Instances of simple "A is B" sentences don't return any results.
I believe there should be some sort of output, as other SRL engines do return results.
The same goes for "I am." The expected result is an ARG1 for "I" and a predicate of "am."

This used to work with an earlier version:
&lt;denchmark-code&gt;allennlp==1.0.0
allennlp-models==1.0.0
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;


None

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

OS: macOS 10.15.7 (Catalina)
Python version: 3.8.6 (via home-brew)
&lt;denchmark-code&gt;allennlp==1.2.2
allennlp-models==1.2.2
attrs==20.3.0
blis==0.4.1
boto3==1.16.24
botocore==1.19.24
catalogue==1.0.0
certifi==2020.11.8
chardet==3.0.4
click==7.1.2
conllu==4.2.1
cymem==2.0.4
dataclasses==0.6
filelock==3.0.12
ftfy==5.8
future==0.18.2
h5py==3.1.0
idna==2.10
importlib-metadata==3.1.0
iniconfig==1.1.1
jmespath==0.10.0
joblib==0.17.0
jsonnet==0.17.0
jsonpickle==1.4.1
murmurhash==1.0.4
nltk==3.5
numpy==1.19.4
overrides==3.1.0
packaging==20.4
plac==1.1.3
pluggy==0.13.1
preshed==3.0.4
protobuf==3.14.0
py==1.9.0
py-rouge==1.1
pyparsing==2.4.7
pytest==6.1.2
python-dateutil==2.8.1
regex==2020.11.13
requests==2.25.0
s3transfer==0.3.3
sacremoses==0.0.43
scikit-learn==0.23.2
scipy==1.5.4
sentencepiece==0.1.91
six==1.15.0
spacy==2.3.2
srsly==1.0.4
tensorboardX==2.1
thinc==7.4.1
threadpoolctl==2.1.0
tokenizers==0.9.3
toml==0.10.2
torch==1.7.0
tqdm==4.53.0
transformers==3.5.1
typing-extensions==3.7.4.3
urllib3==1.26.2
wasabi==0.8.0
wcwidth==0.2.5
word2number==1.1
zipp==3.4.0
&lt;/denchmark-code&gt;


&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;

&lt;denchmark-link:https://demo.allennlp.org/semantic-role-labeling&gt;Visit the demo website for SRL&lt;/denchmark-link&gt;


Example:
Enter almost any variation of:
"I am here."
"We are people."
"I am."

#  https://demo.allennlp.org/semantic-role-labeling/MjU3NDk3NA==

# or
from allennlp.predictors.predictor import Predictor

allen_predictor_srl = Predictor.from_path(
    "./models/bert-base-srl-2020.11.19.tar.gz"
)

output = allen_predictor_srl.predict(sentence="I am here.")
print(output)

# observe nothing

My install script:
python3 -m venv env
source ./env/bin/activate


pip3 install --upgrade pip

pip3 install -U --no-cache-dir

pip3 install -U allennlp allennlp-models --no-cache-dir

python3 -m spacy download en_core_web_lg    --no-cache-dir
python3 -m spacy download en_core_web_sm    --no-cache-dir
python3 -m spacy download en_vectors_web_lg --no-cache-dir
python3 -m spacy download de_core_news_md   --no-cache-dir



UPDATE: I tried downgrading to v1.0 and am still experiencing the issue. I tried installing from source. Getting rid of all other dependencies to see what would happen. In addition to the issue I'm describing, results are generally worse for subordinate clauses and the like. It's unclear whether this is an allennlp bug or a bug related to some dependency. The online demo has similar issues.
UPDATE2: I tried on a completely different machine (Linux with NVIDIA GPUs) using pip -- same result. Could something be wrong with the toolchain/dependencies?
	</description>
	<comments>
		<comment id='1' author='KTRosenberg' date='2020-11-26T13:56:28Z'>
		Hi &lt;denchmark-link:https://github.com/KTRosenberg&gt;@KTRosenberg&lt;/denchmark-link&gt;
, I don't know what's wrong with SRL module, it seems to work incorrectly with the new version of pretrained model (2020.11.19).
However, most of my cases (tested with yours) just works fine with Python 3.6.4, allennlp==1.2.0, allennlp-models==1.2.0 and bert-base-srl-2020.09.03.
		</comment>
		<comment id='2' author='KTRosenberg' date='2020-11-26T14:04:32Z'>
		Thanks for your reply. I will double-check. Is it good enough to install those versions of allennlp using pip?
I hope we can arrive at a “best” version again. These seem to be severe breaking changes for rather simple examples.
		</comment>
		<comment id='3' author='KTRosenberg' date='2020-11-26T17:37:21Z'>
		Hi &lt;denchmark-link:https://github.com/hieudepchai&gt;@hieudepchai&lt;/denchmark-link&gt;
 I tried an install of those versions of allennlp and that particular model. Allennlp downloads the small dataset for spacy. I enter "I am here." and "This is a dog" and I still get no verbs. Are you sure it's not calling out somewhere in the background? I remember seeing printouts referring to Amazon AWS services of sorts.
Am I supposed to configure something else? It just seems like something is completely wrong with a  installation.
I'm using Python 3.8, but that shouldn't matter. In my old setup, which is still running on a temporary cloud instance, it was still working fine. The version of Spacy was older though.
Is there a way in AllenNLP to specify the larger Spacy dataset or... I am really not sure what is going wrong here.
		</comment>
		<comment id='4' author='KTRosenberg' date='2020-12-01T02:22:40Z'>
		&lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 It appears that &lt;denchmark-link:https://github.com/allenai/allennlp-demo/commit/7dd97dd05031fa7ac5d4ffb0efea0db30fd9ee41&gt;this&lt;/denchmark-link&gt;
 update has broken the SRL model in the demo. (Also, the modelcard still has the old url; I'll update that once we fix this).
		</comment>
		<comment id='5' author='KTRosenberg' date='2020-12-01T02:41:44Z'>
		I tried switching to that older model, but I still had the same issue.
		</comment>
		<comment id='6' author='KTRosenberg' date='2020-12-03T02:29:58Z'>
		Ok, I digged in a bit more. Spacy's model tags "is" etc. as &lt;denchmark-link:https://universaldependencies.org/u/pos/all.html#:~:text=AUX%20%3A%20auxiliary&amp;text=An%20auxiliary%20is%20a%20function,%2C%20aspect%2C%20voice%20or%20evidentiality.&gt;"AUX"&lt;/denchmark-link&gt;
 while the predictor &lt;denchmark-link:https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/predictors/srl.py#L108&gt;uses the tag&lt;/denchmark-link&gt;
 "VERB" to create the list of instances to run forward upon. &lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 I'm not sure what the correct behavior should be in this case.
&lt;denchmark-link:https://github.com/KTRosenberg&gt;@KTRosenberg&lt;/denchmark-link&gt;
 Can you confirm that this worked with earlier versions of the library? I get the same behavior (i.e., no verbs in the output) even with  and , and this part of the code has not changed recently. Also, since you mention that other SRL engines return some output in such cases, can you give examples of these engines and their outputs?
		</comment>
		<comment id='7' author='KTRosenberg' date='2020-12-03T03:09:35Z'>
		&lt;denchmark-link:https://github.com/AkshitaB&gt;@AkshitaB&lt;/denchmark-link&gt;
 It doesn't work with older versions of the library anymore--even AllenNLP 1.0 with the model I am sure I used with it. Around August or September, I had a remote server installed for a project on which AllenNLP 1.0.0 was installed. If I ssh onto that machine, I still get expected results.
When I did the installation, I think I was using an older version of Spacy. I wonder if something changed there (or with another dependencies). If you'd like, I could get back to you with a full list of libraries installed on that still-working machine.
This is a library I found that uses AllenNLP internally (&lt;denchmark-link:https://github.com/Riccorl/transformer-srl/issues/5&gt;link to relevant issue&lt;/denchmark-link&gt;
), but with a different model, which also suggests to me that maybe something is wrong with the way the default BERT models interact with Spacy(?). Of course I'm just throwing guesses.
One thing that's good about that SRL library is that it adds lemmas, frame ids, and most helpful, Propbank tags for the verbs. Those have been very helpful so far.
		</comment>
		<comment id='8' author='KTRosenberg' date='2020-12-04T17:25:25Z'>
		&lt;denchmark-link:https://github.com/KTRosenberg&gt;@KTRosenberg&lt;/denchmark-link&gt;
 The issue appears to be because of an older version of Spacy. You can try specifying an older version or the medium or large version of the spacy tokenizer in the predictor.
		</comment>
		<comment id='9' author='KTRosenberg' date='2020-12-04T17:31:29Z'>
		I can no longer install an older version of Spacy. I was saying that the newer version might be the cause of the issue.
Will the issue be looked-into more? From what you just wrote, it sounds like AllenNLP doesn't play well with newer versions of Spacy.
Also, how do you specify a larger version of the Spacy tokenizer in the predictor?
		</comment>
		<comment id='10' author='KTRosenberg' date='2020-12-04T17:45:11Z'>
		&lt;denchmark-link:https://github.com/KTRosenberg&gt;@KTRosenberg&lt;/denchmark-link&gt;
 I don't think we have time to look into this in the short term.  The issue is more subtle than "AllenNLP doesn't play well with newer versions of Spacy".  This particular discrepancy is specific to the SRL model.  The SRL is trained on the CONLL dataset, which uses Penn Treebank POS tags.  I believe in this scheme, "is" is labeled as a verb.  However Spacy uses universal dependencies, where in these examples, "is" is labeled an AUX as &lt;denchmark-link:https://github.com/AkshitaB&gt;@AkshitaB&lt;/denchmark-link&gt;
 pointed out earlier.  We presently don't label AUX as a verb, because sometimes it is not a verb.
I think a reasonable fix for your problem would be to add a disjunction to &lt;denchmark-link:https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/predictors/srl.py#L108&gt;https://github.com/allenai/allennlp-models/blob/master/allennlp_models/structured_prediction/predictors/srl.py#L108&lt;/denchmark-link&gt;
 which checks if the lemma is "be", but I'm not sure how general this solution is and I worry that it's a slippery slope to requiring additional hacks.  If you try this out and it works well, we would welcome a contribution.
		</comment>
		<comment id='11' author='KTRosenberg' date='2020-12-04T17:46:19Z'>
		&lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/AkshitaB&gt;@AkshitaB&lt;/denchmark-link&gt;
 could you answer how to specify a different version of the Spacy tokenizer in the predictor?  You could certainly write a custom predictor (and start by copying the existing one) but there may be an easier way.
		</comment>
		<comment id='12' author='KTRosenberg' date='2020-12-04T17:48:41Z'>
		Looks like someone made a PR: &lt;denchmark-link:https://github.com/allenai/allennlp-models/pull/178&gt;allenai/allennlp-models#178&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='KTRosenberg' date='2020-12-04T18:08:32Z'>
		&lt;denchmark-link:https://github.com/schmmd&gt;@schmmd&lt;/denchmark-link&gt;
 For what it's worth, that pull request looks like exactly what is needed. "to have" should also be a verb.
		</comment>
		<comment id='14' author='KTRosenberg' date='2020-12-05T12:11:27Z'>
		&lt;denchmark-link:https://github.com/schmmd&gt;@schmmd&lt;/denchmark-link&gt;
, you say:

We presently don't label AUX as a verb, because sometimes it is not a verb.

If that is the case then my change in the PR isn't good enough, because it just includes all words labelled as VERB and AUX without filtering.
&lt;denchmark-link:https://universaldependencies.org/u/pos/AUX_.html&gt;https://universaldependencies.org/u/pos/AUX_.html&lt;/denchmark-link&gt;

From this description, it sounds like it's language-dependent. For English, my solution seems to make sense, but for some languages treating AUX as a VERB might make no sense. (I don't know, just hypothesising)
Maybe I should make it conditional? Accept AUX only if it's English. (we can include more languages, but I don't know what are the other languages where AUX is always a verb)
Here I found another interesting discussion on this topic:
&lt;denchmark-link:https://github.com/UniversalDependencies/docs/issues/625&gt;UniversalDependencies/docs#625&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='KTRosenberg' date='2020-12-05T16:37:42Z'>
		Or we could add a boolean like include_auxiliaries to all the relevant methods and leave it for users to decide.
		</comment>
		<comment id='16' author='KTRosenberg' date='2020-12-05T18:41:25Z'>
		Does Spacy also consider “have” an auxiliary? As mentioned in that pull request, it seems odd that “have” would not be considered a verb. I wonder what should be done in cases such as “I have seen.” There are definitely exceptions to the rule.
		</comment>
		<comment id='17' author='KTRosenberg' date='2020-12-07T16:12:07Z'>
		&lt;denchmark-link:https://github.com/wangrat&gt;@wangrat&lt;/denchmark-link&gt;
 if it's easy to condition on English, that makes a lot of sense.  I think your PR is good, given that it'd addressing a very real problem that two people ran into in the same week.
		</comment>
		<comment id='18' author='KTRosenberg' date='2020-12-07T21:42:12Z'>
		
@schmmd For what it's worth, that pull request looks like exactly what is needed. "to have" should also be a verb.

Or maybe it should be something else. "To have X". It would be easier for NLP systems to have a way to identify these together.
		</comment>
		<comment id='19' author='KTRosenberg' date='2020-12-07T22:11:41Z'>
		Ok, tomorrow I will modify my PR to condition on English if possible. Then I just have to adjust some tests so the new behaviour passes them and it will be good to go.
We can continue this discussion and if someone comes up with a better solution to the problem we can introduce it later in a new PR. For now this seems to be a step forward.
		</comment>
		<comment id='20' author='KTRosenberg' date='2020-12-07T22:13:40Z'>
		&lt;denchmark-link:https://github.com/wangrat&gt;@wangrat&lt;/denchmark-link&gt;
 this PR is clearly a step forward!  Thanks for putting it together, and I'll be glad when it's merged.
		</comment>
		<comment id='21' author='KTRosenberg' date='2020-12-09T18:38:32Z'>
		The &lt;denchmark-link:https://github.com/allenai/allennlp-models/pull/178&gt;PR&lt;/denchmark-link&gt;
 has been merged. Thanks &lt;denchmark-link:https://github.com/KTRosenberg&gt;@KTRosenberg&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/wangrat&gt;@wangrat&lt;/denchmark-link&gt;
 for bringing up the issue, and the discussion!
		</comment>
	</comments>
</bug>