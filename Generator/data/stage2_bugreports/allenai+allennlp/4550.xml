<bug id='4550' author='nitishgupta' open_date='2020-08-12T04:29:28Z' closed_time='2020-08-18T11:57:01Z'>
	<summary>[Models] BART model output is incorrect shape</summary>
	<description>
&lt;denchmark-h:h2&gt;Checklist&lt;/denchmark-h&gt;


 I have verified that the issue exists against the master branch of AllenNLP.
 I have read the relevant section in the contribution guide on reporting bugs.
 I have checked the issues list for similar or identical bug reports.
 I have checked the pull requests list for existing proposed fixes.
 I have checked the CHANGELOG and the commit log to find out if the bug was already fixed in the master branch.
 I have included in the "Description" section below a traceback from any exceptions related to this bug.
 I have included in the "Related issues or possible duplicates" section beloew all related issues and possible duplicate issues (If there are none, check this box anyway).
 I have included in the "Environment" section below the name of the operating system and Python version that I was using when I discovered this bug.
 I have included in the "Environment" section below the output of pip freeze.
 I have included in the "Steps to reproduce" section below a minimally reproducible example.

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

The output of the BART model is incorrect here -- &lt;denchmark-link:https://github.com/allenai/allennlp-models/blob/master/allennlp_models/generation/models/bart.py#L206&gt;https://github.com/allenai/allennlp-models/blob/master/allennlp_models/generation/models/bart.py#L206&lt;/denchmark-link&gt;

It should be (batch_size, seq_len, vocab_size) but is (batch_size, 1, vocab_size)

Python traceback:




&lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;


None

&lt;denchmark-h:h2&gt;Environment&lt;/denchmark-h&gt;

OS: Linux
Python version: 3.7.7

Output of pip freeze:

-e git+git@github.com:allenai/allennlp.git@e53d18580807dabff707f618f7e148c98d25da18#egg=allennlp
-e git+git@github.com:allenai/allennlp-models.git@45f85ce67b869e6f33fb0a38bd9ae17bd99f287c#egg=allennlp_models
apex @ git+https://github.com/NVIDIA/apex.git@459de22d59c64e30fd4b368c368c5b74e269f3dd
appdirs==1.4.4
attrs==19.3.0
bert-score==0.3.5
black==19.10b0
bleach==3.1.5
blis==0.4.1
boto3==1.14.29
botocore==1.17.29
catalogue==1.0.0
certifi==2020.6.20
cffi==1.14.1
chardet==3.0.4
click==7.1.2
codecov==2.1.8
colorama==0.4.3
conllu==3.1.1
coverage==5.2.1
cryptography==3.0
cycler==0.10.0
cymem==2.0.3
dateparser==0.7.6
docutils==0.15.2
editdistance==0.5.3
en-core-web-lg @ https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.1/en_core_web_lg-2.3.1.tar.gz
en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz
filelock==3.0.12
flake8==3.8.3
flaky==3.7.0
ftfy==5.8
future==0.18.2
googledrivedownloader==0.4
h5py==2.10.0
idna==2.10
importlib-metadata==1.7.0
jeepney==0.4.3
Jinja2==2.11.2
jmespath==0.10.0
joblib==0.16.0
jsonnet==0.16.0
jsonpickle==1.4.1
jsons==1.2.0
keyring==21.2.1
kiwisolver==1.2.0
livereload==2.6.2
lunr==0.5.8
lxml==4.5.2
Markdown==3.2.2
markdown-include==0.5.1
MarkupSafe==1.1.1
matplotlib==3.3.0
mccabe==0.6.1
mkdocs==1.1.2
mkdocs-material==5.5.5
mkdocs-material-extensions==1.0
mkl-fft==1.1.0
mkl-random==1.1.1
mkl-service==2.3.0
more-itertools==8.4.0
murmurhash==1.0.2
mypy==0.782
mypy-extensions==0.4.3
nltk==3.5
nr.collections==0.0.1
nr.databind.core==0.0.16
nr.databind.json==0.0.13
nr.interface==0.0.3
nr.metaclass==0.0.5
nr.parsing.date==0.2.0
nr.pylang.utils==0.0.3
nr.stream==0.0.4
nr.utils.re==0.1.0
numpy==1.18.5
olefile==0.46
overrides==3.1.0
packaging==20.4
pandas==1.1.0
pathspec==0.8.0
pathtools==0.1.2
Pillow @ file:///tmp/build/80754af9/pillow_1594307325547/work
pkginfo==1.5.0.1
plac==1.1.3
pluggy==0.13.1
preshed==3.0.2
protobuf==3.12.2
py==1.9.0
py-cpuinfo==7.0.0
py-rouge==1.1
pycodestyle==2.6.0
pycparser==2.20
pydoc-markdown @ git+https://github.com/NiklasRosenstein/pydoc-markdown.git@f0bf8af1db4f11581c19d206d4ed1ab34b4854c1
pyflakes==2.2.0
Pygments==2.6.1
pymdown-extensions==7.1
pyparsing==2.4.7
pytest==5.4.3
pytest-benchmark==3.2.3
pytest-cov==2.10.0
python-dateutil==2.8.1
pytz==2020.1
PyYAML==5.3.1
readme-renderer==26.0
regex==2020.7.14
requests==2.24.0
requests-toolbelt==0.9.1
responses==0.10.15
rfc3986==1.4.0
ruamel.yaml==0.16.10
ruamel.yaml.clib==0.2.0
s3transfer==0.3.3
sacremoses==0.0.43
sacrerouge==0.0.4
scikit-learn==0.23.1
scipy==1.5.2
seaborn==0.10.1
SecretStorage==3.1.2
sentencepiece==0.1.91
six==1.15.0
spacy==2.3.2
srsly==1.0.2
tensorboardX==2.1
thinc==7.4.1
threadpoolctl==2.1.0
tokenizers==0.8.1rc1
toml==0.10.1
torch==1.5.1
torchvision==0.6.0a0+82fd1c8
tornado==6.0.4
tqdm==4.48.0
transformers==3.0.2
twine==3.2.0
typed-ast==1.4.1
typing-extensions==3.7.4.2
typish==1.7.0
tzlocal==2.1
Unidecode==1.1.1
urllib3==1.25.10
wasabi==0.7.1
watchdog==0.10.3
wcwidth==0.2.5
webencodings==0.5.1
word2number==1.1
zipp==3.1.0



&lt;denchmark-h:h2&gt;Steps to reproduce&lt;/denchmark-h&gt;


Example source:

x = torch.LongTensor([[0, 133, 766, 9]])
m = torch.BoolTensor([[True, True, True, True]])
bart = BartForConditionalGeneration.from_pretrained("facebook/bart-large", output_past=True)
y = bart(input_ids=x, attention_mask=m, decoder_input_ids=x, decoder_attention_mask=m)[0]
y.size()   # output == torch.Size([1, 1, 50265])



	</description>
	<comments>
		<comment id='1' author='nitishgupta' date='2020-08-12T04:38:08Z'>
		&lt;denchmark-link:https://github.com/dirkgr&gt;@dirkgr&lt;/denchmark-link&gt;
 - I saw that you recently added BART to the allennlp-models, hence you might be the best person to know about this.
		</comment>
		<comment id='2' author='nitishgupta' date='2020-08-13T20:14:14Z'>
		Apologies for the false alarm -- I found a solution here: &lt;denchmark-link:https://github.com/huggingface/transformers/issues/6353&gt;huggingface/transformers#6353&lt;/denchmark-link&gt;

One line fix;  needs to be passed to the BART model's .
I tried to test the CNN/DM BART model here but, (1) I first ran into an issue with the data link in the config, (2) I downloaded the tar manually but the dataset reader was taking forever to untar and I killed the process.
Is it possible to release a small sample dataset to test the model. Once I'm able to test, I can send a PR with the change if that helps.
		</comment>
		<comment id='3' author='nitishgupta' date='2020-08-14T09:38:59Z'>
		I did not dig into the details, but is this something we should change on our end?
What was the issue with the data link in the config?
Untarring will indeed take a long time. It has to create many small files, which is never ideal. I'd be happy to look at various PRs that address this, for example:

change the data format so that the data lives in a few large files
show a progress bar while un-tarring
add a small dataset and make it the default in the config, add the large dataset in a commented-out line in the config

		</comment>
		<comment id='4' author='nitishgupta' date='2020-08-15T15:57:00Z'>
		Weirdly I do not get an error when I try to train this model, but get one doing something very similar.
I'm closing this now, will reopen if I face issues.
		</comment>
		<comment id='5' author='nitishgupta' date='2020-08-17T12:04:17Z'>
		Alright, but I am quite interested in the issue with the data link? We try pretty hard to make it so you can run the training configs out of the box (as long as the data isn't copyright protected, at least).
		</comment>
		<comment id='6' author='nitishgupta' date='2020-08-17T14:19:37Z'>
		Okay, yeah I just confirmed and trying to train using the URL provided does run into an issue:
&lt;denchmark-code&gt;  File "/mnt/castor/seas_home/n/nitishg/code/allennlp-models-master/allennlp_models/generation/dataset_readers/cnn_dm.py", line 144, in _read
    "Story with url '%s' and hash '%s' not found" % (url, url_hash)
allennlp.common.checks.ConfigurationError: Story with url 'http://web.archive.org/web/20070716092219id_/http://us.cnn.com:80/2007/US/07/13/btsc.obrien.criminallyinsane/index.html' and hash 'ee8871b15c50d0db17b0179a6d2beab35065f1e9' not found
&lt;/denchmark-code&gt;

This runs if I download the .tar.gz locally and point to that. Haven't dug into what the issue might be.
P.S. I'm using OpenSuse linux.
		</comment>
		<comment id='7' author='nitishgupta' date='2020-08-18T11:57:01Z'>
		That sounds like it's a case of &lt;denchmark-link:https://github.com/allenai/allennlp/issues/4501&gt;#4501&lt;/denchmark-link&gt;
. You probably tried to run the config, and killed the extraction half-way through. Now it thinks the extraction is already there, even though only have the files are in it. You can fix this by removing the extraction directory, and then running the config again. You'll have to be patient until the extraction is complete.
I'll close this, but feel free to re-open if we didn't catch all the issues.
		</comment>
	</comments>
</bug>