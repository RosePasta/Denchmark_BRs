<bug id='4803' author='plroit' open_date='2020-11-18T16:24:00Z' closed_time='2020-11-19T19:15:46Z'>
	<summary>SRL model produces wrong outputs on the same examples taken from the official demo</summary>
	<description>

 I have verified that the issue exists against the master branch of AllenNLP.
 I have checked the issues list for similar or identical bug reports.
 I have checked the pull requests list for existing proposed fixes.
 I have checked the CHANGELOG and the [commit log]
 I have included in the "Related issues or possible duplicates"
 I have included in the "Steps to reproduce" section below a minimally reproducible example.

&lt;denchmark-h:h2&gt;Description&lt;/denchmark-h&gt;

Hello,
I use AllenNLP version: 1.2.1 and I follow instructions for the SRL predictor (based on BERT)
in the demo: &lt;denchmark-link:https://demo.allennlp.org/semantic-role-labeling/&gt;https://demo.allennlp.org/semantic-role-labeling/&lt;/denchmark-link&gt;

The srl model I load is stored in this path:
&lt;denchmark-link:https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz&gt;https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz&lt;/denchmark-link&gt;

and I load the predictor locally, following the usage instructions in the demo.
When I input the sentence, taken from the demo to my local predictor (on my machine, not the demo website, obviously)
the predictions get very weird, very different than the model advertised in the demo, and not inline with the high scores that I know this model has.
sentence:

However, voters decided that if the stadium was such a good idea someone would build it himself, and rejected it 59% to 41%.

I get the following predictions:
decided:

'description': '[ARGM-PRD: However ,] [ARG0: voters] [V: decided] [ARG1: that if the stadium] was such a good idea someone would build it himself , and rejected it 59 % to 41 %

would

However , voters decided that [ARG1: if the stadium was such a good idea] someone [V: would] [ARGM-TMP: build it himself ,] and rejected it 59 % to 41 % .

build

However , voters decided that if the stadium was such a good idea someone would [V: build] [ARG1: it himself] , and rejected it 59 % to 41 %

rejected

However , voters decided that if the stadium was such a good idea someone would build it himself , and [V: rejected] it 59 % to 41 % .

&lt;denchmark-h:h2&gt;Related issues or possible duplicates&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/allenai/allennlp/issues/3166&gt;#3166&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='plroit' date='2020-11-19T00:52:39Z'>
		I think the problem is that we do constrained decoding on the word pieces, but we want to do it on tokens. I seem to remember this from a discussion with &lt;denchmark-link:https://github.com/DeNeutoy&gt;@DeNeutoy&lt;/denchmark-link&gt;
 a long time ago.
		</comment>
		<comment id='2' author='plroit' date='2020-11-19T01:13:24Z'>
		I'm actually not seeing that problem in the output this time. I'll investigate if simply re-training turns out not to fix this.
		</comment>
		<comment id='3' author='plroit' date='2020-11-19T18:27:55Z'>
		The version we're advertising in the demo is curiously old. I'm getting much better results (though not identical ones) with a newer model. I made a pull request here: &lt;denchmark-link:https://github.com/allenai/allennlp-demo/pull/629&gt;allenai/allennlp-demo#629&lt;/denchmark-link&gt;

As a workaround, you should be able to get good results by using https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.11.19.tar.gz as your model URL.
		</comment>
		<comment id='4' author='plroit' date='2020-11-19T19:15:46Z'>
		That PR is now merged. Let me know if you find it still broken! I didn't test things exhaustively, just with your example.
		</comment>
	</comments>
</bug>