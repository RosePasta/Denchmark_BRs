<bug id='4392' author='edchengg' open_date='2020-06-22T14:17:30Z' closed_time='2020-09-03T23:27:40Z'>
	<summary>Can't reproduce SRL result with allennlp==1.0.0</summary>
	<description>
System (please complete the following information):
OS: Ubuntu 18.04.3 LTS
Python version: 3.7
AllenNLP version: v1.0.0
PyTorch version: 1.5
Allennlp-models: v1.0.0
Question
Hi &lt;denchmark-link:https://github.com/DeNeutoy&gt;@DeNeutoy&lt;/denchmark-link&gt;
 , I try to reproduce the results on the OntoNotes dataset (conll 2012) in the Shi et al., 2019 paper used in the SRL demo. However, I could only get F1 around 0.79.
Command I used:
&lt;denchmark-code&gt;allennlp evaluate https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz /data/conll-formatted-ontonotes-5.0/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/conll-2012-test/data/english
&lt;/denchmark-code&gt;

I also tried to train the model with config file in allennlp-models but only get to F1=79.
I found a related issue &lt;denchmark-link:https://github.com/allenai/allennlp/issues/4220&gt;#4220&lt;/denchmark-link&gt;
 and was able to reproduce the result (86.5) with allennlp==0.9 and an old checkpoint &lt;denchmark-link:https://s3-us-west-2.amazonaws.com/allennlp/models/bert-base-srl-2019.06.17.tar.gz&gt;https://s3-us-west-2.amazonaws.com/allennlp/models/bert-base-srl-2019.06.17.tar.gz&lt;/denchmark-link&gt;
. But I guess it might be worth reporting the issue since 1.0 is a stable version now.
Any help would be appreciated!
	</description>
	<comments>
		<comment id='1' author='edchengg' date='2020-06-26T16:14:54Z'>
		Possibly related to &lt;denchmark-link:https://github.com/allenai/allennlp/issues/4216&gt;#4216&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='edchengg' date='2020-06-27T19:05:09Z'>
		
Possibly related to #4216

I guess there are some problems with pytorch_transformer and transformer lib.
		</comment>
		<comment id='3' author='edchengg' date='2020-07-22T09:16:42Z'>
		I saw in &lt;denchmark-link:https://github.com/allenai/allennlp/issues/4457&gt;#4457&lt;/denchmark-link&gt;
 that the BERT SRL model is trained again. I evaluated it with  and it still produce F1 below 80. Is it normal to have this performance since the 1.1 is not stable yet or it should work by now?
Command
&lt;denchmark-code&gt;allennlp evaluate "https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.07.14.tar.gz" [data]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='edchengg' date='2020-07-23T20:25:36Z'>
		By changing the indexer in the dataset reader from  SingleIdTokenIndexer to PretrainedTransformerIndexer the model seems to work as intended. I cannot complete a full train at the moment but the scores are higher after few epochs than the previous full train.
		</comment>
		<comment id='5' author='edchengg' date='2020-07-24T14:30:34Z'>
		
By changing the indexer in the dataset reader from SingleIdTokenIndexer to PretrainedTransformerIndexer the model seems to work as intended. I cannot complete a full train at the moment but the scores are higher after few epochs than the previous full train.

Thanks! I will test it asap
		</comment>
	</comments>
</bug>