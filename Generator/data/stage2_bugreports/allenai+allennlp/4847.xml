<bug id='4847' author='epwalsh' open_date='2020-12-07T00:02:33Z' closed_time='2020-12-21T16:47:18Z'>
	<summary>Multi-process data loader bug with TensorField (RuntimeError: received 0 items of ancdata)</summary>
	<description>
I discovered this issue while using the new MultiprocessDataLoader with num_workers &gt; 0 and max_instances_in_memory set to some high number (1000 in my case) to load batches that are built with instances that contain TensorFields.
&lt;denchmark-code&gt;  ...
  File "/home/epwalsh/AllenAI/allennlp/allennlp/data/data_loaders/multi_process_data_loader.py", line 236, in __iter__
    yield from self._iter_batches()
  File "/home/epwalsh/AllenAI/allennlp/allennlp/data/data_loaders/multi_process_data_loader.py", line 421, in _iter_batches
    raise e
RuntimeError: received 0 items of ancdata
&lt;/denchmark-code&gt;

The issue is stems from the fact that tensors are passed between processes using shared memory, but some systems (like the one I was on) may have strict limits on shared memory by default. So if you pile too many tensors into shared memory by having  too high, you're going to run into this. &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/973#issuecomment-291287925&gt;pytorch/pytorch#973 (comment)&lt;/denchmark-link&gt;
.
Luckily the solution is simple: either decrease max_instances_in_memory (bringing it down to 100 worked in my case), or increase the shared memory available to your training process.
	</description>
	<comments>
		<comment id='1' author='epwalsh' date='2020-12-21T16:47:16Z'>
		This issue is being closed due to lack of activity. If you think it still needs to be addressed, please comment on this thread ðŸ‘‡
		</comment>
	</comments>
</bug>