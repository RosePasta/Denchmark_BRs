<bug id='4826' author='mahnerak' open_date='2020-11-30T15:44:24Z' closed_time='2021-01-14T17:32:47Z'>
	<summary>TrackEpochCallback is not an EpochCallback</summary>
	<description>
Is there any reason why TrackEpochCallback should not inherit from EpochCallback?



allennlp/allennlp/training/trainer.py


        Lines 179 to 188
      in
      5b30658






 



 @EpochCallback.register("track_epoch_callback") 



 class TrackEpochCallback: 



 """ 



     A callback that you can pass to the `GradientDescentTrainer` to access the current epoch number 



     in your model during training. This callback sets `model.epoch`, which can be read inside of 



     `model.forward()`. Since the EpochCallback passes `epoch=-1` 



     at the start of the training, we set `model.epoch = epoch + 1` which now denotes the number of 



     completed epochs at a given training state. 



     """ 





	</description>
	<comments>
		<comment id='1' author='mahnerak' date='2020-11-30T17:00:51Z'>
		No, this was an oversight. Thanks for catching it. Would you like to make a PR to fix?
		</comment>
		<comment id='2' author='mahnerak' date='2020-11-30T17:06:09Z'>
		Sure! I'll make a PR.
		</comment>
		<comment id='3' author='mahnerak' date='2020-12-15T16:50:47Z'>
		&lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
 this is just a friendly ping to make sure you haven't forgotten about this issue 
		</comment>
		<comment id='4' author='mahnerak' date='2020-12-15T17:46:37Z'>
		Hey &lt;denchmark-link:https://github.com/mahnerak&gt;@mahnerak&lt;/denchmark-link&gt;
 are you still planning on making a PR for this? If not I can do it.
		</comment>
		<comment id='5' author='mahnerak' date='2020-12-15T23:49:56Z'>
		Yes, I do. I was just preparing a couple of other notes on Callbacks and wanted to submit them as a single PR.
		</comment>
		<comment id='6' author='mahnerak' date='2020-12-15T23:55:08Z'>
		&lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
 The  callbacks are called within the  block.


However, I was expecting  callbacks to be called even in case of an error. Or, IDK, maybe there should be another way to inform the callback about the end of the training (so it can do a cleanup).
		</comment>
		<comment id='7' author='mahnerak' date='2020-12-16T00:15:57Z'>
		As there are no many third-party callbacks implemented for AllenNLP (yet) and the backwards-compatibility is not an issue right now, I think it's better to revisit the callback API.
For example, we may need on_start() callback instead of firing on_epoch(epoch=-1).
Also, I don't get why there should be separate BatchCallback, EndCallback, EpochCallback, and a metaclass TrainCallback to rule them all. I believe you had your reasons to implement it this way. But why not to have a single Callback class with __init__(self, serialization_dir, trainer), on_start(), on_batch_start(), on_batch_end(), on_epoch_start(), on_epoch_end(), on_end(), on_error(), on_after_backward(), etc...?
If someone wants to have a callback just for epochs, they can implement only a single method on_epoch_end().
I just feel the API of callbacks is the only non-intuitive abstraction in AllenNLP.
Pytorch-lightning has much straightforward callback interface.
		</comment>
		<comment id='8' author='mahnerak' date='2020-12-16T19:19:59Z'>
		Yea... this was kind of a half-baked feature to compromise with the folks (including me) who wanted to stick with the CallbackTrainer. So I'm all for making improvements, but we're committed to strictly adhering to Semantic Versioning, and so any breaking changes will have to go into our next major release: v2.0.
We are already working towards our v2.0 release though on a separate branch, so you could make a PR to that branch if you're interested. The branch is called vision (because the main focus of the 2.0 release is supporting vision + text models).
		</comment>
		<comment id='9' author='mahnerak' date='2020-12-16T19:24:09Z'>
		Okay, so I'll try to make a PR on non-breaking changes and after that will make major changes on vision branch.
		</comment>
		<comment id='10' author='mahnerak' date='2020-12-16T19:24:37Z'>
		Sounds great
		</comment>
		<comment id='11' author='mahnerak' date='2020-12-31T16:57:11Z'>
		&lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
 this is just a friendly ping to make sure you haven't forgotten about this issue 
		</comment>
		<comment id='12' author='mahnerak' date='2021-01-14T17:19:22Z'>
		&lt;denchmark-link:https://github.com/epwalsh&gt;@epwalsh&lt;/denchmark-link&gt;
 this is just a friendly ping to make sure you haven't forgotten about this issue 
		</comment>
		<comment id='13' author='mahnerak' date='2021-01-14T17:32:44Z'>
		Closing via &lt;denchmark-link:https://github.com/allenai/allennlp/pull/4893&gt;#4893&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/mahnerak&gt;@mahnerak&lt;/denchmark-link&gt;
 would you still like to propose changes to the callback API? Now would be good time since we are trying to wrap things up for 2.0. After the 2.0 release we won't be making any breaking changes for a while.
		</comment>
		<comment id='14' author='mahnerak' date='2021-01-17T19:05:40Z'>
		I'll try to make a proposal on:

Removing separate EpochCallback, BatchCallback in favour of a unified TrainerCallback with methods on_epoch_end(), on_batch_end().
Not calling EpochCallback at first step with epoch = -1 in favour of on_train_start()
End callbacks are called with method on_train_end(). If an error has occurred, it is provided as an argument.

I'll prepare a PR for these changes. The other features of TrainerCallback may be easily added without any breaking changes.
		</comment>
		<comment id='15' author='mahnerak' date='2021-01-18T18:48:00Z'>
		These sound like good changes, but it breaks the API, and we are very close to releasing 2.0. Unless the PR is perfect by Tuesday night, we'll have to ship it in 2.1, and make sure it's backwards compatible.
		</comment>
	</comments>
</bug>