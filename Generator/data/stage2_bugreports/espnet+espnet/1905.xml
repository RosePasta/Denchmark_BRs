<bug id='1905' author='rppravin' open_date='2020-05-05T23:29:32Z' closed_time='2020-05-08T18:45:42Z'>
	<summary>Loading a Transformer architecture based pre-trained model in Python</summary>
	<description>
Following code (based on &lt;denchmark-link:https://espnet.github.io/espnet/notebook/asr_cli.html#load-model&gt;https://espnet.github.io/espnet/notebook/asr_cli.html#load-model&lt;/denchmark-link&gt;
) to load pre-trained model in Python using "model.json" file, works for RNN based models but not Transformer based models.
For example, I try to load a pre-trained Transformer based model based on Libripeech, such as shown below. When I print "model" after the step "model = E2E.build(idim, odim, **conf)", I see an RNN based architecture not Transformer based architecture as expected.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

import json
import torch
from espnet.nets.pytorch_backend.e2e_asr import E2E
model_dir = "espnet/egs/librispeech/asr1/exp/train_960_pytorch_train_pytorch_transformer.v1_aheads8_batch-bins15000000_specaug/results"
with open(model_dir + "/model.json", "r") as f:
idim, odim, conf = json.load(f)
model = E2E.build(idim, odim, **conf)
model.load_state_dict(torch.load(model_dir + "/model.val5.avg.best"))
model.cpu().eval()
vocab = conf["char_list"]
print(vocab)
model
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Can you please let me know if E2E is expected to work for Transofmer based architecture? If not, is there an easy way to load a Transformer architecture based pre-trained using a Python based interface, and use it (similar to E2E based model loading for RNN)?
Thanks!
	</description>
	<comments>
		<comment id='1' author='rppravin' date='2020-05-06T13:15:15Z'>
		it works with Transformer but ensure that the pre trained model is Transformer not RNN. could you  check the model.json and check the config file
		</comment>
		<comment id='2' author='rppravin' date='2020-05-07T05:55:12Z'>
		Thanks for your reply.
I am not able to use the E2E for Transformer based models. I had to make the following changes to the code in my original message to get it working.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

import json
import torch
import argparse
from espnet.bin.asr_recog import get_parser
import kaldiio
import re
from espnet.nets.beam_search import BeamSearch
from pdb import set_trace as bp
from espnet.utils.dynamic_import import dynamic_import
from espnet.asr.asr_utils import get_model_conf
import os
from espnet.asr.asr_utils import torch_load
model_dir = root + "espnet/egs/librispeech/asr1/exp/train_960_pytorch_train_pytorch_transformer.v1_aheads8_batch-bins15000000_specaug/results"
model_path=model_dir+'/'+'model.acc.best'
idim, odim, train_args = get_model_conf(model_path, os.path.join(os.path.dirname(model_path), 'model.json'))
model_module = train_args.model_module
model_class = dynamic_import(model_module)
model = model_class(idim, odim, train_args)
torch_load(model_path, model)
model.eval()
vocab = train_args.char_list
print(vocab)
model
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Thanks!
		</comment>
	</comments>
</bug>