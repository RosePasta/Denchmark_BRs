<bug id='2505' author='alucassch' open_date='2020-09-20T18:35:57Z' closed_time='2020-09-21T23:03:09Z'>
	<summary>Can't reproduce results using conformer model using different code versions</summary>
	<description>

I trained a conformer model with espnet1 commit tag v0.9.1 with my own data and tests and got pretty good results as expected.
After update to v0.9.3 the results got a lot worse. I could check that I can reproduce the results until the commit &lt;denchmark-link:https://github.com/espnet/espnet/commit/4345515d95bb21ab09c159cff469f60f6d255123&gt;4345515&lt;/denchmark-link&gt;
 where the results should be like
&lt;denchmark-h:h3&gt;WER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
7197
96.9
2.8
0.4
0.9
4.0
27.1



&lt;denchmark-h:h3&gt;CER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
41860
99.3
0.4
0.3
0.4
1.1
27.1



&lt;denchmark-h:h3&gt;TER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
10006
96.7
2.5
0.8
0.5
3.8
27.1



An example of two hypothesis of the same utterance
score: -0.71    hyp: ▁pesquisa▁é▁uma▁coisa▁que▁muda▁toda▁hora
score: -2.58    hyp: ▁pesquisa▁é▁uma▁coisa▁que▁muda▁toda▁a▁hora
which is in fact the ground truth.
when I change to commit &lt;denchmark-link:https://github.com/espnet/espnet/commit/b26563316320f31e21b2ae2f5c6567128ed33db7&gt;b265633&lt;/denchmark-link&gt;
 and I tested some others until &lt;denchmark-link:https://github.com/espnet/espnet/commit/27b1d17b84ff59ac7d854113f7903b4995357a94&gt;27b1d17&lt;/denchmark-link&gt;
, this is what happens
&lt;denchmark-h:h3&gt;WER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
7197
18.9
57.2
23.9
9.2
90.3
99.9



&lt;denchmark-h:h3&gt;CER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
41860
47.4
21.1
31.5
8.5
61.1
99.9



&lt;denchmark-h:h3&gt;TER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
10006
20.7
71.2
8.1
27.7
107.0
99.9



The same first examples. The only thing that changed is the commit version
score: -18.83   hyp: ▁é▁uma▁coisa▁aqutoda
score: -21.01   hyp: ▁é▁uma▁coisa▁que▁mutatoda
and saw that there is a new option to train the conformer model "transformer_encoder_activation_type" and the default is the Swish class. Even if it is not set in the model.json is the default option in  e2e_asr_conformer
"--transformer-encoder-activation-type",
type=str,
default="swish"
Setting manually in model.json, didn't fix it.
However, if I change transformer-encoder-activation-type to "relu"  in model.json, the results using &lt;denchmark-link:https://github.com/espnet/espnet/commit/b26563316320f31e21b2ae2f5c6567128ed33db7&gt;b265633&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/espnet/espnet/commit/27b1d17b84ff59ac7d854113f7903b4995357a94&gt;27b1d17&lt;/denchmark-link&gt;
 are:
&lt;denchmark-h:h3&gt;WER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
7197
95.6
3.5
0.9
0.9
5.3
33.6



&lt;denchmark-h:h3&gt;CER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
41860
98.8
0.6
0.6
0.4
1.6
33.6



&lt;denchmark-h:h3&gt;TER&lt;/denchmark-h&gt;




dataset
Snt
Wrd
Corr
Sub
Del
Ins
Err
S.Err




decode_all_model.last10.avg.best_decode_lm
700
10006
94.9
3.3
1.7
0.4
5.4
33.6



Which doesn't make any sense to me because the default should be another activation function than relu as the original training process and also the results are different than the original.
Basic environments:

python version: 3.7.3 (default, Mar 27 2019, 22:11:17)  [GCC 7.3.0]
espnet version: espnet 0.9.x
pytorch version: pytorch 1.4.0

I'm still trying to figure out if I see some change in the middle of the whole process but didn't find anything. I don't want to train the whole model again right now because it's a very large dataset and it would take a whole week.
Thanks for the amazing work!
	</description>
	<comments>
		<comment id='1' author='alucassch' date='2020-09-21T15:03:42Z'>
		Thanks for your report!
&lt;denchmark-link:https://github.com/pengchengguo&gt;@pengchengguo&lt;/denchmark-link&gt;
, do you know what happened?
		</comment>
		<comment id='2' author='alucassch' date='2020-09-21T15:31:13Z'>
		Hi &lt;denchmark-link:https://github.com/alucassch&gt;@alucassch&lt;/denchmark-link&gt;
,
For the previous implementation (before b265633), we didn't add the --transformer-encoder-activation-type parameter, just directly use Swish() function in CNN modules. Since we want to keep most of the Transformer related code unchanged, the PositionalFeedforward module just supports ReLU() function. So your model was trained based on Swish() function in CNN and ReLU() in PositionalFeedforward.
After trying to apply Swish() to PositionalFeedforward modules, we found further improvement in our experiments. So we add an optional choice to encoder's activation function (after b265633). --transformer-encoder-activation-type='swish' means use Swish for both CNN and PositionalFeedforward, while ='relu' means use ReLU() for both too.
For your case, the best way is to retrain a model and maybe can obtain a little further improvement. Or just fix the activation function to  in PositionalFeedforward (&lt;denchmark-link:https://github.com/espnet/espnet/blob/master/espnet/nets/pytorch_backend/transformer/positionwise_feed_forward.py#L27&gt;https://github.com/espnet/espnet/blob/master/espnet/nets/pytorch_backend/transformer/positionwise_feed_forward.py#L27&lt;/denchmark-link&gt;
, set ) can reproduce your results.
		</comment>
		<comment id='3' author='alucassch' date='2020-09-21T23:03:09Z'>
		Great &lt;denchmark-link:https://github.com/pengchengguo&gt;@pengchengguo&lt;/denchmark-link&gt;
 . I understand now what happened. Got my results back again. Thanks for the explanation. I will retrain a new model to check for improvements.
		</comment>
	</comments>
</bug>