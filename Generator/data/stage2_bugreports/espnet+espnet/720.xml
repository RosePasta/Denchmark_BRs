<bug id='720' author='zz12375' open_date='2019-05-09T13:17:10Z' closed_time='2020-01-15T17:42:01Z'>
	<summary>Decoding with rnnLM badly increases CER/WER when ctc_weight=0</summary>
	<description>
Hi! I am using egs/wsj/asr1/run.sh to train my E2E ASR model. I used the default model architecture and default lsm_weight(0.05) and mtlalpha(0.2). But I noticed a big increase of CER/WER when decoding with word rnnLM and ctc_weight=0. Here is my result on test set eval92:
lm_weight=xxx, ctc_weight=xxx, CER/WER
lm_weight=0.0, ctc_weight=0.0, 5.4/15.9
lm_weight=1.0, ctc_weight=0.3, 2.6/5.7
lm_weight=1.0, ctc_weight=0.0, 33.1/37.1
The first two decoding results seem reasonable, so I think there must be something wrong with the third result. Could you give me some suggests to figure out what happened? Thanks!
I used pytorch_backend (pytorch==1.0.1) and warp_ctc, the rnnLM is word-level, produced by run.sh.
	</description>
	<comments>
		<comment id='1' author='zz12375' date='2019-05-10T16:36:49Z'>
		Can you try a character LM? I just want to know the problem comes from the character/word LM or general shallow fusion issues.
		</comment>
		<comment id='2' author='zz12375' date='2019-05-22T07:10:30Z'>
		Sorry for the late, now I have trained a character LM using the following parameters:
"--use_wordlm false --lm_layers 2 --lm_units 650 --lm_opt adam --lm_batchsize 768 --lm_maxlen 150"
and then test the decoding result on WSJ eval_92, using the current E2E model:
lm_weight=1.0, ctc_weight=0.3, Sub(1.5) Del(1.1) Ins(1.2) Cer(3.8), Wer(9.1)
lm_weight=1.0, ctc_weight=0.0, Sub(2.5) Del(11.6) Ins(8.3) Cer(22.5), Wer(27.8)
Things seem to be similar to the word-level LM setting. What's more, I noticed when decoding with LM and without ctc, the 'Del' and 'Ins' increased much more than 'Sub' (this is also observed in the word-level LM setting, I just didn't detail before).
To give you more information, I also traced the decoding result when using char-level LM without ctc. I got a log file &lt;denchmark-link:https://github.com/espnet/espnet/files/3206063/decode.log&gt;decode.log&lt;/denchmark-link&gt;
. Here is a example:
&lt;denchmark-link:https://user-images.githubusercontent.com/29814033/58153887-d31dc300-7ca2-11e9-895a-e0a63923853b.png&gt;&lt;/denchmark-link&gt;

I guess that the reason of the increase of Cer/Wer may be the "early-stop" of the decoding, that means the incorrect computation of "eos" score.
		</comment>
		<comment id='3' author='zz12375' date='2019-05-22T14:42:40Z'>
		Could you tune --penalty and/or --minlenratio?
You may fix most of these types of errors with --minlenratio 0.2 or 0.3.
		</comment>
		<comment id='4' author='zz12375' date='2019-05-23T11:38:30Z'>
		
Hi! I am using egs/wsj/asr1/run.sh to train my E2E ASR model. I used the default model architecture and default lsm_weight(0.05) and mtlalpha(0.2). But I noticed a big increase of CER/WER when decoding with word rnnLM and ctc_weight=0. Here is my result on test set eval92:
lm_weight=xxx, ctc_weight=xxx, CER/WER
lm_weight=0.0, ctc_weight=0.0, 5.4/15.9
lm_weight=1.0, ctc_weight=0.3, 2.6/5.7
lm_weight=1.0, ctc_weight=0.0, 33.1/37.1
The first two decoding results seem reasonable, so I think there must be something wrong with the third result. Could you give me some suggests to figure out what happened? Thanks!
I used pytorch_backend (pytorch==1.0.1) and warp_ctc, the rnnLM is word-level, produced by run.sh.


Hi! I am using egs/wsj/asr1/run.sh to train my E2E ASR model. I used the default model architecture and default lsm_weight(0.05) and mtlalpha(0.2). But I noticed a big increase of CER/WER when decoding with word rnnLM and ctc_weight=0. Here is my result on test set eval92:
lm_weight=xxx, ctc_weight=xxx, CER/WER
lm_weight=0.0, ctc_weight=0.0, 5.4/15.9
lm_weight=1.0, ctc_weight=0.3, 2.6/5.7
lm_weight=1.0, ctc_weight=0.0, 33.1/37.1
The first two decoding results seem reasonable, so I think there must be something wrong with the third result. Could you give me some suggests to figure out what happened? Thanks!
I used pytorch_backend (pytorch==1.0.1) and warp_ctc, the rnnLM is word-level, produced by run.sh.

In this case, you have applied mtlalpha as 0.2, which denotes ctc has been used during training. Thus, during decoding ctc-weight has to be enabled by default. Disabling ctc-weight by setting it as 0 will result in inefficient decoding.
		</comment>
	</comments>
</bug>