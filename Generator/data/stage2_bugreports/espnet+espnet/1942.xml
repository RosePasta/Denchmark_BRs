<bug id='1942' author='RobotGF' open_date='2020-05-19T08:02:41Z' closed_time='2020-05-24T12:14:03Z'>
	<summary>Got worse result in asr training with specaug</summary>
	<description>
When I used espnet2 to train asr_transformer without specaugï¼ŒI got the comparable result as espnet1. But when add specaug in training, the result got much worse. I only use as default.
Add specaug: specaug in  conf/train_asr_transformer.yaml. Is there some bug in specaug in Espnet2?
	</description>
	<comments>
		<comment id='1' author='RobotGF' date='2020-05-19T08:26:58Z'>
		Oh, thank you.
There might be some bugs, but I can't investigate it for a while now, so would you give more detail?
What corpus, the configuration, the result and the acc/loss graph?
		</comment>
		<comment id='2' author='RobotGF' date='2020-05-19T08:35:35Z'>
		My result were trained with our own corpus. Now I'm trying to reproducing this problem with aishell corpus. I will show my results later
		</comment>
		<comment id='3' author='RobotGF' date='2020-05-22T02:26:05Z'>
		My model was training on aishell. And the model setting is as followed:
`/ssd1/shared/local/anaconda3/bin/python3 /ssd3/exec/gaofei/Projects/espnet-master/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols none --train_data_path_and_name_and_type dump/fbank_pitch/train_sp/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_sp/text,text,text --valid_data_path_and_name_and_type dump/fbank_pitch/dev/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/dev/text,text,text --train_shape_file exp-spec-mean/asr_stats/train/speech_shape --train_shape_file exp-spec-mean/asr_stats/train/text_shape.char --valid_shape_file exp-spec-mean/asr_stats/valid/speech_shape --valid_shape_file exp-spec-mean/asr_stats/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp-spec-mean/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=83 --normalize=global_mvn --normalize_conf stats_file=exp-spec-mean/asr_stats/train/feats_stats.npz --ngpu 8 --multiprocessing_distributed True
[gpu63:0/8] 2020-05-21 16:48:12,886 (abs_task:1327) INFO: [train] dataset:
ESPnetDataset(
speech: {"path": "dump/fbank_pitch/train_sp/feats.scp", "type": "kaldi_ark"}
text: {"path": "dump/fbank_pitch/train_sp/text", "type": "text"}
preprocess: &lt;espnet2.train.preprocessor.CommonPreprocessor object at 0x7f0fe48d6470&gt;)
[gpu63:0/8] 2020-05-21 16:48:12,886 (abs_task:1328) INFO: [train] Batch sampler: FoldedBatchSampler(N-batch=1438, batch_size=256, shape_files=['exp-spec-mean/asr_stats/train/speech_shape', 'exp-spec-mean/asr_stats/train/text_shape.char'], sort_in_batch=descending, sort_batch=descending)
[gpu63:0/8] 2020-05-21 16:48:12,887 (abs_task:1330) INFO: [train] mini-batch sizes summary: N-batch=1438, mean=250.6, min=102, max=256
[gpu63:0/8] 2020-05-21 16:48:14,872 (abs_task:1327) INFO: [valid] dataset:
ESPnetDataset(
speech: {"path": "dump/fbank_pitch/dev/feats.scp", "type": "kaldi_ark"}
text: {"path": "dump/fbank_pitch/dev/text", "type": "text"}
preprocess: &lt;espnet2.train.preprocessor.CommonPreprocessor object at 0x7f0fe48d6b38&gt;)
[gpu63:0/8] 2020-05-21 16:48:14,872 (abs_task:1328) INFO: [valid] Batch sampler: FoldedBatchSampler(N-batch=56, batch_size=256, shape_files=['exp-spec-mean/asr_stats/valid/speech_shape', 'exp-spec-mean/asr_stats/valid/text_shape.char'], sort_in_batch=descending, sort_batch=descending)
[gpu63:0/8] 2020-05-21 16:48:14,872 (abs_task:1330) INFO: [valid] mini-batch sizes summary: N-batch=56, mean=255.8, min=246, max=256
[gpu63:0/8] 2020-05-21 16:48:14,892 (asr:239) INFO: Vocabulary size: 4233
/ssd3/exec/gaofei/Projects/espnet-master/espnet2/schedulers/noam_lr.py:43: UserWarning: NoamLR is deprecated. Use WarmupLR(warmup_steps=25000) with Optimizer(lr=0.003952847075210474)
f"NoamLR is deprecated. "
[gpu63:0/8] 2020-05-21 16:48:23,095 (abs_task:1060) INFO: pytorch.version=1.2.0a0+8554416, cuda.available=True, cudnn.version=7402, cudnn.benchmark=False, cudnn.deterministic=False
[gpu63:0/8] 2020-05-21 16:48:23,100 (abs_task:1061) INFO: Model:
ESPnetASRModel(
(specaug): SpecAug(
(time_warp): TimeWarp(window=5, mode=bicubic)
(freq_mask): MaskAlongAxis(mask_width_range=(0, 30), num_mask=2, axis=freq)
(time_mask): MaskAlongAxis(mask_width_range=(0, 40), num_mask=2, axis=time)
)
(normalize): GlobalMVN(stats_file=exp-spec-mean/asr_stats/train/feats_stats.npz, norm_means=True, norm_vars=True)
(encoder): TransformerEncoder(
(embed): Conv2dSubsampling(
(conv): Sequential(
(0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
(1): ReLU()
(2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
(3): ReLU()
)
(out): Sequential(
(0): Linear(in_features=5120, out_features=256, bias=True)
(1): PositionalEncoding(
(dropout): Dropout(p=0.1, inplace=False)
)
)
)
(encoders): MultiSequential(
(0): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(1): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(2): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(3): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(4): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(5): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(6): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(7): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(8): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(9): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(10): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(11): EncoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
)
(after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
)
(decoder): TransformerDecoder(
(embed): Sequential(
(0): Embedding(4233, 256)
(1): PositionalEncoding(
(dropout): Dropout(p=0.1, inplace=False)
)
)
(decoders): MultiSequential(
(0): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(1): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(2): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(3): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(4): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(5): DecoderLayer(
(self_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(src_attn): MultiHeadedAttention(
(linear_q): Linear(in_features=256, out_features=256, bias=True)
(linear_k): Linear(in_features=256, out_features=256, bias=True)
(linear_v): Linear(in_features=256, out_features=256, bias=True)
(linear_out): Linear(in_features=256, out_features=256, bias=True)
(dropout): Dropout(p=0.0, inplace=False)
)
(feed_forward): PositionwiseFeedForward(
(w_1): Linear(in_features=256, out_features=2048, bias=True)
(w_2): Linear(in_features=2048, out_features=256, bias=True)
(dropout): Dropout(p=0.1, inplace=False)
)
(norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(dropout): Dropout(p=0.1, inplace=False)
)
)
(after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
(output_layer): Linear(in_features=256, out_features=4233, bias=True)
)
(ctc): CTC(
(ctc_lo): Linear(in_features=256, out_features=4233, bias=True)
(ctc_loss): CTCLoss()
)
(criterion_att): LabelSmoothingLoss(
(criterion): KLDivLoss()
)
)
[gpu63:0/8] 2020-05-21 16:48:23,100 (abs_task:1064) INFO: Optimizer:
Adam (
Parameter Group 0
amsgrad: False
betas: (0.9, 0.999)
eps: 1e-08
initial_lr: 10.0
lr: 1.5811388300841896e-07
weight_decay: 0
)'
The training loss is get higher than training without specaug.
And the WER on dev set got worse(from 6.79% to 12.29%)
&lt;denchmark-link:https://camo.githubusercontent.com/3190febefd2040302ca0826e0b27220999e5487e370dad5bece3a76b7db0de0b/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f30303753385a496c6c7931676631306c646a3775336a333068733064636467632e6a7067&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://camo.githubusercontent.com/fd2f4b5cf2cbe369fed89809c988426d55bcf6a80b6c1ad24eac06df6b77d566/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f30303753385a496c6c7931676631306c70776335656a333068733064637439382e6a7067&gt;&lt;/denchmark-link&gt;

Training without Spec
&lt;denchmark-link:https://camo.githubusercontent.com/b7fe0fa08c866a867ce3831d26076bfe1653ba64ea529afcd3dc8c2f6826deab/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f30303753385a496c6c7931676631306d383331616a6a333068733064633074392e6a7067&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://camo.githubusercontent.com/cbb74def4509d2f73b99c5691e38afc8481cc2d1d09b9ab447c563b037241f0f/68747470733a2f2f747661312e73696e61696d672e636e2f6c617267652f30303753385a496c6c7931676631306d71713863376a333068733064636d78702e6a7067&gt;&lt;/denchmark-link&gt;

Training with Spec
&lt;denchmark-link:https://github.com/kamo-naoyuki&gt;@kamo-naoyuki&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='RobotGF' date='2020-05-22T04:44:50Z'>
		Specaug is effective for aishell dataset? The result looks normal. Did you get better result with same setting and espnet1?
		</comment>
		<comment id='5' author='RobotGF' date='2020-05-22T05:29:48Z'>
		
Specaug is effective for aishell dataset? The result looks normal. Did you get better result with same setting and espnet1?

It's not effective for aishell dataset. It's negative for the result. When training with espnet1 on older version, it's effecitive, the wer result is compareble with training without specaug(both 6.x%). But on espnet2 , the wer result came to 12.29%(without specaug 6.x%)
		</comment>
		<comment id='6' author='RobotGF' date='2020-05-22T20:16:03Z'>
		I found that specaug and dropout ( for encoder part ) is applied when inference. Sorry, this is really fatal... and thank you again, I could found this problem by your report. I fixed this problem at &lt;denchmark-link:https://github.com/espnet/espnet/pull/1952&gt;#1952&lt;/denchmark-link&gt;
.
Although there might be still the other bug, could you test it again with the same model for now?
		</comment>
		<comment id='7' author='RobotGF' date='2020-05-24T12:14:03Z'>
		
I found that specaug and dropout ( for encoder part ) is applied when inference. Sorry, this is really fatal... and thank you again, I could found this problem by your report. I fixed this problem at #1952.
Although there might be still the other bug, could you test it again with the same model for now?

I'll test it soon. Thank you
		</comment>
		<comment id='8' author='RobotGF' date='2020-05-25T05:46:13Z'>
		
I found that specaug and dropout ( for encoder part ) is applied when inference. Sorry, this is really fatal... and thank you again, I could found this problem by your report. I fixed this problem at #1952.
Although there might be still the other bug, could you test it again with the same model for now?

The result is reasonable now after add model.eval() in my code. No matter training with or without specaug the wer is right as espnet1. And in my own corpus, adding specaug improve the result.
		</comment>
		<comment id='9' author='RobotGF' date='2020-05-25T09:46:42Z'>
		Good. Thanks.
		</comment>
	</comments>
</bug>