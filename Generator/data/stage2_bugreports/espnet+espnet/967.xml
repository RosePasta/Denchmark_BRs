<bug id='967' author='robothubtokyo' open_date='2019-07-16T15:28:18Z' closed_time='2019-07-17T10:18:50Z'>
	<summary>Feature Generation error (CSJ)</summary>
	<description>
We encountered the following error when trying CSJ's Feature Generation.
Before running the script, we moved the data to HDD in our PC, and changed the line 37(CSJDATATOP=~/hdd_mount/CSJ_corpus).
How can we solve this error?
./run.sh --backend pytorch --ngpu 1 stage 0: Data Preparation Finish processing original CSJ data Warning: expected 986 data files (Case : Using 'Academic lecture' and 'Other' data), found 3272. CSJ data preparation succeeded. utils/fix_data_dir.sh: filtered data/train/segments from 440671 to 417408 lines based on filter /tmp/kaldi.64gy/recordings. utils/fix_data_dir.sh: filtered data/train/wav.scp from 3272 to 3214 lines based on filter /tmp/kaldi.64gy/recordings. fix_data_dir.sh: kept 417408 utterances out of 440671 fix_data_dir.sh: old files are kept in data/train/.backup fix_data_dir.sh: kept all 1272 utterances. fix_data_dir.sh: old files are kept in data/eval1/.backup Completed preparation evaluation set eval1 fix_data_dir.sh: kept all 1292 utterances. fix_data_dir.sh: old files are kept in data/eval2/.backup Completed preparation evaluation set eval2 fix_data_dir.sh: kept all 1385 utterances. fix_data_dir.sh: old files are kept in data/eval3/.backup Completed preparation evaluation set eval3 removed tags, space, and &lt;sp&gt; removed tags, space, and &lt;sp&gt; removed tags, space, and &lt;sp&gt; removed tags, space, and &lt;sp&gt; stage 1: Feature Generation utils/subset_data_dir.sh: reducing #utt from 417408 to 4000 utils/subset_data_dir.sh: reducing #utt from 417408 to 413408 Reduced number of utterances from 413408 to 403096 Using fix_data_dir.sh to reconcile the other files. fix_data_dir.sh: kept 403096 utterances out of 413408 fix_data_dir.sh: old files are kept in data/train_nodup/.backup utils/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train_nodup, in data/temp1 utils/validate_data_dir.sh: Error: in data/temp1, recording-ids extracted from segments and reco2dur file utils/validate_data_dir.sh: differ, partial diff is: --- /tmp/kaldi.PQlb/recordings	2019-07-17 00:15:15.097729018 +0900 +++ /tmp/kaldi.PQlb/recordings.reco2dur	2019-07-17 00:15:15.605705021 +0900 @@ -1,3176 +0,0 @@ -sp0.9-A01M0009 -sp0.9-A01M0013 -sp0.9-A01M0014 ... -sp0.9-S11M1618 -sp0.9-S11M1626 -sp0.9-S11M1640 -sp0.9-S11M1643 -sp0.9-S11M1670 -sp0.9-S11M1689 [Lengths are /tmp/kaldi.PQlb/recordings=3176 versus /tmp/kaldi.PQlb/recordings.reco2dur=0]
	</description>
	<comments>
		<comment id='1' author='robothubtokyo' date='2019-07-16T15:42:14Z'>
		This seems to be a problem in Kaldi. Which version of Kaldi are you using?
		</comment>
		<comment id='2' author='robothubtokyo' date='2019-07-16T16:01:05Z'>
		Thank you for your reply.
We are using 5.5.
		</comment>
		<comment id='3' author='robothubtokyo' date='2019-07-16T22:22:28Z'>
		Probably &lt;denchmark-link:https://groups.google.com/forum/#!topic/kaldi-help/N-Y4QXTHZk4&gt;this&lt;/denchmark-link&gt;
 would help?
		</comment>
		<comment id='4' author='robothubtokyo' date='2019-07-17T09:05:10Z'>
		Thank you.
We found some broken wave files in CSJ corpus.
Removing those, the error didn't appear.
I'm so sorry for bothering you.
		</comment>
	</comments>
</bug>