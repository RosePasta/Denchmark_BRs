<bug id='2037' author='wentaoxandry' open_date='2020-06-13T08:29:35Z' closed_time='2020-08-11T17:33:16Z'>
	<summary>Question about validation</summary>
	<description>
I have a question about espnet validation, I run a ASR code on espnet, if I choose the Batchsize 8, 10, 16, 32, it is all right with validation, but if I choose Batchsize 12, 13 , I got validation report only on even epochs, like this
&lt;denchmark-link:https://user-images.githubusercontent.com/47325204/84564050-67504180-ad60-11ea-92b0-1f70a7f67d91.png&gt;&lt;/denchmark-link&gt;

But at the first epoch, I can still get model.acc.best and at the odd epochs there are still attention plots.
I want to ask will it cause a bad performance? How can I fix that?
Thank you
	</description>
	<comments>
		<comment id='1' author='wentaoxandry' date='2020-06-15T13:07:39Z'>
		This is strange.
How many minibatches do you have?
We might have some if statement issues in the reporter.
		</comment>
		<comment id='2' author='wentaoxandry' date='2020-06-15T13:28:04Z'>
		&lt;denchmark-link:https://github.com/sw005320&gt;@sw005320&lt;/denchmark-link&gt;
  Thank you for your reply.
I haven't change minibatches size, so it sets as default

Actually I use multi gpus, I run programm with 6 gpus, so the batch-size times 6, is that the problem?
Here is my conf file
`
&lt;denchmark-h:h1&gt;encoder related&lt;/denchmark-h&gt;

transformer-input-layer: conv2d
elayers: 12
eunits: 2048
&lt;denchmark-h:h1&gt;decoder related&lt;/denchmark-h&gt;

dlayers: 6
dunits: 2048
&lt;denchmark-h:h1&gt;attention related&lt;/denchmark-h&gt;

adim: 256
aheads: 4
&lt;denchmark-h:h1&gt;transformer related&lt;/denchmark-h&gt;

model-module: "espnet.avsr.e2e_asr_transformer:E2E"
&lt;denchmark-h:h1&gt;hybrid CTC/attention&lt;/denchmark-h&gt;

mtlalpha: 0.3
&lt;denchmark-h:h1&gt;label smoothing&lt;/denchmark-h&gt;

lsm-type: unigram
lsm-weight: 0.1
&lt;denchmark-h:h1&gt;minibatch related&lt;/denchmark-h&gt;

batch-size: 10
maxlen-in: 512  # if input length  &gt; maxlen_in, batchsize is automatically reduced
maxlen-out: 150 # if output length &gt; maxlen_out, batchsize is automatically reduced
&lt;denchmark-h:h1&gt;optimization related&lt;/denchmark-h&gt;

sortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs
opt: noam
epochs: 100
dropout-rate: 0.1
accum-grad: 2
grad-clip: 5
patience: 0
transformer-lr: 1.1
transformer-warmup-steps: 25000
transformer-attn-dropout-rate: 0.0
transformer-length-normalized-loss: False
transformer-init: pytorch`
		</comment>
		<comment id='3' author='wentaoxandry' date='2020-06-15T13:31:20Z'>
		Sorry, my question is about the data size.
How many iterations (# of minibatches) per epoch for each setting?
This might be a clue of what happens inside.
		</comment>
		<comment id='4' author='wentaoxandry' date='2020-06-15T13:45:06Z'>
		If I set Batchsize 10, with multi GPUs, Batch-size turns to 60, it has  5400 iterations per epoch.
If Batchsize is 12, with multi GPUs, it turns to 72, it has 4500 iterations per epoch.
If Batchsize is 14, with multi GPUs, it turns to 84 and it has 3800 iterations per epoch.
		</comment>
		<comment id='5' author='wentaoxandry' date='2020-06-15T20:37:35Z'>
		Thanks, we might have some miscalculation in the multiple GPU cases, and I'm checking &lt;denchmark-link:https://github.com/espnet/espnet/blob/master/espnet/asr/pytorch_backend/asr.py#L700-L704&gt;https://github.com/espnet/espnet/blob/master/espnet/asr/pytorch_backend/asr.py#L700-L704&lt;/denchmark-link&gt;
, but I could not find any reason.
Does the log file (e.g., exp/train_*/results/log) also skip the first epoch result?
		</comment>
		<comment id='6' author='wentaoxandry' date='2020-06-16T06:19:47Z'>
		Yes, the log file will also skip the validation in the first epoch.
&lt;denchmark-code&gt;    {
        "main/loss_ctc": 65.88698414802552,
        "main/loss_att": 67.41240377426148,
        "main/acc": 0.3148509654926277,
        "main/loss": 66.95477811813355,
        "epoch": 0,
        "iteration": 4400,
        "elapsed_time": 14120.765120225959
    },
    {
        "main/loss_ctc": 66.79868741035462,
        "main/loss_att": 69.06077649593354,
        "main/acc": 0.31638951099298823,
        "main/loss": 68.38214993000031,
        "epoch": 1,
        "iteration": 4500,
        "elapsed_time": 14952.44688442722
    },
    {
        "main/loss_ctc": 61.24658613204956,
        "main/loss_att": 61.76517287254333,
        "main/acc": 0.32849703807741876,
        "main/loss": 61.60959687232971,
        "epoch": 1,
        "iteration": 4600,
        "elapsed_time": 15268.524780564941
    },
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='wentaoxandry' date='2020-06-19T21:36:03Z'>
		Sorry for my late response. I was checking the code, but could not find a reason.
Although it does not appear, I think this would not change the performance so seriously.
So, you may proceed with your experiments anyway.
Sorry again.
		</comment>
		<comment id='8' author='wentaoxandry' date='2020-08-11T17:33:15Z'>
		OKï¼Œ thank you :)
		</comment>
	</comments>
</bug>