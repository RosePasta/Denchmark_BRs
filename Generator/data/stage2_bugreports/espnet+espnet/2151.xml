<bug id='2151' author='astikbiswas' open_date='2020-07-04T05:36:55Z' closed_time='2020-12-08T09:56:56Z'>
	<summary>TypeError: 'kenlm.State' object is not subscriptable</summary>
	<description>
Hello All,
I have been trying to follow aishell/asr1/run.sh recipe to implement n-gram scorer using kenlm. Everything went fine. However, I have encountered an error during decoding as given below:
2020-07-03 15:16:48,343 (recog:133) INFO: (1/514) decoding engsot_00002_u00001_engsot
2020-07-03 15:16:48,607 (beam_search:353) INFO: max output length: 54
2020-07-03 15:16:48,607 (beam_search:354) INFO: min output length: 0
Traceback (most recent call last):
File "/espnet/espnet/bin/asr_recog.py", line 311, in 
main(sys.argv[1:])
File "/espnet/espnet/bin/asr_recog.py", line 281, in main
recog_v2(args)
File "/espnet/espnet/asr/pytorch_backend/recog.py", line 138, in recog_v2
x=enc, maxlenratio=args.maxlenratio, minlenratio=args.minlenratio
File "/espnet/tools/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 489, in call
result = self.forward(*input, **kwargs)
File "/espnet/espnet/nets/beam_search.py", line 361, in forward
best = self.search(running_hyps, x)
File "/espnet/espnet/nets/beam_search.py", line 321, in search
states=self.merge_states(states, part_states, part_j),
File "/espnet/espnet/nets/beam_search.py", line 276, in merge_states
new_states[k] = d.select_state(part_states[k], part_idx)
File "/espnet/espnet/nets/scorer_interface.py", line 51, in select_state
return None if state is None else state[i]
TypeError: 'kenlm.State' object is not subscriptable
I did google search but not found any helpful advise. Please advise me how to get rid of that.
The decoding snippet is as per standard format:
${decode_cmd} JOB=1:${nj} ${expdir}/${decode_dir}/log/decode.JOB.log 
asr_recog.py 
--config ${decode_config} 
--ngpu ${ngpu} 
--backend ${backend} 
--batchsize 0 
--recog-json ${feat_recog_dir}/split${nj}utt/data.JOB.json 
--result-label ${expdir}/${decode_dir}/data.JOB.json 
--model ${expdir}/results/${recog_model}  
--rnnlm ${lmexpdir}/rnnlm.model.best 
--ngram-model ${ngramexpdir}/${n_gram}gram.bin 
--api v2
	</description>
	<comments>
		<comment id='1' author='astikbiswas' date='2020-07-06T05:39:01Z'>
		Update: I did encountered this problem only when I choose --ngram-scorer "part". If I set --ngram-scorer "full", it is working fine.
		</comment>
		<comment id='2' author='astikbiswas' date='2020-07-06T13:49:00Z'>
		Thanks for your report (and thanks for testing our new function).
&lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
, could you take a look at this issue?
		</comment>
		<comment id='3' author='astikbiswas' date='2020-07-06T14:08:36Z'>
		yes, I will check it later. Thanks for you feedback &lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='astikbiswas' date='2020-07-07T02:05:24Z'>
		&lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;
 could you test  --ngram-scorer "part" in aishell egs? I tried it in aishell egs with "part" ngram-scorer, it looks fine.
		</comment>
		<comment id='5' author='astikbiswas' date='2020-07-07T04:56:15Z'>
		Thanks for response &lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
. I did ran an experiment with a subset of aishell data using aishell egs recipe and encountered same problem when using default part option. Decoding log is given below:-
asr_recog.py --config conf/decode.yaml --ngpu 0 --backend pytorch --batchsize 0 --recog-json dump/test/deltafalse/split12utt/data.1.json --result-label exp/train_sp_pytorch_train/decode_test_decode_lm_4/data.1.json --model exp/train_sp_pytorch_train/results/model.last10.avg.best --rnnlm exp/train_rnnlm_pytorch_lm/rnnlm.model.best --ngram-model exp/train_ngram/4gram.bin --api v2
2020-07-07 06:43:17,423 (asr_recog:253) INFO: python path = (None)
2020-07-07 06:43:17,423 (asr_recog:258) INFO: set random seed = 1
2020-07-07 06:43:17,423 (asr_recog:269) INFO: backend = pytorch
/espnet/tools/venv/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
from numba.decorators import jit as optional_jit
/espnet/tools/venv/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
from numba.decorators import jit as optional_jit
2020-07-07 06:43:36,734 (recog:34) WARNING: experimental API for custom LMs is selected by --api v2
2020-07-07 06:43:36,748 (deterministic_utils:26) INFO: torch type check is disabled
2020-07-07 06:43:36,748 (asr_utils:478) INFO: reading a config file from exp/train_sp_pytorch_train/results/model.json
2020-07-07 06:43:36,774 (asr_init:169) WARNING: reading model parameters from exp/train_sp_pytorch_train/results/model.last10.avg.best
2020-07-07 06:43:37,215 (encoder:131) INFO: encoder self-attention layer type = self-attention
2020-07-07 06:43:38,040 (decoder:112) INFO: decoder self-attention layer type = self-attention
2020-07-07 06:43:39,541 (asr_utils:478) INFO: reading a config file from exp/train_rnnlm_pytorch_lm/model.json
2020-07-07 06:43:40,408 (recog:123) INFO: Decoding device=cpu, dtype=torch.float32
2020-07-07 06:43:40,490 (recog:133) INFO: (1/598) decoding BAC009S0764W0121
2020-07-07 06:43:41,399 (beam_search:353) INFO: max output length: 103
2020-07-07 06:43:41,399 (beam_search:354) INFO: min output length: 0
Traceback (most recent call last):
File "/espnet/espnet/bin/asr_recog.py", line 311, in 
main(sys.argv[1:])
File "/espnet/espnet/bin/asr_recog.py", line 281, in main
recog_v2(args)
File "/espnet/espnet/asr/pytorch_backend/recog.py", line 138, in recog_v2
x=enc, maxlenratio=args.maxlenratio, minlenratio=args.minlenratio
File "/espnet/tools/venv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 489, in call
result = self.forward(*input, **kwargs)
File "/espnet/espnet/nets/beam_search.py", line 361, in forward
best = self.search(running_hyps, x)
File "/espnet/espnet/nets/beam_search.py", line 321, in search
states=self.merge_states(states, part_states, part_j),
File "/espnet/espnet/nets/beam_search.py", line 276, in merge_states
new_states[k] = d.select_state(part_states[k], part_idx)
File "/espnet/espnet/nets/scorer_interface.py", line 51, in select_state
return None if state is None else state[i]
TypeError: 'kenlm.State' object is not subscriptable
		</comment>
		<comment id='6' author='astikbiswas' date='2020-07-07T07:09:43Z'>
		&lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;
 Could you update to the newest version? It seems already fixed by new ngram batch PR
		</comment>
		<comment id='7' author='astikbiswas' date='2020-07-07T09:18:16Z'>
		My Espnet version is not older than two week. However I will do as per your suggestion. Thanks &lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
 .
		</comment>
		<comment id='8' author='astikbiswas' date='2020-07-28T17:21:05Z'>
		
@astikbiswas Could you update to the newest version? It seems already fixed by new ngram batch PR

Same issue here. Could you please point to that specific PR? Thanks.
		</comment>
		<comment id='9' author='astikbiswas' date='2020-07-29T01:36:13Z'>
		&lt;denchmark-link:https://github.com/tbright17&gt;@tbright17&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/espnet/espnet/pull/2066&gt;#2066&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='astikbiswas' date='2020-08-08T13:52:50Z'>
		I encountered the same problem as you. Have you solved it?
		</comment>
		<comment id='11' author='astikbiswas' date='2020-08-10T10:30:29Z'>
		&lt;denchmark-link:https://github.com/RenJinan&gt;@RenJinan&lt;/denchmark-link&gt;
 if you set --ngram-scorer "full", it should work fine...
		</comment>
		<comment id='12' author='astikbiswas' date='2020-08-10T18:57:52Z'>
		&lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
, do you mean that it still has a problem when ?
		</comment>
		<comment id='13' author='astikbiswas' date='2020-08-11T01:07:16Z'>
		I fix this, after &lt;denchmark-link:https://github.com/espnet/espnet/pull/2066&gt;#2066&lt;/denchmark-link&gt;
 , both work.
		</comment>
		<comment id='14' author='astikbiswas' date='2020-08-11T01:20:07Z'>
		Thanks. I just wanted to confirm it because the same question has been posted several times.
		</comment>
		<comment id='15' author='astikbiswas' date='2020-08-11T02:02:53Z'>
		&lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
  Could you add a unittest for NgramPartScorer?
		</comment>
		<comment id='16' author='astikbiswas' date='2020-08-11T02:26:09Z'>
		Yes, I will, but later.
		</comment>
		<comment id='17' author='astikbiswas' date='2020-08-11T02:54:01Z'>
		&lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;
  hello, I meet the same problem.where is "--ngram-scorer" hyper?
		</comment>
		<comment id='18' author='astikbiswas' date='2020-08-11T05:12:42Z'>
		&lt;denchmark-link:https://github.com/sunnnnnnnny&gt;@sunnnnnnnny&lt;/denchmark-link&gt;
 please find the snippet:-
  asr_recog.py \ --config ${decode_config} \ --ngpu ${ngpu} \ --backend ${backend} \ --batchsize 0 \ --recog-json ${feat_recog_dir}/split${nj}utt/data.JOB.json \ --result-label ${expdir}/${decode_dir}/data.JOB.json \ --model ${expdir}/results/${recog_model}  \ --rnnlm ${lmexpdir}/rnnlm.model.best \ --ngram-model ${ngramexpdir}/${n_gram}gram.bin \ --ngram-scorer "full" \ --api v2
		</comment>
		<comment id='19' author='astikbiswas' date='2020-08-11T06:09:05Z'>
		same problem with "--ngram-scorer part" . It works fine using "--ngram-scorer full" , but decoding is slower.
		</comment>
		<comment id='20' author='astikbiswas' date='2020-08-11T08:13:57Z'>
		&lt;denchmark-link:https://github.com/astikbiswas&gt;@astikbiswas&lt;/denchmark-link&gt;
  ok,thank you. I see it, i set  solve it ,Hhhhhh.
		</comment>
		<comment id='21' author='astikbiswas' date='2020-08-11T08:45:47Z'>
		Hello,

making ngram scorer weight to 0, does not have any effect on n-gram on the
final output.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, 11 Aug, 2020, 1:44 pm sunnnnnnnny, ***@***.***&gt; wrote:
 @astikbiswas &lt;https://github.com/astikbiswas&gt; ok,thank you. I see it, i
 set ngram-weight =0.0 solve it ,Hhhhhh.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#2151 (comment)&gt;, or
 unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/APFRJLKWYI5JPZOSYATQPQTSAD4VJANCNFSM4OQHZ4FA&gt;
 .



		</comment>
		<comment id='22' author='astikbiswas' date='2020-08-13T01:24:55Z'>
		WIP, I found it indeed exists.
		</comment>
		<comment id='23' author='astikbiswas' date='2020-08-18T08:28:14Z'>
		add
def select_state(self, state, i):
return state
in "ngram.py" solves this problem.
Is this right?
		</comment>
		<comment id='24' author='astikbiswas' date='2020-08-18T08:31:13Z'>
		&lt;denchmark-link:https://github.com/cosmo1995&gt;@cosmo1995&lt;/denchmark-link&gt;
 yes
as &lt;denchmark-link:https://github.com/espnet/espnet/pull/2299&gt;#2299&lt;/denchmark-link&gt;

		</comment>
		<comment id='25' author='astikbiswas' date='2020-08-18T08:34:42Z'>
		OK, that's fine. I did not see that before.
		</comment>
	</comments>
</bug>