<bug id='1974' author='Cescfangs' open_date='2020-05-27T02:14:32Z' closed_time='2020-06-06T23:00:06Z'>
	<summary>ngram scorer issues</summary>
	<description>
Please correct me if I'm wrong, I think we're scoring p(yn|y0~yn-1) here, however following code score p(y0~yn) actually:



espnet/espnet/nets/scorers/ngram.py


        Lines 56 to 61
      in
      263e3c6






 scores = torch.full(next_token.size(), state[0]) 



 for i, j in enumerate(next_token): 



 scores[i] += self.lm.BaseScore( 



 out_state, self.chardict[j], self.tmpkenlmstate 



     ) 



 return scores, [state[0], out_state] 





I suggest:
        for i, j in enumerate(next_token):
            scores[i] = self.lm.BaseScore(
                out_state, self.chardict[j], self.tmpkenlmstate
            )
and below is my decoding result with Aishell(the model was trained with other mandarin dataset, and the ngram lm was trained with much larger corpus):



Aishell test
CER
weight




baseline
6.8%
0


+ngram part scorer(origin)
7.2%
0.1


+ngram part scorer(my suggestion)
6.3%
0.1


+ngram part scorer(my suggestion)
5.6%
0.3


+ngram part scorer(my suggestion)
5.1%
0.5


+ngram part scorer(my suggestion)
4.7%
0.7


+ngram part scorer(my suggestion)
4.4%
0.9



Another issue is the NgramFullScorer, which is too slow for large vocab like chinese:



espnet/espnet/asr/pytorch_backend/recog.py


        Lines 68 to 71
      in
      263e3c6






 if args.ngram_model: 



 from espnet.nets.pytorch_backend.scorers.ngram import NgramFullScorer 



 



 ngram = NgramFullScorer(args.ngram_model, train_args.char_list) 





here is my results:



20 utt
decoding time




baseline
280 s


+full scorer
975 s


+part scorer
358 s



So I would like to suggest using ngram part scorer for decoding:
if args.ngram_model:
    from espnet.nets.pytorch_backend.scorers.ngram import NgramPartScorer 
 
    ngram = NgramPartScorer(args.ngram_model, train_args.char_list) 
	</description>
	<comments>
		<comment id='1' author='Cescfangs' date='2020-05-27T12:22:16Z'>
		Wow!
This is super cool.
Thanks for pointing out.
&lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
, could you fix it accordingly?
&lt;denchmark-link:https://github.com/espnet/espnet/pull/1946&gt;#1946&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='Cescfangs' date='2020-05-28T04:10:50Z'>
		&lt;denchmark-link:https://github.com/Cescfangs&gt;@Cescfangs&lt;/denchmark-link&gt;

and for the first point, my personal understanding is, the last decoding already decoded the score p
I read the example in &lt;denchmark-link:https://github.com/kpu/kenlm/blob/87e85e66c99ceff1fab2500a7c60c01da7315eec/python/example.py#L37-L38&gt;https://github.com/kpu/kenlm/blob/87e85e66c99ceff1fab2500a7c60c01da7315eec/python/example.py#L37-L38&lt;/denchmark-link&gt;

For example, currently, if the ngram would be score p(y_{n}|y_{0}~y{n-1}), which could be augmented as p(y_{n}|y_{0}~y{n-1})=p(y_{n}|y_{n-1})*p(y_{n-1}|y_{0}~y{n-2}), and this p(y_{n-1}|y_{0}~y{n-2}) could be getted from the last decoding named state[1].
But I think your suggestion looks like 1 gram. The result loos better might since the testset in aishell is quite short.
yes, I already implement the NgramPartScorer as an option in recog.py
&lt;denchmark-link:https://github.com/qmpzzpmq/espnet/blob/627926b54ac2c134c7bc8517855689e66bd766e5/espnet/bin/asr_recog.py#L177-L183&gt;https://github.com/qmpzzpmq/espnet/blob/627926b54ac2c134c7bc8517855689e66bd766e5/espnet/bin/asr_recog.py#L177-L183&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='Cescfangs' date='2020-05-28T06:20:36Z'>
		
@Cescfangs
and for the first point, my personal understanding is, the last decoding already decoded the score p
I read the example in https://github.com/kpu/kenlm/blob/87e85e66c99ceff1fab2500a7c60c01da7315eec/python/example.py#L37-L38
For example, currently, if the ngram would be score p(y_{n}|y_{0}~y{n-1}), which could be augmented as p(y_{n}|y_{0}~y{n-1})=p(y_{n}|y_{n-1})*p(y_{n-1}|y_{0}~y{n-2}), and this p(y_{n-1}|y_{0}~y{n-2}) could be getted from the last decoding named state[1].
But I think your suggestion looks like 1 gram. The result loos better might since the testset in aishell is quite short.
yes, I already implement the NgramPartScorer as an option in recog.py
https://github.com/qmpzzpmq/espnet/blob/627926b54ac2c134c7bc8517855689e66bd766e5/espnet/bin/asr_recog.py#L177-L183

Thanks for the explanation, first of all, I tested several datasets including long conversations, the conclusions were quite similar.
I agree the state[1] represents p(yn-1|y0...yn-2), but I think you made a mistake about , it's actually a incremental scoring method, which means it scores p(yn|y0...yn-1) instead of p(yn|yn-1)(state make this happen).
The example in kenlm verified my opinion indeed, if  is scoring p(yn|yn-1) how could the accumulated one equals the sentence score?
here is a small experiment about :
&lt;denchmark-link:https://user-images.githubusercontent.com/11382612/83106993-05e96b00-a0f0-11ea-9815-b5dfdc3e65fd.PNG&gt;&lt;/denchmark-link&gt;

as you can see the scores are different because of the context
		</comment>
		<comment id='4' author='Cescfangs' date='2020-05-28T07:01:24Z'>
		I don't understand you mean of "verified".
Since in the example &lt;denchmark-link:https://github.com/kpu/kenlm/blob/87e85e66c99ceff1fab2500a7c60c01da7315eec/python/example.py#L41&gt;https://github.com/kpu/kenlm/blob/87e85e66c99ceff1fab2500a7c60c01da7315eec/python/example.py#L41&lt;/denchmark-link&gt;

the score of '
		</comment>
		<comment id='5' author='Cescfangs' date='2020-05-28T07:08:13Z'>
		&lt;denchmark-link:https://github.com/Cescfangs&gt;@Cescfangs&lt;/denchmark-link&gt;

p()=p(银行|
		</comment>
		<comment id='6' author='Cescfangs' date='2020-05-28T07:12:23Z'>
		&lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
 thanks for the replay, I re-checked about the , and I think you're right about the ngram state:
model.BaseScore(state2, '我', state)
model.BaseScore(state, '是', state2)
model.BaseScore(state2, '我', state)
model.BaseScore(state, '是', state2)
model.BaseScore(state2, '我', state)
model.BaseScore(state, '是', state2)
model.BaseScore(state2, '我', state)
model.BaseScore(state, '是', state2)

 -0.58933...
So it's actually a ngram incremental scoring method, context holds within ngram indeed.
		</comment>
		<comment id='7' author='Cescfangs' date='2020-05-28T07:36:44Z'>
		&lt;denchmark-link:https://github.com/qmpzzpmq&gt;@qmpzzpmq&lt;/denchmark-link&gt;
 Ok, I made a mistake, for RNNLM, we're scoring p(yn|y0...yn-1), but for ngram lm, we are scoring p(yn|yn-3,yn-2,yn-1), right? If so I think we don't need to accumulate ngram scores either, it's the limitation of ngram lm, but I think this is how it works.
		</comment>
		<comment id='8' author='Cescfangs' date='2020-05-28T07:55:29Z'>
		&lt;denchmark-link:https://github.com/Cescfangs&gt;@Cescfangs&lt;/denchmark-link&gt;
. I will talk with &lt;denchmark-link:https://github.com/sw005320&gt;@sw005320&lt;/denchmark-link&gt;
 later to choose an appropriate one, big thanks for your result.
		</comment>
	</comments>
</bug>