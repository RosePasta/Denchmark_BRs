<bug id='1948' author='yuexianghubit' open_date='2020-05-21T04:43:28Z' closed_time='2020-06-06T23:02:13Z'>
	<summary>Transformer input layer type error</summary>
	<description>
Hello there,
When I specify the transformer input layer as 'embed', it will occur problem:
RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)
I think it's due to that the type of the input tensor mismatched the type of input of torch.nn.Embedding.
Hope you guys to fix this error.
Thanks
	</description>
	<comments>
		<comment id='1' author='yuexianghubit' date='2020-05-21T15:45:08Z'>
		Are you talking about 


espnet/espnet2/asr/encoder/transformer_encoder.py


         Line 83
      in
      536d163






 elif input_layer == "embed": 




?
Did you use it for your speech feature input?
This is intended for a one-hot representation like test input.
		</comment>
		<comment id='2' author='yuexianghubit' date='2020-05-22T04:34:59Z'>
		Oh, got it. Thanks!
I was trying to use it for speech feature input.
		</comment>
	</comments>
</bug>