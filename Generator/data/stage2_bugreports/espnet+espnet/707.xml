<bug id='707' author='gruly' open_date='2019-04-27T08:57:08Z' closed_time='2020-05-16T08:21:33Z'>
	<summary>Missing file in iwslt18st recipe</summary>
	<description>
Line 106 in run.sh from egs/iwslt18st/st1/:
local/data_prep_train.sh ${datadir}
--&gt; data_prep_train.sh is missing in local/ directory
	</description>
	<comments>
		<comment id='1' author='gruly' date='2019-05-01T02:08:53Z'>
		&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
, can you upload this?
		</comment>
		<comment id='2' author='gruly' date='2019-05-08T22:53:21Z'>
		I switched to branch iwslt18st then i found the working recipe
&lt;denchmark-link:url&gt;https://github.com/espnet/espnet/tree/iwslt18/egs/iwslt18st/st1/local&lt;/denchmark-link&gt;

However, at stage 4 - Network Training, the training process always be idle after training some epochs without reporting any error.
		</comment>
		<comment id='3' author='gruly' date='2019-05-10T16:32:40Z'>
		&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
, could you answer it?
		</comment>
		<comment id='4' author='gruly' date='2019-05-11T12:15:30Z'>
		Can you please upload the file local/data_prep_train.sh
		</comment>
		<comment id='5' author='gruly' date='2019-05-12T12:45:02Z'>
		&lt;denchmark-link:https://github.com/gruly&gt;@gruly&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bravewolf&gt;@bravewolf&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/adarshjaju&gt;@adarshjaju&lt;/denchmark-link&gt;

Very sorry for the late reply.
I already have the correct files in the local repo.
I will soon complete this issue after PR &lt;denchmark-link:https://github.com/espnet/espnet/pull/563&gt;#563&lt;/denchmark-link&gt;
 because there are some conflicts between them.
		</comment>
		<comment id='6' author='gruly' date='2019-05-12T21:42:23Z'>
		There are several other files that are missing:
local/parse_xml.py
local/remove_punctuation.pl
local/ctm2segments.py
		</comment>
		<comment id='7' author='gruly' date='2019-05-22T09:56:06Z'>
		Can you please update on the issue?
		</comment>
		<comment id='8' author='gruly' date='2019-05-22T11:16:30Z'>
		&lt;denchmark-link:https://github.com/adarshjaju&gt;@adarshjaju&lt;/denchmark-link&gt;

OK. I'm back on this.
		</comment>
		<comment id='9' author='gruly' date='2019-06-03T09:52:24Z'>
		Thank you for making the changes.
The updated code for IWSLT18 ST runs without any errors. But in the last phase of stage 2: Dictionary and JSON Data Preparation, the JSON files are updated, and it contains target sequences for both the languages. But in the training phase,  in the Custom batch converter function, LoadInputsAndTargets utility is called with 'ASR' mode, which returns the batch only with the one target sequence and the second target sequence is ignored. There you have also mentioned that the option (second target) is only used for 'tts' mode. Then why are you updating the JSON file in stage 2? ( my doubt is where exactly the second target sequence is used while training the ST model)
		</comment>
		<comment id='10' author='gruly' date='2019-06-04T11:09:03Z'>
		&lt;denchmark-link:https://github.com/adarshjaju&gt;@adarshjaju&lt;/denchmark-link&gt;

I prepared 2nd target references for multi-task learning. I just used it for my internal experiments.
I'll make it option for v.0.4.0 branch. Thank you for letting me know.
I recommend you to follow v.0.4.0 branch if you want to do it ASAP.
		</comment>
		<comment id='11' author='gruly' date='2019-06-04T14:51:22Z'>
		In the iwslt18 st1 recipe:
by default the $set variable of the local/data_prep_eval.sh is defined as the second argument ${part} in line 127 of the run.sh script:
126     for part in dev2010 tst2010 tst2013 tst2014 tst2015; do
127         local/data_prep_eval.sh ${st_ted} ${part}
128     done
Then, in local/data_prep_eval.sh, line 26, there is:
26     yml=$src/test-db.yaml
Last, the yml variable will be used in line 138 to make segment files.
But test-db.yaml files do not exist in the downloaded data.
To create these files, it seems that we must uncomment the lines 120 to 130 that use the LIUM speaker diarization tool:
120 # (1b) Segmente audio file with LIUM diarization tool
121 # if [ $set != tst2018 ]; then
122 #     echo "" &gt; $src/test-db.yaml
123 #     for f in cat $src/FILE_ORDER; do
124 #         java -jar ../../../tools/lium_spkdiarization-8.4.1.jar --fInputSpeechThr=0.0 --fInputMask=$wav_dir/$f.wav --sOutputMask=$wa    v_dir/$f.seg $f --saveAllStep
125 #         # using *.s.seg for now, we live with possibly bad segmentation instead of throwing away to much stuff
126 #         # also sort by start offset of utterance
127 #         cat $wav_dir/$f.s.seg | grep --invert-match ";;" | sort -n -k3 | awk '{print "- {"wav": "PATH/wavs/" $1 ".wav", "offse    t":" $3/100 ", "duration":" ($4)/100 "}"}' &gt;&gt; $src/test-db.yaml
128 #     done
129 #     sed -i 's\PATH'$src'\g' $src/test-db.yaml
130 # fi
131 # NOTE: audio segmentaion and golden transcripts don't match here
132 # After finishing the training stage, hyp and ref are aligned by a RWTH tool
133
The problem is that without uncommenting lines 120-130, the recipe cannot work.
But why are they commented? Any reason?
In addition, by uncommenting these lines, we need to install a tool (LIUM_SpkDiarization) that is not listed in the ESP.net requirements. (LIUM_SpkDiarization is a Java tool easy to install).
		</comment>
		<comment id='12' author='gruly' date='2019-06-04T21:21:50Z'>
		Thanks, &lt;denchmark-link:https://github.com/gruly&gt;@gruly&lt;/denchmark-link&gt;
 for pointing out the issue. I just checked that these yaml files are not so large and I'm fine for either option of creating them from LIUM_SpkDiarization or uploading these files in the local directory as a part of recipe.
&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
. do you have comments?
&lt;denchmark-code&gt;$ ls -hl /export/b08/inaguma/IWSLT/*/IWSLT*/test-db.yaml
-rw-r--r-- 1 ws18hinag fax 119K Oct  2  2018 /export/b08/inaguma/IWSLT/dev2010/IWSLT.dev2010/test-db.yaml
-rw-r--r-- 1 ws18hinag fax 202K Sep 20  2018 /export/b08/inaguma/IWSLT/tst2010/IWSLT.tst2010/test-db.yaml
-rw-r--r-- 1 ws18hinag fax 152K Sep 20  2018 /export/b08/inaguma/IWSLT/tst2013/IWSLT.tst2013/test-db.yaml
-rw-r--r-- 1 ws18hinag fax 173K Sep 20  2018 /export/b08/inaguma/IWSLT/tst2014/IWSLT.tst2014/test-db.yaml
-rw-r--r-- 1 ws18hinag fax 169K Sep 20  2018 /export/b08/inaguma/IWSLT/tst2015/IWSLT.tst2015/test-db.yaml
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='gruly' date='2019-06-05T00:15:30Z'>
		&lt;denchmark-link:https://github.com/sw005320&gt;@sw005320&lt;/denchmark-link&gt;
 Can I upload them? LIUM_SpkDiarization is not perfect, so it's possible to enhance segmentation using better VAD (will be implemented in future ESPnet?).
I mean we can update them by overwriting segmentation files in .
		</comment>
		<comment id='14' author='gruly' date='2019-06-05T12:52:49Z'>
		&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
, in , I found the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/export/a08/shinji/201707e2e/espnet_iwslt18/egs/iwslt18/asr1/../../../espnet/bin/asr_recog.py", line 140, in &lt;module&gt;
    main(sys.argv[1:])
  File "/export/a08/shinji/201707e2e/espnet_iwslt18/egs/iwslt18/asr1/../../../espnet/bin/asr_recog.py", line 128, in main
    recog(args)
  File "/export/a08/shinji/201707e2e/espnet_iwslt18/espnet/asr/pytorch_backend/asr.py", line 505, in recog
    new_js[name] = add_results_to_json(js[name], nbest_hyps, train_args.char_list)
  File "/export/a08/shinji/201707e2e/espnet_iwslt18/espnet/asr/asr_utils.py", line 470, in add_results_to_json
    out_dic = dict(js['output'][0].items())
&lt;/denchmark-code&gt;

It seems that  does not include the output text for dev2010.en tst2010.en tst2013.en tst2014.en tst2015.en, which may be come from &lt;denchmark-link:https://github.com/espnet/espnet/blob/master/egs/iwslt18/asr1/run.sh#L280-L283&gt;https://github.com/espnet/espnet/blob/master/egs/iwslt18/asr1/run.sh#L280-L283&lt;/denchmark-link&gt;

Can you fix it?
		</comment>
		<comment id='15' author='gruly' date='2019-06-06T09:42:36Z'>
		dev2010.en and tst*.en should not include any outputs becasue there is no reference per utterance.
So that is the correct observation. Instead i will fix the recognition part.
		</comment>
		<comment id='16' author='gruly' date='2019-06-06T09:44:02Z'>
		oh I see.
thanks for the clarification!
		</comment>
		<comment id='17' author='gruly' date='2019-06-06T11:31:38Z'>
		
@sw005320 Can I upload them? LIUM_SpkDiarization is not perfect, so it's possible to enhance segmentation using better VAD (will be implemented in future ESPnet?).
I mean we can update them by overwriting segmentation files in local.

&lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
 My opinion is that you could indeed consider these test-db.yaml files as a part of the recipe (as suggested by &lt;denchmark-link:https://github.com/sw005320&gt;@sw005320&lt;/denchmark-link&gt;
) and upload them. And write an information about this somewhere in the recipe, maybe simply as a comment.
		</comment>
		<comment id='18' author='gruly' date='2019-06-06T11:39:43Z'>
		&lt;denchmark-link:https://github.com/gruly&gt;@gruly&lt;/denchmark-link&gt;
 Yes. Please follow &lt;denchmark-link:https://github.com/espnet/espnet/pull/808&gt;#808&lt;/denchmark-link&gt;
. You can check how to obtain test-db.yaml.
Another option is to upload other types of segmentation files (time information) then modify scripts in .
Do you have segmentation files in your local environments? And is it possible to upload them Google Drive if you have?
		</comment>
		<comment id='19' author='gruly' date='2019-06-06T11:49:43Z'>
		Thank you &lt;denchmark-link:https://github.com/hirofumi0810&gt;@hirofumi0810&lt;/denchmark-link&gt;
.
I have segmentation files provided by IWSLT18 organizers last year: &lt;denchmark-link:https://sites.google.com/site/iwsltevaluation2018/Lectures-task&gt;https://sites.google.com/site/iwsltevaluation2018/Lectures-task&lt;/denchmark-link&gt;

I can share if you are interested. They also were computed with LIUM_SpkDiarization (by organizers)
		</comment>
		<comment id='20' author='gruly' date='2019-06-06T12:02:36Z'>
		&lt;denchmark-link:https://github.com/gruly&gt;@gruly&lt;/denchmark-link&gt;
 Accutually I was a participant of IWSLT2018.
But their segmentation files were very noisy, which was a crucial problem for evaluation.
Almost all participants implemented their own VAD to obtain better segmentation.
		</comment>
		<comment id='21' author='gruly' date='2019-06-06T12:05:18Z'>
		OK. So, I do not have other files.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 Le 6 juin 2019 à 14:02, Hirofumi Inaguma ***@***.***&gt; a écrit :

 @gruly &lt;https://github.com/gruly&gt; Accutually I was a participant of IWSLT2018.
 But their segmentation files were very noisy, which was a crucial problem for evaluation.
 Almost all participants implemented their own VAD to obtain better segmentation.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub &lt;#707?email_source=notifications&amp;email_token=AACDYC5ETIDFBUGATDUBV6DPZD4GFA5CNFSM4HI3ZJM2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXCT3LY#issuecomment-499465647&gt;, or mute the thread &lt;https://github.com/notifications/unsubscribe-auth/AACDYCYUB2H27PZEGUBTHTDPZD4GFANCNFSM4HI3ZJMQ&gt;.



		</comment>
	</comments>
</bug>