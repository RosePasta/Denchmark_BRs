<bug id='1361' author='danoneata' open_date='2019-11-15T20:13:09Z' closed_time='2020-05-15T10:00:08Z'>
	<summary>join_suffix.py script might affect BPE units in TED-LIUM 2 recipe</summary>
	<description>
Hello! When running the TED-LIUM recipe egs/tedlium2/asr1 I have some problems with the BPE model. Namely, among the units from data/lang_char/train_trim_sp_unigram500_units.txt I see tokens such as
&lt;denchmark-code&gt;FARTHERTHANTHESUN_2005-0022785-0022859 8
_1990-0059139-0059166 15
_1998-0065813-0065847 16
_2007-0021335-0021365 17
_2010-0114108-0114304 18
_2010G-0026501-0026536 19
&lt;/denchmark-code&gt;

which are obviously parts of the segment ids. Am I the only one experiencing this problem?
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

I did some debugging and the error traceback looks something along these lines:

The file data/train_trim_sp/text contains lines with no text, but only the segment id; the cut -f 2 -d " " command will return just the segment id in this, as it doesn't find the delimiter:

&lt;denchmark-code&gt;CarolineLavelleFARTHERTHANTHESUN_2005-0022785-0022859
&lt;/denchmark-code&gt;


The empty lines appear because in the data/train.orig/stm there is missing a space between the gender information &lt;o,f0,female&gt; and the text 's:

&lt;denchmark-code&gt;CarolineLavelleFARTHERTHANTHESUN_2005 A CarolineLavelleFARTHERTHANTHESUN_2005 227.85 228.59 &lt;o,f0,female&gt;'s
&lt;/denchmark-code&gt;


The missing space is caused by the local/join_suffix.py script which joins a word starting with an apostrophe to the previous one.

	</description>
	<comments>
		<comment id='1' author='danoneata' date='2019-11-18T23:50:09Z'>
		
I did some debugging and the error traceback looks something along these lines:

The file data/train_trim_sp/text contains lines with no text, but only the segment id; the cut -f 2 -d " " command will return just the segment id in this, as it doesn't find the delimiter:

CarolineLavelleFARTHERTHANTHESUN_2005-0022785-0022859


I don't know why it happens, as the Kaldi text format is like that
&lt;denchmark-code&gt;&lt;UTT ID&gt; &lt;word1&gt; &lt;word2&gt; ...
&lt;/denchmark-code&gt;

and cut -f 2- -d" " data/${train_set}/text  should extract &lt;word1&gt; &lt;word2&gt; .... Or do you mean to say that the generated text is not like the above?
		</comment>
		<comment id='2' author='danoneata' date='2019-11-19T08:46:42Z'>
		That is indeed the text format, but for some lines there is only &lt;UTT ID&gt; and no words; for example:
&lt;denchmark-code&gt;CarolineLavelleFARTHERTHANTHESUN_2005-0015816-0015843 you
CarolineLavelleFARTHERTHANTHESUN_2005-0022254-0022348 you
CarolineLavelleFARTHERTHANTHESUN_2005-0022785-0022859
&lt;/denchmark-code&gt;

Running the cut -f 2- -d" " command on these lines yields:
&lt;denchmark-code&gt;you
you
CarolineLavelleFARTHERTHANTHESUN_2005-0022785-0022859
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='danoneata' date='2019-11-19T13:04:22Z'>
		Oh, I got it.
If you add the option in remove_longshortdata.sh --minchars 1 in
&lt;denchmark-code&gt;https://github.com/espnet/espnet/blob/master/egs/tedlium2/asr1/run.sh#L86-L87
&lt;/denchmark-code&gt;

Then, it must be OK.
I think we need to change the default value of minchars=1 in remove_longshortdata.sh.
		</comment>
		<comment id='4' author='danoneata' date='2019-11-19T14:39:39Z'>
		Thanks! Yes, that's one possible solution. Another one would be to add the -s flag to the cut command â€“ this would filter out the lines that do not contain the delimiter. However, I believe the root cause is related to the way in which join_suffix.py interacts with the STM files; but fixing this will require a bit more work and care.
I have realized that the same problem also occurs in the original Kaldi recipe, but the effect there is not as obvious, as they use the text data only to evaluate the language model.
		</comment>
	</comments>
</bug>