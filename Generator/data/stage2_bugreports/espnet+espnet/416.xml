<bug id='416' author='ruizhilijhu' open_date='2018-09-20T02:22:54Z' closed_time='2020-05-15T09:57:44Z'>
	<summary>Issue when lm_weight=0</summary>
	<description>
I have run wsj script with wordLM.  I just used attention model without CTC. Without wordlm, the results looked reasonable. But when I use wordLM with lm_weight=0,0.5,1; the results are higher which are unexpected. Using the same LM on model trained with CTC, it worked fine.
Also, "no wordLM" should have the same results as "wordlm=0". Anyone experienced the similar issue before?



 
Dev
Dev
Eval
Eval




 
CER
WER
CER
WER


no wordlm
7.8
19.4
6
15.4


wordlm 0
17
27.8
15.5
24.3


wordlm 0.5
18.6
24
18.9
22.6


wordlm 1
33.5
37.3
33.2
35.5



	</description>
	<comments>
		<comment id='1' author='ruizhilijhu' date='2018-09-20T05:49:46Z'>
		I am also facing the se issue man..
On Thu, 20 Sep 2018 at 04:22, ruizhilijhu ***@***.***&gt; wrote:
 I have run wsj script with wordLM. I just used attention model without
 CTC. Without wordlm, the results looked reasonable. But when I use wordLM
 with lm_weight=0,0.5,1; the results are higher which are unexpected. Using
 the same LM on model trained with CTC, it worked fine.

 Also, "no wordLM" should have the same results as "wordlm=0". Anyone
 experienced the similar issue before?
   Dev Dev Eval Eval
   CER WER CER WER
 no wordlm 7.8 19.4 6 15.4
 wordlm 0 17 27.8 15.5 24.3
 wordlm 0.5 18.6 24 18.9 22.6
 wordlm 1 33.5 37.3 33.2 35.5

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;&lt;denchmark-link:https://github.com/espnet/espnet/issues/416&gt;#416&lt;/denchmark-link&gt;
&gt;, or mute the thread
 &lt;&lt;denchmark-link:https://github.com/notifications/unsubscribe-auth/AHJUVfHSxRogHYOUT8-SHAAzdOyOjFbHks5ucvwAgaJpZM4WxRKl&gt;https://github.com/notifications/unsubscribe-auth/AHJUVfHSxRogHYOUT8-SHAAzdOyOjFbHks5ucvwAgaJpZM4WxRKl&lt;/denchmark-link&gt;
&gt;
 .

-- 
Peace,
Murali Karthick Baskar
		</comment>
		<comment id='2' author='ruizhilijhu' date='2018-09-20T17:33:42Z'>
		&lt;denchmark-link:https://github.com/ruizhilijhu&gt;@ruizhilijhu&lt;/denchmark-link&gt;
, thanks for your report.
Can you give us the number of insertion, deletion, and substitution errors as well?
I just want to know whether it comes from a search issue.
&lt;denchmark-link:https://github.com/takaaki-hori&gt;@takaaki-hori&lt;/denchmark-link&gt;
, could you check this behavior?
		</comment>
		<comment id='3' author='ruizhilijhu' date='2018-09-24T16:12:51Z'>
		DEV CER:



 
Corr
Sub
Del
Ins
Err
S.Err




No wordlm
93.7
3.1
3.2
1.6
7.8
88.5


wordlm 0
84.4
2.8
12.8
1.4
17
90.1


wordlm 0.5
82.6
1.9
15.5
1.3
18.6
81.3


wordlm 1
69
2.3
28.7
2.5
33.5
88.5



DEV WER:



 
Corr
Sub
Del
Ins
Err
S.Err




No wordlm
82.9
14.7
2.4
2.3
19.4
87.1


wordlm 0
74.4
14.3
11.3
2.2
27.8
88.7


wordlm 0.5
77.7
7.7
14.6
1.6
24
77.7


wordlm 1
65.5
7.2
27.4
2.8
37.3
86.1



		</comment>
		<comment id='4' author='ruizhilijhu' date='2018-09-24T17:53:28Z'>
		Thanks. This looks like that it only increases the deletion. Anyway, &lt;denchmark-link:https://github.com/takaaki-hori&gt;@takaaki-hori&lt;/denchmark-link&gt;
 is checking this.
		</comment>
		<comment id='5' author='ruizhilijhu' date='2018-09-24T19:16:58Z'>
		FYI, it looks like if I train a model with only attention (no ctc), this problem exists.
		</comment>
		<comment id='6' author='ruizhilijhu' date='2018-09-27T20:25:40Z'>
		I found that this bug came from -inf that appears when computing word LM probabilities due to log(0) or division by zero. But with CTC, this does not happen (I am not sure why).
Actually, -inf * 0.0 = nan, so even if we set lm_weight=0, it still affects decoding. I already fixed this bug and will PR soon.
Note that, even with the fixed version, lm_weight needs to be small (e.g. 0.2) when we don't use CTC for decoding. Otherwise the WER will be around 30% in WSJ.
		</comment>
	</comments>
</bug>