<bug id='404' author='sameerkhurana10' open_date='2018-09-01T20:28:56Z' closed_time='2019-10-10T04:25:28Z'>
	<summary>ASR training hangs in epoch 0, after few iterations</summary>
	<description>
Hi,
using
Espnet commit: &lt;denchmark-link:https://github.com/espnet/espnet/commit/18ed8b0d76ae4bb32ce901152fdb35d1fc7484e4&gt;18ed8b0&lt;/denchmark-link&gt;
 - Tue Aug 28 10:56:46 2018 -0400
Pytorch: 0.4.1
Trying out librispeech. The training just stops (hangs) in epoch 0 after few iterations.
I am using pytorch backend with ngpus=4. There is no error in the log.
tail -f train.log  0           300         288.4       324.985        251.815                                                                                  0.343726                         456.825       1e-08        total [#.................................................]  3.62% this epoch [###########################.......................] 54.35% 300 iter, 0 epoch / 15 epochs 0.69902 iters/sec. Estimated time to finish: 3:10:15.971187.
Output of nvidia-smi. GPU utilization remains at zero after few iterations
&lt;denchmark-link:https://user-images.githubusercontent.com/7698301/44949410-9cdfa100-adfe-11e8-92db-4633c0435432.png&gt;&lt;/denchmark-link&gt;

using cuda-8.0.61 and cudnn-6
Any comments on this?
	</description>
	<comments>
		<comment id='1' author='sameerkhurana10' date='2018-09-01T21:14:11Z'>
		Hi &lt;denchmark-link:https://github.com/sameerkhurana10&gt;@sameerkhurana10&lt;/denchmark-link&gt;
. Thank you for your report.
Which python do you use?
And could you try to change following lines as follows?



espnet/src/asr/asr_pytorch.py


        Lines 267 to 272
      in
      afe1fe8






 train_iter = chainer.iterators.MultiprocessIterator( 



 TransformDataset(train, converter.transform), 



 batch_size=1, n_processes=1, n_prefetch=8, maxtasksperchild=20) 



 valid_iter = chainer.iterators.SerialIterator( 



 TransformDataset(valid, converter.transform), 



 batch_size=1, repeat=False, shuffle=False) 





# Now
    train_iter = chainer.iterators.MultiprocessIterator(
        TransformDataset(train, converter.transform),
        batch_size=1, n_processes=1, n_prefetch=8, maxtasksperchild=20)
    valid_iter = chainer.iterators.SerialIterator(
        TransformDataset(valid, converter.transform),
        batch_size=1, repeat=False, shuffle=False)

# Change like this
    train_iter = chainer.iterators.SerialIterator(
        TransformDataset(train, converter.transform),
        batch_size=1)
    valid_iter = chainer.iterators.SerialIterator(
        TransformDataset(valid, converter.transform),
        batch_size=1, repeat=False, shuffle=False)
I'm not sure, but I doubt that data has not been sent from iterator.
		</comment>
		<comment id='2' author='sameerkhurana10' date='2018-09-01T21:51:02Z'>
		thanks &lt;denchmark-link:https://github.com/kan-bayashi&gt;@kan-bayashi&lt;/denchmark-link&gt;

using python-3.6.
With the suggested changes, the epoch 0 is finished successfully.
		</comment>
		<comment id='3' author='sameerkhurana10' date='2018-09-01T22:12:12Z'>
		Thank you for your quick report.
If the training hangs with upper snippets, please let me know.
Maybe MultiProcessIterator has a bug if we use python3.
&lt;denchmark-link:https://github.com/jnishi&gt;@jnishi&lt;/denchmark-link&gt;
, do you have any idea to fix it?
		</comment>
		<comment id='4' author='sameerkhurana10' date='2018-09-02T15:00:57Z'>
		Thanks for reporting.
&lt;denchmark-link:https://github.com/kan-bayashi&gt;@kan-bayashi&lt;/denchmark-link&gt;
 I have not heard about bugs related to MultiprocessIterator and python3. There are only open issues about MultiprocessIterator with OpenCV.
&lt;denchmark-link:https://github.com/chainer/chainer/issues/4412&gt;chainer/chainer#4412&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.chainer.org/en/latest/tips.html?highlight=Multiprocess#my-training-process-gets-stuck-when-using-multiprocessiterator&gt;https://docs.chainer.org/en/latest/tips.html?highlight=Multiprocess#my-training-process-gets-stuck-when-using-multiprocessiterator&lt;/denchmark-link&gt;

Anyway, I will try to run with multi-GPU and python 3. If it stopped, I check it.
		</comment>
		<comment id='5' author='sameerkhurana10' date='2018-09-07T07:02:19Z'>
		I also confirmed this phenomena in the case of Python 3.6.4.
It should be fixed.
		</comment>
		<comment id='6' author='sameerkhurana10' date='2018-09-07T20:55:40Z'>
		Hi &lt;denchmark-link:https://github.com/kan-bayashi&gt;@kan-bayashi&lt;/denchmark-link&gt;
 ,
After training for 12/15 epochs, I get the error:
Exception in main training loop: [Errno 2] No such file or directory: train_trim/deltafalse/feats.24.ark
But the file exists...
Something wrong with the iterator?
Traceback (most recent call last): File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/training/trainer.py", line 306, in run File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/training/updaters/standard_updater.py", line 149, in update File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_pytorch.py", line 118, in update_core batch = train_iter.next() File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/iterators/serial_iterator.py", line 57, in __next__ File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/iterators/serial_iterator.py", line 57, in &lt;listcomp&gt; File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/dataset/dataset_mixin.py", line 67, in __getitem__ File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/datasets/transform_dataset.py", line 52, in get_example File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_pytorch.py", line 147, in transform return load_inputs_and_targets(item) File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_utils.py", line 76, in load_inputs_and_targets xs = [kaldi_io_py.read_mat(b[1]['input'][0]['feat']) for b in batch] File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_utils.py", line 76, in &lt;listcomp&gt; xs = [kaldi_io_py.read_mat(b[1]['input'][0]['feat']) for b in batch] File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/utils/kaldi_io_py.py", line 364, in read_mat fd = open_or_fd(file_or_fd) File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/utils/kaldi_io_py.py", line 60, in open_or_fd fd = open(file, mode) Will finalize trainer extensions and updater before reraising the exception. Traceback (most recent call last): File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/egs/mgb2/asr1/../../../src/bin/asr_train.py", line 194, in &lt;module&gt; main() File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/egs/mgb2/asr1/../../../src/bin/asr_train.py", line 188, in main train(args) File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_pytorch.py", line 361, in train trainer.run() File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/training/trainer.py", line 320, in run File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/six.py", line 693, in reraise File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/training/trainer.py", line 306, in run File "/data/sls/u/sameerk/zen/icassp2018/e2e_pt/tools/espnet/tools/venv/lib/python3.6/site-packages/chainer/training/updaters/standard_updater.py", line 149, in update File "/data/sls/qcri/asr/sameer_v1/scratch/e2e_pt/tools/espnet/src/asr/asr_pytorch.py", line 118, in update_core batch = train_iter.next()
		</comment>
		<comment id='7' author='sameerkhurana10' date='2018-09-19T13:20:06Z'>
		&lt;denchmark-link:https://github.com/jnishi&gt;@jnishi&lt;/denchmark-link&gt;
, do you have any idea of fixing this python3 issue?
I think this is critical.
		</comment>
		<comment id='8' author='sameerkhurana10' date='2018-09-26T15:53:51Z'>
		I can confirm that: (a) this bug is not python3 specific, I have run into the same issue with python2; (b) Replacing MultiprocessIterator with SerialIterator fixes the problem for me.
The number of iters I get through varies, but I never make it past the first epoch. Often it stops at about 300-400 iters, but it has made it to ~3000 and ~6000 iters before stopping.
Shinji, given what you mentioned yesterday about the MultiprocessIterator and memory usage (by the way, bumping requested memory to 20GB fixed my issue), perhaps this is another reason to revert to SerialIterator?
		</comment>
		<comment id='9' author='sameerkhurana10' date='2018-09-26T16:20:18Z'>
		We just started to use SerialIterator as a default (&lt;denchmark-link:https://github.com/espnet/espnet/pull/424&gt;#424&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='10' author='sameerkhurana10' date='2018-12-12T15:28:38Z'>
		python-3.7 hangs using MultiProcessIterator , and MultiProcessIterator  has no arg maxtasksperchild
		</comment>
		<comment id='11' author='sameerkhurana10' date='2018-12-12T17:28:32Z'>
		you need to apply this patch to chainer



espnet/tools/Makefile


         Line 38
      in
      60682e8






 chainer_patch.done: espnet.done 





		</comment>
		<comment id='12' author='sameerkhurana10' date='2019-04-02T13:32:44Z'>
		&lt;denchmark-link:https://github.com/creatorscan&gt;@creatorscan&lt;/denchmark-link&gt;
 thanks ~
		</comment>
		<comment id='13' author='sameerkhurana10' date='2019-08-22T04:53:51Z'>
		same problem still. Considering re-write IO part with pytorch dataloader.
&lt;denchmark-code&gt;chainer/iterators/multiprocess_iterator.py:28: TimeoutWarning: Stalled dataset is detected. 
See the documentation of MultiprocessIterator for common causes and workarounds:
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://docs.chainer.org/en/stable/reference/generated/chainer.iterators.MultiprocessIterator.html&gt;https://docs.chainer.org/en/stable/reference/generated/chainer.iterators.MultiprocessIterator.html&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='sameerkhurana10' date='2019-08-22T18:08:25Z'>
		&lt;denchmark-link:https://github.com/jnishi&gt;@jnishi&lt;/denchmark-link&gt;
, could you take a look at it again?
		</comment>
		<comment id='15' author='sameerkhurana10' date='2019-08-24T13:24:50Z'>
		I met the same problem.
 is a buggy, I agree with &lt;denchmark-link:https://github.com/bobchennan&gt;@bobchennan&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>