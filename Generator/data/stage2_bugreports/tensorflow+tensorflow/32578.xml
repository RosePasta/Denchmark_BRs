<bug id='32578' author='mpdn' open_date='2019-09-17T09:30:36Z' closed_time='2019-12-01T02:50:58Z'>
	<summary>sparse_softmax_cross_entropy_with_logits fails for symbolic tensors in eager mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0-rc0
Python version: 3.6

This code:
&lt;denchmark-code&gt;tf.nn.sparse_softmax_cross_entropy_with_logits(
    tf.keras.layers.Input((None,), dtype=tf.int32),
    tf.keras.layers.Input((None,None)))
&lt;/denchmark-code&gt;

Fails with this exception:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 3477, in sparse_softmax_cross_entropy_with_logits_v2
    labels=labels, logits=logits, name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py", line 3410, in sparse_softmax_cross_entropy_with_logits
    array_ops.shape(logits)[:-1]))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/check_ops.py", line 506, in assert_equal
    if not condition:
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 765, in __bool__
    self._disallow_bool_casting()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 534, in _disallow_bool_casting
    self._disallow_in_graph_mode("using a `tf.Tensor` as a Python `bool`")
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py", line 523, in _disallow_in_graph_mode
    " this function with @tf.function.".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
&lt;/denchmark-code&gt;

But this works:
&lt;denchmark-code&gt;tf.compat.v1.disable_eager_execution()
tf.nn.sparse_softmax_cross_entropy_with_logits(
    tf.keras.layers.Input((None,), dtype=tf.int32),
    tf.keras.layers.Input((None,None)))
&lt;/denchmark-code&gt;

Seems similar to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31848&gt;#31848&lt;/denchmark-link&gt;
, although the underlying issue here is  not faring well with symbolic tensors in eager mode. The issue seems to be from here:



tensorflow/tensorflow/python/ops/check_ops.py


        Lines 330 to 334
      in
      d5efc0e






 if context.executing_eagerly(): 



 test_op = op_func(x, y) 



 condition = math_ops.reduce_all(test_op) 



 if condition: 



 return 





Here a tensor is cast to a boolean in eager mode, but that is not possible in the case of a symbolic keras tensor - even though tensorflow is executing eagerly.
	</description>
	<comments>
		<comment id='1' author='mpdn' date='2019-09-18T06:54:59Z'>
		I have tried on colab with TF version 2.0.0-rc0, 2.0.0-rc1 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/662cb67709e65d8df22e61fe73232033/untitled198.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='mpdn' date='2019-09-18T22:17:38Z'>
		@noctune Can you try this way and let me know what you think. Thanks!
&lt;denchmark-code&gt;import tensorflow as tf 
tf.__version__
a = tf.keras.layers.Input((None,), dtype=tf.int32)
b = tf.keras.layers.Input((None,None))
@tf.function
def crossEntropy_estimate(a,b):
  return tf.nn.sparse_softmax_cross_entropy_with_logits(a, b)

tf.keras.layers.Lambda(crossEntropy_estimate,arguments={'a':a, 'b':b})
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='mpdn' date='2019-09-19T10:49:54Z'>
		What I ended up using is slightly different:
&lt;denchmark-code&gt;import tensorflow as tf
a = tf.keras.layers.Input((None,), dtype=tf.int32)
b = tf.keras.layers.Input((None,None))
tf.keras.layers.Lambda(lambda args: tf.nn.sparse_softmax_cross_entropy_with_logits(*args))((a,b))
&lt;/denchmark-code&gt;

It's a weird workaround, but it works. Thanks!
		</comment>
		<comment id='4' author='mpdn' date='2019-09-19T13:31:49Z'>
		I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='5' author='mpdn' date='2019-09-19T13:31:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32578&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32578&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='mpdn' date='2019-09-19T13:47:27Z'>
		
I am closing the issue as it was resolved.

A workaround was presented, but it seems to me like the underlying issue is still not resolved. Shouldn't sparse_softmax_cross_entropy_with_logits work with symbolic tensors?
		</comment>
		<comment id='7' author='mpdn' date='2019-11-27T23:28:15Z'>
		&lt;denchmark-link:https://github.com/mpdn&gt;@mpdn&lt;/denchmark-link&gt;
 how are you using this? You can combine tf ops with Keras layers in a model created in the Keras functional style.
		</comment>
		<comment id='8' author='mpdn' date='2019-11-28T07:16:51Z'>
		I was trying to create a custom loss that had a dependency on the label, similar to this stackoverflow answer: &lt;denchmark-link:https://stackoverflow.com/a/57919819/798414&gt;https://stackoverflow.com/a/57919819/798414&lt;/denchmark-link&gt;

I don't quite get what you mean by the "you can combine tf ops with Keras layers...", as this issue is a bug when trying to do exactly that.
		</comment>
		<comment id='9' author='mpdn' date='2019-12-01T02:50:57Z'>
		Thank you for the response. You can create a custom loss that depends on the label by using  API in a custom layer. Please see the add_loss examples here. The VAE example is close to what you are looking for: &lt;denchmark-link:https://www.tensorflow.org/guide/keras/custom_layers_and_models&gt;https://www.tensorflow.org/guide/keras/custom_layers_and_models&lt;/denchmark-link&gt;

Here is another small &lt;denchmark-link:https://colab.research.google.com/drive/1mz1vtC-iVAkgMQLRZGNBSDTUqTowgSNK&gt;colab&lt;/denchmark-link&gt;
 example.
		</comment>
		<comment id='10' author='mpdn' date='2019-12-01T02:50:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32578&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32578&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>