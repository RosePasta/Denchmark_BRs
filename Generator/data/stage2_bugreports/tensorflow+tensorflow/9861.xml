<bug id='9861' author='jan-apptornado' open_date='2017-05-12T15:24:37Z' closed_time='2017-06-16T22:41:39Z'>
	<summary>Exporting and loading models with crossed_columns gives errors</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes, see below
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
ubuntu 16.04
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
1.1.0

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I trained a LinearClassifier that includes a crossed_column. When I export it and then load and run it again I get an error message: "ValueError: No op named SparseFeatureCross in defined operations".
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

To train and export the model I used the following python script:
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.contrib.learn.python.learn.utils import input_fn_utils

def input_fn():
    features = {'a': tf.constant([[1],[2]]),
                'b': tf.constant([[3],[4]]) }
    labels = tf.constant([0, 1])
    return features, labels

feature_a = tf.contrib.layers.sparse_column_with_integerized_feature("a", bucket_size=10)
feature_b = tf.contrib.layers.sparse_column_with_integerized_feature("b", bucket_size=10)
feature_c = tf.contrib.layers.crossed_column([feature_a, feature_b], hash_bucket_size=100)
feature_columns = [feature_a, feature_b, feature_c]
model = tf.contrib.learn.LinearClassifier(feature_columns=feature_columns)
model.fit(input_fn=input_fn, steps=10)

feature_spec = tf.contrib.layers.create_feature_spec_for_parsing(feature_columns)
serving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)
model.export_savedmodel('simple-cross/export', serving_input_fn)
&lt;/denchmark-code&gt;

To load and run the model I used the following python script:
&lt;denchmark-code&gt;import tensorflow as tf

def _int_feature(value):
  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

with tf.Session() as session:
    model = tf.saved_model.loader.load(session, ['serve'], "simple-cross/export/1494601566/")
    probs = tf.get_default_graph().get_tensor_by_name('linear/binary_logistic_head/predictions/probabilities:0')

    feature_dict = {'a': _int_feature(value=0),
                    'b': _int_feature(value=5)}
    example = tf.train.Example(features=tf.train.Features(feature=feature_dict)).SerializeToString()
    feed_dict = { 'input_example_tensor:0' : [example] }
    print(session.run(probs, feed_dict=feed_dict))
&lt;/denchmark-code&gt;

(BTW: is this the best way to import/run a saved model? It feels like plugging in constants like linear/binary_logistic_head/predictions/probabilities:0 isn't the way to go.)
This results in the following error:
&lt;denchmark-code&gt;ValueError: No op named SparseFeatureCross in defined operations.
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Notes&lt;/denchmark-h&gt;

When I add the import
&lt;denchmark-code&gt;from tensorflow.contrib.learn.python.learn.utils import input_fn_utils
&lt;/denchmark-code&gt;

to the load/run script, it magically works.
Unfortunately, I like to run the model from Java as well, and in Java there is no analogous workaround AFAIK (input_fn_utils doesn't exist there).
	</description>
	<comments>
		<comment id='1' author='jan-apptornado' date='2017-05-12T16:00:19Z'>
		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
: Looks like a bug.  Can you take a look?
		</comment>
		<comment id='2' author='jan-apptornado' date='2017-05-12T21:08:23Z'>
		It seems saved model load couldn't find the contrib ops.
&lt;denchmark-link:https://github.com/sukritiramesh&gt;@sukritiramesh&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/davidsoergel&gt;@davidsoergel&lt;/denchmark-link&gt;
 do you have idea what's going on?
		</comment>
		<comment id='3' author='jan-apptornado' date='2017-05-12T21:24:24Z'>
		The usage of the lower level of SavedModel APIs for loading from python/saved_model seems correct. &lt;denchmark-link:https://github.com/davidsoergel&gt;@davidsoergel&lt;/denchmark-link&gt;
 Could this be stemming from export_savedmodel(...)?
		</comment>
		<comment id='4' author='jan-apptornado' date='2017-05-12T23:17:13Z'>
		Ops defined in contrib are built as shared libraries which need to be loaded into the address space before they are used. Currently, this load happens when the corresponding Python module is imported. Unfortunately, no other piece of code knows where to find the shared libraries for ops found in the graph.
As a workaround for now, add:
from tensorflow.contrib.layers.python import ops
to your program before invoking  (which triggers a &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/contrib/layers/python/ops/sparse_feature_cross_op.py#L30&gt;load library call&lt;/denchmark-link&gt;
), so something like:
import tensorflow as tf
from tensorflow.contrib.layers.python import ops
with tf.Session() as session:
    model = tf.saved_model.loader.load(session, ['serve'], "simple-cross/export/1494601566/")
FWIW, you can see all the custom op libraries installed with the pip package using something like:
find $(dirname $(python -c "import tensorflow; print tensorflow.__file__")) -name "*.so"
Unfortunately, loading custom op libraries from within Java or other language bindings is not working at the moment, primarily because the way custom op libraries are built right now requires the use of  when loading them. We &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/pywrap_tensorflow.py#L31&gt;hack this up in Python right now&lt;/denchmark-link&gt;
.
A believe a more correct solution would be to have the custom op libraries explicitly depend on the framework shared library and not rely on , but that is a longer fix (FYI &lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
)
In the mean time, possible workarounds for Java will require some source modification and compilation of libtensorflow_jni.so. Options include:

Changing load_library.cc to use RTLD_GLOBAL and then initiating a call to TF_LoadLibrary from Java
Statically linking the ops needed by adding explicit dependencies in the BUILD rule

I'm sincerely sorry that things aren't in better shape at this time. Improving support for custom (contrib) ops in other languages is on our TODO list. A related aside, ops needed for the linear model used in wide-and-deep are slowly moving towards core anyway (e.g. commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/65283e269fac1306089303143daf550b7b1a6658&gt;65283e2&lt;/denchmark-link&gt;
).
Hope that helps.
FYI &lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/skye&gt;@skye&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='jan-apptornado' date='2017-08-29T00:07:15Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;


Improving support for custom (contrib) ops in other languages is on our TODO list.

Any idea when this might happen ?
		</comment>
		<comment id='6' author='jan-apptornado' date='2017-08-29T00:20:55Z'>
		&lt;denchmark-link:https://github.com/pavanky&gt;@pavanky&lt;/denchmark-link&gt;
 relatively soon! The code is written and tested, it just needs review and the ironing out of some final details. Mid September if things go according to schedule.
		</comment>
		<comment id='7' author='jan-apptornado' date='2017-08-29T16:30:15Z'>
		For crossed_column, you can switch to core versions of feature_columns. tf.feature_column.*
such as tf.feature_column.crossed_column. Exporting and loading should work if you use these ones. Also please use core version of estimator too such as tf.estimator.DNNLinearCombinedClassifier.
		</comment>
	</comments>
</bug>