<bug id='41540' author='ghost(ghost)' open_date='2020-07-19T11:23:37Z' closed_time='2020-07-30T17:42:24Z'>
	<summary>Train a tensorflow model using 1 Terabyte swap file</summary>
	<description>
Hi there,
i want to train a tensorflow model that is huge and require alot of memory.
So i increased the swap file size and swapiness, but in training it also uses the ram so it fails.
Is there a way to train tensorflow with using swap file as memory?
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2020-07-20T07:40:26Z'>
		&lt;denchmark-link:https://github.com/deepseek&gt;@deepseek&lt;/denchmark-link&gt;

This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!
		</comment>
		<comment id='2' author='ghost(ghost)' date='2020-07-20T09:16:32Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
  i already did,
But this is a very serious question to answer, when dealing which large scale data, and i mean real big data that requires Terabytes of RAM. Corporations trying to build a huge model at that scale, it's vital to shift training from using the actual RAM, and instead use the swap. Note that my storage is fast M.2
Answering this question is a serious matter
		</comment>
		<comment id='3' author='ghost(ghost)' date='2020-07-30T17:42:24Z'>
		There are several tricks you can try, including decreasing batch size and looking into &lt;denchmark-link:https://www.tensorflow.org/guide/mixed_precision&gt;mixed precision&lt;/denchmark-link&gt;
, but the community on Stack Overflow is better prepared to answer and advise. If there are specific bugs or feature requests that come out of this, please open a new Issue.
		</comment>
		<comment id='4' author='ghost(ghost)' date='2020-07-30T17:42:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41540&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41540&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ghost(ghost)' date='2020-08-07T11:49:58Z'>
		&lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;
 it's not about mixed precision, it's about using the system storage as memory instead of ram.
		</comment>
	</comments>
</bug>