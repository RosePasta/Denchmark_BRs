<bug id='29472' author='tms2003' open_date='2019-06-06T03:20:46Z' closed_time='2019-10-03T05:35:24Z'>
	<summary>[TF2.0]tf.lite.converter.convert() error:Cannot find the Placeholder op that is an input to the ReadVariableOp.   watch my second problem</summary>
	<description>
I test this code for save model in  tf-nightly-2.0-gpu  in ubuntu 19.04,   tf.saved_model.save(model, saved_model_dir)       and get a error:
&lt;denchmark-h:h2&gt;AttributeError: 'TypeError' object has no attribute 'message'&lt;/denchmark-h&gt;

my code like this:
&lt;denchmark-code&gt;# -*- coding: utf-8 -*-
from __future__ import absolute_import, division, print_function, unicode_literals



import tensorflow as tf

import os
import numpy as np
import matplotlib.pyplot as plt

tf.__version__

"""## Setup Input Pipeline

Download the flowers dataset.
"""





_URL = "https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"

zip_file = tf.keras.utils.get_file(origin=_URL, 
                                   fname="flower_photos.tgz", 
                                   extract=True)

base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')

"""Use `ImageDataGenerator` to rescale the images.

Create the train generator and specify where the train dataset directory, image size, batch size.

Create the validation generator with similar approach as the train generator with the flow_from_directory() method.
"""

IMAGE_SIZE = 224
BATCH_SIZE = 64

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255, 
    validation_split=0.2)

train_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='training')

val_generator = datagen.flow_from_directory(
    base_dir,
    target_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE, 
    subset='validation')

for image_batch, label_batch in train_generator:
  break
image_batch.shape, label_batch.shape

"""Save the labels in a file which will be downloaded later."""

print (train_generator.class_indices)

labels = '\n'.join(sorted(train_generator.class_indices.keys()))

with open('labels.txt', 'w') as f:
  f.write(labels)


"""## Create the base model from the pre-trained convnets

Create the base model from the **MobileNet V2** model developed at Google, and pre-trained on the ImageNet dataset, a large dataset of 1.4M images and 1000 classes of web images.

First, pick which intermediate layer of MobileNet V2 will be used for feature extraction. A common practice is to use the output of the very last layer before the flatten operation, the so-called "bottleneck layer". The reasoning here is that the following fully-connected layers will be too specialized to the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.

Let's instantiate an MobileNet V2 model pre-loaded with weights trained on ImageNet. By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top, which is ideal for feature extraction.
"""

IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                              weights='imagenet')

"""## Feature extraction
You will freeze the convolutional base created from the previous step and use that as a feature extractor, add a classifier on top of it and train the top-level classifier.
"""

base_model.trainable = False

"""### Add a classification head"""

model = tf.keras.Sequential([
  base_model,
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(5, activation='softmax')
])

"""### Compile the model

You must compile the model before training it.  Since there are two classes, use a binary cross-entropy loss.
"""

model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

model.summary()

print('Number of trainable variables = {}'.format(len(model.trainable_variables)))

"""### Train the model

&lt;!-- TODO(markdaoust): delete steps_per_epoch in TensorFlow r1.14/r2.0 --&gt;
"""

epochs = 2

history = model.fit(train_generator, 
                    epochs=epochs, 
                    validation_data=val_generator)

"""### Learning curves

Let's take a look at the learning curves of the training and validation accuracy/loss when using the MobileNet V2 base model as a fixed feature extractor.
"""

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""## Fine tuning
In our feature extraction experiment, you were only training a few layers on top of an MobileNet V2 base model. The weights of the pre-trained network were **not** updated during training.

One way to increase performance even further is to train (or "fine-tune") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic features maps to features associated specifically to our dataset.

### Un-freeze the top layers of the model

All you need to do is unfreeze the `base_model` and set the bottom layers be un-trainable. Then, recompile the model (necessary for these changes to take effect), and resume training.
"""

base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))

# Fine tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

"""### Compile the model

Compile the model using a much lower training rate.
"""

model.compile(loss='categorical_crossentropy',
              optimizer = tf.keras.optimizers.Adam(1e-5),
              metrics=['accuracy'])

model.summary()

print('Number of trainable variables = {}'.format(len(model.trainable_variables)))

"""### Continue Train the model"""

history_fine = model.fit(train_generator, 
                         epochs=2,
                         validation_data=val_generator)

"""## Convert to TFLite

Saved the model using `tf.saved_model.save` and then convert the saved model to a tf lite compatible format.
"""

#####  error code,save failed ............!!!!!!!!!!!!!!!!!!!!!!!!!1
saved_model_dir = 'save/fine_tuning'
tf.saved_model.save(model, saved_model_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

"""Download the converted model and labels"""

# from google.colab import files

# files.download('model.tflite')
# files.download('labels.txt')


acc = history_fine.history['accuracy']
val_acc = history_fine.history['val_accuracy']

loss = history_fine.history['loss']
val_loss = history_fine.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()


&lt;/denchmark-code&gt;

and  this is  mistake:
&lt;denchmark-code&gt;W0606 11:03:53.153013 140230779684672 saved_model.py:748] Skipping full serialization of Keras layer &lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f894c11be80&gt;, because it does not have an input spec defined.
W0606 11:03:53.165678 140230779684672 saved_model.py:748] Skipping full serialization of Keras layer &lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f89a64fdba8&gt;, because it does not have an input spec defined.
Traceback (most recent call last):
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 712, in serialize_all_attributes
    save_model_default_signature)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 850, in _wrap_layer_functions
    fn.get_concrete_function()
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 681, in get_concrete_function
    self._initialize(args, kwargs, add_initializers_to=initializer_map)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 359, in _initialize
    *args, **kwds))
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1401, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1689, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1582, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py", line 728, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 309, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 994, in call_and_return_conditional_losses
    return layer_call(inputs, training=training), layer.get_losses_for(inputs)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/normalization.py", line 651, in call
    outputs = self._fused_batch_norm(inputs, training=training)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/normalization.py", line 533, in _fused_batch_norm
    self.add_update(mean_update)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1117, in add_update
    updates = [process_update(x) for x in updates]
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1117, in &lt;listcomp&gt;
    updates = [process_update(x) for x in updates]
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1113, in process_update
    reachable = tf_utils.get_reachable_from_inputs(relevant_inputs, [update])
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py", line 134, in get_reachable_from_inputs
    raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))
TypeError: Expected Operation, Variable, or Tensor, got None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mint/ai/tensorflow/flowerlite/flowers_tf_lite.py", line 204, in &lt;module&gt;
    tf.saved_model.save(model, saved_model_dir)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py", line 812, in save
    checkpoint_graph_view)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py", line 65, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py", line 139, in list_functions
    self._serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py", line 2234, in _list_functions_for_serialization
    fns = (saved_model.serialize_all_attributes(self, serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 712, in serialize_all_attributes
    save_model_default_signature)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 818, in _wrap_layer_functions
    original_attrs = _replace_child_layer_functions(layer, serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 891, in _replace_child_layer_functions
    layer_fns = (serialize_all_attributes(child_layer, serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 712, in serialize_all_attributes
    save_model_default_signature)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 818, in _wrap_layer_functions
    original_attrs = _replace_child_layer_functions(layer, serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 891, in _replace_child_layer_functions
    layer_fns = (serialize_all_attributes(child_layer, serialization_cache)
  File "/home/mint/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py", line 716, in serialize_all_attributes
    'message: {}'.format(layer, e.message))
AttributeError: 'TypeError' object has no attribute 'message'

&lt;/denchmark-code&gt;

the save code is ok at 2.0alpha0 ,but dismiss some  function like this :tf.lite.TFLiteConverter.from_saved_model
this is my tf2.0 version :
&lt;denchmark-code&gt;&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; print(tf.__version__)
2.0.0-dev20190605

&lt;/denchmark-code&gt;

I think it's bug?is it ?
	</description>
	<comments>
		<comment id='1' author='tms2003' date='2019-06-10T11:34:37Z'>
		Have tried on Colab with TF version 2.0.0-dev20190605 and was able to get mentioned output.
		</comment>
		<comment id='2' author='tms2003' date='2019-06-13T00:19:52Z'>
		&lt;denchmark-link:https://github.com/tms2003&gt;@tms2003&lt;/denchmark-link&gt;
 I don't see any issue in saved_model as it ran through without any errors. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/8415f5b8b3f5f8f1ed4f7470437cdb9f/tf_29472_saved_model.ipynb&gt;gist&lt;/denchmark-link&gt;
. Please provide a small reproducible code if there are any more issues. Thanks!
		</comment>
		<comment id='3' author='tms2003' date='2019-06-13T08:45:54Z'>
		
I test this code for save model in tf-nightly-2.0-gpu in ubuntu 19.04, tf.saved_model.save(model, saved_model_dir) and get a error:


the save code is ok at 2.0alpha0 ,but dismiss some function like this :tf.lite.TFLiteConverter.from_saved_model
this is my tf2.0 version :
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; print(tf.__version__)
2.0.0-dev20190605

I think it's bug?is it ?

It's ok in beta0,but  I get error when covert:
my code:
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
and error:
&lt;denchmark-code&gt;traceback (most recent call last):
  File "D:/aisource/tf/flowertflite/flowers_tf_lite.py", line 253, in &lt;module&gt;
    tflite_model = converter.convert()
  File "D:\ProgramData\Miniconda3\envs\tf20\lib\site-packages\tensorflow\lite\python\lite.py", line 348, in convert
    self._funcs[0])
  File "D:\ProgramData\Miniconda3\envs\tf20\lib\site-packages\tensorflow\python\framework\convert_to_constants.py", line 166, in convert_variables_to_constants_v2
    raise ValueError("Cannot find the Placeholder op that is an input "
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
&lt;/denchmark-code&gt;

The same error in :
&lt;denchmark-link:https://colab.research.google.com/gist/tms2003/e65a1e3bc1c5e978a4436ad377b0a92a/tf_29472_saved_model.ipynb&gt;https://colab.research.google.com/gist/tms2003/e65a1e3bc1c5e978a4436ad377b0a92a/tf_29472_saved_model.ipynb&lt;/denchmark-link&gt;

ValueError                                Traceback (most recent call last)
 in ()
1
----&gt; 2 tflite_model = converter.convert()
3
4
1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2(func)
164         input_name = get_name(map_name_to_node[input_name].input[0])
165       if map_name_to_node[input_name].op != "Placeholder":
--&gt; 166         raise ValueError("Cannot find the Placeholder op that is an input "
167                          "to the ReadVariableOp.")
168       # Build a map of Placeholder ops that are inputs to ReadVariableOps to the
ValueError: Cannot find the Placeholder op that is an input to the ReadVariableOp.
so,anybody can help me?
		</comment>
		<comment id='4' author='tms2003' date='2019-06-13T12:55:49Z'>
		&lt;denchmark-link:https://github.com/tms2003&gt;@tms2003&lt;/denchmark-link&gt;
 I can reproduce the same error as you listed. Could you edit the title accordingly.
Thanks!
		</comment>
		<comment id='5' author='tms2003' date='2019-07-01T17:28:34Z'>
		Hi, I see the same error when trying to convert a RNN model to tflite but not when converting a fully connected or CNN model? Does anyone know if tf.keras.layers.LSTM and tf.keras.layers.GRU ops have issues with conversion to TFLite models?
When the tflite converter encounters the lstm node, it find a "Enter" op instead of "Placeholder" op and causes the conversion to fail. For my case the node and the corresponding op where is fails are:
node
name: "lstm/while/ReadVariableOp_1"
op: "ReadVariableOp"
input: "lstm/while/ReadVariableOp/Enter"
input: "^lstm/while/Identity"
attr {
key: "dtype"
value {
type: DT_FLOAT
}
}
input op
name: "lstm/while/ReadVariableOp/Enter"
op: "Enter"
input: "lstm/recurrent_kernel"
attr {
key: "T"
value {
type: DT_RESOURCE
}
}
attr {
key: "frame_name"
value {
s: "lstm/while/while_context"
}
}
attr {
key: "is_constant"
value {
b: true
}
}
attr {
key: "parallel_iterations"
value {
i: 32
}
}
Is there a remedy around this or tf.keras.layers.LSTM are just not usable with TFLite?
		</comment>
		<comment id='6' author='tms2003' date='2019-07-12T17:30:23Z'>
		There is currently limited support for LSTMs in TFLite. The documented path is available &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/examples/lstm/g3doc/README.md&gt;here&lt;/denchmark-link&gt;
. We are working on improving our support of control flow based operations and models.
		</comment>
		<comment id='7' author='tms2003' date='2019-09-24T03:49:15Z'>
		i am getting this error while saving my model and converting it into tfLite :
ValueError                                Traceback (most recent call last)
 in 
1 saved_model_dir = 'Documents/fine_tuning'
----&gt; 2 tf.saved_model.save(model, saved_model_dir)
3
4 converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
5 tflite_model = converter.convert()
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\saved_model\save.py in save(obj, export_dir, signatures)
820   object_saver = util.TrackableSaver(checkpoint_graph_view)
821   asset_info, exported_graph = _fill_meta_graph_def(
--&gt; 822       meta_graph_def, saveable_view, signatures)
823   saved_model.saved_model_schema_version = (
824       constants.SAVED_MODEL_SCHEMA_VERSION)
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\saved_model\save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions)
508   resource_initializer_ops = []
509   with exported_graph.as_default():
--&gt; 510     object_map, resource_map, asset_info = saveable_view.map_resources()
511     for resource_initializer_function in resource_initializer_functions:
512       asset_dependencies = []
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\saved_model\save.py in map_resources(self)
243             and capture not in self.captured_tensor_node_ids):
244           copied_tensor = constant_op.constant(
--&gt; 245               tensor_util.constant_value(capture))
246           node_id = len(self.nodes)
247           node = _CapturedConstant(
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\framework\constant_op.py in constant(value, dtype, shape, name)
244   """
245   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--&gt; 246                         allow_broadcast=True)
247
248
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
282       tensor_util.make_tensor_proto(
283           value, dtype=dtype, shape=shape, verify_shape=verify_shape,
--&gt; 284           allow_broadcast=allow_broadcast))
285   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)
286   const_tensor = g.create_op(
~\AppData\Local\Continuum\anaconda3\envs\hello-tf\lib\site-packages\tensorflow\python\framework\tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)
452   else:
453     if values is None:
--&gt; 454       raise ValueError("None values not supported.")
455     # if dtype is provided, forces numpy array to be the type
456     # provided if possible.
ValueError: None values not supported.
		</comment>
		<comment id='8' author='tms2003' date='2019-09-29T18:02:35Z'>
		I am also getting the same error
opt/conda/lib/python3.6/site-packages/tensorflow/lite/python/lite.py in from_keras_model_file(cls, model_file, input_arrays, input_shapes, output_arrays, custom_objects)
760     _set_tensor_shapes(input_tensors, input_shapes)
761
--&gt; 762     graph_def = _freeze_graph(sess, input_tensors, output_tensors)
763     return cls(graph_def, input_tensors, output_tensors)
764
/opt/conda/lib/python3.6/site-packages/tensorflow/lite/python/util.py in freeze_graph(sess, input_tensors, output_tensors)
236     output_arrays = [get_tensor_name(tensor) for tensor in output_tensors]
237     return tf_graph_util.convert_variables_to_constants(sess, graph_def,
--&gt; 238                                                         output_arrays)
239   else:
240     return sess.graph_def
/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
322               'in a future version' if date is None else ('after %s' % date),
323               instructions)
--&gt; 324       return func(*args, **kwargs)
325     return tf_decorator.make_decorator(
326         func, new_func, 'deprecated',
/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py in convert_variables_to_constants(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)
300         source_op_name = get_input_name(map_name_to_node[source_op_name])
301       if map_name_to_node[source_op_name].op != "VarHandleOp":
--&gt; 302         raise ValueError("Cannot find the variable that is an input "
303                          "to the ReadVariableOp.")
304
ValueError: Cannot find the variable that is an input to the ReadVariableOp.
Does anyone has any solution?
		</comment>
		<comment id='9' author='tms2003' date='2019-10-01T21:29:10Z'>
		&lt;denchmark-link:https://github.com/tms2003&gt;@tms2003&lt;/denchmark-link&gt;
 Can you try  and let us know. I ran it in  and I don't see any error. &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/8dc40269e8223c9eb66f286f94e1d621/tf_29472_saved_model.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the gist. I just changed epochs from 2 to 1 just to save some TF runtime.
If you think the issue was resolved by TF2.0 then please close this issue. Thanks!
		</comment>
		<comment id='10' author='tms2003' date='2019-10-03T05:35:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29472&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29472&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='tms2003' date='2020-01-15T12:55:51Z'>
		
Hi, I see the same error when trying to convert a RNN model to tflite but not when converting a fully connected or CNN model? Does anyone know if tf.keras.layers.LSTM and tf.keras.layers.GRU ops have issues with conversion to TFLite models?
When the tflite converter encounters the lstm node, it find a "Enter" op instead of "Placeholder" op and causes the conversion to fail. For my case the node and the corresponding op where is fails are:
node
name: "lstm/while/ReadVariableOp_1"
op: "ReadVariableOp"
input: "lstm/while/ReadVariableOp/Enter"
input: "^lstm/while/Identity"
attr {
key: "dtype"
value {
type: DT_FLOAT
}
}
input op
name: "lstm/while/ReadVariableOp/Enter"
op: "Enter"
input: "lstm/recurrent_kernel"
attr {
key: "T"
value {
type: DT_RESOURCE
}
}
attr {
key: "frame_name"
value {
s: "lstm/while/while_context"
}
}
attr {
key: "is_constant"
value {
b: true
}
}
attr {
key: "parallel_iterations"
value {
i: 32
}
}
Is there a remedy around this or tf.keras.layers.LSTM are just not usable with TFLite?

&lt;denchmark-link:https://github.com/mrudulaathi&gt;@mrudulaathi&lt;/denchmark-link&gt;
 You able to resolve this one ?
		</comment>
		<comment id='12' author='tms2003' date='2020-01-15T17:03:41Z'>
		&lt;denchmark-link:https://github.com/gunjanddave&gt;@gunjanddave&lt;/denchmark-link&gt;
 You should be able to resolve your conversion issues by setting the flag  to . If that does not resolve your issues, please file a new bug with your error and details on how to reproduce your error.
		</comment>
		<comment id='13' author='tms2003' date='2020-01-18T14:27:46Z'>
		
@gunjanddave You should be able to resolve your conversion issues by setting the flag experimental_new_converter to True. If that does not resolve your issues, please file a new bug with your error and details on how to reproduce your error.

Perfect it worked. Thanks.
		</comment>
	</comments>
</bug>