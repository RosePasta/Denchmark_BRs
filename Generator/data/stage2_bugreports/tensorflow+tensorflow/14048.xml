<bug id='14048' author='meccaLeccaHi' open_date='2017-10-27T23:19:18Z' closed_time='2018-11-16T23:23:53Z'>
	<summary>CUDNN_STATUS_INTERNAL_ERROR</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.2
TensorFlow installed from (source or binary): binary (via pip)
TensorFlow version (use command below): ('v1.3.0-rc2-20-g0787eee', '1.3.0')
Python version: 2.7
Bazel version (if compiling from source): n/a
CUDA/cuDNN version: Cuda 8.0 (via pip) / cuDNN 6.0.21
GPU model and memory: GeForce GTX 1060 6GB
Host compiler version : GCC 4.9.3

Exact steps to reproduce (as per &lt;denchmark-link:https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/&gt;nvidia Tensorflow demo&lt;/denchmark-link&gt;
):
$ git clone -b update-models-1.0 &lt;denchmark-link:https://github.com/tensorflow/models&gt;https://github.com/tensorflow/models&lt;/denchmark-link&gt;

$ cd models/tutorials/image/imagenet
$ python classify_image.py
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Tensorflow fails to run demo script, despite having installed (and re-installed) as per the &lt;denchmark-link:https://www.tensorflow.org/install/install_linux&gt;manual&lt;/denchmark-link&gt;
. Any help would be  appreciated.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

2017-10-27 16:09:51.154970: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-27 16:09:51.155000: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-27 16:09:51.349207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-10-27 16:09:51.349589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.80GiB
2017-10-27 16:09:51.349610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-10-27 16:09:51.349617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-10-27 16:09:51.349631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
2017-10-27 16:09:51.672521: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
2017-10-27 16:09:52.006440: E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-10-27 16:09:52.006471: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-10-27 16:09:52.006481: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &amp;algorithms)
Aborted (core dumped)
	</description>
	<comments>
		<comment id='1' author='meccaLeccaHi' date='2017-10-28T09:07:25Z'>
		The error messages suggest that there was an issue initializing CUDNN.
Could you share the output of nvidia-smi right after you observe this crash? Are there any other processes that might be using the GPU that are running along with your program?
		</comment>
		<comment id='2' author='meccaLeccaHi' date='2017-10-28T16:06:45Z'>
		Sure! See below. No other processes are running when I've tried this. I've also tried restarting to ensure that the GPU memory was totally cleared, but the same issue occurs.
`+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 106...  Off  | 00000000:01:00.0  On |                  N/A |
|  0%   36C    P8     9W / 120W |     52MiB /  6071MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1250      G   /usr/lib/xorg/Xorg                            50MiB |
+-----------------------------------------------------------------------------+
`
		</comment>
		<comment id='3' author='meccaLeccaHi' date='2017-10-30T22:20:47Z'>
		&lt;denchmark-h:h4&gt;I've since upgraded my GPU, upgraded gcc to v5.4, reinstalled CUDA-8.0 (from with apt-get install), and modified my .bashrc file as per this post. The relevant portion of the latest .bashrc file is shown here:&lt;/denchmark-h&gt;

'export CUDA_ROOT=/usr/local/cuda
export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda/lib64/"
export PATH="/usr/local/cuda/bin:$PATH"
export PATH="/usr/local/cuda-8.0/bin:$PATH"
export CUDA_VISIBLE_DEVICES=0
export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/lib64
#export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda-8.0/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64"'
&lt;denchmark-h:h4&gt;But I still get the following error. I've tried the solutions in the troubleshooting guide to no avail.&lt;/denchmark-h&gt;

'&gt;&gt;&gt; import tensorflow
Traceback (most recent call last):
File "", line 1, in 
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/init.py", line 24, in 
from tensorflow.python import *
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/python/init.py", line 49, in 
from tensorflow.python import pywrap_tensorflow
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in 
_pywrap_tensorflow_internal = swig_import_helper()
File "/home/adam/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory
Failed to load the native TensorFlow runtime.
See &lt;denchmark-link:https://www.tensorflow.org/install/install_sources#common_installation_problems&gt;https://www.tensorflow.org/install/install_sources#common_installation_problems&lt;/denchmark-link&gt;

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.'
&lt;denchmark-h:h4&gt;Output of 'nvidia-smi':&lt;/denchmark-h&gt;

'+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX TIT...  Off  | 00000000:01:00.0 Off |                  N/A |
| 22%   40C    P8    14W / 250W |      2MiB / 12207MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GT 610      Off  | 00000000:07:00.0 N/A |                  N/A |
| 40%   35C    P8    N/A /  N/A |     48MiB /   963MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1                    Not Supported                                       |
+-----------------------------------------------------------------------------+'
		</comment>
		<comment id='4' author='meccaLeccaHi' date='2017-10-30T22:56:22Z'>
		&lt;denchmark-link:https://github.com/meccaLeccaHi&gt;@meccaLeccaHi&lt;/denchmark-link&gt;
 : Sorry that you're running into this. The error messages suggest trouble using CUDA/CUDNN, or in this last case, errors in loading the  library.
So the errors have changed after your reinstall? What is the location of libcusolver.so.8.0 on your filesystem?
		</comment>
		<comment id='5' author='meccaLeccaHi' date='2017-10-30T23:15:11Z'>
		Thanks for your help!
I was able to move past the original error by adding the following line, in particular, to my .bashrc file:
export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/lib64
But, I am still unable to import the tensorflow module.
libcusolver.so.8.0 is located at:
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcusolver.so.8.0
		</comment>
		<comment id='6' author='meccaLeccaHi' date='2017-10-30T23:27:20Z'>
		Hmm....so not in your LD_LIBRARY_PATH. Just to verify that libcusolver.so.8.0 is accessible to the linker, can you also list out the output of ldconfig -p | grep libcusolver?
		</comment>
		<comment id='7' author='meccaLeccaHi' date='2017-10-31T05:09:02Z'>
		Happy to.
$ ldconfig -p | grep libcusolver           libcusolver.so.7.5 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libcusolver.so.7.5 libcusolver.so (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libcusolver.so 
		</comment>
		<comment id='8' author='meccaLeccaHi' date='2017-10-31T05:18:45Z'>
		OK, if I add '/usr/local/cuda-8.0/targets/x86_64-linux/lib' to my LD_LIBRARY_PATH, importing tensorflow is successful (so, many thanks to you for that). But, I am still experiencing my original error which is shown below:
`$ python classify_image.py


Downloading inception-2015-12-05.tgz 100.0%
Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.
2017-10-30 22:14:54.542348: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 22:14:54.542378: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-30 22:14:54.705978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-10-30 22:14:54.706540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:01:00.0
Total memory: 11.92GiB
Free memory: 11.80GiB
2017-10-30 22:14:54.706561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-10-30 22:14:54.706568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-10-30 22:14:54.706578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)
2017-10-30 22:14:55.237837: W tensorflow/core/framework/op_def_util.cc:333] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().
2017-10-30 22:14:58.319995: E tensorflow/stream_executor/cuda/cuda_dnn.cc:371] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-10-30 22:14:58.320026: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-10-30 22:14:58.320035: F tensorflow/core/kernels/conv_ops.cc:672] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &amp;algorithms)
Aborted (core dumped)
`


		</comment>
		<comment id='9' author='meccaLeccaHi' date='2017-10-31T05:18:49Z'>
		Based on that, it would appear that libcusolver.so.8.0 is not available to the linker when TensorFlow is loading (i.e., /usr/local/cuda-8.0/targets/x86_64-linux/lib is not in the search path for dynamic libraries).
Not quite sure how you ended up in this state, but it seems that you'd want to correct that by updating your ld.conf, or perhaps including /usr/local/cuda-8.0/targets/x86_64-linux/lib and related paths in your LD_LIBRARY_PATH
		</comment>
		<comment id='10' author='meccaLeccaHi' date='2017-10-31T15:42:23Z'>
		Just to be clear (as my response preceded your last comment)- that worked in eliminating that error, which is great, but the original error still persists (see my last comment for details). Thanks again, asimshankar!
		</comment>
		<comment id='11' author='meccaLeccaHi' date='2017-10-31T20:36:26Z'>
		We ran into similar error (CUDNN_STATUS_INTERNAL_ERROR), but it was not happening when we ran python as root. It always failed when run as other, non-root user.
The root cause in the end was in the nvidia-persistenced daemon, which by default runs on Ubuntu under nvidia-persistenced user (which is member of same named group).
Adding the non-root user to nvidia-persistenced group (sudo usermod -a -G nvidia-persistenced my-nonroot-user) resolved the issue.
		</comment>
		<comment id='12' author='meccaLeccaHi' date='2017-10-31T20:48:26Z'>
		Thanks jstastny, but I did exactly as you say and the error still persists.
		</comment>
		<comment id='13' author='meccaLeccaHi' date='2017-10-31T20:51:07Z'>
		&lt;denchmark-link:https://github.com/meccaLeccaHi&gt;@meccaLeccaHi&lt;/denchmark-link&gt;
 -- did you log out and back again (or issued other way of reloading the groups of your user)? You can validate what are you in by  command.
Just to validate -- it works for you when run under  user, right?
		</comment>
		<comment id='14' author='meccaLeccaHi' date='2017-10-31T21:29:37Z'>
		
I have tried logging out and then back in again, but still experience the same error.
Running the command as sudo does not work, as the tensorflow module is not found (see below). Perhaps because I installed using conda as non-root user (e.g. 'conda install tensorflow-gpu').
$ sudo python classify_image.py  [sudo] password for adam:  Traceback (most recent call last): File "classify_image.py", line 46, in &lt;module&gt; import tensorflow as tf ImportError: No module named tensorflow 
'nvidia-persistenced' is among the groups shown when I run the 'groups' command.

		</comment>
		<comment id='15' author='meccaLeccaHi' date='2017-11-02T05:31:55Z'>
		Does it work if you do the conda thing as root?
		</comment>
		<comment id='16' author='meccaLeccaHi' date='2017-11-02T15:23:24Z'>
		Strangely, I get the same missing module error even after running the following commands:
sudo -s
conda install tensorflow-gpu
tensorflow-gpu seems to install without error, but is not available when I try running python as root.
		</comment>
		<comment id='17' author='meccaLeccaHi' date='2017-11-03T19:41:08Z'>
		I have the exact same problem. Tried all recommended steps here, no luck. Running on Linux Mint 18.2 (Ubuntu 16.04), nvidia-375 (384.90), CUDA 8.0.61-1 + CuDNN 6.0, TensorFlow 1.3.0 and 1.4.0, default Python 2.7, no Anaconda. I once got it working right after reboot, but subsequent executions always failed. Seems like driver gets stuck in some weird state... It started happening only a few days ago, maybe some Ubuntu/Mint update exposed this problem.
		</comment>
		<comment id='18' author='meccaLeccaHi' date='2017-12-05T17:28:16Z'>
		Just to be sure, could you try the newest version?
		</comment>
		<comment id='19' author='meccaLeccaHi' date='2018-01-24T22:57:02Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='20' author='meccaLeccaHi' date='2018-06-13T06:28:23Z'>
		I'm facing the same issue.
I have
Geforce GTX 1050Ti
Tensorflow 1.8.0
CUDA 9.0
cuDNN 7.0
No process is occupying the GPU, and rebooting has no effect. The last time this stopped working, it was a user rights problem, and disappeared when I added my user to nvidia-persistenced. User is probably not the issue, since it won't work with sudo either. Please help.
		</comment>
		<comment id='21' author='meccaLeccaHi' date='2018-07-11T20:55:31Z'>
		could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
I am also facing the same issue.
		</comment>
		<comment id='22' author='meccaLeccaHi' date='2018-07-16T03:16:24Z'>
		&lt;denchmark-link:https://github.com/chintler&gt;@chintler&lt;/denchmark-link&gt;
 I have the exact same problem as yours, have you solved it yet?
		</comment>
		<comment id='23' author='meccaLeccaHi' date='2018-08-23T07:28:05Z'>
		same for me in windows , any help plz
		</comment>
		<comment id='24' author='meccaLeccaHi' date='2018-08-25T19:47:21Z'>
		Please re-open issue.  This still hasn't been solved, even with latest TF 1.10
		</comment>
		<comment id='25' author='meccaLeccaHi' date='2018-08-31T22:07:01Z'>
		&lt;denchmark-link:https://github.com/reedwm&gt;@reedwm&lt;/denchmark-link&gt;
 can you take a look or redirect? Thanks.
		</comment>
		<comment id='26' author='meccaLeccaHi' date='2018-09-01T00:27:23Z'>
		Someone who still has the issue, can you paste the full output of the error and refill the issues template? TensorFlow now requires cuda 9.0 unless built from source, and I cannot reproduce this issue.
		</comment>
		<comment id='27' author='meccaLeccaHi' date='2018-09-25T21:59:38Z'>
		I am getting the same issue with window 10, tensorflow 1.10 and cuda 9.0. The error is
2018-09-25 17:15:39.657620: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018-09-25 17:15:39.657926: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018-09-25 17:15:39.679944: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn.cc:352] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
		</comment>
		<comment id='28' author='meccaLeccaHi' date='2018-10-10T12:39:53Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='29' author='meccaLeccaHi' date='2018-10-18T14:59:05Z'>
		I get the same error on Linux with TensorFlow 1.10 and CUDA 9.0.
Apparently cuDNN is trying to allocate more memory than it should, as if the gpu_options.per_process_gpu_memory_fraction option (which we use) weren't strictly respected. In my case this error occurs when there is little free GPU memory:
&lt;denchmark-code&gt;tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
&lt;/denchmark-code&gt;

Then the process crashes with segmentation fault (SIGSEGV).
		</comment>
		<comment id='30' author='meccaLeccaHi' date='2018-10-18T22:10:44Z'>
		&lt;denchmark-link:https://github.com/adampl&gt;@adampl&lt;/denchmark-link&gt;
 So there is a floor that we need? Are you comfortable enough with the code to send a fix to print out a more meaningful error message?
		</comment>
		<comment id='31' author='meccaLeccaHi' date='2018-10-19T16:53:21Z'>
		&lt;denchmark-link:https://github.com/drpngx&gt;@drpngx&lt;/denchmark-link&gt;
 Unfortunately I'm not familiar with TF code, but it's not the error message that needs to be fixed, but the error itself.
		</comment>
		<comment id='32' author='meccaLeccaHi' date='2018-10-19T22:18:27Z'>
		If I understand correctly, the problem is that the memory fraction cannot be honored if there's too little GPU memory available, resulting in an error. I am assuming that there's a reason for that and it can't be fixed. If it cannot be fixed, then we would want to detect that case and return a more informative error message. (If it can be fixed, then we should fix it). Am I right?
		</comment>
		<comment id='33' author='meccaLeccaHi' date='2018-10-24T14:29:35Z'>
		The error occurs only when there is little free memory, because in such case if cuDNN exceeds the fraction, the GPU is unable to allocate the requested amount of memory. Nonetheless I suspect that the fraction is always (or often) exceeded regardless of the amount of free memory, but it just doesn't result in a fatal error because there is enough free memory.
		</comment>
		<comment id='34' author='meccaLeccaHi' date='2018-11-06T17:10:01Z'>
		This work for me:
&lt;denchmark-link:http://tuxvoid.blogspot.com/2017/08/tensorflow-could-not-create-cudnn.html&gt;http://tuxvoid.blogspot.com/2017/08/tensorflow-could-not-create-cudnn.html&lt;/denchmark-link&gt;

		</comment>
		<comment id='35' author='meccaLeccaHi' date='2018-11-16T23:23:53Z'>
		Closing as this issue is resolved, feel free to reopen if it comes up again.
		</comment>
		<comment id='36' author='meccaLeccaHi' date='2018-11-17T11:15:52Z'>
		&lt;denchmark-link:https://github.com/wt-huang&gt;@wt-huang&lt;/denchmark-link&gt;
 How do you know it's resolved?
		</comment>
		<comment id='37' author='meccaLeccaHi' date='2018-12-07T21:54:59Z'>
		I got the same error when using convolutions (repeatedly), other Tensor operations were running fine. I have not updated anything and kept the same Tensorflow and CUDA version under which the same code was running before.
Deleting the .nv dir (nvidia cache) in my local home directory completely solved the issue for me. Might also explain why another commenter had success with running Python as root.
		</comment>
		<comment id='38' author='meccaLeccaHi' date='2018-12-14T19:29:55Z'>
		I am getting the same issue with window 10, tensorflow 1.10 and cuda 9.0. The error is
2018-12-15 03:57:16.143788: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-12-15 03:57:16.525560: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties:
name: GeForce GTX 750 Ti major: 5 minor: 0 memoryClockRate(GHz): 1.163
pciBusID: 0000:01:00.0
totalMemory: 1.00GiB freeMemory: 819.61MiB
2018-12-15 03:57:16.533704: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2018-12-15 03:57:17.570206: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-15 03:57:17.575885: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0
2018-12-15 03:57:17.579652: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N
2018-12-15 03:57:17.583488: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 537 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0, compute capability: 5.0)
2018-12-15 03:57:24.779936: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_dnn.cc:352] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
[I 03:57:42.363 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports
kernel be56b0b3-f661-4997-a9de-8543bfea49f9 restarted
[I 03:57:54.253 NotebookApp] Saving file at /Desktop/tensorflow/tfobject/models/research/object_detection/object_detection_tutorial.ipynb
		</comment>
	</comments>
</bug>