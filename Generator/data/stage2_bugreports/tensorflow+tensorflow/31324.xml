<bug id='31324' author='bjornsing' open_date='2019-08-04T19:15:01Z' closed_time='2019-10-01T23:16:04Z'>
	<summary>Passing a Variable as learning_rate to Adam optimizer does not work as expected</summary>
	<description>
tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): binary through pip3
TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
Python version: sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: 10.0.130_410.48 / 10.0-linux-x64-v7.4.2.24
GPU model and memory: GeForce GTX 1080 with 7598 MB memory

Describe the current behavior
If a tf.Variable is passed as learning_rate to the Adam optimizer, and the variable is later changed that does not seem to affect the optimizer. Instead, the optimizer seems to "cache" the value of the variable at the time when the optimizer was constructed.
Describe the expected behavior
My expectation was that if I pass a tf.Variable as the learning_rate argument to tf.keras.optimizers.Adam(), and later assign a new value to the variable, that would affect the optimization.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION)

import sys
print(sys.version_info)

tf_a = tf.Variable(1.0)
print('Variable tf_a initialized to {}.'.format(tf_a.numpy()))

tf_lr = tf.Variable(0.1, trainable=False)

tf_opt = tf.keras.optimizers.Adam(learning_rate=tf_lr)

@tf.function
def train_step():
    with tf.GradientTape() as tf_tape:
        tf_loss = tf_a**2
        
    tf_gradients = tf_tape.gradient(tf_loss, [tf_a])

    tf_opt.apply_gradients(zip(tf_gradients, [tf_a]))

print('After one step with learning rate {}... '.format(tf_lr.numpy()), end='')
train_step()
print('Variable tf_a is {}.'.format(tf_a.numpy()))

tf_lr.assign(0.0)

for _ in range(10):
    print('After another step, now with learning rate {}... '.format(tf_lr.numpy()), end='')
    train_step()
    print('Variable tf_a is {}.'.format(tf_a.numpy()))
&lt;/denchmark-code&gt;

The code above produces the following output on my system:
&lt;denchmark-code&gt;v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)
Variable tf_a initialized to 1.0.
After one step with learning rate 0.10000000149011612... Variable tf_a is 0.8999971747398376.
After another step, now with learning rate 0.0... Variable tf_a is 0.8004083633422852.
After another step, now with learning rate 0.0... Variable tf_a is 0.7015821933746338.
After another step, now with learning rate 0.0... Variable tf_a is 0.6039347052574158.
After another step, now with learning rate 0.0... Variable tf_a is 0.5079591274261475.
After another step, now with learning rate 0.0... Variable tf_a is 0.41423195600509644.
After another step, now with learning rate 0.0... Variable tf_a is 0.3234161138534546.
After another step, now with learning rate 0.0... Variable tf_a is 0.23625943064689636.
After another step, now with learning rate 0.0... Variable tf_a is 0.1535806804895401.
After another step, now with learning rate 0.0... Variable tf_a is 0.07624538242816925.
After another step, now with learning rate 0.0... Variable tf_a is 0.005127914249897003.
&lt;/denchmark-code&gt;

As you can see tf_a keeps changing at a fast pace. My expectation was that after setting the learning rate variable to 0.0 updates would no-longer change tf_a.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='bjornsing' date='2019-08-05T09:30:11Z'>
		I tried executing the code on Colab, was able to reproduce the issue with Tensorflow 2.0.0.beta1. Please see the gist &lt;denchmark-link:https://colab.research.google.com/drive/1jA-_Y3ZOprr6i_xIrTiXQWCmu3UyNKL0&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='bjornsing' date='2019-08-06T08:24:20Z'>
		Hi,
This is an interesting fact to point out, however I believe the proper way of setting up custom learning rates is to use an instance of a class inheriting tf.keras.optimizers.schedules.LearningRateSchedule, which returns a learning rate based on the ordinal of each optimization step, e.g. in your case:
class MyLrate(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, lrate=.1):
        self.lrate = lrate

    def __call__(self, step):
        return tf.cond(tf.greater(step, 0), lambda: 0., lambda: self.lrate))
Note however that changing the lrate property of such an instance will not affect the optimizer's learning rate either. I think this is due to its depending on a graph node being create based on a single call to the passed object rather than on making calls at each step (i.e. in the formula, self.lrate will be fixed to the value in place when passed to the optimizer and not checked for at each step). There probably is a workaround to this, but I do not know it.
		</comment>
		<comment id='3' author='bjornsing' date='2019-08-06T12:18:11Z'>
		Thanks, and yes, I filed a separate bug for the changing-lrate-has-no-effect-problem (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31323&gt;#31323&lt;/denchmark-link&gt;
).
The workaround I've found is to assign to the learning_rate property on the optimizer object, as in:
&lt;denchmark-code&gt;tf_opt.learning_rate.assign(0.0)
&lt;/denchmark-code&gt;

Seems to work, but can't see that it's documented anywhere.
		</comment>
		<comment id='4' author='bjornsing' date='2019-08-06T12:46:20Z'>
		Nice workaround! It would indeed be worth documenting.
		</comment>
		<comment id='5' author='bjornsing' date='2019-08-08T19:14:50Z'>
		Interesting.
I searched the code a little. In both the v1 and v2 optimizers, if you pass a variable as the initial learning rate it gets used as the initial value for the real learning rate variable.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a062a8c1f6a89c88a908813add05a0bfd5d523b9/tensorflow/python/keras/optimizers.py#L176&gt;Optimizer v1 here&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a062a8c1f6a89c88a908813add05a0bfd5d523b9/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L606&gt;Optimizer V2 here&lt;/denchmark-link&gt;

This should probably warn, fail or use the passed variable.
&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 It looks like you wrote a lot of the optimizer_v2 code. What do you think?
		</comment>
		<comment id='6' author='bjornsing' date='2019-08-08T19:29:53Z'>
		I will look into it. Something weird probably happened, it should capture the variable but seem it doesn't.
Meanwhile to unblock you, you can do tf_opt.lr = 0.0 and that should work
		</comment>
		<comment id='7' author='bjornsing' date='2019-10-01T23:16:04Z'>
		&lt;denchmark-link:https://github.com/bjornsing&gt;@bjornsing&lt;/denchmark-link&gt;
 I think this was resolved in . Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/dfcdb51d1f8123e38185461f56334726/tf31324.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Output from your code with TF2.0 is as follows. After setting the learning rate variable to 0.0, tf_a was constant as expected.
&lt;denchmark-code&gt;v2.0.0-rc2-26-g64c3d38 2.0.0
sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)
Variable tf_a initialized to 1.0.
After one step with learning rate 0.10000000149011612... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
After another step, now with learning rate 0.0... Variable tf_a is 0.9000001549720764.
&lt;/denchmark-code&gt;

I am closing this issue as it was resolved in TF2,0. Please feel free to open if the issue persists. Thanks!
		</comment>
		<comment id='8' author='bjornsing' date='2019-10-01T23:16:06Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31324&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31324&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='bjornsing' date='2019-10-01T23:24:08Z'>
		Oh sorry to update this. Yes it is fixed before our official launch (yesterday)
		</comment>
	</comments>
</bug>