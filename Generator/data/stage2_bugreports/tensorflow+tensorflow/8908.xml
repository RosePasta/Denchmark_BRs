<bug id='8908' author='dustinvtran' open_date='2017-04-02T16:17:13Z' closed_time='2017-06-13T18:37:47Z'>
	<summary>Bijectors in contrib.distributions not available</summary>
	<description>
In 1.1.0rc0 and beyond, all bijectors are moved into a subdirectory in contrib.distributions. This seems to make it unavailable?
ds = tf.contrib.distributions
ds.bijectors
## Traceback (most recent call last):
##   File "&lt;stdin&gt;", line 1, in &lt;module&gt;
## AttributeError: 'module' object has no attribute 'bijectors'

ds.Bijector
## Traceback (most recent call last):
##   File "&lt;stdin&gt;", line 1, in &lt;module&gt;
## AttributeError: 'module' object has no attribute 'Bijector'
In my install location of /Users/dvt/Envs/tf1.1/lib/python2.7/site-packages/tensorflow/contrib/distributions, it seems like it would be imported, as the following line exists:
from tensorflow.contrib.distributions.python.ops.bijectors import *
However, inspecting the ds submodule, no bijectors are available.
ds.__dict__.keys()
## ['Deterministic', '__path__', 'QuantizedDistribution', 'softplus_inverse', 'Mixture', 'ExpRelaxedOneHotCategorical', 'ConditionalTransformedDistribution', 'Exponential', 'ConditionalDistribution', '__file__', 'StudentTWithAbsDfSoftplusScale', 'RelaxedOneHotCategorical', 'StudentT', 'ReparameterizationType', 'Categorical', 'MultivariateNormalTriL', 'VectorDeterministic', 'TransformedDistribution', 'Chi2', 'MultivariateNormalDiagPlusLowRank', '_allowed_symbols', 'Gamma', 'normal_conjugates_known_scale_predictive', '__builtins__', 'WishartFull', '__name__', 'Normal', 'ExponentialWithSoftplusRate', 'InverseGamma', 'WishartCholesky', 'Distribution', 'RelaxedBernoulli', 'Bernoulli', 'Beta', 'Binomial', '__doc__', 'BetaWithSoftplusConcentration', 'MultivariateNormalDiagWithSoftplusScale', 'NOT_REPARAMETERIZED', 'BernoulliWithSigmoidProbs', 'Laplace', 'GammaWithSoftplusConcentrationRate', 'Poisson', 'FULLY_REPARAMETERIZED', 'DirichletMultinomial', 'matrix_diag_transform', 'RegisterKL', 'InverseGammaWithSoftplusConcentrationRate', 'Uniform', 'NegativeBinomial', 'Geometric', 'LaplaceWithSoftplusScale', '__package__', 'Dirichlet', 'MultivariateNormalDiag', 'Logistic', 'Chi2WithAbsDf', 'NormalWithSoftplusScale', 'normal_conjugates_known_scale_posterior', 'kl', 'Multinomial', 'OneHotCategorical']
	</description>
	<comments>
		<comment id='1' author='dustinvtran' date='2017-04-02T16:21:16Z'>
		Please take  look &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='dustinvtran' date='2017-06-09T12:01:29Z'>
		A workaround:
&lt;denchmark-code&gt;import sys
sys.path.insert(0, tf.__path__[0] + '/contrib/distributions/python/ops')
import bijectors as bijector
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='dustinvtran' date='2017-06-12T03:01:16Z'>
		Does this work?

from tensorflow.contrib.distributions.python.ops import bijectors as bijector
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Jun 9, 2017 5:01 AM, "Frans Zdyb" ***@***.***&gt; wrote:
 A workaround:

 import sys
 sys.path.insert(0, tf.__path__[0] + '/contrib/distributions/python/ops')
 import bijectors as bijector

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#8908 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtimyLxAW1y0VDzP1jgldQOl1laQBx0ks5sCTQygaJpZM4Mw2Q1&gt;
 .



		</comment>
		<comment id='4' author='dustinvtran' date='2017-06-12T20:16:28Z'>
		Yes.
		</comment>
		<comment id='5' author='dustinvtran' date='2017-06-13T18:10:45Z'>
		Use that for now.  We're shuffling things around to get part of the code
into core and I think some of these issues will be fixed then.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Jun 12, 2017 1:17 PM, "Dustin Tran" ***@***.***&gt; wrote:
 Yes.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#8908 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtim3cEoPPG0CWNdLN4pxV9y_dkAUsMks5sDZzFgaJpZM4Mw2Q1&gt;
 .



		</comment>
	</comments>
</bug>