<bug id='28760' author='npuichigo' open_date='2019-05-16T08:23:36Z' closed_time='2019-06-14T11:16:29Z'>
	<summary>TF2.0 custom dynamic rnn with autograph and tensorflow datasets fails to run</summary>
	<description>
When I followed the effective tensorflow2 instructions to try custom dynamic loop optimized with autograph, I encountered the following errors. It seems the sequence length used in dynamic rnn became None. Everything is fine if I disable tf.function and replace DynamicRNN with DynamicRNNV2, which uses eager execution.
# model.py
import tensorflow as tf
from tensorflow.keras import layers


class Model(tf.keras.Model):
  def __init__(self, vocab_size, emb_size, rnn_size):
    super(Model, self).__init__()
    self.embedding = layers.Embedding(vocab_size, emb_size)
    self.rnn = DynamicRNN(rnn_size)

  def call(self, x):
    x = self.embedding(x)
    x, _ = self.rnn(x)
    return x

class DynamicRNN(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV1, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  @tf.function
  def call(self, input_data):
    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    for i in tf.range(input_data.shape[1]):
      print(input_data)
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs = outputs.write(i, output)
    return tf.transpose(outputs.stack(), [1, 0, 2]), state

class DynamicRNNV2(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV2, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  def call(self, input_data):
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    outputs = []
    for i in range(input_data.shape[1]):
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs.append(tf.expand_dims(output, 1))
    return tf.concat(outputs, axis=1), state
&lt;denchmark-code&gt;2019-05-16 08:15:39.248597: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcublas.so.10.0
I0516 08:15:39.560903 140231802230528 train.py:55] (256, 120, 16)
Tensor("input_data:0", shape=(256, 160, 16), dtype=float32)
I0516 08:15:40.161331 140231802230528 train.py:55] (256, 160, 16)
Tensor("input_data:0", shape=(256, None, 16), dtype=float32)
Traceback (most recent call last):
  File "train.py", line 59, in &lt;module&gt;
    app.run(main)
  File "/opt/conda/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/opt/conda/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "train.py", line 54, in main
    output = model(question)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/workspace/code/tf_workspace/dataset_test/model.py", line 36, in call
    x, _ = self.rnn(x)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 424, in __call__
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1305, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1625, in _maybe_define_function
    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1527, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 713, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 329, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2126, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 705, in wrapper
    ), args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 360, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmppfaea7ty.py", line 20, in tf__call
    outputs, state = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (input_data.shape[1],), None), None, loop_body, (outputs, state))
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 264, in converted_call
    return _call_unconverted(f, args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 173, in _call_unconverted
    return f(*args)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1305, in range
    limit = ops.convert_to_tensor(limit, dtype=dtype, name="limit")
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1086, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1144, in convert_to_tensor_v2
    as_ref=False)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1223, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 455, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
&lt;/denchmark-code&gt;

# train.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys

from absl import app
from absl import flags
from absl import logging
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.python.ops import control_flow_util

from model import Model

sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))

control_flow_util.ENABLE_CONTROL_FLOW_V2 = True

FLAGS = flags.FLAGS

flags.DEFINE_integer("batch_size", 256, "Batch size.")


def main(_):
  dataset_train, info = tfds.load(name="squad/bytes",
                                  split=tfds.Split.TRAIN, with_info=True,
                                  data_dir="tensorflow_datasets",
                                  batch_size=FLAGS.batch_size)

  vocab_size = info.features["question"].encoder.vocab_size
  model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)

  for i in range(1):
    for features in dataset_train:
      question = features["question"]
      output = model(question)
      logging.info(output.shape)


if __name__ == "__main__":
  app.run(main)
	</description>
	<comments>
		<comment id='1' author='npuichigo' date='2019-05-20T14:27:11Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
 Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?
Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;the Github new issue template&lt;/denchmark-link&gt;
.
We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!
		</comment>
		<comment id='2' author='npuichigo' date='2019-05-22T02:14:17Z'>
		&lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;
 Related information is listed below.
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.6.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0 / 7.5
GPU model and memory: Tesla P100 16G

Describe the current behavior
Tensorflow dataset doesn't work well with custom dynamic loop (for-clause) with autograph.
Describe the expected behavior
Custom for loop with eager execution use sequence length as condition. When adding tf.function decorator to it, the sequence length used in dynamic rnn became None after two steps. Everything is fine if I disable tf.function and replace DynamicRNN with DynamicRNNV2, which uses eager execution.
Code to reproduce the issue
# model.py
import tensorflow as tf
from tensorflow.keras import layers


class Model(tf.keras.Model):
  def __init__(self, vocab_size, emb_size, rnn_size):
    super(Model, self).__init__()
    self.embedding = layers.Embedding(vocab_size, emb_size)
    self.rnn = DynamicRNN(rnn_size)

  def call(self, x):
    x = self.embedding(x)
    x, _ = self.rnn(x)
    return x

class DynamicRNN(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV1, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  @tf.function
  def call(self, input_data):
    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    for i in tf.range(input_data.shape[1]):
      print(input_data)
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs = outputs.write(i, output)
    return tf.transpose(outputs.stack(), [1, 0, 2]), state

class DynamicRNNV2(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV2, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  def call(self, input_data):
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    outputs = []
    for i in range(input_data.shape[1]):
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs.append(tf.expand_dims(output, 1))
    return tf.concat(outputs, axis=1), state
# train.py
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys

from absl import app
from absl import flags
from absl import logging
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.python.ops import control_flow_util

from model import Model

sys.path.append(os.path.dirname(os.path.dirname(sys.path[0])))

control_flow_util.ENABLE_CONTROL_FLOW_V2 = True

FLAGS = flags.FLAGS

flags.DEFINE_integer("batch_size", 256, "Batch size.")


def main(_):
  dataset_train, info = tfds.load(name="squad/bytes",
                                  split=tfds.Split.TRAIN, with_info=True,
                                  data_dir="tensorflow_datasets",
                                  batch_size=FLAGS.batch_size)

  vocab_size = info.features["question"].encoder.vocab_size
  model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)

  for i in range(1):
    for features in dataset_train:
      question = features["question"]
      output = model(question)
      logging.info(output.shape)


if __name__ == "__main__":
  app.run(main)
Other info / logs
&lt;denchmark-code&gt;2019-05-16 08:15:39.248597: I tensorflow/stream_executor/platform/default/dso_loader.cc:43] Successfully opened dynamic library libcublas.so.10.0
I0516 08:15:39.560903 140231802230528 train.py:55] (256, 120, 16)
Tensor("input_data:0", shape=(256, 160, 16), dtype=float32)
I0516 08:15:40.161331 140231802230528 train.py:55] (256, 160, 16)
Tensor("input_data:0", shape=(256, None, 16), dtype=float32)
Traceback (most recent call last):
  File "train.py", line 59, in &lt;module&gt;
    app.run(main)
  File "/opt/conda/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/opt/conda/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "train.py", line 54, in main
    output = model(question)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/workspace/code/tf_workspace/dataset_test/model.py", line 36, in call
    x, _ = self.rnn(x)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 678, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 424, in __call__
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1305, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1625, in _maybe_define_function
    args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1527, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 713, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 329, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2126, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 705, in wrapper
    ), args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 360, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File "/tmp/tmppfaea7ty.py", line 20, in tf__call
    outputs, state = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (input_data.shape[1],), None), None, loop_body, (outputs, state))
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 264, in converted_call
    return _call_unconverted(f, args, kwargs)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py", line 173, in _call_unconverted
    return f(*args)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1305, in range
    limit = ops.convert_to_tensor(limit, dtype=dtype, name="limit")
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1086, in convert_to_tensor
    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1144, in convert_to_tensor_v2
    as_ref=False)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1223, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 305, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 284, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 455, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='npuichigo' date='2019-05-27T13:02:31Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
 After I execute the provided code in google colab, I get the below message.
FATAL Flags parsing error: Unknown command line flag 'f'
Pass --helpshort or --helpfull to see help on flags.
An exception has occurred, use %tb to see the full traceback.
SystemExit: 1
		</comment>
		<comment id='4' author='npuichigo' date='2019-05-28T02:02:56Z'>
		In order to run in google colab, you need to remove absl app.
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow
!pip install tensorflow==2.0.0-alpha0
!pip install tensorflow_datasets

import os
import sys

from absl import logging
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.python.ops import control_flow_util


control_flow_util.ENABLE_CONTROL_FLOW_V2 = True

BATCH_SIZE = 32


from tensorflow.keras import layers


class Model(tf.keras.Model):
  def __init__(self, vocab_size, emb_size, rnn_size):
    super(Model, self).__init__()
    self.embedding = layers.Embedding(vocab_size, emb_size)
    self.rnn = DynamicRNN(rnn_size)

  def call(self, x):
    x = self.embedding(x)
    x, _ = self.rnn(x)
    return x

class DynamicRNN(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNN, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  @tf.function
  def call(self, input_data):
    outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    for i in tf.range(input_data.shape[1]):
      print(input_data)
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs = outputs.write(i, output)
    return tf.transpose(outputs.stack(), [1, 0, 2]), state

  
class DynamicRNNV2(layers.Layer):
  def __init__(self, rnn_size):
    super(DynamicRNNV2, self).__init__()
    self.rnn_size = rnn_size
    self.cell = layers.GRU(rnn_size, return_state=True)

  def call(self, input_data):
    state = tf.zeros((input_data.shape[0], self.rnn_size), dtype=tf.float32)
    outputs = []
    for i in range(input_data.shape[1]):
      output, state = self.cell(tf.expand_dims(input_data[:, i, :], 1), state)
      outputs.append(tf.expand_dims(output, 1))
    return tf.concat(outputs, axis=1), state


dataset_train, info = tfds.load(name="squad/bytes",
                                split=tfds.Split.TRAIN, with_info=True,
                                data_dir="tensorflow_datasets",
                                batch_size=BATCH_SIZE)

vocab_size = info.features["question"].encoder.vocab_size
model = Model(vocab_size=vocab_size, emb_size=16, rnn_size=16)

for i in range(1):
  for features in dataset_train:
    question = features["question"]
    output = model(question)
    logging.info(output.shape)
		</comment>
		<comment id='5' author='npuichigo' date='2019-05-28T02:03:09Z'>
		&lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='npuichigo' date='2019-05-28T10:08:21Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
 Able to reproduce the issue in 2.0.0-alpha0, tf nightly.
		</comment>
		<comment id='7' author='npuichigo' date='2019-06-06T16:41:11Z'>
		I wasn't able to reproduce this issue with tf-nightly-2.0-preview, which means this issue was somehow fixed between alpha release and nightly. &lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
, could u try on nightly version?
		</comment>
		<comment id='8' author='npuichigo' date='2019-06-06T16:50:35Z'>
		Also, by looking at your code, I think the dynamic RNN doesn't make much sense from RNN model building perspective.
The cell field you used, which is a keras.layer.GRU, is actually a whole GRU layer, not just a cell. It will take care of looping through all the timesteps, and you don't have to manage the looping by the for loop. Since the GRU/LSTM can handle dynamic timestep size, you actually can just feed the input tensor to it, which might have a dynamic timestep size.
So your implementation of DynamicRNN is just a builtin GRU layer.
If you want to build your owner GRU layer with some custom behavior, instead of using keras.layers.GRU as a cell, you should use keras.layers.GRUCell, which will take a 2D input (one step at a time).
		</comment>
		<comment id='9' author='npuichigo' date='2019-06-14T11:16:29Z'>
		&lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 Thank you for your advice! I found the bug when I tried to implement a seq2seq decoder using custom dynamic rnn with autograph, so the code above is just to illustrate the problem. I used tf-nightly-2.0-preview and the bug seems to have been fixed.
		</comment>
		<comment id='10' author='npuichigo' date='2019-06-14T11:16:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28760&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28760&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='npuichigo' date='2019-10-28T05:13:06Z'>
		demo for  custom dynamic rnn with autograph .
		</comment>
	</comments>
</bug>