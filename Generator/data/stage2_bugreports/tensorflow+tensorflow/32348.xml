<bug id='32348' author='simonnanty' open_date='2019-09-09T11:21:15Z' closed_time='2019-10-08T23:18:22Z'>
	<summary>Unable to load model with custom loss function with tf.keras.models.load_model</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tensorflow==2.0.0rc0
Python version: 2.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: None
GPU model and memory: None

Describe the current behavior
I have saved a simple feed-forward Keras model. When I try to load it with the following code, I get an error.
&lt;denchmark-code&gt;from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)
model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')

# Useless custom loss here
def custom_loss(y_true, y_pred):
    return keras.backend.mean(keras.backend.square(y_true - y_pred), axis=-1)

model.compile(loss=custom_loss, optimizer=keras.optimizers.RMSprop())

model.save("model/", save_format='tf')

# Here comes the bug:
new_model = keras.models.load_model('model/', custom_objects={'loss': custom_loss})
&lt;/denchmark-code&gt;

The error:

Traceback (most recent call last):
File "", line 1, in 
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 147, in load_model
return saved_model_load.load(filepath, compile)
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 93, in load
model._training_config))  # pylint: disable=protected-access
File ".env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
result = method(self, *args, **kwargs)
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 340, in compile
self.loss, self.output_names)
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1350, in prepare_loss_functions
loss_functions = [get_loss_function(loss) for _ in output_names]
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1350, in 
loss_functions = [get_loss_function(loss) for _ in output_names]
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1086, in get_loss_function
loss_fn = losses.get(loss)
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py", line 1166, in get
return deserialize(identifier)
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py", line 1157, in deserialize
printable_module_name='loss function')
File ".env/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py", line 210, in deserialize_keras_object
raise ValueError('Unknown ' + printable_module_name + ':' + object_name)
ValueError: Unknown loss function:loss

My understanding of the issue
I checked in the TF code and I found the following:

The function deserialize_keras_object from generic_utils.py has indeed a custom_objects argument
deserialize from losses.py has this argument too
get (from losses.py), the function that calls deserialize does not fills in this argument
So that, even though I give custom_objects to load_model function, it is not passed to deserialize_keras_object at the end.

Could someone check this issue and implement the needed changes for this to work?
Thank you for your help!
	</description>
	<comments>
		<comment id='1' author='simonnanty' date='2019-09-09T13:12:28Z'>
		I found a workaround: calling load_model with compile=False and compile the model separately afterwards.
However, it would be nice that this works directly, too
		</comment>
		<comment id='2' author='simonnanty' date='2019-09-10T09:53:05Z'>
		I have tried on colab with TF version 2.0.0rc0 ,2.0.0-dev20190909 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/3f894e9b9800a3548a414f024eecfa74/untitled169.ipynb&gt;here.&lt;/denchmark-link&gt;
Thanks!
		</comment>
		<comment id='3' author='simonnanty' date='2019-10-08T23:18:22Z'>
		&lt;denchmark-link:https://github.com/simonnanty&gt;@simonnanty&lt;/denchmark-link&gt;
 When you have any , you can save the model and compile. Then load model with the . So you need to move only one line  above . Complete code is as follows.
&lt;denchmark-code&gt;from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = layers.Dense(64, activation='relu', name='dense_2')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)
model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')

# Useless custom loss here
def custom_loss(y_true, y_pred):
    return keras.backend.mean(keras.backend.square(y_true - y_pred), axis=-1)

model.save("model", save_format='tf')
model.compile(loss=custom_loss, optimizer=keras.optimizers.RMSprop())
# Here comes the bug (no bug)
new_model = keras.models.load_model('model', custom_objects={'loss': custom_loss})
&lt;/denchmark-code&gt;

Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/d8e1ade42ea9493beb1c797ed3a5cb10/untitled550.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
I am closing this issue. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='4' author='simonnanty' date='2019-10-08T23:18:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32348&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32348&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='simonnanty' date='2019-10-09T07:08:20Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
, I like to save the model after training is done, therefore I have to compile it first.
		</comment>
		<comment id='6' author='simonnanty' date='2019-10-09T18:26:51Z'>
		&lt;denchmark-link:https://github.com/Shubham3101&gt;@Shubham3101&lt;/denchmark-link&gt;
 Custom functions are not serializable as they are not compatible. If you want to save after training, then follow this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32348#issuecomment-529467228&gt;workaround&lt;/denchmark-link&gt;
. You could also get around this error by defining  a custom Metric/loss object, and overwriting the get_config() . Check the &lt;denchmark-link:https://www.tensorflow.org/beta/guide/keras/training_and_evaluation&gt;link&lt;/denchmark-link&gt;
 for more details.
There is another &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32612&gt;similar issue&lt;/denchmark-link&gt;
 that we will use to track the progress. Thanks!
		</comment>
		<comment id='7' author='simonnanty' date='2020-03-20T12:05:02Z'>
		Even when inheriting the Keras Loss class this does not seems to work out of the box.
If I am using a loss like :
&lt;denchmark-code&gt;class WeightedBinaryCrossentropy(tf.keras.losses.Loss):

    def __init__(self, pos_weight, name='WeightedBinaryCrossentropy'):
        super().__init__(name=name)
        self.pos_weight = pos_weight

    def call(self, y_true, y_pred):
        # For numerical stability clip predictions to log stable numbers
        y_pred = tf.keras.backend.clip(y_pred,
                                       tf.keras.backend.epsilon(),
                                       1 - tf.keras.backend.epsilon())
        # Compute weighted binary cross entropy
        wbce = y_true * -tf.math.log(y_pred) * self.pos_weight + (1 - y_true) * -tf.math.log(1 - y_pred)
        # Reduce by mean
        return tf.reduce_mean(wbce)

&lt;/denchmark-code&gt;

Is there a way to provide the class implementation so compilation is done automatically?
		</comment>
		<comment id='8' author='simonnanty' date='2020-03-20T18:51:19Z'>
		&lt;denchmark-link:https://github.com/Danfoa&gt;@Danfoa&lt;/denchmark-link&gt;
 Please create a new issue with details related to issue and a standalone code to reproduce the issue. Thanks!
		</comment>
	</comments>
</bug>