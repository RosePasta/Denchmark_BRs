<bug id='30850' author='dzhu' open_date='2019-07-18T16:46:51Z' closed_time='2019-07-19T20:16:29Z'>
	<summary>Restoring Keras model fails inside a distribution strategy scope</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
TensorFlow installed from (source or binary): binary (using pip)
TensorFlow version (use command below): both v1.14.0-rc1-22-gaf24dc9 1.14.0 and v2.0.0-beta0-17-g8e423e3 2.0.0-beta1
Python version: 3.7.3
CUDA/cuDNN version: CUDA 10.1.168-4, cuDNN 7.6.1.34-1
GPU model and memory: NVIDIA Quadro P2000, 4GB

Describe the current behavior
Inside a distribution strategy scope, restoring a Keras model (that has been trained at all) with tf.keras.models.load_model raises the exception shown below (while handling the optimizer in particular, it seems).
(Looks a bit similar to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28599&gt;#28599&lt;/denchmark-link&gt;
 if you squint, but many details differ.)
Describe the expected behavior
Restoring the model should succeed.
Code to reproduce the issue
import numpy as np, tensorflow as tf

strategy = tf.distribute.MirroredStrategy()
path = "/tmp/model.hdf5"

with strategy.scope():
    # Construct model.
    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
    # Do a fit so the optimizer weights are created. Removing this lets the restore succeed.
    model.fit(np.array([[1]]), np.array([[1]]))
    # Save and attempt to restore.
    tf.keras.models.save_model(model, path)
    tf.keras.models.load_model(path)
Other info / logs
Traceback for TF 2.0 (TF 1.14 is the same except for line numbers):
&lt;denchmark-code&gt;  File ".../tensorflow/python/keras/saving/save.py", line 137, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ".../tensorflow/python/keras/saving/hdf5_format.py", line 187, in load_model_from_hdf5
    model._make_train_function()
  File ".../tensorflow/python/keras/engine/training.py", line 1974, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)
  File ".../tensorflow/python/keras/optimizer_v2/optimizer_v2.py", line 491, in get_updates
    grads = self.get_gradients(loss, params)
  File ".../tensorflow/python/keras/optimizer_v2/optimizer_v2.py", line 391, in get_gradients
    grads = gradients.gradients(loss, params)
  File ".../tensorflow/python/ops/gradients_impl.py", line 158, in gradients
    unconnected_gradients)
  File ".../tensorflow/python/ops/gradients_util.py", line 543, in _GradientsHelper
    for x in xs
  File ".../tensorflow/python/ops/gradients_util.py", line 543, in &lt;listcomp&gt;
    for x in xs
  File ".../tensorflow/python/distribute/values.py", line 643, in handle
    raise ValueError("`handle` is not available outside the replica context"
ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='dzhu' date='2019-07-19T20:16:29Z'>
		Hi - we don't support saving with hdf5 format. However, you can save and restore with the standard TF format - just remove the hdf5 extension from the file path. See &lt;denchmark-link:https://www.tensorflow.org/beta/tutorials/distribute/save_and_load&gt;https://www.tensorflow.org/beta/tutorials/distribute/save_and_load&lt;/denchmark-link&gt;
 for more information.
		</comment>
		<comment id='2' author='dzhu' date='2019-07-19T20:16:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30850&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30850&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='dzhu' date='2019-07-20T20:02:03Z'>
		Unfortunately, that does not resolve the issue: it makes save_model fail, so that the program never even gets a chance to load the model.
With TF 1.14: removing the extension still defaults to HDF5, leading to the same exception, and specifying save_format="tf" gives this:
&lt;denchmark-code&gt;  File ".../tensorflow/python/keras/saving/save.py", line 86, in save_model
    'Saving the model as SavedModel is not supported in TensorFlow 1.X'
NotImplementedError: Saving the model as SavedModel is not supported in TensorFlow 1.Xgraph mode. Please enable eager execution or use the "h5" save format.
&lt;/denchmark-code&gt;

(I don't think it would be feasible for me to use eager execution, due to external constraints.)
With TF 2.0: removing the extension and specifying save_format="tf" both give this exception:
&lt;denchmark-code&gt;  File ".../tensorflow/python/keras/saving/save.py", line 106, in save_model
    saved_model.save(model, filepath, overwrite, include_optimizer)
  File ".../tensorflow/python/keras/saving/saved_model.py", line 1492, in save
    save_lib.save(model, filepath)
  File ".../tensorflow/python/saved_model/save.py", line 835, in save
    meta_graph_def, saveable_view, signatures)
  File ".../tensorflow/python/saved_model/save.py", line 531, in _fill_meta_graph_def
    object_map, resource_map, asset_info = saveable_view.map_resources()
  File ".../tensorflow/python/saved_model/save.py", line 252, in map_resources
    new_variable = resource_variable_ops.copy_to_graph_uninitialized(obj)
  File ".../tensorflow/python/ops/resource_variable_ops.py", line 1791, in copy_to_graph_uninitialized
    synchronization=var.synchronization,
  File ".../tensorflow/python/ops/variables.py", line 514, in synchronization
    raise NotImplementedError
NotImplementedError
&lt;/denchmark-code&gt;

Using model.save instead of save_model has the same issues.
Those exceptions occur even with the modified and reduced code shown below, with (1) the call to save_model outside the scope, as suggested by the linked document, and (2) no call to fit (though the same exceptions happen with fit present as well).
import tensorflow as tf

strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
tf.keras.models.save_model(model, "/tmp/model", save_format="tf")
(Side note: Though I am able to test with 2.0, a solution for 1.x would be more immediately useful for me. But any help with either version is highly appreciated, of course!)
		</comment>
		<comment id='4' author='dzhu' date='2019-07-20T21:45:07Z'>
		The error you see with 2.0 has been fixed, which version of 2.0 are you testing with?
For 1.x, maybe you need to use a different API then if that one is not supported. Do you need only the weights from the trained model or do you need the graph too?
		</comment>
		<comment id='5' author='dzhu' date='2019-07-21T05:18:41Z'>
		For TF 2.0, I have  and . I installed via . That is the latest released version on both &lt;denchmark-link:https://github.com/tensorflow/tensorflow/releases&gt;GitHub&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://pypi.org/project/tensorflow-gpu/#history&gt;PyPI&lt;/denchmark-link&gt;
, as far as I can tell.
If I understand TF correctly, I don't need to store the graph, as I am restoring in Python with access to the same code that created the model originally. So perhaps save_model and load_model are overkill. However, I do need the state of the optimizer, which rules out using just model.{save,load}_weights. I also attempted to load one copy of the model outside the scope, construct another copy inside the scope, and then use model.{get,set}_weights and model.optimizer.{get,set}_weights, but it seems that the optimizer weights are not created until model.fit has been called with data, so that runs into issues around mismatch of expected number of weights.
In TF 1.14, I also tried tf.contrib.saved_model.{save,load}_keras_model, which fails in a different way:
import numpy as np, tensorflow as tf

strategy = tf.distribute.MirroredStrategy()
path = "/tmp/model"

with strategy.scope():
    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
    model.fit(np.array([[1]]), np.array([[1]]))
    tf.contrib.saved_model.save_keras_model(model, path)

    model = tf.contrib.saved_model.load_keras_model(path)
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
    model.fit(np.array([[1]]), np.array([[1]]))
gives this exception inside the second model.fit:
&lt;denchmark-code&gt;  File ".../tensorflow/python/keras/engine/training.py", line 649, in fit
    validation_freq=validation_freq)
  File ".../tensorflow/python/keras/engine/training_distributed.py", line 143, in fit_distributed
    steps_name='steps_per_epoch')
  File ".../tensorflow/python/keras/engine/training_arrays.py", line 274, in model_iteration
    batch_outs = f(actual_inputs)
  File ".../tensorflow/python/keras/backend.py", line 3292, in __call__
    run_metadata=self.run_metadata)
  File ".../tensorflow/python/client/session.py", line 1458, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense_2/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense_2/kernel/N10tensorflow3VarE does not exist.
         [[{{node dense_3/MatMul/ReadVariableOp}}]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='dzhu' date='2019-07-26T02:14:14Z'>
		for 2.0, please test with the latest nightly version: &lt;denchmark-link:https://pypi.org/project/tf-nightly-gpu-2.0-preview/&gt;https://pypi.org/project/tf-nightly-gpu-2.0-preview/&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='dzhu' date='2019-07-31T04:03:18Z'>
		Thanks, it seems to work with the 2.0 preview version.
For TF 1.14, I've found a workaround, which I'll document here for anyone else coming across this:

Save the model with tf.keras.models.save_model.
Load a copy of the model outside the strategy scope using tf.keras.models.load_model. Retrieve its weights using model.get_weights() and model.optimizer.get_weights().
Create and compile a new copy of the model inside the scope, in the same way as you did the first time.
Now, in a callback, copy the loaded weights to the newly compiled model and its optimizer. The callback is key: the optimizer weights are not created before the call to model.fit, so the copying cannot be done in the normal flow of code, but the on_train_begin callback runs after the weights are created and before any training has happened.

An example of what the callback might look like:
class LoadWeightsCallback(tf.keras.callbacks.Callback):
    _chief_worker_only = False

    def __init__(self, weights, optimizer_weights):
        self.weights = weights
        self.optimizer_weights = optimizer_weights

    def on_train_begin(self, logs=None):
        self.model.set_weights(self.weights)
        self.model.optimizer.set_weights(self.optimizer_weights)
		</comment>
		<comment id='8' author='dzhu' date='2019-08-06T15:13:19Z'>
		Hi &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 , I tried your suggestion of removing 'h5' extension from the file's name and then I followed tutorial on your provided line but I am receiving following error. Please suggest me if there is a way to train the model again on multiple GPUs from lastly saved model file. Thank you!
&lt;denchmark-code&gt;  File "model_with_tfsplit.py", line 98, in &lt;module&gt;
    model =tf.keras.models.load_model(model_path) # Loading for retraining
  File "/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/saving/save.py", line 138, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File "/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 187, in load_model_from_hdf5
    model._make_train_function()
  File "/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 2059, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)
  File "/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py", line 506, in get_updates
    return [self.apply_gradients(grads_and_vars)]
  File "/home/rishabh/.local/lib/python2.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py", line 438, in apply_gradients
    return distribute_ctx.get_replica_context().merge_call(
AttributeError: 'NoneType' object has no attribute 'merge_call'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='dzhu' date='2019-08-06T16:14:32Z'>
		Looking at the logs, it seems that the hdf5 code is still being used in the loading part? Can you use the tf format instead? (or use 2.0 which automatically uses TF format i believe?)
		</comment>
		<comment id='10' author='dzhu' date='2019-08-06T18:10:42Z'>
		Hallo Priya,
thank you for your reply. I am actually using TF 2.0 latest nightly.
Although, just to be clear, do I have to save the file during initial
training without ".h5" extension? or Can I just rename the file because I
saved the model with ".h5" extension and then renamed the file for the
reloading and training which resulted in the error above.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Aug 6, 2019 at 6:22 PM guptapriya ***@***.***&gt; wrote:
 Looking at the logs, it seems that the hdf5 code is still being used in
 the loading part? Can you use the tf format instead? (or use 2.0 which
 automatically uses TF format i believe?)

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#30850?email_source=notifications&amp;email_token=ADZMMPAH4CSOIJF4IHJ7QZ3QDGQKXA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3VVJ6Y#issuecomment-518739195&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ADZMMPAG5E7ISMB5DB57XPTQDGQKXANCNFSM4IE5S5OQ&gt;
 .



		</comment>
		<comment id='11' author='dzhu' date='2019-08-06T18:22:43Z'>
		Yes, you need to save it in tf format to begin with to be able to load back with tf format. just changing the filename later does not help.
		</comment>
		<comment id='12' author='dzhu' date='2019-08-06T18:41:37Z'>
		Alright, I understand. So, there is no other way to continue training on
multiple GPUs.? The thing is my model and datasets are huge so it take many
hours to train for one epoch even. :(
I already have issues (raise this issue here on Github already) training my
model faster on 4 GPUs. Thank you for your help Priya!
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Aug 6, 2019 at 8:29 PM guptapriya ***@***.***&gt; wrote:
 Yes, you need to save it in tf format to begin with to be able to load
 back with tf format. just changing the filename later does not help.

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#30850?email_source=notifications&amp;email_token=ADZMMPGOZCFGCGGJANP2SATQDG7JTA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3WA57I#issuecomment-518786813&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ADZMMPDSMOITGZZQLNF42H3QDG7JTANCNFSM4IE5S5OQ&gt;
 .



		</comment>
		<comment id='13' author='dzhu' date='2019-08-06T18:54:28Z'>
		&lt;denchmark-link:https://github.com/rishabhsahrawat&gt;@rishabhsahrawat&lt;/denchmark-link&gt;
 if you only care about weights and have the model code still, you can simply load the weights into a non distributed setup first. Then copy the weights into a distributed model using set_weights. Similar to workaround proposed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30850#issuecomment-513523828&gt;#30850 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='dzhu' date='2019-08-06T20:28:28Z'>
		Yes I still have the model. I will try your suggestion tomorrow morning and
will get back to you. Thank you:)
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Aug 6, 2019 at 9:02 PM guptapriya ***@***.***&gt; wrote:
 @rishabhsahrawat &lt;https://github.com/rishabhsahrawat&gt; if you only care
 about weights and have the model code still, you can simply load the
 weights into a non distributed setup first. Then copy the weights into a
 distributed model using set_weights. Similar to workaround proposed in #30850
 (comment)
 &lt;#30850 (comment)&gt;

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#30850?email_source=notifications&amp;email_token=ADZMMPEYYZBAPVM2W5UU6KTQDHDEZA5CNFSM4IE5S5O2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3WDXVA#issuecomment-518798292&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ADZMMPHOZ3AKUKZLDWJCOGLQDHDEZANCNFSM4IE5S5OQ&gt;
 .



		</comment>
		<comment id='15' author='dzhu' date='2019-08-07T10:20:11Z'>
		Hi &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 , I tried your suggestion on which I am facing following error.
&lt;denchmark-code&gt;ValueError: You called `set_weights(weights)` on optimizer Adam with a  weight list of length 19, but the optimizer was expecting 0 weights
&lt;/denchmark-code&gt;

This is how I am applying it.
&lt;denchmark-code&gt;model =tf.keras.models.load_model('saved_model.h5')# weight loading
model_weights = model.get_weights()
opt_weights = model.optimizer.get_weights()# optimizers weight

mirrored_strategy = tf.distribute.MirroredStrategy()
with mirrored_strategy.scope():
    &lt;model definition including model.compile()&gt;

class LoadWeightsCallback(tf.keras.callbacks.Callback):
    _chief_worker_only = False

    def __init__(self, weights, optimizer_weights):
        self.weights = weights
        self.optimizer_weights = optimizer_weights

    def on_train_begin(self, logs=None):
        self.model.set_weights(self.weights)
        self.model.optimizer.set_weights(self.optimizer_weights)

model.fit(train_data, epochs=20 , callbacks = [LoadWeightsCallback(model_weights, opt_weights)]
&lt;/denchmark-code&gt;

If I try without loading optimizer's weight and just update layers weights, then I receive , but if I either choose only one device in  or just don't define the model inside  then it trains. I only have 2 Tesla T4 GPUs now but earlier when I had 4, I could train the same model on selecting 2 GPUs. I also could use all 4 GPUs but the training speed was slower on 4. There is really a lot going on in  function. Here is my &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31162&gt;issue&lt;/denchmark-link&gt;
 with this.
		</comment>
		<comment id='16' author='dzhu' date='2019-08-25T06:00:23Z'>
		I think the optimizer weights issue is because sometimes optimizer weights are only created during the first step. So when you try to load the weights before training starts, weights have not yet been created.
One workaround can be to just do 1 step first and then load the weights. &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 do you know what could be a better alternative for loading optimizer weights ?
		</comment>
		<comment id='17' author='dzhu' date='2019-10-14T10:05:43Z'>
		with official released tf 2.0, I meet the similar error even try to load the tf format model.
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense/kernel_34381 from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not
exist. (Could not find resource: localhost/dense/kernel_34381) [Op:ReadVariableOp]
		</comment>
		<comment id='18' author='dzhu' date='2019-11-15T17:00:10Z'>
		
For TF 2.0, I have tf.version.VERSION == '2.0.0-beta1' and tf.version.GIT_VERSION == 'v2.0.0-beta0-17-g8e423e3'. I installed via pip install tensorflow-gpu==2.0.0b1. That is the latest released version on both GitHub and PyPI, as far as I can tell.
If I understand TF correctly, I don't need to store the graph, as I am restoring in Python with access to the same code that created the model originally. So perhaps save_model and load_model are overkill. However, I do need the state of the optimizer, which rules out using just model.{save,load}_weights. I also attempted to load one copy of the model outside the scope, construct another copy inside the scope, and then use model.{get,set}_weights and model.optimizer.{get,set}_weights, but it seems that the optimizer weights are not created until model.fit has been called with data, so that runs into issues around mismatch of expected number of weights.
In TF 1.14, I also tried tf.contrib.saved_model.{save,load}_keras_model, which fails in a different way:
import numpy as np, tensorflow as tf

strategy = tf.distribute.MirroredStrategy()
path = "/tmp/model"

with strategy.scope():
    model = tf.keras.models.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
    model.fit(np.array([[1]]), np.array([[1]]))
    tf.contrib.saved_model.save_keras_model(model, path)

    model = tf.contrib.saved_model.load_keras_model(path)
    model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.metrics.mse)
    model.fit(np.array([[1]]), np.array([[1]]))
gives this exception inside the second model.fit:
  File ".../tensorflow/python/keras/engine/training.py", line 649, in fit
    validation_freq=validation_freq)
  File ".../tensorflow/python/keras/engine/training_distributed.py", line 143, in fit_distributed
    steps_name='steps_per_epoch')
  File ".../tensorflow/python/keras/engine/training_arrays.py", line 274, in model_iteration
    batch_outs = f(actual_inputs)
  File ".../tensorflow/python/keras/backend.py", line 3292, in __call__
    run_metadata=self.run_metadata)
  File ".../tensorflow/python/client/session.py", line 1458, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable dense_2/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/dense_2/kernel/N10tensorflow3VarE does not exist.
         [[{{node dense_3/MatMul/ReadVariableOp}}]]


anyluck on resolving this?
		</comment>
		<comment id='19' author='dzhu' date='2020-06-15T20:16:35Z'>
		Same error here too
		</comment>
	</comments>
</bug>