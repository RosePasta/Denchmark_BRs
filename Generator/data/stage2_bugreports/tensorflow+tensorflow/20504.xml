<bug id='20504' author='tianyapiaozi' open_date='2018-07-03T08:43:07Z' closed_time='2019-02-23T00:32:54Z'>
	<summary>freeze_graph failed with core dump</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.8
Python version: 2.7
Bazel version (if compiling from source):0.11.1
GCC/Compiler version (if compiling from source): 4.9.2
CUDA/cuDNN version: none
GPU model and memory: none
Exact command to reproduce:
bazel-bin/tensorflow/python/tools/freeze_graph --input_saved_model_dir ~/tmp/model/test.model --saved_model_tags=serve --output_node_names=Test/Sigmoid --output_graph ~/tmp/model/test_model.pb

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Core dump occurred when I tried to freeze a 7.6G saved model.
&lt;denchmark-code&gt;$ du -sh test.model/
7.6G	test.model/
&lt;/denchmark-code&gt;

2018-07-03 16:15:26.895400: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
Converted 16 variables to const ops.
[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/wire_format.cc:830] CHECK failed: (output-&gt;ByteCount()) == (expected_endpoint): : Protocol message serialized to a size different from what was originally expected.  Perhaps it was modified by another thread during serialization?
terminate called after throwing an instance of 'google::protobuf::FatalException'
what():  CHECK failed: (output-&gt;ByteCount()) == (expected_endpoint): : Protocol message serialized to a size different from what was originally expected.  Perhaps it was modified by another thread during serialization?
Aborted (core dumped)
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;(gdb) bt
#0  0x00007f7a6cd575f7 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
#1  0x00007f7a6cd58ce8 in __GI_abort () at abort.c:90
#2  0x00007f7a61d356bd in __gnu_cxx::__verbose_terminate_handler () at ../../.././libstdc++-v3/libsupc++/vterminate.cc:95
#3  0x00007f7a61d33726 in __cxxabiv1::__terminate (handler=&lt;optimized out&gt;) at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:47
#4  0x00007f7a61d33771 in std::terminate () at ../../.././libstdc++-v3/libsupc++/eh_terminate.cc:57
#5  0x00007f7a61d33988 in __cxxabiv1::__cxa_throw (obj=0xd10f070, tinfo=0x7f7a61aad2f0 &lt;typeinfo for google::protobuf::FatalException&gt;, dest=0x7f7a61a1e8f0 &lt;google::protobuf::FatalException::~FatalException()&gt;)
    at ../../.././libstdc++-v3/libsupc++/eh_throw.cc:87
#6  0x00007f7a61a1f71c in google::protobuf::internal::LogMessage::Finish() ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#7  0x00007f7a619ff402 in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#8  0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#9  0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#10 0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#11 0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#12 0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#13 0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#14 0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#15 0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#16 0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#17 0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#18 0x00007f7a619fe0d8 in google::protobuf::internal::WireFormat::SerializeFieldWithCachedSizes(google::protobuf::FieldDescriptor const*, google::protobuf::Message const&amp;, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
#19 0x00007f7a619ff35f in google::protobuf::internal::WireFormat::SerializeWithCachedSizes(google::protobuf::Message const&amp;, int, google::protobuf::io::CodedOutputStream*) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#20 0x00007f7a618ccd40 in google::protobuf::python::cmessage::InternalSerializeToString(google::protobuf::python::CMessage*, _object*, _object*, bool) ()
   from /home/user/.cache/bazel/_bazel_user/c06ab0b1cffa9a52f3e96df3f3fdd0d6/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/tools/freeze_graph.runfiles/protobuf_archive/python/google/protobuf/pyext/_message.so
#21 0x00007f7a6dae8aa4 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#22 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#23 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#24 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#25 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#26 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#27 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#28 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#29 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#30 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#31 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#32 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#33 0x00007f7a6dae876f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#34 0x00007f7a6daea0bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#35 0x00007f7a6daea1c2 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#36 0x00007f7a6db035ff in run_mod () from /lib64/libpython2.7.so.1.0
#37 0x00007f7a6db047be in PyRun_FileExFlags () from /lib64/libpython2.7.so.1.0
#38 0x00007f7a6db05a49 in PyRun_SimpleFileExFlags () from /lib64/libpython2.7.so.1.0
#39 0x00007f7a6db16b9f in Py_Main () from /lib64/libpython2.7.so.1.0
#40 0x00007f7a6cd43b15 in __libc_start_main (main=0x4006f0 &lt;main&gt;, argc=8, ubp_av=0x7fffc3fae458, init=&lt;optimized out&gt;, fini=&lt;optimized out&gt;, rtld_fini=&lt;optimized out&gt;, stack_end=0x7fffc3fae448)
    at libc-start.c:274
#41 0x0000000000400721 in _start ()
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='tianyapiaozi' date='2018-10-01T12:49:40Z'>
		&lt;denchmark-link:https://github.com/tianyapiaozi&gt;@tianyapiaozi&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
  Hello, I too am facing a similar issue when trying to freeze a 2.1G saved model. Any updates on how to solve this or how can it be prevented?
		</comment>
		<comment id='2' author='tianyapiaozi' date='2018-10-18T17:36:42Z'>
		Same noise here when I try to move to a really large dataset. Can't provide exact sizes, unfortunately. Rank amateur playing with a canned estimator.
&lt;denchmark-code&gt;INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /home/ec2-user/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:113: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.
Instructions for updating:
keep_dims is deprecated, use keepdims instead
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
[libprotobuf FATAL google/protobuf/wire_format.cc:830] CHECK failed: (output-&gt;ByteCount()) == (expected_endpoint): : Protocol message serialized to a size different from what was originally expected.  Perhaps it was modified by another thread during serialization?
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: (output-&gt;ByteCount()) == (expected_endpoint): : Protocol message serialized to a size different from what was originally expected.  Perhaps it was modified by another thread during serialization?
Aborted
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='tianyapiaozi' date='2019-02-23T00:32:54Z'>
		Unfortunately we're not likely to be able to fix this soon, since protobuf has some built-in limits around a maximum size of 2GB. Closing as infeasible.
		</comment>
	</comments>
</bug>