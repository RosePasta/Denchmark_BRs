<bug id='3277' author='rueberger' open_date='2016-07-11T22:00:32Z' closed_time='2016-07-13T21:04:06Z'>
	<summary>Broadcast 0-rank tensors when computing gradients for tf.nn.relu</summary>
	<description>
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: OSX (macOS....?), CPU only, version 0.9.0
Perhaps this is desired behavior, but I would have much appreciated a more descriptive warning at least, which would have saved much debugging.
I haven't found a small reproducible case for this: but in the code I originally found this bug, no error is raised as the other variables are trained, leaving me scratching my head as to why the linear rectified variable was not being trained.
The same issue also occurs for tf.nn.softplus, and perhaps other methods as well.
&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
sess = tf.Session()

x = tf.Variable(100.)
y = tf.nn.relu(x)
loss = y ** 2
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss)
sess.run(tf.initialize_all_variables())

sess.run(train_op)

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    729     try:
--&gt; 730       return fn(*args)
    731     except errors.OpError as e:

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    711                                  feed_dict, fetch_list, target_list,
--&gt; 712                                  status, run_metadata)
    713 

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---&gt; 66                 next(self.gen)
     67             except StopIteration:

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()
    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--&gt; 450           pywrap_tensorflow.TF_GetCode(status))
    451   finally:

InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0
     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-51-ea082b2869a4&gt; in &lt;module&gt;()
----&gt; 1 sess.run(train_op)

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    380     try:
    381       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 382                          run_metadata_ptr)
    383       if run_metadata:
    384         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    653     movers = self._update_with_movers(feed_dict_string, feed_map)
    654     results = self._do_run(handle, target_list, unique_fetches,
--&gt; 655                            feed_dict_string, options, run_metadata)
    656 
    657     # User may have fetched the same tensor multiple times, but we

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    721     if handle is None:
    722       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--&gt; 723                            target_list, options, run_metadata)
    724     else:
    725       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
    741         except KeyError:
    742           pass
--&gt; 743       raise type(e)(node_def, op, message)
    744 
    745   def _extend_graph(self):

InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 0
     [[Node: gradients_29/Relu_5_grad/ReluGrad = ReluGrad[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"](gradients_29/pow_9_grad/tuple/control_dependency, Relu_5)]]
Caused by op 'gradients_29/Relu_5_grad/ReluGrad', defined at:
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py", line 170, in _run_module_as_main
    "__main__", mod_spec)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/__main__.py", line 3, in &lt;module&gt;
    app.launch_new_instance()
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/traitlets/config/application.py", line 596, in launch_instance
    app.start()
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelapp.py", line 442, in start
    ioloop.IOLoop.instance().start()
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/ioloop.py", line 162, in start
    super(ZMQIOLoop, self).start()
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/ioloop.py", line 883, in start
    handler_func(fd_obj, events)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py", line 440, in _handle_events
    self._handle_recv()
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py", line 414, in _run_callback
    callback(*args, **kwargs)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tornado/stack_context.py", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/kernelbase.py", line 391, in execute_request
    user_expressions, allow_stdin)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/ipykernel/ipkernel.py", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "&lt;ipython-input-49-21a2f038fac9&gt;", line 5, in &lt;module&gt;
    train_op = optimizer.minimize(loss)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py", line 193, in minimize
    grad_loss=grad_loss)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py", line 250, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py", line 482, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py", line 233, in _ReluGrad
    return gen_nn_ops._relu_grad(grad, op.outputs[0])
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 1374, in _relu_grad
    features=features, name=name)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py", line 703, in apply_op
    op_def=op_def)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 1231, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'Relu_5', defined at:
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/runpy.py", line 170, in _run_module_as_main
    "__main__", mod_spec)
[elided 17 identical lines from previous traceback]
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/IPython/core/interactiveshell.py", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "&lt;ipython-input-49-21a2f038fac9&gt;", line 2, in &lt;module&gt;
    y = tf.nn.relu(x)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 1312, in relu
    result = _op_def_lib.apply_op("Relu", features=features, name=name)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py", line 703, in apply_op
    op_def=op_def)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 2297, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/Users/andrew/anaconda/envs/tf_dev/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 1231, in __init__
    self._traceback = _extract_stack()
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;What have you tried?&lt;/denchmark-h&gt;

The problem is resolved by expanding the dimensions of x:
&lt;denchmark-code&gt;import tensorflow as tf
sess = tf.Session()

x = tf.Variable(100.)
y = tf.nn.relu(tf.expand_dims(x, 0))
loss = y ** 2
optimizer = tf.train.AdamOptimizer(learning_rate=0.1)
train_op = optimizer.minimize(loss)
sess.run(tf.initialize_all_variables())

sess.run(train_op)
# runs fine
&lt;/denchmark-code&gt;

I wonder if it would be possible to do this automatically?
	</description>
	<comments>
		<comment id='1' author='rueberger' date='2016-07-12T00:50:51Z'>
		So I checked this out, does seem to be a bug. The good news is it looks like it might be really easy to fix.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/numeric_op.h#L90&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/numeric_op.h#L90&lt;/denchmark-link&gt;

Just add NDIM_CASE(0); on line 90 and the template magic should take care of the rest.
I'll work on getting this submitted.
		</comment>
		<comment id='2' author='rueberger' date='2016-07-13T15:49:32Z'>
		Looks like the fix got pushed. Could you check whether this solves the issue with your more complicated example?
Thank you for the awesome bug report!
		</comment>
		<comment id='3' author='rueberger' date='2016-07-14T14:29:16Z'>
		Yup! All is well. Thanks for quickly dispatching this one!
		</comment>
	</comments>
</bug>