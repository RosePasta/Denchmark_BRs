<bug id='35358' author='vicpara' open_date='2019-12-23T12:01:44Z' closed_time='2020-01-23T18:17:23Z'>
	<summary>Read data from TFRecordDataset throws TensorShape error</summary>
	<description>
Describe the current behavior
I'm trying to save/load a numpy dataset into a TFRecordDataset in TF2.0 for training on TPU. Saving succeeds but when reading the file I and I pass the data through a model I get an error about the shape of the tensors.
I compared the tensors resulted from reading the TFRecordDataset and they are equal. The dataset I get read back from the file reader is a  instead of a .
I have also opened an issue on stack overflow here: &lt;denchmark-link:https://stackoverflow.com/questions/59314315/read-data-from-tfrecorddataset-throws-tensorshape-error&gt;https://stackoverflow.com/questions/59314315/read-data-from-tfrecorddataset-throws-tensorshape-error&lt;/denchmark-link&gt;
 .
Describe the expected behaviour
Reading the file should result in a dataset identical with the one that was written. Running the dataset through a model should produce similar effects.
 .
A minimum reproducible example is available as a Python notebook here &lt;denchmark-link:https://gist.github.com/vicpara/3b4ea00553a1990620a2df77d8b6aa1f&gt;https://gist.github.com/vicpara/3b4ea00553a1990620a2df77d8b6aa1f&lt;/denchmark-link&gt;
  .
System information
tf_env_collect.sh output:
&lt;denchmark-code&gt;== check python ===================================================
python version: 3.7.4
python branch: 
python build version: ('default', 'Sep 29 2019 19:47:40')
python compiler version: Clang 10.0.1 (clang-1001.0.46.4)
python implementation: CPython


== check os platform ===============================================
os: Darwin
os kernel version: Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64
os release version: 18.7.0
os platform: Darwin-18.7.0-x86_64-i386-64bit
linux distribution: ('', '', '')
linux os distribution: ('', '', '')
mac version: ('10.14.6', ('', '', ''), 'x86_64')
uname: uname_result(system='Darwin', node='Viktors-MacBook-Pro.local', release='18.7.0', version='Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64', machine='x86_64', processor='i386')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 10.0.1 (clang-1001.0.46.4)
Target: x86_64-apple-darwin18.7.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== check pips ===================================================
numpy                    1.17.2              
protobuf                 3.9.2               
tensorflow               2.0.0               
tensorflow-datasets      1.2.0               
tensorflow-estimator     2.0.0               
tensorflow-metadata      0.14.0              

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.0.0
tf.version.GIT_VERSION = v2.0.0-rc2-26-g64c3d382ca
tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)
/Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
/Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_collect.sh: line 147: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.0.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /Users/victor/.pyenv/versions/3.7.4/lib/python3.7/site-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 4, 'final', 0)

== bazel version  ===============================================
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='vicpara' date='2019-12-24T05:19:46Z'>
		&lt;denchmark-link:https://github.com/vicpara&gt;@vicpara&lt;/denchmark-link&gt;

I tried to execute your code with TF 2.0 and was not able to reproduce it.However i tried with TF 2.1.0-rc1 and i am seeing different error message .Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/51dd46b75fa2933f579a44d53340e80d/untitled496.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='vicpara' date='2020-01-04T22:43:01Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 How can I help reproducing this error on TF2.0. I am also wondering if I'm using the api incorrectly. Thanks.
		</comment>
		<comment id='3' author='vicpara' date='2020-01-06T07:11:57Z'>
		&lt;denchmark-link:https://github.com/vicpara&gt;@vicpara&lt;/denchmark-link&gt;

Sorry my bad for the typo error.
I am getting the below error message with TF 2.0

I am getting the below error message with 2.1.0-rc1 and 2.1.0-rc2

		</comment>
		<comment id='4' author='vicpara' date='2020-01-07T21:40:22Z'>
		duplicate &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24520&gt;#24520&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='vicpara' date='2020-01-08T08:40:56Z'>
		i have the same problem.
i create TFRecord file to save MNIST image as below:
with tf.io.TFRecordWriter(path='./MNIST.tfrecords') as tf_writer:        
    for image, label in zip(x_train, y_train):
        feature = {
            'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.serialize_tensor(image).numpy()])),
            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))            
        }
        example = tf.train.Example(features=tf.train.Features(feature=feature))
        tf_writer.write(example.SerializeToString())
then use  tf.data.TFRecordDataset to load the file object.
datasets_tfrecord = tf.data.TFRecordDataset('MNIST.tfrecords')
it's my feature mapping:
feature_type = {
    'image': tf.io.FixedLenFeature([], tf.string),
    'label': tf.io.FixedLenFeature([], tf.int64)
}
then set parser function:
def parser_tfrecord(tfrecord_example):
    _feature = tf.io.parse_single_example(tfrecord_example, feature_type)
    _feature['image'] = tf.io.parse_tensor(_feature['image'], tf.float64)
    return _feature['image'], _feature['label']
use map function:
datasets = datasets_tfrecord.map(parser_tfrecord)
i try to print shape or show image , and all is fine:
for image, label in datasets.take(1):
    plt.imshow(image.numpy()[:, :, 0])
    plt.title(label.numpy())
plt.show()
then structure model:
model = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), padding='valid', activation='tanh'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), padding='valid', activation='tanh'),
    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, activation='tanh'),
    tf.keras.layers.Dense(84, activation='tanh'),
    tf.keras.layers.Dense(10, activation='softmax'),
])
and compile
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss=tf.keras.losses.sparse_categorical_crossentropy,
    metrics=['accuracy']
)
finally, fit the model
model.fit(datasets,
          epochs=5, 
          steps_per_epoch=int(len(x_train)/128))
get the error message as below:
Train for 468 steps
Epoch 1/5
  1/468 [..............................] - ETA: 12s

ValueErrorTraceback (most recent call last)
&lt;ipython-input-156-a8a69bd97ab0&gt; in &lt;module&gt;()
----&gt; 1 get_ipython().run_cell_magic(u'time', u'', u'model.fit(datasets,\n          epochs=5, \n          steps_per_epoch=int(len(x_train)/128))')

/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc in run_cell_magic(self, magic_name, line, cell)
   2115             magic_arg_s = self.var_expand(line, stack_depth)
   2116             with self.builtin_trap:
-&gt; 2117                 result = fn(magic_arg_s, cell)
   2118             return result
   2119 

&lt;/usr/local/lib/python2.7/dist-packages/decorator.pyc:decorator-gen-60&gt; in time(self, line, cell, local_ns)

/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc in &lt;lambda&gt;(f, *a, **k)
    186     # but it's overkill for just that one bit of state.
    187     def magic_deco(arg):
--&gt; 188         call = lambda f, *a, **k: f(*a, **k)
    189 
    190         if callable(arg):

/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc in time(self, line, cell, local_ns)
   1187         if mode=='eval':
   1188             st = clock2()
-&gt; 1189             out = eval(code, glob, local_ns)
   1190             end = clock2()
   1191         else:

&lt;timed eval&gt; in &lt;module&gt;()

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--&gt; 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--&gt; 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.pyc in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--&gt; 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---&gt; 86                               distributed_function(input_fn))
     87 
     88   return execution_function

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--&gt; 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in _call(self, *args, **kwds)
    492       # In this case we have not created variables on the first call. So we can
    493       # run the first trace but we should fail if variables are created.
--&gt; 494       results = self._stateful_fn(*args, **kwds)
    495       if self._created_variables:
    496         raise ValueError("Creating variables on a non-first call to a function"

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in __call__(self, *args, **kwargs)
   1820   def __call__(self, *args, **kwargs):
   1821     """Calls a graph function specialized to the inputs."""
-&gt; 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-&gt; 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/function.pyc in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/func_graph.pyc in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--&gt; 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/def_function.pyc in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in distributed_function(input_iterator)
     64     """A single step of the distributed execution across replicas."""
     65     x, y, sample_weights = _prepare_feed_values(
---&gt; 66         model, input_iterator, mode)
     67     # Call `Model.{train,test,predict}_on_batch` on every replica passing
     68     # PerReplicas as arguments.  On every replica inside this call, each

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in _prepare_feed_values(model, inputs, mode)
    110     for inputs will always be wrapped in lists.
    111   """
--&gt; 112   inputs, targets, sample_weights = _get_input_from_iterator(inputs)
    113 
    114   # When the inputs are dict, then we want to flatten it in the same order as

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.pyc in _get_input_from_iterator(iterator)
    147   # Validate that all the elements in x and y are of the same type and shape.
    148   dist_utils.validate_distributed_dataset_inputs(
--&gt; 149       distribution_strategy_context.get_strategy(), x, y, sample_weights)
    150   return x, y, sample_weights
    151 

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_distributed_dataset_inputs(distribution_strategy, x, y, sample_weights)
    306   # If each element of x and y are not tensors, we cannot standardize and
    307   # validate the input and targets.
--&gt; 308   x_values_list = validate_per_replica_inputs(distribution_strategy, x)
    309 
    310   if y is not None:

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_per_replica_inputs(distribution_strategy, x)
    354     if not context.executing_eagerly():
    355       # Validate that the shape and dtype of all the elements in x are the same.
--&gt; 356       validate_all_tensor_shapes(x, x_values)
    357     validate_all_tensor_types(x, x_values)
    358 

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.pyc in validate_all_tensor_shapes(x, x_values)
    371 def validate_all_tensor_shapes(x, x_values):
    372   # Validate that the shape of all the elements in x have the same shape
--&gt; 373   x_shape = x_values[0].shape.as_list()
    374   for i in range(1, len(x_values)):
    375     if x_shape != x_values[i].shape.as_list():

/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/tensor_shape.pyc in as_list(self)
   1169     """
   1170     if self._dims is None:
-&gt; 1171       raise ValueError("as_list() is not defined on an unknown TensorShape.")
   1172     return [dim.value for dim in self._dims]
   1173 

ValueError: as_list() is not defined on an unknown TensorShape.
i am not sure where is wrong, please give me a hand.
		</comment>
		<comment id='6' author='vicpara' date='2020-01-17T08:18:23Z'>
		i find, if use tf.GradientTape() to get gradient and train model, it's work fine.
the same TFRecord, just different training mode.
define loss function and optimizer:
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adam()
train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')
set training step function.
def train_step(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x)
        loss = loss_object(y, predictions)
    
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    
    train_loss(loss)
    train_accuracy(y, predictions)
set batch size
datasets = datasets.batch(64)
training model
for epoch in range(1):  
    for x, y in datasets:
        train_step(x, y)
it work fine.
and i find something interesting.
above, i set batch one time, and batch size is 64, so the shape is 64x28x28x1
for x, y in datasets:
    print(x.shape)
    break

# (64, 28, 28, 1)
if i set batch again, the shape will become 64x64x28x28x1
datasets = datasets.batch(64)

for x, y in datasets:
    print(x.shape)
    break

# (64, 64, 28, 28, 1)
if set again, it will raise exception. i don't sure it's bug or not.
		</comment>
		<comment id='7' author='vicpara' date='2020-01-23T18:17:23Z'>
		Closing this issue since we are already tracking this with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24520&gt;#24520&lt;/denchmark-link&gt;
 Thanks!
		</comment>
		<comment id='8' author='vicpara' date='2020-01-23T18:17:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35358&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35358&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='vicpara' date='2020-01-28T16:47:29Z'>
		
datasets = datasets.batch(64)
for x, y in datasets:
    print(x.shape)
    break
if i set batch again, the shape will become 64x64x28x28x1

datasets = datasets.batch(64) doesn't set the batch size. It actually tells the dataset object that at runtime it should batch everything you pass through into batches of 64. If you call batch twice then you get the result above. I think the function works as expected.
		</comment>
		<comment id='10' author='vicpara' date='2020-01-30T01:05:46Z'>
		

datasets = datasets.batch(64)
for x, y in datasets:
    print(x.shape)
    break
if i set batch again, the shape will become 64x64x28x28x1

datasets = datasets.batch(64) doesn't set the batch size. It actually tells the dataset object that at runtime it should batch everything you pass through into batches of 64. If you call batch twice then you get the result above. I think the function works as expected.

Hi. thanks for your reply.
but according &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch&gt;tensorflow document&lt;/denchmark-link&gt;
，it means 『Combines consecutive elements of this dataset into batches.』, and the "batches" from parameter "batch_size", then you get "batch_size" return array every time.
so i think, datasets = datasets.batch(64) is set batch size, tell the dataset object every time get how many record for you need.
&lt;denchmark-link:https://user-images.githubusercontent.com/28851695/73411053-01c66000-433f-11ea-8a2a-d71c8a09117a.png&gt;&lt;/denchmark-link&gt;

if call twice get the result is as expected,  why call third time raise exception?but maybe it's not important, for general we wouldn't do such operation.
		</comment>
		<comment id='11' author='vicpara' date='2020-01-30T01:34:20Z'>
		
Closing this issue since we are already tracking this with #24520 Thanks!

finally, according &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24520&gt;#24520&lt;/denchmark-link&gt;
 , i modify as bellow..
parser function
def parser_tfrecord(tfrecord_example):
    _feature = tf.io.parse_single_example(tfrecord_example, feature_type)
    _feature['image'] = tf.io.parse_tensor(_feature['image'], tf.float64)
   # add this line
    _feature['image'].set_shape((28,28,1))
    return _feature['image'], _feature['label']
then it work fine. thanks for help.
		</comment>
	</comments>
</bug>