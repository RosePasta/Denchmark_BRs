<bug id='33072' author='tcottin' open_date='2019-10-05T22:26:39Z' closed_time='2019-12-12T20:02:15Z'>
	<summary>Distributed training Keras ConvLSTM2D layer with stateful=True failing</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0-dev20191004
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0.130/7.6
GPU model and memory: 2x GeForce GTX 1080 Ti, 10481 MB

Describe the current behavior
Training Keras model with ConvLSTM2D stateful layer fails to train under distributed scope.
If I set stateful to False it distributed learning works.
Error message:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "D:\work\aicomp\challenges\fatigue\ws\stateful_mirrored\src\test.py", line 17, in &lt;module&gt;
    model.fit(dataset, steps_per_epoch=1, epochs=1)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 766, in fit
    use_multiprocessing=use_multiprocessing)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 333, in fit
    total_epochs=epochs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py", line 86, in execution_function
    distributed_function(input_fn))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 554, in __call__
    result = self._call(*args, **kwds)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 600, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 493, in _initialize
    *args, **kwds))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\function.py", line 2320, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\function.py", line 2628, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\function.py", line 2517, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\framework\func_graph.py", line 943, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 435, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py", line 73, in distributed_function
    per_replica_function, args=(x, y, sample_weights))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py", line 764, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py", line 1820, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\mirrored_strategy.py", line 688, in _call_for_each_replica
    fn, args, kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\mirrored_strategy.py", line 200, in _call_for_each_replica
    coord.join(threads)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\training\coordinator.py", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\six.py", line 693, in reraise
    raise value
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\training\coordinator.py", line 297, in stop_on_exception
    yield
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\mirrored_strategy.py", line 909, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\autograph\impl\api.py", line 292, in wrapper
    return func(*args, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py", line 264, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py", line 311, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py", line 252, in _process_single_batch
    training=training))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py", line 127, in _model_loss
    outs = model(inputs, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py", line 759, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\network.py", line 712, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\network.py", line 868, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\layers\convolutional_recurrent.py", line 299, in __call__
    return super(ConvRNN2D, self).__call__(inputs, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\layers\recurrent.py", line 631, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py", line 759, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\layers\convolutional_recurrent.py", line 938, in call
    initial_state=initial_state)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\layers\convolutional_recurrent.py", line 397, in call
    updates.append(K.update(self.states[i], states[i]))
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\keras\backend.py", line 1557, in update
    return state_ops.assign(x, new_x)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\ops\state_ops.py", line 228, in assign
    return ref.assign(value, name=name)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\values.py", line 1040, in assign
    return self._assign_func(f=assign_fn, *args, **kwargs)
  File "D:\work\aicomp\tf2_nightly_venv\lib\site-packages\tensorflow_core\python\distribute\values.py", line 1020, in _assign_func
    variable_type="MirroredVariable"))
ValueError: You must specify an aggregation method to update a MirroredVariable in Replica Context. You can do so by passing an explicit value for argument `aggregation` to tf.Variable(..).e.g. `tf.Variable(..., aggregation=tf.VariableAggregation.SUM)``tf.VariableAggregation` lists the possible aggregation methods.This is required because MirroredVariable should always be kept in sync. When updating them or assigning to them in a replica context, we automatically try to aggregate the values before updating the variable. For this aggregation, we need to know the aggregation method. Another alternative is to not try to update such MirroredVariable in replica context, but in cross replica context. You can enter cross replica context by calling `tf.distribute.get_replica_context().merge_call(merge_fn, ..)`.Inside `merge_fn`, you can then update the MirroredVariable using `tf.distribute.StrategyExtended.update()`.
&lt;/denchmark-code&gt;

Describe the expected behavior
Train model distributed without error.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

from tensorflow.keras.layers import Input, ConvLSTM2D
from tensorflow.keras.models import Model

mirrored_strategy = tf.distribute.MirroredStrategy()

with mirrored_strategy.scope():
    model_input = Input(shape=(None, 3, 3, 1), batch_size=1)
    model = ConvLSTM2D(1, kernel_size=3, stateful=True)(model_input)    
    model = Model(inputs=[model_input], outputs=[model])
    model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta())    
    input_dataset = tf.data.Dataset.from_tensors(tf.random.uniform([1, 3, 3, 1])).batch(1)
    output_dataset = tf.data.Dataset.from_tensors(tf.random.uniform([1, 3, 3, 1])).batch(1)
    dataset = tf.data.Dataset.zip((input_dataset, output_dataset))
    model.fit(dataset, steps_per_epoch=1, epochs=1)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='tcottin' date='2019-10-09T08:52:58Z'>
		Could reproduce the issue with TF Version 2.0. Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/1b2a8bfdef1007a0c70b78f327a8dbd2/33072.ipynb&gt;Gist&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='tcottin' date='2019-12-12T20:02:15Z'>
		We currently &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent.py#L434&gt;don't support&lt;/denchmark-link&gt;
 tf.distribute strategy with stateful RNNs.
		</comment>
		<comment id='3' author='tcottin' date='2019-12-12T20:02:17Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33072&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33072&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='tcottin' date='2020-01-21T02:10:18Z'>
		By which release is the support to be extended? Any plans?
		</comment>
	</comments>
</bug>