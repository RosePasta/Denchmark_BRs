<bug id='9855' author='shuuki4' open_date='2017-05-12T08:47:01Z' closed_time='2017-05-13T07:48:16Z'>
	<summary>Unexpected error at contrib.seq2seq's BeamSearchDecoder</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below):  v1.1.0-rc2-773-g7fa0cf39f
Bazel version (if compiling from source):  0.4.5
CUDA/cuDNN version:  None
GPU model and memory: CPU

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, when the beam width is smaller than number of vocabs.
This is a part of _beam_search_step operation in beam_search_decoder.py:
&lt;denchmark-code&gt;  scores = _get_scores(
      log_probs=total_probs,
      sequence_lengths=new_prediction_lengths,
      length_penalty_weight=length_penalty_weight)

  time = ops.convert_to_tensor(time, name="time")
  # During the first time step we only consider the initial beam
  scores_flat = control_flow_ops.cond(
      time &gt; 0,
      lambda: array_ops.reshape(scores, [batch_size, -1]),
      lambda: scores[:, 0])

  # Pick the next beams according to the specified successors function
  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)
  next_beam_scores.set_shape([static_batch_size, beam_width])
  word_indices.set_shape([static_batch_size, beam_width])
&lt;/denchmark-code&gt;

Since the shape of scores is [batch_size, beam_width, vocab_size],  the shape of scores_flat is[batch_size, vocab_size] at time step 0. However, if k &lt; shape[-1] in nn.top_k operation, it just throws InvalidArgumentError: input must have at least k columns. Thus the code just throws an error and dies.
I think code should be modified to handle cases where vocab_size ** n &lt; beam_width, or at least throw an appropriate error message when the input is vocab_size &lt; beam_width.
	</description>
	<comments>
		<comment id='1' author='shuuki4' date='2017-05-12T15:55:53Z'>
		Nice catch!  Seems like the top_k operation should be shielded with a min.  Would be up for submitting a small PR?
		</comment>
		<comment id='2' author='shuuki4' date='2017-05-13T04:29:26Z'>
		OK, I fixed the issue and made PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/9875&gt;#9875&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>