<bug id='27209' author='jpangburn' open_date='2019-03-27T18:40:08Z' closed_time='2019-04-09T19:10:40Z'>
	<summary>TensorFlowLiteSwift performance problem with bitcode enabled on iOS</summary>
	<description>
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I converted the SpeechCommands example to use the TensorFlowLiteSwift API instead of the C wrapper in the original example.


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.4


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPad Mini 2 real device and iPhone 6s simulator


TensorFlow installed from (source or binary): source


TensorFlow version (use command below): latest commit is 95e72f8 from March 22.


Python version: N/A for this problem


Bazel version (if compiling from source): 0.23.2


GCC/Compiler version (if compiling from source):
$ gcc --version
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.14.sdk/usr/include/c++/4.2.1
Apple LLVM version 10.0.0 (clang-1000.11.45.5)
Target: x86_64-apple-darwin18.5.0


CUDA/cuDNN version: N/A


GPU model and memory: N/A


Describe the current behavior
Compiling the TensorFlowLiteC_framework with bitcode support enabled slows down model inference on the sample model from ~72 ms (without bitcode support) to ~1200 ms (with bitcode support).
Describe the expected behavior
Would be nice if performance was approximately equivalent.
Code to reproduce the issue
Compile the TensorFlowLiteC_framework without bitcode support:
bazel build tensorflow/lite/experimental/c:TensorFlowLiteC_framework -c opt --ios_multi_cpus=x86_64,armv7,arm64
Then for comparison compile it with bitcode support:
bazel build tensorflow/lite/experimental/c:TensorFlowLiteC_framework -c fastbuild --ios_multi_cpus=x86_64,armv7,arm64 --apple_bitcode=embedded --copt=-fembed-bitcode
Use these with the experimental TensorFlowLiteSwift CocoaPod (not yet publicly available, see &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25800&gt;#25800&lt;/denchmark-link&gt;
 for reference) to perform a model inference on a real device or a simulator.  Regardless of debug/release build, if you use the framework with bitcode support in it then performance suffers greatly.
Other info / logs
If it would help to provide my Xcode project, I'm happy to provide it.  The Podfile would need to be modified to locate your own build CocoaPods because the TensorFlowLiteC pod uses the framework in question and it's not yet publicly available.
	</description>
	<comments>
		<comment id='1' author='jpangburn' date='2019-04-06T00:12:41Z'>
		Is -c fastbuild required for bitcode support? In general, we don't really make any promises about performance in debug builds, particularly debug builds running on emulators.
		</comment>
		<comment id='2' author='jpangburn' date='2019-04-06T00:34:46Z'>
		On the referenced issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25800&gt;#25800&lt;/denchmark-link&gt;
 @temrich said we needed that switch for bitcode support at least until bazel 0.24 is available.  You think that switch (vs ) is what's making all the difference?  Nothing to do with bitcode?
Regarding emulators, I think the numbers above were my numbers on a real device.  Simulator is much faster, but with somewhat similar ratios of performance to a real device.
		</comment>
		<comment id='3' author='jpangburn' date='2019-04-09T19:10:40Z'>
		@temrich just released a publicly available TensorFlowLiteSwift pod and it doesn't have this problem.  Performance is the same with/without bitcode enabled so I'm closing this issue.
		</comment>
		<comment id='4' author='jpangburn' date='2019-04-09T19:10:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27209&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27209&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>