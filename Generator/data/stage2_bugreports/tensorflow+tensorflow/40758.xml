<bug id='40758' author='philpearl' open_date='2020-06-24T11:10:31Z' closed_time='2020-07-06T19:00:32Z'>
	<summary>Apparent memory leak when using multiple input tensors with Go</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, 20.04, Mac OS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Nop
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.0.1, 2.2. Bug also present in the master branch.
Python version: Not using python.
Bazel version (if compiling from source): 0.26.1
GCC/Compiler version (if compiling from source): 7.5.0
CUDA/cuDNN version: not using
GPU model and memory: not using

Describe the current behaviour
When serving a model using Go and CPUs where the model has multiple input tensors, memory usage goes up until we run out and restart. The leak is in 'C' memory, not the Go heap.
Describe the expected behaviour
Memory usage does not increase
Standalone code to reproduce the issue
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
There's an apparent C memory leak serving models with Go &amp; CPUs if you use multiple input tensors and use Session.Run. It isn't in fact a "leak" - the executors_ hashmap in tensorflow::DirectSession just grows very large. This is caused by an unfortunate interaction between Go's random map iteration and the keys generated for this hashmap in DirectSession::GetOrCreateExecutor.
The Go session.Run interface takes a map[tf.Output]*tf.Tensor to describe the input tensors. From this the Go TF code extracts a list of input tensor operations. Since in Go map iteration order is random, the order of this list is random and likely changes every time. The session converts this to a list of input names, which remains in random order. When we reach DirectSession:GetOrCreateExecutor the key for the executor cache is partially built from this randomly ordered list of names.
GetOrCreateExecutor actually builds two keys: one in the supplied order and then one in sorted order. Both are kept in the executors_ hashmap. The unsorted version is present as a performance improvement.
The number of possible unique keys generated from n randomly ordered names is n! In my case I have 23 inputs, so 23 names and 23! possibilities. 23! is  approximately 2.58 * 10^22. We rapidly run out of memory storing these unsorted keys.
I think the fix will be to order the inputs in the Go code (in newCRunArgs). I'm planning to submit a PR with a fix along these lines.
	</description>
	<comments>
		<comment id='1' author='philpearl' date='2020-07-06T19:00:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40758&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>