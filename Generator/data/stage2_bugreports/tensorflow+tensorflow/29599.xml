<bug id='29599' author='jsl303' open_date='2019-06-10T15:03:19Z' closed_time='2019-08-29T04:32:13Z'>
	<summary>model.fit_generator(verbose=0/2) prints multiple lines per epoch during validation.</summary>
	<description>
Custom code: Yes (included below)
OS Platform: Debian GNU/Linux 9.8 (stretch) (GNU/Linux 4.9.0-8-amd64 x86_64)
TensorFlow installed from: conda install -c anaconda tensorflow-gpu
TensorFlow version: 1.13.1
Python version: 3.7.1
CUDA/cuDNN version: 10.0
GPU model and memory: Tesla P4 7611MiB
Describe the current behavior
When verbose=0, it should be silent, but it prints out multiple lines during validation. It's same for verbose=2.
Describe the expected behavior
It should be "0 = silent, 1 = progress bar, 2 = one line per epoch."
Code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.utils import Sequence

class CustomCallback(Callback):
	def __init__(self, patience=10, restore_best=True, dir="weights"):
		super().__init__()
		self.best_score = 0.0
		self.best_epoch = 0
		self.best_weights = None
		self.patience = patience
		self.restore_best = restore_best

	def on_epoch_end(self, epoch, logs={}):
		score = logs["val_acc"]
		if score&gt;self.best_score:
			self.best_score = score
			self.best_epoch = epoch
			self.best_weights = self.model.get_weights()
			print(f"\nBest Score: {self.best_score*100:.2f}")
		else: print(f"\nBest Epoch: {self.best_epoch+1}, Best Score: {self.best_score*100:.2f}")

		if self.patience&gt;0 and epoch-self.best_epoch &gt;= self.patience:
			print(f"\nStopping... Best Epoch: {self.best_epoch+1}, Best Score: {self.best_score*100:.2f}")
			self.stopped_epoch = epoch
			self.model.stop_training = True
			if self.restore_best: 		self.model.set_weights(self.best_weights)
    
class DataGenerator(Sequence):
	def __init__(self,x, y, batch_size=32):
		self.x = x
		self.y = y
		self.batch_size = batch_size
		self.on_epoch_end()

	def __len__(self):
		return int(np.ceil(len(self.x) / float(self.batch_size)))

	def on_epoch_end(self):
		self.indexes = np.arange(len(self.x))
		np.random.shuffle(self.indexes)
	
	def __getitem__(self, index):
		indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
		x_batch = self.x[indexes]
		y_batch = self.y[indexes]
		return x_batch, y_batch

def dense_model(input_shape, output_shape):
	inputs = Input(input_shape)
	x = Flatten()(inputs)
	x = Dense(300, activation='relu')(x)
	x = Dense(100, activation="relu")(x)
	outputs = Dense(output_shape, activation='softmax')(x)
	model = Model(inputs=inputs, outputs=outputs)
	model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
	return model

(x_train, y_train), (x_test, y_test) = mnist.load_data()
height, width = 28, 28
input_shape = (height, width)
output_shape = 10
x_train = x_train/255
x_test = x_test/255
y_train = to_categorical(y_train, output_shape)
y_test = to_categorical(y_test, output_shape)
model = dense_model(input_shape, output_shape)
history = model.fit_generator(DataGenerator(x_train, y_train), epochs=12, validation_data=DataGenerator(x_test, y_test), verbose=0)
&lt;/denchmark-code&gt;

Other info / logs
Epoch 1/12 1/313 [..............................] - ETA: 17s - loss: 0.1513 - acc: 0.9688 25/313 [=&gt;............................] - ETA: 1s - loss: 0.1436 - acc: 0.9525 48/313 [===&gt;..........................] - ETA: 0s - loss: 0.1517 - acc: 0.9479 ...
	</description>
	<comments>
		<comment id='1' author='jsl303' date='2019-06-11T08:32:46Z'>
		&lt;denchmark-link:https://github.com/jsl303&gt;@jsl303&lt;/denchmark-link&gt;
 Please provide minimal code snippet to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='jsl303' date='2019-06-11T20:39:05Z'>
		Yes, I provided the code.
		</comment>
		<comment id='3' author='jsl303' date='2019-06-12T10:26:54Z'>
		&lt;denchmark-link:https://github.com/jsl303&gt;@jsl303&lt;/denchmark-link&gt;
 I tried reproducing the issue on colab with Tf-gpu 1.13.1 but I am unable to reproduce it. Can you help me to reproduce the reported issue. Thanks!
		</comment>
		<comment id='4' author='jsl303' date='2019-06-14T15:06:11Z'>
		It's strange. In Notebook environment, nothing gets printed as expected.

However, if I run as a script, it prints out the validation.

I also tried on colab, nothing gets printed.

I tried on Kaggle as a python script as well as my local machine, then
validation result gets printed.

Maybe Jupyter suppresses the output?

Could you try on your local machine with just command line? It's a very
simple, so it shouldn't take long at all.

Thanks!
		</comment>
		<comment id='5' author='jsl303' date='2019-08-29T04:32:13Z'>
		&lt;denchmark-link:https://github.com/jsl303&gt;@jsl303&lt;/denchmark-link&gt;
 I tried running in Spyder IDE, Jupyter and google colab and I don't see those lines of output. It may be due to some logging settings.
Sorry, I'm going to close this issue because I don't think it's feasible for us to fix anything in Tensorflow to resolve. Feel free to open a new feature request or re-open if you feel strongly about that. Thanks!
		</comment>
		<comment id='6' author='jsl303' date='2019-08-29T04:32:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29599&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29599&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>