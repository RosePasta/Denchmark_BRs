<bug id='9234' author='yaroslavvb' open_date='2017-04-15T07:27:46Z' closed_time='2018-09-23T20:38:02Z'>
	<summary>Segfaults/NaN's in SVD</summary>
	<description>
I'm getting failures trying to run SVD on a particular matrix. The result is either all NaN's for u matrix, or it's segfaults like below.
To reproduce, run this script in Python3: &lt;denchmark-link:https://github.com/yaroslavvb/stuff/blob/master/svd_test.py&gt;https://github.com/yaroslavvb/stuff/blob/master/svd_test.py&lt;/denchmark-link&gt;

I can't see anything special about this matrix beside the fact that it's badly conditioned. IE, I can perform SVD on this matrix in Mathematica &lt;denchmark-link:https://www.wolframcloud.com/objects/f16d71a7-cc47-4a3d-b686-da440670eed3&gt;fine&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;

&lt;denchmark-code&gt; #0  0x00007fffe320e121 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::perturbCol0(Eigen::Ref&lt;Eigen::Array&lt;float, -1, 1, 0, -1, 1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt; const&amp;, Eigen::Ref&lt;Eigen::Array&lt;float, -1, 1, 0, -1, 1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt; const&amp;, Eigen::Ref&lt;Eigen::Array&lt;long, 1, -1, 1, 1, -1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt; const&amp;, Eigen::Matrix&lt;float, -1, 1, 0, -1, 1&gt; const&amp;, Eigen::Ref&lt;Eigen::Array&lt;float, -1, 1, 0, -1, 1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt; const&amp;, Eigen::Ref&lt;Eigen::Array&lt;float, -1, 1, 0, -1, 1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt; const&amp;, Eigen::Ref&lt;Eigen::Array&lt;float, -1, 1, 0, -1, 1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt;) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #1  0x00007fffe320fa81 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::computeSVDofM(long, long, Eigen::Matrix&lt;float, -1, -1, 0, -1, -1&gt;&amp;, Eigen::Matrix&lt;float, -1, 1, 0, -1, 1&gt;&amp;, Eigen::Matrix&lt;float, -1, -1, 0, -1, -1&gt;&amp;) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #2  0x00007fffe321e21c in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #3  0x00007fffe321dbb8 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #4  0x00007fffe32220bd in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::compute(Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; const&amp;, unsigned int) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #5  0x00007fffe32227a1 in tensorflow::SvdOp&lt;float&gt;::ComputeMatrix(tensorflow::OpKernelContext*, tensorflow::gtl::InlinedVector&lt;Eigen::Map&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; const, 0, Eigen::Stride&lt;0, 0&gt; &gt;, 4&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;Eigen::Map&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt;, 0, Eigen::Stride&lt;0, 0&gt; &gt;, 4&gt;*) ()                                                                 from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so                                       #6  0x00007fffe3228c75 in tensorflow::LinearAlgebraOp&lt;float&gt;::ComputeTensorSlice(tensorflow::OpKernelContext*, long long, tensorflow::gtl::InlinedVector&lt;tensorflow::Tensor const*, 4&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;tensorflow::TensorShape, 4&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;tensorflow::Tensor*, 4&gt; const&amp;, tensorflow::gtl::InlinedVector&lt;tensorflow::TensorShape, 4&gt; const&amp;) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so



&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='yaroslavvb' date='2017-06-16T21:34:19Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 Do you want to take a look or triage further?
		</comment>
		<comment id='2' author='yaroslavvb' date='2017-09-15T20:24:35Z'>
		I'm also experiencing this issue, though only segfaults. np.linalg.svd works on the same matrices, but calling with tf.py_func is of course much slower than the "native" tf function.
		</comment>
		<comment id='3' author='yaroslavvb' date='2017-09-15T20:35:56Z'>
		&lt;denchmark-link:https://github.com/strubell&gt;@strubell&lt;/denchmark-link&gt;
 I've had good luck with SVD through numpy. Because SVD is O(n^3) operation, the O(n^2) overhead of copying things between scipy/TF becomes negligible for 1000x1000 mats or larger. Scipy/mkl version of SVD is considerably faster than TF version due to multi-threading, and the few crashes I've seen with scipy can be worked around by setting MKL_NUM_THREADS to lower number (ie, 15)
You can do something like &lt;denchmark-link:https://github.com/yaroslavvb/stuff/blob/dcc5e8d63ee0aaa7052d061e4fd155aabd2dac7f/whitening_util.py#L816&gt;SvdWrapper&lt;/denchmark-link&gt;
 to easily switch between TensorFlow and scipy versions of SVD , example usage is in &lt;denchmark-link:https://gist.github.com/yaroslavvb/3894d69491eb8db444fc6698d89cb48e&gt;kfac_example&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='yaroslavvb' date='2017-09-15T20:43:51Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 maybe long term solution to speed/correctness is to make gesdd available in TensorFlow? Either new implementation, or MKL version -- &lt;denchmark-link:https://software.intel.com/en-us/mkl-developer-reference-fortran-gesdd?language=en&gt;gesdd&lt;/denchmark-link&gt;
 . There's also &lt;denchmark-link:https://software.intel.com/en-us/mkl-developer-reference-c-gesvd&gt;gesvd&lt;/denchmark-link&gt;
 which may be more robust, but also takes 3x longer
		</comment>
		<comment id='5' author='yaroslavvb' date='2017-09-22T00:14:37Z'>
		I just reran the test in latest TensorFlow and it works if you use GPU.
On CPU I still get NaN's (there should be no NaNs)
&lt;denchmark-code&gt;export CUDA_VISIBLE_DEVICES=
python svd_test.py

u any NaNs: True
u all NaNs: True
matrix0 any NaNs: False
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='yaroslavvb' date='2017-09-22T18:19:17Z'>
		&lt;denchmark-link:https://github.com/yaroslavvb&gt;@yaroslavvb&lt;/denchmark-link&gt;
 Cool! Latest as in head or release (1.3)?
		</comment>
		<comment id='7' author='yaroslavvb' date='2017-09-22T18:32:48Z'>
		head, it looks like GPU op was added recently
		</comment>
		<comment id='8' author='yaroslavvb' date='2017-10-10T14:24:33Z'>
		&lt;denchmark-link:https://github.com/strubell&gt;@strubell&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/yaroslavvb&gt;@yaroslavvb&lt;/denchmark-link&gt;
 FYI if you use py_func on a CPU tensor there's no overhead to copy it back and forth between tf and numpy in most cases (we only copy now if the tensor is not in column-order), and since numpy doesn't hold the gil during SVD you shouldn't see too much python overhead.
		</comment>
		<comment id='9' author='yaroslavvb' date='2017-10-10T14:54:03Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 we no longer need to do numpy tricks to force alignment?
		</comment>
		<comment id='10' author='yaroslavvb' date='2017-10-10T15:07:43Z'>
		You only need to force alignment when going from numpy to tensorflow, not
the other way around. I assume when you take the SVD you're not sending the
full U, S, and V matrices back but something smaller.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Oct 10, 2017 at 8:00 AM, Yaroslav Bulatov ***@***.***&gt; wrote:
 @alextp &lt;https://github.com/alextp&gt; we no longer need to do numpy tricks
 to force alignment?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#9234 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxV72ppi3AVEF_pp7HIRv9c4iQs3mks5sq4Z4gaJpZM4M-R0j&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='11' author='yaroslavvb' date='2017-10-11T15:25:44Z'>
		BTW, running this example under debug mode triggers a debug assert inside Eigen
python: external/eigen_archive/Eigen/src/Core/DenseCoeffsBase.h:180: Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::CoeffReturnType Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::operator()(Eigen::Index) const [with Derived = Eigen::Ref&lt;Eigen::Array&lt;long int, 1, -1&gt; &gt;; Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::CoeffReturnType = const long int&amp;; Eigen::Index = long int]: Assertion index &gt;= 0 &amp;&amp; index &lt; size()' failed.
`
index is -1
full strack trace
&lt;denchmark-code&gt;#0  0x00007ffff6a19428 in __GI_raise (sig=sig@entry=6)
    at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007ffff6a1b02a in __GI_abort () at abort.c:89
#2  0x00007ffff6a11bd7 in __assert_fail_base (fmt=&lt;optimized out&gt;, 
    assertion=assertion@entry=0x7fffe90b0dd7 "index &gt;= 0 &amp;&amp; index &lt; size()", 
    file=file@entry=0x7fffe90b0a60 "external/eigen_archive/Eigen/src/Core/DenseCoeffsBase.h", line=line@entry=180, 
    function=function@entry=0x7fffe90f83a0 &lt;Eigen::DenseCoeffsBase&lt;Eigen::Ref&lt;Eigen::Array&lt;long, 1, -1, 1, 1, -1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt;, 0&gt;::operator()(long) const::__PRETTY_FUNCTION__&gt; "Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::CoeffReturnType Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::operator()(Eigen::Index) const [with Derived = Eigen::Ref&lt;Eigen::Array&lt;long int, 1, -1&gt; &gt;; Eigen::DenseCoeffsBas"...) at assert.c:92
#3  0x00007ffff6a11c82 in __GI___assert_fail (
    assertion=0x7fffe90b0dd7 "index &gt;= 0 &amp;&amp; index &lt; size()", 
    file=0x7fffe90b0a60 "external/eigen_archive/Eigen/src/Core/DenseCoeffsBase.h", line=180, 
    function=0x7fffe90f83a0 &lt;Eigen::DenseCoeffsBase&lt;Eigen::Ref&lt;Eigen::Array&lt;long, 1, -1, 1, 1, -1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt;, 0&gt;::operator()(long) const::__PRETTY_FUNCTION__&gt; "Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::CoeffReturnType Eigen::DenseCoeffsBase&lt;Derived, 0&gt;::operator()(Eigen::Index) const [with Derived = Eigen::Ref&lt;Eigen::Array&lt;long int, 1, -1&gt; &gt;; Eigen::DenseCoeffsBas"...)
    at assert.c:101
#4  0x00007fffe36caf0a in Eigen::DenseCoeffsBase&lt;Eigen::Ref&lt;Eigen::Array&lt;long, 1, -1, 1, 1, -1&gt;, 0, Eigen::InnerStride&lt;1&gt; &gt;, 0&gt;::operator() (
    this=0x7fff9cff6850, index=-1)
    at external/eigen_archive/Eigen/src/Core/DenseCoeffsBase.h:180
#5  0x00007fffe386ece0 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::perturbCol0 (this=0x7fff9cff7540, col0=..., diag=..., perm=..., 
    singVals=..., shifts=..., mus=..., zhat=...)
    at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:908
#6  0x00007fffe386b161 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::computeSVDofM (this=0x7fff9cff7540, firstCol=393, n=391, U=..., 
    singVals=..., V=...) at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:637
#7  0x00007fffe386806f in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::divide (this=0x7fff9cff7540, firstCol=393, lastCol=783, firstRowW=393, 
    firstColW=393, shift=0)
    at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:533
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
#8  0x00007fffe3867253 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::divide (this=0x7fff9cff7540, firstCol=0, lastCol=783, firstRowW=0, 
    firstColW=0, shift=0) at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:428
#9  0x00007fffe38661f3 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::compute (this=0x7fff9cff7540, matrix=..., computationOptions=40)
    at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:277
#10 0x00007fffe3865a67 in Eigen::BDCSVD&lt;Eigen::Matrix&lt;float, -1, -1, 1, -1, -1&gt; &gt;::BDCSVD (this=0x7fff9cff7540, matrix=..., computationOptions=40)
    at external/eigen_archive/Eigen/src/SVD/BDCSVD.h:136
#11 0x00007fffe386587a in tensorflow::SvdOp&lt;float&gt;::ComputeMatrix (
    this=0x255f7d0, context=0x7fff9cff8900, inputs=..., 
    outputs=0x7fff9cff7770) at ./tensorflow/core/kernels/svd_op_impl.h:88
#12 0x00007fffe38afc66 in tensorflow::LinearAlgebraOp&lt;float&gt;::ComputeTensorSlice (this=0x255f7d0, context=0x7fff9cff8900, matrix_index=0, inputs=..., 
    input_matrix_shapes=..., outputs=..., output_matrix_shapes=...)
    at tensorflow/core/kernels/linalg_ops_common.cc:247
#13 0x00007fffe38b4b5a in tensorflow::LinearAlgebraOp&lt;float&gt;::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}::operator()(long long, long long) const (__closure=0x7fff78000c20, begin=0, end=1)
    at tensorflow/core/kernels/linalg_ops_common.cc:104
#14 0x00007fffe38b73aa in std::_Function_handler&lt;void (long long, long long), tensorflow::LinearAlgebraOp&lt;float&gt;::Compute(tensorflow::OpKernelContext*)::{lambda(long long, long long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long long&amp;&amp;, std::_Any_data const&amp;) (__functor=..., 
    __args#0=&lt;unknown type in /home/yaroslav/anaconda3/envs/tf13dbg/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x1373b2da, DIE 0x137a9da2&gt;, 
    __args#1=&lt;unknown type in /home/yaroslav/anaconda3/envs/tf13dbg/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x1373b2da, DIE 0x137a9da7&gt;) at /usr/include/c++/5/functional:1871
#15 0x00007fffe5606ec7 in std::function&lt;void (long long, long long)&gt;::operator()(long long, long long) const (this=0x7fff9cff7e00, __args#0=0, __args#1=1)
    at /usr/include/c++/5/functional:2267
#16 0x00007fffe814d296 in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;)::{lambda(long, long)#1}::operator()(long, long) const (__closure=0x7fff9cff7ba0, first=0, 
    last=1) at tensorflow/core/lib/core/threadpool.cc:100
#17 0x00007fffe814f744 in std::_Function_handler&lt;void (long, long), tensorflow:---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
:thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;)::{lambda(long, long)#1}&gt;::_M_invoke(std::_Any_data const&amp;, long&amp;&amp;, std::_Any_data const&amp;) (__functor=..., 
    __args#0=&lt;unknown type in /home/yaroslav/anaconda3/envs/tf13dbg/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x45a6c0ff, DIE 0x45a8a9d0&gt;, 
    __args#1=&lt;unknown type in /home/yaroslav/anaconda3/envs/tf13dbg/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, CU 0x45a6c0ff, DIE 0x45a8a9d5&gt;) at /usr/include/c++/5/functional:1871
#18 0x00007fffe2537f55 in std::function&lt;void (long, long)&gt;::operator()(long, long) const (this=0x7fff9cff7ba0, __args#0=0, __args#1=1)
    at /usr/include/c++/5/functional:2267
#19 0x00007fffe2537849 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&amp;, std::function&lt;long (long)&gt;, std::function&lt;void (long, long)&gt;) const (this=0x7fff9cff7c10, n=1, cost=..., block_align=..., f=...)
    at external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h:177
#20 0x00007fffe814ce49 in Eigen::ThreadPoolDevice::parallelFor(long, Eigen::TensorOpCost const&amp;, std::function&lt;void (long, long)&gt;) const (
    this=0x7fff9cff7c10, n=1, cost=..., f=...)
    at external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h:257
#21 0x00007fffe814d4c8 in tensorflow::thread::ThreadPool::Impl::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;) (
    this=0x106d810, total=1, cost_per_unit=5782683648, fn=...)
    at tensorflow/core/lib/core/threadpool.cc:100
#22 0x00007fffe814bec6 in tensorflow::thread::ThreadPool::ParallelFor(long long, long long, std::function&lt;void (long long, long long)&gt;) (this=0x1044540, 
    total=1, cost_per_unit=5782683648, fn=...)
    at tensorflow/core/lib/core/threadpool.cc:128
#23 0x00007fffe60ef1fc in tensorflow::Shard(int, tensorflow::thread::ThreadPool*, long long, long long, std::function&lt;void (long long, long long)&gt;) (
    max_parallelism=12, workers=0x1044540, total=1, cost_per_unit=5782683648, 
    work=...) at tensorflow/core/util/work_sharder.cc:35
#24 0x00007fffe38af084 in tensorflow::LinearAlgebraOp&lt;float&gt;::Compute (
    this=0x255f7d0, context=0x7fff9cff8900)
    at tensorflow/core/kernels/linalg_ops_common.cc:109
#25 0x00007fffe5786d8b in tensorflow::ThreadPoolDevice::Compute (
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
    this=0xcdd990, op_kernel=0x255f7d0, context=0x7fff9cff8900)
    at tensorflow/core/common_runtime/threadpool_device.cc:59
#26 0x00007fffe572a36c in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0x255dd60, tagged_node=..., scheduled_usec=0)
    at tensorflow/core/common_runtime/executor.cc:1652
#27 0x00007fffe572c358 in tensorflow::(anonymous namespace)::ExecutorState::&lt;lambda()&gt;::operator()(void) const (__closure=0x255eb60)
    at tensorflow/core/common_runtime/executor.cc:2055
#28 0x00007fffe5733284 in std::_Function_handler&lt;void(), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(const TaggedNodeSeq&amp;, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::&lt;lambda()&gt; &gt;::_M_invoke(const std::_Any_data &amp;) (__functor=...)
    at /usr/include/c++/5/functional:1871
#29 0x00007fffe1caabbe in std::function&lt;void ()&gt;::operator()() const (
    this=0x2559f00) at /usr/include/c++/5/functional:2267
#30 0x00007fffe814d1c6 in tensorflow::thread::EigenEnvironment::ExecuteTask (
    this=0x2522338, t=...) at tensorflow/core/lib/core/threadpool.cc:81
#31 0x00007fffe814f409 in Eigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::WorkerLoop (this=0x2522330, thread_id=6)
    at external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:232
#32 0x00007fffe814dc36 in Eigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}::operator()() const ()
    at external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:65
#33 0x00007fffe8150758 in std::_Function_handler&lt;void (), Eigen::NonBlockingThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) (__functor=...) at /usr/include/c++/5/functional:1871
#34 0x00007fffe1caabbe in std::function&lt;void ()&gt;::operator()() const (
    this=0x2553a80) at /usr/include/c++/5/functional:2267
#35 0x00007fffe814cf2f in tensorflow::thread::EigenEnvironment::CreateThread(std::function&lt;void ()&gt;)::{lambda()#1}::operator()() const (__closure=0x2553a80)
    at tensorflow/core/lib/core/threadpool.cc:56
#36 0x00007fffe814e6ac in std::_Function_handler&lt;void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function&lt;void ()&gt;)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) (__functor=...) at /usr/include/c++/5/functional:1871


&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='yaroslavvb' date='2018-02-07T23:54:37Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 any update?
		</comment>
		<comment id='13' author='yaroslavvb' date='2018-09-08T23:59:56Z'>
		Just tried it out on with latest MKL-compiled TensorFlow on Amazon instance, and crash was not there -- &lt;denchmark-link:https://github.com/yaroslavvb/stuff/blob/master/linalg-benchmark/launch_tensorflow_svd_crash.py&gt;https://github.com/yaroslavvb/stuff/blob/master/linalg-benchmark/launch_tensorflow_svd_crash.py&lt;/denchmark-link&gt;

However I suspect that takes a different code path (MKL)
		</comment>
		<comment id='14' author='yaroslavvb' date='2018-09-23T18:41:17Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
	</comments>
</bug>