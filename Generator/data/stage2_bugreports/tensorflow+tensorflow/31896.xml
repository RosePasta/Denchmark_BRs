<bug id='31896' author='LaCandela' open_date='2019-08-22T15:10:02Z' closed_time='2020-05-04T04:08:03Z'>
	<summary>tf-2.0.0rc0-gpu tf.dataset bug</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code: yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): docker image
TensorFlow version (use command below): tensorflow/tensorflow:2.0.0rc0-gpu-py3
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CUDA 10
GPU model and memory:

Describe the current behavior
I am using tf.keras for training with the dataset api and TFrecords. At the beginning of the training the dataset api tries to load and shuffle the whole training dataset so the memory fills up and the process dies.  I cannot train my model at all. I am not using any .shuffle() calls in my dataset pipeline.
Describe the expected behavior
The dataset should not load and shuffle the records unless the .shuffle() call is issued.
Code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
import os
import cv2
import tensorflow.keras.layers as K

def extract_fn(data_record):
    features = {
        'data': tf.io.FixedLenFeature([], tf.string)
    }
    sample = tf.io.parse_single_example(data_record, features)
    data = tf.image.decode_image(sample['data'])

    return data, 1.


class DataGenerator(tf.keras.utils.Sequence):

    def __init__(self, dataset_iterator, len):
        self.dataset_iterator = dataset_iterator
        self.len = len

    def __len__(self):
        # number of batches per epoch
        return self.len

    def __getitem__(self, index):
        # Generate one batch of data

        next_element = next(self.dataset_iterator)
        x = next_element[0]
        y = next_element[1]

        return x, y


with tf.io.TFRecordWriter("dummy_dataset.tfrecords") as writer:
    data = np.float32(np.random.random(size=(1000, 1000, 3)) * 255)
    data = cv2.imencode(".png", data)[1].tostring()
    example = tf.train.Example(features=tf.train.Features(
        feature={'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[data]))}))
    for i in range(10000):
        writer.write(example.SerializeToString())

dataset = tf.data.TFRecordDataset(["dummy_dataset.tfrecords"])
dataset = dataset.map(extract_fn)
n_batch = 3
dataset = dataset.batch(batch_size=n_batch, drop_remainder=True)

dataset = dataset.repeat(5)
dataset_iterator = iter(dataset)
next_element = next(dataset_iterator)

data_generator = DataGenerator(dataset_iterator, int(10000/n_batch))

input = K.Input(shape=(1000, 1000, 3), name='input')
net = K.Conv2D(1, 3, activation='sigmoid')(input)
output = K.GlobalAveragePooling2D()(net)
model = tf.keras.models.Model(inputs=input, outputs=output)

model.compile(loss='mse', optimizer='sgd')

model.fit(x=data_generator, epochs=10)
&lt;/denchmark-code&gt;

Other info / logs
note that code generates about 28GB dummy data in a tfrecord file since I am having this issue when I am trying to use the dataset api with tf.keras.utils.Sequence on a tfrecord file.
EDIT(robieta): code formatting.
	</description>
	<comments>
		<comment id='1' author='LaCandela' date='2019-08-23T04:09:51Z'>
		&lt;denchmark-link:https://github.com/LaCandela&gt;@LaCandela&lt;/denchmark-link&gt;
 ,
In order to expedite the trouble-shooting process, please provide complete code snippet to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='LaCandela' date='2019-08-29T11:50:02Z'>
		I found that the issue arises when I am trying to use tf.keras.utils.Sequence to create a data generator and using that to feed the model.fit. I provided a small script. Please note that it generates about 28GB dummy data in a tfrecord file since I am having this issue when I am trying to use the dataset api with tf.keras.utils.Sequence on a tfrecord file. I need to use the tf.keras.utils.Sequence because it allows me to do some preprocessing that I can performe on GPU. As best I know, I cannot do that with dataset.map().
		</comment>
		<comment id='3' author='LaCandela' date='2019-10-07T08:40:04Z'>
		Hi! I was wondering if there was any progress in this issue...
It still exists in the recently released 2.0 docker image.
		</comment>
		<comment id='4' author='LaCandela' date='2019-10-07T19:16:44Z'>
		&lt;denchmark-link:https://github.com/LaCandela&gt;@LaCandela&lt;/denchmark-link&gt;
 I reduced the dummy_data size and ran it with . I don't see any issues. &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/007ed87a42cce8f0993933fd6c1c8b83/tf31896.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the gist. Thanks!
		</comment>
		<comment id='5' author='LaCandela' date='2019-10-08T15:23:47Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Well, My TFrecords file size for the training is in the range of ~30GB and I cannot reduce that. The dataset api tries to fill a shuffle buffer which I am not calling at all (no dataset.shuffle() call) and quickly fills up my memory. It seems as if the whole TFrecords is loaded into memory. The issue is still present in TF2.0.
		</comment>
		<comment id='6' author='LaCandela' date='2019-10-21T23:38:29Z'>
		Why are using DataGenerator instead of passing your dataset directly to model.fit?
		</comment>
		<comment id='7' author='LaCandela' date='2019-10-22T08:51:42Z'>
		Because I want to do the preprocessing on the GPU and if I use the dataset.map() function the operations are performed on the CPU (as best I know). Now, I have the feeling that it is against the Tensorflow "mindset" but it would be great to have the possibility to experiment with the preproc (augmentation, ground truth generation) on the GPU approach.
		</comment>
		<comment id='8' author='LaCandela' date='2019-10-22T18:53:06Z'>
		The map dataset op will be placed on CPU but ops inside of the user-defined function passed into the map transformation can be placed on GPU.
As for the problem you are seeing, my best guess is that something in Keras internals might end up prefetching the contents of the entire generator ahead of time. &lt;denchmark-link:https://github.com/robieta&gt;@robieta&lt;/denchmark-link&gt;
 could you please comment on what could be going on? Thanks.
		</comment>
		<comment id='9' author='LaCandela' date='2019-10-22T20:24:27Z'>
		I believe the issue is that shuffle defaults to True in model.fit, which will call .shuffle(len(sequence)) internally. (Prefetching all of the elements.) It does, however, strike me that for a Sequence this is not very efficient. (Since we can just directly index said sequence) I am already working on the data adapter; I will update it accordingly.
		</comment>
		<comment id='10' author='LaCandela' date='2020-04-20T11:56:03Z'>
		&lt;denchmark-link:https://github.com/LaCandela&gt;@LaCandela&lt;/denchmark-link&gt;
 Could you check with latest TF version and let us know if the problem still persists or not.    Thanks!
		</comment>
		<comment id='11' author='LaCandela' date='2020-04-27T04:52:09Z'>
		&lt;denchmark-link:https://github.com/LaCandela&gt;@LaCandela&lt;/denchmark-link&gt;
  Any updates regarding this issue? Thanks!
		</comment>
		<comment id='12' author='LaCandela' date='2020-05-04T04:08:03Z'>
		&lt;denchmark-link:https://github.com/LaCandela&gt;@LaCandela&lt;/denchmark-link&gt;
  Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='13' author='LaCandela' date='2020-05-04T04:08:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31896&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31896&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>