<bug id='36996' author='chn-lee-yumi' open_date='2020-02-23T18:37:55Z' closed_time='2020-06-02T08:05:19Z'>
	<summary>[Colab][TF2.x] Socket closed - Error received from peer</summary>
	<description>
I was trying to train an GAN. Here is the code:
(Full code on Colab: &lt;denchmark-link:https://colab.research.google.com/drive/1TUKZnOEPT8C8mVJ1iK90n32qT2SiJ6Xo&gt;https://colab.research.google.com/drive/1TUKZnOEPT8C8mVJ1iK90n32qT2SiJ6Xo&lt;/denchmark-link&gt;
)
with strategy.scope():
    # generator_model
    generator_model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(512, activation='relu', input_shape=noise_shape),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.Dense(784, activation='tanh'),
        tf.keras.layers.Reshape(img_shape)
    ])
    generator_model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),
                            loss='binary_crossentropy',
                            metrics=['accuracy'])
    generator_model.summary()

    # discriminator_model
    discriminator_model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=img_shape),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.Dropout(0.1),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid'),
    ])
    discriminator_model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),
                                loss='binary_crossentropy')
    discriminator_model.summary()

    # combined_model
    z = tf.keras.layers.Input(shape=noise_shape)
    discriminator_model.trainable = False 
    valid = discriminator_model(generator_model(z)) 
    combined_model = tf.keras.models.Model(z, valid) 
    combined_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))
    combined_model.summary()

# train
for epoch in range(10000):
    idx = np.random.randint(0, x_train.shape[0], batch_size)
    imgs = x_train[idx]
    noise = np.random.normal(0, 1, (batch_size, 100))
    gen_imgs = generator_model.predict(noise.astype(np.float32))

    # train discriminator_model
    d_loss_real = discriminator_model.fit(imgs.astype(np.float32), np.ones((batch_size, 1)))
    d_loss_fake = discriminator_model.fit(gen_imgs.astype(np.float32), np.zeros((batch_size, 1)))
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # train combined_model
    noise = np.random.normal(0, 1, (batch_size * 2, 100))
    valid_y = np.array([1] * batch_size * 2)  
    g_loss = combined_model.fit(noise.astype(np.float32), valid_y)
When I run, it throws out Socket closed.
Train on 128 samples
 32/128 [======&gt;.......................] - ETA: 7s
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
&lt;ipython-input-1-5ba8c95500e1&gt; in &lt;module&gt;()
     82 
     83     # train discriminator_model
---&gt; 84     d_loss_real = discriminator_model.fit(imgs.astype(np.float32), np.ones((batch_size, 1)))
     85     d_loss_fake = discriminator_model.fit(gen_imgs.astype(np.float32), np.zeros((batch_size, 1)))
     86     d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

10 frames
/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--&gt; 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--&gt; 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--&gt; 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---&gt; 98                               distributed_function(input_fn))
     99 
    100   return execution_function

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in map_structure(func, *structure, **kwargs)
    566 
    567   return pack_sequence_as(
--&gt; 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in &lt;listcomp&gt;(.0)
    566 
    567   return pack_sequence_as(
--&gt; 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in _non_none_constant_value(v)
    128 
    129 def _non_none_constant_value(v):
--&gt; 130   constant_value = tensor_util.constant_value(v)
    131   return constant_value if constant_value is not None else v
    132 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py in constant_value(tensor, partial)
    820   """
    821   if isinstance(tensor, ops.EagerTensor):
--&gt; 822     return tensor.numpy()
    823   if not is_tensor(tensor):
    824     return tensor

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in numpy(self)
    940     """
    941     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--&gt; 942     maybe_arr = self._numpy()  # pylint: disable=protected-access
    943     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    944 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in _numpy(self)
    908       return self._numpy_internal()
    909     except core._NotOkStatusException as e:
--&gt; 910       six.raise_from(core._status_to_exception(e.code, e.message), None)
    911 
    912   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: Socket closed
Additional GRPC error information:
{"created":"@1582482234.677879877","description":"Error received from peer","file":"external/grpc/src/core/lib/surface/call.cc","file_line":1039,"grpc_message":"Socket closed","grpc_status":14}
	</description>
	<comments>
		<comment id='1' author='chn-lee-yumi' date='2020-02-23T19:10:01Z'>
		After some debug, I simplify the code. It may easier to be analyzed.
Colab link: &lt;denchmark-link:https://colab.research.google.com/drive/1ZhbfF0jqtOU2Gz5k1-M_-T-frQQ10v-D&gt;https://colab.research.google.com/drive/1ZhbfF0jqtOU2Gz5k1-M_-T-frQQ10v-D&lt;/denchmark-link&gt;

%tensorflow_version 2.x

import numpy as np
import tensorflow as tf
import os

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()

with strategy.scope():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(1, activation='sigmoid'),
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy')

d_loss_real = model.fit(x_train.astype(np.float32), np.ones((x_train.shape[0],1)))
It will throw the same error.
&lt;denchmark-code&gt;WARNING:tensorflow:TPU system 10.77.68.2:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.
WARNING:tensorflow:TPU system 10.77.68.2:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.
INFO:tensorflow:Initializing the TPU system: 10.77.68.2:8470
INFO:tensorflow:Initializing the TPU system: 10.77.68.2:8470
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
Train on 60000 samples
   32/60000 [..............................] - ETA: 57:25
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
&lt;ipython-input-4-75afcd6f6fcd&gt; in &lt;module&gt;()
     19     model.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy')
     20 
---&gt; 21 d_loss_real = model.fit(x_train.astype(np.float32), np.ones((x_train.shape[0],1)))

10 frames
/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--&gt; 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--&gt; 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--&gt; 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---&gt; 98                               distributed_function(input_fn))
     99 
    100   return execution_function

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in map_structure(func, *structure, **kwargs)
    566 
    567   return pack_sequence_as(
--&gt; 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py in &lt;listcomp&gt;(.0)
    566 
    567   return pack_sequence_as(
--&gt; 568       structure[0], [func(*x) for x in entries],
    569       expand_composites=expand_composites)
    570 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py in _non_none_constant_value(v)
    128 
    129 def _non_none_constant_value(v):
--&gt; 130   constant_value = tensor_util.constant_value(v)
    131   return constant_value if constant_value is not None else v
    132 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py in constant_value(tensor, partial)
    820   """
    821   if isinstance(tensor, ops.EagerTensor):
--&gt; 822     return tensor.numpy()
    823   if not is_tensor(tensor):
    824     return tensor

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in numpy(self)
    940     """
    941     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--&gt; 942     maybe_arr = self._numpy()  # pylint: disable=protected-access
    943     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    944 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in _numpy(self)
    908       return self._numpy_internal()
    909     except core._NotOkStatusException as e:
--&gt; 910       six.raise_from(core._status_to_exception(e.code, e.message), None)
    911 
    912   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: Socket closed
Additional GRPC error information:
{"created":"@1582484923.512283972","description":"Error received from peer","file":"external/grpc/src/core/lib/surface/call.cc","file_line":1039,"grpc_message":"Socket closed","grpc_status":14}
SEARCH STACK OVERFLOW
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='chn-lee-yumi' date='2020-02-24T01:42:33Z'>
		I solve the problem.
Replace
d_loss_real = model.fit(x_train.astype(np.float32), np.ones((x_train.shape[0],1)))
with
d_loss_real = model.fit(x_train.astype(np.float32), np.ones((x_train.shape[0],1)).astype(np.float32))
It seems is a bug. I think it should throw out TypeError.
		</comment>
		<comment id='3' author='chn-lee-yumi' date='2020-02-24T20:13:18Z'>
		&lt;denchmark-link:https://github.com/chn-lee-yumi&gt;@chn-lee-yumi&lt;/denchmark-link&gt;
 Yes agreed. The error doesn't look to be intuitive.
		</comment>
		<comment id='4' author='chn-lee-yumi' date='2020-05-27T17:51:27Z'>
		&lt;denchmark-link:https://github.com/chn-lee-yumi&gt;@chn-lee-yumi&lt;/denchmark-link&gt;
,
I was able to run the code without any issues with TF v2.2. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/f838683868b5e02729ba910248474a8d/36996.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='5' author='chn-lee-yumi' date='2020-06-01T03:07:02Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;

Hello, I have checked the code, it can run on TF v2.2 without any issues. The colab default TF 2.x version had changed to TF v2.2 too.
		</comment>
		<comment id='6' author='chn-lee-yumi' date='2020-06-02T08:05:19Z'>
		&lt;denchmark-link:https://github.com/chn-lee-yumi&gt;@chn-lee-yumi&lt;/denchmark-link&gt;
,
Thank you for the update. Marking the issue as closed, as it is resolved. Thanks!
		</comment>
		<comment id='7' author='chn-lee-yumi' date='2020-06-02T08:05:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36996&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36996&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>