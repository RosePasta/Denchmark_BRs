<bug id='37593' author='buaasun' open_date='2020-03-14T11:21:45Z' closed_time='2020-03-20T21:00:31Z'>
	<summary>bug in C++ API "AddSymbolicGradients"</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution: CentOS Linux 7.4
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Unknown
TensorFlow installed from (source or binary):source
TensorFlow version (use command below): TF 2.0
Python version:3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from
source): 8.3
CUDA/cuDNN version: None
GPU model and memory: None

Describe the current behavior
I build a graph, then call AddSymbolicGradients to generate gradients, but I found the order of generated gradients does not match inputs. My inputs are [a,b], but the generated gradients are [b_grad, a_grad]
Describe the expected behavior
gradients order match inputs. Gradients of inputs [a,b] should be [a_grad, b_grad]

I checked the code in tensorflow/cc/framework/gradients.cc &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/07112a5c7e233989652ecac3184f0dd640e1462b/tensorflow/cc/framework/gradients.cc#L532&gt;L532&lt;/denchmark-link&gt;

    size_t dx_index = 0;
    for (const Edge* e : n-&gt;in_edges()) {
      if (e-&gt;IsControlEdge()) continue;
      if (dx_index == dx.size()) {
        return errors::Internal(
            "Invalid gradient output index: ", dx_index, " size: ", dx.size());
      }
      TF_RETURN_IF_ERROR(
          BackpropAlongEdge(dx[dx_index++], {e-&gt;src(), e-&gt;src_output()}));
    }
I think dx_index in code should be e-&gt;dst_input(), because in_edges() returns a unordered_set which order is not match dx, the input index of edge is dst_input().The right code may be:
for (const Edge* e : n-&gt;in_edges()) {
      if (e-&gt;IsControlEdge()) continue;
      int dx_index = e-&gt;dst_input();
      if (dx_index &gt;= dx.size()) {
        return errors::Internal("Invalid gradient output index: ", dx_index, " size: ", dx.size());
      }
      TF_RETURN_IF_ERROR(BackpropAlongEdge(dx[dx_index], {e-&gt;src(), e-&gt;src_output()}));
    }
After I modified the code, my program seems works fine.
	</description>
	<comments>
		<comment id='1' author='buaasun' date='2020-03-16T07:19:39Z'>
		&lt;denchmark-link:https://github.com/buaasun&gt;@buaasun&lt;/denchmark-link&gt;

could you please provide us with simple stand alone code for us to replicate the issue faced by you.
		</comment>
		<comment id='2' author='buaasun' date='2020-03-17T05:54:39Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;

This error occurs with a low probability.  returns EdgeSet which contains , so  are ordered by the pointer of Edge. In most cases, pointers are allocated sequentially, so it works. But when executed many times, the error occurs randomly.
I write a simple unit test as below.
#include "tensorflow/cc/client/client_session.h"
#include "tensorflow/cc/framework/grad_op_registry.h"
#include "tensorflow/cc/framework/gradients.h"
#include "tensorflow/cc/framework/testutil.h"
#include "tensorflow/cc/ops/standard_ops.h"
#include "tensorflow/core/framework/graph.pb.h"
#include "tensorflow/core/framework/node_def_util.h"
#include "tensorflow/core/framework/tensor_testutil.h"
#include "tensorflow/core/lib/core/status_test_util.h"
#include "tensorflow/core/platform/test.h"

namespace tensorflow {
namespace {
using namespace ops;

class GradientsTest : public ::testing::Test {
 protected:
  GradientsTest() {}

  void TestSingle(const Scope&amp; scope) {
    int N = 5 + rand() % 10;
    // Construct forward graph.
    OutputList inputs;
    for (int i = 0; i &lt; N; ++i) {
      auto a = Const(scope, i, {1});
      inputs.push_back(a);
    }

    auto pack = Stack(scope, inputs);
    TF_ASSERT_OK(scope.status());

    // Construct grad inputs.
    OutputList output_grads;
    Tensor ts(DT_INT32, {N, 1});
    auto v = ts.matrix&lt;int32&gt;();
    for (int i = 0; i &lt; N; ++i) {
      v(i, 0) = i;
    }
    auto dy = Const(scope, ts);
    output_grads.push_back(dy);
    // Call AddSymbolicGradients.
    std::vector&lt;Output&gt; grad_outputs;
    TF_ASSERT_OK(AddSymbolicGradients(scope, {pack.output}, inputs, output_grads, &amp;grad_outputs));
    ClientSession session((scope));
    std::vector&lt;Tensor&gt; in_grad;
    TF_ASSERT_OK(session.Run(grad_outputs, &amp;in_grad));
    for (int i = 0; i &lt; N; ++i) {
      test::ExpectTensorEqual&lt;int&gt;(in_grad[i], test::AsTensor&lt;int&gt;({i}, {1}));
    }
  }
};
TEST_F(GradientsTest, SubScopeTest) {
  Scope scope = Scope::NewRootScope();
  for (int cnt = 0; cnt &lt; 1000; ++cnt) {
    LOG(INFO) &lt;&lt; cnt;
    TestSingle(scope.NewSubScope(std::to_string(cnt)));
  }
}

}  // namespace
}  // namespace tensorflow
As in code, the test run 1000 cnts, about 5 of them failed.
		</comment>
		<comment id='3' author='buaasun' date='2020-03-17T18:06:35Z'>
		I don't work on TF anymore, sorry!
		</comment>
		<comment id='4' author='buaasun' date='2020-03-17T23:32:14Z'>
		Thanks for debugging this! Your proposal looks good. Would you like to send a PR for the fix?
		</comment>
		<comment id='5' author='buaasun' date='2020-03-20T21:00:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37593&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37593&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>