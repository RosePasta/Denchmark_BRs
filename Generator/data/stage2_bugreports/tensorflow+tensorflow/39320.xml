<bug id='39320' author='edurenye' open_date='2020-05-08T17:09:53Z' closed_time='2020-05-14T07:56:48Z'>
	<summary>Breakpoints do not stop inside tf.function</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
TensorFlow installed from (source or binary): binary (pip)
TensorFlow version (use command below): 2.2.0
Python version: 3.7
CUDA/cuDNN version: CUDA 10.1 / cuDNN 7
GPU model and memory: GeForce RTX 2060 6GB GDDR6

Describe the current behavior
If in the code from below you set a breakpoint in the line print('Dummy function') it will not stop.
&lt;denchmark-code&gt;import tensorflow as tf

def read_tfrecord(x):
    print('Dummy function')
    return x

dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
print(dataset)
dataset = dataset.map(lambda x: read_tfrecord(x))
&lt;/denchmark-code&gt;

Describe the expected behavior
The code execution should stop at that line and you should be able to debug that function.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

def read_tfrecord(x):
    print('Dummy function')
    return x

dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
print(dataset)
dataset = dataset.map(lambda x: read_tfrecord(x))
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
First I though it was a problem with the debugger that I was using so I created an issue there (&lt;denchmark-link:https://github.com/jupyterlab/debugger/issues/435&gt;jupyterlab/debugger#435&lt;/denchmark-link&gt;
).
Then they said it might be to the underlying debugger that it was using (ptvsd / debugpy) since the problem was also present in Visual Studio Code, and both debuggers use the same, so I created an issue there as well (&lt;denchmark-link:https://github.com/microsoft/debugpy/issues/228&gt;microsoft/debugpy#228&lt;/denchmark-link&gt;
).
And they now point out that it might be related to how tensorflow is build, so maybe the problem comes from Tensorflow and the way it creates the threads, read comment: &lt;denchmark-link:https://github.com/microsoft/debugpy/issues/228#issuecomment-624908204&gt;microsoft/debugpy#228 (comment)&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='edurenye' date='2020-05-11T06:56:05Z'>
		&lt;denchmark-link:https://github.com/edurenye&gt;@edurenye&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.2-rc4 .Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/46a30c34caf46264e947d1737ad5a7b2/untitled871.ipynb&gt;here.&lt;/denchmark-link&gt;
Is this the expected behavior?Thanks!
		</comment>
		<comment id='2' author='edurenye' date='2020-05-11T09:56:14Z'>
		You can't test in colab, colab doesn't have a debugger that you can use to set breakpoints as far as I know.
You need jupyter or Visual Studio Code.
You can't do something like this in colab:
&lt;denchmark-link:https://user-images.githubusercontent.com/6824576/81548935-50dc5200-937e-11ea-8286-b261065f0ff3.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='edurenye' date='2020-05-12T19:52:40Z'>
		Yes I was able to reproduce this.
&lt;denchmark-link:https://user-images.githubusercontent.com/47574994/81738873-463dbd80-944f-11ea-91a0-06bcda41de2e.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='edurenye' date='2020-05-12T20:39:08Z'>
		&lt;denchmark-link:https://github.com/edurenye&gt;@edurenye&lt;/denchmark-link&gt;
 can you check whether you can set a breakpoint within ? tf.data wraps all user defined functions in  and I suspect that the behavior you have observed is not specific to tf.data and applies generally to all s.
		</comment>
		<comment id='5' author='edurenye' date='2020-05-13T16:28:45Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 I tried with the following code:
&lt;denchmark-code&gt;import tensorflow as tf

@tf.function
def f(x, y):
    print('Operate')
    return x ** 2 + y

x = tf.constant([2, 3])
y = tf.constant([3, -2])
f(x, y)
&lt;/denchmark-code&gt;

And I set a breakpoint as before, it did not stop at the breakpoint.
So, yes, it happens with all tf.functions.
		</comment>
		<comment id='6' author='edurenye' date='2020-05-13T16:32:46Z'>
		
Note: AutoGraph is compatible with Eager, but the converse is not always true, so exercise care when making modifications to the code while debugging.

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md#debugging-tffunction-tfconfigexperimental_execute_functions_eagerly&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md#debugging-tffunction-tfconfigexperimental_execute_functions_eagerly&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='edurenye' date='2020-05-13T17:53:02Z'>
		"In Tensorflow 2.0, eager execution is enabled by default." Is that not true?
Thank you! I'll try that, but there is something fishy here.
		</comment>
		<comment id='8' author='edurenye' date='2020-05-13T17:58:57Z'>
		That documentation is obsolete apparently.
I got this:
&lt;denchmark-code&gt;AttributeError: module 'tensorflow._api.v2.config' has no attribute 'run_functions_eagerly'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='edurenye' date='2020-05-13T18:00:22Z'>
		&lt;denchmark-link:https://github.com/edurenye&gt;@edurenye&lt;/denchmark-link&gt;
 What is you code snippet?
		</comment>
		<comment id='10' author='edurenye' date='2020-05-13T18:05:34Z'>
		&lt;denchmark-code&gt;import tensorflow as tf

tf.config.run_functions_eagerly(True)

@tf.function
def f(x, y):
    print('Operate')
    return x ** 2 + y

x = tf.constant([2, 3])
y = tf.constant([3, -2])
f(x, y)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='edurenye' date='2020-05-13T18:08:30Z'>
		I don't get AttributeError: module 'tensorflow._api.v2.config' has no attribute 'run_functions_eagerly with your code. What TF version are you using?
		</comment>
		<comment id='12' author='edurenye' date='2020-05-13T18:42:40Z'>
		As says in the issue description, I'm using version 2.2.
And seems that this method just exists in Nightly. I can't test right now, but I will when I have time.
But I don't understand why this is needed if TF 2.0 should be eager by default, my guess is that everything is eager except the tf.function.
The other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code.
		</comment>
		<comment id='13' author='edurenye' date='2020-05-13T18:53:33Z'>
		On TF 2.2 was tf.config.experimental_run_functions_eagerly(True).
I think the point is:

To get performant and portable models, use tf.function to make graphs out of your programs.


When using @tf.function, you can temporarily toggle graph execution by using tf.config.experimental_execute_functions_eagerly. This will effectively run the annotated code eagerly, without transformation. Since AutoGraph has semantics consistent with Eager, it's an effective way to debug the code step-by-step.

		</comment>
		<comment id='14' author='edurenye' date='2020-05-13T19:14:49Z'>
		Reassigning to &lt;denchmark-link:https://github.com/jaingaurav&gt;@jaingaurav&lt;/denchmark-link&gt;
 for triage as this is not specific to tf.data.
		</comment>
		<comment id='15' author='edurenye' date='2020-05-13T22:15:12Z'>
		Thank you very much &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 !!! It works perfectly.
		</comment>
		<comment id='16' author='edurenye' date='2020-05-14T04:15:26Z'>
		&lt;denchmark-link:https://github.com/edurenye&gt;@edurenye&lt;/denchmark-link&gt;

Glad to know it worked. Please close this thread as the issue was resolved. Thanks!
		</comment>
		<comment id='17' author='edurenye' date='2020-05-14T07:56:48Z'>
		Yes, thank you!
I guess this:

The other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code.

Is not compatible with this:

To get performant and portable models, use tf.function to make graphs out of your programs.

So I can close this issue.
And I will close the issues from the other projects as well.
Thank you very much everybody that was involved!
		</comment>
		<comment id='18' author='edurenye' date='2020-05-14T07:56:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39320&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39320&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='19' author='edurenye' date='2020-05-14T08:02:52Z'>
		
The other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code

If the code is transformed debugging with the orignal breakpoint doesn't make sense.
		</comment>
	</comments>
</bug>