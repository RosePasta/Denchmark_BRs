<bug id='39564' author='ahmedalesh' open_date='2020-05-14T23:09:45Z' closed_time='2020-05-19T18:28:18Z'>
	<summary>[RNN] Error Optimizing Tensorflow keras model</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina v 10.15.3
TensorFlow installed from (source or binary): binary (pip install tensorflow)
TensorFlow version (or github SHA if from source):  2.1.0

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;import tensorflow as tf

x_inputs = tf.keras.layers.Input((3,229,1))
x = tf.keras.layers.Conv2D(32, (3,3), padding='same')(x_inputs)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation('relu')(x)
x = tf.keras.layers.Dropout(0.25)(x)
x = tf.keras.layers.MaxPooling2D((1,2))(x)
x = tf.keras.layers.Conv2D(64, (3,3), padding='same')(x)
x = tf.keras.layers.BatchNormalization()(x)
x = tf.keras.layers.Activation('relu')(x)
x = tf.keras.layers.MaxPooling2D((1,2))(x)
x = tf.keras.layers.Reshape((-1,tf.keras.backend.int_shape(x)[-1] * tf.keras.backend.int_shape(x)[-2]))(x)
x = tf.keras.layers.LSTM(256)(x)
x = tf.keras.layers.Dense(1)(x)
x = tf.keras.layers.Activation('sigmoid')(x)
model = tf.keras.models.Model(x_inputs, x)
model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.allow_custom_ops = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;2020-05-14 16:58:55.177804: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-05-14 16:58:55.177972: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-05-14 16:58:55.332306: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-05-14 16:58:55.332333: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 836 nodes (0), 1109 edges (0), time = 27.123ms.
2020-05-14 16:58:55.332339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 836 nodes (0), 1109 edges (0), time = 70.348ms.
2020-05-14 16:58:55.332343: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_body_42042
2020-05-14 16:58:55.332348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-05-14 16:58:55.332353: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332358: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_cond_42307
2020-05-14 16:58:55.332363: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-05-14 16:58:55.332369: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_body_42308
2020-05-14 16:58:55.332380: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332385: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_body_42685
2020-05-14 16:58:55.332395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-05-14 16:58:55.332399: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332404: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_cond_42041
2020-05-14 16:58:55.332409: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332415: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332421: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_cond_42950
2020-05-14 16:58:55.332445: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332486: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_cond_42684
2020-05-14 16:58:55.332497: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332502: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:55.332507: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_body_42951
2020-05-14 16:58:55.332512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-05-14 16:58:55.332544: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-05-14 16:58:58.205307: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-05-14 16:58:58.205687: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-05-14 16:59:00.586252: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-05-14 16:59:00.586377: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 420 nodes (-60), 591 edges (-90), time = 1090.02698ms.
2020-05-14 16:59:00.586382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 420 nodes (0), 591 edges (0), time = 381.193ms.
2020-05-14 16:59:00.586385: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_body_42308_frozen
2020-05-14 16:59:00.586390: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 3.961ms.
2020-05-14 16:59:00.586393: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.811ms.
2020-05-14 16:59:00.586474: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_cond_42041_frozen
2020-05-14 16:59:00.586484: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.298ms.
2020-05-14 16:59:00.586489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.254ms.
2020-05-14 16:59:00.586492: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_backward_lstm_1_while_cond_42307_frozen
2020-05-14 16:59:00.586496: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.761ms.
2020-05-14 16:59:00.586499: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.358ms.
2020-05-14 16:59:00.586657: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_1_forward_lstm_1_while_body_42042_frozen
2020-05-14 16:59:00.586668: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.465ms.
2020-05-14 16:59:00.586673: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.419ms.
2020-05-14 16:59:00.586678: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_body_42685_frozen
2020-05-14 16:59:00.586683: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.247ms.
2020-05-14 16:59:00.586687: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.45ms.
2020-05-14 16:59:00.586790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_body_42951_frozen
2020-05-14 16:59:00.586802: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (-2), 155 edges (0), time = 4.046ms.
2020-05-14 16:59:00.586808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 107 nodes (0), 155 edges (0), time = 2.454ms.
2020-05-14 16:59:00.586813: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_backward_lstm_2_while_cond_42950_frozen
2020-05-14 16:59:00.586817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.334ms.
2020-05-14 16:59:00.586820: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.245ms.
2020-05-14 16:59:00.586958: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: model_1_bidirectional_2_forward_lstm_2_while_cond_42684_frozen
2020-05-14 16:59:00.586967: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.286ms.
2020-05-14 16:59:00.586987: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.247ms.

``
**Any other info / logs**
The model comprises of multiple LSTM, and some other custom layers. Without quantization, the model conversion works only with the experimental_new_converter set to true. Removing the LSTM layer fixes the issue
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ahmedalesh' date='2020-05-14T23:47:51Z'>
		&lt;denchmark-link:https://github.com/ahmedalesh&gt;@ahmedalesh&lt;/denchmark-link&gt;
 Please share a model or standalone code to reproduce the issue? Thanks!
		</comment>
		<comment id='2' author='ahmedalesh' date='2020-05-15T00:10:08Z'>
		I have updated the issue with a standalone code
You can also find a standalone code here
&lt;denchmark-link:https://colab.research.google.com/drive/1iXWuI10KpWfp57989kkmoakiI9f3bF2I?usp=sharing&gt;https://colab.research.google.com/drive/1iXWuI10KpWfp57989kkmoakiI9f3bF2I?usp=sharing&lt;/denchmark-link&gt;

Without the experimental new converter, I am able to convert the model but unable to load the model from memory or allocate tensors after
		</comment>
		<comment id='3' author='ahmedalesh' date='2020-05-16T02:13:03Z'>
		Hi &lt;denchmark-link:https://github.com/ahmedalesh&gt;@ahmedalesh&lt;/denchmark-link&gt;
,
A couple of things

tf.lite.Optimize.DEFAULT should only be set if using quantization
rnn is only supported converting from_saved_model

I made a working version of the code at:
&lt;denchmark-link:https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing&gt;https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ahmedalesh' date='2020-05-17T01:30:36Z'>
		
Hi @ahmedalesh,
A couple of things

tf.lite.Optimize.DEFAULT should only be set if using quantization
rnn is only supported converting from_saved_model

I made a working version of the code at:
https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing

Thanks &lt;denchmark-link:https://github.com/daverim&gt;@daverim&lt;/denchmark-link&gt;
 for the working version. However, I do intend to use quantization. As.I mentioned earlier, by not setting quantization, the model conversion works. I tried your code and when i set tf.lite.Optimize.DEFAULT, the issue persists.
This is a similar working version to your notebook but using'from_keras_model without quantizing the model weight.
&lt;denchmark-link:https://colab.research.google.com/drive/13lN61zcxoepgBFn5ZjSGqHDS-qYefVPU?usp=sharing&gt;https://colab.research.google.com/drive/13lN61zcxoepgBFn5ZjSGqHDS-qYefVPU?usp=sharing&lt;/denchmark-link&gt;

I am confident the issue is because of the LSTM layer in the model, using both tf saver and keras model save does not fix the issue.
Ahmed
		</comment>
		<comment id='5' author='ahmedalesh' date='2020-05-18T10:38:32Z'>
		Ah sorry, I must have been really confused when I wrote my response. My apologies.
The reason why your code doesn't work is because the lstm layer is being converted as a subgraph, which the quantizer does not support.
To get this to work, you need the converter to convert the lstm layer as a builtin op, for which you should use convert_from_saved_model in combination with the concrete function to fix the batch size.
I've updated my gist here:
&lt;denchmark-link:https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing&gt;https://colab.research.google.com/drive/1OVnfSk45qTYBzbLJeyte05QDAxNKA6CI?usp=sharing&lt;/denchmark-link&gt;

I left out the update to tf-nightly as well as a  setting a correct batch size in my previous version.
If you look at the resulting graph using Netron you will see that the while loop is replaced with a UnidirectionalSequenceLstmOp (&lt;denchmark-link:https://imgur.com/2PJSJTG&gt;https://imgur.com/2PJSJTG&lt;/denchmark-link&gt;
) Since this is a single op, the quantizer doesn't fail on multiple subgraphs.
Using your version will have the while loop rather than the fused op, and that's why it doesn't work.
Hope that helps.
		</comment>
		<comment id='6' author='ahmedalesh' date='2020-05-19T18:28:18Z'>
		&lt;denchmark-link:https://github.com/daverim&gt;@daverim&lt;/denchmark-link&gt;
 thanks a lot that seems to help using tf-nightly, I would be closing the issue now.
		</comment>
		<comment id='7' author='ahmedalesh' date='2020-05-29T03:37:35Z'>
		&lt;denchmark-link:https://github.com/ahmedalesh&gt;@ahmedalesh&lt;/denchmark-link&gt;
 Hi I'm dealing with the same error. Could you tell which version is it to fix it ? Thx
		</comment>
		<comment id='8' author='ahmedalesh' date='2020-06-01T17:05:24Z'>
		
@ahmedalesh Hi I'm dealing with the same error. Could you tell which version is it to fix it ? Thx

&lt;denchmark-link:https://github.com/07freedom&gt;@07freedom&lt;/denchmark-link&gt;
 Hello, I was able to use 2.3.0-dev20200601 to do the conversion. You can

		</comment>
	</comments>
</bug>