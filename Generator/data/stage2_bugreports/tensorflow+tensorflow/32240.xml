<bug id='32240' author='elyasmehtabuddin' open_date='2019-09-05T15:27:54Z' closed_time='2019-09-09T23:09:51Z'>
	<summary>TPU has unsupported tensorflow op "LogUniformCandidateSampler" using XLA</summary>
	<description>
Using NCE loss for an NLP model and ran into an issue where XLA doesn't compile using TPU.
&lt;denchmark-code&gt;No registered 'LogUniformCandidateSampler' OpKernel for XLA_CPU_JIT devices compatible with node node LogUniformCandidateSampler
&lt;/denchmark-code&gt;

System information

Using Google's cloud TPU with Tensorflow 1.14
tf_env.txt

Describe the current behavior
I get an error when running the code on TPU because XLA doesn't support candidate samplers.
image:
&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/64356249-60b5c200-cfb7-11e9-9a09-9f9a35057f6e.png&gt;&lt;/denchmark-link&gt;

Describe the expected behavior
I expect the model to be able to run and calculate loss on TPU using XLA
Code to reproduce the issue
&lt;denchmark-code&gt;import os
import tensorflow as tf
from tensorflow.python.compiler.xla import xla

def my_model(features, labels):
  nce_weights = tf.get_variable(
    name="nce_weights",
    shape=[10, 4],
    initializer=tf.random_uniform_initializer(-1.0, 1.0)
  )
  nce_biases = tf.get_variable(
    name="nce_biases",
    shape=[10],
    initializer=tf.zeros_initializer()
  )

  num_sampled = 1
  num_classes = 10

  sampler_func = tf.random.log_uniform_candidate_sampler
  sampled_values = sampler_func(
    true_classes=tf.cast(labels, tf.dtypes.int64),
    num_sampled=num_sampled,
    range_max=num_classes,
    num_true=1,
    unique=True,
    seed=None,
  )

  loss = tf.reduce_mean(
    tf.nn.nce_loss(
      weights=nce_weights,
      biases=nce_biases,
      labels=labels,
      inputs=features,
      num_sampled=num_sampled,
      num_classes=num_classes,
      sampled_values=sampled_values,
    )
  )

  optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)
  return loss, optimizer

sess = tf.Session()
features = tf.constant(1.2, shape=[1, 4], dtype=tf.float32)
labels = tf.constant(1, shape=[1, 1], dtype=tf.float32)

[y] = xla.compile(my_model, inputs=[features, labels])

sess.run(tf.global_variables_initializer())
sess.run(y)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0905 08:26:12.392647 140303472117184 deprecation_wrapper.py:119] From issue.py:45: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-09-05 08:26:12.529939: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-05 08:26:12.908472: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-09-05 08:26:12.908636: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557f84258f10 executing computations on platform Host. Devices:
2019-09-05 08:26:12.908650: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
W0905 08:26:13.021475 140303472117184 deprecation_wrapper.py:119] From issue.py:6: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0905 08:26:13.398072 140303472117184 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
W0905 08:26:13.421444 140303472117184 deprecation_wrapper.py:119] From issue.py:42: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

W0905 08:26:13.709804 140303472117184 deprecation_wrapper.py:119] From issue.py:51: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2019-09-05 08:26:14.238822: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-09-05 08:26:14.645355: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at xla_ops.cc:343 : Invalid argument: Detected unsupported operations when trying to compile graph cluster_18305510630026920806[] on XLA_CPU_JIT: LogUniformCandidateSampler (No registered 'LogUniformCandidateSampler' OpKernel for XLA_CPU_JIT devices compatible with node {{node LogUniformCandidateSampler}}
	.  Registered:  device='CPU'
){{node LogUniformCandidateSampler}}
	This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS="tf_xla_auto_jit=2" which will attempt to use xla to compile as much of the graph as the compiler is able to.
Traceback (most recent call last):
  File "issue.py", line 52, in &lt;module&gt;
    sess.run(y)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph cluster_18305510630026920806[] on XLA_CPU_JIT: LogUniformCandidateSampler (No registered 'LogUniformCandidateSampler' OpKernel for XLA_CPU_JIT devices compatible with node node LogUniformCandidateSampler (defined at issue.py:27) 
	.  Registered:  device='CPU'
)node LogUniformCandidateSampler (defined at issue.py:27) 
	This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS="tf_xla_auto_jit=2" which will attempt to use xla to compile as much of the graph as the compiler is able to.
	 [[cluster]]

Errors may have originated from an input operation.
Input Source operations connected to node LogUniformCandidateSampler:
 Cast (defined at issue.py:22)

Input Source operations connected to node LogUniformCandidateSampler:
 Cast (defined at issue.py:22)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='elyasmehtabuddin' date='2019-09-06T10:48:20Z'>
		I have tried on colab with TF version 1.14, Nightly versions and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/0108c56cf87abb2f2fd74b39884d878f/untitled161.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='elyasmehtabuddin' date='2019-09-09T18:46:27Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I am also willing to contribute to the tensorflow source code if need be
		</comment>
		<comment id='3' author='elyasmehtabuddin' date='2019-09-09T21:00:02Z'>
		&lt;denchmark-link:https://github.com/elyasmehtabuddin&gt;@elyasmehtabuddin&lt;/denchmark-link&gt;
 Please feel free to contribute by raising PR's &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pulls&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='elyasmehtabuddin' date='2019-09-09T23:09:51Z'>
		Unfortunately this is not a supported op that you can use on TPUs. The list of compatible base op for TPUs is available at &lt;denchmark-link:https://cloud.google.com/tpu/docs/tensorflow-ops&gt;https://cloud.google.com/tpu/docs/tensorflow-ops&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='5' author='elyasmehtabuddin' date='2019-09-09T23:09:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32240&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32240&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='elyasmehtabuddin' date='2019-09-10T07:35:14Z'>
		&lt;denchmark-link:https://github.com/frankchn&gt;@frankchn&lt;/denchmark-link&gt;
 Are there plans to support this op in the future for XLA (not TPU)?
		</comment>
		<comment id='7' author='elyasmehtabuddin' date='2019-09-10T21:52:33Z'>
		I've filed a feature request for this internally, but I am not sure it would get on our roadmap in the short term.
		</comment>
	</comments>
</bug>