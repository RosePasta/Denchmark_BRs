<bug id='34610' author='BuiNgocHai' open_date='2019-11-26T09:30:26Z' closed_time='2019-12-19T19:31:05Z'>
	<summary>Difference output when dumb freeze .pb from .hdf5</summary>
	<description>
Hi I'm trying to dumb frozen .pb graph from .hdf5 file but I my .pb have difference output with .h5 file
&lt;denchmark-h:h3&gt;input and output name of .hdf5 file&lt;/denchmark-h&gt;

All input nodes: [&lt;tf.Tensor 'input_1:0' shape=(?, 256, 320, 3) dtype=float32&gt;]
All output nodes: [&lt;tf.Tensor 'fcn17/truediv:0' shape=(?, ?, ?, 4) dtype=float32&gt;]
&lt;denchmark-h:h3&gt;and output value of hdf5 file like this:&lt;/denchmark-h&gt;

array([[[[0.95520484, 0.02454368, 0.01151993, 0.0087315 ],
         [0.96743697, 0.01915975, 0.00736554, 0.00603788],
         [0.97429854, 0.01614887, 0.00556678, 0.00398591],
         ...,
         [0.96292394, 0.01786121, 0.00704672, 0.01216816],
         [0.95855474, 0.02005052, 0.00870537, 0.0126894 ],
         [0.9483133 , 0.02560406, 0.01250436, 0.01357825]],
         ...,
         [0.6439966 , 0.33929765, 0.01019213, 0.00651362],
         [0.64723253, 0.3306629 , 0.01337334, 0.00873124],
         [0.649275  , 0.3211698 , 0.01852187, 0.0110333 ]]]],
      dtype=float32)
&lt;denchmark-h:h3&gt;this is output of .pb file ( 'fcn17/truediv:0' ) :&lt;/denchmark-h&gt;

[[[0.24999999 0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.24999999 0.24999999]
  ...
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]
  [0.25       0.25       0.25       0.25      ]]]
and i see my output of hdf5 file difference pb file
&lt;denchmark-h:h3&gt;this is my code i try to dumb freeze graph from hdf5 file&lt;/denchmark-h&gt;

def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):
    """
    Freezes the state of a session into a pruned computation graph.

    Creates a new computation graph where variable nodes are replaced by
    constants taking their current value in the session. The new graph will be
    pruned so subgraphs that are not necessary to compute the requested
    outputs are removed.
    @param session The TensorFlow session to be frozen.
    @param keep_var_names A list of variable names that should not be frozen,
                          or None to freeze all the variables in the graph.
    @param output_names Names of the relevant graph outputs.
    @param clear_devices Remove the device directives from the graph for better portability.
    @return The frozen graph definition.
    """
    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))
        output_names = output_names or []
        output_names += [v.op.name for v in tf.global_variables()]
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = ""
        frozen_graph = tf.graph_util.convert_variables_to_constants(
            session, input_graph_def, output_names, freeze_var_names)
        return frozen_graph

def freeze_graph_keras(net, model_dir):
    """Extract the sub graph defined by the output nodes and convert 
    all its variables into constant 
    Args:
        model_dir: the root folder containing the checkpoint state file
        output_node_names: a string, containing all the output node's names, 
                            comma separated
    """

    # The export path contains the name and the version of the model
    tf.keras.backend.set_learning_phase(0)  # Ignore dropout at inference
    file_name = os.path.basename(model_dir).replace('.hdf5', '.pb')
    model_dir = os.path.dirname(model_dir)
    print(os.path.join(model_dir, file_name))
    with tf.keras.backend.get_session() as sess:
        tf.initialize_all_variables().run()
        frozen_graph = freeze_session(K.get_session(),
                                      output_names=[out.op.name for out in net.outputs])
        tf.train.write_graph(frozen_graph, model_dir,
                             file_name, as_text=False)
    print('All input nodes:', net.inputs)
    print('All output nodes:', net.outputs)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_dir", type=str,
                        default="path.hdf5", help="Model folder to export")

    args = parser.parse_args()                    

    model = build_my_model((256,320,3), num_classes=4,
                    lr_init=1e-3, lr_decay=5e-4)
    model.load_weights('path')
    freeze_graph_keras(model, args.model_dir)
I'm using tensorflow version 1.14.0 and keras 2.2.4
	</description>
	<comments>
		<comment id='1' author='BuiNgocHai' date='2019-11-28T09:18:45Z'>
		&lt;denchmark-link:https://github.com/BuiNgocHai&gt;@BuiNgocHai&lt;/denchmark-link&gt;
,
Can you please clarify the reason for Freezing the Graph i.e., if you are planning to deploy the model in Mobile Device, etc..
		</comment>
		<comment id='2' author='BuiNgocHai' date='2019-11-29T10:19:57Z'>
		I want to Freezing the Graph for my project with ROS, i have some problem with run Keras with ROS but .pb is OK and .pb will be faster also I don't want show my summary model when i submit my project so i think i need Freezing the Graph for this.
		</comment>
		<comment id='3' author='BuiNgocHai' date='2019-12-02T23:49:11Z'>
		&lt;denchmark-link:https://github.com/BuiNgocHai&gt;@BuiNgocHai&lt;/denchmark-link&gt;
 Can you try  and also share a simple standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='4' author='BuiNgocHai' date='2019-12-10T11:49:41Z'>
		Here is my model
def focal_loss(gamma=2., alpha=.25):
	def focal_loss_fixed(y_true, y_pred):
		pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
		pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
		return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))
	return focal_loss_fixed

def dice_coef(y_true, y_pred):
    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)

def mean_iou(num_classes):
    def iou(y_true, y_pred):
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred, num_classes)
        K.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        return score
    return iou


def model(shape, num_classes, lr_init, lr_decay,  alpha=1.0, include_top=True, weights=None):
    mbl = applications.mobilenet.MobileNet(weights=None, include_top=False, input_shape=shape)
    x = mbl.output

    model_tmp =  Model(inputs = mbl.input, outputs = x)
    layer5, layer8, layer13 = model_tmp.get_layer('conv_pw_5_relu').output, model_tmp.get_layer('conv_pw_8_relu').output, model_tmp.get_layer('conv_pw_13_relu').output

    fcn14 = Conv2D(filters=2 , kernel_size=1, name='fcn14')(layer13)
    fcn15 = Conv2DTranspose(filters=layer8.get_shape().as_list()[-1] , kernel_size=4, strides=2, padding='same', name='fcn15')(fcn14)
    fcn15_skip_connected = Add(name="fcn15_plus_vgg_layer8")([fcn15, layer8])
    fcn16 = Conv2DTranspose(filters=layer5.get_shape().as_list()[-1], kernel_size=4, strides=2, padding='same', name="fcn16_conv2d")(fcn15_skip_connected)
    # Add skip connection
    fcn16_skip_connected = Add(name="fcn16_plus_vgg_layer5")([fcn16, layer5])
    # Upsample again
    fcn17 = Conv2DTranspose(filters=4, kernel_size=16, strides=(8, 8), padding='same', name="fcn17", activation="softmax")(fcn16_skip_connected)

    
    model = Model(inputs = mbl.input, outputs = fcn17)

    model.compile(optimizer=Adam(lr=lr_init, decay=lr_decay),
                  loss='categorical_crossentropy',
                  metrics=[mean_iou(num_classes=num_classes), dice_coef])
    
    return model
		</comment>
		<comment id='5' author='BuiNgocHai' date='2019-12-11T00:12:10Z'>
		&lt;denchmark-link:https://github.com/BuiNgocHai&gt;@BuiNgocHai&lt;/denchmark-link&gt;
 Can you please provide a standalone code. I cannot run the current code you shared. Thanks!
		</comment>
		<comment id='6' author='BuiNgocHai' date='2019-12-19T19:31:05Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='7' author='BuiNgocHai' date='2019-12-19T19:31:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34610&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34610&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>