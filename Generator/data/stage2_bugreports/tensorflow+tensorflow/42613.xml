<bug id='42613' author='rafiqhasan' open_date='2020-08-24T07:26:24Z' closed_time='2021-01-01T15:04:54Z'>
	<summary>TF 2.3 Saved model | Experimental features not working properly</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.3.0
Python version: 3.7
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior:
While serving a TF 2.3 trained saved model created with tf.keras.layers.experimental.preprocessing features, TMS(Tensorflow model server ) gives error on prediction. However predict method on the model runs absolutely fine without any error, seems to be something specific to TMS. Does TMS currently not support the new experimental pre-processing features that were added in TF 2.3.
I also noticed that saved_model_cli also throws error that Op type not registered 'DenseBincount' in binary but that could be related to saved_model_cli not yet updated in Colab with TF 2.3 support.
Bug has also been opened on TMS but it seems that the bug is not in serving but in TF runtime: &lt;denchmark-link:https://github.com/tensorflow/serving/issues/1720#issuecomment-678842670&gt;tensorflow/serving#1720 (comment)&lt;/denchmark-link&gt;
 ( FYI: &lt;denchmark-link:https://github.com/christisg&gt;@christisg&lt;/denchmark-link&gt;
  )
Describe the expected behavior:
Saved model should work properly in Tensorflow serving and also show up properly in saved_model_cli

Run GIST - &lt;denchmark-link:https://gist.github.com/rafiqhasan/6f00aecf1feafd83ba9dfefef8907ee8#file-dl-e2e-taxi-dataset-tf2-keras-ipynb&gt;https://gist.github.com/rafiqhasan/6f00aecf1feafd83ba9dfefef8907ee8#file-dl-e2e-taxi-dataset-tf2-keras-ipynb&lt;/denchmark-link&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;import json
import requests

#Create payload
data_py = {"instances":[{'dropoff_latitude': [41.920452],
                         'dropoff_longitude': [-87.679955],
                         'pickup_latitude': [41.952823],
                         'pickup_longitude': [-87.653244],
                         'trip_start_day': ["1"],
                         'trip_start_hour': ["5"],
                         'trip_start_month': ["6"]}]}

data = json.dumps(data_py)
print("payload: ", data)

#Run request on TMS
headers = {"content-type": "application/json"}
json_response = requests.post('http://localhost:8507/v1/models/model:predict', data=data, headers=headers)
json_response.text
&lt;/denchmark-code&gt;

Error message:
&lt;denchmark-code&gt;{
    "error": "Missing 0-th output from {{node functional_3/category_encoding_13/bincount/DenseBincount}}"
}
&lt;/denchmark-code&gt;

But model prediction standalone code works:
&lt;denchmark-code&gt;# ##Prediction on model
# ## BUT HERE ALL FEATURES HAVE TO BE PASSED, EVEN THE Calculated ones
data = tf.data.Dataset.from_tensor_slices({'dropoff_latitude': [[41.920452]],
                         'dropoff_longitude': [[-87.679955]],
                         'pickup_latitude': [[41.952823]],
                         'pickup_longitude': [[-87.653244]],
                         'trip_start_day': [["1"]],
                         'trip_start_hour': [["5"]],
                         'trip_start_month': [["6"]],
                         'distance':[[0.02]]})

m_.predict(data)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rafiqhasan' date='2020-08-24T15:38:35Z'>
		Was able to reproduce the issue with TF v2.3. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/2449c4a116ca8306a754bcf9f700df07/42613.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='rafiqhasan' date='2020-08-27T11:00:43Z'>
		do we know the root cause now ?
		</comment>
		<comment id='3' author='rafiqhasan' date='2020-09-07T13:49:26Z'>
		Team, any response ? Can't deploy an "experimental features" saved model to TMS.
		</comment>
		<comment id='4' author='rafiqhasan' date='2020-09-10T07:57:28Z'>
		Infact, upon careful investigation of the error message from saved_model_cli - it says as below and inline with the error that TMS is raising for the saved model.
&lt;denchmark-code&gt;c_api.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type), buf)
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'DenseBincount' in binary running on 5e1999aea28d. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='rafiqhasan' date='2020-09-18T17:30:36Z'>
		Open since 25 days , no response !
		</comment>
		<comment id='6' author='rafiqhasan' date='2020-11-21T12:53:24Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
  : Should we stop expecting a resolution on this ? This is a production issue and is escalating more than ever as we are not able to deploy models using these feature engineering options.
		</comment>
		<comment id='7' author='rafiqhasan' date='2021-01-01T15:04:54Z'>
		TF 2.4 has fixed this problem specifically for the in-model inferencing, however tensorflow_model_server based inferencing issue still persists and is open here - &lt;denchmark-link:https://github.com/tensorflow/serving/issues/1720&gt;tensorflow/serving#1720&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='rafiqhasan' date='2021-01-01T15:04:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42613&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42613&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>