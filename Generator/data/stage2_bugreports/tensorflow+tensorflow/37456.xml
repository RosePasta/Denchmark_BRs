<bug id='37456' author='italo-goncalves' open_date='2020-03-09T22:42:25Z' closed_time='2020-08-27T00:43:35Z'>
	<summary>Ops with SparseTensor on GPU gives result in CPU.</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  custom code
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:
TensorFlow installed from (source or
binary): binary (conda)
TensorFlow version (use command below): 2.1.0
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from
source):
CUDA/cuDNN version: CUDA 10.1
GPU model and memory: NVIDIA GTX 1060 6 GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When executing operations on sparse tensors in the GPU (within a tf.device block), the result is stored in the CPU. This is causing a huge slowdown in my program, as the data is being copied around between GPU and GPU multiple times.
I have verified that this occurs with the functions tf.sparse.sparse_dense_matmul and tf.sparse.reduce_sum. It may also occur with others. Is this the intended behavior? I am missing something?
Describe the expected behavior
The result of an operation on a sparse tensor with the GPU should stay in the GPU.

See &lt;denchmark-link:https://colab.research.google.com/drive/1BpG8P8dEzDDmtMBIGgSA2wOMzEm4bCzL&gt;this Colab notebook&lt;/denchmark-link&gt;
.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Thanks in advance.
	</description>
	<comments>
		<comment id='1' author='italo-goncalves' date='2020-03-11T06:03:35Z'>
		Was able to replicate the issue with Tf 2.1.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/71a5af89e786fbc5a935c1b53dc87576/untitled435.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='italo-goncalves' date='2020-08-26T23:17:46Z'>
		Unfortunately this is by design, SparseReduceSum OP is not implemented for GPU, see declaration:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_reduce_op.cc&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_reduce_op.cc&lt;/denchmark-link&gt;

Very few sparse ops are supported on GPU.
		</comment>
		<comment id='3' author='italo-goncalves' date='2020-08-26T23:19:42Z'>
		See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24404&gt;#24404&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='italo-goncalves' date='2020-08-27T00:43:35Z'>
		Thanks for the update. In this case I'm closing the issue.
		</comment>
		<comment id='5' author='italo-goncalves' date='2020-08-27T00:43:37Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37456&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37456&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>