<bug id='24322' author='remibasaru' open_date='2018-12-12T19:16:19Z' closed_time='2019-02-22T03:19:28Z'>
	<summary>java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model issue</summary>
	<description>
Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: Samsung S5
TensorFlow installed from (source or binary): Binary
TensorFlow version: 1.12
Python version: 3.5
Installed using virtualenv? pip? conda?: conda
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the problem
I have created my own architecture, on tensorflow and I have used Toco to convert to .tflite, However the android app still throws the following error: "java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model."
Provide the exact sequence of commands / steps that you executed before running into the problem
'''
AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(MODEL_PATH);
FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
FileChannel fileChannel = inputStream.getChannel();
long startOffset = fileDescriptor.getStartOffset();
long declaredLength = fileDescriptor.getDeclaredLength();
return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
'''
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='remibasaru' date='2019-02-13T18:18:14Z'>
		Apologies for the delay in response. Is this still an issue for you?
Can you please take a look at duplicate &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/23628&gt;#23628&lt;/denchmark-link&gt;
? Thanks!
		</comment>
		<comment id='2' author='remibasaru' date='2019-02-13T22:29:55Z'>
		Hi there, I'm trying to convert a Tensorflow 1.12 / Keras model with TFLiteConverter.from_keras_model_file. I've got no issue doing this on Colaboratory (tf 1.12), but when I run my model I encounter the dreaded error :
"Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model" error. with firebase-ml-model-interpreter:16.2.4
The model structure is the following :
Input(884)
BatchNormalization()
Reshape(52,17)
LSTM(256, unroll=True, return_sequences=True)
LSTM(256, unroll=True)
BatchNormalization()
Dense(260)
I previously successfully converted and used similar models, but without Reshape and (unrolled) LSTM layers.
(EDIT) For information, doing the Batchnormalization layer after the Reshape prevent the conversion from happening.
Any advice on version or changes I should make ?
Thank you very much in advance.
		</comment>
		<comment id='3' author='remibasaru' date='2019-02-22T03:19:28Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
&lt;denchmark-link:https://github.com/NicolasVidal&gt;@NicolasVidal&lt;/denchmark-link&gt;
 Can you please post a &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;new issue&lt;/denchmark-link&gt;
 explaining your problem if it still persists? thanks
		</comment>
		<comment id='4' author='remibasaru' date='2019-07-26T13:00:17Z'>
		I'm having the same issue, converted the model with from_keras_model_file, tried to load it in Android but gives me this error:
java.lang.IllegalArgumentException: Contents of /conv.tflite does not encode a valid TensorFlowLite model: Could not open '/conv.tflite'.The model is not a valid Flatbuffer file
		</comment>
	</comments>
</bug>