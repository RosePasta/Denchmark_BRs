<bug id='26886' author='mmuratarat' open_date='2019-03-19T15:28:02Z' closed_time='2019-09-11T17:58:09Z'>
	<summary>Restoring a saved model and evaluating on a new Tensorflow Data object</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary (for GPU)
TensorFlow version: GIT: v1.9.0-0-g25c197e023, TF: 1.9.0
Python version: Python 3.5.2
CUDA/cuDNN version: 10.0, V10.0.130
GPU model and memory: 4 X Nvidia GeForce GTX 1080 Ti (11GB)

I have this saved model and I want to restore it. After I restore, I want to evaluate it on a new dataset which I feeding with a Tensorflow Data input pipeline. For convenience I created an LSTM model using MNIST dataset and I am feeding data using reinitializable iterator of Tensorflow Data API.
&lt;denchmark-code&gt;#Ignore the warnings
import warnings
warnings.filterwarnings("ignore")

import sys
import pandas as pd
import tensorflow as tf
import numpy as np

import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (8,7)
%matplotlib inline

old_v = tf.logging.get_verbosity()
tf.logging.set_verbosity(tf.logging.ERROR)
from tensorflow.examples.tutorials.mnist import input_data

#Data parameters
num_inputs = 28
num_classes = 2
num_steps=28

mnist = input_data.read_data_sets("MNIST_data/")

X_train = mnist.train.images[mnist.train.labels &lt; 2].reshape((-1, num_steps, num_inputs))
y_train = mnist.train.labels[mnist.train.labels &lt; 2]

X_val = mnist.validation.images[mnist.validation.labels &lt; 2].reshape((-1, num_steps, num_inputs))
y_val = mnist.validation.labels[mnist.validation.labels &lt; 2]

X_test = mnist.test.images[mnist.test.labels &lt; 2].reshape([-1, num_steps, num_inputs])
y_test = mnist.test.labels[mnist.test.labels &lt; 2]

tf.logging.set_verbosity(old_v)

print(X_train.shape)
#(11623, 28, 28)
print(y_train.shape)
#(11623,)
print(X_val.shape)
#(1042, 28, 28)
print(y_val.shape)
#(1042,)
print(X_test.shape)
#(2115, 28, 28)
print(y_test.shape)
#(2115,)

# CREATE THE COMPUTATIONAL GRAPH
initial_learning_rate=0.0001
num_neurons = 128
num_layers = 1

graph = tf.Graph()
with graph.as_default():
    
    features_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, num_steps, num_inputs])
    labels_placeholder = tf.placeholder(tf.int32, shape=[None])

    batch_size = 128

    # create the training dataset
    Xtrain = tf.data.Dataset.from_tensor_slices(features_placeholder)
    # apply a one-hot transformation to each label for use in the neural network
    ytrain = tf.data.Dataset.from_tensor_slices(labels_placeholder).map(lambda z: tf.one_hot(z, 2))
    # zip the x and y training data together and batch and Prefetch data for faster consumption
    train_dataset = tf.data.Dataset.zip((Xtrain, ytrain)).batch(batch_size)

    # create the validation dataset
    Xval = tf.data.Dataset.from_tensor_slices(features_placeholder)
    # apply a one-hot transformation to each label for use in the neural network
    yval = tf.data.Dataset.from_tensor_slices(labels_placeholder).map(lambda z: tf.one_hot(z, 2))
    # zip the x and y validation data together and shuffle, batch etc.
    validation_dataset = tf.data.Dataset.zip((Xval, yval)).batch(batch_size)

    # create the testing dataset
    Xtest = tf.data.Dataset.from_tensor_slices(features_placeholder)
    # apply a one-hot transformation to each label for use in the neural network
    ytest = tf.data.Dataset.from_tensor_slices(labels_placeholder).map(lambda z: tf.one_hot(z, 2))
    # zip the x and y testing data together and shuffle, batch etc.
    testing_dataset = tf.data.Dataset.zip((Xtest, ytest)).batch(batch_size)

    iterator = tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)
    X, y = iterator.get_next()

    training_init_op = iterator.make_initializer(train_dataset)
    validation_init_op = iterator.make_initializer(validation_dataset)
    testing_init_op = iterator.make_initializer(testing_dataset)

    with tf.name_scope("graph_inputs"):
        output_keep_prob = tf.placeholder_with_default(1.0, shape=(), name ="output_dropout")

    def build_lstm_cell(num_neurons, output_keep_prob):
        """Returns a dropout-wrapped LSTM-cell.
        See https://stackoverflow.com/a/44882273/2628369 for why this local function is necessary.
        Returns:
        tf.contrib.rnn.DropoutWrapper: The dropout-wrapped LSTM cell.
        """
        initializer = tf.contrib.layers.xavier_initializer()
        lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_neurons, initializer=initializer, forget_bias=1.0, state_is_tuple=True, name='LSTM_cell')
        lstm_cell_drop = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=output_keep_prob)
        return lstm_cell_drop
    
    with tf.name_scope("LSTM"):
        with tf.name_scope("Cell"):
            #kernel = tf.get_variable(name = 'kernel_0',shape=[156, 512], initializer=tf.contrib.layers.xavier_initializer(), trainable=False)
            #bias = tf.get_variable(name='bias_0',shape=[512],initializer=tf.zeros_initializer(), trainable=False)
            multi_layer_cell = tf.contrib.rnn.MultiRNNCell([build_lstm_cell(num_neurons, output_keep_prob) for _ in range(num_layers)], state_is_tuple=True)
        with tf.name_scope("Model"):
            outputs, states = tf.nn.dynamic_rnn(cell=multi_layer_cell, inputs=X, swap_memory=False, time_major = False, dtype=tf.float32)#[Batch_size, time_steps, num_neurons]
        with tf.name_scope("Graph_Outputs"):
            outputs = tf.transpose(outputs, [1, 0, 2]) # [num_timesteps, batch_size, num_neurons]
            outputs = tf.gather(outputs, int(outputs.get_shape()[0]) - 1) # [batch_size, num_neurons]
        with tf.variable_scope('Softmax'):
            softmax_w = tf.get_variable(name="softmax_w", initializer=tf.truncated_normal(shape=[num_neurons, num_classes], stddev=np.sqrt(2.0 /num_neurons), dtype=tf.float32))
            softmax_b = tf.get_variable(name="softmax_b", initializer=tf.constant(value= 2.0 / num_neurons, shape=[num_classes], dtype=tf.float32))
            logits= tf.matmul(outputs, softmax_w) + softmax_b #[Batch_size X time_steps, num_classes]
        with tf.name_scope('Predictions'):
            predictions = tf.nn.softmax(logits, name="predictions")  #[Batch_size, num_classes]
        with tf.name_scope("Accuracy"):
                accuracy, accuracy_update_op  = tf.metrics.accuracy(labels = tf.argmax(y,1), predictions = tf.argmax(predictions, axis = 1), name = 'accuracy')
                running_vars_accuracy = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope="LSTM/Accuracy")
        with tf.name_scope("AUC"):
                auc, auc_update_op  = tf.metrics.auc(labels = tf.argmax(y,1), predictions = predictions[:,1], name = 'auc')
                running_vars_auc = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope="LSTM/AUC")
        with tf.name_scope('Loss'):
            xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y, name='xentropy')
            loss = tf.reduce_mean(xentropy, name="loss")
        with tf.name_scope('Train'):
            optimizer= tf.train.AdamOptimizer(learning_rate=initial_learning_rate)
            trainer=optimizer.minimize(loss, name="training_op")
        with tf.name_scope("Saver"):
            saver = tf.train.Saver(var_list=tf.trainable_variables()) 
        with tf.name_scope("init"):
            global_variables_init = tf.global_variables_initializer()
            running_vars_initializer_accuracy = tf.variables_initializer(var_list=running_vars_accuracy)
            running_vars_initializer_auc = tf.variables_initializer(var_list=running_vars_auc)

#EXECUTE THE COMPUTATIONAL GRAPH
#Network parameters
num_epochs = 20
max_checks_without_progress = 200
check_without_progress = 0
best_loss = np.infty
output_keep_var = 0.5

def get_model_params():
    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)
    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}

def restore_model_params(model_params):
    gvar_names = list(model_params.keys())
    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + "/Assign")
                  for gvar_name in gvar_names}
    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}
    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}
    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)
    
    
with tf.Session(graph = graph) as sess:
    global_variables_init.run()
    final_model_path = "./my_deep_model_MNIST.ckpt"
        
    print("Initialized")
    # Training cycle
    val_loss = []
    val_accuracy = []
    train_loss = []
    train_accuracy = []
    total_train_batch = int(X_train.shape[0]/ batch_size + 1)
    total_val_batch = int(X_val.shape[0]/ batch_size + 1)
        
    for epoch in range(0, num_epochs):
        avg_cost_train = 0.
        avg_accuracy_train =0
        avg_cost_val = 0.
        avg_accuracy_val =0
        
        
        running_vars_initializer_accuracy.run()
        running_vars_initializer_auc.run()
        sess.run(training_init_op, feed_dict={features_placeholder: X_train, labels_placeholder: y_train})
        # Loop over all batches
        for _ in range(total_train_batch):
            _, miniBatchCost_train, _, _ = sess.run([trainer, loss, accuracy_update_op, auc_update_op], feed_dict={output_keep_prob: output_keep_var})
            avg_cost_train += miniBatchCost_train / total_train_batch
        accuracy_train = sess.run(accuracy)
        AUC_train = sess.run(auc)
        train_loss.append(avg_cost_train)
        train_accuracy.append(avg_accuracy_train)
        
        running_vars_initializer_accuracy.run()
        running_vars_initializer_auc.run()
        sess.run(validation_init_op, feed_dict={features_placeholder: X_val, labels_placeholder: y_val})
        for _ in range(total_val_batch):
            miniBatchCost_val, _, _ = sess.run([loss, accuracy_update_op, auc_update_op])
            avg_cost_val += miniBatchCost_val / total_val_batch
        accuracy_val = sess.run(accuracy)
        AUC_val = sess.run(auc)
        val_loss.append(avg_cost_val)
        val_accuracy.append(avg_accuracy_val)
        
        if avg_cost_val &lt; best_loss:
            save_path = saver.save(sess, final_model_path)
            best_params = get_model_params()
            best_loss = avg_cost_val
            check_without_progress = 0
            save_message = "*"
        else:
            check_without_progress +=1
            save_message = ""
            if check_without_progress &gt; max_checks_without_progress:
                print("Stopping Early! Loss has not improved in {} epochs".format(max_checks_without_progress))
                break
    
        print("Epoch: {:d}-".format(epoch), \
              "Training Loss: {:.6f}, ".format(avg_cost_train), \
              "Training Accuracy: {:&gt;.2%}, ".format(accuracy_train), \
              "Training AUC: {:&gt;.2%},".format(AUC_train), \
              "Validation Loss: {:.6f}, ".format(avg_cost_val), \
              "Validation Accuracy: {:&gt;.2%},".format(accuracy_val), \
              "Validation AUC: {:&gt;.2%},".format(AUC_val),\
              save_message)
    print("Optimization Finished!")

    # If we used early stopping then rollback to the best model found
    if best_params:
        restore_model_params(best_params)
    
    total_test_batch = int(X_test.shape[0]/ batch_size + 1)
    running_vars_initializer_accuracy.run()
    running_vars_initializer_auc.run()
    sess.run(testing_init_op, feed_dict={features_placeholder: X_test, labels_placeholder: y_test})
    for _ in range(total_test_batch):
        sess.run([accuracy_update_op, auc_update_op])
    accuracy_test= sess.run(accuracy)
    auc_test= sess.run(auc)
    print("Final test accuracy: {:&gt;.2%}".format(accuracy_test), "Final test AUC: {:&gt;6.1%}".format(auc_test))
    
    plt.plot(train_loss, label='Train Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Cost')
    plt.title("Loss")
    plt.legend()
    plt.show()
&lt;/denchmark-code&gt;

The model is saved. I try to restore model and use it to evaluate on ANOTHER dataset object (assuming test set of MNIST is a new dataset).
&lt;denchmark-code&gt;tf.reset_default_graph()
with tf.Session() as sess:
    new_saver = tf.train.import_meta_graph('my_deep_model_MNIST.ckpt.meta')
    new_saver.restore(sess, tf.train.latest_checkpoint('./'))
    print("Restored Operations from MetaGraph")
    g = tf.get_default_graph()
    
    predictions = g.get_tensor_by_name('LSTM/Predictions/predictions:0')
    
    accuracy_update_op = g.get_tensor_by_name('LSTM/Accuracy/accuracy/update_op:0')
    accuracy = g.get_tensor_by_name('LSTM/Accuracy/accuracy/value:0')
    
    auc_update_op = g.get_tensor_by_name('LSTM/AUC/auc/update_op:0')
    auc = g.get_tensor_by_name('LSTM/AUC/auc/value:0')
    
    ################ Let's start another dataset object################
    batch_size = 128
    Xtest = mnist.test.images[mnist.test.labels &lt; 2].reshape([-1, num_steps, num_inputs])
    ytest = mnist.test.labels[mnist.test.labels &lt; 2]

    featuresplaceholder = tf.placeholder(dtype=tf.float32, shape=[None, num_steps, num_inputs])
    labelsplaceholder = tf.placeholder(tf.int32, shape=[None])
    

    train = tf.data.Dataset.from_tensor_slices(featuresplaceholder)
    train = tf.data.Dataset.from_tensor_slices(labelsplaceholder).map(lambda z: tf.one_hot(z, 2))
    dataset = tf.data.Dataset.zip((train, train)).batch(batch_size)

    iterator = tf.data.Iterator.from_structure(dataset.output_types,dataset.output_shapes)
    X, y = iterator.get_next()
    dataset_init_op = iterator.make_initializer(dataset)
    ###############################################################
    
    total_test_batch = int(Xtest.shape[0]/ batch_size + 1)
    tf.local_variables_initializer().run()
    sess.run(dataset_init_op, feed_dict={featuresplaceholder: Xtest, labelsplaceholder: ytest})
    for _ in range(total_test_batch):
        sess.run([accuracy_update_op, auc_update_op])
    accuracy_test= sess.run(accuracy)
    auc_test= sess.run(auc)
    print("Final test accuracy: {:&gt;.2%}".format(accuracy_test), "Final test AUC: {:&gt;6.1%}".format(auc_test))
&lt;/denchmark-code&gt;

However, I am having an FailedPreconditionError error, even though I initialize the iterator using  sess.run(dataset_init_op, feed_dict={featuresplaceholder: Xtest, labelsplaceholder: ytest}). That is really strange because the same code works without using Tensorflow Data API and using only feed_dict.
&lt;denchmark-code&gt;---------------------------------------------------------------------------
FailedPreconditionError                   Traceback (most recent call last)
/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1321     try:
-&gt; 1322       return fn(*args)
   1323     except errors.OpError as e:

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1306       return self._call_tf_sessionrun(
-&gt; 1307           options, feed_dict, fetch_list, target_list, run_metadata)
   1308 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1408           self._session, options, feed_dict, fetch_list, target_list,
-&gt; 1409           run_metadata)
   1410     else:

FailedPreconditionError: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,28,28], [?,2]], output_types=[DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](Iterator)]]
	 [[Node: IteratorGetNext/_11 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_17_IteratorGetNext", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()]]

During handling of the above exception, another exception occurred:

FailedPreconditionError                   Traceback (most recent call last)
&lt;ipython-input-2-20929b658f9d&gt; in &lt;module&gt;()
     37     sess.run(dataset_init_op, feed_dict={featuresplaceholder: Xtest, labelsplaceholder: ytest})
     38     for _ in range(total_test_batch):
---&gt; 39         sess.run([accuracy_update_op, auc_update_op])
     40     accuracy_test= sess.run(accuracy)
     41     auc_test= sess.run(auc)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    898     try:
    899       result = self._run(None, fetches, feed_dict, options_ptr,
--&gt; 900                          run_metadata_ptr)
    901       if run_metadata:
    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1134       results = self._do_run(handle, final_targets, final_fetches,
-&gt; 1135                              feed_dict_tensor, options, run_metadata)
   1136     else:
   1137       results = []

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1314     if handle is None:
   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,
-&gt; 1316                            run_metadata)
   1317     else:
   1318       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1333         except KeyError:
   1334           pass
-&gt; 1335       raise type(e)(node_def, op, message)
   1336 
   1337   def _extend_graph(self):

FailedPreconditionError: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,28,28], [?,2]], output_types=[DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](Iterator)]]
	 [[Node: IteratorGetNext/_11 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_17_IteratorGetNext", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()]]

Caused by op 'IteratorGetNext', defined at:
  File "/usr/lib/python3.5/runpy.py", line 184, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.5/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py", line 16, in &lt;module&gt;
    app.launch_new_instance()
  File "/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py", line 658, in launch_instance
    app.start()
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py", line 486, in start
    self.io_loop.start()
  File "/home/musara1/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py", line 148, in start
    self.asyncio_loop.run_forever()
  File "/usr/lib/python3.5/asyncio/base_events.py", line 345, in run_forever
    self._run_once()
  File "/usr/lib/python3.5/asyncio/base_events.py", line 1312, in _run_once
    handle._run()
  File "/usr/lib/python3.5/asyncio/events.py", line 125, in _run
    self._callback(*self._args)
  File "/home/musara1/.local/lib/python3.5/site-packages/tornado/ioloop.py", line 743, in _run_callback
    ret = callback()
  File "/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py", line 536, in &lt;lambda&gt;
    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))
  File "/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py", line 450, in _handle_events
    self._handle_recv()
  File "/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File "/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py", line 432, in _run_callback
    callback(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/zmq/eventloop/minitornado/stack_context.py", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py", line 399, in execute_request
    user_expressions, allow_stdin)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File "/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py", line 2662, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py", line 2785, in _run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py", line 2901, in run_ast_nodes
    if self.run_code(code, result):
  File "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py", line 2961, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "&lt;ipython-input-2-20929b658f9d&gt;", line 3, in &lt;module&gt;
    new_saver = tf.train.import_meta_graph('my_deep_model_MNIST.ckpt.meta')
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py", line 1960, in import_meta_graph
    **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/meta_graph.py", line 744, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py", line 432, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py", line 442, in import_graph_def
    _ProcessNewOps(graph)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py", line 234, in _ProcessNewOps
    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 3563, in _add_new_tf_operations
    for c_op in c_api_util.new_tf_operations(self)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 3563, in &lt;listcomp&gt;
    for c_op in c_api_util.new_tf_operations(self)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 3450, in _create_op_from_tf_operation
    ret = Operation(c_op, self)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 1740, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

FailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,28,28], [?,2]], output_types=[DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](Iterator)]]
	 [[Node: IteratorGetNext/_11 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_17_IteratorGetNext", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"]()]]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mmuratarat' date='2019-09-05T23:30:13Z'>
		&lt;denchmark-link:https://github.com/mmuratarat&gt;@mmuratarat&lt;/denchmark-link&gt;
 Is this still an issue? If yes, could you try with recent TF versions (, , ) and let us know whether the issue persists?
Please try to follow new tutorials &lt;denchmark-link:https://www.tensorflow.org/guide/saved_model&gt;Save and Restore&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://www.tensorflow.org/guide/datasets&gt;datasets&lt;/denchmark-link&gt;
. Also, try to provide a simplified standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='mmuratarat' date='2019-09-11T17:58:09Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='3' author='mmuratarat' date='2019-09-11T17:58:10Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26886&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26886&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>