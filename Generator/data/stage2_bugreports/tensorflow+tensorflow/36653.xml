<bug id='36653' author='gudiandian' open_date='2020-02-11T10:05:11Z' closed_time='2020-02-12T06:11:28Z'>
	<summary>Results difference after converting a tensorflow op to TfLite</summary>
	<description>
System information

Have I written custom code: No
OS Platform and Distribution: MacOS 10.15
TensorFlow version: 2.0
Python version: 3.6.9

Describe the current behavior
I converted a Tensorflow model with only one Tensorflow Keras layer tf.keras.layers.Conv2D to TFLite and ran the TFLite model. There was no quantization when converting the model.
Describe the expected behavior
The expected output of the TFLite model should be the same as the output of the Tensorflow model. However, the output of the TFLite model is slightly different from the result of the original Tensorflow model. I'm not sure whether this is a bug of TFLite framework or there was something wrong when I converted the Tensorflow model toTFLite.
Code to reproduce the issue
import tensorflow as tf

input = tf.keras.layers.Input(shape=(224, 224, 3), dtype='float32')
output = (filters=64, kernel_size=(7,7), strides=(2,2), padding='valid', data_format="channels_last", activation='linear', dilation_rate=(1,1), bias_initializer='zeros')(input)
tfmodel = tf.keras.Model(inputs=input, outputs=output)

x = tf.random.normal([1,224, 224, 3], dtype=tf.float32)
tf_y = tfmodel(x)

conv = tf.lite.TFLiteConverter.from_keras_model(tfmodel)
lite_bytes = conv.convert()
interp = tf.lite.Interpreter(model_content=lite_bytes)

input_index = interp.get_input_details()[0]['index']
output_index = interp.get_output_details()[0]['index']
interp.resize_tensor_input(input_index, [1, 224, 224, 3])
interp.allocate_tensors()
interp.set_tensor(input_index, x)
interp.invoke()
lite_y = interp.get_tensor(output_index)
Other info / logs
The issue is similar when the Conv2D layer is replaced with BatchNormalization layer.
	</description>
	<comments>
		<comment id='1' author='gudiandian' date='2020-02-11T22:38:22Z'>
		@MonicaGu I ran your code and find very very small mismatch (in the 7th decimal) in the results between keras  and tflite_model. Do you see significantly different results. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/e7d0429feef15a434a36e5226c10f214/untitled819.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='gudiandian' date='2020-02-12T03:16:48Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 In my case, I also found very small mismatch in the 7th or 6th decimal. I am not sure is this small mismatch inevitable? Or is this caused by a bug in the computation of Conv2D in TFLite? Thank you!
		</comment>
		<comment id='3' author='gudiandian' date='2020-02-12T06:11:28Z'>
		It's expected behavior. Since floating point has limited precision, calculated results can be vary by order of execution.
&lt;denchmark-link:https://en.wikipedia.org/wiki/Floating-point_arithmetic#Accuracy_problems&gt;https://en.wikipedia.org/wiki/Floating-point_arithmetic#Accuracy_problems&lt;/denchmark-link&gt;

You can see we're allowing 1e-5 (0.00001) errors in our TFLite kernel testing.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/conv_test.cc#L819&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/conv_test.cc#L819&lt;/denchmark-link&gt;

So the 7th or 6th decimal difference looks good.
		</comment>
		<comment id='4' author='gudiandian' date='2020-02-12T06:11:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36653&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36653&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>