<bug id='40233' author='willbattel' open_date='2020-06-07T07:31:31Z' closed_time='2020-06-16T11:50:12Z'>
	<summary>Encountered fatal Python error with TFLite Experimental Converter</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tensorflow/tensorflow:latest-gpu Docker image on Ubuntu 20.04 host on GCP Compute Engine VM
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
Python version: 3.6.9
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 10.2 (Using Docker TensorFlow GPU image)
GPU model and memory: Tesla V100-SXM2-16GB


I'm using the new QAT API demonstrated in the docs &lt;denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training_example&gt;here&lt;/denchmark-link&gt;
. Then I'm taking the resulting model and converting it to TFLite, again referencing the docs. Everything works as advertised until converting the model, where I encounter an error (see logs below).
Describe the expected behavior
I expected to get a converted model I could save as a tflite binary. I was only able to do this when explicitly disabling the experimental converter.
Standalone code to reproduce the issue
I don't have this available at the moment- I will try to provide this when able. In the meantime, this is the code snippet surrounding the problem. Let me know if this is insufficient.
&lt;denchmark-code&gt;model = tfmot.quantization.keras.quantize_model(model)
model.compile(optimizer=optimizer, loss=loss)
history = model.fit(train_dataset, epochs=FLAGS.epochs, callbacks=callbacks, validation_data=val_dataset)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
# converter.experimental_new_converter = False # Must uncomment this line to convert successfully
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open("output.tflite", 'wb') as f:
    f.write(tflite_model)
&lt;/denchmark-code&gt;

Our model is made up of the following Keras layers: Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, and BatchNormalization organized into several sub-models. Each submodel is quantized on its own because the  API does not have native support for submodels. &lt;denchmark-link:https://github.com/tensorflow/model-optimization/issues/377#issuecomment-623586866&gt;This &lt;/denchmark-link&gt;
 was the recommended workaround until that is added.
Other info / logs
It's a long one, here is what was spit out. All lines following line 59 were output together at the end. From my point of view the console didn't update from line 59 for several minutes until it all appeared together. I checked nvidia-smi while I waited and noticed GPU VRAM usage was at 100% (almost 16GB was being used by the Python process running this script) but GPU utilization was at 0%. Checking htop showed RAM and CPU usage very low at the time.
&lt;denchmark-link:https://pastebin.com/LMNefb3V&gt;https://pastebin.com/LMNefb3V&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='willbattel' date='2020-06-08T08:54:06Z'>
		&lt;denchmark-link:https://github.com/willbattel&gt;@willbattel&lt;/denchmark-link&gt;
,
In order to expedite the trouble-shooting process, could you please provide the complete code or the  file you are using in the code. Thanks!
		</comment>
		<comment id='2' author='willbattel' date='2020-06-08T20:16:45Z'>
		Sure, I'll try to bring that code over. I need to clean it up first.
		</comment>
		<comment id='3' author='willbattel' date='2020-06-15T18:44:32Z'>
		
Sure, I'll try to bring that code over. I need to clean it up first.

&lt;denchmark-link:https://github.com/willbattel&gt;@willbattel&lt;/denchmark-link&gt;
,
Any updates regarding this? Thanks!
		</comment>
		<comment id='4' author='willbattel' date='2020-06-15T23:43:29Z'>
		
Any updates regarding this? Thanks!

Not yet. I've been delayed by other work that is higher priority because this issue wasn't blocking for us. Because it works if you disable the experimental converter, I just wanted to submit the issue for your reference. If I find time to submit a reproducible sample, I'll add that in this thread- I can't just drop in what we ran because it is littered with clutter, proprietary code, etc.... In the mean time, if you would like to close this issue you can do so. We could re-open it later, or I could always submit a new issue if need-be.
		</comment>
		<comment id='5' author='willbattel' date='2020-06-16T11:50:05Z'>
		&lt;denchmark-link:https://github.com/willbattel&gt;@willbattel&lt;/denchmark-link&gt;
,
Thank you for the update. Marking the issue as close, please feel free to reopen if necessary. Thanks!
		</comment>
		<comment id='6' author='willbattel' date='2020-06-16T11:50:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40233&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40233&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>