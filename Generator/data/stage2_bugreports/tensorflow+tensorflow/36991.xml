<bug id='36991' author='janosh' open_date='2020-02-23T13:03:27Z' closed_time='2020-02-25T11:58:20Z'>
	<summary>How to get integer batch size in Keras model.fit()</summary>
	<description>
I'm trying to use model.fit() on a Sequential model consisting of custom layers subclassing tf.keras.layers.Layer. Using GradientTape where I feed every batch in explicitly works fine (including in graph mode with tf.function). Trying to use the high-level Keras API for training,
model.compile(loss=loss_fn, optimizer="adam")
model.fit(X_train, y_train)
I get a bunch of ValueError: None values not supported. for things like
def call(self, x):
    ...
    epsilon = tf.random.normal(x.shape)  # reparametrization trick
    ...
since x.shape[0] is None. So the question is, how do I get an integer batch size when using model.fit()? I tried
model.compile(loss=loss_fn, optimizer="adam")
model.fit(
    X_train, y_train, batch_size=64, steps_per_epoch=X_train.shape[0] // 64,
)
but that makes no difference. x.shape[0] remains None during graph creation.
	</description>
	<comments>
		<comment id='1' author='janosh' date='2020-02-23T15:41:59Z'>
		Can you please try numpy.shape(X_train)[0]//64
		</comment>
		<comment id='2' author='janosh' date='2020-02-23T15:51:58Z'>
		Please let me know if it works.
		</comment>
		<comment id='3' author='janosh' date='2020-02-23T17:39:50Z'>
		&lt;denchmark-link:https://github.com/ghosalsattam&gt;@ghosalsattam&lt;/denchmark-link&gt;
 Makes no difference.
		</comment>
		<comment id='4' author='janosh' date='2020-02-23T18:02:27Z'>
		Can you provide me the full code?
		</comment>
		<comment id='5' author='janosh' date='2020-02-23T20:00:07Z'>
		&lt;denchmark-link:https://github.com/ghosalsattam&gt;@ghosalsattam&lt;/denchmark-link&gt;
 Sorry, the code should remain private for now. But the following stripped down example already exhibits the problem:
import tensorflow as tf

class Foo(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__()

    def call(self, x):
        return tf.random.normal(x.shape)

model = tf.keras.Sequential([Foo()])

model.compile()

model.fit(tf.random.normal([10,5]), tf.random.normal([10]))
		</comment>
		<comment id='6' author='janosh' date='2020-02-24T04:42:15Z'>
		It is difficult to say something if I don't have any information of x. But from the error it seems that in the function, the value of x passed does not match the x you intend to pass.  May be it is an array of None.
		</comment>
		<comment id='7' author='janosh' date='2020-02-24T14:11:06Z'>
		&lt;denchmark-link:https://github.com/janosh&gt;@janosh&lt;/denchmark-link&gt;
,
I tried to run the above code snippet and am facing an error stating . You can find the gist of it &lt;denchmark-link:https://colab.sandbox.google.com/gist/saikumarchalla/641b725d245017106586ab46c03acdea/36991.ipynb&gt;here&lt;/denchmark-link&gt;
.
Could you please confirm if you are facing the same error? Thanks!
		</comment>
		<comment id='8' author='janosh' date='2020-02-24T14:12:28Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 Yes, that's the error I'm getting as well.
		</comment>
		<comment id='9' author='janosh' date='2020-02-24T15:10:50Z'>
		&lt;denchmark-link:https://github.com/janosh&gt;@janosh&lt;/denchmark-link&gt;

Then you can try using batch size =1
I used the approach for a slightly different case and it worked there.
You can use the format of batch size used in predict().
for i in range(30,70):
print(i)
Pixels,img=detectCorner(path,i)
if(len(Pixels)==0):
continue
Roi=findClusters(Pixels,img)
print(Roi)
crop = np.empty((40,32,32,1),dtype=int)
for roi in range(len(Roi)):
for j in range(30,70):
ll=Roi[roi][0]
ur=Roi[roi][1]
print(ll,ur)
img1=pronounce(data[:,:,j].T)
#print(ll[0],ur[0])
crop1=img1[ur[0]:ll[0],ll[1]:ur[1]]
plt.imshow(crop1,'gray')
#plt.show()
crop1=cv2.resize(crop1,interpolation=cv2.INTER_CUBIC,dsize=(32,32))
crop[j-30,]=np.expand_dims(crop1,axis=2)
#print(np.shape(crop[roi]))
#crop[roi]=np.expand_dims(crop[roi],axis=2)
a=classifier.predict_classes(crop)#batch size=1
For details:
&lt;denchmark-link:https://stackoverflow.com/questions/35289773/cannot-convert-a-partially-converted-tensor-in-tensorflow&gt;https://stackoverflow.com/questions/35289773/cannot-convert-a-partially-converted-tensor-in-tensorflow&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='janosh' date='2020-02-24T15:11:11Z'>
		Hope this helps.
		</comment>
		<comment id='11' author='janosh' date='2020-02-24T17:23:07Z'>
		Use tf.shape(x) instead of x.shape.
x.shape is the static shape of x and evaluates to (None,5).
tf.shape(x) on the other hand is the dynamic shape of x and is evaluated as the actual shape of x when training/predicting.
		</comment>
		<comment id='12' author='janosh' date='2020-02-24T17:36:15Z'>
		&lt;denchmark-link:https://github.com/sixChar&gt;@sixChar&lt;/denchmark-link&gt;
 Thanks, I tried that as well but it's not really a solution. The errors in my case are thrown by some nested functions that really only need to know the size of the first dimension of . If I pass in  instead of , nothing changes. I get the same errors saying  for things like  where  was passed in as .  I suspect that it might work if I pass in the whole tensor and only call tf.shape in the nested functions themselves. But I'd prefer not to do that since those functions don't need to know anything except .
		</comment>
		<comment id='13' author='janosh' date='2020-02-24T20:22:43Z'>
		Could you give an example of the kind of code that still causes the same error when using tf.shape(x)[0]?
		</comment>
		<comment id='14' author='janosh' date='2020-02-25T11:58:20Z'>
		&lt;denchmark-link:https://github.com/sixChar&gt;@sixChar&lt;/denchmark-link&gt;
 Oops, I take it all back. I tried producing a minimal example that errors with . Didn't manage though. So I went back to my actual code and tried to find out why I was still getting the error there. Turns out there was one place I had overlooked converting from  to . To be fair, the graph code you get when debugging  is pretty near unreadable which is why I'd missed it. Sorry about the noise.
		</comment>
		<comment id='15' author='janosh' date='2020-02-25T11:58:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36991&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36991&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='janosh' date='2020-02-25T15:56:55Z'>
		One final suggestion though: I think it would help if the &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/shape?version=nightly&gt;docs on tf.shape&lt;/denchmark-link&gt;
 as well as the &lt;denchmark-link:https://www.tensorflow.org/guide/keras/custom_layers_and_models&gt;Writing custom layers and models with Keras&lt;/denchmark-link&gt;
 guide had a note on this, i.e. that  should be used instead of  when defining custom layers and models to avoid  errors.
		</comment>
		<comment id='17' author='janosh' date='2020-02-25T20:27:55Z'>
		&lt;denchmark-link:https://github.com/janosh&gt;@janosh&lt;/denchmark-link&gt;
 Would you like to update docs through PR? Thanks!
		</comment>
		<comment id='18' author='janosh' date='2020-02-26T10:40:52Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 PR submitted. Suggestions for improvement welcome.
		</comment>
		<comment id='19' author='janosh' date='2020-08-17T16:53:10Z'>
		&lt;denchmark-link:https://github.com/Al-Badri179&gt;@Al-Badri179&lt;/denchmark-link&gt;
 Can you please open a new issue with a simple standalone code to reproduce the issue? Thanks!
		</comment>
		<comment id='20' author='janosh' date='2020-08-17T19:13:17Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 ok, sorry for inconvenience
		</comment>
	</comments>
</bug>