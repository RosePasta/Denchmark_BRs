<bug id='39643' author='tanguycdls' open_date='2020-05-18T10:03:07Z' closed_time='2020-07-22T01:52:06Z'>
	<summary>predict on batch and predict have different behavior Assert and control depedencies</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
I have a custom keras layer with an assertion and a control depedencies:
&lt;denchmark-code&gt;class CustomLayer(Layer):
  def call(self, inputs):
    assert_same_batch_size = tf.assert_equal(tf.shape(inputs[0])[0],
                                                 tf.shape(inputs[1])[0], message="inputs do not have equal batch_size")
    with tf.control_dependencies([assert_same_batch_size]):
      return tf.reshape(inputs[0], (tf.shape(inputs[0])[0], 3))   # i want it to break

a = Input(shape=1)
b = Input(shape=1)
out = CustomLayer()([a, b])
m = Model([a, b], out)
&lt;/denchmark-code&gt;


m.predict_on_batch([tf.constant(np.ones((10, 1))), tf.constant(np.ones((15, 1)))])

&lt;denchmark-code&gt;ValueError: Cannot reshape a tensor with 10 elements to shape [10,3] (30 elements) for '{{node model_2/custom_layer_8/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](model_2/Cast, model_2/custom_layer_8/Reshape/shape)' with input shapes: [10,1], [2] and with input tensors computed as partial shapes: input[1] = [10,3].
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;def generator(): # we use a generator to trick tf dataset into letting us use different nbr of rows in each vector
#(otherwise caught by tf.data.dataset.from_tensor_slices)
  for a in range(1):
    yield [tf.constant(np.ones((10, 1))), tf.constant(np.ones((15, 1)))]
m.predict(generator())
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;InvalidArgumentError:  assertion failed: [inputs do not have equal batch_size] [.....
&lt;/denchmark-code&gt;

Describe the expected behavior
The assertion error should be raised in both scenario with predict_on_batch and with predict. We dont know if its because control depencies is not used with predict_on_batch or if it comes from the assert.

&lt;denchmark-link:https://colab.research.google.com/gist/tanguycdls/d36d2a1175cec79143d0a3e9dddfbbad/untitled14.ipynb&gt;https://colab.research.google.com/gist/tanguycdls/d36d2a1175cec79143d0a3e9dddfbbad/untitled14.ipynb&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='tanguycdls' date='2020-05-19T14:02:41Z'>
		&lt;denchmark-link:https://github.com/tanguycdls&gt;@tanguycdls&lt;/denchmark-link&gt;

Can you please refer to these links for the value error faced in your gist:&lt;denchmark-link:https://stackoverflow.com/questions/51746179/valueerror-cannot-reshape-a-tensor-with-99872-elements-to-shape-1-125-1-8&gt;
link&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://www.dotnetperls.com/reshape-tensorflow&gt;link1&lt;/denchmark-link&gt;
 and for the invalid argument please refer to: &lt;denchmark-link:https://stackoverflow.com/questions/58609967/tensorflow-2-0-condition-x-y-did-not-hold-element-wise&gt;link&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/models/issues/2737&gt;link1&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32333&gt;link2&lt;/denchmark-link&gt;
, let us know if this helps.
		</comment>
		<comment id='2' author='tanguycdls' date='2020-05-19T14:10:45Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 thanks for your message !
my point is not the actual errors (that i produced on purpose): its that for the same input predict yields to an error the assert_same_batch_size error and predict_on_batch breaks later in ValueError: Cannot reshape a tensor with 10.
I think its odd that predict and predict_on_batch does not yield to the same error being caught for the same input.
		</comment>
		<comment id='3' author='tanguycdls' date='2020-05-19T14:16:13Z'>
		I am able to replicate the issue reported please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/4abf0d96e9e3d11b30e74dcc98a959cc/untitled189.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='tanguycdls' date='2020-05-29T01:09:19Z'>
		&lt;denchmark-link:https://github.com/tanguycdls&gt;@tanguycdls&lt;/denchmark-link&gt;
 I think there is some typo or extra dimension as input to the .
I changed one line as follows and the two errors are similar and shows  related to mismatch in batch_size. Please take a look at the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/62a964d8cba44476778bfa17bde76459/untitled189.ipynb#scrollTo=b5zRT4LoOXzK&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
&lt;denchmark-code&gt;assert_same_batch_size = tf.assert_equal(tf.shape(inputs[0]),
                                                 tf.shape(inputs[1]), message="inputs do not have equal batch_size")
&lt;/denchmark-code&gt;

Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='5' author='tanguycdls' date='2020-05-29T08:13:31Z'>
		Hi &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks for the response !
I checked and yes it works but actually we only want to check the first shape dim not the second one ! Maybe it's the get_item that breaks it ? maybe i can try a tf.gather instead of [0]? I will try and get back to you.
		</comment>
		<comment id='6' author='tanguycdls' date='2020-07-08T00:11:13Z'>
		&lt;denchmark-link:https://github.com/tanguycdls&gt;@tanguycdls&lt;/denchmark-link&gt;
 Is this still an issue for you? Thanks!
		</comment>
		<comment id='7' author='tanguycdls' date='2020-07-15T00:55:16Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='tanguycdls' date='2020-07-22T01:52:05Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='9' author='tanguycdls' date='2020-07-22T01:52:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39643&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39643&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>