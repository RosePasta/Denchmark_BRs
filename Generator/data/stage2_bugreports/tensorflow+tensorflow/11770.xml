<bug id='11770' author='JohnScolaro' open_date='2017-07-26T01:36:39Z' closed_time='2017-12-09T02:24:27Z'>
	<summary>tf.contrib.data.Dataset filter documentation broken</summary>
	<description>
With the old input pipeline functions, in tf.train.batch() you could specify the "allow_smaller_final_batch" parameter, which would allow or disallow a smaller final batch. With the new input pipeline functions in tf.contrib.data, the batch function allows a smaller final batch by default, and (to the best of my knowledge) there is no way to skip this last half-batch to ensure all batch sizes are equal.
Is there a possibility that a "allow_smaller_final_batch" flag could be added to the new batch function?
	</description>
	<comments>
		<comment id='1' author='JohnScolaro' date='2017-07-26T06:17:22Z'>
		My guess is that this is more cleanly accomplished using the filter() method on Dataset, where the predicate is one that checks that tf.shape(value)[batch_dim] == batch_size.  So something like
dataset = .. your dataset
dataset = dataset.filter(lambda t: tf.equal(tf.shape(t)[0], batch_size))
and then your iterator will only yield values where the Tensor matches the expected batch size.
(If this satisfies your use case, feel free to close this issue).
		</comment>
		<comment id='2' author='JohnScolaro' date='2017-07-26T08:10:28Z'>
		Thanks a bunch &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
. That does exactly what I wanted it too, and much neater than just catching an exception and not training on that specific batch.
It might be worth bringing this up though: The reason I wasn't able to find the filter function is because the file located &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/data/python/ops/dataset_ops.py&gt;here&lt;/denchmark-link&gt;
 is missing a ``` to end the code example (on line 632), and this has included the filter function in the Enumerate sections code, rendering it unsearchable. &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/contrib/data/TFRecordDataset#enumerate&gt;See here&lt;/denchmark-link&gt;

Is this something that can be fixed?
Thanks again for the help.
		</comment>
		<comment id='3' author='JohnScolaro' date='2017-07-26T16:27:41Z'>
		Definitely, I'll retitle the bug accordingly!  I'll also point you towards the following, which is also a helpful reference:  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/programmers_guide/datasets.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/programmers_guide/datasets.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='JohnScolaro' date='2017-12-09T02:24:27Z'>
		Hey, this specific bug has been fixed by the deprecation of enumerate() to enumerate_dataset()
(see here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/enumerate_ops.py&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/python/ops/enumerate_ops.py&lt;/denchmark-link&gt;
)
So I'm closing this out unless there's a reason to keep it open?
		</comment>
	</comments>
</bug>