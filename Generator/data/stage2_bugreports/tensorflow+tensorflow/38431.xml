<bug id='38431' author='adfayed' open_date='2020-04-10T13:09:23Z' closed_time='2020-08-12T09:21:12Z'>
	<summary>Converting retrained ssd_resnet50_v1 object detection model to TFLite for use on Coral USB Accelerator</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): tf-nightly installed through pip
TensorFlow version (or github SHA if from source): 2.2.0.dev20200401
Nvidia GeForce GTX 1050 Ti Driver Version: 440.64.00
Cuda compilation tools, release 9.0, V9.0.176
CUDNN_MAJOR 7 CUDNN_MINOR 0 CUDNN_PATCHLEVEL 5
Edge TPU Compiler version 2.1.302470888

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;import tensorflow as tf

BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

list_ds_Dianthus = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Dianthus''*/*/*'))
list_ds_DustyMiller = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/DustyMiller''*/*/*'))
list_ds_Pansy = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Pansy''*/*/*'))
list_all = list_ds_Dianthus.concatenate(list_ds_DustyMiller).concatenate(list_ds_Pansy)
#len(list(list_all))

def get_label(file_path):
  parts = tf.strings.split(file_path, '/')
  class_name = tf.strings.split(parts[-3], '1')
  class_name = tf.strings.split(class_name, '2')
  class_name = tf.strings.split(class_name, '3')
  class_name = tf.strings.split(class_name, '4')
  return class_name

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 

def process_path(file_path):
  label = get_label(file_path)
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

num_calibration_steps= 1000

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open("/home/afayed/Desktop/output_tflite_graph.tflite", "wb").write(tflite_quant_model)
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. 
We are working on supporting control flow ops, 
please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. 
Some of the operators in the model are not supported by the 
standard TensorFlow Lite runtime and are not recognized by TensorFlow. 
If you have a custom implementation 
for them you can disable this error with --allow_custom_ops, or by setting 
allow_custom_ops=True when calling tf.lite.TFLiteConverter(). 
Here is a list of builtin operators you 
are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, 
GATHER, GREATER, GREATER_EQUAL,
LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, 
RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, 
SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, 
WHERE.Here is a list of operators for which you will need custom implementations: 
DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-h:h4&gt;Model ckpt 5 used here as a .tar.&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;Frozen graph generated here&lt;/denchmark-h&gt;

&lt;denchmark-h:h4&gt;saved_model.pb used here&lt;/denchmark-h&gt;

Failure details
Conversion not successful...
Any other info / logs
&lt;denchmark-h:h1&gt;Detailed explanation&lt;/denchmark-h&gt;

I am trying to use custom training data to retrain 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03' (model obtained from model zoo here ) following Google's Retrain an object detection model tutorial
I retrained it on custom training data using TensorFlow with GPU devel version 1.12.0-rc2 on a docker container built with this Dockerfile.
I also tried retraining with TensorFlow with GPU version 1.15.2. The pipeline config file I am using is available here.
I have made sure I used a fixed_shape_resizer and included "max_number_of_boxes: 200" in train_input_reader and eval_input_reader and all of that.
My image dimensions as found in pipeline_v2.config are 320,320.
I found the new Experimental Converter here
&lt;denchmark-h:h2&gt;So, my process is as such:&lt;/denchmark-h&gt;

I start the docker container and start retraining from ckpt 0 that is given by downloading the model from the model zoo:
&lt;denchmark-code&gt;sudo docker run --gpus all --name edgetpu-detect \
--rm -it --privileged -p 6006:6006 \
--mount type=bind,src=${DETECT_DIR},dst=/tensorflow/models/research/learn_pet \
detect-tutorial
&lt;/denchmark-code&gt;

For the sake of testing lets only retrain 5 steps (I've tried up to 20,000 giving the same results):
&lt;denchmark-code&gt;./retrain_detection_model.sh --num_training_steps 5 --num_eval_steps 100
&lt;/denchmark-code&gt;

retrain_detection_model.sh found &lt;denchmark-link:https://drive.google.com/open?id=1mMErPY2j68cNGDS_pmh9gbdAKOAvWmLB&gt;here&lt;/denchmark-link&gt;

(&lt;denchmark-link:https://drive.google.com/open?id=1nDNSpEyjExg-_L_wpaDJaNlbVrRvfbp8&gt;https://drive.google.com/open?id=1nDNSpEyjExg-_L_wpaDJaNlbVrRvfbp8&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;python /tensorflow/tensorflow/python/tools/saved_model_cli.py show --dir /tensorflow/models/research/learn_pet/train/export/Servo/1586336368/ --all &gt; /tensorflow/models/research/learn_pet/train/saved_model_cli_output.txt```
&lt;/denchmark-code&gt;

I then export a frozen graph using export_tflite_ssd_graph.py (unedited) both through 1.12.0-rc2 and 1.15.2 code shown here is using TF 1.15.2:
&lt;denchmark-code&gt;python object_detection/export_tflite_ssd_graph.py --pipeline_config_path="/tensorflow/models/research/learn_pet/ckpt/pipeline_v2.config" --trained_checkpoint_prefix="/tensorflow/models/research/learn_pet/train/model.ckpt-5" --output_directory="/tensorflow/models/research/learn_pet/models" 
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;root@d97ce87cb12f:/tensorflow/models/research# python object_detection/export_tflite_ssd_graph.py --pipeline_config_path="/tensorflow/learn_pet/ckpt/pipeline_v2.config" --trained_checkpoint_prefix="/tensorflow/learn_pet/train/model.ckpt-5" --output_directory="/tensorflow/learn_pet/models"
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0410 12:39:17.462405 140155277027136 module_wrapper.py:139] From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0410 12:39:17.465477 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0410 12:39:17.465742 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0410 12:39:17.468422 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0410 12:39:17.471358 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /tensorflow/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

W0410 12:39:18.826324 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

W0410 12:39:19.233271 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0410 12:39:19.890158 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-04-10 12:39:19.891180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 12:39:19.908694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.909025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:19.909296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.910343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:19.911197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:19.911425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:19.912640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:19.913612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:19.916425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:19.916589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.916980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.917217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:19.917530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 12:39:19.941192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 12:39:19.941657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efacc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 12:39:19.941674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 12:39:19.987579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.987958: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7905220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 12:39:19.987995: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 12:39:19.988151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.988386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:19.988425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.988441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:19.988454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:19.988469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:19.988485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:19.988499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:19.988516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:19.988588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.988915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.989197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:19.989246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.989760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 12:39:19.989773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2020-04-10 12:39:19.989782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2020-04-10 12:39:19.989861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.990093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.990307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2888 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0410 12:39:20.492587 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0410 12:39:20.495462 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.895448 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.895938 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896350 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896607 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896919 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897162 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897400 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897668 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897969 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898177 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898397 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898632 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898874 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899109 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899347 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899583 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899877 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900119 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900363 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900600 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900838 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901076 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901296 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901502 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901758 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901966 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902171 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902374 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902588 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902798 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903002 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903205 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903466 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903675 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903881 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904086 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904299 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904532 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904742 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904950 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.949430 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.949680 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.964820 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.965119 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.980214 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.980386 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.996045 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.996264 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.011528 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.011718 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.027328 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.027498 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.044524 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.044679 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.061121 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.061372 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.076568 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.076805 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.092691 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.092893 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.107756 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.107955 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.123640 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.123864 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.206912 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.297351 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.426005 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.500694 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add
I0410 12:39:22.099278 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add
I0410 12:39:22.099895 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add
I0410 12:39:22.100310 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add
I0410 12:39:22.100712 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add
I0410 12:39:22.101081 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add
I0410 12:39:22.101440 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add
I0410 12:39:22.101804 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add
I0410 12:39:22.102235 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add
I0410 12:39:22.102601 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add
I0410 12:39:22.103026 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add
I0410 12:39:22.103431 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add
I0410 12:39:22.103817 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add
I0410 12:39:22.104173 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add
I0410 12:39:22.104722 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add
I0410 12:39:22.105071 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add
I0410 12:39:22.105430 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add
INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add
I0410 12:39:22.105675 140155277027136 quantize.py:262] Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add
INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add_1
I0410 12:39:22.111881 140155277027136 quantize.py:262] Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add_1
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/conv1/add_fold
I0410 12:39:22.121784 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.122250 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.122534 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.122827 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.123043 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.123297 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.123489 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.123872 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.124067 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.124314 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.124595 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.124916 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.125163 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/add_fold
I0410 12:39:22.125458 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/add_fold
I0410 12:39:22.125700 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.126079 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.126330 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.126605 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.126782 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127025 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127182 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127393 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127542 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127753 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127903 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128112 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/add_fold
I0410 12:39:22.128261 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128529 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.128677 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128887 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.129033 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.129251 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.129395 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_2/add_fold
I0410 12:39:22.129603 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_1/add_fold
I0410 12:39:22.129747 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/add_fold
I0410 12:39:22.129896 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/add_fold
I0410 12:39:22.130037 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.130177 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.130314 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.130451 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.130587 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.130723 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.130858 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.130995 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.131131 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.131264 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.131427 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.131577 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.131731 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.131886 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.132046 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.132216 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.132382 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.132542 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.132689 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.132832 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.132973 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.133126 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.133264 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.133402 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.133538 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.133684 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.133875 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.134034 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.134214 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.134354 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.134491 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.134625 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.134763 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.134897 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.135031 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.135166 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.135301 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.135435 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.135572 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.135709 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.135844 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/add_fold
WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0410 12:39:22.138879 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0410 12:39:22.693765 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2020-04-10 12:39:23.471555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.471913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:23.471967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:23.471993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:23.472027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:23.472041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:23.472053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:23.472066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:23.472083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:23.472137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:23.472493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 12:39:23.472501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2020-04-10 12:39:23.472508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2020-04-10 12:39:23.472571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2888 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from /tensorflow/learn_pet/train/model.ckpt-5
I0410 12:39:23.473652 140155277027136 saver.py:1284] Restoring parameters from /tensorflow/learn_pet/train/model.ckpt-5
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0410 12:39:25.057172 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W0410 12:39:25.057349 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 923 variables.
I0410 12:39:25.800305 140155277027136 graph_util_impl.py:334] Froze 923 variables.
INFO:tensorflow:Converted 923 variables to const ops.
I0410 12:39:25.936274 140155277027136 graph_util_impl.py:394] Converted 923 variables to const ops.
2020-04-10 12:39:26.212524: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
root@d97ce87cb12f:/tensorflow/models/research# 

&lt;/denchmark-code&gt;

Now up until here everything goes relatively fine. However, converting this frozen graph or the resulting saved_model.pb from retraining causes issues.
&lt;denchmark-h:h3&gt;Method 1: converting a frozen using TFLite Converter (typically following the tutorial)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;tflite_convert  --output_file="/tensorflow/models/research/learn_pet/models/output_tflite_graph.tflite"   --graph_def_file="/tensorflow/models/research/learn_pet/models/tflite_graph.pb"   --inference_type=QUANTIZED_UINT8  --input_arrays='normalized_input_image_tensor'   --output_arrays="TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3" --mean_values=128 --std_dev_values=128 --input_shapes=1,320,320,3  --change_concat_input_ranges=false --allow_nudging_weights_to_use_fast_gemm_kernel=true --allow_custom_ops
&lt;/denchmark-code&gt;

I get this output message:
&lt;denchmark-code&gt;root@fe9c39ea1f8e:/tensorflow/models/research# tflite_convert  --output_file="/tensorflow/models/research/learn_pet/models/output_tflite_graph.tflite"   --graph_def_file="/tensorflow/models/research/learn_pet/models/tflite_graph.pb"   --inference_type=QUANTIZED_UINT8  --input_arrays='normalized_input_image_tensor'   --output_arrays="TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3" --mean_values=128 --std_dev_values=128 --input_shapes=1,320,320,3 \--change_concat_input_ranges=false --allow_nudging_weights_to_use_fast_gemm_kernel=true --allow_custom_ops        
2020-04-10 11:05:40.265936: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 11:05:40.330137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 11:05:40.330537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.11GiB
2020-04-10 11:05:40.330577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-04-10 11:05:40.571784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 11:05:40.571846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-04-10 11:05:40.571855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-04-10 11:05:40.571999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2822 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File "/usr/local/bin/tflite_convert", line 11, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py", line 412, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 125, in run
    _sys.exit(main(argv))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py", line 408, in run_main
    _convert_model(tflite_flags)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py", line 162, in _convert_model
    output_data = converter.convert()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/lite.py", line 464, in convert
    **converter_kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py", line 311, in toco_convert_graph_def
    input_data.SerializeToString())
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py", line 135, in toco_convert_protos
    (stdout, stderr))
RuntimeError: TOCO failed see console for info.
2020-04-10 11:05:43.184443: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TFLite_Detection_PostProcess
2020-04-10 11:05:43.418899: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1987 operators, 2964 arrays (0 quantized)
2020-04-10 11:05:43.488337: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1987 operators, 2964 arrays (0 quantized)
2020-04-10 11:05:46.741187: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 360 operators, 642 arrays (1 quantized)
2020-04-10 11:05:46.750968: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 360 operators, 642 arrays (1 quantized)
2020-04-10 11:05:46.755164: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 234 operators, 516 arrays (1 quantized)
2020-04-10 11:05:46.758687: F tensorflow/contrib/lite/toco/tooling_util.cc:1634] Array FeatureExtractor/resnet_v1_50/fpn/top_down/nearest_neighbor_upsampling/mul, which is an input to the Reshape operator producing the output array FeatureExtractor/resnet_v1_50/fpn/top_down/nearest_neighbor_upsampling/Reshape_1, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
Aborted

None
root@fe9c39ea1f8e:/tensorflow/models/research#
&lt;/denchmark-code&gt;

So I try adding  --default_ranges_min=0 and --default_ranges_max=6 following a Relu6 similar issue and it works, but fails at the edgetpu_compiler with:
Code used:
&lt;denchmark-code&gt;afayed@metecs-0497:~/coral/detection_ag/models$ sudo edgetpu_compiler output_tflite_graph.tflite
Edge TPU Compiler version 2.1.302470888 
ERROR: :79 input-&gt;params.zero_point != output-&gt;params.zero_point (107 != 0)
ERROR: Node number 77 (PACK) failed to prepare.

Internal compiler error. Aborting!
afayed@metecs-0497:~/coral/detection_ag/models$
&lt;/denchmark-code&gt;

Trying to convert the saved_model.pb route becomes a lot more interesting! This file gets generated after retraining in dir:
/tensorflow/models/research/learn_pet/train/export/Servo/1586490086/saved_model.pb
There are a few scripts I have found and stitched together. I will paste them each with their respective output: (The following is being run outside the docker container on my tf-nightly 2.2.0.dev20200401 pip install)
&lt;denchmark-h:h3&gt;Method 2 try 1: (converting a saved_model.pb using TFLite Converter)&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
converter.experimental_new_converter = **True or False**
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_quant_model = converter.convert()
&lt;/denchmark-code&gt;

I know the above used tf.float16 I was trying to get something... anything out of the converter. I might try GPU inference and drop the Coral USB Accelerator at this point with all this hassle or if its not even possible to use these more powerful models.
Output:
&lt;denchmark-code&gt;afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:52:09.463558: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:52:09.463687: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:52:09.463710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:52:11.015862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:52:11.033075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.033430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:52:11.033684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.035302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:52:11.036590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:52:11.036867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:52:11.038115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:52:11.038672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:52:11.040090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:52:11.040214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.040514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.040744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:52:11.041008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:52:11.065286: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:52:11.065997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf50e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:52:11.066016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:52:11.105688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.106075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf740d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:52:11.106093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:52:11.106271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.106524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:52:11.106575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.106590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:52:11.106604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:52:11.106618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:52:11.106632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:52:11.106646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:52:11.106659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:52:11.106705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.107028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.107216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:52:11.107242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.107840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:52:11.107853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:52:11.107862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:52:11.107946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.108196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.108428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2889 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:52:11.142004 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142286 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142424 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142553 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142632 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659588 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659760 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659844 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659930 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.660046 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539669 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539836 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539940 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.540039 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.540147 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977087 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977231 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977302 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977363 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977421 139754160563968 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
Traceback (most recent call last):
  File "/home/afayed/Desktop/test.py", line 6, in &lt;module&gt;
    tflite_quant_model = converter.convert()
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py", line 418, in convert
    raise ValueError("This converter can only convert a single "
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
afayed@metecs-0497:~$ 
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Method 2 try 2:&lt;/denchmark-h&gt;

Here I try the 'tf.lite.OpsSet.TFLITE_BUILTINS' and  'tf.lite.OpsSet.SELECT_TF_OPS'
&lt;denchmark-code&gt;import tensorflow as tf
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([1,320,320,3])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:54:40.829681: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:54:40.829826: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:54:40.829836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:54:42.415761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:54:42.433531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.433764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:54:42.433970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.435321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:54:42.436558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:54:42.436804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:54:42.438298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:54:42.438873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:54:42.440300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:54:42.440422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.440706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.440901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:54:42.441211: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:54:42.465540: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:54:42.466703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb492f10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:54:42.466747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:54:42.513942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.514292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb4b61a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:54:42.514310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:54:42.514512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.514784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:54:42.514855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.514901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:54:42.514913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:54:42.514940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:54:42.514950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:54:42.514960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:54:42.514990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:54:42.515094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.515367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.515614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:54:42.515671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.516305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:54:42.516329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:54:42.516336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:54:42.516450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.516728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.516989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2889 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:54:42.553511 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.553783 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.553906 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.554021 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.554129 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.084858 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085023 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085146 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085255 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085352 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004590 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004742 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004844 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004932 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004984 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414238 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414433 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414536 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414678 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414774 139909104785152 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
Traceback (most recent call last):
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py", line 634, in set_shape
    unknown_shape)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 0 and 4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/afayed/Desktop/test.py", line 4, in &lt;module&gt;
    concrete_func.inputs[0].set_shape([1,320,320,3])
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py", line 637, in set_shape
    raise ValueError(str(e))
ValueError: Shapes must be equal rank, but are 0 and 4
afayed@metecs-0497:~$ 
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Method 2 try 3 fixing set_shape() to an empty array:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:56:49.944995: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:56:49.945132: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:56:49.945157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:56:50.596387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:56:50.613734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.613967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:50.614179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.615449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:50.616734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:50.617019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:50.618337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:50.619126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:50.620796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:50.620927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.621282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.621526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:50.621866: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:56:50.645443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:56:50.646094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6ca8e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:56:50.646140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:56:50.686690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6ccc110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:56:50.687046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:56:50.687214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:50.687508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.687520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:50.687531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:50.687541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:50.687551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:50.687561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:50.687571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:50.687658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.688156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:50.688198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.688912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:56:50.688923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:56:50.688947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:56:50.689028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.689310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.689592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:56:51.706341 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706622 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706747 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706877 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.707004 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.241864 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242060 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242195 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242302 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242417 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198438 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198575 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198707 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198782 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198846 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791184 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791393 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791527 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791616 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791716 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:56:56.510059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.510283: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 04:56:56.510477: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:56:56.510978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:56.511212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:56.511225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:56.511237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:56.511248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:56.511259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:56.511269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:56.511281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:56.511320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:56.511774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:56:56.511780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:56:56.511784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:56:56.511879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.512118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.512332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:56:56.562991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:56:56.563023: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 04:56:56.563028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
W0410 04:56:56.611888 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612050 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612152 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612239 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612321 139958945724160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:57:04.038498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.038786: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 04:57:04.038887: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:57:04.039420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.039698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:57:04.039781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:04.039814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:57:04.039826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:57:04.039851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:57:04.039862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:57:04.039872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:57:04.039902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:57:04.039942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:57:04.040460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:57:04.040467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:57:04.040472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:57:04.040530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:57:05.077944: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:57:05.077966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 572.089ms.
2020-04-10 04:57:05.078096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 197.05ms.
Traceback (most recent call last):
  File "/home/afayed/Desktop/test.py", line 14, in &lt;module&gt;
    tflite_model = converter.convert()
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py", line 464, in convert
    **converter_kwargs)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 203, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 04:57:06.359298: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:57:06.359375: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:57:06.359384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:57:07.195543: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-04-10 04:57:07.195587: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-04-10 04:57:07.626685: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:57:07.653251: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:57:07.653736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd39c1ec330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:57:07.653752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:57:07.655781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:57:07.701689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.701992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd39c2d6980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:57:07.702007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:57:07.702163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.702387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:57:07.702674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:07.704034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:57:07.705345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:57:07.705605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:57:07.706943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:57:07.707795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:57:07.709657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:57:07.709776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.710048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.710245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:57:07.710290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:07.710886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:57:07.710895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:57:07.710919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:57:07.711001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.711232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.711447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2250 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
loc(callsite("Equal"("/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py":559:0) at callsite("/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py":528:0 at "/home/afayed/Desktop/test.py":6:0))): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;!tf.string&gt;'
loc("case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
Traceback (most recent call last):
  File "/home/afayed/.local/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: /home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:559:7: error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;!tf.string&gt;'
      root = load_v1_in_v2.load(export_dir, tags)
      ^
/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:528:3: note: called from
  return load_internal(export_dir, tags)
  ^
/home/afayed/Desktop/test.py:6:1: note: called from
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
^
&lt;unknown&gt;:0: error: loc("case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'




afayed@metecs-0497:~$ 
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Method 2 try 4 with a representative dataset (Experimental Conv set to True):&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open("/home/afayed/Desktop/output_tflite_graph.tflite", "wb").write(tflite_quant_model)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:59:25.945004: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:25.945179: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:25.945191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:59:26.606701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:59:26.624591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.624832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:26.625073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.626365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:26.627619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:26.627865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:26.629198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:26.629971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:26.631630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:26.631723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.631985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.632169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:26.632490: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:59:26.657430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:59:26.658056: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54cf5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:26.658127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:59:26.698387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.698734: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54f2840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:26.698751: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:59:26.698947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:26.699285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.699298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:26.699339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:26.699362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:26.699390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:26.699400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:26.699411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:26.699463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:26.700007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.700625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:26.700635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:26.700660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:26.700750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.701018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.701311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:59:27.646008 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646277 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646404 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646530 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646658 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166036 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166230 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166350 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166450 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166565 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039237 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039395 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039500 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039588 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039674 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453517 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453718 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453832 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453950 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.454065 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:59:32.095622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.095855: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 04:59:32.096054: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:59:32.096504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.096702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:32.096732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:32.096744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:32.096755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:32.096765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:32.096774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:32.096784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:32.096794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:32.096834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:32.097391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:32.097416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:32.097422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:32.097561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.098006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:59:32.149381: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:59:32.149406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 04:59:32.149411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
W0410 04:59:32.196574 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196784 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196887 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196958 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.197010 140401577404160 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:59:39.254102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.254359: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 04:59:39.254457: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:59:39.254974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:39.255293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:39.255337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:39.255349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:39.255372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:39.255381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:39.255416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:39.255426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:39.255477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:39.255979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:39.255986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:39.256003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:39.256090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.256326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.256558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:59:40.209379: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:59:40.209410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 522.985ms.
2020-04-10 04:59:40.209481: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 186.768ms.
Traceback (most recent call last):
  File "/home/afayed/Desktop/test.py", line 32, in &lt;module&gt;
    tflite_quant_model = converter.convert()
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py", line 464, in convert
    **converter_kwargs)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 203, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 04:59:41.441981: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:41.442083: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:41.442091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:59:42.242273: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-04-10 04:59:42.242303: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-04-10 04:59:42.652620: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:59:42.677332: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:59:42.678004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2cc1ec790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:42.678035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:59:42.680364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:59:42.720113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.720401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2cc2d6f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:42.720417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:59:42.720579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.720802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:42.721080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:42.722453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:42.723755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:42.724027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:42.725595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:42.726508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:42.728483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:42.728633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.728920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.729150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:42.729198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:42.729846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:42.729856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:42.729881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:42.729971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.730223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.730515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2250 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
loc(callsite("Equal"("/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py":559:0) at callsite("/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py":528:0 at "/home/afayed/Desktop/test.py":23:0))): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;!tf.string&gt;'
loc("case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0"): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
Traceback (most recent call last):
  File "/home/afayed/.local/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: /home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:559:7: error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;!tf.string&gt;'
      root = load_v1_in_v2.load(export_dir, tags)
      ^
/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:528:3: note: called from
  return load_internal(export_dir, tags)
  ^
/home/afayed/Desktop/test.py:23:1: note: called from
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
^
&lt;unknown&gt;:0: error: loc("case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'
&lt;unknown&gt;:0: error: loc("case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0"): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor&lt;*x!tf.string&gt;'




afayed@metecs-0497:~$ 
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Method 2 try 5 with a representative dataset (Experimental Conv set to False):&lt;/denchmark-h&gt;

And finally, this try is what headed this issue
Code:
&lt;denchmark-code&gt;import tensorflow as tf

BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

list_ds_Dianthus = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Dianthus''*/*/*'))
list_ds_DustyMiller = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/DustyMiller''*/*/*'))
list_ds_Pansy = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Pansy''*/*/*'))
list_all = list_ds_Dianthus.concatenate(list_ds_DustyMiller).concatenate(list_ds_Pansy)
#len(list(list_all))

def get_label(file_path):
  parts = tf.strings.split(file_path, '/')
  class_name = tf.strings.split(parts[-3], '1')
  class_name = tf.strings.split(class_name, '2')
  class_name = tf.strings.split(class_name, '3')
  class_name = tf.strings.split(class_name, '4')
  return class_name

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 
	#resize the image into 224*224 

def process_path(file_path):
  label = get_label(file_path)
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

num_calibration_steps= 1000

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open("/home/afayed/Desktop/output_tflite_graph.tflite", "wb").write(tflite_quant_model)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;afayed@metecs-0497:~$ python3 ~/Desktop/Metecs\ Work/quant_aware_training.py 
2020-04-10 06:06:04.479099: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:04.479217: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:04.479231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 06:06:05.141022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 06:06:05.159643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.159956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:05.160224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.161735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:05.163092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:05.163399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:05.164713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:05.165613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:05.167462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:05.167624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.168101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.168436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:05.168831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 06:06:05.193418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 06:06:05.194356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62f8550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 06:06:05.194381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 06:06:05.234776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.235127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x631b7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 06:06:05.235144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 06:06:05.235310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.235556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:05.235612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.235650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:05.235670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:05.235706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:05.235727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:05.235750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:05.235771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:05.235826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.236058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.236253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:05.236304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.236934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:05.236945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:05.236969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:05.237066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.237329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.237577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 06:06:06.524962 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525167 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525248 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525318 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525382 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102755 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102902 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102976 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.103037 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.103093 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.689994 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690133 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690204 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690261 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690316 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.211912 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212095 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212220 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212320 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212404 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 06:06:11.022645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.022909: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 06:06:11.023001: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 06:06:11.023880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:11.024205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:11.024249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:11.024261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:11.024283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:11.024293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:11.024324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:11.024357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:11.024423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:11.024962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:11.024988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:11.024993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:11.025169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.025432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.025671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 06:06:11.074813: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 06:06:11.074848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 06:06:11.074853: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
W0410 06:06:11.121850 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'global_step:0' shape=() dtype=int64_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122043 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122144 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122252 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122336 140508644669184 wrap_function.py:214] Unable to create a python object for variable &lt;tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref&gt; because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 06:06:18.903261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.903541: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0
2020-04-10 06:06:18.903687: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 06:06:18.904242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.904630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:18.904684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:18.904706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:18.904729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:18.904750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:18.904772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:18.904794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:18.904817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:18.904878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:18.905414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:18.905426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:18.905435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:18.905511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.906185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 06:06:19.968587: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 06:06:19.968617: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 595.545ms.
2020-04-10 06:06:19.968697: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 203.882ms.
Traceback (most recent call last):
  File "/home/afayed/Desktop/Metecs Work/quant_aware_training.py", line 65, in &lt;module&gt;
    tflite_quant_model = converter.convert()
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py", line 464, in convert
    **converter_kwargs)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py", line 203, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 06:06:21.294618: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:21.294725: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:21.294733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 06:06:22.409963: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ParseSingleExample
2020-04-10 06:06:22.410302: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeRaw
2020-04-10 06:06:22.410346: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410366: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2020-04-10 06:06:22.410433: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410488: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410520: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2020-04-10 06:06:22.410540: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng
2020-04-10 06:06:22.410627: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410660: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeGif
2020-04-10 06:06:22.410673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeBmp
2020-04-10 06:06:22.412680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412718: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412730: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412929: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-10 06:06:22.465849: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1111 operators, 2079 arrays (0 quantized)
2020-04-10 06:06:22.514192: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1070 operators, 1975 arrays (0 quantized)
2020-04-10 06:06:22.568968: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1070 operators, 1975 arrays (0 quantized)
2020-04-10 06:06:22.789451: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.811142: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.825665: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.836283: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.867522: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2020-04-10 06:06:22.870222: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 31687618
2020-04-10 06:06:22.871172: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871184: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871211: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871217: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871222: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871230: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871236: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871242: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871249: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872020: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872027: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872031: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872663: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872672: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872698: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872704: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872708: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872716: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872724: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872728: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872748: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873543: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873551: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873556: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.874173: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, WHERE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
Traceback (most recent call last):
  File "/home/afayed/.local/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/afayed/.local/lib/python3.5/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, WHERE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.



afayed@metecs-0497:~$ 

&lt;/denchmark-code&gt;

I limit memory growth using
physical_devices = tf.config.list_physical_devices('GPU') tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)]) logical_devices = tf.config.list_logical_devices('GPU')
Please help, I am also trying to do this with faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 and thats where I found about the Experimental Converter working for RCNNs. My goal is to run either of these models on the Coral USB Accelerator after retraining with my own custom training data. I did not edit any scripts generating either of these models. Thanks in advanced
	</description>
	<comments>
		<comment id='1' author='adfayed' date='2020-04-13T15:01:40Z'>
		&lt;denchmark-link:https://github.com/adfayed&gt;@adfayed&lt;/denchmark-link&gt;

i have tried the very first code snippet shared by you and face a different error, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/9c375191d5507bf04ae9c81f7c55b1a4/untitled136.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='adfayed' date='2020-04-13T16:04:32Z'>
		
@adfayed
i have tried the very first code snippet shared by you and face a different error, please find the gist here

Please disregard (comment out) code lines number 6, 7, and 8. Like I mentioned they are only to limit GPU usage to 500 Mb.
The error you are getting is probably due to the use of Tensorflow 1.15 not Tensorflow-gpu or maybe a different index for you GPU card on your system.
		</comment>
		<comment id='3' author='adfayed' date='2020-04-14T09:59:07Z'>
		&lt;denchmark-link:https://github.com/adfayed&gt;@adfayed&lt;/denchmark-link&gt;

with nightly and gpu, the error faced is as per &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/5ce4ddd36cb0cfc023f2c683f88e29c6/38431.ipynb&gt;this gist&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='adfayed' date='2020-04-14T10:11:19Z'>
		Did you try commenting that out? That is totally beside the point. Please comment out those lines I get the same error with them commented out.
		</comment>
		<comment id='5' author='adfayed' date='2020-04-14T12:57:57Z'>
		&lt;denchmark-link:https://github.com/adfayed&gt;@adfayed&lt;/denchmark-link&gt;

from the error shared, it says the files used by you is not shared, we will not be able to replicate unless we have all dependencies "/home/afayed/coral/detection_ag/ag; No such file or directory [Op:MatchingFiles]" is the error.
		</comment>
		<comment id='6' author='adfayed' date='2020-04-15T01:25:08Z'>
		That folder detection_ag/ag is all my training data, it consists of &gt; 100Gb of different sub-folders of images and their corresponding detection bounding boxes data.
My issue is not with retraining. Retraining the model ckpt goes very smooth just as it should, I only included the inital part and the script used for retraining to provide a clear picture from start to finish if one can spot something wrong.
Quoting the issue detailed above, up until this comment:
"Now up until here everything goes relatively fine. However, converting this frozen graph or the resulting saved_model.pb from retraining causes issues.
Method 1: converting a frozen using TFLite Converter (typically following the tutorial)"
is the point where the issue opened here (Converting retrained ssd_resnet50_v1 object detection model to TFLite for use on Coral USB Accelerator) crops up. Converting the model ckpt into a usable format on the Coral USB Accelerator is the goal. This is why I have included, "1. Model Ckpt trained, 2. Frozen graph, 3. saved_model.pb", pipeline config file and Tensorflow versions I used. That should be all you need. It would be tough to share all the retraining images especially since it might have propriety repercussions and licensing issues.
Thanks,
Please do let me know of any other clarifications needed, I know my post is lengthy and might be all over the place. I just wanted to provide you with as much information as possible of the process start to finish.
		</comment>
		<comment id='7' author='adfayed' date='2020-04-28T14:59:54Z'>
		Hello? &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

Will anyone please be of assistance?
		</comment>
		<comment id='8' author='adfayed' date='2020-07-13T13:08:49Z'>
		TFLite does not support control flow v1 ops like Switch or Merge. Please try creating a model with v2 control flow ops. And you are using a few TF ops that are not natively supported by TFLite. Please consider using a Flex delegate.
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2&gt;https://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.tensorflow.org/lite/guide/ops_select&gt;https://www.tensorflow.org/lite/guide/ops_select&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='adfayed' date='2020-07-13T16:30:25Z'>
		Please follow &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md&gt;these instructions&lt;/denchmark-link&gt;
 for converting an SSD model for TFLite.
		</comment>
		<comment id='10' author='adfayed' date='2020-07-29T08:20:30Z'>
		&lt;denchmark-link:https://github.com/adfayed&gt;@adfayed&lt;/denchmark-link&gt;

Please update as per above comment.
		</comment>
		<comment id='11' author='adfayed' date='2020-08-05T08:22:58Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='12' author='adfayed' date='2020-08-12T09:21:09Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='13' author='adfayed' date='2020-08-12T09:21:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38431&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38431&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>