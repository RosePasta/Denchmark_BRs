<bug id='28010' author='KichangKim' open_date='2019-04-21T02:57:01Z' closed_time='2019-08-02T21:43:01Z'>
	<summary>[TF2.0] Not JSON Serializable error wasn thrown when using tf.keras.activations operators in keras model.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): tensorflow-gpu 2.0.0a0
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10
GPU model and memory: Geforce 1070

Describe the current behavior
When I used tf.keras.activations operators in my keras model, serialization of model was failed due to Not JSON Serializable error.
Describe the expected behavior
It should be serialized without any error.
Code to reproduce the issue
&lt;denchmark-code&gt;from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape=(784,), name='digits')
x = layers.Activation('relu')(inputs)
# x = keras.activations.relu(inputs)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)


model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')
model.summary()

model.save('path_to_my_model.h5')
&lt;/denchmark-code&gt;

If you changed from Activation() to relu, it failed to serialize.
	</description>
	<comments>
		<comment id='1' author='KichangKim' date='2019-04-29T19:43:45Z'>
		I have slightly edited your code to be consistent with  tf.keras and was able to reproduce the error using TF-gpu 2.0 alpha.
import tensorflow as tf
#from tensorflow import keras
#from tensorflow.keras import layers

inputs = tf.keras.Input(shape=(784,), name='digits')
#x = tf.keras.layers.Activation('relu')(inputs)
x = tf.keras.activations.relu(inputs)
outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')
model.summary()

model.save('path_to_my_model.h5')
Output:
---&gt; 13 model.save('path_to_my_model.h5')
TypeError: ('Not JSON Serializable:', b'\n\x06Relu_8\x12\x04Relu\x1a\tdigits_25*\x07\n\x01T\x12\x020\x01')
		</comment>
		<comment id='2' author='KichangKim' date='2019-05-01T03:19:50Z'>
		I got the same error, but with:

tf.keras.backend.expand_dims
tf.keras.backend.squeeze
tf.expand_dims
tf.squeeze

returns:
W0501 00:06:16.129765 139790005454464 tf_logging.py:161] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\n\nExpandDims\x12\nExpandDims\x1a\x05input\x1a\x0eExpandDims/dim*\x07\n\x01T\x12\x020\x01*\n\n\x04Tdim\x12\x020\x03')
		</comment>
		<comment id='3' author='KichangKim' date='2019-05-10T00:40:02Z'>
		Additionally, using "+" operator instead of tf.keras.layers.Add makes this issue same.
		</comment>
		<comment id='4' author='KichangKim' date='2019-05-26T16:09:18Z'>
		I am facing the same issue, any suggestions or solutions for work around for now ??
		</comment>
		<comment id='5' author='KichangKim' date='2019-07-03T15:10:18Z'>
		I am having the same issue when using tf.concat in an otherwise keras-only model (can't use keras Concatenations due to issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30355&gt;#30355&lt;/denchmark-link&gt;
 ).
Only work around I have found so far is to use model.save_weights(). When loading, you need to redefine the model and then use model.load_weights()
		</comment>
		<comment id='6' author='KichangKim' date='2019-07-17T08:05:15Z'>
		Having same issue with TF 1.14 and Python 3.6 with tf.transpose and tensorflow.python.keras.layers.concatenate :
W0717 09:24:35.629342 14908 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\n\ttranspose\x12\tTranspose\x1a\ndense/Relu\x1a\x0etranspose/perm*\x0b\n\x05Tperm\x12\x020\x03*\x07\n\x01T\x12\x020\x01')
W0717 13:56:19.515430 16984 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', b'\n\x05Shape\x12\x05Shape\x1a\x15concatenate_28/concat*\x07\n\x01T\x12\x020\x01*\x0e\n\x08out_type\x12\x020\x03')
Thus  with  causes the training to stop because it fails to backup the model (I get a useless model file of 6 KB).
As &lt;denchmark-link:https://github.com/mketcha&gt;@mketcha&lt;/denchmark-link&gt;
 mentionned, a workaround is to use . But it should only be temporary waiting a fix because saving only the weights forces to keep the code of the corresponding model somewhere and this is really annoying if the model code changes often.
		</comment>
		<comment id='7' author='KichangKim' date='2019-07-20T16:21:54Z'>
		Same problem here. Is this being worked on?
&lt;denchmark-code&gt; Model failed to serialize as JSON. Ignoring...
('Not JSON Serializable:',
b'\n\tLeakyRelu\x12\tLeakyRelu\x1a\x1cbatch_normalization/Identity*\x07\n\x01T\x12\x020\x01*\x0e\n\x05alpha\x12\x05%\xcd\xccL&gt;')
&lt;/denchmark-code&gt;

TensorFlow 2.0.0-b1
		</comment>
		<comment id='8' author='KichangKim' date='2019-07-22T18:41:17Z'>
		Was able to repro and have a fix out for this, should be in in a day or two
		</comment>
		<comment id='9' author='KichangKim' date='2019-07-29T08:02:39Z'>
		Hello,
Any news? Thanks
		</comment>
		<comment id='10' author='KichangKim' date='2019-07-29T16:31:48Z'>
		
Hello,
Any news? Thanks

Should be fixed: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/7cc180f107f142432358ac33787466de90afd776&gt;7cc180f&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='KichangKim' date='2019-08-02T21:43:01Z'>
		Closing this issue since its fixed in latest tf nightly build '2.0.0-dev20190802'
Thanks!
		</comment>
		<comment id='12' author='KichangKim' date='2019-08-02T21:43:03Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28010&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28010&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='KichangKim' date='2020-03-15T20:07:47Z'>
		Had the problem callbacks.ModelCheckpoint and ModelCheckpoint, setting save_weights_only=True solved the problem for me.
		</comment>
		<comment id='14' author='KichangKim' date='2020-09-02T07:55:42Z'>
		
Had the problem callbacks.ModelCheckpoint and ModelCheckpoint, setting save_weights_only=True solved the problem for me.

&lt;denchmark-link:https://github.com/yassinetb&gt;@yassinetb&lt;/denchmark-link&gt;
 Did you have any solution for the error "TypeError: ('Not JSON Serializable:', tf.float32)" from setting save_weights_only=False
		</comment>
	</comments>
</bug>