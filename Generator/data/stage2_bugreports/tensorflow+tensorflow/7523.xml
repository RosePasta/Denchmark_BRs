<bug id='7523' author='Bruczzz' open_date='2017-02-15T10:48:53Z' closed_time='2017-02-27T16:48:00Z'>
	<summary>Tensorflow graph transform quantize_weights Compression method creates corrupted graph.</summary>
	<description>
Hi,
I have retrained inception v3 model using retrain.py on classes (People, Animal, Plants, Buildings, Birds) and the size is 87.5 MB. At this stage, the model works fine when I try classification using label_image example.
But, model compressed using quantization methods is producing false or incorrect results. As mentioned below, I have tried two ways of model compression using quantized methods, however both of these are producing a corrupted compressed model that gives incorrect classification results.
 Shrinking file size method in graph_transform. GitHub link: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&lt;/denchmark-link&gt;

Step 1: Tried compression with round_weights method - size of model was still same (87.5 MB) and classification on images works perfectly.
Step 2: Compression using quantize_weights method - (as suggested by Pete Warden, I ran the command after removing " and newlines ) quantized model got created with size (22 MB) but it is producing false or incorrect results, and giving the same class irrespective of which image is given as input (plant, bird, etc.). Below are sample results for three images none of which were animal images:
Image 1 (plant)

Animal (1): 0.999713
Plants (5): 0.00028519
Buildings (3): 1.18105e-06
People (2): 1.77942e-07
Birds (4): 5.95436e-08

Image 2 (bird)

Animal (1): 0.981817
Plants (5): 0.0170753
Buildings (3): 0.000743494
People (2): 0.000190974
Birds (4): 0.000148184

Image 3 (building)

Animal (1): 0.991817
Plants (5): 0.0070753
Buildings (3): 0.00143494
People (2): 0.00090974
Birds (4): 0.000148184

 Quantization method link : &lt;denchmark-link:https://www.tensorflow.org/how_tos/quantization/&gt;https://www.tensorflow.org/how_tos/quantization/&lt;/denchmark-link&gt;

 bazel build tensorflow/contrib/quantization/tools:quantize_graph 
ERROR: no such package 'tensorflow/contrib/quantization/tools': BUILD       file not found on package path.
Used  bazel build tensorflow/tools/quantization:quantize_graph  command for running build.
On running following command after adding dependencies "//tensorflow/contrib/quantization:cc_ops",
"//tensorflow/contrib/quantization/kernels:quantized_ops", to BUILD file of label_image.

bazel-bin/tensorflow/tools/quantization/quantize_graph \
--input=Trained_Model/CompressedJunkRetrained_graph.pb \
--output_node_names="final_result" --output=/Trained_Model/quantized_graph.pb \
--mode=eightbit

Note: Used final_result in output_node_names instead of softmax.
This is giving the following error:
ERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/tools/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.
ERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such target '//tensorflow/tools/quantization:cc_ops': target 'cc_ops' not declared in package 'tensorflow/tools/quantization' defined by /tensorflow-master/tensorflow/tools/quantization/BUILD and referenced by '//tensorflow/examples/label_image:label_image'.
ERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.
If I run the same command without adding dependencies, it is compressing the model successfully.
But again in this quantized model images are getting wrongly classified.
	</description>
	<comments>
		<comment id='1' author='Bruczzz' date='2017-02-15T14:06:29Z'>
		I am fighting with the same issue at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7150&gt;#7150&lt;/denchmark-link&gt;
. Good luck to both of us :). From what I got from &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/andrewharp&gt;@andrewharp&lt;/denchmark-link&gt;
 it seems that  is obsolete now and state of the art way to quantize graph is graph transform transformation . However, for me, it corrupts one of two output layers in a way that it shows always very high probablity in favor of one category no matter what input is.
Maybe it will be interesting to change order of you categories before training-&gt; put Plants on first place and see whether it will be showing this 0.99+ to Plants instead of Animals. I would try it on my own in my network, however right now I am at work :).
		</comment>
		<comment id='2' author='Bruczzz' date='2017-02-16T07:15:20Z'>
		I have tried that also &lt;denchmark-link:https://github.com/bazinac&gt;@bazinac&lt;/denchmark-link&gt;
 (changed the order of subfolders in train directory and order of labels in label.txt ).No matter what the input image is, quantized model gives high probability for Animals.
Rarely, say 1 in 100 input image getting classified as other class but that is again incorrect result.
Thanks.
		</comment>
		<comment id='3' author='Bruczzz' date='2017-02-16T08:56:45Z'>
		Yeah I got same results.  Have you just retrained the inception  network using tutorial,  or have you added some logic/nodes?
		</comment>
		<comment id='4' author='Bruczzz' date='2017-02-16T10:21:52Z'>
		I just retrained as explained in tutorial... I have not done anything apart from that.
		</comment>
		<comment id='5' author='Bruczzz' date='2017-02-17T22:52:31Z'>
		&lt;denchmark-link:https://github.com/cwhipkey&gt;@cwhipkey&lt;/denchmark-link&gt;
, could you take a look?
		</comment>
		<comment id='6' author='Bruczzz' date='2017-02-19T09:52:16Z'>
		I have tried it from scratch using TF 1.0 to see whether something has changed. I have downloaded newest TF source, built and upgraded my scripts. However, this bug in quantize_weights transformation unfortunatelly still persists, which is unpleasant for me :). See results table in latest post in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7150&gt;#7150&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='Bruczzz' date='2017-02-22T10:33:59Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
  I have followed the steps given in TF GitHub link. Still I am stuck with quantization process.
Kindly help to proceed with my project.
Thanks :)
		</comment>
		<comment id='8' author='Bruczzz' date='2017-02-22T13:15:42Z'>
		Would it be possible to share your trained model (before quantization) and the three test examples?
		</comment>
		<comment id='9' author='Bruczzz' date='2017-02-23T08:58:31Z'>
		&lt;denchmark-link:https://github.com/cwhipkey&gt;@cwhipkey&lt;/denchmark-link&gt;
 Okay, how would you recommend I share the model? I would prefer uploading it on Google Drive/Dropbox and providing you a link privately so as to avoid open access to it. Kindly let me know. Appreciate your help in this.
		</comment>
		<comment id='10' author='Bruczzz' date='2017-02-24T11:44:10Z'>
		&lt;denchmark-link:https://github.com/cwhipkey&gt;@cwhipkey&lt;/denchmark-link&gt;
 Here is the Google Drive link for the trained model (before quantization), labels file and 3 test samples as requested: &lt;denchmark-link:https://drive.google.com/open?id=0B_C9PPLt_DEuMk00Z29td0FGVTQ&gt;https://drive.google.com/open?id=0B_C9PPLt_DEuMk00Z29td0FGVTQ&lt;/denchmark-link&gt;

Before Quantaization Results:

I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_building.jpg
I tensorflow/examples/label_image/main.cc:210] buildings (1): 0.96819
I tensorflow/examples/label_image/main.cc:210] plants (0): 0.0134963
I tensorflow/examples/label_image/main.cc:210] birds (3): 0.0107289
I tensorflow/examples/label_image/main.cc:210] people (4): 0.00518653
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.00239875
I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_bird.jpeg
I tensorflow/examples/label_image/main.cc:210] birds (3): 0.988302
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.00705346
I tensorflow/examples/label_image/main.cc:210] plants (0): 0.00391275
I tensorflow/examples/label_image/main.cc:210] buildings (1): 0.000384585
I tensorflow/examples/label_image/main.cc:210] people (4): 0.00034682
I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_plant.jpg
I tensorflow/examples/label_image/main.cc:210] plants (0): 0.999204
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.000394156
I tensorflow/examples/label_image/main.cc:210] buildings (1): 0.000203822
I tensorflow/examples/label_image/main.cc:210] people (4): 0.000172411
I tensorflow/examples/label_image/main.cc:210] birds (3): 2.5524e-05

After Quantaization Results:

I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_building.jpg.
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.996291
I tensorflow/examples/label_image/main.cc:210] people (4): 0.00340083
I tensorflow/examples/label_image/main.cc:210] birds (3): 0.000162176
I tensorflow/examples/label_image/main.cc:210] plants (0): 7.45604e-05
I tensorflow/examples/label_image/main.cc:210] buildings (1): 7.18933e-05
I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_bird.jpeg
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.999115
I tensorflow/examples/label_image/main.cc:210] people (4): 0.000881293
I tensorflow/examples/label_image/main.cc:210] birds (3): 3.28949e-06
I tensorflow/examples/label_image/main.cc:210] plants (0): 2.49182e-07
I tensorflow/examples/label_image/main.cc:210] buildings (1): 7.07635e-08
I tensorflow/examples/label_image/main.cc:309] IMAGE NAME::::::::test_plant.jpg
I tensorflow/examples/label_image/main.cc:210] animals (2): 0.999486
I tensorflow/examples/label_image/main.cc:210] people (4): 0.000509206
I tensorflow/examples/label_image/main.cc:210] birds (3): 4.86689e-06
I tensorflow/examples/label_image/main.cc:210] plants (0): 3.50618e-08
I tensorflow/examples/label_image/main.cc:210] buildings (1): 1.62856e-08

Thanks again :)
		</comment>
		<comment id='11' author='Bruczzz' date='2017-02-24T17:06:45Z'>
		&lt;denchmark-link:https://github.com/Bruczzz&gt;@Bruczzz&lt;/denchmark-link&gt;
 Could you try the steps in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms/#eight-bit-calculations&gt;eight-bit-calculations&lt;/denchmark-link&gt;
 instead of quantize_graph. Meanwhile, I'll be looking into why quantize_graph seems to misbehave. Thanks for sharing the model.
		</comment>
		<comment id='12' author='Bruczzz' date='2017-02-24T17:38:27Z'>
		I'm still looking into quantize_graph, but here's a quick update.
In short, avoid using only 'quantize_weights' with transform_graph. Prefer the full transforms from 'eight-bit-calculations'.
I've run the following two commands on the files &lt;denchmark-link:https://github.com/Bruczzz&gt;@Bruczzz&lt;/denchmark-link&gt;
 provided:
&lt;denchmark-code&gt;transform_graph --logtostderr --in_graph=./Retrained_graph.pb --out_graph=./Quantized_nodes_and_weights_graph.pb --inputs=Mul:0 --outputs=final_result:0 --transforms='add_default_attributes strip_unused_nodes(type=float, shape="1,299,299,3") remove_nodes(op=Identity, op=CheckNumerics) fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes'
transform_graph --logtostderr --in_graph=./Retrained_graph.pb --out_graph=./Quantized_only_weights_graph.pb --inputs=Mul:0 --outputs=final_result:0 --transforms='quantize_weights'
&lt;/denchmark-code&gt;

And the performance of the two quantized graphs is:
&lt;denchmark-code&gt;test_bird.jpeg
-&gt; Retrained:  birds (3): 0.988302
-&gt; Quantized (nodes and weights):  birds (3): 0.964491
-&gt; Quantized (only weights):  animals (2): 0.56042
test_plant.jpg
-&gt; Retrained:  plants (0): 0.999204
-&gt; Quantized (nodes and weights):  plants (0): 0.999696
-&gt; Quantized (only weights):  animals (2): 0.669282
test_buliding.jpg
-&gt; Retrained:  buildings (1): 0.968189
-&gt; Quantized (nodes and weights):  buildings (1): 0.943537
-&gt; Quantized (only weights):  animals (2): 0.490827
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='Bruczzz' date='2017-02-27T09:12:21Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
 Thanks for your help :)
Model is working fine after full transform with "eight bit calculations"
		</comment>
	</comments>
</bug>