<bug id='10705' author='hyunjik11' open_date='2017-06-14T14:32:25Z' closed_time='2017-12-30T00:15:40Z'>
	<summary>undocumented change in variable scope from tf 1.0.1 to tf 1.1.0</summary>
	<description>
System Information

Custom code, a minimal reproducible example provided below
Linux Fedora 24 and Fedora 25
TensorFlow installed from binary using pip
TensorFlow version 1.0.1 and 1.1.0
CUDA 8.0/cuDNN 5.1
GeForce GTX 1080

Problem
I'm trying to run some code that I wrote for tensorflow 1.0.1 on tensorflow 1.1.0.
It seems like tf.contrib.layers.fully_connected is showing different behaviour for 1.1.0 compared to 1.0.1. See below for a minimal reproducible example showing the difference.
Source code and logs
Tensorflow 1.0.1, Fedora 24:
&lt;denchmark-code&gt;Python 2.7.13 (default, May 10 2017, 20:04:36) 
[GCC 6.3.1 20161221 (Red Hat 6.3.1-1)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.contrib.layers.fully_connected(inputs=tf.placeholder(shape=[None,3],dtype=tf.float32),num_outputs=3,reuse=True,scope='DNN')
&lt;tf.Tensor 'DNN/Relu:0' shape=(?, 3) dtype=float32&gt;
&gt;&gt;&gt; tf.__version__
'1.0.1'
&lt;/denchmark-code&gt;

Tensorflow 1.1.0, Fedora 25:
&lt;denchmark-code&gt;Python 2.7.13 (default, May 10 2017, 20:04:28) 
[GCC 6.3.1 20161221 (Red Hat 6.3.1-1)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.contrib.layers.fully_connected(inputs=tf.placeholder(shape=[None,3],dtype=tf.float32),num_outputs=3,reuse=True,scope='DNN')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 181, in func_with_args
    return func(*args, **current_args)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1433, in fully_connected
    outputs = layer.apply(inputs)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 320, in apply
    return self.__call__(inputs, **kwargs)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 286, in __call__
    self.build(input_shapes[0])
  File "/usr/lib/python2.7/site-packages/tensorflow/python/layers/core.py", line 123, in build
    trainable=True)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 349, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 1389, in wrapped_custom_getter
    *args, **kwargs)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 275, in variable_getter
    variable_getter=functools.partial(getter, **kwargs))
  File "/usr/lib/python2.7/site-packages/tensorflow/python/layers/base.py", line 228, in _add_variable
    trainable=trainable and self.trainable)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1334, in layer_variable_getter
    return _model_variable_getter(getter, *args, **kwargs)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py", line 1326, in _model_variable_getter
    custom_getter=getter, use_resource=use_resource)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 181, in func_with_args
    return func(*args, **current_args)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 262, in model_variable
    use_resource=use_resource)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 181, in func_with_args
    return func(*args, **current_args)
  File "/usr/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py", line 217, in variable
    use_resource=use_resource)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 341, in _true_getter
    use_resource=use_resource)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py", line 671, in _get_single_variable
    "VarScope?" % name)
ValueError: Variable DNN/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
&gt;&gt;&gt; tf.__version__
'1.1.0'
&lt;/denchmark-code&gt;

Looking at the release notes for Tensorflow 1.1, there is no mention of change in behaviour of variable scope for tf.contrib.layers.fully_connected. But it seems like in 1.1 we have to create variables manually using tf.get_variable() before using tf.contrib.layers.fully_connected. Am I missing something?
	</description>
	<comments>
		<comment id='1' author='hyunjik11' date='2017-06-14T16:19:52Z'>
		Generally speaking, there is no guarantee of backward compatibility in the contrib area as it is considered "in-flux" and "unsupported". However, &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/lukaszkaiser&gt;@lukaszkaiser&lt;/denchmark-link&gt;
  might have some knowledge of this change.
		</comment>
		<comment id='2' author='hyunjik11' date='2017-06-14T16:35:08Z'>
		No need to create variable manually, sorry for the misunderstanding! The variable reuse mechanism had a bug in 1.0.1 which ignored reuse checking: you shouldn't set "reuse=True" if the variable hasn't been created before. Just set "reuse=None", I hope that works. I'm closing for now, please reopen if it doesn't work for you, we'll help. Sorry for the problem!
		</comment>
		<comment id='3' author='hyunjik11' date='2017-06-14T16:49:57Z'>
		Thanks for the quick reply &lt;denchmark-link:https://github.com/lukaszkaiser&gt;@lukaszkaiser&lt;/denchmark-link&gt;
!
		</comment>
		<comment id='4' author='hyunjik11' date='2017-06-15T10:05:56Z'>
		&lt;denchmark-link:https://github.com/lukaszkaiser&gt;@lukaszkaiser&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;

Thanks for the replies, but if I set , I can't use these variables again with the same code.
For example, suppose I have a function that maps inputs to outputs of a certain fixed DNN:
&lt;denchmark-code&gt;def build_dnn(input):
    output = tf.contrib.layers.fully_connected(inputs=input, num_outputs=3,reuse=None,scope='DNN')
    return output
&lt;/denchmark-code&gt;

Then in tensorflow 1.1.0, calling build_dnn twice will give me the following error:
&lt;denchmark-code&gt;ValueError: Variable DNN/weights already exists, disallowed. Did you mean to set reuse=True in VarScope?
&lt;/denchmark-code&gt;

If I use reuse=True for build_dnn, I will get the error in my previous post.
Back in Tensorflow 1.0.1, I was able to just set reuse=True in build_dnn and call it as many times as I want. How can I achieve something similar in Tensorflow 1.1.0?
		</comment>
		<comment id='5' author='hyunjik11' date='2017-06-15T16:34:40Z'>
		Just add the reuse parameter to your build_dnn function, and call it with "None" first time and with "True" the other one.
		</comment>
		<comment id='6' author='hyunjik11' date='2017-06-15T16:52:05Z'>
		A note to explain this behavior: it was introduced due to a bug made when moving tf.contrib.layers to use the same code as tf.layers. The behavior now is the same as before the bug (in earlier versions of TF), and it is now the same as tf.layers. So ignoring reuse in tf.contrib.layers was really a contrib bug.
		</comment>
		<comment id='7' author='hyunjik11' date='2017-12-20T19:14:58Z'>
		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
	</comments>
</bug>