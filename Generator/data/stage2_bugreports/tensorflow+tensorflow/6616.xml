<bug id='6616' author='yoslber' open_date='2017-01-03T13:50:23Z' closed_time='2017-04-18T15:29:22Z'>
	<summary>fake_quant_with_min_max_args has odd behavior</summary>
	<description>
&lt;denchmark-h:h3&gt;Description&lt;/denchmark-h&gt;

On a simple linear regression example, fake_quant_with_min_max_args is not working. If I change to fake_quant_with_min_max_vars with trainable quantization min/max ranges, it works just fine.
The min/max values are the same in both approaches.
Reproducer included below.
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

None
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu 14.04.5, Python 2.7
Installed version of CUDA and cuDNN: Cuda 8, CuDNN 5.1
If installed from binary pip package, provide:


A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl


The output from python -c "import tensorflow; print(tensorflow.__version__)". 0.12.1


&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

Below is a small reproducer, adapted from the example at &lt;denchmark-link:https://www.tensorflow.org/get_started/&gt;https://www.tensorflow.org/get_started/&lt;/denchmark-link&gt;

import tensorflow as tf
import numpy as np

# Create 10000 phony x, y data points in NumPy, y = x * 123.456 + 78.9
x_data = np.random.rand(10000).astype(np.float32)
y_data = x_data * 123.456 + 78.9

# Try to find values for W and b that compute y_data = W * x_data + b
# (We know that W should be 123.456 and b 78.9, but TensorFlow will
# figure that out for us.)
W = tf.Variable(tf.random_uniform([1], 0.0, 255.0))
b = tf.Variable(tf.zeros([1]))

# Now we quantize the weights and bias 
# The expected result after training should be 
# y = x * 123 + 79
W = tf.fake_quant_with_min_max_args(W, min=0.0, max=255.0)
b = tf.fake_quant_with_min_max_args(b, min=0.0, max=255.0)

y = W * x_data + b # Model

loss = tf.reduce_mean(tf.square(y - y_data))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)

# Fit the line.
for step in range(201):
    sess.run(train)
    if step % 20 == 0:
        print(step, sess.run(loss), sess.run(W), sess.run(b))
Output is a random rounded values for W and b, depending on run, but not the expected W=123, b=79, and the loss is large.
&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

If I instead use  as illustrated below, it works fine (by printing, we have verified that the quantization ranges are [0,255] for each training iteration). The loss decreases and the values for W and b are as expected. The example is adapted from &lt;denchmark-link:https://www.tensorflow.org/get_started/&gt;https://www.tensorflow.org/get_started/&lt;/denchmark-link&gt;

import tensorflow as tf
import numpy as np

# Create 10000 phony x, y data points in NumPy, y = x * 123.456 + 78.9
x_data = np.random.rand(10000).astype(np.float32)
y_data = x_data * 123.456 + 78.9

W = tf.Variable(tf.random_uniform([1], 0.0, 255.0))
b = tf.Variable(tf.zeros([1]))

# Now we quantize the weights and bias
# The expected result after training should be 
# y = x * 123 + 79   Note that we train the quantization ranges
qmin = tf.Variable(0.0)
qmax = tf.Variable(255.0)
W = tf.fake_quant_with_min_max_vars(W, min=qmin, max=qmax)

qminb = tf.Variable(0.0)
qmaxb = tf.Variable(255.0)
b = tf.fake_quant_with_min_max_vars(b, min=qminb, max=qmaxb)

y = W * x_data + b # Model

loss = tf.reduce_mean(tf.square(y - y_data))
optimizer = tf.train.GradientDescentOptimizer(0.5)
train = optimizer.minimize(loss)

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)

# Fit the line.
for step in range(201):
    sess.run(train)
    if step % 20 == 0:
        print(step, sess.run(loss), sess.run(W), sess.run(b))

print('Quantization ranges',  sess.run(qmin), sess.run(qmax), sess.run(qminb), sess.run(qmaxb))
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
	</description>
	<comments>
		<comment id='1' author='yoslber' date='2017-04-10T21:13:12Z'>
		It looks like the gradient function for fake_quant_with_min_max_args forgets to pass the min max range.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L1877&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L1877&lt;/denchmark-link&gt;

I'll send a fix.
		</comment>
		<comment id='2' author='yoslber' date='2018-11-23T01:17:02Z'>
		Hi, &lt;denchmark-link:https://github.com/yoslber&gt;@yoslber&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/suharshs&gt;@suharshs&lt;/denchmark-link&gt;

in the prcess of  quantification ï¼Œ how to decide the value of  min and max  in  tf.fake_quant_with_min_max_vars(input, min, max)
		</comment>
	</comments>
</bug>