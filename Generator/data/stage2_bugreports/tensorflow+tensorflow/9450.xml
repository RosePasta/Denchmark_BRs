<bug id='9450' author='mingdachen' open_date='2017-04-26T00:35:42Z' closed_time='2017-06-16T21:12:31Z'>
	<summary>Compute gradient inside tf.while_loop using TensorArray</summary>
	<description>
I was trying to call opt.compute_gradients() inside the while_loop, but it failed with the error message:
&lt;denchmark-code&gt;AttributeError: 'WhileContext' object has no attribute 'pred'
&lt;/denchmark-code&gt;

I found a similiar problem in &lt;denchmark-link:http://stackoverflow.com/questions/42313788/how-to-do-opt-compute-gradients-multiple-times-in-single-sess-run&gt;stackoverflow&lt;/denchmark-link&gt;

test code:
batch_size = 2
inputs = tf.ones((batch_size, 10))
labels = tf.zeros((batch_size, 1))
outputs = tf.layers.dense(inputs, units=1)
loss = outputs - labels
loss_ta = tf.TensorArray(dtype=tf.float32, size=batch_size)
loss_ta = loss_ta.unstack(loss)

opt = tf.train.AdamOptimizer(0.1)
init_grad = []
vars_list = tf.trainable_variables()
for var in vars_list:
    init_grad.append(tf.zeros_like(var))

i = tf.constant(0, dtype=tf.int32)
def condition(i, *args):
    return tf.less(i, batch_size)
def loop_fn(i, gradients, all_loss):
    loss_ = all_loss.read(i)
    grads = opt.compute_gradients(loss_, vars_list)
    for idx, (grad, var) in enumerate(grads):
        gradients[idx] += grad
    return i + 1, gradients, all_loss
_, final_grad, _ = tf.while_loop(condition, loop_fn, [i, init_grad, loss_ta])

train_op = opt.apply_gradients(zip(final_grad, vars_list))
Seems like the problem is in the TensorArray, if I do not read loss from the TensorArray, it will be fine. Besides, I am using version1.0.1 on CPU
	</description>
	<comments>
		<comment id='1' author='mingdachen' date='2017-04-26T15:04:21Z'>
		&lt;denchmark-link:https://github.com/yuanbyu&gt;@yuanbyu&lt;/denchmark-link&gt;
 Do you know what the problem is here?  Is it possible to improve the error messages?
		</comment>
		<comment id='2' author='mingdachen' date='2017-06-16T21:12:31Z'>
		Closing since &lt;denchmark-link:https://github.com/yuanbyu&gt;@yuanbyu&lt;/denchmark-link&gt;
 is gone.
		</comment>
	</comments>
</bug>