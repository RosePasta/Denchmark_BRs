<bug id='34101' author='ThinerDAS' open_date='2019-11-08T14:43:36Z' closed_time='2020-12-15T17:04:02Z'>
	<summary>batch_gather_nd op &amp;lt;del&amp;gt;Size Op&amp;lt;/del&amp;gt; missing for Tensorflow Lite</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
TensorFlow installed from (source or binary): binary docker latest
TensorFlow version (or github SHA if from source):v2.0.0-rc2-26-g64c3d38 2.0.0

Any model using batch_gather_nd (gather_nd when batch!=0 and input tensor has indefinite batch dimension) will rely on Size op (batch_gather_nd-&gt;meshgrid-&gt;size-&gt;Size) when the batch dim is -1 (unspecified). Lack of Size op renders gather_nd op useless in many cases.
Another possible fix here: decouple batch_gather_nd from Size. (Is that possible?)
Here I used a monkey patch here to solve the problem: when batch dimension is 1, do not call meshgrid and directly use the range above the line since range does not rely on size.
&lt;denchmark-code&gt;    mesh_list = meshgrid(*dim_ranges, indexing="ij") if dim_ranges else []
&lt;/denchmark-code&gt;

changed into
&lt;denchmark-code&gt;    if len(dim_ranges)==0:
      mesh_list = [] 
    elif len(dim_ranges)==1:
      mesh_list = dim_ranges
    else:
      mesh_list = meshgrid(*dim_ranges, indexing="ij") if dim_ranges else []
&lt;/denchmark-code&gt;

That might be helpful if anyone want to use batch_gather_nd on tensorflow lite.
Update: I am wrong here. batch_gather_nd is not supported in tensorflow lite at all. The reason lies in that batch_gather_nd used range with indefinite length, which makes the dimension of the output empty; however range is used later and tiled and concatenated etc, however in the eyes of tensorflow optimizer, the shape is always [] so they are noop and any operation related are noop, effectively makes shape of every tensor related empty (shape=[]). So it is the batch_gather_nd op that is missing
Update: I have just noticed that Tensorflow Lite will always generate code for batch=1, so a fast solution is: set a export_lite flag in keras model definition part and make the lambda layer for batch_gather_nd act specially when exporting for tensorflow lite - return the tensor as if batch=1 even when batch=None actually.
So the problem remained for tensorflow devs here is: support the harmonious implementation of batch_gather_nd between tensorflow and tensorflow lite; or natively provide a GatherNd layer in keras that works correctly in tensorflow lite.
Summary:
Expected behavior: using gather_nd when batch=1 should generate correct graph when a keras model is exported into tensorflow lite
Actual behavior: batch_gather_nd fails to generate correct dimension for its output in tensorflow lite.
Reproduce: To reproduce behavior, use gather_nd in one lambda layer (with batch=1) and export the model into tensorflow lite
Problem: gather_nd should be specially dealt with in exporting process.
Monkey patch in user code: in the gather_nd function in your Lambda layer, check out whether you are exporting into a tensorflow lite binary. If an exporting is in progress, take as if the dim is 1 and keep the batch_dims=0. When arg=[params,indices], simply gather_nd(arg[0][0], arg[1]) will do the job.
Solution: make a dedicated GatherNd layer in keras who can correctly handle the different behavior between tensorflow and tensorflow lite.
	</description>
	<comments>
		<comment id='1' author='ThinerDAS' date='2020-12-01T16:04:00Z'>
		&lt;denchmark-link:https://github.com/ThinerDAS&gt;@ThinerDAS&lt;/denchmark-link&gt;
,
Is this still an issue? Could you please update TensorFlow to v2.3 and check if you are still facing the same issue. Thanks!
		</comment>
		<comment id='2' author='ThinerDAS' date='2020-12-08T16:27:50Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='ThinerDAS' date='2020-12-15T17:04:00Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='4' author='ThinerDAS' date='2020-12-15T17:04:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34101&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34101&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>