<bug id='28250' author='joelzou925' open_date='2019-04-29T05:49:13Z' closed_time='2019-07-24T18:01:57Z'>
	<summary>Embedding Layer backpropagation issue during training when using Subclass API</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): There doesn't seem to be any example of using subclass API with model.fit with embedding layer
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):   binary
TensorFlow version (use command below):  tf-nightly-gpu-2.0-preview (2.0.0.dev20190428)
Python version: 3.6.5
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0
GPU model and memory:  Geforce 940M 2GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When using Embedding Layer inside a Subclass Model with variable length between batches,
during training (model.fit), errors out as expected list of [batch_size, previous_batch_seq_len], received [batch_size, current_batch_seq_len].  Looks like it is unable to backpropagate correctly to the Embedding Layer with variable length.
However there is no error when the Embedding Layer is set to trainable=False, or to use the embedding layer in a Functional API.
Describe the expected behavior
There should not be any dimension error during back propagation for the Embedding Layer when using subclass API, when the same layer works in functional API with same model/inputs.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;vocab_size=2
label_size = 2
class Model(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.word_embedding = tf.keras.layers.Embedding(vocab_size, 100, trainable=True)
        self.encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True))
        self.classifier = tf.keras.layers.Dense(label_size)
        
    def call(self, word_ids):
        x = self.word_embedding(word_ids)
        x = self.encoder(x)
        x = self.classifier(x)
        return x


loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True, reduction='none')

def loss_function(real, pred):
    real = tf.reshape(real, (-1,))
    pred = tf.reshape(pred, (-1, pred.shape[-1]))
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)

    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask

    return tf.reduce_mean(loss_)


def accuracy(y_true, y_pred):
    y_pred = tf.argmax(tf.reshape(y_pred, (-1, y_pred.shape[-1])), axis=-1)
    y_true = tf.reshape(y_true, (-1,))
    y_pred = y_pred[y_true &gt; 0]
    y_true = y_true[y_true &gt; 0]
    return tf.metrics.categorical_accuracy(y_true[y_true &gt; 0], y_pred[y_true &gt; 0])


model = Model()
model.compile(optimizer=tf.optimizers.Adam(), loss=loss_function, metrics=[accuracy])
model.fit(dataset)
&lt;/denchmark-code&gt;

train_data would be a tf.dataset produced using padded_batch that produces (word_ids, ner_tags) as inputs, labels.
Here I created a toy example:
&lt;denchmark-code&gt;def generator():
    for data in zip([[1, 1, 1], [1, 1, 1, 1]], [[2, 2, 2], [2, 2, 2, 2]]):
        yield data
dataset = tf.data.Dataset.from_generator(generator, output_types=(tf.int64, tf.int64))
dataset = dataset.padded_batch(1, ((None,), (None,)))
&lt;/denchmark-code&gt;

which will create 2 batches of size 1,  first batch has length 3, second batch has length 4.
When embedding layer trainable set to False, model.fit runs successfully.
When trainable set to True, it gets following error:
InvalidArgumentError: Operation expected a list with 3 elements but got a list with 4 elements.
	</description>
	<comments>
		<comment id='1' author='joelzou925' date='2019-04-30T00:21:41Z'>
		&lt;denchmark-link:https://github.com/joelzou925&gt;@joelzou925&lt;/denchmark-link&gt;
 Could you create a GitHub gist or format the code above so that it is clear so that we can reproduce the issue and resolve it faster. Thanks!
		</comment>
		<comment id='2' author='joelzou925' date='2019-04-30T00:50:45Z'>
		
@joelzou925 Could you create a GitHub gist or format the code above so that it is clear so the we can reproduce the issue and resolve it faster. Thanks!

Sorry it was late night, I have updated the code and created a toy dataset that reproduces the problem.
		</comment>
		<comment id='3' author='joelzou925' date='2019-05-01T16:14:45Z'>
		I could reproduce the issue with TF2.0.0-alpha0 and TF-nightly-2.0-preview. I noticed different `InvalidArgumentError' as shown below
InvalidArgumentError: Received a label value of 2 which is outside the valid range of [0, 2).  Label values: 2 2 2 [[{{node loss/output_1_loss/SparseCategoricalCrossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_keras_scratch_graph_3574] . Thanks!
		</comment>
		<comment id='4' author='joelzou925' date='2019-07-24T18:01:57Z'>
		&lt;denchmark-link:https://github.com/joelzou925&gt;@joelzou925&lt;/denchmark-link&gt;
 I don't see any error with the latest .
Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/d6407dac539bf2b15db7daf205dea360/untitled315.ipynb&gt;gist&lt;/denchmark-link&gt;
.
I am closing the issue. Feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='5' author='joelzou925' date='2019-07-24T18:01:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28250&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28250&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>