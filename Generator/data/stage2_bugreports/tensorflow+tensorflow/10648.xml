<bug id='10648' author='freakanth' open_date='2017-06-12T13:29:11Z' closed_time='2017-09-12T13:06:42Z'>
	<summary>Segmentation Fault (core dumped) on exit from unit test that imports `tf.contrib.rnn`</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.0.0
Bazel version (if compiling from source): 0.4.4
CUDA/cuDNN version: 8.0/5110
GPU model and memory: GeForce GTX 980 Ti
Exact command to reproduce: python -m unittest discover -s tests -p "example_test.py"(see below for details)

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I am running Tensorflow code from within the Python unittest module. The individual unit-tests, each of which train a specific architecture, run successfully with an OK. However, I observed that given the above described system configuration, I receive a Segmentation Fault (core dumped) just before the program exits. And this leads to the overall test being marked as FAIL (despite the individual tests passing).
On further investigation, I observed that the segmentation fault can be prevented from occurring by preventing the tensorflow/contrib/rnn/python/ops/_gru_ops.so file from being loaded by the load_op_library function inside tensorflow.contrib.rnn.python.ops.gru_ops
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Say I have a folder my_code that contains a tests folder where my unit-tests are all located. The error can be reproduced by running an example_test.py (given below) within the unittest module using the call python -m unittest discover -s tests -p "example_test.py" from within the my_codedirectory. The filemy_code/tests/example_tests.py` contains the following:
&lt;denchmark-code&gt;import unittest                               
import tensorflow as tf                       
                                              
class SomeTestClass(unittest.TestCase): 
    """Some docstring."""              
                                              
    def test_something(self):          
        print("Testing something...\n")
        print tf.contrib.rnn.LSTMCell         
        session = tf.Session()                
        session.close()                       
&lt;/denchmark-code&gt;

Note that the error occurs only when both session is created and there is a reference to tf.contrib.rnn.
	</description>
	<comments>
		<comment id='1' author='freakanth' date='2017-06-12T22:42:23Z'>
		I'm having the same problem - my python code that uses TensorFlow will segfault when the python process terminates. I'm also using TF 1.0.0, but haven't touched any of the source code.
I am also seeing the problem ONLY when I use both tf.Session() AND anything in tf.contrib.rnn.
		</comment>
		<comment id='2' author='freakanth' date='2017-06-13T17:41:18Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
, do you have any ideas on this? I am able to reproduce this.
		</comment>
		<comment id='3' author='freakanth' date='2017-06-13T17:45:33Z'>
		I was able to reproduce this in 1.0.1, but I found that in the nightly build it works fine, so I'd recommend upgrading to at least 1.2.
		</comment>
		<comment id='4' author='freakanth' date='2017-06-13T17:48:32Z'>
		I am using tensorflow-gpu binary and could not reproduce this with v1.1.0 (current PyPI version).
Log is &lt;denchmark-link:https://gist.github.com/byronyi/54d30dd39f5420d883a1a26919e6ad7c&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='5' author='freakanth' date='2017-06-13T17:57:44Z'>
		Yes - I don't see the problem in v1.1 or higher. However, our team is heavily using v1.0 and we won't be able to upgrade everything anytime soon....
For what it's worth, I found a temporary fix:
I have a train() method, in which i have something like
&lt;denchmark-code&gt;def train(self, ...):
    self.get_model(...)
    self.fit(...)
&lt;/denchmark-code&gt;

in which get_model() builds the model:
&lt;denchmark-code&gt;def get_model(self, ...):
    tf.reset_default_graph()
    self.tf_graph = tf.Graph()
    with self.tf_graph.as_default():
        build graph...(this is where I use tf.contrib.rnn)
&lt;/denchmark-code&gt;

and fit() trains the model:
&lt;denchmark-code&gt;def fit(self, ...):
    with self.tf_graph.as_default():
        self.sess = tf.Session()
        self.sess.run(...)
&lt;/denchmark-code&gt;

The temporary fix I added was in train():
&lt;denchmark-code&gt;def train(self, ...):
    _ = tf.Session()   # adding this makes the segfault go away
    self.get_model(...)
    self.fit(...)
&lt;/denchmark-code&gt;

What's interesting is the session returned from _ = tf.Session() is never used anywhere, because in fit() I make a new session and use that session.
Hopefully this helps anyone who's also stuck in v1.0 for the moment...
		</comment>
		<comment id='6' author='freakanth' date='2017-09-12T13:07:19Z'>
		This issue is automatically closed due to lack of activity. Please re-open if this is still an issue for you. Thanks!
		</comment>
	</comments>
</bug>