<bug id='8102' author='aliosmanulusoy' open_date='2017-03-05T14:26:08Z' closed_time='2017-05-01T16:22:26Z'>
	<summary>Scatter_nd doc not clear about concurrent updates</summary>
	<description>
The doc on the scatter_nd does not specify the consequence of multiple updates that reference the same location.
I've tested this using the following code:
indices = tf.constant([[4], [3], [1], [1]])
updates = tf.constant([9, 10, 11, 12])
shape = tf.constant([8])
scatter = tf.scatter_nd(indices, updates, shape)
with tf.Session() as sess:
  print sess.run(scatter)
The resulting tensor is:
[0, 23, 0, 10, 9, 0, 0, 0]
So it seems the updates are added. Is this the intended usage? If so, it would be great to clarify this in the docs.
Thanks!
	</description>
	<comments>
		<comment id='1' author='aliosmanulusoy' date='2017-03-06T21:17:09Z'>
		The CPU/GPU implementation initializes to zero and uses &lt;denchmark-link:https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/scatter_nd_op.cc#L189&gt;add&lt;/denchmark-link&gt;
 rather than assign.
It seems like a somewhat stronger promise than assign, where the output would be
&lt;denchmark-code&gt;[0, 12, 0, 10, 9, 0, 0, 0] or [0, 11, 0, 10, 9, 0, 0, 0]
&lt;/denchmark-code&gt;

non-deterministically, or in an order that we define.
&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 for opinion
		</comment>
		<comment id='2' author='aliosmanulusoy' date='2017-08-09T20:49:27Z'>
		&lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
 the document is still confusing for this function.

WARNING: The order in which updates are applied is nondeterministic, so the output will be nondeterministic if indices contains duplicates.

Even if order is nondeterministic, the summation is deterministic. Why not just promise that duplicates will be summed?
		</comment>
		<comment id='3' author='aliosmanulusoy' date='2017-08-09T20:55:05Z'>
		I didn't write the code or the doc, so I'm not the best person to clarify this, but maybe because order of operations for floating point values matter that it's still technically a non-deterministic result.  See "catastrophic cancellation" for cases where addition order matters.
		</comment>
		<comment id='4' author='aliosmanulusoy' date='2017-08-09T20:59:33Z'>
		Also, I think the language implies all updates will be attempted in some order, but feel free to send a PR to update the doc to clarify that point, if you think it's useful.
		</comment>
		<comment id='5' author='aliosmanulusoy' date='2017-08-09T21:04:15Z'>
		OK. Thanks.
		</comment>
		<comment id='6' author='aliosmanulusoy' date='2017-10-20T15:25:50Z'>
		Is there a way to change add to update?
		</comment>
		<comment id='7' author='aliosmanulusoy' date='2017-11-02T15:46:28Z'>
		If you are in the unpooling business:
&lt;denchmark-link:https://github.com/teramototoya&gt;@teramototoya&lt;/denchmark-link&gt;
 what I did as a hack: with &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/unique_with_counts&gt;https://www.tensorflow.org/api_docs/python/tf/unique_with_counts&lt;/denchmark-link&gt;
 i counted the multiplication in the indices and i divided the tensor which was holding the values (aka tensor named 'updates' in the first comment)  with this counter
so when add() comes it will undo what the division made
you can check this simple script: &lt;denchmark-link:https://github.com/csnemes2/conv-net-viz/blob/master/ut_unpool.py&gt;https://github.com/csnemes2/conv-net-viz/blob/master/ut_unpool.py&lt;/denchmark-link&gt;

If not, so your problem is general, then you have to somehow flatten your indices, and then tf.unique, see this post:
&lt;denchmark-link:https://stackoverflow.com/questions/44117430/how-to-use-tf-scatter-nd-without-accumulation&gt;https://stackoverflow.com/questions/44117430/how-to-use-tf-scatter-nd-without-accumulation&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='aliosmanulusoy' date='2017-11-03T07:43:16Z'>
		&lt;denchmark-link:https://github.com/csnemes2&gt;@csnemes2&lt;/denchmark-link&gt;
 I also tried the same implementation as your hack, but I could not do it well. It worked well with your implementation! Thank you!
		</comment>
	</comments>
</bug>