<bug id='31688' author='dicastro' open_date='2019-08-16T12:40:33Z' closed_time='2019-08-19T14:44:11Z'>
	<summary>Different result when evaluating tflite model from python and from android</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Nokia 7 plus
TensorFlow installed from (source or binary): don't know (I am using Google Colab)
TensorFlow version (use command below): 1.14.0 (git version: v1.14.0-0-g87989f6959 - compiler version: 7.4.0)
Python version: 3.6.8
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): c++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CUDA/cuDNN version: 10.0
GPU model and memory: NVIDIA-SMI 418.67 - 15079MiB

Describe the current behavior
I've trained a model using keras (in google colab), then I've converted the keras h5 file to tflite using TFLiteConverter (also in google colab) by using this code:
import tensorflow as tf

tflite_converter = tf.lite.TFLiteConverter.from_keras_model_file(&lt;KERAS_H5_MODEL_PATH&gt;)

tflite_model = tflite_converter.convert()

with open(&lt;KERAS_TFLITE_DEST_PATH&gt;, 'wb') as tflite_model_file:
    tflite_model_file.write(tflite_model)
After that, I've run the tflite model (in google colab also):
import numpy as np
import tensorflow as tf

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=tflite_model_path)
interpreter.allocate_tensors()

input_data = np.ones((1, 256, 256, 3), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output = [interpreter.get_tensor(output_details[0]['index'])[0], interpreter.get_tensor(output_details[1]['index'])[0]]
The tflite model can be found &lt;denchmark-link:https://drive.google.com/file/d/1cxXHtBGJk5h__6Elf4ZLvtJW8mdRs4_f/view?usp=sharing&gt;here&lt;/denchmark-link&gt;

However, when I run the tflite model in an android app (using the same input data) y get different outputs:
(This code is based on &lt;denchmark-link:https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android&gt;this example&lt;/denchmark-link&gt;
 from tensorflow)
AssetFileDescriptor fileDescriptor = assets.openFd(&lt;MODEL_TFLITE_FILENAME&gt;);
FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
FileChannel fileChannel = inputStream.getChannel();
long startOffset = fileDescriptor.getStartOffset();
long declaredLength = fileDescriptor.getDeclaredLength();
MappedByteBuffer model = fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);

Interpreter.Options interpreterOptions = new Interpreter.Options().setNumThreads(1);
tfLite = new Interpreter(model, interpreterOptions);

float[][][][] floatValues = new float[1][256][256][3];

for (int i = 0; i &lt; 256; i++) {
    for (int j = 0; j &lt; 256; j++) {
        for (int k = 0; k &lt; 3; k++) {
            floatValues[0][i][j][k] = 1.0f;
        }
    }
}

Object[] inputArray = {floatValues};

output1 = new float[1][8][8][18];
output2 = new float[1][16][16][18];

Map&lt;Integer, Object&gt; outputMap = new HashMap&lt;&gt;();
outputMap.put(0, output1);
outputMap.put(1, output2);

tfLite.runForMultipleInputsOutputs(inputArray, outputMap);
The output values I get in the android code are not the same as the outputs obtained with python code.
&lt;denchmark-code&gt;// This outputs correspond to output1[0][0][0]

 Python results    |  Android results
 0 &gt;   0.06118933  |  0 &gt;   0.061190486
 1 &gt; - 0.50384498  |  1 &gt; - 0.50384396
 2 &gt; - 0.30500048  |  2 &gt; - 0.30500013
 3 &gt; - 0.18725708  |  3 &gt; - 0.18725668
 4 &gt; -12.56872463  |  4 &gt; -12.568727
 5 &gt; - 3.53239870  |  5 &gt; - 3.5323968
 6 &gt;   0.26756036  |  6 &gt;   0.26756087
 7 &gt; - 0.63708508  |  7 &gt; - 0.6370841
 8 &gt; - 0.11959708  |  8 &gt; - 0.119596675
 9 &gt; - 0.42219949  |  9 &gt; - 0.42219883
10 &gt; -12.26699734  | 10 &gt; -12.266998
11 &gt; - 3.42504168  | 11 &gt; - 3.4250417
12 &gt;   0.29714739  | 12 &gt;   0.2971481
13 &gt; - 0.76750284  | 13 &gt; - 0.7675022
14 &gt; - 0.13859260  | 14 &gt; - 0.13859189
15 &gt; - 0.02096577  | 15 &gt; - 0.020965554
16 &gt; -12.78137684  | 16 &gt; -12.781382
17 &gt; - 3.34643984  | 17 &gt; - 3.3464384
&lt;/denchmark-code&gt;

Here the results are similar, there is a small difference. However I've also tried with a real input (comming from an image), and in this case, the results in android are totally different.
This is a model to detect objects in images (yolo v3 tiny) and I've constated that the values obtained with python code are the correct ones. When I run the python code with a real input (an image) it detects the objects.

Why do I get different outputs in android?
Do I have to do something special to run model in android?
Do I have to do something different in model conversion from H5 to tflite?
Does it has something to do with the way as java works with floats?
Should I use a quantized version of the model?

Describe the expected behavior
The expected behavior is to get the same result running the model in android that when I run the model in python
Code to reproduce the issue
Already provided in the description of the current behavior
Other info / logs
The tflite model can be found &lt;denchmark-link:https://drive.google.com/file/d/1cxXHtBGJk5h__6Elf4ZLvtJW8mdRs4_f/view?usp=sharing&gt;here&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='dicastro' date='2019-08-19T14:44:11Z'>
		Seems like those differences are normal. After correcting some bug in the code that processes the output of the model I have noticed that these differences do not alter the final result.
		</comment>
		<comment id='2' author='dicastro' date='2019-08-19T14:44:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31688&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31688&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='dicastro' date='2019-08-28T17:18:23Z'>
		Hey stuck with same issue for almost 3 days now. Can you tell me what the bug was in your android code?
(I think I responded to your SO post as well)
		</comment>
		<comment id='4' author='dicastro' date='2019-08-30T04:57:38Z'>
		I've already seen your SO comment :-)
The first bug was iterating the output vectors of the TFLITE model. YOLOv3 Tiny has two outputs o sizes 8x8 and 16x16 when the input has 256x256 size. However I had the same for (with the same limit) to iterate both outputs. It was a copy+paste bug.And also, at the beginning I was also comparing badly the python results and the Android ones (the comparison in this question is ok). This was because in the python implementation there was a function that modified an input and I was using that modified input to compare with the Android one (unmodified).
		</comment>
	</comments>
</bug>