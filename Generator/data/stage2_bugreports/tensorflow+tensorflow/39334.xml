<bug id='39334' author='zhangqibot' open_date='2020-05-09T05:59:42Z' closed_time='2020-05-11T05:34:08Z'>
	<summary>value error raised whern calling export_saved_model() with estimator model</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS
TensorFlow version (use command below): TensorFlow 2.0 CPU | v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: python3.6
CUDA/cuDNN version: None
GPU model and memory: None

&lt;denchmark-h:h2&gt;Value Error raised whern calling export_saved_model() with estimator model&lt;/denchmark-h&gt;

I am trying to export my trained estimator model for serving. The estimator model was converted from keras model with tf.keras.estimator.model_to_estimator, and I have successfully trained and evaluated it. However, when I am trying to save the model to local disk for serving,  a bug just bothered me... the codes and the logs are as listed below:
&lt;denchmark-h:h2&gt;codes&lt;/denchmark-h&gt;

model_estimator = tf.keras.estimator.model_to_estimator(keras_model=model)
# ...
model_estimator.train(input_fn=dataset_func, steps=STEPS_PER_EPOCH)
model_estimator.evaluate(input_fn=dataset_func, steps=STEPS_PER_EPOCH)
# ...
model_estimator.export_saved_model(model_path, serving_input_fn) # bug comes from here
&lt;denchmark-h:h2&gt;log for Error info&lt;/denchmark-h&gt;

INFO:tensorflow:Calling model_fn.
[2020-05-09 13:20:56] - estimator.py[line:1147] - INFO: Calling model_fn.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    470                 preferred_dtype=default_dtype,
--&gt; 471                 as_ref=input_arg.is_ref)
    472             if input_arg.number_attr and len(

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_n_to_tensor(values, dtype, name, as_ref, preferred_dtype, ctx)
   1364             preferred_dtype=preferred_dtype,
-&gt; 1365             ctx=ctx))
   1366   return ret

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)
   1270           "Tensor conversion requested dtype %s for Tensor with dtype %s: %r" %
-&gt; 1271           (dtype.name, value.dtype.name, value))
   1272     return value

ValueError: Tensor conversion requested dtype int64 for Tensor with dtype float32: &lt;tf.Tensor 'no_mask_4_115/no_mask_4/Identity:0' shape=(None, 1) dtype=float32&gt;

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-76-01ac33b3b8f1&gt; in &lt;module&gt;
----&gt; 1 model_estimator.export_saved_model(model_path, serving_input_fn)

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in export_saved_model(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)
    733         as_text=as_text,
    734         checkpoint_path=checkpoint_path,
--&gt; 735         strip_default_attrs=True)
    736 
    737   def experimental_export_all_saved_models(

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _export_all_saved_models(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)
    856             builder, input_receiver_fn_map, checkpoint_path,
    857             save_variables, mode=ModeKeys.PREDICT,
--&gt; 858             strip_default_attrs=strip_default_attrs)
    859         save_variables = False
    860 

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _add_meta_graph_for_mode(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)
    929           labels=getattr(input_receiver, 'labels', None),
    930           mode=mode,
--&gt; 931           config=self.config)
    932 
    933       export_outputs = export_lib.export_outputs_for_mode(

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1146 
   1147     logging.info('Calling model_fn.')
-&gt; 1148     model_fn_results = self._model_fn(features=features, **kwargs)
   1149     logging.info('Done calling model_fn.')
   1150 

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in model_fn(features, labels, mode)
    286         features=features,
    287         labels=labels,
--&gt; 288         optimizer_config=optimizer_config)
    289     model_output_names = []
    290     # We need to make sure that the output names of the last layer in the model

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in _clone_and_build_model(mode, keras_model, custom_objects, features, labels, optimizer_config)
    225       in_place_reset=(not keras_model._is_graph_network),
    226       optimizer_iterations=global_step,
--&gt; 227       optimizer_config=optimizer_config)
    228 
    229   if sample_weight_tensors is not None:

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in clone_and_build_model(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)
    632         clone = clone_model(model, input_tensors=input_tensors)
    633     else:
--&gt; 634       clone = clone_model(model, input_tensors=input_tensors)
    635 
    636     if all([isinstance(clone, Sequential),

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in clone_model(model, input_tensors, clone_function)
    420   else:
    421     return _clone_functional_model(
--&gt; 422         model, input_tensors=input_tensors, layer_fn=clone_function)
    423 
    424 

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in _clone_functional_model(model, input_tensors, layer_fn)
    193   input_tensors, output_tensors, created_layers = (
    194       network.reconstruct_from_config(model_config,
--&gt; 195                                       created_layers=created_layers))
    196   metrics_names = model.metrics_names
    197   model = Model(input_tensors, output_tensors, name=model.name)

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)
   1850       if layer in unprocessed_nodes:
   1851         for node_data in unprocessed_nodes.pop(layer):
-&gt; 1852           process_node(layer, node_data)
   1853 
   1854   input_tensors = []

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in process_node(layer, node_data)
   1797       if not isinstance(input_tensors, dict) and len(flat_input_tensors) == 1:
   1798         input_tensors = flat_input_tensors[0]
-&gt; 1799       output_tensors = layer(input_tensors, **kwargs)
   1800 
   1801       # Update node index map.

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    845                     outputs = base_layer_utils.mark_as_return(outputs, acd)
    846                 else:
--&gt; 847                   outputs = call_fn(cast_inputs, *args, **kwargs)
    848 
    849             except errors.OperatorNotAllowedInGraphError as e:

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/merge.py in call(self, inputs)
    180         return y
    181     else:
--&gt; 182       return self._merge_function(inputs)
    183 
    184   @tf_utils.shape_type_conversion

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/merge.py in _merge_function(self, inputs)
    392 
    393   def _merge_function(self, inputs):
--&gt; 394     return K.concatenate(inputs, axis=self.axis)
    395 
    396   @tf_utils.shape_type_conversion

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in concatenate(tensors, axis)
   2706     return sparse_ops.sparse_concat(axis, tensors)
   2707   else:
-&gt; 2708     return array_ops.concat([to_dense(x) for x in tensors], axis)
   2709 
   2710 

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py in wrapper(*args, **kwargs)
    178     """Call target, and fall back on dispatchers if there is a TypeError."""
    179     try:
--&gt; 180       return target(*args, **kwargs)
    181     except (TypeError, ValueError):
    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in concat(values, axis, name)
   1429           dtype=dtypes.int32).get_shape().assert_has_rank(0)
   1430       return identity(values[0], name=name)
-&gt; 1431   return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
   1432 
   1433 

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in concat_v2(values, axis, name)
   1255   _attr_N = len(values)
   1256   _, _, _op = _op_def_lib._apply_op_helper(
-&gt; 1257         "ConcatV2", values=values, axis=axis, name=name)
   1258   _result = _op.outputs[:]
   1259   _inputs_flat = _op.inputs

/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    497                                 (prefix, dtype.name))
    498               else:
--&gt; 499                 raise TypeError("%s that don't all match." % prefix)
    500             else:
    501               raise TypeError(

TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64] that don't all match.
Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='zhangqibot' date='2020-05-11T05:34:10Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39334&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39334&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>