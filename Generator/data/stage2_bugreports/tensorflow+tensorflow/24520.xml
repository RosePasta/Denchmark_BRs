<bug id='24520' author='dineshdharme' open_date='2018-12-22T16:43:03Z' closed_time='2020-05-11T22:19:39Z'>
	<summary>"ValueError: Cannot take the length of Shape with unknown rank". error when passing tf.data.Dataset tensors to model.fit</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): "18.04.1 LTS (Bionic Beaver)"
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tf.VERSION = 1.12.0
Python version: python3.6
Bazel version (if compiling from source): no
GCC/Compiler version (if compiling from source): no
CUDA/cuDNN version: cuda9.0 with cuDNN 7.4.1
GPU model and memory: GTX 1080 with 8 GB

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
I am trying to pass the tfrecords read through tf.data.Dataset api into the model.fit .
Since the images could be of different sizes, I am storing the image shapes into tfrecords itself which are
later on read and applied to the img data using  tf.reshape . But the tensorflow.keras is unable to determine the shape of this image data at this stage and throws the error.
&lt;denchmark-code&gt;def _parse_function(proto):
    keys_to_features = {"im_path": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),
                        "im_shape": tf.FixedLenSequenceFeature([], tf.int64, allow_missing=True),
                        "im_arr": tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),
                        "label": tf.FixedLenSequenceFeature([], tf.int64, allow_missing=True),
                        }

    parsed_features = tf.parse_single_example(serialized=proto, features=keys_to_features)
    parsed_features['im_arr'] = parsed_features['im_arr'][0]
    parsed_features['label'] = parsed_features['label'][0]
    parsed_features['im_arr'] = tf.decode_raw(parsed_features['im_arr'], tf.uint8)
    parsed_features['im_arr'] = tf.reshape(parsed_features['im_arr'], parsed_features['im_shape'])

    return parsed_features['im_arr'], parsed_features['label']
&lt;/denchmark-code&gt;

The error thrown is as follows :
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "issue/IssueScript.py", line 75, in &lt;module&gt;
    verbose=1)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1536, in fit
    validation_split=validation_split)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 992, in _standardize_user_data
    class_weight, batch_size)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1117, in _standardize_weights
    exception_prefix='input')
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py", line 284, in standardize_input_data
    data = [standardize_single_array(x) for x in data]
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py", line 284, in &lt;listcomp&gt;
    data = [standardize_single_array(x) for x in data]
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py", line 218, in standardize_single_array
    if x.shape is not None and len(x.shape) == 1:
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py", line 579, in __len__
    raise ValueError("Cannot take the length of Shape with unknown rank.")
ValueError: Cannot take the length of Shape with unknown rank.
&lt;/denchmark-code&gt;

So as a debugging step, I removed the length check present in the standardize_single_array function by changing the check as (note the False and part which bypasses the length check)
&lt;denchmark-code&gt;  if x is None:
    return None
  if False and (x.shape is not None and len(x.shape) == 1):
    if tensor_util.is_tensor(x):
      return array_ops.expand_dims(x, axis=1)
    else:
      return np.expand_dims(x, 1)
  return x
&lt;/denchmark-code&gt;

Then I get the following error
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "issue/IssueScript.py", line 75, in &lt;module&gt;
    verbose=1)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1536, in fit
    validation_split=validation_split)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 992, in _standardize_user_data
    class_weight, batch_size)
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1154, in _standardize_weights
    exception_prefix='target')
  File "opt/github/example-classification/env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py", line 323, in standardize_input_data
    'with shape ' + str(data_shape))
ValueError: Error when checking target: expected activation_4 to have 2 dimensions, but got array with shape (None,)
&lt;/denchmark-code&gt;

I did the same with the above error. I removed the check present at line 323 by commenting out the length check as follows.
&lt;denchmark-code&gt;        """
        if len(data_shape) != len(shape):
          raise ValueError('Error when checking ' + exception_prefix +
                           ': expected ' + names[i] + ' to have ' +
                           str(len(shape)) + ' dimensions, but got array '
                           'with shape ' + str(data_shape))
        """
&lt;/denchmark-code&gt;

Now the training proceeds smoothly without error. I believe there is issue with tf.reshape when tensors are supplied as a shape to the function.

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Code : &lt;denchmark-link:https://github.com/dineshdharme/tensorflow-issue1&gt;https://github.com/dineshdharme/tensorflow-issue1&lt;/denchmark-link&gt;

Just run : 
I have also added a tfrecords generating script tfrecords_utils.py which you can call by
To generate tfrecords file using the image data present in the data folder :
python3 issue/tfrecords_utils.py
	</description>
	<comments>
		<comment id='1' author='dineshdharme' date='2018-12-22T18:40:43Z'>
		&lt;denchmark-link:https://github.com/dineshdharme&gt;@dineshdharme&lt;/denchmark-link&gt;
 Added PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/24522&gt;#24522&lt;/denchmark-link&gt;
 for the fix.
		</comment>
		<comment id='2' author='dineshdharme' date='2019-01-14T08:27:23Z'>
		Even fixing the issues &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/24522&gt;#24522&lt;/denchmark-link&gt;
  in my local code i still see the same problem. My code snippet is as:
&lt;denchmark-code&gt;def get_image_arr(path, width, height, img_norm="divide"):
  try:
    img = cv2.imread(path, 1)
    if img_norm == "sub_and_divide":
      img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1
    elif img_norm == "sub_mean":
      img = cv2.resize(img, (width, height))
      img = img.astype(np.float32)
      img[:,:,0] -= 103.939
      img[:,:,1] -= 116.779
      img[:,:,2] -= 123.68
    elif img_norm == "divide":
      img = cv2.resize(img, (width, height))
      img = img.astype(np.float32)
      img = img/255.0
    return img
  
  except Exception as e:
    print (e)
    

def get_groundtruth_arr(path, width, height, n_classes=1):
  try:
    gt_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    gt_img = gt_img.astype(np.float32)
    gt_img = cv2.resize(gt_img, (width, height))
    gt_img = gt_img/255.0
    gt_img_exp = np.expand_dims(gt_img, axis=2)
    
    return gt_img_exp
      
  except Exception as e:
    print (e)

def get_x_and_y(im, gt):
  X = get_image_arr(im, input_width, input_height)
  Y = get_groundtruth_arr(gt, output_width, output_height)
  print(X.ndim)
  return X, Y

images_path = train_images_path
gt_path = train_gt_path
images = glob.glob( images_path + "*.jpg" ) + glob.glob( images_path + "*.png" ) +  glob.glob( images_path + "*.jpeg" )
images.sort()
ground_truth  = glob.glob( gt_path + "*.jpg" ) + glob.glob( gt_path + "*.png" ) +  glob.glob( gt_path + "*.jpeg" )
ground_truth.sort()

dataset = tf.data.Dataset.from_tensor_slices((images, ground_truth))

dataset = dataset.map(lambda img, gt_img: tuple(tf.py_func(
                      get_x_and_y, [img, gt_img], [tf.float32, tf.float32])))

dataset = dataset.shuffle(dataset_size(train_images_path)).batch(BATCH_SZ)

&lt;/denchmark-code&gt;

The error i get is following:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-99-deead2a4c31f&gt; in &lt;module&gt;()
----&gt; 1 model.fit(dataset, epochs=1, steps_per_epoch=per_epoch_steps, validation_data=val_dataset, validation_steps=steps_validation, verbose=1, callbacks=[tbCallBack])

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)
    920           steps_per_epoch=steps_per_epoch,
    921           validation_steps=validation_steps,
--&gt; 922           steps_name='steps_per_epoch')
    923 
    924   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, steps_name, **kwargs)
    143 
    144   # Prepare input data.
--&gt; 145   ins = _prepare_feed_values(model, inputs, targets, sample_weights, mode)
    146   if not is_dataset:
    147     num_samples_or_steps = _get_num_samples_or_steps(ins, batch_size,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py in _prepare_feed_values(model, inputs, targets, sample_weights, mode)
    424     inputs, targets, sample_weights = model._standardize_user_data(
    425         inputs,
--&gt; 426         extract_tensors_from_dataset=True)
    427 
    428   inputs = training_utils.ModelInputs(inputs).as_list()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2456           feed_input_shapes,
   2457           check_batch_axis=False,  # Don't enforce the batch size.
-&gt; 2458           exception_prefix='input')
   2459 
   2460     if y is not None:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    303       data = [
    304           x.values if x.__class__.__name__ == 'DataFrame' else x for x in data
--&gt; 305       ]
    306   else:
    307     data = data.values if data.__class__.__name__ == 'DataFrame' else data

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py in &lt;listcomp&gt;(.0)
    303       data = [
    304           x.values if x.__class__.__name__ == 'DataFrame' else x for x in data
--&gt; 305       ]
    306   else:
    307     data = data.values if data.__class__.__name__ == 'DataFrame' else data

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py in standardize_single_array(x, expected_shape)
    234 
    235   #if (x.shape is not None
--&gt; 236   if tensor_util.is_tensor(x):
    237       x_shape_ndims = x.shape.ndims if x.shape is not None else None
    238   else:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in __len__(self)
    746     """Returns the rank of this shape, or raises ValueError if unspecified."""
    747     if self._dims is None:
--&gt; 748       raise ValueError("Cannot take the length of shape with unknown rank.")
    749     return len(self._dims)
    750 

ValueError: Cannot take the length of shape with unknown rank.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='dineshdharme' date='2019-05-19T20:06:44Z'>
		&lt;denchmark-link:https://github.com/milinddeore&gt;@milinddeore&lt;/denchmark-link&gt;
 for what it's worth, I ran into the same error when using , and was able to fix the issue by passing in an argument for &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#args_7&gt;output_shapes&lt;/denchmark-link&gt;
. I didn't even have to specify the exact dimensions - using something like  worked in the case of using 3 dimensional images. While the  method doesn't have have the same parameter, I wonder if there is an analogous way to set the shape (even if filled with , but having the right dimensionality) that might resolve your issue until this PR is merged.
So, I have an imagenet generator outputting (image, label) of shape ((224, 224, 3), (1, )).
Original code that leads to that same error being thrown:
&lt;denchmark-code&gt;dataset = tf.Dataset.from_generator(
    generator, output_types=('float32', 'uint8')
)
&lt;/denchmark-code&gt;

Fixed code that prevents that error:
&lt;denchmark-code&gt;dataset = tf.Dataset.from_generator(
    generator, output_types=('float32', 'uint8'),
    output_shapes=(tf.TensorShape((None, None, None)), tf.TensorShape((1, )))
)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='dineshdharme' date='2019-07-16T01:57:28Z'>
		I have also encountered this issue when passing tf.data to tf.keras fit method.
Unlike &lt;denchmark-link:https://github.com/sallamander&gt;@sallamander&lt;/denchmark-link&gt;
 though, I used  instead of .
The shape can then be defined inside the mapping function.
&lt;denchmark-code&gt;def preprocessing(img_path):
    train_img = load_img(img_path) # Unrelated implementation thus not shown
    train_img = tf.reshape(train_img, shape=(input_width, input_height, input_channel))
    return train_img

train_data = tf.data.Dataset.from_tensor_slices(img_paths)
train_data = train_data.shuffle(len(img_paths)).map(preprocessing)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='dineshdharme' date='2019-07-18T19:31:41Z'>
		I have the same error like so:
 File "C:\Program Files\JetBrains\PyCharm Community Edition 2019.1.1\helpers\pydev\pydevd.py", line 1758, in &lt;module&gt; main() File "C:\Program Files\JetBrains\PyCharm Community Edition 2019.1.1\helpers\pydev\pydevd.py", line 1752, in main globals = debugger.run(setup['file'], None, None, is_module) File "C:\Program Files\JetBrains\PyCharm Community Edition 2019.1.1\helpers\pydev\pydevd.py", line 1147, in run pydev_imports.execfile(file, globals, locals)  # execute the script File "C:\Program Files\JetBrains\PyCharm Community Edition 2019.1.1\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile exec(compile(contents+"\n", file, 'exec'), glob, loc) File "C:/Users/hep01/PycharmProjects/DWIDL/3DUnet1.1_with_tfdata_pipeline.py", line 138, in &lt;module&gt; model.fit(data_train,epochs=1,callbacks=[checkpointer]) File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training.py", line 780, in fit steps_name='steps_per_epoch') File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py", line 174, in model_iteration ins = _prepare_feed_values(model, inputs, targets, sample_weights, mode) File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py", line 501, in _prepare_feed_values extract_tensors_from_dataset=True) File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training.py", line 2651, in _standardize_user_data exception_prefix='input') File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py", line 334, in standardize_input_data standardize_single_array(x, shape) for (x, shape) in zip(data, shapes) File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py", line 334, in &lt;listcomp&gt; standardize_single_array(x, shape) for (x, shape) in zip(data, shapes) File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\keras\engine\training_utils.py", line 265, in standardize_single_array if (x.shape is not None and len(x.shape) == 1 and File "C:\Users\hep01\PycharmProjects\DWIDL\venv\lib\site-packages\tensorflow\python\framework\tensor_shape.py", line 825, in __len__ raise ValueError("Cannot take the length of shape with unknown rank.") ValueError: Cannot take the length of shape with unknown rank.
Interestingly, the error does not exist when I use CPU to tun the training. It appears after I installed a GPU with toolbox such as CUDA and cuDNN. Hope that info helps for debugging this.
		</comment>
		<comment id='6' author='dineshdharme' date='2019-07-24T05:45:42Z'>
		Same situation here. Installing the  nightly build of today (July 24th, 2019) with:
&lt;denchmark-code&gt;pip install tf-nightly-2.0-preview
&lt;/denchmark-code&gt;

in colaboratory.
If I use a strategy, in this case to access a TPU, I get the error:
&lt;denchmark-code&gt;ValueError: Cannot take the length of shape with unknown rank.
&lt;/denchmark-code&gt;

However, if I just avoid the use of an strategy, thinks work smoothly.
I am using a dataset.map which includes a numpy_function that calls a python object that is in charge of the training.
class DummyTrainer:
    def __init__(self, file_path, samples):
        self.file_path = file_path
        self.samples = samples
        self.index_array = np.random.permutation(self.samples)

    def _calc_image(self, index):
        filename= os.path.join(self.file_path, str(i)+'.png')
        if os.path.isfile(filename):
            img_raw = tf.io.read_file(filename)
            img = tf.io.decode_png(img_raw, channels=1)
            img = tf.dtypes.cast(img, tf.float32) / 256.0
            return img
        else:
            return None

    def _dataset_function(self, index):
        return tuple(tf.numpy_function(
            self._calc_image, [index],
            [tf.float32, tf.uint8]))

    def get_trainer_dataset(self):
        # Reading the images from the numpy array of indexes
        dataset = Dataset.from_tensor_slices(
            self.index_array[:self.trainer_samples])
        return dataset.map(self._dataset_function).shuffle(1)

trainer = DummyTrainer('data', 256)

model.fit(trainer.get_trainer_dataset(), ...)
My first guess would be something related with serialization.
		</comment>
		<comment id='7' author='dineshdharme' date='2019-08-05T20:26:13Z'>
		same problem with tf1.14
		</comment>
		<comment id='8' author='dineshdharme' date='2019-09-19T04:19:41Z'>
		Also having this problem with tf1.14
In my case, I encountered the problem when using a tf.data.Dataset, with which I had mapped a python function using a combination of tf.data.Dataset.map() and tf.py_func. I was able to sidestep the issue by specifying the shape of the tensor returned from tf.py_func, as below:
        def mappable_fn(x):
            result_tensors = tf.py_func(func=my_py_func,
                                        inp=[my_py_func_args],
                                        Tout=[my_py_func_output_types])
            result_tensor.set_shape(the_shape_i_know_ahead_of_time)
            return (result_tensor)
Obviously this will only work if you know the shapes of the tensor(s) ahead of time.
		</comment>
		<comment id='9' author='dineshdharme' date='2020-01-07T23:14:36Z'>
		Thanks for flagging this. Looks like we don't check the shape correctly in several different places -- fix in progress.
		</comment>
		<comment id='10' author='dineshdharme' date='2020-01-28T19:44:42Z'>
		&lt;denchmark-link:https://github.com/rachellim&gt;@rachellim&lt;/denchmark-link&gt;
 I encountered exactly the same thing as &lt;denchmark-link:https://github.com/adriancaruana&gt;@adriancaruana&lt;/denchmark-link&gt;
 . His proposed solution works for me with . Be sure to apply  to the tensor  by , and not within .
		</comment>
		<comment id='11' author='dineshdharme' date='2020-02-18T17:33:10Z'>
		I'm currently using tf.version: 2.1.0 docker image from TensorFlow docker hub.
I encountered this issue when I used tf.data.TFRecordDataset() as an argument of model.fit().
As &lt;denchmark-link:https://github.com/birkanatici&gt;@birkanatici&lt;/denchmark-link&gt;
 mentioned, using dataset.as_numpy_iterator() helped me to resolve the error, but it's just workaround.
		</comment>
		<comment id='12' author='dineshdharme' date='2020-02-18T17:49:38Z'>
		@dartlune -- please see my comment above (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24520#issuecomment-577325475&gt;#24520 (comment)&lt;/denchmark-link&gt;
). Does the workaround of using  help?
		</comment>
		<comment id='13' author='dineshdharme' date='2020-02-18T18:13:16Z'>
		&lt;denchmark-link:https://github.com/rachellim&gt;@rachellim&lt;/denchmark-link&gt;
 Oh, I thought that only tensor(non-scalar) should be applied .
After I apply  to a scalar, the error is gone!
Thank you 
		</comment>
		<comment id='14' author='dineshdharme' date='2020-02-20T15:25:13Z'>
		Hello All,
I am currently working with Tensorflow 2.1
I am trying to implement MirroredStrategy to an Image captions generator. I am getting the above-said error when I try to start training.
Code snippet
`
&lt;denchmark-code&gt;   with strategy.scope():

	def map_func(img_name, cap):
	img_tensor = np.load(img_name.decode('utf-8')+'.npy')
	img_tensor.set_shape(299,299)
	return img_tensor, cap

   dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))

   dataset = dataset.map(lambda item1, item2: tf.numpy_function(map_func, [item1, item2], [tf.float32, tf.int32]))

   dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
   dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

   train_dist_dataset = strategy.experimental_distribute_dataset(dataset)`
&lt;/denchmark-code&gt;

Error
Traceback (most recent call last): File "MirrorTrainer_Image2Smilex.py", line 88, in &lt;module&gt; train_dist_dataset = strategy.experimental_distribute_dataset(dataset) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/distribute_lib.py", line 677, in experimental_distribute_dataset return self._extended._experimental_distribute_dataset(dataset)  # pylint: disable=protected-access File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/mirrored_strategy.py", line 580, in _experimental_distribute_dataset split_batch_by=self._num_replicas_in_sync) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py", line 89, in get_distributed_dataset input_context=input_context) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/distribute/input_lib.py", line 509, in __init__ dataset = distribute._RebatchDataset(dataset, split_batch_by) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/data/experimental/ops/distribute.py", line 110, in __init__ rebatch, dataset_ops.get_structure(input_dataset)) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/data/util/nest.py", line 245, in map_structure structure[0], [func(*x) for x in entries]) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/data/util/nest.py", line 245, in &lt;listcomp&gt; structure[0], [func(*x) for x in entries]) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/data/experimental/ops/distribute.py", line 105, in rebatch batch_size = recalculate_batch_size(type_spec._to_legacy_output_shapes()) File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/data/experimental/ops/distribute.py", line 90, in recalculate_batch_size if len(output_shapes) &lt; 1: File "/home/kohulan/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py", line 822, in __len__ raise ValueError("Cannot take the length of shape with unknown rank.") ValueError: Cannot take the length of shape with unknown rank.
Any idea to come across this problem? Or even a different distributed training implementation for Image Captioning will be much helpful
		</comment>
		<comment id='15' author='dineshdharme' date='2020-02-20T18:46:04Z'>
		@Nixon59-lab, you're encountering a different issue (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34469&gt;#34469&lt;/denchmark-link&gt;
) that has since been fixed at head. You might want to try the tf nightly build. This will also be fixed in 2.2.
		</comment>
		<comment id='16' author='dineshdharme' date='2020-03-07T21:13:26Z'>
		&lt;denchmark-link:https://github.com/rachellim&gt;@rachellim&lt;/denchmark-link&gt;
 Yes, this works for me, :
def load_image(file, label):
    nifti = np.asarray(nibabel.load(file.numpy().decode('utf-8')).get_fdata()).astype(np.float32)

    xs, ys, zs = np.where(nifti != 0)
    nifti = nifti[min(xs):max(xs) + 1, min(ys):max(ys) + 1, min(zs):max(zs) + 1]
    nifti = nifti[0:100, 0:100, 0:100]
    nifti = np.reshape(nifti, (100, 100, 100, 1))
    return nifti, label


@tf.autograph.experimental.do_not_convert
def load_image_wrapper(file, label):
    result_tensors = tf.py_function(load_image, [file, label], [tf.float64, tf.float64])
    result_tensors[0].set_shape([100, 100, 100, 1])
    result_tensors[1].set_shape([None])
    return result_tensors


dataset = tf.data.Dataset.from_tensor_slices((train, labels))
dataset = dataset.map(load_image_wrapper, num_parallel_calls=24)
dataset = dataset.repeat(50)
dataset = dataset.batch(12, drop_remainder=True)
dataset = dataset.prefetch(buffer_size=6)
However, the performance is quite bad, comparable to the old Keras fit_generator(), which defeats the whole purpose of tf.data.
Does anyone know how to increase the performance of the dataset?
Can an iterator be used with Keras' model.fit()?
I've tried all of this:
dataset = tf.data.Dataset.from_tensor_slices((train, labels))
dataset = dataset.map(load_image_wrapper, num_parallel_calls=12)
dataset = dataset.repeat(50)
dataset = dataset.prefetch(buffer_size=2)
dataset = dataset.apply(tf.data.experimental.prefetch_to_device('/device:GPU:0', 1))
dataset = dataset.batch(12, drop_remainder=True)
		</comment>
		<comment id='17' author='dineshdharme' date='2020-03-08T14:44:57Z'>
		I have figured it out.
With keras, to improve performance:
def load_image(file, label):
    nifti = np.asarray(nibabel.load(file.numpy().decode('utf-8')).get_fdata()).astype(np.float32)

    xs, ys, zs = np.where(nifti != 0)
    nifti = nifti[min(xs):max(xs) + 1, min(ys):max(ys) + 1, min(zs):max(zs) + 1]
    nifti = nifti[0:100, 0:100, 0:100]
    nifti = np.reshape(nifti, (100, 100, 100, 1))
    return nifti, label


@tf.autograph.experimental.do_not_convert
def load_image_wrapper(file, label):
    return tf.py_function(load_image, [file, label], [tf.float64, tf.float64])


dataset = tf.data.Dataset.from_tensor_slices((train, labels))
dataset = dataset.map(load_image_wrapper, num_parallel_calls=32)
dataset = dataset.prefetch(buffer_size=1)
dataset = dataset.apply(tf.data.experimental.prefetch_to_device('/device:GPU:0', 1))
# Now my dataset size is 522, and for batch, I'm creating a single batch of the entire dataset.
dataset = dataset.batch(522, drop_remainder=True).repeat()

# Initialise iterator
iterator = iter(dataset)

# get x and y
batch_image, batch_label = iterator.get_next()

# Over here, supply model.fit with x &amp; y, and THEN supply your batch size here.
model.fit(batch_image, batch_label, epochs=100, batch_size=12)
Why does this work? Is this even the correct implementation?
		</comment>
		<comment id='18' author='dineshdharme' date='2020-03-10T04:16:54Z'>
		set_shape([]) for scalar tensors worked me too.
		</comment>
		<comment id='19' author='dineshdharme' date='2020-04-07T01:00:14Z'>
		
I encountered the same problem when using the from_tensor_slices in the tf.keras model.fit method. I use dataset.as_numpy_iterator() as a workaround.
Use like:
dataset = tf.data.Dataset.from_tensor_slices(....).map(...)
model.fit(dataset.as_numpy_iterator())

Instead of:
dataset = tf.data.Dataset.from_tensor_slices(....).map(...)
model.fit(dataset)


I tried this but now it is very slow. At first it took milliseconds for one step. It is now taking 17s per step. Any way around the speed?
		</comment>
		<comment id='20' author='dineshdharme' date='2020-04-07T17:49:22Z'>
		&lt;denchmark-link:https://github.com/eaaarmah&gt;@eaaarmah&lt;/denchmark-link&gt;
 - instead of using , use  in your map function to give your dataset a known shape (or at least, known rank). Please read all the comments above in this thread for examples.
		</comment>
		<comment id='21' author='dineshdharme' date='2020-04-07T17:55:37Z'>
		&lt;denchmark-link:https://github.com/dominthomas&gt;@dominthomas&lt;/denchmark-link&gt;
, two things:
(1) i would recommend using tf.data.experimental.AUTOTUNE as the parallelism setting on your map function, e.g.
dataset = dataset.map(map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)
This dynamically picks the optimal parallelism setting at runtime for best performance -- reducing the need to set the parallelism manually. Let me know how this works for you.
If you want to understand how to debug input pipeline performance, the TF team recently released the TF profiler with TF 2.2. It can help you understand which parts of the input pipeline are slow. We can chat about that in a separate thread - the team is also working on releasing a guide to debugging input pipeline performance using the TF profiler.
Tutorial: &lt;denchmark-link:https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&gt;https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&lt;/denchmark-link&gt;

Guide: &lt;denchmark-link:https://www.tensorflow.org/guide/profiler&gt;https://www.tensorflow.org/guide/profiler&lt;/denchmark-link&gt;

(2) The second code snippet you shared "works" (doesn't raise an error or require set_shape) because you're passing the outputs of the iterator directly to keras. The set_shape workaround is only necessary when you're passing the dataset directly to keras; it has to do with how keras handles dataset shapes.
		</comment>
		<comment id='22' author='dineshdharme' date='2020-04-17T22:20:52Z'>
		I have to agree with &lt;denchmark-link:https://github.com/dominthomas&gt;@dominthomas&lt;/denchmark-link&gt;
 here compared to using a Sequence with multiprocessing on all 24 cores, this is way, way way slower (20 hours versus 4 using multiprocessing for an epoch for me).  I get no parallelism using TF.dataset I assume b/c I am using a pyfunc, b/c I couldn't figure out how to put all my work into TF.  My Sequence functions involve using a pandas index file, and reading out from a binary numpy file based on the pandas index, maybe there is a way to do this in pure dataset notation, but right now the documentation is so opaque I can't figure it out.
		</comment>
		<comment id='23' author='dineshdharme' date='2020-04-24T02:25:17Z'>
		
I have figured it out.
With keras, to improve performance:
def load_image(file, label):
    nifti = np.asarray(nibabel.load(file.numpy().decode('utf-8')).get_fdata()).astype(np.float32)

    xs, ys, zs = np.where(nifti != 0)
    nifti = nifti[min(xs):max(xs) + 1, min(ys):max(ys) + 1, min(zs):max(zs) + 1]
    nifti = nifti[0:100, 0:100, 0:100]
    nifti = np.reshape(nifti, (100, 100, 100, 1))
    return nifti, label


@tf.autograph.experimental.do_not_convert
def load_image_wrapper(file, label):
    return tf.py_function(load_image, [file, label], [tf.float64, tf.float64])


dataset = tf.data.Dataset.from_tensor_slices((train, labels))
dataset = dataset.map(load_image_wrapper, num_parallel_calls=32)
dataset = dataset.prefetch(buffer_size=1)
dataset = dataset.apply(tf.data.experimental.prefetch_to_device('/device:GPU:0', 1))
# Now my dataset size is 522, and for batch, I'm creating a single batch of the entire dataset.
dataset = dataset.batch(522, drop_remainder=True).repeat()

# Initialise iterator
iterator = iter(dataset)

# get x and y
batch_image, batch_label = iterator.get_next()

# Over here, supply model.fit with x &amp; y, and THEN supply your batch size here.
model.fit(batch_image, batch_label, epochs=100, batch_size=12)
Why does this work? Is this even the correct implementation?

&lt;denchmark-link:https://github.com/dominthomas&gt;@dominthomas&lt;/denchmark-link&gt;
 have you had any success using cache with the working code that you have posted?
		</comment>
		<comment id='24' author='dineshdharme' date='2020-04-24T23:09:12Z'>
		&lt;denchmark-link:https://github.com/nickkimer&gt;@nickkimer&lt;/denchmark-link&gt;
 I've tried caching and it didn't enhance the performance, I suspect the bottleneck is in the load_image function, as there is a computation there to remove background, just for some context, these are MRI images; so it's removing  slices in all 3 dimensional planes that doesn't contain tissue.
I will test out the TF profiler &lt;denchmark-link:https://github.com/rachellim&gt;@rachellim&lt;/denchmark-link&gt;
 mentioned, which could prove my suspicion, but even then, with a 32 core cpu, this shouldn't be an issue.
&lt;denchmark-link:https://github.com/rachellim&gt;@rachellim&lt;/denchmark-link&gt;
 Thank you for the reply, however, when I use , performance is around 30% lower. Explicitly stating to use 32 cores works best in my scenario.
		</comment>
		<comment id='25' author='dineshdharme' date='2020-04-28T17:07:16Z'>
		&lt;denchmark-link:https://github.com/dominthomas&gt;@dominthomas&lt;/denchmark-link&gt;
  - thanks for the info. i'm interested in understanding why AUTOTUNE isn't performing well for you. can you start a separate github issue about the performance issues you're facing?
		</comment>
		<comment id='26' author='dineshdharme' date='2020-05-11T21:00:27Z'>
		Ok. I managed to get a solution working using only the Protobuf api available in tensorflow. This approach avoid serializing numpy data to bytes and passing the raw bytes to the TFRecord. This approach forces the use of a special py_function that cannot be serialized and moved on the graph when sending data to the TPU or in a distributed environment.
The code is available at &lt;denchmark-link:https://gist.github.com/vicpara/5c23c78d0f3105af53798272e628d2ad&gt;https://gist.github.com/vicpara/5c23c78d0f3105af53798272e628d2ad&lt;/denchmark-link&gt;
 .
As the map function that does the tensor manipulation of the feature dictionary produced by the TFRecordDataset is not required anymore, the above approach also avoids the additional set_shape operation outside the @py_function scope in an additional map operation.
Lastly, i feel i managed to get a decent solution that at least solves my problem to a satisfactory level. It's easy to add more features of different kinds after getting to understand how is TF using protobuf to serialize these features which is not the easiest thing ever. Having run into all these issues i would like to mention the following:


Just by looking at this issue alone one can find that the support given here is quite disconsiderate. This API goes 90% to do something and then just drops the ball. The errors are obscure, the documentation arcane and difficult to decipher and the proper examples almost lacking. Within a year and a half there has been little guidance that came from the TF devs to help address all these issues raised here.


(Tensorflow Dataset)[https://github.com/tensorflow/datasets] goes a long way to fix so many issues around the current API when it comes to making the serialization and deserialization experience smooth. They almost completely built their own mechanism barely using anything provided in this one. It does introduce an additional functionality around publishing a dataset to the cloud but they do fill in a lot of issues around the existing protobuf protocol.


Tensors as they currently stand contain all the information needed to get fully serialized/deserialized in the backend. You have there the shape, the types and the values. For the typical standard use it should be straight forward.
Why do put your API users to such pain of digging in multiple source repos to fix your half baked solutions ?


The dev support for tensorflow related issues is incredibly slow and mostly not helpful. It pretty much says that we have an error because we have an error and don't do that to not get the error.


The documentation lacks supporting examples, the examples are trivial and the error hide so much of the magic happening inside the graph.


What kind of community do you want around Tensorflow? Is Tensorflow just for the academics? You seem to cater mostly to the academics and presume all datasets are and should be floating freely in the cloud. Are the academics going to sell out your TPU time?
Your declared intentions in the promotional videos of TF relating to the industry adoption don't correspond to the level of support you show here nor to the maturity, documentation and completeness of the APIs.
If you feel the industry people should move to PyTorch  and forget about using TF with ease I'd appreciate to find out about this sooner rather than later.
		</comment>
		<comment id='27' author='dineshdharme' date='2020-05-11T22:19:29Z'>
		&lt;denchmark-link:https://github.com/dineshdharme&gt;@dineshdharme&lt;/denchmark-link&gt;
 Thanks for the issue!
Apologies for the delay, tf.keras's built-in training loops just went through a major rewrite in order to support custom training steps out-of-the-box. Many fixes were blocked on this rewrite.
This is now fixed at head, here's an example of passing Tensors of unknown rank to Model.fit:
import tensorflow as tf
import numpy as np

def my_numpy_fn(x, y):
  return -x, -y

features = np.arange(10).astype(np.float32)
labels = 2 * features
ds = tf.data.Dataset.from_tensor_slices((features, labels))
# Do a transformation that loses rank information.
ds = ds.map(
    lambda x, y: tf.numpy_function(
        my_numpy_fn, inp=[x, y], Tout=[tf.float32, tf.float32]
        )
    ).batch(2)

assert iter(ds).output_shapes[0] == tf.TensorShape(None)

# Model works with Tensors of unknown rank.
# Note that if your Model uses layers like `Dense`, etc. that
# only work with ceratin ranks, you should still use `x.set_shape`
# before passing the data to that layer, to give the Model a hint
# about the rank.
class MyModel(tf.keras.Model):
  def call(self, x):
    return 2 * x

model.compile('sgd', 'mse')
model.fit(ds)
For more info on the rewrite, please check out the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/releases/tag/v2.2.0&gt;2.2 release notes&lt;/denchmark-link&gt;

		</comment>
		<comment id='28' author='dineshdharme' date='2020-05-11T22:19:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24520&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24520&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='29' author='dineshdharme' date='2020-06-23T19:44:35Z'>
		I was getting this error with the multi-input, generator code below,
ValueError: Cannot take the length of shape with unknown rank.
upgrading to v2.2 resolved the issue thanks
&lt;denchmark-code&gt;def gen_obs():
    for i in itertools.count(1):
        action = env.action_space.sample()
        #print(action)
        obs, rew,dn,inf = env.step(action)
        print(obs, rew,dn,inf)
        #yield ([obs[0],obs[1],obs[2],obs[3], rew, dn], [10.0])
        yield {"reference_pa":[obs[0]], "perception_pa":[obs[1]]}, [10.0]
      

ds_counter = tf.data.Dataset.from_generator(gen_obs, output_types=({"reference_pa":tf.float32, "perception_pa":tf.float32}, tf.float32))

history = model.fit(ds_counter, epochs=20, verbose=True)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='30' author='dineshdharme' date='2020-07-13T11:02:49Z'>
		Same here, upgrade to TF2.2 solved the problem.
		</comment>
		<comment id='31' author='dineshdharme' date='2020-09-10T14:21:01Z'>
		I have same problem, here was my code:
def distort_simclr(image):
   image = tf.cast(image, tf.float32)
   v1 = color_distortion(image / 255.)
  v2 = color_distortion(image / 255.)
 return v1, v2
training_set = tf.data.Dataset.from_generator(path, output_types=(tf.float32, tf.float32), output_shapes = ([2,224,224,3],[2,2]))
training_set = training_set.map(distort_simclr, num_parallel_calls=tf.data.experimental.AUTOTUNE)
I find this error:
TypeError: tf__distort_simclr() takes 1 positional argument but 2 were given
		</comment>
		<comment id='32' author='dineshdharme' date='2020-09-10T16:20:43Z'>
		&lt;denchmark-link:https://github.com/aynesss&gt;@aynesss&lt;/denchmark-link&gt;
 , that's a different problem. Namely, your generator dataset has two components , but the function you supply to map only takes one argument. In this case, assuming your generator produces an (image, label) tuple, you probably want to rewrite your  function to take two arguments ().
See the documentation of &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map&gt;dataset.map&lt;/denchmark-link&gt;
 for more details ("The input signature of map_func is determined by the structure of each element in this dataset.")
		</comment>
	</comments>
</bug>