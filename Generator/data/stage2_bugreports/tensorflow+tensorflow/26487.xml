<bug id='26487' author='liupeng89' open_date='2019-03-08T14:40:17Z' closed_time='2019-08-02T21:55:32Z'>
	<summary>Using "for input_image in tf.data.Dataset: " TypeError: zip argument #1 must support iteration</summary>
	<description>
I try using the tf,data.Dataset to load my own images from local directory.
But when I want to feed batch_size data to model, I got a TypeError: zip argument &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1&gt;#1&lt;/denchmark-link&gt;
 must support iteration
Here is my code
&lt;denchmark-code&gt;Import tensorflow as tf
tf.enable_eager_execution()


import os
import time
import numpy as np
import matplotlib.pyplot as plt
import PIL
from IPython.display import clear_output

train_dataset = tf.data.Dataset.list_files(image_path + 'train_imgs/*png')
train_dataset = train_dataset.shuffle(200)
train_dataset = train_dataset.map(lambda x: load_image(x))
train_dataset = train_dataset.batch(16)

val_dataset = tf.data.Dataset.list_files(image_path + 'val_imgs/*.png')
val_dataset = val_dataset.shuffle(200)
val_dataset = val_dataset.map(lambda x: load_image(x))
val_dataset = val_dataset.batch(16)

test_dataset = tf.data.Dataset.list_files(image_path + 'test_imgs/*.png')
test_dataset = test_dataset.shuffle(200)
test_dataset = test_dataset.map(lambda x: load_image(x))
test_dataset = test_dataset.batch(16)

# train/test dataset batch shape: (16, 256, 256, 1)

class Downsample(tf.keras.Model):
    def __init__(self, filters, size, apply_batchnorm=True):
        super(Downsample, self).__init__()
        self.apply_batchnorm = apply_batchnorm
        
        initializer = tf.random_normal_initializer(0., 0.02)
        
        self.conv1 = tf.keras.layers.Conv2D(filters, 
                                            (size, size), 
                                            strides=2, 
                                            padding='same', 
                                            kernel_initializer=initializer)
        if self.apply_batchnorm:
            self.batchnorm = tf.keras.layers.BatchNormalization()
    
    def call(self, x, training):
        x = self.conv1(x)
        if self.apply_batchnorm:
            x = self.batchnorm(x, training=training)
        x = tf.nn.leaky_relu(x)
        return x

class Upsample(tf.keras.Model):
    def __init__(self, filters, size, apply_dropout=False):
        super(Upsample, self).__init__()
        self.apply_dropout = apply_dropout
        initializer = tf.random_normal_initializer(0., 0.02)
        
        self.up_conv = tf.keras.layers.Conv2DTranspose(filters,
                                                      (size, size),
                                                      strides=2,
                                                      padding='same',
                                                      kernel_initializer=initializer,
                                                      use_bias=False)
        self.batchnorm = tf.keras.layers.BatchNormalization()
        if self.apply_dropout:
            self.dropout = tf.keras.layers.Dropout(0.5)
    
    def call(self, x, training):
        x = self.up_conv(x)
        x = self.batchnorm(x, training=training)
        if self.apply_dropout:
            x = self.dropout(x, training=training)
        x = tf.nn.relu(x)
        return x

class Network(tf.keras.Model):
    def __init__(self):
        super(Network, self).__init__()
        initializer = tf.random_normal_initializer(0., 0.02)
        
        self.down1 = Downsample(64, 4, apply_batchnorm=False)
        self.down2 = Downsample(128, 4)
        self.down3 = Downsample(256, 4)
        self.down4 = Downsample(512, 4)
        self.down5 = Downsample(512, 4)
        self.down6 = Downsample(512, 4)
        self.down7 = Downsample(512, 4)
        self.down8 = Downsample(512, 4)
        
        self.up1 = Upsample(512, 4, apply_dropout=True)
        self.up2 = Upsample(512, 4, apply_dropout=True)
        self.up3 = Upsample(512, 4, apply_dropout=True)
        self.up4 = Upsample(512, 4)
        self.up5 = Upsample(256, 4)
        self.up6 = Upsample(128 ,4)
        self.up7 = Upsample(64, 4)
        
        self.last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS,
                                                   (4, 4),
                                                   strides=2,
                                                   padding='same',
                                                   kernel_initializer=initializer)
        
        @tf.contrib.eager.defun
        def call(self, x, training):
            # x shape == (bs, 256, 256, 3)    
            x1 = self.down1(x, training=training) # (bs, 128, 128, 64)
            x2 = self.down2(x1, training=training) # (bs, 64, 64, 128)
            x3 = self.down3(x2, training=training) # (bs, 32, 32, 256)
            x4 = self.down4(x3, training=training) # (bs, 16, 16, 512)
            x5 = self.down5(x4, training=training) # (bs, 8, 8, 512)
            x6 = self.down6(x5, training=training) # (bs, 4, 4, 512)
            x7 = self.down7(x6, training=training) # (bs, 2, 2, 512)
            x8 = self.down8(x7, training=training) # (bs, 1, 1, 512)

            x9 = self.up1(x8, x7, training=training) # (bs, 2, 2, 1024)
            x10 = self.up2(x9, x6, training=training) # (bs, 4, 4, 1024)
            x11 = self.up3(x10, x5, training=training) # (bs, 8, 8, 1024)
            x12 = self.up4(x11, x4, training=training) # (bs, 16, 16, 1024)
            x13 = self.up5(x12, x3, training=training) # (bs, 32, 32, 512)
            x14 = self.up6(x13, x2, training=training) # (bs, 64, 64, 256)
            x15 = self.up7(x14, x1, training=training) # (bs, 128, 128, 128)

            x16 = self.last(x15) # (bs, 256, 256, 3)
            x16 = tf.nn.tanh(x16)
            
            return x16

def train(dataset, epochs):
    for epoch in range(epochs):
        start = time.time()
        
        for input_image in dataset:
#             print(input_image.shape)
            with tf.GradientTape() as net_tape:
                output = net(input_image, training=True)
                loss = net_loss(input_image, output)
                
            net_gradients = net_tape.gradient(loss, net.variables)
            optimizer.apply_gradients(zip(net_gradients, net.variables))
        
        if epoch % 1 == 0:
            clear_output(wait=True)
            for inp, tar in test_dataset.take(1):
                generate_images(net, inp, tar)
        
        # saving checkpoint evey 20 epochs
        if (epoch + 1) % 20 == 0:
            checkpoint.save(file_prefix=checkpoint_prefix)
        
        print('Time taken for epoch {} is {} sec\n'.format(epoch+1, time.time()-start))

train(train_dataset, epochs)`

Now I got a Error:

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-36-d0e3ab41d250&gt; in &lt;module&gt;()
----&gt; 1 train(train_dataset, epochs)

&lt;ipython-input-35-58c1c7be4acb&gt; in train(dataset, epochs)
      6 #             print(input_image.shape)
      7             with tf.GradientTape() as net_tape:
----&gt; 8                 output = net(input_image, training=True)
      9                 loss = net_loss(input_image, output)
     10 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    701 
    702       if not in_deferred_mode:
--&gt; 703         outputs = self.call(inputs, *args, **kwargs)
    704         if outputs is None:
    705           raise ValueError('A layer\'s `call` method should return a Tensor '

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py in call(self, inputs, training, mask)
    718     outputs, _ = self._run_internal_graph(inputs,
    719                                           training=training,
--&gt; 720                                           mask=masks)
    721     return outputs
    722 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask)
    853     # does not return a list the same size as `call`
    854     tensor_map = {}
--&gt; 855     for x, y, mask in zip(self.inputs, inputs, masks):
    856       tensor_map[str(id(x))] = (y, mask)
    857 

TypeError: zip argument #1 must support iteration


input_image Tensor shape is (16, 256, 256, 1)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='liupeng89' date='2019-03-08T15:21:17Z'>
		Tensorflow : 1.9
		</comment>
		<comment id='2' author='liupeng89' date='2019-03-18T14:01:50Z'>
		As far as I can tell, the  part of your program is working correctly, and something is failing inside Keras. At a guess, some part of the internal code is expecting multiple inputs, but it's raising an error when it only receives one input. I'm not sure if that's a potential user error or a bug, so forwarding this to &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 for triage.
		</comment>
		<comment id='3' author='liupeng89' date='2019-07-16T20:52:35Z'>
		Can you clarify what version of TF you are using? If 1.9, please upgrade to a more recent version, and see if the issue still occurs. If you are interested in using eager execution, I would encourage you to use the &lt;denchmark-link:https://www.tensorflow.org/beta&gt;TensorFlow 2.0 Beta&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='liupeng89' date='2019-08-02T21:55:31Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='5' author='liupeng89' date='2019-08-02T21:55:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26487&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26487&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>