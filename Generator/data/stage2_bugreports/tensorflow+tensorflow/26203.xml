<bug id='26203' author='liuheng92' open_date='2019-02-28T11:59:58Z' closed_time='2019-03-29T09:02:08Z'>
	<summary>tf.graph_util.convert_variables_to_constants converts a different  pb parameters with orginal ckpt</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
The result using 'tf.graph_util.convert_variables_to_constants' api is different with 'freeze_graph.freeze_graph'
when i use 'freeze_graph.freeze_graph',  the result is same as ckpt， but different with the output when i use use 'tf.graph_util.convert_variables_to_constants' api. Why???
# using 'tf.graph_util.convert_variables_to_constants' api
    with tf.get_default_graph().as_default():
        input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name = 'input_images')
        

        input_images = readdata.mean_image_subtraction(input_images)

        with slim.arg_scope(resnet_v1.resnet_arg_scope(weight_decay=1e-5)):
            outputs, _ = resnet_v1.resnet_v1_50(input_images,  is_training=False, scope='resnet_v1_50', num_classes=FLAGS.num_classes)
            saver = tf.train.Saver()

            with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:
                tf.train.write_graph(sess.graph.as_graph_def(), '.', 'resnet50.pbtxt', as_text=False)
                saver.restore(sess, '../model.ckpt-5723')

                pb_file_path = 'model_5723.pb'
                constant_graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def,["resnet_v1_50/predictions/Softmax"])

                with tf.gfile.FastGFile(pb_file_path, mode='wb') as f:
                    f.write(constant_graph.SerializeToString())
#using 'freeze_graph' api
    with tf.get_default_graph().as_default():
        input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name = 'input_images')
        

        input_images = readdata.mean_image_subtraction(input_images)

        with slim.arg_scope(resnet_v1.resnet_arg_scope(weight_decay=1e-5)):
            outputs, _ = resnet_v1.resnet_v1_50(input_images,  is_training=False, scope='resnet_v1_50', num_classes=FLAGS.num_classes)

            saver = tf.train.Saver()

            with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:
                tf.train.write_graph(sess.graph.as_graph_def(), '.', 'resnet50.pbtxt', as_text=False)

                freeze_graph.freeze_graph('./resnet50.pbtxt', "", True, '../model.ckpt-5723', "resnet_v1_50/predictions/Softmax", "save/restore_all", "save/Const:0","model_freeze.pb", True, "")
                
Describe the expected behavior
using 'tf.graph_util.convert_variables_to_constants' api , the output parameters should be same as ckpt.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='liuheng92' date='2019-02-28T23:11:08Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 do you know anything about graph freezing functionality?
Unfortunately I think tf.graph_util.convert_variables_to_constants is deprecated, so I'm not sure if we have the bandwidth to address this.
		</comment>
		<comment id='2' author='liuheng92' date='2019-03-01T02:46:01Z'>
		
@petewarden do you know anything about graph freezing functionality?
Unfortunately I think tf.graph_util.convert_variables_to_constants is deprecated, so I'm not sure if we have the bandwidth to address this.

oh, I see. I found a warning in &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/graph_util/convert_variables_to_constants&gt;tensorflow api docs&lt;/denchmark-link&gt;
. But I am using old version(1.4.0), there is no api named "tf.compat.v1.graph_util.convert_variables_to_constants". So which api can I use for converting ckpt to pb？"freeze_graph.freeze_graph" api？
		</comment>
		<comment id='3' author='liuheng92' date='2019-03-01T22:34:44Z'>
		cc &lt;denchmark-link:https://github.com/gargn&gt;@gargn&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='liuheng92' date='2019-03-27T17:38:57Z'>
		freeze_graph.freeze_graph calls tf.graph_util.convert_variables_to_constants it is likely a problem with how you are loading your checkpoints with the Saver. I would suggest looking at how freeze_graph.freeze_graph restores the checkpoint files in order to see what is going wrong.
Loading pbtxt + checkpoints file can look something more like the following:
&lt;denchmark-code&gt;import os
import google3
import tensorflow as tf
from google.protobuf import text_format

def load_graph_in_session(pbtxt_file, checkpoint_file, sess):
  """Loads the graph into the provided session.

  Args:
    pbtxt_file: Text based graph.
    checkpoint_file: Checkpoints file.
    sess: tf.Session to load the graph into.
  """
  # Load pbtxt into GraphDef.
  graph_def = tf.GraphDef()
  with tf.gfile.FastGFile(pbtxt_file, 'r') as f:
    text_format.Merge(f.read(), graph_def)
  _ = tf.import_graph_def(graph_def, name='')

  # Restore variables from checkpoint file.
  var_list = {}
  reader = tf.train.NewCheckpointReader(checkpoint_file)
  var_to_shape_map = reader.get_variable_to_shape_map()

  for key in var_to_shape_map:
    try:
      tensor = sess.graph.get_tensor_by_name(key + ':0')
    except KeyError:
      # This tensor doesn't exist in the graph (for example it's
      # 'global_step' or a similar housekeeping element) so skip it.
      continue
    var_list[key] = tensor

  checkpoint_version = tf.train.SaverDef.V2
  saver = tf.train.Saver(var_list=var_list, write_version=checkpoint_version)
  saver.restore(sess, checkpoint_file)
&lt;/denchmark-code&gt;

If this doesn't work, can you provide the model files (pbtxt + checkpoint files that you are using), or the minimal model files required to reproduce your error as well as a minimal script to reproduce the error.
		</comment>
		<comment id='5' author='liuheng92' date='2019-03-28T12:13:05Z'>
		I can't reproduce this issue now. Maybe it's my mistake. sorry for bothering you.
		</comment>
		<comment id='6' author='liuheng92' date='2019-03-29T09:02:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26203&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26203&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>