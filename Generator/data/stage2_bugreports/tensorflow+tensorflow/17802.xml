<bug id='17802' author='darthdeus' open_date='2018-03-18T03:24:59Z' closed_time='2018-03-20T22:20:23Z'>
	<summary>Importing a meta graph which contains a SummaryWriter doesn't work</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 17.10
TensorFlow installed from (source or binary): binary via pip
TensorFlow version (use command below): v1.6.0-0-gd2e24b6039 1.6.0
Python version: 3.6.4
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 9.0/7.0
GPU model and memory: GTX 1080ti 11G
Exact command to reproduce:

First run this:
import tensorflow as tf
v1 = tf.placeholder(tf.float32, name="v1")
v2 = tf.placeholder(tf.float32, name="v2")
v3 = v1 * v2
vx = tf.Variable(10.0, name="vx")
v4 = v3 * vx
writer = tf.contrib.summary.create_file_writer("foo")
saver = tf.train.Saver([vx])
sess = tf.Session()
sess.run(tf.initialize_all_variables())
sess.run(vx.assign(tf.add(vx, vx)))
result = sess.run(v4, feed_dict={v1:12.0, v2:3.3})
print(result)
saver.save(sess, "./model_ex1")
Then in a different Python instance (it works if done right after the first snippet within the same instance)
import tensorflow as tf
saver = tf.train.import_meta_graph("./model_ex1.meta")
sess = tf.Session()
saver.restore(sess, "./model_ex1")
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Trying to restore the meta graph via import_meta_graph does not work if the graph contains a SummaryWriter as shown in the example above. The example works if import_meta_graph is called within the same instance of Python, or if the tf.contrib.summary.create_file_writer("foo") call is removed from the graph.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-1-1661c33bc0e5&gt; in &lt;module&gt;()
      1 import tensorflow as tf
----&gt; 2 saver = tf.train.import_meta_graph("./model_ex1.meta")
      3 sess = tf.Session()
      4 saver.restore(sess, "./model_ex1")

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1907                                       clear_devices=clear_devices,
   1908                                       import_scope=import_scope,
-&gt; 1909                                       **kwargs)
   1910   if meta_graph_def.HasField("saver_def"):
   1911     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    735     importer.import_graph_def(
    736         input_graph_def, name=(import_scope or ""), input_map=input_map,
--&gt; 737         producer_op_list=producer_op_list)
    738
    739     # Restores all the other collections.

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    430                 'in a future version' if date is None else ('after %s' % date),
    431                 instructions)
--&gt; 432       return func(*args, **kwargs)
    433     return tf_decorator.make_decorator(func, new_func, 'deprecated',
    434                                        _add_deprecated_arg_notice_to_docstring(

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    429   if producer_op_list is not None:
    430     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?
--&gt; 431     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    432
    433   graph = ops.get_default_graph()

~/.miniconda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    209     # Remove any default attr values that aren't in op_def.
    210     if node.op in producer_op_dict:
--&gt; 211       op_def = op_dict[node.op]
    212       producer_op_def = producer_op_dict[node.op]
    213       # We make a copy of node.attr to iterate through since we may modify

KeyError: 'SummaryWriter'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='darthdeus' date='2018-03-19T19:54:40Z'>
		Thanks for the report.
&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 : Do we need to recreate the resource ops on import from the  or something?
		</comment>
		<comment id='2' author='darthdeus' date='2018-03-19T19:59:19Z'>
		This looks like the metagraph is saved from a newer version of tf than it is loaded in. It's failing to find the SummaryWriter op's registration, which doesn't make sense to me.
&lt;denchmark-link:https://github.com/darthdeus&gt;@darthdeus&lt;/denchmark-link&gt;
 is this reproducible if you use tf-nightly?
		</comment>
		<comment id='3' author='darthdeus' date='2018-03-19T20:02:10Z'>
		Ah I just checked and I think I know what's going on. The python code for the generated ops is not getting imported unless you use tf.contrib.summary (because of lazy contrib imports) so we're not registering these summary ops on the separate process which loads the metagraph.
		</comment>
		<comment id='4' author='darthdeus' date='2018-03-19T20:22:34Z'>
		I'm submitting a fix, but a temporary workaround is to have a line like "tf.contrib.summary" somewhere on your program before you try to import the metagraph.
		</comment>
	</comments>
</bug>