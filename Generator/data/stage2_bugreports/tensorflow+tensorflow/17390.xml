<bug id='17390' author='up-to-you' open_date='2018-03-02T23:10:36Z' closed_time='2018-09-16T20:56:37Z'>
	<summary>Full-fledged Java api roadmap?</summary>
	<description>
Are there any estimated plans for Java api development in terms of functionality ? The only absolute choice for Java language nowadays is Deeplearning4j, any plans to occupy a niche for Java language?
By the term "full-fledged" I mean: constructing a graph from scratch (including most common math function/operations, respectively), train CNN, test CNN, recognize the result, all of this using Java language only.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/14094&gt;#14094&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 is still in work and latter frozen for a few days. Just want to know your vision of future.
P.s. need to choose right framework for starting a project at the end of June.
	</description>
	<comments>
		<comment id='1' author='up-to-you' date='2018-03-03T00:37:06Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 Can you comment on this?
		</comment>
		<comment id='2' author='up-to-you' date='2018-03-05T11:29:14Z'>
		any news ?
		</comment>
		<comment id='3' author='up-to-you' date='2018-03-08T20:07:09Z'>
		If we parse the protocol buffer byte array from TensorFlow.opList(), will this give us a full readout of the functions we can pass to Graph.opBuilder? My thought is just to get a list of all available functions with inputs and outputs from opList, then use these to parse valid/invalid values when try to build a graph. Based on how a pre-trained graph is loaded using this Java api, it seems like this approach should work for building a graph from scratch.
I am in the same boat as you &lt;denchmark-link:https://github.com/up-to-you&gt;@up-to-you&lt;/denchmark-link&gt;
, and after looking through DL4J I think my preference is to stick with Tensorflow.
		</comment>
		<comment id='4' author='up-to-you' date='2018-03-08T22:10:54Z'>
		&lt;denchmark-link:https://github.com/Nicholas-Schaub&gt;@Nicholas-Schaub&lt;/denchmark-link&gt;
, thanks a lot, i will test this approach. Nice to have fellow in misfortune :) I hope the guys from Tensorflow will not let our boat drown in the pythonish quagmire :(
UPDATE
TensorFlow.registeredOpList() eventually delivers some operations description, but this is a painfull pain of it's translation to opBuilder , first of all, taking into account Java API is not covered by the TensorFlow API stability guarantees.
I do not have the goal of pushing this problem to Tensorflow developers, i just need information - will their automation tool for Java ops generation be ready soon or not ?
		</comment>
		<comment id='5' author='up-to-you' date='2018-03-08T22:51:08Z'>
		I misspoke. TensorFlow.registeredOpList() is the method I meant to say. I have already parsed the byte array out, and from every check I've made, it matches the Python implementation. I'm just going to make a function that builds a graph like it does in Python and checks the input values for each function against the values given from registeredOpList.
		</comment>
		<comment id='6' author='up-to-you' date='2018-03-09T05:04:04Z'>
		&lt;denchmark-link:https://github.com/up-to-you&gt;@up-to-you&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/Nicholas-Schaub&gt;@Nicholas-Schaub&lt;/denchmark-link&gt;
 : Thanks for your interest. We haven't published a roadmap yet. So far we've been mostly interested in being able to "deploy" models typically architected in Python (often trained, but at least designed) into other languages such as Java.
The next step for the Java API is creating the op functions (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 is being worked on - thanks &lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/kbsriram&gt;@kbsriram&lt;/denchmark-link&gt;
 ). However, we have not yet hashed out a timeline for building higher level APIs on top of that. That said, this is something that can be built on top of the lower level APIs that we do have, so if anyone wants to take a stab at it ... 
To be perfectly honest, it is unlikely that we'll have a significant change in the state of the Java API by June, but hopefully we'll have more of a plan to share by then (CC &lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 )
		</comment>
		<comment id='7' author='up-to-you' date='2018-03-09T10:42:54Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 thanks for your information ! if I understand correctly - &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 will let us construct graph from scratch using Java ? If so, is there any barrier for constructing multilayered CNN ?
Thanks in advance.
		</comment>
		<comment id='8' author='up-to-you' date='2018-03-09T13:29:09Z'>
		&lt;denchmark-link:https://github.com/up-to-you&gt;@up-to-you&lt;/denchmark-link&gt;
, there are a few more pull requests upcoming after &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 to be able to construct a multilayered CNN from scratch in Java using a rich API.
But like &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 said, even with that, there will still be some additional work to do to reach the maturity of the Python API as it contains more logic than what is exposed by the core library, shared by all the clients. For example, gradient backpropagation will still be more easier in Python than in Java (while still feasible). It would be nice if somebody could take a look at this part!
		</comment>
		<comment id='9' author='up-to-you' date='2018-03-10T19:30:00Z'>
		Well...I'm glad I stumbled upon this. I thought that the logic for backpropagation would be in the core library, and the main hurtle was creating functions to use the core library. Looks like I'm building and training in Python and importing into Java.
		</comment>
		<comment id='10' author='up-to-you' date='2018-03-10T20:06:15Z'>
		&lt;denchmark-link:https://github.com/Nicholas-Schaub&gt;@Nicholas-Schaub&lt;/denchmark-link&gt;
 : For now, yeah, building and training in Python and exporting to Java for inference is probably best.
Though, see the &lt;denchmark-link:https://github.com/tensorflow/models/tree/master/samples/languages/java&gt;Java samples&lt;/denchmark-link&gt;
, in particular the linked slides with speaker notes, and the one trivial example of building the model in Python but actually training in Java.
		</comment>
		<comment id='11' author='up-to-you' date='2018-03-10T22:25:20Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 regarding the information you provided (thanks a lot !), i think its better to emphasize efforts on model training maturity, using Java API. In this case we have advantages of both worlds :

declaring model using full-fledged, short, readable Python syntax
training NN and inference with Java, using its performance, multithreading, big-data collaboration etc.

&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 can you please provide video / source link, from where does this slides come ?
		</comment>
		<comment id='12' author='up-to-you' date='2018-03-11T00:37:11Z'>
		The slides are linked to in the README I pointed to, but &lt;denchmark-link:https://docs.google.com/presentation/d/e/2PACX-1vQ6DzxNTBrJo7K5P8t5_rBRGnyJoPUPBVOJR4ooHCwi4TlBFnIriFmI719rDNpcQzojqsV58aUqmBBx/pub?start=false&amp;loop=false&amp;delayms=3000&gt;here they are anyway&lt;/denchmark-link&gt;

They were from a talk I gave in a Java Users Group meeting. I don't think there is a video link.
		</comment>
		<comment id='13' author='up-to-you' date='2018-03-11T03:52:12Z'>
		Just to add something about this: other than the ubiquitous differences between the two languages, what is really interesting about having a Java graph building API compared to Python is the way it enforces tensor type checking at compile time (by using generics). So you know exactly what datatype you are dealing with at the output of an operation and what you can possibly do with it. So I think current efforts are not done in vain... or at least I hope ;)
Implementing the core ops in Java is a big step forward for having a mature client library and yes &lt;denchmark-link:https://github.com/Nicholas-Schaub&gt;@Nicholas-Schaub&lt;/denchmark-link&gt;
, it will be possible to do backpropagation using the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/training_ops.cc&gt;training ops&lt;/denchmark-link&gt;
, for example. But it will not be as easy as in Python until we figure out how to extract and expose the logic implemented in its client library, like its &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/gradient_descent.py&gt;gradient descent optimizer&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='14' author='up-to-you' date='2018-03-11T23:20:07Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 If the issue is just figuring out how to expose the logic, isn't it just a matter of parsing the `registeredOpList' to get a list of functions and their inputs/outputs and writing a rudimentary translator to make sure that the appropriate inputs and outputs are being sent/received? The way it was discussed above, I thought that we would have to implement the gradient descent optimizer. My approach was just to parse the op list and write a generic graph building class that shows which operations are available and what inputs/attributes are needed. If the gradient descent functions are implemented in the core library, then it seems like it's just a matter of then building a simple class to cycle through layers for backpropagation. The hardest part for me seemed like it was going to be parsing the operations list, and then I could build a couple simple classes to build and train.
		</comment>
		<comment id='15' author='up-to-you' date='2018-03-11T23:37:55Z'>
		My thought in implementing this wouldn't be something quite as nice as what Python currently has, but it would be enough to build a graph and train it. During the graph building phase, the individual elements would be added to a JSON string, and then the graph could be built based off the JSON string and checked for errors using the info we get from parsing the op list.
		</comment>
		<comment id='16' author='up-to-you' date='2018-03-12T03:22:36Z'>
		&lt;denchmark-link:https://github.com/Nicholas-Schaub&gt;@Nicholas-Schaub&lt;/denchmark-link&gt;


isn't it just a matter of parsing the registeredOpList...

It is a bit more tricky than that. The  does not provides all the required information to classify the ops properly (for instance, their "group"). This is why it has been decided to import them from a C++ process instead, that links to the individual libraries and generates Java classes for their ops at compile-time. PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 and those upcoming are about this.
Just if you are curious, you might find a snapshot of the ops I have generated (and never tested) a long time ago from a intermediate version of this generator &lt;denchmark-link:https://github.com/karllessard/tensorflow/tree/java-ops-samples/tensorflow/java/src/main/java/org/tensorflow/op&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='17' author='up-to-you' date='2018-03-12T20:13:45Z'>
		Does the grouping matter? I thought having the necessary information to build a function using Graph.opBuilder would have been enough. It seems like this is how the current state of the java side of things imports pretrained networks. Is there ambiguity in function handles between the different groupings? Why isn't having the names of all functions with corresponding inputs and attributes sufficient to use the opBuilder?
I apologize for drawing out the conversation, but it's been incredibly helpful thus far. Thank you for the link.
		</comment>
		<comment id='18' author='up-to-you' date='2018-03-13T13:05:55Z'>
		
Does the grouping matter?

Grouping doesn't matter at the functional level but it does matter at the API level. By this I mean that if you want to list and create classes just parsing the registeredOpList, it will work but you'll endup with a single package (group) of 600 classes or so, which would not be usable/acceptable as an official API for Tensorflow (just think how the auto-complete feature of popular IDEs will react on this). But for personal use, yes that'll do.

I apologize for drawing out the conversation, but it's been incredibly helpful thus far.

No problem it's a real pleasure, we can continue that discussion on a more private channel if you are interested, by joining &lt;denchmark-link:https://groups.google.com/forum/#!forum/tensorflow-java-dev-unofficial&gt;this group&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='19' author='up-to-you' date='2018-03-17T23:22:17Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 can you please shed some light on other pull requests planned after &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 which will allow to construct multilayered CNN ? I'm gonna make some performance benchmarks in comparison to python impl's, since training elapsed time depends not only on C++/CUDA implementation, but on fetching and treatment of data too (before feeding it to CNN). And I make big bets, that in this part of whole process, Java will surpass Pythonish approach.
P.s. it will be more clearly for results if whole NN lifecycle will be build using Java. Just for some reflection on an abstract level &lt;denchmark-link:https://benchmarksgame.alioth.debian.org/u64q/python.html&gt;Python vs Java benchmarks&lt;/denchmark-link&gt;

		</comment>
		<comment id='20' author='up-to-you' date='2018-03-18T04:16:29Z'>
		&lt;denchmark-link:https://github.com/up-to-you&gt;@up-to-you&lt;/denchmark-link&gt;
 : FYI: if you use the &lt;denchmark-link:https://www.tensorflow.org/programmers_guide/datasets&gt;tf.data APIs&lt;/denchmark-link&gt;
 to feed data to your model, then all the data is read, processed, and fed by the TensorFlow runtime, so the frontend language is unlikely to be a bottleneck. Long story short,  it will generally be possible to get the same performance irrespective of frontend language.
		</comment>
		<comment id='21' author='up-to-you' date='2018-03-18T22:18:27Z'>
		&lt;denchmark-link:https://github.com/up-to-you&gt;@up-to-you&lt;/denchmark-link&gt;
 : very interesting, indeed. Asim brought an interesting point with the  APIs but it would still be very nice to benchmark the performances of the Java client independently on this.
Timewise, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/16120&gt;#16120&lt;/denchmark-link&gt;
 has been accepted and is just waiting to be merged. After this, the target is that I come up with another PR by the end of the month which will actually generates the Op classes in the  jar.
From there, you'll be able to build a graph in Java using those classes. More PR(s) will still come after to wrap those classes with a builder-like API but functionally, they should be ready to be used directly.
		</comment>
		<comment id='22' author='up-to-you' date='2018-03-21T15:53:45Z'>
		BTW, it's already possible to use the full C and C++ APIs with the &lt;denchmark-link:https://github.com/bytedeco/javacpp-presets/tree/master/tensorflow&gt;JavaCPP Presets for TensorFlow&lt;/denchmark-link&gt;
, and we can pretty much do anything we want with that including building graphs and accessing the ops, for example:
&lt;denchmark-link:https://tebesu.github.io/posts/Training-a-TensorFlow-graph-in-C++-API&gt;https://tebesu.github.io/posts/Training-a-TensorFlow-graph-in-C++-API&lt;/denchmark-link&gt;

&lt;denchmark-link:https://matrices.io/training-a-deep-neural-network-using-only-tensorflow-c/&gt;https://matrices.io/training-a-deep-neural-network-using-only-tensorflow-c/&lt;/denchmark-link&gt;

If there is anything missing from the bindings though, it should be a simple matter to add, so please do let me know! I'm very interested in making C++ libraries usable from Java and in understanding what is lacking, the difficulties, etc. So any feedback is welcome! Thanks
		</comment>
		<comment id='23' author='up-to-you' date='2018-03-21T20:18:58Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
, First of all, its awesome, really!
But, as &lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
  mentioned - there are a lot of logic, implemented at python level. For example i can't find api, that allows to write something like this:
l1 = tf.layers.dense(x, L1, activation = tf.nn.relu, use_bias = True )
l2 = tf.layers.dense(l1, L2, activation = tf.nn.relu , use_bias = True )
...
and, honestly, unfortunately, i don't know how to implement same logic, using existing Java api in Tensorflow project, nor in your bindings.
		</comment>
		<comment id='24' author='up-to-you' date='2018-03-21T22:56:23Z'>
		Thanks! Yes, I am aware a lot is implemented only in Python, but at some
point it needs to be implemented in either C++ or in Java. Imagine it gets
implemented in a user-friendly API in C++, what would make you not use
JavaCPP? What would still be missing? That's the kind of feedback I'm
looking for. :)
		</comment>
		<comment id='25' author='up-to-you' date='2018-03-23T17:38:39Z'>
		I'm glad I've held off working on making up my own solution to this problem since it sounds like things are starting to come down the pipe.
&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 What would make me not use JavaCPP is that I need to do things in native Java. If it's included in a dll that's fine, otherwise it's a headache.
		</comment>
		<comment id='26' author='up-to-you' date='2018-06-06T13:10:00Z'>
		Hi guys, please let me reiterate my thoughts on this.
I think JavaCPP can be a useful addition to the current Java client but I would keep its usage internal. It perfectly fits as a replacement to the actual JNI bridge, being more flexible and probably more performant. But I would stick to a thin layer of pure-Java for classes that are exposed publicly, so we can easily introduce Java-specific features, like generics, and have more control over the API in general.
That being said, I don't want to sound dramatic but I think that open-source development is all about collaboration and not competition. Competition is a complete no-fit. Our goal is to develop the best Java client for TensorFlow, no matter how, and we should merge all of our efforts towards this end only. &lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
, if you can't agree with this, then I don't think I can help you much here. BTW, you say that you get no reply from me but I can't recall or find any question or request from you.
		</comment>
		<comment id='27' author='up-to-you' date='2018-06-07T03:00:25Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 Don't worry, I agree. I asked about how we could build a graph for training, but I did not get a reply, so I simply assumed it wasn't possible. If this is not the case, please say so! I'm merely trying to make it clear what is possible and what isn't, what needs to get done, etc. I am always trying to find ways to communicate in a more friendly way, but I admit it is not easy for me, as I simply get ignored if I don't "push" a little.
		</comment>
		<comment id='28' author='up-to-you' date='2018-06-07T09:24:24Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 : Regarding adding symbolic gradients in the Java API, we'd have to add a Java function corresponding to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/65c05bc2ac19f51f7027e66350bc71652662125c/tensorflow/c/c_api.h#L1127&gt;TF_AddGradients&lt;/denchmark-link&gt;
. So, you're right it doesn't exist yet, but should be easy to add as a method on .
		</comment>
		<comment id='29' author='up-to-you' date='2018-06-07T13:05:22Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 : actually writing down an Mnist example in Java, I already ended up with the need to implement the JNI binding for  in . Another PR ready to get in line for you ;)
&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 : Glad to hear that! Then, I think we can start to discuss on how you could help contributing. I really think we need another communication channel than this thread to synchronize everybody's efforts. I suggest we use this &lt;denchmark-link:https://groups.google.com/forum/#!forum/tensorflow-java-dev-unofficial&gt;unofficial group&lt;/denchmark-link&gt;
 for now until Google can setup something for us (and I invite everybody in this thread to join it). And maybe we can have a separate branch to consolidate our work, ideally in TF repo? &lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 , can you help us with all of this?
Thanks
		</comment>
		<comment id='30' author='up-to-you' date='2018-06-08T05:39:31Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 Well, it's not just about me contributing, it's also about changing  frame of mind. You keep writing everything in C++ and JNI manually, why? You have to understand this doesn't look attractive to Java developers. Could we start by making a list of what's missing from JavaCPP? Is it just the Bazel build for now or is there something else that I should look at first?
&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 I've applied to join your group. Thanks! As for a branch, if you keep your fork up to date, I think we can just all use that for now as well.
		</comment>
		<comment id='31' author='up-to-you' date='2018-06-08T13:13:43Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 : At a high level, I feel that the  should be on creating the right API to  TensorFlow from Java. The details of how that API is  (JavaCPP, manual JNI, C++ or Java code generator etc.) is secondary, and changeable. The "right" API is characterized by appropriate abstractions that are easy to understand for a Java developer, a thoughtful exposure of features, and performance.
If we agree on that (that the experience of the API user is paramount) then we can have a productive conversation on the implementation details. I don't believe we should be working the other way around (i.e., being driven by what's easy to implement).
With regards to what's missing in JavaCPP - I don't have a list handy, and maybe nothing is missing. Honestly, I haven't devoted enough time to thinking through the details of what switching to JavaCPP would entail. Which is where contributions can help. Since you're passionate about this, perhaps you could do that? Some things to think about in a concrete proposal would be:


What does the end-user Java API look like? Would it make sense to implement the current Java API (with generics etc.) using JavaCPP for the native-call redirection, or would it make sense to define a smaller C++ class and generate its interface? For example, compare the Tensor class in current Java API vs. JavaCPP wrapped over the C++ Tensor class. Along the same lines, since so far the primary interest in the Java API has been in deploying trained models in an application - the APIs for that should be succinct and easy to comprehend (examples).


How would we scope the effort required and benefits of it? For example, assuming we stick with the existing org.tensorflow.Tensor API, what does it take to back it with JavaCPP? Can we quantify the benefits (e.g., improved performance in some cases, like perhaps creating large tensors on Android or something)? Or if the proposal is to have a different API for the Java user, how do we evaluate? For example, can we evaluate the change in APIs by writing examples including "load a model and serve for inference" and "fine tune a previously trained model" and "construct a trained model".


Once this is scoped out, who is going to drive the changes?


Is it possible to break this down into small sets of changes/projects? For example, the code generator that Karl is working on could just as well be done in Java (no JNI) and doing that may be a reasonable project (Karl has ideas on switching to that, but wanted to get his C++ version in first just because he has that almost working and again, most users of the API won't care whether the Java code was generated one way or another).


I'm not at all suggesting that I'm convinced that JavaCPP isn't the appropriate choice here. However, I haven't had the opportunity to think through all these details, and probably won't have much time to devote to that in the near future. So if someone wants to think this through and write it up and come up with concrete proposals (that can be &lt;denchmark-link:https://github.com/tensorflow/community&gt;shared as an RFC&lt;/denchmark-link&gt;
 (&lt;denchmark-link:https://groups.google.com/a/tensorflow.org/d/msg/developers/6Irde5yjUBc/SRool5ghAgAJ&gt;example&lt;/denchmark-link&gt;
)), we're open to that. Perhaps there is some precedence here? For example, I noticed that there are &lt;denchmark-link:https://github.com/bytedeco/javacpp-presets/tree/master/mxnet&gt;JavaCPP presets of MXNet&lt;/denchmark-link&gt;
 as well, while MXNet also has &lt;denchmark-link:https://github.com/apache/incubator-mxnet/tree/master/scala-package/core/src/main/scala/org/apache/mxnet&gt;handwritten scala bindings&lt;/denchmark-link&gt;
 instead of generating them from the C++ (though admittedly I know nothing about Scala or the implementation/design choices in MXNet). Perhaps you've been through similar thinking there as well?
Long story short, I'd say that the barrier to "use JavaCPP" isn't anyone's "mindset", it's simply a person putting the effort to dig into the details of what that means. Or perhaps I'm misunderstanding you and there is a concrete proposal you're suggesting?
		</comment>
		<comment id='32' author='up-to-you' date='2018-06-09T08:52:36Z'>
		My point isn't about what the end user API should look like, it's about how to get there. There is no need to change what's already been done for the API at all. But you've spend over 2 years hacking in C++ and forcing contributors like &lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 to contribute in C++. Why not let them contribute to the effort by doing it in Java? We can use the C/C++ API of TensorFlow or of anything else like MXNet for that matter, from Java. Why does no one (other than Skymind) does it that way? I don't know, why should I know? I spend a lot of time arguing about that, but never got a satisfying answer. If no one does something, does it automatically make it wrong?
TensorFlow could have a  policy to do as much as possible in C++, sure, I guess, but you should make that clear if that's the case. Is it the case?
		</comment>
		<comment id='33' author='up-to-you' date='2018-06-11T01:11:32Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 Maybe what we need is a separate repo like &lt;denchmark-link:https://github.com/tensorflow/swift&gt;https://github.com/tensorflow/swift&lt;/denchmark-link&gt;
 where contributors wouldn't be limited to contrived hybrid C++/Java solutions? Such a project would essentially become a consumer of the core of TensorFlow and evolve from there...
		</comment>
		<comment id='34' author='up-to-you' date='2018-06-11T01:34:56Z'>
		&lt;denchmark-link:https://github.com/saudet&gt;@saudet&lt;/denchmark-link&gt;
 that's similar to what I have mentioned earlier and it seems there is no plan for such integration yet. But even if they are willing to do such project I don't want this to hurt what is being done right now. It is already 2018 and we still do not have a proper implementation of TF for Java/Kotlin. This waiting is at the excruciating level (even c# has a TF implementation now). I personally don't want this to delay for more fancy features, they can be hopefully developed later on.
		</comment>
		<comment id='35' author='up-to-you' date='2018-06-11T14:15:05Z'>
		&lt;denchmark-link:https://github.com/arnaghizadeh&gt;@arnaghizadeh&lt;/denchmark-link&gt;
 : I agree with you here. Just FYI, I think the major reason why it is taking so long is that a lot of time is spent in code reviews before features can get merged into the master branch. I am not blaming Asim for that, I think he's doing a fantastic job to keep the code neat and under control. But having a separate branch to experiment some features on our side before creating a PR in TensorFlow might help to develop things more dynamically and to get that full-fledged Java client out faster.
If TensorFlow is not able to provide us that branch, maybe we should simply start our own and start to do some cherry-picking after.
		</comment>
		<comment id='36' author='up-to-you' date='2018-06-22T22:23:34Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 I am not sure if the current setup will let us do that in the Tensorflow repo, though I do think it's a good idea for velocity. &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 is it possible to give a sub-team a branch, or is a cloned repo a better idea?
		</comment>
		<comment id='37' author='up-to-you' date='2018-06-25T17:01:02Z'>
		Branches are complicated. I would create a fork, keep its master branch synched with tensorflow/tensorflow, and work on a branch off of that. Then, make occasional PRs from there to tensorflow/tensorflow master. Do you think that would work?
		</comment>
		<comment id='38' author='up-to-you' date='2018-06-26T22:24:26Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
  I think that would work, yes, how the commits into that fork would be moderated?
Right now, I'm doing all my PR from my personal repo, which is very convenient, but the fork would really help if other developers manifest a serious interest in contributing for the Java client also (which seems to be the case reading those previous comments).
		</comment>
		<comment id='39' author='up-to-you' date='2018-06-27T00:03:58Z'>
		Oh, my suggestion was that you review the commits on your fork (or, you can also give others write access to let others review).
If there are more than a couple of regular contributors, we can also set up a special interest group for you, and talk about moving the repo to the tensorflow org. The process would be mainly the same though: you review contributions and you can move at high speed, and you make larger, but less frequent PRs back to TF. &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 what do you think?
We could also talk about moving the Java bindings out of the TensorFlow repo altogether. We'd have to figure out how to package that, but that would remove the need to sync back to TF altogether, which could be quite attractive.
&lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 FYI
		</comment>
		<comment id='40' author='up-to-you' date='2018-06-27T01:53:38Z'>
		
Oh, my suggestion was that you review the commits on your fork (or, you can also give others write access to let others review).

On my end, I agree with that plan, let's do this for now and see if some other serious contributors would like to do it differently, I'll send a link to that new branch soon, thanks!
		</comment>
		<comment id='41' author='up-to-you' date='2018-06-27T18:38:51Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 yep, we're already having SIG conversations.... will post an update on that soon.
		</comment>
		<comment id='42' author='up-to-you' date='2018-08-31T07:55:26Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
: It has been 64 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='43' author='up-to-you' date='2018-09-15T18:35:19Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
: It has been 79 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='44' author='up-to-you' date='2018-09-16T20:56:37Z'>
		This conversation seems to have run its course. Closing this issue since I don't know of any plans on the docs side to publish a separate Java roadmap (here's the &lt;denchmark-link:https://www.tensorflow.org/community/roadmap&gt;general TF roadmap&lt;/denchmark-link&gt;
 that was recently updated).
Sounds like the mailing lists/SIGs are the best way to keep up with new developments.
		</comment>
		<comment id='45' author='up-to-you' date='2018-09-16T21:07:02Z'>
		there is no mention of the Java API in the road-map though, it seems that Java is going to be ignored for TF 2.0?
		</comment>
		<comment id='46' author='up-to-you' date='2018-09-16T21:25:03Z'>
		TF 2.0 is certainly focused on Python, as you'll see in the design reviews at &lt;denchmark-link:https://github.com/tensorflow/community/pulls&gt;https://github.com/tensorflow/community/pulls&lt;/denchmark-link&gt;

The Java APIs will continue to be mainly focused on loading and serving models (to integrate into existing applications) and the low level API for building graphs.  Higher level APIs to build models aren't something that are on the roadmap of the TensorFlow maintainers.
For that we'd encourage community driven efforts. As mentioned above, perhaps a SIG (if there is enough interest in design and development) or just great projects like JavaCPP presets mentioned above.
		</comment>
		<comment id='47' author='up-to-you' date='2018-09-18T03:11:01Z'>
		FYI, since TF 1.10, operations wrappers have been added to build and train graphs in Java (please note that it is still at an experimental stage).
A minimalist example of their usage can be found &lt;denchmark-link:https://github.com/karllessard/models/tree/java-examples/samples/languages/java/mnist&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='48' author='up-to-you' date='2018-09-18T03:24:29Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 - the dl4j team is committed to supporting the javacpp stack. We have the high level keras api already built (maintained by &lt;denchmark-link:https://github.com/maxpumperla&gt;@maxpumperla&lt;/denchmark-link&gt;
 ) - we are also seeing people building demos not even a few weeks after its release: &lt;denchmark-link:https://github.com/tzolov/mtcnn-java&gt;https://github.com/tzolov/mtcnn-java&lt;/denchmark-link&gt;
 - we also have an equivalent api that could easily compliment tf.data.  Rather than a bunch of 1 off repos, why don't we focus on this upcoming TF 2.0 and being able to do a proper java SIG where we can address this?
		</comment>
		<comment id='49' author='up-to-you' date='2018-09-18T04:05:03Z'>
		It seems that closing this issue just ignited it ;)
&lt;denchmark-link:https://github.com/agibsonccc&gt;@agibsonccc&lt;/denchmark-link&gt;
 , personally I'm all for having a SIG where all those matters could be discussed and efforts could be merged, a big  for this. I'm not sure though where all this is going since the current topic is about the current state of the TF Java client but discussions always tend to be dragged in the directions of other projects. When you talk about focusing on TF2.0, you mean in Tensorflow or in DL4J?
		</comment>
		<comment id='50' author='up-to-you' date='2018-09-18T04:34:38Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 We're still interested in doing this as part of dl4j or TF we don't care.  It really depends on what the TF team is interested in doing with 2.0. The team had expressed interest in merging efforts somehow. We'd prefer not to be rewriting things your team is already doing. We're interested in providing a graph runner regardless since we have to interop with every stack anyways. We're going to be doing something similar with onnx as well.
		</comment>
		<comment id='51' author='up-to-you' date='2018-09-25T03:20:40Z'>
		&lt;denchmark-link:https://github.com/karllessard&gt;@karllessard&lt;/denchmark-link&gt;
 Great work, thanks for the contribution! The JavaCPP Presets for TensorFlow now include your Java ops wrappers, with builds on Maven for Android, Linux, Mac, and Windows, compiled against and bundled with MKL-DNN, CUDA, and cuDNN (that is, no need to install them, all binaries get pulled from Maven), along with a more complex JNI loader than the default one in TensorFlow that works well with multiple class loaders and Windows applications including JavaFX ones:
&lt;denchmark-link:https://github.com/bytedeco/javacpp-presets/tree/master/tensorflow&gt;https://github.com/bytedeco/javacpp-presets/tree/master/tensorflow&lt;/denchmark-link&gt;

They seem to work fine, but let me know if you find any issues or would like to change something. With a bit more work, I'm sure we could get all this to interoperate with the rest of the C/C++ APIs that come with the presets. That would be nice, given that at that level, JavaCPP can share memory with zero-copy and manage with scopes the resources used by multiple APIs, not only from TensorFlow but from other native libraries as well, such as OpenCV, FFmpeg, or Tesseract:
&lt;denchmark-link:http://bytedeco.org/news/2018/07/17/bytedeco-as-distribution/&gt;http://bytedeco.org/news/2018/07/17/bytedeco-as-distribution/&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>