<bug id='29099' author='danaugrs' open_date='2019-05-28T23:17:25Z' closed_time='2019-09-06T21:43:37Z'>
	<summary>Drastically different behavior between TF1 and TF2</summary>
	<description>
I've noticed drastically different behavior of the following code between 2.0.0-alpha0 and 1.13.1.
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = mnist.load_data()
x_train = x_train_raw.reshape(60000, 784)
x_test = x_test_raw.reshape(10000, 784)
y_train = to_categorical(y_train_raw)
y_test = to_categorical(y_test_raw)

basic_net = Sequential([
    Dense(36, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
])

W_bio = np.load('W_bio.npy')

basic_net.layers[0].set_weights([W_bio.transpose(), basic_net.layers[0].get_weights()[1]])
basic_net.layers[0].trainable = False
basic_net.compile(optimizer=Adam(lr=0.0001), metrics=['accuracy'], loss='categorical_crossentropy')
basic_net.fit(x=x_train, y=y_train, epochs=15)
In 2.0.0-alpha0 the accuracy of the network consistently reaches &gt;80% in the first few epochs. In 1.13.1 the accuracy consistently reaches only &lt;20% after all 15 epochs. What is going on?
Here is the file with weights: &lt;denchmark-link:https://drive.google.com/file/d/12O0XE98jl_yYmiBbZMWyLMaeZiHH-FXH/view?usp=sharing&gt;W_bio.npy&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='danaugrs' date='2019-05-29T15:06:05Z'>
		The difference in behavior has something to do with using ReLU. If instead the activation function used for the hidden layer is sigmoid then the behavior becomes the same in TF1 and TF2 (&lt;20% accuracy).
		</comment>
		<comment id='2' author='danaugrs' date='2019-05-30T11:08:48Z'>
		&lt;denchmark-link:https://github.com/danaugrs&gt;@danaugrs&lt;/denchmark-link&gt;
 I hope you are using ReLU for the hidden layers now. Can you please let us know if we have to keep this issue open
		</comment>
		<comment id='3' author='danaugrs' date='2019-05-30T15:40:24Z'>
		&lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;
 I think you seriously misunderstood my last comment. I was just helping whoever is going to debug this difference in behavior between  and  by pointing out that it probably lies in the ReLU implementation. The difference in behavior is only apparent when using ReLU. All the other activation functions I've tried lead to the same behavior in both versions.
		</comment>
		<comment id='4' author='danaugrs' date='2019-07-17T06:04:16Z'>
		The accuracy difference doesn't seem to be as severe now, but it is definitely still present (~65% vs. ~85%) However switching to distribution strategy (which changes the execution path) restores the accuracy in 2.0. We're standardizing on the latter path, so this should be fixed before the 2.0 release. In the mean time something like:
&lt;denchmark-code&gt;with tf.distribute.OneDeviceStrategy("GPU:0").scope():
  basic_net = Sequential([
    Dense(36, activation='relu', input_shape=(784,)),
    Dense(10, activation='softmax')
  ])
  
  basic_net.compile(optimizer=Adam(lr=0.0001), metrics=['accuracy'], loss="categorical_crossentropy")
  basic_net.fit(x=x_train, y=y_train, epochs=15)
&lt;/denchmark-code&gt;

will do the right thing. Thanks for the report, and for the fantastic repro.
cc &lt;denchmark-link:https://github.com/tomerk&gt;@tomerk&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='danaugrs' date='2019-09-06T21:43:36Z'>
		&lt;denchmark-link:https://github.com/danaugrs&gt;@danaugrs&lt;/denchmark-link&gt;
 I think the issue was resolved in  and . I ran your code in both the versions and the accuracy after 15 Epochs is  and  with  and .
Here is &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/d57e90aed84f74b7c422bccb23abf48b/tfnightly20preview_29099_keras_perfomance_relu.ipynb&gt;gist&lt;/denchmark-link&gt;
 with  and &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/415672186e6fcadd6093198dc33be64e/tfnightly_29099_keras_perfomance_relu.ipynb&gt;here is the gist&lt;/denchmark-link&gt;
 with .
I am closing the issue as it was resolved recent nightly. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='6' author='danaugrs' date='2019-09-06T21:43:38Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29099&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29099&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>