<bug id='31687' author='jmgc' open_date='2019-08-16T12:39:25Z' closed_time='2019-09-27T17:43:41Z'>
	<summary>TPUStrategy incompatibility with tf.io.read_file</summary>
	<description>
System information
I am using Colaboratory and Google cloud.

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 4.9.168-1+deb9u5
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): unknown
TensorFlow version (use command below): 1.14
Python version: 3.5.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
The script ends with a segmentation fault or abort.
Describe the expected behavior
Just a clean run.
Code to reproduce the issue
# Importing all necessary libraries
import tensorflow as tf
import cv2
import random as rnd
import os

if int(tf.__version__.split('.')[0]) == 1:
    print(tf.__version__)
    tf.enable_eager_execution()

@tf.function
def _read_test(filename):
    img_raw = tf.io.read_file(tf.squeeze(filename))
    return img_raw

import numpy as np
image = np.array([[rnd.randint(0, 255) for _ in range(936)] for _ in range(1024)])
cv2.imwrite('0.png', image);

raw = _read_test(tf.constant('0.png'))

tf.keras.backend.clear_session()

if 'TPU_NAME' in os.environ:
    TPU_WORKER = 'grpc://' + os.environ['TPU_NAME']
    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)
    tf.config.experimental_connect_to_host(resolver.master())
    tf.contrib.distribute.initialize_tpu_system(resolver)
    strategy = tf.contrib.distribute.TPUStrategy(resolver)
elif 'COLAB_TPU_ADDR' in os.environ:
    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']
    resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)
    tf.config.experimental_connect_to_host(resolver.master())
    tf.contrib.distribute.initialize_tpu_system(resolver)
    strategy = tf.contrib.distribute.TPUStrategy(resolver)
else:
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

#print(strategy)

with strategy.scope():
    pass

print('success')
Other info / logs
The previous code is part of an image processing Neural Network. The image files are read while running the code to minimize the disk usage. The code runs smoothly in a CPU or GPU environment, however it crashes in a TPU one.
	</description>
	<comments>
		<comment id='1' author='jmgc' date='2019-08-17T07:00:34Z'>
		&lt;denchmark-code&gt;All input files and the model directory must use a cloud storage
bucket path (gs://bucket-name/...), and this bucket must be accessible 
from the TPU server. Note that all data processing and model checkpointing 
is performed on the TPU server, not the local machine
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='jmgc' date='2019-08-17T07:52:07Z'>
		The example has been run in Colaboratory and the TPU server through a ssh connection. I am not running it on my local machine.
		</comment>
		<comment id='3' author='jmgc' date='2019-08-18T07:27:49Z'>
		&lt;denchmark-link:https://github.com/jmgc&gt;@jmgc&lt;/denchmark-link&gt;
 your images/ data should be stored on a GCS bucket, and then change it to something like this
&lt;denchmark-code&gt;# raw = _read_test(tf.constant('0.png'))
raw = _read_test(tf.constant('gs://your-bucket-name/0.png'))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='jmgc' date='2019-08-18T09:18:17Z'>
		&lt;denchmark-link:https://github.com/srihari-humbarwadi&gt;@srihari-humbarwadi&lt;/denchmark-link&gt;
 I have tested it in a TPU server and it seems to work, however, in Colaboratory it does not find the bucket. Is it possible to access a drive in a similar way as using a bucket? If not, how can I read files in Colaboratory?
		</comment>
		<comment id='5' author='jmgc' date='2019-08-18T12:42:18Z'>
		You will have to create a service account in GCP with access to GCS bucket you intend to read data from. Then use the credentials(json) of this service account in the snippet given below
&lt;denchmark-code&gt;with tf.Session() as sess:
    with open('&lt;YOUR CREDENTIALS JSON&gt;', 'r') as f: 
        auth_info = json.load(f)
        tf.contrib.cloud.configure_gcs(sess, credentials=auth_info)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='jmgc' date='2019-08-18T15:16:23Z'>
		Sorry, I am not able to follow all the acronyms. Can I access a drive disk from a TPU in Colaboratory?
		</comment>
		<comment id='7' author='jmgc' date='2019-08-18T15:58:32Z'>
		&lt;denchmark-link:https://github.com/jmgc&gt;@jmgc&lt;/denchmark-link&gt;
 I never used TPU before (plan to give it a try soon), but my understanding is that TPU does not give you access to a local file system so you have to use a remote file system such as GCS (with  scheme that TF support)
I would assume other types of remote file system such as s3 (AWS) or azfs (Azure) should work as well, as long as the TF version you use support the scheme (e.g, s3://bucket/object, azfs://...).
		</comment>
		<comment id='8' author='jmgc' date='2019-08-20T05:54:03Z'>
		&lt;denchmark-link:https://github.com/jmgc&gt;@jmgc&lt;/denchmark-link&gt;
 Did you try &lt;denchmark-link:https://github.com/yongtang&gt;@yongtang&lt;/denchmark-link&gt;
's solution.
		</comment>
		<comment id='9' author='jmgc' date='2019-08-20T09:09:46Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
, I did not because I have tried the bucket solution, and I still have a segmentation fault in my full script. I am working on another minimal test to show the error.
		</comment>
		<comment id='10' author='jmgc' date='2019-08-28T19:37:19Z'>
		I have been working and modified my code to use a bucket. I have found the same error reported in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32043&gt;#32043&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='11' author='jmgc' date='2019-08-29T18:29:20Z'>
		Hi &lt;denchmark-link:https://github.com/jmgc&gt;@jmgc&lt;/denchmark-link&gt;
, do you have any sample code / colab that I can look at? Also in general we are currently not supporting TPUs with 2.0 yet.
		</comment>
		<comment id='12' author='jmgc' date='2019-09-27T17:43:40Z'>
		Closing issue for now, feel free to reopen.
		</comment>
		<comment id='13' author='jmgc' date='2019-09-27T17:43:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31687&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31687&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>