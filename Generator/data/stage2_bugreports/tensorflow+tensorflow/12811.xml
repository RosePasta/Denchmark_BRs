<bug id='12811' author='Kitter' open_date='2017-09-05T06:34:41Z' closed_time='2017-09-08T07:51:25Z'>
	<summary>The predict results using java and python is different</summary>
	<description>
My graph contains the following statements:
tf.contrib.layers.batch_norm(incoming, is_training=is_training, scale=True, decay=0.99)
 tf.contrib.layers.dropout(incoming, keep_prob=keep_prob, is_training=is_training)
When the variable is_training is set to True, the saved model give the same result using Java and Python. The result is right.
But, when the variable is_training is set to False, the saved model give different result using Java and Python. Python give a right result. Java give a wrong result.
Why does this happen?
Tensorflow:1.2.0
OS: centos7
Java:Sun jdk 1.8.0.144
Python:3.4.5
	</description>
	<comments>
		<comment id='1' author='Kitter' date='2017-09-07T01:17:39Z'>
		That's interesting. Do you happen to have a full repro case?
		</comment>
		<comment id='2' author='Kitter' date='2017-09-07T01:31:44Z'>
		&lt;denchmark-link:https://github.com/Kitter&gt;@Kitter&lt;/denchmark-link&gt;
 : Is there any more information you can provide?  A more complete example to help reproduce the problem will help. Can you share the saved model and the code you're using to load and execute it in Java and/or Python?
		</comment>
		<comment id='3' author='Kitter' date='2017-09-07T08:15:21Z'>
		&lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 :
python code:
&lt;denchmark-code&gt;encoder_size = 64
decoder_size = 17
model_file='/test/model.pb'
with tf.gfile.FastGFile(model_file, 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    _ = tf.import_graph_def(graph_def, name='')

with tf.Session() as sess:
    input_feed={}
    file_name = "/test/test.png"
    img = Image.open(file_name)
    im = img.convert('L')
    im = np.asarray(im, dtype=np.uint8)
    imdata = np.array([[im]], dtype=int)
    input_feed['img_data:0']= imdata
    input_feed['zero_paddings:0']= np.zeros(shape=[1, 1, 512], dtype=float)
    for l in range(int(encoder_size) - 1):
        input_feed['encoder_mask'+str(l)+':0'] = np.array([[1]], dtype=float)
    input_feed['encoder_mask'+str(int(encoder_size) - 1)+':0'] = np.array([[0]], dtype=float)
    input_feed['decoder0:0'] = np.array([1], dtype=int)
    outputs= []
    decoders = []
    for l in range(int(decoder_size)):
        if l == 0:
            decoder = sess.graph.get_tensor_by_name('model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection/AttnOutputProjection/BiasAdd:0')
        else:
            decoder = sess.graph.get_tensor_by_name('model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection_' + str(l) + '/AttnOutputProjection/BiasAdd:0')
        decoders.append(decoder)
    decoders=sess.run(decoders,input_feed)
    decoders=np.argmax(decoders, 2)
    for output in decoders:
        outputs.append(output[0])
    print(outputs)
&lt;/denchmark-code&gt;

Java code:
&lt;denchmark-code&gt;   private static final int DECODER_SIZE = 17;
   private static float[][][][] convertImageToArray(BufferedImage bf) {
        int width = bf.getWidth();
        int height = bf.getHeight();
        int[] data = new int[width * height];
        bf.getRGB(0, 0, width, height, data, 0, width);
        float[][][][] rgbArray = new float[1][1][height][width];
        for (int i = 0; i &lt; height; i++) {
            for (int j = 0; j &lt; width; j++) {
                rgbArray[0][0][i][j] = data[i * width + j];
            }
        }
        return rgbArray;
   }

   String imageFilePath = "/test/test.png";
   String modelDir="/test/model.pb";
   byte[] graphDef = Files.readAllBytes(Paths.get(modelDir));
   File imageFile = new File(imageFilePath);
   BufferedImage im = ImageIO.read(imageFile);
   float[][][][] imgData = convertImageToArray(im);
   Graph g = new Graph();
   g.importGraphDef(graphDef);
   Session s = new Session(g);
   String imageData = "img_data";
   String decodeName = "decoder0";
   int encoderSize = 64;
   String zeroPaddingName = "zero_paddings";
   Runner runner = s.runner().feed(imageData, Tensor.create(imgData));
   runner = runner.feed(decodeName, Tensor.create(new int[]{1}));
   runner = runner.feed(zeroPaddingName,  Tensor.create(new float[1][1][512]));
   for(int index = 0; index &lt; encoderSize; index++){
        float[][] encoderMask = new float[1][1];
        encoderMask[0][0] = 1;
        if(index == encoderSize - 1) encoderMask[0][0] = 0;
        String encoderMaskName = "encoder_mask" + index;
        runner = runner.feed(encoderMaskName, Tensor.create(encoderMask));
    }
   String outputName;
   int[] encodes = new int[DECODER_SIZE];
   String prefix = "model_with_buckets/embedding_attention_decoder_3/attention_decoder/AttnOutputProjection";
   for(int index = 0; index &lt; DECODER_SIZE; index++){
       if(index == 0){
           outputName = prefix + "/AttnOutputProjection/BiasAdd";
       } else {
           outputName = prefix + "_" + index + "/AttnOutputProjection/BiasAdd";
       }
       runner.fetch(outputName);
    }
   List&lt;Tensor&gt; tensorList = runner.runAndFetchMetadata().outputs;
   s.close();
   for(Tensor result : tensorList){
      final long[] rshape = result.shape();
      if (result.numDimensions() != 2 || rshape[0] != 1) {
          throw new RuntimeException(String.format(
              "Expected model to produce a [1 N] shaped tensor where N is the number of labels, instead it produced one with shape %s",
              Arrays.toString(rshape)));
      }
      int charNum = (int) rshape[1];
      float[] outputs = result.copyTo(new float[1][charNum])[0];
      int bestLabelIdx = maxIndex(outputs);
      int index = tensorList.indexOf(result);
      encodes[index] = bestLabelIdx;
   }
&lt;/denchmark-code&gt;

saved model: &lt;denchmark-link:http://61.136.1.102:9001/model.pb&gt;model.pb&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Kitter' date='2017-09-07T15:23:22Z'>
		&lt;denchmark-link:https://github.com/Kitter&gt;@Kitter&lt;/denchmark-link&gt;
 still working on my first coffee, so forgive me if this first blush is wrong, but it looks like your Python code is converting the image data to grayscale () whereas i don't see any color space affectation in the Java code.
If that blush is wrong, does everything look equal if you dump the Python generated pixel array data and compare it to a dump of the Java generated pixel array data?
Also, purely out of curiosity, why choose PIL operations instead of the &lt;denchmark-link:https://www.tensorflow.org/api_guides/python/image&gt;TF image operations&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='5' author='Kitter' date='2017-09-08T02:22:17Z'>
		&lt;denchmark-link:https://github.com/quaeler&gt;@quaeler&lt;/denchmark-link&gt;
  I add converting of image grayscale  in Java code, the result is the same as before. There is no improvement.
		</comment>
		<comment id='6' author='Kitter' date='2017-09-08T02:30:17Z'>
		&lt;denchmark-link:https://github.com/Kitter&gt;@Kitter&lt;/denchmark-link&gt;
 can you put your  some place from where it can be downloaded; also, could you post the code with which you did the Java BI grayscale conversion? Also, also, did you do a pixel array dump from each Python and Java and compare the values?
		</comment>
		<comment id='7' author='Kitter' date='2017-09-08T03:37:56Z'>
		&lt;denchmark-link:https://github.com/quaeler&gt;@quaeler&lt;/denchmark-link&gt;

Java BI grayscale conversion code:
&lt;denchmark-code&gt;	BufferedImage grayImage = new BufferedImage(width, height, BufferedImage.TYPE_BYTE_GRAY);
	for (int i = 0; i &lt; width; i++) {
		for (int j = 0; j &lt; height; j++) {
			int rgb = bf.getRGB(i, j);
			grayImage.setRGB(i, j, rgb);
		}
	}
&lt;/denchmark-code&gt;

image file &lt;denchmark-link:http://61.136.1.102:9001/test.png&gt;:test.png&lt;/denchmark-link&gt;

It is strange that Java and Python use  the &lt;denchmark-link:http://61.136.1.102:9001/model_true.pb&gt;model_true.pb&lt;/denchmark-link&gt;
 (is_training is set to True),  the result is same.
		</comment>
		<comment id='8' author='Kitter' date='2017-09-08T05:12:53Z'>
		Thanks for the assets.
I'm sorry to be hung up on this, but we're on board with the pixel values being used in Python and Java being wholly different - ya? (The values in the Python ndarray are nicely in the 0-255 range however the Java values being returned from BI are bitwise'd 8-bit R, G, B (and probably A since this is a PNG) resulting in the 'float' values being in the general region of -1.4E7 range.)
(I'm spinning down for the day - will try to look at the saved models tomorrow.)
		</comment>
		<comment id='9' author='Kitter' date='2017-09-08T06:51:34Z'>
		&lt;denchmark-link:https://github.com/quaeler&gt;@quaeler&lt;/denchmark-link&gt;

Thanks for your help.
This is my fault.I tried using tensorflowâ€˜s API to read the picture file. I got the right result.
		</comment>
		<comment id='10' author='Kitter' date='2018-04-24T13:37:30Z'>
		&lt;denchmark-link:https://github.com/Kitter&gt;@Kitter&lt;/denchmark-link&gt;

Could you please tell me which tensorflow's API you use to read the picture file in java? Thank you!
		</comment>
		<comment id='11' author='Kitter' date='2018-05-02T09:20:59Z'>
		&lt;denchmark-link:https://github.com/q657198385&gt;@q657198385&lt;/denchmark-link&gt;

I use java.nio.file.Files to read image file data, then use tensorflow API to did the grayscale conversion. I get the correct result.
source code:
&lt;denchmark-code&gt;private static Tensor constructAndExecuteGraphToNormalizeImage(byte[] imageBytes) {
    Graph g = new Graph();
    GraphBuilder b = new GraphBuilder(g);
    final Output input = b.constant("img_data", imageBytes);
    final float mean = 117f;
    final float scale = 1f;
    Output output = b.binaryOp("Reshape",b.div(b.sub(b.cast(b.decodeJpeg(input, 1), DataType.FLOAT), 
    b.constant("mean", mean)), b.constant("scale", scale)), b.constant("make_batch", new int[]{1,1,32,256}));
    Session s = new Session(g);
    Tensor tensor = s.runner().fetch(output.op().name()).run().get(0);
    s.close();
    return tensor;
}
byte[] imageBytes = Files.readAllBytes(Paths.get("src/test/resources/test.png"));
Tensor image = constructAndExecuteGraphToNormalizeImage(imageBytes);
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>