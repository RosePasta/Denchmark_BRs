<bug id='37548' author='drasmuss' open_date='2020-03-12T19:47:01Z' closed_time='2020-06-18T00:37:02Z'>
	<summary>Keras connectivity metadata is not set correctly in TF 2.2.0rc0</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
TensorFlow installed from (source or
binary): binary
TensorFlow version (use command below): 2.2.0rc0
Python version: 3.6.10
Bazel
version (if compiling from source): N/A
GCC/Compiler version (if compiling from
source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
If a Keras model is applied to inputs with mismatched (but compatible) shape, the model is applied correctly but none of the Keras connectivity metadata (e.g. inbound/outbound_nodes or keras_history) is updated.
Describe the expected behavior
The Keras connectivity metadata should be updated, so after the model is applied there should be new inbound/outbound nodes for that application, and all the Tensors created by that application should have their keras_history set appropriately (this is the behaviour in TF&lt;=2.1.0).
Standalone code to reproduce the issue
import tensorflow as tf


for input_shape in [(1,), (1, 1)]:
    print("input_shape", input_shape)

    sub_in = tf.keras.Input((1,))
    relu_layer = tf.keras.layers.ReLU()
    sub_out = relu_layer(sub_in)
    submodel = tf.keras.Model(sub_in, sub_out)

    assert len(relu_layer.inbound_nodes) == 1

    inp = tf.keras.Input(input_shape)
    out = submodel(inp)

    assert len(relu_layer.inbound_nodes) == 2
The assert len(relu_layer.inbound_nodes) == 2 condition fails when input_shape=(1, 1), indicating that no new inbound nodes were created when submodel was applied to inp.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The issue is that when this function is applied &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926&lt;/denchmark-link&gt;
 it creates new tensors, which do not have a keras_history set. Then this condition evaluates to  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L947&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L947&lt;/denchmark-link&gt;
, so the  function is never called here &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L952&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/base_layer.py#L952&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='drasmuss' date='2020-03-13T05:40:37Z'>
		Was able to replicate the issue with Tf 2.2.rc0.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/8b75a84496af15d6c8e7a70fe383c98e/untitled448.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='drasmuss' date='2020-03-15T04:56:34Z'>
		I think gist created by &lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 has some problem.
Here is the gist created by &lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 ,
import tensorflow as tf
for input_shape in [(1,), (1, 1)]:
    print("input_shape", input_shape)
    
    # Code Section 1
    sub_in = tf.keras.Input((1,))
    relu_layer = tf.keras.layers.ReLU()
    sub_out = relu_layer(sub_in)
    submodel = tf.keras.Model(sub_in, sub_out)

    assert len(relu_layer.inbound_nodes) == 1

    # Code section 2
    inp = tf.keras.Input(input_shape)
    out = submodel(inp)

    assert len(relu_layer.inbound_nodes) == 2
Now, Take a look at section code 1 &amp; 2. Observe that there is no use of input_shape in code section 1. And relu_layer is defined in code section 1. So, len(relu.inbound_nodes) is independent of the value of input_shape. And moreover, in code section 2 assert statement, you are asserting inbound_nodes of relu_layer which is not even used in inp and out in code section 2 and is independent of value of input_shape.
That's why it gives assertion error. I have verified the code. Below code works fine.
import tensorflow as tf
for input_shape in [(1,), (1, 1)]:
    print("input_shape", input_shape)
    
    # Code Section 1
    sub_in = tf.keras.Input((1,))
    relu_layer = tf.keras.layers.ReLU()
    sub_out = relu_layer(sub_in)
    submodel = tf.keras.Model(sub_in, sub_out)

    assert len(relu_layer.inbound_nodes) == 1

    # Code section 2
    inp = tf.keras.Input(input_shape)
    out = relu_layer(inp)

    assert len(relu_layer.inbound_nodes) == 2
I have just added relu_layer instead of submodel in code section 2.
&lt;denchmark-link:https://github.com/drasmuss&gt;@drasmuss&lt;/denchmark-link&gt;
 , Please give your comments too.
		</comment>
		<comment id='3' author='drasmuss' date='2020-03-15T11:17:09Z'>
		
Observe that there is no use of input_shape in code section 1. And relu_layer is defined in code section 1. So, len(relu.inbound_nodes) is independent of the value of input_shape. And moreover, in code section 2 assert statement, you are asserting inbound_nodes of relu_layer which is not even used in inp and out in code section 2 and is independent of value of input_shape.

"Code section 1" creates , which is used in "Code section 2". So effectively all of "Code section 1" is being repeated in "Code section 2". You can read more about how this works in Keras here &lt;denchmark-link:https://www.tensorflow.org/guide/keras/functional#all_models_are_callable_just_like_layers&gt;https://www.tensorflow.org/guide/keras/functional#all_models_are_callable_just_like_layers&lt;/denchmark-link&gt;
.

That's why it gives assertion error. I have verified the code. Below code works fine

Your code avoids the problem, it doesn't solve it (because the root of the issue is in this section &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc0/tensorflow/python/keras/engine/network.py#L926&lt;/denchmark-link&gt;
, as pointed out above, which is not called if you're not using a submodel). The original example should work if the Keras connectivity were being set correctly, which you can verify by setting the TensorFlow version to any value &lt;2.2.
		</comment>
		<comment id='4' author='drasmuss' date='2020-03-26T00:37:09Z'>
		&lt;denchmark-link:https://github.com/drasmuss&gt;@drasmuss&lt;/denchmark-link&gt;
 We are going to be updating the code to remove metadata from all nested layers going forward. 'inbound_nodes' property on layers has been deprecated as it is an internal implementation detail.
		</comment>
		<comment id='5' author='drasmuss' date='2020-03-26T01:25:38Z'>
		&lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
 Is there an alternate way to determine, given a tensor, what the internal layer was that generated that tensor? I.e., given the code example from above
&lt;denchmark-code&gt;    sub_in = tf.keras.Input((1,))
    relu_layer = tf.keras.layers.ReLU()
    sub_out = relu_layer(sub_in)
    submodel = tf.keras.Model(sub_in, sub_out)

    inp = tf.keras.Input(input_shape)
    out = submodel(inp)
&lt;/denchmark-code&gt;

when given out, I need to be able to retrieve relu_layer. The only way I was able to do this previously was by traversing through the metadata, but if that is being removed then I'll need another method.
		</comment>
		<comment id='6' author='drasmuss' date='2020-03-27T18:33:00Z'>
		&lt;denchmark-link:https://github.com/drasmuss&gt;@drasmuss&lt;/denchmark-link&gt;
 What is the use case for this? We do not currently have a method as this is internal implementation detail of functional model construction.
		</comment>
		<comment id='7' author='drasmuss' date='2020-03-27T18:56:26Z'>
		I need to be able to determine the graph structure of a functional Keras model (i.e. the full graph of which layers are connected to which other layers). And it is a model defined by external users, so I don't have direct access to the model definition, I just have the Keras Model object.
		</comment>
		<comment id='8' author='drasmuss' date='2020-06-08T20:28:00Z'>
		Can you use model.layers to navigate and find the graph of layers in the inner model?
		</comment>
		<comment id='9' author='drasmuss' date='2020-06-08T21:07:18Z'>
		No, because model.layers just tells you which layer objects are in the model, not how they are connected to each other. For example, consider a model like this
&lt;denchmark-code&gt;inp = x = tf.keras.layers.Input(shape=(2,))
my_layer = tf.keras.layers.Dense(units=2)
x = my_layer(x)
x = my_layer(x)
x = my_layer(x)
model = tf.keras.Model(inp, x)
&lt;/denchmark-code&gt;

model.layers just shows one Input layer and one Dense layer. If you want to recreate the structure of that model, you have to look at the Keras connectivity metadata of my_layer.
		</comment>
		<comment id='10' author='drasmuss' date='2020-06-08T21:20:22Z'>
		We do not have any public properties or methods for this today. We have tensor._keras_history which will provide that information, but since this is a private property we do not recommend relying on it (similar as _inbound_nodes).
		</comment>
		<comment id='11' author='drasmuss' date='2020-06-09T19:19:49Z'>
		I would love to not rely on private properties, but as you say there is no way to get this information through public properties. So if we want the Keras graph structure (which doesn't seem like a really unusual use case) that's our only option ðŸ˜„.
Do you have a timeline for when you plan on removing this functionality? And are there any plans to provide equivalent information through some other data structure, or will it just be impossible to recover the Keras graph structure at that point?
		</comment>
		<comment id='12' author='drasmuss' date='2020-06-13T01:42:00Z'>
		I have fixed the original issue. ie. you can use _keras_history or inbound_nodes to get the information. There are no plans at this time to add properties describing the Keras graph structure.
		</comment>
		<comment id='13' author='drasmuss' date='2020-06-18T00:37:02Z'>
		&lt;denchmark-link:https://github.com/drasmuss&gt;@drasmuss&lt;/denchmark-link&gt;
 this issue has been fixed in the latest tf-nightly and the next TF 2.3.0 release should have it. Please feel free to reopen if it does not work for you.
		</comment>
		<comment id='14' author='drasmuss' date='2020-06-18T00:37:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37548&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37548&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='drasmuss' date='2020-07-08T14:16:32Z'>
		Confirmed that this is fixed in TF 2.3.0rc0, thanks!
		</comment>
	</comments>
</bug>