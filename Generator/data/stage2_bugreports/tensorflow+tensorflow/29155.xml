<bug id='29155' author='proszx' open_date='2019-05-30T02:57:59Z' closed_time='2019-06-06T18:48:42Z'>
	<summary>when i use conv algorithm</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Debian
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below):1.13.1,1.14.0，2.0.0a0，1.9.0
Python version:3.7,3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:Cuda 10/7.5.0,7.4.2,7.4.1,7.4.0,Cuda 9 can't support 2060
GPU model and memory:rtx 2060 6GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Describe the expected behavior
Code to reproduce the issue
conda activate base
2.0.0-alpha0
2019-05-29 19:58:31.543654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-29 19:58:31.557759: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-05-29 19:58:31.670769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-05-29 19:58:31.672348: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b57a0a60 executing computations on platform CUDA. Devices:
2019-05-29 19:58:31.672364: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): Graphics Device, Compute Capability 7.5
2019-05-29 19:58:31.693201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2904000000 Hz
2019-05-29 19:58:31.693619: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55c9b580db30 executing computations on platform Host. Devices:
2019-05-29 19:58:31.693637: I tensorflow/compiler/xla/service/service.cc:169] StreamExecutor device (0): ,
2019-05-29 19:58:31.693791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties:
name: Graphics Device major: 7 minor: 5 memoryClockRate(GHz): 1.71
pciBusID: 0000:01:00.0
totalMemory: 5.76GiB freeMemory: 5.17GiB
2019-05-29 19:58:31.693804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-05-29 19:58:31.693844: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-05-29 19:58:31.694402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-05-29 19:58:31.694413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021] 0
2019-05-29 19:58:31.694419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0: N
2019-05-29 19:58:31.694516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4990 MB memory) -&gt; physical GPU (device: 0, name: Graphics Device, pci bus id: 0000:01:00.0, compute capability: 7.5)
Number of training examples: 60000
Number of test examples: 10000
Epoch 1/5
2019-05-29 19:58:32.786674: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.
2019-05-29 19:58:36.114172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-05-29 19:58:36.288348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-05-29 19:58:36.934479: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945020: E tensorflow/stream_executor/cuda/cuda_dnn.cc:338] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2019-05-29 19:58:36.945127: W tensorflow/core/common_runtime/base_collective_executor.cc:214] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[{{node conv2d/Conv2D}}]]
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='proszx' date='2019-05-31T04:48:40Z'>
		&lt;denchmark-link:https://github.com/proszx&gt;@proszx&lt;/denchmark-link&gt;
 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Could you provide more details about the issue. Thanks!
		</comment>
		<comment id='2' author='proszx' date='2019-05-31T08:24:57Z'>
		
@proszx为了加快故障排除过程，请提供一个代码片段来重现此处报告的问题。您能提供有关该问题的更多详细信息吗？谢谢！

i just run the demo cnn of tensorflow2.0.0a0(fashion mnist),
and same problems on tensorflow from 1.13.1,1.14
beside 20‘s gpu doesn't support cuda9,i installed it but it's failed.
i run with same netowrk structure by torch, and it's ok
and nearly all 20's gpu has same problem(google knows ~)
sorry for bothering you and thx
here is the code for tf 2.0.0a0
import tensorflow as tf
import tensorflow_datasets as tfds
import math
import numpy as np
import matplotlib.pyplot as plt
import tqdm
import tqdm.auto
tqdm.tqdm = tqdm.auto.tqdm
dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)
train_dataset, test_dataset = dataset['train'], dataset['test']
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']
num_train_examples = metadata.splits['train'].num_examples
num_test_examples = metadata.splits['test'].num_examples
print("Number of training examples: {}".format(num_train_examples))
print("Number of test examples:     {}".format(num_test_examples))
def normalize(images, labels):
images = tf.cast(images, tf.float32)  # Casts a tensor to a new type
images /= 255
return images, labels
train_dataset =  train_dataset.map(normalize)
test_dataset  =  test_dataset.map(normalize)
model = tf.keras.Sequential([
tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,
input_shape=(28, 28, 1)),
tf.keras.layers.MaxPooling2D((2, 2), strides=2),
tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),
tf.keras.layers.MaxPooling2D((2, 2), strides=2),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(128, activation=tf.nn.relu),
tf.keras.layers.Dense(10,  activation=tf.nn.softmax)
])
model.compile(optimizer='adam',
loss='sparse_categorical_crossentropy',
metrics=['accuracy'])
BATCH_SIZE = 32
train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE)
test_dataset = test_dataset.batch(BATCH_SIZE)
model.fit(train_dataset, epochs=5, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))
test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))
print('Accuracy on test dataset:', test_accuracy)
here is the code for 1.13.1
import tensorflow as tf
import tensorflow.examples.tutorials.mnist.input_data as input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
x = tf.placeholder(tf.float32, [None, 784])
y_actual = tf.placeholder(tf.float32, shape=[None, 10])
def weight_variable(shape):
initial = tf.truncated_normal(shape, stddev=0.1)
return tf.Variable(initial)
def bias_variable(shape):
initial = tf.constant(0.1, shape=shape)
return tf.Variable(initial)
def conv2d(x, W):
return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
def max_pool(x):
return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')
x_image = tf.reshape(x, [-1,28,28,1])
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool(h_conv1)
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool(h_conv2)
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])
h_pool2_flat = tf.reshape(h_pool2, [-1, 7764])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
keep_prob = tf.placeholder("float")
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])
y_predict=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
cross_entropy = -tf.reduce_sum(y_actual*tf.log(y_predict))
train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_predict,1), tf.argmax(y_actual,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
sess=tf.InteractiveSession()
sess.run(tf.initialize_all_variables())
for i in range(20000):
batch = mnist.train.next_batch(50)
if i%100 == 0:
train_acc = accuracy.eval(feed_dict={x:batch[0], y_actual: batch[1], keep_prob: 1.0})
print('step',i,'training accuracy',train_acc)
train_step.run(feed_dict={x: batch[0], y_actual: batch[1], keep_prob: 0.5})
test_acc=accuracy.eval(feed_dict={x: mnist.test.images, y_actual: mnist.test.labels, keep_prob: 1.0})
print("test accuracy",test_acc)
		</comment>
		<comment id='3' author='proszx' date='2019-05-31T10:44:33Z'>
		&lt;denchmark-link:https://github.com/proszx&gt;@proszx&lt;/denchmark-link&gt;
 It worked for Tensorflow 2.0.0.alpha CPU version and GPU version.have a look on colab link for &lt;denchmark-link:https://colab.sandbox.google.com/drive/1pCSvY0-PfFAZu8MnTco5X1-gxTCi4wi0#scrollTo=n_a432xtShru&gt;CPU&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/drive/1Z9UQAluZBRWOJ2dW61uu8qBJ88-AJSFy#scrollTo=vzHHnVM2Tbxy&gt;GPU&lt;/denchmark-link&gt;
. Please let me know if still stuck. Thanks!
		</comment>
		<comment id='4' author='proszx' date='2019-05-31T10:46:31Z'>
		&lt;denchmark-link:https://github.com/proszx&gt;@proszx&lt;/denchmark-link&gt;
 I tried to reproduce the issue on Tensorflow 1.13.1 but i got following error
ValueError: Dimensions must be equal, but are 7764 and 3136 for 'MatMul_1' (op: 'MatMul') with input shapes: [?,7764], [3136,1024]. Thanks!
		</comment>
		<comment id='5' author='proszx' date='2019-06-01T03:14:01Z'>
		
@proszx It worked for Tensorflow 2.0.0.alpha CPU version and GPU version.have a look on colab link for CPU and GPU. Please let me know if still stuck. Thanks!

i can't open that and i'm not sure that device is 20 series GPU
and problem is stills stuck me
ok, I just know torch is ok for this problem.
		</comment>
		<comment id='6' author='proszx' date='2019-06-06T04:38:38Z'>
		&lt;denchmark-link:https://github.com/reedwm&gt;@reedwm&lt;/denchmark-link&gt;
 would you help to take a look? Thanks.
		</comment>
		<comment id='7' author='proszx' date='2019-06-06T18:48:41Z'>
		Closing, as this looks like a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24496&gt;#24496&lt;/denchmark-link&gt;
. It looks like there is a workaround in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727&gt;this comment&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='8' author='proszx' date='2019-06-06T18:48:44Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29155&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29155&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>