<bug id='39287' author='Rubix982' open_date='2020-05-08T00:27:56Z' closed_time='2020-05-08T14:29:52Z'>
	<summary>Using tf.nn.softmax with tensor of dtype `int321 throws exception - works fine with float32</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution: Arch Linux, but I'm actually using collab .
TensorFlow installed from (source or binary): Using Google Collab.
TensorFlow version (use command below): Tensorflow 2.x, setup using %tensorflow_version 2.x in the notebook
Python version: 3.6.9

Describe the current behavior
Error is thrown when a tensor is used in the  with  of , as seen below,
&lt;denchmark-link:https://user-images.githubusercontent.com/41635766/81356987-02b02000-90ec-11ea-9d77-de3a3509559d.png&gt;&lt;/denchmark-link&gt;

However, in contrast, when the  are converted to a , like below, the code works,
&lt;denchmark-link:https://user-images.githubusercontent.com/41635766/81357051-24a9a280-90ec-11ea-91c6-c4e4b3a5ecfa.png&gt;&lt;/denchmark-link&gt;

Describe the expected behavior
I should get back the array of values like I have with float32.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;%tensorflow_version 2.x
import tensorflow as tf

tensor = tf.constant( [[10, 2], [1, 1]] )
print(tf.nn.softmax(tensor))
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
&lt;ipython-input-26-dff233aef206&gt; in &lt;module&gt;()
      1 tensor = tf.constant( [[10, 2], [1, 1]] )
----&gt; 2 print(tf.nn.softmax(tensor))

4 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

NotFoundError: Could not find valid device for node.
Node:{{node Softmax}}
All kernels registered for op Softmax :
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_BFLOAT16, DT_HALF]
 [Op:Softmax]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Other Info:&lt;/denchmark-h&gt;

Another similar issue exist(ed) &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33685&gt;here&lt;/denchmark-link&gt;
.
&lt;denchmark-h:h2&gt;Possible Solution&lt;/denchmark-h&gt;

tf.nn.softmax should automatically promote intx to floatx in the function itself, or generate an error that intx can't be used, where x is either 64 or 32 bits.
Thank you.
	</description>
	<comments>
		<comment id='1' author='Rubix982' date='2020-05-08T01:45:05Z'>
		Hi &lt;denchmark-link:https://github.com/Rubix982&gt;@Rubix982&lt;/denchmark-link&gt;
 ,
From the official specs of Tensorflow, "logits: A non-empty Tensor. Must be one of the following types: half, float32, float64.", and  is not in the supported data type list, you can check the detailed specs here
&lt;denchmark-link:https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/nn/softmax#args&gt;https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/nn/softmax#args&lt;/denchmark-link&gt;

Thanks
		</comment>
		<comment id='2' author='Rubix982' date='2020-05-08T05:58:32Z'>
		Hi &lt;denchmark-link:https://github.com/LeicongLi&gt;@LeicongLi&lt;/denchmark-link&gt;
 .
I see, but the error message is confusing. It's just that the error message was confusing. The solution can be either,
1): Error message for the user to convert their  or , to either dtypes of , , ,
2): Promote  or  to  to  ( typecast ), in that case in the function itself.
3): Error message should be friendlier since  does not make much quick sense when the solution is just to just change the dtype of the input.
Thank you.
		</comment>
		<comment id='3' author='Rubix982' date='2020-05-08T10:11:35Z'>
		I am able to replicate the error message as reported, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/9106fba3b7d13137d64474dd79892fef/2.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Rubix982' date='2020-05-08T12:29:59Z'>
		Thank you, &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 . The gist captures the issue.
		</comment>
		<comment id='5' author='Rubix982' date='2020-05-08T13:41:01Z'>
		&lt;denchmark-link:https://github.com/Rubix982&gt;@Rubix982&lt;/denchmark-link&gt;
 Agree with you that may be the error message could have been better but the later part of the error message clearly mentions all the kernels available for this . Moreover, the docs on TF &lt;denchmark-link:https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/nn/softmax#args&gt;webpage&lt;/denchmark-link&gt;
 clearly mentions what  are supported for this . Generally this  is used in the last layer of network where all the inputs to this  are in one of the  the kernel supports. As this  heavily used in the training (in every step with in each epoch), I guess adding  check may affect runtime performance.
I guess there are two options (1) writing simple function of softmax calculation or create a feature request mentioning which kind of use-cases will get benefited, or (2) updating the error message. Feel free to open a PR to update the error message. Thanks!
		</comment>
		<comment id='6' author='Rubix982' date='2020-05-08T14:29:52Z'>
		Hi &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 !
Agreed, the second option does seem easier to do.
Will definitely look into updating the error message through a PR.
Thank you for your time!
Closing this issue.
		</comment>
		<comment id='7' author='Rubix982' date='2020-05-08T14:29:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39287&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39287&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>