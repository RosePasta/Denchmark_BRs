<bug id='40671' author='fangminyu' open_date='2020-06-22T12:59:30Z' closed_time='2020-06-29T16:51:24Z'>
	<summary>[TF 1.15] unexpected segment faults for seemingly "reasonable and correct" codes</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7  (but libtensorflow.so is built in official docker image tensorflow/serving:1.15.0-devel-gpu)
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.15.0
Python version: 3
Bazel version (if compiling from source): 0.24.1
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: 10.0
GPU model and memory: 1080Ti 11178MiB

Describe the current behavior
It is by-product of tensorflow serving. In official docker image (tensorflow/serving:1.15.0-devel-gpu) , we build tensorflow serving 1.15 based on tensorflow 1.15. Everything is OK for tensorflow serving mode, and it has been deployed in our product environment. However, we meet the bottleneck of inter-process for current tensorflow serving, hence we consider using direct local GPU infer.
Luckily tensorflow is already included in tensorflow serving.  In tensorflow folder we build tensorflow_cc. using following command:
cd ./tensorflow
export  TF_NEED_CUDA=1
export  TF_NEED_S3=1
export  TF_CUDA_COMPUTE_CAPABILITIES="3.5,5.2,6.1"
export  TF_NEED_GCP=1
export  TF_NEED_JEMALLOC=0
export  TF_NEED_HDFS=0
export  TF_NEED_OPENCL=0
export  TF_NEED_MKL=0
export  TF_NEED_VERBS=0
export  TF_NEED_MPI=0
export  TF_DOWNLOAD_MKL=0
export  TF_NEED_GDR=0
export  TF_ENABLE_XLA=0
export  TF_CUDA_CLANG=0
export  TF_NEED_OPENCL_SYCL=0
export  GCC_HOST_COMPILER_PATH=/usr/bin/gcc
export  PYTHON_BIN_PATH=/usr/bin/python
export  PYTHON_LIB_PATH=/usr/lib/python2.7/site-packages/
export  CC_OPT_FLAGS="-march=native"
bazel build -c opt --config=cuda --copt=-mavx --verbose_failures tensorflow:libtensorflow_cc.so
Build is OK as:
&lt;denchmark-code&gt;INFO: From Compiling external/snappy/snappy-sinksource.cc:    
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-stubs-internal.cc:                                            
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy.cc:                                   
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++                                                                                             
Target //tensorflow:libtensorflow_cc.so up-to-date:                             
  bazel-bin/tensorflow/libtensorflow_cc.so                                               
INFO: Elapsed time: 1258.352s, Critical Path: 455.73s                                                                                                                  
INFO: 7436 processes: 7436 local.                                                                                                                                                
INFO: Build completed successfully, 11163 total actions  
&lt;/denchmark-code&gt;

Then I import following files into my project:
&lt;denchmark-code&gt;  libtensorflow_cc.so
  libtensorflow_framework.so.1 so
  c_api.h
  tf_atrrtype.h
  tf_datatype.h
  tf_status.h
tf_tensor.h
&lt;/denchmark-code&gt;

My code calls only C api of tensorflow (which is tested in old cpu tensorflow 1.13 version, and main code logic is OK), and main code is below:
&lt;denchmark-code&gt;// init session
    TF_Session * sess;
    TF_SessionOptions* sess_opts = TF_NewSessionOptions();
    if(proto_len &gt; 0)
    {
        TF_SetConfig(sess_opts,(void*)options_proto, proto_len, status);

        if(TF_GetCode(status) != TF_OK)
        {
            TF_DeleteSessionOptions(sess_opts);
            return NULL;
        }
    }
    sess = TF_NewSession(graph, sess_opts, status);

// session infer (most crashes occurs here)
TF_SessionRun(...)
&lt;/denchmark-code&gt;

SPECIAL NOTE: due to environment and other dependencies issues, my personal project  has to be built in local GPU centos (default glibc is old 2.17). In order to exclude the difference of gcc and glibc,   I build my project by using the same gcc 5.4.0 (the same as tensorflow/serving:1.15.0-devel-gpu) and the same glibc 2.23 (the same as tensorflow/serving:1.15.0-devel-gpu). Here is change of cmakelist.txt:
&lt;denchmark-code&gt;set(third_links ${third_links}
    -Wl,--rpath=/myf12/Code/glibc-2.23/install/lib
    -Wl,--dynamic-linker=/myf12/Code/glibc-2.23/install/lib/ld-2.23.so
    -lrt
    )
list(INSERT third_links 0 "-L /myf12/Code/glibc-2.23/install/lib/") 
&lt;/denchmark-code&gt;

where third_links will be used as
&lt;denchmark-code&gt;target_link_libraries(xxx	${third_links} )
&lt;/denchmark-code&gt;

Build is ok and here is ldd info:
&lt;denchmark-code&gt;ldd bin.debug/fst
        linux-vdso.so.1 =&gt;  (0x00007ffc51718000)
        libdl.so.2 =&gt; /myf12/Code/glibc-2.23/install/lib/libdl.so.2 (0x00007f2c4f224000)
        libtensorflow_cc_v1.15_avx.so =&gt; /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so (0x00007f2c11963000)
        librt.so.1 =&gt; /myf12/Code/glibc-2.23/install/lib/librt.so.1 (0x00007f2c1175b000)
        libjemalloc.so.2 =&gt; /mnt/lustre/cm/shared/global/src/misc/jemalloc/5.2.1/lib/libjemalloc.so.2 (0x00007f2c112cc000)
        libpthread.so.0 =&gt; /myf12/Code/glibc-2.23/install/lib/libpthread.so.0 (0x00007f2c110af000)
        libstdc++.so.6 =&gt; /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libstdc++.so.6 (0x00007f2c10d34000)
        libm.so.6 =&gt; /myf12/Code/glibc-2.23/install/lib/libm.so.6 (0x00007f2c10a2e000)
        libgcc_s.so.1 =&gt; /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libgcc_s.so.1 (0x00007f2c10817000)
        libc.so.6 =&gt; /myf12/Code/glibc-2.23/install/lib/libc.so.6 (0x00007f2c10476000)
        /myf12/Code/glibc-2.23/install/lib/ld-2.23.so =&gt; /lib64/ld-linux-x86-64.so.2 (0x00007f2c4f42a000)
        libcusparse.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcusparse.so.10.0 (0x00007f2c0ca0c000)
        libcusolver.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcusolver.so.10.0 (0x00007f2c04325000)
        libnvinfer.so.5 =&gt; /mnt/lustre/cm/shared/global/src/machinelearning/tensorrt/TensorRT-5.0.2.6/lib/libnvinfer.so.5 (0x00007f2bfcec8000)
        libnvinfer_plugin.so.5 =&gt; /mnt/lustre/cm/shared/global/src/machinelearning/tensorrt/TensorRT-5.0.2.6/lib/libnvinfer_plugin.so.5 (0x00007f2bfc995000)
        libcublas.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcublas.so.10.0 (0x00007f2bf83ff000)
        libcudnn.so.7 =&gt; /mnt/lustre/cm/shared/global/src/dev/cudnn/7.5.1/lib64/libcudnn.so.7 (0x00007f2be2de0000)
        libcufft.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcufft.so.10.0 (0x00007f2bdc92b000)
        libcurand.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcurand.so.10.0 (0x00007f2bd87c4000)
        libcudart.so.10.0 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libcudart.so.10.0 (0x00007f2bd854a000)
        libgomp.so.1 =&gt; /mnt/lustre/cm/shared/global/src/dev/gcc/5.4.0/lib64/libgomp.so.1 (0x00007f2bd8327000)
        libnvToolsExt.so.1 =&gt; /mnt/lustre/cm/shared/global/src/dev/cuda/10.0/lib64/libnvToolsExt.so.1 (0x00007f2bd811e000)

&lt;/denchmark-code&gt;

Program crashes due to segment fault as below:
&lt;denchmark-code&gt;2020-06-22 12:03:56.005532: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                       
2020-06-22 12:03:56.007051: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0                                                                 
2020-06-22 12:03:56.650162: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:                               
2020-06-22 12:03:56.650296: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0                                                                                        
2020-06-22 12:03:56.650307: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N                                                                                        
2020-06-22 12:03:56.652890: F external/org_tensorflow/tensorflow/core/common_runtime/device.cc:28] Check failed: DeviceNameUtils::ParseFullName(name(), &amp;parsed_name_) Invalid device name:
&lt;/denchmark-code&gt;

core dump is
&lt;denchmark-code&gt;#0  0x00007f0482651298 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007f048265271a in __GI_abort () at abort.c:89
#2  0x00007f048e307a34 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#3  0x00007f048dc2921f in tensorflow::Device::Device(tensorflow::Env*, tensorflow::DeviceAttributes const&amp;) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007f048dc62e64 in tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&amp;, tensorflow::DeviceAttributes const&amp;) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007f048d4d9166 in tensorflow::BaseGPUDevice::BaseGPUDevice(tensorflow::SessionOptions const&amp;, std::string const&amp;, tensorflow::gtl::IntType&lt;tensorflow::Bytes_tag_, long long&gt;, tensorflow::DeviceLocality const&amp;, tensorflow::gtl::IntType&lt;tensorflow::TfGpuId_tag_, int&gt;, std::string const&amp;, tensorflow::Allocator*, tensorflow::Allocator*, bool, int) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#6  0x00007f048d4e40c8 in tensorflow::GPUDeviceFactory::CreateGPUDevice(tensorflow::SessionOptions const&amp;, std::string const&amp;, tensorflow::gtl::IntType&lt;tensorflow::Bytes_tag_, long long&gt;, tensorflow::DeviceLocality const&amp;, tensorflow::gtl::IntType&lt;tensorflow::TfGpuId_tag_, int&gt;, std::string const&amp;, tensorflow::Allocator*, tensorflow::Allocator*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#7  0x00007f048d4dcc9e in tensorflow::BaseGPUDeviceFactory::CreateGPUDevice(tensorflow::SessionOptions const&amp;, std::string const&amp;, tensorflow::gtl::IntType&lt;tensorflow::TfGpuId_tag_, int&gt;, long long, tensorflow::DeviceLocality const&amp;, std::vector&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt;, std::allocator&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt; &gt; &gt;*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#8  0x00007f048d4e1f2a in tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&amp;, std::string const&amp;, std::vector&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt;, std::allocator&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt; &gt; &gt;*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#9  0x00007f048dc299c9 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&amp;, std::string const&amp;, std::vector&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt;, std::allocator&lt;std::unique_ptr&lt;tensorflow::Device, std::default_delete&lt;tensorflow::Device&gt; &gt; &gt; &gt;*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#10 0x00007f048c709161 in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&amp;, tensorflow::Session**) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#11 0x00007f048dca7380 in tensorflow::NewSession(tensorflow::SessionOptions const&amp;, tensorflow::Session**) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
&lt;/denchmark-code&gt;

Then I fix "bug" in following line 


tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc


         Line 1265
      in
      590d6ee






 const string device_name = 





from
&lt;denchmark-code&gt;const string device_name =
      strings::StrCat(name_prefix, "/device:GPU:", tf_gpu_id.value());
&lt;/denchmark-code&gt;

into
&lt;denchmark-code&gt;const string device_name = name_prefix + "/device:GPU:" + std::to_string(tf_gpu_id.value());
&lt;/denchmark-code&gt;

Previous crash is avoided (see new log "Created TensorFlow device" ) and rerun again. It crashes again in "InferStatically":
&lt;denchmark-code&gt;2020-06-22 12:08:22.185006: I external/org_tensorflow/tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                       
2020-06-22 12:08:22.186563: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1768] Adding visible gpu devices: 0                                                                 
2020-06-22 12:08:23.047640: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:                                
2020-06-22 12:08:23.047693: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0                                                                                        
2020-06-22 12:08:23.047705: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N                                                                                        
2020-06-22 12:08:23.050308: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8164 MB memory) -&gt;
 physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)                                                                                                    
                                                                                                                                                                                                           
                                                                                                                                                                                                           
^[[A^[[ASegmentation fault (core dumped)    

#0  0x00007fa69ce6ce96 in std::_Hashtable&lt;tensorflow::NodeDef const*, std::pair&lt;tensorflow::NodeDef const* const, tensorflow::grappler::NodeState&gt;, std::allocator&lt;std::pair&lt;tensorflow::NodeDef const* cons
t, tensorflow::grappler::NodeState&gt; &gt;, std::__detail::_Select1st, std::equal_to&lt;tensorflow::NodeDef const*&gt;, std::hash&lt;tensorflow::NodeDef const*&gt;, std::__detail::_Mod_range_hashing, std::__detail::_Defau
lt_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits&lt;false, false, true&gt; &gt;::_M_find_before_node(unsigned long, tensorflow::NodeDef const* const&amp;, unsigned long) const [clo
ne .isra.856] () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so

#1  0x00007fa69ce76041 in tensorflow::grappler::VirtualScheduler::GetNodeStateOrCreateIt(tensorflow::NodeDef const*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so         
#2  0x00007fa69ce78d9b in tensorflow::grappler::VirtualScheduler::Init(tensorflow::grappler::GrapplerItem const*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so            
#3  0x00007fa69ce569df in tensorflow::grappler::AnalyticalCostEstimator::PredictCosts(tensorflow::GraphDef const&amp;, tensorflow::RunMetadata*, tensorflow::grappler::Costs*) const ()                        
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007fa69ce4f37f in tensorflow::grappler::VirtualCluster::Run(tensorflow::grappler::GrapplerItem const&amp;, tensorflow::RunMetadata*) ()                                                                
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007fa69cdddb5a in tensorflow::grappler::GraphMemory::InferStatically(std::unordered_map&lt;std::string, tensorflow::DeviceProperties, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, tensorflow::DeviceProperties&gt; &gt; &gt; const&amp;) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                     
#6  0x00007fa69cdce427 in tensorflow::grappler::(anonymous namespace)::IdentifySwappingCandidates(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, std::unordered_set&lt;std::string, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::string&gt; &gt;*, std::unordered_map&lt;tensorflow::NodeDef*, tensorflow::grappler::(anonymous namespace)::SwapInfo, std::hash&lt;tensorflow::NodeDef*&gt;, std::equal_to&lt;tensorflow::NodeDef*&gt;, std::allocator&lt;std::pair&lt;tensorflow::NodeDef* const, tensorflow::grappler::(anonymous namespace)::SwapInfo&gt; &gt; &gt;*) [clone .constprop.1020] ()                      
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#7  0x00007fa69cdd091d in tensorflow::grappler::(anonymous namespace)::SwappingPass(tensorflow::RewriterConfig_MemOptType, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, std::unordered_set&lt;std::string, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::string&gt; &gt;*) [clone .constprop.1019] ()                                                                         
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#8  0x00007fa69cdd3a97 in tensorflow::grappler::MemoryOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&amp;, tensorflow::GraphDef*) ()                             
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#9  0x00007fa69cd01e5a in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                            
#10 0x00007fa69cd03431 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&amp;, tensorflow::GraphDef*) ()                          
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#11 0x00007fa69cd04c64 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&amp;, tensorflow::GraphDef*) ()                               
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#12 0x00007fa69cd070af in tensorflow::grappler::RunMetaOptimizer(tensorflow::grappler::GrapplerItem const&amp;, tensorflow::ConfigProto const&amp;, tensorflow::DeviceBase*, tensorflow::grappler::Cluster*, tensorflow::GraphDef*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#13 0x00007fa69ccf5fa8 in tensorflow::GraphExecutionState::OptimizeGraph(tensorflow::BuildGraphOptions const&amp;, std::unique_ptr&lt;tensorflow::Graph, std::default_delete&lt;tensorflow::Graph&gt; &gt;*, std::unique_ptr&lt;tensorflow::FunctionLibraryDefinition, std::default_delete&lt;tensorflow::FunctionLibraryDefinition&gt; &gt;*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                       
#14 0x00007fa69ccf8361 in tensorflow::GraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&amp;, std::unique_ptr&lt;tensorflow::ClientGraph, std::default_delete&lt;tensorflow::ClientGraph&gt; &gt;*) ()   
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#15 0x00007fa69bd9e46a in tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&amp;, std::unordered_map&lt;std::string, std::unique_ptr&lt;tensorflow::Graph, std::default_delete&lt;tensorflow::Graph&gt; &gt;, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, std::unique_ptr&lt;tensorflow::Graph, std::default_delete&lt;tensorflow::Graph&gt; &gt; &gt; &gt; &gt;*, std::unique_ptr&lt;tensorflow::FunctionLibraryDefinition, std::default_delete&lt;tensorflow::FunctionLibraryDefinition&gt; &gt;*, tensorflow::DirectSession::RunStateArgs*, absl::InlinedVector&lt;tensorflow::DataType, 4ul, std::allocator&lt;tensorflow::DataType&gt; &gt;*, absl::InlinedVector&lt;tensorflow::DataType, 4ul, std::allocator&lt;tensorflow::DataType&gt; &gt;*, long long*) ()                                                                        
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#16 0x00007fa69bd9f9de in tensorflow::DirectSession::CreateExecutors(tensorflow::CallableOptions const&amp;, std::unique_ptr&lt;tensorflow::DirectSession::ExecutorsAndKeys, std::default_delete&lt;tensorflow::DirectSession::ExecutorsAndKeys&gt; &gt;*, std::unique_ptr&lt;tensorflow::DirectSession::FunctionInfo, std::default_delete&lt;tensorflow::DirectSession::FunctionInfo&gt; &gt;*, tensorflow::DirectSession::RunStateArgs*) ()      
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#17 0x00007fa69bda1d64 in tensorflow::DirectSession::GetOrCreateExecutors(absl::Span&lt;std::string const&gt;, absl::Span&lt;std::string const&gt;, absl::Span&lt;std::string const&gt;, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                                          
#18 0x00007fa69bda3648 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&amp;, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt;
&gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, std::vector&lt;tensorflow::Tensor, std::allocator&lt;tensorflow::Tensor&gt; &gt;*, tensorflow::RunMetadata*) () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so                                                                                                 
#19 0x00007fa696f70911 in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;, std::allocator&lt;std::pair&lt;std::string, tensorflow::Tensor&gt; &gt; &gt; const&amp;, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, TF_Tensor**, std::vector&lt;std::string, std::allocator&lt;std::string&gt; &gt; const&amp;, TF_Buffer*, TF_Status*) [clone .constprop.628] ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#20 0x00007fa696f71179 in TF_SessionRun () from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so 
&lt;/denchmark-code&gt;

Then I fix "bug" in following line 


tensorflow/tensorflow/core/grappler/costs/graph_properties.cc


         Line 2140
      in
      590d6ee






 fed_ports[tensor_id.node()].insert(tensor_id.index()); 





from
&lt;denchmark-code&gt;fed_ports[tensor_id.node()].insert(tensor_id.index());
&lt;/denchmark-code&gt;

into:
&lt;denchmark-code&gt;      if (fed_ports.find(tensor_id.node()) == fed_ports.end())
      {
         std::unordered_set&lt;int&gt; ports = {tensor_id.index()};
         fed_ports[tensor_id.node()] = ports;
      }
      else
      {
         fed_ports[tensor_id.node()].insert(tensor_id.index());
      }
&lt;/denchmark-code&gt;

This crash is fixed  and rerun again. It crashes again in "GetNodeStateOrCreateIt" .
&lt;denchmark-code&gt;#0  0x00007f348a9f4e46 in std::_Hashtable&lt;tensorflow::NodeDef const*, std::pair&lt;tensorflow::NodeDef const* const, tensorflow::grappler::NodeState&gt;, std::allocator&lt;std::pair&lt;tensorflow::NodeDef const* const, tensorflow::grappler::NodeState&gt; &gt;, std::__detail::_Select1st, std::equal_to&lt;tensorflow::NodeDef const*&gt;, std::hash&lt;tensorflow::NodeDef const*&gt;, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits&lt;false, false, true&gt; &gt;::_M_find_before_node(unsigned long, tensorflow::NodeDef const* const&amp;, unsigned long) const [clone .isra.856] ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#1  0x00007f348a9fe1f5 in tensorflow::grappler::VirtualScheduler::GetNodeStateOrCreateIt(tensorflow::NodeDef const*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#2  0x00007f348aa00e5d in tensorflow::grappler::VirtualScheduler::Init(tensorflow::grappler::GrapplerItem const*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#3  0x00007f348a9de98f in tensorflow::grappler::AnalyticalCostEstimator::PredictCosts(tensorflow::GraphDef const&amp;, tensorflow::RunMetadata*, tensorflow::grappler::Costs*) const ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#4  0x00007f348a9d732f in tensorflow::grappler::VirtualCluster::Run(tensorflow::grappler::GrapplerItem const&amp;, tensorflow::RunMetadata*) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so
#5  0x00007f348a965b0a in tensorflow::grappler::GraphMemory::InferStatically(std::unordered_map&lt;std::string, tensorflow::DeviceProperties, std::hash&lt;std::string&gt;, std::equal_to&lt;std::string&gt;, std::allocator&lt;std::pair&lt;std::string const, tensorflow::DeviceProperties&gt; &gt; &gt; const&amp;) ()
   from /myf12/Code/asr-kernel/third/tensorflow/libtensorflow_cc_v1.15_avx.so

&lt;/denchmark-code&gt;

After quickly fixing 2 bugs, it is unexpected and impossible for me to see theses "obvious bugs" in tensorflow release 1.15.  I strongly suspect it relates to some build configuration or running configuration.
Can you help check it? Thanks.
	</description>
	<comments>
		<comment id='1' author='fangminyu' date='2020-06-24T20:06:00Z'>
		Could you please attach the c_api.h file you use, and complete .cc file?
		</comment>
		<comment id='2' author='fangminyu' date='2020-06-24T22:08:16Z'>
		Also, can you try using 1.15.3 instead of 1.15.0?
		</comment>
		<comment id='3' author='fangminyu' date='2020-06-28T07:41:36Z'>
		&lt;denchmark-link:https://github.com/xldrx&gt;@xldrx&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/mihaimaruseac&gt;@mihaimaruseac&lt;/denchmark-link&gt;

Thank for your reply.
First of all, I would like to share latest progress:
In order to exclude factors introduced by compilation and runtime, I move my whole project into offcial Tensorflow Docker environment (tensorflow/serving:1.15.0-devel-gpu Ubuntu 16.04.6 LTS ). It means tensorflow_cc.so and my project binary are both compiled in the same compilation enviornment. Then I run my program for simple tf infer, and its result is correct. There is no crash.
Then I copy binary from Docker to my product environment (centos7), and use glibc 2.23 dependencies. Result is still correct as expectation.
I suspect it may lead to some conclusion:

problem may be introduced by compilation time (previously my binary is compiled in centos with the same GCC 5.4 and glibc 2.23 as official tensroflow dev Docker)
runtime is OK becuase binary (compiled in tensorflow docker) can run successful in centos environment.
my binary is working and code should be correct

Is there any comment for this?
		</comment>
		<comment id='4' author='fangminyu' date='2020-06-28T08:35:11Z'>
		&lt;denchmark-link:https://github.com/xldrx&gt;@xldrx&lt;/denchmark-link&gt;

Please refer to my last comment that probably indicates my code is working.
Anyway, I still provide my information as below.
I attach all 5 unchanged files ( &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4841915/c_api_tf_1.15.h.tar.gz&gt;c_api_tf_1.15.h.tar.gz&lt;/denchmark-link&gt;
 ) relate to c_api.h for branch tensorflow 1.15:

tensorflow/c/tf_attrtype.h
tensorflow/c/tf_datatype.h
tensorflow/c/tf_status.h
tensorflow/c/tf_tensor.h
tensorflow/c/c_api.h

For business resaon, I can not paste complete code. Here is main code which covers every step for calling function TF_* :
// get node info
int tf_utils_get_node(TF_Output * node, TF_Graph * graph,const char * op_name, int index)
{
    node-&gt;oper = TF_GraphOperationByName(graph, op_name);
    node-&gt;index = 0;
    if(node-&gt;oper == NULL)
    {
        printf("cannot find %s\n", op_name);
        return -1;
    }
    return 0;
}


// creaye session
TF_Session * tf_utils_new_session(TF_Graph * graph, const char * options_proto, int proto_len, TF_Status * status)
{
    TF_Session * sess;
    TF_SessionOptions* sess_opts = TF_NewSessionOptions();
    if(proto_len &gt; 0)
    {
        TF_SetConfig(sess_opts,(void*)options_proto, proto_len, status);

        if(TF_GetCode(status) != TF_OK)
        {
            printf("Can't set session options %s\n", TF_Message(status));
            TF_DeleteSessionOptions(sess_opts);
            return NULL;
        }
    }

    sess = TF_NewSession(graph, sess_opts, status);
    TF_DeleteSessionOptions(sess_opts);
    if(TF_GetCode(status) != TF_OK)
    {
        printf("Can't new session: %s\n", TF_Message(status));
        return NULL;
    }
    return sess;
}

TF_Buffer * buffer; // init is ignored
TF_Status *status = TF_NewStatus();
TF_Graph * graph = TF_NewGraph();
TF_ImportGraphDefOptions* opts = TF_NewImportGraphDefOptions();
TF_GraphImportGraphDef(graph, buffer, opts, status);
if(TF_GetCode(status) != TF_OK)
{
    printf("Can't import GraphDef:%s\n", TF_Message(status));
    return NULL;
}
TF_DeleteImportGraphDefOptions(opts);

// for loop to init TF_Output by getting operation by name
TF_Output feeds[4], fetches[4];
(for loop)
{
   if(tf_utils_get_node(&amp;(feeds[0], graph, "ac_input", 0) != 0)
   {
      printf("error...\n");
      return;
   }
}

// create session
TF_Session *sess = tf_utils_new_session(graph, NULL, 0, status);

// loop to init tensor for input
TF_Tensor *  input_ts_begin, input_ts, input_length_ts, input_flag, pre_state_ts;
int begin_input_buf_size, input_buf_size;// init by model info
(for loop)
{
    int64_t dims[] = {1, begin_input_buf_size};
    input_ts_begin = TF_AllocateTensor(TF_FLOAT, dims, 2, begin_input_buf_size * sizeof(float));
    
    dims[1] = input_buf_size;
    input_ts = TF_AllocateTensor(TF_FLOAT, dims, 2, input_buf_size * sizeof(float));
    // ignore others
}

// start warmup
int *input_length = TF_TensorData(input_length_ts);
int *input_flag = TF_TensorData(input_flag);
// create feed data
int64_t dims[] = {1, 0};
TF_Tensor *input_ts = NULL;
dims[1] = in_cols * num_sample;
input_ts = TF_AllocateTensor(TF_FLOAT, dims, 2,  dims[1] * sizeof(float));
*input_length = num_sample;
*input_flag = 0;
float* input_buf; //init by real input data
memcpy(TF_TensorData(input_ts), input_buf, sizeof(float)*num_sample);

TF_Tensor* feedValues[] = {input_ts, input_length_ts, pre_state_ts, input_flag};
TF_Tensor* fetchValues[2] = {0};
// crash occurs here!!!
TF_SessionRun(sess,
        NULL, // Run options.
        feeds, feedValues,  num_inputs, // Input tensors, input tensor values, number of inputs.
        fetches, fetchValues, num_outputs, // Output tensors, output tensor values, number of outputs.
        NULL, 0, // Target operations, number of targets.
        NULL, // Run metadata.
        status // Output status.
        );

In my previous comment, crash occurs in TF_SessionRun. Can you help double-check whether it is OK?
		</comment>
		<comment id='5' author='fangminyu' date='2020-06-28T16:17:42Z'>
		You have to build your application using the same C/C++/python toolchain as the one TF was build with. That's why building in the TF container worked.
This requirement is because of &lt;denchmark-link:https://learnlistt.com/list/understanding-c-abi-compatibility&gt;ABI compatiblity&lt;/denchmark-link&gt;
 issues.
		</comment>
		<comment id='6' author='fangminyu' date='2020-06-29T02:32:44Z'>
		&lt;denchmark-link:https://github.com/mihaimaruseac&gt;@mihaimaruseac&lt;/denchmark-link&gt;
  As I can figured out it in Docker which is acceptable for us, should I close it?
		</comment>
		<comment id='7' author='fangminyu' date='2020-06-29T15:48:30Z'>
		I think so, this seems to be caused by ABI breakages and using Docker should go around those issues.
		</comment>
		<comment id='8' author='fangminyu' date='2020-06-29T16:51:23Z'>
		&lt;denchmark-link:https://github.com/fangminyu&gt;@fangminyu&lt;/denchmark-link&gt;
 Thank for the additional information. It seems it is safe to close this issue.
		</comment>
		<comment id='9' author='fangminyu' date='2020-06-29T16:51:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40671&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40671&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>