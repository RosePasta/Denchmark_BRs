<bug id='36400' author='MarcelSimon' open_date='2020-02-01T06:51:46Z' closed_time='2020-09-17T09:01:57Z'>
	<summary>Metrics passed to on_batch_end(...) in Keras are inconsistent</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Uubntu 18.04
TensorFlow installed from (source or binary): pip tensorflow-gpu
TensorFlow version (use command below): 2.1
Python version: 3.7
CUDA/cuDNN version:
GPU model and memory: K80
Exact command to reproduce: see code below

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

The method on_batch_end of tf.keras.callbacks.Callback receives a parameter logs, which contains, e.g., loss and accuracy. While loss is the actual loss of the current batch, accuracy is a moving average and the same as printed by the progressbar of model.fit(...).
The expected behavior is a consistent behavior, i.e. either both values are moving average or both are the actual batch values. I don't have a clear preference for either of both, but the moving average probably creates the least amount of confusion as the is consistent with the progress bar and the function on_epoch_end.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

The following snipped shows the current bevior:
    from tensorflow import keras
    from tensorflow.keras import layers

    inputs = keras.Input(shape=(784,), name='digits')
    x = layers.Dense(4*4096, activation='relu', name='dense_1')(inputs)
    x = layers.Dense(4*4096, activation='relu', name='dense_2')(x)
    x = layers.Dense(4*4096, activation='relu', name='dense_3')(x)
    outputs = layers.Dense(10, activation='softmax', name='predictions')(x)

    model = keras.Model(inputs=inputs, outputs=outputs)
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train = x_train.reshape(60000, 784).astype('float32') / 255
    y_train = y_train.astype('float32')

    class PrintStatsCallback(keras.callbacks.Callback):
        def on_batch_end(self, epoch, logs=None):
            print('\nON_BATCH_END: loss: {loss:.4f} accuracy: {accuracy:.4f}'.format_map(logs))

    # Specify the training configuration (optimizer, loss, metrics)
    model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    model.fit(x_train, y_train,
              steps_per_epoch=10,
              batch_size=1024,
              callbacks=[PrintStatsCallback()])
The output is currently as follows:
&lt;denchmark-code&gt;    Train on 60000 samples
    
    ON_BATCH_END: loss: 2.3004 accuracy: 0.1543
     1024/60000 [..............................] - ETA: 1:18 - loss: 2.3004 - accuracy: 0.1543
    ON_BATCH_END: loss: 2.2151 accuracy: 0.2715
     2048/60000 [&gt;.............................] - ETA: 1:11 - loss: 2.2578 - accuracy: 0.2715
    ON_BATCH_END: loss: 2.1440 accuracy: 0.3613
     3072/60000 [&gt;.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613
    ...
&lt;/denchmark-code&gt;

For example, compare the last two lines:
ON_BATCH_END: loss: 2.1440 accuracy: 0.3613
to
3072/60000 [&gt;.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613
The accuracy of both on_batch_end and the progress bar are identical, but the loss value differs as the loss value is not a moving average.
	</description>
	<comments>
		<comment id='1' author='MarcelSimon' date='2020-02-04T09:17:07Z'>
		I have tried on colab with TF version 2.1.0-rc2, 2.2.0-dev20200203 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/7d88b982abb771879829ca3381ae581c/untitled615.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='MarcelSimon' date='2020-04-25T01:32:19Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 Why not providing a parameter (in the  method) that allows you to control what the user sees in the progress bar? Similarly, the callbacks should have options to specify what the user sees and not.
This should at least be well-documented. It's not documented anywhere what the progress bar is actually displaying!!
I've just spent 3 days trying to understand an apparent a weird behaviour, and it turned out that this was just Keras printing a moving average in the progress bar (rather than the actual loss for the single step of the epoch).
		</comment>
		<comment id='3' author='MarcelSimon' date='2020-09-16T22:46:14Z'>
		&lt;denchmark-link:https://github.com/MarcelSimon&gt;@MarcelSimon&lt;/denchmark-link&gt;
 I think this was resolved in recent . Can you please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/1904128c076a3f65e34be9fb74525f89/untitled615.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
The batch_end values are different from the epoch results.
&lt;denchmark-code&gt;ON_BATCH_END: loss: 2.3029 accuracy: 0.0898
 1/10 [==&gt;...........................] - ETA: 12:49 - loss: 2.3029 - accuracy: 0.0898
ON_BATCH_END: loss: 2.2617 accuracy: 0.1714
 2/10 [=====&gt;........................] - ETA: 11:11 - loss: 2.2823 - accuracy: 0.1306
ON_BATCH_END: loss: 2.2223 accuracy: 0.2292
 3/10 [========&gt;.....................] - ETA: 9:47 - loss: 2.2623 - accuracy: 0.1635 
ON_BATCH_END: loss: 2.1837 accuracy: 0.3313
 4/10 [===========&gt;..................] - ETA: 8:23 - loss: 2.2427 - accuracy: 0.2054
ON_BATCH_END: loss: 2.1452 accuracy: 0.4010
 5/10 [==============&gt;...............] - ETA: 7:00 - loss: 2.2232 - accuracy: 0.2445
ON_BATCH_END: loss: 2.1072 accuracy: 0.4518
 6/10 [=================&gt;............] - ETA: 5:35 - loss: 2.2039 - accuracy: 0.2791
ON_BATCH_END: loss: 2.0682 accuracy: 0.4915
 7/10 [====================&gt;.........] - ETA: 4:11 - loss: 2.1845 - accuracy: 0.3094
ON_BATCH_END: loss: 2.0298 accuracy: 0.5209
 8/10 [=======================&gt;......] - ETA: 2:47 - loss: 2.1651 - accuracy: 0.3359
ON_BATCH_END: loss: 1.9884 accuracy: 0.5462
 9/10 [==========================&gt;...] - ETA: 1:23 - loss: 2.1455 - accuracy: 0.3592
ON_BATCH_END: loss: 1.9457 accuracy: 0.5699
10/10 [==============================] - 839s 84s/step - loss: 2.1092 - accuracy: 0.3975
&lt;tensorflow.python.keras.callbacks.History at 0x7f6fc8b59518&gt;
&lt;/denchmark-code&gt;

Please verify once and close the issue if this was resolved for you. thanks!
		</comment>
		<comment id='4' author='MarcelSimon' date='2020-09-17T09:01:57Z'>
		Looks good, thanks!
		</comment>
		<comment id='5' author='MarcelSimon' date='2020-09-17T09:01:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36400&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36400&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>