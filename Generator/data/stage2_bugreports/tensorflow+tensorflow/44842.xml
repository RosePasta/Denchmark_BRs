<bug id='44842' author='RomanGirin' open_date='2020-11-13T15:35:33Z' closed_time='2020-11-14T22:49:39Z'>
	<summary>Error while trying to load model's weights for fine-tuning (transfer learning)</summary>
	<description>
System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): binary (no errors during installation)
TensorFlow version: 2.3.1 (with GPU support)
Python version: 3.7.5
CUDA/cuDNN version: 10.1
GPU model and memory: RTX 1660 Ti 6.00GB
Describe the current behavior
I reproduce my issue on oversimplified code.
I'm trying to train model for one dataset (say, on MNIST) and then fine-tune it on another (with different number of classes, say 5).
After I have created model for '5 classes task' I'm trying to load the weights from original model using
model.load_weights(path, by_name=True, skip_mismatch=True)
But I got an error:
ValueError: Shapes (5,) and (10,) are incompatible
I hoped that setting the params by_name=True, skip_mismatch=True will be enough to handle differences between the models.
How to correct load weights for slightly different model?
Standalone code to reproduce the issue
Oversimplified script to recreate the trouble
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
import os

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation='softmax')])

model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam())

batch_size = 128
epochs = 3
model.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test))

ver = 0
path = os.path.join(os.getcwd(), str(ver))
model.save_weights(path)


different_model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(5, activation='softmax')]) # say, we change the number of classes here for further fine-tuning

# here I got an error!!!!!!! isn't by_name=True, skip_mismatch=True not enough?
different_model.load_weights(path, by_name=True, skip_mismatch=True)

# fine-tuning/transfer learning is supposed here for some application where we classify 5 cls

print('loaded!')
&lt;/denchmark-code&gt;

It's a serious and urgent problem for my project!
Any help is appreciated!!!
	</description>
	<comments>
		<comment id='1' author='RomanGirin' date='2020-11-14T12:52:24Z'>
		I think this is a project specific support request not a bug. Please close this and post on our &lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;Stackoverflow channel&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='RomanGirin' date='2020-11-14T22:49:39Z'>
		&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 I wouldn't say it's project specific. The issue described entirely in term of MNIST and simple 'standard' CNN (in fact, you can use just 'one-conv-layer-followed-by-dense-classifier' network to reproduce it)
Found work-around loading weights before adding layers which may cause shape mismatch. More about loading checkpoints in TF's docs here &lt;denchmark-link:https://www.tensorflow.org/guide/checkpoint#loading_mechanics&gt;https://www.tensorflow.org/guide/checkpoint#loading_mechanics&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='RomanGirin' date='2020-11-14T22:49:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44842&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44842&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='RomanGirin' date='2020-11-14T23:14:25Z'>
		
(in fact, you can use just 'one-conv-layer-followed-by-dense-classifier' network to reproduce it)

Yes it is what I meant, but in you case was a code snippet, and I also I meant that it is not bug as you have used a bug template for this issue.
It could be a bug if you are confused by the error message and you want to improve it.
But seems to me a support request on your code example and it is why I suggest you to use our Stackoverflow channel.
		</comment>
		<comment id='5' author='RomanGirin' date='2020-11-15T00:24:26Z'>
		Also if you use h5ext filename format in your save and load path it will run fine as is
		</comment>
	</comments>
</bug>