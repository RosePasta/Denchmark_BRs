<bug id='34579' author='awaizman1' open_date='2019-11-25T09:32:25Z' closed_time='2019-12-04T03:40:28Z'>
	<summary>Suspected memory leak - model.predict</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NA
TensorFlow installed from (source or binary):
binary wheel via PyPI
TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d382ca 2.0.0
Python version:
3.6.8
Bazel version (if compiling from source):
NA
GCC/Compiler version (if compiling from source):
NA
CUDA/cuDNN version:
NA
GPU model and memory:
NA

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
I'm suspecting a memory leak on keras model.predict (running on cpu only).
Performing model.predict in an infinite loop - demonstrates memory leak trend (~400MB in 30min, please see image below).
This trend happens even though I call gc.collect() on every iteration.
In addition - using gc.get_objects() I can see that every iteration leaks exactly 1298 new objects. Using objgraph the leaked objects are:
tuple                          751101      +741
list                           202237      +197
dict                           155046      +137
Tensor                          26665       +27
TF_Output                       26621       +27
Operation                       26686       +27
_InputList                      26686       +27
Dimension                       15675       +16
set                             18103       +15
TraceableStack                  11629       +12
TensorShape                     10845       +11
builtin_function_or_method      10757        +9
OrderedDict                      8799        +9
weakref                         14739        +6
TensorSpec                       3873        +4
Condition                        2926        +3
deque                            2930        +3
_local                           2925        +3
ObjectIdentitySet                2909        +3
ScopedTFGraph                    2909        +3
GroupLock                        2909        +3
FuncGraph                        2906        +3
ObjectIdentityWeakSet            2908        +3
_EagerDefinedFunction            2904        +3
ScopedTFFunction                 2904        +3
_EagerDefinedFunctionDeleter     2904        +3
Describe the expected behavior
Memory shouldn't increase over time when calling gc.collect() nor should there be objects leaks per prediction.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
from collections import defaultdict
import gc
import objgraph

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)


def mem_stat():
    
    objs = gc.get_objects()
    print("total objects count", len(objs))
    
c = 1
while True:
    print("----------- iter", c)

    model.predict(x_test)
    
    gc.collect()

    print("mem stat after predict:")
    mem_stat()
    objgraph.show_growth(limit=30)
    c += 1

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
&lt;denchmark-link:https://user-images.githubusercontent.com/17004015/69528569-27b63980-0f77-11ea-8db3-ada1688c4d3b.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='awaizman1' date='2019-11-25T11:01:27Z'>
		This seems to be related to &lt;denchmark-link:https://github.com/keras-team/keras/issues/13118&gt;this Keras issue&lt;/denchmark-link&gt;
. It's hard to say though whether the bug is rooted in Keras or TensorFlow.
		</comment>
		<comment id='2' author='awaizman1' date='2019-11-26T05:59:04Z'>
		I have tried on colab with TF version 2.0 ,2.1.0-dev20191125 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/255d880fc37a666d928184da1579fb88/untitled410.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='awaizman1' date='2019-11-26T18:57:48Z'>
		Hi &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
,
I run your colab notebook and it seems that at least in term of objects leak - version 2.1.0dev is stable (I can't see addition of python objects per iteration).
Can you please approve? If you believe it solved in 2.1.0 do you think there will be a fix in 2.0 too or should I wait for 2.1.0?
Thanks!
		</comment>
		<comment id='4' author='awaizman1' date='2019-12-04T03:40:28Z'>
		&lt;denchmark-link:https://github.com/awaizman1&gt;@awaizman1&lt;/denchmark-link&gt;
 you are right, the issues seems to be resolved now. Thank you!
		</comment>
		<comment id='5' author='awaizman1' date='2019-12-04T03:40:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34579&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34579&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='awaizman1' date='2020-01-17T06:43:50Z'>
		model.predict_on_batch fix for me.
		</comment>
	</comments>
</bug>