<bug id='36547' author='jmsmdy' open_date='2020-02-07T16:19:19Z' closed_time='2020-08-07T00:33:55Z'>
	<summary>Documentation error for tf.signal.frame</summary>
	<description>
&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;




tensorflow/tensorflow/python/ops/signal/shape_ops.py


        Lines 55 to 199
      in
      cf7fcf1






 @tf_export("signal.frame") 



 def frame(signal, frame_length, frame_step, pad_end=False, pad_value=0, axis=-1, 



 name=None): 



 """Expands `signal`'s `axis` dimension into frames of `frame_length`. 



  



   Slides a window of size `frame_length` over `signal`'s `axis` dimension 



   with a stride of `frame_step`, replacing the `axis` dimension with 



   `[frames, frame_length]` frames. 



  



   If `pad_end` is True, window positions that are past the end of the `axis` 



   dimension are padded with `pad_value` until the window moves fully past the 



   end of the dimension. Otherwise, only window positions that fully overlap the 



   `axis` dimension are produced. 



  



   For example: 



  



   ```python 



   # A batch size 3 tensor of 9152 audio samples. 



   audio = tf.random.normal([3, 9152]) 



  



   # Compute overlapping frames of length 512 with a step of 180 (frames overlap 



   # by 332 samples). By default, only 50 frames are generated since the last 



   # 152 samples do not form a full frame. 



   frames = tf.signal.frame(audio, 512, 180) 



   frames.shape.assert_is_compatible_with([3, 50, 512]) 



  



   # When pad_end is enabled, the final frame is kept (padded with zeros). 



   frames = tf.signal.frame(audio, 512, 180, pad_end=True) 



   frames.shape.assert_is_compatible_with([3, 51, 512]) 



   ``` 



  



   Args: 



     signal: A `[..., samples, ...]` `Tensor`. The rank and dimensions 



       may be unknown. Rank must be at least 1. 



     frame_length: The frame length in samples. An integer or scalar `Tensor`. 



     frame_step: The frame hop size in samples. An integer or scalar `Tensor`. 



     pad_end: Whether to pad the end of `signal` with `pad_value`. 



     pad_value: An optional scalar `Tensor` to use where the input signal 



       does not exist when `pad_end` is True. 



     axis: A scalar integer `Tensor` indicating the axis to frame. Defaults to 



       the last axis. Supports negative values for indexing from the end. 



     name: An optional name for the operation. 



  



   Returns: 



     A `Tensor` of frames with shape `[..., frames, frame_length, ...]`. 



  



   Raises: 



     ValueError: If `frame_length`, `frame_step`, `pad_value`, or `axis` are not 



       scalar. 



   """ 



 with ops.name_scope(name, "frame", [signal, frame_length, frame_step, 



 pad_value]): 



 signal = ops.convert_to_tensor(signal, name="signal") 



 frame_length = ops.convert_to_tensor(frame_length, name="frame_length") 



 frame_step = ops.convert_to_tensor(frame_step, name="frame_step") 



 axis = ops.convert_to_tensor(axis, name="axis") 



 



 signal.shape.with_rank_at_least(1) 



 frame_length.shape.assert_has_rank(0) 



 frame_step.shape.assert_has_rank(0) 



 axis.shape.assert_has_rank(0) 



 



 result_shape = _infer_frame_shape(signal, frame_length, frame_step, pad_end, 



 axis) 



 



 # Axis can be negative. Convert it to positive. 



 signal_rank = array_ops.rank(signal) 



 axis = math_ops.range(signal_rank)[axis] 



 



 signal_shape = array_ops.shape(signal) 



 outer_dimensions, length_samples, inner_dimensions = array_ops.split( 



 signal_shape, [axis, 1, signal_rank - 1 - axis]) 



 length_samples = array_ops.reshape(length_samples, []) 



 num_outer_dimensions = array_ops.size(outer_dimensions) 



 num_inner_dimensions = array_ops.size(inner_dimensions) 



 



 # If padding is requested, pad the input signal tensor with pad_value. 



 if pad_end: 



 pad_value = ops.convert_to_tensor(pad_value, signal.dtype) 



 pad_value.shape.assert_has_rank(0) 



 



 # Calculate number of frames, using double negatives to round up. 



 num_frames = -(-length_samples // frame_step) 



 



 # Pad the signal by up to frame_length samples based on how many samples 



 # are remaining starting from last_frame_position. 



 pad_samples = math_ops.maximum( 



 0, frame_length + frame_step * (num_frames - 1) - length_samples) 



 



 # Pad the inner dimension of signal by pad_samples. 



 paddings = array_ops.concat( 



           [array_ops.zeros([num_outer_dimensions, 2], dtype=pad_samples.dtype), 



            [[0, pad_samples]], 



 array_ops.zeros([num_inner_dimensions, 2], dtype=pad_samples.dtype)], 



 0) 



 signal = array_ops.pad(signal, paddings, constant_values=pad_value) 



 



 signal_shape = array_ops.shape(signal) 



 length_samples = signal_shape[axis] 



 else: 



 num_frames = math_ops.maximum( 



 0, 1 + (length_samples - frame_length) // frame_step) 



 



 subframe_length = util_ops.gcd(frame_length, frame_step) 



 subframes_per_frame = frame_length // subframe_length 



 subframes_per_hop = frame_step // subframe_length 



 num_subframes = length_samples // subframe_length 



 



 slice_shape = array_ops.concat([outer_dimensions, 



                                     [num_subframes * subframe_length], 



 inner_dimensions], 0) 



 subframe_shape = array_ops.concat([outer_dimensions, 



                                        [num_subframes, subframe_length], 



 inner_dimensions], 0) 



 subframes = array_ops.reshape(array_ops.strided_slice( 



 signal, array_ops.zeros_like(signal_shape), 



 slice_shape), subframe_shape) 



 



 # frame_selector is a [num_frames, subframes_per_frame] tensor 



 # that indexes into the appropriate frame in subframes. For example: 



 # [[0, 0, 0, 0], [2, 2, 2, 2], [4, 4, 4, 4]] 



 frame_selector = array_ops.reshape( 



 math_ops.range(num_frames) * subframes_per_hop, [num_frames, 1]) 



 



 # subframe_selector is a [num_frames, subframes_per_frame] tensor 



 # that indexes into the appropriate subframe within a frame. For example: 



 # [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]] 



 subframe_selector = array_ops.reshape( 



 math_ops.range(subframes_per_frame), [1, subframes_per_frame]) 



 



 # Adding the 2 selector tensors together produces a [num_frames, 



 # subframes_per_frame] tensor of indices to use with tf.gather to select 



 # subframes from subframes. We then reshape the inner-most 



 # subframes_per_frame dimension to stitch the subframes together into 



 # frames. For example: [[0, 1, 2, 3], [2, 3, 4, 5], [4, 5, 6, 7]]. 



 selector = frame_selector + subframe_selector 



 



 frames = array_ops.reshape( 



 array_ops.gather(subframes, selector, axis=axis), 



 array_ops.concat([outer_dimensions, [num_frames, frame_length], 



 inner_dimensions], 0)) 



 



 if result_shape: 



 frames.set_shape(result_shape) 



 return frames 





Documentation:
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/signal/frame&gt;https://www.tensorflow.org/api_docs/python/tf/signal/frame&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

In the following example, the count of frames generated with pad_end=False is incorrect
&lt;denchmark-code&gt;# A batch size 3 tensor of 9152 audio samples.
audio = tf.random.normal([3, 9152])

# Compute overlapping frames of length 512 with a step of 180 (frames overlap
# by 332 samples). By default, only 50 frames are generated since the last
# 152 samples do not form a full frame.
frames = tf.signal.frame(audio, 512, 180)
frames.shape.assert_is_compatible_with([3, 50, 512])
&lt;/denchmark-code&gt;

In fact, only 49 frames are generated with pad_true=False (the default).
&lt;denchmark-h:h3&gt;Clear description&lt;/denchmark-h&gt;

Suppose we are given a tensor x with x.shape[-1] == N, a frame_length == K, and a frame_step == k.
To compute tf.signal.frame(x, frame_length, frame_step) (here default axis=-1 and pad_end=False), we could equivalently stack along axis -2 the following list of slices:
&lt;denchmark-code&gt;[x[..., 0:K],
 x[..., k:K+k],
 x[..., 2*k:K+2*k],
 x[..., 3*k:K+3*k],
 ...
 x[..., j*k:K+j*k]]
&lt;/denchmark-code&gt;

where j is the maximum integer such that K+j*k &lt;= N.
We can compute that j = (N - K) // k, so the number of slices in this list is j+1 = 1 + (N - K) // k.
In the example here, N = 9152, K=512, k=180, so:
&lt;denchmark-code&gt;j+1 = 1 + (9152-512) // 180 = 1 + 8640 // 180 = 1+48 = 49
&lt;/denchmark-code&gt;

Thus in the example given, the return shape should be [3, 49, 512], not [3, 50, 512]. Attached is a screenshot showing that this is indeed the behavior of tf.signal.frame, so it is an error in the documentation not in the code.
&lt;denchmark-link:https://user-images.githubusercontent.com/47697814/74045729-497e6480-499b-11ea-9107-12305554ee18.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Submit a pull request?&lt;/denchmark-h&gt;

I am planning to submit a pull request.
	</description>
	<comments>
		<comment id='1' author='jmsmdy' date='2020-04-19T16:53:43Z'>
		&lt;denchmark-link:https://github.com/jmsmdy&gt;@jmsmdy&lt;/denchmark-link&gt;

as there is a pr to monitor this issue, can we close this issue.
		</comment>
		<comment id='2' author='jmsmdy' date='2020-08-07T00:33:55Z'>
		Closing this issue since the associated PR has been merged.
It's effective with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/ops/signal/shape_ops.py#L58-L216&gt;TF 2.3&lt;/denchmark-link&gt;
 documentation.
Thanks!
		</comment>
	</comments>
</bug>