<bug id='6509' author='SergeyBykov1' open_date='2016-12-26T23:47:13Z' closed_time='2017-02-22T23:33:03Z'>
	<summary>Issue with tf.one_hot() in 0.12.0 in GPU mode (CUDA_ERROR_ILLEGAL_ADDRESS)</summary>
	<description>
I'm using a LeNet-5 mnist example from Udacity's course. Link to the source code is below.
Training works ok on a CPU (config = tf.ConfigProto(device_count = {'GPU': 0})),
but fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' error:

I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.01GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
Training...
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected Event status: 1

I have reproduced same error on two setups.
Environment 1 (Home PC):

windows 10;
latest anaconda 4.2.0, python 3.5;
cuda 8
cudnn 5.1 (for win10)
tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)
GeForce GTX 1060 6Gb

Environment 2 (Work PC):

windows 7;
latest anaconda 4.2.0, python 3.5;
cuda 8
cudnn 5.1 (for win7)
tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)
GeForce GTX 660 3Gb

I'm sharing two scripts with minor changes that allow a workaround:
&lt;denchmark-link:https://drive.google.com/open?id=0B6jkkqMOGy5cNHh3TVpxU283Ykk&gt;https://drive.google.com/open?id=0B6jkkqMOGy5cNHh3TVpxU283Ykk&lt;/denchmark-link&gt;

Main difference:
Script from example that crashes (LabLenetBad.py) uses raw mnist label data with the tf.one_hot() call.
The workaround (LabLenetGood.py) reads mnist data with (one_hot=True) flag and does not use tf.one_hot() call on the Y placeholder.
I think that tf.one_hot does not work properly on the gpu.
	</description>
	<comments>
		<comment id='1' author='SergeyBykov1' date='2016-12-27T06:16:56Z'>
		&lt;denchmark-link:https://github.com/vlfeat/matconvnet/issues/65&gt;vlfeat/matconvnet#65&lt;/denchmark-link&gt;

In this issue, I see that some people were able to go around the problem by changing their drivers.
Can it be the same issue here?
		</comment>
		<comment id='2' author='SergeyBykov1' date='2016-12-27T13:31:09Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 I've updated Nvidia's driver to the most recent version (376.33) on my Work PC.
The issue still occurs.
I'd like to note that sometimes it triggers only CUDA_ERROR_ILLEGAL_ADDRESS error.
But sometimes it triggers CUDA_ERROR_ILLEGAL_ADDRESS + some cudnn errors.

E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to que
ry event: CUDA_ERROR_ILLEGAL_ADDRESS
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected Event status: 1
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_IN
TERNAL_ERROR
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_B
AD_PARAM
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\kernels\conv_ops.cc:532] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(
&amp;algorithms)

P.S. I've written a similar comment already, but it has strangely disappeared from the topic.
		</comment>
		<comment id='3' author='SergeyBykov1' date='2016-12-27T22:50:51Z'>
		I know there is a problem with one_hot(T=uint8) that results in the CUDA_ERROR_ILLEGAL_ADDRESS.
Looked at this in the past but found nothing obvious in the source.
Let me attach a debugger and see if we find this.
This happens only for T=uint8, int32 will work fine.
		</comment>
		<comment id='4' author='SergeyBykov1' date='2017-01-03T18:33:43Z'>
		Thanks for sharing!! I had the same problem and when I replace the tf.one_hot by the following hand-written implementation it finally works.
#instead of    one_hot_y = tf.one_hot(y, 43)
num_labels = 43
sparse_labels = tf.reshape(y, [-1, 1])
derived_size = tf.shape(sparse_labels)[0]
indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])
concated = tf.concat(1, [indices, sparse_labels])
outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])
one_hot_y = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)
		</comment>
		<comment id='5' author='SergeyBykov1' date='2017-01-05T23:28:44Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 any idea what the problem is here?
		</comment>
		<comment id='6' author='SergeyBykov1' date='2017-01-05T23:47:36Z'>
		&lt;denchmark-h:h2&gt;a simple repro case attached (only happens on windows/gpu).
I'm think this showed only for uint8 in the past but now I see it also for int32.&lt;/denchmark-h&gt;

import tensorflow as tf
import numpy as np
data = np.zeros(shape=(3, 5), dtype='int32')
input = tf.placeholder(tf.int32, data.shape, name="input")
one_hot_op = tf.one_hot(input, depth=3, dtype=tf.float32)
init = tf.initialize_all_variables()
with tf.Session() as sess:
sess.run(init)
print(sess.run(one_hot_op, feed_dict = {input : data}))
		</comment>
		<comment id='7' author='SergeyBykov1' date='2017-01-05T23:54:49Z'>
		CC &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 (for windows) &lt;denchmark-link:https://github.com/zheng-xq&gt;@zheng-xq&lt;/denchmark-link&gt;
 (for CUDA, in case error message looks familiar)
		</comment>
		<comment id='8' author='SergeyBykov1' date='2017-01-06T07:11:13Z'>
		Could be a bug in eigens generator API cuda impl that only shows in Windows.
		</comment>
		<comment id='9' author='SergeyBykov1' date='2017-01-06T07:11:40Z'>
		Do you get the same issue with tf.reverse_sequence?
		</comment>
		<comment id='10' author='SergeyBykov1' date='2017-01-06T16:11:02Z'>
		tf.reverse_sequence works ok, at least tensorflow/python/kernel_tests/reverse_sequence_op_test.py does pass.
tensorflow/python/kernel_tests/diag_op_test.py fails.
I can collect some info with nvidia debugger ... takes me a little: need to recompile with enough symbol info.
		</comment>
		<comment id='11' author='SergeyBykov1' date='2017-01-06T19:40:40Z'>
		Merging duplicate issues.
&lt;denchmark-link:https://github.com/weixsong&gt;@weixsong&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/aclaussen1&gt;@aclaussen1&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/buaahsh&gt;@buaahsh&lt;/denchmark-link&gt;

Quoting some information from a duplicate:
(&lt;denchmark-link:https://github.com/buaahsh&gt;@buaahsh&lt;/denchmark-link&gt;
)

Here is my code:
with tf.Session() as sess:
with tf.device("/cpu:0"):
x = tf.ones(shape=[3, 3])
x_diag = tf.diag_part(x)
x_diag_matrix = tf.matrix_diag(x_diag)
print(sess.run(x_diag_matrix))
It works ok on a CPU but fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' &gt;error:
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:27:00.0
Total memory: 11.16GiB
Free memory: 11.09GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0: Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40m, pci bus id: 0000:27:00.0)
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0. Your kernel may not have been built with NUMA support.
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected &gt;Event status: 1
I have tried
x = tf.ones(shape=[3, 3])
x_diag = tf.diag_part(x)
and x_diag_matrix = tf.matrix_diag([1., 1., 1.]) , Both work ok in a GPU mode. Maybe the tensor couldn't &gt;be input of tf.matrix_diag() in a Windows GPU mode?

		</comment>
		<comment id='12' author='SergeyBykov1' date='2017-01-07T00:43:57Z'>
		not funny: after recompiling the cuda kernels with -G one_hot works now.
The diag_op still dies:

CUmodule 1c133fcdc00 - [4] const operator()_ - Line 40	CUDA
CUmodule 1c133fcdc00 - [3] const coeff - Line 130	CUDA
CUmodule 1c133fcdc00 - [2] evalScalar - Line 136	CUDA
CUmodule 1c133fcdc00 - [1] run - Line 209	CUDA
CUmodule 1c133fcdc00 - [0] EigenMetaKernel&lt;TensorEvaluator&lt;TensorAssignOp&lt;TensorMap&lt;Tensor&lt;double,int=2,int=1,__int64&gt;,int=16,MakePointer&gt;,TensorGeneratorOp&lt;MatrixDiagPartGenerator,TensorMap&lt;Tensor&lt;double,int=2,int=1,__int64&gt;,int=16,MakePointer&gt; const &gt; const &gt; const ,GpuDevice&gt;,__int64&gt; - Line 244	CUDA

I'll spend some more time on this later today.
		</comment>
		<comment id='13' author='SergeyBykov1' date='2017-01-08T01:34:43Z'>
		Derek, looks like a Windows cuda / eigen issue.
		</comment>
		<comment id='14' author='SergeyBykov1' date='2017-01-08T01:35:25Z'>
		Sergey, can you run the job with cuda-memcheck?  You may have to recompile -c dbg.  Not sure.
		</comment>
		<comment id='15' author='SergeyBykov1' date='2017-01-10T10:07:57Z'>
		I'm facing the same issue, I ran the cuda-memcheck on the job and I see a lot of null pointer accesses from EigenMetaKernel.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/695756/error_log.txt&gt;error_log.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='SergeyBykov1' date='2017-01-12T09:41:31Z'>
		Wondering if anyone is looking into this. An update would be good.
		</comment>
		<comment id='17' author='SergeyBykov1' date='2017-01-12T15:52:55Z'>
		I'm looking at but have not had luck yet. My biggest issue is that when I compile the kernels with full debug info my repro case doesn't fail anymore. But I found that the one_hot tests in tensorflow/python/kernel_tests/one_hot_op_test.py.py can still repro a crash and before it crashes the results of tests are already wrong. When it crashes the arguments in EigenMetaKernel-&gt;EigenMetaKernelEval are wrong, like step_size is some very high number.
I'll spend some more time on it today and might need help if I don't find something.
		</comment>
		<comment id='18' author='SergeyBykov1' date='2017-01-12T18:05:04Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/benoitsteiner&gt;@benoitsteiner&lt;/denchmark-link&gt;

Adding for possible issues in Eigen.
		</comment>
		<comment id='19' author='SergeyBykov1' date='2017-01-13T22:13:59Z'>
		A small update here: I've managed to reproduce the failures, but I'll have to rely on people more experienced in Eigen/CUDA/MSVC to figure out why this op is being compiled to incorrect code on Windows.
In the mean time, I've sent out &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/6822&gt;#6822&lt;/denchmark-link&gt;
, which disables the broken GPU kernels for  (and some  and , which seem to have the same failure mode, and both also use the generator interface), while we work on a fix.
		</comment>
		<comment id='20' author='SergeyBykov1' date='2017-02-01T12:21:52Z'>
		Hi guys, what's the status on this?
I've encountered the same bug on Windows/GPU with a GTX Titan Black.
When I replaced
target_one_hot=tf.onehot(targets,vocab_size_targets,dtype=tf.float32)
with the workaround by name-name
it worked just fine.
here's the function wrapper i used for the workaround:
&lt;denchmark-code&gt;def one_hot_patch(x,depth):
                #workaround by name-name
                sparse_labels=tf.reshape(x,[-1,1])
                derived_size=tf.shape(sparse_labels)[0]
                indices=tf.reshape(tf.range(0,derived_size,1),[-1,1])
                concated=tf.concat(1,[indices,sparse_labels])
                outshape=tf.concat(0,[tf.reshape(derived_size,[1]),tf.reshape(depth,[1])])
                return tf.sparse_to_dense(concated, outshape,1.0,0.0)
target_one_hot=one_hot_patch(targets,vocab_size_targets)
&lt;/denchmark-code&gt;

my targets and vocab_size_targets are both tf.int32 Tensors.
I'm currently on r0.12 (pip installation) with cuda 8.0 and CuDNN 5.1
		</comment>
		<comment id='21' author='SergeyBykov1' date='2017-02-01T15:31:39Z'>
		&lt;denchmark-link:https://github.com/Pyrestone&gt;@Pyrestone&lt;/denchmark-link&gt;
 We disabled the broken GPU kernel for  in the Windows build, so if you upgrade to 1.0.0rc0 you should no longer need the patch.
		</comment>
		<comment id='22' author='SergeyBykov1' date='2017-02-07T02:31:15Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 Then the problems are now gone?  (I am using win10 64bit tf-gpu-0.12.1 with cuda 8.0 and CuDNN 5.1) I found that this problem(InternalError: Blas SGEMM launch failed :~) remains even after upgrading tf version to 1.0.0.rc1.
I encountered similar issue with 0.12.1 and tried suggested get-arounds and found the results are strange. &lt;denchmark-link:https://github.com/jaejun-yoo/Three-ways-to-avoid-tf.one_hot-function-&gt;Here&lt;/denchmark-link&gt;
 you can find three get-arounds I have tried to avoid using tf.one_hot().
I found that the substitutes worked fine(give the same output with one-hot) but the final results (came out from the script) were somewhat strange or wrong... I doubt that this is due to the other issue cuz I have only changed the part for one_hot function in the code which worked fine before it. Maybe my fault somewhere?... :(
		</comment>
		<comment id='23' author='SergeyBykov1' date='2017-02-09T05:22:11Z'>
		I have the same issue with tf.one_hot() . Here is my settings:

Windows 10
NVIDIA GeForce GTX 1070
Cuda 8.0
CuDnn 5.1
TensorFlow 0.12

Error:    Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
Kernel died
		</comment>
		<comment id='24' author='SergeyBykov1' date='2017-02-09T06:08:45Z'>
		The problem is resolved in 1.0.0-rc0, 1 or 2..
Please upgrade and try again.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Feb 8, 2017 at 9:23 PM, smasoudn ***@***.***&gt; wrote:
 I have the same issue with tf.one_hot() . Here is my settings:

    - Windows 10
    - NVIDIA GeForce GTX 1070
    - Cudda 8.0
    - CuDnn 5.1
    - TensorFlow 0.12

 Error: Error polling for event status: failed to query event:
 CUDA_ERROR_ILLEGAL_ADDRESS
 Kernel died

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#6509 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AHlCOdbcNeg2bUAbLAbdDZ9D51-oEuGOks5raqK0gaJpZM4LV8wy&gt;
 .



		</comment>
		<comment id='25' author='SergeyBykov1' date='2017-02-09T06:30:56Z'>
		tested rc2 windows 10, gtx 1060, cuda 8 cudnn 5.1
The kernel diag_op_test fails
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1060 3GB, pci bus id: 0000:03:00.0)
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected Event status: 1
I am still getting this error in some code I am running.  Doesnt happen with the cpu version
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:404] error retrieving driver version: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\kernels\conv_ops.cc:605] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms)
		</comment>
		<comment id='26' author='SergeyBykov1' date='2017-02-09T07:50:28Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/6822&gt;#6822&lt;/denchmark-link&gt;
 explicitly disables diag_op_test because of failures when using GPU.
We are working on debugging those problems.
		</comment>
		<comment id='27' author='SergeyBykov1' date='2017-02-09T15:03:34Z'>
		So is there some official statement about what GPUs and versions of CUDA and cudnn work on windows 10 and for all platforms for that matter?  It is just Pascal that has the issue?  It would be helpful if there were some specific information about what features work and don't work, rather than run code and get random errors.
While I know that certain tests fail, I am not familiar enough with tensor flow yet to fully understand what that means for what features of the api won't work.
Thanks
		</comment>
		<comment id='28' author='SergeyBykov1' date='2017-02-10T02:05:55Z'>
		&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 I tested rc2 and the error message was gone (which didn't in rc1). Thank you for your comment!
		</comment>
		<comment id='29' author='SergeyBykov1' date='2017-02-22T02:16:59Z'>
		I come up with the same issue. It can be solved by the solution provided byname-name
Here is my computer info:

Win 8.1  (64bit)
GPU     GT 750M 4G (GK107)
CUDA  8.0.60
cuDNN  5.1
tensorflow-gpu 0.12.1

I have tried tensorflow-gpu 1.0.0 (not sure whether rc1 or 2) (Install using pip install tensorflow-gpu)
It actually make things worse, the program will get error in both situations.
(1. with the original code      2. replace the tf.one_hot() )
Here is the info I have got in tensorflow-gpu 1.0.0 with tf.one_hot()
&lt;denchmark-code&gt;ValueError                                Traceback (most recent call last)
&lt;ipython-input-8-967bb02bb6da&gt; in &lt;module&gt;()
      2 
      3 logits = LeNet(x)
----&gt; 4 cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)
      5 loss_operation = tf.reduce_mean(cross_entropy)
      6 optimizer = tf.train.AdamOptimizer(learning_rate = rate)

C:\Users\name \Miniconda3\envs\env1\lib\site-packages\tensorflow\python\ops\nn_ops.py in softmax_cross_entropy_with_logits(_sentinel, labels, logits, dim, name)
   1576   """
   1577   _ensure_xent_args("softmax_cross_entropy_with_logits", _sentinel,
-&gt; 1578                     labels, logits)
   1579 
   1580   # TODO(pcmurray) Raise an error when the labels do not sum to 1. Note: This

C:\Users\name \Miniconda3\envs\env1\lib\site-packages\tensorflow\python\ops\nn_ops.py in _ensure_xent_args(name, sentinel, labels, logits)
   1531   if sentinel is not None:
   1532     raise ValueError("Only call `%s` with "
-&gt; 1533                      "named arguments (labels=..., logits=..., ...)" % name)
   1534   if labels is None or logits is None:
   1535     raise ValueError("Both labels and logits must be provided.")

ValueError: Only call `softmax_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)
&lt;/denchmark-code&gt;

The info I have got in tensorflow-gpu 0.12.1 with tf.one_hot() is
&lt;denchmark-code&gt;c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
&lt;/denchmark-code&gt;

		</comment>
		<comment id='30' author='SergeyBykov1' date='2017-02-22T16:43:25Z'>
		&lt;denchmark-link:https://github.com/MikeZhu92&gt;@MikeZhu92&lt;/denchmark-link&gt;
 The error you're seeing seems to be from one of the breaking function signature changes that were made before the 1.0 release. Fortunately the solution to  problem is simple. Replace the following line in your code:
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)
...with the following line that names the arguments:
&lt;denchmark-code&gt;cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='31' author='SergeyBykov1' date='2017-02-22T23:25:43Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 Thank you for help, I didn't realize that yesterday.
It fixes the issue in tensorflow-gpu 1.0.0. For 0.12.1 it's still give me error message about the cuDNN stuff.
I have switched to 1.0.0 to push myself going through some updated features in the latest version.
Tensorflow is evolving really fast 
		</comment>
		<comment id='32' author='SergeyBykov1' date='2017-02-28T05:04:10Z'>
		I solved the problem by upgrading cuDNN to v5.1 version. You can have a try.
cuDNN download : &lt;denchmark-link:https://developer.nvidia.com/rdp/cudnn-download&gt;https://developer.nvidia.com/rdp/cudnn-download&lt;/denchmark-link&gt;

		</comment>
		<comment id='33' author='SergeyBykov1' date='2017-08-31T17:26:59Z'>
		I can confirm that upgrading to higher than 0.12 resolved this issue.
[...gpu_event_mgr.cc:198] Unexpected Event status: 1 lead me to this thread
My machine has 2 1080s running tf 0.12.0rc1 and using tf.onehot, causing my gpu driver to crash, as well as python.
Upgraded to tf 1.0.0 and updated some concat and SparseTensor calls, and my program worked.
		</comment>
	</comments>
</bug>