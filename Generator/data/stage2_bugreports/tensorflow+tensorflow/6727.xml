<bug id='6727' author='krautt' open_date='2017-01-08T17:31:40Z' closed_time='2017-03-20T15:23:38Z'>
	<summary>tf.contrib.learn.monitors.ValidationMonitor hangs when passed input_fn parameter</summary>
	<description>
Hello!
I have been working my way through the  tf.contrib.learn &lt;denchmark-link:https://www.tensorflow.org/tutorials/&gt;tutorials&lt;/denchmark-link&gt;
 and have been attempting to integrate the tf.contrib.learn.monitors.ValidationMonitor into the 'deep' classifier in wide_n_deep.py as shown below.
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?  I searched both Github and Stakeoverflow with the terms 'tensorflow,' 'input_fn,' and 'validationmonitor' but wasn't able to find anyone else who reported similar issues.&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System:  I ran this on Ubuntu Server 16.04 on a physical I7 with a GTX1080 gpu when i noticed the problem.  I know that i was using the GPU on the original physical box from previous tests, and because during the hang the nvidia_smi command showed considerable load on the GPU.  I was able to replicate the problem with CPU on a 16.04 VM as well.
Installed version of CUDA and cuDNN:
&lt;denchmark-code&gt;/home/andersonjas/libcudnn5-dev_5.1.5-1+cuda8.0_amd64.deb
/home/andersonjas/libcudnn5_5.1.5-1+cuda8.0_amd64.deb
&lt;/denchmark-code&gt;

If installed from binary pip package, provide:

A link to the pip package you installed:
from Anaconda 2.7 64 bit package:

&lt;denchmark-code&gt;pip install tensorflow
&lt;/denchmark-code&gt;


The output from python -c "import tensorflow; print(tensorflow.__version__)".

&lt;denchmark-code&gt;andersonjas@ubuntu:~$ python -c "import tensorflow; print(tensorflow.__version__)"
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
0.11.head

&lt;/denchmark-code&gt;

If installed from source, provide

The commit hash (git rev-parse HEAD)
The output of bazel version

&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(input_fn=lambda:input_fn(df_test), 
                       every_n_steps=50)
m.fit(input_fn=lambda: input_fn(df_train), steps=151,monitors=[validation_monitor])
Doing this in a jupyter notebool causes the code to hang indefinitely.  To make completely sure that i don't have a bug in my own code i can make the following change:
validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(input_fn=lambda:input_fn(df_test), 
                       every_n_steps=50)
m.fit(input_fn=lambda: input_fn(df_train), steps=151) #,monitors=[validation_monitor])
and then the code executes fine.
&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

I also built an input_fn interface to the iris and boston housing price predictor code code, each showed similar 'hangs'
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
As a noob, i'm learning that esoteric error messages are a luxury :-),  in this case the code just hangs indefinitely.
	</description>
	<comments>
		<comment id='1' author='krautt' date='2017-01-09T18:38:19Z'>
		FWIW,  tf.contrib.learn.monitors.ValidationMonitor  works like a champ when passed x,y parameters instead of input_fn, as instructed by the &lt;denchmark-link:https://www.tensorflow.org/tutorials/monitors/&gt;tutorial&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='krautt' date='2017-03-02T12:56:03Z'>
		suffered from the same issue.
Logsï¼š
WARNING:tensorflow:From c:\users\jay\appdata\local\programs\python\python35\lib\site-packages\tensorflow\contrib\learn\python\learn\monitors.py:322: BaseMonitor.init (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.
Instructions for updating:
Monitors are deprecated. Please use tf.train.SessionRunHook.
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_id': 0, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_environment': 'local', '_save_checkpoints_steps': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E539FE77F0&gt;, '_tf_config': gpu_options {
per_process_gpu_memory_fraction: 1
}
, '_save_summary_steps': 100, '_task_type': None, '_is_chief': True, '_master': '', '_num_ps_replicas': 0, '_evaluation_master': ''}
DEBUG:tensorflow:Setting feature info to {'work': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False), 'indexWork': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False), 'index': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False)}.
DEBUG:tensorflow:Setting labels info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False)
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='index', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='indexWork', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='work', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:From c:\users\jay\appdata\local\programs\python\python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 1003 into /tmp/count_model202020K\model.ckpt.
INFO:tensorflow:loss = 10987.0, step = 1003
DEBUG:tensorflow:Given features: {'work': &lt;tf.Tensor 'Const_1:0' shape=(283,) dtype=int64&gt;, 'indexWork': &lt;tf.Tensor 'Const_2:0' shape=(283,) dtype=int64&gt;, 'index': &lt;tf.Tensor 'Const:0' shape=(283,) dtype=int64&gt;}, required signatures: {'work': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False), 'indexWork': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False), 'index': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False)}.
DEBUG:tensorflow:Given labels: Tensor("Const_3:0", shape=(283,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(594)]), is_sparse=False).
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='index', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='indexWork', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
DEBUG:tensorflow:Transforming feature_column _RealValuedColumn(column_name='work', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:From c:\users\jay\appdata\local\programs\python\python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
INFO:tensorflow:Starting evaluation at 2017-03-02-13:00:23
		</comment>
		<comment id='3' author='krautt' date='2017-03-09T16:56:38Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Who would be the right person to look at ValidationMonitor now?  (&lt;denchmark-link:https://github.com/ilblackdragon&gt;@ilblackdragon&lt;/denchmark-link&gt;
 wrote this)
&lt;denchmark-link:https://github.com/JaySWang&gt;@JaySWang&lt;/denchmark-link&gt;
 why did you unassign him?
		</comment>
		<comment id='4' author='krautt' date='2017-03-13T09:53:15Z'>
		I have the same issue. Please see details below.
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System:

MacOS Sierra 10.12.3 (16D32)
Python 2.7.10

Installed version of CUDA and cuDNN:
n/a

&lt;denchmark-link:https://pypi.python.org/packages/db/0b/8ca3299122cb22f763df7076938b12d7f9e8a814d3ab7a80df6a41ef81f7/tensorflow-1.0.1-cp27-cp27m-macosx_10_11_x86_64.whl#md5=5f0f52fc2e5243d40d6ced52c6a56c69&gt;https://pypi.python.org/packages/db/0b/8ca3299122cb22f763df7076938b12d7f9e8a814d3ab7a80df6a41ef81f7/tensorflow-1.0.1-cp27-cp27m-macosx_10_11_x86_64.whl#md5=5f0f52fc2e5243d40d6ced52c6a56c69&lt;/denchmark-link&gt;


1.0.1
&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code):&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/837779/linear.py.zip&gt;linear.py.zip&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

n/a
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/837781/6727_logs.txt&gt;6727_logs.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='krautt' date='2017-03-17T18:48:05Z'>
		I just found a workaround to what might be the same issue in Tensorflow 0.12.1. Maybe it will be helpful here.
ValidationMonitor did not support the x=...y=... input, and when using input_fn, I found it would loop forever the first time it tried to run the monitor during a fit() call. The log output looked like it was calculating the validation metrics over and over in an infinite loop.
After looking at the source for ValidationMonitor I found a parameter eval_steps that defaulted to None. In other places in the contrib.learn codebase 'None' implies 'forever', so I tried adding eval_steps=1 to the constructor, and now it works as advertised.
e.g.
&lt;denchmark-code&gt;        validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(
            input_fn=lambda: input_function(test_data, test_labels),
            eval_steps=1,  # Try adding this
            metrics=validation_metrics,
            every_n_steps=10,
        )   

        estimator.fit(
            input_fn=lambda: input_function(training_data, training_labels),
            steps=training_epochs,
            monitors=[validation_monitor],
        ) 
&lt;/denchmark-code&gt;

Hope that helps!
		</comment>
		<comment id='6' author='krautt' date='2017-03-20T10:57:35Z'>
		Hi &lt;denchmark-link:https://github.com/gmacleod&gt;@gmacleod&lt;/denchmark-link&gt;
,
thanks for pointing out this eval_steps parameter.
I can confirm that the issue can't be reproduced once eval_steps set to "1".
		</comment>
		<comment id='7' author='krautt' date='2017-03-20T15:23:38Z'>
		I will close this issue. The semantics might be awkward, but the workaround is simple and we have deprecated monitors in favor of Hooks.
		</comment>
		<comment id='8' author='krautt' date='2017-03-20T17:58:15Z'>
		Awesome. Thanks for the follow up.  Eager to try it out.
		</comment>
		<comment id='9' author='krautt' date='2017-04-07T03:53:57Z'>
		Great, it solved my problem!
		</comment>
		<comment id='10' author='krautt' date='2017-05-06T03:26:50Z'>
		&lt;denchmark-link:https://github.com/gmacleod&gt;@gmacleod&lt;/denchmark-link&gt;
  Thanks for pointing out this solution! It happened in R1.1 too
		</comment>
		<comment id='11' author='krautt' date='2017-05-17T07:50:17Z'>
		&lt;denchmark-link:https://github.com/gmacleod&gt;@gmacleod&lt;/denchmark-link&gt;
 In tf1.1.0 , even adding eval_steps=1 to the constructor, it just output the validation log one time at the end of first n_steps, not every n_steps. Do you have the same problem?
		</comment>
		<comment id='12' author='krautt' date='2017-05-19T00:35:05Z'>
		&lt;denchmark-link:https://github.com/gmacleod&gt;@gmacleod&lt;/denchmark-link&gt;
 Thanks!! Happens in R1.1 as well.
		</comment>
		<comment id='13' author='krautt' date='2017-05-19T16:17:04Z'>
		&lt;denchmark-link:https://github.com/GuohongLi&gt;@GuohongLi&lt;/denchmark-link&gt;
  Maybe you should change the params in   to save the model weights, and then you can make the monitors. &lt;denchmark-link:https://www.tensorflow.org/get_started/monitors&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='krautt' date='2017-05-21T02:19:30Z'>
		This indeed solves my problem. However, now the validationmonitor only trigger ONE time, any solution for this?
validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(
input_fn=lambda: input_fn(df_test),
every_n_steps=25,metrics=validation_metrics,
eval_steps=1,
early_stopping_metric="auc",
early_stopping_metric_minimize=False,
early_stopping_rounds=100)
INFO:tensorflow:Validation (step 25): loss = 404.011, accuracy = 0.859006, labels/prediction_mean = 1.88953e-07, labels/actual_label_mean = 0.140994, accuracy/baseline_label_mean = 0.140994, auc = 0.5, auc_precision_recall = 0.570497, accuracy/threshold_0.500000_mean = 0.859006, precision/positive_threshold_0.500000_mean = 0.0, recall/positive_threshold_0.500000_mean = 0.0, precision = 0.0, recall = 0.0, global_step = 1
INFO:tensorflow:global_step/sec: 5.23263
INFO:tensorflow:loss = 51.8876, step = 101 (19.112 sec)
INFO:tensorflow:global_step/sec: 28.5071
INFO:tensorflow:loss = 5.04256, step = 201 (3.508 sec)
INFO:tensorflow:global_step/sec: 25.6652
INFO:tensorflow:loss = 11.7246, step = 301 (3.896 sec)
INFO:tensorflow:global_step/sec: 29.4536
INFO:tensorflow:loss = 10.9838, step = 401 (3.395 sec)
INFO:tensorflow:global_step/sec: 28.0369
INFO:tensorflow:loss = 8.74781, step = 501 (3.567 sec)
INFO:tensorflow:global_step/sec: 27.9563
INFO:tensorflow:loss = 10.7869, step = 601 (3.577 sec)
INFO:tensorflow:global_step/sec: 27.0742
INFO:tensorflow:loss = 17.0162, step = 701 (3.694 sec)
INFO:tensorflow:global_step/sec: 27.3682
INFO:tensorflow:loss = 4.63466, step = 801 (3.654 sec)
INFO:tensorflow:global_step/sec: 27.6004
INFO:tensorflow:loss = 6.31007, step = 901 (3.623 sec)
INFO:tensorflow:global_step/sec: 27.6511
INFO:tensorflow:loss = 2.64077, step = 1001 (3.616 sec)
INFO:tensorflow:global_step/sec: 27.4551
INFO:tensorflow:loss = 1.91578, step = 1101 (3.642 sec)
INFO:tensorflow:global_step/sec: 27.7833
INFO:tensorflow:loss = 7.05945, step = 1201 (3.599 sec)
INFO:tensorflow:global_step/sec: 28.0504
INFO:tensorflow:loss = 2.11703, step = 1301 (3.565 sec)
INFO:tensorflow:global_step/sec: 28.0631
INFO:tensorflow:loss = 7.89242, step = 1401 (3.563 sec)
INFO:tensorflow:global_step/sec: 27.6421
INFO:tensorflow:loss = 13.6624, step = 1501 (3.618 sec)
INFO:tensorflow:global_step/sec: 27.7735
INFO:tensorflow:loss = 2.61309, step = 1601 (3.601 sec)
INFO:tensorflow:global_step/sec: 27.5637
INFO:tensorflow:loss = 7.0057, step = 1701 (3.628 sec)
INFO:tensorflow:global_step/sec: 27.2692
INFO:tensorflow:loss = 5.1032, step = 1801 (3.667 sec)
INFO:tensorflow:global_step/sec: 27.225
INFO:tensorflow:loss = 1.73602, step = 1901 (3.673 sec)
INFO:tensorflow:Saving checkpoints for 2000 into /var/folders/dg/jxsw2s955c1f91h17nxqm4hm395n3_/T/tmpquiqiew6/model.ckpt.
INFO:tensorflow:Loss for final step: 1.56839.
		</comment>
		<comment id='15' author='krautt' date='2017-06-02T08:08:12Z'>
		&lt;denchmark-link:https://github.com/gmacleod&gt;@gmacleod&lt;/denchmark-link&gt;
 Thanks eval_steps = 1 fixed the problem!
&lt;denchmark-link:https://github.com/lancerts&gt;@lancerts&lt;/denchmark-link&gt;

I was able to trigger validation monitor multiple time by setting saving checkpoints.
the relevant code
&lt;denchmark-code&gt;classifier = tf.contrib.learn.DNNClassifier(
    ...,
    config = tf.contrib.learn.RunConfig(save_checkpoints_steps = 100, save_checkpoints_secs = None)
)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='16' author='krautt' date='2017-06-10T05:42:01Z'>
		from tensorflow output,
INFO:tensorflow:Saving dict for global step 39807: accuracy = 0.85421, accuracy/baseline_label_mean = 0.14821, accuracy/threshold_0.500000_mean = 0.85421, auc = 0.686321, global_step = 39807, labels/actual_label_mean = 0.14821, labels/prediction_mean = 0.146081, loss = 0.39175, precision/positive_threshold_0.500000_mean = 0.580026, recall/positive_threshold_0.500000_mean = 0.0591728, validate_confusion_matrix = [[84052 699]
[14430 819]], validate_streaing_precision = 0.580026, validate_streaing_recall = 0.0591728, validate_streaming_auc = 0.525859
WARNING:tensorflow:Skipping summary for validate_confusion_matrix, must be a float or np.float32.
WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.
INFO:tensorflow:Validation (step 40000): loss = 0.39175, accuracy = 0.85421, labels/prediction_mean = 0.146081, labels/actual_label_mean = 0.14821, accuracy/baseline_label_mean = 0.14821, auc = 0.686321, accuracy/threshold_0.500000_mean = 0.85421, precision/positive_threshold_0.500000_mean = 0.580026, recall/positive_threshold_0.500000_mean = 0.0591728, validate_confusion_matrix = [[84052 699]
[14430 819]], validate_streaing_precision = 0.580026, validate_streaing_recall = 0.0591728, validate_streaming_auc = 0.525859, global_step = 39807
Why are this two AUC differs so much? When i use model.evaluate on train, validate, test data set, all the output AUCs are very close to the first auc shows in bold above.
So what is the validation_streaming_auc is calculating? I have reset the local variables in each epoch.
		</comment>
	</comments>
</bug>