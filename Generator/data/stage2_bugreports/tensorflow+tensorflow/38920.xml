<bug id='38920' author='said120276' open_date='2020-04-26T16:56:31Z' closed_time='2020-04-28T11:38:54Z'>
	<summary>AutoGraph failed  to convert if statement into the equivalent tf.cond  in a RNN custom cell</summary>
	<description>
System information


I have written custom code.


OS Windows 10:


TensorFlow version : 2 . 1 .0


Python version: 3.6


CUDA/cuDNN version: 10.1   /  7.6.5


GPU model and memory: rtx 2070



I write a custom cell to be used in  a RNN model, the cell has some 'if' statements where a condition is  tf.Variable.  When I use &lt;denchmark-link:https://github.com/function&gt;@function&lt;/denchmark-link&gt;
 to build a graph, the 'if 'condition work fine in  the model class but throw an error in the custom cell class :
&lt;denchmark-code&gt;TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
Encountered error:

using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
&lt;/denchmark-code&gt;

Describe the expected behavior
AutoGraph should convert if statements into the equivalent tf.cond
Standalone code to reproduce the issue
&lt;denchmark-h:h1&gt;custom cell&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;class tst_cell(tf.keras.layers.Layer):

    def __init__(self ):
         super(tst_cell , self).__init__()
         self.corr      = tf.keras.layers.Dense(4)
         self.state_size = 1
      
    def call (self ,inpt ,  states  ):
   
        if ee == 0 :            #  throw the error  !!!!!!
            print('cell  ee == 0')
            
        self.corr_s    = self.corr(inpt)
    
        return self.corr_s , states
 

 
    def get_initial_state(self,inputs, batch_size , dtype ):
   
       
      init_stat= tf.zeros((2,1) , dtype = dtype)
        
      return init_stat    


&lt;/denchmark-code&gt;

ee = tf.Variable(0) # global variable used in 'if' condition 
&lt;denchmark-h:h1&gt;the model&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;class tst_rnn_model(tf.keras.Model):
     def __init__ (self):
        super(tst_rnn_model , self).__init__()
       
        self.msk = tf.keras.layers.Masking(mask_value=0. , input_shape = (6,3))
        
        self.tst_gmm_cell        = tst_cell()
        
        self.tst_rnn_gmm          = tf.keras.layers.RNN(self.tst_gmm_cell ,  return_sequences=True )

     @tf.function  
     def call (self , inpt ):
        
        if ee == 0 :        # work fine  !!!!!
            print('model ee == 0')
            
        x = self.msk(inpt)
        mask = self.msk.compute_mask(inpt)
        outputs = self.tst_rnn_gmm(x , mask = mask)

        return outputs


data=np.arange(36.).reshape(2,6,3)
tst_model = tst_rnn_model()
out = tst_model(data)   
out
&lt;/denchmark-code&gt;

Other info / logs Include any logs
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

TypeError                                 Traceback (most recent call last)
 in 
29 #run the model
30 tst_model = tst_rnn_model()
---&gt; 31 out = tst_model(data)
32 out
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in call(self, inputs, *args, **kwargs)
820           with base_layer_utils.autocast_context_manager(
821               self._compute_dtype):
--&gt; 822             outputs = self.call(cast_inputs, *args, **kwargs)
823           self._handle_activity_regularization(inputs, outputs)
824           self._set_mask_metadata(inputs, outputs, input_masks)
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in call(self, *args, **kwds)
566         xla_context.Exit()
567     else:
--&gt; 568       result = self._call(*args, **kwds)
569
570     if tracing_count == self._get_tracing_count():
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
613       # This is the first call of call, so we have to initialize.
614       initializers = []
--&gt; 615       self._initialize(args, kwds, add_initializers_to=initializers)
616     finally:
617       # At this point we know that the initialization is complete (or less
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
495     self._concrete_stateful_fn = (
496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 497             *args, **kwds))
498
499     def invalid_creator_scope(*unused_args, **unused_kwds):
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
2387       args, kwargs = None, None
2388     with self._lock:
-&gt; 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
2390     return graph_function
2391
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
2701
2702       self._function_cache.missed.add(call_context_key)
-&gt; 2703       graph_function = self._create_graph_function(args, kwargs)
2704       self._function_cache.primary[cache_key] = graph_function
2705       return graph_function, args, kwargs
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
2591             arg_names=arg_names,
2592             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2593             capture_by_value=self._capture_by_value),
2594         self._function_attributes,
2595         # Tell the ConcreteFunction to clean up its graph once it goes out of
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
976                                           converted_func)
977
--&gt; 978       func_outputs = python_func(*func_args, **func_kwargs)
979
980       # invariant: func_outputs contains only Tensors, CompositeTensors,
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
437         # wrapped allows AutoGraph to swap in a converted function. We give
438         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 439         return weak_wrapped_fn().wrapped(*args, **kwds)
440     weak_wrapped_fn = weakref.ref(wrapped_fn)
441
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in bound_method_wrapper(*args, **kwargs)
3209     # However, the replacer is still responsible for attaching self properly.
3210     # TODO(mdan): Is it possible to do it here instead?
-&gt; 3211     return wrapped_fn(*args, **kwargs)
3212   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)
3213
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\framework\func_graph.py in wrapper(*args, **kwargs)
966           except Exception as e:  # pylint:disable=broad-except
967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
969             else:
970               raise
TypeError: in converted code:
&lt;denchmark-code&gt;&lt;ipython-input-219-ee4d06aa06c9&gt;:22 call  *
    outputs = self.tst_rnn_gmm(x , mask = mask)
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\layers\recurrent.py:644 __call__
    return super(RNN, self).__call__(inputs, **kwargs)
c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py:785 __call__
    str(e) + '\n"""')

TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
Encountered error:
"""
using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
"""
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='said120276' date='2020-04-27T10:42:12Z'>
		&lt;denchmark-link:https://github.com/said120276&gt;@said120276&lt;/denchmark-link&gt;

I am not seeing any error message in TF version 2.2.rc3().Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/6d3deecc5c6b08101557a12401e57959/untitled830.ipynb&gt;here&lt;/denchmark-link&gt;
.Please verify once and close the issue. Thanks!
		</comment>
		<comment id='2' author='said120276' date='2020-04-27T17:21:28Z'>
		Thank you for your reply . So it was a bug in the previous version ? I will upgrade to tensorflow 2.2 and try this night.
		</comment>
		<comment id='3' author='said120276' date='2020-04-28T07:07:17Z'>
		&lt;denchmark-link:https://github.com/said120276&gt;@said120276&lt;/denchmark-link&gt;

Please close this thread if it solves your question in latest TF version(2.2-rc3). Thanks!
		</comment>
		<comment id='4' author='said120276' date='2020-04-28T11:38:53Z'>
		Work fine in TF version 2.2.rc3.Thanks
		</comment>
		<comment id='5' author='said120276' date='2020-04-28T11:38:55Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38920&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38920&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>