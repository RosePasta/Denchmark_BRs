<bug id='31174' author='peastman' open_date='2019-07-30T22:43:23Z' closed_time='2020-04-03T09:13:58Z'>
	<summary>TF 1.14 Keras model throws exception when inputs are not the deepest nodes</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.14.0
Python version: 3.6.9
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: 10.1
GPU model and memory: Titan V

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
TensorFlow 1.14 introduced a bug in Keras models.  The specific change is the introduction of these lines:



tensorflow/tensorflow/python/keras/engine/network.py


        Lines 849 to 850
      in
      a5120db






 # Ignore the InputLayers when computing the graph. 



 depth_keys = depth_keys[1:] 





They make the assumption that a model's inputs will be deeper than any other node.  When that is not true, any nodes whose depth is equal to or greater than the inputs does not get evaluated, producing an exception.
The problem is demonstrated by the following script.  It creates a model where an input and a variable have the same depth.  In TensorFlow 1.13 this runs correctly, but in 1.14 it throws an exception:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "test.py", line 17, in &lt;module&gt;
    print(model(model.inputs))
  File "/home/peastman/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/home/peastman/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py", line 751, in call
    return self._run_internal_graph(inputs, training=training, mask=mask)
  File "/home/peastman/miniconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py", line 903, in _run_internal_graph
    assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)
AssertionError: Could not compute output Tensor("add/add:0", shape=(?, 1), dtype=float32)
&lt;/denchmark-code&gt;

Describe the expected behavior
Calling the model should return a Tensor, not throw an exception.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
import tensorflow.keras.layers as layers

class Variable(layers.Layer):

  def __init__(self, initial_value, **kwargs):
    super(Variable, self).__init__(**kwargs)
    self.var = tf.Variable(initial_value)

  def call(self, inputs):
    return self.var

var = Variable([1.0])([])
input = layers.Input(shape=(1,))
output = layers.Add()([input, var])
model = tf.keras.Model(inputs=[input], outputs=[output])
print(model(model.inputs))
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='peastman' date='2019-08-05T22:41:26Z'>
		After searching for a workaround, I've concluded this bug is more severe than I originally thought.  It doesn't actually matter where in the tree the Variable layer appears.  All that matters is that it takes no inputs, but is not itself an Input layer.  Any layer with those properties anywhere in a model produces the exception.
		</comment>
		<comment id='2' author='peastman' date='2019-08-16T21:12:30Z'>
		This issue exists tf-nightly version 1.15.0-dev20190816
		</comment>
		<comment id='3' author='peastman' date='2019-08-16T22:35:20Z'>
		&lt;denchmark-link:https://github.com/peastman&gt;@peastman&lt;/denchmark-link&gt;
 You'll have to make a Layer that creates a Variable and adds it to input, it's not possible to have a Keras Layer that takes no inputs in the Functional API
		</comment>
		<comment id='4' author='peastman' date='2019-08-16T22:48:26Z'>
		In what sense is it not possible?  It worked perfectly up through TF 1.13.
		</comment>
		<comment id='5' author='peastman' date='2019-08-16T22:51:22Z'>
		Note that the sample script is just a minimal reproduction.  The real models where I'm encountering this error are much more complicated.  But generally speaking, it's very common for computation graphs to have branches that don't depend on any inputs, just on variables.
		</comment>
		<comment id='6' author='peastman' date='2020-04-03T09:13:58Z'>
		&lt;denchmark-link:https://github.com/peastman&gt;@peastman&lt;/denchmark-link&gt;
 Closing this issue as it is the intended behaviour.Thanks!
		</comment>
		<comment id='7' author='peastman' date='2020-04-03T09:14:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31174&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31174&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>