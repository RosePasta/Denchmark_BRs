<bug id='11438' author='RylanSchaeffer' open_date='2017-07-11T21:07:37Z' closed_time='2017-12-21T04:19:15Z'>
	<summary>Switching Session to MonitoredTrainingSession Produces Negative Dimension Tensors from Queues</summary>
	<description>
I already &lt;denchmark-link:https://stackoverflow.com/questions/44831580/receiving-negative-input-dimensions-with-tensorflow-monitoredtrainingsession&gt;posted&lt;/denchmark-link&gt;
 on StackOverflow, but received no response.
I've made some changes to my code since posting on StackOverflow, but the problem is still the same: the readers and queues I use without a problem with a vanilla tf.Session() work fine, but if I try to switch to a tf.train.MonitoredTrainingSession, I get the following error:
InvalidArgumentError (see above for traceback): Shape [15,-1,4] has negative dimensions [[Node: define_inputs/y = Placeholder[dtype=DT_FLOAT, shape=[15,?,4], _device="/job:local/replica:0/task:0/cpu:0"]()]]
I'm using TensorFlow v1.2.0-5-g435cdfc 1.2.1. Here's my code. This works:
&lt;denchmark-code&gt;# fix random seed to permit comparison between training runs
tf.set_random_seed(seed=0)

# define graph
model = import_model()

with tf.Session() as monitored_sess:

    monitored_sess.run(tf.global_variables_initializer())

    # create coordinator to handle threading
    coord = tf.train.Coordinator()

    # start threads to enqueue input minibatches for training
    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)

    data = monitored_sess.run([training_data])
    x, y, x_lengths, y_lengths = data[0]

    # when done, ask the threads to stop
    coord.request_stop()

    # wait for threads to finish
    coord.join(threads)
&lt;/denchmark-code&gt;

But then, this code doesn't work:
&lt;denchmark-code&gt;tf.set_random_seed(seed=0)

# define graph
model = import_model()

# create a one process cluster with an in-process server
server = tf.train.Server.create_local_server()

# define hooks for writing summaries and model variables to disk
hooks = construct_training_hooks(model.summary_op, model.loss, train_log_directory)

# create monitored training session to write model variables and summaries to disk
with tf.train.MonitoredTrainingSession(master=server.target,
                                       config=tf.ConfigProto(allow_soft_placement=True),
                                       is_chief=True,
                                       hooks=hooks) as monitored_sess:

    # create coordinator to handle threading
    coord = tf.train.Coordinator()

    # start threads to enqueue input minibatches for training
    threads = tf.train.start_queue_runners(sess=monitored_sess, coord=coord)

    # train
    data = monitored_sess.run([training_data])
    x, y, x_lengths, y_lengths = data[0]

    # when done, ask the threads to stop
    coord.request_stop()

    # wait for threads to finish
    coord.join(threads)
&lt;/denchmark-code&gt;

The function construct_training_hooks is pretty straightforward:
&lt;denchmark-code&gt;def construct_training_hooks(summary_op, loss, train_log_directory):
    hooks = [tf.train.StopAtStepHook(last_step=tf.flags.FLAGS.max_steps),
             tf.train.CheckpointSaverHook(checkpoint_dir=train_log_directory,
                                          saver=tf.train.Saver(),
                                          save_steps=5),
             tf.train.SummarySaverHook(output_dir=train_log_directory,
                                       summary_op=summary_op,
                                       save_steps=1),
             tf.train.NanTensorHook(loss_tensor=loss)]

    return hooks
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='RylanSchaeffer' date='2017-07-12T03:30:03Z'>
		Is it possible for you to try the code at head? I think this may be fixed (at least that error is no longer generated by the shape code).
		</comment>
		<comment id='2' author='RylanSchaeffer' date='2017-07-13T16:44:25Z'>
		Sorry if this is a really stupid question, but what does "try the code at head" mean?
		</comment>
		<comment id='3' author='RylanSchaeffer' date='2017-07-13T16:50:42Z'>
		I'm sorry I wasn't clear! (Not a stupid question :) I meant to try the most recently checked-in code which I think has fixed this problem, rather than the version 1.2.0 that you report above.
If you don't want to wait for the next release that would mean &lt;denchmark-link:https://www.tensorflow.org/install/install_sources&gt;installing from sources&lt;/denchmark-link&gt;
 or trying the &lt;denchmark-link:https://github.com/tensorflow/tensorflow&gt;nightly binaries&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='RylanSchaeffer' date='2017-07-16T03:26:35Z'>
		&lt;denchmark-link:https://github.com/MicaelCarvalho&gt;@MicaelCarvalho&lt;/denchmark-link&gt;
 Any update on then this is going to be release?
I see the same problem when restoring a saved session.
		</comment>
		<comment id='5' author='RylanSchaeffer' date='2017-08-28T03:14:16Z'>
		I'm unable to reproduce this problem.
Please provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new&gt;the Github new issue template&lt;/denchmark-link&gt;
.
We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!
		</comment>
		<comment id='6' author='RylanSchaeffer' date='2017-08-28T20:35:55Z'>
		&lt;denchmark-link:https://github.com/ali01&gt;@ali01&lt;/denchmark-link&gt;
 , previously I was using TensorFlow v1.2.0-5-g435cdfc 1.2.1 on macOS Sierra version 10.12.6. I used pip to install.
I'll try to create a simplified example that recreates the problem, but I had to abandon that code because it wasn't working and I needed to make progress on my internship project, so I don't know if/when I'll get to it.
		</comment>
		<comment id='7' author='RylanSchaeffer' date='2017-09-20T17:54:12Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
, do you have any insight?
		</comment>
		<comment id='8' author='RylanSchaeffer' date='2017-09-21T16:37:52Z'>
		The original error is printed in TF 1.2 when you call sess.run() on some tensor/op that depends on a placeholder and do not feed that placeholder. (The error message is improved in TF 1.3.) The cause is probably a hidden sess.run() call in one of the queue runners.
IIRC, you should never call tf.train.start_queue_runners(sess) where sess is a MonitoredSession, because it will attempt to run hooks in every queue runner run() call. These hooks (e.g. for summaries) might be what is causing the placeholder to be evaluated. Instead, you must rely on the MonitoredSession to start the queue runners for you.
		</comment>
		<comment id='9' author='RylanSchaeffer' date='2017-12-20T19:09:46Z'>
		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='RylanSchaeffer' date='2017-12-21T04:19:15Z'>
		Closing due to lack of activity.
		</comment>
		<comment id='11' author='RylanSchaeffer' date='2018-02-05T05:15:53Z'>
		i have the save questions. is there any examples to show how to start queue_runners rely on MonitoredSession ? thanks. &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>