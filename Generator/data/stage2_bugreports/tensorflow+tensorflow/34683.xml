<bug id='34683' author='diNatale' open_date='2019-11-28T10:39:57Z' closed_time='2020-07-14T08:45:58Z'>
	<summary>TensorArray objects improperly handled as tf.function arguments or return values</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 16.04
TensorFlow installed from (source or binary): tensorflow-gpu from binary
TensorFlow version (use command below): 2.0.0
Python version: 3.6.7
CUDA/cuDNN version: CUDA 10.0, cuDNN 7.6.0.64
GPU model and memory: GeForce GTX  1080

Describe the current behavior
When you return a created TensorArray from a function decorated with tf.function, the returned object is an empty Tensor with an illegal state:
object type is tf.Tensor(, shape=(), dtype=variant)
This object cannot be used and will throw an exception when attempting to use it.
See also attached image for more details.
Example of the exception, when calling concat method:
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'concat'
Describe the expected behavior
The returned object should be a legal TensorArray instance, as is the case when you use only Eager mode functions.
In this case the object type is &lt;tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f73b0386208&gt;
The code works fine if all functions are in Eager mode (see code example).
The code works fine if you concat the TensorArray before returning it (see code example).
Code to reproduce the issue
&lt;denchmark-code&gt;@tf.function
def accumulate_no_error_graph(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr.concat()

def accumulate_no_error_eager(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr

@tf.function
def accumulate_error_graph(d):
    arr = tf.TensorArray(tf.float32, num_rows)

    for i in range(num_rows):
        arr = arr.write(i, d[i])

    return arr

num_rows = 10
a = tf.random.uniform([num_rows, 2])

# Works well
data = accumulate_no_error_eager(a)
print(f'From eager: {data}')

data = accumulate_no_error_graph(a)
print(f'From Graph with concat: {data}')

# Doesn't work!
data = accumulate_error_graph(a)
print(f'From Graph no concat: {data}')
&lt;/denchmark-code&gt;

Other info / logs
Output of the code:
&lt;denchmark-code&gt;From eager: &lt;tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7ff67c5ac470&gt;
From Graph with concat: [0.6765479  0.28778458 0.85561883 0.41792393 0.667024   0.35702074
 0.33666503 0.6575141  0.05998921 0.06930244 0.05852807 0.65689635
 0.4156996  0.39695132 0.78036475 0.79794145 0.96339357 0.49462914
 0.885311   0.04960382]

Traceback (most recent call last):
ValueError: Tensorflow type 21 not convertible to numpy dtype.
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/569000/69805111-a7970a80-11e8-11ea-8233-54b2385728c0.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='diNatale' date='2019-11-28T10:40:38Z'>
		This issue is linked to the discussion at the end of this issue:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30409&gt;Issue 30409&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='diNatale' date='2019-11-28T13:06:38Z'>
		A similar issue is around passing TensorArrays as arguments: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30409#issuecomment-508983979&gt;#30409 (comment)&lt;/denchmark-link&gt;

Updating the bug title a bit to catch both cases.
		</comment>
		<comment id='3' author='diNatale' date='2019-11-29T05:39:59Z'>
		I have tried on colab with TF version 2.0 ,2.1.0-dev20191128  and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/cc1b34dba4b052e81ff306fc3976507f/untitled415.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='diNatale' date='2020-01-09T22:43:48Z'>
		TensorArrays have completely different representations in graph and eager modes. Inside graphs (tf.function) a TensorArray is a DT_VARIANT type tensor wrapping a vector&lt;Tensor*&gt; whereas in eager mode it is just a python list of EagerTensors so they are not really interoperable. This was done to avoid keeping a copy of the entire TensorArray when performing an operation in eager mode.
A workaround for now maybe to return arr.stack() from the tf.function and unstack the returned value using tf.TensorArray(tf.float32, num_rows).unstack(accumulate_error_graph(a)). If we support returning TensorArrays from tf.function this is what we might end up doing under the hood. Even if we don't support this, we should definitely raise a better error message at function tracing time maybe.
		</comment>
		<comment id='5' author='diNatale' date='2020-06-30T18:42:46Z'>
		&lt;denchmark-link:https://github.com/diNatale&gt;@diNatale&lt;/denchmark-link&gt;
,
Could you please check &lt;denchmark-link:https://github.com/saxenasaurabh&gt;@saxenasaurabh&lt;/denchmark-link&gt;
's workaround and let us know if you are still facing the issue. Thanks!
		</comment>
		<comment id='6' author='diNatale' date='2020-07-07T14:05:29Z'>
		
Could you please check @saxenasaurabh's workaround and let us know if you are still facing the issue. Thanks!

&lt;denchmark-link:https://github.com/diNatale&gt;@diNatale&lt;/denchmark-link&gt;
,
Any updates regarding this? Please feel free to close the issue if resolved. Thanks!
		</comment>
		<comment id='7' author='diNatale' date='2020-07-09T07:10:22Z'>
		Hi &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 ,
Unfortunately I have "neglected" my tf2/eager implementation due to these and a couple more issues, and had to focus hard on pushing on the older version (tf1-compatible).
I will try to give it higher priority soon.
Cheers
		</comment>
		<comment id='8' author='diNatale' date='2020-07-14T08:45:10Z'>
		
Unfortunately I have "neglected" my tf2/eager implementation due to these and a couple more issues, and had to focus hard on pushing on the older version (tf1-compatible).
I will try to give it higher priority soon.
Cheers

&lt;denchmark-link:https://github.com/daganesh&gt;@daganesh&lt;/denchmark-link&gt;
,
Please submit a new issue from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;this link&lt;/denchmark-link&gt;
 and fill in the template, so that we can track the issue there. Thanks!
		</comment>
		<comment id='9' author='diNatale' date='2020-07-14T08:45:55Z'>
		
Any updates regarding this? Please feel free to close the issue if resolved. Thanks!

&lt;denchmark-link:https://github.com/diNatale&gt;@diNatale&lt;/denchmark-link&gt;
,
Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='10' author='diNatale' date='2020-07-14T08:45:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34683&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34683&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>