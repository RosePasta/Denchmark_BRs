<bug id='38478' author='fcqfcq' open_date='2020-04-12T17:55:36Z' closed_time='2020-05-04T22:06:51Z'>
	<summary>[tflite] FlexAddV2</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
TensorFlow installed from (source or binary):
TensorFlow version (or github SHA if from source):

Provide the text output from tflite_convert
&lt;denchmark-code&gt;# Copy and paste here
&lt;/denchmark-code&gt;

Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Also, please include a link to a GraphDef or the model if possible.
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
	</description>
	<comments>
		<comment id='1' author='fcqfcq' date='2020-04-12T17:57:10Z'>
		model_path ='converted_model_tf2.tflite'
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()
&lt;denchmark-code&gt;  1 model_path ='converted_model_tf2.tflite'
  2 interpreter = tf.lite.Interpreter(model_path=model_path)
&lt;/denchmark-code&gt;

----&gt; 3 interpreter.allocate_tensors()
/anaconda/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
242   def allocate_tensors(self):
243     self._ensure_safe()
--&gt; 244     return self._interpreter.AllocateTensors()
245
246   def _safe_to_run(self):
/anaconda/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
104
105     def AllocateTensors(self):
--&gt; 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
107
108     def Invoke(self):
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 2 (FlexAddV2) failed to prepare.
		</comment>
		<comment id='2' author='fcqfcq' date='2020-04-14T19:21:21Z'>
		How are you converting the mode to tf lite?
If using target_spec.supported_ops can you try to convert the model with SELECT_TF_OPS?
converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
		</comment>
		<comment id='3' author='fcqfcq' date='2020-04-20T20:33:24Z'>
		To run the model with select TF operators,  you can follow the method in &lt;denchmark-link:https://www.tensorflow.org/lite/guide/ops_select#running_the_model&gt;https://www.tensorflow.org/lite/guide/ops_select#running_the_model&lt;/denchmark-link&gt;
.
Unfortunately, python package for select TF operators are not supported yet. You can run the model using Android or iOS  library.
		</comment>
		<comment id='4' author='fcqfcq' date='2020-04-27T21:08:39Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='fcqfcq' date='2020-05-04T22:06:50Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='fcqfcq' date='2020-05-04T22:06:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38478&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38478&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>