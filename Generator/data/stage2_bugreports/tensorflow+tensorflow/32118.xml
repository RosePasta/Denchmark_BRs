<bug id='32118' author='terhorst' open_date='2019-08-30T14:22:40Z' closed_time='2019-10-22T15:40:40Z'>
	<summary>[TF2] Parallel optimizers in eager mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.10
TensorFlow installed from (source or binary): pip install tensorflow==2.0.0beta1
Python version: 3.7

Describe the current behavior
I would like to optimize a large number of subproblems in parallel using TF 2.0. (For example, to compute the bootstrapped s.e. of the MLE.) It seems like this is not currently possible.
Code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf

class opt:
    def __init__(self):
        self.x = None
    @tf.function
    def __call__(self, data):
        if self.x is None:
            self.x = tf.Variable(0., dtype=tf.float64)
            self.opt = tf.keras.optimizers.SGD(1.)
        x = self.x
        opt = self.opt
        for _ in range(10):
            with tf.GradientTape() as tape:
                obj = tf.reduce_mean((data - x) ** 2)
            g = tape.gradient(obj, x)
            opt.apply_gradients([(g, x)])
        return x

data = np.random.normal(size=10000)
K = 10
replicates = np.random.choice(data, size=(K, 10000), replace=True)

@tf.function
def g():
    return tf.map_fn(lambda r: opt()(r), replicates, dtype=tf.float64)

g()
&lt;/denchmark-code&gt;

Other info / logs
The above code throws the error:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.FailedPreconditionError:  Error while reading resource variable SGD/learning_rate_130 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/SGD/learning_rate_130/N10tensorflow3VarE does not exist.
         [[{{node map/while/body/_1/StatefulPartitionedCall/SGD/SGD/update/Cast/ReadVariableOp}}]] [Op:__inference_g_1191]

Function call stack:
g
&lt;/denchmark-code&gt;

I believe this is because the optimizer creates variables as part of its initialization. These variables are not preserved between calls to opt().
If I try to define a new optimizer at each call to opt(), then tf.function complains that variables are being created on the non-first call.
The code works if I do not decorate g() with @tf.function.
Thus far the only workaround I have found is to manually implement the gradient update rule, forgoing the use of tf.keras.optimizers completely. But I'm hoping there's a better way.
	</description>
	<comments>
		<comment id='1' author='terhorst' date='2019-08-30T14:52:57Z'>
		I was able to get this to work by manually initializing the optimizer variables:
&lt;denchmark-code&gt;class opt:
    def __init__(self):
        self.x = None
    @tf.function
    def __call__(self, data):
        if self.x is None:
            self.x = tf.Variable(0., dtype=tf.float64, name="x")
            self.opt = tf.keras.optimizers.SGD()
        x = self.x
        opt = self.opt
        x.assign(0.)
        for v in opt.variables():
            v.assign(0)  # initialize itercount to 0
        for _ in range(100):
            with tf.GradientTape() as tape:
                obj = tf.reduce_mean((data - x) ** 2)
            g = tape.gradient(obj, x)
            opt.apply_gradients([(g, x)])
        return x
&lt;/denchmark-code&gt;

The code runs, and indeed runs faster when I decorate g() with @tf.function than when I don't. But CPU usage stays around 100%, even when I make the optimization problem less trivial, so I'm not sure if it's actually running in parallel.
		</comment>
		<comment id='2' author='terhorst' date='2019-09-03T09:53:53Z'>
		Issue replicating for the given code for TF 2.0beta, please find the &lt;denchmark-link:https://colab.research.google.com/gist/oanush/9e8621ef80159028163e646710109ad8/32118.ipynb&gt;gist&lt;/denchmark-link&gt;
.
Thanks!
		</comment>
		<comment id='3' author='terhorst' date='2019-09-17T07:18:48Z'>
		Hi &lt;denchmark-link:https://github.com/terhorst&gt;@terhorst&lt;/denchmark-link&gt;
 ,  unfortunately, tf.function can't trace dynamic Variable creations wrapped in map_fn properly, and probably we won't prioritize it in the near future.
Though you can simply take out the initialization out of g and use Python list comprehension like below, and it will run in parallel.
class opt:
    def __init__(self):
        self.x = None
    @tf.function
    def __call__(self, data):
        if self.x is None:
            self.x = tf.Variable(0., dtype=tf.float64)
            self.opt = tf.keras.optimizers.SGD(1.)
        x = self.x
        opt = self.opt
        for _ in tf.range(10):
            with tf.GradientTape() as tape:
                obj = tf.reduce_mean((data - x) ** 2)
            g = tape.gradient(obj, x)
            opt.apply_gradients([(g, x)])
        return x

data = np.random.normal(size=10000)
K = 10
replicates = np.random.choice(data, size=(K, 10000), replace=True)
opts = [opt() for _ in range(len(replicates))]

@tf.function
def g(replicates):
    return [opts[i](replicates[i]) for i in range(len(opts))]

g(replicates)
		</comment>
		<comment id='4' author='terhorst' date='2019-10-02T17:24:15Z'>
		&lt;denchmark-link:https://github.com/terhorst&gt;@terhorst&lt;/denchmark-link&gt;
 please let us know  if the suggestion by &lt;denchmark-link:https://github.com/kkimdev&gt;@kkimdev&lt;/denchmark-link&gt;
 is helpful and we can close the issue.
		</comment>
		<comment id='5' author='terhorst' date='2019-10-22T12:36:29Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='6' author='terhorst' date='2019-10-22T15:40:40Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='7' author='terhorst' date='2019-10-22T15:40:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32118&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32118&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>