<bug id='29751' author='prateethvnayak' open_date='2019-06-13T17:52:16Z' closed_time='2019-08-02T00:22:07Z'>
	<summary>KeyError: 'ParallelInterleaveDataset' in Tf &amp;gt;= 1.13 (mkl/gpu)</summary>
	<description>
OS Platform and Distribution - Linux Ubuntu 16.04)
TensorFlow installed from Anaconda dist 3.6.
TensorFlow version 1.13-mkl / 1.13-gpu
Python version: Python 3.6.6 :: Anaconda, Inc.
*
There is an import error on  while importing one of the models from the model zoo / coral_ready model. The import works fine on 1.12 but not &gt;= 1.13 ver

The model should be otherwise loaded with the placeholder and graph

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
The model was taken from here - [Model Link] (&lt;denchmark-link:http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz&gt;http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz&lt;/denchmark-link&gt;
)
&lt;denchmark-link:https://coral.withgoogle.com/models/&gt;Model Website&lt;/denchmark-link&gt;

Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "ssd_test.py", line 6, in &lt;module&gt;
    model = Importers.ImportMeta(dir_path=model_dir, quantizer='LINEAR')
  File "/home/local/SRI/e32640/Documents/aiquantizer/Importers.py", line 89, in __init__
    self.import_graph()
  File "/home/local/SRI/e32640/Documents/aiquantizer/Importers.py", line 118, in import_graph
    clear_devices=True)
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1435, in import_meta_graph
    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1457, in _import_meta_graph_with_return_elements
    **kwargs))
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py", line 806, in import_scoped_meta_graph_with_return_elements
    return_elements=return_elements)
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/importer.py", line 399, in import_graph_def
    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
  File "/home/local/SRI/e32640/anaconda3/envs/tf13-gpu/lib/python3.6/site-packages/tensorflow/python/framework/importer.py", line 159, in _RemoveDefaultAttrs
    op_def = op_dict[node.op]
KeyError: 'ParallelInterleaveDataset'

&lt;/denchmark-code&gt;

UPDATE [1]:
The following code snippet is used for importing the model downloaded from the model zoo
&lt;denchmark-code&gt;model_dir = 'ssd_mobilenet_v2/'
meta = glob.glob(model_dir + "*.meta")[0]
ckpt = meta.replace('.meta', '').strip()

graph = tf.Graph()
with graph.as_default():
    with tf.Session() as sess:
        reader = tf.train.import_meta_graph(meta, clear_devices=True)
        reader.restore(sess, ckpt)
        writer = tf.summary.FileWriter(logdir=model_dir, graph=tf.get_default_graph())  # write to event
        writer.flush()
        vari = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
        for var in vari:
            print(var.name, "\n")
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='prateethvnayak' date='2019-06-14T11:24:07Z'>
		Will it be possible for a small code snippet that can reproduce the issue. It will really help us to proceed faster. Thanks!
		</comment>
		<comment id='2' author='prateethvnayak' date='2019-06-14T15:37:06Z'>
		&lt;denchmark-link:https://github.com/achandraa&gt;@achandraa&lt;/denchmark-link&gt;
  Have updated the issue with a snippet. The simple importer is what I have used.
I had a similar issue earlier and it is still open &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27752#issue-432019580&gt;#27752&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='prateethvnayak' date='2019-06-24T21:33:17Z'>
		Jiri, did we remove this op? If so I'm guessing it was just experimental?
		</comment>
		<comment id='4' author='prateethvnayak' date='2019-06-24T21:52:34Z'>
		The op was renamed to ExperimentalParallelInterleaveDataset.
		</comment>
		<comment id='5' author='prateethvnayak' date='2019-06-26T15:07:41Z'>
		Do we have a solution for this? I'm trying to reload the .meta file for a model that I downloaded from  this colab notebook &lt;denchmark-link:https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/asr_transformer.ipynb#scrollTo=Qz5u2O5LvShm&gt;https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/asr_transformer.ipynb#scrollTo=Qz5u2O5LvShm&lt;/denchmark-link&gt;
. The following code
&lt;denchmark-code&gt;sess = tf.Session()
new_saver = tf.train.import_meta_graph('t2t_checkpoints/model.ckpt-230000.meta')

&lt;/denchmark-code&gt;

throws this error
&lt;denchmark-code&gt;---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-8-05d93930a4a2&gt; in &lt;module&gt;
      1 sess = tf.Session()
----&gt; 2 new_saver = tf.train.import_meta_graph('t2t_checkpoints/model.ckpt-230000.meta')

~/transformer/lib/python3.5/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1447   return _import_meta_graph_with_return_elements(meta_graph_or_file,
   1448                                                  clear_devices, import_scope,
-&gt; 1449                                                  **kwargs)[0]
   1450 
   1451 

~/transformer/lib/python3.5/site-packages/tensorflow/python/training/saver.py in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)
   1471           import_scope=import_scope,
   1472           return_elements=return_elements,
-&gt; 1473           **kwargs))
   1474 
   1475   saver = _create_saver_from_imported_meta_graph(meta_graph_def, import_scope,

~/transformer/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements)
    855         input_map=input_map,
    856         producer_op_list=producer_op_list,
--&gt; 857         return_elements=return_elements)
    858 
    859     # TensorFlow versions before 1.9 (not inclusive) exported SavedModels

~/transformer/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--&gt; 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

~/transformer/lib/python3.5/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    398   if producer_op_list is not None:
    399     # TODO(skyewm): make a copy of graph_def so we're not mutating the argument?
--&gt; 400     _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    401 
    402   graph = ops.get_default_graph()

~/transformer/lib/python3.5/site-packages/tensorflow/python/framework/importer.py in _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
    158     # Remove any default attr values that aren't in op_def.
    159     if node.op in producer_op_dict:
--&gt; 160       op_def = op_dict[node.op]
    161       producer_op_def = producer_op_dict[node.op]
    162       # We make a copy of node.attr to iterate through since we may modify

KeyError: 'ParallelInterleaveDataset'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='prateethvnayak' date='2019-06-27T17:29:50Z'>
		The solution for this is to update the serialized checkpoint, replacing occurrences of ParallelInterleaveDataset with ExperimentalParallelInterleaveDataset.
		</comment>
		<comment id='7' author='prateethvnayak' date='2019-06-27T18:12:14Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Thank you for your reply! What about  instances? Leaving them unchanged causes the same error. Changing them to  cases 
		</comment>
		<comment id='8' author='prateethvnayak' date='2019-06-27T18:22:34Z'>
		All experimental tf.data ops renamed as part of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/bf70c447d68070e81c1dbc2ebf0b6b0d8ae2c597&gt;bf70c44&lt;/denchmark-link&gt;
 need to be updated accordingly.
		</comment>
		<comment id='9' author='prateethvnayak' date='2019-06-27T18:24:32Z'>
		Notably, ParallelInterleaveDatasetV2 should not be renamed. I suspect that when you replaced ParallelInterleaveDataset to ExperimentalParallelInterleaveDataset you also accidentally renamed ParallelInterleaveDatasetV2 to ExperimentalParallelInterleaveDatasetV2.
		</comment>
		<comment id='10' author='prateethvnayak' date='2019-07-01T13:38:08Z'>
		Any updates on this keyerror ?
There is also another KeyError called FixedLengthDatasetV2.
		</comment>
		<comment id='11' author='prateethvnayak' date='2019-07-01T13:51:11Z'>
		Do you mean FixedLengthRecordDatasetV2? That operation has not been renamed, so I suspect that is a different issue. Please create a separate issue with details on how to reproduce the error.
		</comment>
		<comment id='12' author='prateethvnayak' date='2019-07-01T14:04:10Z'>
		Hello &lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
. Thanks a lot for your help. What's the best way to update the serialized checkpoint? I tried replacing occurrences (as you suggested) using vim, but now I have a corrupted checkpoint file. Also, do I have to update  to  in Tensorflow files such as , , , and .
		</comment>
		<comment id='13' author='prateethvnayak' date='2019-07-01T16:26:24Z'>
		I think the best way would be to write a simple program that reads the checkpoint file, parses the proto the file contains (I believe this would be &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/meta_graph.proto&gt;metagraph&lt;/denchmark-link&gt;
, then walks the data structure to update all occurrences of the renamed transformations, and saves the updated proto to a new file.
If you do not mind sharing your checkpoint file, I can write the utility for you and share it via my github.
		</comment>
		<comment id='14' author='prateethvnayak' date='2019-07-01T16:46:42Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 That would be great. I really couldn't find a way to manipulate metagraph to remove those nodes and replace with a simple placeholder.
TF suggests to use  tools for which you need to bazel build it.
How can I share the meta+ckpt files with you ?
		</comment>
		<comment id='15' author='prateethvnayak' date='2019-07-01T17:09:29Z'>
		How big is it? Could you use Google Drive or Dropbox and share a link to it?
		</comment>
		<comment id='16' author='prateethvnayak' date='2019-07-01T17:18:33Z'>
		
How big is it? Could you use Google Drive or Dropbox and share a link to it?

The link is in the issue description.
		</comment>
		<comment id='17' author='prateethvnayak' date='2019-07-03T00:58:51Z'>
		Is using tf-nightly an option for you? Instead of providing a tool for fixing the checkpoint, I am leaning towards fixing TensorFlow to be able to read the checkpoint. However, this change would only be available in the nightly build.
		</comment>
		<comment id='18' author='prateethvnayak' date='2019-07-03T01:36:10Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
, I think rather than fixing in nightly-build, its better to update the model-zoo models stripped off these experimental nodes.
yes nightly-build does help, but hope it gels well with other tf operations. It would be really great if you could provide a snippet on how you strip off such nodes. I never really go-to use the graph-transform tools that level since we need to bazel build it
		</comment>
		<comment id='19' author='prateethvnayak' date='2019-07-09T14:50:28Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Any leads on the error ?
		</comment>
		<comment id='20' author='prateethvnayak' date='2019-07-09T22:37:48Z'>
		&lt;denchmark-link:https://github.com/prateethvnayak&gt;@prateethvnayak&lt;/denchmark-link&gt;
 it is not possible to fix the model-zoo model in a way that would work with all versions of Tensorflow.
Note that the tf-nightly build of TensorFlow should now correctly handle the model thanks to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/de9c460b06b437a44ebb3d795d9ff3cc20a8c4f1&gt;de9c460&lt;/denchmark-link&gt;
. Could you please verify that the error is indeed no longer present? Thank you.
		</comment>
		<comment id='21' author='prateethvnayak' date='2019-08-02T00:22:07Z'>
		I'm not familiar with this code, so unassigning myself.
		</comment>
		<comment id='22' author='prateethvnayak' date='2019-08-02T00:22:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29751&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29751&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='prateethvnayak' date='2019-11-19T09:07:45Z'>
		In tensorflow 1.12,  also has the problem.
How could I give a workaround.
Thanks!
		</comment>
		<comment id='24' author='prateethvnayak' date='2020-03-26T00:09:20Z'>
		Is the proposed find/replace solution above still recommended?
I'm running into this problem when attempting to write the imported meta graph from this object detection api model: &lt;denchmark-link:http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz&gt;http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import tensorflow as tf

sess = tf.Session()
tf.train.import_meta_graph("/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03/model.ckpt.meta")
tf.summary.FileWriter("__tb", sess.graph)
&lt;/denchmark-code&gt;

My tf version is 1.14.0
NOTE: I'm writing this file to view the output ops in tensorboard so that I can then use tf 1.14.0's freeze_graph() function to then save a frozen graph of the model and perform inference with it.
		</comment>
		<comment id='25' author='prateethvnayak' date='2020-03-26T00:51:16Z'>
		Yes, the best know solution is to update the serialized checkpoint, replacing occurrences of ParallelInterleaveDataset with ExperimentalParallelInterleaveDataset.
		</comment>
		<comment id='26' author='prateethvnayak' date='2020-03-26T03:06:43Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Thanks for the information.  Do you know of a resource explaining how to do this?  I noticed earlier in this thread, that some were having trouble doing the replacement.
		</comment>
		<comment id='27' author='prateethvnayak' date='2020-06-04T15:44:02Z'>
		&lt;denchmark-link:https://github.com/jdcast&gt;@jdcast&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 I had the same issue, but somehow fixed it by the following code on TF 1.14.0.
I hope this would be helpful to you.
import os

from google.protobuf import text_format
import tensorflow as tf


def read_meta_graph_file(filename):
    # https://github.com/tensorflow/tensorflow/blob/87989f69597d6b2d60de8f112e1e3cea23be7298/tensorflow/python/framework/meta_graph.py#L670  # NOQA
    meta_graph_def = tf.MetaGraphDef()
    if not tf.gfile.Exists(filename):
        raise IOError("File %s does not exist." % filename)
    file_content = tf.gfile.GFile(filename, "rb").read()
    try:
        meta_graph_def.ParseFromString(file_content)
        return meta_graph_def
    except Exception:
        pass

    try:
        text_format.Merge(file_content.decode("utf-8"), meta_graph_def)
    except text_format.ParseError as e:
        raise IOError("Cannot parse file %s: %s." % (filename, str(e)))

    return meta_graph_def


# https://raw.githubusercontent.com/tensorflow/tensorflow/87989f69597d6b2d60de8f112e1e3cea23be7298/tensorflow/core/ops/compat/ops_history.v1.pbtxt  # NOQA
# EDIT HERE
_CONVERSION = {
    'ParallelInterleaveDataset': 'ExperimentalParallelInterleaveDataset',
    'MapAndBatchDatasetV2': 'ExperimentalMapAndBatchDataset',
}


def _rename_op(s):
    for k, v in _CONVERSION.items():
        if k in s:
            return s.replace(k, v)
    return s


def convert(input_file, output_file):
    meta_graph_def = read_meta_graph_file(input_file)
    for node in meta_graph_def.graph_def.node:
        node.name = _rename_op(node.name)
        node.op = _rename_op(node.op)
        node.input[:] = [_rename_op(s) for s in node.input]
    tf.io.write_graph(meta_graph_def,
                      os.path.dirname(output_file),
                      os.path.basename(output_file),
                      as_text=False)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--meta_file", required=True)
    parser.add_argument("--output_file", required=True)
    parser.add_argument("--check", action="store_true")
    args = parser.parse_args()
    convert(args.meta_file, args.output_file)
    if args.check:
        _saver = tf.train.import_meta_graph(args.output_file)
		</comment>
		<comment id='28' author='prateethvnayak' date='2020-08-19T12:01:35Z'>
		
In tensorflow 1.12, also has the problem.
How could I give a workaround.
Thanks!

Have you solve the problem? I have the same problem with you.
		</comment>
	</comments>
</bug>