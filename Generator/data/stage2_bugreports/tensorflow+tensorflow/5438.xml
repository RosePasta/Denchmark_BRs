<bug id='5438' author='wangyang0918' open_date='2016-11-07T06:56:32Z' closed_time='2016-11-17T22:53:03Z'>
	<summary>TensorBoard could not refresh automatically when use HDFS path as logdir?</summary>
	<description>
Environment
&lt;denchmark-link:https://github.com/tensorflow/ecosystem/blob/master/docker/Dockerfile.hdfs&gt;https://github.com/tensorflow/ecosystem/blob/master/docker/Dockerfile.hdfs&lt;/denchmark-link&gt;

I use the following command to start a tensorflow job. It works well. However, the tensor board could not refresh automatically unless restart the tensor board server.
&lt;denchmark-code&gt;
python mnist.py --data_dir=hdfs://hdpalt/user/danrtsey.wy/mnist-data --train_dir=hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;
tensorboard --logdir=hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1
&lt;/denchmark-code&gt;

BTW, i find the file size of event file on HDFS does not update. Although, the content has changed. Is this the reason?
&lt;denchmark-code&gt;
$hadoop fs -ls hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135
-rw-r--r--   3 yarn danrtsey.wy         40 2016-11-07 14:29 hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;
$hadoop fs -cat hdfs://hdpalt/user/danrtsey.wy/.slider/checkpoints/test1/events.out.tfevents.1478500140.8e103b0b7135 | wc -l
9312
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='wangyang0918' date='2016-11-07T19:00:49Z'>
		&lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/danmane&gt;@danmane&lt;/denchmark-link&gt;
, any ideas won why this might be?
		</comment>
		<comment id='2' author='wangyang0918' date='2016-11-10T06:23:46Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/danmane&gt;@danmane&lt;/denchmark-link&gt;
, I think the reason is that when a HDFS file writing, its length got by listStatus/getFileStatus from Namenode will not be updated until the block completed or the file created with SyncFlag.UPDATE_LENGTH. But the new data flushed from OutputStream will be available to read for new InputStream. A workaround is to reopen the inputstream repeatedly, like the implementation of HBase replication.
		</comment>
		<comment id='3' author='wangyang0918' date='2016-11-17T22:53:03Z'>
		Fixed internally and will show up during the next commit sync within a day or so.
We now reopen the inputstream upon reaching EOF as suggested by &lt;denchmark-link:https://github.com/RenChunde&gt;@RenChunde&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='wangyang0918' date='2016-11-17T22:53:51Z'>
		Also note that the file size still doesn't update when listing the directory, but the new contents are available for reading and show up on tensorboard.
		</comment>
		<comment id='5' author='wangyang0918' date='2016-11-18T02:14:57Z'>
		Thanks a lot for your attention to this issue. I will help to confirm after the next commit sync.
		</comment>
	</comments>
</bug>