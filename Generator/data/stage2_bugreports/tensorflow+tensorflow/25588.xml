<bug id='25588' author='nhubbard' open_date='2019-02-07T14:25:02Z' closed_time='2019-07-29T13:55:46Z'>
	<summary>Object Detection: Build for TF Lite Demo completes successfully, but custom model fails with operations error</summary>
	<description>
Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 29 x86_64
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Moto Z3 Play
TensorFlow installed from (source or binary): Source
TensorFlow version: v1.12.0 or v1.13.0-rc0
Python version: 3.6 latest revision
Installed using virtualenv? pip? conda?: virtualenv
Bazel version (if compiling from source): 0.21
GCC/Compiler version (if compiling from source): gcc (GCC) 8.2.1 20181215 (Red Hat 8.2.1-6)
CUDA/cuDNN version: none, TPU used for training
GPU model and memory: none, TPU used for training

Describe the problem
Provide the exact sequence of commands / steps that you executed before running into the problem


Model built using TPU training command listed in documentation for running on the cloud


Model downloaded from Google Cloud storage bucket


Exported model using:


python -m object_detection/export_tflite_ssd_graph \
--pipeline_config_path=$CONFIG_FILE \
--trained_checkpoint_prefix=$CHECKPOINT_PATH \
--output_directory=$OUTPUT_DIR \
--add_postprocessing_op=true

Converted model using TOCO:

bazel run -c opt //tensorflow/contrib/lite/toco:toco \
--incompatible_package_name_is_a_function=false \
-- \
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \
--input_shapes=1,640,640,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
--inference_type=FLOAT \
--allow_custom_ops


Edited the Bazel BUILD file to include exported model, and edited DetectionActivity to include custom model and change to non-quantized ops.


Built application using:


bazel build -c opt --config=android_arm64 --cxxopt='--std=c++11' "//tensorflow/contrib/lite/examples/android:tflite_demo"

Ran demo with Android Studio APK profiler, and observed the following error message using Logcat: (snipped for clarity)

&lt;denchmark-code&gt;Cannot create interpreter: Didn't find custom op for name 'ResizeNearestNeighbor' with version 1
&lt;/denchmark-code&gt;

Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Here are all of the files that I have present:

Training Configuration: https://storage.cloud.google.com/robocubs-ml/debug/config/tpu.config
Checkpoint Files

Checkpoint Descriptor: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/checkpoint
Graph: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/graph.pbtxt
Checkpoint Data: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/model.ckpt-246400.data-00000-of-00001
Checkpoint Index: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/model.ckpt-246400.index
Checkpoint Meta: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/model.ckpt-246400.meta
Pipeline Config: https://storage.cloud.google.com/robocubs-ml/debug/checkpoint/pipeline.config


Saved Model

Checkpoint Descriptor: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/checkpoint
Frozen Inference Graph: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/checkpoint
Checkpoint Data: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/model.ckpt.data-00000-of-00001
Checkpoint Index: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/model.ckpt.index
Checkpoint Meta: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/model.ckpt.meta
Pipeline Config: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/pipeline.config
Saved Model: https://storage.cloud.google.com/robocubs-ml/debug/exported_model/saved_model/saved_model.pb


TensorFlow Lite Files

TFLite Graph: https://storage.cloud.google.com/robocubs-ml/debug/tflite/tflite_graph.pb
TFLite Graph (PBTXT): https://storage.cloud.google.com/robocubs-ml/debug/tflite/tflite_graph.pbtxt
Final TFLite Model: https://storage.cloud.google.com/robocubs-ml/debug/tflite/detect.tflite



	</description>
	<comments>
		<comment id='1' author='nhubbard' date='2019-07-12T19:25:35Z'>
		ResizeNearestNeighbor should be supported now. Can you check out the source from head and try again? Thanks.
		</comment>
		<comment id='2' author='nhubbard' date='2019-07-27T12:23:01Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='3' author='nhubbard' date='2019-07-29T13:55:46Z'>
		Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!
		</comment>
		<comment id='4' author='nhubbard' date='2019-07-29T13:55:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=25588&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=25588&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>