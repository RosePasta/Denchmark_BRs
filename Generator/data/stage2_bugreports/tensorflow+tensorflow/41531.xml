<bug id='41531' author='ARozental' open_date='2020-07-18T19:34:21Z' closed_time='2020-08-17T19:08:52Z'>
	<summary>tf.ragged.stack issue</summary>
	<description>
tf.ragged.stack(input) return tf.Tensor if the first dim of the input is of length 1 and tf.RaggedTensor if not.
This is a problem as those types don't share the same interface and if the length of the input is not know in advance (as is often the case when using ragged tensors) one must have in "if" condition inside the graph to check the output type.
&lt;denchmark-code&gt;tf.ragged.stack([[1,2,3]]) =&gt; tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)
tf.ragged.stack([[1,2,3],[1,2,3]]) =&gt;  &lt;tf.RaggedTensor [[1, 2, 3], [1, 2, 3]]&gt;

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ARozental' date='2020-07-20T07:20:12Z'>
		I have tried in colab with TF version 2.2, 2.3-rc1, nightly version() and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/ca64601372cfa6fe3938590894ae5d51/untitled149.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='ARozental' date='2020-08-17T19:08:52Z'>
		tf.ragged.stack's first argument is a list of tensors, not a single tensor.  And the length of that list is always known in advance (i.e., at graph-construction time).  So you don't need any conditional inside the graph here.
In general, RaggedTensor operations return a tf.Tensor if it can statically determine that the result has no ragged dimensions.  This has some advantages in terms of efficiency (Tensor operations are sometimes more efficient than RaggedTensor ops) and flexibility (tf.Tensor supports more operations than RaggedTensor).  So this is working as intended.
That said, I agree that it's annoying to have an API that may return either a Tensor or a RaggedTensor since, as you point out, they have somewhat different interfaces.  This is a side-effect of the current RaggedTensor design, where ragged tensors are defined recursively, and you can't create a RaggedTensor with rank&lt;2.  We have some thoughts about how RaggedTensor could be refactored to avoid this (so ragged ops and ops that take ragged inputs would always return a RaggedTensor object, even if the result has no ragged dimensions); but it's somewhat difficult to change in a backwards-compatible way.
For now, I think the best solution for your case may be to write something like the following:
&lt;denchmark-code&gt;x = tf.ragged.stack([[1,2,3]])
if isinstance(x, tf.Tensor):
  x = tf.RaggedTensor.from_tensor(x)
&lt;/denchmark-code&gt;

(Note that this will fail with a shape error if x.shape.rank&lt;2, since RaggedTensor can currently only be used if rank&gt;=2.  Also, depending on what you're doing downstream of this operation, you may want to explicitly specify ragged_rank when calling from_tensor.)
		</comment>
		<comment id='3' author='ARozental' date='2020-08-17T19:08:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41531&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41531&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>