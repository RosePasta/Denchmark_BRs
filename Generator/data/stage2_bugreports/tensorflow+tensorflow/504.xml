<bug id='504' author='FreakTheMighty' open_date='2015-12-14T01:12:32Z' closed_time='2016-06-06T20:01:47Z'>
	<summary>Transfer learning tutorial</summary>
	<description>
The &lt;denchmark-link:https://www.tensorflow.org/versions/master/tutorials/image_recognition/index.html#usage-with-python-api&gt;image recognitions tutorial&lt;/denchmark-link&gt;
 suggests exploring transfer learning as an exercise. I would like to see a tutorial dedicated to the topic and would be especially interested in transfer learning using the Inception-V3 model.
	</description>
	<comments>
		<comment id='1' author='FreakTheMighty' date='2015-12-17T00:15:58Z'>
		If there is anyone with more knowledge than me, I'd be interested in collaborating on this.
		</comment>
		<comment id='2' author='FreakTheMighty' date='2016-01-14T04:16:10Z'>
		+1
		</comment>
		<comment id='3' author='FreakTheMighty' date='2016-01-14T11:18:17Z'>
		It could be interesting to add something about extension of net archs without scratch retraining if there are plans to introduce &lt;denchmark-link:http://arxiv.org/abs/1511.05641&gt;Net2Net&lt;/denchmark-link&gt;
 in Tensorflow. There is already an &lt;denchmark-link:https://github.com/soumith/net2net.torch&gt;initial Torch implementation&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='FreakTheMighty' date='2016-01-14T18:07:34Z'>
		I think this Caffe tutorial is a pretty good template &lt;denchmark-link:http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html&gt;http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='FreakTheMighty' date='2016-01-21T17:55:36Z'>
		+1 A tutorial on transfer learning would be fantastic!
		</comment>
		<comment id='6' author='FreakTheMighty' date='2016-01-21T23:48:40Z'>
		+1
		</comment>
		<comment id='7' author='FreakTheMighty' date='2016-01-24T11:52:19Z'>
		&lt;denchmark-link:https://github.com/goodfeli&gt;@goodfeli&lt;/denchmark-link&gt;
 Is there any plan to make a PR of your Net2Net tensorflow implementation?
		</comment>
		<comment id='8' author='FreakTheMighty' date='2016-01-24T17:44:08Z'>
		&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 Currently there is no plan in place. Tianqi wrote our Net2Net implementation during his summer internship, before TensorFlow was ready for release. API changes to TensorFlow that preceded the release broke the Net2Net code. I currently don't have time to repair it because I am working full time on the Deep Learning textbook (&lt;denchmark-link:http://www.deeplearningbook.org&gt;www.deeplearningbook.org&lt;/denchmark-link&gt;
).
Also, Net2Net is "knowledge transfer" which is different from "transfer learning." Transfer learning is when one net does well on two tasks, because it can transfer something it has learned from the first task to the second task. Knowledge transfer is when two nets do well on the same task, because the second net has copied the knowledge of how to do the task from the first.
		</comment>
		<comment id='9' author='FreakTheMighty' date='2016-01-24T18:13:54Z'>
		Thank you I did not know this specific sub differentiation. I thought that you can easily mix both: transfer on another task and then let the arch to expand in width and depth to better adapt on the new task.
		</comment>
		<comment id='10' author='FreakTheMighty' date='2016-01-25T07:39:49Z'>
		/cc &lt;denchmark-link:https://github.com/tqchen&gt;@tqchen&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='FreakTheMighty' date='2016-02-14T18:24:35Z'>
		+1
		</comment>
		<comment id='12' author='FreakTheMighty' date='2016-02-14T18:50:13Z'>
		Check out examples/image_retraining on master. It's not a tutorial yet, but &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 is working on it.
		</comment>
		<comment id='13' author='FreakTheMighty' date='2016-02-14T19:00:12Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 This is fantastic! Thanks for alerting us.
		</comment>
		<comment id='14' author='FreakTheMighty' date='2016-02-14T19:02:05Z'>
		To be explicit this is an example of retraining the final layer of Inception and leaving the convolutional weights untouched. We see this as being at one end of the spectrum; it's extremely quick to train (e.g. 30 mins on a single CPU), but won't give quite as good results as fine-tuning all the weights (which takes longer).
We plan to support full retraining too, and training from scratch, but wanted to make this example available as soon as it was complete. We haven't updated the website yet (we're still sorting out the large protobuf loading issue that currently requires hacks to the protobuf lib source - &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/836&gt;#836&lt;/denchmark-link&gt;
) but the usage guide is here:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='FreakTheMighty' date='2016-02-14T19:21:30Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Pete, this is a great start. Thanks for your work on this.
		</comment>
		<comment id='16' author='FreakTheMighty' date='2016-02-14T19:24:50Z'>
		Agreed. Thanks Pete
		</comment>
		<comment id='17' author='FreakTheMighty' date='2016-02-15T18:56:05Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Thank you for this great work. We are waiting full retraining too.
		</comment>
		<comment id='18' author='FreakTheMighty' date='2016-02-17T17:07:50Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
  I  follow the instructions in order to retrain the model with new flower photos. I put both  new output files (pb and txt file) to the label image example. I get this error
E tensorflow/examples/label_image/main.cc:302] Running model failed: Not found: FetchOutputs node softmax: not found
		</comment>
		<comment id='19' author='FreakTheMighty' date='2016-02-17T19:02:09Z'>
		You need to pass in the name of the new output layer, 'final_output' (edit - that should be 'final_result'), as the output_layer flag to label_image. I'll update the tutorial documentation to add this info, apologies for the confusion.
		</comment>
		<comment id='20' author='FreakTheMighty' date='2016-02-19T02:10:59Z'>
		+1
		</comment>
		<comment id='21' author='FreakTheMighty' date='2016-02-22T08:01:09Z'>
		Can anyone help me out in modifying the android demo? I successfully trained with the flowers data set and put the .pb and .txt and in the assets folder and did the respective changes to the names of the files in the source code. When I ran it, I didn't see any labelling happening. I tried changing the number of classes in the TensorFlowListener class but that didn't do anything. I believe I have to do something similar to as &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 mentioned with the output_layer flag(?!) but I don't know where to do that in the android demo.
		</comment>
		<comment id='22' author='FreakTheMighty' date='2016-02-22T10:37:53Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Hi pete, I also ran the label image example and the --output_layer flag should point to 'final_result' but not 'final_output' as it is defined in the retrain.py
		</comment>
		<comment id='23' author='FreakTheMighty' date='2016-02-22T12:15:15Z'>
		Some more things I tried to do with the android demo were changing the output_tensor_names output:0 to pool_3, pool_3:0, softmax and input tensor name input:0 to Mul, Mul:0. I am confused that in the main.cc of label images example, Mul and pool3 etc. works whereas output:0 and input:0 don't work and this is the opposite case in the android demo.
		</comment>
		<comment id='24' author='FreakTheMighty' date='2016-02-22T16:35:42Z'>
		Apologies for my typo above, I've corrected it to read final_result. I will also be adding examples of how to load the models in label_image and classify_image.py.
The port/without port syntax is confusing too, I'll look into why that's different between the demos. In general we use the bare name to reference an operator, and the port version to grab the output of an op.
		</comment>
		<comment id='25' author='FreakTheMighty' date='2016-02-22T21:36:41Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Hi Pete, thank you for your reply. I have been hammering on this all day and still haven't figured it out. I noticed there is a GraphDefBuilder that creates the nodes for the label_image example. Where is that in the Android Demo? Are the nodes created in some different way? If so, is it possible that not having the GraphDefBuilder is causing the port/without port problem? Ty.
		</comment>
		<comment id='26' author='FreakTheMighty' date='2016-02-23T00:51:52Z'>
		The Android code doesn't use GraphDefBuilder, it just loads the file directly into a GraphDef:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc#L91&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc#L91&lt;/denchmark-link&gt;

As long as you make sure you've added your model file as an asset, that should work to load it.
There are some additional parameters you'll need to change, like the input image size and the 'mean' to subtract from all the inputs, and you'll need to add a standard deviation parameter too:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc#L45&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/jni/tensorflow_jni.cc#L45&lt;/denchmark-link&gt;

If you look at the default values for those flags in label_image, that should help.
What's the exact error that you're hitting by the way? That may help be more targeted in my ideas.
		</comment>
		<comment id='27' author='FreakTheMighty' date='2016-03-04T16:55:13Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Everything works fantastically if I do it with Bazel, but I'm trying to use the output_graph.pb files and output_labels.txt files with the image_classify.py file, not just the label image example.
		</comment>
		<comment id='28' author='FreakTheMighty' date='2016-04-07T07:28:33Z'>
		&lt;denchmark-link:https://github.com/oweingrod&gt;@oweingrod&lt;/denchmark-link&gt;
 Hi, did you get your code working?
		</comment>
		<comment id='29' author='FreakTheMighty' date='2016-04-12T16:41:03Z'>
		Yes. You have to manually write the ".pbtxt" file so your UIDs can map with your classes.
		</comment>
		<comment id='30' author='FreakTheMighty' date='2016-04-16T22:06:33Z'>
		Hi, I am working on retraining Inception's Final Layer for New Categories. I am following steps at - &lt;denchmark-link:https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training&gt;https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training&lt;/denchmark-link&gt;

The build step(bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain)for the retrainer is working good. But when I try to run the second step -   bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos, I encounter below error : -bash: bazel-bin/examples/image_retraining/retrain.py: No such file or directory
I would appreciate some help or suggestions on this. Thanks.
		</comment>
		<comment id='31' author='FreakTheMighty' date='2016-04-17T07:33:37Z'>
		&lt;denchmark-link:https://github.com/dhananjaymehta&gt;@dhananjaymehta&lt;/denchmark-link&gt;
: I would file a separate bug for that issue.
		</comment>
		<comment id='32' author='FreakTheMighty' date='2016-04-17T18:59:29Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Thanks for the suggestion, I will open a new bug for the issue.
		</comment>
		<comment id='33' author='FreakTheMighty' date='2016-04-20T06:58:04Z'>
		&lt;denchmark-link:https://github.com/oweingrod&gt;@oweingrod&lt;/denchmark-link&gt;
: can you point me to where i can learn how that is done (re: "*.pbtxt")?
got past  and it's the key to my next problem.
&lt;denchmark-code&gt;  File "tensorflow/models/image/imagenet/classify_image.py", line 82, in __init__
    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)
  File "tensorflow/models/image/imagenet/classify_image.py", line 125, in load
    name = uid_to_human[val]
KeyError: 'n02119789'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='34' author='FreakTheMighty' date='2016-04-20T07:22:30Z'>
		&lt;denchmark-link:https://github.com/josefmonje&gt;@josefmonje&lt;/denchmark-link&gt;
 If you're retraining on your own images, then the label files which are generated will also be different. The default code uses two different files to map whatever prediction the model gave, into the human readable form. Is your data set also like that?
The mapping file which you require should be automatically generated while training with the bazel command. One .pb file, and one .txt file will be generated by default.
		</comment>
		<comment id='35' author='FreakTheMighty' date='2016-04-20T07:31:43Z'>
		@eldor4do: i have output_graph.pb and output_labels.txt from retraining. i'm missing the .pbtxt file this part of the code is supposed to look for it.
		</comment>
		<comment id='36' author='FreakTheMighty' date='2016-04-20T07:44:27Z'>
		&lt;denchmark-link:https://github.com/josefmonje&gt;@josefmonje&lt;/denchmark-link&gt;
 Check from here, maybe this will be useful. &lt;denchmark-link:https://github.com/eldor4do/Tensorflow-Examples/blob/master/retraining-example.py#L82&gt;https://github.com/eldor4do/Tensorflow-Examples/blob/master/retraining-example.py#L82&lt;/denchmark-link&gt;

I do not think it needs the .pbtxt file, only the output_labels.txt file should be enough.
		</comment>
		<comment id='37' author='FreakTheMighty' date='2016-04-20T08:01:54Z'>
		thanks @eldor4do! worked for me. made some edits to work with Python 3 and sent PR üëç
		</comment>
		<comment id='38' author='FreakTheMighty' date='2016-04-20T14:18:29Z'>
		That's a very useful example @eldor4do, thanks! I will update the docs to point to that, if you don't mind?
		</comment>
		<comment id='39' author='FreakTheMighty' date='2016-04-20T14:23:10Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Sure,  no problem!
&lt;denchmark-link:https://github.com/josefmonje&gt;@josefmonje&lt;/denchmark-link&gt;
 welcome! and i merged your PR
		</comment>
		<comment id='40' author='FreakTheMighty' date='2016-06-06T18:51:24Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
: This thread seems to have deviated quite a bit from the original request.  Should we mark it resolved and reopen other issues as required?
		</comment>
		<comment id='41' author='FreakTheMighty' date='2016-06-06T19:53:02Z'>
		+1
On Mon, Jun 6, 2016 at 11:51 AM Geoffrey Irving &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;

wrote:

@petewarden https://github.com/petewarden: This thread seems to have
deviated quite a bit from the original request. Should we mark it resolved
and reopen other issues as required?
‚Äî
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub
#504 (comment),
or mute the thread
https://github.com/notifications/unsubscribe/AAjO_SFTinXLttgqlwUgZtN09xXNO6Mgks5qJGw7gaJpZM4G0cHg
.

		</comment>
		<comment id='42' author='FreakTheMighty' date='2016-06-06T20:02:23Z'>
		Resolving for now, please open more specific issues if problems persist, or ask on StackOverflow if  you have questions.
		</comment>
		<comment id='43' author='FreakTheMighty' date='2017-01-11T11:30:51Z'>
		&lt;denchmark-link:https://github.com/syed-ahmed&gt;@syed-ahmed&lt;/denchmark-link&gt;
 .
Can you please tell me how you created .pb file from model.ckpt.
Thanks.
		</comment>
		<comment id='44' author='FreakTheMighty' date='2017-01-11T23:40:58Z'>
		&lt;denchmark-link:https://github.com/Bruczzz&gt;@Bruczzz&lt;/denchmark-link&gt;
 Hi, you can check out this script: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py&gt;freeze_graph.py&lt;/denchmark-link&gt;
. Also, pete warden has posted a nice documentation on deployment. Check it out: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md&gt;Graph Transform Tool&lt;/denchmark-link&gt;

		</comment>
		<comment id='45' author='FreakTheMighty' date='2017-01-12T07:39:32Z'>
		Thanks &lt;denchmark-link:https://github.com/syed-ahmed&gt;@syed-ahmed&lt;/denchmark-link&gt;
 .
I tried retraining model specified in &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/inception/README.md&gt;https://github.com/tensorflow/models/blob/master/inception/README.md&lt;/denchmark-link&gt;

and i tried this on CPU version of tensorflow . i can create model.ckpt files and checkpoints. How to convert into .pb file .
And I tired &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md&lt;/denchmark-link&gt;

this way also. gen/head is not declared error occurred ... so i tried running ./configure , this is asking for cuda version and location. but i am not using GPU version. I dont know how to proceed further? Can you Please help?
		</comment>
		<comment id='46' author='FreakTheMighty' date='2017-01-12T11:02:04Z'>
		&lt;denchmark-link:https://github.com/syed-ahmed&gt;@syed-ahmed&lt;/denchmark-link&gt;
  I have figured out the issue. Its running fine now .
It will be helpfull ,if you tell how to train a model from scratch with our own image data set.
		</comment>
		<comment id='47' author='FreakTheMighty' date='2017-09-12T02:43:01Z'>
		Hi &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 ,
Thanks for such a usefull example for retraining inception.
But this sample uses a .pb file for retraining.Is there a method to use .ckpt for retraining?
If so any sample code would be of great help.
There is not much clarity if the same can be done for other opensource models such as Resnet50,101, etc
It would be very kind of you if you could guide on this.
Thanks
		</comment>
		<comment id='48' author='FreakTheMighty' date='2017-09-14T01:14:00Z'>
		&lt;denchmark-link:https://github.com/Bruczzz&gt;@Bruczzz&lt;/denchmark-link&gt;
 it sounds like you were able to get around your .ckpt-&gt;.pb file problems. Can you please share what the fix was?
		</comment>
		<comment id='49' author='FreakTheMighty' date='2018-02-20T10:56:45Z'>
		&lt;denchmark-link:https://github.com/cy89&gt;@cy89&lt;/denchmark-link&gt;
 since I also managed to do transfer learning with checkpoints I might as well chime in.
Note that this is using tf.slim and python.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.contrib.slim.nets import inception as nn_architecture
from tensorflow.contrib import slim

with slim.arg_scope(nn_architecture.inception_v3_arg_scope()):
    logits, endpoints = nn_architecture.inception_v3(images, 
                                                     num_classes=10,
                                                     is_training=True)

#these nodes are not loaded from the checkpoint and are left uninitialized  
retrain = ['InceptionV3/Logits', 'InceptionV3/AuxLogits', 'InceptionV3/Mixed_7c', 'InceptionV3/Mixed_7b'] 
variables_to_restore = slim.get_variables_to_restore(exclude=retrain)  # this checks the current graph, so no custom nodes can be defined at this point, only those from create_network()

sess = tf.Session()
saver = tf.train.Saver(variables_to_restore)
saver.restore(sess, CHECKPOINT_PATH)

#specify which layers should be trained, all others will not be touched
variables_to_train = tf.trainable_variables('InceptionV3/Logits') + tf.trainable_variables('InceptionV3/AuxLogits') + tf.trainable_variables('InceptionV3/Mixed_7c') + tf.trainable_variables('InceptionV3/Mixed_7b')

train_step = slim.learning.create_train_op(total_loss, optimizer, variables_to_train=variables_to_train) 
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/Syzygy2048/OverheadVehicleDetection/tree/master/mnist&gt;Here&lt;/denchmark-link&gt;
 you can find a working example for the mnist dataset with inception, resnet and resception
		</comment>
	</comments>
</bug>