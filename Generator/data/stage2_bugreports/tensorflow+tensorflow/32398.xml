<bug id='32398' author='ghannum' open_date='2019-09-10T22:35:01Z' closed_time='2020-03-13T16:01:22Z'>
	<summary>ValueError from invalid weights while loading older .h5 model</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version: 1.13.1 &amp; v1.12.1-10753-g1c2ae57 2.0.0-dev20190910
Python version: 3.7.4
CUDA/cuDNN version: 10.1
GPU model and memory:

Describe the current behavior
I created a tfkeras model and saved it to .h5 format using TF version 1.13.1. The model can be loaded and used for inference just fine in 1.13.1. After upgrading to TF 2.0 (nightly build), loading the model results in a ValueError (see traceback below).
I am using tf.compat.v1.disable_v2_behavior() in case that might make a difference.
Describe the expected behavior
V1 models should load correctly, or present the user with a way to migrate the model to a more compatible format.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Relevant traceback info:
&lt;denchmark-code&gt;  File "*/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py", line 146, in load_mode
l
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File "*/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 171, in lo
ad_model_from_hdf5
    load_weights_from_hdf5_group(f['model_weights'], model.layers)
  File "*/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 697, in lo
ad_weights_from_hdf5_group
    str(len(weight_values)) + ' elements.')
ValueError: Layer #1 (named "encoder_bn_0" in the current model) was found to correspond to layer encoder_bn_0 in the save file. However t
he new layer encoder_bn_0 expects 7 weights, but the saved weights have 8 elements.
&lt;/denchmark-code&gt;

I added some print statements to get info on the weights for this batchnorm (w. renorm) layer. The names for the weights in the original model are:
&lt;denchmark-code&gt;['encoder_bn_0/gamma:0', 'encoder_bn_0/beta:0', 'encoder_bn_0/moving_mean:0', 'encoder_bn_0/moving_variance:0', 'encoder_bn_0/renorm_mean:
0', 'encoder_bn_0/renorm_mean_weight:0', 'encoder_bn_0/renorm_stddev:0', 'encoder_bn_0/renorm_stddev_weight:0']
&lt;/denchmark-code&gt;

The expected weight placeholders are:
&lt;denchmark-code&gt;[&lt;tf.Variable 'encoder_bn_0/gamma:0' shape=(96,) dtype=float32&gt;, &lt;tf.Variable 'encoder_bn_0/beta:0' shape=(96,) dtype=float32&gt;, &lt;tf.Variab
le 'encoder_bn_0/moving_mean:0' shape=(96,) dtype=float32&gt;, &lt;tf.Variable 'encoder_bn_0/moving_variance:0' shape=(96,) dtype=float32&gt;, &lt;tf.
Variable 'encoder_bn_0/moving_stddev:0' shape=(96,) dtype=float32&gt;, &lt;tf.Variable 'encoder_bn_0/renorm_mean:0' shape=(96,) dtype=float32&gt;,
&lt;tf.Variable 'encoder_bn_0/renorm_stddev:0' shape=(96,) dtype=float32&gt;]
&lt;/denchmark-code&gt;

I'm guessing the format for saving batchnorm (w.renorm) parameters changed at some point? Is there a way to make this backwards compatible? Or perhaps a way to migrate the save file?
	</description>
	<comments>
		<comment id='1' author='ghannum' date='2019-09-11T09:04:34Z'>
		&lt;denchmark-link:https://github.com/ghannum&gt;@ghannum&lt;/denchmark-link&gt;
, Make sure that your code fully compatible to TensorFlow 2.0 before  inference. Please refer the &lt;denchmark-link:https://www.tensorflow.org/beta/guide/migration_guide?hl=en&gt;Tensorflow website&lt;/denchmark-link&gt;
 for further guidance.  Thanks!
		</comment>
		<comment id='2' author='ghannum' date='2019-09-11T15:59:19Z'>
		As a first step to check TF2 compatibility, I tried running with the new 1.15-rc0 release. The error remains as-is. I don't believe this is a 2.0-specific issue. Release 1.14 works ok, so the issue is somewhere between 1.14 and 1.15/2.0.
		</comment>
		<comment id='3' author='ghannum' date='2019-09-11T16:04:22Z'>
		I also tried to load/save my model using 1.14 to effectively move the problem forward. I get the same issue trying to load it in 1.15.
		</comment>
		<comment id='4' author='ghannum' date='2019-09-12T04:00:41Z'>
		&lt;denchmark-link:https://github.com/ghannum&gt;@ghannum&lt;/denchmark-link&gt;
, Will it be possible to provide the code to reproduce the issue. Thanks!
		</comment>
		<comment id='5' author='ghannum' date='2019-09-19T17:47:38Z'>
		create_model.py
&lt;denchmark-code&gt;#!/usr/bin/env python3
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np
from tensorflow.compat.v1.keras.models import save_model

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.BatchNormalization(renorm=True),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5)

test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)

save_model(model, "model.h5")
&lt;/denchmark-code&gt;

load_model.py
&lt;denchmark-code&gt;#!/usr/bin/env python3
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np
from tensorflow.compat.v1.keras.models import load_model

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
train_images = train_images / 255.0
test_images = test_images / 255.0

model = load_model("model.h5")
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)
&lt;/denchmark-code&gt;

Here are two scripts which will reproduce the issue. The first creates a simple keras model and saves it to .h5 format. The second loads the model and prints a validation measure. If you run the first in TF1.13, the second will fail in TF1.15. This is only a problem with the BatchNormalization renorm option set to True.
		</comment>
		<comment id='6' author='ghannum' date='2019-09-20T09:51:27Z'>
		&lt;denchmark-link:https://github.com/ghannum&gt;@ghannum&lt;/denchmark-link&gt;
, Thanks for the code.
I tried on colab with Tf 2.0.0.rc1, I didn't receive any error, Please take a look at colab &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/7a0df6ba3bf7a2f0fae872eff1c710e1/untitled162.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='ghannum' date='2019-09-20T14:41:03Z'>
		It looks like you ran both scripts in Tf 2.0.0.rc1. The error only occurs if the model was created in Tf 1.13. This is a backwards-compatibility issue with the file format / parser. That gist tool is awesome btw.
		</comment>
		<comment id='8' author='ghannum' date='2019-09-23T09:04:09Z'>
		&lt;denchmark-link:https://github.com/ghannum&gt;@ghannum&lt;/denchmark-link&gt;
,
I tried with Tensorflow 1.13.1 on colab but i didn't get any error. Please see the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/f050afc522840a9706dbaeb49d37e6b7/untitled163.ipynb&gt;gist&lt;/denchmark-link&gt;
. I executed both the create model and load_model with same TF. Is there any specific reason to use two different versions of TF. Thanks!
		</comment>
		<comment id='9' author='ghannum' date='2019-09-23T14:59:50Z'>
		Thanks for trying 1.13. The error is only when the model is created in 1.13 and loaded in 1.1.5/2.0 (two different versions). The backwards compatibility is important because these models take considerable time and resources to train (months in some cases). I currently have several important models in 1.13 and would like to continue using them after upgrading to 1.15. I imagine this sort of continuous compatibility is part of the 1.X design scope. Even if the file format changes, there should be some migration path.
In this case, I've identified the difference in the renorm parameters being stored (see errors above and a summary below). Can we identify why these changes were made and how one might make them compatible? Either the code can be made to recognize both formats, or there can be some procedure to upgrade the file?
Thanks again for your help!
BatchNormalization weight names in 1.13:
&lt;denchmark-code&gt;gamma, beta, moving_mean, moving_variance, renorm_mean, renorm_mean_weight, renorm_stddev, renorm_stddev_weight
&lt;/denchmark-code&gt;

BatchNormalization weight names in 1.15/2.0:
&lt;denchmark-code&gt;gamma, beta, moving_mean, moving_variance, moving_stddev, renorm_mean, renorm_stddev
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='ghannum' date='2019-10-03T00:05:42Z'>
		I was able to reproduce the reported behavior. Built was model using TF 1.13.1 but failed to load using TF 1.15.0-rc2. It loads successfully in TF 1.14.0
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-2-3427bf5f75af&gt; in &lt;module&gt;()
     12 test_images = test_images / 255.0
     13 
---&gt; 14 model = load_model("model.h51")
     15 test_loss, test_acc = model.evaluate(test_images, test_labels)
     16 print('Test accuracy:', test_acc)

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py in load_weights_from_hdf5_group(f, layers)
    689                        str(len(symbolic_weights)) +
    690                        ' weights, but the saved weights have ' +
--&gt; 691                        str(len(weight_values)) + ' elements.')
    692     weight_value_tuples += zip(symbolic_weights, weight_values)
    693   K.batch_set_value(weight_value_tuples)

ValueError: Layer #1 (named "batch_normalization_v1" in the current model) was found to correspond to layer batch_normalization_v1 in the save file. However the new layer batch_normalization_v1 expects 7 weights, but the saved weights have 8 elements.
		</comment>
		<comment id='11' author='ghannum' date='2019-10-04T21:35:22Z'>
		Looks like the  variable was removed between 1.14 and 1.15 (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/af15fb8624a0c0eabdd00ba1653cbbd4734c3b36&gt;af15fb8&lt;/denchmark-link&gt;
). Accidentally breaking checkpoints is extremely easy. I would recommend that in the future, use the TensorFlow checkpoints (by specifying ), which are more robust when dealing with variable changes.
You can migrating the Savefile following these steps (requires using different versions of TensorFlow).
Using TensorFlow 1.13 (or 1.14):

Load the model using model = tf.keras.models.load_model
Save the model into two separate files:

model.save_weights('model_weights.ckpt', save_format='tf')
The weights file will still contain the renorm_stddev_weight variable, but will be omitted when loading.

  with open('model_config.json', 'w') as f:
    f.write(model.to_json()) 





Using TensorFlow 1.15:

Load the model:
model = tf.keras.models.model_from_json(open('model_config.json').read())
model.load_weights('model_weights.ckpt')

The batch normalization layer will not have the renorm_stddev_weight variable, but the rest of the variable values will be restored.
Now save the model by calling model.save('model.h5')

&lt;denchmark-link:https://github.com/bcoopers&gt;@bcoopers&lt;/denchmark-link&gt;
 I'm not super familiar with the BatchNormalization layer. I'm a bit concerned about correctness since a variable was entirely removed. If a model were trained using the , and then loaded without it, would it still function correctly?
		</comment>
		<comment id='12' author='ghannum' date='2019-11-19T16:10:56Z'>
		I have the same problem, but with the 2.0 beta1 and 2.0 release/tf-nightly-gpu..
		</comment>
		<comment id='13' author='ghannum' date='2019-11-19T17:37:05Z'>
		I found a temporary hack which allowed me to load the old model and get it saved into a compatible format.
I modify the file:
tensorflow_core/python/keras/saving/hdf5_format.py
&lt;denchmark-code&gt;# Temporary workaround to load old weights
if len(weight_values) != len(symbolic_weights) and len(symbolic_weights)==7:
        weight_values = weight_values[0:4] + [np.sqrt(weight_values[3])] + [weight_values[4]] + [weight_values[6]]

# Rest of the code...
if len(weight_values) != len(symbolic_weights):
      raise ValueError('Layer #' + str(k) + ' (named "' + layer.name +
...
...
...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='ghannum' date='2019-11-19T17:49:37Z'>
		Hi!
With the drop weight, you got the same result? Such as, predict or resume train
		</comment>
		<comment id='15' author='ghannum' date='2019-11-19T18:05:19Z'>
		So far it's looking correct...
		</comment>
		<comment id='16' author='ghannum' date='2020-03-11T12:39:44Z'>
		&lt;denchmark-link:https://github.com/ghannum&gt;@ghannum&lt;/denchmark-link&gt;

Is this still an issue. Please feel free to close the issue if it is resolved
		</comment>
		<comment id='17' author='ghannum' date='2020-03-13T16:01:24Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32398&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32398&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>