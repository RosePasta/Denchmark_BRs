<bug id='13336' author='dieka13' open_date='2017-09-27T07:30:22Z' closed_time='2017-12-20T01:23:14Z'>
	<summary>Cannot assign a device for operation 'save/ShardedFilename_1' when exporting custom Estimator</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux ubuntu254 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
TensorFlow installed from (source or binary):
pip
TensorFlow version (use command below):
tf.VERSION = 1.3.0
Python version:
2.7.6
Bazel version (if compiling from source):
CUDA/cuDNN version:
release 8.0, V8.0.44 / 6.0
GPU model and memory:
GTX Titan Black 6 GB, GTX 1060 6 GB
Exact command to reproduce:
run estimator_CNN.py

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Continued from &lt;denchmark-link:https://groups.google.com/a/tensorflow.org/forum/#!searchin/discuss/export/discuss/XHABHQG5l2I/jZBvc0-NBgAJ&gt;this discussion&lt;/denchmark-link&gt;
. I want to export a custom Estimator (multiple CNN layer + CTC loss in multi GPU setting derived from cifar-10 multi GPU example) using . But i encountered this error:

this should not occured in 1.3.0 (please see discussion)
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

environment &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1336111/tf_env.txt&gt;tf_env.txt&lt;/denchmark-link&gt;

full error trace &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1336110/error.txt&gt;error.txt&lt;/denchmark-link&gt;

source code &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1336108/TF_bug.zip&gt;TF_bug.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='dieka13' date='2017-09-28T16:31:05Z'>
		&lt;denchmark-link:https://github.com/ispirmustafa&gt;@ispirmustafa&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/isaprykin&gt;@isaprykin&lt;/denchmark-link&gt;

Looks like the sharded saver on GPU bug is back.
Sharded savers have a bunch of string processing ops and cannot live on GPUs. If they're forced onto GPUs by collocation, they break in this way.
I haven't looked at all the code yet, so I'm not positive yet, but I think we have to fix Saver.
		</comment>
		<comment id='2' author='dieka13' date='2017-11-15T04:13:15Z'>
		UPDATE
I have tried to export another custom Estimator (Recurrent CNN) in the same machine, trained with single GPU with latest tensorflow 1.4.0 and export it successfully.
However if I add with tf.device('/device:GPU:0') to the model function, the same error occurs even if the training just use a single GPU.
		</comment>
		<comment id='3' author='dieka13' date='2017-11-15T18:37:14Z'>
		This sounds something that likely got fixed &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/bf05a2eef97863fc78778bcde5987f93af8a7598&gt;here&lt;/denchmark-link&gt;
.
I think this should go away if you try &lt;denchmark-link:https://www.tensorflow.org/install/install_sources&gt;the latest source version&lt;/denchmark-link&gt;
 or wait for 1.5.
		</comment>
		<comment id='4' author='dieka13' date='2017-12-20T01:13:40Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='5' author='dieka13' date='2017-12-20T01:23:13Z'>
		Sure, tensorflowbutler.  I'm pretty sure it's fixed in that commit I pointed to.
		</comment>
		<comment id='6' author='dieka13' date='2018-02-10T03:05:43Z'>
		Hello, it seems that my confirmation reply didn't posted correctly and i just realized that now, I'm sorry.
as &lt;denchmark-link:https://github.com/isaprykin&gt;@isaprykin&lt;/denchmark-link&gt;
 suggested, building from source was working.
However, when I building latest tensorflow serving from source with GPU support, this exact error show up again. from what i know, tensorflow serving will pull latest tensorflow nighly, so this fix will have been merged, right?
I use different machine when i try this, It only use a single GTX 1070  this time. is it because I load a 2 GPU model in a single GPU machine?
I don't know if this is a tensorflow issue or serving issue. I will create new issue in a appropriate repo if needed.
Thank You.
		</comment>
		<comment id='7' author='dieka13' date='2018-02-26T19:35:46Z'>
		&lt;denchmark-link:https://github.com/dieka13&gt;@dieka13&lt;/denchmark-link&gt;
 when do you encounter that error? When you run export_savedmodel? Or when you load it into tensorflow/serving?
		</comment>
		<comment id='8' author='dieka13' date='2018-02-27T02:21:22Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 when I load it into tensorflow serving.
no problem when running export_savedmodel now.
I also run into another similar device assignment issue in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17149&gt;#17149&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='dieka13' date='2018-02-27T02:56:21Z'>
		Then I believe this is best filed as an issue to tensorflow/serving.
&lt;denchmark-link:https://github.com/nfiedel&gt;@nfiedel&lt;/denchmark-link&gt;
 FYI.
		</comment>
		<comment id='10' author='dieka13' date='2018-02-27T17:05:49Z'>
		This is key the key log message: "Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available". The binary you are trying to run most likely does not link in the GPU kernels. The supported build targets (tensorflow_model_server model_servers/BUILD) and pre-built binaries (installable via apt-get) currently support CPU with and without AVX, but not yet GPU. If you want to try adding a "tensorflow_gpu_model_server" that is probably the next step in sorting this out. You are also welcome to file a feature request under serving. Thanks!
		</comment>
		<comment id='11' author='dieka13' date='2018-02-28T04:01:37Z'>
		&lt;denchmark-link:https://github.com/nfiedel&gt;@nfiedel&lt;/denchmark-link&gt;
: but i used tensorflow/serving built with , is that still the case?
		</comment>
		<comment id='12' author='dieka13' date='2018-03-05T19:27:23Z'>
		&lt;denchmark-link:https://github.com/dieka13&gt;@dieka13&lt;/denchmark-link&gt;
 : Am not 100% certain, but pretty sure you need both the config as well as ops to be linked-in.
		</comment>
		<comment id='13' author='dieka13' date='2020-05-04T10:54:54Z'>
		&lt;denchmark-link:https://github.com/dieka13&gt;@dieka13&lt;/denchmark-link&gt;
 : I also encounter the same error

Is there any solution as of now?
		</comment>
	</comments>
</bug>