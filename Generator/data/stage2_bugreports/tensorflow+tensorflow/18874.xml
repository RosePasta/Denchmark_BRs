<bug id='18874' author='nikonikolov' open_date='2018-04-25T20:28:39Z' closed_time='2019-04-03T20:39:13Z'>
	<summary>Faulty numpy randomness when using GPU</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code: Yes
OS Platform and Distribution: Tested on Slackware Linux 14.2 and Ubuntu 16.04
TensorFlow installed from: binary
TensorFlow version: tested on both 1.4 and 1.6
Python version: 3.6
CUDA/cuDNN version: 8.0 for TF 1.4 and 9.0 for TF 1.6
Bazel version: N/A
GPU model and memory: tested on GTX 960M and GTX 1080
Exact command to reproduce: N/A

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I am unable to reproduce random numbers generated from numpy when I use it in combination with TF. In the beginning of all my tests, I set
&lt;denchmark-code&gt;tf.set_random_seed(seed)
np.random.seed(seed)
&lt;/denchmark-code&gt;

I have been debugging, and when I use numpy and no TF, all results are reproducible. When I add the TF code, the random numbers stop being reproducible. When I use both TF and numpy, I get the following results:

TF variables are initialized to the same value every time (OK)
When I use np.random.RandomState() with a set seed instead of direct calls to np.random.uniform(), np.random.normal(), etc, results are reproducible (OK)
When I use direct calls to np.random.uniform(), np.random.normal(), etc, results are reproducible on CPU but not on GPU (NOT OK)
1080
Since the results are reproducible when using CPU but not GPU, it made me think that this might be a possible bug.

I am not using any threads so the problem is definitely not caused by race conditions. I am monitoring reproducibility of results only by the random numbers which are generated, which are not in any way affected by the training results from the TF neural net. What is really strange is that the piece of code that seems to be affecting the results is the part about computing and backpropagating gradients. I do not expect that this uses any random numbers generated by numpy in the backend. Furthermore, even if it did, the order of my calls to np.random and to sess.run is always deterministic, so the same random numbers should be observed between separate runs.
My code is somewhat too big at the moment to post. I can try to compile some simple example where the issue occurs, but I first wanted to make sure that this is indeed not the expected behavior.
	</description>
	<comments>
		<comment id='1' author='nikonikolov' date='2018-04-26T06:36:38Z'>
		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
Bazel version
GPU model and memory
Exact command to reproduce
		</comment>
		<comment id='2' author='nikonikolov' date='2018-04-26T08:19:24Z'>
		Updated
		</comment>
		<comment id='3' author='nikonikolov' date='2018-04-27T16:57:30Z'>
		Many GPU ops, like convolutions, are not deterministic. So even if you don't use any random numbers, you might get different results for GPU ops if you run them multiple times. See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/12871&gt;#12871&lt;/denchmark-link&gt;
.
I'm going to assume this is the issue and close this, because you said this is only affecting the gradients, which often involve doing convolutions. Please comment/reopen if you think this is not the case.
		</comment>
		<comment id='4' author='nikonikolov' date='2018-04-27T18:48:04Z'>
		Thanks for the response. I think you misunderstood what I was saying, maybe I was not clear enough.
Here is a mock up (just to illustrate the issue, it is not the exact piece of code which reproduces the problem):
&lt;denchmark-code&gt;seed = 42
np.random.seed(seed)
tf.set_random_seed(seed)

# build graph
sess = tf.Session()
rands = []

for i in range(30000):
  r = np.random.uniform(0,1)
  rands.append(r)
  sess.run(train_op, feed_dict=...)
&lt;/denchmark-code&gt;

The issue that I am experiencing is that rands ends up with different numbers between runs. This is happening only when using GPU. On CPU, the numbers are the same. When I remove the line sess.run(train_op, feed_dict=...), everything works fine. Also if I use prng = np.random.RandomState(); prng.seed(seed) and then sample with r = prng.uniform(0,1), the generated numbers are the same between runs on both CPU and GPU (sess.run(train_op, feed_dict=...) is also being executed).
I was wondering whether this is expected behavior? If not, I will try to create a proper example which reproduces the problem so we can debug further.
		</comment>
		<comment id='5' author='nikonikolov' date='2018-04-27T19:02:42Z'>
		So the issue is that running TensorFlow sessions seems to affect the random numbers that numpy generates.
/CC &lt;denchmark-link:https://github.com/zffchen78&gt;@zffchen78&lt;/denchmark-link&gt;
 do you know if this is expected? IMO this shouldn't occur, because TensorFlow should only use it's own seed for randomness.
		</comment>
		<comment id='6' author='nikonikolov' date='2018-04-27T19:19:53Z'>
		Yes, that seems to be the case for some reason. That's what I narrowed it down to while I was debugging my code.
		</comment>
		<comment id='7' author='nikonikolov' date='2019-03-19T20:37:26Z'>
		&lt;denchmark-link:https://github.com/nikonikolov&gt;@nikonikolov&lt;/denchmark-link&gt;
 Could check whether the error persists with TF1.12 or 1.13? Thanks!
		</comment>
		<comment id='8' author='nikonikolov' date='2019-04-03T20:39:13Z'>
		Closing due to lack of recent activity, but please let me know if I'm mistaken. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.
		</comment>
		<comment id='9' author='nikonikolov' date='2019-04-03T20:39:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=18874&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=18874&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>