<bug id='38224' author='Saran-nns' open_date='2020-04-04T19:09:35Z' closed_time='2020-10-12T23:05:06Z'>
	<summary>Ensemble of custom sequential models</summary>
	<description>
I am trying to split the sequential models and combine them back in reference to the documentation on &lt;denchmark-link:https://www.tensorflow.org/tutorials/images/cnn&gt;CNN&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras import datasets, layers, models
tf.keras.backend.set_floatx('float64')
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Data&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Model 1:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;class Model1(tf.keras.Model):

  def __init__(self):
    super(Model1,self).__init__(name = 'Model1')
    self.model = models.Sequential()

  def call(self,inputs):
    # self.model.add(layers.Input(shape=(32, 32, 3)))
    self.model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(32,32,3)))
    self.model.add(layers.MaxPooling2D((2, 2)))
    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    self.model.add(layers.MaxPooling2D((2, 2)))
    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    
    return self.model
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Model 2:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;class Model2(tf.keras.Model):
  def __init__(self):
    super(Model2,self).__init__(name = 'Model2')
    self.model = models.Sequential()
  def call(self,inputs):
    self.model.add(layers.Reshape((32,32,1),input_shape=(32,32,1))
    self.model.add(layers.Flatten())
    self.model.add(layers.Dense(64, activation='relu')) 
    self.model.add(layers.Dense(10))
    return self.model
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Ensemble of above two models:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;class Ensemble(tf.keras.Model):
  def __init__(self,model1, model2):
    super(Ensemble,self).__init__(name = 'Ensemble')
    self.model = models.Sequential()
    self.model.add(model1)
    self.model.add(model2)

  def call(self,inputs):
    output = self.model(inputs)
    return output

# class Ensemble(tf.keras.Model):

#   def __init__(self,model1, model2):
#     super(Ensemble,self).__init__(name = 'Ensemble')
#     self.model1 = model1
#     self.model2 = model2
#   def call(self,inputs):
#     output = self.model1(inputs)
#     output = self.model2(output)
#     return output
&lt;/denchmark-code&gt;

Initialize and build the model
&lt;denchmark-code&gt;model1 = Model1()
model2 = Model2()
model = Ensemble(model1,model2)
model.build((32,32,3))
model.summary()
&lt;/denchmark-code&gt;

Model: "Ensemble"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
Model1 (Model1)              multiple                  56320
_________________________________________________________________
Model2 (Model2)              multiple                  66250
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
&lt;denchmark-h:h3&gt;Compile and fit the model&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;# Compile model
model.compile(optimizer='adam',
                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=10, batch_size=64,
                      validation_data=(test_images, test_labels))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Returns:&lt;/denchmark-h&gt;

ValueError: The name "conv2d" is used 2 times in the model. All layer names should be unique.
&lt;denchmark-h:h3&gt;Error trace below:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Epoch 1/10
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-12-e612d6023946&gt; in &lt;module&gt;()
      5 # Train the model
      6 history = model.fit(train_images, train_labels, epochs=10, batch_size=64,
----&gt; 7                       validation_data=(test_images, test_labels))

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---&gt; 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    783                 batch_size=batch_size):
    784               callbacks.on_train_batch_begin(step)
--&gt; 785               tmp_logs = train_function(iterator)
    786               # Catch OutOfRangeError for Datasets of unknown size.
    787               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--&gt; 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--&gt; 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-&gt; 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-&gt; 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *
        outputs = self.distribute_strategy.run(
    &lt;ipython-input-5-a5fe0db529f5&gt;:38 call  *
        output = self.model(inputs)
    &lt;ipython-input-3-e360f03e53e3&gt;:9 call  *
        self.model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(32,32,3)))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:456 _method_wrapper  **
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:224 add
        self._init_graph_network(self.inputs, self.outputs, name=self.name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:456 _method_wrapper
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:302 _init_graph_network
        self.inputs, self.outputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1798 _map_graph_network
        str(all_names.count(name)) + ' times in the model. '

    ValueError: The name "conv2d" is used 2 times in the model. All layer names should be unique.
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Bit of troubleshooting:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;for i, la in enumerate(model.layers):
  print(la.name)
  for j, laye in enumerate(la.layers):
    print(laye.name)
    for k, lay in enumerate(laye.layers):
      print(lay.name) 
&lt;/denchmark-code&gt;

Returns:
&lt;denchmark-code&gt;sequential
conv2d
max_pooling2d
conv2d_1
max_pooling2d_1
conv2d_2
model2
sequential_1
reshape
flatten
dense
dense_1
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;The name scope 'conv2d' is invoked only once? Is there any documentation/ feature to combine two sequential models?&lt;/denchmark-h&gt;


Tensorflow '2.2.0-rc2' : Colab
(&lt;denchmark-link:https://colab.research.google.com/drive/1mlZJBh2BAsOGKziXZ9V60Web53c7vRI0&gt;https://colab.research.google.com/drive/1mlZJBh2BAsOGKziXZ9V60Web53c7vRI0&lt;/denchmark-link&gt;
)
	</description>
	<comments>
		<comment id='1' author='Saran-nns' date='2020-04-06T05:33:49Z'>
		&lt;denchmark-link:https://github.com/Saran-nns&gt;@Saran-nns&lt;/denchmark-link&gt;

please let us know which tensorflow version are you facing the issue in
		</comment>
		<comment id='2' author='Saran-nns' date='2020-04-12T17:42:11Z'>
		&lt;denchmark-link:https://github.com/Saran-nns&gt;@Saran-nns&lt;/denchmark-link&gt;

please update on the above comment
		</comment>
		<comment id='3' author='Saran-nns' date='2020-04-12T19:01:41Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  I am using Tensorflow '2.2.0-rc2' : Colab;
Apparently, the error disappeared when i compile the model directly without building it.
However, i received new error while fitting the model.
Error trace:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-7-e612d6023946&gt; in &lt;module&gt;()
      5 # Train the model
      6 history = model.fit(train_images, train_labels, epochs=10, batch_size=64,
----&gt; 7                       validation_data=(test_images, test_labels))

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---&gt; 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    783                 batch_size=batch_size):
    784               callbacks.on_train_batch_begin(step)
--&gt; 785               tmp_logs = train_function(iterator)
    786               # Catch OutOfRangeError for Datasets of unknown size.
    787               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--&gt; 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--&gt; 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-&gt; 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-&gt; 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:467 train_step  **
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__
        losses = self.call(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1555 sparse_categorical_crossentropy
        y_pred = ops.convert_to_tensor_v2(y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1283 convert_to_tensor_v2
        as_ref=False)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:262 constant
        allow_broadcast=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl
        allow_broadcast=allow_broadcast))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto
        "supported type." % (type(values), values))

    TypeError: Failed to convert object of type &lt;class 'tensorflow.python.keras.engine.sequential.Sequential'&gt; to Tensor. Contents: &lt;tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7c24e8fe48&gt;. Consider casting elements to a supported type.```
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='Saran-nns' date='2020-04-14T11:50:28Z'>
		i am able to replicate this issue, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/d5a4ec5a134db77080734fb355ce50f0/38224.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='Saran-nns' date='2020-04-22T13:39:27Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 Any update on this issue, please.
		</comment>
		<comment id='6' author='Saran-nns' date='2020-10-12T23:05:06Z'>
		You should create all layers during build, not call. It's likely that call got invoked twice (because we need to trace the graph)
		</comment>
		<comment id='7' author='Saran-nns' date='2020-10-12T23:05:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38224&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38224&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>