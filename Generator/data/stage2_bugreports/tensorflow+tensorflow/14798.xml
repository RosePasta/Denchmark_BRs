<bug id='14798' author='carlthome' open_date='2017-11-22T14:54:06Z' closed_time='2017-12-11T18:33:15Z'>
	<summary>Provide a list of supported XLA operations like TensorFlow Lite</summary>
	<description>
TensorFlow Lite provides a list of currently supported ops &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md&gt;here&lt;/denchmark-link&gt;
 and I wonder if XLA could also have such a list. It's rough to develop and train a model with the full TensorFlow Python API only to get stuck during AOT compilation because of missing ops kernels in the tf2xla bridge.
	</description>
	<comments>
		<comment id='1' author='carlthome' date='2017-12-11T18:33:14Z'>
		We now have some auto-generated tables listing the supported ops on CPU and GPU:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/cpu_supported_ops.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/cpu_supported_ops.md&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/gpu_supported_ops.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/gpu_supported_ops.md&lt;/denchmark-link&gt;

Unlike the TFLite docs, we don't have a breakdown starting from the Python APIs; the above tables are based on the op names in the GraphDef.  At the moment, if we wanted the Python API breakdown, we'd need to do that manually, and that seems unlikely to remain up-to-date.  I hope the above tables are still useful though.
		</comment>
		<comment id='2' author='carlthome' date='2017-12-11T22:05:27Z'>
		Thanks!
		</comment>
	</comments>
</bug>