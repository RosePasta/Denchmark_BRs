<bug id='45241' author='WrathofBhuvan11' open_date='2020-11-28T06:32:36Z' closed_time='2020-12-24T09:33:56Z'>
	<summary>InvalidArgumentError:  assertion failed: [predictions must be &amp;lt;= 1] [Condition x &amp;lt;= y did not hold element-wise:] [x (model/dense_3/Relu:0) = ] [[0.179184318 1.62250423 0...]...] [y (metrics/auc/Cast_2/x:0) = ] [1] 	 [[{{node metrics/auc/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]] [Op:__inference_distributed_function_8508]</summary>
	<description>
Updated version of issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/45219&gt;#45219&lt;/denchmark-link&gt;

I'm trying a new model involving word embedding for labels as well as Image classification in order to increase accuracy of the Image classifier.
I'm using tensorflow Version 2.
Here is the code of the model and summary.
&lt;denchmark-code&gt;def build_mobilenet_embedd_model(img_input ):
    input_x = Input(shape = (img_input.shape[1:]), name='feature')
    base_model = MobileNet(include_top= False, input_shape=img_input.shape[1:], weights='imagenet')(input_x)
    avgpool_x = GlobalAveragePooling2D()(base_model)
    dense1_x = Dense(2048, activation='relu')(avgpool_x)
    batch1_x = BatchNormalization()(dense1_x)
    dropout1_x = Dropout(0.2)(batch1_x)
    dense2_x = Dense(512, activation='relu')(dropout1_x)
    batch2_x = BatchNormalization()(dense2_x)
    dropout2_x = Dropout(0.2)(batch2_x)
    predictions = Dense(len(all_labels), activation='relu')(dropout2_x)
    embedd_layer = Embedding(13, 100, weights=[embedding_matrix], trainable=False,name = "embedding_1")(predictions)
    flatten = Flatten(name="flatten")(embedd_layer)
    final_predictions = Dense(13, activation='relu')(flatten)
    model = keras.models.Model(inputs= input_x, outputs = final_predictions)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics= METRICS
    model.summary()
    return model
&lt;/denchmark-code&gt;

and here is the summary:-
&lt;denchmark-code&gt;Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
feature (InputLayer)         [(None, 128, 128, 3)]     0         
_________________________________________________________________
mobilenet_1.00_128 (Model)   (None, 4, 4, 1024)        3228864   
_________________________________________________________________
global_average_pooling2d_5 ( (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 2048)              2099200   
_________________________________________________________________
batch_normalization_10 (Batc (None, 2048)              8192      
_________________________________________________________________
dropout_10 (Dropout)         (None, 2048)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 512)               1049088   
_________________________________________________________________
batch_normalization_11 (Batc (None, 512)               2048      
_________________________________________________________________
dropout_11 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 13)                6669      
_________________________________________________________________
embedding_1 (Embedding)      (None, 13, 100)           1300      
_________________________________________________________________
flatten (Flatten)            (None, 1300)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 13)                16913     
=================================================================
Total params: 6,412,274
Trainable params: 6,383,966
Non-trainable params: 28,308
_________________________________________________________________
&lt;/denchmark-code&gt;

Adding embedd_layer  and flatten layer after the layer prediction resulted in this error to pop-up,
when I run the model fit I'll get this warning  &amp; error message.
&lt;denchmark-code&gt;WARNING:tensorflow:From &lt;ipython-input-23-65f5e4d4075d&gt;:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
Train for 660 steps, validate on 1024 samples
Epoch 1/30
WARNING:tensorflow:Gradients do not exist for variables ['conv1/kernel:0', 'conv1_bn/gamma:0', 'conv1_bn/beta:0', 'conv_dw_1/depthwise_kernel:0', 'conv_dw_1_bn/gamma:0', 'conv_dw_1_bn/beta:0', 'conv_pw_1/kernel:0', 'conv_pw_1_bn/gamma:0', 'conv_pw_1_bn/beta:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_2_bn/gamma:0', 'conv_dw_2_bn/beta:0', 'conv_pw_2/kernel:0', 'conv_pw_2_bn/gamma:0', 'conv_pw_2_bn/beta:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_3_bn/gamma:0', 'conv_dw_3_bn/beta:0', 'conv_pw_3/kernel:0', 'conv_pw_3_bn/gamma:0', 'conv_pw_3_bn/beta:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_4_bn/gamma:0', 'conv_dw_4_bn/beta:0', 'conv_pw_4/kernel:0', 'conv_pw_4_bn/gamma:0', 'conv_pw_4_bn/beta:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_5_bn/gamma:0', 'conv_dw_5_bn/beta:0', 'conv_pw_5/kernel:0', 'conv_pw_5_bn/gamma:0', 'conv_pw_5_bn/beta:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_6_bn/gamma:0', 'conv_dw_6_bn/beta:0', 'conv_pw_6/kernel:0', 'conv_pw_6_bn/gamma:0', 'conv_pw_6_bn/beta:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_7_bn/gamma:0', 'conv_dw_7_bn/beta:0', 'conv_pw_7/kernel:0', 'conv_pw_7_bn/gamma:0', 'conv_pw_7_bn/beta:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_8_bn/gamma:0', 'conv_dw_8_bn/beta:0', 'conv_pw_8/kernel:0', 'conv_pw_8_bn/gamma:0', 'conv_pw_8_bn/beta:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_9_bn/gamma:0', 'conv_dw_9_bn/beta:0', 'conv_pw_9/kernel:0', 'conv_pw_9_bn/gamma:0', 'conv_pw_9_bn/beta:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_10_bn/gamma:0', 'conv_dw_10_bn/beta:0', 'conv_pw_10/kernel:0', 'conv_pw_10_bn/gamma:0', 'conv_pw_10_bn/beta:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_11_bn/gamma:0', 'conv_dw_11_bn/beta:0', 'conv_pw_11/kernel:0', 'conv_pw_11_bn/gamma:0', 'conv_pw_11_bn/beta:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_12_bn/gamma:0', 'conv_dw_12_bn/beta:0', 'conv_pw_12/kernel:0', 'conv_pw_12_bn/gamma:0', 'conv_pw_12_bn/beta:0', 'conv_dw_13/depthwise_kernel:0', 'conv_dw_13_bn/gamma:0', 'conv_dw_13_bn/beta:0', 'conv_pw_13/kernel:0', 'conv_pw_13_bn/gamma:0', 'conv_pw_13_bn/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['conv1/kernel:0', 'conv1_bn/gamma:0', 'conv1_bn/beta:0', 'conv_dw_1/depthwise_kernel:0', 'conv_dw_1_bn/gamma:0', 'conv_dw_1_bn/beta:0', 'conv_pw_1/kernel:0', 'conv_pw_1_bn/gamma:0', 'conv_pw_1_bn/beta:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_2_bn/gamma:0', 'conv_dw_2_bn/beta:0', 'conv_pw_2/kernel:0', 'conv_pw_2_bn/gamma:0', 'conv_pw_2_bn/beta:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_3_bn/gamma:0', 'conv_dw_3_bn/beta:0', 'conv_pw_3/kernel:0', 'conv_pw_3_bn/gamma:0', 'conv_pw_3_bn/beta:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_4_bn/gamma:0', 'conv_dw_4_bn/beta:0', 'conv_pw_4/kernel:0', 'conv_pw_4_bn/gamma:0', 'conv_pw_4_bn/beta:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_5_bn/gamma:0', 'conv_dw_5_bn/beta:0', 'conv_pw_5/kernel:0', 'conv_pw_5_bn/gamma:0', 'conv_pw_5_bn/beta:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_6_bn/gamma:0', 'conv_dw_6_bn/beta:0', 'conv_pw_6/kernel:0', 'conv_pw_6_bn/gamma:0', 'conv_pw_6_bn/beta:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_7_bn/gamma:0', 'conv_dw_7_bn/beta:0', 'conv_pw_7/kernel:0', 'conv_pw_7_bn/gamma:0', 'conv_pw_7_bn/beta:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_8_bn/gamma:0', 'conv_dw_8_bn/beta:0', 'conv_pw_8/kernel:0', 'conv_pw_8_bn/gamma:0', 'conv_pw_8_bn/beta:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_9_bn/gamma:0', 'conv_dw_9_bn/beta:0', 'conv_pw_9/kernel:0', 'conv_pw_9_bn/gamma:0', 'conv_pw_9_bn/beta:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_10_bn/gamma:0', 'conv_dw_10_bn/beta:0', 'conv_pw_10/kernel:0', 'conv_pw_10_bn/gamma:0', 'conv_pw_10_bn/beta:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_11_bn/gamma:0', 'conv_dw_11_bn/beta:0', 'conv_pw_11/kernel:0', 'conv_pw_11_bn/gamma:0', 'conv_pw_11_bn/beta:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_12_bn/gamma:0', 'conv_dw_12_bn/beta:0', 'conv_pw_12/kernel:0', 'conv_pw_12_bn/gamma:0', 'conv_pw_12_bn/beta:0', 'conv_dw_13/depthwise_kernel:0', 'conv_dw_13_bn/gamma:0', 'conv_dw_13_bn/beta:0', 'conv_pw_13/kernel:0', 'conv_pw_13_bn/gamma:0', 'conv_pw_13_bn/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.
  1/660 [..............................] - ETA: 8:05:51WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr
&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\util\deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--&gt; 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1304         use_multiprocessing=use_multiprocessing,
   1305         shuffle=shuffle,
-&gt; 1306         initial_epoch=initial_epoch)
   1307 
   1308   @deprecation.deprecated(

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--&gt; 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--&gt; 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--&gt; 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---&gt; 98                               distributed_function(input_fn))
     99 
    100   return execution_function

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--&gt; 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    630         # Lifting succeeded, so variables are initialized and we can run the
    631         # stateless function.
--&gt; 632         return self._stateless_fn(*args, **kwds)
    633     else:
    634       canon_args, canon_kwds = \

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-&gt; 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-&gt; 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-&gt; 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=("executor_type", executor_type, "config_proto", config),
--&gt; 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---&gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

E:\anaconda\envs\gputest\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError:  assertion failed: [predictions must be &lt;= 1] [Condition x &lt;= y did not hold element-wise:] [x (model/dense_3/Relu:0) = ] [[0.179184318 1.62250423 0...]...] [y (metrics/auc/Cast_2/x:0) = ] [1]
	 [[{{node metrics/auc/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]] [Op:__inference_distributed_function_8508]

Function call stack:
distributed_function
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='WrathofBhuvan11' date='2020-11-30T06:53:51Z'>
		&lt;denchmark-link:https://github.com/WrathofBhuvan11&gt;@WrathofBhuvan11&lt;/denchmark-link&gt;

Code shared has syntax errors, can you please share a colab gist with the issue faced.
		</comment>
		<comment id='2' author='WrathofBhuvan11' date='2020-12-02T15:25:51Z'>
		
@WrathofBhuvan11
Code shared has syntax errors, can you please share a colab gist with the issue faced.

Can you please say what u r referring to as syntax error ?
		</comment>
		<comment id='3' author='WrathofBhuvan11' date='2020-12-10T08:05:30Z'>
		&lt;denchmark-link:https://github.com/WrathofBhuvan11&gt;@WrathofBhuvan11&lt;/denchmark-link&gt;

Can you please share your code with the issue reported in a colab gist.
		</comment>
		<comment id='4' author='WrathofBhuvan11' date='2020-12-17T09:03:58Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='WrathofBhuvan11' date='2020-12-24T09:33:54Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='WrathofBhuvan11' date='2020-12-24T09:33:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45241&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45241&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='WrathofBhuvan11' date='2020-12-24T12:49:01Z'>
		InvalidArgumentError:  assertion failed: [predictions must be &gt;= 0] [Condition x &gt;= y did not hold element-wise:] [x (sequential/dense_2/Sigmoid:0) = ] [[-nan][-nan][-nan]...] [y (Cast_6/x:0) = ] [0]
[[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_1772]
Function call stack:
train_function
		</comment>
		<comment id='8' author='WrathofBhuvan11' date='2021-01-03T18:25:21Z'>
		If you continue marking all the open problems as stale and close them they will never be resolved. These issues persist throughout the whole platform and nobody seems to care
		</comment>
		<comment id='9' author='WrathofBhuvan11' date='2021-01-18T13:38:04Z'>
		&lt;denchmark-link:https://github.com/hanneswiedenhofer&gt;@hanneswiedenhofer&lt;/denchmark-link&gt;

Please create a new issue as this issue was closed as there was no response from user.
		</comment>
	</comments>
</bug>