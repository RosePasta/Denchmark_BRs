<bug id='40420' author='gigadeplex' open_date='2020-06-12T19:42:10Z' closed_time='2020-09-08T06:21:42Z'>
	<summary>'tf.Dilation2D' op is neither a custom op nor a flex op</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab, python 3.6
TensorFlow installed from (source or binary):
TensorFlow version (or github SHA if from source):

Provide the text output from tflite_convert
&lt;denchmark-code&gt;INFO:tensorflow:Saver not created because there are no variables in the graph to restore

---------------------------------------------------------------------------

ConverterError                            Traceback (most recent call last)

&lt;ipython-input-6-6ce9f2d0000a&gt; in &lt;module&gt;()
      6                                        tf.lite.OpsSet.SELECT_TF_OPS]
      7 
----&gt; 8 tflite_model = converter.convert()
      9 
     10 # Save the TF Lite model.

2 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--&gt; 227       raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-06-12 18:51:22.076900: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-06-12 18:51:22.076954: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-06-12 18:51:22.626844: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.
2020-06-12 18:51:22.954133: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F
2020-06-12 18:51:23.172150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000134999 Hz
2020-06-12 18:51:23.172487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-12 18:51:23.172520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-12 18:51:23.180594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-12 18:51:23.271482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.271997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561ef1c2b100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-12 18:51:23.272026: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1
2020-06-12 18:51:23.272188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.272524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1
coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-12 18:51:23.272923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-12 18:51:23.274901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-12 18:51:23.276599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-12 18:51:23.277233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-12 18:51:23.279053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-12 18:51:23.279837: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-12 18:51:23.283468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-12 18:51:23.283603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.284015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.285247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-06-12 18:51:23.288818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-12 18:51:23.293809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-12 18:51:23.293841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-06-12 18:51:23.293870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-06-12 18:51:23.297246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.297674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-12 18:51:23.298025: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2020-06-12 18:51:23.298071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5523 MB memory) -&gt; physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)
2020-06-12 18:51:30.236028: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 18874368 exceeds 10% of system memory.
loc("Dilation2D"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_1"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_2"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_3"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_4"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_5"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_6"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_7"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_8"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_9"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_10"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_11"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_12"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_13"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_14"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_15"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_16"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_17"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_18"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_19"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_20"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_21"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_22"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_23"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_24"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_25"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_26"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_27"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_28"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_29"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_30"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_31"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
loc("Dilation2D_32"): error: 'tf.Dilation2D' op is neither a custom op nor a flex op
error: failed while converting: 'main'
Ops that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D
Traceback (most recent call last):
  File "/usr/local/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: &lt;unknown&gt;:0: error: loc("Dilation2D"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_1"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_2"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_3"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_4"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_5"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_6"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_7"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_8"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_9"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_10"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_11"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_12"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_13"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_14"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_15"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_16"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_17"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_18"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_19"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_20"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_21"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_22"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_23"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_24"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_25"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_26"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_27"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_28"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_29"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_30"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_31"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: loc("Dilation2D_32"): 'tf.Dilation2D' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: error: failed while converting: 'main'
Ops that need custom implementation (enabled via setting the -emit-custom-ops flag): Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D,Dilation2D
&lt;/denchmark-code&gt;


First download this saved model
&lt;denchmark-link:https://drive.google.com/file/d/136KmfVwBT2htxPDZeYw4-TXmxPYe7Vsa/view?usp=sharing&gt;https://drive.google.com/file/d/136KmfVwBT2htxPDZeYw4-TXmxPYe7Vsa/view?usp=sharing&lt;/denchmark-link&gt;

Second run:
&lt;denchmark-code&gt;import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model('saved')
converter.target_spec.supported_types = [tf.float16]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()
&lt;/denchmark-code&gt;

I am posting this to request the Dilation2D op for tflite. Thanks.
	</description>
	<comments>
		<comment id='1' author='gigadeplex' date='2020-06-12T21:47:57Z'>
		&lt;denchmark-link:https://github.com/thaink&gt;@thaink&lt;/denchmark-link&gt;
 could you help adding tf.Dilation2D op to flex?
		</comment>
		<comment id='2' author='gigadeplex' date='2020-06-15T02:16:42Z'>
		Sure. let me make a PR.
		</comment>
		<comment id='3' author='gigadeplex' date='2020-06-25T20:36:07Z'>
		
Sure. let me make a PR.

Any updates?
		</comment>
		<comment id='4' author='gigadeplex' date='2020-06-29T04:42:35Z'>
		The op is added at the head of master. Could you check?
		</comment>
		<comment id='5' author='gigadeplex' date='2020-07-01T16:54:15Z'>
		
The op is added at the head of master. Could you check?

Wow, thank you. I didn't get a notification of this comment. I'll check it out right now!
		</comment>
		<comment id='6' author='gigadeplex' date='2020-09-08T06:16:43Z'>
		
Sure. let me make a PR.

error: 'tf.ConcatV2' op is neither a custom op nor a flex op
error: 'tf.All' op is neither a custom op nor a flex op
could you please fixed similar op tf.ConcatV2 and tf.All for tflite convert ?
		</comment>
		<comment id='7' author='gigadeplex' date='2020-09-08T06:21:07Z'>
		&lt;denchmark-link:https://github.com/AloneGu&gt;@AloneGu&lt;/denchmark-link&gt;
 Both  and  ops can be supported via Select TF ops. Please convert your model with the Select TF op set.
&lt;denchmark-link:https://www.tensorflow.org/lite/guide/ops_select&gt;https://www.tensorflow.org/lite/guide/ops_select&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.tensorflow.org/lite/guide/reduce_binary_size&gt;https://www.tensorflow.org/lite/guide/reduce_binary_size&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='gigadeplex' date='2020-09-08T06:21:43Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40420&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40420&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>