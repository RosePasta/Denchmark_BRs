<bug id='34950' author='WZMIAOMIAO' open_date='2019-12-09T04:04:29Z' closed_time='2020-01-30T23:38:32Z'>
	<summary>load_weights h5file failed (cause by BN layer) in tensorflow2.0</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.0.0-rc1-51-g2646d23074 2.0.0-rc2
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: NO
GPU model and memory: NO

Describe the current behavior
I save my model using .h5 format(model.save_weights("./save_weights/resNet.h5")). And I load this weights(model.load_weights('./save_weights/resNet.h5', by_name=True)) then failed. this error is shape mismatch.
i did some tests:
(1) when i save model using ckpt format, i can successfully load weights.
(2) when i save model that no use bn layer using h5 format, i can successfully load weights.
Describe the expected behavior
i think i should load model weights(include bn layer) using .h5 format.
Code to reproduce the issue
(1) i tracked the problem. the problem is in "\tensorflow_core\python\keras\saving\hdf5_format.py" file(754 line, "if K.int_shape(symbolic_weights[i]) != weight_values[i].shape:").
(2) when i load model weights, i find the variables order(layers order) is different between "symbolic_weights" and "weight_values" . so you can't simply use list index to load weights.
(3) the main reason is caused by bn layer. i check the varables "symbolic_weights" and "weight_values",  the bn parameters order in "weight_values" is like [gamma, bata, mean, variance, gamma, bata, mean, variance] but in "symbolic_weights" is like [gamma, bata, gamma, bata, mean, variance, mean, variance].

Traceback (most recent call last):
File "E:\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\network.py", line 1175, in load_weights
saving.load_weights_from_hdf5_group_by_name(f, self.layers)
File "E:\Anaconda3\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py", line 760, in load_weights_from_hdf5_group_by_name
str(weight_values[i].shape) + '.')
ValueError: Layer &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/4&gt;#4&lt;/denchmark-link&gt;
 (named "block1"), weight &lt;tf.Variable 'block1/unit_1/conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=
array([[[[ 0.00050041, -0.06431282, -0.00577746, ..., -0.05891485,
-0.02970275, -0.06618612],
.......
-0.04930668, -0.02927044]]]], dtype=float32)&gt; has shape (3, 3, 64, 64), but the saved weight has shape (64,).
	</description>
	<comments>
		<comment id='1' author='WZMIAOMIAO' date='2019-12-10T06:02:54Z'>
		Will it be possible to share minimal standalone code or Colab link to reproduce the issue in our environment.It will be helpful for localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='WZMIAOMIAO' date='2019-12-10T07:04:58Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
  Hello,

&lt;denchmark-code&gt;model.save_weights("./save_weights/resNet_{}.h5".format(epoch))
&lt;/denchmark-code&gt;

second, I just simply load model weights( .h5 format).
&lt;denchmark-code&gt;feature = resnet101(num_classes=5, include_top=False)
model = tf.keras.Sequential([feature,
                             tf.keras.layers.GlobalAvgPool2D(),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(1024),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(5)])
model.load_weights('./save_weights/resNet_5.h5', by_name=True)
&lt;/denchmark-code&gt;

if you try to load model weights( .h5 format) that have bn layers, maybe meet this bug.
this problem from  "\tensorflow_core\python\keras\saving\hdf5_format.py"
&lt;denchmark-code&gt;# Set values.
      for i in range(len(weight_values)):
        if K.int_shape(symbolic_weights[i]) != weight_values[i].shape:
          raise ValueError('Layer #' + str(k) +' (named "' + layer.name +
                           '"), weight ' + str(symbolic_weights[i]) +
                           ' has shape {}'.format(K.int_shape(
                               symbolic_weights[i])) +
                           ', but the saved weight has shape ' +
                           str(weight_values[i].shape) + '.')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='WZMIAOMIAO' date='2019-12-12T08:22:50Z'>
		&lt;denchmark-link:https://github.com/WZMIAOMIAO&gt;@WZMIAOMIAO&lt;/denchmark-link&gt;

Will it be possible to provide reproducible code and .h5 file . It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='4' author='WZMIAOMIAO' date='2019-12-12T10:19:05Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 hello，I just tested it again. I find that when i load weights if i comment out “feature.trainable=False”, i can get error from hdf5_format.py . the test code is following:
&lt;denchmark-code&gt;import tensorflow as tf


def my_model(im_height=64, im_width=64):
    in_im = tf.keras.Input(shape=(im_height, im_width, 3))
    # 64x64x3
    x = tf.keras.layers.Conv2D(
        filters=32, kernel_size=3, strides=2, padding="same", use_bias=False)(in_im)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)
    # 32x32x32
    x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)
    # 16x16x32
    x = tf.keras.layers.Conv2D(
        filters=64, kernel_size=3, strides=2, padding="same", use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)
    # 8x8x64

    model = tf.keras.Model(inputs=in_im, outputs=x)

    return model


# save weights
feature = my_model()
feature.trainable = False
model = tf.keras.Sequential([feature,
                             tf.keras.layers.GlobalAvgPool2D(),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(1024),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(5)])
model.save_weights('my_net.h5')

# load weights
feature = my_model()
# feature.trainable = False
model = tf.keras.Sequential([feature,
                             tf.keras.layers.GlobalAvgPool2D(),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(1024),
                             tf.keras.layers.Dropout(rate=0.2),
                             tf.keras.layers.Dense(5)])
model.load_weights('my_net.h5')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='WZMIAOMIAO' date='2019-12-13T09:40:31Z'>
		I have tried on colab with TF version 2.0 ,2.1.0-rc1 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/addfb60c246fc9b1b625e1c448dce0da/untitled477.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='WZMIAOMIAO' date='2020-01-30T23:38:32Z'>
		Currently hdf5 weights are saved with a specific ordering that depends on whether layers/variables are trainable. It's difficult to change this behavior as it would break all currently existing checkpoints.
Can you set trainable to False after the weights have been loaded? Alternatively, stick to using the ckpt format. Unfortunately there's not much we can do to fix this for hdf5.
		</comment>
		<comment id='7' author='WZMIAOMIAO' date='2020-01-30T23:38:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34950&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34950&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>