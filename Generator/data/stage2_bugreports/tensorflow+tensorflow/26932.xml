<bug id='26932' author='keesduisters' open_date='2019-03-20T11:09:09Z' closed_time='2019-03-25T10:59:31Z'>
	<summary>tf lite java api model interpretation error</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Nexus 5 emulator, API version 23
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): ('v1.12.0-10426-g4b1ee1a7b1', '1.14.1-dev20190319')
Python version: Python 2.7.15rc1
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
When loading a custom model using the TF lite api for android, the output tensor dimensions become malformed. This causes an exception:
&lt;denchmark-code&gt;java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [0, 2] and a Java object with shape [1, 2].
        at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:242)
        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:116)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:157)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:250)
        at org.tensorflow.lite.Interpreter.run(Interpreter.java:228)
        ...
&lt;/denchmark-code&gt;

It is a custom model, see attachment. Various validation scripts have shown no anomalies in the model.
I have spent some effort on debugging, validating the behavior of the API. However, I get stuck at the native methods.
The code below shows that before execution, the tensors do have the right shape.
&lt;denchmark-code&gt;        network = new Interpreter(modelFile, options);

        logger.info(String.format("Input tensor count: %d",network.getInputTensorCount()));
        for(int input_i = 0; input_i&lt; network.getInputTensorCount(); input_i ++ ) {
            Tensor input = network.getInputTensor(input_i);
            logger.info(String.format(" Tensor %d:", input_i));
            logger.info(String.format("  Type %s", toStringName(input.dataType())));
            logger.info(String.format("  Dimensions %d", input.numDimensions()));
            logger.info(String.format("  Shape %s", Arrays.toString(input.shape())));
        }

        logger.info(String.format("Output tensor count: %d",network.getOutputTensorCount()));
        for(int output_i = 0; output_i&lt; network.getInputTensorCount(); output_i ++ ) {
            Tensor output = network.getOutputTensor(output_i);
            logger.info(String.format(" Tensor %d:", output_i));
            logger.info(String.format("  Type %s", toStringName(output.dataType())));
            logger.info(String.format("  Dimensions %d", output.numDimensions()));
            logger.info(String.format("  Shape %s", Arrays.toString(output.shape())));
        }

        float[][][][] input = adapter.convert(_input);
        float[][] output = {{0f, 0f}};

        network.run(input, output);

&lt;/denchmark-code&gt;

It seems like in NativeInterpreterWrapper, the size of the output tensor is corrected after model execution, near the line:
&lt;denchmark-code&gt;    run(interpreterHandle, errorHandle);
    long inferenceDurationNanoseconds = System.nanoTime() - inferenceStartNanos;

    // Allocation can trigger dynamic resizing of output tensors, so refresh all output shapes.
    if (needsAllocation) {
      for (int i = 0; i &lt; outputTensors.length; ++i) {
        if (outputTensors[i] != null) {
          outputTensors[i].refreshShape(); // &lt;-- 
        }
      }
    }
&lt;/denchmark-code&gt;

It seems like this method checks the output dimensions with the c++ backend code, and corrects this in the Java part. At this point, the mismatch arrises.
However, if I perform the check before the model runs, the mismatch is already present.
Describe the expected behavior
No exception, no need to resize the tensor to a 0-dimensional array.

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/2987811/bugreport.zip&gt;bugreport.zip&lt;/denchmark-link&gt;

Model: lite_model_v2.zip
Java: LiteEvaluator.java
Dependency:
Equal behavior exists for both
implementation 'org.tensorflow:tensorflow-lite:1.13.1'
and
implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
Other info / logs
	</description>
	<comments>
		<comment id='1' author='keesduisters' date='2019-03-20T17:59:50Z'>
		Thanks for the report, I'll take a look.
		</comment>
		<comment id='2' author='keesduisters' date='2019-03-20T18:06:07Z'>
		What is the shape of your input tensor?
		</comment>
		<comment id='3' author='keesduisters' date='2019-03-20T18:35:57Z'>
		I've run your code, and if I give it the natural (1, 3, 200, 1) shape it behaves as expected. I'll need to know what shape you're providing.
Note that not all graphs support dynamic resizing based on the input shape. If you have any operators in the graph with fixed shape assumptions, the resize may fail or produce an invalid shape.
		</comment>
		<comment id='4' author='keesduisters' date='2019-03-25T10:59:31Z'>
		The bug was in my own code; the shape provided was (1, 200, 3, 1) i.s.o. (1, 3, 200, 1). Appologies, and thanks for looking into it.
I'm not much of an expert in using neural networks, but the fact that no error is ever produced about mismatching input shapes seems odd to me.
Is it desired to insert different-shaped inputs, or would it be a nice new feature to validate the inputs?
		</comment>
		<comment id='5' author='keesduisters' date='2019-03-25T10:59:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26932&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26932&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>