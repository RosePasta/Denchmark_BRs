<bug id='39489' author='wenhui-prudencemed' open_date='2020-05-13T06:51:06Z' closed_time='2020-12-01T18:11:01Z'>
	<summary>Add support of uint8 and int8 for MEAN op</summary>
	<description>
@tensorflow/micro
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/reduce.cc#L113&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/reduce.cc#L113&lt;/denchmark-link&gt;

// TODO(b/144955155): Support uint8(b/144955155) and int8(b/144955018)
Could you implement this so we can use the MEAN op in int8 model?
	</description>
	<comments>
		<comment id='1' author='wenhui-prudencemed' date='2020-05-13T09:50:04Z'>
		Hi Meghna,
Can you give an update on these bugs?
		</comment>
		<comment id='2' author='wenhui-prudencemed' date='2020-05-13T17:38:37Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 I've re-assigned the task.
		</comment>
		<comment id='3' author='wenhui-prudencemed' date='2020-08-18T18:03:02Z'>
		Are there any good work arounds for this? I am trying to do transfer learning on MobileNet and then run it on TF Micro.
Following the TF Tutorial, it uses a GlobalAveragePooling2D layer before the classifier which uses the reduce() function in it. Is there an alternate architecture that would work?
&lt;denchmark-code&gt;global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
feature_batch_average = global_average_layer(feature_batch) 
prediction_layer = tf.keras.layers.Dense(1)
prediction_batch = prediction_layer(feature_batch_average)
print(prediction_batch.shape)

x = global_average_layer(x)
x = tf.keras.layers.Dropout(0.2)(x)
outputs = prediction_layer(x)
model = tf.keras.Model(inputs, outputs)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='wenhui-prudencemed' date='2020-08-18T23:22:39Z'>
		As theGlobalAveragePooling2D() layer uses theMEAN operator internally, and as we don't support uint8/int8 versions of the MEAN operator -- these models cannot be converted to int-only TFLite models and thus, cannot be used with TFLite Micro.
You can get rid of the MEAN op dependency by replacing GlobalAveragePooling2D() with two operators that are supported as follows:
BEFORE
&lt;denchmark-code&gt;base_model =  tf.keras.applications.MobileNetV2(....)
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(1)
])
&lt;/denchmark-code&gt;

AFTER
&lt;denchmark-code&gt;base_model =  tf.keras.applications.MobileNetV2(....)
POOL_SIZE = base_model.layers[-1].output.shape.as_list()[1:3]
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.AveragePooling2D(POOL_SIZE),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1),
])
&lt;/denchmark-code&gt;

You need to now estimate the POOL_SIZE that was automatically estimated by the GlobalAveragePooling2D() op, but it's better to use this workaround (and easier) than adding uint8/int8 support for the MEAN op. :)
Let us know if this works for you!
		</comment>
		<comment id='5' author='wenhui-prudencemed' date='2020-08-19T03:15:27Z'>
		&lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 Thanks for responding! That fix worked perfectly. I was able to export a TFLite model and run it on an OpenMV H7 Plus.
		</comment>
		<comment id='6' author='wenhui-prudencemed' date='2020-12-01T18:11:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39489&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39489&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>