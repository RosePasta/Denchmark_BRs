<bug id='11155' author='alanyee' open_date='2017-06-29T23:58:32Z' closed_time='2018-09-15T01:09:05Z'>
	<summary>head.py still uses scalar_summary</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Sierra 10.12.5
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.2.1
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

head.py still uses logging_ops.scalar_summary despite the method being a depreciated, leading to warnings. The problem seems to start from estimator.fit and estimator.evaluate
&lt;denchmark-h:h3&gt;Source code&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow as tf
# NumPy is often used to load, manipulate and preprocess data.
import numpy as np

# Declare list of features. We only have one real-valued feature. There are many
# other types of columns that are more complicated and useful.
features = [tf.contrib.layers.real_valued_column("x", dimension=1)]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# logistic regression, linear classification, logistic classification, and
# many neural network classifiers and regressors. The following code
# provides an estimator that does linear regression.
estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.contrib.learn.io.numpy_input_fn({"x":x_train}, y_train,
                                              batch_size=4,
                                              num_epochs=1000)
eval_input_fn = tf.contrib.learn.io.numpy_input_fn(
    {"x":x_eval}, y_eval, batch_size=4, num_epochs=1000)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.fit(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_loss = estimator.evaluate(input_fn=input_fn)

eval_loss = estimator.evaluate(input_fn=eval_input_fn)

print "train loss: %r"% train_loss
print "eval loss: %r"% eval_loss
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1l/v82bx7_s5zvf7z8wlgjz4j_06gd09g/T/tmpQRR2VF
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
2017-06-29 16:53:02.952908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952925: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-29 16:53:02.952934: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /Users/admin/Library/Python/2.7/lib/python/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
train metrics: {'loss': 9.803332e-07, 'global_step': 1000}
eval metrics: {'loss': 0.0026192721, 'global_step': 1000}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='alanyee' date='2017-06-30T02:12:57Z'>
		Hi,
You are right! I have created a pull request in order to use   which you can modify locally if you want to get rid of the error. Have a look to proposed file changes in  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/11159&gt;#11159&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>