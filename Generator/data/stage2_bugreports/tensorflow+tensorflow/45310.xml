<bug id='45310' author='mwlon' open_date='2020-12-01T21:42:37Z' closed_time='2020-12-24T04:33:56Z'>
	<summary>Segmentation fault during training simple decision tree classifier</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac Catalina 10.15.7
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
Python version: 3.8.6
CUDA/cuDNN version: NA?
GPU model and memory: using CPU

Describe the current behavior
I was trying to train a boosted tree, got a seg fault, and ultimately replicated it with this canned example from &lt;denchmark-link:https://www.tensorflow.org/tutorials/estimator/boosted_trees&gt;https://www.tensorflow.org/tutorials/estimator/boosted_trees&lt;/denchmark-link&gt;
 .
What I get is a segmentation fault detailed below.
Describe the expected behavior
I would expect this to run and print the result, rather than giving a segmentation fault.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import pandas as pd

# Load dataset.
dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

import tensorflow as tf
tf.random.set_seed(123)

CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
  return tf.feature_column.indicator_column(
      tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
  # Need to one-hot encode categorical features.
  vocabulary = dftrain[feature_name].unique()
  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
  feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                           dtype=tf.float32))

# Use entire batch since this is such a small dataset.
NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=True):
  def input_fn():
    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
    if shuffle:
      dataset = dataset.shuffle(NUM_EXAMPLES)
    # For training, cycle thru dataset as many times as need (n_epochs=None).
    dataset = dataset.repeat(n_epochs)
    # In memory training doesn't use batching.
    dataset = dataset.batch(NUM_EXAMPLES)
    return dataset
  return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)

# Since data fits into memory, use entire dataset per layer. It will be faster.
# Above one batch is defined as the entire dataset.
n_batches = 1
est = tf.estimator.BoostedTreesClassifier(feature_columns,
                                          n_batches_per_layer=n_batches)

# The model will stop training once the specified number of trees is built, not
# based on the number of steps.
est.train(train_input_fn, max_steps=100)

# Eval.
result = est.evaluate(eval_input_fn)
print(pd.Series(result))
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;WARNING:tensorflow:Using temporary folder as model directory: /var/folders/97/twhbc2yn6l77_rh7vn94hf7c0000gp/T/tmptaagswd_
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:398: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
2020-12-01 16:40:43.597377: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-01 16:40:43.614731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d8e78c990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-01 16:40:43.614747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/head.py:637: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to "careful_interpolation" instead.
WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to "careful_interpolation" instead.
zsh: segmentation fault  python temp2.py
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mwlon' date='2020-12-02T12:35:44Z'>
		&lt;denchmark-link:https://github.com/mwlon&gt;@mwlon&lt;/denchmark-link&gt;
,
I was able to run both the &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/3c85ec6b94a7bbe4ec6f80a3efd3be9d/boosted_trees.ipynb&gt;tutorial&lt;/denchmark-link&gt;
 and the &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/bfe1717eb35ef5fe61cec94122769ec5/45310.ipynb&gt;code snippet&lt;/denchmark-link&gt;
 you have provided, without any issues. Please check the linked gist for reference.
Could you please try run the code in a new virtual environment and check if you are facing the same issue? Thanks!
		</comment>
		<comment id='2' author='mwlon' date='2020-12-02T17:39:45Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 Yes, that's actually exactly what I did. I created a new venv, installed ONLY tensorflow and pandas (via ), and then got this issue. Did you run with Catalina, the same package versions, etc?
&lt;denchmark-code&gt;(tf) % python --version 
Python 3.8.6
(tf) % pip list
Package                Version
---------------------- ---------
absl-py                0.11.0
astunparse             1.6.3
cachetools             4.1.1
certifi                2020.11.8
chardet                3.0.4
gast                   0.3.3
google-auth            1.23.0
google-auth-oauthlib   0.4.2
google-pasta           0.2.0
grpcio                 1.33.2
h5py                   2.10.0
idna                   2.10
Keras-Preprocessing    1.1.2
Markdown               3.3.3
numpy                  1.18.5
oauthlib               3.1.0
opt-einsum             3.3.0
pandas                 1.1.4
pip                    20.2.1
protobuf               3.14.0
pyasn1                 0.4.8
pyasn1-modules         0.2.8
python-dateutil        2.8.1
pytz                   2020.4
requests               2.25.0
requests-oauthlib      1.3.0
rsa                    4.6
setuptools             49.2.1
six                    1.15.0
tensorboard            2.4.0
tensorboard-plugin-wit 1.7.0
tensorflow             2.3.1
tensorflow-estimator   2.3.0
termcolor              1.1.0
urllib3                1.26.2
Werkzeug               1.0.1
wheel                  0.36.0
wrapt                  1.12.1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='mwlon' date='2020-12-02T17:44:00Z'>
		Here's the most relevant segment from the Mac "Python unexpectedly quit" popup log. Let me know if you want more detail from this:
&lt;denchmark-code&gt;Application Specific Information:
abort() called
Python(20849,0x10e2d1dc0) malloc: *** error for object 0x3f8000003f800000: pointer being freed was not allocated
 

Thread 0 Crashed:: Dispatch queue: com.apple.main-thread
0   libsystem_kernel.dylib        	0x00007fff711a633a __pthread_kill + 10
1   libsystem_pthread.dylib       	0x00007fff71262e60 pthread_kill + 430
2   libsystem_c.dylib             	0x00007fff7112d808 abort + 120
3   libsystem_malloc.dylib        	0x00007fff7122350b malloc_vreport + 548
4   libsystem_malloc.dylib        	0x00007fff7122640f malloc_report + 151
5   libtensorflow_framework.2.dylib	0x000000013d6281ad tensorflow::shape_inference::InferenceContext::~InferenceContext() + 861
6   libtensorflow_framework.2.dylib	0x000000013d73b570 std::__1::unique_ptr&lt;tensorflow::ExtendedInferenceContext, std::__1::default_delete&lt;tensorflow::ExtendedInferenceContext&gt; &gt;::~unique_ptr() + 96
7   libtensorflow_framework.2.dylib	0x000000013d739d56 tensorflow::ShapeRefiner::~ShapeRefiner() + 406
8   _pywrap_tensorflow_internal.so	0x0000000124b559aa TF_DeleteGraph + 186
9   _pywrap_tf_session.so         	0x000000013ec728d7 void pybind11::cpp_function::initialize&lt;void (*&amp;)(TF_Graph*), void, TF_Graph*, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::call_guard&lt;pybind11::gil_scoped_release&gt; &gt;(void (*&amp;)(TF_Graph*), void (*)(TF_Graph*), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::call_guard&lt;pybind11::gil_scoped_release&gt; const&amp;)::'lambda'(pybind11::detail::function_call&amp;)::operator()(pybind11::detail::function_call&amp;) const + 103
10  _pywrap_tf_session.so         	0x000000013ec5770f pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 2943
11  org.python.python             	0x000000010c3b3f8e cfunction_call_varargs + 171
12  org.python.python             	0x000000010c3b3a7d _PyObject_MakeTpCall + 274
13  org.python.python             	0x000000010c454847 call_function + 804
14  org.python.python             	0x000000010c451257 _PyEval_EvalFrameDefault + 29861
15  org.python.python             	0x000000010c3b42c2 function_code_fastcall + 106
16  org.python.python             	0x000000010c3f9a73 call_unbound_noarg + 76
17  org.python.python             	0x000000010c3f7500 slot_tp_finalize + 72
18  org.python.python             	0x000000010c49957f collect + 1918
19  org.python.python             	0x000000010c498d88 collect_with_callback + 58
20  org.python.python             	0x000000010c498d1f PyGC_Collect + 93
21  org.python.python             	0x000000010c47d045 Py_FinalizeEx + 135
22  org.python.python             	0x000000010c49816f Py_RunMain + 1414
23  org.python.python             	0x000000010c49867e pymain_main + 306
24  org.python.python             	0x000000010c4986cc Py_BytesMain + 42
25  libdyld.dylib                 	0x00007fff7105ecc9 start + 1
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='mwlon' date='2020-12-02T17:51:36Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 I've replicated the issue on  Catalina (10.15.7) machine, creating a venv with python 3.8.2 this time, installing tensorflow and pandas, and running the exact same script.
		</comment>
		<comment id='5' author='mwlon' date='2020-12-04T10:11:45Z'>
		&lt;denchmark-link:https://github.com/mwlon&gt;@mwlon&lt;/denchmark-link&gt;

you can try to run this cmd before run the model

		</comment>
		<comment id='6' author='mwlon' date='2020-12-05T04:23:27Z'>
		&lt;denchmark-link:https://github.com/zhenql&gt;@zhenql&lt;/denchmark-link&gt;
 This is what I get:
&lt;denchmark-code&gt;(tf) % ulimit -s 102400
ulimit: value exceeds hard limit

(tf) % ulimit -a       
-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192
-c: core file size (blocks)         0
-v: address space (kbytes)          unlimited
-l: locked-in-memory size (kbytes)  unlimited
-u: processes                       2784
-n: file descriptors                256
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='mwlon' date='2020-12-06T06:46:58Z'>
		
Did you run with Catalina, the same package versions, etc?

&lt;denchmark-link:https://github.com/mwlon&gt;@mwlon&lt;/denchmark-link&gt;
,
Thank you for the updates. I had run the code on Ubuntu 18.04 with TensorFlow 2.3.0 and Pandas 1.1.4.
		</comment>
		<comment id='8' author='mwlon' date='2020-12-07T07:40:23Z'>
		&lt;denchmark-link:https://github.com/mwlon&gt;@mwlon&lt;/denchmark-link&gt;

 or other size more than 8192.
I'm not sure if the method works though my tf program always require more stack size.
		</comment>
		<comment id='9' author='mwlon' date='2020-12-10T03:41:26Z'>
		&lt;denchmark-link:https://github.com/mwlon&gt;@mwlon&lt;/denchmark-link&gt;
 Did you check whether you have the same issue on the local (without ). May be there is something limiting the memory.
Also, can you please check with other python version with venv. Thanks!
		</comment>
		<comment id='10' author='mwlon' date='2020-12-17T04:03:58Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='11' author='mwlon' date='2020-12-24T04:33:54Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='12' author='mwlon' date='2020-12-24T04:33:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45310&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45310&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>