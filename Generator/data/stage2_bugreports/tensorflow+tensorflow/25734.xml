<bug id='25734' author='elyasmehtabuddin' open_date='2019-02-14T03:06:33Z' closed_time='2019-02-19T19:52:20Z'>
	<summary>TPU has XLA compilation issue on TF 1.13rc1</summary>
	<description>
I am getting an issue with using XLA on the cloud TPU on tensorflow version 1.13 (but not 1.12).
tag:comp:tpus
comp:tpus
System information

Using Google's cloud TPU with Tensorflow 1.12

System info:
&lt;denchmark-code&gt;== cat /etc/issue ===============================================
Linux aportnoy 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux
VERSION_ID="9"
VERSION="9 (stretch)"

== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 6.3.0-18+deb9u1) 6.3.0 20170516
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux aportnoy 4.9.0-8-amd64 #1 SMP Debian 4.9.130-2 (2018-10-27) x86_64 GNU/Linux

== check pips ===================================================
numpy (1.16.1)
protobuf (3.6.1)
tensorflow (1.12.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.12.0
tf.GIT_VERSION = v1.12.0-0-ga6d8ffae09
tf.COMPILER_VERSION = v1.12.0-0-ga6d8ffae09
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
&lt;/denchmark-code&gt;

Describe the current behavior
When I uninstall tensorflow 1.12 and install tensorflow 1.13 via:
pip3 uninstall tensorflow
pip3 install tensorflow==1.13.0rc1
Then run my model, I get a very strange error which looks like this:
&lt;denchmark-code&gt;aportnoy@aportnoy:~$ python3 script.py
2019-02-13 17:59:43.159373: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-13 17:59:43.165347: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-02-13 17:59:43.165597: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5642dd857ad0 executing computations on platform Host. Devices:
2019-02-13 17:59:43.165641: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
WARNING:tensorflow:From /home/aportnoy/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-02-13 17:59:43.305988: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:179] Subgraph fingerprint:7855156155640739707
2019-02-13 17:59:43.401974: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at xla_ops.cc:310 : Invalid argument: Expected LHS feature dimension (value 19) to be a multiple of feature_group_count (value 728), and LHS feature 
dimension / feature_group_count = RHS feature dimension (value 1); got &lt;conv&gt;(f32[1,19,19,728,1], f32[1,19,19,728,1])
Dimension numbers: {kernel_input_feature_dimension: 4
kernel_output_feature_dimension: 1
kernel_spatial_dimensions: 0
kernel_spatial_dimensions: 2
kernel_spatial_dimensions: 3
input_batch_dimension: 4
input_feature_dimension: 1
output_batch_dimension: 3
output_feature_dimension: 4
input_spatial_dimensions: 0
input_spatial_dimensions: 2
input_spatial_dimensions: 3
output_spatial_dimensions: 0
output_spatial_dimensions: 1
output_spatial_dimensions: 2
}.
         [[{{node gradients/sep0/separable_conv2d/depthwise_grad/DepthwiseConv2dNativeBackpropFilter}}]]
&lt;/denchmark-code&gt;

Describe the expected behavior
When using tensorflow version 1.12 there isn't an error:
&lt;denchmark-code&gt;aportnoy@aportnoy:~$ python3 script.py
2019-02-13 18:19:58.250311: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-13 18:19:58.404755: I tensorflow/compiler/jit/encapsulate_xla_computations_pass.cc:179] Subgraph fingerprint:1939207595948626618
2019-02-13 18:19:58.499394: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-02-13 18:19:58.499806: I tensorflow/compiler/xla/service/service.cc:149] XLA service 0x7f39fc00b5b0 executing computations on platform Host. Devices:
2019-02-13 18:19:58.499871: I tensorflow/compiler/xla/service/service.cc:157]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
&lt;/denchmark-code&gt;

Code to reproduce the issue
My script.py, reproduce with python3 script.py
&lt;denchmark-code&gt;import os
import tensorflow as tf
from tensorflow.contrib.compiler import xla

data_format = 'channels_first'

def simple(features, labels):
  net = features

  net = tf.keras.layers.SeparableConv2D(728, [3, 3],
    strides=1,
    padding='same',
    data_format=data_format,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    name='sep0')(net)
  
  net = tf.keras.layers.Flatten(data_format=data_format)(net)
  net = tf.keras.layers.Dense(10, activation=None, use_bias=True, name='fully0')(net)

  labels = tf.stop_gradient(labels)
  loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=net) )

  train_step = tf.train.GradientDescentOptimizer(1e-6).minimize(loss)

  return net, train_step

config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)

images = tf.constant(1.2, shape=[1, 728, 19, 19], dtype=tf.float32)
labels = tf.constant(1, shape=[1, 10], dtype=tf.float32)

[y] = xla.compile(simple, inputs=[images, labels])

sess.run(tf.global_variables_initializer())
sess.run(y)
&lt;/denchmark-code&gt;

Other info / logs
The issue only exists on the new 1.13.
I would use 1.12 but my situation requires me to use 'channels_first' for my model, XLA enabled, and 1.13.
Here are also images of me running the script ( First on 1.12 which is working then on 1.13 which doesn't work ) :
&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/52759838-37edc100-2fc2-11e9-8cfc-955a15a098c8.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/52759837-37edc100-2fc2-11e9-85cf-45b599252e27.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='elyasmehtabuddin' date='2019-02-14T18:01:13Z'>
		Can you try on master?
		</comment>
		<comment id='2' author='elyasmehtabuddin' date='2019-02-14T18:30:05Z'>
		FYI internal tracking b/124448884
		</comment>
		<comment id='3' author='elyasmehtabuddin' date='2019-02-14T18:35:25Z'>
		Alright,
Using a separate machine I use for building, I just built tensorflow from scratch using the latest master branch and created the whl file (using -c opt). This produced a whl file with the name of tensorflow-1.12.0-cp35-cp35m-linux_x86_64.whl which I installed after uninstalling my current tensorflow using pip.
I then ran the script.py that reproduces the issue, and the issue does NOT happen. Output here:
&lt;denchmark-code&gt;Limited tf.compat.v2.summary API due to missing TensorBoard installation
2019-02-14 18:34:03.829934: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2019-02-14 18:34:03.845549: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2693675000 Hz
2019-02-14 18:34:03.856202: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x4013f20 executing computations on platform Host. Devices:
2019-02-14 18:34:03.856244: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
WARNING: Logging before flag parsing goes to stderr.
W0214 18:34:03.872129 140737353991936 deprecation.py:506] From /home/elyas/.local/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
&lt;/denchmark-code&gt;

However keep in mind this doesn't resolve my issue, I need this issue to be resolved on version 1.13
Thanks
		</comment>
		<comment id='4' author='elyasmehtabuddin' date='2019-02-14T18:54:23Z'>
		I've reproduced this on docker in 1.13.0rc0 and 1.13.0rc1 but it seems to not a problem on nightly or 1.12. So yes it is definitely a problem unique to 1.13 RC as you say. We're taking a look at this and will keep you posted.
		</comment>
		<comment id='5' author='elyasmehtabuddin' date='2019-02-19T19:52:20Z'>
		Closing this issue since the PR has been merged. Thanks!
		</comment>
		<comment id='6' author='elyasmehtabuddin' date='2019-02-19T21:01:38Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 No, thank you!
		</comment>
	</comments>
</bug>