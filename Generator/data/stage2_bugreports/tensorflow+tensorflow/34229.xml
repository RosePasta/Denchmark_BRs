<bug id='34229' author='MachineJeff' open_date='2019-11-13T12:30:19Z' closed_time='2019-12-09T23:52:38Z'>
	<summary>after graph_transforms with pb file , something went error</summary>
	<description>
&lt;denchmark-h:h2&gt;Enviroment&lt;/denchmark-h&gt;

GPU Type: Tesla T4
Nvidia Driver Version: 418.87.01
CUDA Version: 10.1.243
CUDNN Version: 7.6.3
Python Version: 3.7.4
TensorFlow Version: 1.14.1
Bazel Version: 0.24.1
Operating System Version: Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-142-generic x86_64)
&lt;denchmark-h:h2&gt;Tools&lt;/denchmark-h&gt;

graph_transforms
It's a toolkit in tensorflow original code (tensorflow/tools/graph_transforms)
&lt;denchmark-h:h2&gt;Step&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;1. build&lt;/denchmark-h&gt;

bazel build tensorflow/tools/graph_transforms:transform_graph
&lt;denchmark-h:h3&gt;2. transform pb&lt;/denchmark-h&gt;

bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=my.pb \
--out_graph=out.pb \
--inputs='inputs' \
--outputs='BiasAdd' \
--transforms='
add_default_attributes
strip_unused_nodes(type=float)
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
round_weights(num_steps=256)
quantize_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'
&lt;denchmark-h:h3&gt;3. test origin pb file i.e. my.pb, it's OK&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;4. test output pb file i.e. out.pb , it went error:&lt;/denchmark-h&gt;

(0) Invalid argument: requested_output_max must be &gt;= requested_output_min, but got -nan and 0
	 [[{{node Tacotron-2/inference/decoder/while/CustomDecoderStep/mul/eightbit/requantize}}]]
	 [[Tacotron-2/inference/decoder/while/CustomDecoderStep/decoder_LSTM/decoder_LSTM/multi_rnn_cell/cell_0/decoder_LSTM_1/add/_545]]

(1) Invalid argument: requested_output_max must be &gt;= requested_output_min, but got -nan and 0
	 [[{{node Tacotron-2/inference/decoder/while/CustomDecoderStep/mul/eightbit/requantize}}]]
&lt;denchmark-h:h2&gt;Additional&lt;/denchmark-h&gt;

I used the following code to test if pb file worked:
def pb2inference(args):
    tf.reset_default_graph()
    my_graph_def = tf.GraphDef()
    with tf.gfile.GFile(args.pb, 'rb') as fid:
        serialized_graph = fid.read()
        my_graph_def.ParseFromString(serialized_graph)
        tf.import_graph_def(my_graph_def, name = '')

    my_graph = tf.get_default_graph()

    inputs = my_graph.get_tensor_by_name('inputs:0')
    out = my_graph.get_tensor_by_name('BiasAdd:0')

    with tf.Session(graph=my_graph) as sess:
        feed_dict = {inputs:seq}
        out= sess.run(out, feed_dict = feed_dict)
It worked in my.pb, but got error in out.pb. In addition, the transform process has no warning or error.
	</description>
	<comments>
		<comment id='1' author='MachineJeff' date='2019-11-22T23:27:21Z'>
		Please attach input pbfile to repro the reported issue. Thanks!
		</comment>
		<comment id='2' author='MachineJeff' date='2019-12-09T23:52:38Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='3' author='MachineJeff' date='2019-12-09T23:52:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34229&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34229&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>