<bug id='33094' author='luvwinnie' open_date='2019-10-06T23:45:43Z' closed_time='2019-10-25T18:28:58Z'>
	<summary>Tensorflow 2.0.0 / tf.keras.layers.TimeDistributed layer can't be save to saved Model</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution : Colaboratory (GPU Runtime)
tensorflow version: 2.0.0
python version: 3.6.8

Describe the current behavior
The model defined which has tf.keras.layers.timeDistributed layer cannot be save by model.save() function.
It shows the error below
&lt;denchmark-code&gt;ValueError                                Traceback (most recent call last)
/usr/lib/python3.6/inspect.py in getfullargspec(func)
   1125                                        skip_bound_arg=False,
-&gt; 1126                                        sigcls=Signature)
   1127     except Exception as ex:

41 frames
ValueError: no signature found for builtin &lt;tensorflow.python.keras.saving.saved_model.save_impl.LayerCall object at 0x7f74467284a8&gt;

The above exception was the direct cause of the following exception:

TypeError                                 Traceback (most recent call last)
/usr/lib/python3.6/inspect.py in getfullargspec(func)
   1130         # else. So to be fully backwards compatible, we catch all
   1131         # possible exceptions here, and reraise a TypeError.
-&gt; 1132         raise TypeError('unsupported callable') from ex
   1133 
   1134     args = []

TypeError: unsupported callable
&lt;/denchmark-code&gt;

Describe the expected behavior
In tensorflow 2.0.0 supposed the model.save model default to be saved in SavedModel format.
Code to reproduce the issue
&lt;denchmark-code&gt;
def get_data():
  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)
  mnist_train, mnist_test = datasets['train'], datasets['test']

  BUFFER_SIZE = 10000

  BATCH_SIZE_PER_REPLICA = 64
  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync

  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255

    return image, label

  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

  return train_dataset, eval_dataset

def get_model():
  with mirrored_strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        # tf.keras.layers.Flatten(),
        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='softmax')),
        # tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation='softmax')),
        # tf.keras.layers.Dense(10, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Adam(),
                  metrics=['accuracy'])
    return model

model = get_model()
model.save("test_save")
&lt;/denchmark-code&gt;

Other info / logs
The not only can be reproduce in Colaboratory, but also in normal Ubuntu machien which installed with tensorflow-gpu 2.0.0
	</description>
	<comments>
		<comment id='1' author='luvwinnie' date='2019-10-09T11:19:32Z'>
		Could reproduce this issue with TF Version 2.0. Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/c698628e49bce4d456daac7c2ddf3bea/33094.ipynb&gt;Gist&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='luvwinnie' date='2019-10-18T21:39:02Z'>
		Also running into this. Here's a concise test case:
&lt;denchmark-code&gt;model = tf.keras.Sequential([tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1), input_shape=(None, 1))])
model.save('test_save')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='luvwinnie' date='2019-10-23T01:48:41Z'>
		does this issues got any progress?
		</comment>
		<comment id='4' author='luvwinnie' date='2019-10-24T23:52:21Z'>
		Any update?
		</comment>
		<comment id='5' author='luvwinnie' date='2019-10-25T00:38:22Z'>
		This appears to be an error with Python 3. Submitting a fix to resolve this.
		</comment>
		<comment id='6' author='luvwinnie' date='2019-10-25T18:29:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33094&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33094&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='luvwinnie' date='2019-10-26T08:36:28Z'>
		so is this been fixed to tensorflow-gpu 2.0 stable build? or i have to install another build?
		</comment>
		<comment id='8' author='luvwinnie' date='2019-10-29T15:46:31Z'>
		&lt;denchmark-link:https://github.com/luvwinnie&gt;@luvwinnie&lt;/denchmark-link&gt;
 It was fixed in  which is development version of  (will be released in
the near future). Thanks!
		</comment>
	</comments>
</bug>