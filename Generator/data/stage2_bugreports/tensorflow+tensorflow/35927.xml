<bug id='35927' author='xuchengggg' open_date='2020-01-16T07:00:58Z' closed_time='2020-03-02T19:07:00Z'>
	<summary>error when set converter.experimental_new_converter = True</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): pip install
TensorFlow version (or github SHA if from source): tf-nightly == 2.1.0-dev20200101

Command used to run the converter or code if youâ€™re using the Python API
&lt;denchmark-code&gt;def model():
    input_image = keras.layers.Input(shape=[])
    C3, C4, C5 = resnet_graph(input_image)
    P3, P4, P5, P6, P7 = FPN_graph(C3, C4, C5)
    loc_data, conf_data, mask_data = predict_graph(P3, P4, P5, P6, P7)
    proto_data = protonet(P3)
    anchors = get_priors(config.IMAGE_SHAPE)
    refined_boxes = DecodeBoxes(loc_data, anchors)
    # batch_multiclass_non_max_suppression() is in object_detection.core.post_processing.py
    boxes, scores, class_ids, mask_coef, num_detection =   batch_multiclass_non_max_suppression()
    masks = AssemblyMask(mask_coef, proto_out, boxes)
    model = keras.models.Model([input_image],[boxes, class_ids, scores, masks, num_detections])
   return model

model = model()
model.load_weights('.h5')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
tflite_model = converter.convert()    
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-16 14:11:43.696917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:11:43.696927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-16 14:11:43.696936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-16 14:11:43.696944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-16 14:11:43.696952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-16 14:11:43.696960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-16 14:11:43.696968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-16 14:11:43.697006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:43.697323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:43.697611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-01-16 14:11:43.697635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:11:43.698527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 14:11:43.698539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-01-16 14:11:43.698544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-01-16 14:11:43.698621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:43.698944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:43.699248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8422 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-01-16 14:11:58.365227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.365704: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2020-01-16 14:11:58.365842: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-01-16 14:11:58.366283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.366583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-16 14:11:58.366616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:11:58.366627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-16 14:11:58.366636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-16 14:11:58.366645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-16 14:11:58.366655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-16 14:11:58.366664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-16 14:11:58.366674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-16 14:11:58.366709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.367016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.367298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-01-16 14:11:58.367315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 14:11:58.367319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-01-16 14:11:58.367323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-01-16 14:11:58.367372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.367682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:11:58.367971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8422 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-01-16 14:11:58.687280: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: graph_to_optimize
2020-01-16 14:11:58.687309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: Graph size after: 1511 nodes (0), 3113 edges (0), time = 51.53ms.
2020-01-16 14:11:58.687313: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: Graph size after: 1511 nodes (0), 3113 edges (0), time = 55.71ms.
2020-01-16 14:11:58.687315: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: yolact_yolact_detection_map_while_cond_24503
2020-01-16 14:11:58.687319: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-01-16 14:11:58.687322: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-01-16 14:11:58.687324: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: yolact_yolact_detection_map_while_body_24504
2020-01-16 14:11:58.687327: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-01-16 14:11:58.687330: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-01-16 14:12:00.043387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.043733: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2020-01-16 14:12:00.043796: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-01-16 14:12:00.044138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.044457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-16 14:12:00.044485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:12:00.044496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-16 14:12:00.044505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-16 14:12:00.044515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-16 14:12:00.044524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-16 14:12:00.044533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-16 14:12:00.044542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-16 14:12:00.044572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.044887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.045176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-01-16 14:12:00.045194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 14:12:00.045199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-01-16 14:12:00.045202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-01-16 14:12:00.045251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.045555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:00.045994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8422 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-01-16 14:12:06.926724: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: graph_to_optimize
2020-01-16 14:12:06.926752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 955 nodes (-556), 2636 edges (-445), time = 208.331ms.
2020-01-16 14:12:06.926756: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 955 nodes (0), 2636 edges (0), time = 80.347ms.
2020-01-16 14:12:06.926759: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: yolact_yolact_detection_map_while_cond_24503_frozen
2020-01-16 14:12:06.926762: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 19 nodes (0), 8 edges (0), time = 0.333ms.
2020-01-16 14:12:06.926765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 19 nodes (0), 8 edges (0), time = 0.201ms.
2020-01-16 14:12:06.926767: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:815] Optimization results for grappler item: yolact_yolact_detection_map_while_body_24504_frozen
2020-01-16 14:12:06.926770: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 4210 nodes (-252), 5496 edges (-407), time = 6253.95508ms.
2020-01-16 14:12:06.926773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:817]   constant_folding: Graph size after: 4210 nodes (0), 5496 edges (0), time = 99.047ms.
Traceback (most recent call last):
  File "/home/chengxu/deeplearning/tensorflow-2.0-study/yolact.py", line 1567, in &lt;module&gt;
    tflite_model = converter.convert()
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py", line 490, in convert
    **converter_kwargs)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 476, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 215, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
WARNING:tensorflow:Falling back to tensorflow client, its recommended to install the cloud tpu client directly with pip install cloud-tpu-client .
2020-01-16 14:12:08.249581: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:108] Ignored output_format.
2020-01-16 14:12:08.249608: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:114] Ignored drop_control_dependency.
2020-01-16 14:12:08.674483: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-16 14:12:08.698096: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 3600000000 Hz
2020-01-16 14:12:08.698483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf05e1f380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-16 14:12:08.698496: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-16 14:12:08.700080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-16 14:12:08.752405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.752789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf05e3f110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-01-16 14:12:08.752801: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-01-16 14:12:08.752929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.753249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-16 14:12:08.753413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:12:08.754500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-16 14:12:08.755559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-16 14:12:08.755751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-16 14:12:08.756823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-16 14:12:08.757307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-16 14:12:08.759489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-16 14:12:08.759597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.759997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.760301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-01-16 14:12:08.760338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:12:08.760970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 14:12:08.760980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-01-16 14:12:08.760999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-01-16 14:12:08.761074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.761435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:12:08.761758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8039 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
loc(callsite("yolact/yolact_detection/map/TensorArrayV2_5"("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py":425:0) at callsite("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py":574:0 at callsite("/home/chengxu/deeplearning/tensorflow-2.0-study/utils/shape_utils.py":228:0 at callsite("/home/chengxu/deeplearning/tensorflow-2.0-study/core/post_processing.py":476:0 at callsite("/home/chengxu/deeplearning/tensorflow-2.0-study/yolact.py":1118:0 at callsite("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py":308:0 at callsite("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py":785:0 at callsite("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py":918:0 at callsite("/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py":744:0 at "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py":785:0)))))))))): error: operand type 'tensor&lt;i32&gt;' is not compatible with preceding operands; expected rank: 1
Traceback (most recent call last):
  File "/home/chengxu/anaconda3/envs/tf-nightly/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: /home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py:425:7: error: operand type 'tensor&lt;i32&gt;' is not compatible with preceding operands; expected rank: 1
      name=name)
      ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:574:7: note: called from
      return func(*args, **kwargs)
      ^
/home/chengxu/deeplearning/tensorflow-2.0-study/utils/shape_utils.py:228:9: note: called from
        return tf.map_fn(fn, elems, dtype, parallel_iterations, back_prop)
        ^
/home/chengxu/deeplearning/tensorflow-2.0-study/core/post_processing.py:476:7: note: called from
      parallel_iterations=parallel_iterations)
      ^
/home/chengxu/deeplearning/tensorflow-2.0-study/yolact.py:1118:98: note: called from
                                                                                                 masks=mask_data)
                                                                                                 ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py:308:7: note: called from
      return func(*args, **kwargs)
      ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:785:19: note: called from
                  outputs = call_fn(cast_inputs, *args, **kwargs)
                  ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:918:11: note: called from
          output_tensors = layer(computed_tensors, **kwargs)
          ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:744:9: note: called from
        convert_kwargs_to_constants=base_layer_utils.call_context().saving)
        ^
/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:785:19: note: called from
                  outputs = call_fn(cast_inputs, *args, **kwargs)
                  ^

Process finished with exit code 1







if remove converter.experimental_new_converter = True

WARNING:absl:Please consider switching to use new converter by setting experimental_new_converter to true. Old converter (TOCO) is deprecated and flow will be switched on by default to use new converter soon.
Traceback (most recent call last):
  File "/home/chengxu/deeplearning/tensorflow-2.0-study/yolact.py", line 1567, in &lt;module&gt;
    tflite_model = converter.convert()
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py", line 490, in convert
    **converter_kwargs)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 476, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 215, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
WARNING:tensorflow:Falling back to tensorflow client, its recommended to install the cloud tpu client directly with pip install cloud-tpu-client .
2020-01-16 14:54:09.455905: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-16 14:54:09.477996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 3600000000 Hz
2020-01-16 14:54:09.478678: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55641b1a91a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-16 14:54:09.478691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-16 14:54:09.480333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-16 14:54:09.539873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.540262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55641b23d750 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-01-16 14:54:09.540278: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-01-16 14:54:09.540443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.540744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-16 14:54:09.540885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:54:09.542169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-16 14:54:09.543344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-16 14:54:09.543537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-16 14:54:09.544789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-16 14:54:09.545460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-16 14:54:09.548110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-16 14:54:09.548224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.548649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.548942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2020-01-16 14:54:09.548974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-16 14:54:09.549580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-16 14:54:09.549591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-01-16 14:54:09.549598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-01-16 14:54:09.549669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.550038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-16 14:54:09.550342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8020 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-01-16 14:54:09.621430: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-01-16 14:54:09.621470: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.621481: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-01-16 14:54:09.621489: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.621497: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-01-16 14:54:09.621505: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.621513: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-01-16 14:54:09.621520: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.621527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-01-16 14:54:09.621535: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.621542: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-01-16 14:54:09.621553: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622587: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-01-16 14:54:09.622602: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622657: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-01-16 14:54:09.622667: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622707: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-01-16 14:54:09.622716: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622737: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-01-16 14:54:09.622744: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622759: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-01-16 14:54:09.622776: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622782: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622788: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622793: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622798: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622804: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622809: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622814: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622819: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622824: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-01-16 14:54:09.622833: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-01-16 14:54:09.622843: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-01-16 14:54:09.622852: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-01-16 14:54:09.622861: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-01-16 14:54:09.622871: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-01-16 14:54:09.641969: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 655 operators, 1254 arrays (0 quantized)
2020-01-16 14:54:09.652164: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 655 operators, 1254 arrays (0 quantized)
2020-01-16 14:54:09.701043: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 236 operators, 568 arrays (0 quantized)
2020-01-16 14:54:09.704528: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 233 operators, 562 arrays (0 quantized)
2020-01-16 14:54:09.707893: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 233 operators, 562 arrays (0 quantized)
2020-01-16 14:54:09.711235: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 233 operators, 562 arrays (0 quantized)
2020-01-16 14:54:09.713664: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 233 operators, 562 arrays (0 quantized)
2020-01-16 14:54:09.715367: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 233 operators, 562 arrays (0 quantized)
2020-01-16 14:54:09.726982: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 18249152 bytes, theoretical optimal value: 11829248 bytes.
2020-01-16 14:54:09.727774: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 8641389
2020-01-16 14:54:09.729089: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, DIV, EXP, EXPAND_DIMS, FULLY_CONNECTED, GREATER_EQUAL, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, REDUCE_MAX, REDUCE_MIN, RELU, RESHAPE, RESIZE_BILINEAR, STRIDED_SLICE, SUB, SUM, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File "/home/chengxu/anaconda3/envs/tf-nightly/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/home/chengxu/anaconda3/envs/tf-nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, DIV, EXP, EXPAND_DIMS, FULLY_CONNECTED, GREATER_EQUAL, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, REDUCE_MAX, REDUCE_MIN, RELU, RESHAPE, RESIZE_BILINEAR, STRIDED_SLICE, SUB, SUM, TANH, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.

Process finished with exit code 1

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='xuchengggg' date='2020-01-16T19:21:50Z'>
		Your model contains control flow and therefore is not supported in our old converter.
Regarding the new converter (i.e. when experimental_new_converter = True), it is not obvious where your error is coming from. Can you provide a reproducible example with functions like resnet_graph defined. Alternatively, can you provide the model file so we can reproduce your conversion on our end.
Reassigning to &lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 who has more familiarity with the new converter errors.
		</comment>
		<comment id='2' author='xuchengggg' date='2020-01-17T06:05:16Z'>
		Hi, the wights are too big, so I just post the minimal code which can produce same problem. [
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4075261/model.zip&gt;model.zip&lt;/denchmark-link&gt;

](url)
In the old tensorflow version like tf1.12, tf1.14, NonMaxSuppressionV3 is not supported when convert  the model to tflite, but in tf-nightly, there is no error about NonMaxSuppression, is it supported now?
For the latest tensorflow, is it supported to convert object detection model rather than SSD to tflite?
		</comment>
		<comment id='3' author='xuchengggg' date='2020-01-18T02:36:35Z'>
		Can you please share the TF graph def or at least instructions on running the scripts you shared
Thanks
		</comment>
		<comment id='4' author='xuchengggg' date='2020-01-18T02:44:55Z'>
		Just need tf-nightly, python 3.7, and run model.py, it would print the same error as I mentioned.
		</comment>
		<comment id='5' author='xuchengggg' date='2020-01-22T05:28:30Z'>
		Having a similar issue with the new converter erroring out. python/keras/engine/network.py seems to be the common element. Using nightly-tf from today and new converter.
2020-01-21 17:20:47.380130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4119 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1)
loc(callsite("mask_rcnn/mrcnn_detection/map/TensorArrayV2_1"("/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py":425:0) at callsite("/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py":574:0 at callsite("/home/testuser/projects/cleancahome/CamAi/CamAi/mrcnn_model.py":786:0 at callsite("/home/testuser/projects/cleancahome/CamAi/CamAi/mrcnn_model.py":850:0 at callsite("/home/testuser/projects/cleancahome/CamAi/CamAi/mrcnn_utils.py":845:0 at callsite("/home/testuser/projects/cleancahome/CamAi/CamAi/mrcnn_model.py":851:0 at callsite("/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py":308:0 at callsite("/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py":779:0 at callsite("/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py":918:0 at "/home/testuser/projects/cleancahome/venv37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py":744:0)))))))))): error: operand type 'tensor' is not compatible with preceding operands; expected rank: 1
Traceback (most recent call last):
		</comment>
		<comment id='6' author='xuchengggg' date='2020-01-27T19:26:45Z'>
		&lt;denchmark-link:https://github.com/haozha111&gt;@haozha111&lt;/denchmark-link&gt;
 Can you please have a look, specifically on TensorList issues.
Thanks
		</comment>
		<comment id='7' author='xuchengggg' date='2020-01-28T01:08:05Z'>
		Sure. I will need to take some time to repro the problem. This might not relate to tensorlist though.
(note that you can't get rid of converter.experimental_new_converter = True), since your graph contains control flows which can only be handled by the new converter.
		</comment>
		<comment id='8' author='xuchengggg' date='2020-01-30T02:31:41Z'>
		Hmm,
The failure from the converter is because of concat op failing verification
According to the tensorflow op
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/concat&gt;https://www.tensorflow.org/api_docs/python/tf/concat&lt;/denchmark-link&gt;

"The number of dimensions of the input tensors must match, and all dimensions except axis must be equal."
But the Concat has inputs
(tensor, tensor&lt;1xi32&gt;, tensor)
Can you please confirm that you are expecting concat to receive these shapes ?
Thanks
		</comment>
		<comment id='9' author='xuchengggg' date='2020-01-30T03:14:55Z'>
		Do you mean error is in line 517 detections = tf.concat(..)? It is not necessary, so if i remove those lines, it will be successful?
		</comment>
		<comment id='10' author='xuchengggg' date='2020-02-05T02:49:14Z'>
		The error is
"error: operand type 'tensor' is not compatible with preceding operands; expected rank: 1
for dt in dtype_flat]"
If you looked at the stack trace presented in failure
... map_fn.py:242:9: note: called from for dt in dtype_flat]
... yolact_test.py:602:32: note: called from dtype=tf.float32)
...yolact_test.py:676:46: note: called from
lambda x, y, w, m, p: refine_detections_graph_3(x, y, w, m, p, self.config),
...yolact_test.py:88:9: note: called from
output_slice = graph_fn(*inputs_slice)
...yolact_test.py:677:46: note: called from
self.config.IMAGES_PER_GPU)
You need to fix your model as this is requirement of concat op, not specific to the converter.
		</comment>
		<comment id='11' author='xuchengggg' date='2020-02-05T02:50:23Z'>
		If you still having problems after fixing the model, please reopen the issue and we will be happy to help.
Thanks for the feedback
		</comment>
		<comment id='12' author='xuchengggg' date='2020-02-05T02:50:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35927&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35927&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='xuchengggg' date='2020-02-26T05:21:48Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Hi, thank you for your answer. There is a problem, if the error is just in concat op, it should print error after model.build rather than converter. And this code works fine in prediction. So i wonder if there are any differences of concat op between tensorflow and tensorflow Lite?
		</comment>
		<comment id='14' author='xuchengggg' date='2020-02-27T17:26:12Z'>
		I was checking some other issue and i think it might be related. Reopening and checking.
		</comment>
		<comment id='15' author='xuchengggg' date='2020-02-28T02:22:57Z'>
		Hey, I found that if i use map_fn in subclass of keras.layers.Layer which would print same error as above. As shown in code
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
import numpy as np

physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) &gt; 0, "Not enough GPU handware devices available"
tf.config.experimental.set_memory_growth(physical_devices[0], True)

def batch_slice(inputs, graph_fn, batch_size, names=None):
    if not isinstance(inputs, list):
        inputs = [inputs]

    outputs = []
    for i in range(batch_size):
        inputs_slice = [x[i] for x in inputs]
        output_slice = graph_fn(*inputs_slice)
        if not isinstance(output_slice, (tuple, list)):
            output_slice = [output_slice]
        outputs.append(output_slice)

    outputs = list(zip(*outputs))

    if names is None:
        names = [None] * len(outputs)

    result = [tf.stack(o, axis=0, name=n)
              for o, n in zip(outputs, names)]
    if len(result) == 1:
        result = result[0]

    return result

def refine_detections_graph(conf_data):
    def test(class_id):
        return conf_data
    class_id = tf.range(10)
    r = tf.map_fn(test, class_id, dtype=tf.float32)
    return r

class DetectionLayer(keras.layers.Layer):
    def __init__(self):
        super(DetectionLayer, self).__init__()

    def call(self, inputs):
        conf_data = inputs[0]

        r = batch_slice([conf_data],
                        lambda x: refine_detections_graph(x),1)
        return r

input_image = keras.layers.Input([300,300,3])
x = keras.layers.Conv2D(64, (3,3), strides=2, padding='same')(input_image)
x = keras.layers.Conv2D(128, (3,3), strides=2, padding='same')(x)
x = keras.layers.Conv2D(256, (3,3), strides=2, padding='same')(x)
pred_score = keras.layers.Conv2D(10, (3,3), strides=2, padding='same', activation='softmax')(x)
pred_score = keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 10]))(pred_score)

result = DetectionLayer()([pred_score])

model = keras.models.Model(inputs = input_image, outputs = result)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                                        tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

&lt;/denchmark-code&gt;

However, if I just use function rather than use subclass of keras.layers.Layer, it can be converted successfully.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
import numpy as np

physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) &gt; 0, "Not enough GPU handware devices available"
tf.config.experimental.set_memory_growth(physical_devices[0], True)

def batch_slice(inputs, graph_fn, batch_size, names=None):
    if not isinstance(inputs, list):
        inputs = [inputs]

    outputs = []
    for i in range(batch_size):
        inputs_slice = [x[i] for x in inputs]
        output_slice = graph_fn(*inputs_slice)
        if not isinstance(output_slice, (tuple, list)):
            output_slice = [output_slice]
        outputs.append(output_slice)
    outputs = list(zip(*outputs))

    if names is None:
        names = [None] * len(outputs)

    result = [tf.stack(o, axis=0, name=n)
              for o, n in zip(outputs, names)]
    if len(result) == 1:
        result = result[0]

    return result

def refine_detections_graph(conf_data):
    def test(class_id):
        return conf_data
    class_id = tf.range(10)
    r = tf.map_fn(test, class_id, dtype=tf.float32)
    return r

class DetectionLayer(keras.layers.Layer):
    def __init__(self):
        super(DetectionLayer, self).__init__()

    def call(self, inputs):
        conf_data = inputs[0]

        r = batch_slice([conf_data],
                        lambda x: refine_detections_graph(x),1)
        return r

input_image = keras.layers.Input([300,300,3])
x = keras.layers.Conv2D(64, (3,3), strides=2, padding='same')(input_image)
x = keras.layers.Conv2D(128, (3,3), strides=2, padding='same')(x)
x = keras.layers.Conv2D(256, (3,3), strides=2, padding='same')(x)

pred_score = keras.layers.Conv2D(10, (3,3), strides=2, padding='same', activation='softmax')(x)
pred_score = keras.layers.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 10]))(pred_score)

result = batch_slice([pred_score], lambda x: refine_detections_graph(x), 1)

model = keras.models.Model(inputs = input_image, outputs = result)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

And one more question, in old version of keras, output tensors to a Model must be the output of a TensorFlow 'Layer' while in new version, there seems to be no such restriction?
		</comment>
		<comment id='16' author='xuchengggg' date='2020-03-02T19:03:29Z'>
		Hi,
When you pass pure python function to output, keras will create a layer per tensorflow op. Please see:



tensorflow/tensorflow/python/keras/engine/base_layer.py


         Line 2756
      in
      dd662a9






 class TensorFlowOpLayer(Layer): 





Essentially they shouldn't have semantic differences but the generated graph may have some differences.
		</comment>
		<comment id='17' author='xuchengggg' date='2020-03-02T19:07:00Z'>
		I will close this issue now since you already have a walk-around.
I also did an investigation about why your model can't convert before, it seems that this hits an unsupported case in TF lite converter:



tensorflow/tensorflow/compiler/mlir/lite/transforms/lower_static_tensor_list.cc


         Line 350
      in
      efc60f1






 // If the `element_shape` is a scalar, we know that it's dynamic shape 





TensorArrays in TF can be dynamic shaped, but in TF Lite we don't support this. I added a check here to return this error during the pass, rather than silently generating the wrong graph (the ill-formed concat op).
		</comment>
		<comment id='18' author='xuchengggg' date='2020-03-02T19:07:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35927&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35927&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>