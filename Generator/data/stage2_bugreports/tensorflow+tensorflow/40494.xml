<bug id='40494' author='adrian-dalessandro' open_date='2020-06-16T03:05:32Z' closed_time='2020-06-16T08:34:55Z'>
	<summary>tf-nightly build spits out thousands of lines about "whitelisting" during training</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2
Python version: 3.6.2
CUDA/cuDNN version: release 10.0, V10.0.130
GPU model and memory: TITAN X

Describe the current behavior
I am attempting to train a model using the tf-nightly build using the tf.data.Dataset api. It works (and continues to train) but prints out thousands (if not hundreds of thousands) of lines about "whitelisting" parameters.
Other info / logs
This is an example of what it's printing out:
I0615 19:58:57.821352 140192954160896 ag_logging.py:140] Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_t
o_update_var at 0x7f80b7957620&gt;: from cache
Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;: from cache
I0615 19:58:57.822939 140192954160896 ag_logging.py:140] Converted call: &lt;function OptimizerV2._distributed_apply..apply_gr
ad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_1_bn/gamma:0' shape=(256,) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v2/conv4_block
11_1_bn/FusedBatchNormGradV3:1' shape=(256,) dtype=float32&gt;)
kwargs: {}
Converted call: &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_1_bn/gamma:0' shape=(256,) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v2/conv4_block
11_1_bn/FusedBatchNormGradV3:1' shape=(256,) dtype=float32&gt;)
kwargs: {}
I0615 19:58:57.823056 140192954160896 ag_logging.py:140] Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_t
o_update_var at 0x7f80b7957620&gt;: from cache
Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;: from cache
I0615 19:58:57.824649 140192954160896 ag_logging.py:140] Converted call: &lt;function OptimizerV2._distributed_apply..apply_gr
ad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_1_bn/beta:0' shape=(256,) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v2/conv4_block1
1_1_bn/FusedBatchNormGradV3:2' shape=(256,) dtype=float32&gt;)
kwargs: {}
Converted call: &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_1_bn/beta:0' shape=(256,) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v2/conv4_block1
1_1_bn/FusedBatchNormGradV3:2' shape=(256,) dtype=float32&gt;)
kwargs: {}
I0615 19:58:57.824765 140192954160896 ag_logging.py:140] Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_t
o_update_var at 0x7f80b7957620&gt;: from cache
Whitelisted &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;: from cache
I0615 19:58:57.826352 140192954160896 ag_logging.py:140] Converted call: &lt;function OptimizerV2._distributed_apply..apply_gr
ad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_2_conv/kernel:0' shape=(3, 3, 256, 256) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v
2/conv4_block11_2_conv/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32&gt;)
kwargs: {}
Converted call: &lt;function OptimizerV2._distributed_apply..apply_grad_to_update_var at 0x7f80b7957620&gt;
args: (&lt;tf.Variable 'conv4_block11_2_conv/kernel:0' shape=(3, 3, 256, 256) dtype=float32&gt;, &lt;tf.Tensor 'gradient_tape/resnet152v
2/conv4_block11_2_conv/Conv2DBackpropFilter:0' shape=(3, 3, 256, 256) dtype=float32&gt;)
kwargs: {}
	</description>
	<comments>
		<comment id='1' author='adrian-dalessandro' date='2020-06-16T08:03:57Z'>
		&lt;denchmark-link:https://github.com/adrian-dalessandro&gt;@adrian-dalessandro&lt;/denchmark-link&gt;

Can you please share a simple stand alone code for us to replicate the issue faced or if possible share a colab gist for us to analyse the issue.
		</comment>
		<comment id='2' author='adrian-dalessandro' date='2020-06-16T08:34:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40494&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40494&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>