<bug id='41840' author='stefano555' open_date='2020-07-28T22:00:27Z' closed_time='2020-12-02T21:30:00Z'>
	<summary>Issue with a specific dataset with tf lite full integer quantisation uint8</summary>
	<description>
TensorFlow version: tf-nightly 2.4.0-dev20200728
Keras: 2.4.3
Python: 3.6.9
Issue: I trained DenseNet-169 with my dataset, validation accuracy 67.8%. My dataset (10k training images, 2k test images) is made in this way: each picture is 3 different pictures 200x200 pixels int8 piled up together. In the google colab file training_densenet169 is it possible to find a tool to visualise the images.
After training I convert the model with tf converter (see colab file tf_to_tf_lite converter) to tf lite full integer uint8 quantisation. The tf lite model is subsequently tested with the google colab file test_tf_lite_cpu. The test shows that the tf lite model doesn't work, it predicts always the same value.
I made the following tests.

I changed my dataset so to have only one channel (therefore not the three pictures pile up). I trainined it with accuracy 67.8%, converted to tf lite, and tested it. The test failed.
I then took the cifar10 dataset,  multiply by 7 the size in order to have 224x224 pixels images with 3 channels, and trained densenet169, conerted to tf lite, and tested. It worked.

My ideas:

cifar10 is similar to my dataset, and it works. Is it possible that maybe there is a bug so that my images size 200x200 don't work but cifar10 size 224x224 does?
If you can, have a look to my dataset. Is there anything specific that could trigger a failure mode in the converter? I couldn't see anything specific.

Additional information: All of the other tf lite quantisations work perfectly, only the full integer quantisation doesn't work.
Everything can be found in this google folder: &lt;denchmark-link:https://drive.google.com/drive/u/0/folders/11XruNeJzdIm9DTn7FnuIWYaSalqg2F0B&gt;https://drive.google.com/drive/u/0/folders/11XruNeJzdIm9DTn7FnuIWYaSalqg2F0B&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='stefano555' date='2020-07-28T22:06:18Z'>
		Dear &lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 this is for you. I am sorry but I cannot find how to assign you to this issue, could you do it?
		</comment>
		<comment id='2' author='stefano555' date='2020-08-06T02:29:41Z'>
		I looked into test_tf_lite_cpu.ipynb and it looks like what you're doing seems fine.
&lt;denchmark-code&gt;## Before we get started, for reference:

## 1. dynamic range optimization
converter.optimizations = [tf.lite.Optimize.DEFAULT]

## 2. integer quantization with float fallback
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen

## 3. integer quantization
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8  # or tf.uint8
converter.inference_output_type = tf.uint8  # or tf.uint8
&lt;/denchmark-code&gt;

Could try this the following in test_tf_lite_cpu.ipynb and get back to me with the results?

Create all 3 tflite models and run inference on them in the notebook on ~5 images. Have the code and outputs in notebook so I can review it. This will help us understand at which optimization it fails.
For 3. integer quantization - Is it possible to print an input image at different stages as given below?

input to the original model
input to the representative dataset function (while quantizing)
input to the interpreter (before manually quantizing)
We need to ensure that i, ii, iii have the exact same range of values.



		</comment>
		<comment id='3' author='stefano555' date='2020-08-06T08:51:35Z'>
		Hi &lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 I am currently on holiday but I'll get back to you as soon as possible. Please keep the issue open in the meantime.
		</comment>
		<comment id='4' author='stefano555' date='2020-09-04T10:58:49Z'>
		Dear &lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
, first of all, thanks for keeping the issue open, I appreciate that.
I am working on that right now but a new issue about my google drive has appeared so it is taking a little more time.
Could you please specify what you mean by "input to the representative dataset function (while quantizing)"?
		</comment>
		<comment id='5' author='stefano555' date='2020-09-05T22:03:30Z'>
		"input to the representative dataset function (while quantizing)" = when you specify the representative dataset function, you will define a small set of images that will be used to quantize the model during conversion. Print one of these inputs/images. The reason why we want to do this is because we need to verify that the images are preprocessed the same way as your training dataset.
Hope this helps. Let me know if you need more details.
		</comment>
		<comment id='6' author='stefano555' date='2020-09-08T19:41:38Z'>
		Hi,
I've done what you asked me. Let me guide you through the results.

you can find in the file tf_to_tflite_convert the code to create the 3 models (called DenseNet169_2020_07_27_dyn_range_debug, DenseNet169_2020_07_27_int_quant_float_debug, DenseNet169_2020_07_27_int_quant_uint_debug). You can find the tests on the code test_tf_lite_cpu.

These are the results calculated over 100 pics (tf model accuracy is 68.6% calculated over 2000 pics):
dynamic range: time/inference 8.4 seconds, accuracy 35%
float fallback: time/inference 9.3 seconds, accuracy 41%
integer: time/inference 9.3 seconds, accuracy 60%
These results are in contrast with what I found on the 16th of June, where my results were (with the same model and calculated over 2000 pics)
dynamic range: time/inference 297 ms, accuracy 63.65%
float fallback: time/inference 81.92 seconds, accuracy 68.6%
integer: time/inference 9.3 seconds, it predicted always the same value.
So it looks like dynamic range and float fallback have worsened their performance, being slower and way less accurate than before (but why?). On the other hand, full integer finally it looks like it is doing something sensible.

You can find a visualisation of i and iii at the end of test_tf_lite_cpu and of ii in tf_to_tflite_converter.

p.s. you asked to print ~ 5 pics but you'll see the output of the inference is calculated over 100 pics. if you need to test it and you want less pictures, just play with the parameter number_pics.
		</comment>
		<comment id='7' author='stefano555' date='2020-10-25T11:30:31Z'>
		Dear &lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 , I would like to ask you if you happen to have any news.
		</comment>
		<comment id='8' author='stefano555' date='2020-12-02T21:30:00Z'>
		It looks like you have forgotten to set the input tensors when running inference for dynamic range and float fallback!
Reference: &lt;denchmark-link:https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/&gt;https://thinkmobile.dev/testing-tensorflow-lite-image-classification-model/&lt;/denchmark-link&gt;

Specifically these parts:

TFLite Inference Resize
TFLite Inference set tensors and run inference

Your code:
&lt;denchmark-code&gt;#inference
t1_dynamic = time.time()
interpreter_dynamic.invoke()
t2_dynamic = time.time()
&lt;/denchmark-code&gt;

Expected code:
&lt;denchmark-code&gt;#inference
interpreter_dynamic.set_tensor(input_details_dynamic[0]['index'], x_test_a_list)
t1_dynamic = time.time()
interpreter_dynamic.invoke()
t2_dynamic = time.time()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='stefano555' date='2020-12-02T21:30:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41840&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41840&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>