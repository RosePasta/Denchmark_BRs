<bug id='40919' author='FalsoMoralista' open_date='2020-06-29T16:43:07Z' closed_time='2020-07-10T15:14:57Z'>
	<summary>Cannot add tensor to the batch: number of elements does not match (while Iterating through dataset elements).</summary>
	<description>
System info:
Os: MacOs catalina (10.15.5 )
Tensorflow: 2.0.0 installed over anaconda navigator (1.9.12 python 3.7) enviroment
Code:
# Load dataset from TFRecord file:
dataset = tf.data.TFRecordDataset(filenames=data_dir)
parsed_dataset = dataset.map(parsing_fn).batch(32)
print(parsed_dataset)
for image,label in parsed_dataset.take(2):
    print(image, label)

Output:

&lt;denchmark-code&gt;&lt;BatchDataset shapes: ((None, None) (None,)), types: (tf.float32, tf.int64)&gt;

InvalidArgumentError: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [810000], [batch]: [243712] [Op:IteratorGetNextSync]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;Helper functions below&lt;/denchmark-h&gt;

( TFRecord writed using tensorflow 1.14.0 over google colaboratory)
&lt;denchmark-h:h2&gt;Parsing function:&lt;/denchmark-h&gt;

def parsing_fn(serialized):

    features = \
        {
            'image': tf.FixedLenFeature([], tf.string),
            'label': tf.FixedLenFeature([], tf.int64)
        }

    # Parse the serialized data so we get a dict with our data.
    parsed_example = tf.parse_single_example(serialized=serialized,
                                             features=features)

    # Get the image as raw bytes.
    image_raw = parsed_example['image']

    # Decode the raw bytes so it becomes a tensor with type.
    image = tf.decode_raw(image_raw, tf.uint8)
    
    # The type is now uint8 but we need it to be float.
    image = tf.cast(image, tf.float32)

    label = parsed_example['label']

    return image, label
&lt;denchmark-h:h2&gt;Code used to create the TFRecord files&lt;/denchmark-h&gt;

    with tf.python_io.TFRecordWriter(out_path) as writer:

          data = \
              {
                  'image': wrap_bytes(img_bytes),
                  'label': wrap_int64(label)
              }

          # Wrap the data as TensorFlow Features.
          feature = tf.train.Features(feature=data)

          # Wrap again as a TensorFlow Example.
          example = tf.train.Example(features=feature)

          # Serialize the data.
          serialized = example.SerializeToString()
            
          # Write the serialized data to the TFRecords file.
          writer.write(serialized)
def wrap_int64(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def wrap_bytes(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
	</description>
	<comments>
		<comment id='1' author='FalsoMoralista' date='2020-06-30T05:01:23Z'>
		&lt;denchmark-link:https://github.com/FalsoMoralista&gt;@FalsoMoralista&lt;/denchmark-link&gt;

Please confirm if the issue is resolved.
		</comment>
		<comment id='2' author='FalsoMoralista' date='2020-06-30T13:31:12Z'>
		I still can't use the batch operation.
		</comment>
		<comment id='3' author='FalsoMoralista' date='2020-07-04T08:51:45Z'>
		&lt;denchmark-link:https://github.com/FalsoMoralista&gt;@FalsoMoralista&lt;/denchmark-link&gt;
 Hi, I am encountering the same issue and would like to know if you have managed to fix it.
		</comment>
		<comment id='4' author='FalsoMoralista' date='2020-07-04T10:01:36Z'>
		
@FalsoMoralista Hi, I am encountering the same issue and would like to know if you have managed to fix it.

Not yet... maybe you could also post some code of yours too so we can try to come up to a solution
		</comment>
		<comment id='5' author='FalsoMoralista' date='2020-07-04T15:08:29Z'>
		&lt;denchmark-link:https://github.com/FalsoMoralista&gt;@FalsoMoralista&lt;/denchmark-link&gt;
 I put my code in this Colab &lt;denchmark-link:https://colab.research.google.com/drive/1G3CrPrQHrm08uhdTO1fJUh5OYuncWA1X#scrollTo=b6zZalRPvHrq&gt;notebook&lt;/denchmark-link&gt;
.
The error comes from the .batch(batch_size) part:
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = (train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE))
I iterate through the dataset in the plotting cell right after that:
for batch in train_dataset.take(1):
Interestingly enough, when I changed my batch_size to 1, it works (but well that batch_size comes with some another problems).
In your case, it's the number '32' within
parsed_dataset = dataset.map(parsing_fn).batch(32)
Worth to mention that I'm following Keras' OCR example &lt;denchmark-link:https://keras.io/examples/vision/captcha_ocr/&gt;here&lt;/denchmark-link&gt;
 and I ran their code just fine.
		</comment>
		<comment id='6' author='FalsoMoralista' date='2020-07-08T08:14:54Z'>
		&lt;denchmark-link:https://github.com/FalsoMoralista&gt;@FalsoMoralista&lt;/denchmark-link&gt;

Please update is this is still an issue.
		</comment>
		<comment id='7' author='FalsoMoralista' date='2020-07-09T14:37:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40919&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40919&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='FalsoMoralista' date='2020-07-10T15:14:57Z'>
		I guess that setting the a buffer size before batching may fix this issue.
train_dataset = train_dataset.shuffle(buffer_size=2500,reshuffle_each_iteration=True)
		</comment>
		<comment id='9' author='FalsoMoralista' date='2020-07-10T15:14:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40919&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40919&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='FalsoMoralista' date='2020-11-26T12:23:20Z'>
		
@FalsoMoralista I put my code in this Colab notebook.
The error comes from the .batch(batch_size) part:
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = (train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE))
I iterate through the dataset in the plotting cell right after that:
for batch in train_dataset.take(1):
Interestingly enough, when I changed my batch_size to 1, it works (but well that batch_size comes with some another problems).
In your case, it's the number '32' within
parsed_dataset = dataset.map(parsing_fn).batch(32)
Worth to mention that I'm following Keras' OCR example here and I ran their code just fine.

Worked for me, Thanks a lot üëç
		</comment>
	</comments>
</bug>