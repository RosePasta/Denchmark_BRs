<bug id='29863' author='zendevil' open_date='2019-06-17T07:00:06Z' closed_time='2019-08-02T19:29:00Z'>
	<summary>Error when using unique_with_counts function.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
On Windows Subsystem for Linux. Python 3.6.7. Tensorflow 1.13.1.
Code:
&lt;denchmark-code&gt;X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)
print(X_train.shape)
print(X_test.shape)
x = tf.placeholder(float, shape=X_train.shape)
y = tf.placeholder(float, shape=X_test.shape[1:])
computeL0Dist = tf.count_nonzero(x - y, axis=[1])
find_k_closest_tr_products = tf.contrib.framework.argsort(computeL0Dist, direction='ASCENDING')
find_labels_k_closest_tr_products = tf.gather(y_train, find_k_closest_tr_products[0:paramk])
print('SHAPE', find_labels_k_closest_tr_products.shape)
find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
find_predicted_label = tf.gather(find_u_labels, tf.argmax(find_counts))
&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;(49, 1611)
(49, 1611)

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

2019-06-17 11:51:40.240971: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-17 11:51:40.248082: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800000000 Hz
2019-06-17 11:51:40.250639: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x377c490 executing computations on platform Host. Devices:
2019-06-17 11:51:40.252480: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
Traceback (most recent call last):
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1334, in _do_call
    return fn(*args)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1317, in _run_fn
    self._extend_graph()
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1352, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'UniqueWithCounts' used by {{node UniqueWithCounts}}with these attrs: [T=DT_BOOL, out_idx=DT_INT32]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[{{node UniqueWithCounts}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "knn.py", line 101, in &lt;module&gt;
    predicted_label = sess.run([find_predicted_label], feed_dict={x:X_train, y:X_test[i_te_p]})
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 929, in run
    run_metadata_ptr)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1328, in _do_run
    run_metadata)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'UniqueWithCounts' used by node UniqueWithCounts (defined at knn.py:91) with these attrs: [T=DT_BOOL, out_idx=DT_INT32]
Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[node UniqueWithCounts (defined at knn.py:91) ]]

Caused by op 'UniqueWithCounts', defined at:
  File "knn.py", line 91, in &lt;module&gt;
    find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py", line 1450, in unique_with_counts
    return gen_array_ops.unique_with_counts(x, out_idx, name)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py", line 10543, in unique_with_counts
    "UniqueWithCounts", x=x, out_idx=out_idx, name=name)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3300, in create_op
    op_def=op_def)
  File "/home/psharma/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'UniqueWithCounts' used by node UniqueWithCounts (defined at knn.py:91) with these attrs: [T=DT_BOOL, out_idx=DT_INT32]Registered devices: [CPU, XLA_CPU]
Registered kernels:
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_STRING]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_HALF]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT32]; out_idx in [DT_INT32]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT64]
  device='CPU'; T in [DT_INT64]; out_idx in [DT_INT32]

         [[node UniqueWithCounts (defined at knn.py:91) ]]
&lt;/denchmark-code&gt;

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Describe the expected behavior
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='zendevil' date='2019-06-18T08:59:11Z'>
		&lt;denchmark-link:https://github.com/zendevil&gt;@zendevil&lt;/denchmark-link&gt;
 Looks like above code snippet is incomplete to reproduce the issue. Please provide the full code snippet to reproduce. Thanks!
		</comment>
		<comment id='2' author='zendevil' date='2019-06-18T13:15:15Z'>
		There are some variables that are defined in a file called google_res which I import. You probably can recreate error without that file. Good luck debugging this.
&lt;denchmark-code&gt;from sklearn.model_selection import train_test_split
import time

import numpy as np

import requests
from requests.auth import HTTPBasicAuth

from google_res import *

from imblearn.over_sampling import SMOTE



def knn(X_train, y_train, X_test, y_test):
    paramk = 11
    x = tf.placeholder(float, shape=X_train.shape)
    y = tf.placeholder(float, shape=X_test.shape[1:])
    computeL0Dist = tf.count_nonzero(x - y, axis=[1])
    find_k_closest_tr_products = tf.contrib.framework.argsort(computeL0Dist, direction='ASCENDING')
    find_labels_k_closest_tr_products = tf.gather(y_train, find_k_closest_tr_products[0:paramk])
    print('SHAPE', find_labels_k_closest_tr_products.shape)
    find_u_labels, find_idex, find_counts = tf.unique_with_counts(find_labels_k_closest_tr_products)
    find_predicted_label = tf.gather(find_u_labels, tf.argmax(find_counts))
    
    # running through the graph
    num_errs = 0
    num_test_products = y_test.shape[0]
    num_train_products = y_train.shape[0]
    
    with tf.Session() as sess:
        for i_te_p in range(0, num_test_products):
            predicted_label = sess.run([find_predicted_label], feed_dict={x:X_train, y:X_test[i_te_p]})
            if predicted_label == y_train[i_te_p]:
                num_errs += 1
                print(num_errs, "/", i_te_p)
                print("\t\t",predicted_label[0], "\t\t\t\t",t_labels[i_te_p])

                if (1):
                    plt.figure(1)
                    plt.subplot(1, 2, 1)
                    plt.imshow(y_test[i_te_p])
                    plt.title('test image has label %i' %(predicted_label[0]))

                    for i in range(num_train_products):
                        if y_train[i] == predicted_label:
                            plt.subplot(1, 2, 2)
                            plt.imshow(x_train[i])
                            plt.title('Correctly labeled as %i' % y_test[i_te_p])
                            plt.draw()
                            break
                    plt.savefig('./results.png')

start_time = time.time()
click_data = np.load('click_data.npy').tolist()
#search_terms_main = list(dict.fromkeys(search_terms_main))

search_terms = [i.split(' ') for i in search_terms_main]
# print(search_terms)
skipgram = []

# using dynamic programming 
def generate_skipgrams(li, length):
    skipgrams = []
    skipgrams.append([]) # we'll keep the zero length empty
    skipgrams.append([])
    for i in li:
        wrapper = []
        wrapper.append(i)
        skipgrams[1].append(wrapper)
    for i in range(1, length):
        skipgrams.append([])
        for j in range(len(skipgrams[i])):
            for k in range(len(li)):
                if not skipgrams[i][j][-1] == li[k]:
                    wrapper = []
                    wrapper.append(li[k])
                    to_append = skipgrams[i][j] + wrapper
                    
                    skipgrams[i + 1].append('%27' +'%20'.join(to_append) + '%27')
                    #skipgrams[i + 1].append(to_append)
    return (skipgrams[length])


skipgrams = []
for j in range(len(search_terms_main)):
    skipgrams.append(generate_skipgrams(search_terms_main[j].split(' '), 2))

num_features = 0 # for computing padding
for i in range(len(skipgrams)):
    if len(skipgrams[i]) &gt; num_features:
        #print(len(skipgrams[i]))
        num_features = len(skipgrams[i])


#print(skipgrams)
#print(num_features)


def pad(skipgrams, max_pad_len):
    padded_skipgrams = []
    for i in range(len(skipgrams)):
        pad_len = max_pad_len - len(skipgrams[i])
        wrapper = []
        for j in range(pad_len):
            wrapper.append('%27%27')
        padded_skipgrams.append(skipgrams[i] + wrapper)

    return padded_skipgrams

skipgrams = pad(skipgrams, num_features)
#print(skipgrams)

# for i in range(len(skipgrams)):
#     print(len(skipgrams[i]))
# Dhiran's code. Expect Errors

first_phrase = [i.replace(' ','%20') for i in search_terms_main]
all_features = [] # stores all the features from feature_clean from various requests


def get_ngrams(l, n):
    ngrams = []
    for i in range(len(l) - n + 1):
        ngrams.append([])
        for j in range(n):
            ngrams[i].append(l[i+j])
    return ngrams


maximum = 0
# query = ''

for i in range(len(search_terms_main)):
    if len(search_terms_main[i].split(' ')) &gt; maximum:
        maximum  = len(search_terms_main[i].split(' '))
        # query = search_terms_main[i]
ngrams = [] # ngrams for each search term

for c, st in enumerate(search_terms_main):
    ngrams.append([]) # this will contain all ngrams for the search term st.
    st_arr = st.split(' ')
    for n in range(1, len(st_arr) + 1):
        ngrams[c].append(get_ngrams(st_arr, n))
    

padding = []
for i in range(maximum):
    padding.append(0)
#print(len(padding))
#print(len(ngrams))

# adding first level padding
for i in range(len(ngrams)):
    for j in range(len(ngrams[i]), maximum):
            ngrams[i].append([])

for i in range(len(ngrams)):
    for j in range(maximum):
        for k in range(maximum - len(ngrams[i][j]) - j):
            padding_unit = []
            # for l in range(j + 1):
            #     padding_unit.append('')
            ngrams[i][j].append(padding_unit)

#first_phrase = first_phrase[154:]
#print(ngrams)
print('first phrase', len(first_phrase))

def get_prod_list(query):
    product_list = []
    for i in range(len(click_data)):   
        if click_data[i][0] == query:
            product_list.append(int(click_data[i][1]))
    return product_list


def clean_list(li):
    return list(map(lambda x: x.split('=')[1], li))

features_x = {}
features_y = {}
total_conf = [[0,0],[0,0]]


first_phrase = list(dict.fromkeys(first_phrase))

for j, elem in enumerate(first_phrase):
    print('so come here', j)
    #print(elem)
    url = '''http://xx.xxx.xx.xx:xxxx/solr/SomeName/select?defType=edismax&amp;fl=[features%20efi.text_0=%27'''+first_phrase[j] + '%27'

    feature_count = 1
    # if j == 2:
    #     break
    # for i in range(len(search_terms[j])):
    #     print('search_terms', search_terms[j][i])
    #     url += '%20efi.text_' + str(feature_count) + '=' + search_terms[j][i]
    #     feature_count += 1

    # add all the ngram terms
    for k in range(len(ngrams[j])): # this goes from 1 gram to 13 grams 
        for l in range(maximum - k): # from one grams to 13grams
            to_add = ngrams[j][k][l] 
            url_compat = '%27' + '%20'.join(to_add) + '%27'
            url+= '%20efi.text_'+ str(feature_count) + '=' + url_compat
            feature_count += 1

    # all skipgrams
    for i in range(len(skipgrams[j])):
        url += '%20efi.text_' + str(feature_count) + '=' + skipgrams[j][i]
        feature_count += 1
    
    print('FEATURE COUNT', feature_count)
    # The last part 
    url += '''],%20score,%20tm_name,%20ts_title,%20tm_field_category_parent_name,%20ts_field_product_brand_1,%20id&amp;indent=on&amp;q='''+first_phrase[j]+'''&amp;qf=ts_field_summary+ts_field_product_specifications+tm_name+ts_title+tm_field_category_parent_name+ts_field_product_brand_1+ts_field_product_details&amp;wt=json'''
    val = requests.get(url, verify=False, auth=HTTPBasicAuth('user', 'S0MEPass\/\/0rd'))
    
    #ids = []
    #category = []
    #title = []
    features = {}
    
    if (val.json() == None):
        print('SKIPPING')
        continue
    print(elem)
    #print(val.json())
    for c, i in enumerate(val.json()['response']['docs']):
        print(i['id'][-7:-3])
        features[int(i['id'][-7:-3])] = i['[features]'].split(',')
   
    features = {k: list(map(lambda x: float(x.split('=')[1]), v)) for k, v in features.items()}    
    #print(features)
    # two extra to store query and id 
    features_x[elem] = []
    features_y[elem] = []
    for k, v in features.items():
        features_x[elem].append(v)
        products = get_prod_list(elem.replace('%20', ' '))
        
        if k in products:
            features_y[elem].append(True)
        else:
            features_y[elem].append(False)
    #print('FEATURES X', features_x[elem])
    #print('FEATURES Y', features_y[elem])
    features_x[elem] = np.asarray(features_x[elem], dtype=float)
    if (False in features_y[elem] and list(features_y[elem]).count(True) &gt; 1):
        os = SMOTE(random_state=0, k_neighbors = 1)
        features_x[elem], features_y[elem] = os.fit_sample(features_x[elem], features_y[elem])    
        X_train, X_test, y_train, y_test = train_test_split(features_x[elem], features_y[elem], test_size=0.3, random_state=0)
        knn(X_train, X_test, y_train, y_test)
        total_conf += confusion


print(total_conf)
print((time.time()-start_time))



print(conf_all)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='zendevil' date='2019-06-19T04:52:01Z'>
		&lt;denchmark-link:https://github.com/zendevil&gt;@zendevil&lt;/denchmark-link&gt;
 I am unable to reproduce the issue with above code snippet. Looks some entities are not defined like search_terms_main. Can you help us to reproduce the issue. Thanks!
		</comment>
		<comment id='4' author='zendevil' date='2019-06-20T01:23:18Z'>
		I think the issue is that bool support is not available for unique_with_counts. Added a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/29986&gt;#29986&lt;/denchmark-link&gt;
 for the fix.
		</comment>
		<comment id='5' author='zendevil' date='2019-08-02T19:29:01Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29863&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29863&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>