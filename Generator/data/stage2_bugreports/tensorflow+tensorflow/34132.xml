<bug id='34132' author='FancyVin' open_date='2019-11-10T06:53:05Z' closed_time='2019-11-19T05:58:18Z'>
	<summary>BatchNorm doesn't work in custom Model or Layer.</summary>
	<description>
System information
-Windows10

TensorFlow: 2.0.0
Python version: 3.7

Describe the current behavior
InaccessibleTensorError: The tensor 'Tensor("batch_normalization/batch_normalization_trainable:0", dtype=bool)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=3078774714504); accessed from: FuncGraph(name=keras_graph, id=3077450685512).
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU

def get_norm(norm_type):
    if norm_type == "batch":
        return BatchNormalization()
    else:
        raise ValueError(f"Unrecognized norm_type {norm_type}")

class Discriminator(Model):
    def __init__(self,
                 base_filters=32,
                 lrelu_alpha=0.2,
                 pad_type="same",
                 norm_type="batch"):
        super(Discriminator, self).__init__(name="Discriminator")
        # 1------------------------------------------
        self.conv1 = Conv2D(
                filters=base_filters, # 32
                kernel_size=3,     
                padding=pad_type
                )
        self.relu1 = LeakyReLU(alpha=lrelu_alpha)
        
        # 2-------------------------------------------
        self.conv2a = Conv2D(
                filters=base_filters*2, # 64
                strides=2,
                kernel_size=3, 
                padding=pad_type
                )
        self.relu2a = LeakyReLU(alpha=lrelu_alpha)
        self.conv2b = Conv2D(
                filters=base_filters*4, # 128
                kernel_size=3, 
                padding=pad_type
                )
        self.norm2 = get_norm(norm_type)
        self.relu2b = LeakyReLU(alpha=lrelu_alpha)
        
        # 3-----------------------------------------------
        self.conv3a = Conv2D(
                filters=base_filters*4, # 128
                strides=2,
                kernel_size=3, 
                padding=pad_type
                )
        self.relu3a = LeakyReLU(alpha=lrelu_alpha)
        self.conv3b = Conv2D(
                filters=base_filters*8, # 256
                kernel_size=3, 
                padding=pad_type
                )
        self.norm3 = get_norm(norm_type)
        self.relu3b = LeakyReLU(alpha=lrelu_alpha)
        
        # 4----------------------------------------------
        self.conv4 = Conv2D(
                filters=base_filters*8, # 256
                kernel_size=3, 
                padding=pad_type
                )
        self.norm4 = get_norm(norm_type)
        self.relu4 = LeakyReLU(alpha=lrelu_alpha)
        
        # final--------------------------------------------
        self.conv_final = Conv2D(
                filters=1, # 256
                kernel_size=3, 
                padding=pad_type
                )

    def build(self, input_shape):
        super(Discriminator, self).build(input_shape)

    def call(self, input_tensor, training=False):
        # 1---------------------------------------------------
        x = self.conv1(input_tensor, training=training)
        x = self.relu1(x, training=training)
        
        # 2--------------------------------------------------
        x = self.conv2a(x, training=training)
        x = self.relu2a(x, training=training)
        x = self.conv2b(x, training=training)
        x = self.norm2(x, training=training)
        x = self.relu2b(x, training=training)
        
        # 3------------------------------------------------
        x = self.conv3a(x, training=training)
        x = self.relu3a(x, training=training)
        x = self.conv3b(x, training=training)
        x = self.norm3(x, training=training)
        x = self.relu3b(x, training=training)
        
        # 4-------------------------------------------------
        x = self.conv4(x, training=training)
        x = self.norm4(x, training=training)
        x = self.relu4(x, training=training)
        
        # final--------------------------------------------
        x = self.conv_final(x, training=training)
        
        return x

if __name__ == "__main__":
    import numpy as np

    shape = (1, 128, 128, 3)
    nx = np.random.rand(*shape).astype(np.float32)
    t = tf.keras.Input(shape=nx.shape[1:], batch_size=nx.shape[0])

    #tf.keras.backend.clear_session()
    d = Discriminator()
    out = d(t)
    d.summary()
    print(f"Input  Shape: {t.shape}")
    print(f"Output Shape: {out.shape}")
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='FancyVin' date='2019-11-11T10:03:37Z'>
		&lt;denchmark-link:https://github.com/FancyVin&gt;@FancyVin&lt;/denchmark-link&gt;
,
When trying to reproduce your error, an intermediate error, shown below has occurred,  . Can you please help us reproduce the error. Thanks!
		</comment>
		<comment id='2' author='FancyVin' date='2019-11-11T17:41:27Z'>
		Related / Duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32477&gt;32477&lt;/denchmark-link&gt;
 I guess.
		</comment>
		<comment id='3' author='FancyVin' date='2019-11-15T10:07:33Z'>
		&lt;denchmark-link:https://github.com/FancyVin&gt;@FancyVin&lt;/denchmark-link&gt;
,
As &lt;denchmark-link:https://github.com/cecabert&gt;@cecabert&lt;/denchmark-link&gt;
 mentioned, it is a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32477&gt;32477&lt;/denchmark-link&gt;
. Please confirm if we can close this issue as it's being tracked there. Thanks!
		</comment>
		<comment id='4' author='FancyVin' date='2019-11-16T01:43:21Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;


@FancyVin,
When trying to reproduce your error, an intermediate error, shown below has occurred, ModuleNotFoundError: No module named 'keras_contrib'. Can you please help us reproduce the error. Thanks!

I updated the code, it should work now.
		</comment>
		<comment id='5' author='FancyVin' date='2019-11-19T05:58:18Z'>
		Closing the issue as it is the duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32477&gt;32477&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='FancyVin' date='2019-11-19T05:58:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34132&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34132&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>