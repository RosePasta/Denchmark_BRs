<bug id='35056' author='EtagiBI' open_date='2019-12-12T10:39:59Z' closed_time='2020-01-29T08:19:29Z'>
	<summary>ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.</summary>
	<description>
Hello,
I'm trying to implement a Unet segmentation model using Keras with Tensorflow backend. I created a Conda virual environement and installed Tensorflow 2.0.0 package via Conda package manager.
&lt;denchmark-link:https://user-images.githubusercontent.com/20855725/70704814-9542c380-1cf4-11ea-8b80-df3bb9d48d38.png&gt;&lt;/denchmark-link&gt;

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
TensorFlow installed from (source or binary): source, I guess
TensorFlow version (use command below): 2.0.0
Python version: 3.6.9
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: 10.1 / 7.6.5.32
GPU model and memory: 1080Ti / 16 Gb

Describe the current behavior
Learning process crashes with a following error:
ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.
Describe the expected behavior
Learning process goes fine =).
Code to reproduce the issue
Here's a complete code:
&lt;denchmark-code&gt;import numpy as np
import os
import cv2
from tensorflow.python.keras.models import Model
from tensorflow.python.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from tensorflow.python.keras.layers.core import Lambda, RepeatVector, Reshape
from tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose
from tensorflow.python.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from tensorflow.python.keras.layers.merge import concatenate, add
from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.python.keras.optimizers import Adam
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

def data_gen(templates_folder, masks_folder, im_width, batch_size):
    c = 0
    n = os.listdir(templates_folder)  # List of training images
    m = os.listdir(masks_folder)
    # random.shuffle(n)

    while (True):
        img = np.zeros((batch_size, im_width, im_width, 1)).astype('float')
        mask = np.zeros((batch_size, im_width, im_width, 1)).astype('float')

        for i in range(c, c + batch_size):  # initially from 0 to 16, c = 0.

            train_img = cv2.imread(templates_folder + '/' + n[i], cv2.IMREAD_GRAYSCALE) / 255.
            train_img = train_img.reshape(im_width, im_width, 1)

            img[i - c] = train_img  # add to array - img[0], img[1], and so on.
            train_mask = cv2.imread(masks_folder + '/' + m[i], cv2.IMREAD_GRAYSCALE) / 255.
            train_mask = train_mask.reshape(im_width, im_width, 1)  # Add extra dimension for parity with train_img size [512 * 512 * 3]

            mask[i - c] = train_mask

        c += batch_size
        if (c + batch_size &gt;= len(os.listdir(templates_folder))):
            c = 0
            # random.shuffle(n)
        yield img, mask

def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):
    # first layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same")(input_tensor)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    # second layer
    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer="he_normal", padding="same")(x)
    if batchnorm:
        x = BatchNormalization()(x)
    x = Activation("relu")(x)
    return x

def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):
    # contracting path
    c1 = conv2d_block(input_img, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)
    p1 = MaxPooling2D((2, 2))(c1)
    p1 = Dropout(dropout * 0.5)(p1)

    c2 = conv2d_block(p1, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)
    p2 = MaxPooling2D((2, 2))(c2)
    p2 = Dropout(dropout)(p2)

    c3 = conv2d_block(p2, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)
    p3 = MaxPooling2D((2, 2))(c3)
    p3 = Dropout(dropout)(p3)

    c4 = conv2d_block(p3, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
    p4 = Dropout(dropout)(p4)

    c5 = conv2d_block(p4, n_filters=n_filters * 16, kernel_size=3, batchnorm=batchnorm)

    # expansive path
    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    u6 = Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters=n_filters * 8, kernel_size=3, batchnorm=batchnorm)

    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    u7 = Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters=n_filters * 4, kernel_size=3, batchnorm=batchnorm)

    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    u8 = Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters=n_filters * 2, kernel_size=3, batchnorm=batchnorm)

    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    u9 = Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters=n_filters * 1, kernel_size=3, batchnorm=batchnorm)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
    model = Model(inputs=[input_img], outputs=[outputs])
    return model

callbacks = [
    EarlyStopping(patience=10, verbose=1),
    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),
    ModelCheckpoint("model-prototype.h5", verbose=1, save_best_only=True, save_weights_only=True)
]

im_width = 1536
im_height = 1536

input_img = Input((im_height, im_width, 1), name='img')
model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)

model.compile(optimizer=Adam(lr=0.001), loss="binary_crossentropy", metrics=["accuracy"])

train_templates_path = "E:/train/templates"
train_masks_path = "E:/train/masks"
valid_templates_path = "E:/valid/templates"
valid_masks_path = "E:/valid/masks"

train_generator = data_gen(train_templates_path, train_masks_path, im_width, batch_size = 4)
val_generator = data_gen(valid_templates_path, valid_masks_path, im_width, batch_size = 4)

results = model.fit_generator(train_generator, epochs=5, steps_per_epoch=10, validation_data=val_generator, validation_steps=1, callbacks=callbacks)
&lt;/denchmark-code&gt;

Other info / logs
Here's a complete error log:
&lt;denchmark-code&gt;2019-12-12 15:19:36.384413: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2019-12-12 15:19:36.386318: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 16. Tune using inter_op_parallelism_threads for best performance.
Epoch 1/5
Traceback (most recent call last):
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 527, in _apply_op_helper
    preferred_dtype=default_dtype)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\ops.py", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 286, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 227, in constant
    allow_broadcast=True)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 265, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\tensor_util.py", line 437, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 541, in _apply_op_helper
    values, as_ref=input_arg.is_ref).dtype.name
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\ops.py", line 1296, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 286, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 227, in constant
    allow_broadcast=True)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\constant_op.py", line 265, in _constant_impl
    allow_broadcast=allow_broadcast))
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\tensor_util.py", line 437, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:/Explorium/python/networks_learning.py", line 143, in &lt;module&gt;
    results = model.fit_generator(train_generator, epochs=5, steps_per_epoch=10, validation_data=val_generator, validation_steps=1, callbacks=callbacks)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 1297, in fit_generator
    steps_name='steps_per_epoch')
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\engine\training_generator.py", line 265, in model_iteration
    batch_outs = batch_function(*batch_data)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 1017, in train_on_batch
    self._make_train_function()
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 2116, in _make_train_function
    params=self._collected_trainable_weights, loss=self.total_loss)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\optimizers.py", line 476, in get_updates
    grads = self.get_gradients(loss, params)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\keras\optimizers.py", line 92, in get_gradients
    if None in grads:
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\ops\math_ops.py", line 1336, in tensor_equals
    return gen_math_ops.equal(self, other)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py", line 3626, in equal
    name=name)
  File "C:\Users\E-soft\Anaconda3\envs\Explorium\lib\site-packages\tensorflow_core\python\framework\op_def_library.py", line 545, in _apply_op_helper
    (input_name, err))
ValueError: Tried to convert 'y' to a tensor and failed. Error: None values not supported.
&lt;/denchmark-code&gt;

Note! Changing imports from
"from tensorflow.python.keras.models import Model"
to
"from tensorflow.keras.models import Model"
doesn't work. I get another error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "E:/Explorium/python/networks_learning.py", line 6, in &lt;module&gt;
    from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape
ModuleNotFoundError: No module named 'tensorflow.keras.layers.core'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='EtagiBI' date='2019-12-13T08:28:41Z'>
		&lt;denchmark-link:https://github.com/EtagiBI&gt;@EtagiBI&lt;/denchmark-link&gt;
, Could you provide the supporting files to replicate the reported issue. Thanks!
		</comment>
		<comment id='2' author='EtagiBI' date='2019-12-13T10:02:17Z'>
		
@EtagiBI, Could you provide the supporting files to replicate the reported issue. Thanks!

&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 Unfortunately, I'm not allowed to share the whole dataset (not to mention it's huge), but I can provide some extamples:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3960188/Dataset.zip&gt;Dataset.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='EtagiBI' date='2019-12-17T08:43:10Z'>
		I was able to reproduce the issue with Tf 2.0.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/45d85483511e7784bbf7e91d3ca65f2f/untitled312.ipynb#scrollTo=iYpBkcu82gGS&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='EtagiBI' date='2020-01-06T23:02:11Z'>
		&lt;denchmark-link:https://github.com/EtagiBI&gt;@EtagiBI&lt;/denchmark-link&gt;
 Please change all the imports as given below.
&lt;denchmark-code&gt;from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape
from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose
from tensorflow.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from tensorflow.keras.layers.merge import concatenate, add
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
&lt;/denchmark-code&gt;

which should help you in solving the issue.
For more information, take a look at this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32646#issuecomment-533250690&gt;comment&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='5' author='EtagiBI' date='2020-01-16T22:32:42Z'>
		&lt;denchmark-link:https://github.com/EtagiBI&gt;@EtagiBI&lt;/denchmark-link&gt;
 Did the above comment solve your issue. Can I close this issue?
		</comment>
		<comment id='6' author='EtagiBI' date='2020-01-20T13:54:09Z'>
		
@EtagiBI Please change all the imports as given below.
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape
from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose
from tensorflow.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from tensorflow.keras.layers.merge import concatenate, add
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

which should help you in solving the issue.
For more information, take a look at this comment. Thanks!

&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 thank you. Unfortunately, it doesn't work, because there's no subfolder named "keras" in "tensorflow-core" folder.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "E:/Explorium/python/networks_learning.py", line 7, in &lt;module&gt;
    from tensorflow.keras.layers.core import Lambda, RepeatVector, Reshape
ModuleNotFoundError: No module named 'tensorflow.keras.layers.core'
&lt;/denchmark-code&gt;

Here's my "tensorflow-core" folder:
&lt;denchmark-link:https://user-images.githubusercontent.com/20855725/72731422-8550b600-3bb5-11ea-9fc1-46f2f6b6943c.png&gt;&lt;/denchmark-link&gt;

As you can see, there's a "python" subfolder that contains following files and directories including "keras":
&lt;denchmark-link:https://user-images.githubusercontent.com/20855725/72731763-28a1cb00-3bb6-11ea-9827-0c4c47144a9e.png&gt;&lt;/denchmark-link&gt;

So, that's why I was using "tensorflow.python.keras" in my imports.
		</comment>
		<comment id='7' author='EtagiBI' date='2020-01-28T21:28:49Z'>
		I am sorry for the above comment but try following this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32646#issuecomment-554609113&gt;comment&lt;/denchmark-link&gt;
. just replace

in place of

I tried running this and my session is crashing due to high usage of RAM
		</comment>
		<comment id='8' author='EtagiBI' date='2020-01-29T08:19:29Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
, the following imports work indeed:
&lt;denchmark-code&gt;from tensorflow.python.keras.models import Model
from tensorflow.python.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout
from tensorflow.python.keras.layers.core import Lambda, RepeatVector, Reshape
from tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose
from tensorflow.python.keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D
from tensorflow.python.keras.layers.merge import concatenate, add
from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
&lt;/denchmark-code&gt;

And yes, I get a memory allocation error as well =(....
Anyway, thanks!
		</comment>
		<comment id='9' author='EtagiBI' date='2020-01-29T08:19:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35056&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35056&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>