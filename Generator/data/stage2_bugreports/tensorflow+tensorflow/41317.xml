<bug id='41317' author='digital-idiot' open_date='2020-07-12T09:53:30Z' closed_time='2020-07-14T12:40:59Z'>
	<summary>Undefined behavior in tf.multiply</summary>
	<description>
System information

OS Platform and Distribution: Linux 5.7.8-5, Manjaro KDE
TensorFlow installed from: conda-forge
TensorFlow version: 2.2.0
Python version: 3.8.3
GCC/Compiler version: 10.1.0
CUDA/cuDNN version: 10.2
GPU model and memory:  GeForce RTX 2070, 7982 MiB

Current behavior
In [1]: a = np.random.randint(0, 10, (2, 2))                                                                                                                                                                            

In [2]: w = np.array([2, 5])                                                                                                                                                                                            

In [3]: x = tf.convert_to_tensor(a)                                                                                                                                                                                     

In [4]: y = tf.convert_to_tensor(w)                                                                                                                                                                                     

In [5]: x                                                                                                                                                                                                               
Out[5]: 
&lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[8, 0],
       [5, 7]])&gt;

In [6]: y                                                                                                                                                                                                               
Out[6]: &lt;tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 5])&gt;

In [7]: x * y                                                                                                                                                                                                           
Out[7]: 
&lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[9, 6],
       [0, 0]])&gt;
In [8]: tf.multiply(x, y)                                                                                                                                                                                               
Out[8]: 
&lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[0, 6],
       [7, 3]])&gt;
Each time the multiplication operation is performed without any modification to x and y the results were different. I could not find any plausible explanation of this behavior.
Expected behavior
When I performed same multiplication in numpy it computed the expected result.
In [9]: a                                                                                                                                                                                                               
Out[9]: 
array([[8, 0],
       [5, 7]])

In [10]:  w                                                                                                                                                                                                              
Out[10]: array([2, 5])

In [11]: a * w                                                                                                                                                                                                           
Out[11]: 
array([[16,  0],
       [10, 35]])
Is there any explanation behind this unexpected behavior? If it is intended behavior then how do I compute the result I expect in this case?
	</description>
	<comments>
		<comment id='1' author='digital-idiot' date='2020-07-12T11:35:52Z'>
		Hi,
I tried to replicate the issue and here is the link to my [Notebook]:(&lt;denchmark-link:https://colab.research.google.com/drive/107mR4pm9OexQEBNDHHpA94LJL84jkZdy?usp=sharing&gt;https://colab.research.google.com/drive/107mR4pm9OexQEBNDHHpA94LJL84jkZdy?usp=sharing&lt;/denchmark-link&gt;
)
I was not able to replicate this.
		</comment>
		<comment id='2' author='digital-idiot' date='2020-07-12T15:44:18Z'>
		I rechecked the issue and found that this behavior occurs when another instance of tensorflow running with considerable GPU memory usage. For example:
&lt;denchmark-code&gt;+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      5214      G   /usr/lib/Xorg                                516MiB |
|    0      6005      G   /usr/bin/kwin_x11                            177MiB |
|    0      6066      G   /usr/bin/plasmashell                          68MiB |
|    0      6500      G   /snap/pycharm-community/202/jbr/bin/java       3MiB |
|    0     44308      G   /usr/lib/firefox/firefox                       2MiB |
|    0   1107722      G   /usr/lib/firefox/firefox                       2MiB |
|    0   3337621      C   ...e/xxxx/.conda/envs/Py3Dev/bin/python     6745MiB |
|    0   3400212      C   ...e/xxxx/.conda/envs/Py3Dev/bin/python      407MiB |
+-----------------------------------------------------------------------------+

&lt;/denchmark-code&gt;

The reported behavior occurs. And the behavior is not identical each time. However, once it reported CUDA_ERROR_OUT_OF_MEMORY but returned the resulting tensor as zeros.
In [1]: import numpy as np                                                                                                                                                                                               

In [2]: import tensorflow as tf                                                                                                                                                                                          

In [3]: a = np.random.randint(0, 10, (2, 2))                                                                                                                                                                             

In [4]: b = np.array([2, 5])                                                                                                                                                                                             

In [5]: x = tf.convert_to_tensor(a)

n [6]: y = tf.convert_to_tensor(b)                                                                                                                                                                                      

In [7]: x                                                                                                                                                                                                                
Out[7]: 
&lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[0, 4],
       [4, 0]])&gt;

In [8]: y                                                                                                                                                                                                                
Out[8]: &lt;tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 5])&gt;

In [9]: x * y                                                                                                                                                                                                           
2020-07-12 17:07:47.029298: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 187.12M (196214784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
Out[9]: 
&lt;tf.Tensor: shape=(2, 2), dtype=int64, numpy=
array([[0, 0],
       [0, 0]])&gt;
But it continued to generate garbage values in subsequent tries without any error. My guess is, it is a memory related issue. If if is indeed out of memory shouldn't it throw an exception without returning anything, instead of and warning / info?
Otherwise, it generates correct result when there is plenty of free GPU memory.
		</comment>
		<comment id='3' author='digital-idiot' date='2020-07-13T10:14:39Z'>
		&lt;denchmark-link:https://github.com/digital-idiot&gt;@digital-idiot&lt;/denchmark-link&gt;

I tried in colab with TF version 2.2 and i am not seeing any issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/d5c442e058d727ffd6a96b5a4e3eafb6/untitled110.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='4' author='digital-idiot' date='2020-07-14T12:41:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41317&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41317&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>