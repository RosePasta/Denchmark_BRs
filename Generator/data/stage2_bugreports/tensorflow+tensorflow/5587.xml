<bug id='5587' author='codingyourlife' open_date='2016-11-13T22:27:24Z' closed_time='2018-01-29T22:35:08Z'>
	<summary>iOS No OpKernel to support TruncatedNormal</summary>
	<description>
I have a NN similar to this one: &lt;denchmark-link:http://stackoverflow.com/a/38576462/828184&gt;http://stackoverflow.com/a/38576462/828184&lt;/denchmark-link&gt;
 and my iOS project is based on the simple contrib example.
I write out the graph.pb file like so (and replace it with the original iOS one):
tf.train.write_graph(sess.graph_def, 'NNModel/', 'graph.pb', as_text=False)
But XCode crashes on execution with this error:

RunModelViewController.mm: Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered kernels:

[[Node: OutputLayer/truncated_normal/TruncatedNormal = TruncatedNormalT=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0]]

I guess it's because of the usage of tf.truncated_normal(...). Is there an alternative to that call or am I doing something wrong?
So far I got a minimalistic multiplication graph working on iOS but no trained NN.
	</description>
	<comments>
		<comment id='1' author='codingyourlife' date='2016-11-14T16:39:08Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 What do folks do if we haven't listed their favorite op in the mobile whitelist?
		</comment>
		<comment id='2' author='codingyourlife' date='2016-11-14T17:00:55Z'>
		We need to document this properly, but if you're using bazel, find the right .cc file and add it to android_extended_ops_group1 or 2 in tensorflow/core/kernels/BUILD, and add it to tensorflow/contrib/makefile/tf_op_files.txt too for the makefile build.
		</comment>
		<comment id='3' author='codingyourlife' date='2016-11-14T17:01:44Z'>
		Oh, and to find the right .cc file, look for REGISTER_KERNEL("TruncatedNormal", ...) in the source code.
		</comment>
		<comment id='4' author='codingyourlife' date='2016-11-14T17:11:51Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Should I leave this bug open to track the documentation part?
		</comment>
		<comment id='5' author='codingyourlife' date='2016-11-14T18:00:03Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 Yes, that does make sense.
		</comment>
		<comment id='6' author='codingyourlife' date='2017-06-16T17:18:23Z'>
		Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.
		</comment>
		<comment id='7' author='codingyourlife' date='2017-06-21T16:09:47Z'>
		I'm hitting this issue today. I created a simple NN (straight-line) example in Python with 1 node (1 weight + 1 bias), trained it and exported the graph. Using an example on StackOverflow, I tried to import this graph into C++ on a Raspberry Pi like device (C.H.I.P. $9 board) on which I had painstakingly compiled the static tensorflow C++ library. I tested the tensorflow installation using the pi_examples/ which worked fine. I also ensured that clear_devices was set to True when exporting the graph from Python as that was the training machine.
terminate called after throwing an instance of 'std::runtime_error'
what():  Error creating graph: Invalid argument: No OpKernel was registered to support Op 'TruncatedNormal' with these attrs.  Registered devices: [CPU], Registered kernels:

&lt;denchmark-code&gt; [[Node: truncated_normal/TruncatedNormal = TruncatedNormal[T=DT_INT32, _output_shapes=[[1,1]], dtype=DT_FLOAT, seed=0, seed2=0](truncated_normal/shape)]]
&lt;/denchmark-code&gt;

Aborted
chip@chip:~/tensorflow$ grep -Fsnr REGISTER_KERNEL . | grep "TruncatedNormal"
./tensorflow/core/kernels/parameterized_truncated_normal_op.cc:361:  REGISTER_KERNEL_BUILDER(Name("ParameterizedTruncatedNormal") 
./tensorflow/core/kernels/parameterized_truncated_normal_op.cc:375:  REGISTER_KERNEL_BUILDER(Name("ParameterizedTruncatedNormal") \
Grep-ing, I couldn't find an exact match for the TruncatedNormal kernel in the source code either. Please help!
		</comment>
		<comment id='8' author='codingyourlife' date='2017-06-21T17:38:38Z'>
		Tangential-note: I just realized that the TruncatedNormal is the distribution I was using to randomly initialize my weights (in this case, 1 weight). Clearly, this kernel isn't needed as part of the inference graph as the weights have already been trained and will remain constant.
Reading up on optimizing the exported graph for inference, it looks like bazel is needed for that, along with some python tools. Is there any way to ask export_meta_graph() to only export the inference graph to side-step this issue?
		</comment>
		<comment id='9' author='codingyourlife' date='2017-12-22T07:39:27Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='codingyourlife' date='2018-01-05T19:09:37Z'>
		Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='codingyourlife' date='2018-01-24T13:23:17Z'>
		Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='12' author='codingyourlife' date='2018-01-29T22:35:08Z'>
		We know cover this a bit better in the documentation:
&lt;denchmark-link:https://www.tensorflow.org/mobile/prepare_models&gt;https://www.tensorflow.org/mobile/prepare_models&lt;/denchmark-link&gt;

I hope this covers the problems people are running into, so closing out this bug unless there's new information.
		</comment>
	</comments>
</bug>