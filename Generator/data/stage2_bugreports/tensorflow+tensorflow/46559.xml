<bug id='46559' author='arkadeepnc' open_date='2021-01-20T22:33:34Z' closed_time='2021-01-21T14:21:45Z'>
	<summary>Issue on using tf.vectorized_map on a function with a tf.while_loop</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): conda install tensorflow-gpu in a conda env
TensorFlow version (use command below): 2.2
Python version: 3.8.3
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): No
CUDA/cuDNN version: 10.2
GPU model and memory:  GeForce RTX 2060 SUPER computeCapability: 7.5, Memory  8 GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
The included code tries to vectorize a function which adds 10.0 to the input and does so through a while loop which adds 1.0 each time (for 10 times). The function runs perfectly when using tf.map_fn and fails when using tf.vectorized_map
Describe the expected behavior
The function would not run when using vectorized map and the error points towards   Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower
Standalone code to reproduce the issue
&lt;denchmark-code&gt;if __name__ == "__main__":
    import tensorflow as tf
    @tf.function()
    def add(a):       
        i = tf.constant(0, dtype = tf.int32)
        c = tf.constant(1., dtype = tf.float32)
        loop_index = lambda  i, c, a: i &lt; 10
        def body(i, c, a):
            a = c + a
            i = i + 1
            return i,c, a
        i,c, a = tf.while_loop(loop_index, body, [i,c, a],\
             shape_invariants=[tf.TensorShape(()), tf.TensorShape(()),tf.TensorShape([1])], back_prop= False, parallel_iterations=1)

        return a

    counter =  tf.reshape(tf.range(0, 40, delta = 1, dtype = tf.float32), shape = [40,1])

    all_ = tf.vectorized_map(add, counter) # does not work
    # all_ = tf.map_fn(add, counter)
    print(all_, '&lt;-- should be [40,1] float32 tensor with elements [10., 11., ...49.]')
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;2021-01-20 17:26:53.074085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-01-20 17:26:53.101801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.102114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.71GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-20 17:26:53.102265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.103295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-20 17:26:53.104241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-20 17:26:53.104386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-20 17:26:53.105247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-20 17:26:53.105734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-20 17:26:53.107658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-20 17:26:53.107742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.108011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.108212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-20 17:26:53.108397: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2021-01-20 17:26:53.112400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3600000000 Hz
2021-01-20 17:26:53.112694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55853e36c7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-01-20 17:26:53.112704: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-01-20 17:26:53.112820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.71GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2021-01-20 17:26:53.113143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.113154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-01-20 17:26:53.113163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-01-20 17:26:53.113171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-01-20 17:26:53.113180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-01-20 17:26:53.113188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-01-20 17:26:53.113197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-01-20 17:26:53.113232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.113760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-01-20 17:26:53.113779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-01-20 17:26:53.182683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-20 17:26:53.182703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-01-20 17:26:53.182707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-01-20 17:26:53.182837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-01-20 17:26:53.183550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6620 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-01-20 17:26:53.184629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55853ec63ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-01-20 17:26:53.184638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
WARNING:tensorflow:From distransTest.py:266: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.while_loop(c, b, vars, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))
ERROR:tensorflow:Got error while pfor was converting op name: "loop_body/PartitionedCall"
op: "PartitionedCall"
input: "loop_body/GatherV2"
attr {
  key: "Tin"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: "Tout"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_read_only_resource_inputs"
  value {
    list {
    }
  }
}
attr {
  key: "config"
  value {
    s: ""
  }
}
attr {
  key: "config_proto"
  value {
    s: "\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0012\005*\0010J\0008\001"
  }
}
attr {
  key: "executor_type"
  value {
    s: ""
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_add_57"
    }
  }
}
with inputs (&lt;tf.Tensor 'loop_body/GatherV2:0' shape=(1,) dtype=float32&gt;,)
, converted inputs [WrappedTensor(t=&lt;tf.Tensor 'loop_body/GatherV2/params:0' shape=(40, 1) dtype=float32&gt;, is_stacked=True, is_sparse_stacked=False)]
in user code:

    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *
        [converter._convert_helper(x).t for x in func._func_graph_outputs])
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1460 _convert_helper  **
        raise ValueError("No converter defined for %s\n%s\ninputs: %s. "

    ValueError: No converter defined for StatelessWhile
    name: "while"
    op: "StatelessWhile"
    input: "while/loop_counter"
    input: "while/maximum_iterations"
    input: "Const"
    input: "Const_1"
    input: "a"
    attr {
      key: "T"
      value {
        list {
          type: DT_INT32
          type: DT_INT32
          type: DT_INT32
          type: DT_FLOAT
          type: DT_FLOAT
        }
      }
    }
    attr {
      key: "_lower_using_switch_merge"
      value {
        b: true
      }
    }
    attr {
      key: "_num_original_outputs"
      value {
        i: 5
      }
    }
    attr {
      key: "_read_only_resource_inputs"
      value {
        list {
        }
      }
    }
    attr {
      key: "body"
      value {
        func {
          name: "while_body_20"
        }
      }
    }
    attr {
      key: "cond"
      value {
        func {
          name: "while_cond_19"
        }
      }
    }
    attr {
      key: "output_shapes"
      value {
        list {
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
            dim {
              size: 1
            }
          }
        }
      }
    }
    attr {
      key: "parallel_iterations"
      value {
        i: 1
      }
    }
    
    inputs: [WrappedTensor(t=&lt;tf.Tensor 'while/loop_counter/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'while/maximum_iterations/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'Const/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'Const_1/pfor/Const:0' shape=() dtype=float32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'args_0:0' shape=(40, 1) dtype=float32&gt;, is_stacked=True, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

Here are the pfor conversion stack traces:
ERROR:tensorflow:name: "loop_body/PartitionedCall"
op: "PartitionedCall"
input: "loop_body/GatherV2"
attr {
  key: "Tin"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: "Tout"
  value {
    list {
      type: DT_FLOAT
    }
  }
}
attr {
  key: "_read_only_resource_inputs"
  value {
    list {
    }
  }
}
attr {
  key: "config"
  value {
    s: ""
  }
}
attr {
  key: "config_proto"
  value {
    s: "\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0012\005*\0010J\0008\001"
  }
}
attr {
  key: "executor_type"
  value {
    s: ""
  }
}
attr {
  key: "f"
  value {
    func {
      name: "__inference_add_57"
    }
  }
}

created at:
    File "distransTest.py", line 273, in &lt;module&gt;
    all_ = tf.vectorized_map(add, counter) # does not work
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 407, in vectorized_map
    return pfor(loop_fn, batch_size)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 198, in pfor
    outputs = f()
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 957, in wrapper
    return autograph.converted_call(
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 183, in f
    return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 237, in _pfor_impl
    loop_fn_outputs = loop_fn(loop_var)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 400, in loop_fn
    return fn(gathered_elems)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 1661, in _filtered_call
    return self._call_flat(
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 1760, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 621, in call
    outputs = functional_ops.partitioned_call(
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/functional_ops.py", line 1180, in partitioned_call
    op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 3257, in create_op
    return self._create_op_internal(op_type, inputs, dtypes, input_types, name,
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 593, in _create_op_internal
    return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 3319, in _create_op_internal
    ret = Operation(
    File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py", line 1791, in __init__
    self._traceback = tf_stack.extract_stack()

Traceback (most recent call last):
  File "distransTest.py", line 273, in &lt;module&gt;
    all_ = tf.vectorized_map(add, counter) # does not work
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 407, in vectorized_map
    return pfor(loop_fn, batch_size)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py", line 198, in pfor
    outputs = f()
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 505, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py", line 2657, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py", line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:3600 f  *
        [converter._convert_helper(x).t for x in func._func_graph_outputs])
    /home/arka/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:1460 _convert_helper  **
        raise ValueError("No converter defined for %s\n%s\ninputs: %s. "

    ValueError: No converter defined for StatelessWhile
    name: "while"
    op: "StatelessWhile"
    input: "while/loop_counter"
    input: "while/maximum_iterations"
    input: "Const"
    input: "Const_1"
    input: "a"
    attr {
      key: "T"
      value {
        list {
          type: DT_INT32
          type: DT_INT32
          type: DT_INT32
          type: DT_FLOAT
          type: DT_FLOAT
        }
      }
    }
    attr {
      key: "_lower_using_switch_merge"
      value {
        b: true
      }
    }
    attr {
      key: "_num_original_outputs"
      value {
        i: 5
      }
    }
    attr {
      key: "_read_only_resource_inputs"
      value {
        list {
        }
      }
    }
    attr {
      key: "body"
      value {
        func {
          name: "while_body_20"
        }
      }
    }
    attr {
      key: "cond"
      value {
        func {
          name: "while_cond_19"
        }
      }
    }
    attr {
      key: "output_shapes"
      value {
        list {
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
          }
          shape {
            dim {
              size: 1
            }
          }
        }
      }
    }
    attr {
      key: "parallel_iterations"
      value {
        i: 1
      }
    }
    
    inputs: [WrappedTensor(t=&lt;tf.Tensor 'while/loop_counter/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'while/maximum_iterations/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'Const/pfor/Const:0' shape=() dtype=int32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'Const_1/pfor/Const:0' shape=() dtype=float32&gt;, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=&lt;tf.Tensor 'args_0:0' shape=(40, 1) dtype=float32&gt;, is_stacked=True, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='arkadeepnc' date='2021-01-21T09:00:41Z'>
		&lt;denchmark-link:https://github.com/arkadeepnc&gt;@arkadeepnc&lt;/denchmark-link&gt;

I have tried in colab with TF-GPU versions 2.3 , 2.4 and I am not seeing any issue.Attached gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/43c6698c61e793b03cb1f82d0b62f6fd/untitled627.ipynb&gt;here&lt;/denchmark-link&gt;
.
Please, verify once and close the issue. Thanks!
		</comment>
		<comment id='2' author='arkadeepnc' date='2021-01-21T14:21:45Z'>
		Thanks &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
. The issue is specific to my setup and is not present on TF2.4. I tested this on my system ans can confirm this.
Closing the issue.
		</comment>
		<comment id='3' author='arkadeepnc' date='2021-01-21T14:21:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46559&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46559&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>