<bug id='37441' author='rakeshmothukuru1' open_date='2020-03-09T11:14:20Z' closed_time='2020-08-26T15:18:57Z'>
	<summary>ValueError: Cannot convert a Tensor of dtype resource to a NumPy array</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  N/A, as it can be reproduced in Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  N/A
TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1
Python version: - Bazel
version (if compiling from source): N/A
GCC/Compiler version (if compiling from
source): N/A
CUDA/cuDNN version: - GPU model and memory: N/A

Describe the current behavior: It is resulting in Error, InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array., while running the First Code but is working fine when tf.keras.Input is replaced with tf.Variable in the Second Code.
Describe the expected behavior: Code should work fine with tf.keras.Input as well
Standalone code to reproduce the issue
&lt;denchmark-code&gt;  **Code with Error:**
&lt;/denchmark-code&gt;

import tensorflow as tf
num_uids = 50
#input_uid = tf.keras.layers.Input(shape=(1,), dtype=tf.int32, batch_size = 32)
input_uid = tf.keras.layers.Input(shape=(1,), dtype=tf.int32)
params = tf.Variable(tf.random.normal((num_uids, 9)), trainable=True)
param = tf.gather_nd(params, input_uid)
#input_shared_features = tf.keras.layers.Input(shape=(128,), dtype=tf.float32, batch_size = 32)
input_shared_features = tf.keras.layers.Input(shape=(128,), dtype=tf.float32)
combined = tf.concat([param, input_shared_features], axis=-1)
net = tf.keras.layers.Dense(128)(combined)
&lt;denchmark-code&gt;  **Working Code:**
&lt;/denchmark-code&gt;

import tensorflow as tf
num_uids = 50
input_uid = tf.Variable(tf.ones((32, 1), dtype=tf.int32))
params = tf.Variable(tf.random.normal((num_uids, 9)), trainable=True)
param = tf.gather_nd(params, input_uid)
input_shared_features = tf.Variable(tf.ones((32, 128), dtype=tf.float32))
combined = tf.concat([param, input_shared_features], axis=-1)
net = tf.keras.layers.Dense(128)(combined)
Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/b3427c06cab54beed19a381339c932e0/so_59962509.ipynb&gt;Github Gist&lt;/denchmark-link&gt;
.
There is a &lt;denchmark-link:https://stackoverflow.com/questions/59962509/valueerror-cannot-convert-a-tensor-of-dtype-resource-to-a-numpy-array&gt;Stack Overflow Question&lt;/denchmark-link&gt;
 also, associated with this issue.
	</description>
	<comments>
		<comment id='1' author='rakeshmothukuru1' date='2020-03-09T11:44:27Z'>
		I have replicated this issue in nightly as well and the issue persist, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/4a455a71f944fba5432b96ce7cae23e6/37441.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='rakeshmothukuru1' date='2020-04-18T18:50:19Z'>
		I have the same problem. I've been confused for a long time···
		</comment>
		<comment id='3' author='rakeshmothukuru1' date='2020-04-23T08:18:26Z'>
		Same problem here.
Tensorflow version
'2.2.0-rc3'
Code to reproduce the issue:
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_datasets as tfds

embedding = "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1"
hub_layer = hub.KerasLayer(embedding, input_shape=[], 
                           dtype=tf.string, trainable=True)

Dense = tf.keras.layers.Dense
fc_model = tf.keras.Sequential()
fc_model.add(hub_layer)
fc_model.add(Dense(4096, activation=tf.nn.swish))
fc_model.add(Dense(1))

ds_train, ds_val, ds_test = tfds.load(
    name="imdb_reviews", 
    split=('train[:60%]', 'train[60%:]', 'test'),
    as_supervised=True)

fc_model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

fc_model.fit(ds_train.shuffle(10000).batch(512), validation_data=ds_test.batch(512), epochs=5, verbose=1)

def representative_dataset_gen():
  for _ in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    yield [input]


converter = tf.lite.TFLiteConverter.from_keras_model(fc_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()
&lt;/denchmark-code&gt;

The issue:
&lt;denchmark-code&gt;
---------------------------------------------------------------------------

InvalidArgumentError                      Traceback (most recent call last)

&lt;ipython-input-31-b07abdccac46&gt; in &lt;module&gt;()
      8 converter.optimizations = [tf.lite.Optimize.DEFAULT]
      9 converter.representative_dataset = representative_dataset_gen
---&gt; 10 tflite_quant_model = converter.convert()

6 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)
    457     frozen_func, graph_def = (
    458         _convert_to_constants.convert_variables_to_constants_v2_as_graph(
--&gt; 459             self._funcs[0], lower_control_flow=False))
    460     input_tensors = [
    461         tensor for tensor in frozen_func.inputs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)
    704   """
    705   graph_def, converted_inputs = _convert_variables_to_constants_v2_impl(
--&gt; 706       func, lower_control_flow, aggressive_inlining)
    707   frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)
    708   return frozen_func, graph_def

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py in _convert_variables_to_constants_v2_impl(func, lower_control_flow, aggressive_inlining)
    455 
    456   # Get mapping from node name to variable value.
--&gt; 457   tensor_data = _get_tensor_data(func)
    458 
    459   # Get mapping from function name to argument types.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py in _get_tensor_data(func)
    215       data = map_index_to_variable[idx].numpy()
    216     else:
--&gt; 217       data = val_tensor.numpy()
    218     tensor_data[tensor_name] = {
    219         "data": data,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in numpy(self)
    959     """
    960     # TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.
--&gt; 961     maybe_arr = self._numpy()  # pylint: disable=protected-access
    962     return maybe_arr.copy() if isinstance(maybe_arr, np.ndarray) else maybe_arr
    963 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
    927       return self._numpy_internal()
    928     except core._NotOkStatusException as e:
--&gt; 929       six.raise_from(core._status_to_exception(e.code, e.message), None)
    930 
    931   @property

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='rakeshmothukuru1' date='2020-04-24T18:01:27Z'>
		I am facing the same issue. Any updates on a potential fix? Thanks.
		</comment>
		<comment id='5' author='rakeshmothukuru1' date='2020-05-04T05:48:05Z'>
		I had the same issue. The code worked when I manually entered data using tf.Variable but failed when I tried to build a model.
		</comment>
		<comment id='6' author='rakeshmothukuru1' date='2020-05-04T11:22:07Z'>
		Same issue, any update?
		</comment>
		<comment id='7' author='rakeshmothukuru1' date='2020-05-21T09:07:42Z'>
		I also had the same issue. Are there any solutions?
		</comment>
		<comment id='8' author='rakeshmothukuru1' date='2020-06-02T21:32:13Z'>
		I have posted a solution in the stackoverflow question associated with this issue - &lt;denchmark-link:https://stackoverflow.com/a/62161525/2352424&gt;https://stackoverflow.com/a/62161525/2352424&lt;/denchmark-link&gt;

Hope that helps
		</comment>
		<comment id='9' author='rakeshmothukuru1' date='2020-06-17T21:15:04Z'>
		I had the same issue, and was able to work around it like this:
indices = Input(name='indices', shape=(), dtype='int32')
params = tf.Variable(params)

class GatherLayer(keras.layers.Layer):
    def call(self, indices, params):
        return tf.gather(params, indices)

output = GatherLayer()(indices, params)
Rather unintuitively, the critical part is actually that the function arguments (params and indices) are swapped in the custom layer. If you don't do that, you still get the same error. I didn't dig deeper into why this is the case.
		</comment>
		<comment id='10' author='rakeshmothukuru1' date='2020-06-25T21:23:11Z'>
		
I had the same issue, and was able to work around it like this:
indices = Input(name='indices', shape=(), dtype='int32')
params = tf.Variable(params)

class GatherLayer(keras.layers.Layer):
    def call(self, indices, params):
        return tf.gather(params, indices)

output = GatherLayer()(indices, params)
Rather unintuitively, the critical part is actually that the function arguments (params and indices) are swapped in the custom layer. If you don't do that, you still get the same error. I didn't dig deeper into why this is the case.

As obtuse as this might be, this worked for me too!
		</comment>
		<comment id='11' author='rakeshmothukuru1' date='2020-06-27T23:10:25Z'>
		I have the same issue:
&lt;denchmark-code&gt;def makeSimpleModelNoFeatures(
    hp = {
        'max_tokens':    5000, 
        'ngrams':        (1, 2), 
        'units':         64, 
        'learning_rate': 1e-3,
        'dropout':       0.2,
        'layers':        2
    }
):
    vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(
        max_tokens        = int(hp.get('max_tokens')),
        ngrams            = hp.get('ngrams') if type(hp.get('ngrams')) == tuple else int(hp.get('ngrams')),
        output_mode       = 'tf-idf',
        pad_to_max_tokens = True,
    )
    vectorizer.adapt(TEXTS)
    
    textInput     = tf.keras.Input(shape=(1,),  name = 'text', dtype = tf.string)
    
    x = vectorizer(textInput)
    x = tf.keras.layers.Dropout(hp.get('dropout'))(x)
    
    for index in range(hp.get('layers')):
        x = tf.keras.layers.Dense(hp.get('units'), activation = 'relu')(x)
        x = tf.keras.layers.Dropout(hp.get('dropout'))(x)
    
    output = tf.keras.layers.Dense(
        1, 
        activation       = 'sigmoid',
        bias_initializer = tf.keras.initializers.Constant(INITIAL_BIAS) if INITIAL_BIAS else None
    )(x)
    
    model = tf.keras.Model(inputs = textInput, outputs = output)
    model.compile(
        optimizer = tf.keras.optimizers.Adam(lr = hp.get('learning_rate')),
        loss      = tf.keras.losses.BinaryCrossentropy(),
        metrics   = METRICS,
    )

    return model

EPOCHS       = 10
BATCH_SIZE   = 3000
checkpointer = getCheckpointer('ngrams, no features, no weigths')

model   = makeSimpleModelNoFeatures()
history = model.fit(
    x               = trainInput['text'],
    y               = trainLabels,
    batch_size      = BATCH_SIZE,
    epochs          = EPOCHS,
    validation_data = (validationInput['text'], validationLabels),
    callbacks       = [checkpointer],
    class_weight    = None,
    verbose         = 2,
)

tfliteModel = tf.lite.TFLiteConverter.from_keras_model(model).convert()

with tf.io.gfile.GFile('ngrams_20200628.tflite', 'wb') as f:
    f.write(tfliteModel)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='rakeshmothukuru1' date='2020-08-10T19:41:23Z'>
		&lt;denchmark-link:https://github.com/rakeshmothukuru1&gt;@rakeshmothukuru1&lt;/denchmark-link&gt;
 were you able to resolve the issue?
		</comment>
		<comment id='13' author='rakeshmothukuru1' date='2020-08-26T15:18:57Z'>
		&lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
,
Sorry for the delayed response. Yes, it is resolved. Thank you &lt;denchmark-link:https://github.com/anjany&gt;@anjany&lt;/denchmark-link&gt;
 for the workaround.
		</comment>
		<comment id='14' author='rakeshmothukuru1' date='2020-08-26T15:18:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37441&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37441&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='rakeshmothukuru1' date='2020-10-29T07:47:29Z'>
		for reference, I was coming across the same problem within a custom layer I wrote. Changing the order of the inputs fixed it, though this seems like a problem that may need a real fix.
		</comment>
		<comment id='16' author='rakeshmothukuru1' date='2020-10-30T01:09:50Z'>
		&lt;denchmark-link:https://github.com/stephen-systemfriend&gt;@stephen-systemfriend&lt;/denchmark-link&gt;
  What version of TF are you running?
For TF 2.3.0, I get no errors for the following code snippet:
&lt;denchmark-code&gt;import tensorflow as tf
input = tf.keras.layers.Input(shape=(1,), dtype=tf.int32, batch_size = 32)
params = tf.Variable(tf.random.normal((50, 9)), trainable=True)

# Version 1
output = tf.gather_nd(params, input)
# No error

# Version 2
class UpdatedTFGather(tf.keras.layers.Layer):
    def call(self, input, params):
        return tf.gather_nd(params, input)
output = UpdatedTFGather()(input, params)
# No error
&lt;/denchmark-code&gt;

Also, the tf.gather_nd function arguments are expected to be of type "tf.Tensor" and not "tf.keras.layers.Layer". Thus, it is best to use the following code which will work across all TF versions:
&lt;denchmark-code&gt;import tensorflow as tf
input = tf.Variable(tf.ones((32, 1), dtype=tf.int32))
params = tf.Variable(tf.random.normal((50, 9)), trainable=True)
output = tf.gather_nd(params, input)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='rakeshmothukuru1' date='2020-10-30T02:01:00Z'>
		TensorFlow 2.2.0
The code in question was a custom implementation of attention, but if I took the inputs as (value, query) then I would hit this error for some set of inputs. In the same structure it already was successfully called 5 times for other inputs, and changing the order to query, value fixed it
There are no explicit calls to tf.gather_nd
		</comment>
		<comment id='18' author='rakeshmothukuru1' date='2020-10-30T21:15:37Z'>
		&lt;denchmark-link:https://github.com/stephen-systemfriend&gt;@stephen-systemfriend&lt;/denchmark-link&gt;
  Thank you for the details. As it's not a blocker and you have a workaround, I hope that should do for now. If you face a major blocker, feel free to re-open this issue with further information.
		</comment>
	</comments>
</bug>