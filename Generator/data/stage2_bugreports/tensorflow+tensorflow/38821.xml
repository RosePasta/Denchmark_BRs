<bug id='38821' author='17patelumang' open_date='2020-04-23T00:04:21Z' closed_time='2020-05-21T17:49:41Z'>
	<summary>TF 2.1.0 savedModel input_fn from TF 1.15.x</summary>
	<description>
TensorFlow installed from : binary
TensorFlow version : 2.1.0
Python version: 3.7.3
&lt;denchmark-code&gt;import numpy as np
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()


print(tf.__version__)

############### Function we wrote ############

@tf.function
def tile_nd_ragged2(a, b):
  # Need a sentinel, otherwise it's hard to give it the initial shape we need.
  # We'll drop the sentinel at the end.
  acc = tf.ragged.constant([[[]]], dtype=a.dtype)
  
  print('acc is', acc)
  # Work one row at a time...
  # for i1 in tf.range(len(a.nested_row_lengths()[0])):    # Should be able to write `for a1, b1 in zip(a, b)` soon.
  def outer_loop_test(i1, _):
    return i1 &lt; len(a.nested_row_lengths()[0])

  def outer_loop_body(i1, acc):
    
    a1 = a[i1]
    b1 = b[i1]

    # If the components have variable length, we can't use a TensorArray anymore,
    # so use a RaggedTensor instead.
    acc1 = tf.ragged.constant([[]], dtype=a.dtype)
    def loop_test(i2, _):
      shape = None
      if isinstance(a1, tf.RaggedTensor):
        print(" --- ragged --- ")
        print(a1)
        print(shape)
        shape = tf.shape(a1.nested_row_lengths()[0])[0]
      else:
        print(" --- tensor --- ")
        print(a1)
        
        shape = tf.shape(a1)[0]
        print(tf.shape(a1))
        print(shape)

      return i2 &lt; shape
      #return i2 &lt; tf.cast(a1.nested_row_lengths()[0][i1], tf.int32)
    def loop_body(i2, acc1):
      #print(a1[i2])
      a2 = a1[i2]
      b2 = b1[i2]

      for _ in range(len(b2)):
        acc1 = tf.concat([acc1, tf.expand_dims(a2, 0)], axis=0)
      return i2 + 1, acc1

    _, acc1 = tf.while_loop(loop_test, loop_body, [0, acc1],shape_invariants=[tf.TensorShape([]), tf.TensorShape([None, None])])
    acc1 = acc1[1:]  # Drop the sentinel.
    acc = tf.concat([acc, tf.expand_dims(acc1, 0)], axis=0)    # Add the row to the final result.

    return i1 + 1, acc

  _, acc = tf.while_loop(
      outer_loop_test, outer_loop_body,
      [0, acc],
      shape_invariants=[
                        tf.TensorShape([]),
                        tf.TensorShape([None, None, None])
                        ]
      )
  acc = acc[1:]  # Drop the sentinel.
  return acc



###############  export_input_fn ############


def export_input_fn():
    serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name ="text") 

    s1Split = tf.strings.split([serialized_tf_example],result_type="RaggedTensor")
    s1Split = tf.strings.split(s1Split,sep='@',result_type="RaggedTensor")
    result  = tile_nd_ragged2(s1Split,s1Split)
    result_tf = result.to_tensor()[:1,:,:][0][0]
    #result_tf = result.to_tensor()
    result_int = tf.strings.to_number(result_tf,out_type=tf.int32)

    features ={}
    features["f1"]=result_int ### this will be tf.Tensor([1], shape=(1,), dtype=int32)
    
    reciever_tensor = {"text": serialized_tf_example}
    print(reciever_tensor)   
    return tf.estimator.export.ServingInputReceiver(features, reciever_tensor)

########### Training ###############
x_feature = tf.feature_column.numeric_column('f1')
train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
      x = {"f1": np.array([1., 2., 3., 4.])},      # Input features
      y = np.array([1.5, 3.5, 5.5, 7.5]),         # true labels
      batch_size=1,
      num_epochs=1,
      shuffle=True)

regressor = tf.estimator.LinearRegressor(feature_columns=[x_feature])
regressor.train(input_fn=train_input_fn, steps=10)

samples = np.array([1])
predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(x={"f1": samples},num_epochs=1,shuffle=False)
predictions = list(regressor.predict(input_fn=predict_input_fn))
print("---------")
print(predictions)


print("--------- training finished ---------")


regressor.export_saved_model("./model",export_input_fn,as_text=False)
&lt;/denchmark-code&gt;

I have above code originally written in TF 1.15.0 , currently i am trying to port it to TF 2.1.0. I am basically trying to generate savedModel using customized feature transformation as above . When I run the above code it works well but its due to tf.disable_v2_behavior() .
I am currently trying to comment out
&lt;denchmark-code&gt;import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
&lt;/denchmark-code&gt;

and use
&lt;denchmark-code&gt;import tensorflow  as tf
&lt;/denchmark-code&gt;

and try to convert  to TF 2.1.0 .
Now TF 2.1.0 has no tf.placeholder  so i tried converting it using
serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name ="text") 
and got error
TypeError: Expected int32, got None of type 'NoneType' instead  atserialized_tf_example = tf.Variable(tf.zeros([None]), dtype=tf.string, name='text')
This might not be the right way to do it but all i want is to get savedModel having feature processing inside savedModel in TF 2.1.0 .
Any help will be appreciated.
	</description>
	<comments>
		<comment id='1' author='17patelumang' date='2020-04-26T19:20:54Z'>
		any-update on this ?
		</comment>
		<comment id='2' author='17patelumang' date='2020-04-28T13:48:07Z'>
		&lt;denchmark-link:https://github.com/17patelumang&gt;@17patelumang&lt;/denchmark-link&gt;

Can you please share the standalone code from tf 2.1 where the error is faced for us to replicate the issue, or if possible please share a gist of the code and error faced for us to analyse
		</comment>
		<comment id='3' author='17patelumang' date='2020-04-28T14:15:06Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  code i already provided above :)
		</comment>
		<comment id='4' author='17patelumang' date='2020-05-05T10:30:24Z'>
		&lt;denchmark-link:https://github.com/17patelumang&gt;@17patelumang&lt;/denchmark-link&gt;

I ran the code shared, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/106bcca967ad7fafce2572bc8029a9fc/2.ipynb&gt;gist here&lt;/denchmark-link&gt;
 , does this confirm your issue. else please share a colab gist for us to analyse.
		</comment>
		<comment id='5' author='17patelumang' date='2020-05-07T04:41:33Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  yes . however i want to run it without 
		</comment>
		<comment id='6' author='17patelumang' date='2020-05-21T17:49:41Z'>
		&lt;denchmark-link:https://github.com/17patelumang&gt;@17patelumang&lt;/denchmark-link&gt;
 - You can check out the Saved Model guides linked below for some pointers, and I would encourage you to post this on Stack Overflow, as there is a larger community that can help there. If you can narrow down the issue to a particular bug, please open a new issue with a minimal reproduction of that bug.
&lt;denchmark-link:https://www.tensorflow.org/guide/saved_model&gt;https://www.tensorflow.org/guide/saved_model&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='17patelumang' date='2020-05-21T17:49:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38821&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38821&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>