<bug id='26075' author='kyfanc' open_date='2019-02-25T07:09:21Z' closed_time='2019-06-28T19:12:57Z'>
	<summary>TFLite model converted from pb file yields different output values</summary>
	<description>
System information:
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
macOS Mojave version 10.14.3
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
IPhone XS (iOS 12.1.4)
TensorFlow installed from (source or binary):
bazel tools: build from source
python imports: install with pip tensorflow==1.12.0
TensorFlow version (use command below):
bazel tools: github branch r1.13 commit bade323390591fff6fc82b7eeb4a6cc30f807389 Fri Feb 22 11:00:40 2019 -0800
python imports: ('v1.12.0-rc2-3-ga6d8ffae09', '1.12.0')
Python version:
Python 2.7.10
Bazel version (if compiling from source):
Build label: 0.22.0
GCC/Compiler version (if compiling from source):
&lt;denchmark-code&gt;Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 10.0.0 (clang-1000.11.45.5)
Target: x86_64-apple-darwin18.2.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
&lt;/denchmark-code&gt;

CUDA/cuDNN version:
N/A
GPU model and memory:
N/A
Exact command to reproduce:
I trained a custom model based on MobileNetV2 with a fews convolution layers and fully connected layer on top to output ranking score of input images. I tried to convert the model to tflite for running on iOS, but found that the output values of tflite model are different from origin model even with same inputs. Same behaviour is observed for tflite interpreter for iOS and python and also bazel-tools. Models trained with different input size of MobileNetV2 (224, 160, 96) also produce similar behaviour.
I suppose the output values for tflite and original tensorflow model should output the same value?
the following link is a zip of the models files and output uploaded onto google drive
&lt;denchmark-link:https://drive.google.com/file/d/1tZVQk7kk5fCEnvnvOjZs1oF0y6YDLfOc/view?usp=sharing&gt;https://drive.google.com/file/d/1tZVQk7kk5fCEnvnvOjZs1oF0y6YDLfOc/view?usp=sharing&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;# path variables

CKPT_META_PATH=checkpoints/mvfn_096.ckpt-15000.meta
CKPT_WEIGHT_PATH=checkpoints/mvfn_096.ckpt-15000
FROZEN_PB_PATH=mvfn_096.pb
TFLITE_PATH=mvfn_096.tflite
TB_PATH=tb_log
TFLITE_VIS_HTML_PATH=mvfn_096_tflite.html
INPUT_IMAGE_SIZE=96
TF_PATH="" # path to tensorflow repo
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# freeze graph

python ${TF_PATH}/tensorflow/python/tools/freeze_graph.py \
    --input_binary=true \
    --input_meta_graph=${CKPT_META_PATH} \
    --input_checkpoint=${CKPT_WEIGHT_PATH} \
    --output_graph=${FROZEN_PB_PATH} \
    --output_node_names="ranker/score_func"
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# convert pb to tflite

bazel run tensorflow/lite/toco:toco -- \
    --input_file=${FROZEN_PB_PATH} \
    --input_format=${TENSORFLOW_GRAPHDEF} \
    --output_file=TFLITE_PATH \
    --output_format=TFLITE \
    --inference_type=FLOAT \
    --inference_input_type=FLOAT \
    --input_arrays=input_image \
    --output_arrays="ranker/score_func" \
    --input_shapes=1,${INPUT_IMAGE_SIZE},${INPUT_IMAGE_SIZE},3                # fix input batch size to 1
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# pb to tensorboard for visualization

python ${TF_PATH}/tensorflow/python/tools/import_pb_to_tensorboard.py \
    --model_dir=${FROZEN_PB_PATH} \
    --log_dir=${TB_PATH}
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# visualize tflite

bazel run tensorflow/lite/tools:visualize -- ${TFLITE_PATH} ${TFLITE_VIS_HTML_PATH}
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# diff tflite &amp; pb

bazel run tensorflow/lite/testing:tflite_diff_example_test -- \
    --tensorflow_model=${FROZEN_PB_PATH} \
    --tflite_model=${TFLITE_PATH} \
    --input_layer="input_image" \
    --input_layer_type=float \
    --input_layer_shape=1,${INPUT_IMAGE_SIZE},${INPUT_IMAGE_SIZE},3 \
    --output_layer="ranker/score_func"
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# output of tflite_diff_example_test
# pb model and tflite model have different output values

2019-02-25 05:34:28.723184: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA
There were errors in invocation '', output tensor '170':
  index 0: got 1.76843, but expected -4.20755
There were errors in invocation '', output tensor '170':
  index 0: got 0.762267, but expected -3.9918
There were errors in invocation '', output tensor '170':
  index 0: got 0.110205, but expected -4.65119
There were errors in invocation '', output tensor '170':
  index 0: got 1.10238, but expected -4.45592
There were errors in invocation '', output tensor '170':
  index 0: got 1.5811, but expected -4.54539
There were errors in invocation '', output tensor '170':
  index 0: got 1.34377, but expected -4.36198
There were errors in invocation '', output tensor '170':
  index 0: got 1.87406, but expected -4.3289
There were errors in invocation '', output tensor '170':
  index 0: got 2.33834, but expected -4.49968
There were errors in invocation '', output tensor '170':
  index 0: got 1.16959, but expected -4.78387
There were errors in invocation '', output tensor '170':
  index 0: got 1.22668, but expected -4.53048
There were errors in invocation '', output tensor '170':
  index 0: got 0.570301, but expected -4.27984
There were errors in invocation '', output tensor '170':
  index 0: got -0.875985, but expected -4.32995
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='kyfanc' date='2019-03-05T09:42:25Z'>
		I figured I made a mistake during step of freezing graph. My network is based on slim's mobilenet_v2 which contains batch_norm operations. My checkpoints' meta is saved with graph where is_training=True. The output pb file skipped all moving_mean and moving_variance in batch_norm operations. Somehow the tflite file generated from this pb file yields different values.
My solution was to reconstruct graph with is_training=False, then load my checkpoint weight, and convert to pb and tflite in python. Then inference by checkpoint, pb, and tflite return consistant values.
&lt;denchmark-code&gt;# snipplet of my model
# when training set is_training=True
# when infer or freeze graph set is_training=False
def build_model(is_training):
    images = tf.PlaceHolder() # for input images
    with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=is_training)):
        _, endpoints = mobilenet_v2.mobilenet(images)
    feature_map = endpoints['layer_19'] # select middle layer as feature map
    score = some_other_layers(feature_map)
    return score
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# ckpt to pb &amp; tflite
with tf.Session() as sess:
    build_model(is_training=False)
    saver = tf.train.Saver(tf.global_variables())

    # Load weights
    saver.restore(sess, weight_path)

    # Freeze the graph
    frozen_graph_def = tf.graph_util.convert_variables_to_constants(
        sess,
        sess.graph_def,
        output_node_names)

    # Save the frozen graph
    with open(pb_path, 'wb') as f:
      f.write(frozen_graph_def.SerializeToString())

if tf.__version__[:4] == "1.13":
  converter = tf.lite.TFLiteConverter.from_frozen_graph(
    pb_path, input_node_names, output_node_names, 
      input_shapes=input_shapes)
else:
  converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(
    pb_path, input_node_names, output_node_names, 
      input_shapes=input_shapes)
tflite_model = converter.convert()
open(tflite_path, "wb").write(tflite_model)
&lt;/denchmark-code&gt;

However, I still don't understand why the pb and tflite yields different values given that the batch_norm should be (falsely) fixated by freeze_graph.py. Also would it be possible to add checking in freeze_graph.py to warn user about the is_training thing?
		</comment>
		<comment id='2' author='kyfanc' date='2019-03-19T03:27:36Z'>
		Load balance to &lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 -- could you take a look?
		</comment>
		<comment id='3' author='kyfanc' date='2019-03-19T15:34:48Z'>
		Hi chrisfan918,
Can you share the pb and tflite files after your freeze graph fix.
Thanks
		</comment>
		<comment id='4' author='kyfanc' date='2019-03-25T07:26:10Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 here are the pb, tflite, ckpt files
&lt;denchmark-link:https://drive.google.com/file/d/1-sjLKab-RMlj5GRVmirvifltNPWtnqJy/view?usp=sharing&gt;https://drive.google.com/file/d/1-sjLKab-RMlj5GRVmirvifltNPWtnqJy/view?usp=sharing&lt;/denchmark-link&gt;

Note that the ckpt is different from previous uploaded ckpt. As I have made some minor namespace changes in some_other_layers and retrained since the fix, and it is a bit complex to recover the exact model code of previous version. But the graph should be more or less the same.
		</comment>
		<comment id='5' author='kyfanc' date='2019-04-23T21:29:42Z'>
		Hi chrisfan918,
Sorry for late reply as i was out of office. Trying on some random data. I can see the outputs are matching up to 1e-5.
What is the difference that you see ? is it more/less than this
Thanks
		</comment>
		<comment id='6' author='kyfanc' date='2019-06-28T19:12:57Z'>
		Issue is stale. Closing.
		</comment>
		<comment id='7' author='kyfanc' date='2019-06-28T19:12:58Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26075&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26075&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>