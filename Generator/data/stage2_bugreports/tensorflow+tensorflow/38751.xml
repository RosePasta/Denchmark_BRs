<bug id='38751' author='fly3366' open_date='2020-04-21T14:13:07Z' closed_time='2020-04-25T08:07:34Z'>
	<summary>[Keras Application]May a bug under gradientTape?</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Window 10 1804
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
None
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
every 2.1.0 cpu/gpu
Python version:
3.7.7
Bazel version (if compiling from source):None
GCC/Compiler version (if compiling from source):None
CUDA/cuDNN version:10
GPU model and memory: MSI GTX 1070 8GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
unknown 2.1.0
install from conda

Describe the current behavior
tf.keras.application work under GradientTape may crash by:
LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)
Describe the expected behavior
May GradientTape need pass Keras Application's Model?
Or Keras Application's Model could be set distrainable?
Standalone code to reproduce the issue
simple
def vgg16_encode(vgg_input_img_tensor):
    vgg16_model = VGG16(weights='imagenet', include_top=False)
    vgg_input_img = preprocess_input(vgg_input_img_tensor)
    vgg16_output = vgg16_model.predict(vgg_input_img)
    return vgg16_output

with tf.GradientTape() as tape:
    //use vgg16_encode here
Other info / logs
tree:
File "C:/233/test.py", line 29, in vgg16_encode
vgg16_output = vgg16_model.predict(vgg_input_img)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 1013, in predict
use_multiprocessing=use_multiprocessing)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 498, in predict
workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 475, in _model_iteration
total_epochs=1)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py", line 128, in run_one_epoch
batch_outs = execution_function(iterator)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py", line 98, in execution_function
distributed_function(input_fn))
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 568, in call
result = self._call(*args, **kwds)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\def_function.py", line 638, in _call
return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 1611, in _filtered_call
self.captured_inputs)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 1697, in _call_flat
forward_function, args_with_tangents = forward_backward.forward()
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 1423, in forward
self._inference_args, self._input_tangents)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 1185, in forward
self._forward_and_backward_functions(inference_args, input_tangents))
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 1379, in _forward_and_backward_functions
outputs, inference_args, input_tangents)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py", line 890, in _build_functions_for_outputs
src_graph=self._func_graph)
File "C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\ops\gradients_util.py", line 623, in _GradientsHelper
(op.name, op.type))
LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)
Process finished with exit code 1
	</description>
	<comments>
		<comment id='1' author='fly3366' date='2020-04-21T14:37:15Z'>
		&lt;denchmark-link:https://github.com/fly3366&gt;@fly3366&lt;/denchmark-link&gt;

could you please refer to these issues with similar error:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33135&gt;#33135&lt;/denchmark-link&gt;
 #&lt;denchmark-link:https://www.gitmemory.com/issue/tensorflow/tensorflow/33135/539915524&gt;link1&lt;/denchmark-link&gt;

the code shared is incomplete, please provide with simple standalone code for us to replicate the issue.
		</comment>
		<comment id='2' author='fly3366' date='2020-04-21T15:32:22Z'>
		like this...
import tensorflow as tf
    from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input


    def vgg16_encode(vgg_input_img_tensor):
        vgg16_model = VGG16(weights='imagenet', include_top=False)
        vgg_input_img = preprocess_input(vgg_input_img_tensor)
        vgg16_output = vgg16_model.predict(vgg_input_img)
        return vgg16_output


    with tf.GradientTape() as tape:
        vgg16_encode(tf.Variable(tf.ones([1, 256, 256, 3])))
		</comment>
		<comment id='3' author='fly3366' date='2020-04-22T01:46:39Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='fly3366' date='2020-04-22T05:01:31Z'>
		&lt;denchmark-link:https://github.com/fly3366&gt;@fly3366&lt;/denchmark-link&gt;

i ran the code shared by you and face &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/f89499ad4a9baf36d2c13ac090ef2a70/untitled143.ipynb&gt;this error&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='fly3366' date='2020-04-22T08:31:03Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input


def vgg16_encode(vgg_input_img_tensor):
    vgg16_model = VGG16(weights='imagenet', include_top=False)
    vgg_input_img = preprocess_input(vgg_input_img_tensor)
    vgg16_output = vgg16_model.predict(vgg_input_img)
    return vgg16_output


with tf.GradientTape() as tape:
    vgg16_encode(tf.Variable(tf.ones([1, 256, 256, 3])))
sorry, some spaces may be add when markdown's covert
		</comment>
		<comment id='6' author='fly3366' date='2020-04-22T16:10:29Z'>
		i am able to replicate this issue, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/542e9fd6330a656c7c372befa001c57a/untitled145.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='fly3366' date='2020-04-23T18:36:06Z'>
		&lt;denchmark-link:https://github.com/fly3366&gt;@fly3366&lt;/denchmark-link&gt;
 Please take a look at this issue &lt;denchmark-link:https://stackoverflow.com/questions/50784337/gradients-of-operations-done-in-the-tensorflow-data-dataset-map-function&gt;here&lt;/denchmark-link&gt;
 and I don't think you are using gradient tape the right way and hence the error.
		</comment>
		<comment id='8' author='fly3366' date='2020-04-25T08:07:34Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;

Thanks. Use  solved it.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input


def vgg16_encode(vgg_input_img_tensor):
    vgg16_model = VGG16(weights='imagenet', include_top=False)
    vgg_input_img = preprocess_input(vgg_input_img_tensor)
    vgg16_output = vgg16_model.predict(vgg_input_img)
    return vgg16_output


with tf.GradientTape(watch_accessed_variables=False) as tape:
    vgg16_encode(tf.Variable(tf.ones([1, 256, 256, 3])))
    // Another model
    tape.watch(model.trainable_variables)
&lt;/denchmark-code&gt;

Do you have plan to add some like unwatch(variables)?
Some keras's Application may need disable watching default.
		</comment>
		<comment id='9' author='fly3366' date='2020-04-25T08:07:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38751&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38751&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>