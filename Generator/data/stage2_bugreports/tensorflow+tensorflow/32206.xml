<bug id='32206' author='DocDriven' open_date='2019-09-04T12:14:12Z' closed_time='2020-05-25T12:26:33Z'>
	<summary>tflite: RandomStandardNormal not convertible with pure tensorflow, but works with keras</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): docker
TensorFlow version (use command below): 1.15.0-dev20190821
Python version: 3.6.8

I have an variational autoencoder model utilizing tf.random.normal function. I want to convert it into a tflite model.
I have written code in keras that achieves that. The conversion works and I get reasonable results. However, if I re-write the model with tensorflow-only operations (no keras so to speak), the converter claims that RandomStandardNormal is not available for tflite:
&lt;denchmark-code&gt;2019-09-04 12:04:12.858787: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: RandomStandardNormal
2019-09-04 12:04:12.859104: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 21 operators, 32 arrays (0 quantized)
2019-09-04 12:04:12.859336: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 21 operators, 32 arrays (0 quantized)
2019-09-04 12:04:12.859712: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 9 operators, 21 arrays (0 quantized)
2019-09-04 12:04:12.859823: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 9 operators, 21 arrays (0 quantized)
2019-09-04 12:04:12.859876: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 9 operators, 21 arrays (0 quantized)
2019-09-04 12:04:12.859972: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 320 bytes, theoretical optimal value: 256 bytes.
2019-09-04 12:04:12.860009: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 8592
2019-09-04 12:04:12.860269: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.
Traceback (most recent call last):
  File "/usr/local/bin/toco_from_protos", line 10, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, FULLY_CONNECTED, LOGISTIC, MUL. Here is a list of operators for which you will need custom implementations: RandomStandardNormal.
&lt;/denchmark-code&gt;

This is very confusing, as the keras model used the very same function and it worked. Does keras do something under the hood?

I have created a repo for this &lt;denchmark-link:https://github.com/DocDriven/tflite_tests&gt;HERE&lt;/denchmark-link&gt;
. Steps to reproduce this issue:

Execute python keras_model.py to train and save the keras model
Execute python keras_conversion.py to create the tflite model without errors
Execute python tf_model.py to train, save and freeze the pure tf model
Execute python tf_conversion.py to try the conversion and get the error

	</description>
	<comments>
		<comment id='1' author='DocDriven' date='2019-12-10T06:23:56Z'>
		Hi. I reproduced the same result in TF==1.15 and I found out that the pure TF model conversion succeeded if removing optimization options &amp; adding Flex op options like this:
  converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, inputs, outputs)
  # Uncomment the following two lines show segmentation fault.
  # converter.representative_dataset = representative_dataset_gen
  # converter.optimizations = [tf.lite.Optimize.DEFAULT]

  # TODO(jaeyoo) : Add custom op for RandomStandardNormal
  supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
  supported_ops += [tf.lite.OpsSet.SELECT_TF_OPS]
  converter.target_spec.supported_ops = supported_ops

  tflite_file_name = 'vae_classic.tflite'
  tflite_model = converter.convert()
Could you check it on your side?
		</comment>
		<comment id='2' author='DocDriven' date='2020-05-11T11:26:59Z'>
		&lt;denchmark-link:https://github.com/DocDriven&gt;@DocDriven&lt;/denchmark-link&gt;

Is this still an issue.
		</comment>
		<comment id='3' author='DocDriven' date='2020-05-18T11:44:27Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='4' author='DocDriven' date='2020-05-25T12:26:31Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='5' author='DocDriven' date='2020-05-25T12:26:35Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32206&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32206&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>