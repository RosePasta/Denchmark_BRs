<bug id='42253' author='murdockhou' open_date='2020-08-12T07:13:50Z' closed_time='2020-09-29T00:44:03Z'>
	<summary>Dose quantization aware training support tf.GradientTape() training?</summary>
	<description>
I'm using , and I run below code for quantization aware training, seems that using tf.GradientTape() do nothing when run quantization aware training. Here is useful code which is tensorflow example &lt;denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training_example&gt;code&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;import os
import tensorflow as tf
from tensorflow import keras
import numpy as np

# Load MNIST dataset
# Mine network to download this is too slow, so I download it handly. You can also use this command line:

# mnist = keras.datasets.mnist
# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()

def load_mnist(path):
    with np.load(path, allow_pickle=True) as f:
        x_train, y_train = f['x_train'], f['y_train']
        x_test, y_test = f['x_test'], f['y_test']

        return (x_train, y_train), (x_test, y_test)
(train_images, train_labels), (test_images, test_labels) = load_mnist(path='mnist.npz')

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=1,
  validation_split=0.1,
)

import tensorflow_model_optimization as tfmot

quantize_model = tfmot.quantization.keras.quantize_model

# q_aware stands for for quantization aware.
q_aware_model = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model.summary()
train_images_subset = train_images[0:1000] # out of 60000
train_labels_subset = train_labels[0:1000]
q_aware_model.fit(train_images_subset, train_labels_subset,
                  batch_size=500, epochs=1, validation_split=0.1)
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
&lt;/denchmark-code&gt;

which you will get this output finally:
&lt;denchmark-code&gt;Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer (QuantizeLaye (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
2/2 [==============================] - 0s 98ms/step - loss: 0.1444 - accuracy: 0.9589 - val_loss: 0.1748 - val_accuracy: 0.9800
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.961899995803833
&lt;/denchmark-code&gt;

If using tf.GradientTape() for quant-aware-training (using same model trained before):
&lt;denchmark-code&gt;# q_aware stands for for quantization aware.
q_aware_model2 = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model2.summary()

batch_size = 500
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_subset, train_labels_subset))
train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=False)

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

for epoch in range(1):
    for x, y in train_dataset:
        with tf.GradientTape() as tape:
            preds = q_aware_model2(x)
            loss = loss_fn(y, preds)
        grads = tape.gradient(loss, q_aware_model2.trainable_variables)
        optimizer.apply_gradients(zip(grads, q_aware_model2.trainable_variables))
        
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model2.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
&lt;/denchmark-code&gt;

you will get output like this:
&lt;denchmark-code&gt;Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer_5 (QuantizeLa (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.11349999904632568
&lt;/denchmark-code&gt;

And the q_aware_model2 results is soo smaller than q_aware_model results. By the way, the  q_aware_model2 results is as same as when you did not do tf.GradientTape() training:
&lt;denchmark-code&gt;# q_aware stands for for quantization aware.
q_aware_model2 = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model2.summary()

batch_size = 500
train_dataset = tf.data.Dataset.from_tensor_slices((train_images_subset, train_labels_subset))
train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=False)

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

# for epoch in range(1):
#     for x, y in train_dataset:
#         with tf.GradientTape() as tape:
#             preds = q_aware_model2(x)
#             loss = loss_fn(y, preds)
#         grads = tape.gradient(loss, q_aware_model2.trainable_variables)
#         optimizer.apply_gradients(zip(grads, q_aware_model2.trainable_variables))
        
_, baseline_model_accuracy = model.evaluate(
    test_images, test_labels, verbose=0)

_, q_aware_model_accuracy = q_aware_model2.evaluate(
   test_images, test_labels, verbose=0)

print('Baseline test accuracy:', baseline_model_accuracy)
print('Quant test accuracy:', q_aware_model_accuracy)
&lt;/denchmark-code&gt;

You will get same output as using tf.GradientTape() training. Seems like tf.GradientTape() do nothing when quantization-aware-training:
&lt;denchmark-code&gt;Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
quantize_layer_6 (QuantizeLa (None, 28, 28)            3         
_________________________________________________________________
quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         
_________________________________________________________________
quant_conv2d (QuantizeWrappe (None, 26, 26, 12)        147       
_________________________________________________________________
quant_max_pooling2d (Quantiz (None, 13, 13, 12)        1         
_________________________________________________________________
quant_flatten (QuantizeWrapp (None, 2028)              1         
_________________________________________________________________
quant_dense (QuantizeWrapper (None, 10)                20295     
=================================================================
Total params: 20,448
Trainable params: 20,410
Non-trainable params: 38
_________________________________________________________________
Baseline test accuracy: 0.9613000154495239
Quant test accuracy: 0.11349999904632568
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='murdockhou' date='2020-08-13T02:36:04Z'>
		still need help. Could anyone can fix this?
		</comment>
		<comment id='2' author='murdockhou' date='2020-08-20T08:49:32Z'>
		one week passed, still no answer.
		</comment>
		<comment id='3' author='murdockhou' date='2020-08-20T15:59:49Z'>
		&lt;denchmark-link:https://github.com/murdockhou&gt;@murdockhou&lt;/denchmark-link&gt;
 Sorry for the late response. we are looking into it. Thanks!
		</comment>
		<comment id='4' author='murdockhou' date='2020-09-01T07:45:10Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Any progress?
		</comment>
		<comment id='5' author='murdockhou' date='2020-09-15T02:58:58Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Any progress?
		</comment>
		<comment id='6' author='murdockhou' date='2020-09-25T01:56:02Z'>
		Is there anyone who can solve this? I have waiting for long time.
		</comment>
		<comment id='7' author='murdockhou' date='2020-09-29T00:44:03Z'>
		There is a bug in your code.
Please use preds = q_aware_model2(x, training=True) instead of preds = q_aware_model2(x). Because you are not building the training graph, the gradient tape does not do anything.
For QAT related issues, please file them in the Model Optimization Toolkit &lt;denchmark-link:https://github.com/tensorflow/model-optimization&gt;repo&lt;/denchmark-link&gt;
. We keep a closer tab for MOT related issues there.
		</comment>
		<comment id='8' author='murdockhou' date='2020-09-29T00:44:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42253&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42253&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>