<bug id='18689' author='tranhungnghiep' open_date='2018-04-19T11:32:51Z' closed_time='2018-05-08T20:28:49Z'>
	<summary>[Request] Pre-build support old CPU</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NA
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9.4 (stretch)
CPU model: Intel(R) Xeon(R) CPU E7- 8837  @ 2.67GHz and any "old" CPU
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.7.0
Python version: 3.6.4
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: import tensorflow

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Since version 1.6 prebuilt binaries use AVX instructions, thus TF cannot be used on "old" CPUs. However, many of them are not that old. In fact, I was surprise that my server cannot run TF. I believe many people run into the same problem because those CPUs are popular in many labs at universities.
This is bad because it blocks many potential users/researchers from trying TF and starting using TF. User should not build TF themselves, because building by each user is daunting and resource-wasteful.
So if it is not technically impossible, please provide alternative prebuilt binaries that support old CPUs.
	</description>
	<comments>
		<comment id='1' author='tranhungnghiep' date='2018-04-19T11:58:15Z'>
		You can find unofficial builds from other repo.
		</comment>
		<comment id='2' author='tranhungnghiep' date='2018-04-19T12:07:41Z'>
		&lt;denchmark-link:https://github.com/PaulWang1905&gt;@PaulWang1905&lt;/denchmark-link&gt;
 I should have mentioned that I could not find unofficial prebuilt for neither 1.6 nor 1.7. Moreover, I think this is a legitimate need, thus it should be supported officially.
		</comment>
		<comment id='3' author='tranhungnghiep' date='2018-04-19T18:12:29Z'>
		I am facing the same issue. My recent laptop can run TF without issue but on my desktop computer at the lab, I can't since the CPU is quite old.
Building it is a possibility but honestly, it's quite a complex task...
If you are aware of some repo that provides unofficial Linux builds for old CPU please tell us.
		</comment>
		<comment id='4' author='tranhungnghiep' date='2018-04-20T05:30:40Z'>
		Also please consider document this problem clearer, or make the error message more informative. Currently import tensorflow just exit the program, kills python and says Illegal instruction.
		</comment>
		<comment id='5' author='tranhungnghiep' date='2018-04-20T07:29:05Z'>
		which generation is your microarchitecture?  I build tensorflow, but not for CPU. I can build unofficial builds if you guys really need
		</comment>
		<comment id='6' author='tranhungnghiep' date='2018-04-20T09:56:45Z'>
		&lt;denchmark-link:https://github.com/PaulWang1905&gt;@PaulWang1905&lt;/denchmark-link&gt;
 My CPU is &lt;denchmark-link:https://ark.intel.com/products/53576/Intel-Xeon-Processor-E7-8837-24M-Cache-2_66-GHz-6_40-GTs-Intel-QPI&gt;Intel(R) Xeon(R) CPU E7- 8837&lt;/denchmark-link&gt;
. Detailed information is below. Thanks a lot!

vendor_id       : GenuineIntel
cpu family      : 6
model           : 47
model name      : Intel(R) Xeon(R) CPU E7- 8837  @ 2.67GHz
stepping        : 2
microcode       : 0x36
cpu MHz         : 2659.832
cache size      : 24576 KB
physical id     : 0
siblings        : 8
core id         : 0
cpu cores       : 8
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 11
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good noplxtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt aes lahf_lm kaiser tpr_shadow vnmi flexpriority ept vpid dthermida arat
bugs            : clflush_monitor
bogomips        : 5319.66
clflush size    : 64
cache_alignment : 64
address sizes   : 44 bits physical, 48 bits virtual

		</comment>
		<comment id='7' author='tranhungnghiep' date='2018-04-20T13:40:46Z'>
		Here is mine:
&lt;denchmark-code&gt;vendor_id	: GenuineIntel
cpu family	: 6
model		: 26
model name	: Intel(R) Core(TM) i7 CPU         960  @ 3.20GHz
stepping	: 5
microcode	: 0x19
cpu MHz		: 1652.866
cache size	: 8192 KB
physical id	: 0
siblings	: 8
core id		: 3
cpu cores	: 4
apicid		: 7
initial apicid	: 7
fpu		: yes
fpu_exception	: yes
cpuid level	: 11
wp		: yes
flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti tpr_shadow vnmi flexpriority ept vpid dtherm ida
bugs		: cpu_meltdown spectre_v1 spectre_v2
bogomips	: 6414.75
clflush size	: 64
cache_alignment	: 64
address sizes	: 36 bits physical, 48 bits virtual
power management:

&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='tranhungnghiep' date='2018-04-30T16:04:27Z'>
		Unfortunately we are unable to provide pre-built binaries without AVX. Unofficial third-party builds may be your best option.
		</comment>
		<comment id='9' author='tranhungnghiep' date='2018-05-01T12:29:37Z'>
		Forcing usage of machines with Intel CPU's that contain the AVX instruction is a false move in my opinion. I have been testing other AI platforms and they have no such requirement, Also when one is primarily focusing on GPU acceleration for AI apps the usage of AVX instruction becomes a mute point. This move is making it problematic for many user groups not having access to the latest CPU's for example hobbyists and schools with older hardware. Please consider a AVX free build or me and others will be forced to ditch TensorFlow for another platform.
		</comment>
		<comment id='10' author='tranhungnghiep' date='2018-05-01T21:43:33Z'>
		&lt;denchmark-link:https://github.com/makeandbreak&gt;@makeandbreak&lt;/denchmark-link&gt;

I have some questions to better understand the situation and please anyone response not just makeandbreak:

Do you do training on the older CPUs? and If so what do you train and how long does it take?
What are you doing with TensorFlow on those systems?  (I have a guess I do not want to lead the answer)

We are looking into options.  AVX very much speeds up performance for CPU over SSE, this is also true for AMD processors.  The move was done to improve out of the box performance for CPU users in general as well as those doing inference, which is often done on CPU and gets a large boost from AVX.
This section is not to win you over but you let you know the thought process at a high level.  I looked at the Intel CPU line.  Sandy bridge, which is where AVX started came out, was in 2011.  AWS makes it fairly hard to get non-AVX systems for anything but random web serving and that is still limited.  I suspected many users are using mac book pros and other laptops that are sandy bridge and newer.  AVX provides a significant boost and I wanted to get that to end users.
Finally for this comment, the build matrix is very large because it needs to be supported, e.g. all unit tests need to pass and it should be performance tested.  We want to make a pragmatic decision and your feed back is very helpful.  We do not know what we do not know and I personally want to balance ensuring people can use TensorFlow, with TensorFlow being fast, and the testing workload.
The MKL build from Intel might work but I think they still default to AVX for ops other than those handled by MKL.  We are looking at this option.  It has been almost a year but I did test MKL on AMD Ryzen and it was fine and can be tested again.  Painful to test as at the time and even still now there are not many or any cloud providers with AMD systems, I suspect some schools still have opterons laying around.
		</comment>
		<comment id='11' author='tranhungnghiep' date='2018-05-01T21:46:29Z'>
		Assigning to myself in the short-term until we have a final answer.  If someone has a public build for 1.8 feel free to share in the short-term.  The rub is do you do python 2, 3 both and do you also do mac and windows along with linux.  :-)  The matrix explodes fast.
		</comment>
		<comment id='12' author='tranhungnghiep' date='2018-05-01T23:27:02Z'>
		Why we cannot approach a solution like &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/12541&gt;#12541&lt;/denchmark-link&gt;
?
Update: I cannot find the original mention about intrinsics but there was already another very old issue when AVX was still not enabled.
		</comment>
		<comment id='13' author='tranhungnghiep' date='2018-05-02T10:36:38Z'>
		tfboyd
My main use case is learning the functionality provided in AI tool kits
(TensorFlow being one of them) for specific problem solving scenarios.
As such the data and model sizes are always a subset of the real world cases.
When I have selected a specific toolkit and created the initial data and model
the work will continue on a AVX enabled platforms with also magnificent GPU
resources or we will use cloud computing solutions.
I have not found execution times to be unreasonable for the data and models I use.
Restricting the compiled (none AVX) binaries to Python 3 could be
considered a reasonable limitation as 2 is in depreciation mode.
When is comes to platforms I would assume Windows 10 64bit and Ubuntu 18.04 LTS 64bit
would cover most of the user base on none AVX platforms.
Just to note my 'old' platform is: Intel Core i7 875K, 16 GB DDR3 RAM, NVIDIA GeForce
GTX 1050 Ti 4 GB DDR5
It's base performance has not dissapointed me so far so updating it just for AVX is as
I see it a waste of money. I would need a new CPU, motherboard and possible memory (DDR4)
		</comment>
		<comment id='14' author='tranhungnghiep' date='2018-05-02T10:52:47Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 Thanks for looking into this.
About TF working process, I code up the model on my laptop (AVX). Then test that everything is working well on the CPU server (No AVX, large HDD/RAM, many CPU). Finally run training on a GPU server (shared and scheduled for many experiments).
The alternative build TF on CPU does not need to be fast, just workable is enough.
Pardon me for not knowing much about the building process, but is it possible to change building flags and keep everything else the same?
		</comment>
		<comment id='15' author='tranhungnghiep' date='2018-05-04T12:01:01Z'>
		I'm using a several years old CPU without AVX support and currently forced to stay with TF 1.5 for this reason, so I'm not able to benefit from newer updates and bug fixes.
I've got several options (except buying a whole new computer):

Try to compile latest TF from source (I'm using windows) - I'm working on getting to it, but it seems quite challenging (installing updates would be a complicated procedure as well).
Buy a compatible GPU and skip CPU-based training/prediction altogether (??!).

Question: will tensorflow-gpu work on a processor without AVX? (and if it currently will, will non-AVX systems be guaranteed to be supported for the next few years?)
		</comment>
		<comment id='16' author='tranhungnghiep' date='2018-05-05T09:41:24Z'>
		 users: I've found an &lt;denchmark-link:https://github.com/fo40225/tensorflow-windows-wheel&gt;unofficial wheel repository&lt;/denchmark-link&gt;
 that includes a comprehensive collection (seems to be actively maintained) of pre-compiled binaries for many system combinations, including /// (No AVX) for both CPU and GPU (I've installed the CPU only version and it seems to work fine so far).
Several other repositories, including some MacOS and Linux builds:
&lt;denchmark-link:https://github.com/mind/wheels&gt;https://github.com/mind/wheels&lt;/denchmark-link&gt;
 (not sure if maintained anymore)
&lt;denchmark-link:https://github.com/lakshayg/tensorflow-build&gt;https://github.com/lakshayg/tensorflow-build&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/yaroslavvb/tensorflow-community-wheels/issues&gt;https://github.com/yaroslavvb/tensorflow-community-wheels/issues&lt;/denchmark-link&gt;
 (various community contributed builds but doesn't cover everything)
		</comment>
		<comment id='17' author='tranhungnghiep' date='2018-05-08T13:13:36Z'>
		&lt;denchmark-link:https://github.com/fo40225/tensorflow-windows-wheel&gt;https://github.com/fo40225/tensorflow-windows-wheel&lt;/denchmark-link&gt;
 seems to work. I used
&lt;denchmark-code&gt;pip install tensorflow_gpu-1.8.0-cp36-cp36m-win_amd64.whl
&lt;/denchmark-code&gt;

whl-file local copy downloaded from
&lt;denchmark-code&gt;tensorflow-windows-wheel/1.8.0/py36/GPU/cuda91cudnn71sse2/
&lt;/denchmark-code&gt;

		</comment>
		<comment id='18' author='tranhungnghiep' date='2018-05-08T14:55:12Z'>
		This is really useful information, while words can seem easy at times I want to express that we are working through this for the right solution.  What I am hearing is that it is really important to have a build that works anywhere as there are very likely "many" (hard to quantify but many seems fair) users on 6+ year old hardware and having it just work is very important.    &lt;denchmark-link:https://github.com/tatianashp&gt;@tatianashp&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
    I helped make this choice and I am having second thoughts for sure and I do not like leaving you without a solution.  I do not believe there are huge changes in versions, so I hope you will user a slightly older version while we sort everything out.
		</comment>
		<comment id='19' author='tranhungnghiep' date='2018-05-08T14:56:02Z'>
		Adding &lt;denchmark-link:https://github.com/tatianashp&gt;@tatianashp&lt;/denchmark-link&gt;
  as an owner for visibility.
		</comment>
		<comment id='20' author='tranhungnghiep' date='2018-05-08T15:58:10Z'>
		Thank you for looking into this. Are you guys aware of similar builds for Linux? I know I could compile it myself but that would spare me one day of work...
		</comment>
		<comment id='21' author='tranhungnghiep' date='2018-05-08T20:28:49Z'>
		&lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 I agree that we need a better solution. For now, the only choices for those with old CPUs are to use community supported build, build from source or use an older version of TensorFlow.
&lt;denchmark-link:https://github.com/hadim&gt;@hadim&lt;/denchmark-link&gt;
 Building from source on Linux is not as difficult as it might seem and well documented. Please give a try if nobody from the community volunteers a pre-build wheel. Let us know if you have any questions.
		</comment>
		<comment id='22' author='tranhungnghiep' date='2018-05-08T21:04:34Z'>
		I didn't say it was complicated, just that I would have to spend some time on it while a simple pip install would have been done in a minute :-)
		</comment>
		<comment id='23' author='tranhungnghiep' date='2018-05-08T22:31:51Z'>
		What if a user on linux cannot sudo? Can they compile tf locally?
		</comment>
		<comment id='24' author='tranhungnghiep' date='2018-05-08T22:40:03Z'>
		Userspace compilation should be possible.
		</comment>
		<comment id='25' author='tranhungnghiep' date='2018-05-09T10:20:29Z'>
		I was looking at a few other AI toolkits to see if they require AVX support from the CPU. I could not find this to be the case. For example &lt;denchmark-link:https://www.microsoft.com/en-us/cognitive-toolkit/&gt;https://www.microsoft.com/en-us/cognitive-toolkit/&lt;/denchmark-link&gt;
 (CNTK) latest version works fine on my system.
		</comment>
		<comment id='26' author='tranhungnghiep' date='2018-05-09T11:01:59Z'>
		I think that also pytorch has as &lt;denchmark-link:https://github.com/pytorch/pytorch/issues/4825&gt;SIMD dispatcher&lt;/denchmark-link&gt;
. In the updated TF &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/community/roadmap.md#cpu-optimizations&gt;Roadmap&lt;/denchmark-link&gt;
  we have:

Dynamic loading of SIMD-optimized kernels

That was add on 22th Feb
		</comment>
		<comment id='27' author='tranhungnghiep' date='2018-05-09T18:42:43Z'>
		We also have "MKL for Linux and Windows" in the roadmap. The build will be SSE-based and will use MKL dynamic SIMD dispatch to leverage AVX or AVX2 when it's present. This is likely to happen before dynamic loading of SIMD-optimized kernels.
		</comment>
		<comment id='28' author='tranhungnghiep' date='2018-05-10T23:52:22Z'>
		I would like to ask the same question &lt;denchmark-link:https://github.com/rotemdan&gt;@rotemdan&lt;/denchmark-link&gt;
 asked above i.e.
"will tensorflow-gpu work on a processor without AVX?"
I'm running into the issue where I have a new GPU (gtx 1060) but an old CPU (6+ years old). I'm stuck at TF 1.5. Is there a way to get 1.7 or 1.8 to work?
		</comment>
		<comment id='29' author='tranhungnghiep' date='2018-05-11T00:44:30Z'>
		Yes, you should be able to install from source without trouble, assuming you have the dependencies installed (all called out in the installation guide).
		</comment>
		<comment id='30' author='tranhungnghiep' date='2018-05-16T08:52:01Z'>
		"will tensorflow-gpu work on a processor without AVX?"
I have tested TensorFlow 1.8 GPU on windows and it seems AVX code is in the base code. So in other words no it does not work.
		</comment>
		<comment id='31' author='tranhungnghiep' date='2018-06-02T01:49:13Z'>
		FYI, here is a Docker image that can build TensorFlow &lt;denchmark-link:https://github.com/hadim/docker-tensorflow-builder&gt;https://github.com/hadim/docker-tensorflow-builder&lt;/denchmark-link&gt;
. It can help to compile TF on a wide range of configurations as long as you have Docker installed on it.
		</comment>
		<comment id='32' author='tranhungnghiep' date='2018-06-07T21:32:28Z'>
		Just adding my 2c to the thread... The laptop i use for the initial check of the code before running it on the cloud has ssd and not enough space to build tf. It's uncomplicated build, yes... But huge.
		</comment>
		<comment id='33' author='tranhungnghiep' date='2018-06-21T14:53:56Z'>
		I built Tensorflow 1.8 on a GPU-less Ubuntu box without AVX support. Maybe this wheel is useful for some of you: &lt;denchmark-link:https://github.com/maxhgerlach/tensorflow-1.8.0-ubuntu16.04-py27-no_avx-xeon_x5650&gt;repo&lt;/denchmark-link&gt;

		</comment>
		<comment id='34' author='tranhungnghiep' date='2018-06-21T21:42:35Z'>
		Thank you! I actually did the same a few days ago, with external usb drive. Bazel was not impressed... But, after a short fight, i managed to make a wheel. It's on my github repos. Thank you again for your offer. I still think tf should provide such no strings attached wheel.
		</comment>
		<comment id='35' author='tranhungnghiep' date='2018-09-11T02:13:11Z'>
		If you're not going to support non-AVX, at least improve your checks or errors. "Illegal instruction" in response to "import keras" is not helpful.
		</comment>
		<comment id='36' author='tranhungnghiep' date='2018-09-11T15:36:30Z'>
		
I built Tensorflow 1.8 on a GPU-less Ubuntu box without AVX support. Maybe this wheel is useful for some of you: repo

This worked great on my old xeon E5507. Thanks a bunch!!!!!
		</comment>
		<comment id='37' author='tranhungnghiep' date='2019-02-17T15:16:58Z'>
		Confirming that TF 1.8 CPU build without AVX from &lt;denchmark-link:https://github.com/maxhgerlach&gt;@maxhgerlach&lt;/denchmark-link&gt;
 works on Intel Pentium G4400 (Skylake) without AVX.
		</comment>
		<comment id='38' author='tranhungnghiep' date='2019-12-06T17:46:47Z'>
		I built a Tensorflow 2.0 version running with old CPUs not compatible with AVX instructions nor SSE. See here on my Github : &lt;denchmark-link:https://github.com/Anakeyn/Tensorflow2.0ForOldComputers&gt;https://github.com/Anakeyn/Tensorflow2.0ForOldComputers&lt;/denchmark-link&gt;
.
Rem : this is a Linux version !!! I tested it under Windows 10 WSL Ubuntu 18.04 LTS on a Lenovo PR-G700 with Intel Celeron CPU 1000M 1,80 Ghz (2013 CPU) and directly under Linux Ubuntu 18.04.3 LTS on an HP Pavillon DV6 with Intel Core 2 Duo CPU T6600 2.2 GHz x 2  (2009 CPU) and it works.
		</comment>
		<comment id='39' author='tranhungnghiep' date='2020-04-02T06:10:53Z'>
		
I built a Tensorflow 2.0 version running with old CPUs not compatible with AVX instructions nor SSE. See here on my Github : https://github.com/Anakeyn/Tensorflow2.0ForOldComputers.
Rem : this is a Linux version !!! I tested it under Windows 10 WSL Ubuntu 18.04 LTS on a Lenovo PR-G700 with Intel Celeron CPU 1000M 1,80 Ghz (2013 CPU) and directly under Linux Ubuntu 18.04.3 LTS on an HP Pavillon DV6 with Intel Core 2 Duo CPU T6600 2.2 GHz x 2 (2009 CPU) and it works.

Thank you man! I was trying to update tensorflow with a source build, but accidentally broke my server while trying. So I was trying to find precompiled binaries and I am glad I found yours!
		</comment>
		<comment id='40' author='tranhungnghiep' date='2020-04-02T07:53:46Z'>
		

I built a Tensorflow 2.0 version running with old CPUs not compatible with AVX instructions nor SSE. See here on my Github : https://github.com/Anakeyn/Tensorflow2.0ForOldComputers.
Rem : this is a Linux version !!! I tested it under Windows 10 WSL Ubuntu 18.04 LTS on a Lenovo PR-G700 with Intel Celeron CPU 1000M 1,80 Ghz (2013 CPU) and directly under Linux Ubuntu 18.04.3 LTS on an HP Pavillon DV6 with Intel Core 2 Duo CPU T6600 2.2 GHz x 2 (2009 CPU) and it works.

Thank you man! I was trying to update tensorflow with a source build, but accidentally broke my server while trying. So I was trying to find precompiled binaries and I am glad I found yours!

You're welcome! Thank you for your feedback!
		</comment>
	</comments>
</bug>