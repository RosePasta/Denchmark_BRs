<bug id='40631' author='AakashSasikumar' open_date='2020-06-20T06:47:09Z' closed_time='2020-06-26T14:17:18Z'>
	<summary>@tf.function decorated functions cannot access class varaiables, tf.print() doesn't work</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.5
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0
Python version: 3.6.10
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: -
GPU model and memory: Training on CPU

Describe the current behavior
I am trying to create a Q Learning algorithm using TF2. I have this class variable called memory that keeps increasing in size as training goes on. Inside the @tf.function decorated weight update function, when I print the size of memory, it seems to be always 1 (doesn't seem to increase). Here are the different configurations with which I tried this code,

With tf.compat.v1.disable_eager_execution() and @tf.function decorator

The tf.print() call inside this decorated function doesn't work, so I am not sure if this is actually training the model or not


With only @tf.function decorator,

The tf.print() call inside the decorated function works, but the class variable size is always constant (1).


With only tf.compat.v1.disable_eager_execution(),

The code raises this error TypeError: 'Tensor' object does not support item assignment
I tried to convert the Tensor into a numpy array, but it raises this error 'Tensor' object has no attribute 'numpy'


With neither tf.compat.v1.disable_eager_execution() nor @tf.function decorator,

The code works as expected but is extremely slow (because of the eager execution I presume)



Describe the expected behavior

The @tf.function decorator to be able to handle class variables that change during runtime.
The tf.print() calls to work even when tf.compat.v1.disable_eager_execution() is called

As listed above, method 1 seems to work as there are no errors, but there is no way for me to check whether my model is actually training or not as the tf.print() call doesn't seem to work. Ideally, I want method 1 to work as this is the fastest form of execution that matches the speeds of a similar implementation in TF1.1
Standalone code to reproduce the issue
import tensorflow as tf
from tensorflow import keras
import numpy as np
import random
import tqdm
import yfinance as yf


# tf.compat.v1.disable_eager_execution()
ticker = "AAPL"
df_full = yf.Ticker("{}".format(ticker)).history("max").reset_index()
df = df_full.copy()["Close"]
data = df.copy()


class DQN:
    def __init__(self, data, lookBack=30,
                 gamma=0.95, epsilon=0.5,
                 epsilonMin=0.01, epsilonDecay=0.8,
                 learningRate=0.001, money=10000):
        # NOT IMPORTANT
        self.lookBack = lookBack
        self.initialMoney = money
        self.actionSize = 3

        self.data = data
        self.gamma = gamma
        self.epsilon = epsilon
        self.epsilonMin = epsilonMin
        self.epsilonDecay = epsilonDecay
        self.learningRate = learningRate

        self.memory = []

    def buildModel(self):
        keras.backend.clear_session()
        model = keras.models.Sequential()
        model.add(keras.layers.Dense(256, input_shape=[self.lookBack],
                                     activation="relu"))
        model.add(keras.layers.Dense(self.actionSize))

        self.optimizer = keras.optimizers.RMSprop(lr=self.learningRate,
                                                  epsilon=0.1,
                                                  rho=0.99)
        self.lossFunc = keras.losses.mean_squared_error
        model.compile(loss="mse", optimizer=self.optimizer)
        self.model = model

    def getAction(self, state):
        # NOT IMPORTANT
        if random.random() &lt;= self.epsilon:
            return random.randrange(self.actionSize)
        else:
            return np.argmax(self.model.predict(state)[0])

    def createDataset(self):
        # NOT IMPORTANT
        tmp = self.data.copy()
        tmp = tmp.diff(1).dropna().values
        shape = tmp.shape[:-1] + (tmp.shape[-1] - self.lookBack + 1,
                                  self.lookBack)
        strides = tmp.strides + (tmp.strides[-1],)
        self.dataset = np.lib.stride_tricks.as_strided(tmp, shape=shape,
                                                       strides=strides)

    def getReward(self, action, currentPrice):
        # NOT IMPORTANT
        return 0

    # @tf.function
    def updateWeights(self):
        # IMPORTANT
        tf.print(len(self.memory))
        if len(self.memory) &gt;= self.batchSize:
            endIndex = len(self.memory)
            startIndex = endIndex - self.batchSize
            batchData = []
            for i in range(startIndex, endIndex):
                batchData.append(self.memory[i])
            X = np.zeros((self.batchSize, self.lookBack))
            Y = np.zeros((self.batchSize, self.actionSize))
            states = np.array([item[0] for item in batchData])
            newStates = np.array([item[3] for item in batchData])
            Q = self.model(states)
            QNext = self.model(newStates)
            for i in range(len(batchData)):
                state, action, reward, nextState = batchData[i]
                target = Q[i]
                target[action] = reward
                target[action] += self.gamma * np.max(QNext[i])

                X[i] = state
                Y[i] = target
            self.model.train_on_batch(X, Y)
            if self.epsilon &gt; self.epsilonMin:
                self.epsilon *= self.epsilonDecay

    def train(self, epochs=200, logFreq=1):
        # IMPORTANT
        for epoch in range(epochs):
            self.profit = 0
            self.money = self.initialMoney
            for timeStep in tqdm.tqdm(range(self.lookBack, len(self.data)-1)):
                currentPrice = data[timeStep]
                currentState = self.dataset[timeStep-self.lookBack]
                nextState = self.dataset[timeStep-self.lookBack+1]

                action = self.getAction(currentState.reshape(1, -1))

                reward = self.getReward(action, currentPrice)

                self.memory.append((currentState, action, reward, nextState))

                self.updateWeights()


test = DQN(data)
test.createDataset()
test.buildModel()
test.train(100)
The important functions are marked as so. Please take a look at those functions, all others are just helper functions for reproducibility.
Other info / logs

Entire traceback for method 3,

&lt;denchmark-code&gt;/Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
WARNING:tensorflow:From /Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
  0%|                                                                                                                        | 0/9933 [00:00&lt;?, ?it/s]2020-06-20 12:13:31.271860: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-20 12:13:31.286799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9662abf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-20 12:13:31.286826: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  0%|                                                                                                                        | 0/9933 [00:00&lt;?, ?it/s]
Traceback (most recent call last):
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 122, in &lt;module&gt;
    test.train(100)
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 116, in train
    self.updateWeights()
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 91, in updateWeights
    target[action] = reward
TypeError: 'Tensor' object does not support item assignmenttext
&lt;/denchmark-code&gt;


Entire traceback for method 3 when I try converting the tf.Tensor into a numpy array,

&lt;denchmark-code&gt;/Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.
  warnings.warn(msg)
WARNING:tensorflow:From /Users/aakashsasikumar/.pyenv/versions/3.6.10/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
  0%|                                                                                                                        | 0/9933 [00:00&lt;?, ?it/s]2020-06-20 12:15:24.714805: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-20 12:15:24.728233: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbdd92625a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-20 12:15:24.728260: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
  0%|                                                                                                                        | 0/9933 [00:00&lt;?, ?it/s]
Traceback (most recent call last):
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 122, in &lt;module&gt;
    test.train(100)
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 116, in train
    self.updateWeights()
  File "/Users/aakashsasikumar/Documents/Code/Python/StockMate/Misc/Benchmarks/QLearningAgentTF2.py", line 90, in updateWeights
    target = Q[i].numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='AakashSasikumar' date='2020-06-22T05:12:16Z'>
		&lt;denchmark-link:https://github.com/AakashSasikumar&gt;@AakashSasikumar&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.2 and i am seeing the below error message.().Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/b3ad60005941bf9a96aa5a392c17a23b/untitled50.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='AakashSasikumar' date='2020-06-23T08:34:03Z'>
		Sorry about that. This should fix it.
import tensorflow as tf
from tensorflow import keras
import numpy as np
import random
import tqdm
import yfinance as yf


tf.compat.v1.disable_eager_execution()
ticker = "AAPL"
df_full = yf.Ticker("{}".format(ticker)).history("max").reset_index()
df = df_full.copy()["Close"]
data = df.copy()


class DQN:
    def __init__(self, data, lookBack=30,
                 gamma=0.95, epsilon=0.5,
                 epsilonMin=0.01, epsilonDecay=0.8,
                 learningRate=0.001, money=10000):
        # NOT IMPORTANT
        self.lookBack = lookBack
        self.initialMoney = money
        self.actionSize = 3
        self.batchSize = 32

        self.data = data
        self.gamma = gamma
        self.epsilon = epsilon
        self.epsilonMin = epsilonMin
        self.epsilonDecay = epsilonDecay
        self.learningRate = learningRate

        self.memory = []

    def buildModel(self):
        keras.backend.clear_session()
        model = keras.models.Sequential()
        model.add(keras.layers.Dense(256, input_shape=[self.lookBack],
                                     activation="relu"))
        model.add(keras.layers.Dense(self.actionSize))

        self.optimizer = keras.optimizers.RMSprop(lr=self.learningRate,
                                                  epsilon=0.1,
                                                  rho=0.99)
        self.lossFunc = keras.losses.mean_squared_error
        model.compile(loss="mse", optimizer=self.optimizer)
        self.model = model

    def getAction(self, state):
        # NOT IMPORTANT
        if random.random() &lt;= self.epsilon:
            return random.randrange(self.actionSize)
        else:
            return np.argmax(self.model.predict(state)[0])

    def createDataset(self):
        # NOT IMPORTANT
        tmp = self.data.copy()
        tmp = tmp.diff(1).dropna().values
        shape = tmp.shape[:-1] + (tmp.shape[-1] - self.lookBack + 1,
                                  self.lookBack)
        strides = tmp.strides + (tmp.strides[-1],)
        self.dataset = np.lib.stride_tricks.as_strided(tmp, shape=shape,
                                                       strides=strides)

    def getReward(self, action, currentPrice):
        # NOT IMPORTANT
        return 0

    @tf.function
    def updateWeights(self):
        # IMPORTANT
        tf.print(len(self.memory))
        if len(self.memory) &gt;= self.batchSize:
            endIndex = len(self.memory)
            startIndex = endIndex - self.batchSize
            batchData = []
            for i in range(startIndex, endIndex):
                batchData.append(self.memory[i])
            X = np.zeros((self.batchSize, self.lookBack))
            Y = np.zeros((self.batchSize, self.actionSize))
            states = np.array([item[0] for item in batchData])
            newStates = np.array([item[3] for item in batchData])
            Q = self.model(states)
            QNext = self.model(newStates)
            for i in range(len(batchData)):
                state, action, reward, nextState = batchData[i]
                target = Q[i]
                target[action] = reward
                target[action] += self.gamma * np.max(QNext[i])

                X[i] = state
                Y[i] = target
            self.model.train_on_batch(X, Y)
            if self.epsilon &gt; self.epsilonMin:
                self.epsilon *= self.epsilonDecay

    def train(self, epochs=200, logFreq=1):
        # IMPORTANT
        for epoch in range(epochs):
            self.profit = 0
            self.money = self.initialMoney
            for timeStep in tqdm.tqdm(range(self.lookBack, len(self.data)-1)):
                currentPrice = data[timeStep]
                currentState = self.dataset[timeStep-self.lookBack]
                nextState = self.dataset[timeStep-self.lookBack+1]

                action = self.getAction(currentState.reshape(1, -1))

                reward = self.getReward(action, currentPrice)

                self.memory.append((currentState, action, reward, nextState))

                self.updateWeights()


test = DQN(data)
test.createDataset()
test.buildModel()
test.train(100)
		</comment>
		<comment id='3' author='AakashSasikumar' date='2020-06-23T12:32:55Z'>
		&lt;denchmark-link:https://github.com/AakashSasikumar&gt;@AakashSasikumar&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.2 .Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/45b4bed9448d501d4bb87ba9a00cd37f/untitled55.ipynb&gt;here&lt;/denchmark-link&gt;
.You are also seeing the same behavior?.Thanks!
		</comment>
		<comment id='4' author='AakashSasikumar' date='2020-06-24T12:02:21Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

For 3 out of the 4 methods I am getting the same behavior. But for the second one, where you commented out tf.compat.v1.disable_eager_execution() and left @tf.function as it is, the tf.print() function works. Here is my output,
&lt;denchmark-code&gt;  0%|                                       | 0/9935 [00:00&lt;?, ?it/s]1
  0%|                             | 1/9935 [00:00&lt;1:10:16,  2.36it/s]1
1
1
1
1
1
  0%|                               | 7/9935 [00:00&lt;49:59,  3.31it/s]1
1
1
1
1
1
1
1
1
1
1
1
1
1
  0%|                              | 21/9935 [00:00&lt;35:22,  4.67it/s]1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
  0%|                              | 36/9935 [00:00&lt;25:05,  6.58it/s]1
1
1
1
1
1
1
1
1
1
1
1
  0%|▏                             | 48/9935 [00:00&lt;18:00,  9.15it/s]1
1
1
1
1
1
1
1
1
  1%|▏                             | 57/9935 [00:00&lt;13:10, 12.49it/s]1
1
1
1
1
1
1
1
1
  1%|▏                             | 66/9935 [00:01&lt;09:47, 16.79it/s]

&lt;/denchmark-code&gt;

Also, I stopped the code before it finished, that's why the output is much smaller. In fact, I would suggest you do the same, it doesn't need to train for 100 epochs. When you are running it, just modify the last line from test.train(100) to test.train(5).
Another thing to note is that I am not running this on google colab, I am running it locally in my terminal. Would that make any difference?
		</comment>
		<comment id='5' author='AakashSasikumar' date='2020-06-24T12:12:18Z'>
		Also, here are a few warnings that I get when tensorflow is imported. Not sure if its gonna help, but I'll add it nonetheless.
&lt;denchmark-code&gt;2020-06-24 17:40:15.940898: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-24 17:40:15.952995: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac845b3a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 17:40:15.953014: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='AakashSasikumar' date='2020-06-25T00:16:25Z'>
		Option 2 is definitely the recommended method, you should not need to disable eager execution.
Glancing over the code, a few things that tf.function definitely doesn't work well with, so the output of tf.print is expected:

self.memory is a Python list; you should use a Tensor or RaggedTensor instead
tf.function doesn't monitor class members for retracing; you should instead design updateWeights using a functional style - pass all inputs as arguments, and return all calculated values
mutations, like X[i] = state are still not supported; for this case, I think accumulating the values using a TensorArray is better

I recommend reading this guide to get a better intuition on how tf.function works: &lt;denchmark-link:https://www.tensorflow.org/guide/function&gt;https://www.tensorflow.org/guide/function&lt;/denchmark-link&gt;

The AutoGraph guide also contains a bit more information on how is the tf.function code transformed into a TF graph: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='AakashSasikumar' date='2020-06-25T04:40:29Z'>
		&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;

Thank you, I will take a look into TensorArrays and making updateWeights() functional.
The thing is, Option 1(where eager mode is disabled) is much faster for me, nearly 10 times faster than Option 2. Is it safe for me to assume that Option 1 works just as Option 2 provided the inputs are same? If not, then I would have to go back to using TF1.0, as this is the only other way I'm getting similar speeds as Option 1.
		</comment>
		<comment id='8' author='AakashSasikumar' date='2020-06-25T12:24:05Z'>
		Yes, the expectation is that Option 1 has the same output as Option 2. But without eager execution, Option 1 just builds a graph and never runs it - you should not see any tf.print outputs at all, as you'd need all sorts of control dependencies sessions and initializers boilerplate - which explains the apparent speed-up. Using TF 2 is definitely recommended because it's easier to use and has much better support, and we can still optimize the slow parts with tf.function.
		</comment>
		<comment id='9' author='AakashSasikumar' date='2020-06-26T07:28:44Z'>
		&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;

I think I have a little better understanding of how tf.function works. I looked through some of the documentation and tutorials, but I haven't seen any guide on how to modify a tensor inside a tf.function. I tried converting it into a tf.Variable() but there was an error saying . After some searching around, I realized this was a done to limit the number of variables that are created. But what is the recommended way to manipulate a tensor inside a tf.function.
I modified my code so that the below part is a function decorated with tf.function.
X = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)
Y = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)
with tf.GradientTape() as tape:
    Q = self.model(states)
    QNext = self.model(newStates)
    for i in range(len(states)):
        state, action, reward, _ = states[i], actions[i], rewards[i], newStates[i]
        target = tf.Variable(Q[i], name="temp")
        nextQ = QNext[i][tf.math.argmax(QNext[i])]
        newVal = reward + self.gamma * nextQ
        target[action].assign(newVal)

        X.write(i, state)
        Y.write(i, target)
    loss = self.lossFunc(self.model(X.stack()), Y.stack())
    grads = tape.gradient(loss, self.model.trainable_weights)
    self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))
As you can see above, I want to calculate a value with an output from the model. Do I have to further split these into smaller functions and decorate them with tf.functions?
		</comment>
		<comment id='10' author='AakashSasikumar' date='2020-06-26T13:21:08Z'>
		Modifying tensors is one of the pain points we're currently looking at. Variable is definitely not recommended, because operations on Variable are not differentiable.
In the meantime, I recommend using scatter_nd_update, which would approximately look like this:
&lt;denchmark-code&gt;target = Q[i]
target = tf.tensor_scatter_nd_update(target, [[action]], [newval]])
&lt;/denchmark-code&gt;

This might appear as if it creates unnecessary copies, but the TF runtime can optimize those away.
Another option is to use a local TensorArray, along with unstack(), write(), stack(), but that is not as nice and less efficient, too.
		</comment>
		<comment id='11' author='AakashSasikumar' date='2020-06-26T14:17:10Z'>
		Alright. I think we can go ahead and close this issue now. Thanks a lot
		</comment>
		<comment id='12' author='AakashSasikumar' date='2020-06-26T14:17:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40631&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40631&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>