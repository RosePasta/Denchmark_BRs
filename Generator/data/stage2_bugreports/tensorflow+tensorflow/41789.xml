<bug id='41789' author='davmre' open_date='2020-07-27T21:33:54Z' closed_time='2020-10-08T23:00:08Z'>
	<summary>Error computing gradient of a vectorized scan loop</summary>
	<description>
This code snippet uses tf.scan to compute a sum of squared residuals, wraps it in tf.vectorized_map, and attempts to take the gradient:
import numpy as np
import tensorflow as tf

np.random.seed(seed=42)
data = np.random.randn(100).astype(np.float32)

def log_prob(x):
  return tf.reduce_sum(tf.scan(
      lambda _, yi: (x - yi)**2,
      elems=data,
      initializer=tf.convert_to_tensor(0.),))

x = tf.Variable(tf.random.normal([10]))
v_log_prob = lambda x: tf.vectorized_map(log_prob, x)
with tf.GradientTape() as tape:
  lp = tf.reduce_sum(v_log_prob(x))
g = tape.gradient(lp, x)
I would expect the gradient to be a vector of the same size as x. Instead it raises an exception InvalidArgumentError: Operation 'loop_body/scan/while/pfor/PartitionedCall' has no attr named '_XlaCompile'..
Full stack trace
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2512       with c_api_util.tf_buffer() as buf:
-&gt; 2513         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2514         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'loop_body/scan/while/pfor/PartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
67 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--&gt; 331       xla_compile = op.get_attr("_XlaCompile")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2516       # Convert to ValueError for backwards compatibility.
-&gt; 2517       raise ValueError(str(e))
   2518     x = attr_value_pb2.AttrValue()

ValueError: Operation 'loop_body/scan/while/pfor/PartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2512       with c_api_util.tf_buffer() as buf:
-&gt; 2513         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2514         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'while' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--&gt; 331       xla_compile = op.get_attr("_XlaCompile")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2516       # Convert to ValueError for backwards compatibility.
-&gt; 2517       raise ValueError(str(e))
   2518     x = attr_value_pb2.AttrValue()

ValueError: Operation 'while' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2512       with c_api_util.tf_buffer() as buf:
-&gt; 2513         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2514         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'while/while_body/cond' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--&gt; 331       xla_compile = op.get_attr("_XlaCompile")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2516       # Convert to ValueError for backwards compatibility.
-&gt; 2517       raise ValueError(str(e))
   2518     x = attr_value_pb2.AttrValue()

ValueError: Operation 'while/while_body/cond' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2512       with c_api_util.tf_buffer() as buf:
-&gt; 2513         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2514         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'while/while_body/cond/PartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--&gt; 331       xla_compile = op.get_attr("_XlaCompile")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2516       # Convert to ValueError for backwards compatibility.
-&gt; 2517       raise ValueError(str(e))
   2518     x = attr_value_pb2.AttrValue()

ValueError: Operation 'while/while_body/cond/PartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2512       with c_api_util.tf_buffer() as buf:
-&gt; 2513         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2514         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'loop_body/scan/while/TensorArrayV2Write/TensorListSetItem/pfor/Tile' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    330     try:
--&gt; 331       xla_compile = op.get_attr("_XlaCompile")
    332       xla_separate_compiled_gradients = op.get_attr(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2516       # Convert to ValueError for backwards compatibility.
-&gt; 2517       raise ValueError(str(e))
   2518     x = attr_value_pb2.AttrValue()

ValueError: Operation 'loop_body/scan/while/TensorArrayV2Write/TensorListSetItem/pfor/Tile' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-230-367bca75a1b1&gt; in &lt;module&gt;()
      1 with tf.GradientTape() as tape:
----&gt; 2   lp = v_log_prob(x)
      3 g = tape.gradient(lp, x)

&lt;ipython-input-229-89f89e42229e&gt; in &lt;lambda&gt;(x)
      1 x = tf.Variable(tf.random.normal([10]))
----&gt; 2 v_log_prob = lambda x: tf.vectorized_map(log_prob, x)
      3 print(v_log_prob(x))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in vectorized_map(fn, elems, fallback_to_while_loop)
    448     batch_size = array_ops.shape(first_elem)[0]
    449   return pfor(loop_fn, batch_size,
--&gt; 450               fallback_to_while_loop=fallback_to_while_loop)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/control_flow_ops.py in pfor(loop_fn, iters, fallback_to_while_loop, parallel_iterations)
    202       def_function.run_functions_eagerly(False)
    203     f = def_function.function(f)
--&gt; 204   outputs = f()
    205   if functions_run_eagerly is not None:
    206     def_function.run_functions_eagerly(functions_run_eagerly)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    794       else:
    795         compiler = "nonXla"
--&gt; 796         result = self._call(*args, **kwds)
    797 
    798       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    860               *args, **kwds)
    861       # If we did not create any variables the trace we have is good enough.
--&gt; 862       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    863 
    864     def fn_with_cond(*inner_args, **inner_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs, cancellation_manager)
   1856                            resource_variable_ops.BaseResourceVariable))],
   1857         captured_inputs=self.captured_inputs,
-&gt; 1858         cancellation_manager=cancellation_manager)
   1859 
   1860   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1937         possible_gradient_type,
   1938         executing_eagerly)
-&gt; 1939     forward_function, args_with_tangents = forward_backward.forward()
   1940     if executing_eagerly:
   1941       flat_outputs = forward_function.call(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward(self)
   1442     """Builds or retrieves a forward function for this call."""
   1443     forward_function = self._functions.forward(
-&gt; 1444         self._inference_args, self._input_tangents)
   1445     return forward_function, self._inference_args + self._input_tangents
   1446 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward(self, inference_args, input_tangents)
   1194       (self._forward, self._forward_graph, self._backward,
   1195        self._forwardprop_output_indices, self._num_forwardprop_outputs) = (
-&gt; 1196            self._forward_and_backward_functions(inference_args, input_tangents))
   1197     return self._forward
   1198 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _forward_and_backward_functions(self, inference_args, input_tangents)
   1346     outputs = self._func_graph.outputs[:self._num_inference_outputs]
   1347     return self._build_functions_for_outputs(
-&gt; 1348         outputs, inference_args, input_tangents)
   1349 
   1350 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _build_functions_for_outputs(self, outputs, inference_args, input_tangents)
    904             self._func_graph.inputs,
    905             grad_ys=gradients_wrt_outputs,
--&gt; 906             src_graph=self._func_graph)
    907 
    908       captures_from_forward = [

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr("_XlaScope").decode()
    335     except ValueError:
--&gt; 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in &lt;lambda&gt;()
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _rewrite_forward_and_call_backward(self, op, *doutputs)
    717   def _rewrite_forward_and_call_backward(self, op, *doutputs):
    718     """Add outputs to the forward call and feed them to the grad function."""
--&gt; 719     forward_function, backwards_function = self.forward_backward(len(doutputs))
    720     if not backwards_function.outputs:
    721       return backwards_function.structured_outputs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward_backward(self, num_doutputs)
    626     if forward_backward is not None:
    627       return forward_backward
--&gt; 628     forward, backward = self._construct_forward_backward(num_doutputs)
    629     self._cached_function_pairs[num_doutputs] = (forward, backward)
    630     return forward, backward

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _construct_forward_backward(self, num_doutputs)
    674           args=[], kwargs={},
    675           signature=signature,
--&gt; 676           func_graph=backwards_graph)
    677       backwards_graph_captures = backwards_graph.external_captures
    678       captures_from_forward = [

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _backprop_function(*grad_ys)
    664             self._func_graph.inputs,
    665             grad_ys=grad_ys,
--&gt; 666             src_graph=self._func_graph)
    667 
    668     with self._func_graph.as_default():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr("_XlaScope").decode()
    335     except ValueError:
--&gt; 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in &lt;lambda&gt;()
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py in _WhileGrad(op, *grads)
    352   body_grad_graph, args = _create_grad_func(
    353       ys, xs, non_none_grads, cond_graph, body_graph,
--&gt; 354       util.unique_grad_fn_name(body_graph.name), op, maximum_iterations)
    355 
    356   if body_grad_graph.while_op_needs_rewrite:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py in _create_grad_func(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)
    624       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,
    625                                          maximum_iterations, while_op,
--&gt; 626                                          body_graph_inputs, body_graph_outputs))
    627 
    628   # Update the list of outputs with tensors corresponding to the captured

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py in &lt;lambda&gt;(*args)
    620   grad_func_graph = func_graph_module.func_graph_from_py_func(
    621       name,
--&gt; 622       lambda *args: _grad_fn(ys, xs, args, body_graph),
    623       args, {},
    624       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/while_v2.py in _grad_fn(ys, xs, args, func_graph)
    680   grad_outs = gradients_util._GradientsHelper(
    681       ys, xs, grad_ys=grad_ys, src_graph=func_graph,
--&gt; 682       unconnected_gradients="zero")
    683 
    684   # TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr("_XlaScope").decode()
    335     except ValueError:
--&gt; 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in &lt;lambda&gt;()
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in _IfGrad(op, *grads)
    119   # functions.
    120   true_grad_graph = _create_grad_func(
--&gt; 121       true_graph, grads, util.unique_grad_fn_name(true_graph.name))
    122   false_grad_graph = _create_grad_func(
    123       false_graph, grads, util.unique_grad_fn_name(false_graph.name))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in _create_grad_func(func_graph, grads, name)
    382       name,
    383       lambda: _grad_fn(func_graph, grads), [], {},
--&gt; 384       func_graph=_CondGradFuncGraph(name, func_graph))
    385 
    386 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in &lt;lambda&gt;()
    381   return func_graph_module.func_graph_from_py_func(
    382       name,
--&gt; 383       lambda: _grad_fn(func_graph, grads), [], {},
    384       func_graph=_CondGradFuncGraph(name, func_graph))
    385 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in _grad_fn(func_graph, grads)
    372   result = gradients_util._GradientsHelper(
    373       ys, func_graph.inputs, grad_ys=grad_ys,
--&gt; 374       src_graph=func_graph)
    375 
    376   return result

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr("_XlaScope").decode()
    335     except ValueError:
--&gt; 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in &lt;lambda&gt;()
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _rewrite_forward_and_call_backward(self, op, *doutputs)
    717   def _rewrite_forward_and_call_backward(self, op, *doutputs):
    718     """Add outputs to the forward call and feed them to the grad function."""
--&gt; 719     forward_function, backwards_function = self.forward_backward(len(doutputs))
    720     if not backwards_function.outputs:
    721       return backwards_function.structured_outputs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in forward_backward(self, num_doutputs)
    626     if forward_backward is not None:
    627       return forward_backward
--&gt; 628     forward, backward = self._construct_forward_backward(num_doutputs)
    629     self._cached_function_pairs[num_doutputs] = (forward, backward)
    630     return forward, backward

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _construct_forward_backward(self, num_doutputs)
    674           args=[], kwargs={},
    675           signature=signature,
--&gt; 676           func_graph=backwards_graph)
    677       backwards_graph_captures = backwards_graph.external_captures
    678       captures_from_forward = [

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _backprop_function(*grad_ys)
    664             self._func_graph.inputs,
    665             grad_ys=grad_ys,
--&gt; 666             src_graph=self._func_graph)
    667 
    668     with self._func_graph.as_default():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in _MaybeCompile(scope, op, func, grad_fn)
    334       xla_scope = op.get_attr("_XlaScope").decode()
    335     except ValueError:
--&gt; 336       return grad_fn()  # Exit early
    337 
    338   if not xla_compile:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py in &lt;lambda&gt;()
    681                 # functions.
    682                 in_grads = _MaybeCompile(grad_scope, op, func_call,
--&gt; 683                                          lambda: grad_fn(op, *out_grads))
    684               else:
    685                 # For function call ops, we add a 'SymbolicGradient'

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py in _TileGrad(op, grad)
    827         grad.values, math_ops.mod(grad.indices, input_shape_0), input_shape_0)
    828     split_shape = array_ops.concat([[1], split_shape[1:]], axis=0)
--&gt; 829   input_grad = math_ops.reduce_sum(array_ops.reshape(grad, split_shape), axes)
    830   # Fix shape inference
    831   if not context.executing_eagerly():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """Call target, and fall back on dispatchers if there is a TypeError."""
    200     try:
--&gt; 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in reduce_sum(input_tensor, axis, keepdims, name)
   2001 
   2002   return reduce_sum_with_dims(input_tensor, axis, keepdims, name,
-&gt; 2003                               _ReductionDims(input_tensor, axis))
   2004 
   2005 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py in reduce_sum_with_dims(input_tensor, axis, keepdims, name, dims)
   2012   return _may_reduce_to_scalar(
   2013       keepdims, axis,
-&gt; 2014       gen_math_ops._sum(input_tensor, dims, keepdims, name=name))
   2015 
   2016 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in _sum(input, axis, keep_dims, name)
  10537   _, _, _op, _outputs = _op_def_library._apply_op_helper(
  10538         "Sum", input=input, reduction_indices=axis, keep_dims=keep_dims,
&gt; 10539                name=name)
  10540   _result = _outputs[:]
  10541   if _execute.must_record_gradient():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    607             _SatisfiesTypeConstraint(base_type,
    608                                      _Attr(op_def, input_arg.type_attr),
--&gt; 609                                      param_name=input_name)
    610           attrs[input_arg.type_attr] = attr_value
    611           inferred_from[input_arg.type_attr] = input_name

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py in _SatisfiesTypeConstraint(dtype, attr_def, param_name)
     59           "allowed values: %s" %
     60           (param_name, dtypes.as_dtype(dtype).name,
---&gt; 61            ", ".join(dtypes.as_dtype(x).name for x in allowed_list)))
     62 
     63 

TypeError: Value passed to parameter 'input' has DataType variant not in list of allowed values: float32, float64, int32, uint8, int16, int8, complex64, int64, qint8, quint8, qint32, bfloat16, uint16, complex128, float16, uint32, uint64


Here's a colab notebook reproducing the issue with the current tf nightly:
&lt;denchmark-link:https://colab.sandbox.google.com/drive/14ytDF-74jvDYtJXff0IktJLBin_BuKYJ#scrollTo=GvZjAFbX_-Un&gt;https://colab.sandbox.google.com/drive/14ytDF-74jvDYtJXff0IktJLBin_BuKYJ#scrollTo=GvZjAFbX_-Un&lt;/denchmark-link&gt;

Ashish, any idea where this might be coming from?
	</description>
	<comments>
		<comment id='1' author='davmre' date='2020-07-28T11:20:00Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/00a5a6362cb18c09336d2369af70b4f1/41789-2-3.ipynb&gt;TF v2.3&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/4deafc99c656bbb30e95e48af55bd2f5/41789-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
.
Whereas, running the code with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/1a4b9e46d97c471cfd0390f83761d0ac/41789-2-2.ipynb#scrollTo=B8GR_KaP1brK&gt;TF v2.2&lt;/denchmark-link&gt;
 throws an error stating 
Please find the attached gist. Thanks!
		</comment>
		<comment id='2' author='davmre' date='2020-07-28T12:45:38Z'>
		Hello &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;

Thanks for testing this!
I remembered that I also encountered this  error using TF v2.2 and solved it using discussions in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17702&gt;#17702&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://colab.research.google.com/drive/1X7IJi78VRx-wvg74lVWpMjmi4zrGAznq?usp=sharing&gt;Colab notebook&lt;/denchmark-link&gt;
. But resolving  issue resulted in many other errors.
		</comment>
		<comment id='3' author='davmre' date='2020-09-20T04:24:28Z'>
		I have checked the code snippet with latest  tensorflow version and still I am getting the same error message. Any updates on this &lt;denchmark-link:https://github.com/agarwal-ashish&gt;@agarwal-ashish&lt;/denchmark-link&gt;
 . Thanks
		</comment>
		<comment id='4' author='davmre' date='2020-10-08T23:00:08Z'>
		Thank you for the report. Should be fixed with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/e01adec56da68c9335bb9a7736c82b0f66ddcc43&gt;e01adec&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='davmre' date='2020-10-08T23:00:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41789&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41789&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>