<bug id='29879' author='durandg12' open_date='2019-06-17T16:36:21Z' closed_time='2020-08-09T19:50:07Z'>
	<summary>SequenceFeatures layer requires a SparseTensor... only to convert it to a regular Tensor</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
TensorFlow installed from (source or binary): from pip install
TensorFlow version (use command below): v1.12.1-3259-gf59745a381 2.0.0-beta0
Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

Describe the current behavior
When I call a SequenceFeatures layer on a dense tensor, like a tensor produced with numpy, a TypeError is raised because SequenceFeatures call method expects a SparseTensor as input. When looking at the log it appears that the function producing the TypeError is sparse_tensor_to_dense. So, SequenceFeatures does expect a SparseTensor, only to convert it to a dense Tensor, and fails if given a Tensor that is already dense.
Describe the expected behavior
I think SequenceFeatures call should accepts dense Tensor objects and just don't try to convert them from sparse to dense.
Code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.feature_column import sequence_numeric_column
from tensorflow.keras.experimental import SequenceFeatures

#print(tf.version.GIT_VERSION, tf.version.VERSION)

seq_fc = sequence_numeric_column('feature1')
seq_layer = SequenceFeatures(seq_fc)

batch_size, sequence_length = 3, 5
raw_data = np.array(range(batch_size * sequence_length), dtype=np.float32)
data = np.reshape(raw_data, (batch_size, sequence_length))

dict_data = {'feature1': data}
seq_layer(dict_data)
&lt;/denchmark-code&gt;

This produces the following error log:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-5-aa46f578fa6e&gt; in &lt;module&gt;
      1 dict_data = {'feature1': data}
----&gt; 2 seq_layer(dict_data)

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    710           with base_layer_utils.autocast_context_manager(
    711               input_list, self._mixed_precision_policy.should_cast_variables):
--&gt; 712             outputs = self.call(inputs, *args, **kwargs)
    713           self._handle_activity_regularization(inputs, outputs)
    714           self._set_mask_metadata(inputs, outputs, input_masks)

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/sequence_feature_column.py in call(self, features)
    138       with ops.name_scope(column.name):
    139         dense_tensor, sequence_length = column.get_sequence_dense_tensor(
--&gt; 140             transformation_cache, self._state_manager)
    141         # Flattens the final dimension to produce a 3D Tensor.
    142         output_tensors.append(self._process_dense_tensor(column, dense_tensor))

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/feature_column/sequence_feature_column.py in get_sequence_dense_tensor(self, transformation_cache, state_manager)
    553     sp_tensor = transformation_cache.get(self, state_manager)
    554     dense_tensor = sparse_ops.sparse_tensor_to_dense(
--&gt; 555         sp_tensor, default_value=self.default_value)
    556     # Reshape into [batch_size, T, variable_shape].
    557     dense_shape = array_ops.concat(

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in sparse_tensor_to_dense(sp_input, default_value, validate_indices, name)
   1447     TypeError: If `sp_input` is not a `SparseTensor`.
   1448   """
-&gt; 1449   sp_input = _convert_to_sparse_tensor(sp_input)
   1450 
   1451   return gen_sparse_ops.sparse_to_dense(

~/Documents/tf2beta/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py in _convert_to_sparse_tensor(sp_input)
     66     return sparse_tensor.SparseTensor.from_value(sp_input)
     67   if not isinstance(sp_input, sparse_tensor.SparseTensor):
---&gt; 68     raise TypeError("Input must be a SparseTensor.")
     69   return sp_input
     70 

TypeError: Input must be a SparseTensor.
&lt;/denchmark-code&gt;

Workaround
Converting the input to sparse before calling SequenceFeatures does make the code work:
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.feature_column import sequence_numeric_column
from tensorflow.keras.experimental import SequenceFeatures

#print(tf.version.GIT_VERSION, tf.version.VERSION)

seq_fc = sequence_numeric_column('feature1')
seq_layer = SequenceFeatures(seq_fc)

batch_size, sequence_length = 3, 5
raw_data = np.array(range(batch_size * sequence_length), dtype=np.float32)
data = np.reshape(raw_data, (batch_size, sequence_length))

#####
# convert the input tensor in a sparse tensor
zero = tf.constant(0, dtype=tf.float32)
where = tf.not_equal(data, zero)
indices = tf.where(where)
values = tf.gather_nd(data, indices)
sparse = tf.SparseTensor(indices, values, data.shape)
dict_data_but_sparse = {'feature1': sparse}
#####

seq_layer(dict_data_but_sparse)
&lt;/denchmark-code&gt;

correctly outputs the following:
&lt;denchmark-code&gt;(&lt;tf.Tensor: id=367, shape=(3, 5, 1), dtype=float32, numpy=
 array([[[ 0.],
         [ 1.],
         [ 2.],
         [ 3.],
         [ 4.]],
 
        [[ 5.],
         [ 6.],
         [ 7.],
         [ 8.],
         [ 9.]],
 
        [[10.],
         [11.],
         [12.],
         [13.],
         [14.]]], dtype=float32)&gt;,
 &lt;tf.Tensor: id=355, shape=(3,), dtype=int64, numpy=array([5, 5, 5])&gt;)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='durandg12' date='2019-06-19T12:33:30Z'>
		I have tried  on colab with TF version 2.0 beta and was able to reproduce the issue.
		</comment>
		<comment id='2' author='durandg12' date='2019-06-22T00:10:12Z'>
		I looked at this a little but and this particular conversion is indeed simply to eliminate. I am not at all sure we're not requiring sparsity elsewhere in the sequence feature columns though. &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 would know better.
		</comment>
		<comment id='3' author='durandg12' date='2019-10-01T17:18:29Z'>
		The issue is still here in tf2.0.0 and it keeps needing to add unnecessary operations in my models. I use the new tf.sparse_to_dense as a workaround now but in the end it is almost the same as before.
		</comment>
		<comment id='4' author='durandg12' date='2020-03-06T20:16:15Z'>
		&lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 Any update on this?  The issue persists in 2.2.0-dev20200306.  Many thanks.
		</comment>
		<comment id='5' author='durandg12' date='2020-04-04T13:37:50Z'>
		This could probably be fixed by not converting a dense tensor, and also needs to update how to get sequence_length from a dense tensor (tf.shape(input_tensor)[1])
		</comment>
		<comment id='6' author='durandg12' date='2020-05-09T15:48:11Z'>
		Not a fix but to avoid some code, you may with to use the  from  math library, which ultimately achieves the same thing as the work around suggested by &lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
.
Continuing from the Workaround example above:
&lt;denchmark-code&gt;import tensorflow_probability as tfp
print(tfp.math.dense_to_sparse(data))
&lt;/denchmark-code&gt;

or easier still, from tensorflow itself:
&lt;denchmark-code&gt;print(tf.sparse.from_dense(data))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='durandg12' date='2020-08-09T18:06:54Z'>
		I am able to replicate the issue on tf-nightly(2.4.0-dev20200809), please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/57ce89aa46458594e15178ab4c10349f/untitled345.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='8' author='durandg12' date='2020-08-09T19:50:07Z'>
		We'd encourage you to try &lt;denchmark-link:https://github.com/tensorflow/community/blob/master/rfcs/20191212-keras-categorical-inputs.md#workflow-1----official-guide-on-how-to-replace-feature-columns-with-kpl&gt;Keras Preprocessing Layers&lt;/denchmark-link&gt;
. Feel free to re-open this issue if this doesn't work.
We will try to deprecated SequenceFeatures (given it's experimental and it literally doesn't work well with Keras)
		</comment>
		<comment id='9' author='durandg12' date='2020-08-09T19:50:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29879&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29879&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>