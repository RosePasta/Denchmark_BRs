<bug id='14018' author='sugeeth14' open_date='2017-10-27T06:35:38Z' closed_time='2020-02-24T00:32:19Z'>
	<summary>Tutorial request for hybrid model (word+character)</summary>
	<description>
The implementation done in the paper:
&lt;denchmark-link:http://aclweb.org/anthology/P/P16/P16-1100.pdf&gt;http://aclweb.org/anthology/P/P16/P16-1100.pdf&lt;/denchmark-link&gt;

is a hybrid seq2seq model with advancements where the encoder is fed with inputs based on following two cases:
1.Normal vector representation of a word (Embedding vector) - when the word input is present in the vocabulary
2.Output of another LSTM network - when the word is out of vocabulary and a separate character based LSTM is used to generate an embedding on the fly
Consider the following example sentence:
"The brown fox jumped over the lazy dog"
Assume these are the words present in the vocabulary: The, brown, jumped, over, dog - These words are fed to the seq2seq encoder as such
out of vocabulary(OOV) words are: fox, lazy - These words are passed to a character LSTM and the output of the same is passed to the seq2seq model along with the above words
These both word level and character level encoder needs to be trained end to end simultaneously.
Since the implementation is a bit different from the normal seq2seq can a tutorial or example of such case be added to the examples section?
	</description>
	<comments>
		<comment id='1' author='sugeeth14' date='2017-10-27T17:46:45Z'>
		&lt;denchmark-link:https://github.com/wolffg&gt;@wolffg&lt;/denchmark-link&gt;
 FYI
		</comment>
		<comment id='2' author='sugeeth14' date='2017-11-06T21:38:21Z'>
		second!
I'm trying to implement this model in tf, ( &lt;denchmark-link:https://arxiv.org/abs/1606.01700&gt;https://arxiv.org/abs/1606.01700&lt;/denchmark-link&gt;
 ) which receives the same word at the word and character level to a lookup table and bidirectional LSTM (respectively), the output of both is then concatenated using a "gate" function before sending the imbedding to another LSTM.
Their Theano source-code is here: &lt;denchmark-link:https://github.com/&gt;https://github.com/&lt;/denchmark-link&gt;
 nyu-dl/gated_word_char_rlm.
		</comment>
		<comment id='3' author='sugeeth14' date='2018-01-04T19:26:01Z'>
		&lt;denchmark-link:https://github.com/nealwu&gt;@nealwu&lt;/denchmark-link&gt;
 maybe a good suggestion for the model garden?
		</comment>
		<comment id='4' author='sugeeth14' date='2018-01-04T22:55:59Z'>
		Thanks, we'll keep this in mind.
		</comment>
		<comment id='5' author='sugeeth14' date='2018-08-24T21:42:43Z'>
		Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the contributions welcome label. Thank you.
		</comment>
		<comment id='6' author='sugeeth14' date='2019-01-27T18:31:40Z'>
		Hi &lt;denchmark-link:https://github.com/MarkDaoust&gt;@MarkDaoust&lt;/denchmark-link&gt;
  is this issue being worked on or can I give it a try? Thanks
		</comment>
		<comment id='7' author='sugeeth14' date='2020-02-24T00:32:29Z'>
		It has been 29 days that this pull-request has stalled. Please create a new pull-request with the requested changes.
		</comment>
	</comments>
</bug>