<bug id='39647' author='deshiyan1010' open_date='2020-05-18T11:45:26Z' closed_time='2020-06-01T14:10:56Z'>
	<summary>FailedPreconditionError:  Error while reading resource variable _AnonymousVar878 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar878/N10tensorflow3VarE does not exist. 	 [[node mul_584/ReadVariableOp (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_34197]</summary>
	<description>
I'm getting this error and I'm not able to debug it. This is the complete code of CGAN.
&lt;denchmark-code&gt;from __future__ import print_function, division
from keras.datasets import mnist
from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply
from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import UpSampling2D, Conv2D,Conv2DTranspose
from keras.models import Sequential, Model
from keras.optimizers import Adam
from keras.layers import concatenate
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

class CGAN():
    def __init__(self):
        # Input shape
        self.img_rows = 28
        self.img_cols = 28
        self.channels = 1
        self.img_shape = (self.img_rows, self.img_cols, self.channels)
        self.num_classes = 10
        self.latent_dim = 100

        optimizer = Adam(0.0002, 0.5)

    # Build and compile the discriminator
        self.discriminator = self.build_discriminator()
        self.discriminator.compile(loss=['binary_crossentropy'],
            optimizer=optimizer,
            metrics=['accuracy'])

    # Build the generator
        self.generator = self.build_generator()

    # The generator takes noise and the target label as input
    # and generates the corresponding digit of that label
        noise = Input(shape=(self.latent_dim,))
        label = Input(shape=(10,))
        img = self.generator([noise, label])

    # For the combined model we will only train the generator
        self.discriminator.trainable = False

    # The discriminator takes generated image as input and determines validity
    # and the label of that image
        valid = self.discriminator([img, label])

    # The combined model  (stacked generator and discriminator)
    # Trains generator to fool discriminator
        self.combined = Model([noise, label], valid)
        self.combined.compile(loss=['binary_crossentropy'],
        optimizer=optimizer)

    def build_generator(self):
      image_resize = self.img_rows // 4
  # network parameters
      kernel_size = 5
      layer_filters = [128, 64, 32, 1]

      inputs = Input(shape=(self.latent_dim,))
      x = inputs
      labels = Input(shape=(10,))

      x  = concatenate([inputs, labels], axis=1)
      x = Dense(image_resize * image_resize * layer_filters[0])(x)
      x = Reshape((image_resize, image_resize, layer_filters[0]))(x)

      for filters in layer_filters:
    # first two convolution layers use strides = 2
    # the last two use strides = 1
          if filters &gt; layer_filters[-2]:
              strides = 2
          else:
              strides = 1
          x = BatchNormalization()(x)
          x = Activation('relu')(x)
          x = Conv2DTranspose(filters=filters,
                              kernel_size=kernel_size,
                             strides=strides,
                             padding='same')(x)

      x = Activation('sigmoid')(x)
 
      return Model([inputs, labels], x, name='generator')


    def build_discriminator(self):
      kernel_size = 5
     layer_filters = [32, 64, 128, 256]

      inputs = Input(shape=(self.img_rows,self.img_rows,1))
      x = inputs
      labels = Input(shape=(10,))
      y = Dense(self.img_rows * self.img_rows)(labels)
      y = Reshape((self.img_rows, self.img_rows, 1))(y)
      x = concatenate([x, y])

      for filters in layer_filters:
    # first 3 convolution layers use strides = 2
    # last one uses strides = 1
        if filters == layer_filters[-1]:
          strides = 1
        else:
          strides = 2
        x = LeakyReLU(alpha=0.2)(x)
        x = Conv2D(filters=filters,
                kernel_size=kernel_size,
                strides=strides,
                padding='same')(x)

      x = Flatten()(x)
      x = Dense(1)(x)
      x = Activation('sigmoid')(x)
 
      return Model([inputs, labels], x, name='discriminator')


    def train(self, epochs, batch_size=128, sample_interval=50):

    # Load the dataset
        (X_train, y_train), (_, _) = mnist.load_data()

    # Configure input
        X_train = (X_train.astype(np.float32) - 127.5) / 127.5
        X_train = np.expand_dims(X_train, axis=3)
        #y_train = to_categorical(y_train)
    

    # Adversarial ground truths
        valid = np.ones((batch_size, 1))
        fake = np.zeros((batch_size, 1))

        for epoch in range(epochs):

        # ---------------------
        #  Train Discriminator
        # ---------------------

        # Select a random half batch of images
            idx = np.random.randint(0, X_train.shape[0], batch_size)
            imgs, labels = X_train[idx], y_train[idx]
            labels = to_categorical(labels)
        # Sample noise as generator input
            noise = np.random.normal(0, 1, (batch_size, 100))

        # Generate a half batch of new images
            gen_imgs = self.generator.predict([noise, labels])

        # Train the discriminator
            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)
            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # ---------------------
        #  Train Generator
        # ---------------------

        # Condition on labels
            sampled_labels = to_categorical(np.random.randint(0, 10, batch_size).reshape(-1, 1))

        # Train the generator
            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)

        # Plot the progress
            print ("%d [D loss: %f, acc.: %.2f%%] [G loss: %f]" % (epoch, d_loss[0], 100*d_loss[1], g_loss))

        # If at save interval =&gt; save generated image samples
        #if epoch % sample_interval == 0:
         #   self.sample_images(epoch)

''' def sample_images(self, epoch):
    r, c = 2, 5
    noise = np.random.normal(0, 1, (r * c, 100))
    sampled_labels = to_categorical(np.arange(0, 10).reshape(-1, 1))

    gen_imgs = self.generator.predict([noise, sampled_labels])

    # Rescale images 0 - 1
    gen_imgs = 0.5 * gen_imgs + 0.5

    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')
            axs[i,j].set_title("Digit: %d" % sampled_labels[cnt])
            axs[i,j].axis('off')
            cnt += 1
    fig.savefig("images/%d.png" % epoch)
    plt.close() '''


if __name__ == '__main__':
    cgan = CGAN()
    cgan.train(epochs=20000, batch_size=32, sample_interval=200)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='deshiyan1010' date='2020-05-18T12:54:54Z'>
		&lt;denchmark-link:https://github.com/deshiyan1010&gt;@deshiyan1010&lt;/denchmark-link&gt;

In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here.
Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.
We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!
		</comment>
		<comment id='2' author='deshiyan1010' date='2020-05-25T13:26:25Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='deshiyan1010' date='2020-06-01T14:10:54Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='4' author='deshiyan1010' date='2020-06-01T14:10:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39647&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39647&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='deshiyan1010' date='2020-06-09T14:05:05Z'>
		any solution ??
		</comment>
	</comments>
</bug>