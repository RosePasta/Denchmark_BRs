<bug id='44788' author='thierryherrmann' open_date='2020-11-12T01:11:17Z' closed_time='2020-12-11T15:39:52Z'>
	<summary>bad shape of index returned by UniqueWithCountsV2 in graph mode</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2.0
Python version: 3.6.9
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
The index returned by tf.raw_ops.UniqueWithCountsV2 does not have the right shape when used in graph mode.
Describe the expected behavior
The index returned by tf.raw_ops.UniqueWithCountsV2 should have the right shape when used iin graph mode.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Here's some simple code to illustrate the problem:
import tensorflow as tf

# The same function: decorated with tf.function (will be executed in graph mode) and 
# not decorated (will be executed in eager mode)

@tf.function
def graph_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

def eager_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

c = tf.constant([[0,0,1], 
                 [0,0,1], 
                 [0,0,2], 
                 [0,0,1]])
_ = graph_func(c)
_ = eager_func(c)
Prints this:
&lt;denchmark-code&gt;idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
&lt;/denchmark-code&gt;

The first output doesn’t make sense. The shape doesn’t even match the printed tensor.
Investigating further with a dataset:
ds = tf.data.Dataset.from_tensor_slices(c).repeat(40).batch(4)
_ = graph_func(next(iter(ds)))
_ = eager_func(next(iter(ds)))
Prints this:
&lt;denchmark-code&gt;idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
&lt;/denchmark-code&gt;

graph_func is executed in graph mode. The behavior is still unexpect (shape [4 3] instead of [4]).
But if we the data comes from the dataset through a map function for example (both functions are executed in graph mode), it works as expected:
&lt;denchmark-code&gt;_ = next(iter(ds.map(graph_func)))
_ = next(iter(ds.map(eager_func)))
&lt;/denchmark-code&gt;

This time, prints the expected result:
&lt;denchmark-code&gt;idx shape [4] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='thierryherrmann' date='2020-11-12T14:34:13Z'>
		The following is a possible workaround:
@tf.function
def graph_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    idx = tf.reshape(idx, [-1])   # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
    idx = idx[:tf.shape(x)[0]]    # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

_ = graph_func(c)
&lt;denchmark-code&gt;idx shape [4] idx [0 0 1 0]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='thierryherrmann' date='2020-11-12T16:52:58Z'>
		Was able to reproduce the issue with TF v2.2, 2.3 and nightly versions. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/8868ab137c4c82e5ca07c08ee4802198/44788.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='thierryherrmann' date='2020-12-11T15:39:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44788&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44788&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>