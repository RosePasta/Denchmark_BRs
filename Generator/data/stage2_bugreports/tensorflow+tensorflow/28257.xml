<bug id='28257' author='BelieveOP5' open_date='2019-04-29T11:44:27Z' closed_time='2019-05-06T18:06:19Z'>
	<summary>tf.py_function doesn't calculate output shape correctly when using in dataset.map</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac os mojave
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.6.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: no
GPU model and memory: no

&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

# The tuples are unpacked into the positional arguments of the mapped function
def load_and_preprocess_from_path_label(path, label):
    
    print(path)
    print(label)

    target = np.ndarray((2, 128, 128)).astype('float32')
    label = np.ndarray((128, 128)).astype('float32')
    
    return target, label

inputs_list = sorted(['{:05d}.npy'.format(i) for i in range(50)])
targets_list = sorted(['{:05d}.npy'.format(i) for i in range(50)])

ds = tf.data.Dataset.from_tensor_slices((inputs_list, targets_list))
image_label_ds = ds.map(
    load_and_preprocess_from_path_label,
#     lambda single_input, single_target: tuple(
#         tf.py_function(
#             load_and_preprocess_from_path_label,
#             [single_input, single_target],
#             [tf.float32, tf.float32])
#     ),
)
image_label_ds = image_label_ds.batch(2)
print(image_label_ds)

devices = ['/device:CPU:0']
strategy = tf.distribute.MirroredStrategy(devices)

with strategy.scope():
    image_label_ds_iterator = strategy.make_dataset_iterator(image_label_ds)

&lt;/denchmark-code&gt;

there is my code above, you can run it directly in jupyter.
when using py_function, the dataset.map function can't calculate output image shape correctly, which will be using in mirrored strategy distribution, and it throw out an error, which i think is caused by last problem.
&lt;denchmark-code&gt;&lt;BatchDataset shapes: (&lt;unknown&gt;, &lt;unknown&gt;), types: (tf.float32, tf.float32)&gt;

ValueError                                Traceback (most recent call last)
&lt;ipython-input-35-f6c2c4912d88&gt; in &lt;module&gt;
     33 
     34 with strategy.scope():
---&gt; 35     image_label_ds_iterator = strategy.make_dataset_iterator(image_label_ds)

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py in make_dataset_iterator(self, dataset)
    355       computation.  User should call `initialize` on the returned iterator.
    356     """
--&gt; 357     return self._extended._make_dataset_iterator(dataset)  # pylint: disable=protected-access
    358 
    359   def make_input_fn_iterator(self,

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/mirrored_strategy.py in _make_dataset_iterator(self, dataset)
    569   def _make_dataset_iterator(self, dataset):
    570     return input_lib.DatasetIterator(
--&gt; 571         dataset, self._input_workers, self._num_replicas_in_sync)
    572 
    573   def _make_input_fn_iterator(

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in __init__(self, dataset, input_workers, split_batch_by)
    247     assert isinstance(input_workers, InputWorkers)
    248     if split_batch_by:
--&gt; 249       dataset = batching._RebatchDataset(dataset, split_batch_by)  # pylint: disable=protected-access
    250 
    251     iterators = []

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/batching.py in __init__(self, input_dataset, num_workers)
    747     input_shapes = dataset_ops.get_legacy_output_shapes(self._input_dataset)
    748     input_classes = dataset_ops.get_legacy_output_classes(self._input_dataset)
--&gt; 749     output_shapes = nest.map_structure(recalculate_output_shapes, input_shapes)
    750 
    751     self._structure = structure.convert_legacy_structure(

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py in map_structure(func, *structure, **check_types_dict)
    245 
    246   return pack_sequence_as(
--&gt; 247       structure[0], [func(*x) for x in entries])
    248 
    249 

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/util/nest.py in &lt;listcomp&gt;(.0)
    245 
    246   return pack_sequence_as(
--&gt; 247       structure[0], [func(*x) for x in entries])
    248 
    249 

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/data/experimental/ops/batching.py in recalculate_output_shapes(output_shapes)
    732     def recalculate_output_shapes(output_shapes):
    733       """Recalculates the output_shapes after dividing it by num_workers."""
--&gt; 734       if len(output_shapes) &lt; 1:
    735         raise ValueError("Input shape should have at least one dimension.")
    736       if (tensor_shape.dimension_value(output_shapes[0]) and

~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py in __len__(self)
    792     """Returns the rank of this shape, or raises ValueError if unspecified."""
    793     if self._dims is None:
--&gt; 794       raise ValueError("Cannot take the length of shape with unknown rank.")
    795     return len(self._dims)
    796 

ValueError: Cannot take the length of shape with unknown rank.
&lt;/denchmark-code&gt;

but if u use it not by py_function, it can calculate and distributed correctly. but i don't know how to get the value transfer to this function, it shows as args_0:0 and args_1:0
&lt;denchmark-code&gt;Tensor("args_0:0", shape=(), dtype=string)
Tensor("args_1:0", shape=(), dtype=string)
&lt;BatchDataset shapes: ((None, 2, 128, 128), (None, 128, 128)), types: (tf.float32, tf.float32)&gt;
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='BelieveOP5' date='2019-05-01T17:37:46Z'>
		I could reproduce the issue using TF2.0.0-alpha0 and tf-nightly. Thanks!
		</comment>
		<comment id='2' author='BelieveOP5' date='2019-05-05T08:19:36Z'>
		
I could reproduce the issue using TF2.0.0-alpha0 and tf-nightly. Thanks!

thanks for your info.
		</comment>
		<comment id='3' author='BelieveOP5' date='2019-05-06T18:06:19Z'>
		&lt;denchmark-link:https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape&gt;https://stackoverflow.com/questions/42590431/output-from-tensorflow-py-func-has-unknown-rank-shape&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='BelieveOP5' date='2019-05-06T18:06:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28257&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28257&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='BelieveOP5' date='2019-09-15T19:52:24Z'>
		This problem has not been solved. Why does the return value be "unknown"
		</comment>
		<comment id='6' author='BelieveOP5' date='2019-09-16T19:37:17Z'>
		&lt;denchmark-link:https://github.com/primejava&gt;@primejava&lt;/denchmark-link&gt;
 have you read through the StackOverflow post linked above?
		</comment>
	</comments>
</bug>