<bug id='25092' author='AakashKumarNain' open_date='2019-01-22T06:35:52Z' closed_time='2019-01-30T00:05:36Z'>
	<summary>Data Augmentation and pre-processing in tf.data.Dataset</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tf-2.0-preview
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: Cuda 10
GPU model and memory: K80

Describe the current behavior
Suppose I want to do transfer learning. I use the base model from tf.keras.appliactions, for example, VGG16. During transfer learning/fine-tuning, there are two steps that we almost always follow:

Pre-process each batch. e.g  subtract imagenet mean, converting values in range [0,1] or [-1,1]
Data Augmentation

The actual pipeline looks like this:
def get _model()
  base_model = tf.keras.applications.vgg16.VGG16(...)
  base_model_output = base_model.output

  # add new layers
  x = tf.keras.layers.Flatten()(base_model_output)(x)
  x = tf.keras.layers.Dense(...)(x)
  ...
  model = Model(base_model.input, output)
  model.compile(..)
  return model

model = get_model()
dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.batch(32).repeat()
In order to pre-process the images and perform data augmentation, I can write a function and map the dataset elements to it. For example,
def _parse_function(filename, label):
  image_string = tf.read_file(filename)
  image_decoded = tf.image.decode_jpeg(image_string)
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
 
  # preprocess
  image_resized = tf.expand_dims(image_resized, axis=0)
  image_resized = vgg.preprocess_input(image_resized)
  image_resized =  tf.squeeze(image_resized)
  
  # perform augmentation using tf or some other library like Augmenter
  image_resized = ....

  return image_resized, label
This works fine but I see two problems with this approach:


We are not utilising vectorization. In order to preprocess, we expand the dimensions to reshape the image in [1, H, W, C] form and then we apply vgg.preprocess_input() function. The problem is that we are doing too many extra operations expand_dims and squeeze whereas preprocess_input() can operate on a batch which is the ideal case.


Data Augmentation libraries like Augmentor or imgaug works with batches and performing augmentation on random samples of a batch makes more sense than for each image but there is no way to achieve this if we are using map with datasets.


This is a performance bottleneck IMO.  It might be the case that I am missing something here. Please correct me if that's the case.
	</description>
	<comments>
		<comment id='1' author='AakashKumarNain' date='2019-01-30T00:05:36Z'>
		You can use .batch on a dataset (after resize) to coalesce consecutive examples into a batch, and perform subsequent steps on the batch (using .map). This of course assumes that vgg_preprocess is written in a batch compatible manner.
Questions of this sort are likely better directed at StackOverflow.
		</comment>
	</comments>
</bug>