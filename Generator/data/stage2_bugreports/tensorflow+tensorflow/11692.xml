<bug id='11692' author='meijun' open_date='2017-07-23T15:20:45Z' closed_time='2017-08-08T20:01:28Z'>
	<summary>A bug of tf.reduce_logsumexp with `-inf`</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux CentOS 7
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.2.0
Python version: 2.7.13
Bazel version (if compiling from source):
CUDA/cuDNN version: 8.0/5.1.3
GPU model and memory: Tesla K40m, 11439MiB
Exact command to reproduce:  python -c "import tensorflow as tf; print tf.Session().run(tf.reduce_logsumexp(float('-inf')))"

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

The doc of tf.reduce_logsumexp says it

Computes log(sum(exp(elements across dimensions of a tensor))).

However, it does not when the tensor is -inf.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;python -c "import tensorflow as tf; print tf.Session().run(tf.reduce_logsumexp(float('-inf')))"
&lt;/denchmark-code&gt;

prints
&lt;denchmark-code&gt;nan
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;python -c "import tensorflow as tf; print tf.Session().run(tf.log(tf.reduce_sum(tf.exp(float('-inf')))))"
&lt;/denchmark-code&gt;

prints
&lt;denchmark-code&gt;-inf
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='meijun' date='2017-07-24T07:25:19Z'>
		The tf.reduce_logsumexp source code currently is:
def reduce_logsumexp(input_tensor,
                     axis=None,
                     keep_dims=False,
                     name=None,
                     reduction_indices=None):
  """TF 1.2.0 source code"""
  with ops.name_scope(name, "ReduceLogSumExp", [input_tensor]) as name:
    my_max = array_ops.stop_gradient(
        reduce_max(
            input_tensor,
            axis=axis,
            reduction_indices=reduction_indices,
            keep_dims=True))
    result = gen_math_ops.log(
        reduce_sum(
            gen_math_ops.exp(input_tensor - my_max),
            axis,
            keep_dims=True,
            reduction_indices=reduction_indices)) + my_max
    if not keep_dims:
      if isinstance(axis, int):
        axis = [axis]
      result = array_ops.squeeze(result, axis)
    return result
I have written my own tf_reduce_logsumexp to fix the bug:
def tf_reduce_logsumexp(input_tensor,
                        axis=None,
                        keep_dims=False,
                        name=None,
                        reduction_indices=None):
    """Fix tf.reduce_logsumexp"""
    with tf.name_scope(name, "tf_ReduceLogSumExp", [input_tensor]) as name:
        raw_max = tf.reduce_max(
            input_tensor,
            axis=axis,
            reduction_indices=reduction_indices,
            keep_dims=True)
        my_max = tf.stop_gradient(
            tf.where(
                tf.is_finite(raw_max),
                raw_max,
                tf.zeros_like(raw_max)))
        result = tf.log(
            tf.reduce_sum(
                tf.exp(input_tensor - my_max),
                axis,
                keep_dims=True,
                reduction_indices=reduction_indices)) + my_max
        if not keep_dims:
            if isinstance(axis, int):
                axis = [axis]
            result = tf.squeeze(result, axis)
        return result
		</comment>
		<comment id='2' author='meijun' date='2017-07-25T01:15:32Z'>
		&lt;denchmark-link:https://github.com/fastturtle&gt;@fastturtle&lt;/denchmark-link&gt;
, could you take a look?
		</comment>
		<comment id='3' author='meijun' date='2017-07-25T16:24:53Z'>
		This looks like a reasonable fix, would you be willing to submit it as a pull-request?
		</comment>
		<comment id='4' author='meijun' date='2017-07-25T17:12:20Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 Sure, I will try it.
		</comment>
	</comments>
</bug>