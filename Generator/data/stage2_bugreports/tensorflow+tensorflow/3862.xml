<bug id='3862' author='girving' open_date='2016-08-16T22:27:20Z' closed_time='2018-02-07T23:30:26Z'>
	<summary>tf.cumprod's gradient produces nans given zeros</summary>
	<description>
Example:
&lt;denchmark-code&gt;tf.reset_default_graph()
var = tf.Variable([0.])
cumprod = tf.cumprod(var)
grad = tf.gradients(cumprod, var)
init = tf.initialize_all_variables()
with tf.Session() as sess:
  sess.run(init)
  print(sess.run(grad))

---&gt; [array([ nan], dtype=float32)]
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/ibab&gt;@ibab&lt;/denchmark-link&gt;
 Do you know the right way to fix this?
	</description>
	<comments>
		<comment id='1' author='girving' date='2016-08-16T23:07:40Z'>
		I've placed a comment on this in the gradient code here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/51fd9c024c4544ba1ef60862ec3f55b6e3ae79b1/tensorflow/python/ops/math_grad.py#L889&gt;tensorflow/python/ops/math_grad.py#L889&lt;/denchmark-link&gt;

I've spent some time trying to come up with a version that doesn't use a division by x, but didn't  come up with anything elegant.
		</comment>
		<comment id='2' author='girving' date='2016-08-16T23:47:34Z'>
		Hmm, that is pretty awkward:
&lt;denchmark-code&gt;v = [x, y, z]
cumprod = [x, xy, xyz]
grad = [dx + y dy + yz dz, x dy + xz dz, xy dz]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='girving' date='2016-08-16T23:54:18Z'>
		So in general you need all prefix products with each possible entry excluded.  Unfortunately if you write those as products of contiguous ranges you need quadratically many ranges.  Ug.
		</comment>
		<comment id='4' author='girving' date='2016-12-02T01:37:14Z'>
		A fast O(n) solution.
Assume the input vector x and the upstream gradient g has the form:
&lt;denchmark-code&gt;x = [x1 x2 x3 ... xn, 0, -, -, ...]
g = [g1 g2 g3 ... gn, gnp1, -, -, ...]
&lt;/denchmark-code&gt;

- Elements are irrelevant in this computation because the leftmost 0 cause cumprod become 0 after that.
The downstream gradient is:
&lt;denchmark-code&gt;[ dx1 ... dx &lt;use unsafe method&gt; ] + [ cumprod(x1,x2,x3...xn) * gnp1 ] + [0, 0, 0 ... 0]
&lt;/denchmark-code&gt;

To gain full speedup, the forward computation should record the index of first occurrence of 0, and automatically memset(0) for the results after that. This optimization is unique to cumprod and can't be done to cumsum. The backward computation can just use that index to quickly do the job.
Maybe it's a good idea to modify cumprod interface to def cumprod(input, use_unsafe_grad=False), so that user can force unsafe method if it can ensure no zero elements in input.
So far, this is useful in Deepmind's DNC model because it has a cumprod which often encounters zero.
Sorry, not familiar with C++, so no PR yet.
		</comment>
		<comment id='5' author='girving' date='2017-09-06T12:03:36Z'>
		The following workaround helps to avoid the NaN gradient issue (it lacks the exclusive or reverse flags but they're easy enough to implement):
def cumprod(tensor, axis=0):
    transpose_permutation = None
    n_dim = len(tensor.get_shape())
    if n_dim &gt; 1 and axis != 0:

        if axis &lt; 0:
            axis = n_dim + axis

        transpose_permutation = np.arange(n_dim)
        transpose_permutation[-1], transpose_permutation[0] = 0, axis

    tensor = tf.transpose(tensor, transpose_permutation)

    def prod(acc, x):
        return acc * x

    prob = tf.scan(prod, tensor)
    tensor = tf.transpose(prob, transpose_permutation)
    return tensor
Can anyone comment on efficiency of this approach?
		</comment>
		<comment id='6' author='girving' date='2018-02-07T23:30:26Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
It looks like there is a workaround posted.
		</comment>
		<comment id='7' author='girving' date='2019-09-21T18:23:40Z'>
		I submitted a fix to this issue in the PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/32714&gt;#32714&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>