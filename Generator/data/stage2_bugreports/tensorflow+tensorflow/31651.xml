<bug id='31651' author='OlavHN' open_date='2019-08-15T18:17:32Z' closed_time='2020-02-25T01:43:10Z'>
	<summary>keras.optimizers.Adam cannot apply gradients if ResourceVariable has unknown shape.</summary>
	<description>
With ResourceVariables we specify unknown shape dimensions for variables which can be resized after initializations similarly to how validate_shape=False worked previously.
Applying gradients to ResourceVariables with unknown dimension sizes using tf.keras.optimizers.Adam currently crashes with the exception

ValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)

Attached is a minimal example to reproduce:
&lt;denchmark-code&gt;import tensorflow as tf

print(tf.__version__)

w = tf.Variable([[1.0]], shape=tf.TensorShape([None]))
with tf.GradientTape() as tape:
  loss = w * w

grad = tape.gradient(loss, w)
tf.keras.optimizers.SGD().apply_gradients([(grad, w)])
print('that worked')
tf.keras.optimizers.Adam().apply_gradients([(grad, w)])
print('that crashed')
&lt;/denchmark-code&gt;

Outputs:
&lt;denchmark-code&gt;2.0.0-beta1
that worked
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)
   1862         shape = constant_op._tensor_shape_tensor_conversion_function(
-&gt; 1863             tensor_shape.TensorShape(shape))
   1864       except (TypeError, ValueError):

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _tensor_shape_tensor_conversion_function(s, dtype, name, as_ref)
    325     raise ValueError(
--&gt; 326         "Cannot convert a partially known TensorShape to a Tensor: %s" % s)
    327   s_list = s.as_list()

ValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-174-2eba6f36340c&gt; in &lt;module&gt;
      6 tf.keras.optimizers.SGD().apply_gradients([(grad, w)])
      7 print('that worked')
----&gt; 8 tf.keras.optimizers.Adam().apply_gradients([(grad, w)])
      9 print('that crashed')

~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in apply_gradients(self, grads_and_vars, name)
    433         _ = self.iterations
    434         self._create_hypers()
--&gt; 435         self._create_slots(var_list)
    436 
    437       self._prepare(var_list)

~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/adam.py in _create_slots(self, var_list)
    143     # Separate for-loops to respect the ordering of slot variables from v1.
    144     for var in var_list:
--&gt; 145       self.add_slot(var, 'm')
    146     for var in var_list:
    147       self.add_slot(var, 'v')

~/.local/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in add_slot(self, var, slot_name, initializer)
    576             dtype=var.dtype,
    577             trainable=False,
--&gt; 578             initial_value=initial_value)
    579       backend.track_variable(weight)
    580       slot_dict[slot_name] = weight

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    260       return cls._variable_v1_call(*args, **kwargs)
    261     elif cls is Variable:
--&gt; 262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)
    254         synchronization=synchronization,
    255         aggregation=aggregation,
--&gt; 256         shape=shape)
    257 
    258   def __call__(cls, *args, **kwargs):

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in &lt;lambda&gt;(**kws)
    235                         shape=None):
    236     """Call on Variable class. Useful to force the signature."""
--&gt; 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    239       previous_getter = _make_getter(getter, previous_getter)

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)
   2549       synchronization=synchronization,
   2550       aggregation=aggregation,
-&gt; 2551       shape=shape)
   2552 
   2553 

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    262       return cls._variable_v2_call(*args, **kwargs)
    263     else:
--&gt; 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    265 
    266 

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
    462           synchronization=synchronization,
    463           aggregation=aggregation,
--&gt; 464           shape=shape)
    465 
    466   def __repr__(self):

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)
    606           with ops.name_scope("Initializer"), device_context_manager(None):
    607             initial_value = ops.convert_to_tensor(
--&gt; 608                 initial_value() if init_from_fn else initial_value,
    609                 name="initial_value", dtype=dtype)
    610           # Don't use `shape or initial_value.shape` since TensorShape has

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py in __call__(self, shape, dtype)
     96   def __call__(self, shape, dtype=dtypes.float32):
     97     dtype = dtypes.as_dtype(dtype)
---&gt; 98     return array_ops.zeros(shape, dtype)
     99 
    100 

~/.local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)
   1864       except (TypeError, ValueError):
   1865         # Happens when shape is a list with tensor elements
-&gt; 1866         shape = ops.convert_to_tensor(shape, dtype=dtypes.int32)
   1867     if not shape._shape_tuple():
   1868       shape = reshape(shape, [-1])  # Ensure it's a vector

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)
   1098   preferred_dtype = deprecation.deprecated_argument_lookup(
   1099       "dtype_hint", dtype_hint, "preferred_dtype", preferred_dtype)
-&gt; 1100   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
   1101 
   1102 

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)
   1156       name=name,
   1157       preferred_dtype=dtype_hint,
-&gt; 1158       as_ref=False)
   1159 
   1160 

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)
   1235 
   1236     if ret is None:
-&gt; 1237       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1238 
   1239     if ret is NotImplemented:

~/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _tensor_shape_tensor_conversion_function(s, dtype, name, as_ref)
    324   if not s.is_fully_defined():
    325     raise ValueError(
--&gt; 326         "Cannot convert a partially known TensorShape to a Tensor: %s" % s)
    327   s_list = s.as_list()
    328   int64_value = 0

ValueError: Cannot convert a partially known TensorShape to a Tensor: (None,)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='OlavHN' date='2019-08-16T10:01:13Z'>
		I am able to reproduce the issue with Tensorflow 2.0.0.beta1. Please take a look at colab gist &lt;denchmark-link:https://colab.research.google.com/drive/1gHDBXwR_VRorIYITJkc7gBinojOP2puy&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='OlavHN' date='2020-02-25T01:43:10Z'>
		You may achieve this by setting , as its value is  by default for ref variable (see &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/Variable?version=nightly#__init__&gt;here&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='3' author='OlavHN' date='2020-02-25T01:43:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31651&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31651&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='OlavHN' date='2020-09-04T23:58:09Z'>
		Setting validate_shape=False does nothing to solve this issue. I just encountered it under Tensorflow version 1.15. The problem is that the apply_gradients method of the Adam optimizer appears to require the shape to be fully known, however the SGD optimizer does not. validate_shape=False simply allows a tf.Variable to be initialized without a fully known shape. What's frustrating is that I actually know the shape in my case and could supply a hint to make optimization work. However, there is no way to specify the static shape of a tf.Variable object (the set_shape method is apparently not implemented for tf.Variables and tf.ensure_shape returns a new Tensor object that cannot be optimized).
		</comment>
	</comments>
</bug>