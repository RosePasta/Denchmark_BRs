<bug id='32242' author='awav' open_date='2019-09-05T15:35:11Z' closed_time='2020-11-05T05:34:06Z'>
	<summary>[TF2.0] Checkpoint doesn't store non-TF objects</summary>
	<description>
Hello all,
I found that tf.train.Checkpoint doesn't save non-TF objects and tf.Tensors. The MWE below shows the case:
import tensorflow as tf

class A(tf.Module):
    def __init__(self):
        super().__init__()
        self.scalar = 1.
        self.variable = tf.Variable(1.)
        self.tensor = tf.convert_to_tensor(1.)
        self.list = [tf.convert_to_tensor(10.0), 20.0, tf.Variable(0.0)]

    def __str__(self):
        return f"scalar={self.scalar}, variable={self.variable.numpy()}, tensor={self.tensor}, list={self.list}"


a_module = A()
checkpoint = tf.train.Checkpoint(a=a_module)
manager = tf.train.CheckpointManager(checkpoint, '/tmp/example', max_to_keep=3)
manager.save()

print(f"1. {a_module}")

#### modify

a_module.scalar = -100.
a_module.variable.assign(123.)
a_module.tensor = tf.convert_to_tensor(-12.)
a_module.list = [3., 3.]

print(f"2. {a_module}")

#### restore
checkpoint.restore(manager.latest_checkpoint)

print(f"3. {a_module}")
Output:
1. scalar=1.0, variable=1.0, tensor=1.0, list=ListWrapper([&lt;tf.Tensor: id=9, shape=(), dtype=float32, numpy=10.0&gt;, 20.0, &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0&gt;])
2. scalar=-100.0, variable=123.0, tensor=-12.0, list=ListWrapper([3.0, 3.0])
3. scalar=-100.0, variable=1.0, tensor=-12.0, list=ListWrapper([3.0, 3.0])
In the output you can see that the checkpointer restores only the variable and completely ignores other fields of the A object.
I expected that at least pythonic objects, numpy and TF tensors should be stored by the checkpointer on the disk. Is that a normal behavior?
If the answer is yes: I think that this feature should be implemented, otherwise it is very confusing and not straightforward why the checkpoint saves some objects and others not.
no: this is a bug, must be fixed.
System information

OS Platform and Distribution: macOS 10.14.6
TensorFlow version: v1.12.1-10419-g5138353309 2.0.0-dev20190905
Python version: 3.6.8

	</description>
	<comments>
		<comment id='1' author='awav' date='2019-09-06T10:34:05Z'>
		I have tried on colab with TF version 2.0.0-dev20190903, 2.0.0-rc0 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/e4d3e264f71cd7372f17020f0db42c76/untitled160.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='awav' date='2019-09-21T16:23:49Z'>
		Hello &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/rchao&gt;@rchao&lt;/denchmark-link&gt;
! Any updates on the topic?
		</comment>
		<comment id='3' author='awav' date='2019-09-30T15:34:01Z'>
		Hello &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/rchao&gt;@rchao&lt;/denchmark-link&gt;
 again! Does anyone have looked at this issue?
		</comment>
		<comment id='4' author='awav' date='2019-09-30T15:56:18Z'>
		&lt;denchmark-link:https://github.com/rchao&gt;@rchao&lt;/denchmark-link&gt;
 could you PTAL?
		</comment>
		<comment id='5' author='awav' date='2019-09-30T19:50:47Z'>
		Reassigning to &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 to take a look or triage. Thanks.
		</comment>
		<comment id='6' author='awav' date='2019-09-30T19:57:35Z'>
		Hi &lt;denchmark-link:https://github.com/awav&gt;@awav&lt;/denchmark-link&gt;
,
This is intended. Tensorflow checkpoints only save and restore the variables/other TensorFlow objects with state. Constants tensors and python objects won't be included in the Checkpoint, and this is expected because some constants (e.g. lookup tables) can get exceedingly large.
There is an experimental API that lets you save arbitrary python values to the Checkpoint. Check it out here: &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/train/experimental/PythonState&gt;https://www.tensorflow.org/api_docs/python/tf/train/experimental/PythonState&lt;/denchmark-link&gt;

Feel free to submit a PR with clarifications to docstring of &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint&gt;tf.train.Checkpoint&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='7' author='awav' date='2019-09-30T19:57:37Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32242&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32242&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='awav' date='2019-10-01T15:15:51Z'>
		Hello &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 ,
Okay, what's about this line: self.list = [tf.convert_to_tensor(10.0), 20.0, tf.Variable(0.0)], the list has a variable, but it is not stored in the checkpoint.

Constants tensors and python objects won't be included in the Checkpoint, and this is expected because some constants (e.g. lookup tables) can get exceedingly large.
Variables can be exceedingly large as well. The literals can and should be stored in a checkpoint.

Writing a serializer for int, float and str every time when I need to store them is a bit weird.
Can we keep an issue open?
		</comment>
		<comment id='9' author='awav' date='2019-10-01T21:20:30Z'>
		When the values were restored, the list no longer contained any variables. Checkpoint.restore only restores the values of the tensorflow objects, but will not modify the objects or datastructures containing those objects. In other words, it will not rewrite the elements in the list.
What would be the use case for storing python ints/floats/strings?
edit: Just noticed that you had written a response in the quoted text.
Yes, variables can get large as well. I guess a better reason that constants aren't saved out is that they aren't expected to change when training. Checkpoints are used to save/restore different states of the model.
		</comment>
		<comment id='10' author='awav' date='2020-10-22T04:17:32Z'>
		&lt;denchmark-link:https://github.com/awav&gt;@awav&lt;/denchmark-link&gt;
,
Any updates regarding this? Please take a look at &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
's comment above and let us know if this is still an issue. Thanks!
		</comment>
		<comment id='11' author='awav' date='2020-10-29T04:49:21Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='12' author='awav' date='2020-11-05T05:34:05Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='13' author='awav' date='2020-11-05T05:34:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32242&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32242&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>