<bug id='2295' author='sesse' open_date='2016-05-09T18:52:25Z' closed_time='2016-07-25T15:33:40Z'>
	<summary>pow() gradients create +inf at 0.0</summary>
	<description>
Hi,
I had a pipeline where I was first clamping to [0..1] and then doing x^2.4 (converting to/from gamma RGB to linear RGB):
&lt;denchmark-code&gt;y = tf.minimum(tf.maximum(y, 0.0), 1.0)
gamma = tf.constant(1.0/2.4, tf.float32)
y = tf.pow(y, gamma)
&lt;/denchmark-code&gt;

However, this instantly created inf values (and NaNs in the next step), seemingly due to the use of log() to compute the gradients. The gradient of pow() in 0.0 should be pretty well defined as long as the exponent is nonzero; at the very least, it is not infinity.
As a workaround, clamping to 1e-5 instead of 0.0 caused the NaNs to disappear.
	</description>
	<comments>
		<comment id='1' author='sesse' date='2016-05-12T07:13:58Z'>
		Just out of curiosity, what is the gradient value at y = 1e-5 then?
		</comment>
		<comment id='2' author='sesse' date='2016-05-12T09:33:54Z'>
		I have no idea, I never printed them out. But the graph trained just fine.
		</comment>
		<comment id='3' author='sesse' date='2016-05-12T16:55:46Z'>
		The fast way to solve this is an add an extra op that does x * log y and does the right thing for x = y = 0.  The slow way is to do that in Python via tf.select(tf.equal(x, 0), 0, x * tf.log(y)).  Unfortunate that simplistic code doesn't work out of the box because tf.select doesn't broadcast.
The simple way to solve it is to use x * tf.log(y + y.dtype.epsilon) in the gradient.  Probably we should just do that.
&lt;denchmark-link:https://github.com/sesse&gt;@sesse&lt;/denchmark-link&gt;
: I'm happy to review if you want to make the change, but won't be able to work on this soon.
		</comment>
	</comments>
</bug>