<bug id='20521' author='gaffordb' open_date='2018-07-03T14:10:35Z' closed_time='2018-08-14T20:19:50Z'>
	<summary>prefetch_to_device not working with SparseTensor when fetching to GPU</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code: yes
OS Platform and Distribution: Linux Ubuntu 14.04
TensorFlow installed from: source
TensorFlow version: 1.9
Python version: 2.7
Bazel version: 0.12.0
GCC/Compiler version: 4.8.4
CUDA/cuDNN version: 9.1
GPU model and memory: GTX 1080, 8114MiB
Exact command to reproduce:
(Any sparse tensor being prefetched to GPU will work here, this is just one short example)

&lt;denchmark-code&gt;import tensorflow as tf

# Set up simple sparse tensor
ds = tf.data.Dataset.from_tensors(tf.contrib.layers.dense_to_sparse([1], 0))

# prefetch to GPU
gpu_ds = ds.apply(tf.contrib.data.prefetch_to_device('/gpu:0'))

# Get a value
gpu_iter = gpu_ds.make_one_shot_iterator()
val = gpu_iter.get_next()

# Barf
with tf.Session() as sess:
    sess.run(val)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Bug resulting from prefetch_to_device with the following conditions:

device is GPU
dataset element contains a sparse tensor

Iterator functions appropriately, only when you try to use the data do you run into the error. (see log for error)
Also, as a side note which may or may not be relevant, I've found that even a single sparse tensor in an element will spoil any other nice, kind, and dense tensors in the pack. So, if, in the previous example, I were to do the following, I would still run into an error:
&lt;denchmark-code&gt;import tensorflow as tf
# Make a sparse tensor
ds = tf.data.Dataset.from_tensors(tf.contrib.layers.dense_to_sparse([1], 0))

# Add in a non-sparse component
ds = ds.map(lambda x: (x,1))

# Prefetch to device
gpu_ds = ds.apply(tf.contrib.data.prefetch_to_device('/gpu:0'))

# Pull out vals
gpu_iter = gpu_ds.make_one_shot_iterator()
val_sparse, val_normal = gpu_iter.get_next()

# Uh oh!
with tf.Session() as sess:
    sess.run(val_normal)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Log&lt;/denchmark-h&gt;

Traceback (most recent call last):
File "sparse_bunk.py", line 17, in 
sess.run(val_normal)
File "/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 877, in run
run_metadata_ptr)
File "/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1100, in _run
feed_dict_tensor, options, run_metadata)
File "/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1272, in _do_run
run_metadata)
File "/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1291, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: No unary variant device copy function found for direction: 1 and Variant type_name: tensorflow::Tensor
[[Node: FunctionBufferingResourceGetNext = FunctionBufferingResourceGetNext&lt;denchmark-link:FunctionBufferingResource&gt;output_types=[DT_VARIANT, DT_INT32], _device="/job:localhost/replica:0/task:0/device:GPU:0"&lt;/denchmark-link&gt;
]]
Thank you
	</description>
	<comments>
		<comment id='1' author='gaffordb' date='2018-07-13T16:31:52Z'>
		Have I written custom code: yes
OS Platform and Distribution: Linux Ubuntu 14.04
TensorFlow installed from: source
TensorFlow version: 1.9
Python version: 2.7
Bazel version: 0.12.0
GCC/Compiler version: 4.8.4
CUDA/cuDNN version: 9.1
GPU model and memory: Tesla K40, K80
I have been getting a similar error when I use MirroredStrategy() for training across multiple devices. Here is the stack trace for it:

`  File "train.py", line 113, in 
tf.app.run()
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
_sys.exit(main(argv))
File "train.py", line 110, in main
classifier.train(input_fn=lambda: _get_input_stream())
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 376, in train
loss = self._train_model(input_fn, hooks, saving_listeners)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1141, in _train_model
return self._train_model_distributed(input_fn, hooks, saving_listeners)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1366, in _train_model_distributed
saving_listeners)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1449, in _train_with_estimator_spec
_, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 583, in run
run_metadata=run_metadata)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 1059, in run
run_metadata=run_metadata)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 1150, in run
raise six.reraise(*original_exc_info)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 1135, in run
return self._sess.run(*args, **kwargs)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 1207, in run
run_metadata=run_metadata)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 987, in run
return self._sess.run(*args, **kwargs)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 877, in run
run_metadata_ptr)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1100, in _run
feed_dict_tensor, options, run_metadata)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1272, in _do_run
run_metadata)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1291, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: No unary variant device copy function found for direction: 1 and Variant type_name: tensorflow::Tensor
[[Node: FunctionBufferingResourceGetNext = FunctionBufferingResourceGetNext&lt;denchmark-link:FunctionBufferingResource&gt;output_types=[DT_FLOAT, DT_STRING, DT_INT32, DT_VARIANT], _device="/job:localhost/replica:0/task:0/device:GPU:0"&lt;/denchmark-link&gt;
]]
[[Node: GroupCrossDeviceControlEdges_0/train/OptimizeLoss/global_norm/gradient_norm/tags/_766 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_1235_..._norm/tags", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]
Caused by op u'FunctionBufferingResourceGetNext', defined at:
File "train.py", line 113, in 
tf.app.run()
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 125, in run
_sys.exit(main(argv))
File "train.py", line 110, in main
classifier.train(input_fn=lambda: _get_input_stream())
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 376, in train
loss = self._train_model(input_fn, hooks, saving_listeners)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1141, in _train_model
return self._train_model_distributed(input_fn, hooks, saving_listeners)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1241, in _train_model_distributed
input_fn, model_fn_lib.ModeKeys.TRAIN))
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 1011, in _get_features_and_labels_from_input_fn
return estimator_util.parse_input_fn_result(result)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/estimator/util.py", line 111, in parse_input_fn_result
result = iterator.get_next()
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/values.py", line 619, in get_next
data_list = self._iterator.get_next(name=name)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/contrib/distribute/python/prefetching_ops_v2.py", line 124, in get_next
self.output_types, self.output_classes)), name=name)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/contrib/data/python/ops/gen_dataset_ops.py", line 351, in function_buffering_resource_get_next
output_types=output_types, name=name)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
op_def=op_def)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py", line 432, in new_func
return func(*args, **kwargs)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 3212, in create_op
op_def=op_def)
File "/home/weinman/virtualenv/tf-b2fe2a874/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1702, in init
self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
InternalError (see above for traceback): No unary variant device copy function found for direction: 1 and Variant type_name: tensorflow::Tensor
[[Node: FunctionBufferingResourceGetNext = FunctionBufferingResourceGetNext&lt;denchmark-link:FunctionBufferingResource&gt;output_types=[DT_FLOAT, DT_STRING, DT_INT32, DT_VARIANT], _device="/job:localhost/replica:0/task:0/device:GPU:0"&lt;/denchmark-link&gt;
]]
[[Node: GroupCrossDeviceControlEdges_0/train/OptimizeLoss/global_norm/gradient_norm/tags/_766 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_1235_..._norm/tags", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"&lt;/denchmark-link&gt;
]]`

My guess is that the underlying issue should be the same. I do not make any explicit calls to prefetch_to_device(Insert GPU here) with sparse tensors anywhere in my code. Hence, the issue probably lies with references to prefetching ops under the hood.
		</comment>
		<comment id='2' author='gaffordb' date='2018-07-18T05:16:32Z'>
		I think I'm experiencing the same error here.
After staring at it for a while, I realized that the direction (HOST_TO_DEVICE = 1), the recv_device ("/job:localhost/replica:0/task:0/device:CPU:0"), and the send_device ("/job:localhost/replica:0/task:0/device:GPU:0") don't seem to be in agreement.
Perhaps I'm misunderstanding what's going on here, but maybe it's a simple issue related to getting the direction of the copy correct?
		</comment>
		<comment id='3' author='gaffordb' date='2018-07-18T20:35:27Z'>
		&lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 Any thoughts on the above?
		</comment>
		<comment id='4' author='gaffordb' date='2018-08-02T19:09:36Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='5' author='gaffordb' date='2018-08-09T01:46:22Z'>
		So &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 added some support recently that makes this go away. I ran the same piece of code with tf-nightly-gpu and seems to work.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/02ae1e2e781b8e049d1fc1ab7b52f6ee7edb4423#diff-3d32c23cf21d0adac13fdd28576dd6f9&gt;02ae1e2#diff-3d32c23cf21d0adac13fdd28576dd6f9&lt;/denchmark-link&gt;

Please test it and let me know if there is still a problem.
		</comment>
		<comment id='6' author='gaffordb' date='2018-08-14T20:19:50Z'>
		Everything I've tested appears to work. Thank you!
		</comment>
	</comments>
</bug>