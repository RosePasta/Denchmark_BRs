<bug id='25746' author='holyhao' open_date='2019-02-14T07:10:38Z' closed_time='2019-07-29T13:54:53Z'>
	<summary>Object detection ppn tflite works wrong on mobile</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):N
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: HUAWEI MATE20
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below):1.10
Python version:3.6
Bazel version (if compiling from source):1.15
GCC/Compiler version (if compiling from source):1.9
CUDA/cuDNN version:8.0
GPU model and memory:16GB

I used  object detection API, the ssd_mobilenetV2 is working well including the train, eval ,inference on pc ,and .tflite on phone.
Recently, i try ppn_mobilenetv1, the train and eval is well. The frozen_inference_graph.pb also work well on pc and the results are right. When i convert it to tflite_graph.pb, then convert it to detect.tflite. No errors occur. But when it runs on the mobile, it shows totally wrong results. I can not find anything wrong here. Could anyone please help me find it out?
	</description>
	<comments>
		<comment id='1' author='holyhao' date='2019-02-14T21:40:21Z'>
		&lt;denchmark-link:https://github.com/holyhao&gt;@holyhao&lt;/denchmark-link&gt;
 Could you provide any code to reproduce the bug? or could you provide more detailed steps/commands you followed? Thanks!
		</comment>
		<comment id='2' author='holyhao' date='2019-02-15T01:35:17Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 hi，thanks for your reply, to reproduce the bug：
1.Download the ppn_mobilnetV1 &lt;denchmark-link:http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz&gt;http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz&lt;/denchmark-link&gt;

2.Conver it to tflite, no errors occur
&lt;denchmark-code&gt;CONFIG_PATH=../pipeline.config 
CHECKPOINT_PATH=../model.ckpt 
OUTPUT_DIR=../results/	
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;python object_detection/export_tflite_ssd_graph.py \ 
--pipeline_config_path $CONFIG_PATH \ 
--trained_checkpoint_prefix $CHECKPOINT_PATH \ 
--output_directory $OUTPUT_DIR \ 
--add_postprocessing_op=true
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;bazel-bin/tensorflow/contrib/lite/toco/toco \ 
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \ 
--input_shapes=1,300,300,3 \ 
--input_arrays=normalized_input_image_tensor \ 
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \ 
--inference_type=FLOAT \ --allow_custom_ops
&lt;/denchmark-code&gt;


Run it on mobile, i use the tensorflow-lite from tensoflow 1.10

As I mentioned above, ssd_mobilenetV2 works well from the framework. The frozen_inference_graph.pb of ppn_mobilenetv1 works well on pc. But when the tf.lite of ppn_mobilenetv1  runs on the mobile, it shows totally wrong results. I Look through the export_tflite_ssd_graph.py and export_inference_graph.py . I wonder how it works well for ssd_mobilenetV2 and wrong for ppn_mobilenetv1 on mobile, and how it works well  for ppn_mobilenetv1 on pc and wrong on the mobile. Looking forward to your help.
		</comment>
		<comment id='3' author='holyhao' date='2019-07-12T19:24:23Z'>
		Hi &lt;denchmark-link:https://github.com/holyhao&gt;@holyhao&lt;/denchmark-link&gt;
, are you still experiencing a problem with the model? Thanks.
		</comment>
		<comment id='4' author='holyhao' date='2019-07-27T12:23:03Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='5' author='holyhao' date='2019-07-29T13:54:53Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='6' author='holyhao' date='2019-07-29T13:54:55Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=25746&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=25746&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>