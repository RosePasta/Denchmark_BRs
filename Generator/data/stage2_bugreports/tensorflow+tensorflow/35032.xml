<bug id='35032' author='CNugteren' open_date='2019-12-11T16:28:38Z' closed_time='2019-12-26T22:05:00Z'>
	<summary>cuBLAS failure for large convolutions in V100 GPUs</summary>
	<description>
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.15.0 or 2.0.0
Python version: 3.7.3
CUDA/cuDNN version: 10.0 and 7.6.4
GPU model and memory: Tesla V100 with either 16GB or 32GB
Exact command to reproduce: python tf_v100_cublas_crash_tf1.py (from the gist below)

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

If I run a large 1x1 convolution with FP16 on a Tesla V100, cuBLAS crashes with the following kind of message:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal: Blas SGEMM launch failed : m=9584640, n=17, k=17
     [[node graph_final_part/conv/conv2d/Conv2D (defined at ~/.virtualenvs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
     [[ExpandDims_9/_3631]]
  (1) Internal: Blas SGEMM launch failed : m=9584640, n=17, k=17
     [[node graph_final_part/conv/conv2d/Conv2D (defined at ~/.virtualenvs/tf/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]
&lt;/denchmark-code&gt;

This comes from this place in the TF code:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_ops.cc#L698&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/conv_ops.cc#L698&lt;/denchmark-link&gt;

The root cause is such TensorFlow code for example:
&lt;denchmark-code&gt;conv_op = tf.layers.Conv2D(filters=17, kernel_size=(1, 1))
in_t = tf.ones(shape=(10, 1152, 832, 17), dtype=tf.float16)
&lt;/denchmark-code&gt;

It works again if I:

Make the input tensor smaller
Use FP32 instead of FP16
Run on a CPU instead of the V100 GPU
Use a GeForce Titan X GPU instead of a V100
Use TF 1.14 on a V100 GPU (but not TF 1.15.0 or 2.0.0)

&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

A small gist with a fully working example of only ~10 lines can be found here:
&lt;denchmark-link:https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf1-py&gt;https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf1-py&lt;/denchmark-link&gt;
 (TF 1.15.0 version)
&lt;denchmark-link:https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf2-py&gt;https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf2-py&lt;/denchmark-link&gt;
 (TF 2.0.0 version)
I even tried to mimic the cuBLAS call but that didn't crash, so it seems a TensorFlow bug rather than cuBLAS, unless I made a mistake of course:
&lt;denchmark-link:https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_mimic-cu&gt;https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_mimic-cu&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='CNugteren' date='2019-12-13T05:34:15Z'>
		Sample code snippet is working as expected on Colab with Tf 1.15 and Tf 2.0.
Please see the gist of &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/ac001417dc6c92becd9971be07f98456/untitled299.ipynb&gt;Tf 1.15&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/0cbe3a109bb78b10a31e81f367cbfac8/untitled300.ipynb&gt;Tf 2.0&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='CNugteren' date='2019-12-13T08:04:59Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
, sorry I don't have a Google account so I can't run that. But are you sure this is on a V100? If so, please share all the details of the nvidia drivers and cuda/cudnn setup that you are using in this Colab environment.
		</comment>
		<comment id='3' author='CNugteren' date='2019-12-13T09:25:31Z'>
		&lt;denchmark-link:https://github.com/CNugteren&gt;@CNugteren&lt;/denchmark-link&gt;
, Google Colab uses P100.
		</comment>
		<comment id='4' author='CNugteren' date='2019-12-13T10:07:09Z'>
		So please test it on a V100, that's where the bug manifests, as you can see from my description.
		</comment>
		<comment id='5' author='CNugteren' date='2019-12-13T23:24:22Z'>
		I wasn't able to reproduce this on a Titan-V.  Can enable &lt;denchmark-link:https://docs.nvidia.com/cuda/cublas/index.html#cublasLoggerConfigure&gt;cuBLAS logging&lt;/denchmark-link&gt;
 and attach the generated log?  Maybe that will uncover a smoking gun.
		</comment>
		<comment id='6' author='CNugteren' date='2019-12-16T09:08:28Z'>
		OK good idea, I've done that now.
Running the official TF 1.15.0 on a V100 with CUDA 10.0 and cuDNN 7.6.4 with NVIDIA driver 418.56:
python3 &lt;denchmark-link:https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf1-py&gt;https://gist.github.com/CNugteren/c40f0f34f2af759b2d900223fefadbfd#file-tf_v100_cublas_crash_tf1-py&lt;/denchmark-link&gt;

Results in regular output as follows:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3966986/regular_output.txt&gt;regular_output.txt&lt;/denchmark-link&gt;

And with CUBLAS_LOGINFO_DBG=1 set also this cuBLAS specific output:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3966990/cublas_report.txt&gt;cublas_report.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='CNugteren' date='2019-12-26T22:05:00Z'>
		I was able to reproduce this on a TitanV.  This fails with TF 2.0.0 but passes with tf-nightly (2.1.0-dev20191226).  It could have been a TF issue that got fixed or a CUDA issue that was fixed in 10.1 (2.0.0 uses CUDA 10, TF nightly uses CUDA 10.1).
I'm closing this for now, please reopen if there is something more for us to do here.
		</comment>
		<comment id='8' author='CNugteren' date='2019-12-26T22:05:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35032&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35032&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='CNugteren' date='2019-12-27T10:06:22Z'>
		Thanks &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
. Just for your information: I also tried with my own compiled version of TF 1.15.0 with the latest CUDA 10.1 and that didn't solve the issue, so I doubt that that changed it. But I'm glad it is fixed in TF 2.1. So that also means you won't backport this fix to the 1.x branch (e.g. 1.15.1)?
		</comment>
		<comment id='10' author='CNugteren' date='2019-12-27T15:43:06Z'>
		
So that also means you won't backport this fix to the 1.x branch (e.g. 1.15.1)?

I don't think there are any plans for a 1.15.1 release (CC &lt;denchmark-link:https://github.com/goldiegadde&gt;@goldiegadde&lt;/denchmark-link&gt;
 ).
And at this point I'm not even sure what change fixed this, given that you're saying it wasn't the CUDA upgrade.
		</comment>
		<comment id='11' author='CNugteren' date='2019-12-30T19:42:22Z'>
		Exeperienced this as well with a V100, NVIDIA drivers 418, CUDA 10.1 and 2.1.0rc2:

tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found. (0) Internal: Blas GEMM launch failed : a.shape=(1000, 1024), b.shape=(1024, 3), m=1000, n=3, k=1024
[[{{node mrcnn_class_logits/dense/MatMul}}]]
[[add_metric_2/Identity/_3667]] (1) Internal: Blas GEMM launch failed : a.shape=(1000, 1024), b.shape=(1024, 3), m=1000, n=3, k=1024
[[{{node mrcnn_class_logits/dense/MatMul}}]]

Was successful with an image based on today's nightly-gpu-py3 with digest 7cdb1957c9bf.
		</comment>
	</comments>
</bug>