<bug id='2447' author='mrry' open_date='2016-05-21T00:54:12Z' closed_time='2016-06-15T19:01:58Z'>
	<summary>TensorFlow segfaults on attempting to save a large variable</summary>
	<description>
The checkpoint format writes the value of a variable into a Protocol Buffer, which has a 2GB limit. The saving mechanism does not validate the size of a variable—which can be much larger than 2GB—before attempting to write it into the Protocol Buffer. The following code can cause a segfault:
with tf.Session("") as sess:
  # Declare a variable of size 4GB.                                                                                                                    
  var = tf.Variable(tf.zeros([1024, 1024, 1024], dtype=tf.float32))
  save = tf.train.Saver({var.op.name: var})
  var.initializer.run()
  save.save(sess, save_path)
	</description>
	<comments>
	</comments>
</bug>