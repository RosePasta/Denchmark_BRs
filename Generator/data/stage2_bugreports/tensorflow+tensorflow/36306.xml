<bug id='36306' author='terhorst' open_date='2020-01-29T11:59:57Z' closed_time='2020-12-03T16:39:18Z'>
	<summary>Gradients do not propagate when iterating over dataset in graph mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.15
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2.0-dev20200128
Python version: 3.8

Describe the current behavior
Gradients become None if iterating over a tf.data.Dataset in graph mode. The correct answer is returned in eager mode.
Describe the expected behavior
Gradients in eager and graph mode should be the same.
Code to reproduce the issue
Example:
&lt;denchmark-code&gt;data = tf.range(10, dtype=tf.float32)
ds = tf.data.Dataset.from_tensor_slices(data)
u = tf.Variable(1., dtype=tf.float32)

with tf.GradientTape(persistent=True) as g:
    loss1 = ds.reduce(tf.constant(0.), lambda x, y: x + (y - u) ** 2)
    loss2 = tf.reduce_sum([(y - u) ** 2 for y in ds.as_numpy_iterator()])
print(g.gradient(loss1, u))  # returns None
print(g.gradient(loss2, u))  # returns correct gradient
&lt;/denchmark-code&gt;

The same behavior is observed when using for x in ds: ... inside of a @tf.function.
Gist &lt;denchmark-link:https://colab.research.google.com/gist/terhorst/b51638f5e9657eb7f44553922c5a93c5/untitled3.ipynb&gt;here&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='terhorst' date='2020-01-29T12:20:45Z'>
		A workaround is to move the GradientTape inside of the accumulated function, and accumulate gradients alongside the loss.
		</comment>
		<comment id='2' author='terhorst' date='2020-01-30T05:25:48Z'>
		I have tried on colab with TF version 2.2.0-dev20200129 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/1641e618441ed823560057b4d24c6d75/untitled604.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='3' author='terhorst' date='2020-07-21T12:02:31Z'>
		I have tried on colab with TF version 2.3-rc1, 2.4.0-dev20200721 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/750d4f1c916c795e98adad09c28bf03c/untitled163.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='4' author='terhorst' date='2020-12-03T16:39:18Z'>
		&lt;denchmark-link:https://github.com/terhorst&gt;@terhorst&lt;/denchmark-link&gt;
 tf.data does not support gradients. Closing this issue as of now since it is the intended behavior.Thanks!
		</comment>
		<comment id='5' author='terhorst' date='2020-12-03T16:39:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36306&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36306&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>