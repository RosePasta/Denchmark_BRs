<bug id='44137' author='smehra34' open_date='2020-10-19T09:13:35Z' closed_time='2020-10-20T14:36:41Z'>
	<summary>CUDA_ERROR_NOT_INITIALIZED when using multiprocessing with ImageDataGenerator + random hue preprocessing function</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Red Hat 7.4
TensorFlow installed from (source or binary):
TensorFlow version (use command below): 2.3.0
Python version: 3.7.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source): GCC 7.3.0
CUDA/cuDNN version: CUDA 10.1/cuDNN 7.6.5

Describe the current behavior
Currently using ImageDataGenerator to load my data and apply random augmentations during training. This works fine with multiprocessing (setting use_multiprocessing=True in model.fit), until I add a preprocessing function into my data generator to perform random hue augmentations (using tf.image.random_hue). Doing this gives me the following error:
2020-10-19 18:33:13.420481: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error 
I've also tried using tf.image.stateless_random_hue from tf-nightly, since that adjusts the hue deterministically, however I run into the same issue regardless.
It works as expected when I set use_multiprocessing=False, however since I'm training on a large dataset this would create a significant bottleneck, so any possible fixes or workarounds would be greatly appreciated.
Standalone code to reproduce the issue
(example code assuming there are train and test directories contain 2 classes of images to be read in using flow_from_directory)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, BatchNormalization,
                                     MaxPool2D, Flatten, Dense)
from tensorflow.keras.optimizers import Adam
from tensorflow.image import random_hue
import numpy as np

# random hue augmentations - PROBLEMATIC WITH MULTIPROCESSING
def color_augmentation(image):
    return random_hue(image, 0.1)

# get the data generators
# apply random augmentations during training including hue augmentations
train_datagen = ImageDataGenerator(
    rescale=1./255,
    vertical_flip = True,
    horizontal_flip = True,
    preprocessing_function = color_augmentation
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    'train/',
    target_size = (96, 96),
    batch_size = 32,
)

test_generator = test_datagen.flow_from_directory(
    'test/',
    target_size = (96, 96),
    batch_size = 32,
)

# create model
model = Sequential()
model.add(Conv2D(filters=32, strides=1,input_shape=(96,96,3),
                 activation='relu', kernel_size=3, padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D())
model.add(Conv2D(filters=64, strides=1, activation='relu',
                 kernel_size=3, padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D())
model.add(Flatten())
model.add(Dense(units=2, activation='softmax'))

# compile model
model.compile(
    optimizer=Adam(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# fit the model, using multiprocessing
history = model.fit(
    x = train_generator,
    steps_per_epoch = len(train_generator),
    epochs = 5,
    verbose = 1,
    validation_data = test_generator,
    validation_steps = len(test_generator),
    workers = 4,
    use_multiprocessing = True,
    max_queue_size = 8
)
Other info / logs
&lt;denchmark-code&gt;2020-10-19 19:34:54.590677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-19 19:34:57.529118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-19 19:34:57.547866: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-10-19 19:34:57.552945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555558e11bd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-19 19:34:57.552983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-19 19:34:57.556307: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-10-19 19:34:57.784089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555558ea46c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-19 19:34:57.784175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-10-19 19:34:57.786709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s
2020-10-19 19:34:57.786764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-19 19:34:57.791365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-10-19 19:34:57.795504: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-10-19 19:34:57.797375: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-10-19 19:34:57.801231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-10-19 19:34:57.803387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-10-19 19:34:57.811940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-19 19:34:57.815365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-19 19:34:57.815402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-10-19 19:34:58.501529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-19 19:34:58.501575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-10-19 19:34:58.501581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-10-19 19:34:58.503865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/device:GPU:0 with 14951 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:25:00.0, compute capability: 6.0)
2020-10-19 19:34:58.862187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0
coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s

...

WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.
Found GPU at: /device:GPU:0
Found 1200 images belonging to 2 classes.
Found 200 images belonging to 2 classes.
Epoch 1/5
2020-10-19 19:34:59.947779: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:34:59.949834: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:34:59.952581: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:34:59.956651: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.090631: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.135802: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.171513: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.221924: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.358671: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-10-19 19:35:00.403905: F tensorflow/stream_executor/cuda/cuda_driver.cc:219] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='smehra34' date='2020-10-19T09:32:38Z'>
		&lt;denchmark-link:https://github.com/smehra34&gt;@smehra34&lt;/denchmark-link&gt;

Please, share thr complete standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. I have tried in colab and i am seeing the below error message.(FileNotFoundError: [Errno 2] No such file or directory: 'train/'). Thanks!
		</comment>
		<comment id='2' author='smehra34' date='2020-10-19T09:59:28Z'>
		Sorry about that, here's the same code but loading in the CIFAR10 dataset instead.
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, BatchNormalization,
                                     MaxPool2D, Flatten, Dense)
from tensorflow.keras.optimizers import Adam
from tensorflow.image import random_hue
from tensorflow.keras.datasets import cifar10
import numpy as np


# random hue augmentations - PROBLEMATIC WITH MULTIPROCESSING
def color_augmentation(image):
    return random_hue(image, 0.1)

# get the datagenerators. Apply random augmentations during training including
# random hue augmentations
train_datagen = ImageDataGenerator(
    rescale=1./255,
    vertical_flip = True,
    horizontal_flip = True,
    preprocessing_function = color_augmentation
)

test_datagen = ImageDataGenerator(rescale=1./255)

(x_train, y_train),(x_test, y_test) = cifar10.load_data()

train_generator = train_datagen.flow(
     x_train, y=y_train, batch_size=32
)

test_generator = test_datagen.flow(
    x_test, y=y_test, batch_size=32
)

# create model
model = Sequential()
model.add(Conv2D(filters=32, strides=1,input_shape=(32,32,3),
                 activation='relu', kernel_size=3, padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D())
model.add(Conv2D(filters=64, strides=1, activation='relu',
                 kernel_size=3, padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D())
model.add(Flatten())
model.add(Dense(units=10, activation='softmax'))

# compile model
model.compile(
    optimizer=Adam(learning_rate=0.01),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# fit the model, using multiprocessing
history = model.fit(
    x = train_generator,
    steps_per_epoch = len(train_generator),
    epochs = 5,
    verbose = 1,
    validation_data = test_generator,
    validation_steps = len(test_generator),
    workers = 4,
    use_multiprocessing = True,
    max_queue_size = 8
)
		</comment>
		<comment id='3' author='smehra34' date='2020-10-20T07:00:49Z'>
		&lt;denchmark-link:https://github.com/smehra34&gt;@smehra34&lt;/denchmark-link&gt;

I tried in colab with TF version 2.3 but the code is keep on running. Please, see the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/b45c8035f32ee121cf3c715af034dc19/untitled467.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='4' author='smehra34' date='2020-10-20T07:19:47Z'>
		Sorry I probably wasn't clear enough before but when that warning comes up, it seems to just hang and not actually train the model rather than throwing an error and terminating the program. I tried using your gist and the same thing happens. If you look at the runtime log on colab, the same CUDA_ERROR_NOT_INITIALISED warning shows up, and the model doesn't actually seem to be training at all (verbose flag is set to 1, however it doesn't show that anything is training. If you set use_multiprocessing=False however, or get rid of the random_hue preprocessing function, it all works as expected).
		</comment>
		<comment id='5' author='smehra34' date='2020-10-20T07:39:43Z'>
		&lt;denchmark-link:https://github.com/smehra34&gt;@smehra34&lt;/denchmark-link&gt;

Glad to know it worked. Please,close this thread if your issue was resolved. Thanks!
		</comment>
		<comment id='6' author='smehra34' date='2020-10-20T07:50:24Z'>
		No I mean it's still not working. Even though the program doesn't terminate due to this warning, it's not executing as it should be either. It just hangs indefinitely without actually training the model.
		</comment>
		<comment id='7' author='smehra34' date='2020-10-20T12:49:26Z'>
		&lt;denchmark-link:https://github.com/smehra34&gt;@smehra34&lt;/denchmark-link&gt;
 If you try with 2.3.x/tf-nightly you will see a warning:

		</comment>
		<comment id='8' author='smehra34' date='2020-10-20T13:53:45Z'>
		&lt;denchmark-link:https://github.com/smehra34&gt;@smehra34&lt;/denchmark-link&gt;
 As mentioned above, try using tf.data would solve your problem
		</comment>
		<comment id='9' author='smehra34' date='2020-10-20T14:36:41Z'>
		Thanks &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
! Just tested it briefly and wrapping the data generators with  seems to do the trick. I'll close this issue.
		</comment>
		<comment id='10' author='smehra34' date='2020-10-20T14:36:43Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44137&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44137&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>