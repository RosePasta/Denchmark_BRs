<bug id='38279' author='mattdutson' open_date='2020-04-06T18:03:16Z' closed_time='2020-05-28T18:24:12Z'>
	<summary>MutableGraphView::SortTopologically error with tf.nn.conv2d in custom RNN cell</summary>
	<description>
System information

Have I written custom code: yes
OS Platform and Distribution: Ubuntu 18.04 LTS
TensorFlow installed from: binary (conda install tensorflow-gpu=2.1)
TensorFlow version: 2.1.0
Python version: 3.7.7
CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6
GPU model and memory: GeForce GTX 1080, 8 GB

Describe the current behavior
Calling predict on a model containing a custom RNN layer whose cell calls tf.nn.conv2d results in the following error being printed to the console:
&lt;denchmark-code&gt;2020-04-06 12:40:50.843591: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/sequential/rnn/while/body/_1/input/_55' -&gt; 'sequential/rnn/while/body/_1/add'}.
&lt;/denchmark-code&gt;

The prediction proceeds (and appears to be correct), but has poor performance.
This does not occur if the tf.nn.conv2d is replaced with other similar operations (tf.nn.conv1d for example).
Describe the expected behavior
The expected behavior is for no error to be produced.
Standalone code to reproduce the issue
The following code produces the error:
import tensorflow as tf


class CustomCell(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        self.state_size = [tf.TensorShape((16, 16, 1))]
        super(CustomCell, self).__init__(**kwargs)

    def call(self, inputs, states, **kwargs):
        output = states[0] + tf.nn.conv2d(inputs, tf.ones((3, 3, 1, 1)), (1, 1), "SAME")
        new_state = output
        return output, new_state


model = tf.keras.models.Sequential()
model.add(tf.keras.layers.RNN(CustomCell(), batch_input_shape=(1, 1, 16, 16, 1)))

# Error here
model.predict(tf.ones(model.input_shape))
If the conv2d is replaced with conv1d, however, no error occurs:
import tensorflow as tf


class CustomCell(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        self.state_size = [tf.TensorShape((16, 1))]
        super(CustomCell, self).__init__(**kwargs)

    def call(self, inputs, states, **kwargs):
        output = states[0] + tf.nn.conv1d(inputs, tf.ones((3, 1, 1)), (1,), "SAME")
        new_state = output
        return output, new_state


model = tf.keras.models.Sequential()
model.add(tf.keras.layers.RNN(CustomCell(), batch_input_shape=(1, 1, 16, 1)))

# No error
model.predict(tf.ones(model.input_shape))
	</description>
	<comments>
		<comment id='1' author='mattdutson' date='2020-04-07T08:41:16Z'>
		&lt;denchmark-link:https://github.com/mattdutson&gt;@mattdutson&lt;/denchmark-link&gt;
,
I was able to run the above code snippets without any error messages with both &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/1bfea7bbe1311e108c5864964ef07b91/38279-2-1.ipynb&gt;TF v2.1&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a5a66e6f344ce0fd75943c7d48426305/38279-2-2.ipynb&gt;TF v2.2.0rc2&lt;/denchmark-link&gt;
. Please find the attached gist.
Could you please try running the same code in a virtual environment and let us know if it works? Thanks!
		</comment>
		<comment id='2' author='mattdutson' date='2020-04-07T16:54:53Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 Thanks for the quick reply. It looks like IPython is hiding/suppressing the error message. If you upload the example code snippet to a file  in the Colab folder and then run from the command-line via  you can see the error message.
		</comment>
		<comment id='3' author='mattdutson' date='2020-04-08T19:10:29Z'>
		I have the same issue
		</comment>
		<comment id='4' author='mattdutson' date='2020-04-08T23:41:41Z'>
		I noticed today that the error goes away if the RNN layer is constructed with unroll=True.
		</comment>
		<comment id='5' author='mattdutson' date='2020-04-08T23:42:21Z'>
		Unrolling is apparently more memory-intensive, however.
		</comment>
		<comment id='6' author='mattdutson' date='2020-04-09T07:59:37Z'>
		Was able to reproduce the issue with TF v2.2.0rc2 and TF-nightly. Please find the gist &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/d59dbcfeb6358851fb6f2994e49f7357/38279-2-2.ipynb#scrollTo=sxLOo03U2rnI&amp;line=1&amp;uniqifier=1&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='mattdutson' date='2020-04-10T11:41:06Z'>
		Please let me know when you have a fix, thanks!    On Thursday, April 9, 2020, 03:59:55 PM GMT+8, amahendrakar &lt;notifications@github.com&gt; wrote:




Was able to reproduce the issue with TF v2.2.0rc2 and TF-nightly. Please find the gist here. Thanks!

â€”
You are receiving this because you commented.
Reply to this email directly, view it on GitHub, or unsubscribe.
		</comment>
		<comment id='8' author='mattdutson' date='2020-05-04T17:49:04Z'>
		Seems to  be a grappler issue.
		</comment>
		<comment id='9' author='mattdutson' date='2020-05-28T18:24:12Z'>
		This appears to be fixed in the latest version at head. I cannot reproduce the error with the code snippet provided. Feel free to reopen if you see this again.
		</comment>
		<comment id='10' author='mattdutson' date='2020-05-28T18:24:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38279&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38279&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='mattdutson' date='2020-06-01T19:36:59Z'>
		Just tested this with tf-nightly. The issue does not appear to be resolved. Running the first snippet results in the following error message:
&lt;denchmark-code&gt;2020-06-01 14:34:55.279045: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:575] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'sequential/rnn/while/next_iteration/_37-0-0-TransposeNCHWToNHWC-LayoutOptimizer' -&gt; 'sequential/rnn/while/merge/_13'}.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='12' author='mattdutson' date='2020-06-01T19:38:03Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 Don't think I have the permissions required to reopen the issue. Could you reopen it?
		</comment>
		<comment id='13' author='mattdutson' date='2020-11-12T04:10:15Z'>
		I have the same issue, any advice?
		</comment>
		<comment id='14' author='mattdutson' date='2020-11-17T15:20:41Z'>
		In my case, it seems that the error occurs when I let tensorflow do its Layout optimization.
As soon as I added:
tf.config.optimizer.set_experimental_options({'layout_optimizer': False})
the error disappeared. I suspect the optimization procedure to be the origin of the problem. This should be investigated.
Hope it helps !
		</comment>
	</comments>
</bug>