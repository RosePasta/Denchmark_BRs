<bug id='2957' author='mrry' open_date='2016-06-20T16:10:07Z' closed_time='2016-06-22T02:32:32Z'>
	<summary>Dequeueing immediately after starting threads fails</summary>
	<description>
From &lt;denchmark-link:http://stackoverflow.com/questions/37878696/dequeue-immediately-after-starting-threads-fails&gt;a question on Stack Overflow&lt;/denchmark-link&gt;
, the following code fails:
import tensorflow as tf
import time
with tf.Graph().as_default():
    filename_list = ['data_batch_{}.mat'.format(i+1) for i in range(5)]
    filename_queue = tf.train.string_input_producer(filename_list)

    with tf.Session() as sess:
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)

        #time.sleep(1) # If I uncomment this it works
        for i in range(5):
            print(sess.run(filename_queue.dequeue()))

        coord.request_stop()
        coord.join(threads)
...with the following error:
NotFoundError: FetchOutputs node input_producer_Dequeue:0: not found
It turns out that my fix for &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/2425&gt;#2425&lt;/denchmark-link&gt;
 was incomplete, and there is still a race between concurrent graph modification and  calls. I'm preparing a fix.
	</description>
	<comments>
		<comment id='1' author='mrry' date='2016-06-22T02:32:32Z'>
		Fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/91d65f6e5971302081a9348c4188a5031c30b021&gt;91d65f6&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>