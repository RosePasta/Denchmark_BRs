<bug id='38748' author='Flamefire' open_date='2020-04-21T12:55:54Z' closed_time='2020-06-06T00:23:28Z'>
	<summary>Using tf.Dataset in non-eager mode impossible</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0
Python version: 3.7.4

Describe the current behavior
I'd like to compare eager and non-eager mode using a custom training loop and a TF Dataset as the input.
This seems to be impossible as shape information seems to be unavailable and even basic training loops throw "Attempting to capture an EagerTensor without building a function."
I also couldn't find any documentation on how to do that.
Describe the expected behavior
Custom training loops should be possible in graph (non-eager) mode with tf.Dataset and documented
Standalone code to reproduce the issue
Heavily reduced example:
&lt;denchmark-code&gt;import tensorflow as tf
tf.compat.v1.disable_eager_execution()

def preprocess(x, l):
    return tf.image.convert_image_dtype(x, tf.float32), l

train_data, test_data = tf.keras.datasets.mnist.load_data()
train_data = tf.data.Dataset.from_tensor_slices(train_data).map(preprocess)

@tf.function
def run_loop(model, data):
    res = True
    for x, y in data:
        batch_size = int(x.shape[0])
        res = model(x)[0] == 1.
    return res

model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation='softmax')])
result = run_loop(model, train_data.batch(32, drop_remainder=False)) # drop_remainder=True for "EagerTensor" exception
&lt;/denchmark-code&gt;

Other info / logs
The first failure in the above is the line with batch_size as it tries to convert a None value, but at that point the value should be known already.
Changing the default drop_remainder to True avoids this.
The tensor causing the "capture..." failure has a dtype of resource. Not sure what that is.
Obviously the above doesn't do much, but reproduces the failure. My real training loop has all the GradientTape, loss, callbacks etc.
	</description>
	<comments>
		<comment id='1' author='Flamefire' date='2020-04-21T14:45:45Z'>
		&lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;

i ran the code shared by you and face this error,please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/dcf9229cae9d4ee245ee7907ed73c4d6/untitled145.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='Flamefire' date='2020-05-07T13:08:01Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='Flamefire' date='2020-05-07T13:15:29Z'>
		not solved
		</comment>
		<comment id='4' author='Flamefire' date='2020-05-07T14:09:05Z'>
		&lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;

Please update as per above comment
		</comment>
		<comment id='5' author='Flamefire' date='2020-05-07T14:17:05Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 Sorry? You said you ran the code provided and facing the same error reported here. To quote:

TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'

Which is mentioned in the description:

The first failure in the above is the line with batch_size as it tries to convert a None value, but at that point the value should be known already.
Changing the default drop_remainder to True avoids this.

So what is missing?
		</comment>
		<comment id='6' author='Flamefire' date='2020-06-04T18:50:56Z'>
		&lt;denchmark-link:https://github.com/tomerk&gt;@tomerk&lt;/denchmark-link&gt;
 could you please take a look (or triage to someone on the Keras team)? Thank you.
		</comment>
		<comment id='7' author='Flamefire' date='2020-06-04T21:28:14Z'>
		Hi &lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;
,
A few things here:

Why are you trying to use a custom training loop and disabling eager execution?  Generally speaking if you're using a custom training loop (as opposed to using tf1 session-based code) then disabling eager execution probably isn't the right way to achieve whatever you're trying to achieve. If you're trying to get graph performance using tf.function will do that. But, I see you're using a tf.function and calling compat.v1 to disable eager execution. So what's the goal here?

Many TF2-only apis won't work properly if you've explicitly disabled eager. This can pop up with pretty unexpected error messages

The tensor's .shape attribute actually  isn't  known at that point in time.
tensor.shape is a static property on the tensor that is set at tensor construction time and can always be accessed as a direct python object. When you don't drop the remainder the batch size is unknown and will be None in the static property.

If you want to dynamically grab the batch size and use it in your computation you need to use tf.shape(x[0]). tf.shape returns a tensor representing whatever the shape of the tensor is at the point when it's used.
From the documentation of tensor.shape:
&lt;denchmark-code&gt;    """Returns a `tf.TensorShape` that represents the shape of this tensor.

    &gt;&gt;&gt; t = tf.constant([1,2,3,4,5])
    &gt;&gt;&gt; t.shape
    TensorShape([5])

    `tf.Tensor.shape` is equivalent to `tf.Tensor.get_shape()`.

    In a `tf.function` or when building a model using
    `tf.keras.Input`, they return the build-time shape of the
    tensor, which may be partially unknown.

    A `tf.TensorShape` is not a tensor. Use `tf.shape(t)` to get a tensor
    containing the shape, calculated at runtime.

    See `tf.Tensor.get_shape()`, and `tf.TensorShape` for details and examples.
    """
&lt;/denchmark-code&gt;


I was originally seeing the "capture EagerTensor" exception you mentioned, but it no longer seems to be appearing for me... do you see it in the tf-nightly &amp; with the batch size access fixed?

Keep in mind it's very low priority for us to fix if you're using compat.v1.disable_eager_execution unless it's an active regression from TF1 running the same code.
		</comment>
		<comment id='8' author='Flamefire' date='2020-06-05T07:06:41Z'>
		&lt;denchmark-link:https://github.com/tomerk&gt;@tomerk&lt;/denchmark-link&gt;
 Thanks for your response


As written in the OP I wanted to compare eager and non-eager execution of the same code. From your response I conclude that using the v2 APIs this is simply not intended and hence impossible and only worked by chance. Maybe this could be made more clear in the documentation? From the current description I understood that "eager" is the default which trades off performance for ease of use. I hence wanted to see what happens when it is turned off and expected a performance improvement. The problem with tf.function is, that it does not fully recover graph performance. Likely due to synchronization happening after each batch to get the metric values from the GPUs and maybe due to different data handling (preprocessing, uploading, ...). Also some callbacks can't be run inside a tf.function so the whole training loop can't be wrapped in a tf.function but only the individual steps


Thanks for the clarification. It seems I used that previously outside of a tf.function where it worked. The quoted part of the documentation is pretty clear. Haven't seen that previously or it was updated since.


Can confirm this is fixed in the nightly.


		</comment>
		<comment id='9' author='Flamefire' date='2020-06-06T00:23:05Z'>
		The way to think about TF2 is it's eager (by default), and you can enter a tf.function to run part of your code in a graph for performance reasons.
tf.compat.v1.disable_eager_execution isn't designed for entering a graph for performance reasons, it's meant as a totally-legacy-compatibility toggle if you find yourself in a situation where you need to run graph-only TF1 code with TF2 binaries. This might happen e.g. if you're actively migrating code from TF1 to TF2, or running legacy code in an environment that only has TF2 installed.
From the TF api docs for compat.v1.disable_eager_execution:
&lt;denchmark-code&gt;This function can only be called before any Graphs, Ops, or Tensors have been created. It can be used at the beginning of the program for complex migration projects from TensorFlow 1.x to 2.x.
&lt;/denchmark-code&gt;

Please let us know how we could clarify this, or if it was a different piece of documentation that led you to believe that to build graphs in TF2 you are supposed to call disable_eager_execution()
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Generally speaking if code doesn't run in a tf.function it would not run in a legacy TF 1.x graph at all, so that's unlikely to be the cause of tf.function not matching TF 1.x graph performance. E.g. datasets can be constructed (or passed into) tf.functions, so it's possible to iterate over your entire dataset in a tf.function call.
Callbacks don't usually have to be called every training step, so you can roll several training steps into one tf.function and only run callbacks in between them. If you're writing a custom loop it's possible to do yourself in your loop. As of recently, Keras models have a  you can override to do just when you're fitting the model with . (Guides for this are in progress I believe, or &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 should be able to point you to some). These callbacks wouldn't run inside a TF 1.x graph regardless.
That's not to say  never has overheads. Depending on how you write your code, you might accidentally cause the function to retrace/recompile more than you expected. If that's the case you should look at the "better performance" w/ tf.functions guide:
&lt;denchmark-link:https://www.tensorflow.org/guide/function&gt;https://www.tensorflow.org/guide/function&lt;/denchmark-link&gt;

Any part of your code that is inside a single tf.function trace should run just as fast (or faster) w/ TF2 as it would in a TF1 graph though. (and for things that don't feel free to file a bug!)
		</comment>
		<comment id='10' author='Flamefire' date='2020-06-06T00:23:28Z'>
		Closing this issue for now because the reported error is fixed in nightly.
		</comment>
		<comment id='11' author='Flamefire' date='2020-06-06T00:23:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38748&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38748&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>