<bug id='35523' author='darthbhyrava' open_date='2020-01-01T12:58:47Z' closed_time='2020-02-06T18:48:19Z'>
	<summary>Tensorflow 2.0 (GPU) throws CancelledErrors while fitting models</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): r2.0
Python version: 3.6.9
Bazel version (if compiling from source): 0.26.0
GCC/Compiler version (if compiling from source): 7.4.0
CUDA/cuDNN version: v10.1
GPU model and memory: GeForce RTX 2070 Super (8GB)

Describe the current behavior
The script throws a CancelledError when fitting the model (very 1st epoch)
Describe the expected behavior
$ model.fit( ... ) is executed without throwing any errors.
Code to reproduce the issue
&lt;denchmark-code&gt;model = Sequential()
model.add(Embedding(vocab_size, dimensions,weights=[embedding_matrix], input_length=pad2, trainable=True))
model.add(GRU(128, return_sequences=True))
model.add(MaxPooling1D())
model.add(AveragePooling1D())
model.add(GRU(128))
model.add(Dense(len(set(outputs)), activation='sigmoid'))
checkpoint = ModelCheckpoint('model-%s-%s-%s-%s' %(setting, indicators, case, str(window_size)), verbose=1, monitor='val_acc', save_best_only=True, mode='auto')
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print(model.summary())
# The summary is as expected
train, dev = padded_docs[:split], padded_docs[split:]
y_train, y_dev = y[:split], y[split:]
model.fit(train, y_train, epochs=epochs, verbose=1, callbacks=[checkpoint], batch_size=batch_size, validation_data=(dev, y_dev))
# This is where the script fails
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;CancelledError                            Traceback (most recent call last)
&lt;ipython-input-18-ba796bf236a0&gt; in &lt;module&gt;
     70         train, dev = padded_docs[:split], padded_docs[split:]
     71         y_train, y_dev = y[:split], y[split:]
---&gt; 72         model.fit(train, y_train, epochs=epochs, verbose=1, callbacks=[checkpoint], batch_size=batch_size, validation_data=(dev, y_dev))
     73         pred = model.predict(dev, batch_size=batch_size)
     74         model.save('./cross-fold-models/model-%s-%s-%s-%s-%s' %(setting, indicators, case, str(window_size), str(number)))

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--&gt; 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--&gt; 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--&gt; 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---&gt; 86                               distributed_function(input_fn))
     87 
     88   return execution_function

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--&gt; 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    518         # Lifting succeeded, so variables are initialized and we can run the
    519         # stateless function.
--&gt; 520         return self._stateless_fn(*args, **kwds)
    521     else:
    522       canon_args, canon_kwds = \

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   1821     """Calls a graph function specialized to the inputs."""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-&gt; 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-&gt; 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-&gt; 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=("executor_type", executor_type, "config_proto", config),
--&gt; 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---&gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node Adam/Adam/update/AssignSubVariableOp/_45}}]]
	 [[Reshape_14/_42]] [Op:__inference_distributed_function_18141]

Function call stack:
distributed_function
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='darthbhyrava' date='2020-01-01T13:04:51Z'>
		I see that this error has been raised before:

33721: Downgrading TF to 1.14 'solved' the issue. I cannot downgrade TF from 2.0
33200: Fixing gast did not solve the issue.
SO Question: My CUDA version isn't an issue.

Some more context:

To fix a previous issue about mismatched versions, I had to refer to this answer and append a tensorflow prefix to all my keras imports.

		</comment>
		<comment id='2' author='darthbhyrava' date='2020-01-02T04:18:03Z'>
		I am having the same issue.
		</comment>
		<comment id='3' author='darthbhyrava' date='2020-01-02T05:59:01Z'>
		&lt;denchmark-link:https://github.com/darthbhyrava&gt;@darthbhyrava&lt;/denchmark-link&gt;

Looks like code is incomplete. Request you to provide colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='4' author='darthbhyrava' date='2020-01-16T12:39:59Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='5' author='darthbhyrava' date='2020-01-17T03:58:00Z'>
		&lt;denchmark-link:https://github.com/darthbhyrava&gt;@darthbhyrava&lt;/denchmark-link&gt;

Any update on this issue please. Thanks!
		</comment>
		<comment id='6' author='darthbhyrava' date='2020-01-17T04:04:15Z'>
		Not OP, but I am not longer receiving this issue
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Jan 16, 2020 at 9:58 PM ravikyram ***@***.***&gt; wrote:
 @darthbhyrava &lt;https://github.com/darthbhyrava&gt;
 Any update on this issue please. Thanks!

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#35523?email_source=notifications&amp;email_token=AHPAW4YETG5PSCBBOQQPSTDQ6EUE7A5CNFSM4KB3BUX2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJGLVLY#issuecomment-575453871&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AHPAW43MMI7V6RJ4ULNJS7LQ6EUE7ANCNFSM4KB3BUXQ&gt;
 .



		</comment>
		<comment id='7' author='darthbhyrava' date='2020-01-18T07:05:44Z'>
		
@darthbhyrava
Looks like code is incomplete. Request you to provide colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!

Thanks for the response, apologies for the delay in replying.
I cannot provide supporting files or the entire code, they're proprietary in nature. However I can provide details for the parameters in the embedding layer, and the nature of the data set with simple examples:
&lt;denchmark-code&gt;from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

# vocab_size
t = Tokenizer(split=" ",lower=True, filters='@')
t.fit_on_texts(X)
vocab_size = len(t.word_index) + 1

# dimensions
dimensions = 300

# embedding_matrix
embedding_matrix = np.zeros((vocab_size, dimensions))
# zeros replaced with GloVe embeddings, shape remains same

# pad2 and padded_docs
encoded_docs = t.texts_to_sequences(X)
max_len = []
for each in encoded_docs:
	max_len.append(len(each))
pad2 = max(max_len)
padded_docs = pad_sequences(encoded_docs, maxlen=pad2, padding='post')

# outputs
Number of labels for classification

# y
Corresponding labels for the input sequences
&lt;/denchmark-code&gt;

Please let me know if additional info is needed.
Also, my workaround was to eventually downgrade tensorflow (to r1.15) and CUDA (to 10.0).
		</comment>
		<comment id='8' author='darthbhyrava' date='2020-01-21T21:10:32Z'>
		&lt;denchmark-link:https://github.com/darthbhyrava&gt;@darthbhyrava&lt;/denchmark-link&gt;
 As mentioned in the other &lt;denchmark-link:https://github.com/keras-team/keras/issues/12379#issuecomment-471339468&gt;post&lt;/denchmark-link&gt;
, did you import modules from ? If the issue was cleared by using tensorflow.keras.* then please close the issue.
If the issue is with keras module (if you are using ) , then please post it in the &lt;denchmark-link:https://github.com/keras-team/keras/issues&gt;`keras repository here&lt;/denchmark-link&gt;
. If the issue persists even after importing modules from tensorflow.keras.**, then please use a public data to create a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='9' author='darthbhyrava' date='2020-02-06T18:46:47Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='10' author='darthbhyrava' date='2020-02-06T18:48:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35523&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35523&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>