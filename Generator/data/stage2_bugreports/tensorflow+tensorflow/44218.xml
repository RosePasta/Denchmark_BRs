<bug id='44218' author='palatos' open_date='2020-10-22T03:07:40Z' closed_time='2020-10-22T23:56:08Z'>
	<summary>ModelCheckpoint() verbose changed?</summary>
	<description>

TensorFlow version (use command below): 2.3.0
Python version: 3.7.6

Describe the current behavior
When using tf.keras.callbacks.ModelCheckpoint() with verbose = 1 the callback behaves weirdly.
If I monitor the validation metric, during epochs where the checkpoint is triggered, the validation metric is not shown in the training output. The callback output reads fewer information than it previously did, making it harder to understand if it's working as intended. For example, it currently says something like:
&lt;denchmark-code&gt;14/14 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9929
Epoch 00001: saving model to model.h5
&lt;/denchmark-code&gt;

Describe the expected behavior
Checking some older code, the output used to be something like:
&lt;denchmark-code&gt;14/14 [==============================] - ETA: 0s - loss: 0.0253 - acc: 0.9929 - val_loss: 0.1335 - val_acc: 0.93469
Epoch 00001: val_acc improved from -inf to 0.93469, saving model to model.h5
&lt;/denchmark-code&gt;

This output makes it clearer the checkpoint is monitoring the correct quantity and when the changes are happening.
I just want to be double sure that the current ModelCheckpoint() is doing the expected thing, even if the output is more minimal?
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
The following code should be copy-paste-able and should reproduce the problem:
&lt;denchmark-code&gt;import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf

# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print("x_train shape:", x_train.shape)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)

model.summary()

my_callbacks = [
    tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor = 'val_categorical_accuracy', verbose =2),
]

batch_size = 128
epochs = 5

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["categorical_accuracy"])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks = my_callbacks)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='palatos' date='2020-10-22T04:23:10Z'>
		&lt;denchmark-link:https://github.com/palatos&gt;@palatos&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.3 , nightly version () and i am not seeing any issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/f2845463028b1167dd44d4d776d14105/untitled477.ipynb&gt;here&lt;/denchmark-link&gt;
.Please, verify once and close the issue, if you feel it is working as expected. Thanks!
		</comment>
		<comment id='2' author='palatos' date='2020-10-22T04:37:40Z'>
		Thank you for creating that collab notebook. I ran the code there for a slightly larger number of epochs on the tensorflow 2.3.0 part of the code, and notice how the model is checkpointing every epoch even when "val_categorical_accuracy" doesn't improve. This is not how the checkpoint is supposed to behave. Looking at the tf-nightly code further down on your gist I see this incorrect behavior also happened on your own run.
Here is the output for some epochs where val_categorical_accuracy did not improve but the model still checkpointed anyway:
&lt;denchmark-code&gt;Epoch 00007: saving model to model.h5
422/422 [==============================] - 2s 5ms/step - loss: 0.0637 - categorical_accuracy: 0.9801 - val_loss: 0.0554 - val_categorical_accuracy: 0.9850
Epoch 8/55
422/422 [==============================] - ETA: 0s - loss: 0.0585 - categorical_accuracy: 0.9820
Epoch 00008: saving model to model.h5
422/422 [==============================] - 2s 5ms/step - loss: 0.0585 - categorical_accuracy: 0.9820 - val_loss: 0.0542 - val_categorical_accuracy: 0.9847
Epoch 9/55
421/422 [============================&gt;.] - ETA: 0s - loss: 0.0561 - categorical_accuracy: 0.9824
Epoch 00009: saving model to model.h5
422/422 [==============================] - 2s 5ms/step - loss: 0.0561 - categorical_accuracy: 0.9824 - val_loss: 0.0537 - val_categorical_accuracy: 0.9837
&lt;/denchmark-code&gt;

Can you confirm if this is the case? The way the print-outs are arranged also makes it confusing as to whether the Model Checkpoint is really doing what it's supposed to do.
		</comment>
		<comment id='3' author='palatos' date='2020-10-22T21:42:32Z'>
		&lt;denchmark-link:https://github.com/palatos&gt;@palatos&lt;/denchmark-link&gt;
 I think we are missing . Please check the &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint&gt;TF page&lt;/denchmark-link&gt;
 of ModelCheckpoint. When I add  as shown below, everything worked as you are expecting.
&lt;denchmark-code&gt;my_callbacks = [
    tf.keras.callbacks.ModelCheckpoint(filepath='Epoch_{epoch:04d}_model.h5', monitor = 'val_categorical_accuracy', verbose =2,save_best_only=True),
]
&lt;/denchmark-code&gt;

In the arguments section, it clearly mentions

if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten. If filepath doesn't contain formatting options like {epoch} then filepath will be overwritten by each new better model.

Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/f0d5f342820c216c5654aa369cc948b6/untitled477.ipynb&gt;gist here&lt;/denchmark-link&gt;
.  In the gist, you can see starting epoch=12, validation accuracy was not improved and the model was not saved. Just to show model saving, i added epoch number in to to the filename. Thanks!
Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='4' author='palatos' date='2020-10-22T23:56:08Z'>
		
Please verify once and close the issue if this was resolved for you. Thanks!

You are right, it was that argument that was missing. Thank you!
I'll close the issue now.
		</comment>
		<comment id='5' author='palatos' date='2020-10-22T23:56:10Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44218&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44218&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>