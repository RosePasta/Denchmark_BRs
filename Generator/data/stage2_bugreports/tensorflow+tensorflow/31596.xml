<bug id='31596' author='michaelbenayoun' open_date='2019-08-13T22:26:37Z' closed_time='2020-05-28T17:10:49Z'>
	<summary>TFLiteConverter fails with tf.gather when the params argument is a layer attribute</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.5 LTS
TensorFlow installed from (source or binary): conda
TensorFlow version (use command below): 2.0.0-dev20190807
Python version: 3.6.8
CUDA/cuDNN version: 10.0
GPU model and memory: 8 x Tesla P100-PCIE-16GB

Describe the current behavior
I am not able to convert a SavedModel to a FlatBuffer using TFLiteConverter when the corresponding tf.keras.Model contains a layer with a tf.gather op for which the params argument comes from a variable that was initialized in the build method of that said layer.
When the params argument is from a locally defined variable, or when using tf.nn.embedding_lookup instead of tf.gather, everything works perfectly fine.
It also applies to tf.gather_nd.
Describe the expected behavior
I expect tf.gather to work for the case in which the params argument is an attribute of the tf.keras.layers.Layer, just as it does for the other cases mentioned.
Code to reproduce the issue
I wrote a toy example to reproduce the issue, it might be clearer than the description above.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
print(tf.__version__)

class Embedding(tf.keras.layers.Layer):
    def __init__(self, vocab_size, hidden_size):
        super(Embedding, self).__init__()
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
    
    def build(self, input_shape):
        self.shared_weights = self.add_weight(
            "weights",
            shape=(self.vocab_size, self.hidden_size),
            dtype=tf.float32,
            initializer=tf.random_normal_initializer(
                mean=0.0, 
                stddev=self.hidden_size ** (-0.5)
            )
        )
    
    def call(self, input_):
        # return tf.nn.embedding_lookup(self.shared_weights, input_)
        # return tf.gather(tf.zeros(shape=(self.vocab_size, self.hidden_size)), input_)
        return tf.gather(self.shared_weights, input_)


class SimpleModel(tf.keras.Model):
    def __init__(self, vocab_size, hidden_size):
        super(SimpleModel, self).__init__()
        self.embedding_layer = Embedding(vocab_size, hidden_size)
    
    @tf.function(input_signature=[tf.TensorSpec(shape=(None, ), dtype=tf.int64, name='input')])
    def call(self, input_):
        return self.embedding_layer(input_)

vocab_size = 20000
hidden_size = 300

# Building the model.
model = SimpleModel(vocab_size, hidden_size)
input_ = tf.random.uniform(shape=(20, ), dtype=tf.int64, maxval=100)
model(input_)

# Exporting to SavedModel.
saved_model_dir = 'simple_model/'
tf.saved_model.save(model, saved_model_dir)

# TFLite conversion.
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/michael/.conda/envs/tf20/bin/toco_from_protos", line 10, in &lt;module&gt;
    sys.exit(main())
  File "/home/michael/.conda/envs/tf20/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/michael/.conda/envs/tf20/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/michael/.conda/envs/tf20/lib/python3.6/site-packages/absl/app.py", line 300, in run
    _run_main(main, args)
  File "/home/michael/.conda/envs/tf20/lib/python3.6/site-packages/absl/app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "/home/michael/.conda/envs/tf20/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 52, in execute
    enable_mlir_converter)
Exception: Placeholder statefulpartitionedcall_args_1 should be specied by input_arrays.

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='michaelbenayoun' date='2019-08-14T03:29:16Z'>
		Issue replicating with TF nightly-2.0-preview.
		</comment>
		<comment id='2' author='michaelbenayoun' date='2019-08-19T14:56:42Z'>
		Follow-up: another (temporary) solution I found is to use tf.identity,  return tf.gather(tf.identity(self.shared_weights), input_) works fine.
It might not be the most efficient way of fixing the issue (especially for large tensors) but it works.
		</comment>
		<comment id='3' author='michaelbenayoun' date='2019-08-26T20:26:57Z'>
		This should be fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/b42547e3bca7ab796f40f20726f4b09bf552e833&gt;b42547e&lt;/denchmark-link&gt;
. Please reopen if the original code doesn't work in the nightly.
		</comment>
		<comment id='4' author='michaelbenayoun' date='2019-08-26T20:26:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31596&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31596&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='michaelbenayoun' date='2019-09-04T14:51:57Z'>
		Updated tensorflow 2.0 preview to the 20190903 nightly and still facing an issue.
&lt;denchmark-h:h4&gt;Code to reproduce&lt;/denchmark-h&gt;

The code is basically the same as before: it runs when using tf.nn.embedding_lookup or wrapping the shared weights with a tf.identity op, but fails in the regular case with a tf.gather.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
print(tf.__version__)

import os

class Embedding(tf.keras.layers.Layer):
    def __init__(self, vocab_size, hidden_size):
        super(Embedding, self).__init__()
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
    
    def build(self, input_shape):
        self.shared_weights = self.add_weight(
            "weights",
            shape=(self.vocab_size, self.hidden_size),
            dtype=tf.float32,
            initializer=tf.random_normal_initializer(
                mean=0.0, 
                stddev=self.hidden_size ** (-0.5)
            )
        )
    
    def call(self, input_, mode="embedding"):
        # return tf.gather(tf.identity(self.shared_weights), input_)
        # return tf.nn.embedding_lookup(self.shared_weights, input_)
        return tf.gather(self.shared_weights, input_)


class SimpleModel(tf.keras.Model):
    def __init__(self, vocab_size, hidden_size):
        super(SimpleModel, self).__init__()
        self.embedding_layer = Embedding(vocab_size, hidden_size)
    
    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 25), dtype=tf.int64, name='input')])
    def call(self, input_):
        return self.embedding_layer(input_)

vocab_size = 20000
hidden_size = 300

# Building the model.
model = SimpleModel(vocab_size, hidden_size)
input_ = tf.random.uniform(shape=(10, 25), dtype=tf.int64, maxval=100)
model(input_)

# Exporting to SavedModel.
saved_model_dir = 'simple_model/'
tf.saved_model.save(model, saved_model_dir)

# TFLite conversion.
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

&lt;denchmark-h:h4&gt;Other info / logs&lt;/denchmark-h&gt;

Although it is not the same error message as before (ResourceGather related), I think it might be related to the initial issue.
&lt;denchmark-code&gt;2019-09-04 10:49:32.751617: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 6 operators, 9 arrays (0 quantized)
2019-09-04 10:49:32.751814: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 6 operators, 9 arrays (0 quantized)
2019-09-04 10:49:32.751891: F tensorflow/lite/toco/graph_transformations/resolve_gather_attributes.cc:47] Check failed: axis_data.size() == 1 (2 vs. 1)Multidimensional gather not supported on {Gather operator with output StatefulPartitionedCall/embedding_4/Gather}
Fatal Python error: Aborted
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='michaelbenayoun' date='2020-05-14T16:01:07Z'>
		
Updated tensorflow 2.0 preview to the 20190903 nightly and still facing an issue.

&lt;denchmark-link:https://github.com/michaelbenayoun&gt;@michaelbenayoun&lt;/denchmark-link&gt;
,
I was able to run the code without any issues with the latest TF-nightly i.e. 2.3.0-dev20200514. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/dfb9e315b72999f54e8e6f258d155195/31596-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='michaelbenayoun' date='2020-05-21T16:26:15Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='michaelbenayoun' date='2020-05-28T17:10:45Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='9' author='michaelbenayoun' date='2020-05-28T17:10:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31596&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31596&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>