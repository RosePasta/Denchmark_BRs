<bug id='34620' author='antofara' open_date='2019-11-26T17:36:37Z' closed_time='2019-12-05T09:45:44Z'>
	<summary>Batch size reset to 1 after conversion</summary>
	<description>
System information

OS Platform and Distribution Windows 10 and Ubuntu 64 bit
TensorFlow installed from (source or binary): pip
TensorFlow version (or github SHA if from source): 2.0.0

Command used to run the converter or code if youâ€™re using the Python API
x=tf.keras.Input(shape=(256,1), batch_size=50)
y=tf.keras.layers.Convolution1D(kernel_size=5,filters=8,input_shape=(50,256,1))(x)
model=tf.keras.Model(x,y)
# compile and train
# ... 
converter=tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
converter.representative_dataset = setgen
modelq=converter.convert()

conv_interpreter=tf.lite.Interpreter(model_content=modelq)
input_details = conv_interpreter.get_input_details()
The output from the converter invocation
&lt;denchmark-code&gt;{'name': 'input_5',
 'index': 8,
 'shape': array([   1, 256,    1]),
 'dtype': numpy.float32,
 'quantization': (0.0, 0)}
&lt;/denchmark-code&gt;

Failure details
Despite before conversion the batch size is explicitly set to 50, after conversion the batch size is always 1.
The reason why I am trying to have batch size &gt;1 is because the model has to be executed in the edge TPU and I want to exploit as best the parallelism offered by the chip, thus performing the convolution on as many inputs as possible in parallel.
If not supported by TF Lite, any suggestion to achieve the same result is welcome and appreciated
	</description>
	<comments>
		<comment id='1' author='antofara' date='2019-12-04T19:12:36Z'>
		&lt;denchmark-link:https://github.com/antofara&gt;@antofara&lt;/denchmark-link&gt;
 I ran your code in  and I see batch_size set as 50. There were lots of improvements recently and team is continuously improving the converter.
I have also added new experimental new converter as . Please check the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/c7f8adcc2be802258e522540b0c61472/untitled686.ipynb&gt;here&lt;/denchmark-link&gt;
.
Please close the issue if it was resolved for you. Otherwise, please share a colab gist with a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='antofara' date='2019-12-05T09:45:44Z'>
		Thanks &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

Solved with the following fixes:
TF version: '2.1.0-dev20191204'

		</comment>
		<comment id='3' author='antofara' date='2019-12-05T09:45:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34620&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34620&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>