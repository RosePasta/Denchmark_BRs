<bug id='29951' author='mttbx' open_date='2019-06-19T07:46:33Z' closed_time='2019-06-26T05:55:13Z'>
	<summary>Segmentation fault when using cpp custom op in tf.data.Dataset.map in tensorflow2.0</summary>
	<description>
It seems if I have cpp custom op in a python function and I pass the python function to tf.data.Dataset.map it will crush.
If I only call this python function outside, It will be ok.
I've spend a whole afternoon to find the bug. I'm really mad about this bug.
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux ubuntu 18.04
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below): 2.0b1
Python version:3.6
CUDA/cuDNN version:10/7.4
GPU model and memory:7.5/24gb
&lt;denchmark-code&gt;
import tensorflow as tf
import pdb
extr_module = tf.load_op_library('./build/libextr_module.so')
res = extr_module.test_bug() # ok

def aaa(filename):
    res = extr_module.test_bug() # Segmentation fault (core dumped)

    return tf.zeros([1], tf.float32)
    
dataset = tf.data.TextLineDataset(['aaa']).map(aaa)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;#include "tensorflow/core/framework/op_kernel.h"
#include "tensorflow/core/framework/register_types.h"
#include "tensorflow/core/framework/tensor.h"
#include "tensorflow/core/framework/tensor_shape.h"
#include "tensorflow/core/framework/register_types.h"
#include "tensorflow/core/framework/op.h"
#include "tensorflow/core/framework/shape_inference.h"
#include "tensorflow/core/util/work_sharder.h"

#include &lt;iostream&gt;
#include &lt;cmath&gt;

using namespace tensorflow;

REGISTER_OP("TestBug")
    .Output("dummy: float")
    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
        c-&gt;set_output(0, c-&gt;MakeShape({1}));
        return Status::OK();
    });

class TestBugOp : public OpKernel
{
public:
explicit TestBugOp(OpKernelConstruction* context)
        : OpKernel(context)
{

}

void Compute(OpKernelContext* context) override
{
    Tensor* dummy = NULL;
    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, {1},
                                                     &amp;dummy));
}
};

REGISTER_KERNEL_BUILDER(
  Name("TestBug").Device(DEVICE_CPU),
  TestBugOp
);
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;
CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
PROJECT(extr_module)


# compiler flags
SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11 -O2 ${OpenMP_CXX_FLAGS} -Wall -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -DGOOGLE_CUDA=1")

# TensorFlow dependencies
EXECUTE_PROCESS(COMMAND python3 -c "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'; import tensorflow as tf; print(tf.sysconfig.get_include(), end='', flush=True)"  OUTPUT_VARIABLE TF_INC)

EXECUTE_PROCESS(COMMAND python3 -c "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'; import tensorflow as tf; print(tf.sysconfig.get_lib(), end='', flush=True)"  OUTPUT_VARIABLE TF_LIB)


MESSAGE(STATUS "Found TF_INC: " ${TF_INC})
#MESSAGE(STATUS "Found TF_INC_EXTERNAL: " ${TF_INC}/external/nsync/public)
MESSAGE(STATUS "Found TF_LIB: " ${TF_LIB})


INCLUDE_DIRECTORIES(${TF_INC})
#INCLUDE_DIRECTORIES(${TF_INC}/external/nsync/public)
LINK_DIRECTORIES(${TF_LIB})


ADD_LIBRARY(extr_module SHARED
  testbug.cc
)

TARGET_LINK_LIBRARIES(extr_module tensorflow_framework)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mttbx' date='2019-06-20T10:26:26Z'>
		any feedback?
		</comment>
		<comment id='2' author='mttbx' date='2019-06-21T22:36:10Z'>
		Can you give us a stack trace? Hard to do anything without.
For safety, you must build your extension against the same version of all dependencies as TF. I think in your case the only thing that matters is TensorFlow itself, and if you're building against 2.0b1, you should be fine, just mentioning it as a thing to check.
		</comment>
		<comment id='3' author='mttbx' date='2019-06-22T07:32:11Z'>
		My tensorflow version:
&lt;denchmark-code&gt;&gt;&gt;&gt; tf.version.VERSION
'2.0.0-beta1'
&gt;&gt;&gt; tf.version.GIT_VERSION
'v2.0.0-beta0-16-g1d91213fe7'
&lt;/denchmark-code&gt;

I don't have debug version of tensorflow, so I just attach gdb to my python, here's the result:
&lt;denchmark-code&gt;Thread 1 "python3" received signal SIGSEGV, Segmentation fault.
0x00007ff2905d4809 in tensorflow::shape_inference::InferenceContext::MakeShape(std::initializer_list&lt;tensorflow::shape_inference::DimensionOrConstant&gt;) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/../libtensorflow_framework.so.2
&lt;/denchmark-code&gt;

So it seems stopped at SetShapeFn. If I don't call it in map member function, it can totally run without crush.
		</comment>
		<comment id='4' author='mttbx' date='2019-06-22T07:54:12Z'>
		Here's bt result:
&lt;denchmark-code&gt;#0  0x00007ff255dbe809 in tensorflow::shape_inference::InferenceContext::MakeShape(std::initializer_list&lt;tensorflow::shape_inference::DimensionOrConstant&gt;) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/../libtensorflow_framework.so.2
#1  0x00007ff24c6c0a3e in {lambda(tensorflow::shape_inference::InferenceContext*)#1}::_FUN(tensorflow::shape_inference::InferenceContext*) ()
   from ./build/libextr_module.so
#2  0x00007ff24c6c0ad0 in std::_Function_handler&lt;tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)&gt;::_M_invoke(std::_Any_data const&amp;, tensorflow::shape_inference::InferenceContext*&amp;&amp;) ()
   from ./build/libextr_module.so
#3  0x00007ff255dbc9bd in tensorflow::shape_inference::InferenceContext::Run(std::function&lt;tensorflow::Status (tensorflow::shape_inference::InferenceContext*)&gt; const&amp;) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/../libtensorflow_framework.so.2
#4  0x00007ff25f08b980 in tensorflow::ShapeRefiner::RunShapeFn(tensorflow::Node const*, tensorflow::OpRegistrationData const*, tensorflow::ExtendedInferenceContext*) () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007ff25f08d4a8 in tensorflow::ShapeRefiner::AddNode(tensorflow::Node const*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007ff25bea7d2a in TF_FinishOperation () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007ff25972fde6 in _wrap_TF_FinishOperation () from /usr/local/lib/python3.6/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00000000004f858d in ?? ()
#9  0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#10 0x00000000004f7a28 in ?? ()
#11 0x00000000004f876d in ?? ()
#12 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#13 0x00000000004f6128 in ?? ()
#14 0x00000000004f426e in _PyFunction_FastCallDict ()
#15 0x00000000005a1481 in ?? ()
#16 0x0000000000512a60 in ?? ()
#17 0x000000000053ee21 in ?? ()
#18 0x000000000057ec0c in _PyObject_FastCallKeywords ()
#19 0x00000000004f88ba in ?? ()
#20 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#21 0x00000000004f6128 in ?? ()
#22 0x000000000056ff4c in ?? ()
#23 0x000000000057c2fe in PyObject_Call ()
#24 0x00000000004facb1 in _PyEval_EvalFrameDefault ()
#25 0x00000000004f6128 in ?? ()
#26 0x00000000004f7d60 in ?? ()
#27 0x00000000004f876d in ?? ()
#28 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#29 0x00000000004f6128 in ?? ()
#30 0x00000000004f7d60 in ?? ()
#31 0x00000000004f876d in ?? ()
#32 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#33 0x00000000004f6128 in ?? ()
#34 0x00000000004f7d60 in ?? ()
#35 0x00000000004f876d in ?? ()
#36 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
#37 0x00000000004f4944 in ?? ()
#38 0x00000000004f876d in ?? ()
#39 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#40 0x00000000004f6128 in ?? ()
#41 0x000000000056fd6b in ?? ()
#42 0x000000000057c2fe in PyObject_Call ()
#43 0x00000000004facb1 in _PyEval_EvalFrameDefault ()
#44 0x00000000004f6128 in ?? ()
#45 0x000000000056fd6b in ?? ()
#46 0x000000000057c2fe in PyObject_Call ()
#47 0x00000000004facb1 in _PyEval_EvalFrameDefault ()
#48 0x00000000004f6128 in ?? ()
#49 0x000000000056fe24 in ?? ()
#50 0x000000000057c2fe in PyObject_Call ()
#51 0x00000000004facb1 in _PyEval_EvalFrameDefault ()
#52 0x00000000004f6128 in ?? ()
#53 0x00000000004f7d60 in ?? ()
#54 0x00000000004f876d in ?? ()
#55 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#56 0x00000000004f6128 in ?? ()
#57 0x00000000004f7d60 in ?? ()
#58 0x00000000004f876d in ?? ()
#59 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#60 0x00000000004f7a28 in ?? ()
#61 0x00000000004f876d in ?? ()
#62 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#63 0x00000000004f6128 in ?? ()
#64 0x00000000004f426e in _PyFunction_FastCallDict ()
#65 0x00000000005a1481 in ?? ()
#66 0x000000000057c2fe in PyObject_Call ()
#67 0x00000000004facb1 in _PyEval_EvalFrameDefault ()
#68 0x00000000004f6128 in ?? ()
#69 0x00000000004f7d60 in ?? ()
#70 0x00000000004f876d in ?? ()
#71 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#72 0x00000000004f6128 in ?? ()
#73 0x00000000004f426e in _PyFunction_FastCallDict ()
#74 0x00000000005a1481 in ?? ()
#75 0x0000000000512a60 in ?? ()
#76 0x000000000053ee21 in ?? ()
#77 0x000000000057ec0c in _PyObject_FastCallKeywords ()
#78 0x00000000004f88ba in ?? ()
#79 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#80 0x00000000004f6128 in ?? ()
---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit---
#81 0x00000000004f426e in _PyFunction_FastCallDict ()
#82 0x00000000005a1481 in ?? ()
#83 0x0000000000512a60 in ?? ()
#84 0x000000000053ee21 in ?? ()
#85 0x000000000057ec0c in _PyObject_FastCallKeywords ()
#86 0x00000000004f88ba in ?? ()
#87 0x00000000004fa6c0 in _PyEval_EvalFrameDefault ()
#88 0x00000000004f6128 in ?? ()
#89 0x00000000004f7d60 in ?? ()
#90 0x00000000004f876d in ?? ()
#91 0x00000000004f98c7 in _PyEval_EvalFrameDefault ()
#92 0x00000000004f6128 in ?? ()
#93 0x00000000004f9023 in PyEval_EvalCode ()
#94 0x00000000006415b2 in ?? ()
#95 0x000000000064166a in PyRun_FileExFlags ()
#96 0x0000000000643730 in PyRun_SimpleFileExFlags ()
#97 0x000000000062b26e in Py_Main ()
#98 0x00000000004b4cb0 in main ()

&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='mttbx' date='2019-06-23T04:57:55Z'>
		It crashes in the shape function, in the MakeShape call. Maybe for some reason the InferenceContext isn't valid?
&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 is there anything special in how this is used by .map?
		</comment>
		<comment id='6' author='mttbx' date='2019-06-24T07:35:59Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Same problem in  of tf 1.14.
All custom ops can work with tf 1.13.1 docker image, but fail in 1.14.
I have test g++ 5, 7, 8, all failed.
		</comment>
		<comment id='7' author='mttbx' date='2019-06-24T14:09:19Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Same problem. This fatal is seriousness. Please fix it emergency.
		</comment>
		<comment id='8' author='mttbx' date='2019-06-24T14:14:35Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/13308&gt;#13308&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='mttbx' date='2019-06-24T14:20:19Z'>
		&lt;denchmark-link:https://github.com/zh794390558&gt;@zh794390558&lt;/denchmark-link&gt;
 It may duplicate to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29820&gt;#29820&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='mttbx' date='2019-06-24T14:26:20Z'>
		&lt;denchmark-link:https://github.com/mttbx&gt;@mttbx&lt;/denchmark-link&gt;
 maybe not. I have implement some custom ops, all become fatal, but can work under 1.13.1 docker image.
&lt;denchmark-code&gt;*** Begin stack trace ***
	tensorflow::CurrentStackTrace()
	
	
	gsignal
	
	
	std::_Function_handler&lt;tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)&gt;::_M_invoke(std::_Any_data const&amp;, tensorflow::shape_inference::InferenceContext*&amp;&amp;)
	tensorflow::shape_inference::InferenceContext::Run(std::function&lt;tensorflow::Status (tensorflow::shape_inference::InferenceContext*)&gt; const&amp;)
	tensorflow::ShapeRefiner::RunShapeFn(tensorflow::Node const*, tensorflow::OpRegistrationData const*, tensorflow::ExtendedInferenceContext*)
	tensorflow::ShapeRefiner::AddNode(tensorflow::Node const*)
	TF_FinishOperation
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	_PyFunction_FastCallDict
	
	
	
	_PyObject_FastCallKeywords
	
	_PyEval_EvalFrameDefault
	
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	_PyFunction_FastCallDict
	
	PyObject_Call
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	_PyFunction_FastCallDict
	
	
	
	_PyObject_FastCallKeywords
	
	_PyEval_EvalFrameDefault
	
	_PyFunction_FastCallDict
	
	
	
	_PyObject_FastCallKeywords
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	
	_PyEval_EvalFrameDefault
	
	_PyFunction_FastCallDict
	
	PyObject_Call
	_PyEval_EvalFrameDefault
*** End stack trace ***
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='mttbx' date='2019-06-24T14:47:01Z'>
		I think we should give it a try for gcc 4.8.
		</comment>
		<comment id='12' author='mttbx' date='2019-06-24T20:33:42Z'>
		The stack trace suggests that this is an error in shape inference (and it does not seem to have anything to do with tf.data).
I took a look at the  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/shape_inference.cc#L731&gt;method&lt;/denchmark-link&gt;
 and my guess is that this is an instance of use-after-free race. In particular, given how trivial the method is, my guess is that  object that is used is being destructed (or already destructed) by the time the call happens.
I would bring this to the attention of someone familiar with what happens in TF_FinishOperation.
		</comment>
		<comment id='13' author='mttbx' date='2019-06-24T21:48:04Z'>
		&lt;denchmark-link:https://github.com/josh11b&gt;@josh11b&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 do you know what could be going on here?
		</comment>
		<comment id='14' author='mttbx' date='2019-06-24T23:14:44Z'>
		I believe I'm also seeing this issue. The InferenceContext that's passed to SetShapeFn is a null pointer for me.
Edit: Note that I am using TF1.14, not 2.0b
		</comment>
		<comment id='15' author='mttbx' date='2019-06-26T02:40:16Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Any progress?
		</comment>
		<comment id='16' author='mttbx' date='2019-06-26T04:45:34Z'>
		To build the custom ops, did you use the native system compiler, or did you follow the instructions at &lt;denchmark-link:https://github.com/tensorflow/custom-op&gt;https://github.com/tensorflow/custom-op&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='mttbx' date='2019-06-26T05:54:25Z'>
		problem solved!!! I use g++-4.8 instead!
		</comment>
		<comment id='18' author='mttbx' date='2019-06-26T05:55:13Z'>
		I'm gonna close this issue, because I've found the solution.
		</comment>
		<comment id='19' author='mttbx' date='2019-06-26T05:55:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29951&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29951&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='20' author='mttbx' date='2019-06-26T17:05:21Z'>
		
@martinwicke Same problem in docker image of tf 1.14.
All custom ops can work with tf 1.13.1 docker image, but fail in 1.14.
I have test g++ 5, 7, 8, all failed.

+1
Custom ops compile and run fine on TF1.13.1, but end with a seg-fault on TF1.14. Unable to move production workflow to TF1.14. Please take a look.
		</comment>
		<comment id='21' author='mttbx' date='2019-06-26T17:08:30Z'>
		

@martinwicke Same problem in docker image of tf 1.14.
All custom ops can work with tf 1.13.1 docker image, but fail in 1.14.
I have test g++ 5, 7, 8, all failed.

+1
Custom ops compile and run fine on TF1.13.1, but end with a seg-fault on TF1.14. Unable to move production workflow to TF1.14. Please take a look.

&lt;denchmark-link:https://github.com/sjain-stanford&gt;@sjain-stanford&lt;/denchmark-link&gt;
 I had the same issue; &lt;denchmark-link:https://github.com/mttbx&gt;@mttbx&lt;/denchmark-link&gt;
 discovered that compiling with g++-4.8 does do the trick for whatever reason. g++-4.8 is the same version used in the custom op docker container too.
		</comment>
		<comment id='22' author='mttbx' date='2019-06-26T17:28:23Z'>
		&lt;denchmark-link:https://github.com/Masterchef365&gt;@Masterchef365&lt;/denchmark-link&gt;
 thanks, g++-4.8 did the trick. Still unclear why the previous builds using g++-5.4 against TF &lt;=1.13.1 didn't result in seg-fault.
		</comment>
		<comment id='23' author='mttbx' date='2019-06-26T17:38:21Z'>
		The problem with these compiler incompatibilities is they're basically a
game of russian roulette. You never know when they hit you.
		</comment>
		<comment id='24' author='mttbx' date='2019-06-27T01:57:48Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
  So when to release the fixed docker image for tf1.14?
		</comment>
		<comment id='25' author='mttbx' date='2019-06-27T02:09:14Z'>
		@angersson have we released docker containers for 1.14?

The custom op setup should work though, which container are you using?
		</comment>
		<comment id='26' author='mttbx' date='2019-06-27T07:58:13Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 docker image for 1.14 has released, which tag is  and . And I using these docker image for testing, and deployment.
Another issue, when compile ops with g++-4.8 under 1.14 docker image:
when I using root account to install g++-4.8 and compile ops, all pass. But after install g++-4.8 as root,  I add another user account, then compile error, log as below:
&lt;denchmark-code&gt;gitlab-runner@3dec7a24a2d4:/delta/delta/layers/ops$ ./build.sh delta
prepare dependency
g++   -fPIC -shared -O2 -std=c++11  -I/usr/local/lib/python3.6/dist-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -I/  -c kernels/fbank.cc -o linux_x86_64/obj/kernels/fbank.o  -L/usr/local/lib/python3.6/dist-packages/tensorflow -l:libtensorflow_framework.so.1 
In file included from /usr/include/x86_64-linux-gnu/c++/4.8/bits/os_defines.h:39:0,
                 from /usr/include/x86_64-linux-gnu/c++/4.8/bits/c++config.h:426,
                 from /usr/include/c++/4.8/bits/stl_algobase.h:59,
                 from /usr/include/c++/4.8/vector:60,
                 from /delta/delta/layers/ops/kernels/fbank.h:20,
                 from kernels/fbank.cc:17:
/usr/include/features.h:424:25: fatal error: sys/cdefs.h: No such file or directory
 #  include &lt;sys/cdefs.h&gt;
                         ^
compilation terminated.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='27' author='mttbx' date='2019-06-27T16:19:34Z'>
		&lt;denchmark-link:https://github.com/zh794390558&gt;@zh794390558&lt;/denchmark-link&gt;
, can you try using  instead?  is actually very old (our  are just called ; I'll update the docs to reflect this). Perhaps also , which is newer.
		</comment>
		<comment id='28' author='mttbx' date='2019-06-27T16:24:23Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Yep, they've been released. I'm not totally sure about this use case though, because our versioned containers just pre-install the libraries needed to run TF.  was superceded by  some time ago (I guess I'll need to delete that tag, because it's confusing) and it looks like the  images are mixed ages (with  the youngest).
		</comment>
		<comment id='29' author='mttbx' date='2019-07-03T10:11:59Z'>
		@angersson I think unify the base image of tf docker with ci is important things.
		</comment>
		<comment id='30' author='mttbx' date='2019-08-20T23:26:52Z'>
		The solution to downgrade compilers seems a bit crazy and is very undocumented. While the nod to the incompatible ABI exists in the documentation, it is not at all clear on all the caveats that need to be dealt with.
For example, in our flow, we use c++14 stuff (constexpr) in our custom op implementation which worked swimmingly in tf 1.13 and g++7. Now, because of changes made and some possibly naughty out of scope allocation (potentially), we are being forced to use compilers that produce "more appropriate" code. This all seems sort of crazy to me. Without determinism, the programmer is surely destined for insanity.
Do we know if the fix for this according to the tf gods has been decreed to be "Follow our build flow"?
		</comment>
	</comments>
</bug>