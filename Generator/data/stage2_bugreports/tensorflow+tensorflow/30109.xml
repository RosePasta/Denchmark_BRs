<bug id='30109' author='LukeBolly' open_date='2019-06-25T05:14:02Z' closed_time='2019-07-31T16:59:43Z'>
	<summary>Using keras.layers.BatchNormalization inside keras.layers.TimeDistributed causes bad validation loss/accuracy</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): tensorflow-gpu 1.13.1
Python version: 3.6.7
CUDA/cuDNN version: v10
GPU model and memory: GTX 980M

Describe the current behavior
Using BatchNorm inside a TimeDistributed layer results in poor validation performance. A model trained and validated on identical data can reach 100% train accuracy but never reach that when validating against the same sample. Removing the Batchnorm layer resolves the issue.
See the training results from a toy example:
&lt;denchmark-code&gt;500/500 loss: 1.6910 - sparse_categorical_accuracy: 0.2400 - val_loss: 1.7292 - val_sparse_categorical_accuracy: 0.2000
Epoch 2/100

500/500 loss: 1.2619 - sparse_categorical_accuracy: 0.5600 - val_loss: 1.6112 - val_sparse_categorical_accuracy: 0.2000
Epoch 3/100

500/500 loss: 0.9130 - sparse_categorical_accuracy: 0.9200 - val_loss: 1.5113 - val_sparse_categorical_accuracy: 0.2000
Epoch 4/100

500/500  loss: 0.6420 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4297 - val_sparse_categorical_accuracy: 0.2000
Epoch 5/100
...
...
...
500/500 loss: 8.2955e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.1042 - val_sparse_categorical_accuracy: 0.2000
Epoch 100/100
&lt;/denchmark-code&gt;

Describe the expected behavior
When training and validating on an identical sample, the model should get the same accuracy during both training and validation. To eliminate the possibility that this is caused by a difference between the running mean/variance and the batchwise mean/variance, a very small value of BatchNorm Momentum was trialed. It was observed that modifying Momentum appears to have no effect. BatchNorm should not affect a model's ability to make good predictions.
Code to reproduce the issue
The following code shows the issue. Run it a few times and watch the validation accuracy/loss.
&lt;denchmark-code&gt;from tensorflow import keras
import tensorflow as tf
import numpy as np
import random

time_steps = 5
sample_width = 20
kernel_size = 3
num_filters = 5
num_classes = 5

def build_graph():
    with tf.name_scope("SequenceProcess"):
        sequence_input = keras.layers.Input(shape=(time_steps, sample_width))

        with tf.name_scope("TimeDistributed"):
            sample_input = keras.layers.Input(shape=(sample_width,))

            conv = keras.layers.Reshape([sample_width, 1])(sample_input)
            conv = keras.layers.BatchNormalization(momentum=0.01)(conv)
            conv = keras.layers.Conv1D(num_filters, kernel_size, padding='same')(conv)
            encoded_sample = keras.layers.Reshape((num_filters * sample_width,))(conv)

            sample_model = keras.models.Model(sample_input, encoded_sample)

        processed_samples = keras.layers.TimeDistributed(sample_model)(sequence_input)
        fc = keras.layers.Dense(num_classes, activation='softmax')(processed_samples)

        sequence_model = keras.models.Model(sequence_input, fc)
        sequence_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])

    return sequence_model

def generate_data():
    steps = []
    for i in range(time_steps):
        sample_data = np.random.rand(sample_width)
        steps.append(sample_data)
    steps = np.array(steps)

    labels = []
    for i in range(time_steps):
        label = random.randint(0, num_classes - 1)
        labels.append([label])
    labels = np.array(labels)

    input_data = []
    input_labels = []

    for i in range(1000):
        input_data.append(steps)
        input_labels.append(labels)

    return np.array(input_data), np.array(input_labels)

if __name__ == '__main__':
    data, labels = generate_data()
    model = build_graph()
    model.fit(data, labels, 10, 100, validation_split= 0.5)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='LukeBolly' date='2019-06-26T10:55:05Z'>
		&lt;denchmark-link:https://github.com/LukeBolly&gt;@LukeBolly&lt;/denchmark-link&gt;
 I am able to reproduce the issue on colab with Tensorflow-gpu 1.13.1 by executing multiple times.
		</comment>
		<comment id='2' author='LukeBolly' date='2019-07-04T02:31:00Z'>
		It turns out the running mean and variance aren't being updated:
if you add these lines after the fit
&lt;denchmark-code&gt;    weights = model.layers[1].layer.layers[2].get_weights()
    print('\ngamma:\t\t' + str(weights[0][0]) + '\nrunning mean:\t\t' + str(weights[2][0]) + '\n')
    print('beta:\t' + str(weights[1][0]) + '\nrunning variance:\t' + str(weights[3][0]) + '\n')
&lt;/denchmark-code&gt;

you'll get the output:
&lt;denchmark-code&gt;gamma:		1.1386212
running mean:		0.0

beta:	0.06730438
running variance:	1.0
&lt;/denchmark-code&gt;

Here are some possibly related issues:
&lt;denchmark-link:https://github.com/keras-team/keras/issues/7466#issuecomment-500002720&gt;keras-team/keras#7466 (comment)&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/keras-team/keras/issues/12400&gt;keras-team/keras#12400&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/keras-team/keras/pull/7467&gt;keras-team/keras#7467&lt;/denchmark-link&gt;

If you've got an idea how I could work around this in the meantime, it would be much appreciated.
		</comment>
		<comment id='3' author='LukeBolly' date='2019-07-04T08:24:03Z'>
		The running mean and variance update in 1.14, though the results still don't seem right
&lt;denchmark-code&gt;Epoch 1/5
loss: 1.2191 - sparse_categorical_accuracy: 0.5640 - val_loss: 0.9704 - val_sparse_categorical_accuracy: 0.6000
Epoch 2/5
loss: 0.2219 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.9911 - val_sparse_categorical_accuracy: 0.4000
Epoch 3/5
loss: 0.0514 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0707 - val_sparse_categorical_accuracy: 0.4000
Epoch 4/5
loss: 0.0236 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0686 - val_sparse_categorical_accuracy: 0.4000
Epoch 5/5
loss: 0.0139 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.0246 - val_sparse_categorical_accuracy: 0.4000

gamma:			1.1039916
running mean:		0.18822414

beta:			0.15830743
running variance:	0.63675237
&lt;/denchmark-code&gt;

Given that the Momentum value is basically 0, validation_accuracy should be roughly equal to train_accuracy
		</comment>
		<comment id='4' author='LukeBolly' date='2019-07-04T08:45:03Z'>
		It turns out momentum is more complicated than I thought. A value of 0.5 makes the train and validation accuracies match.
Using a value close to 0 causes the moving averages to overshoot, and you end up with something like this:
&lt;denchmark-code&gt;running mean:		1.0374619		running variance:	-0.82485986
running mean:		0.010333061		running variance:	0.9818245
running mean:		1.0272316		running variance:	-0.80686545
running mean:		0.020461679		running variance:	0.9640094
running mean:		1.017204		running variance:	-0.7892276
running mean:		0.03038919		running variance:	0.94654715
running mean:		1.0073754		running variance:	-0.7719393
running mean:		0.040119976		running variance:	0.9294311
running mean:		0.99774146		running variance:	-0.7549938
running mean:		0.04965794		running variance:	0.9126543
&lt;/denchmark-code&gt;

which explains the unstable validation loss.
Long story short, don't use a Momentum below 0.5 and don't use BatchNorm inside TimeDistributed in 1.13.
		</comment>
		<comment id='5' author='LukeBolly' date='2019-07-31T16:59:45Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30109&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30109&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>