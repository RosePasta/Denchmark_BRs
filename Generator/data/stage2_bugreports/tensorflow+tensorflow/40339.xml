<bug id='40339' author='bjourne' open_date='2020-06-10T02:03:22Z' closed_time='2020-10-31T01:49:28Z'>
	<summary>Error in the tpu.ipynb notebook</summary>
	<description>
I'm trying to implement the code in this notebook &lt;denchmark-link:https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb&gt;https://github.com/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb&lt;/denchmark-link&gt;

The lines for updating the training loss and accuracy are incorrect:
training_loss.update_state(loss * strategy.num_replicas_in_sync)
training_accuracy.update_state(labels, logits)
I don't understand the intent behind updating the loss with the product of the number of replicas and the batch loss but it gives the wrong result. Changing the line to
training_loss.update_state(labels, logits)
appears to solve the bug.
I also changed the definition of training_loss from a metrics.Mean to a metrics.SparseCategoricalCrossentropy.
	</description>
	<comments>
		<comment id='1' author='bjourne' date='2020-06-11T17:13:18Z'>
		&lt;denchmark-link:https://github.com/rxsang&gt;@rxsang&lt;/denchmark-link&gt;
 can you confirm if this code is correct, and either fix or add a couple of comments explaining?
Thanks.
		</comment>
		<comment id='2' author='bjourne' date='2020-06-11T19:01:01Z'>
		Hi bjourne@,
Thanks for the feedbacks. Pasting all the code related to loss calculating in the current guide.
&lt;denchmark-code&gt;with tf.GradientTape() as tape:
    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)
    loss = tf.nn.compute_average_loss(loss, global_batch_size=batch_size)
grads = tape.gradient(loss, model.trainable_variables)
optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))
training_loss.update_state(loss * strategy.num_replicas_in_sync)
&lt;/denchmark-code&gt;

The reason is when working with DistributionStrategy, you first

compute the loss
calculate the gradients per replica
aggregate the gradients across all the replicas

The reason is in 3#, the aggregation is the sum of all replicas. So if your loss is a mean loss, the gradients will be num_replicas_in_sync larger than expected. That's why we scale the loss by num_replicas_in_sync in 2#. However for the reported loss, we don't want to see the scaled loss, thus we multiply num_replicas_in_sync back.
The way you suggest will also work, but it will compute SparseCategoricalCrossentropy twice. Given calculating this metric should be cheap, I can change it to this one if this is clearer.
Does that make sense to you?
		</comment>
		<comment id='3' author='bjourne' date='2020-06-11T23:53:31Z'>
		Thanks for your response. Two things I don't understand. Why isn't the training accuracy calculated in the same way? Shouldn't it also suffer from the same kind of scaling issues? And when I write it the way you suggest, I get losses in the range 400 to 600. So I think there must be a bug there? Does it matter that my model does not use logits?
		</comment>
		<comment id='4' author='bjourne' date='2020-10-10T04:12:55Z'>
		&lt;denchmark-link:https://github.com/bjourne&gt;@bjourne&lt;/denchmark-link&gt;
 Can you please share a simple standalone code to reproduce your issue? Thanks!
If this was already resolved, then please close the issue. Thanks!
		</comment>
		<comment id='5' author='bjourne' date='2020-10-24T01:22:56Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='6' author='bjourne' date='2020-10-31T01:49:26Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
	</comments>
</bug>