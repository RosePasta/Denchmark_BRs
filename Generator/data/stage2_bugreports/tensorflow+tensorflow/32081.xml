<bug id='32081' author='Aashish-1008' open_date='2019-08-29T09:50:32Z' closed_time='2020-04-17T17:55:26Z'>
	<summary>Distributed training not working properly: Waiting for model to be ready. Ready_for_local_init_op: Variables not initialized: global_step</summary>
	<description>
Hello,
I am using tfhub elmo embedding for NER model training.
Training works fine for a single machine.
When I am training to do training on GCP ML engine with 1 master node, 2 parameter server, 3 worker node.
Training started on master node,
But on all three worker node, I am getting this logs continuously for 1 hours,
looks like training is not getting started on worker node.
I am using these versions which currently supported by Google cloud ML Engine:
Python: 3.5
Tensorflow: 1.13.1
ML engine resource usage:
&lt;denchmark-code&gt;trainingInput:
    scaleTier: CUSTOM
    masterType: large_model
    workerType: standard
    parameterServerType: standard
    workerCount: 3
    parameterServerCount: 2
&lt;/denchmark-code&gt;

Waiting for model to be ready. Ready_for_local_init_op: Variables not initialized: global_step, module/bilm/char_embed, module/bilm/CNN/W_cnn_0, module/bilm/CNN/b_cnn_0, module/bilm/CNN/W_cnn_1, module/bilm/CNN/b_cnn_1, module/bilm/CNN/W_cnn_2, module/bilm/CNN/b_cnn_2, module/bilm/CNN/W_cnn_3, module/bilm/CNN/b_cnn_3, module/bilm/CNN/W_cnn_4, module/bilm/CNN/b_cnn_4, module/bilm/CNN/W_cnn_5, module/bilm/CNN/b_cnn_5, module/bilm/CNN/W_cnn_6, module/bilm/CNN/b_cnn_6, module/bilm/CNN_high_0/W_carry, module/bilm/CNN_high_0/b_carry, module/bilm/CNN_high_0/W_transform, module/bilm/CNN_high_0/b_transform, module/bilm/CNN_high_1/W_carry, module/bilm/CNN_high_1/b_carry, module/bilm/CNN_high_1/W_transform, module/bilm/CNN_high_1/b_transform, module/bilm/CNN_proj/W_proj, module/bilm/CNN_proj/b_proj, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias, module/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias, module/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias, module/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias, module/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel, module/aggregation/weights, module/aggregation/scaling, lstm_fused_cell/kernel, lstm_fused_cell/bias, lstm_fused_cell_1/kernel, lstm_fused_cell_1/bias, dense/kernel, dense/bias, crf, beta1_power, beta2_power, lstm_fused_cell/kernel/Adam, lstm_fused_cell/kernel/Adam_1, lstm_fused_cell/bias/Adam, lstm_fused_cell/bias/Adam_1, lstm_fused_cell_1/kernel/Adam, lstm_fused_cell_1/kernel/Adam_1, lstm_fused_cell_1/bias/Adam, lstm_fused_cell_1/bias/Adam_1, dense/kernel/Adam, dense/kernel/Adam_1, dense/bias/Adam, dense/bias/Adam_1, crf/Adam, crf/Adam_1, ready: None
	</description>
	<comments>
		<comment id='1' author='Aashish-1008' date='2019-08-30T06:47:09Z'>
		Request you to provide standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='Aashish-1008' date='2019-08-30T07:13:05Z'>
		Here is the code:
dataset function:
`def dataset_fn(words, tags, params=None, shuffle_and_repeat=False):
params = params if params is not None else {}
shapes = (([None], ()), [None])
types = ((tf.string, tf.int32), tf.string)
defaults = (('', 0), 'O')
&lt;denchmark-code&gt;dataset = tf.data.Dataset.from_generator(
    functools.partial(generator_fn, words, tags),
    output_shapes=shapes, output_types=types)

if shuffle_and_repeat:
    dataset = dataset.shuffle(params['buffer']).repeat(params['epochs'])

dataset = (dataset
           .padded_batch(params.get('batch_size', 20), shapes, defaults)
           .prefetch(1))
return dataset`
&lt;/denchmark-code&gt;

`def model_fn(features, labels, mode, params):
# Read vocabs and inputs
dropout = params['dropout']
&lt;denchmark-code&gt;# Input tensor.
if (mode == tf.estimator.ModeKeys.PREDICT):
    words, nwords = features['words'], features['nwords']
else:
    words, nwords = features

training = (mode == tf.estimator.ModeKeys.TRAIN)



with tf.gfile.GFile(params['vocab_tags_path'], 'r') as f:
    indices = [idx for idx, tag in enumerate(f) if tag.strip() != 'O']
    num_tags = len(indices) + 1

embeddings = ElmoEmbedding(words)

embeddings = tf.layers.dropout(embeddings, rate=dropout, training=training)
# print("---------embeddings-------------")
# print(embeddings, (mode == tf.estimator.ModeKeys.PREDICT))
# print(features)
# LSTM
t = tf.transpose(embeddings, perm=[1, 0, 2])
# print(t.shape)
lstm_cell_fw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])
lstm_cell_bw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])
lstm_cell_bw = tf.contrib.rnn.TimeReversedFusedRNN(lstm_cell_bw)
output_fw, _ = lstm_cell_fw(t, dtype=tf.float32, sequence_length=nwords)
output_bw, _ = lstm_cell_bw(t, dtype=tf.float32, sequence_length=nwords)
output = tf.concat([output_fw, output_bw], axis=-1)
output = tf.transpose(output, perm=[1, 0, 2])
output = tf.layers.dropout(output, rate=dropout, training=training)

# CRF
logits = tf.layers.dense(output, num_tags)
crf_params = tf.get_variable("crf", [num_tags, num_tags], dtype=tf.float32)
pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, nwords)

if mode == tf.estimator.ModeKeys.PREDICT:
    # Predictions
    reverse_vocab_tags = tf.contrib.lookup.index_to_string_table_from_file(
        params['vocab_tags_path'])
    pred_strings = reverse_vocab_tags.lookup(tf.to_int64(pred_ids))
    predictions = {
        # 'pred_ids': pred_ids,
        'tags': pred_strings,
        'score': _
    }

    predictions["key"] = tf.identity(features["key"])

    return tf.estimator.EstimatorSpec(mode, predictions=predictions)
else:
    # Loss
    vocab_tags = tf.contrib.lookup.index_table_from_file(params['vocab_tags_path'])
    tags = vocab_tags.lookup(labels)
    log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(
        logits, tags, nwords, crf_params)
    loss = tf.reduce_mean(-log_likelihood)

    # Metrics
    weights = tf.sequence_mask(nwords)

    accuracy_op = tf.metrics.accuracy(tags, pred_ids, weights)
    precision_op = precision(tags, pred_ids, num_tags, indices, weights)
    recall_op = recall(tags, pred_ids, num_tags, indices, weights)
    f1_op = f1(tags, pred_ids, num_tags, indices, weights)

    metrics = {
        "eval_accuracy": accuracy_op,
        "eval_precision": precision_op,
        "eval_recall": recall_op,
        "eval_f1": f1_op
    }

    # for metric_name, op in metrics.items():
    #     tf.summary.scalar(metric_name, op[1])

    if mode == tf.estimator.ModeKeys.EVAL:
        return tf.estimator.EstimatorSpec(
            mode, loss=loss, eval_metric_ops=metrics)

    elif mode == tf.estimator.ModeKeys.TRAIN:

        train_tensors_log = {
            'accuracy': accuracy_op[1],
            'loss': loss,
            'global_step': tf.train.get_or_create_global_step()
        }

        logging_hook = tf.train.LoggingTensorHook(tensors=train_tensors_log, every_n_iter=5)

        training_accuracy = tf.summary.scalar("training_accuracy", accuracy_op[1])
        training_loss = tf.summary.scalar("training_loss", loss)
        training_precision = tf.summary.scalar("training_precision", precision_op[1])
        training_recall = tf.summary.scalar("training_recall", recall_op[1])
        training_f1 = tf.summary.scalar("training_f1", f1_op[1])

        summary_hook = tf.train.SummarySaverHook(save_steps=2, output_dir=params["checkpoint_path"],
                                                 summary_op=tf.summary.merge(
                                                     [training_accuracy, training_loss, training_precision,
                                                      training_recall, training_f1]))

        train_op = tf.train.AdamOptimizer().minimize(
            loss, global_step=tf.train.get_or_create_global_step())
        return tf.estimator.EstimatorSpec(
            mode, loss=loss, train_op=train_op, training_hooks=[logging_hook, summary_hook])`
&lt;/denchmark-code&gt;

`strategy = tf.contrib.distribute.ParameterServerStrategy()
&lt;denchmark-code&gt;def train_inpf(input_context=None):
    train_dataset = dataset_fn(params["train_words_path"], params["train_tags_path"],
                               params, shuffle_and_repeat=True)
    # if input_context:
    #     train_dataset = train_dataset.shard(input_context.num_input_pipelines,
    #                                         input_context.input_pipeline_id)
    return train_dataset

def eval_inpf(input_context=None):
    eval_dataset = dataset_fn(params["test_words_path"], params["test_tags_path"])
    # if input_context:
    #     eval_dataset = eval_dataset.shard(input_context.num_input_pipelines,
    #                                       input_context.input_pipeline_id)
    return eval_dataset

# with strategy.scope():
#     iterator = strategy.make_input_fn_iterator(
#         train_inpf)
#     replica_results = strategy.extended.call_for_each_replica(
#         replica_fn, iterator.get_next())

cfg = tf.estimator.RunConfig(save_checkpoints_steps=5, train_distribute=strategy)  # train_distribute=strategy, eval_distribute=strategy

estimator = tf.estimator.Estimator(model_fn, params["checkpoint_path"], cfg, params)
Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)

hook = tf.contrib.estimator.stop_if_no_increase_hook(
    estimator, 'f1', 500, min_steps=8000, run_every_secs=120)

train_spec = tf.estimator.TrainSpec(input_fn=train_inpf, max_steps=100000)  # hooks=[hook], max_steps=2000
eval_spec = tf.estimator.EvalSpec(input_fn=eval_inpf, throttle_secs=1200)  # , throttle_secs=120

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)`
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='Aashish-1008' date='2019-09-26T23:33:10Z'>
		ML Engine currently only supports estimator distributed training but not through tf.distribute.
The team is working on enabling that support soon. In the meantime you can add  this snippet to the beginning of your program:
import json, os
tf_config_json = json.loads(os.environ.get('TF_CONFIG', '{}'))
if tf_config_json and tf_config_json['cluster'].get('master', None):
tf_config_json['cluster']['chief'] = tf_config_json['cluster'].pop('master')
if tf_config_json['task']['type'] == 'master':
tf_config_json['task']['type'] = 'chief'
os.environ['TF_CONFIG'] = json.dumps(tf_config_json)
		</comment>
		<comment id='4' author='Aashish-1008' date='2019-10-11T16:42:02Z'>
		&lt;denchmark-link:https://github.com/sshrdp&gt;@sshrdp&lt;/denchmark-link&gt;
 meet same problem. What 's the meaning of "estimator distributed training but not through tf.distribute" ?
		</comment>
		<comment id='5' author='Aashish-1008' date='2019-12-16T03:45:17Z'>
		If you don't specify any distribution strategy and just run an estimator with parameter servers, you will not run into this issue.
		</comment>
		<comment id='6' author='Aashish-1008' date='2020-04-17T17:55:26Z'>
		If you're providing your own container, you need to use set your job's trainingInput.useChiefInTfConfig to true.
See this for more details: &lt;denchmark-link:https://cloud.google.com/ai-platform/training/docs/distributed-training-details#chief-versus-master&gt;https://cloud.google.com/ai-platform/training/docs/distributed-training-details#chief-versus-master&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Aashish-1008' date='2020-04-17T17:55:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32081&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32081&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>