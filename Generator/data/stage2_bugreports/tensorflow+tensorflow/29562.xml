<bug id='29562' author='trilokpadhi' open_date='2019-06-08T18:15:59Z' closed_time='2019-07-03T18:46:30Z'>
	<summary>Custom Layer in tensorflow v2.0.0beta throws object has no attribute '_expects_mask_arg' error</summary>
	<description>
I am trying to reconsturct an image based on three inputs of previous layers normal (None,128,128,3),albedo(None,128,128,3) and lighting(27) . But here the code still says object has no attribute '_expects_mask_arg' error .I have presented my code here in which I have implemented a custom layer using Tensorflow v2 beta using the high level API.
The code begins here .
class Reconstruction_Layer(tf.keras.layers.Layer):
&lt;denchmark-code&gt;    def __init__(self,input_shape):
   # super(Reconstruction_Layer, self).__init__()
    #self.num_outputs = num_outputs
    #self.pixel=np.zeros((9),dtype=int)
    
    self.sphar=np.zeros((9),dtype=float)
    self.y=np.zeros((9),dtype=float)
    self.reconstructed_img=np.zeros((128,128,3),dtype=float)
    #self.y=tf.zeros([128,128,9])
    self.normal_light=np.zeros((128,128,9),dtype=float)
    self.y_temp=np.zeros((9),dtype=float)
    w_init = tf.random_normal_initializer()
    self.r_img = tf.Variable(initial_value=w_init(shape=input_shape),dtype='float32',trainable=True)

   

def build(self, input_shape):
    print(input_shape)
    super(Reconstruction_Layer, self).build(input_shape)
        


def call(self,input_layer,*args,**kwargs):
    self.normal,self.albedo = input_layer
    super().__call__(self,*args,**kwargs)
        
    
    """
    self.normal=np.array(self.normal)
    self.albedo=np.array(self.albedo)
    self.light=np.array(self.light)
    """
    for i in range(128):
        for j in range(128):
            #self.y=spherical_harmonic_calc(self.normal(i,j))
            
            self.pixel=self.normal[i,j,:]
            
            np.reshape(self.pixel,(3))
            
            #self.normal_light(i,j)= self.y
            self.sphar[0]=(1/((4*math.pi)**0.5))
            self.sphar[1]=((3/(4*math.pi))**0.5)*self.pixel[2]
            self.sphar[3]=(((3/(4*math.pi))**0.5)*self.pixel[1])
            self.sphar[4]=((1/2)*((5/(4*math.pi))**0.5)*(3*(self.pixel[2]**2) - 1))
            self.sphar[5]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[0])
            self.sphar[6]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[1])
            self.sphar[7]=((3/2)*((5/(12*math.pi))**0.5)*((self.pixel[0]**2)-(self.pixel[1]**2)))
            self.sphar[8]=(3*((5/(12*math.pi))**0.5)*self.pixel[0]*self.pixel[1])
            
            self.normal_light[i,j,:]=self.sphar
    
    for j in range(128):
        for k in range(128):
            for i in range(3):
                #self.y_temp=self.normal_light(j,k)
                """
                print('self.normal_light[j,k]',self.normal_light[j,k])
                print('self.normal_light[j,k].shape',self.normal_light[j,k].shape)
                print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1])
                print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1].shape)
                """
                self.reconstructed_img[j,k,i]=self.albedo[j,k,i]* tf.tensordot(self.normal_light[j,k],self.light[i*9:(i+1)*9 ],axes=1)
    
    self.reconstructed_img=tf.convert_to_tensor(self.reconstructed_img)
    self.r_img=self.reconstructed_img
    
    def compute_output_shape(self):
        return shape(self.r_img)
 
    return self.r_img
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/20143249/59150910-4a47ab00-8a48-11e9-9dbf-5f9fa24153dc.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='trilokpadhi' date='2019-06-11T12:01:58Z'>
		I have tried to execute the code snippet on Colab with TF 2.0 Beta but was not able to get the mentioned error. Please help us to reproduce the issue or if possible provide us the full snippet that can replicate the issue. Also provide information as platform (operating system and architecture you are using). Thanks!
		</comment>
		<comment id='2' author='trilokpadhi' date='2019-06-11T15:27:44Z'>
		here is the code which reproduces the error:----
`
from tensorflow.keras import layers
from tensorflow.keras.layers import BatchNormalization,Dense,Input
from tensorflow.keras.models import Model
#from keras.layers.advanced_activations import LeakyReLU
from tensorflow.keras.layers import  Conv2DTranspose
from tensorflow.keras.layers import LeakyReLU ,ReLU
from tensorflow.keras.datasets import mnist,cifar10
import numpy as np
input_tensor=Input(shape=(128,128,3))
x=layers.Conv2D(64,(7,7),strides=1,activation='relu',padding='same')(input_tensor)
x=BatchNormalization()(x)
x=layers.Conv2D(128,(3,3),strides=1,activation='relu',padding='same')(x)
x=BatchNormalization()(x)
x=layers.Conv2D(128,(3,3),strides=2,activation='relu',padding='same')(x)
normal_1=BatchNormalization()(x)
normal_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(normal_1)
normal_1=BatchNormalization()(normal_1)
normal_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(normal_1)
output_res_1 = layers.add([normal_1,x])
#Normal Residual Block
#Residual Block 1
normal_1=BatchNormalization()(x)
normal_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(normal_1)
normal_1=BatchNormalization()(normal_1)
normal_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(normal_1)
output_res_1 = layers.add([normal_1,x])
output_normal=output_res_1
output_normal=BatchNormalization()(output_normal)
output_normal=tf.nn.relu(output_normal)
albedo_1=BatchNormalization()(x)
albedo_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(albedo_1)
albedo_1=BatchNormalization()(albedo_1)
albedo_1=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(albedo_1)
output_res_11 = layers.add([albedo_1,x])
output_albedo=output_res_11
output_albedo=BatchNormalization()(output_albedo)
output_albedo=tf.nn.relu(output_albedo)
output_albedo_conv=tf.image.resize(output_albedo,size=[128,128])
output_normal_conv=tf.image.resize(output_normal,size=[128,128])
output_normal_conv=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(output_normal_conv)
output_normal_conv=BatchNormalization()(output_normal_conv)
output_normal_conv=tf.nn.relu(output_normal_conv)
output_normal_conv=layers.Conv2D(64,(3,3),strides=1,activation='relu',padding='same')(output_normal_conv)
output_normal_conv=BatchNormalization()(output_normal_conv)
output_normal_conv=tf.nn.relu(output_normal_conv)
output_normal_conv=layers.Conv2D(3,(1,1),strides=1,padding='same')(output_normal_conv)
output_albedo_conv=layers.Conv2D(128,(1,1),strides=1,activation='relu',padding='same')(output_albedo)
output_albedo_conv=BatchNormalization()(output_albedo_conv)
output_albedo_conv=tf.nn.relu(output_albedo_conv)
output_albedo_conv=layers.Conv2D(64,(3,3),strides=1,activation='relu',padding='same')(output_albedo_conv)
output_albedo_conv=BatchNormalization()(output_albedo_conv)
output_albedo_conv=tf.nn.relu(output_albedo_conv)
output_albedo_conv=layers.Conv2D(3,(1,1),strides=1,padding='same')(output_albedo_conv)
#light Estimator
lighting_vector=layers.Concatenate()([x,output_albedo,output_normal])
lighting_vector=layers.Conv2D(128,(1,1),padding='same')(lighting_vector)
lighting_vector=tf.nn.relu(lighting_vector)
lighting_vector=BatchNormalization()(lighting_vector)
lighting_vector=layers.AveragePooling2D(pool_size=(2, 2), padding='same')(lighting_vector)
lighting_vector=layers.Flatten()(lighting_vector)
lighting_vector=layers.Dense(27,activation='relu')(lighting_vector)
import math
class Reconstruction_Layer(tf.keras.layers.Layer):
&lt;denchmark-code&gt;def __init__(self,input_shape):
   # super(Reconstruction_Layer, self).__init__()
    #self.num_outputs = num_outputs
    #self.pixel=np.zeros((9),dtype=int)
    
    self.sphar=np.zeros((9),dtype=float)
    self.y=np.zeros((9),dtype=float)
    self.reconstructed_img=np.zeros((128,128,3),dtype=float)
    #self.y=tf.zeros([128,128,9])
    self.normal_light=np.zeros((128,128,9),dtype=float)
    self.y_temp=np.zeros((9),dtype=float)
    w_init = tf.random_normal_initializer()
    self.r_img = tf.Variable(initial_value=w_init(shape=input_shape),dtype='float32',trainable=True)

   

def build(self, input_shape):
    print(input_shape)
    super(Reconstruction_Layer, self).build(input_shape)
        


def call(self,input_layer,*args,**kwargs):
    self.normal,self.albedo = input_layer
    super().__call__(self,*args,**kwargs)
        
    
    """
    self.normal=np.array(self.normal)
    self.albedo=np.array(self.albedo)
    self.light=np.array(self.light)
    """
    for i in range(128):
        for j in range(128):
            #self.y=spherical_harmonic_calc(self.normal(i,j))
            
            self.pixel=self.normal[i,j,:]
            
            np.reshape(self.pixel,(3))
            
            #self.normal_light(i,j)= self.y
            self.sphar[0]=(1/((4*math.pi)**0.5))
            self.sphar[1]=((3/(4*math.pi))**0.5)*self.pixel[2]
            self.sphar[3]=(((3/(4*math.pi))**0.5)*self.pixel[1])
            self.sphar[4]=((1/2)*((5/(4*math.pi))**0.5)*(3*(self.pixel[2]**2) - 1))
            self.sphar[5]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[0])
            self.sphar[6]=(3*((5/(12*math.pi))**0.5)*self.pixel[2]*self.pixel[1])
            self.sphar[7]=((3/2)*((5/(12*math.pi))**0.5)*((self.pixel[0]**2)-(self.pixel[1]**2)))
            self.sphar[8]=(3*((5/(12*math.pi))**0.5)*self.pixel[0]*self.pixel[1])
            
            self.normal_light[i,j,:]=self.sphar
    
    for j in range(128):
        for k in range(128):
            for i in range(3):
                #self.y_temp=self.normal_light(j,k)
                """
                print('self.normal_light[j,k]',self.normal_light[j,k])
                print('self.normal_light[j,k].shape',self.normal_light[j,k].shape)
                print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1])
                print('self.light[i*9:(i+1)*9 - 1]',self.light[i*9:(i+1)*9 - 1].shape)
                """
                self.reconstructed_img[j,k,i]=self.albedo[j,k,i]* tf.tensordot(self.normal_light[j,k],self.light[i*9:(i+1)*9 ],axes=1)
    
    self.reconstructed_img=tf.convert_to_tensor(self.reconstructed_img)
    self.r_img=self.reconstructed_img
    
    def compute_output_shape(self):
        return shape(self.r_img)
 
    return self.r_img
&lt;/denchmark-code&gt;

d=[output_normal_conv,output_albedo_conv,lighting_vector]
y=Reconstruction_Layer((128,128,3))(d)
`
		</comment>
		<comment id='3' author='trilokpadhi' date='2019-06-11T15:34:12Z'>
		I am using Ubuntu 18.04 in 64 bit architecture
		</comment>
		<comment id='4' author='trilokpadhi' date='2019-06-14T12:23:09Z'>
		Tried to execute the full code snippet provided on Colab with TF 2.0.0-beta but still unable to get the error. Could you please help and let us know which line or part of code is giving the error. Thanks!
		</comment>
		<comment id='5' author='trilokpadhi' date='2019-06-14T15:45:40Z'>
		Can you please provide the link of the notebook where you tried to run it??
I tried running the above code snippet in google colab and got the follwing error
AttributeError: 'Reconstruction_Layer' object has no attribute '_trainable'
The following is the colab link . Anyone with the lin can also edit .
Thanks!
&lt;denchmark-link:https://colab.research.google.com/drive/1ZSwmN1BCh6nm68bxC9TOcLrzshIesTWg&gt;https://colab.research.google.com/drive/1ZSwmN1BCh6nm68bxC9TOcLrzshIesTWg&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='trilokpadhi' date='2019-06-17T08:44:43Z'>
		Have tried on Colab with TF 2.0beta and was now able to get the mentioned error. Thanks!
		</comment>
		<comment id='7' author='trilokpadhi' date='2019-06-28T22:18:39Z'>
		Apologies for the delay in response. Its difficult to debug extensive models like these, We will greatly appreciate if you can construct a minimal concise code snippet which can reproduce the bug reported rather than whole model. Thanks!
		</comment>
		<comment id='8' author='trilokpadhi' date='2019-07-03T18:46:30Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='9' author='trilokpadhi' date='2019-07-03T18:46:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29562&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29562&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='trilokpadhi' date='2019-08-01T12:31:45Z'>
		You must call the super class  function. This is the source of this particular error, given that _expects_mask_arg is defined in  as can be seen &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L216&gt;here&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>