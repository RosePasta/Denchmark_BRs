<bug id='37404' author='kafan1986' open_date='2020-03-06T22:50:38Z' closed_time='2020-03-07T06:52:55Z'>
	<summary>TFLite inference throwing error at one of the run</summary>
	<description>
System information


Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Followed official classifier example


OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Android 9


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Huawei 9 lite


TensorFlow version (use command below):
implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
implementation 'org.tensorflow:tensorflow-lite-support:0.0.0-nightly'
implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'


Describe the current behavior
I have a model that has 1 input and 2 outputs. I have written the below code for inference using run() rather than runForMultipleInputsOutputs. So first I have a query:
Would running it with runForMultipleInputsOutputs() rather than calling run() twice, make it run faster or does runForMultipleInputsOutputs does same internally?
Now I get right inference for first output layer but for the 2nd output inference, I get the below error message.
java.lang.IllegalArgumentException: Cannot convert between a TensorFlowLite buffer with 32 bytes and a Java Buffer with 8 bytes.
Describe the expected behavior
Should run OK.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;  ```
   // Initialization Code
   tflite = new Interpreter(tfliteModel, tfliteOptions);

    // Loads labels out from the label file.
    labelsAge = ageLabels; //List

    labelsGender = genderLabels; // List

    // Reads type and shape of input and output tensors, respectively.
    int imageTensorIndex = 0;
    int[] imageShape = tflite.getInputTensor(imageTensorIndex).shape(); // {1, height, width, 3}

    imageSizeY = imageShape[1];
    imageSizeX = imageShape[2];
    DataType imageDataType = tflite.getInputTensor(imageTensorIndex).dataType();

    // Creates the input tensor.
    inputImageBuffer = new TensorImage(imageDataType);

    // For Outputs
    //For Age
    int probabilityAgeTensorIndex = 0; // Age
    int[] probabilityAgeShape = tflite.getOutputTensor(probabilityAgeTensorIndex).shape(); // {1, NUM_CLASSES}
    DataType probabilityAgeDataType = tflite.getOutputTensor(probabilityAgeTensorIndex).dataType();

    // Creates the output tensor and its processor.
    outputProbabilityAgeBuffer = TensorBuffer.createFixedSize(probabilityAgeShape, probabilityAgeDataType);

    // Creates the post processor for the output probability.
    probabilityAgeProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();

    //For Gender
    int probabilityGenderTensorIndex = 1; // Gender
    int[] probabilityGenderShape = tflite.getOutputTensor(probabilityGenderTensorIndex).shape(); // {1, NUM_CLASSES}
    DataType probabilityGenderDataType = tflite.getOutputTensor(probabilityGenderTensorIndex).dataType();

    // Creates the output tensor and its processor.
    outputProbabilityGenderBuffer = TensorBuffer.createFixedSize(probabilityGenderShape, probabilityGenderDataType);

    // Creates the post processor for the output probability.
    probabilityGenderProcessor = new TensorProcessor.Builder().add(getPostprocessNormalizeOp()).build();


   //********  Inference code ************
    public AgeGenderValues estimateAgeGender(final Bitmap bitmap) {
    // Logs this method so that it can be analyzed with systrace.
    Trace.beginSection("estimateImage");

    Trace.beginSection("loadImage");
    inputImageBuffer = loadImage(bitmap);
    Trace.endSection();

    // Runs the inference call.
    Trace.beginSection("ageRunInference ");
    tflite.run(inputImageBuffer.getBuffer(), outputProbabilityAgeBuffer.getBuffer().rewind());
    Trace.endSection();

    Trace.beginSection("genderRunInference ");
    // ********** ERROR THROWN AT BELOW STATEMENT  **************
    tflite.run(inputImageBuffer.getBuffer(), outputProbabilityGenderBuffer.getBuffer().rewind());
    Trace.endSection();

    // Gets the map of label and probability.
    Map&lt;String, Float&gt; labeledAgeProbability = new TensorLabel(labelsAge, probabilityAgeProcessor.process(outputProbabilityAgeBuffer)).getMapWithFloatValue();
    Map&lt;String, Float&gt; labeledGenderProbability = new TensorLabel(labelsGender, probabilityGenderProcessor.process(outputProbabilityGenderBuffer)).getMapWithFloatValue();
    Trace.endSection();

    AgeGenderValues tmpAgeGenderValues = new AgeGenderValues();
    // Gets top-k results.
    tmpAgeGenderValues.Age = getTopKProbability(labeledAgeProbability);
    tmpAgeGenderValues.Gender = getTopKProbability(labeledGenderProbability);
    return tmpAgeGenderValues;
}

```
&lt;/denchmark-code&gt;

Graph
&lt;denchmark-link:https://user-images.githubusercontent.com/7953422/76128759-3bb80f80-602b-11ea-9208-92f5716ad320.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='kafan1986' date='2020-03-07T06:52:55Z'>
		Figured it out myself. Closing issue.
		</comment>
		<comment id='2' author='kafan1986' date='2020-03-07T06:52:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37404&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37404&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>