<bug id='24875' author='CtfGo' open_date='2019-01-13T05:13:04Z' closed_time='2019-05-03T01:09:59Z'>
	<summary>How to define a variable with different value for each tower under MirroredStrategy</summary>
	<description>
I tried to train model on multi-gpus with tf estimator and MirroredStrategy. And I found that variables of the model are wrapped as MirroredVariables which are always in sync among towers.
However, there is a variable that needs to have different value for each tower on every step of training, How to define such variable ? that is, a variable with locality T, refers to (&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/DistributionStrategy&gt;https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/DistributionStrategy&lt;/denchmark-link&gt;
)
	</description>
	<comments>
		<comment id='1' author='CtfGo' date='2019-01-15T22:21:59Z'>
		&lt;denchmark-link:https://github.com/CtfGo&gt;@CtfGo&lt;/denchmark-link&gt;
 Please post this kind of support questions at &lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;Stackoverflow&lt;/denchmark-link&gt;
. There is a big community to support. Github is mainly for addressing bugs in installation and performance. Responses to your questions will help others also if you post them on Stackoverflow. Thanks!
		</comment>
		<comment id='2' author='CtfGo' date='2019-01-22T03:22:55Z'>
		I have the same question or feature request. The question posted at &lt;denchmark-link:https://stackoverflow.com/questions/54166123/how-to-define-a-variable-with-different-value-for-each-tower-under-mirroredstrat&gt;Stackoverflow&lt;/denchmark-link&gt;
 doesn't have any response. &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='CtfGo' date='2019-01-22T18:29:38Z'>
		&lt;denchmark-link:https://github.com/CtfGo&gt;@CtfGo&lt;/denchmark-link&gt;
 Please check if there is any solution &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aclosed+MirroredStrategy&gt;here&lt;/denchmark-link&gt;
. If you don't find any solution, then please fill the details in the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new?template=00-bug-performance-issue.md&gt;template&lt;/denchmark-link&gt;
 to find root cause of the issue. Thanks!
		</comment>
		<comment id='4' author='CtfGo' date='2019-01-29T00:03:15Z'>
		&lt;denchmark-link:https://github.com/CtfGo&gt;@CtfGo&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/x10000year&gt;@x10000year&lt;/denchmark-link&gt;
  can you describe the use case, why you need variables which are not synced across towers? Also would you want these variables to be synced at all, or never synced?
		</comment>
		<comment id='5' author='CtfGo' date='2019-01-29T12:20:29Z'>
		&lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;

One of my use cases is to implement truncated back propagation for a unrolled rnn. In this case, for every training step and every tower we read only n steps from a sequence, and compute n steps of the unrolled rnn. The computation starts with the last rnn states from the same sequence, and at the end stores the new rnn states into local variables.  The per tower local/temporary variables are never synced. For each tower we have a custom data input op that guarantees every data sequence is processed by the same tower.
		</comment>
		<comment id='6' author='CtfGo' date='2019-05-03T01:09:59Z'>
		You could try to create variables with VariableSynchronization.ON_READ.  If that doesn't work, you could look into creating a new distribution strategy which implements your logic of syncing them (or in your case not syncing them at all?).  Please re-open if those methods don't help.
		</comment>
		<comment id='7' author='CtfGo' date='2019-05-03T01:10:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=24875&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=24875&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>