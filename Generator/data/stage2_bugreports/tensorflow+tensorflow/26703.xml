<bug id='26703' author='guillaumekln' open_date='2019-03-14T14:40:00Z' closed_time='2020-03-19T14:42:24Z'>
	<summary>[2.0] Combining metrics places updates on the wrong graph</summary>
	<description>
System information

Have I written custom code: Yes
OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from: binary
TensorFlow version: 2.0.0.dev20190311
Python version: 3.6.6
CUDA/cuDNN version: 10.0

Describe the current behavior
I wanted to define a custom metric that is the combination of 2 metrics:
import tensorflow as tf

class F1(tf.metrics.Metric):

  def __init__(self, **kwargs):
    super(F1, self).__init__(**kwargs)
    self.precision = tf.metrics.Precision()
    self.recall = tf.metrics.Recall()

  @property
  def updates(self):
    return self.precision.updates + self.recall.updates

  def update_state(self, y_true, y_pred):
    self.precision.update_state(y_true, y_pred)
    self.recall.update_state(y_true, y_pred)

  def result(self):
    precision = self.precision.result()
    recall = self.recall.result()
    return (2 * precision * recall) / (recall + precision)
But when run in graph mode, the updates operations are placed on the wrong graph which raises an error in the Estimator code:
&lt;denchmark-link:https://github.com/tensorflow/estimator/blob/v2.0.0-alpha/tensorflow_estimator/python/estimator/model_fn.py#L497&gt;https://github.com/tensorflow/estimator/blob/v2.0.0-alpha/tensorflow_estimator/python/estimator/model_fn.py#L497&lt;/denchmark-link&gt;

Am I missing something here? The F1 implementation looks correct so I suspect this is a bug.
Describe the expected behavior
The updates should be placed on the default graph.
Code to reproduce the issue
with tf.Graph().as_default() as graph:
  precision = tf.metrics.Precision()
  precision.update_state([0, 0, 1], [1, 0, 1])
  print(precision.updates[0].graph is graph)  # True

  f1 = F1()
  f1.update_state([0, 0, 1], [1, 0, 1])
  print(f1.updates[0].graph is graph)  # False
	</description>
	<comments>
		<comment id='1' author='guillaumekln' date='2019-03-25T17:41:24Z'>
		&lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
 can you look at this?
		</comment>
		<comment id='2' author='guillaumekln' date='2019-03-25T18:39:32Z'>
		Yes, I am able to repro, will look into the fix.
		</comment>
		<comment id='3' author='guillaumekln' date='2019-03-25T19:07:45Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
 is there a reason you have overridden  property?
We wrap metrics update_state API in tf.function internally to allow users to write simple metric updates. Since you have overridden updates, the updates you get are the updates of the inner Precision, Recall metrics which are in the FuncGraph scope. Your F1 metric should work as expected with both Estimator and Keras APIs without having to override updates. Thank you!
		</comment>
		<comment id='4' author='guillaumekln' date='2019-03-25T19:35:21Z'>
		I'm not sure that's the issue because if you don't override updates, it will still return the updates of the inner Precision and Recall metrics.  For example, when updates is not overriden, the graph of some updates is still not the default one:
f1 = F1()
f1.update_state([0, 0, 1], [1, 0, 1])
print(f1.updates[0].graph is graph)  # True
print(f1.updates[1].graph is graph)  # False
print(f1.updates[2].graph is graph)  # False
I was not sure why there are 3 updates in this case, that's why I overrided updates.
Note that when integrating with Estimator, the error is the same whether updates is overriden or not:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/model_fn.py", line 180, in __new__
    eval_metric_ops = _validate_eval_metric_ops(eval_metric_ops)
  File "/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/model_fn.py", line 573, in _validate_eval_metric_ops
    'eval_metric_ops', '{0}: {1}'.format(key, val.name)))
ValueError: eval_metric_ops with "precision: group_deps" must be from the default graph. Possible causes of this error include: 

1) eval_metric_ops was created outside the context of the default graph.

2) The object passed through to EstimatorSpec was not created in the most recent call to "model_fn".
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='guillaumekln' date='2019-04-10T10:15:27Z'>
		For other users facing this, a possible workaround is to override the __new__ method:
class F1(tf.metrics.Metric):
  def __new__(cls, *args, **kwargs):
    return tf.keras.layers.Layer.__new__(cls)
		</comment>
		<comment id='6' author='guillaumekln' date='2019-09-13T10:10:35Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;
,
Looks like it is fixed in latest Tf 2.0 nightly version.
Please have a look at colab gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/08cfa8cffc1958a581de88b6927ed7ea/untitled148.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='guillaumekln' date='2019-09-13T10:24:49Z'>
		It does not seem like it. The second print should display True.
		</comment>
		<comment id='8' author='guillaumekln' date='2020-03-19T12:47:45Z'>
		&lt;denchmark-link:https://github.com/guillaumekln&gt;@guillaumekln&lt;/denchmark-link&gt;

Could you please check &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/3cd2a6de34d417b28aefcc2db2d6ad07/26703.ipynb&gt;this gist&lt;/denchmark-link&gt;
 run on latest version of tensorflow, and let us know if it helps. Thanks!
		</comment>
		<comment id='9' author='guillaumekln' date='2020-03-19T12:54:29Z'>
		Your gist shows that the issue is still not fixed (both print should output True). However, I'm no longer interested in this issue and it does not seem other users were impacted, so feel free to close it.
		</comment>
		<comment id='10' author='guillaumekln' date='2020-03-19T14:42:24Z'>
		Moving the issue to closed status as confirmed.
		</comment>
		<comment id='11' author='guillaumekln' date='2020-03-19T14:42:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26703&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26703&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>