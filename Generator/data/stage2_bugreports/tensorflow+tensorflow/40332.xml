<bug id='40332' author='lordfiftyfive' open_date='2020-06-09T18:33:27Z' closed_time='2020-06-10T22:10:38Z'>
	<summary>gradient descent and performance issues with Tf 2.1</summary>
	<description>
I am using the latest builds of tensorflow and tensorflow probability respectively with the following code
&lt;denchmark-code&gt;x = x.astype(np.float64)#tf.dtypes.cast(x, tf.int32) #
#x = tf.cast(x, tf.float32)
#x = tensor_util.convert_nonref_to_tensor(x, dtype=x.dtype)

class RBFKernelFn(tf.keras.layers.Layer):
  def __init__(self, **kwargs):
    super(RBFKernelFn, self).__init__(**kwargs)
    dtype = kwargs.get('dtype', None)
    self.amplitude = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='amplitude')
    self.length_scale = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='length_scale')
    
    
  def call(self, x):
    # Never called -- this is just a layer so it can hold variables
    # in a way Keras understands.
    #print(dtype)
    return x

  @property
  def kernel(self):

    
    return tfk.ExponentiatedQuadratic(
      amplitude=self.amplitude,
      length_scale=self.length_scale)
    observation_noise_variance = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')

dtype = np.float64
amplitude = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='amplitude')
length_scale = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='length_scale')
kernel = tfk.ExponentiatedQuadratic(
      amplitude=amplitude,
      length_scale=length_scale)
observation_noise_variance = tfp.util.TransformedVariable(
      1., tfb.Softplus(), dtype=dtype, name='observation_noise_variance')
&lt;/denchmark-code&gt;

and this is the code for the neural network itself
'
&lt;denchmark-code&gt;x_tst = x[189::]
x_range = 237
num_distributions_over_Functions = 1
tf.keras.backend.set_floatx('float64')
#kernel = Brownian #tfp.positive_semidefinite_kernels.ExponentiatedQuadratic#MaternOneHalf()

model = tf.keras.Sequential([
    tf.keras.Input(shape=(1,14), dtype=np.float64),
    tf.keras.layers.LSTM(25,kernel_initializer='ones',activation='tanh', dtype = x.dtype, use_bias=True),
    #tf.keras.layers.InputLayer(input_shape=(10),dtype=x.dtype),#put a 1 before the 9 later
    tf.keras.layers.Dense(50,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(100,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(175,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(250,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(225,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(200,kernel_initializer='ones',use_bias=False),
    #goal is to eventually replace the first dense layer with an LSTM layer
    #tf.keras.layers.LSTM
    #tf.keras.layers.TimeDistributed(Dense(vocabulary)))
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(150,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(125,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(100,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(75,kernel_initializer='ones', use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(50,kernel_initializer='ones',use_bias=False),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dense(25, kernel_initializer='ones',use_bias=False,),
    tfp.layers.VariationalGaussianProcess(
    num_inducing_points=num_inducing_points, kernel_provider=RBFKernelFn(dtype=x.dtype) , event_shape=(1,),
    inducing_index_points_initializer=tf.compat.v1.constant_initializer(
            np.linspace(0,x_range, num=1125,
                        dtype=x.dtype)[..., np.newaxis]), unconstrained_observation_noise_variance_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(x.dtype))),variational_inducing_observations_scale_initializer=(tf.compat.v1.constant_initializer(np.log(np.expm1(1.)).astype(np.float64))), mean_fn=None,
    jitter=1e-06, convert_to_tensor_fn=tfp.distributions.Distribution.sample)


])
&lt;/denchmark-code&gt;

I am getting the following warnings which seem to be impacting my performance further. Before the upgrade I could get near 0 loss with 270 epochs. Now it has stopped improving altogether after a few hundred epochs and gets permanently stuck at 34.
	</description>
	<comments>
		<comment id='1' author='lordfiftyfive' date='2020-06-10T10:07:23Z'>
		&lt;denchmark-link:https://github.com/lordfiftyfive&gt;@lordfiftyfive&lt;/denchmark-link&gt;

I ran the above code but face a different error, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/da44bbf73dd5df5eff55dec0b48d3b21/untitled.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Please share code with all dependencies or share a colab gist for us to analyse the issue faced.
		</comment>
		<comment id='2' author='lordfiftyfive' date='2020-06-10T22:10:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40332&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40332&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>