<bug id='45727' author='yummychop' open_date='2020-12-16T01:00:41Z' closed_time='2021-01-04T21:55:44Z'>
	<summary>Issues about the TRTEngineOp</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.4.0
Python version: 3.6.9
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 11.0/8.0.4
GPU model and memory: GTX 1060 6GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
I tried to convert tensorflow FP32 model to FP16 using tensorRT 7.2.1, when I tried to save the converted model, it complained:
....: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at trt_engine_resource_ops.cc:195 : Not found: Resource TF-TRT/TRTEngineOp_1_0/N10tensorflow8tensorrt22TRTEngineCacheResourceE does not exist.
INFO:tensorflow:Could not find TRTEngineOp_1_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.
The first message seems like a known issue which can be ignored, but the second message seems not OK.
After that when I tried to infer using the converted model tensorflow complained:
....: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:587] Running native segment forPartitionedCall/TRTEngineOp_0_0 due to failure in verifying input shapes: Input shapes do not match input partial shapes stored in graph, for PartitionedCall/TRTEngineOp_0_0: [[28,28]] != [[?,28,28]]
Did I miss some configurations for the TRTEngine?
Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;params = tf.experimental.tensorrt.ConversionParams(
    precision_mode='FP16')
converter = tf.experimental.tensorrt.Converter(
    input_saved_model_dir="my_dir", conversion_params=params)
converter.convert()
converter.save(output_saved_model_dir)
&lt;/denchmark-code&gt;

The above codes are from &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/experimental/tensorrt/Converter&gt;https://www.tensorflow.org/api_docs/python/tf/experimental/tensorrt/Converter&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;print("The signature keys are: ",list(loaded.signatures.keys())) 
infer = loaded.signatures["serving_default"]

im_select = 0 # choose train-image you want to classify
labeling = infer(tf.constant(train_images[im_select],dtype=float))['LastLayer']   ## Here, the Image classification happens; we need the name of the last layer we defined in the beginning
&lt;/denchmark-code&gt;

The above are from &lt;denchmark-link:https://colab.research.google.com/gist/monkeyman85/e04e240cde74be48750d8160e078d5d7/convert_simplemodel_to_tensorrt_rev1.ipynb#scrollTo=oixTGKOSutMN&gt;https://colab.research.google.com/gist/monkeyman85/e04e240cde74be48750d8160e078d5d7/convert_simplemodel_to_tensorrt_rev1.ipynb#scrollTo=oixTGKOSutMN&lt;/denchmark-link&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='yummychop' date='2020-12-16T11:22:09Z'>
		Was able to run the code without any issues on &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/64a21ab36a0bf583844cc5c44af589de/45727.ipynb#scrollTo=oixTGKOSutMN&gt;TF v2.3&lt;/denchmark-link&gt;
.
However, Colab notebook crashes on running &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/de4332ce5b49f4745acd2376eea1897a/45727-2-4.ipynb&gt;TF v2.4&lt;/denchmark-link&gt;
 and TF-nightly. Please check the linked gist for reference. Thanks!
		</comment>
		<comment id='2' author='yummychop' date='2020-12-16T20:42:39Z'>
		&lt;denchmark-link:https://github.com/yummychop&gt;@yummychop&lt;/denchmark-link&gt;
 Did you test with TF 2.4 in your local with cuda 11 installed? Colab is still hosting cuda 10.1 and TF 2.3 therefore testing with TF 2.4 on Colab may not be the right indicator.
		</comment>
		<comment id='3' author='yummychop' date='2020-12-17T00:07:56Z'>
		
@yummychop Did you test with TF 2.4 in your local with cuda 11 installed? Colab is still hosting cuda 10.1 and TF 2.3 therefore testing with TF 2.4 on Colab may not be the right indicator.

I didn't run the Colab directly, I copied the codes from Colab to the local terminal to run them. Anyways I downgraded my TF to 2.3 TR to 6, CUDA to 10.1 and CUDNN to 7. Are there some simple codes to check if the TF-TRT engine works properly? Thank you very much
		</comment>
		<comment id='4' author='yummychop' date='2020-12-18T01:55:04Z'>
		You may try &lt;denchmark-link:https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#usingtftrt&gt;https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#usingtftrt&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='yummychop' date='2020-12-28T21:33:57Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='6' author='yummychop' date='2021-01-04T21:55:43Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='7' author='yummychop' date='2021-01-04T21:55:45Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45727&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45727&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>