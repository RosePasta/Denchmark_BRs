<bug id='18588' author='nuchi' open_date='2018-04-17T06:57:14Z' closed_time='2018-05-20T21:28:44Z'>
	<summary>XLA implementation of FFT on CPU pulls in tf/core:framework</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos 10.11
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): commit 63c6562 (master as of April 15 2018)
Python version:  n/a
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: n/a
GPU model and memory: n/a
Exact command to reproduce: bazel build --config=opt //tensorflow/compiler/xla/service/cpu:runtime_fft. It works, but see below.

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Short version: The CPU implementation of the XLA FFT operation appears to pull in tensorflow::Tensor and ...::TensorShape as a dependency, via //tensorflow/core:framework.
Long version: The FFT implementation comes in three flavors; real-to-complex, complex-to-real, and complex-to-complex. The first two flavors involve allocating a temporary buffer for an intermediate step in the computation. This is currently achieved by creating a tensorflow::Tensor object. This requires linking against //tensorflow/core:framework.
This feels like a bug, or at least unintentional and undesirable. For instance, every other op listed in tensorflow/compiler/xla/service/cpu/BUILD, besides runtime_fft, depends only on :framework_lite. My understanding re: allocating temporary space was that (at least for the AOT compiler, not sure about JIT) there were specific temporary buffers set aside, and that allocation should work through that system; not by just letting malloc run wild. Is that understanding correct? (Aside: Eigen's FFT op internally calls malloc, regardless of FFT flavor, which likewise bypasses the AOT temporary buffers. Is that ok?)
Is anyone currently working on this? (Has anyone noticed anything awry?) If I were to try fixing this myself, would anyone have any suggestions on how to allocate a temporary buffer in an XLA-friendly way? I thought one possibility would be writing an Algebraic Simplifier pass to rewrite real-to-complex and complex-to-real flavors in terms of the complex-to-complex flavor (which doesn't need to create a tf::Tensor), but that's my only idea.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

References:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/cpu/BUILD&gt;tensorflow/compiler/xla/service/cpu/BUILD&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/cpu/runtime_fft_impl.h&gt;tensorflow/compiler/xla/service/cpu/runtime_fft_impl.h&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='nuchi' date='2018-04-18T22:30:18Z'>
		Update: I went ahead and fixed it. If it's ok, I'll open a PR (after I run the unit tests). It still allocates a buffer on the fly, so the memory profiling tools won't catch it, but it'll do it with an Eigen::Tensor instead of a tf::Tensor so it won't need to link in core:framework. I also added a proper option for single-threaded FFT (status quo assigns the multi-threaded version even when single-threaded is requested).
		</comment>
		<comment id='2' author='nuchi' date='2018-05-11T18:44:29Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='3' author='nuchi' date='2018-05-20T21:28:44Z'>
		Fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/18685&gt;#18685&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>