<bug id='20509' author='jdvylder' open_date='2018-07-03T10:06:08Z' closed_time='2018-07-17T09:15:15Z'>
	<summary>Cannot use tf.metrics with MirroredStrategy</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): using nvidia containter: https://docs.nvidia.com/deeplearning/dgx/tensorflow-release-notes/rel_18.06.html#rel_18.06
TensorFlow version (use command below):1.8.0
Python version: 3.5
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 9.0.176
GPU model and memory: nvidia tesla v100
Exact command to reproduce: N/A

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I'm training a network using a custom tf.estimator. To monitor its training i used several metrics from tf. metrics: accuracy, auc, true positives, ... When running this on a single GPU, This works as expected, however when using tf.contrib.distribute.MirroredStrategy i get an exception. Apparently all metrics suffer from the same bug (tested by iteratively leaving the metric out).
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

I tried to extract the relevant part from my code:
&lt;denchmark-code&gt;def configure_trainer(self):
        if self.configuration.get("multi_gpu"):
            distribute = tf.contrib.distribute.MirroredStrategy(num_gpus=2)
        else:
            distribute = None

        run_config = tf.estimator.RunConfig(model_dir=out_dir, tf_random_seed=self.configuration.get("random_seed"),
                                                save_summary_steps=400,
                                                save_checkpoints_steps=1000,
                                                log_step_count_stepss400,
                                                train_distribute=distribute)

        self.trainer = tf.estimator.Estimator(
            model_fn=self.get_model_fn,  
            config=run_config
        )

def get_model_fn(self, mode, features, labels, params):
        self.configure_network(input_tensor=features, output_tensor=labels, mode=mode)
        eval_metrics = self.get_accuracy(self.network.get_output_tensor(),labels)
        return tf.estimator.EstimatorSpec(mode=mode, predictions=self.predictions,
                                              loss=self.loss, train_op=self.trainer_conf.get_train_op_fn(self.loss,mode),
                                              eval_metric_ops=eval_metrics
                                              )
...
def get_accuracy(self, output_tensor,  ground_truth, name=""):
        metric_name = 'Accuracy_' + name
        accuracy = tf.metrics.accuracy(
                labels=ground_truth,
                predictions=tf.argmax(output_tensor, axis=-1),
                name=metric_name)
        tf.summary.scalar(metric_name , accuracy[1])
        return {
            metric_name : accuracy
        }
&lt;/denchmark-code&gt;

This results in the following error trace:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "train.py", line 27, in &lt;module&gt;
    experimenter.run_training_experiment(config)
  File "/media/local/BDA_tf_framework/neuralnetwork/trainingexperimenter.py", line 39, in run_training_experiment
    tf.estimator.train_and_evaluate(self.trainer, self.training_specs, self.eval_specs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py", line 439, in train_and_evaluate
    executor.run()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py", line 518, in run
    self.run_local()
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/training.py", line 650, in run_local
    hooks=train_hooks)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 841, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 977, in _train_model_distributed
    saving_listeners)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5060, in get_controller
    yield default
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 977, in _train_model_distributed
    saving_listeners)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py", line 304, in __exit__
    self._var_creator_scope.__exit__(exception_type, exception_value, traceback)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2283, in variable_creator_scope
    yield
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 2939, in _variable_creator_scope
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2283, in variable_creator_scope
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 884, in _train_model_distributed
    self.config)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/distribute.py", line 756, in call_for_each_tower
    return self._call_for_each_tower(fn, *args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 254, in _call_for_each_tower
    coord.join(threads)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File "/usr/local/lib/python3.5/dist-packages/six.py", line 693, in reraise
    raise value
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/coordinator.py", line 297, in stop_on_exception
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py", line 295, in _mode
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py", line 514, in device_policy
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5060, in get_controller
    yield default
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 4338, in device
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5991, in __exit__
    self._name_scope.__exit__(type_arg, value_arg, traceback_arg)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 4115, in name_scope
    yield "" if new_stack is None else new_stack + "/"
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2097, in __exit__
    self._graph_context_manager.__exit__(type_arg, value_arg, traceback_arg)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5060, in get_controller
    yield default
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5265, in get_controller
    yield g
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 466, in run
    self.done = True
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2283, in variable_creator_scope
    yield
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 2939, in _variable_creator_scope
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2283, in variable_creator_scope
    yield
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 465, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py", line 831, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/media/local/BDA_tf_framework/neuralnetwork/trainingexperimenter.py", line 116, in get_model_fn
    eval_metrics = self.logger.get_eval_metrics(self.predictions, labels)
  File "/media/local/myfiles/Mytraininglogger.py", line 26, in get_eval_metrics
    metrics.update(self.get_accuracy(output_tensor, ground_truth, name=name))
  File "/media/local/BDA_tf_framework/neuralnetwork/traininglogger.py", line 60, in get_accuracy
    name=metric_name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py", line 409, in accuracy
    name or 'accuracy')
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py", line 345, in mean
    return mean_t, update_op
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py", line 2095, in __exit__
    self._current_name_scope.__exit__(type_arg, value_arg, traceback_arg)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5991, in __exit__
    self._name_scope.__exit__(type_arg, value_arg, traceback_arg)
  File "/usr/lib/python3.5/contextlib.py", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 4115, in name_scope
    yield "" if new_stack is None else new_stack + "/"
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/metrics_impl.py", line 332, in mean
    update_total_op = state_ops.assign_add(total, math_ops.reduce_sum(values))
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py", line 251, in assign_add
    return ref.assign_add(value)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py", line 311, in assign_add
    return self.get(device=_get_update_device()).assign_add(*args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distribute/python/values.py", line 283, in _get_update_device
    "Use DistributionStrategy.update() to modify a MirroredVariable.")
RuntimeError: Use DistributionStrategy.update() to modify a MirroredVariable.
Exception ignored in: &lt;generator object get_controller at 0x7f2dec1a2fc0&gt;
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5267, in get_controller
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py", line 136, in pop
IndexError: pop from empty list
Exception ignored in: &lt;generator object get_controller at 0x7f2dec1f0830&gt;
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5267, in get_controller
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py", line 136, in pop
IndexError: pop from empty list
Exception ignored in: &lt;generator object get_controller at 0x7f2dec17d9e8&gt;
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 5267, in get_controller
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/context.py", line 136, in pop
IndexError: pop from empty list
Makefile:19: recipe for target 'train_gpu' failed
make: *** [train_gpu] Error 1
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jdvylder' date='2018-07-09T21:20:12Z'>
		&lt;denchmark-link:https://github.com/jdvylder&gt;@jdvylder&lt;/denchmark-link&gt;
 - Metrics support in distribution strategies was added about a month ago and was not part of the tensorflow 1.8 release. It should be part of the nightly build though. Would it possible for you to try your code with tensorflow nightly build? (&lt;denchmark-link:https://pypi.org/project/tf-nightly-gpu/&gt;https://pypi.org/project/tf-nightly-gpu/&lt;/denchmark-link&gt;
)
		</comment>
		<comment id='2' author='jdvylder' date='2018-07-17T09:15:14Z'>
		Hi &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;

Thanks for the reply. I've tried the nightly build and the training does seem to get past the point where it originally threw the exception. Since I've run into a new &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/20874&gt;bug&lt;/denchmark-link&gt;
, I can't test if the metrics work, but will close this issue since the initial exception seems to be solved.
Thanks
Jonas
		</comment>
		<comment id='3' author='jdvylder' date='2018-07-17T14:18:09Z'>
		This is still an issue. Can this be reopened?
&lt;denchmark-code&gt;tensorflow/python/ops/metrics_impl.py in mean(values, weights, metrics_collections, updates_collections, name)
    374       return mean_t
    375 
--&gt; 376     mean_t = distribute_lib.get_tower_context().merge_call(
    377         aggregate_across_towers, total, count)
    378     update_op = _safe_div(update_total_op, update_count_op, 'update_op')

AttributeError: 'NoneType' object has no attribute 'merge_call'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='jdvylder' date='2018-07-20T00:53:04Z'>
		&lt;denchmark-link:https://github.com/carlthome&gt;@carlthome&lt;/denchmark-link&gt;
 - it seems like your might be seeing this error if you're trying to update metrics in cross tower mode. Typically, we would expect metrics to be computed in tower mode, as that's where your labels and logits etc are available. Could you provide a complete stack trace + your code that triggers this so we can debug further?
		</comment>
		<comment id='5' author='jdvylder' date='2018-07-20T07:50:36Z'>
		This seems to reproduce the error consistently:
import tensorflow as tf


def input_fn():
    dataset = (
        tf.data.Dataset
        .range(100)
        .map(lambda x: tf.random_normal([100]))
        .batch(32)
        .map(lambda x: ({'input': x}, {'output': x}))
        .repeat()
    )
    return dataset


def model_fn(features, labels, mode, params):

    units = features['input'].shape[-1]
    predictions = tf.layers.dense(features['input'], units)
    labels = labels['output']

    loss = tf.losses.mean_squared_error(labels, predictions)
    tf.losses.add_loss(loss)
    loss = tf.losses.get_total_loss()

    if mode == tf.estimator.ModeKeys.EVAL:
        metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}

        return tf.estimator.EstimatorSpec(
            mode,
            loss=loss,
            eval_metric_ops=metrics,
        )

    if mode == tf.estimator.ModeKeys.TRAIN:
        step = tf.train.get_or_create_global_step()
        optimizer = tf.train.AdamOptimizer()
        train_op = optimizer.minimize(loss, step)

        return tf.estimator.EstimatorSpec(
            mode,
            loss=loss,
            train_op=train_op,
        )


estimator = tf.estimator.Estimator(
    model_fn,
    config=tf.estimator.RunConfig(
        save_checkpoints_steps=100,
        train_distribute=tf.contrib.distribute.MirroredStrategy()),
)

tf.estimator.train_and_evaluate(
    estimator,
    train_spec=tf.estimator.TrainSpec(input_fn),
    eval_spec=tf.estimator.EvalSpec(input_fn),
)
Am I doing something wrong? All GPUs are utilized during training but this stack trace pops up upon evaluation:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-2-b27091873f02&gt; in &lt;module&gt;()
     56     estimator,
     57     train_spec=tf.estimator.TrainSpec(input_fn),
---&gt; 58     eval_spec=tf.estimator.EvalSpec(input_fn),
     59 )

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    449         '(with task id 0).  Given task id {}'.format(config.task_id))
    450 
--&gt; 451   return executor.run()
    452 
    453 

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run(self)
    588         config.task_type != run_config_lib.TaskType.EVALUATOR):
    589       logging.info('Running training and evaluation locally (non-distributed).')
--&gt; 590       return self.run_local()
    591 
    592     # Distributed case.

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in run_local(self)
    689         max_steps=self._train_spec.max_steps,
    690         hooks=train_hooks,
--&gt; 691         saving_listeners=saving_listeners)
    692 
    693     eval_result = listener_for_eval.eval_result or _EvalResult(

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    374 
    375       saving_listeners = _check_listeners_type(saving_listeners)
--&gt; 376       loss = self._train_model(input_fn, hooks, saving_listeners)
    377       logging.info('Loss for final step: %s.', loss)
    378       return self

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1141   def _train_model(self, input_fn, hooks, saving_listeners):
   1142     if self._distribution:
-&gt; 1143       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1144     else:
   1145       return self._train_model_default(input_fn, hooks, saving_listeners)

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_distributed(self, input_fn, hooks, saving_listeners)
   1366         return self._train_with_estimator_spec(estimator_spec, worker_hooks,
   1367                                                hooks, global_step_tensor,
-&gt; 1368                                                saving_listeners)
   1369 
   1370   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)
   1449       loss = None
   1450       while not mon_sess.should_stop():
-&gt; 1451         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
   1452     return loss
   1453 

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
    581                           feed_dict=feed_dict,
    582                           options=options,
--&gt; 583                           run_metadata=run_metadata)
    584 
    585   def run_step_fn(self, step_fn):

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1057                               feed_dict=feed_dict,
   1058                               options=options,
-&gt; 1059                               run_metadata=run_metadata)
   1060       except _PREEMPTION_ERRORS as e:
   1061         logging.info('An error was raised. This may be due to a preemption in '

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)
   1148         raise six.reraise(*original_exc_info)
   1149       else:
-&gt; 1150         raise six.reraise(*original_exc_info)
   1151 
   1152 

~/.miniconda3/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--&gt; 693             raise value
    694         finally:
    695             value = None

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, *args, **kwargs)
   1133   def run(self, *args, **kwargs):
   1134     try:
-&gt; 1135       return self._sess.run(*args, **kwargs)
   1136     except _PREEMPTION_ERRORS:
   1137       raise

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1213               results=outputs[hook] if hook in outputs else None,
   1214               options=options,
-&gt; 1215               run_metadata=run_metadata))
   1216     self._should_stop = self._should_stop or run_context.stop_requested
   1217 

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)
    462       if self._timer.should_trigger_for_step(global_step):
    463         self._timer.update_last_triggered_step(global_step)
--&gt; 464         if self._save(run_context.session, global_step):
    465           run_context.request_stop()
    466 

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py in _save(self, session, step)
    487     should_stop = False
    488     for l in self._listeners:
--&gt; 489       if l.after_save(session, step):
    490         logging.info(
    491             "A CheckpointSaverListener requested that training be stopped. "

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in after_save(***failed resolving arguments***)
    495       return True
    496     if self._timer.should_trigger_for_step(global_step_value):
--&gt; 497       self._evaluate(global_step_value)  # updates self.eval_result
    498       if not self._continuous_eval_listener.after_eval(self.eval_result):
    499         logging.info('Exiting evaluation, as requested by '

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in _evaluate(self, global_step_value)
    515     self._timer.update_last_triggered_step(global_step_value)
    516     self.eval_result, self.export_results = (
--&gt; 517         self._evaluator.evaluate_and_export())
    518     if self.eval_result.status != _EvalStatus.EVALUATED:
    519       #  This is unexpected; should never happen.

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py in evaluate_and_export(self)
    882           name=self._eval_spec.name,
    883           checkpoint_path=latest_ckpt_path,
--&gt; 884           hooks=self._eval_spec.hooks)
    885 
    886       # _EvalResult validates the metrics.

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in evaluate(self, input_fn, steps, hooks, checkpoint_path, name)
    461         (scaffold, update_op,
    462          eval_dict, all_hooks) = self._evaluate_build_graph(
--&gt; 463              input_fn, hooks, checkpoint_path)
    464         return self._evaluate_run(
    465             checkpoint_path=checkpoint_path,

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _evaluate_build_graph(self, input_fn, hooks, checkpoint_path)
   1461                                                     model_fn_lib.ModeKeys.EVAL))
   1462     estimator_spec = self._call_model_fn(
-&gt; 1463         features, labels, model_fn_lib.ModeKeys.EVAL, self.config)
   1464 
   1465     # Call to warm_start has to be after model_fn is called.

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1131 
   1132     logging.info('Calling model_fn.')
-&gt; 1133     model_fn_results = self._model_fn(features=features, **kwargs)
   1134     logging.info('Done calling model_fn.')
   1135 

&lt;ipython-input-2-b27091873f02&gt; in model_fn(features, labels, mode, params)
     26 
     27     if mode == tf.estimator.ModeKeys.EVAL:
---&gt; 28         metrics = {'mse': tf.metrics.mean_squared_error(labels, predictions)}
     29 
     30         return tf.estimator.EstimatorSpec(

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean_squared_error(labels, predictions, weights, metrics_collections, updates_collections, name)
   1297   squared_error = math_ops.square(labels - predictions)
   1298   return mean(squared_error, weights, metrics_collections, updates_collections,
-&gt; 1299               name or 'mean_squared_error')
   1300 
   1301 

~/.miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py in mean(values, weights, metrics_collections, updates_collections, name)
    374       return mean_t
    375 
--&gt; 376     mean_t = distribute_lib.get_tower_context().merge_call(
    377         aggregate_across_towers, total, count)
    378     update_op = _safe_div(update_total_op, update_count_op, 'update_op')

AttributeError: 'NoneType' object has no attribute 'merge_call'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='jdvylder' date='2018-07-24T03:52:39Z'>
		&lt;denchmark-link:https://github.com/carlthome&gt;@carlthome&lt;/denchmark-link&gt;
 thanks for the code and stack trace. I think what's happening is that as part of , evaluate gets called in a hook (_NewCheckpointListenerForEvaluate) as part of the training call. This means that the distribution strategy scope that we open in estimator.train (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L1194&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L1194&lt;/denchmark-link&gt;
)  is still open when we execute this hook.
Due to this, the metrics that you create in evaluate are created inside the scope in a cross tower context - and this leads to the error above.
This setup to use _NewCheckpointListenerForEvaluate is new and hence you're probably one of the first people to run into this.
I see 2 options to move forward:

Can you use Estimator.train and Estimator.evaluate directly instead of train_and_evaluate? We've definitely tested those to work as expected in presence of MirroredStrategy (even though evaluate itself is not distributed). The main benefit of using train_and_evaluate (from my understanding) is to run on multiple machines with Parameter Server distribution. Since you are not looking for that, directly using train and evaluate might be better and get around this error.
As I mentioned above, Estimator.evaluate itself in general is not yet distributed under MirroredStrategy so currently it would just run on the first GPU (but should not throw errors). This support is actually in progress right now and should be available in 1-2 weeks. I suspect this might address the issue while using train_and_evaluate as well but I haven't tested that (will do).

Hope this helps!
		</comment>
		<comment id='7' author='jdvylder' date='2018-07-26T10:04:20Z'>
		Thanks for the clarification &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
!
I'm using  because I'd like to do &lt;denchmark-link:https://en.wikipedia.org/wiki/Early_stopping&gt;early stopping&lt;/denchmark-link&gt;
 (checking loss on a validation set every now and then during training, and stopping the training loop when the model stops improving on the validation data). I'm currently doing this with . This also crashes with the same stack trace:
eval_hook = tf.contrib.estimator.InMemoryEvaluatorHook(estimator, validation_input_fn)
estimator.train(training_input_fn, hooks=[early_stopping, eval_hook])
metrics = estimator.evaluate(test_input_fn)
I guess this is a workaround at the moment for local training:
best = float('inf')
for epoch in range(100):
    estimator.train(training_input_fn)
    metrics = estimator.evaluate(validation_input_fn)
    if metrics['loss'] &lt; best:
        best = metrics['loss']
    else:
        tf.logging.info(f'Early stopping after {epoch} epochs.')
        break
but it would be nice to have asynchronous training and validation loops via some high-level construct like train_and_evaluate eventually! The dream would be to write high-level TensorFlow code once, and have that working in any hardware configuration (multi-machine, single-machine, multi-GPU, CPU-only, etc.).
		</comment>
		<comment id='8' author='jdvylder' date='2018-07-27T02:13:10Z'>
		&lt;denchmark-link:https://github.com/carlthome&gt;@carlthome&lt;/denchmark-link&gt;
 absolutely, i am looking into fixing this issue, and also implementing distributed eval directly, both of which should address your issue. Your workaround in the meantime looks right.
		</comment>
		<comment id='9' author='jdvylder' date='2018-07-27T05:49:52Z'>
		Also, please feel free to open a new issue for this with your code and stack trace. Thanks!
		</comment>
		<comment id='10' author='jdvylder' date='2018-07-27T07:57:50Z'>
		&lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 done! &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/21180&gt;#21180&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>