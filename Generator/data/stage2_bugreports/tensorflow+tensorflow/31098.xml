<bug id='31098' author='eriklu' open_date='2019-07-27T13:11:01Z' closed_time='2019-08-29T08:48:32Z'>
	<summary>conda install tensorflow-mkl version raise error: could not create a dilated convolution forward descriptor</summary>
	<description>
keras vesion: 2.2.4, tenssoflow version: 1.13.1
CPU: i3-330
exception stack:
Epoch 1/5
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

AbortedError                              Traceback (most recent call last)
 in 
13                               validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),
14                               steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),
---&gt; 15                               callbacks=[checkpoint, early, tb, csv_logger])
D:\soft\Anaconda3\lib\site-packages\keras\legacy\interfaces.py in wrapper(*args, **kwargs)
89                 warnings.warn('Update your ' + object_name + ' call to the ' +
90                               'Keras 2 API: ' + signature, stacklevel=2)
---&gt; 91             return func(*args, **kwargs)
92         wrapper._original_function = func
93         return wrapper
D:\soft\Anaconda3\lib\site-packages\keras\engine\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
1416             use_multiprocessing=use_multiprocessing,
1417             shuffle=shuffle,
-&gt; 1418             initial_epoch=initial_epoch)
1419
1420     @interfaces.legacy_generator_methods_support
D:\soft\Anaconda3\lib\site-packages\keras\engine\training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
215                 outs = model.train_on_batch(x, y,
216                                             sample_weight=sample_weight,
--&gt; 217                                             class_weight=class_weight)
218
219                 outs = to_list(outs)
D:\soft\Anaconda3\lib\site-packages\keras\engine\training.py in train_on_batch(self, x, y, sample_weight, class_weight)
1215             ins = x + y + sample_weights
1216         self._make_train_function()
-&gt; 1217         outputs = self.train_function(ins)
1218         return unpack_singleton(outputs)
1219
D:\soft\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py in call(self, inputs)
2713                 return self._legacy_call(inputs)
2714
-&gt; 2715             return self._call(inputs)
2716         else:
2717             if py_any(is_tensor(x) for x in inputs):
D:\soft\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py in _call(self, inputs)
2673             fetched = self._callable_fn(*array_vals, run_metadata=self.run_metadata)
2674         else:
-&gt; 2675             fetched = self._callable_fn(*array_vals)
2676         return fetched[:len(self.outputs)]
2677
D:\soft\Anaconda3\lib\site-packages\tensorflow\python\client\session.py in call(self, *args, **kwargs)
1437           ret = tf_session.TF_SessionRunCallable(
1438               self._session._session, self._handle, args, status,
-&gt; 1439               run_metadata_ptr)
1440         if run_metadata:
1441           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)
D:\soft\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py in exit(self, type_arg, value_arg, traceback_arg)
526             None, None,
527             compat.as_text(c_api.TF_Message(self.status.status)),
--&gt; 528             c_api.TF_GetCode(self.status.status))
529     # Delete the underlying status object from memory otherwise it stays alive
530     # as there is a reference to status from this from the traceback due to
AbortedError: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor, in file tensorflow/core/kernels/mkl_conv_ops.cc:1111
[[{{node conv1_1/convolution}}]]
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

the code work well with version without MKL.
	</description>
	<comments>
		<comment id='1' author='eriklu' date='2019-07-30T13:27:42Z'>
		&lt;denchmark-link:https://github.com/eriklu&gt;@eriklu&lt;/denchmark-link&gt;
 ,
Provide the exact sequence of commands / steps that you executed before running into the problem.Thanks!
		</comment>
		<comment id='2' author='eriklu' date='2019-07-30T18:19:43Z'>
		&lt;denchmark-link:https://github.com/eriklu&gt;@eriklu&lt;/denchmark-link&gt;
 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='3' author='eriklu' date='2019-07-31T08:48:46Z'>
		from keras.preprocessing.image import ImageDataGenerator
from keras.applications.mobilenet import preprocess_input, decode_predictions

WIDTH=224
HEIGHT=224
BATCH_SIZE=64
test_dir = '../Dataset/test/'
train_dir = '../Dataset/train/'
val_dir = '../Dataset/val/'

#Train DataSet Generator with Augmentation
print("\nTraining Data Set")
train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)
train_flow = train_generator.flow_from_directory(
    train_dir,
    target_size=(HEIGHT, WIDTH),
    batch_size = BATCH_SIZE
)

#Validation DataSet Generator with Augmentation
print("\nValidation Data Set")
val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)
val_flow = val_generator.flow_from_directory(
    val_dir,
    target_size=(HEIGHT, WIDTH),
    batch_size = BATCH_SIZE
)

#Test DataSet Generator with Augmentation
print("\nTest Data Set")
test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)
test_flow = test_generator.flow_from_directory(
    test_dir,
    target_size=(HEIGHT, WIDTH),
    batch_size = BATCH_SIZE
)




from keras.models import Sequential, Model, load_model
from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger
from keras import optimizers, models
from keras.layers import Dense, Dropout, GlobalAveragePooling2D
from keras import applications
from keras import backend as K
import tensorflow as tf
import os

NUM_PARALLEL_EXEC_UNITS = 0


#Set Performance Parameters for MKL and Tensorflow using Keras backend
#TensorFlow
config = tf.ConfigProto(
    intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,
    inter_op_parallelism_threads=1
)

session = tf.Session(config=config)
K.set_session(session)

#MKL and OpenMP
os.environ["OMP_NUM_THREADS"] = str(NUM_PARALLEL_EXEC_UNITS)
os.environ["KMP_BLOCKTIME"] = "1"
os.environ["KMP_SETTINGS"] = "1"
os.environ["KMP_AFFINITY"]= "granularity=fine,verbose,compact,1,0"



# Initialize mobilenet with transfer learning
base_model = applications.MobileNet(weights='imagenet', 
                                include_top=False, 
                                input_shape=(WIDTH, HEIGHT,3))

# add a global spatial average pooling layer
x = base_model.output

x = GlobalAveragePooling2D()(x)
# and a dense layer
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_flow.class_indices), activation='softmax')(x)

# this is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)

# first: train only the top layers (which were randomly initialized)
# i.e. freeze all convolutional InceptionV3 layers
for layer in base_model.layers:
    layer.trainable = False

# compile the model (should be done *after* setting layers to non-trainable)
model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')
model.summary()



import math
top_layers_file_path="top_layers.mn.hdf5"

checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')
tb = TensorBoard(log_dir='./logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')
early = EarlyStopping(monitor="loss", mode="min", patience=5)
csv_logger = CSVLogger('./logs/mn-log.csv', append=True)

history = model.fit_generator(train_flow, 
                              epochs=5, 
                              verbose=1,
                              validation_data=val_flow,
                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),
                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),
                              callbacks=[checkpoint, early, tb, csv_logger])
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

the exception throw at the last line fit_generator function.
the code come from Intel AIDC. It's a Demo. I can't offer test data here.
you can download the complete zip file from：
&lt;denchmark-link:https://pan.baidu.com/s/1XvLocaijuZ2RnVu_onzrwQ&gt;https://pan.baidu.com/s/1XvLocaijuZ2RnVu_onzrwQ&lt;/denchmark-link&gt;
  the code: 0jwj
You need run Part1-Exploratory_Data_Analysis.ipynb notebook to prepare training data before** you run the Optional-Training_MobileNet.ipynb notebook
I run the code on non-mkl version tensorflow v1.13, it works.  when I want to speed the training , I install the mkl version with "conda install tensorflow-mkl", I encounter the error.
I think maybe it occurs because of my poor CUP: i3-330M (the first i-serial CPU) or I need install some lib.
The CPU-Z shows: Instructions sets	MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, EM64T, VT-x
		</comment>
		<comment id='4' author='eriklu' date='2019-08-01T22:55:20Z'>
		Are you able to install TF with mkl flag and import tensorflow successfully?
The above given code snippet works for you in TF without mkl but fails with TF-MKL? Is my understanding correct here?
		</comment>
		<comment id='5' author='eriklu' date='2019-08-02T02:46:24Z'>
		Yes， it's right.
on normal TF :
I get below info:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;WARNING:tensorflow:From D:\soft\Anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/5
3/319 [..............................] - ETA: 38:33 - loss: 2.7897 - acc: 0.1042 - top_k_categorical_accuracy: 0.5417&lt;/denchmark-h&gt;

the triaining start and run slowly.
I read that mkl version is faster 10x, but I failed with the error.
I have encounter a error about Instructions set when use TF normal version, so I install from a .whl file
compiled with the  Instructions set supported by my poor CPU.
I think the conda and pip install the lib without care CPU。
		</comment>
		<comment id='6' author='eriklu' date='2019-08-10T04:39:38Z'>
		&lt;denchmark-link:https://github.com/eriklu&gt;@eriklu&lt;/denchmark-link&gt;
 Downgrade to TF 1.12.0 : 
		</comment>
		<comment id='7' author='eriklu' date='2019-08-20T00:42:53Z'>
		it works and the speed raise almost 20% than normal tf version， thanks u!
&lt;denchmark-code&gt;Epoch 1/5
 11/319 [&gt;.............................] - ETA: 21:14 - loss: 3.6482 - acc: 0.1477 - top_k_categorical_accuracy: 0.5739
&lt;/denchmark-code&gt;

can you explain the reason for me?
		</comment>
		<comment id='8' author='eriklu' date='2019-08-29T08:48:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31098&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31098&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='eriklu' date='2019-09-12T05:54:25Z'>
		Hi, since we have already upgraded TF. Could you please check the latest Intel distribution? Thank you.
		</comment>
		<comment id='10' author='eriklu' date='2019-09-18T05:19:15Z'>
		(py36) C:\Users\Erik&gt;conda update tensorflow-mkl
Collecting package metadata (repodata.json): done
Solving environment: done
..........
The following packages will be UPDATED:
ipython                              7.7.0-py36h39e3cac_0 --&gt; 7.8.0-py36h39e3cac_0
mkl-service                          2.0.2-py36he774522_0 --&gt; 2.3.0-py36hb782905_0
notebook                                     6.0.0-py36_0 --&gt; 6.0.1-py36_0
numpy                               1.16.4-py36h19fb1c0_0 --&gt; 1.16.5-py36h19fb1c0_0
numpy-base                          1.16.4-py36hc3f5095_0 --&gt; 1.16.5-py36hc3f5095_0
openssl                                 1.1.1c-he774522_1 --&gt; 1.1.1d-he774522_0
qtconsole                                      4.5.3-py_0 --&gt; 4.5.5-py_0
tensorboard                         1.12.2-py36h33f27b4_0 --&gt; 1.14.0-py36he3c9ec2_0
tensorflow                      1.12.0-mkl_py36h4f00353_0 --&gt; 1.14.0-mkl_py36hb88db5b_0
tensorflow-base                 1.12.0-mkl_py36h81393da_0 --&gt; 1.14.0-mkl_py36ha978198_0
tensorflow-mkl                          1.12.0-h4fcabd2_0 --&gt; 1.14.0-h4fcabd2_0
vs2015_runtime                     14.15.26706-h3a45250_4 --&gt; 14.16.27012-hf0eaf9b_0
Proceed ([y]/n)?
......
(py36) E:\test\jupyter&gt;conda list
&lt;denchmark-h:h1&gt;packages in environment at D:\soft\Anaconda3\envs\py36:&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;Name                    Version                   Build  Channel&lt;/denchmark-h&gt;

........
tensorboard               1.14.0           py36he3c9ec2_0
tensorflow                1.14.0          mkl_py36hb88db5b_0
tensorflow-base           1.14.0          mkl_py36ha978198_0
tensorflow-estimator      1.14.0                     py_0
tensorflow-mkl            1.14.0               h4fcabd2_0
termcolor                 1.1.0                    py36_1
terminado                 0.8.2                    py36_0
testpath                  0.4.2                    py36_0
tk                        8.6.8                hfa6e2cd_0
tornado                   6.0.3            py36he774522_0
traitlets                 4.3.2            py36h096827d_0
......
before update:    keras vesion: 2.2.4, tenssoflow version: 1.12.0
after    update:  keras vesion: 2.2.4, tenssoflow version: 1.14.0
the code works well.  but i feel the training speed slow down a little (two minute more from 21:14 to 23:46).
Epoch 1/5
11/319 [&gt;.............................] - ETA: 23:46 - loss: 3.5137 - acc: 0.1534 - top_k_categorical_accuracy: 0.6023
thanks your greate work,
		</comment>
	</comments>
</bug>