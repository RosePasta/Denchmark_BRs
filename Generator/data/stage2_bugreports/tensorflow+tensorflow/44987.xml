<bug id='44987' author='MaxiBoether' open_date='2020-11-18T18:00:58Z' closed_time='2020-12-08T02:14:03Z'>
	<summary>Necessity of "strategy.run" and "distribute_datasets_from_function" for ParameterServers</summary>
	<description>
Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.
The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs&gt;https://www.tensorflow.org/community/contribute/docs&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;

&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/coordinator/ClusterCoordinator&gt;https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/coordinator/ClusterCoordinator&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Clear description&lt;/denchmark-h&gt;




In the example code for create_per_worker_dataset, we use the following code snippet:
&lt;denchmark-code&gt;def per_worker_dataset_fn():
  return strategy.distribute_datasets_from_function(
      lambda x: tf.data.Dataset.from_tensor_slices([3] * 3))

per_worker_dataset = coordinator.create_per_worker_dataset(
    per_worker_dataset_fn)
&lt;/denchmark-code&gt;

Notice the usage of strategy.distribute_datasets_from_function.  In the example for fetch, we do it as follows
&lt;denchmark-code&gt;def dataset_fn():
  return tf.data.Dataset.from_tensor_slices([1, 1, 1])

distributed_dataset = coordinator.create_per_worker_dataset(dataset_fn)
&lt;/denchmark-code&gt;

So in the first example, we use our strategy, while in the second example, we directly plug the dataset into the coordinator. Both works for me when trying it out, but it's not documented what the difference is (or I could not find it).



Again, consider the example for fetch:
&lt;denchmark-code&gt;strategy = ...
coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(
    strategy)

def dataset_fn():
  return tf.data.Dataset.from_tensor_slices([1, 1, 1])

with strategy.scope():
  v = tf.Variable(initial_value=0)

@tf.function
def worker_fn(iterator):
  def replica_fn(x):
    v.assign_add(x)
    return v.read_value()
  return strategy.run(replica_fn, args=(next(iterator),))

distributed_dataset = coordinator.create_per_worker_dataset(dataset_fn)
distributed_iterator = iter(distributed_dataset)
result = coordinator.schedule(worker_fn, args=(distributed_iterator,))
assert coordinator.fetch(result) == 1
&lt;/denchmark-code&gt;

It's not clearly documented why we need the strategy.run indirection of replica_fn. For example, in the example code for create_per_worker_dataset, we do not use this indirection and instead just return the element. I've also tried the upper example without strategy.run and the addition worked fine. So I'm not sure why we need this. Would be great to add this to the documentation.
&lt;denchmark-h:h3&gt;Correct links&lt;/denchmark-h&gt;

Is the link to the source code correct? Yes
&lt;denchmark-h:h3&gt;Parameters defined&lt;/denchmark-h&gt;

Are all parameters defined and formatted correctly? Yes
&lt;denchmark-h:h3&gt;Returns defined&lt;/denchmark-h&gt;

Are return values defined? Yes
&lt;denchmark-h:h3&gt;Raises listed and defined&lt;/denchmark-h&gt;

Are the errors defined? For example,
&lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises&gt;https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Usage example&lt;/denchmark-h&gt;

Is there a usage example?
See the API guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_ref&gt;https://www.tensorflow.org/community/contribute/docs_ref&lt;/denchmark-link&gt;

on how to write testable usage examples.
&lt;denchmark-h:h3&gt;Request visuals, if applicable&lt;/denchmark-h&gt;

Are there currently visuals? If not, will it clarify the content?
&lt;denchmark-h:h3&gt;Submit a pull request?&lt;/denchmark-h&gt;

Are you planning to also submit a pull request to fix the issue? No
	</description>
	<comments>
		<comment id='1' author='MaxiBoether' date='2020-11-19T21:39:17Z'>
		Hi &lt;denchmark-link:https://github.com/MaxiBoether&gt;@MaxiBoether&lt;/denchmark-link&gt;
, we have a new Parameter Server Strategy tutorial that I think will answer your questions. I will link it here when it goes live. I believe it has already been submitted so that should be very soon.
		</comment>
		<comment id='2' author='MaxiBoether' date='2020-11-20T05:03:57Z'>
		Hi &lt;denchmark-link:https://github.com/nikitamaia&gt;@nikitamaia&lt;/denchmark-link&gt;
, where can we find the new Parameter Server Strategy tutorial? Would really appreciate it
		</comment>
		<comment id='3' author='MaxiBoether' date='2020-11-20T08:48:01Z'>
		Hi &lt;denchmark-link:https://github.com/nikitamaia&gt;@nikitamaia&lt;/denchmark-link&gt;
, I was already looking into the latest documentation on the master branch, so the new ParameterServerStrategyV2. I'm not 100% sure if the tutorial is already included in the nightly deployment of the documentation.
Although it would also make sense to be clear in the documentation/docstrings of the source code. Currently, this is not consistent as stated above. So I would be glad if you could explain these two issues, although the tutorial also is much appreciated. I think fixing these inconsistencies will also help me (and others reading the source code in order to maybe contribute) in the shorter term as the tutorial will probably take some more time.
		</comment>
		<comment id='4' author='MaxiBoether' date='2020-11-20T21:07:22Z'>
		The new tutorial is live now, you can see it here &lt;denchmark-link:https://www.tensorflow.org/tutorials/distribute/parameter_server_training&gt;https://www.tensorflow.org/tutorials/distribute/parameter_server_training&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/MaxiBoether&gt;@MaxiBoether&lt;/denchmark-link&gt;
 please take a look and let me know if the tutorial clears up the confusion. The tutorial addresses the use of , as well as . I will also take a look at the docstrings and see what can be added to bring some more clarity.
		</comment>
		<comment id='5' author='MaxiBoether' date='2020-11-25T10:32:53Z'>
		Thank you for uploading the new tutorial. This already cleared up some confusion - but also brought some new one.
I think what confused me and maybe also some others is the concept of data parallelism in parameter servers. In textbook descriptions (e.g. [1]) that parameter servers like ps-lite [2] rely on (that implement a push-pull key-value-store-like interface), the idea is that the dataset is split up between all workers. Now, if we take a look at the "More about dataset creation" section in the TensorFlow tutorial and at the code, we see that actually, dataset_fn is called for every worker (this is also confirmed by a small MWE that I implemented). Hence, every worker has access to the entire dataset, which - at least in my understanding - goes against the data parallelism paradigm. The data may be shuffled, but still the entire dataset needs to be transferred to every worker instead of splitting the dataset up between different workers (as an implementation detail, I wonder when the data is actually transferred to the workers).
Considering the tutorial about DistributedDatasets [3], which shows that the dataset should actually be split across the instances, I do not understand why this is the case. Could you maybe clarify that? I think that also confused me when trying the understand distribute_datasets_from_function. Thank you so much again for the kind support.
[1] &lt;denchmark-link:https://d2l.ai/chapter_computational-performance/parameterserver.html&gt;https://d2l.ai/chapter_computational-performance/parameterserver.html&lt;/denchmark-link&gt;

[2] &lt;denchmark-link:https://github.com/dmlc/ps-lite&gt;https://github.com/dmlc/ps-lite&lt;/denchmark-link&gt;

[3] &lt;denchmark-link:https://www.tensorflow.org/tutorials/distribute/input&gt;https://www.tensorflow.org/tutorials/distribute/input&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='MaxiBoether' date='2020-12-01T01:03:11Z'>
		You are correct that in the current implementation, the dataset_fn is called for each worker, and the data is shuffled. This choice was made keeping in mind the programming model of ParameterServerStrategy. In particular, it prioritizes fault tolerance (ie even if a single worker crashes, the others can proceed), so sharding the data makes less sense.
That all being said, I think we need to make some updates to the Distributed Input guide to indicate that that the autoshard policy currently does not apply to PSS. There are no plans at the moment to support dataset sharding with PSS, but that could certainly change if if becomes a popular feature request.
		</comment>
		<comment id='7' author='MaxiBoether' date='2020-12-08T02:14:03Z'>
		I've added a note to the data sharding section of the &lt;denchmark-link:https://www.tensorflow.org/tutorials/distribute/input#tfdistributestrategyexperimental_distribute_dataset&gt;Distributed Input guide&lt;/denchmark-link&gt;
 that the autoshard policy only applies to MultiWorkerMirroredStrategy and TPUStrategy, and not ParameterServerStrategy.
Closing this issue now since original question was addressed in the Parameter Server Strategy tutorial.
		</comment>
	</comments>
</bug>