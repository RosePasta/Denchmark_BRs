<bug id='7913' author='freepjf' open_date='2017-02-27T07:31:45Z' closed_time='2017-02-27T18:13:42Z'>
	<summary>can there any examples about multi GPU or multi machine training</summary>
	<description>
the news said 64 GPU can acheive 56 speed,how can we build for training test.
can there any examples?
	</description>
	<comments>
		<comment id='1' author='freepjf' date='2017-02-27T18:03:40Z'>
		cc &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='freepjf' date='2017-02-27T18:13:40Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7679&gt;#7679&lt;/denchmark-link&gt;
 Tracking progress on another issue.  We will have both in one script that allows you to try different options, e.g. data formats, ps placement and variable update options.  I would love to release it now as I know many people are really interested.  Closing this issue to keep tracking on the other one.
		</comment>
	</comments>
</bug>