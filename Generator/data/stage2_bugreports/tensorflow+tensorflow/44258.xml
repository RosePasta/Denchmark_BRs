<bug id='44258' author='MustafaAlahmid' open_date='2020-10-23T10:20:56Z' closed_time='2020-10-30T15:46:02Z'>
	<summary>tflite file size is 1KB ?</summary>
	<description>
System information

OS Platform and Distribution (windows 10):
TensorFlow installed from (source):
TensorFlow version (2.3):

im trying to convert my costum model ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8 to tflite so I can deploy it on android phone
First Iam generating tflite graph
&lt;denchmark-code&gt;python export_tflite_graph_tf2.py --pipeline_config_path=D:\models\TensorFlowColored89\workspace\training_demo\models\my_ssd_mobilenet_v2_fpnlite\pipeline.config --trained_checkpoint_dir=D:\models\TensorFlowColored89\workspace\training_demo\exported-models\my_mobilenet_model\checkpoint --output_directory=D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported
&lt;/denchmark-code&gt;

then this command for getting the model.tflite
&lt;denchmark-h:h1&gt;the exact command&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;tflite_convert --saved_model_dir=D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\saved_model --output_file=D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\TFL.tflite

&lt;/denchmark-code&gt;

&lt;denchmark-h:h1&gt;Copy and paste the output here.&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;
(tf) PS D:\models\TensorFlowColored89\models\research\object_detection&gt; tflite_convert --saved_model_dir=D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\saved_model --output_file=D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\TFL.tflite
2020-10-23 12:01:07.115542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-23 12:01:16.832442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-10-23 12:01:17.685510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-10-23 12:01:17.685853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-23 12:01:17.693815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-23 12:01:17.699545: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-23 12:01:17.702309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-23 12:01:17.708703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-23 12:01:17.713493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-23 12:01:17.724389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-23 12:01:17.724807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-23 12:01:17.725887: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-23 12:01:17.736662: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15884ebf8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-23 12:01:17.736911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-23 12:01:17.737896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-10-23 12:01:17.738470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-23 12:01:17.739031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-23 12:01:17.739685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-23 12:01:17.740310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-23 12:01:17.740747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-23 12:01:17.741304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-23 12:01:17.741781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-23 12:01:17.742327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-23 12:01:18.332670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-23 12:01:18.332908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-23 12:01:18.333608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-23 12:01:18.334330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2989 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-10-23 12:01:18.338688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x158b91aab40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-23 12:01:18.338823: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050, Compute Capability 6.1
I1023 12:02:20.237044 33924 lite.py:624] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False
2020-10-23 12:02:23.839000: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-10-23 12:02:23.839271: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
2020-10-23 12:02:23.841449: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\saved_model
2020-10-23 12:02:23.929815: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2020-10-23 12:02:23.930050: I tensorflow/cc/saved_model/loader.cc:250] Reading SavedModel debug info (if present) from: D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\saved_model
2020-10-23 12:02:23.931573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-23 12:02:23.931855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]
2020-10-23 12:02:24.264018: I tensorflow/cc/saved_model/loader.cc:215] Restoring SavedModel bundle.
2020-10-23 12:02:24.910611: I tensorflow/cc/saved_model/loader.cc:199] Running initialization op on SavedModel bundle at path: D:\models\TensorFlowColored89\workspace\training_demo\tflite_exported\saved_model
2020-10-23 12:02:25.185379: I tensorflow/cc/saved_model/loader.cc:319] SavedModel load for tags { serve }; Status: success: OK. Took 1343952 microseconds.
2020-10-23 12:02:27.159515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1
coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.43GiB/s
2020-10-23 12:02:27.160041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-23 12:02:27.161714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-23 12:02:27.162453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-23 12:02:27.163015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-23 12:02:27.163827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-23 12:02:27.164425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-23 12:02:27.164992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-23 12:02:27.165708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-23 12:02:27.166372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-23 12:02:27.166798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-23 12:02:27.167201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-23 12:02:27.167793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2989 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
(tf) PS D:\models\TensorFlowColored89\models\research\object_detection&gt;
&lt;/denchmark-code&gt;

the tfl.tflite file size is 1Kb
Also, please include a link to the saved model or GraphDef
open the file with sublime  and it contains this ;
1c00 0000 5446 4c33 0000 1200 1c00 0400
0800 0c00 1000 1400 0000 1800 1200 0000
0300 0000 1400 0000 1400 0000 8000 0000
1800 0000 2800 0000 0000 0000 0200 0000
c000 0000 7c00 0000 0400 0000 b401 0000
b001 0000 0001 0000 3800 0000 0100 0000
0c00 0000 0800 0c00 0400 0800 0800 0000
0800 0000 0300 0000 1300 0000 6d69 6e5f
7275 6e74 696d 655f 7665 7273 696f 6e00
42ff ffff 0400 0000 1000 0000 0000 0000
0000 0000 0000 0000 0000 0000 0f00 0000
4d4c 4952 2043 6f6e 7665 7274 6564 2e00
ceff ffff 1400 0000 1400 0000 1400 0000
1400 0000 1400 0000 0000 0000 0000 0000
0000 0000 0000 0000 0400 0000 4e6f 4f70
0000 0e00 1800 0400 0800 0c00 1000 1400
0e00 0000 1400 0000 1c00 0000 2000 0000
3000 0000 3000 0000 0200 0000 9800 0000
4400 0000 0100 0000 0000 0000 0400 0000
0100 0000 0100 0000 0100 0000 0100 0000
0000 0000 0400 0000 6d61 696e 0000 0600
0800 0400 0600 0000 0400 0000 0400 0000
0000 0000 beff ffff 1000 0000 0200 0000
0c00 0000 2c00 0000 0000 0000 1900 0000
5374 6174 6566 756c 5061 7274 6974 696f
6e65 6443 616c 6c3a 3300 0000 0400 0600
0400 0000 0000 0e00 1400 0400 0000 0800
0c00 1000 0e00 0000 1000 0000 0100 0000
1c00 0000 3400 0000 0400 0000 0100 0000
4001 0000 4001 0000 0300 0000 1700 0000
7365 7276 696e 675f 6465 6661 756c 745f
696e 7075 743a 3000 fcff ffff 0400 0400
0400 0000
&lt;denchmark-code&gt;# Put link here or attach to the issue.
&lt;/denchmark-code&gt;

Failure details
If the conversion is successful, but the generated model is wrong,
state what is wrong:

Producing wrong results and/or decrease in accuracy
Producing correct results, but the model is slower than expected (model generated from old converter)

Any other info / logs
I think its failing to convert to tflite
	</description>
	<comments>
		<comment id='1' author='MustafaAlahmid' date='2020-10-27T16:57:05Z'>
		&lt;denchmark-link:https://github.com/MustafaAlahmid&gt;@MustafaAlahmid&lt;/denchmark-link&gt;

Please share complete stand alone code for the issue faced or if possible share a colab gist with the issue reported.
		</comment>
		<comment id='2' author='MustafaAlahmid' date='2020-10-28T18:48:00Z'>
		What is the issue here?
		</comment>
		<comment id='3' author='MustafaAlahmid' date='2020-10-29T08:18:22Z'>
		issue solved, the converting didn't work with TF2.3.1, i had to use Nightly version for this
		</comment>
		<comment id='4' author='MustafaAlahmid' date='2020-10-29T18:48:35Z'>
		&lt;denchmark-link:https://github.com/MustafaAlahmid&gt;@MustafaAlahmid&lt;/denchmark-link&gt;

Please move this to closed status as issue is resolved.
		</comment>
		<comment id='5' author='MustafaAlahmid' date='2020-11-30T03:46:41Z'>
		I am having the same issue with TF 2.3.1.  How do I use nightly for this?  Or is it same scripts and everything, just in an env with the latest tf.nightly?
		</comment>
		<comment id='6' author='MustafaAlahmid' date='2020-11-30T05:16:17Z'>
		Actually, I solved it, just created a new conda env as tfnightly and installed package and all dependencies.  Ran the same python script below and it works:
&lt;denchmark-code&gt;import tensorflow as tf
import argparse

# Convert the model
# normal input is 1x string path of model directory
# normal output is 1x file tf.lite at model directory path

def ConvertModel(saved_model_dir, output):
    print(f'TF version is: {tf.__version__}')
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    tflite_model = converter.convert()
    open(output, "wb").write(tflite_model)




if __name__ == "__main__":  #upon python script execution in cmd prompt, __name__ variable is issued and becomes __main__ variable
    parser = argparse.ArgumentParser(description='Convert to tf.lite')
    parser.add_argument('-m', '--model_dir', type=str,  metavar='', help='directory location of the tf_light_frozen_graph')
    parser.add_argument('-o', '--output', type=str, metavar='', help='output path and file name of model')
    args = parser.parse_args()

    ConvertModel(args.model_dir, args.output)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='MustafaAlahmid' date='2020-12-16T16:33:33Z'>
		
Actually, I solved it, just created a new conda env as tfnightly and installed package and all dependencies. Ran the same python script below and it works:
import tensorflow as tf
import argparse

# Convert the model
# normal input is 1x string path of model directory
# normal output is 1x file tf.lite at model directory path

def ConvertModel(saved_model_dir, output):
    print(f'TF version is: {tf.__version__}')
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    tflite_model = converter.convert()
    open(output, "wb").write(tflite_model)




if __name__ == "__main__":  #upon python script execution in cmd prompt, __name__ variable is issued and becomes __main__ variable
    parser = argparse.ArgumentParser(description='Convert to tf.lite')
    parser.add_argument('-m', '--model_dir', type=str,  metavar='', help='directory location of the tf_light_frozen_graph')
    parser.add_argument('-o', '--output', type=str, metavar='', help='output path and file name of model')
    args = parser.parse_args()

    ConvertModel(args.model_dir, args.output)


Sorry, late replay,
yes exactly you make 2 environments, one of them with TF nightly just to convert tf to tflite
		</comment>
	</comments>
</bug>