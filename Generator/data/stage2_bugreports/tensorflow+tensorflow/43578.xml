<bug id='43578' author='ianlokh' open_date='2020-09-26T01:27:48Z' closed_time='2020-12-03T07:29:30Z'>
	<summary>Compiled TF2.3 with MKL on OSX does not progress beyond first epoch</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.3.0
Python version: 3.8.5
Bazel version (if compiling from source): 3.1.0
GCC/Compiler version (if compiling from source): clang 10.0.1
CUDA/cuDNN version: No
GPU model and memory: No

Describe the current behavior
When executing code:

vae.fit(minst_digits, epochs = 30, batch_size = 128)
it does not progress beyond the epoch 1 and seems to hang even after waiting several hours to see if the training progresses beyond epoch 1. I notice that the CPU load is showing 2 threads executing at 100%

Describe the expected behavior
Needs to be able to progress beyond 1st epoch and start training.

Please find the code to run the test here &lt;denchmark-link:https://drive.google.com/file/d/14ntp7WeSGVHOy_Fx_5PS1nIneRS1DjOB/view?usp=sharing&gt;vae 0.1.py&lt;/denchmark-link&gt;

Other info / logs
Basel build info:
bazel build --action_env CC=/usr/local/opt/llvm/bin/clang  --config=noaws --config=nogcp --config=mkl --config=opt -c opt //tensorflow/tools/pip_package:build_pip_package
Console output after export MKLDNN_VERBOSE=1
&lt;denchmark-code&gt;
2020-09-26 08:52:10.680539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc4db8dd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-26 08:52:10.680577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-26 08:52:10.680685: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Model: "encoder"

Layer (type)                    Output Shape         Param #    Connected to                     
input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            
conv2d (Conv2D)                 (None, 14, 14, 32)   320         input_1[0][0]                    
conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       conv2d[0][0]                     
flatten (Flatten)               (None, 3136)         0           conv2d_1[0][0]                   
dense (Dense)                   (None, 16)           50192       flatten[0][0]                    
z_mean (Dense)                  (None, 2)            34          dense[0][0]                      
z_log_var (Dense)               (None, 2)            34          dense[0][0]                      
sampling (Sampling)             (None, 2)            0           z_mean[0][0]                     
                                                                 z_log_var[0][0]                  

Total params: 69,076
Trainable params: 69,076
Non-trainable params: 0

Model: "decoder"
Layer (type)                 Output Shape              Param #   
input_2 (InputLayer)         [(None, 2)]               0         
dense_1 (Dense)              (None, 3136)              9408      
reshape (Reshape)            (None, 7, 7, 64)          0         
conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     
conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     
conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         289       

Total params: 65,089
Trainable params: 65,089
Non-trainable params: 0

Epoch 1/30
dnnl_verbose,info,oneDNN v1.4.0 (commit N/A)
dnnl_verbose,info,cpu,runtime:OpenMP
dnnl_verbose,info,cpu,isa:Intel AVX2
dnnl_verbose,info,gpu,runtime:none
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:Acdb8a:f0,,,32x1x3x3,0.00488281
dnnl_verbose,exec,cpu,convolution,jit:avx2,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb8a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd8b:f0,post_ops:'eltwise_relu;';,alg:convolution_direct,mb128_ic1oc32_ih28oh14kh3sh2dh0ph0_iw28ow14kw3sw2dw0pw0,1.90991
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:ABcd8b8a:f0,,,64x32x3x3,0.0571289
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x32x14x14,1.68311
dnnl_verbose,exec,cpu,convolution,jit:avx2,forward_training,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd8b:f0,post_ops:'eltwise_relu;';,alg:convolution_direct,mb128_ic32oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,3.87109
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x64x7x7,0.25
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x64x7x7,0.225098
dnnl_verbose,exec,cpu,inner_product,gemm:jit,forward_inference,src_f32::blocked:ab:f0 wei_f32::blocked:ba:f0 bia_f32::blocked:a:f0 dst_f32::blocked:ab:f0,post_ops:'eltwise_relu;';,,mb128ic3136oc16,15.105
dnnl_verbose,exec,cpu,inner_product,gemm:jit,forward_inference,src_f32::blocked:ab:f0 wei_f32::blocked:ba:f0 bia_f32::blocked:a:f0 dst_f32::blocked:ab:f0,,,mb128ic16oc2,0.0161133
dnnl_verbose,exec,cpu,inner_product,gemm:jit,forward_inference,src_f32::blocked:ab:f0 wei_f32::blocked:ba:f0 bia_f32::blocked:a:f0 dst_f32::blocked:ab:f0,,,mb128ic16oc2,0.00512695
dnnl_verbose,exec,cpu,inner_product,gemm:jit,forward_inference,src_f32::blocked:ab:f0 wei_f32::blocked:ba:f0 bia_f32::blocked:a:f0 dst_f32::blocked:ab:f0,post_ops:'eltwise_relu;';,,mb128ic2oc3136,2.96802
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:ABcd8a8b:f0,,,64x64x3x3,0.0251465
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x7x7,0.787109
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_data,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8a8b:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic64oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,9.69995
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x64x14x14,2.89893
dnnl_verbose,exec,cpu,eltwise,jit:avx2,forward_training,data_f32::blocked:abcd:f0 diff_undef::undef::f0,,alg:eltwise_relu alpha:0 beta:0,128x14x14x64,0.614014
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:ABcd8a8b:f0,,,64x32x3x3,0.0151367
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x14x14,3.52783
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_data,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8a8b:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic32oc64_ih28oh14kh3sh2dh0ph0_iw28ow14kw3sw2dw0pw0,12.1011
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x32x28x28,2.14697
dnnl_verbose,exec,cpu,eltwise,jit:avx2,forward_training,data_f32::blocked:abcd:f0 diff_undef::undef::f0,,alg:eltwise_relu alpha:0 beta:0,128x28x28x32,1.00903
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32::blocked:cdba:f0 dst_f32:p:blocked:ABcd8a8b:f0,,,32x1x3x3,0.00488281
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x32x28x28,6.56982
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_data,src_f32:p:blocked:aBcd8b:f0 wei_f32:p:blocked:ABcd8a8b:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic1oc32_ih28oh28kh3sh1dh0ph1_iw28ow28kw3sw1dw0pw1,6.87988
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32:p:blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x1x28x28,0.666992
dnnl_verbose,exec,cpu,sum,simple:any,undef,src_f32::blocked:abcd:f0 src_f32::blocked:abcd:f0 src_f32::blocked:abcd:f0 src_f32::blocked:abcd:f0 dst_f32::blocked:abcd:f0,,,128x28x28x1,0.0817871
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:Acdb8a:f0,,,32x1x3x3,0.00292969
dnnl_verbose,exec,cpu,convolution,jit:avx2,forward_training,src_f32::blocked:abcd:f0 wei_f32::blocked:Acdb8a:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic1oc32_ih28oh28kh3sh1dh0ph1_iw28ow28kw3sw1dw0pw1,1.34204
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x32x28x28,3.01611
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32::blocked:acdb:f0 dst_f32:p:blocked:aBcd8b:f0,,,128x1x28x28,0.464111
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,alg:eltwise_relu alpha:0 beta:0,128x32x28x28,2.26904
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x14x14,1.04614
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_weights,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic32oc64_ih28oh14kh3sh2dh0ph0_iw28ow14kw3sw2dw0pw0,2.33911
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:ABcd8b8a:f0 dst_f32::blocked:cdba:f0,,,64x32x3x3,0.0158691
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:ABcd8b8a:f0,,,64x32x3x3,0.013916
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x32x28x28,7.34912
dnnl_verbose,exec,cpu,convolution,jit:avx2,forward_training,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic32oc64_ih28oh14kh3sh2dh0ph0_iw28ow14kw3sw2dw0pw0,11.5352
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x14x14,0.933105
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,alg:eltwise_relu alpha:0 beta:0,128x64x14x14,0.945068
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x7x7,0.780029
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_weights,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic64oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,1.15698
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:ABcd8b8a:f0 dst_f32::blocked:cdba:f0,,,64x64x3x3,0.0258789
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:cdba:f0 dst_f32::blocked:ABcd8b8a:f0,,,64x64x3x3,0.0200195
dnnl_verbose,exec,cpu,convolution,jit:avx2,forward_training,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic64oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,5.6731
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:aBcd8b:f0 dst_f32::blocked:acdb:f0,,,128x64x7x7,0.27002
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:ab:f0 diff_f32::blocked:ab:f0,,alg:eltwise_relu alpha:0 beta:0,128x3136,0.307129
dnnl_verbose,exec,cpu,sum,simple:any,undef,src_f32::blocked:ab:f0 src_f32::blocked:ab:f0 src_f32::blocked:ab:f0 dst_f32::blocked:ab:f0,,,128x2,0.00195312
dnnl_verbose,exec,cpu,sum,simple:any,undef,src_f32::blocked:ab:f0 src_f32::blocked:ab:f0 dst_f32::blocked:ab:f0,,,128x2,0.000976562
dnnl_verbose,exec,cpu,sum,simple:any,undef,src_f32::blocked:ab:f0 src_f32::blocked:ab:f0 dst_f32::blocked:ab:f0,,,128x16,0.000976562
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:ab:f0 diff_f32::blocked:ab:f0,,alg:eltwise_relu alpha:0 beta:0,128x16,0.00390625
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:acdb:f0 dst_f32::blocked:aBcd8b:f0,,,128x64x7x7,0.231201
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,alg:eltwise_relu alpha:0 beta:0,128x64x7x7,0.28418
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_weights,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8b8a:f0 bia_f32::blocked:a:f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic32oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,0.559082
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:ABcd8b8a:f0 dst_f32::blocked:cdba:f0,,,64x32x3x3,0.0100098
dnnl_verbose,exec,cpu,reorder,jit:uni,undef,src_f32::blocked:ABcd8b8a:f0 dst_f32::blocked:ABcd8a8b:f0,,,64x32x3x3,0.012207
dnnl_verbose,exec,cpu,convolution,jit:avx2,backward_data,src_f32::blocked:aBcd8b:f0 wei_f32::blocked:ABcd8a8b:f0 bia_undef::undef::f0 dst_f32::blocked:aBcd8b:f0,,alg:convolution_direct,mb128_ic32oc64_ih14oh7kh3sh2dh0ph0_iw14ow7kw3sw2dw0pw0,3.57495
dnnl_verbose,exec,cpu,eltwise,jit:avx2,backward_data,data_f32::blocked:aBcd8b:f0 diff_f32::blocked:aBcd8b:f0,,alg:eltwise_relu alpha:0 beta:0,128x32x14x14,0.571045
dnnl_verbose,exec,cpu,reorder,simple:any,undef,src_f32::blocked:acdb:f0 dst_f32:p:blocked:aBcd8b:f0,,,128x1x28x28,0.368164

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ianlokh' date='2020-09-26T01:32:43Z'>
		I decide to log under bugs because I was able to build from source TF 2.3.0 successfully, install and run the "Hello World" example. I experienced this issue only with the attached code.
Please find the environment file as attached here &lt;denchmark-link:https://drive.google.com/file/d/1jXRGynFl_ne_dv9WU8azWA8w8yUYpjKR/view?usp=sharing&gt;tf_env.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ianlokh' date='2020-10-29T01:04:45Z'>
		&lt;denchmark-link:https://github.com/ianlokh&gt;@ianlokh&lt;/denchmark-link&gt;

It's not officially support TF+MKL with OSX even though oneDNN supports.  It could be that oneDNN is not compiled with openMP so oneDNN code is not threaded.
In the latest master and also TF2.4, there are some changes to use an opensource  openMP, it has been tested on windows and Linux but not Mac.
Could you try these branches?
		</comment>
		<comment id='3' author='ianlokh' date='2020-11-18T05:56:32Z'>
		&lt;denchmark-link:https://github.com/ianlokh&gt;@ianlokh&lt;/denchmark-link&gt;

Is there any feedback?
		</comment>
		<comment id='4' author='ianlokh' date='2020-12-03T01:48:17Z'>
		&lt;denchmark-link:https://github.com/ianlokh&gt;@ianlokh&lt;/denchmark-link&gt;

Is it possible to close the issue?
		</comment>
		<comment id='5' author='ianlokh' date='2020-12-03T07:29:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43578&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43578&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='ianlokh' date='2020-12-03T07:30:00Z'>
		Thanks Neo for your pointers. I will try it again
		</comment>
		<comment id='7' author='ianlokh' date='2020-12-03T07:49:11Z'>
		Thank you support too!
		</comment>
	</comments>
</bug>