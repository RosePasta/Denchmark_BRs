<bug id='30849' author='jeffreyscholz' open_date='2019-07-18T16:16:04Z' closed_time='2019-07-25T15:26:35Z'>
	<summary>tf.data.experimental.make_csv_dataset cannot decompress files</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.5 (but also tested in RedHat 7)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): pip3
TensorFlow version (use command below): 1.13.1
Python version: 3.7.3
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: CPU

Describe the current behavior
tf.contrib.data.make_csv_dataset cannot decompress gzip files
Describe the expected behavior
When compression_type is set to GZIP, it should decompress a gzip file
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
import pandas as pd

sample_iris = {
    'Id': [1,2,3],
    'SepalLengthCm': [5.1, 4.9, 4.7],
    'SepalWidth': [3.5, 3.0, 3.2],
    'Sepcies': ['Iris-setosa', 'Iris-setosa', 'Iris-setosa']
}

df = pd.DataFrame(sample_iris)
df.to_csv('Iris-compressed.csv.gz', compression='gzip', index=False)

train_files = ['Iris-compressed.csv.gz']
train_batch_size = 4
select_columns = ['Id','SepalLengthCm','SepalWidthCm','Species']

dataset = tf.data.experimental.make_csv_dataset(
    train_files,
    train_batch_size,
    column_names=None,
    column_defaults=None,
    label_name='Species',
    select_columns=select_columns,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    header=True,
    num_epochs=None,
    shuffle=True,
    shuffle_buffer_size=100,
    shuffle_seed=None,
    prefetch_buffer_size=tf.data.experimental.AUTOTUNE,
    num_parallel_reads=1,
    sloppy=True,
    num_rows_for_inference=100,
    compression_type=tf.constant('GZIP')
)
As a sanity check,
gunzip Iris-compressed.csv.gz &amp;&amp; cat Iris-compressed.csv
works as expected, returning
&lt;denchmark-code&gt;1,5.1,3.5,Iris-setosa
2,4.9,3.0,Iris-setosa
3,4.7,3.2,Iris-setosa
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "test.py", line 38, in &lt;module&gt;
    compression_type=tf.constant('GZIP')
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py", line 547, in make_csv_dataset_v1
    compression_type, ignore_errors))
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py", line 434, in make_csv_dataset_v2
    column_names = _infer_column_names(filenames, field_delim, use_quote_delim)
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/data/experimental/ops/readers.py", line 164, in _infer_column_names
    column_names = next(csv.reader(f, **csv_kwargs))
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 220, in __next__
    return self.next()
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 214, in next
    retval = self.readline()
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 179, in readline
    return self._prepare_value(self._read_buf.ReadLineAsString())
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py", line 98, in _prepare_value
    return compat.as_str_any(val)
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/util/compat.py", line 117, in as_str_any
    return as_str(value)
  File "/usr/local/lib/python3.7/site-packages/tensorflow/python/util/compat.py", line 87, in as_text
    return bytes_or_text.decode(encoding)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jeffreyscholz' date='2019-07-19T02:30:48Z'>
		I think the issue is that, make_csv_dataset will try to probe the column name automatically if not present. In order to "probe" the column automatically, it use python's csv module to check for the first line of the file. But the compression_type was not accounted for in this situation.  Once column is available then internally CsvDataset process the file correctly, though.
Created a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/30867&gt;#30867&lt;/denchmark-link&gt;
 for the fix.
		</comment>
		<comment id='2' author='jeffreyscholz' date='2019-07-25T15:26:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30849&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30849&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>