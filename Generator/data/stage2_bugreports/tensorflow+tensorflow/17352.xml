<bug id='17352' author='sseung0703' open_date='2018-03-01T12:12:27Z' closed_time='2018-04-03T17:11:04Z'>
	<summary>[Suggestion]SVD GPU Op is not efficient than CPU.</summary>
	<description>
when I used TF 1.2 version, there is no problem with using SVD
but few days ago i updated my tensorflow version to 1.5 and my code get extremely slow.
so I tested all possibility and  checked issues
finally i found that someone commited SVD GPU op made by cudasolver. in june, 2017
he said that it contain memcopy and it cause bottleneck. it is true and it make svd GPU op extremely slow than former version.
so please remove that op. and if possible, please make proper SVD GPU op  and gradients, and solve problem that tf.svd return nan value.
i uploaded my naive solution to avoid nan value problem and code for compute svd's gradients.
&lt;denchmark-link:https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py&gt;https://github.com/InhaDeeplearningGroup/Academic_research/blob/master/LSH/tensorflow_slim/svdGradients.py&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Linux Ubuntu 16.04
install by binary
TF version : i tested in 1.2, 1.3, 1.4,1.5
python3.5
CUDA : i tested in 7.5, 8.0, 9.0
GPU : gtx1070

	</description>
	<comments>
		<comment id='1' author='sseung0703' date='2018-03-01T19:21:35Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
  Can you comment on this?
		</comment>
		<comment id='2' author='sseung0703' date='2018-03-09T00:41:21Z'>
		It's a known issue. Doing SVD in numpy can be 20x faster than in TensorFlow
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/13222#issuecomment-331642490&gt;#13222 (comment)&lt;/denchmark-link&gt;

Similar with matrix inverses, it's faster to do it in numpy and feed the results back into tf using feed_dict
		</comment>
		<comment id='3' author='sseung0703' date='2018-03-09T00:46:27Z'>
		cc &lt;denchmark-link:https://github.com/shamanDevel&gt;@shamanDevel&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='sseung0703' date='2018-03-09T07:05:59Z'>
		&lt;denchmark-link:https://github.com/yaroslavvb&gt;@yaroslavvb&lt;/denchmark-link&gt;
 yes it's a known issue. so why still have to maintain this inefficient op. i think former version is better than this. i didn't check time but i think at least it is similar with numpy.
		</comment>
		<comment id='5' author='sseung0703' date='2018-03-09T19:33:08Z'>
		&lt;denchmark-link:https://github.com/sseung0703&gt;@sseung0703&lt;/denchmark-link&gt;
 they are both available, by default GPU is used if , but you can force CPU version by using  block.
I agree that it's a regression, defaulting to such slow kernel for SVD gives another way for newcomers to shoot themselves in the foot.
		</comment>
		<comment id='6' author='sseung0703' date='2018-03-09T19:44:36Z'>
		&lt;denchmark-link:https://github.com/yaroslavvb&gt;@yaroslavvb&lt;/denchmark-link&gt;
 it is not good solution. it still has bottleneck cause of communication, but former version is not.
test it in TF 1.2 and later version. tf.svd in TF 1.2 is much faster than later version.
maybe i can change it by installing source. but you know "defaulting to such slow kernel for SVD gives another way for newcomers to shoot themselves in the foot".
		</comment>
		<comment id='7' author='sseung0703' date='2018-03-09T19:47:13Z'>
		&lt;denchmark-link:https://github.com/sseung0703&gt;@sseung0703&lt;/denchmark-link&gt;
 tf 1.2 didn't have GPU version of SVD, so it would have communication bottleneck as well.
		</comment>
		<comment id='8' author='sseung0703' date='2018-03-09T20:07:43Z'>
		&lt;denchmark-link:https://github.com/yaroslavvb&gt;@yaroslavvb&lt;/denchmark-link&gt;
 oh, i didn't know that if there is no gpu op, it forcely use cpu.
Ok, so i use your way until tf.svd's gpu op work properly.
but i still don't know why TF maintain this op.
		</comment>
		<comment id='9' author='sseung0703' date='2018-04-03T17:11:04Z'>
		This issue seems to have been resolved, has not had any extra discussion, and is already a known issue, so I'm closing it to keep the issue tracker focused.
		</comment>
	</comments>
</bug>