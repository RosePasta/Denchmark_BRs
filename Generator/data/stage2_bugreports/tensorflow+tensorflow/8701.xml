<bug id='8701' author='dennybritz' open_date='2017-03-24T19:18:55Z' closed_time='2017-06-16T20:43:16Z'>
	<summary>InvalidArgumentError using tf.learn and eval</summary>
	<description>
See &lt;denchmark-link:https://github.com/google/seq2seq/issues/103&gt;google/seq2seq#103&lt;/denchmark-link&gt;
 for details and user logs.
TLDR; I'm using tf.learn and for some people the evaluation fails with shape errors. This seems to be some kind of GPU memory sharing issue, as subsequent runs seem to consistently increase the shape size:
&lt;denchmark-code&gt;InvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [1280,36240] and labels shape [6272]

InvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [2304,36240] and labels shape [6272]

InvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [4480,36240] and labels shape [6272]
&lt;/denchmark-code&gt;

Evaluation works independently when there is no training in progress. It also doesn't happen when using the CPU only.
I personally have run into similar issues before then multiple processes were trying to share the GPU, but that shouldn't be the case here.
	</description>
	<comments>
		<comment id='1' author='dennybritz' date='2017-03-31T18:10:08Z'>
		&lt;denchmark-link:https://github.com/dennybritz&gt;@dennybritz&lt;/denchmark-link&gt;
, can you identify which line of python caused this error? My guess is this is related to the argument reorder on metrics... from the TensorFlow release notes.
&lt;denchmark-code&gt;Change arg order for {softmax,sparse_softmax,sigmoid}_cross_entropy_with_logits to be (labels, predictions), and force use of named args.
&lt;/denchmark-code&gt;

So go find those and insert explicit keyword argument labels appropriately and it should fix it. Let me know if that fixes you problem. Thanks
		</comment>
		<comment id='2' author='dennybritz' date='2017-03-31T18:18:12Z'>
		I don't think that is the issue. All arguments are named and it only happens to some users (I don't have this problem myself). Also, if you read the original issue you can see that some users managed to "fix" it by disabling bucketing or reducing the dev data.
It looks very much like some kind of GPU memory issue to me.
		</comment>
		<comment id='3' author='dennybritz' date='2017-03-31T20:59:46Z'>
		I'm sorry I missed that. I've seen many examples of shape errors being caused by that change, so it is worth a shot.
Since this issue links to a incomplete summary and then 4 more issues which are themselves just blobs of erros, it's pretty hard to follow what is going on. Let me ask a few clarifying questions, since you've spent a good deal of time looking at this it appears.

What versions of TensorFlow are people using?  "compiled from source from the master branch" is not useful since master changes all the time.
Did all of them manage to run it on CPU only successfully?
What versions of CUDA are people using? Maybe there is a pattern.
What is the command I can run to try this example? Where is the code?

		</comment>
		<comment id='4' author='dennybritz' date='2017-03-31T21:19:58Z'>
		
1.0.0 or 1.0.1 - The code only works with that version.
The people I've talked to, yes. But I will try to ask more.
Not sure, will try to ask.
The command in this tutorial: https://google.github.io/seq2seq/nmt

		</comment>
		<comment id='5' author='dennybritz' date='2017-04-17T20:50:51Z'>
		So, this seems to be related to  in tf.learn, see &lt;denchmark-link:https://github.com/google/seq2seq/issues/103#issuecomment-293796457&gt;google/seq2seq#103 (comment)&lt;/denchmark-link&gt;
.
It seems like the only solution right now is to monkeypatch the Experiment class?
		</comment>
		<comment id='6' author='dennybritz' date='2017-04-17T21:57:34Z'>
		This has the patch: &lt;denchmark-link:https://github.com/google/seq2seq/pull/173&gt;google/seq2seq#173&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='dennybritz' date='2017-04-17T22:57:47Z'>
		Did you mean to reopen?
		</comment>
		<comment id='8' author='dennybritz' date='2017-04-17T23:11:02Z'>
		Yes. I patched it in my code, but that doesn't seem right. I wonder what
the "official" solution is.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Apr 17, 2017 at 3:59 PM drpngx ***@***.***&gt; wrote:
 Did you mean to reopen?

 —
 You are receiving this because you modified the open/close state.


 Reply to this email directly, view it on GitHub
 &lt;#8701 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAYmvTlOCPdaVSYW6UmaSTRNSCvMiV88ks5rw-63gaJpZM4MoqzO&gt;
 .



		</comment>
		<comment id='9' author='dennybritz' date='2017-04-17T23:14:28Z'>
		OK, I wonder if it's best to use the seq2seq thread or this one. &lt;denchmark-link:https://github.com/sguada&gt;@sguada&lt;/denchmark-link&gt;
 what do you think of this issue? It appears that it is related to .
		</comment>
		<comment id='10' author='dennybritz' date='2017-06-16T20:43:14Z'>
		Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.
		</comment>
		<comment id='11' author='dennybritz' date='2017-10-03T08:39:51Z'>
		I meet the same problem.
TF versio: 1.3.1
python version: 3.5.2
code: &lt;denchmark-link:https://gist.github.com/jinyu121/2c2e22f984a993a86f11f1be98f1d14c&gt;https://gist.github.com/jinyu121/2c2e22f984a993a86f11f1be98f1d14c&lt;/denchmark-link&gt;
 (Sorry for the Chinese comments... It's just my note)
data: the flower dataset used in tensorflow examples
data convert: create train and test TXT file with the format 
log:  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1351702/log.log&gt;log.log&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>