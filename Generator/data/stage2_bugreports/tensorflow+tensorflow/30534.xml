<bug id='30534' author='mketcha' open_date='2019-07-09T16:10:20Z' closed_time='2019-07-11T18:57:54Z'>
	<summary>[TF 2.0] Error using VGG-based loss with keras model.compile</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1
Python version: 3.6
CUDA/cuDNN version: cudatoolkit 10.0.130, cudnn 7.6.0
GPU model and memory: NVIDIA GeForce GTX 1080 Ti

Describe the current behavior
The following error (full traceback below) is observed during the  keras compile call when using a pretrained VGG model in my loss function.

AttributeError: 'Tensor' object has no attribute '_cpu_nograd'

This error only occurs in TF 2.0, and does not occur in TF 1.14.
It is worth noting that no error occurs when using a similar loss function in non-eager execution as in &lt;denchmark-link:https://www.tensorflow.org/beta/tutorials/generative/style_transfer&gt;https://www.tensorflow.org/beta/tutorials/generative/style_transfer&lt;/denchmark-link&gt;

Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import models, optimizers, metrics
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.applications.vgg19 import preprocess_input
import numpy as np

#Build Simple Model
inputs = keras.Input(shape=(32,32,3))
x = Conv2D(16, 3, padding = 'same', activation='relu')(inputs)
x = Conv2D(16, 3, padding = 'same', activation='relu')(x)
o = Conv2D( 3, 3, padding = 'same', activation='relu')(x)
model = keras.Model(inputs=inputs, outputs=o)

#Generate dummy data
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_train = x_train.astype('float32') / 255.
y_train = x_train.copy()
x_train = x_train+0.1*np.random.randn(*x_train.shape).astype('f')
train_ds = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train)).shuffle(10000).batch(128)

#Load VGG model
vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape = [32,32,3])
vgg.trainable = False
content_layers = 'block5_conv2'

lossModel = models.Model([vgg.input], vgg.get_layer(content_layers).output, name = 'vggL')

def lossVGG(X,Y):
    Xt = preprocess_input(X*255)
    Yt = preprocess_input(Y*255)
    vggX = lossModel(Xt)
    vggY = lossModel(Yt)
    return tf.reduce_mean(tf.square(vggY-vggX))

optimizer = optimizers.Adam(learning_rate=0.0005)
loss = [lossVGG]
model.compile(optimizer = optimizer, loss = loss)
history = model.fit(train_ds, epochs = 20)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-6-6822dc73d458&gt; in &lt;module&gt;
     40 optimizer = optimizers.Adam(learning_rate=0.0005)
     41 loss = [lossVGG]
---&gt; 42 model.compile(optimizer = optimizer, loss = loss)
     43 history = model.fit(train_ds, epochs = 20)

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
    456     self._self_setattr_tracking = False  # pylint: disable=protected-access
    457     try:
--&gt; 458       result = method(self, *args, **kwargs)
    459     finally:
    460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    335 
    336       # Creates the model loss and weighted metrics sub-graphs.
--&gt; 337       self._compile_weights_loss_and_weighted_metrics()
    338 
    339       # Functions for train, test and predict will

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
    456     self._self_setattr_tracking = False  # pylint: disable=protected-access
    457     try:
--&gt; 458       result = method(self, *args, **kwargs)
    459     finally:
    460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in _compile_weights_loss_and_weighted_metrics(self, sample_weights)
   1492       #                   loss_weight_2 * output_2_loss_fn(...) +
   1493       #                   layer losses.
-&gt; 1494       self.total_loss = self._prepare_total_loss(masks)
   1495 
   1496   def _prepare_skip_target_masks(self):

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in _prepare_total_loss(self, masks)
   1552 
   1553           if hasattr(loss_fn, 'reduction'):
-&gt; 1554             per_sample_losses = loss_fn.call(y_true, y_pred)
   1555             weighted_losses = losses_utils.compute_weighted_loss(
   1556                 per_sample_losses,

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\losses.py in call(self, y_true, y_pred)
    213       Loss values per sample.
    214     """
--&gt; 215     return self.fn(y_true, y_pred, **self._fn_kwargs)
    216 
    217   def get_config(self):

&lt;ipython-input-6-6822dc73d458&gt; in lossVGG(X, Y)
     34 
     35     vggX = lossModel(Xt)
---&gt; 36     vggY = lossModel(Yt)
     37 
     38     return tf.reduce_mean(tf.square(vggY-vggX))

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer.py in __call__(self, inputs, *args, **kwargs)
    594     # framework.
    595     if build_graph and base_layer_utils.needs_keras_history(inputs):
--&gt; 596       base_layer_utils.create_keras_history(inputs)
    597 
    598     # Clear eager losses on top level model call.

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer_utils.py in create_keras_history(tensors)
    197     keras_tensors: The Tensors found that came from a Keras Layer.
    198   """
--&gt; 199   _, created_layers = _create_keras_history_helper(tensors, set(), [])
    200   return created_layers
    201 

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    241             constants[i] = op_input
    242           else:
--&gt; 243             constants[i] = backend.function([], op_input)([])
    244       processed_ops, created_layers = _create_keras_history_helper(
    245           layer_inputs, processed_ops, created_layers)

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\backend.py in __call__(self, inputs)
   3517     # (otherwise it's just a no-op.)
   3518     return nest.pack_sequence_as(
-&gt; 3519         self._outputs_structure, [x._cpu_nograd()._numpy() for x in outputs],  # pylint: disable=protected-access
   3520         expand_composites=True)
   3521 

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\backend.py in &lt;listcomp&gt;(.0)
   3517     # (otherwise it's just a no-op.)
   3518     return nest.pack_sequence_as(
-&gt; 3519         self._outputs_structure, [x._cpu_nograd()._numpy() for x in outputs],  # pylint: disable=protected-access
   3520         expand_composites=True)
   3521 

AttributeError: 'Tensor' object has no attribute '_cpu_nograd'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mketcha' date='2019-07-10T12:30:56Z'>
		I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Thanks!
		</comment>
		<comment id='2' author='mketcha' date='2019-07-10T22:52:43Z'>
		&lt;denchmark-link:https://github.com/mketcha&gt;@mketcha&lt;/denchmark-link&gt;
 Need to add function decoration @tf.function() before custom loss function.
Please check the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/dfd2cf563b1a3e255455b3c54e64d3b8/tf_30534_customloss.ipynb#scrollTo=e3TFz1m2n1sj&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='mketcha' date='2019-07-11T13:38:50Z'>
		Thank you! Including the @tf.function() does work in the provided sample code.  However, if I change the code to now load the model within the function as in:
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import models, optimizers, metrics
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.applications.vgg19 import preprocess_input
import numpy as np

#Build Simple Model
inputs = keras.Input(shape=(32,32,3))
x = Conv2D(16, 3, padding = 'same', activation='relu')(inputs)
x = Conv2D(16, 3, padding = 'same', activation='relu')(x)
o = Conv2D( 3, 3, padding = 'same', activation='relu')(x)
model = keras.Model(inputs=inputs, outputs=o)

#Generate dummy data
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
x_train = x_train.astype('float32') / 255.
y_train = x_train.copy()
x_train = x_train+0.1*np.random.randn(*x_train.shape).astype('f')
train_ds = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train)).shuffle(10000).batch(128)


@tf.function()
def lossVGG(X,Y):
    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape = [32,32,3])
    vgg.trainable = False
    content_layers = 'block5_conv2'

    lossModel = models.Model([vgg.input],vgg.get_layer(content_layers).output,name = 'vggL')

    Xt = preprocess_input(X*255)
    Yt = preprocess_input(Y*255)
    
    vggX = lossModel(Xt)
    vggY = lossModel(Yt)
    
    return tf.reduce_mean(tf.square(vggY-vggX))

optimizer = optimizers.Adam(learning_rate=0.0005)
loss = [lossVGG]
model.compile(optimizer = optimizer, loss = loss)
history = model.fit(train_ds, epochs = 20)
&lt;/denchmark-code&gt;

I now get the following error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-1-34d952c19226&gt; in &lt;module&gt;
     42 optimizer = optimizers.Adam(learning_rate=0.0005)
     43 loss = [lossVGG]
---&gt; 44 model.compile(optimizer = optimizer, loss = loss)
     45 history = model.fit(train_ds, epochs = 20)

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
    456     self._self_setattr_tracking = False  # pylint: disable=protected-access
    457     try:
--&gt; 458       result = method(self, *args, **kwargs)
    459     finally:
    460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    335 
    336       # Creates the model loss and weighted metrics sub-graphs.
--&gt; 337       self._compile_weights_loss_and_weighted_metrics()
    338 
    339       # Functions for train, test and predict will

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
    456     self._self_setattr_tracking = False  # pylint: disable=protected-access
    457     try:
--&gt; 458       result = method(self, *args, **kwargs)
    459     finally:
    460       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in _compile_weights_loss_and_weighted_metrics(self, sample_weights)
   1492       #                   loss_weight_2 * output_2_loss_fn(...) +
   1493       #                   layer losses.
-&gt; 1494       self.total_loss = self._prepare_total_loss(masks)
   1495 
   1496   def _prepare_skip_target_masks(self):

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\training.py in _prepare_total_loss(self, masks)
   1552 
   1553           if hasattr(loss_fn, 'reduction'):
-&gt; 1554             per_sample_losses = loss_fn.call(y_true, y_pred)
   1555             weighted_losses = losses_utils.compute_weighted_loss(
   1556                 per_sample_losses,

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\losses.py in call(self, y_true, y_pred)
    213       Loss values per sample.
    214     """
--&gt; 215     return self.fn(y_true, y_pred, **self._fn_kwargs)
    216 
    217   def get_config(self):

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    426         # Lifting succeeded, so variables are initialized and we can run the
    427         # stateless function.
--&gt; 428         return self._stateless_fn(*args, **kwds)
    429     else:
    430       canon_args, canon_kwds = \

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   1332   def __call__(self, *args, **kwargs):
   1333     """Calls a graph function specialized to the inputs."""
-&gt; 1334     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   1335     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1336 

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   1646       graph_function = self._function_cache.primary.get(cache_key, None)
   1647       if graph_function is None:
-&gt; 1648         graph_function = self._create_graph_function(args, kwargs)
   1649         self._function_cache.primary[cache_key] = graph_function
   1650       return graph_function, args, kwargs

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   1539             arg_names=arg_names,
   1540             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 1541             capture_by_value=self._capture_by_value),
   1542         self._function_attributes)
   1543 

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    714                                           converted_func)
    715 
--&gt; 716       func_outputs = python_func(*func_args, **func_kwargs)
    717 
    718       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    307         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    308         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 309         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    310     weak_wrapped_fn = weakref.ref(wrapped_fn)
    311 

~\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\framework\func_graph.py in wrapper(*args, **kwargs)
    704           except Exception as e:  # pylint:disable=broad-except
    705             if hasattr(e, "ag_error_metadata"):
--&gt; 706               raise e.ag_error_metadata.to_exception(type(e))
    707             else:
    708               raise

ValueError: in converted code:

    &lt;ipython-input-1-34d952c19226&gt;:28 lossVGG  *
        vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape = [32,32,3])
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\applications\__init__.py:70 wrapper
        return base_fun(*args, **kwargs)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\applications\vgg19.py:32 VGG19
        return vgg19.VGG19(*args, **kwargs)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\keras_applications\vgg19.py:112 VGG19
        name='block1_conv1')(img_input)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:616 __call__
        self._maybe_build(inputs)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1966 _maybe_build
        self.build(input_shapes)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\layers\convolutional.py:165 build
        dtype=self.dtype)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:389 add_weight
        aggregation=aggregation)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\training\tracking\base.py:713 _add_variable_with_custom_getter
        **kwargs_for_getter)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\keras\engine\base_layer_utils.py:154 make_variable
        shape=variable_shape if variable_shape else None)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\ops\variables.py:260 __call__
        return cls._variable_v1_call(*args, **kwargs)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\ops\variables.py:221 _variable_v1_call
        shape=shape)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\ops\variables.py:60 getter
        return captured_getter(captured_previous, **kwargs)
    C:\Users\ketchm3\AppData\Local\Continuum\miniconda3\envs\tensor2\lib\site-packages\tensorflow\python\eager\def_function.py:364 invalid_creator_scope
        "tf.function-decorated function tried to create "

    ValueError: tf.function-decorated function tried to create variables on non-first call.
&lt;/denchmark-code&gt;

I can work around it, but still worth noting
		</comment>
		<comment id='4' author='mketcha' date='2019-07-11T18:29:33Z'>
		&lt;denchmark-link:https://github.com/mketcha&gt;@mketcha&lt;/denchmark-link&gt;
 What is your intention behind adding load_model under custom loss function?
This lossVGG will be called every epoch which mean you are trying to create vgg and other variables multiple times in the graph. That is the reason behind ValueError: tf.function-decorated function tried to create variables on non-first call.. Thanks!
		</comment>
		<comment id='5' author='mketcha' date='2019-07-11T18:57:54Z'>
		I agree, adds unnecessary overhead. Was an error that came about while attempting to update TF1.X scripts that I found to TF2.0.
Thanks for the help!
		</comment>
		<comment id='6' author='mketcha' date='2019-07-11T18:57:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30534&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30534&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>