<bug id='27222' author='jackd' open_date='2019-03-28T02:29:06Z' closed_time='2019-03-29T03:19:30Z'>
	<summary>ragged batch_gather fails for ragged indices, non-ragged params</summary>
	<description>
<denchmark-h:h1>System information</denchmark-h>


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below)
OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from: pip
TensorFlow version: ('v1.13.1-0-g6612da8951', '1.13.1')
Python version: 2.7.12
CUDA/cuDNN version: 10.0/7
GPU model and memory: quadro

<denchmark-h:h1>Current behaviour</denchmark-h>

Using tf.batch_gather(params, indices) with a tf.Tensor params and tf.RaggedTensor indices throws an uneccessary error.
import tensorflow as tf
if not tf.executing_eagerly():
    try:
        tf.compat.v1.enable_eager_execution()
    except Exception:
        tf.enable_eager_execution()

params = tf.range(10, dtype=tf.int64)
indices = tf.RaggedTensor.from_row_lengths(
    tf.constant([2, 3, 1, 5, 0], dtype=tf.int64),
    tf.constant([3, 2], dtype=tf.int64))

out = tf.gather(params, indices)
print(out)
# <tf.RaggedTensor [[2, 3, 1], [5, 0]]>
# so far so good

batched_params = tf.expand_dims(params, axis=0)
batched_indices = tf.expand_dims(indices, axis=0)
batched_out = tf.batch_gather(batched_params, batched_indices)
# ValueError: batch shape from indices does not match params shape
<denchmark-h:h1>Expected Behaviour</denchmark-h>

batch_gather behaviour to correspond to gather being mapped across params and indices (see work-around below). If the use-case is sufficiently small that this isn't prioritised, an accurate error message would be preferable.
<denchmark-h:h1>Workaround</denchmark-h>

def batch_gather_workaround(params, indices):
    if (
            isinstance(indices, tf.RaggedTensor) and
            not isinstance(params, tf.RaggedTensor)):
        shape = tf.shape(params, out_type=tf.int64)
        dims = tf.unstack(shape)
        batch_size = dims[0]
        stride = dims[1]
        offset = tf.range(batch_size, dtype=tf.int64)*stride
        offset = tf.reshape(offset, [batch_size] + [1]*(indices.shape.ndims-1))
        flat_params = tf.reshape(params, [batch_size*stride] + dims[2:])
        return tf.gather(flat_params, indices + offset)
    else:
        return tf.batch_gather(params, indices)


batched_out = batch_gather_workaround(batched_params, batched_indices)
# <tf.RaggedTensor [[[2, 3, 1], [5, 0]]]>
	</description>
	<comments>
		<comment id='1' author='jackd' date='2019-03-29T03:19:28Z'>
		I misunderstood how batch_gather is intended to work (thought it was equivalent to gather, just skipping the first dimension). My apologies.
		</comment>
		<comment id='2' author='jackd' date='2019-03-29T03:19:32Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27222&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27222&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>