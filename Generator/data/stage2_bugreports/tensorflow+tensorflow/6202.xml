<bug id='6202' author='yaroslavvb' open_date='2016-12-09T02:12:45Z' closed_time='2016-12-27T23:44:51Z'>
	<summary>Inconsistent API for ones_initializer/zeros_initializer</summary>
	<description>
This &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/cfb2280d3f6ced298681bd1141479a59a06abde8&gt;cl&lt;/denchmark-link&gt;
 has removed  argument from , however, this argument remains for .
This is a breaking change so maybe it should be mentioned in RELEASE.md with instructions on how code should transition (ie ones_initializer should be replaced with ones_initializer()). Currently older code that works in 0.11 fails in 0.12 with obscure message
ie
&lt;denchmark-code&gt;    update = tf.get_variable(name="update", shape=[params_size], dtype=dtype,
                             initializer=tf.ones_initializer)

&lt;/denchmark-code&gt;

fails with
&lt;denchmark-code&gt;...
    initial_value(), name="initial_value", dtype=dtype)
  File "/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 665, in &lt;lambda&gt;
    shape.as_list(), dtype=dtype, partition_info=partition_info)
TypeError: ones_initializer() got multiple values for argument 'dtype'

&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/itsmeolivia&gt;@itsmeolivia&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='yaroslavvb' date='2016-12-15T21:12:37Z'>
		BTW, this seems to be fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/6339&gt;#6339&lt;/denchmark-link&gt;
 (ie, syntax is consistent, both of them need to be tf.ones_initializer() and tf.zeros_initializer() ) , except maybe RELEASE.md could mention that people should add "()" to their tf.ones_initializer
		</comment>
		<comment id='2' author='yaroslavvb' date='2017-01-09T05:06:39Z'>
		I get
TypeError: zeros_initializer() got multiple values for keyword argument 'dtype'
for the inception model command:
bazel-bin/tensorflow_serving/example/inception_export --checkpoint_dir=inception-v3 --export_dir=inception-export
NOTE: I am able to successfully run the MNIST example for tensorflow serving but not the inception one.
I have tried all the recommendations mentioned previously.
The trace is as follows:
Traceback (most recent call last):
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py", line 169, in 
tf.app.run()
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 44, in run
_sys.exit(main(_sys.argv[:1] + flags_passthrough))
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py", line 165, in main
export()
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py", line 79, in export
logits, _ = inception_model.inference(images, NUM_CLASSES + 1)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/inception_model.py", line 87, in inference
scope=scope)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/inception_model.py", line 87, in inception_v3
scope='conv0')
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py", line 155, in func_with_args
return func(*args, **current_args)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/ops.py", line 234, in conv2d
outputs = batch_norm(conv, **batch_norm_params)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py", line 155, in func_with_args
return func(*args, **current_args)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/ops.py", line 90, in batch_norm
restore=restore)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py", line 155, in func_with_args
return func(*args, **current_args)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/variables.py", line 289, in variable
trainable=trainable, collections=collections)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 1063, in get_variable
custom_getter=custom_getter)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 889, in get_variable
custom_getter=custom_getter)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 347, in get_variable
validate_shape=validate_shape)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 332, in _true_getter
caching_device=caching_device, validate_shape=validate_shape)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 683, in _get_single_variable
validate_shape=validate_shape)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variables.py", line 225, in init
expected_shape=expected_shape)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variables.py", line 322, in _init_from_args
initial_value(), name="initial_value", dtype=dtype)
File "/root/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py", line 672, in 
shape.as_list(), dtype=dtype, partition_info=partition_info)
TypeError: zeros_initializer() got multiple values for keyword argument 'dtype'
		</comment>
		<comment id='3' author='yaroslavvb' date='2017-01-10T06:10:43Z'>
		This is a reference is to a different project that includes tensorflow. Confused about what changes I need to make in the tensorflow-serving branch to get rid of this issue.
Appreciate if you can spell out the exact changes I need to make.
		</comment>
		<comment id='4' author='yaroslavvb' date='2017-01-10T18:39:06Z'>
		tf.zeros_initializer had multiple incompatible API changes between 0.11, 0.12, and -master.
If you need compatibility across versions, use tf.constant_initializer(0.0) instead.
		</comment>
		<comment id='5' author='yaroslavvb' date='2017-01-10T22:10:29Z'>
		I am also running into this problem when following the TensorFlow serving tutorial here &lt;denchmark-link:https://tensorflow.github.io/serving/serving_inception.html&gt;https://tensorflow.github.io/serving/serving_inception.html&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='yaroslavvb' date='2017-01-11T03:49:24Z'>
		Still experience the same issue here. Just did a fresh clone of tf_serving to export weights which has the latest tensorflow as well
		</comment>
		<comment id='7' author='yaroslavvb' date='2017-01-11T04:21:27Z'>
		&lt;denchmark-link:https://github.com/neuralearner&gt;@neuralearner&lt;/denchmark-link&gt;
 The issue I described is due to API change affecting user code and can be fixed by changing tf.ones_initializer to tf.ones_initializer() in your program
		</comment>
		<comment id='8' author='yaroslavvb' date='2017-01-11T09:17:31Z'>
		I see that the .pyc files have the zero_initializer. Has anyone tried replacing the zero_initializer function with constant_initializer and regenerated the pyc files. In that case please outline the steps you followed.
		</comment>
		<comment id='9' author='yaroslavvb' date='2017-01-11T18:08:39Z'>
		&lt;denchmark-link:https://github.com/neuralearner&gt;@neuralearner&lt;/denchmark-link&gt;
 I got it working by changing tf.ones_initializer to tf.ones_initializer() and tf.zeros_initializer to tf.zeros_initializer() in .  &lt;denchmark-link:https://github.com/tensorflow/serving/issues/250&gt;This issue&lt;/denchmark-link&gt;
 helped me solve the problem.
		</comment>
		<comment id='10' author='yaroslavvb' date='2017-01-13T15:42:02Z'>
		Thanks &lt;denchmark-link:https://github.com/alexminnaar&gt;@alexminnaar&lt;/denchmark-link&gt;
 ! This solution worked for me. There were a few more hacks required.
For those trying please also note that you need to change all tf.histogram_summary and tf.scalar_summary to tf.summary.histogram and tf.summary.scalar, to successfully load and export the model as indicated in the post pointed by &lt;denchmark-link:https://github.com/alexminnaar&gt;@alexminnaar&lt;/denchmark-link&gt;
 above
		</comment>
		<comment id='11' author='yaroslavvb' date='2017-01-13T17:31:28Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 wrote a tool to try to upgrade code (at least at 0.11?) to 1.0 APIs.  See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/compatibility&lt;/denchmark-link&gt;
 and send PRs / file bugs for better functionality :)
		</comment>
	</comments>
</bug>