<bug id='31360' author='nielsgroen' open_date='2019-08-06T08:22:06Z' closed_time='2019-08-28T09:22:33Z'>
	<summary>Using tf.feature_columns in exported estimators fails when using tf.feature_columns.indicator_column</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code: Yes
OS Platform and Distribution: Windows 10
TensorFlow installed from: binary
TensorFlow version: 1.14.0
Python version: 3.6.8
CUDA/cuDNN version: CPU

Tensorflow Serving information:
Using tensorflow serving docker image, tag latest, as of 05/08/2019 (August 5th):

TensorFlow ModelServer: 1.14.0-rc0
TensorFlow Library: 1.14.0

&lt;denchmark-h:h3&gt;Describe the current behavior&lt;/denchmark-h&gt;

I originally opened an issue at tensorflow/serving, but I got redirected here as it is a tensorflow issue.
Tensorflow serving doesn't handle a 'feature_columns input layer' in the Estimator model_fn.
When using tf.feature_columns.input_layer or tf.keras.layer.DenseFeatures to process feature_columns in the model_fn: If you have a feature_column that is a categorical_column wrapped by an indicator_column, Tensorflow serving fails.
Tensorflow serving doesn't seem to properly handle the indicator_column. It responds with:
{
    "error": "Input to reshape is a tensor with &lt;n&gt; values, but the requested shape has &lt;n squared&gt;\n\t [[{{node input_layer/&lt;feature name&gt;_indicator/Reshape}}]]"
}
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/29ecfbf1e7ab2f073e69770753174667079d10b5/tensorflow/core/kernels/reshape_op.h#L92&gt;The reshape op where the error is thrown&lt;/denchmark-link&gt;

&lt;denchmark-link:https://stackoverflow.com/questions/57327655/is-there-a-way-to-export-custom-tensorflow-r1-14-estimators-that-are-able-to-p&gt;I asked around on stackoverflow&lt;/denchmark-link&gt;
, if there were workarounds, no response so far.
The main advantage of tf.feature_columns happens to be the indicator_column (which allows for easy one-hot encoding of features in the model code). It is also pushed in multiple Tensorflow guides as something that's used. I think this bug blocks practical use of the tf.feature_columns module in production.
When not using the indicator_column as a feature_column, all seems well
&lt;denchmark-h:h3&gt;Describe the expected behavior&lt;/denchmark-h&gt;

Tensorflow serving should just serve inference requests, (as it does when not using indicator_column)
&lt;denchmark-h:h3&gt;Code to reproduce the issue&lt;/denchmark-h&gt;

Script to export saved_models from estimators that use feature_columns:
&lt;denchmark-code&gt;"""Code for testing tensorflow serving reshape bug"""

import tensorflow as tf

feature_columns = [
    # Feature columns that use indicator column
    tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_identity('test', 2))
]

estimator_params = {
    'feature_columns': feature_columns
}


def model_fn(features, labels=None, mode=None, params=None):
    is_training = (mode == tf.estimator.ModeKeys.TRAIN)

    inputs = tf.feature_column.input_layer(features, params['feature_columns'])

    if not is_training:
        return tf.estimator.EstimatorSpec(
            mode,
            predictions=inputs
        )

    a = tf.Variable(1, dtype=tf.float32, trainable=True)

    # Doesn't need to train, but the model needs to be trainable for exporting to work
    loss = tf.reduce_mean(a * inputs)

    optimizer = params.get('optimizer', None) or tf.train.AdamOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())

    return tf.estimator.EstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op
    )


def input_fn():
    return {'test': tf.constant([1, 0], dtype=tf.int64)}, tf.constant([3, 2], dtype=tf.float32)


def serving_input_fn():
    receiver_tensors = {
        'test': tf.placeholder(tf.int64, shape=[None, 1], name='test')
    }

    return tf.estimator.export.ServingInputReceiver(receiver_tensors, receiver_tensors)


# Custom estimator
estimator = tf.estimator.Estimator(model_fn=model_fn, params=estimator_params)
# Canned estimator
# estimator = tf.estimator.DNNRegressor([2, 2, 1], feature_columns=feature_columns)

estimator.train(input_fn=input_fn, steps=5)

estimator.export_saved_model('./', serving_input_fn)
&lt;/denchmark-code&gt;

Serve the generated saved_model with Tensorflow serving.
Now make requests to it.
Example body for custom estimators:
&lt;denchmark-code&gt;{
	"inputs": {
		"test": [0, 1]
	}
}
&lt;/denchmark-code&gt;

Example body for the canned estimator:
&lt;denchmark-code&gt;{
	"signature_name": "predict",
	"inputs": {
		"test": [0, 1]
	}
}
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

All I get as response from tensorflow serving:
&lt;denchmark-code&gt;{
    "error": "Input to reshape is a tensor with 2 values, but the requested shape has 4\n\t [[{{node input_layer/test_indicator/Reshape}}]]"
}
&lt;/denchmark-code&gt;

It seems to always be: "... with n values", "... requested shape has n squared". Always in the reshape op.
I think it may be due to improper (de)serialization to or from Saved Model when using tf.keras.DenseFeatures or tf.feature_column.input_layer.
It may also be some bugged tensorflow op (just guessing)
	</description>
	<comments>
		<comment id='1' author='nielsgroen' date='2019-08-07T08:32:43Z'>
		&lt;denchmark-link:https://github.com/nielsgroen&gt;@nielsgroen&lt;/denchmark-link&gt;
, Will it be possible to provide the code, which i can reproduce the reported issue on colab or jupyter notebook. Thanks!
		</comment>
		<comment id='2' author='nielsgroen' date='2019-08-07T12:32:51Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;



Put the code in a cell in google colab.
When in Colab, on the left you see an arrow to open a sidebar, open it.
Go to 'files'. (This puts you in the '/content' folder)
Once you ran the notebook, refresh the files. (The saved_model should be in /content folder)

Or just run it locally:

copy and paste the python code in a virtual environment with tf-1.14.0 installed.
run it (the saved_model appears in the same folder as that python file you pasted the code to)

Serve the saved_model
Now, since it is an issue which requires serving the said saved_model (remember, it is an issue with exported estimators, so we need to serve it up), we are going to serve the saved_model.
This requires tensorflow serving.
Follow &lt;denchmark-link:https://www.tensorflow.org/tfx/serving/docker&gt;the instructions&lt;/denchmark-link&gt;
 to serve the model.
Make a POST request to tensorflow serving with header application/json and the body provided in the original post ^^.
If you feel like this is outside of your scope to reproduce, could you please reassign?
Thanks for your help.
		</comment>
		<comment id='3' author='nielsgroen' date='2019-08-08T09:28:09Z'>
		I tried replicating the issue with Tensorflow 1.14.0 on Colab. I didn't get any error. Please see the colab &lt;denchmark-link:https://colab.research.google.com/drive/1HNt1FjiPEXAqGMUPjlQS3M7yITYuhUGt&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='nielsgroen' date='2019-08-08T11:40:04Z'>
		&lt;denchmark-h:h3&gt;As is clearly stated in the issue: The script does not produce an error.&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;The script produces a saved_model.&lt;/denchmark-h&gt;

&lt;denchmark-link:https://www.tensorflow.org/guide/saved_model&gt;(what is a saved_model)&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;When serving the saved_model:&lt;/denchmark-h&gt;

Tensorflow serving produces the error (mentioned above) when a request is made (request body mentioned above).
With all due respect, someone who doesn't understand what the issue is about should not assign it to themselves. Whether it be due to a lack of a firm grasp of English (which is totally understandable) or due to other, less desirable, reasons.
		</comment>
		<comment id='5' author='nielsgroen' date='2019-08-28T09:22:32Z'>
		Closing as there is a easy workaround found.
It turns out, when using the indicator_column, making the inputs strictly two-dimensional will work.
&lt;denchmark-code&gt;{
	"signature_name": "predict",
	"inputs": {
		"test": [[0], [1]]  // note the extra dimension
	}
}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='nielsgroen' date='2019-08-28T09:22:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31360&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31360&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>