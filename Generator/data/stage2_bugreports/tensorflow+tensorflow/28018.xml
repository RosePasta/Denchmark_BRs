<bug id='28018' author='TanUkkii007' open_date='2019-04-21T10:59:14Z' closed_time='2020-06-08T07:02:07Z'>
	<summary>AttributeError: 'PerReplica' object has no attribute 'begin'</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): b'unknown' 1.13.1 (installed with conda)
Python version: Python 3.6.8 :: Anaconda, Inc.
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: cuda/9.0.176, cudnn/7.3
GPU model and memory: Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15190 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
2019-04-21 19:03:25.539522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15190 MB memory) -&gt; physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:87:00.0, compute capability: 6.0)

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
When running tf.estimator.Estimator model that registers tf.train.SessionRunHook to evaluation_hooks of tf.estimator.EstimatorSpec in distributed environment, an error AttributeError: 'PerReplica' object has no attribute 'begin' occurs at the beggining of evaluation. This error does not happen if I do not register SessionRunHook to evaluation_hooks. Registering SessionRunHook to training_hooks does not trigger the error even if it is in distributed mode.
I ran my Estimator with tf.estimator.train_and_evaluate.
The distribution configuration I used is tf.contrib.distribute.MirroredStrategy.
The whole error log is attatched at the end.
Describe the expected behavior
Somehow SessionRunHook turned into PerReplica at some point in evaluation code of Estimator. It should remain SessionRunHook's interface in distribution mode.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
This is not a runnable code, but introducing the modification below to some estimator examples might work as a reproducer.
&lt;denchmark-code&gt;distribution = tf.contrib.distribute.MirroredStrategy()
run_config = tf.estimator.RunConfig(train_distribute=distribution,
                                                           eval_distribute=distribution)

hook = tf.train.ProfilerHook(output_dir=model_dir)  # example hook
def model_fn(features, labels, mode, params):
            if mode == tf.estimator.ModeKeys.EVAL:
                return tf.estimator.EstimatorSpec(mode, loss,
                                                      evaluation_hooks=[hook])

estimator = tf.estimator.Estimator(params, model_dir, run_config)

tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:Efficient allreduce is not supported for IndexedSlices.
WARNING:tensorflow:Efficient allreduce is not supported for IndexedSlices.
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:batch_all_reduce invoked for batches size = 1 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
2019-04-21 18:41:17.901359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1
2019-04-21 18:41:17.901414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-21 18:41:17.901425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 
2019-04-21 18:41:17.901432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N Y 
2019-04-21 18:41:17.901439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   Y N 
2019-04-21 18:41:17.902038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15190 MB memory) -&gt; physical GPU (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
2019-04-21 18:41:17.902219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 15190 MB memory) -&gt; physical GPU (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0000:87:00.0, compute capability: 6.0)
WARNING:tensorflow:From /home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from /tmp/model.ckpt-0
WARNING:tensorflow:From /home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file utilities to get mtimes.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /tmp/model.ckpt.
INFO:tensorflow:Initialize strategy
2019-04-21 18:42:04.023667: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2019-04-21 18:42:05.162460: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x555559b95370
2019-04-21 18:42:05.970327: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x555559ba9960
INFO:tensorflow:loss = 52170.477, step = 0
INFO:tensorflow:global_step/sec: 0.0334123
INFO:tensorflow:loss = 54870.64, step = 1 (29.929 sec)
INFO:tensorflow:Saving checkpoints for 3 into /tmp/model.ckpt.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2019-04-21T09:43:02Z
Traceback (most recent call last):
  File "train.py", line 146, in &lt;module&gt;
    main()
  File "train.py", line 142, in main
    use_multi_gpu)
  File "train.py", line 83, in train_and_evaluate
    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 471, in train_and_evaluate
    return executor.run()
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 611, in run
    return self.run_local()
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 712, in run_local
    saving_listeners=saving_listeners)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 358, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1122, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1185, in _train_model_distributed
    self._config._train_distribute, input_fn, hooks, saving_listeners)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1287, in _actual_train_model_distributed
    saving_listeners)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1407, in _train_with_estimator_spec
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 676, in run
    run_metadata=run_metadata)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1171, in run
    run_metadata=run_metadata)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1270, in run
    raise six.reraise(*original_exc_info)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/six.py", line 693, in reraise
    raise value
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1255, in run
    return self._sess.run(*args, **kwargs)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 1335, in run
    run_metadata=run_metadata))
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py", line 582, in after_run
    if self._save(run_context.session, global_step):
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/basic_session_run_hooks.py", line 607, in _save
    if l.after_save(session, step):
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 517, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 537, in _evaluate
    self._evaluator.evaluate_and_export())
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/training.py", line 913, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 469, in evaluate
    name=name)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 509, in _actual_eval
    return _evaluate()
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 500, in _evaluate
    output_dir=self.eval_dir(name))
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1537, in _evaluate_run
    config=self._session_config)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/evaluation.py", line 271, in _evaluate_once
    session_creator=session_creator, hooks=hooks) as session:
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 934, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File "/home/8/18IA1142/miniconda3/envs/tacotron2-tf-1.13/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py", line 636, in __init__
    h.begin()
AttributeError: 'PerReplica' object has no attribute 'begin'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='TanUkkii007' date='2019-07-09T20:53:38Z'>
		I am also experiencing this. Any update &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='2' author='TanUkkii007' date='2019-07-09T21:39:35Z'>
		Can you try using tf.distribute.???Strategy, instead of tf.contrib.distribute.???Strategy and see if it fixed it?
		</comment>
		<comment id='3' author='TanUkkii007' date='2019-07-09T22:08:20Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 I'm using tf.distribute (not tf.contrib.distribute) and I still see the error. Error disappears when all evaluation hooks are removed, same as original post.
		</comment>
		<comment id='4' author='TanUkkii007' date='2019-08-09T18:43:00Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 any update on this? Still broken for me on TF nightly as well.
		</comment>
		<comment id='5' author='TanUkkii007' date='2019-08-09T19:54:48Z'>
		&lt;denchmark-link:https://github.com/isaprykin&gt;@isaprykin&lt;/denchmark-link&gt;
 mind taking a look?
		</comment>
		<comment id='6' author='TanUkkii007' date='2019-08-12T21:57:20Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 Could you please mirror this internally as per comp:dist-strat?
		</comment>
		<comment id='7' author='TanUkkii007' date='2019-09-11T18:42:48Z'>
		I am also experiencing this on latest tf 1.14
		</comment>
		<comment id='8' author='TanUkkii007' date='2019-09-23T12:01:55Z'>
		We are experiencing same. Is there an ETA on a fix?
		</comment>
		<comment id='9' author='TanUkkii007' date='2019-10-03T02:12:18Z'>
		I have this same issue with tf.distribute.experimental.MultiWorkerMirroredStrategy
		</comment>
		<comment id='10' author='TanUkkii007' date='2019-10-09T18:09:32Z'>
		I apologize in advance ... &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 assigned &lt;denchmark-link:https://github.com/isaprykin&gt;@isaprykin&lt;/denchmark-link&gt;
 on Aug 9 2019. Just wondering if this is being actively looked at.
		</comment>
		<comment id='11' author='TanUkkii007' date='2019-10-10T00:52:26Z'>
		Well what fixed it for me was to remove distribution strategy from
run_config = tf.estimator.RunConfig(train_distribute=distribution, eval_distribute=distribution)
Like:
run_config = tf.estimator.RunConfig(train_distribute=distribution, eval_distribute=None)
I have to mention that i talk about
distribution = tf.distribute.MirroredStrategy()
		</comment>
		<comment id='12' author='TanUkkii007' date='2019-12-06T21:15:49Z'>
		&lt;denchmark-link:https://github.com/medphysicsliv&gt;@medphysicsliv&lt;/denchmark-link&gt;
 that makes things run without crashing, yes, but it results in none of my evaluation hooks seemingly doing anything in the multi-node setting. Is there any working way to get multi-worker evaluation hooks currently?
		</comment>
		<comment id='13' author='TanUkkii007' date='2020-01-17T19:38:40Z'>
		Any update on this? It would be great to be able to use evaluation hooks in a distributed setting.
		</comment>
		<comment id='14' author='TanUkkii007' date='2020-01-17T22:41:44Z'>
		&lt;denchmark-link:https://github.com/tensorflow/estimator/blob/168aa7e06125a564d32e3a7a85a4f9e241c6f51b/tensorflow_estimator/python/estimator/estimator.py#L1619&gt;This line&lt;/denchmark-link&gt;
 returns a  object and assigns it to . If we replace the line with:
&lt;denchmark-code&gt;evaluation_hooks = self._eval_distribution.unwrap(grouped_estimator_spec.evaluation_hooks)[0][0]._values
&lt;/denchmark-code&gt;

then the evaluation hooks can be run. However, they need to already work well with multiple GPUs otherwise the results will be wrong. I am not sure if this would introduce bugs in any other places.
		</comment>
		<comment id='15' author='TanUkkii007' date='2020-02-18T04:04:32Z'>
		I think what we need to do is handle list of per-replica hooks correctly. Current code assumes that the grouped_estimator_spec.evaluation_hooks is one PerReplica hook - but it's actually a list. We need to handle them correctly as the training_hooks [1]
We would be happy to take a contribution to fix this if someone in this thread wants to do that?
[1] &lt;denchmark-link:https://github.com/tensorflow/estimator/blob/6915557cef8bfc86f29f87e4467d601e4553b957/tensorflow_estimator/python/estimator/estimator.py#L1336&gt;https://github.com/tensorflow/estimator/blob/6915557cef8bfc86f29f87e4467d601e4553b957/tensorflow_estimator/python/estimator/estimator.py#L1336&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='TanUkkii007' date='2020-06-08T07:02:07Z'>
		This has been fixed (&lt;denchmark-link:https://github.com/tensorflow/estimator/commit/131f54a62ae9ded9057aeb0eb1243d9516373b14&gt;tensorflow/estimator@131f54a&lt;/denchmark-link&gt;
). Please test with TF nightly.
		</comment>
		<comment id='17' author='TanUkkii007' date='2020-06-08T07:02:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28018&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28018&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='TanUkkii007' date='2020-06-17T20:01:57Z'>
		I've confirmed this works for a single-machine with 8 V100 GPUs and MirroredStrategy. Thanks so much!
Is this also expected to work for MultiWorkerMirroredStrategy?
		</comment>
		<comment id='19' author='TanUkkii007' date='2020-06-17T21:34:43Z'>
		Yes this part should work with MultiWorkerMirroredStrategy too.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Jun 17, 2020 at 1:02 PM Brandon McKinzie ***@***.***&gt; wrote:
 I've confirmed this works for a single-machine with 8 V100 GPUs and
 MirroredStrategy. Thanks so much!

 Is this also expected to work for MultiWorkerMirroredStrategy?

 —
 You are receiving this because you modified the open/close state.
 Reply to this email directly, view it on GitHub
 &lt;#28018 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ADLTSF7YNWJE2X4W7P5ROB3RXEOMTANCNFSM4HHLNFPQ&gt;
 .



		</comment>
	</comments>
</bug>