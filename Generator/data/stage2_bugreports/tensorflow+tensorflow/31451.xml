<bug id='31451' author='andmax' open_date='2019-08-08T17:29:53Z' closed_time='2019-11-21T13:34:37Z'>
	<summary>Error when selecting 1 GPU + TensorBoard: "(...) XLA_GPU_JIT device number 0"</summary>
	<description>
On TensorFlow 1.14 (OS Ubuntu 16.04), when I call fit() of a tf.Keras model using TensorBoard as one of the tf.Keras.callbacks, and selecting one GPU to use prior training, it fails with:
&lt;denchmark-code&gt;(...)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py 
in ensure_initialized(self)
    410         if self._execution_mode == ASYNC:
    411           pywrap_tensorflow.TFE_ContextOptionsSetAsync(opts, True)
--&gt; 412         self._context_handle = pywrap_tensorflow.TFE_NewContext(opts)
    413       finally:
    414         pywrap_tensorflow.TFE_DeleteContextOptions(opts)

InvalidArgumentError: Invalid device ordinal value (1). Valid range is [0, 0].
	while setting up XLA_GPU_JIT device number 1
&lt;/denchmark-code&gt;

If I suppress the callbacks argument in fit(), the training works.  The code to reproduce follows:
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import TensorBoard

gpu_id = 0
sess_config = tf.compat.v1.ConfigProto()
sess_config.gpu_options.allow_growth = True
sess_config.gpu_options.visible_device_list = '{}'.format(gpu_id)
sess = tf.compat.v1.Session(config=sess_config)
tf.compat.v1.keras.backend.set_session(sess)

(Xtr, Ytr), (Xva, Yva) = tf.keras.datasets.cifar10.load_data()
Xtr, Ytr, Xva, Yva, nc = Xtr[:1000], Ytr[:1000], Xva[:100], Yva[:100], 10
Xtr, Xva = Xtr.astype('float32') / 255, Xva.astype('float32') / 255
Ytr, Yva, ins = to_categorical(Ytr, nc), to_categorical(Yva, nc), Xtr.shape[1:]

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(8, (3, 3), input_shape=ins, activation='relu'))
model.add(tf.keras.layers.Conv2D(8, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(nc, activation='softmax'))
opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])

l_cb = [TensorBoard(log_dir='./tb_logs/cur', batch_size=32, write_graph=False)]

model.fit(x=Xtr, y=Ytr, batch_size=32, epochs=100, callbacks=l_cb,
          validation_data=(Xva, Yva), shuffle='batch')
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='andmax' date='2019-08-09T09:02:03Z'>
		&lt;denchmark-link:https://github.com/andmax&gt;@andmax&lt;/denchmark-link&gt;

I tried executing the code on Colab with Tensorflow-gpu 1.14.0 but it executed without any error. Can you try once let us know is this still an issue. Thanks!
		</comment>
		<comment id='2' author='andmax' date='2019-08-09T11:12:49Z'>
		Hi &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
  I think the problem happens when you have more than 1 GPU available in the host system and you try to select one by set_session() ConfigProto().  This works fine without the TensorBoard callback, but when I include this callback it breaks with the GPU JIT error.
		</comment>
		<comment id='3' author='andmax' date='2019-09-03T19:50:12Z'>
		Hey &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
, any update on this?  This is causing issues for users who wish to run distributed training with Horovod using  in TensorFlow 1.14.
I was able to repro by running with more than one GPU available and setting visible_device_list and adding the TensorBoard callback.
		</comment>
		<comment id='4' author='andmax' date='2019-09-24T12:14:40Z'>
		Same issue for me here. Adding the TensorBoard callback to runner 0 when running with Horovod causes the issue described here.
		</comment>
		<comment id='5' author='andmax' date='2019-10-15T07:44:18Z'>
		Same issue. tf 1.14, horovod training and running tensorboard only on rank 0.
Workaround that worked for me without disabling tensorboard, was to disable profiling on tensorboard:
keras.callbacks.TensorBoard(log_dir=logdir, profile_batch=0)
		</comment>
		<comment id='6' author='andmax' date='2019-10-15T12:04:15Z'>
		Hi &lt;denchmark-link:https://github.com/shashankprasanna&gt;@shashankprasanna&lt;/denchmark-link&gt;
  help me understand this profile_batch=0 option: does it mean the tensorboard will not follow the training (when you say "disable profiling")?  Then why should we use the tensorboard callback in the first place?  For me it seems that using profile_batch=0 is the same as not using the tensorboard callback at all.
		</comment>
		<comment id='7' author='andmax' date='2019-10-16T01:56:46Z'>
		&lt;denchmark-link:https://github.com/andmax&gt;@andmax&lt;/denchmark-link&gt;
 - I didn't need the profiling capability of tensorboard, just the performance curves and for visualizing the graph which works with this workaround. Tensorboard also offers profiling: &lt;denchmark-link:https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras&gt;TensorBoard Profile&lt;/denchmark-link&gt;
, to profile runtime of every op (traceviewer screenshots in link above). I currently don't need this.
		</comment>
		<comment id='8' author='andmax' date='2019-10-16T11:29:33Z'>
		Hi &lt;denchmark-link:https://github.com/shashankprasanna&gt;@shashankprasanna&lt;/denchmark-link&gt;
  thanks for explaining this!  Much appreciated, I also don't need this type of profiling.
		</comment>
		<comment id='9' author='andmax' date='2019-11-21T13:34:18Z'>
		This issue has been fixed in TF 1.15 and 2.0.
		</comment>
		<comment id='10' author='andmax' date='2019-11-21T13:34:38Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31451&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31451&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>