<bug id='28761' author='Liu-Da' open_date='2019-05-16T08:29:21Z' closed_time='2019-05-28T16:59:56Z'>
	<summary>Can't set an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode</summary>
	<description>
System information

Have I written custom code: No
OS Platform and Distribution: MacOS 10.14.4
TensorFlow installed from: pip install tensorflow==2.0.0-alpha0
TensorFlow version: v1.12.0-9492-g2c319fb415 2.0.0-alpha0
Python version: 3.7.3

Describe the current behavior

Get an Error when setting an initial state for the Bidirectional LSTM Layer of tf.keras 2.0 under eager execution mode

Describe the expected behavior

The code should work with eager execution mode.

Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np


hidden_units = 64
time_step = 50
vocab_size = 100
embed_size = 64
batch_size = 10

embedding = tf.keras.layers.Embedding( vocab_size, embed_size, input_length=time_step, trainable=False )
lstm =  tf.keras.layers.LSTM(hidden_units, return_sequences=False, return_state=True )
bilstm_1 =  tf.keras.layers.Bidirectional(lstm, name='bilstm1')
bilstm_2 =  tf.keras.layers.Bidirectional(lstm, name='bilstm2')
concat =  tf.keras.layers.Concatenate()
dense = tf.keras.layers.Dense(vocab_size, activation='softmax')

def mod(input_1,input_2):
    
    input_1 = embedding(input_1)
    input_2 = embedding(input_2)
    output_1, forward_h, forward_c, backward_h, backward_c = bilstm_1(input_1)
    output_2, _,_,_,_ = bilstm_2(input_2, initial_state=(forward_h, forward_c, backward_h, backward_c))
    output = dense(concat([output_1,output_2]))
    return output

input_1=np.random.randint(0,99,size=[batch_size, time_step])
input_2=np.random.randint(0,99,size=[batch_size, time_step])
target = np.random.randint(2,size=[batch_size])

#test the model
mod(input_1,input_2)

&lt;/denchmark-code&gt;

Other info / logs
The Error detailï¼š
InvalidArgumentError: Incompatible shapes: [2,256] vs. [50,256] [Op:Add] name: bilstm2/add/
	</description>
	<comments>
		<comment id='1' author='Liu-Da' date='2019-05-16T13:45:55Z'>
		&lt;denchmark-link:https://github.com/Liu-Da&gt;@Liu-Da&lt;/denchmark-link&gt;
 Able to reproduce the issue with the provided code.
		</comment>
		<comment id='2' author='Liu-Da' date='2019-05-24T17:31:38Z'>
		Thanks for reporting the issue, will send out the fix very soon.
		</comment>
		<comment id='3' author='Liu-Da' date='2019-05-28T16:57:12Z'>
		This should be fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/2a8f9b1ccfaaebd6f9cf5b5eb972c2dafded4f5e&gt;2a8f9b1&lt;/denchmark-link&gt;
 now.
		</comment>
		<comment id='4' author='Liu-Da' date='2019-05-28T16:59:58Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28761&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28761&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='Liu-Da' date='2019-07-01T09:19:07Z'>
		&lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 Same problem in the  code leads to a different issue in tf 1.14 (graph mode):
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

lstm = tf.keras.layers.LSTM(units=10)
bidirectional = tf.keras.layers.Bidirectional(lstm)

inputs = tf.placeholder(tf.float32, [32, 10, 20])
fw_state = [tf.zeros([32, 10]), tf.zeros([32, 10])]
bw_state = [tf.zeros([32, 10]), tf.zeros([32, 10])]
initial_state = fw_state + bw_state

output = bidirectional(
    inputs=inputs, initial_state=initial_state)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  ...
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/wrappers.py", line 592, in __call__
    return super(Bidirectional, self).__call__(inputs, **kwargs)
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/wrappers.py", line 629, in call
    initial_state=forward_state, **kwargs)
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py", line 2533, in call
    inputs, mask=mask, training=training, initial_state=initial_state)
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py", line 678, in call
    inputs, initial_state, constants)
  File ".../venv/tf1.14/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py", line 787, in _process_inputs
    if len(initial_state) != len(self.states):
TypeError: object of type 'Tensor' has no len()
&lt;/denchmark-code&gt;

Do you think this can be solved in tf 1.x, too, at some point?
Thanks!
		</comment>
	</comments>
</bug>