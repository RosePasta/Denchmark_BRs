<bug id='37376' author='holokai-ai' open_date='2020-03-05T23:03:18Z' closed_time='2020-05-21T22:21:56Z'>
	<summary>Hexagon Delegate not working with quantized EfficientNet Lite0</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Intrinsyc SD820 dev board
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
Python version: 3.6.9
Bazel version (if compiling from source): 1.2.1
GCC/Compiler version (if compiling from source): 7.4.0
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
The Hexagon DSP Delegate is working well on some Google hosted quantized TFLite models (e.g. MobileNets), using the benchmark_model CLI.  However, when using benchmark_model on the newly released EfficientNet Lite models from the URL below, the DSP Delegate fails to engage (0 nodes delegated):
&lt;denchmark-link:https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/lite/README.md&gt;https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/lite/README.md&lt;/denchmark-link&gt;

Example benchmark run:
&lt;denchmark-code&gt;$ adb shell benchmark_model \
   --use_hexagon=true \
   --input_layer=images \
   --input_layer_shape=1,224,224,3 \
   --graph=/sdcard/efficientnet-lite0-int8.tflite
             
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/sdcard/efficientnet-lite0-int8.tflite]
Input layers: [images]
Input shapes: [1,224,224,3]
Input value ranges: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [0]
Max profiling buffer entries: [1024]
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Loaded model efficientnet-lite0-int8.tflite
INFO: Initialized TensorFlow Lite runtime.
remote_handle_control available and used
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 0 nodes delegated out of 64 nodes.

Applied Hexagon delegate.
The input model file size (MB): 5.42276
Initialized session in 93.33ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=9 first=69875 curr=58811 min=58605 max=69875 avg=60623.8 std=3476

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=50 first=60688 curr=58755 min=58527 max=61817 avg=59263.9 std=711

Average inference timings in us: Warmup: 60623.8, Init: 93330, Inference: 59263.9
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=2.44922 overall=9.28125
&lt;/denchmark-code&gt;

At first I thought it was due to the (new?) "Quantize" node at the beginning of the EfficientNet Lite0 network, but pointing "--input_layer" to the next node doesn't help.
&lt;denchmark-link:https://user-images.githubusercontent.com/61851501/76033543-54bca580-5ef1-11ea-96df-8f8e826a6181.png&gt;&lt;/denchmark-link&gt;

Is this a DSP Delegate bug, or an issue with post-training quantization vs quantization-aware training?   If so, when can we expect TF2 quantization-aware training and/or DSP Delegate compatible EfficientNet Lite models?
Thanks
Describe the expected behavior
Majority of the 64 nodes in the EfficientNet Lite0 quantized model above should have been delegated to the DSP, and the inference time should have been much faster.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='holokai-ai' date='2020-03-05T23:38:32Z'>
		Is this model quantized using post-training quantization ? If yes, then it is not yet supported - we are working on it.
		</comment>
		<comment id='2' author='holokai-ai' date='2020-03-05T23:46:02Z'>
		Thank you for your quick reply Karim.
According to the referenced page, it does look like those EfficientNet Lite models were post-training quantized:

Each checkpoint all contains FP tflite and post-training quantized INT8 tflite files. If you use these models or checkpoints, you can cite this efficientnet paper.

Can you point me to pages showing how to do TF2 quantization-aware training myself?  Thanks!
		</comment>
		<comment id='3' author='holokai-ai' date='2020-03-06T00:09:35Z'>
		See the bottom of this page
&lt;denchmark-link:https://www.tensorflow.org/lite/convert/quantization&gt;https://www.tensorflow.org/lite/convert/quantization&lt;/denchmark-link&gt;

"During training: Quantizing models for integer-only execution."
You will also need to set
converter.experimental_new_converter=False
Let me know how it goes.
Thanks
		</comment>
		<comment id='4' author='holokai-ai' date='2020-04-13T15:31:05Z'>
		Hey &lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
 did you manage to get this to work?

Thank you for your quick reply Karim.
According to the referenced page, it does look like those EfficientNet Lite models were post-training quantized:

Each checkpoint all contains FP tflite and post-training quantized INT8 tflite files. If you use these models or checkpoints, you can cite this efficientnet paper.

Can you point me to pages showing how to do TF2 quantization-aware training myself? Thanks!

		</comment>
		<comment id='5' author='holokai-ai' date='2020-04-13T18:05:12Z'>
		Hi &lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/msalvaris&gt;@msalvaris&lt;/denchmark-link&gt;

Quick update:
We started rolling some changes for int8 (post training quantization) support. If you tried at HEAD most of efficient-net should be accelerated.
More ops to be supported soon, also more optimizations.
Please give it a try and give us some feedback.
For the Quantization aware training,
can you explain the issues you are facing.
Thanks
		</comment>
		<comment id='6' author='holokai-ai' date='2020-04-13T19:12:24Z'>
		No issues in particular so far. Just wondered if there was an example to work off since the efficientnet repo doesn't have one AFAIK.
		</comment>
		<comment id='7' author='holokai-ai' date='2020-04-14T09:17:09Z'>
		Thank you for the update on post-training quantization Karim.   Will give
it a try this week.

I got side tracked with another task, but I'm still struggling with TF2
Quantization Aware Training
&lt;&lt;denchmark-link:https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html&gt;https://blog.tensorflow.org/2020/04/quantization-aware-training-with-tensorflow-model-optimization-toolkit.html&lt;/denchmark-link&gt;
&gt;
on my own TF2 Keras model.   One of the problems is BatchNormalization,
which is used a lot in various models.   As a minimal example, if I change
the Keras model below slightly in the QAT example notebook to add
BatchNormalization
(with or without fusing), the floating point training goes fine:

&lt;denchmark-link:https://www.tensorflow.org/model_optimization/guide/quantization/training_example&gt;https://www.tensorflow.org/model_optimization/guide/quantization/training_example&lt;/denchmark-link&gt;


model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), strides=(2, 2)),
  keras.layers.BatchNormalization(fused=True),
  keras.layers.ReLU(max_value=6.0),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dropout(0.2),
  keras.layers.Dense(10, activation=tf.nn.softmax)
])


But the subsequent quantization aware training / fine tuning crashes:

Traceback (most recent call last):
  File "./quantization_aware_training_in_keras_example.py", line 133, in
&lt;module&gt;
    q_aware_model = quantize_model(model)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py",
line 138, in quantize_model
    return quantize_apply(annotated_model)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py",
line 403, in quantize_apply
    unwrapped_model, layer_quantize_map)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_layout_transform.py",
line 67, in apply
    layer_quantize_map.keys(), layer_quantize_map).transform()
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer.py",
line 552, in transform
    custom_objects)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py",
line 399, in from_config
    model.add(layer)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py",
line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py",
line 213, in add
    output_tensor = layer(self.outputs[0])
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py",
line 886, in __call__
    self.name)
  File
"/home/holokai/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py",
line 180, in assert_input_compatibility
    str(x.shape.as_list()))
ValueError: Input 0 of layer conv2d is incompatible with the layer:
expected ndim=4, found ndim=2. Full shape received: [None, 196]


Some papers talk about quantizing batch normalization, but I haven't seen a
simple example that spells out how to implement it in Keras:

   - &lt;denchmark-link:https://arxiv.org/pdf/1712.05877.pdf&gt;https://arxiv.org/pdf/1712.05877.pdf&lt;/denchmark-link&gt;

   - &lt;denchmark-link:https://arxiv.org/pdf/1806.08342.pdf&gt;https://arxiv.org/pdf/1806.08342.pdf&lt;/denchmark-link&gt;


I've tried upgrading to tensorflow2.2.0rc3 as well as tf-nightly to no
avail.   I'm using tensorflow-model-optimization 0.3.0.

Thank you for any pointers
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Apr 13, 2020 at 11:05 AM Karim Nosseir ***@***.***&gt; wrote:
 Hi @holokai-ai &lt;https://github.com/holokai-ai&gt; , @msalvaris
 &lt;https://github.com/msalvaris&gt;

 Quick update:
 We started rolling some changes for int8 (post training quantization)
 support. If you tried at HEAD most of efficient-net should be accelerated.
 More ops to be supported soon, also more optimizations.
 Please give it a try and give us some feedback.

 For the Quantization aware training,
 can you explain the issues you are facing.

 Thanks

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#37376 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AOX4O3OVMTAG5BYCGSYTVB3RMNH65ANCNFSM4LCUGW6Q&gt;
 .



		</comment>
		<comment id='8' author='holokai-ai' date='2020-04-15T23:42:11Z'>
		Thanks again for the tip that the QCOM DSP Delegate now supports post-training quantization.
I recompiled benchmark_model from HEAD, and now the post-training quantized EfficientNet Lite0 model runs on DSP!
&lt;denchmark-code&gt;$ adb shell benchmark_model \
     --use_hexagon=true \
     --input_layer=images \
     --input_layer_shape=1,224,224,3 \
     --graph=/data/local/tmp/efficientnet-lite0-int8.tflite

STARTING!
Duplicate flags: num_threads
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/efficientnet-lite0-int8.tflite]
Input layers: [images]
Input shapes: [1,224,224,3]
Input value ranges: []
Input layer values files: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [1]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Enable platform-wide tracing: [0]
#threads used for CPU inference: [1]
Max number of delegated partitions : [0]
External delegate path : []
External delegate options : []
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Use xnnpack : [0]
Loaded model /data/local/tmp/efficientnet-lite0-int8.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 61 nodes delegated out of 64 nodes with 2 partitions.

loaded libadsprpc.so
Applied Hexagon delegate, and the model graph will be partially executed w/ the delegate.
The input model file size (MB): 5.42276
Initialized session in 402.08ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=36 first=17729 curr=13808 min=13748 max=17729 avg=13940.5 std=641

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=72 first=13889 curr=13840 min=13746 max=13946 avg=13847.2 std=44

Inference timings in us: Init: 402080, First inference: 17729, Warmup (avg): 13940.5, Inference (avg): 13847.2
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=13.0703 overall=13.0703
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	 ModifyGraphWithDelegate	            0.000	  147.622	  147.622	 69.490%	 69.490%	 11108.000	        1	ModifyGraphWithDelegate/0
	         AllocateTensors	          115.380	   64.782	   32.407	 30.510%	100.000%	     0.000	        2	AllocateTensors/0

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	 ModifyGraphWithDelegate	            0.000	  147.622	  147.622	 69.490%	 69.490%	 11108.000	        1	ModifyGraphWithDelegate/0
	         AllocateTensors	          115.380	   64.782	   32.407	 30.510%	100.000%	     0.000	        2	AllocateTensors/0

Number of nodes executed: 2
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	 ModifyGraphWithDelegate	        1	   147.622	    69.490%	    69.490%	 11108.000	        1
	         AllocateTensors	        1	    64.815	    30.510%	   100.000%	     0.000	        2

Timings (microseconds): count=1 curr=212437
Memory (bytes): count=0
2 nodes observed



Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                QUANTIZE	            0.000	    0.158	    0.157	  1.134%	  1.134%	     0.000	        1	[images_int8]:0
	   TfLiteHexagonDelegate	            0.158	   13.088	   13.066	 94.409%	 95.543%	     0.000	        1	[efficientnet-lite0/model/head/AvgPool]:64
	                 RESHAPE	           13.226	    0.004	    0.002	  0.016%	 95.560%	     0.000	        1	[efficientnet-lite0/model/head/Squeeze1]:60
	   TfLiteHexagonDelegate	           13.229	    0.626	    0.610	  4.409%	 99.969%	     0.000	        1	[Softmax_int8]:65
	                QUANTIZE	           13.840	    0.004	    0.004	  0.031%	100.000%	     0.000	        1	[Softmax]:63

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	   TfLiteHexagonDelegate	            0.158	   13.088	   13.066	 94.409%	 94.409%	     0.000	        1	[efficientnet-lite0/model/head/AvgPool]:64
	   TfLiteHexagonDelegate	           13.229	    0.626	    0.610	  4.409%	 98.819%	     0.000	        1	[Softmax_int8]:65
	                QUANTIZE	            0.000	    0.158	    0.157	  1.134%	 99.953%	     0.000	        1	[images_int8]:0
	                QUANTIZE	           13.840	    0.004	    0.004	  0.031%	 99.984%	     0.000	        1	[Softmax]:63
	                 RESHAPE	           13.226	    0.004	    0.002	  0.016%	100.000%	     0.000	        1	[efficientnet-lite0/model/head/Squeeze1]:60

Number of nodes executed: 5
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	   TfLiteHexagonDelegate	        2	    13.676	    98.829%	    98.829%	     0.000	        2
	                QUANTIZE	        2	     0.160	     1.156%	    99.986%	     0.000	        2
	                 RESHAPE	        1	     0.002	     0.014%	   100.000%	     0.000	        1

Timings (microseconds): count=72 first=13880 curr=13834 min=13740 max=13938 avg=13840.2 std=44
Memory (bytes): count=0
5 nodes observed
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='holokai-ai' date='2020-04-16T01:57:00Z'>
		&lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 Can you check the crash from the QAT.
&lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
 Glad it is working, BTW reshape is added now, if you retried you should have 1 hexagon graph, and should be slight faster.
We are working on optimizing few parts too, so stay tuned :)
Thanks
		</comment>
		<comment id='10' author='holokai-ai' date='2020-04-16T22:30:30Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Sure enough, after I recompiled from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/ac271534b897ea2bb78a865971823f814b0151e1&gt;ac27153&lt;/denchmark-link&gt;
, RESHAPE is folded in and there's only one DSP Delegate graph now.
Will post-training quantization support for Hexagon Delegate be part of TF 2.2.0 ?   Right now I don't see the relevant commits in r2.2.   The last commit in the Hexagon Delegate for r2.2 is from Feb 27.
Thanks!
&lt;denchmark-code&gt;$ adb shell benchmark_model \
     --use_hexagon=true \
     --input_layer=images \
     --input_layer_shape=1,224,224,3 \
     --graph=/data/local/tmp/efficientnet-lite0-int8.tflite
...
...
Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	                QUANTIZE	            0.000	    0.165	    0.164	  1.197%	  1.197%	     0.000	        1	[images_int8]:0
	   TfLiteHexagonDelegate	            0.165	   13.573	   13.509	 98.753%	 99.949%	     0.000	        1	[Softmax_int8]:64
	                QUANTIZE	           13.676	    0.007	    0.007	  0.051%	100.000%	     0.000	        1	[Softmax]:63

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	   TfLiteHexagonDelegate	            0.165	   13.573	   13.509	 98.753%	 98.753%	     0.000	        1	[Softmax_int8]:64
	                QUANTIZE	            0.000	    0.165	    0.164	  1.197%	 99.949%	     0.000	        1	[images_int8]:0
	                QUANTIZE	           13.676	    0.007	    0.007	  0.051%	100.000%	     0.000	        1	[Softmax]:63

Number of nodes executed: 3
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	   TfLiteHexagonDelegate	        1	    13.509	    98.764%	    98.764%	     0.000	        1
	                QUANTIZE	        2	     0.169	     1.236%	   100.000%	     0.000	        2

Timings (microseconds): count=73 first=13745 curr=13616 min=13528 max=13861 avg=13679.8 std=86
Memory (bytes): count=0
3 nodes observed
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='holokai-ai' date='2020-04-18T16:35:08Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 I am unable to do quantization aware training for EfficientNet. If I tried  using the recent Keras API but it doesn't work as there is only support for Sequential and Functional models not custom it seems.
If I try to use tf.contrib.quantize it seems to skip quantizing quite a few ops.
Please advise as to what would be the best way to carry out quantization aware training of EfficienetNet model.
		</comment>
		<comment id='12' author='holokai-ai' date='2020-04-19T00:28:50Z'>
		&lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/msalvaris&gt;@msalvaris&lt;/denchmark-link&gt;
  I'm guilty of starting the TF2 QAT question here, but perhaps we should move it to the TFMOT project?   Someone just posted a similar question here:
&lt;denchmark-link:https://github.com/tensorflow/model-optimization/issues/363&gt;tensorflow/model-optimization#363&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='holokai-ai' date='2020-04-19T16:50:28Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 I've been able to run all of Google's post-training quantized EfficientNet Lite models on the Snapdragon 820 DSP using the Hexagon Delegate, except for EfficientNet Lite3.   Running that INT8 model causes a segfault, even though it appears it successfully delegated most of the nodes.  Lite0, Lite1, Lite2 and Lite4 run fine on the DSP Delegate, but not Lite3.  The EfficientNet Lite3 FP32 model runs find on the GPU Delegate.
&lt;denchmark-code&gt;$ adb shell benchmark_model \
    --use_hexagon=true \
    --input_layer=images \
    --input_layer_shape=1,280,280,3 \
    --graph=/data/local/tmp/efficientnet-lite3-int8.tflite

STARTING!
Duplicate flags: num_threads
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [efficientnet-lite3-int8.tflite]
Input layers: [images]
Input shapes: [1,280,280,3]
Input value ranges: []
Input layer values files: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [1]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Enable platform-wide tracing: [0]
#threads used for CPU inference: [1]
Max number of delegated partitions : [0]
External delegate path : []
External delegate options : []
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Use xnnpack : [0]
Loaded model efficientnet-lite3-int8.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libadsprpc.so
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 94 nodes delegated out of 96 nodes with 1 partitions.

Applied Hexagon delegate, and the model graph will be partially executed w/ the delegate.
The input model file size (MB): 9.58559
Initialized session in 510.615ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
Segmentation fault 

&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='holokai-ai' date='2020-04-20T09:49:03Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Now I'm trying my custom model based on EfficientNet Lite0.  Its input image shape is 224,224,1 (grayscale).   The original FP32 trained model runs fine on SD820 CPU as well as GPU (using GPU Delegate).  Next, I used post-training quantization described below to generate an INT8 model:
&lt;denchmark-link:https://www.tensorflow.org/lite/performance/post_training_integer_quant&gt;https://www.tensorflow.org/lite/performance/post_training_integer_quant&lt;/denchmark-link&gt;

I've tried the TFLiteConverter flags DEFAULT as well as OPTIMIZE_FOR_SIZE and gave it some sample images; results are the same.  The resulting INT8 model is about 4x smaller than the FP32 model (as expected) and runs fine on SD820 CPU, but crashes when I try to run on DSP, even though the majority of nodes were successfully delegated.  Excerpt below.
What am I doing wrong?   Thanks for any pointers.
&lt;denchmark-code&gt;$ adb shell benchmark_model \
  --use_hexagon=true \
  --input_layer=images \
  --input_layer_shape=1,224,224,1 \
  --graph=/data/local/tmp/int8.tflite

STARTING!
Duplicate flags: num_threads
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/int8.tflite]
Input layers: [images]
Input shapes: [1,224,224,1]
Input value ranges: []
Input layer values files: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [1]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Enable platform-wide tracing: [0]
#threads used for CPU inference: [1]
Max number of delegated partitions : [0]
External delegate path : []
External delegate options : []
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Use xnnpack : [0]
Loaded model /data/local/tmp/int8.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 59 nodes delegated out of 64 nodes with 2 partitions.

loaded libadsprpc.so
Applied Hexagon delegate, and the model graph will be partially executed w/ the delegate.
The input model file size (MB): 3.69867
Initialized session in 357.232ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
----------------
Timestamp: Sun Jan  4 02:40:23 1970


Log
hexagon/ops/src/op_requantize.c:437:Requantize_8to8: Out range too small compared to in range!
hexagon/src/execute.c:142:execute() failed on node id=af err=-1
hexagon/src/interface.c:1174:fail in execute_inner()

----------------
ERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH
ERROR: Node number 64 (TfLiteHexagonDelegate) failed to invoke.

----------------
Timestamp: Sun Jan  4 02:40:23 1970


Log
hexagon/ops/src/op_requantize.c:437:Requantize_8to8: Out range too small compared to in range!
hexagon/src/execute.c:142:execute() failed on node id=af err=-1
hexagon/src/interface.c:1174:fail in execute_inner()

----------------
ERROR: Failed: Failed to execute graph.. STATE: FAILED_TO_EXECUTE_GRAPH
ERROR: Node number 64 (TfLiteHexagonDelegate) failed to invoke.

----------------
&lt;Same sets of error log lines above repeated many times&gt;
...
...


count=24 first=24384 curr=21268 min=20516 max=24384 avg=21053.6 std=722

Benchmarking failed.

&lt;/denchmark-code&gt;

		</comment>
		<comment id='15' author='holokai-ai' date='2020-04-20T18:36:08Z'>
		&lt;denchmark-link:https://github.com/msalvaris&gt;@msalvaris&lt;/denchmark-link&gt;
 Can you try the instructions i sent earlier for the uint8 per tensor, not the new QAT API.
&lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;



For the 2.2: It is finalized, so we can't add more changes. Also, currently AARs are only available in nightlies. We are working on stable releases for the AARs.


For the efficientnet lite 3
I tried this https://tfhub.dev/tensorflow/lite-model/efficientnet/lite3/int8/1
and works fine.
Can you point me which one you tried ?


For the requantize issue:
We saw a similar issue before, it happens when you have input min/max is too big compared to output min/max. We solved by using 32 bit MULs instead.
With efficientNet i think there was a similar case with one DepthwiseConv range are too big compared -128/127, and you can tune by tweaking your model.
Do you mind sharing the model privately, i am happy to have a look, my guess will be the same issue, and you can tweak the model to avoid the quantization creating this big ranges.


Thanks
		</comment>
		<comment id='16' author='holokai-ai' date='2020-04-20T21:50:17Z'>
		
For the 2.2: It is finalized, so we can't add more changes. Also, currently AARs are only available in nightlies. We are working on stable releases for the AARs.

OK thank you for the clarification!
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;


For the efficientnet lite 3
I tried this https://tfhub.dev/tensorflow/lite-model/efficientnet/lite3/int8/1
and works fine.
Can you point me which one you tried ?

Here's the EfficientNet Lite3 version I used, because TFHub version does not yet allow for fine tuning under TF2 for some reason:
&lt;denchmark-link:https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite&gt;https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite&lt;/denchmark-link&gt;

&lt;denchmark-link:https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/lite/efficientnet-lite3.tar.gz&gt;https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/lite/efficientnet-lite3.tar.gz&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;$ sha1sum efficientnet-lite3-int8.tflite 
f0b94fc6725398bdd775ada491c8457215aa9dd4  efficientnet-lite3-int8.tflite
&lt;/denchmark-code&gt;

This INT8 model works fine on SD820 SOC CPU:
&lt;denchmark-code&gt;$ adb shell benchmark_model \
    --input_layer=images \
    --input_layer_shape=1,280,280,3 \
    --graph=/data/local/tmp/efficientnet-lite3-int8.tflite
...
...
Number of nodes executed: 96
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	                 CONV_2D	       49	   194.236	    80.390%	    80.390%	     0.000	       49
	       DEPTHWISE_CONV_2D	       24	    44.783	    18.535%	    98.924%	     0.000	       24
	                     ADD	       17	     1.752	     0.725%	    99.649%	     0.000	       17
	         FULLY_CONNECTED	        1	     0.513	     0.212%	    99.862%	     0.000	        1
	                QUANTIZE	        2	     0.256	     0.106%	    99.968%	     0.000	        2
	         AVERAGE_POOL_2D	        1	     0.066	     0.027%	    99.995%	     0.000	        1
	                 SOFTMAX	        1	     0.010	     0.004%	    99.999%	     0.000	        1
	                 RESHAPE	        1	     0.002	     0.001%	   100.000%	     0.000	        1

Timings (microseconds): count=50 first=191312 curr=487173 min=190214 max=712336 avg=241662 std=113426
Memory (bytes): count=0
96 nodes observed
&lt;/denchmark-code&gt;

But segfaults on the SD820 SOC DSP:
&lt;denchmark-code&gt;$ adb shell benchmark_model \
    --use_hexagon=true \
    --input_layer=images \
    --input_layer_shape=1,280,280,3 \
    --graph=/data/local/tmp/efficientnet-lite3-int8.tflite
...
...
Loaded model /data/local/tmp/efficientnet-lite3-int8.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 94 nodes delegated out of 96 nodes with 1 partitions.

loaded libadsprpc.so
Applied Hexagon delegate, and the model graph will be partially executed w/ the delegate.
The input model file size (MB): 9.58559
Initialized session in 504.5ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
Segmentation fault 
&lt;/denchmark-code&gt;

I don't think it's a resource issue (e.g. OOM) because the larger efficientnet-lite4-int8.tflite model runs fine on DSP.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;


For the requantize issue:
We saw a similar issue before, it happens when you have input min/max is too big compared to output min/max. We solved by using 32 bit MULs instead.
With efficientNet i think there was a similar case with one DepthwiseConv range are too big compared -128/127, and you can tune by tweaking your model.
Do you mind sharing the model privately, i am happy to have a look, my guess will be the same issue, and you can tweak the model to avoid the quantization creating this big ranges.

OK will do.  Thank you!
		</comment>
		<comment id='17' author='holokai-ai' date='2020-04-21T02:18:10Z'>
		&lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
 I don't have device with 820, but i have Pixel 1 which has 821 and both should use the Hexagon v60.
I tried it and it works fine.
Also tried it on Samsung S9 which has 845
Can you share the logcat of the run
Dump from the run below:
INFO: Initialized TensorFlow Lite runtime.
Func remote_handle64_open not available on this device (NULL).
Func remote_handle64_invoke not available on this device (NULL).
Func remote_handle64_close not available on this device (NULL).
Func remote_handle_control not available on this device (NULL).
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 96 nodes delegated out of 96 nodes with 1 partitions.
loaded libadsprpc.so
Applied Hexagon delegate, and the model graph will be completely executed w/ the delegate.
The input model file size (MB): 9.58559
Initialized session in 1182.01ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=12 first=105922 curr=35738 min=35322 max=105922 avg=41632.8 std=19406
Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=50 first=35693 curr=35259 min=35211 max=37337 avg=35585.2 std=401
Inference timings in us: Init: 1182010, First inference: 105922, Warmup (avg): 41632.8, Inference (avg): 35585.2
		</comment>
		<comment id='18' author='holokai-ai' date='2020-04-21T05:16:45Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Thanks for taking the time to look into this issue.  I mentioned a SD820 dev board, but it actually has a 821 SOC (aka APQ8096pro).  Perhaps it's the difference between Android 9 and 10?  We're unfortunately stuck at Android 9.   SOM vendor says they can't upgrade the SOM to Android 10 due to QCOM, even though essentially the same SOC is on the Pixel 1 running Android 10.
I'm wondering if that's the reason why your target hardware delegates all 96 nodes, but my hardware only delegates 94 nodes?
&lt;denchmark-code&gt;$ adb shell grep ^Hard /proc/cpuinfo
Hardware	: Qualcomm Technologies, Inc APQ8096pro

$ adb shell getprop ro.build.fingerprint
Android/msm8996/msm8996:9/OpenQ820_P_v5.0-PKQ1.181007.001/12:userdebug/test-keys

$ adb shell sha1sum /data/local/tmp/lib*.so
46425e69ef93b4479ac0caabfcfa3e556444ac89  /data/local/tmp/libhexagon_interface.so
f9809aebb6fa4d52d81e6bb2036120849face179  /data/local/tmp/libhexagon_nn_skel.so
cc8ce9a338eb30c42f9b23647fc43bf8c0bddf0d  /data/local/tmp/libhexagon_nn_skel_v65.so
c7ef0ae4234df8f29bf7eca0e82d5e499c23cfbc  /data/local/tmp/libhexagon_nn_skel_v66.so
&lt;/denchmark-code&gt;

Logcat excerpt taken immediately after segfault:
&lt;denchmark-code&gt;--------- beginning of main
01-04 22:28:20.668   990  1015 I chatty  : uid=1021(gps) NDK expire 2 lines
01-04 22:28:34.690   990  1015 W ServiceManagement: Waited one second for android.frameworks.sensorservice@1.0::ISensorManager/default. Waiting another...
01-04 22:28:35.517 14024 14024 I tflite  : Initialized TensorFlow Lite runtime.
01-04 22:28:35.601 14024 14024 V benchmark_model: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1859: Successfully created user PD on domain 0 (attrs 0x0)
01-04 22:28:35.605 14024 14027 V benchmark_model: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:270: rpc latency thread start
01-04 22:28:35.690   990  1015 W ServiceManagement: Waited one second for android.frameworks.sensorservice@1.0::ISensorManager/default. Waiting another...
01-04 22:28:35.776 14024 14024 I tflite  : Created TensorFlow Lite delegate for Hexagon.
01-04 22:28:35.778 14024 14024 I tflite  : Hexagon delegate: 94 nodes delegated out of 96 nodes with 1 partitions.
--------- beginning of crash
01-04 22:28:36.032 14024 14024 F libc    : Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0 in tid 14024 (benchmark_model), pid 14024 (benchmark_model)
01-04 22:28:36.060 14030 14030 I crash_dump64: obtaining output fd from tombstoned, type: kDebuggerdTombstone
01-04 22:28:36.061  1047  1047 I /system/bin/tombstoned: received crash request for pid 14024
01-04 22:28:36.061 14030 14030 I crash_dump64: performing dump of process 14024 (target tid = 14024)
01-04 22:28:36.062 14030 14030 F DEBUG   : *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
01-04 22:28:36.063 14030 14030 F DEBUG   : Build fingerprint: 'Android/msm8996/msm8996:9/OpenQ820_P_v5.0-PKQ1.181007.001/12:userdebug/test-keys'
01-04 22:28:36.063 14030 14030 F DEBUG   : Revision: '0'
01-04 22:28:36.063 14030 14030 F DEBUG   : ABI: 'arm64'
01-04 22:28:36.063 14030 14030 F DEBUG   : pid: 14024, tid: 14024, name: benchmark_model  &gt;&gt;&gt; benchmark_model &lt;&lt;&lt;
01-04 22:28:36.063 14030 14030 F DEBUG   : signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0
01-04 22:28:36.063 14030 14030 F DEBUG   : Cause: null pointer dereference
01-04 22:28:36.063 14030 14030 F DEBUG   :     x0  0000000000000118  x1  0000000000000118  x2  0000000000000003  x3  0000000000000118
01-04 22:28:36.063 14030 14030 F DEBUG   :     x4  0000000000000070  x5  0000000020000000  x6  ffffffffc0000001  x7  000000007fffffff
01-04 22:28:36.063 14030 14030 F DEBUG   :     x8  00000077f61d3bc8  x9  00000077f4b5f780  x10 0000000000000002  x11 00000000000396c0
01-04 22:28:36.063 14030 14030 F DEBUG   :     x12 0000000000000082  x13 0000000000000000  x14 0000000000000000  x15 00000000000396b0
01-04 22:28:36.063 14030 14030 F DEBUG   :     x16 00000000fffffffe  x17 0000000000000001  x18 00000077f6200080  x19 00000077f606d028
01-04 22:28:36.063 14030 14030 F DEBUG   :     x20 00000000000000ff  x21 00000077f61c3580  x22 0000000000000000  x23 00000077f60b7500
01-04 22:28:36.063 14030 14030 F DEBUG   :     x24 0000000000000000  x25 00000077f61c3590  x26 00000077f75ca5e0  x27 00000077f60b7500
01-04 22:28:36.063 14030 14030 F DEBUG   :     x28 0000000040000000  x29 0000007fe7b3d870
01-04 22:28:36.063 14030 14030 F DEBUG   :     sp  0000007fe7b3d7d0  lr  00000056f01833d4  pc  00000056f030a778
01-04 22:28:36.064 14030 14030 F DEBUG   : 
01-04 22:28:36.064 14030 14030 F DEBUG   : backtrace:
01-04 22:28:36.064 14030 14030 F DEBUG   :     #00 pc 000000000031f778  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #01 pc 00000000001983d0  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #02 pc 000000000019b984  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #03 pc 00000000000540a8  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #04 pc 0000000000054a84  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #05 pc 000000000005463c  /system/xbin/benchmark_model
01-04 22:28:36.064 14030 14030 F DEBUG   :     #06 pc 0000000000040a78  /system/xbin/benchmark_model
01-04 22:28:36.065 14030 14030 F DEBUG   :     #07 pc 00000000000d4e54  /system/lib64/libc.so (__libc_init+88)
01-04 22:28:36.117 14030 14030 E crash_dump64: unable to connect to activity manager: Connection refused
01-04 22:28:36.118  1047  1047 E /system/bin/tombstoned: Tombstone written to: /data/tombstones/tombstone_48
01-04 22:28:36.690   990  1015 W ServiceManagement: Waited one second for android.frameworks.sensorservice@1.0::ISensorManager/default. Waiting another...
--------- beginning of system

&lt;/denchmark-code&gt;

I'm at a loss to explain why only Lite3 causes a segfault ...
Thank you
		</comment>
		<comment id='19' author='holokai-ai' date='2020-04-21T08:26:52Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 I tried doing the quantization aware training that is mentioned in the link you shared. It basically links here &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/r1.15/tensorflow/contrib/quantize&gt;https://github.com/tensorflow/tensorflow/tree/r1.15/tensorflow/contrib/quantize&lt;/denchmark-link&gt;

I added the tf.contrib.quantize.create_training_graph and tf.contrib.quantize.create_eval_graph
I am using these within the estimator API and version 15.2 of TF
During training I get
after efficientnet-lite0/model/blocks_13/Add_1           [2020-04-21 08:03:38,183][tensorflow][INFO] - Inserting fake quant op activation_Add_quant after efficientnet-lite0/model/blocks_14/Add_1                 [2020-04-21 08:03:38,215][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/stem/conv2d/add_fold                              [2020-04-21 08:03:38,215][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_0/depthwise_conv2d/add_fold              [2020-04-21 08:03:38,216][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_1/conv2d/add_fold                              [2020-04-21 08:03:38,216][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_1/depthwise_conv2d/add_fold                      [2020-04-21 08:03:38,217][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_2/conv2d/add_fold           [2020-04-21 08:03:38,217][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_2/depthwise_conv2d/add_fold [2020-04-21 08:03:38,218][tensorflow][INFO] - Skipping quant after efficientnet-lite0/model/blocks_3/conv2d/add_fold 
But it does seem to work.
In the validation though it seems to fail with
[2020-04-21 08:09:49,644][tensorflow][INFO] - Restoring parameters from output/model.ckpt-200                                                     2020-04-21 08:09:50.325225: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key efficientnet -lite0/model/blocks_10/post_activation_bypass_quant/max not found in checkpoint   
Not sure whether this is simply an error in the quantization or something else.
		</comment>
		<comment id='20' author='holokai-ai' date='2020-04-22T04:31:32Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 I believe I've fixed the issue of post-training quantization generating errors.   I had inadvertently converted a model that I was using for TF2 QAT, where I had commented out BatchNormalization (because TF2 QAT is apparently not able to handle BatchNormalization yet).   This caused low accuracy even after many epochs, which I suspect made the weights/activations to grow large.
When I put the BatchNormalization back into the model, things converged much more quickly, with higher accuracy.   I was able to quantize that model using post-training quantization without the errors.  The resulting INT8 model ran fine on the SD820 DSP.
Sorry for the false alarm on this post-training quantization issue.
Still hoping to eventually do TF2 QAT for better accuracy, but that's not really a DSP Delegate issue.   Cheers.
&lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 Have you been able to look into the TF2 QAT issue?  Thank you.
		</comment>
		<comment id='21' author='holokai-ai' date='2020-04-22T04:45:24Z'>
		&lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
 Finally reproduced the crash and have a fix, will be merged by tomorrow hopefully.
I will update you when it is merged, so you can retry. Sorry for the trouble.
For the number of nodes difference, it's because we added support for Quantize op recently (i was using HEAD and i assume you were using older branch).
Glad to know it is working now.
Thanks
&lt;denchmark-link:https://github.com/msalvaris&gt;@msalvaris&lt;/denchmark-link&gt;

I am confused with your state now,
if you want to run a quantized model which was quantized using post training quantization then it is supported now, no need to try to use the old uint8 quantization.
Just use nightly, and the int8 versions of efficientnet and other int8 models should work.
If you're having issues with some new model using new QAT API, it will be good to summarize so &lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 can help you.
Thanks
		</comment>
		<comment id='22' author='holokai-ai' date='2020-04-22T04:49:37Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Awesome!   Thank you very much for the quick fix on the EfficientNet Lite3 DSP Delegate crash issue.  Cheers!
		</comment>
		<comment id='23' author='holokai-ai' date='2020-04-22T10:24:09Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;

Sorry for the confusion. I have been able to use post-training quantization which is great but two issues remain:

The drop in accuracy is unacceptable for my use case so wanted to use quantization aware training to try and improve matters
The delegate I am using currently supports uint8 and per tensor quantization, the new spec is int8 and per axis quantization for ops like convolution etc.

It seems I can't use efficientnet with the old quantization aware training and can't use the new keras based one as it only supports sequence and functional models.
If any of the above is incorrect please let me know
		</comment>
		<comment id='24' author='holokai-ai' date='2020-04-24T04:53:29Z'>
		&lt;denchmark-link:https://github.com/msalvaris&gt;@msalvaris&lt;/denchmark-link&gt;
 for # 1 &lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 can help you. For # 2 please try to use nightly the delegate now supports per channel quantization.
&lt;denchmark-link:https://github.com/holokai-ai&gt;@holokai-ai&lt;/denchmark-link&gt;
  Should be fixed now, please retry.
Thanks
		</comment>
		<comment id='25' author='holokai-ai' date='2020-04-24T07:28:47Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
 Yes, I recompiled benchmark_model with the latest fix and INT8 EfficientNet Lite3 no longer causes a segfault.   Thank you for the quick fix!
		</comment>
		<comment id='26' author='holokai-ai' date='2020-04-24T10:01:57Z'>
		Thanks &lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;
!
&lt;denchmark-link:https://github.com/nutsiepully&gt;@nutsiepully&lt;/denchmark-link&gt;
 Any recommendations?
		</comment>
		<comment id='27' author='holokai-ai' date='2020-05-21T22:21:56Z'>
		I am going to close this issue, since the main part about EfficientNet is now resolved.
For the QAT issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/38939&gt;#38939&lt;/denchmark-link&gt;
 looks like tracking it.
Please feel free to reopen or create new issue if you are having problems.
Thanks
		</comment>
		<comment id='28' author='holokai-ai' date='2020-05-21T22:21:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37376&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37376&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>