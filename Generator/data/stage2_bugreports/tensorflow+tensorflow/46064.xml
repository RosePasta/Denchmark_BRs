<bug id='46064' author='shkarupa-alex' open_date='2020-12-30T07:13:54Z' closed_time='2021-01-22T06:12:01Z'>
	<summary>Wrong casting (mixed precision) in attention layers</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): Google Colab
TensorFlow version (use command below): v2.4.0-0-g582c8d236cb 2.4.0
Python version: 3
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): No
CUDA/cuDNN version: No
GPU model and memory: No

Describe the current behavior
When using Attention or AdditiveAttention with mixed precision policy issue occurred due to wrong casting (mask casted to floatx but should be casted to scores.dtype)
Describe the expected behavior
Layers should work without issues with mixed_fp16

&lt;denchmark-link:https://colab.research.google.com/drive/1R2MKXAIrmYBBGkij11m9aG7hLm2AEHjF?usp=sharing&gt;https://colab.research.google.com/drive/1R2MKXAIrmYBBGkij11m9aG7hLm2AEHjF?usp=sharing&lt;/denchmark-link&gt;

 Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The issue comes from here &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/dense_attention.py#L129&gt;https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/dense_attention.py#L129&lt;/denchmark-link&gt;

Should be this:
scores -= 1.e9 * math_ops.cast(padding_mask, dtype=scores.dtype)
	</description>
	<comments>
		<comment id='1' author='shkarupa-alex' date='2020-12-30T09:06:13Z'>
		I have tried in colab with TF version 2.4, Nightly version() and was able to reproduce the issue. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/7b6b6b54fbf4b7df517cb537b726e371/untitled588.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='shkarupa-alex' date='2021-01-10T19:10:36Z'>
		Added a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/46321&gt;#46321&lt;/denchmark-link&gt;
 for the fix.
		</comment>
		<comment id='3' author='shkarupa-alex' date='2021-01-22T06:12:03Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46064&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46064&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>