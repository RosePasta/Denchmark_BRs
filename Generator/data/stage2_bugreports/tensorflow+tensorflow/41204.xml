<bug id='41204' author='konstantin-doncov' open_date='2020-07-08T16:01:14Z' closed_time='2020-09-18T04:41:13Z'>
	<summary>"Tensor is unhashable" and "too many values to unpack" with transformers</summary>
	<description>
System information:

OS: Ubuntu 20.04;
Tensorflow: v2.2.0-rc4-8-g2b96f3662b 2.2.0. Installed used pip3;
Tensorflow-gpu: 2.2.0. Installed used pip3;
Python: 3.8.2;
CUDA Version: 10.2;
cuDNN: 7.6.5;
GPU: GeForce GTX 1050 Ti;


I have successfully installed  and used it for a while. But now I want to use &lt;denchmark-link:https://github.com/huggingface/transformers&gt;transformers&lt;/denchmark-link&gt;
 and I started getting problems, here is &lt;denchmark-link:https://github.com/huggingface/transformers/issues/5555&gt;my previous issues report&lt;/denchmark-link&gt;
. But now I think that some of them are more related to the  then to the .
Here is my code:
&lt;denchmark-code&gt;df = pd.DataFrame({'text': ['SOME ANGRY TEXT!!!', 'Some friendly text :)'], 'label': [1, 0]})

def create_model():
    bert_model = transformers.TFBertModel.from_pretrained("bert-base-cased")
    
    input_ids = tf.keras.layers.Input(shape=(10,), dtype=tf.int32, name='input_ids')
    token_type_ids = tf.keras.layers.Input((10,), dtype=tf.int32, name='token_type_ids')
    attention_mask = tf.keras.layers.Input((10,), dtype=tf.int32, name='attention_mask')
    
    # Use pooled_output(hidden states of [CLS]) as sentence level embedding
    pooled_output = bert_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})[1]
    x = tf.keras.layers.Dropout(rate=0.1)(pooled_output)
    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    model = tf.keras.models.Model(inputs={'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids}, outputs=x)
    return model

bert_model = create_model()
bert_tokenizer = transformers.BertTokenizer.from_pretrained("bert-base-cased")

x = bert_tokenizer.batch_encode_plus(
    df.text.values,
    max_length=10,
    pad_to_max_length=True, 
    return_tensors='tf'
)

bert_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['Accuracy'])

bert_history = bert_model.fit(
    x=x,
    y=df.label.values
)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __hash__(self)
    724     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and
    725         (g is None or g.building_function)):
--&gt; 726       raise TypeError("Tensor is unhashable. "
    727                       "Instead, use tensor.ref() as the key.")
    728     else:

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
&lt;/denchmark-code&gt;

After that I just tried to use &lt;denchmark-link:https://www.kaggle.com/definedennis/pretrained-bert-with-huggingface-tensorflow-2-1/output&gt;this working Kaggle notebook&lt;/denchmark-link&gt;
(it's working because it has output genarated on the Kaggle side,  - &lt;denchmark-link:https://www.kaggle.com/c/nlp-getting-started/data&gt;file from here&lt;/denchmark-link&gt;
):
&lt;denchmark-code&gt;# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tqdm.notebook import tqdm

import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.backend as K
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
from transformers import (
    BertTokenizer,
    TFBertForSequenceClassification,
    TFBertModel,
    BertConfig,
)
tf.__version__

MAX_SEQUENCE_LENGTH = 255
PRETRAINED_MODEL_NAME = 'bert-base-uncased'
BATCH_SIZE = 32

df = pd.read_csv('train.csv')

df.head()

df['target'].value_counts()

df.isnull().sum()

data = df['text'].values
targets = df['target'].values

def create_model():
    bert_model = TFBertModel.from_pretrained(PRETRAINED_MODEL_NAME)
    
    input_ids = layers.Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')
    token_type_ids = layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='token_type_ids')
    attention_mask = layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='attention_mask')
    
    # Use pooled_output(hidden states of [CLS]) as sentence level embedding
    pooled_output = bert_model({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids})[1]
    x = layers.Dropout(rate=0.1)(pooled_output)
    x = layers.Dense(1, activation='sigmoid')(x)
    model = keras.models.Model(inputs={'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_type_ids}, outputs=x)
    return model

tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)
model = create_model()

model.summary()

plot_model(model, to_file='model.png', expand_nested=True, show_shapes=True)

opt = tf.keras.optimizers.Adam(learning_rate=3e-5)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

X_train, X_val, y_train, y_val = train_test_split(data, targets, test_size=0.33, random_state=42, stratify=targets)

X_train = tokenizer.batch_encode_plus(X_train, max_length=MAX_SEQUENCE_LENGTH, pad_to_max_length=True, return_tensors='tf')
X_val = tokenizer.batch_encode_plus(X_val, max_length=MAX_SEQUENCE_LENGTH, pad_to_max_length=True, return_tensors='tf')

history = model.fit(
    x=X_train,
    y=y_train,
    validation_data=(X_val, y_val),
    epochs=3,
    batch_size=BATCH_SIZE
)
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;/usr/lib/python3.8/_collections_abc.py in update(self, other, **kwds)
    835                 self[key] = other[key]
    836         else:
--&gt; 837             for key, value in other:
    838                 self[key] = value
    839         for key, value in kwds.items():

ValueError: too many values to unpack (expected 2)
&lt;/denchmark-code&gt;

So, what is the problem and how can I fix it?
	</description>
	<comments>
		<comment id='1' author='konstantin-doncov' date='2020-07-09T11:14:03Z'>
		@don-prog
Please share code with all dependencies for us to replicate it, i ran the code and face different error, please find &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/1138485a529412b2c195a56262915965/untitled272.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
As per error please refer to below issues:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35673&gt;#35673&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/37497&gt;#37497&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31758&gt;#31758&lt;/denchmark-link&gt;
 #&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/35127&gt;#35127&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://makerspace.aisingapore.org/community/ai4i-7-deep-learning/typeerror-tensor-is-unhashable-instead-use-tensor-ref-as-the-key/&gt;link&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='konstantin-doncov' date='2020-07-09T12:03:54Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 thanks, but I already checked the other answers, nothing helped me. You didn't installed the mentioned  dependency, so you face this error.
Please check &lt;denchmark-link:https://colab.research.google.com/drive/1DT6lSWRZ3CIIm9noaJxPYjtOavWQB23S?usp=sharing&gt;this&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/drive/125jJ0qrXGIe6goNrH_Ja7XPZtYp7nMXU?usp=sharing&gt;this&lt;/denchmark-link&gt;
 gists for reproduction of the errors.
		</comment>
		<comment id='3' author='konstantin-doncov' date='2020-07-13T00:36:45Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 do you have progress with these issues?
		</comment>
		<comment id='4' author='konstantin-doncov' date='2020-07-16T02:18:34Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 please, can you provide a fix for these issues? I've been waiting a week.
		</comment>
		<comment id='5' author='konstantin-doncov' date='2020-07-17T02:25:20Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 are you sure that &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 knows about his assignment on this issue?
		</comment>
		<comment id='6' author='konstantin-doncov' date='2020-08-12T19:16:02Z'>
		@don-prog Please grant me the requests of your gists and also please make them public. Thanks!
		</comment>
		<comment id='7' author='konstantin-doncov' date='2020-08-19T19:27:35Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='konstantin-doncov' date='2020-08-26T19:59:15Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 sorry, I thought that I changed access rules, now they are public.
		</comment>
		<comment id='9' author='konstantin-doncov' date='2020-09-04T03:46:39Z'>
		@don-prog This issue is not related to a bug/performance or feature request. Can you please post this in stackoverflow where there is a wider community to respond. Take a look at this fix &lt;denchmark-link:https://github.com/huggingface/transformers/pull/3683&gt;here&lt;/denchmark-link&gt;
. Looks like this is a transformers issue. Thanks!
		</comment>
		<comment id='10' author='konstantin-doncov' date='2020-09-11T04:16:24Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='11' author='konstantin-doncov' date='2020-09-18T04:41:12Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='12' author='konstantin-doncov' date='2020-09-18T04:41:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41204&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41204&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>