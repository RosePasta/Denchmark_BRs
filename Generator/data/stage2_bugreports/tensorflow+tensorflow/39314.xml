<bug id='39314' author='Flamefire' open_date='2020-05-08T13:36:00Z' closed_time='2020-06-22T18:46:35Z'>
	<summary>[Regression] batch_begin/end callbacks no longer get batch number and size</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
TensorFlow installed from (source or binary): Bianry
TensorFlow version (use command below): 2.2.0

Describe the current behavior
The callbacks are documented at &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin&gt;https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin&lt;/denchmark-link&gt;
 as 
The same used to be the case for on_train_batch_end in 2.1 but this seems to have been dropped for unknown reason. In 2.1 the on_train_batch_begin had a logs[size]=1 which was plain wrong but the value in on_train_batch_end was correct so that could be used.
However in 2.2 the size log has been removed from on_train_batch_end causing existing code to break.
Furthermore contrary to the documentation for neither callback the size is included
Describe the expected behavior
The size should be correctly reported to both callbacks for them to use.
Standalone code to reproduce the issue
Instead of coming up with a MWE I quote the code directly:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L847&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L847&lt;/denchmark-link&gt;
 does not even pass a  parameter so that is clearly wrong
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L855&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L855&lt;/denchmark-link&gt;
 uses the result of the  obtained at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L848&gt;https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L848&lt;/denchmark-link&gt;
 which does not contain batch number or size either.
	</description>
	<comments>
		<comment id='1' author='Flamefire' date='2020-05-18T04:27:10Z'>
		&lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;
 Thanks for the issue! For batch number, you can use the  argument to those methods: 
The batch size is no longer passed to the logs, this is expected due a rewrite of Model.fit. Could you explain your use case? I can advise on how this can be achieved with the new implementation
		</comment>
		<comment id='2' author='Flamefire' date='2020-05-18T06:10:43Z'>
		
The batch size is no longer passed to the logs, this is expected due a rewrite of Model.fit

This is surprising as it is a breaking change not mentioned in the release notes and contradicts the above linked documentation and even the current docstring: 


tensorflow/tensorflow/python/keras/callbacks.py


         Line 418
      in
      1186e3f






         logs: Dict. Has keys `batch` and `size` representing the current batch 






Could you explain your use case? I can advise on how this can be achieved with the new implementation

I have a callback counting the number of examples processed (doing further statistics later). In general the batch size may not be constant (e.g. trailing batch) and passing the batch size to the callback and only counting batches duplicates the batch size and is hence error prone.
		</comment>
		<comment id='3' author='Flamefire' date='2020-05-18T06:20:23Z'>
		
I have a callback counting the number of examples processed (doing further statistics later). In general the batch size may not be constant (e.g. trailing batch) and passing the batch size to the callback and only counting batches duplicates the batch size and is hence error prone.

I think this is best handled by a custom Metric:
class Count(tf.keras.metrics.Metric):
  def __init__(self, name=None, dtype=None, **kwargs):
    super(Count, self).__init__(name, dtype, **kwargs)
    self.count = tf.Variable(0)

  def update_state(self, y_true, y_pred, sample_weight=None):
    first_tensor = tf.nest.flatten(y_true)[0]
    batch_size = tf.shape(first_tensor)[0]
    self.count.assign_add(batch_size)

  def result(self):
    return tf.identity(self.count)
This metric would keep a running total of samples seen each epoch, and the results would be passed to logs

This is surprising as it is a breaking change not mentioned in the release notes and contradicts the above linked documentation and even the current docstring

Good point, we need to update the docstring
EDIT: fixed the metric code
		</comment>
		<comment id='4' author='Flamefire' date='2020-05-18T07:04:47Z'>
		This looks promising. Can this be used in TF 2.1 too? IIRC the metrics are not passed to the callbacks in 2.1.
2 questions on the code: Why is the flatten required? Isn't y_true a Tensor with the first dim being the batch size already?
What is the identity for? It's a no-op isn't it?
		</comment>
		<comment id='5' author='Flamefire' date='2020-05-18T17:22:56Z'>
		Yep this should work in TF2.1 as well, here's a full example (had to fix the metric code a bit):
import tensorflow as tf

class Count(tf.keras.metrics.Metric):
  def __init__(self, name=None, dtype=None, **kwargs):
    super(Count, self).__init__(name, dtype, **kwargs)
    self.count = tf.Variable(0)

  def update_state(self, y_true, y_pred, sample_weight=None):
    first_tensor = tf.nest.flatten(y_true)[0]
    batch_size = tf.shape(first_tensor)[0]
    self.count.assign_add(batch_size)

  def result(self):
    return tf.identity(self.count)


class PrintInfo(tf.keras.callbacks.Callback):
  def on_train_batch_end(self, batch, logs):
    print('Batch number: {}'.format(batch))
    print('Samples seen this epoch: {}'.format(logs['counter']))

model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(optimizer='sgd', loss='mse', metrics=[Count(name='counter')])
x, y = tf.ones((10, 10)), tf.ones((10, 1))
model.fit(x, y, batch_size=2, callbacks=[PrintInfo()], verbose=2)
		</comment>
		<comment id='6' author='Flamefire' date='2020-05-18T17:24:51Z'>
		
2 questions on the code: Why is the flatten required? Isn't y_true a Tensor with the first dim being the batch size already?

It's to handle the case where a multi-output Model is used (just to be robust). If your Model only has 1 output it's not needed. tf.nest.flatten will turn any nested Python structure (tuple, list, dict, etc) into a flat list

What is the identity for? It's a no-op isn't it?

Just to make sure we're not returning the tf.Variable directly. It's probably ok to do this, but this protects from accidental modification
		</comment>
		<comment id='7' author='Flamefire' date='2020-06-09T21:15:16Z'>
		&lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;
 if you are satisfied with the solution, can you please close this issue ?
		</comment>
		<comment id='8' author='Flamefire' date='2020-06-10T07:26:46Z'>
		Well it is a breaking change that was not announced so "satisfied" is relative. But there is a solution now.
I'd say once the documentation (e.g. &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin&gt;https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin&lt;/denchmark-link&gt;
)  is updated this can be closed as that is part of this report and I'm not sure this has been fixed yet.
		</comment>
		<comment id='9' author='Flamefire' date='2020-06-22T03:03:25Z'>
		I would also like to use the same technique to use the batch size in on_train_batch_begin, so I used the example above by just replacing on_train_batch_end with on_train_batch_begin, but it doesn't work. Any suggestion to solve this?
		</comment>
		<comment id='10' author='Flamefire' date='2020-06-22T18:46:34Z'>
		&lt;denchmark-link:https://github.com/Flamefire&gt;@Flamefire&lt;/denchmark-link&gt;
 sorry for not announcing the breaking change, this was a miss. The api docstrings have now been updated in this commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/3f973428767cfbbbeeb412b3d7e0be8e566591fb&gt;591fb&lt;/denchmark-link&gt;
. I will close this issue now. Thanks!
&lt;denchmark-link:https://github.com/KTTrev&gt;@KTTrev&lt;/denchmark-link&gt;
 for your issue, please file a separate issue with a minimal code sample repro of what you are trying to do and what is not working.
		</comment>
		<comment id='11' author='Flamefire' date='2020-06-22T18:46:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39314&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39314&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>