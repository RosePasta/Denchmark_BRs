<bug id='3985' author='Mazecreator' open_date='2016-08-23T14:51:14Z' closed_time='2016-10-31T16:15:25Z'>
	<summary>Refactored GPU installation from source issue (Ubuntu 16.04)</summary>
	<description>
It looks like the GPU installation from source got refactored and is failing to compile on my Ubuntu 16.04, CUDA 8.0, cuDNN 5.0, with GTX 1080 GPU.
I had the GTX 1080 working with the build from a few days ago, but just pulled from the head and now cannot compile so I am not sure if this is the auto_configure for the GPU or not I saw going though.
$ git rev-parse HEAD
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/6d04d601e9e8758ec4642fa9d548b7321d804d63&gt;6d04d60&lt;/denchmark-link&gt;

$ bazel version
Build label: 0.3.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jul 29 09:09:52 2016 (1469783392)
Build timestamp: 1469783392
Build timestamp as int: 1469783392
$ ./configure
GPU configured
INFO: All external dependencies fetch successfully.
Configuration finished
$ bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package  1&gt;~/initial_output.txt 2&gt;&amp;1
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/432724/initial_output.txt&gt;initial_output.txt&lt;/denchmark-link&gt;

GPU CUDA includes were not found so I added line to new file: CROSSTOOL.tpl @ line 66
cxx_builtin_include_directory: "/usr/local/cuda-8.0/include"
$ bazel build -c opt --config=cuda --verbose_failures //tensorflow/tools/pip_package:build_pip_package  1&gt;~/second_output.txt 2&gt;&amp;1
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/432726/second_output.txt&gt;second_output.txt&lt;/denchmark-link&gt;

I think it is complaining about not finding "crosstool_wrapper_driver_is_not_gcc".
I did a "locate" and my version seems to be at the following:
$ locate crosstool_wrapper_driver_is_not_gcc
/home/greg/serving/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
/home/greg/serving/tf_models/syntaxnet/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc
/home/greg/tensorflow/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl
Let me know where the file is that has the path to the crosstool_wrapper.... and I can update the path to test that as a fix unless you know the root cause...
EDIT: BTW, the build works fine without the GPU configuration
	</description>
	<comments>
		<comment id='1' author='Mazecreator' date='2016-08-23T19:24:41Z'>
		&lt;denchmark-link:https://github.com/Mazecreator&gt;@Mazecreator&lt;/denchmark-link&gt;
 - how did you configure your build using the  script? Can you paste the output with the values you entered for CUDA version, etc.?
Also, what are the contents of the directory bazel-tensorflow/external/local_config_cuda/crosstool, including all directories?
		</comment>
		<comment id='2' author='Mazecreator' date='2016-08-23T19:44:21Z'>
		Sure, still had this on my system up:
greg@tensor:~/tensorflow$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Found possible Python library paths:
/usr/local/lib/python2.7/dist-packages
/usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
/usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc-4.9
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]:
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify the Cudnn version you want to use. [Leave empty to use system default]:
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: &lt;denchmark-link:https://developer.nvidia.com/cuda-gpus&gt;https://developer.nvidia.com/cuda-gpus&lt;/denchmark-link&gt;
.
Please note that each additional compute capability significantly increases your build time and binary size.
		</comment>
		<comment id='3' author='Mazecreator' date='2016-08-23T20:35:05Z'>
		Understood, thanks.
To check: does the directory bazel-tensorflow/external/local_config_cuda/crosstool exist in your workspace?
		</comment>
		<comment id='4' author='Mazecreator' date='2016-08-23T20:43:29Z'>
		Sorta, looks like this is a symbolic link at that location but the file/directory doesn't exist.
greg@tensor:/tensorflow/bazel-tensorflow/external/local_config_cuda$ ll
total 16
drwxrwxr-x  2 greg greg 4096 Aug 23 10:32 ./
drwxrwxr-x 74 greg greg 4096 Aug 23 10:32 ../
lrwxrwxrwx  1 greg greg  105 Aug 23 10:32 crosstool -&gt; /home/greg/.cache/bazel/_bazel_greg/f51b04b6e5afee33e06cbb5163e8cd54/external/local_config_cuda/crosstool
lrwxrwxrwx  1 greg greg  100 Aug 23 10:32 cuda -&gt; /home/greg/.cache/bazel/_bazel_greg/f51b04b6e5afee33e06cbb5163e8cd54/external/local_config_cuda/cuda/
greg@tensor:/tensorflow/bazel-tensorflow/external/local_config_cuda$ cat crosstool
cat: crosstool: No such file or directory
greg@tensor:~/tensorflow/bazel-tensorflow/external/local_config_cuda$ cd crosstool
bash: cd: crosstool: No such file or directory
		</comment>
		<comment id='5' author='Mazecreator' date='2016-08-23T21:48:51Z'>
		Interesting. I'll attempt to reproduce this.
In the meantime, if you set your CUDA version explicitly when running the configure script, do you still get the same problem?
		</comment>
		<comment id='6' author='Mazecreator' date='2016-08-23T23:53:09Z'>
		I tried setting CUDA to 8.0 and it compiled with no problems.  I used the default version for cuDNN.
I don't know if this still required the manual edit of adding the "cxx_builtin_include_directory" to the  CROSSTOOL.tpl file.  If you think that may have been resolved with your update, I can try from scratch to see if that issue is also resolved.  Adding the 8.0 for CUDA in configure did fix the last problem.
		</comment>
		<comment id='7' author='Mazecreator' date='2016-08-24T00:05:52Z'>
		Understood. Thanks!
I was able to reproduce this issue and will work on root causing the problem. I have a hunch that it may be related to an issue I mentioned in [https://github.com/&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1157&gt;/issues/1157&lt;/denchmark-link&gt;
#issuecomment-235426495](this comment) but I'll verify to be sure.
		</comment>
		<comment id='8' author='Mazecreator' date='2016-08-24T00:40:09Z'>
		one thing that I noticed is that you have to run ./configure again if you do bazel clean
		</comment>
		<comment id='9' author='Mazecreator' date='2016-08-24T00:56:43Z'>
		&lt;denchmark-link:https://github.com/Mistobaan&gt;@Mistobaan&lt;/denchmark-link&gt;
 Yes, you need to run  again if you run  since running  will also delete the  repository generated by , though in general, you should need to run  due to Bazel's incremental rebuilds. If you find an issue that is causing your workspace to become inconsistent, feel free to bring it to our attention. As mentioned in the documentation on &lt;denchmark-link:http://bazel.io/docs/bazel-user-manual.html#the-clean-command&gt;bazel clean&lt;/denchmark-link&gt;
:

The clean command is provided primarily as a means of reclaiming disk space for workspaces that are no longer needed. However, we recognize that Bazel's incremental rebuilds might not be perfect; clean may be used to recover a consistent state when problems arise.
Bazel's design is such that these problems are fixable; we consider such bugs a high priority, and will do our best fix them. If you ever find an incorrect incremental build, please file a bug report. We encourage developers to get out of the habit of using clean and into that of reporting bugs in the tools.

&lt;denchmark-link:https://github.com/Mazecreator&gt;@Mazecreator&lt;/denchmark-link&gt;
 It seems likely that the reason why the undeclared inclusions error is appearing if the CUDA version is not set is due to the symlink-resolved include path of the CUDA headers not matching any of the  entries in the CROSSTOOL config. While  is a symlink to , the build only works if we have a  entry for the  but not .
I'll look into whether we can add support for resolving symlinks for the cxx_builtin_include_directory entries in Bazel or whether the correct fix is to readlink and add the resolved directory to the CROSSTOOL config.
		</comment>
		<comment id='10' author='Mazecreator' date='2016-08-24T01:04:11Z'>
		Thanks,
Let me  know if there is something you want me to try/test.
		</comment>
		<comment id='11' author='Mazecreator' date='2016-08-27T21:02:26Z'>
		An update on this: I opened &lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/1685&gt;bazelbuild/bazel#1685&lt;/denchmark-link&gt;
 to add a  method for getting the canonical path of a symlink in Skylark repositories I have a patch that is currently in review internally, which I tested with the repro scenario for this bug.
Once the patch for &lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/1685&gt;bazelbuild/bazel#1685&lt;/denchmark-link&gt;
 is in, I'll open a PR for the fix for this bug, but we may have to wait for a new Bazel release before we can merge it since it will use the new  method to resolve  to the canonical path before adding the  entry for the include dir in CROSSTOOL.
		</comment>
		<comment id='12' author='Mazecreator' date='2016-08-29T21:35:52Z'>
		Having a similar issue, although on OS X (CUDA 7.5 and cuDNN4, although have 5 if necessary):
Error log:
&lt;denchmark-code&gt;tensorflow $ sudo bazel build -c opt --config=cuda //tensorflow/...
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
INFO: Elapsed time: 1.629s
&lt;/denchmark-code&gt;

./configure settings:
&lt;denchmark-code&gt;tensorflow $ ./configure
Please specify the location of python. [Default is /Library/Frameworks/Python.framework/Versions/2.7/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] y
Google Cloud Platform support will be enabled for TensorFlow
Found possible Python library paths:
  /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
  /Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages]

/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 4
Please specify the location where cuDNN 4 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: "3.5,5.2"]: 3.0
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.
INFO: Waiting for response from Bazel server (pid 14525)...
WARNING: /private/var/tmp/_bazel_production204/ed2bbf43bcd665c40f1e3ebaa04f68f6/external/boringssl_git/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_production204/ed2bbf43bcd665c40f1e3ebaa04f68f6/external/boringssl_git/WORKSPACE (@boringssl) does not match the name given in the repository's definition (@boringssl_git); this will cause a build error in future versions.
INFO: All external dependencies fetched successfully.
Configuration finished

&lt;/denchmark-code&gt;

Thanks for any assistance
Interestingly, configuring the install to not use any symlinked CUDA libraries has the exact same result:
&lt;denchmark-code&gt;$ ./configure
Please specify the location of python. [Default is /Library/Frameworks/Python.framework/Versions/2.7/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] y
Google Cloud Platform support will be enabled for TensorFlow
Found possible Python library paths:
  /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
  /Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages]

/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /Developer/NVIDIA/CUDA-7.5
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 4
Please specify the location where cuDNN 4 library is installed. Refer to README.md for more details. [Default is /Developer/NVIDIA/CUDA-7.5]: /usr/local/cuda
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: "3.5,5.2"]: 3.0
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
..
INFO: Waiting for response from Bazel server (pid 14734)...
WARNING: /private/var/tmp/_bazel_production204/ed2bbf43bcd665c40f1e3ebaa04f68f6/external/boringssl_git/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_production204/ed2bbf43bcd665c40f1e3ebaa04f68f6/external/boringssl_git/WORKSPACE (@boringssl) does not match the name given in the repository's definition (@boringssl_git); this will cause a build error in future versions.
INFO: All external dependencies fetched successfully.
Configuration finished
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;$ sudo bazel build -c opt --config=cuda //tensorflow/...
Password:
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
ERROR: no such package '@local_config_cuda//crosstool': BUILD file not found on package path.
INFO: Elapsed time: 0.446s
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='Mazecreator' date='2016-08-30T23:45:45Z'>
		&lt;denchmark-link:https://github.com/trevorwelch&gt;@trevorwelch&lt;/denchmark-link&gt;
 Looks like you opened &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/4105&gt;#4105&lt;/denchmark-link&gt;
 for the issue that you are seeing, which seems to be a separate issue from this one.
		</comment>
	</comments>
</bug>