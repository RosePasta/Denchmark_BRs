<bug id='35083' author='mixxen' open_date='2019-12-13T09:19:30Z' closed_time='2020-01-22T23:41:43Z'>
	<summary>Error when setting up virtual devices on system that has multiple physical GPUs</summary>
	<description>
System information

OS Platform and Distribution: Linux Ubuntu 18.04
TensorFlow installed from (source or binary): pip
TensorFlow version: 1.15.0, eager mode
Python version: 3.6.8
CUDA/cuDNN version: 10.0.130, 7.6.0.64
GPU model and memory: V100

Describe the current behavior
set_virtual_device_configuration throws an exception with multiple physical GPUs in eager mode and allow growth.
Describe the expected behavior
Should be able to create virtual devices for multiple physical GPUs.
Code to reproduce the issue
import tensorflow as tf

tf.enable_eager_execution() #required for error
tf.debugging.set_log_device_placement(True)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True #required for error
tf.Session(config=config)

# require multiple physical gpus

physical_devices = tf.config.experimental.list_physical_devices('GPU')

tf.config.experimental.set_virtual_device_configuration(
  physical_devices[0],
  [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100),
   tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100)])

tf.config.experimental.set_virtual_device_configuration(
  physical_devices[1],
  [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100),
   tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100)])

logicals = tf.config.experimental.list_logical_devices('GPU')

print(logicals)
Other info / logs
&lt;denchmark-code&gt;---------------------------------------------------------------------------
AlreadyExistsError                        Traceback (most recent call last)
&lt;ipython-input-1-23cc43a56abd&gt; in &lt;module&gt;
     21    tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100)])
     22 
---&gt; 23 logicals = tf.config.experimental.list_logical_devices('GPU')
     24 
     25 print(logicals)

~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/config.py in list_logical_devices(device_type)
    345     List of LogicalDevice objects
    346   """
--&gt; 347   return context.context().list_logical_devices(device_type=device_type)
    348 
    349 

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py in list_logical_devices(self, device_type)
   1140   def list_logical_devices(self, device_type=None):
   1141     """Return logical devices."""
-&gt; 1142     self.ensure_initialized()
   1143 
   1144     devices = []

~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/context.py in ensure_initialized(self)
    490         if self._default_is_async == ASYNC:
    491           pywrap_tensorflow.TFE_ContextOptionsSetAsync(opts, True)
--&gt; 492         context_handle = pywrap_tensorflow.TFE_NewContext(opts)
    493       finally:
    494         pywrap_tensorflow.TFE_DeleteContextOptions(opts)

AlreadyExistsError: TensorFlow device (GPU:1) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mixxen' date='2019-12-17T01:29:22Z'>
		I just checked and this bug also exists in TF 2.0.
		</comment>
		<comment id='2' author='mixxen' date='2019-12-20T23:07:56Z'>
		&lt;denchmark-link:https://github.com/mixxen&gt;@mixxen&lt;/denchmark-link&gt;
 Did you take a look at this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/19083&gt;issue&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='mixxen' date='2020-01-04T12:25:47Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='4' author='mixxen' date='2020-01-04T21:06:25Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 Looked at that issue 19083, but unsure if it's related.
In my example, I'm trying to create 4 logical GPU devices with 2 physical GPU devices.
I'm able to create N logical devices if there is only 1 physical GPU...so it would seem I should be able to create N logical devices on a system with M physical GPUs.
		</comment>
		<comment id='5' author='mixxen' date='2020-01-04T22:26:57Z'>
		I'm thinking there is a device name conflict when using set_virtual_device_configuration on a system with multiple GPUs. I'm able to create virtual devices for the last listed GPU only. For instance, if a system has 4 GPUs, I am able to create virtual GPUs on physical_devices[3]. Creating virtual devices on GPU 0,1, and 2 will result in the exception above.
		</comment>
		<comment id='6' author='mixxen' date='2020-01-04T23:07:13Z'>
		I think I figured it out. Need to configure all GPUs the same before invoking set_virtual_device_configuration. config.gpu_options seems to only configure the 1st GPU.
The following code works on a 4 GPU system:
&lt;denchmark-code&gt;import tensorflow as tf

tf.compat.v1.enable_eager_execution()
physical_devices = tf.config.experimental.list_physical_devices('GPU')

for gpu in physical_devices:
    tf.config.experimental.set_memory_growth(gpu, True)

for gpu in physical_devices:
    tf.config.experimental.set_virtual_device_configuration(
      gpu,
      [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100),
       tf.config.experimental.VirtualDeviceConfiguration(memory_limit=100)])

logicals = tf.config.experimental.list_logical_devices('GPU')

print(logicals)
&lt;/denchmark-code&gt;

Prints this:
&lt;denchmark-code&gt;[LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:0', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:1', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:2', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:3', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:4', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:5', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:6', device_type='GPU'), LogicalDevice(name='/job:localhost/replica:0/task:0/device:GPU:7', device_type='GPU')]
&lt;/denchmark-code&gt;

I'll do a bit more testing and report back.
		</comment>
		<comment id='7' author='mixxen' date='2020-01-09T22:22:21Z'>
		Sure &lt;denchmark-link:https://github.com/mixxen&gt;@mixxen&lt;/denchmark-link&gt;
 glad that it worked.
		</comment>
		<comment id='8' author='mixxen' date='2020-01-22T23:41:40Z'>
		I am closing this issue as it has been resolved. Please add additional comments and we can open this issue again.
		</comment>
		<comment id='9' author='mixxen' date='2020-01-22T23:41:45Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35083&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35083&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>