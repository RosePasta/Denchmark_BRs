<bug id='41520' author='sidhomj' open_date='2020-07-18T02:42:56Z' closed_time='2020-07-23T17:40:26Z'>
	<summary>Generators not compatible with ragged tensors when using model.fit</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 2.2
Python version: 3.8
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: cuDNN 10
GPU model and memory: V100, 24GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
When providing model.fit with a python generator that creates ragged inputs for a keras model, while the outputs of the generator will allow model.fit to train, if one provides the generator to model.fit, it will not. Below, I have attached a standalone script showing in synthetic data, how when the generator is incorporated into a for loop, the model will fit on the outputs of the generator but if one provides the generator to the model.fit command, it will not train.
Describe the expected behavior
The model should train given the python generator according to the docs.
Standalone code to reproduce the issue
import tensorflow as tf
import numpy as np

def turn_into_ragged(x):
    return tf.RaggedTensor.from_row_lengths(tf.concat(
        [tf.RaggedTensor.from_row_lengths(np.concatenate(sample, axis=0), list(map(len, sample))) for sample in x],
        axis=0), list(map(len, x)))

def get_batches_m(x,y,batch_size=10,random=False):
    """ Return a generator that yields batches from vars. """
    #batch_size = len(x) // n_batches
    if len(x[0]) % batch_size == 0:
        n_batches = (len(x[0]) // batch_size)
    else:
        n_batches = (len(x[0]) // batch_size) + 1

    sel = np.asarray(list(range(x[0].shape[0])))
    if random is True:
        np.random.shuffle(sel)

    for ii in range(0, n_batches * batch_size, batch_size):
        # If we're not on the last batch, grab data with size batch_size
        if ii != (n_batches - 1) * batch_size:
            sel_ind=sel[ii: ii + batch_size]
        else:
            sel_ind = sel[ii:]

        x_out = [turn_into_ragged(var[sel_ind]) for var in x]
        y_out = [var[sel_ind] for var in y]

        yield tuple(x_out),tuple(y_out)

def generate_syn_data(n_i=2000, n_s=30, n_t=200, shape=(10, 10, 3)):
    values = np.random.uniform(0, 1, (n_i, ) + shape).astype(np.float32)
    idx_t = np.random.choice(n_t, n_i)
    _, l = np.unique(idx_t, return_counts=True)
    rt0 = tf.RaggedTensor.from_row_lengths(values, l)
    idx_s = np.random.choice(n_s, n_t)
    _, l = np.unique(idx_s, return_counts=True)
    rt1 = tf.RaggedTensor.from_row_lengths(rt0, l)
    y = tf.constant(np.eye(2)[np.random.choice(2, n_s)].astype(np.float32))
    return  rt1, y

def basic_ragged_graph(input_shapes):
    ragged_inputs = [tf.keras.layers.Input(shape=(None, None) + shape, dtype=tf.float32, ragged=True) for shape in input_shapes]
    sample_aggregation = tf.concat([tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x, axis=(1, 2)))(ragged_input) for ragged_input in ragged_inputs], axis=1)
    logits = tf.keras.layers.Dense(units=2, activation=None)(tf.keras.layers.Flatten()(sample_aggregation))
    return tf.keras.Model(inputs=ragged_inputs, outputs=[logits])

#create simple model that takes 2 ragged inputs and returns 1 output
tile_shape = (10, 10, 3)
model = basic_ragged_graph([tile_shape,tile_shape])
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))

#generate synthetic data for inputs and outputs
x1,x2 = generate_syn_data()[0].numpy(),generate_syn_data()[0].numpy()
y = generate_syn_data()[1].numpy()

#create generator objeect to batch and convert data to tf raggged
train_gen = get_batches_m([x1,x2],[y],batch_size=5,random=True)
#this method uses generator and outputs x_train,y_train that work
for x_train, y_train in train_gen:
    model.fit(x_train, y_train)

#however, when one provides this generator to the model.fit, the model will not train
train_gen = get_batches_m([x1,x2],[y],batch_size=5,random=True)
model.fit(train_gen)
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='sidhomj' date='2020-07-18T03:27:19Z'>
		Apparently, this may be related to an issue described here:  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/41419&gt;#41419&lt;/denchmark-link&gt;
 . I'm wondering if this is a similar problem where the output of the generator is cast to a tensor even though the output of the generator is a ragged tensor.
		</comment>
		<comment id='2' author='sidhomj' date='2020-07-20T08:32:34Z'>
		&lt;denchmark-link:https://github.com/sidhomj&gt;@sidhomj&lt;/denchmark-link&gt;

I ran the code shared and face &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/e955df428d9ad1721c58b70037702ad7/untitled286.ipynb&gt;this error&lt;/denchmark-link&gt;
, please let us know if it confirms your issue.
		</comment>
		<comment id='3' author='sidhomj' date='2020-07-20T11:06:21Z'>
		Yes, this is the error I receive.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


Sent from my iPhone

On Jul 20, 2020, at 4:32 AM, Saduf2019 &lt;notifications@github.com&gt; wrote:

﻿

      External Email - Use Caution



@sidhomj&lt;https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fsidhomj&amp;data=02%7C01%7Cjsidhom1%40jhmi.edu%7C1fc0306f4ee44905c9e008d82c878015%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637308307763337636&amp;sdata=ah%2BL%2FAu7slJdyKzXDs%2BUElZWbeiZlTRjhx1WYL2boO4%3D&amp;reserved=0&gt;
I ran the code shared and face this error&lt;https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcolab.research.google.com%2Fgist%2FSaduf2019%2Fe955df428d9ad1721c58b70037702ad7%2Funtitled286.ipynb&amp;data=02%7C01%7Cjsidhom1%40jhmi.edu%7C1fc0306f4ee44905c9e008d82c878015%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637308307763337636&amp;sdata=aC9eGKCyPfNr3LLy2kVkMN34ieLRIiFITbt9zCzdep8%3D&amp;reserved=0&gt;, please let us know if it confirms your issue.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub&lt;https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F41520%23issuecomment-660885729&amp;data=02%7C01%7Cjsidhom1%40jhmi.edu%7C1fc0306f4ee44905c9e008d82c878015%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637308307763347628&amp;sdata=maLPzx5Rp9JNnLNbQJe2hfrTXU3D1L1ok6ALwkpt164%3D&amp;reserved=0&gt;, or unsubscribe&lt;https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAGVMZTG2ILLE2NRIHIL2QG3R4P6LLANCNFSM4O7IMY3A&amp;data=02%7C01%7Cjsidhom1%40jhmi.edu%7C1fc0306f4ee44905c9e008d82c878015%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637308307763347628&amp;sdata=I%2Bv6GwV%2Bz0KMtpRQYrhoHyhSry0i1Ju%2F2bfN9ClG4O8%3D&amp;reserved=0&gt;.

		</comment>
		<comment id='4' author='sidhomj' date='2020-07-23T17:40:26Z'>
		Python generators work well with numpy arrays, but for TensorFlow composite tensor types like RaggedTensor and SparseTensor, we would recommend you use tf.data.Datasets. You can read more about how to use Datasets in your input pipeline here: &lt;denchmark-link:https://www.tensorflow.org/guide/data&gt;https://www.tensorflow.org/guide/data&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='sidhomj' date='2020-07-23T17:40:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41520&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41520&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>