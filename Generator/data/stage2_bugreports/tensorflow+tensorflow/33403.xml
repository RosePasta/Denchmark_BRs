<bug id='33403' author='jnd77' open_date='2019-10-16T03:11:12Z' closed_time='2020-01-14T02:22:21Z'>
	<summary>max_pool_with_argmax can gives different results on GPU than on CPU</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.13.1
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.1
GPU model and memory: GPU 1080-Ti

Describe the current behavior
When running the test in the code below, one of the tests fail. Somehow, the argmax result of max_pool_with_argmax is different when running with self.session(use_gpu=True).
Interestingly, the failing test behaves as if it was ignoring the batch index in the argmax.
Describe the expected behavior
All 3 tests should pass.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np


class TestMaxPool(tf.test.TestCase):

    def setUp(self):
        tf.reset_default_graph()

    def _test(self, sess):
         # Image with 2 channels, H = 4, W = 4
         image_t = tf.constant([[[1.0, 12.0], [3.0, 14.0], [5.0, 16.0], [7.0, 18.0]],
                           [[11.0, 2.0], [13.0, 4.0], [15.0, 6.0], [17.0, 8.0]],
                           [[38.0, 37.0], [36.0, 35.0], [34.0, 33.0], [32.0, 31.0]],
                           [[28.0, 27.0], [26.0, 25.0], [24.0, 23.0], [22.0, 21.0]]])
         input_t = tf.stack([image_t, image_t])
         _, pool_indices = tf.nn.max_pool_with_argmax(input_t, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
         pool_indices_out = sess.run(pool_indices)

        expected_image_indices = np.array([[[10, 3], [14, 7]], [[16, 17], [20, 21]]])
        self.assertAllEqual(pool_indices_out, np.stack([expected_image_indices, expected_image_indices + 32]))

    def test_with_normal_session(self):
        with tf.Session() as sess:
            self._test(sess)

    def test_with_self_session_and_gpu(self):
        with self.session(use_gpu=True) as sess:
            self._test(sess)

    def test_with_self_session_and_cpu(self):
        with self.session(use_gpu=False) as sess:
            self._test(sess)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='jnd77' date='2019-10-17T07:01:55Z'>
		&lt;denchmark-link:https://github.com/jnd77&gt;@jnd77&lt;/denchmark-link&gt;
, Thanks for reporting the issue.
Please provide the complete code to reproduce the reported issue. Thanks!
		</comment>
		<comment id='2' author='jnd77' date='2019-10-17T08:04:48Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 Thanks for taking a look. The complete code can be found in my original message. Only 2 out of 3 tests are passing ...
		</comment>
		<comment id='3' author='jnd77' date='2019-10-18T09:41:56Z'>
		&lt;denchmark-link:https://github.com/jnd77&gt;@jnd77&lt;/denchmark-link&gt;
, I tried replicating the reported issue. Please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/696ae88444b31f485f5a8a97c723bfb5/untitled210.ipynb&gt;gist&lt;/denchmark-link&gt;
. And provide the more information to reproduce the issue. Thanks!
		</comment>
		<comment id='4' author='jnd77' date='2019-10-19T09:34:01Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 . Here is the &lt;denchmark-link:https://colab.research.google.com/gist/jnd77/e7193cb2eb57c23a35e460c6538751ff/untitled210.ipynb&gt;gist &lt;/denchmark-link&gt;
 reproducing the issue
It looks like the argmax returned by the CPU op follows the documentation and is equal to:
((b * height + y) * width + x) * channels + c
While the one returned by the GPU op ignores the batch:
(y * width + x) * channels + c
Am very unclear why test_with_normal_session is passing, as I thought it would be sent to the GPU.
		</comment>
		<comment id='5' author='jnd77' date='2020-01-14T00:21:40Z'>
		&lt;denchmark-link:https://github.com/jnd77&gt;@jnd77&lt;/denchmark-link&gt;
 Is this still an issue? Can you please try with  and let us know whether the issue persists. If possible, test it in  or . Thanks!
		</comment>
		<comment id='6' author='jnd77' date='2020-01-14T02:22:21Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I did a check with TF1.15.
The function has this new argument: include_batch_in_index
Both CPU and GPU versions give the same (correct) result, whether include_batch_in_index is True or False. And documentation has been updated as well.
All good on my side ! :) Thanks a lot.
		</comment>
		<comment id='7' author='jnd77' date='2020-01-14T02:22:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33403&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33403&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>