<bug id='26995' author='dynamicwebpaige' open_date='2019-03-21T15:36:00Z' closed_time='2019-07-02T12:16:16Z'>
	<summary>2.0 Reference Models: BERT (1 GPU, 8 GPU with dist strat and Keras)</summary>
	<description>
&lt;denchmark-link:https://github.com/google-research/bert&gt;BERT, or Bidirectional Encoder Representations from Transformers&lt;/denchmark-link&gt;
, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks.
The research team's academic paper describes BERT in detail and provides full results on a number of tasks: &lt;denchmark-link:https://arxiv.org/abs/1810.04805&gt;https://arxiv.org/abs/1810.04805&lt;/denchmark-link&gt;
.
An example of using BERT can be found &lt;denchmark-link:https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb&gt;here&lt;/denchmark-link&gt;
.
The purpose of this issue is to migrate models into the TF 2.0 Keras API. Each migrated model must be eager and distribution compatible, with tests, and all associated engineering artifacts.
	</description>
	<comments>
		<comment id='1' author='dynamicwebpaige' date='2019-05-20T21:51:26Z'>
		We are working on this internally and will publish the code before the end of May-2019 assigning to me for now.
		</comment>
		<comment id='2' author='dynamicwebpaige' date='2019-06-17T19:27:36Z'>
		&lt;denchmark-link:https://github.com/tensorflow/models/tree/master/official/bert&gt;https://github.com/tensorflow/models/tree/master/official/bert&lt;/denchmark-link&gt;

The README has not been updated yet, but I think the information below will get you started.
I am only testing the GPU version but it was build for TPU so that would have been tested first.  I do not have the flags to use but I have the test cases we run nightly.  Below is what I know, I have not been going even a little deep into BERT so I don't know how to state the accuracy numbers other than what we are tracking nightly.
BERT (SQUAD):  ~.903
BERT (Classify):  .8603 with mrpc

Test Case SQUAD: official.bert.benchmark.bert_squad_benchmark.BertSquadBenchmarkReal.benchmark_8_gpu
Test Case Classify: official.bert.benchmark.bert_benchmark.BertClassifyAccuracy.benchmark_8_gpu_mrpc

I realize it is a bit painful but you can extract the FLAGS from the tests above. We are still working on performance but we are already exceeding the TF 1.0 for both single and multi-gpu single machine.  FP16 support will be coming soon.  We are working on SQUAD first but the gains would apply to both...in most instances.
Warning: The data in gs://cloud-tpu-checkpoints is public and you can pull that down.  I did not make the actual training data public because I have not taken time to find out if it can be shared directly.  It likely can, but I like to be careful.
I will help if I can; another group owns this but I deal with it daily as well for now.
		</comment>
	</comments>
</bug>