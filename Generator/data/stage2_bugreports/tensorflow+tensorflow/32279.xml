<bug id='32279' author='sayakpaul' open_date='2019-09-06T06:26:10Z' closed_time='2019-09-06T22:32:14Z'>
	<summary>Clarification in the validation_data argument of fit() in nsl.keras.AdversarialRegularization</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.0.0-rc0
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior:
I am trying the newly released neural_structured_learning API. In order to do an experiment, I thought of starting with fine-tuning a VGG16 model and seeing the API's action in that case. I am interested in using the validation_data argument while calling fit() on a nsl.keras.AdversarialRegularization model.
I tried to do two variants:
First one:
adv_model.fit({'feature': X_train, 'label': y_train},
                   validation_data=(X_val, y_val),
                   batch_size=128, epochs=2, verbose=1)
It throws:
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-63-6a9e8b7f90e8&gt; in &lt;module&gt;()
      2 h = adv_model.fit({'feature': X_train, 'label': y_train},
      3                   validation_data={'feature': X_val, 'label': y_val},
----&gt; 4                   batch_size=128, epochs=2, verbose=1)
      5 print("Took {0:.2f} seconds".format(time.time() - start))

6 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in &lt;genexpr&gt;(.0)
    223       inputs = (x,)
    224 
--&gt; 225     num_samples = set(int(i.shape[0]) for i in nest.flatten(inputs))
    226     if len(num_samples) &gt; 1:
    227       msg = "Data cardinality is ambiguous:\n"

IndexError: tuple index out of range
Second one:
adv_model.fit({'feature': X_train, 'label': y_train},
                  validation_data={'feature': X_val, 'label': y_val},
                   batch_size=128, epochs=2, verbose=1)
It throws:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-68-158557e95fb0&gt; in &lt;module&gt;()
      2 h = adv_model.fit({'feature': X_train, 'label': y_train},
      3                   validation_data=(X_val, y_val),
----&gt; 4                   batch_size=128, epochs=2, verbose=1)
      5 print("Took {0:.2f} seconds".format(time.time() - start))

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    732         max_queue_size=max_queue_size,
    733         workers=workers,
--&gt; 734         use_multiprocessing=use_multiprocessing)
    735 
    736   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    222           validation_data=validation_data,
    223           validation_steps=validation_steps,
--&gt; 224           distribution_strategy=strategy)
    225 
    226       total_samples = _get_total_number_of_samples(training_data_adapter)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    561                                     class_weights=class_weights,
    562                                     steps=validation_steps,
--&gt; 563                                     distribution_strategy=distribution_strategy)
    564     elif validation_steps:
    565       raise ValueError('`validation_steps` should not be specified if '

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    591         batch_size=batch_size,
    592         check_steps=False,
--&gt; 593         steps=steps)
    594   adapter = adapter_cls(
    595       x,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)
   2435           feed_input_shapes,
   2436           check_batch_axis=False,  # Don't enforce the batch size.
-&gt; 2437           exception_prefix='input')
   2438 
   2439     # Get typespecs for the input data and sanitize it if necessary.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
    528                        'Expected to see ' + str(len(names)) + ' array(s), '
    529                        'but instead got the following list of ' +
--&gt; 530                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')
    531     elif len(names) &gt; 1:
    532       raise ValueError('Error when checking model ' + exception_prefix +

ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([[[[132., 140.,  64.],
         [135., 142.,  64.],
         [140., 145.,  64.],
         ...,
         [145., 141.,  70.],
         [146., 134.,  86.],
         [148., 128., 100.]],

        [...
But when I fit the model without validation_data, it works fine.
Describe the expected behavior
Either throw some light on the usage in the documentation or in the example.
Code to reproduce the issue
For experimentation, I use Colab, so here's the &lt;denchmark-link:https://colab.research.google.com/drive/1vEIpwdmS9Uj_QVlZVqLT5ZQu77BgKNwX&gt;Colab notebook&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='sayakpaul' date='2019-09-06T18:35:54Z'>
		&lt;denchmark-link:https://github.com/sayakpaul&gt;@sayakpaul&lt;/denchmark-link&gt;
 Can you also post this issue on &lt;denchmark-link:https://github.com/tensorflow/neural-structured-learning/issues&gt;tensorflow/neural-structured-learning repo&lt;/denchmark-link&gt;
 for more visibility to nsl owners? Thanks!
		</comment>
		<comment id='2' author='sayakpaul' date='2019-09-06T22:32:14Z'>
		&lt;denchmark-link:https://github.com/sayakpaul&gt;@sayakpaul&lt;/denchmark-link&gt;
 Thanks for your interest in Neural Structured Learning.
I would recommend setting validation_data to a tf.data.Dataset object. tf.data.Dataset is able to handle a nested structure of Tensor / NumPy arrays. For example:
train_data = tf.data.Dataset.from_tensor_slices(
    {'feature': X_train, 'label': y_train}).batch(batch_size)
val_data = tf.data.Dataset.from_tensor_slices(
    {'feature': X_val, 'label': y_val}).batch(batch_size)
val_steps = X_val.shape[0] / batch_size
adv_model.fit(train_data, validation_data=val_data, validation_steps=val_steps,
              epochs=2, verbose=1)
I will update the documentation to include a sample usage with validation_data.
Please post future issues on the &lt;denchmark-link:https://github.com/tensorflow/neural-structured-learning/issues&gt;tensorflow/neural-structured-learning repo&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='sayakpaul' date='2019-09-06T22:32:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32279&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32279&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='sayakpaul' date='2019-09-07T03:17:25Z'>
		Thanks &lt;denchmark-link:https://github.com/csferng&gt;@csferng&lt;/denchmark-link&gt;
. I was going through the image classification tutorial with NSL last night. I really liked the  section. I think this ecosystem would definitely allow the community to dig into the world of adversarial learning from a code-first approach. I liked how comprehensive it was. You have the keras-like beautiful abstraction as well as many low-level ops.
Thank you.
		</comment>
	</comments>
</bug>