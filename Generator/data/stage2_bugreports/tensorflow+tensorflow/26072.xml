<bug id='26072' author='KaramAbuaisha' open_date='2019-02-25T05:58:33Z' closed_time='2019-06-11T04:53:05Z'>
	<summary>docker tensorflow-tensorflow/latest-gpu slow initialisation of GPU</summary>
	<description>
Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template
System information

OS Platform and Distribution: Ubuntu 16.04
Using Docker (latest-gpu image)
Mobile Device: No
TensorFlow installed from (source or binary): N/A
TensorFlow version: 1.13.0-rc1
Python version:  Python 3.5.2
Installed using virtualenv? pip? conda?: N/A
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
GPU model and memory: Quadro M1200

&lt;denchmark-code&gt;==============NVSMI LOG==============

Timestamp                           : Mon Feb 25 00:50:20 2019
Driver Version                      : 410.78
CUDA Version                        : 10.0

Attached GPUs                       : 1
GPU 00000000:01:00.0
    Product Name                    : Quadro M1200
    Product Brand                   : Quadro
    Display Mode                    : Disabled
    Display Active                  : Disabled
    Persistence Mode                : Enabled
    Accounting Mode                 : Disabled
    Accounting Mode Buffer Size     : 4000
    Driver Model
        Current                     : N/A
        Pending                     : N/A
    Serial Number                   : N/A
    GPU UUID                        : GPU-d9093d17-7927-a053-9104-426e68b1d4ac
    Minor Number                    : 0
    VBIOS Version                   : 82.07.BB.00.13
    MultiGPU Board                  : No
    Board ID                        : 0x100
    GPU Part Number                 : N/A
    Inforom Version
        Image Version               : N/A
        OEM Object                  : N/A
        ECC Object                  : N/A
        Power Management Object     : N/A
    GPU Operation Mode
        Current                     : N/A
        Pending                     : N/A
    GPU Virtualization Mode
        Virtualization mode         : None
    IBMNPU
        Relaxed Ordering Mode       : N/A
    PCI
        Bus                         : 0x01
        Device                      : 0x00
        Domain                      : 0x0000
        Device Id                   : 0x13B610DE
        Bus Id                      : 00000000:01:00.0
        Sub System Id               : 0x224D17AA
        GPU Link Info
            PCIe Generation
                Max                 : 3
                Current             : 3
            Link Width
                Max                 : 16x
                Current             : 16x
        Bridge Chip
            Type                    : N/A
            Firmware                : N/A
        Replays since reset         : 0
        Tx Throughput               : 0 KB/s
        Rx Throughput               : 0 KB/s
    Fan Speed                       : N/A
    Performance State               : P0
    Clocks Throttle Reasons
        Idle                        : Not Active
        Applications Clocks Setting : Active
        SW Power Cap                : Not Active
        HW Slowdown                 : Not Active
            HW Thermal Slowdown     : N/A
            HW Power Brake Slowdown : N/A
        Sync Boost                  : Not Active
        SW Thermal Slowdown         : Not Active
        Display Clock Setting       : Not Active
    FB Memory Usage
        Total                       : 4043 MiB
        Used                        : 3813 MiB
        Free                        : 230 MiB
    BAR1 Memory Usage
        Total                       : 256 MiB
        Used                        : 3 MiB
        Free                        : 253 MiB
    Compute Mode                    : Default
    Utilization
        Gpu                         : 0 %
        Memory                      : 0 %
        Encoder                     : 0 %
        Decoder                     : 0 %
    Encoder Stats
        Active Sessions             : 0
        Average FPS                 : 0
        Average Latency             : 0
    FBC Stats
        Active Sessions             : 0
        Average FPS                 : 0
        Average Latency             : 0
    Ecc Mode
        Current                     : N/A
        Pending                     : N/A
    ECC Errors
        Volatile
            Single Bit            
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : N/A
            Double Bit            
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : N/A
        Aggregate
            Single Bit            
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : N/A
            Double Bit            
                Device Memory       : N/A
                Register File       : N/A
                L1 Cache            : N/A
                L2 Cache            : N/A
                Texture Memory      : N/A
                Texture Shared      : N/A
                CBU                 : N/A
                Total               : N/A
    Retired Pages
        Single Bit ECC              : N/A
        Double Bit ECC              : N/A
        Pending                     : N/A
    Temperature
        GPU Current Temp            : 37 C
        GPU Shutdown Temp           : N/A
        GPU Slowdown Temp           : 96 C
        GPU Max Operating Temp      : 92 C
        Memory Current Temp         : N/A
        Memory Max Operating Temp   : N/A
    Power Readings
        Power Management            : N/A
        Power Draw                  : N/A
        Power Limit                 : N/A
        Default Power Limit         : N/A
        Enforced Power Limit        : N/A
        Min Power Limit             : N/A
        Max Power Limit             : N/A
    Clocks
        Graphics                    : 993 MHz
        SM                          : 993 MHz
        Memory                      : 2505 MHz
        Video                       : 893 MHz
    Applications Clocks
        Graphics                    : N/A
        Memory                      : N/A
    Default Applications Clocks
        Graphics                    : N/A
        Memory                      : N/A
    Max Clocks
        Graphics                    : 1150 MHz
        SM                          : 1150 MHz
        Memory                      : 2505 MHz
        Video                       : 1035 MHz
    Max Customer Boost Clocks
        Graphics                    : N/A
    Clock Policy
        Auto Boost                  : N/A
        Auto Boost Default          : N/A
    Processes
        Process ID                  : 1123
            Type                    : G
            Name                    : /usr/lib/xorg/Xorg
            Used GPU Memory         : 8 MiB
        Process ID                  : 31763
            Type                    : C
            Name                    : python
            Used GPU Memory         : 3791 MiB
&lt;/denchmark-code&gt;

Describe the problem
When using my GPU, it takes several minutes (just over 4 minutes) to initialise to do anything. Issue does not exist when using CPU
Provide the exact sequence of commands / steps that you executed before running into the problem
docker run -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow tensorflow/tensorflow:latest-gpu bash
python test.py
contents of test.py:
&lt;denchmark-code&gt;import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(512, activation=tf.nn.relu),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)
&lt;/denchmark-code&gt;

Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
logs while running test script
&lt;denchmark-code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-02-25 05:46:52.561440: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-25 05:46:52.628689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-25 05:46:52.629997: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x50be7d0 executing computations on platform CUDA. Devices:
2019-02-25 05:46:52.630035: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0
2019-02-25 05:46:52.664820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2019-02-25 05:46:52.666234: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5128500 executing computations on platform Host. Devices:
2019-02-25 05:46:52.666318: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-02-25 05:46:52.666979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.90GiB
2019-02-25 05:46:52.667052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-02-25 05:46:52.669065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-25 05:46:52.669122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-02-25 05:46:52.669152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-02-25 05:46:52.669563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -&gt; physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)
Epoch 1/5
2019-02-25 05:51:01.254939: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
60000/60000 [==============================] - 5s 84us/sample - loss: 0.2207 - acc: 0.9348
Epoch 2/5
60000/60000 [==============================] - 5s 79us/sample - loss: 0.0960 - acc: 0.9714
Epoch 3/5
60000/60000 [==============================] - 5s 78us/sample - loss: 0.0697 - acc: 0.9774
Epoch 4/5
60000/60000 [==============================] - 5s 79us/sample - loss: 0.0536 - acc: 0.9826
Epoch 5/5
60000/60000 [==============================] - 5s 76us/sample - loss: 0.0430 - acc: 0.9857
10000/10000 [==============================] - 0s 29us/sample - loss: 0.0606 - acc: 0.9813
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='KaramAbuaisha' date='2019-02-26T18:23:16Z'>
		&lt;denchmark-link:https://github.com/KaramAbuaisha&gt;@KaramAbuaisha&lt;/denchmark-link&gt;

Thank you for your post. We noticed you have not filled out the fields in the issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md&gt;template&lt;/denchmark-link&gt;
. Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. Thanks!
		</comment>
		<comment id='2' author='KaramAbuaisha' date='2019-02-28T22:59:42Z'>
		I updated the issue, please let me know if there's any important information missing
		</comment>
		<comment id='3' author='KaramAbuaisha' date='2019-03-14T02:00:45Z'>
		Is this the wrong place to ask about this problem?
		</comment>
		<comment id='4' author='KaramAbuaisha' date='2019-03-15T20:30:41Z'>
		Thanks for the detailed instructions but I couldn't reproduce the issue on Volta GPUs.
I suspect that this could be because we don't specify compute compatibility 5.0 required for Quadro M1200 GPU and this results in JIT compilation.
Could you try building a custom docker after adding '5.0' in the list and see if that resolves the problem?



tensorflow/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile


         Line 78
      in
      1c1c24c






 ENV TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2,6.0,6.1,7.0 





		</comment>
		<comment id='5' author='KaramAbuaisha' date='2019-03-16T18:37:28Z'>
		How do I build the custom docker exactly?
I tried something that didn't work:
I pulled this repo, edited the devel-gpu.Dockerfile as recommended and then built the image by executing docker build -f ./dockerfiles/cpu.Dockerfile -t tf .  from tensorflow/tensorflow/tools/dockerfiles
Then I made a container like so: sudo docker run --name test -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 8888:8888 tf:latest bash
But when I tried running the script, I got the following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "test.py", line 1, in &lt;module&gt;
    import tensorflow as tf
ImportError: No module named tensorflow
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='KaramAbuaisha' date='2019-03-19T00:12:45Z'>
		I think I figured out how, I edited this file /tensorflow/tools/dockerfiles/partials/ubuntu/devel-nvidia.partial.Dockerfile to include 5.0 in ENV TF_CUDA_COMPUTE_CAPABILITIES and I then executed the following
&lt;denchmark-code&gt;# Build the tools-helper image so you can run the assembler
$ docker build -t tf-tools -f tools.Dockerfile .

# Set --user to set correct permissions on generated files
$ docker run --user $(id -u):$(id -g) -it -v $(pwd):/tf tf-tools bash

# Next you can make a handy alias depending on what you're doing. When building
# Docker images, you need to run as root with docker.sock mounted so that the
# container can run Docker commands. When assembling Dockerfiles, though, you'll
# want to run as your user so that new files have the right permissions.

# If you're BUILDING OR DEPLOYING DOCKER IMAGES, run as root with docker.sock:
$ alias asm_images="docker run --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py "

# If you're REBUILDING OR ADDING DOCKERFILES, remove docker.sock and add -u:
$ alias asm_dockerfiles="docker run --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py "

# Check assembler flags
$ asm_dockerfiles --help

# Assemble all of the Dockerfiles
$ asm_dockerfiles --release dockerfiles --construct_dockerfiles

# Build devel-gpu-py3 image
$ asm_images --release nightly --build_images  --only_tags_matching="^devel-gpu-py3$"
&lt;/denchmark-code&gt;

I was able to observe that the temporary docker file generated had 5.0 in the list of compute capabilities and confirmed again by running the command docker history --no-trunc tensorflow:devel-gpu-py3 to find that it was listed in there as well. I then ran the same test file mentioned above and found that the issue was not fixed. It still takes 4 minutes to initialize the gpu, here are the logs
&lt;denchmark-code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-03-19 00:07:13.715853: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-19 00:07:13.783574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-19 00:07:13.784535: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x48e23f0 executing computations on platform CUDA. Devices:
2019-03-19 00:07:13.784555: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0
2019-03-19 00:07:13.802868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2019-03-19 00:07:13.804070: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x494c120 executing computations on platform Host. Devices:
2019-03-19 00:07:13.804136: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-03-19 00:07:13.804578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.90GiB
2019-03-19 00:07:13.804632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-03-19 00:07:13.806202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-19 00:07:13.806249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-03-19 00:07:13.806278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-03-19 00:07:13.806642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -&gt; physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)
Epoch 1/5
2019-03-19 00:11:15.093862: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
60000/60000 [==============================] - 6s 105us/sample - loss: 0.2203 - acc: 0.9341
Epoch 2/5
60000/60000 [==============================] - 5s 82us/sample - loss: 0.0978 - acc: 0.9689
Epoch 3/5
60000/60000 [==============================] - 5s 79us/sample - loss: 0.0691 - acc: 0.9772
Epoch 4/5
60000/60000 [==============================] - 5s 78us/sample - loss: 0.0526 - acc: 0.9827
Epoch 5/5
60000/60000 [==============================] - 5s 78us/sample - loss: 0.0440 - acc: 0.9856
10000/10000 [==============================] - 0s 30us/sample - loss: 0.0621 - acc: 0.9805
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='KaramAbuaisha' date='2019-03-21T01:12:08Z'>
		Could you set TF_CPP_MIN_VLOG_LEVEL environment variable to 10 using the following in python?
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '10'
This might help us understand what it is doing between the timestamp '00:07:13.806642' and '00:11:15.093862'?
Also, It seems that some of the users are not having this issue with TensorFlow 2.0 nightly. See,
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652#issuecomment-474471312&gt;#18652 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='KaramAbuaisha' date='2019-03-21T01:22:33Z'>
		Sorry I actually made a mistake earlier, I still get the error ImportError: No module named 'tensorflow' 
		</comment>
		<comment id='9' author='KaramAbuaisha' date='2019-03-21T01:23:31Z'>
		I was actually in the wrong docker container when I tested it again and got the results above
		</comment>
		<comment id='10' author='KaramAbuaisha' date='2019-03-21T02:06:32Z'>
		The commands to build dockerfiles seem correct to me but we need to use "devel-gpu.Dockerfile" Dockerfile while building the docker.
		</comment>
		<comment id='11' author='KaramAbuaisha' date='2019-03-21T03:04:41Z'>
		Even if I make no changes at all, I get the same import error as above so I must be doing something wrong
		</comment>
		<comment id='12' author='KaramAbuaisha' date='2019-03-21T03:17:36Z'>
		Could you confirm that you are editing devel-gpu.Dockerfile file and then running the following command?
docker build -t tf-tools -f dockerfiles/devel-gpu.Dockerfile
(The script you posted has tools.Dockerfile and not devel-gpu.Dockerfile that we need to use.)
If this still does not work, could you run it after setting TF_CPP_MIN_VLOG_LEVEL environment variable?
		</comment>
		<comment id='13' author='KaramAbuaisha' date='2019-03-21T03:24:42Z'>
		I was running this command docker run --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py --release nightly --build_images --run_tests_path=$(realpath tests) --only_tags_matching="^devel-gpu-py3$"
I just tried docker build -f dockerfiles/devel-gpu.Dockerfile .  and it had the same import error as above
&lt;denchmark-code&gt;tf-docker / &gt; python
Python 2.7.12 (default, Nov 12 2018, 14:36:49) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import tensorflow
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ImportError: No module named tensorflow
&lt;/denchmark-code&gt;

		</comment>
		<comment id='14' author='KaramAbuaisha' date='2019-03-21T04:08:07Z'>
		Adding &lt;denchmark-link:https://github.com/tfboyd&gt;@tfboyd&lt;/denchmark-link&gt;
 to see if he knows any obvious issue with building the docker.

Could you try setting TF_CPP_MIN_VLOG_LEVEL environment variable with the default TensorFlow docker to see if that helps investigate?
This issue might have the same underlying issue as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652&gt;#18652&lt;/denchmark-link&gt;
. So marking this as duplicate to that one.
Duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652&gt;#18652&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='15' author='KaramAbuaisha' date='2019-03-21T04:09:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26072&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26072&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='KaramAbuaisha' date='2019-03-21T05:20:18Z'>
		I changed test.py to
&lt;denchmark-code&gt;import tensorflow as tf
import os
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '10'
mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(512, activation=tf.nn.relu),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test, y_test)
&lt;/denchmark-code&gt;

This was the output
&lt;denchmark-code&gt;Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-03-21 05:36:55.633860: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-21 05:36:55.699545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-21 05:36:55.700506: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5250560 executing computations on platform CUDA. Devices:
2019-03-21 05:36:55.700548: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0
2019-03-21 05:36:55.720246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2019-03-21 05:36:55.721723: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52ba280 executing computations on platform Host. Devices:
2019-03-21 05:36:55.721812: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-03-21 05:36:55.722328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.90GiB
2019-03-21 05:36:55.722388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-03-21 05:36:55.724256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-21 05:36:55.724307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-03-21 05:36:55.724333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-03-21 05:36:55.724694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -&gt; physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)
Epoch 1/5
2019-03-21 05:41:16.531234: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
60000/60000 [==============================] - 6s 98us/sample - loss: 0.2175 - acc: 0.9356
Epoch 2/5
60000/60000 [==============================] - 6s 93us/sample - loss: 0.0968 - acc: 0.9707
Epoch 3/5
60000/60000 [==============================] - 6s 93us/sample - loss: 0.0703 - acc: 0.9783
Epoch 4/5
60000/60000 [==============================] - 6s 93us/sample - loss: 0.0528 - acc: 0.9837
Epoch 5/5
60000/60000 [==============================] - 6s 93us/sample - loss: 0.0445 - acc: 0.9854
10000/10000 [==============================] - 0s 39us/sample - loss: 0.0622 - acc: 0.9811
&lt;/denchmark-code&gt;

It looks like there is no difference
		</comment>
		<comment id='17' author='KaramAbuaisha' date='2019-03-21T05:28:32Z'>
		I do not believe that this is a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652&gt;#18652&lt;/denchmark-link&gt;
 because my delay happens after the tensor flow device is created

and the first log afterwards is about the cudas library
2019-03-21 05:18:22.893314: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
while in the issue referenced, the delay happens after
2019-03-21 05:14:11.544914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
		</comment>
		<comment id='18' author='KaramAbuaisha' date='2019-03-21T06:01:12Z'>
		I will investigate building of custom docker for TensorFlow.
		</comment>
		<comment id='19' author='KaramAbuaisha' date='2019-03-29T19:45:02Z'>
		Any updates?
		</comment>
		<comment id='20' author='KaramAbuaisha' date='2019-03-29T20:24:25Z'>
		I do not have a compute compatible device 5.0, but my random guess is the jit compilation.  If you are using docker directly as I expect you are, it will not get cached.  You can test this theory by doing docker interactively (enter with bash) and running the test test twice.  I run nightly tests much bigger than this and the total run time is under 6 minutes and it seems you have a 5 minute gap if I am reading the log correctly.
The compute we include should be:
export TF_CUDA_COMPUTE_CAPABILITIES=3.5,3.7,5.2,6.0,6.1,7.0
One solution, I think, is to run the docker interactive and then commit it.  I think that would then end up working like a workstation without docker.  The reasons we cannot do all of the compatibility versions is it makes the binary too large.  pypi has a limit of 50MB and we already talked them into 350MB.  Each compute is I think 15MB maybe more off the top of my head.
		</comment>
		<comment id='21' author='KaramAbuaisha' date='2019-03-29T20:36:13Z'>
		I have been using docker interactively and I can confirm that that isn't the case. The 4 minute delay occurs everytime I run the script within my container. On the other hand though (if I recall correctly), If I launch a jupyter notebook, the 4 minute delay only occurs the first time fitting a model unless I restart the kernel.
I'd like to try to build a docker with the correct compute capabilities but whenever I do I get the error I mentioned above
&lt;denchmark-code&gt;tf-docker / &gt; python
Python 2.7.12 (default, Nov 12 2018, 14:36:49) 
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import tensorflow
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ImportError: No module named tensorflow
&lt;/denchmark-code&gt;

		</comment>
		<comment id='22' author='KaramAbuaisha' date='2019-03-29T20:46:48Z'>
		do you run:
nvidia-docker run -it -v &lt;your workspace of code&gt;:/workspace  your/docker/image bash
and then run the script twice.  Just asking to be 100% sure, especially due to your memory of the notebook experience.
Just asking to be sure as I dealt with the compile issue in the past (2 years ago maybe) related to kaggle and due to my work flow never realized it was a problem.  I have no other ideas at the moment.  My nightly tests do not have that gap so I am not sure how to repro.
Interesting your notebook does not have the same issue.  Is the notebook local or running inside the Docker image.
		</comment>
		<comment id='23' author='KaramAbuaisha' date='2019-03-29T23:47:07Z'>
		I run
sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash
I just confirmed that both times I run the script it takes 4 minutes before it starts training.
The notebook is running inside the docker container and I ran all the cells in tensorflow-tutorials/basic_classification.ipynb The first time it took 4 minues before starting training but the second time I ran through (without restarting kernel) it started training immediately. If i restart the kernel I must wait 4 minutes before it starts training again.
		</comment>
		<comment id='24' author='KaramAbuaisha' date='2019-03-30T01:13:43Z'>
		That result is a strike against my wild theory.  Thank you for trying.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Mar 29, 2019, 4:50 PM Karam Abuaisha ***@***.***&gt; wrote:
 I run
 sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g)
 --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p
 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash
 I just confirmed that both times I run the script it takes 4 minutes
 before it starts training.
 The notebook is running inside the docker container and I ran all the
 cells in tensorflow-tutorials/basic_classification.ipynb The first time
 it took 4 minues before starting training but the second time I ran through
 (without restarting kernel) it started training immediately. If i restart
 the kernel I must wait 4 minutes before it starts training again.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#26072 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AWZestndP1siBSGpeZKHQD-ypqzyNdK9ks5vbqa_gaJpZM4bPJbW&gt;
 .



		</comment>
		<comment id='25' author='KaramAbuaisha' date='2019-04-23T13:50:41Z'>
		
I will investigate building of custom docker for TensorFlow.

&lt;denchmark-link:https://github.com/smit-hinsu&gt;@smit-hinsu&lt;/denchmark-link&gt;
 were you able to figure out the reason I was having issues with building a custom docker for tensorflow?
		</comment>
		<comment id='26' author='KaramAbuaisha' date='2019-04-29T05:36:25Z'>
		I got the same problem. It seems that it will only occurs in the first time running tensorflow-gpu, hence it is not a serious problem, you can just regard it as a initialization.
The problem is actually about docker. When you using docker, every time you run the code it will build a new container, hence need a new initialization. To solve the problem, you need commit you container as a new image after you got that delay (initialized).
		</comment>
		<comment id='27' author='KaramAbuaisha' date='2019-05-10T01:22:09Z'>
		To me it happens every time I run the python script. The only time the initialization doesn't have to be repeated is if I'm on a jupyter notebook (unless I reset then kernel, then I have to initialize again)
		</comment>
		<comment id='28' author='KaramAbuaisha' date='2019-05-21T09:20:55Z'>
		It depends whether you using a new container to run the python script. If so, it will need a new initialization. To use the initialized docker container: 1. Commit it, it will save all the changes you did to the container to a new image; (or)2. Use "docker exec" to repeatedly use the same container.
		</comment>
		<comment id='29' author='KaramAbuaisha' date='2019-05-23T04:56:06Z'>
		Sorry I'm not being clear, I am not starting a new container when I run the script again. I start my docker like so sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash So that I am able to run scripts and start a jupyter notebook server if i like. Within the same instance of a container, when I run the script multiple times, there is no difference between each execution; \ I always have the same problem where I must wait 4 minutes. The only time it doesn't repeat is when I run the same block of code within an ipython notebook and the kernel is not reset, only in that one case will the initialisation only happen once (until I reset the kernel). I figure it's because the my gpu compute version is not supported by default in the docker. I can't verify this because in the past when I tried to create my own custom docker, I've had tensorflow import errors (completely unrelated to the original issue) and I'm not sure what the reason for that is.
		</comment>
		<comment id='30' author='KaramAbuaisha' date='2019-05-29T06:48:32Z'>
		If you can confirm that you are using the same container, then my solution maybe useless for you. But I still have to mention something which maybe helpful.
docker run is a command to build a new container. (if you don't know this, please search the difference between docker container and docker image)
Check by this:

Run sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash to build the container, run you script, you will suffer initialization. The use run exit in the container bash to exit the container.
After that, run docker exec -it tensorflowgpu bash, run you script again. In my case, the initialization no longer appear.
If this is not helpful, I have to say sorry for wasting your time.

		</comment>
		<comment id='31' author='KaramAbuaisha' date='2019-05-30T02:13:34Z'>
		Yeah I'm aware, I meant that I tried building a new docker image following the steps &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles&gt;here&lt;/denchmark-link&gt;

but when I built a container based on that image I found that I couldn't import the tensorflow module in python and I'm not sure why that occurred. More detail is provided in the previous comments in this thread.

How do I build the custom docker exactly?
I tried something that didn't work:
I pulled this repo, edited the devel-gpu.Dockerfile as recommended and then built the image by executing docker build -f ./dockerfiles/cpu.Dockerfile -t tf .  from tensorflow/tensorflow/tools/dockerfiles
Then I made a container like so: sudo docker run --name test -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 8888:8888 tf:latest bash
But when I tried running the script, I got the following error:
Traceback (most recent call last):
  File "test.py", line 1, in &lt;module&gt;
    import tensorflow as tf
ImportError: No module named tensorflow


		</comment>
		<comment id='32' author='KaramAbuaisha' date='2019-05-30T03:00:45Z'>
		I forgot to mention, when I attempt to install tensorflow inside the container based on my locally built image, I get this error
&lt;denchmark-code&gt;ERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/.local'
Check the permissions.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='33' author='KaramAbuaisha' date='2019-06-11T04:53:05Z'>
		I was able to build tensorflow from source with the correct compute capabilities and it has solved my problem. Thanks for the help!
		</comment>
		<comment id='34' author='KaramAbuaisha' date='2019-06-11T04:53:06Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26072&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26072&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>