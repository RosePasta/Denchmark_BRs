<bug id='45540' author='mynameisteodora' open_date='2020-12-09T13:12:08Z' closed_time='2020-12-10T00:33:49Z'>
	<summary>TFLite java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter on Android SDK 29</summary>
	<description>
Hello. I have a simple Android app connected to an accelerometer. I have a few tflite models in the app, one of which is throwing  a "Failed to run on the given Interpreter" error without any additional information. The code works fine on SDK 25.
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android SDK 29
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy A20e, Android version 10
TFLite version: "org.tensorflow:tensorflow-lite:1.13.1"

Describe the current behavior
When the interpreter is called on the Android 10 phone, this error is thrown:
&lt;denchmark-code&gt;java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: 
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:145)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:250)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at com.specknet.respeckmodeltesting.classification.Classifier.classifyActivityWithFeatures(Classifier.kt:111)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at com.specknet.respeckmodeltesting.live.LiveDataActivity$onCreate$2.onReceive(LiveDataActivity.kt:176)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.app.LoadedApk$ReceiverDispatcher$Args.lambda$getRunnable$0$LoadedApk$ReceiverDispatcher$Args(LoadedApk.java:1646)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.app.-$$Lambda$LoadedApk$ReceiverDispatcher$Args$_BumDX2UKsnxLVrE6UJsJZkotuA.run(Unknown Source:2)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Handler.handleCallback(Handler.java:883)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Handler.dispatchMessage(Handler.java:100)
2020-12-09 13:08:10.987 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Looper.loop(Looper.java:237)
2020-12-09 13:08:10.987 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.HandlerThread.run(HandlerThread.java:67)

&lt;/denchmark-code&gt;

Describe the expected behavior
The code works fine and classifies correctly when run on an Android 7.1.2 phone.
There is no code change between these two phones. Furthermore, other tflite models work on both phones. The only difference I see between the working models and the ones that crash are the conversion types. The models that crash have been "MLIR Converted" (inspected with Netron), and the models that do not crash are TOCO converted.
Is there something preventing MLIR converted models from running on more recent Android versions?
Thank you for your help.
	</description>
	<comments>
		<comment id='1' author='mynameisteodora' date='2020-12-09T13:35:23Z'>
		The TFLite runtime version should be the same version with or higher version than the TFLite converter Python version.
For example, if you convert a model with TF 1.15, you need to use TFLite runtime version 1.15 at least.
Could you make sure that your TFLite runtime version is aligned with the TFLite converter Python version, which is used for the TFLite model generation, especially regarding MLIR converted models?
		</comment>
		<comment id='2' author='mynameisteodora' date='2020-12-09T14:33:22Z'>
		I do not have access to the original model unfortunately, but I tried importing the model as per the instructions here: &lt;denchmark-link:https://www.tensorflow.org/lite/guide/android&gt;https://www.tensorflow.org/lite/guide/android&lt;/denchmark-link&gt;
 and this way it works. So it must be the way I was doing it before might be deprecated?
The approach I had before was like here &lt;denchmark-link:https://github.com/tensorflow/examples/tree/a0ec947023c8c9c4a027fa887e954021d27cc1dd&gt;https://github.com/tensorflow/examples/tree/a0ec947023c8c9c4a027fa887e954021d27cc1dd&lt;/denchmark-link&gt;
.
Anyways thank you, I am happy I found a workaround.
		</comment>
		<comment id='3' author='mynameisteodora' date='2020-12-10T00:33:49Z'>
		&lt;denchmark-link:https://github.com/mynameisteodora&gt;@mynameisteodora&lt;/denchmark-link&gt;
 can you share what the difference was for the other users?
		</comment>
		<comment id='4' author='mynameisteodora' date='2020-12-10T00:33:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45540&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45540&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>