<bug id='11127' author='tonyw' open_date='2017-06-29T04:19:32Z' closed_time='2017-09-17T17:43:48Z'>
	<summary>tf.contrib.keras modules can't Open HDFS file</summary>
	<description>

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS 7
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.1.0
Bazel version (if compiling from source):
CUDA/cuDNN version:5.1.10

I use keras.preprocessing.image.ImageDataGenerator class,I invoke flow_from_directory function,when train_data_dir is a HDFS directory. the script throw exception. I refer the source code.I found the  ImageDataGenerator class not use GFile class to open path.
So,it's possible to use GFile to open file in tf.contrib.keras modules?
	</description>
	<comments>
		<comment id='1' author='tonyw' date='2017-06-29T23:51:34Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 can you comment or redirect? Thanks!
		</comment>
		<comment id='2' author='tonyw' date='2017-08-30T18:46:07Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 can you give any feedback about it? plz, I have the same problem.
		</comment>
		<comment id='3' author='tonyw' date='2017-08-30T19:15:39Z'>
		Keras can open HDF5 files accessible on local filesystem / network. It cannot open HDF5 files on GFS, because GFS does not support HDF5. We have been talking to the HDF group about possibly making that happen in the future.
To open HDFS files that aren't on a locally-accessible filesystem, first copy them locally.
		</comment>
	</comments>
</bug>