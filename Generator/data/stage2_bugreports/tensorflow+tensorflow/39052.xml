<bug id='39052' author='McSlay' open_date='2020-04-30T12:13:27Z' closed_time='2020-05-29T07:29:40Z'>
	<summary>Inference blocks indefinitely on GPU when Eager mode is enabled</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I made small changes (use of opencv to capture images) to the object_detection_tutorial file.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): python -m pip install tensorflow
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
Python version: 3.7
CUDA/cuDNN version: 10.1 / 7.6.5.32
GPU model and memory: GTX 960M 2GB or RTX2070 Super 8 GB

Describe the current behavior
With GPU and Eager mode enabled, running inference blocks indefinitely after processing a few frames (&lt;15).
If I then disable Eager mode, it runs fine.
When eager is disabled and I use a session to process the data, it also blocks indefinitely on GPU.
Everything works fine when only using the CPU
Describe the expected behavior
Being able to run inference on GPU without indefinite blocks with Eager mode enabled.
Code to reproduce the issue
&lt;denchmark-code&gt;import os
import pathlib
import cv2
import numpy as np
import tensorflow as tf

#from object_detection.utils import ops as utils_ops

def load_model(model_name):
    base_url = 'http://download.tensorflow.org/models/object_detection/'
    model_file = model_name + '.tar.gz'
    model_dir = tf.keras.utils.get_file(
        fname=model_name,
        origin=base_url + model_file,
        untar=True)
    model_dir = pathlib.Path(model_dir)/"saved_model"
    model = tf.saved_model.load(str(model_dir))
    model = model.signatures['serving_default']
    return model

def run_inference_for_single_image(model, image):
    image = np.asarray(image)
    input_tensor = tf.convert_to_tensor(image)
    input_tensor = input_tensor[tf.newaxis, ...]
    # Run inference
    print("Inference start")
    model(input_tensor)
    print("Inference end")

if "models" in pathlib.Path.cwd().parts:
    while "models" in pathlib.Path.cwd().parts:
        os.chdir('..')

#disable eager mode
#tf.compat.v1.disable_eager_execution()

MODELNAME = 'ssd_mobilenet_v1_coco_2017_11_17'
DETECTION_MODEL = load_model(MODELNAME)

#utils_ops.tf = tf.compat.v1
tf.gfile = tf.io.gfile

#IMGPATH = PATH_TO_IMAGE
IMAGE = np.zeros((640, 480, 3), np.uint8)

while True:
    run_inference_for_single_image(DETECTION_MODEL, IMAGE)
&lt;/denchmark-code&gt;

I ran this from the research\object_detection folder
Other info / logs
I am not sure how to support the claim of it being a bug. I tried it on different machines and the code is based on an example. I thought it was because there are no error or warning messages before hanging, it works fine when just using the CPU (with or without Eager mode), it works on GPU without Eager mode and it hangs in a library function.
I never did anything like this before. If i did something wrong or more information is required, please let me know.
	</description>
	<comments>
		<comment id='1' author='McSlay' date='2020-05-03T14:22:53Z'>
		&lt;denchmark-link:https://github.com/McSlay&gt;@McSlay&lt;/denchmark-link&gt;

I ran the code shared by you and face an error, please share all dependencies and complete stand alone code for us to help you.
Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/694c1acdc4a31910add3630b3477b0db/39052.ipynb&gt;gist&lt;/denchmark-link&gt;
 for the same.
		</comment>
		<comment id='2' author='McSlay' date='2020-05-04T07:36:41Z'>
		I updated the code. After updating it worked in the gist you linked. Is the gist using the GPU?
I am not sure why it works there but not on the 3 different machines I have tried. What should I do?
		</comment>
		<comment id='3' author='McSlay' date='2020-05-04T08:20:43Z'>
		&lt;denchmark-link:https://github.com/McSlay&gt;@McSlay&lt;/denchmark-link&gt;

yes we can use GPU to do so, please select change runtime and select gpu then save, and run as normal.
		</comment>
		<comment id='4' author='McSlay' date='2020-05-04T08:26:06Z'>
		It works with the GPU enabled in the gist.
How can I get it to work on my own machine aswell?
		</comment>
		<comment id='5' author='McSlay' date='2020-05-05T10:53:21Z'>
		&lt;denchmark-link:https://github.com/McSlay&gt;@McSlay&lt;/denchmark-link&gt;

Could you please run the code in a virtual environment and check if you are facing the same issue
		</comment>
		<comment id='6' author='McSlay' date='2020-05-06T11:21:56Z'>
		Thank you for the suggestion.
I installed tensorflow 2.1.0 (pip install tensorflow==2.1.0) and opencv (pip install opencv-contrib-python) in the virtual environment.
I put the cuDNN dll in the root of the env folder.
I made a python file with the code above, and also put it in the env folder.
It loads the required dll's for the GPU successfully but it still hangs afer a few frames (12 this time).
I am also unable to stop the execution with CTRL+C in the windows terminal.
		</comment>
		<comment id='7' author='McSlay' date='2020-05-08T08:12:33Z'>
		I am not sure what else to try.
I tried a different python version 3.6.8 and a different cuDNN version 7.6.2.24.
Both are within the accepted range for Tensorflow 2.0 as I understand.
Since Cuda is fixed at 10.1, I dont see any other tools I can try different versions of.
In earlier tests I also tried Tensorflow 1.15. This also blocks, but then when running the session.
I also tried the python virtual environment on a different windows machine, one with an RTX 2070 super. Here I only installed tensorflow 2.1.0. And this also blocks after a few frames.
The code itself works, and I am bound to windows. So there is no point in trying Linux.
		</comment>
		<comment id='8' author='McSlay' date='2020-05-08T10:56:04Z'>
		i am able to replicate this, please find the gist here with &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/1018b3abb9759f8b3db7e7c9810db9f0/2.ipynb&gt;disable eager mode&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/76a81a891a558d7c1a7b14359632c94a/untitled169.ipynb&gt;without&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='McSlay' date='2020-05-08T16:05:49Z'>
		&lt;denchmark-link:https://github.com/McSlay&gt;@McSlay&lt;/denchmark-link&gt;
 I ran your code in Eager model with GPU. It was inferencing without any blocks. I added a counter to see how many inferences (with  see below ), later I stopped execution. I tried both  and  and didn't face the issue. &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/c949d112acc3625973f4bbdaf887f995/2.ipynb&gt;gist&lt;/denchmark-link&gt;
 is same as &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 shared above. Did you try similar images (640,480,3) or bigger images? Not sure what is the root-cause.
&lt;denchmark-code&gt;
Inference start
Inference end
61256
Inference start
Inference end
61257
Inference start
Inference end
61258
Inference start
Inference end
61259
Inference start
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
&lt;ipython-input-3-a5d4c7888742&gt; in &lt;module&gt;()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='McSlay' date='2020-05-11T07:38:47Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I also tried larger images (1280 x 720 and 1920 x 1080). These resolutions might be too big (I dont know much about TensorFlow and AI in general). So for the test I tried a small resolution.
I have googled this problem allot, and it seems that I am the only one having this problem. I have tried this on 4 different windows machines, so I am probably installing it wrong.
What I do is:

Install python 3.7
Install tensorflow "pip install tensorflow==2.1"
install cuda toolkit version 10.1 update 2
download cuDNN version 7.6.5.32, extract it and add it to the path variable
run the test code

I also tried

lower the tensorflow versions  (1.15 [changed the code to get it to work on CPU], 2.0)
CUDA toolkit update 1
older cuDNN version: 7.6.2.24

I am not sure if I tried a different model source.
I also tried asking this question on the git page of the object detection. Today I got a reply that stated that the model I am using was not suitable for Tensorflow 2 (&lt;denchmark-link:https://github.com/tensorflow/models/issues/8449&gt;tensorflow/models#8449&lt;/denchmark-link&gt;
). But the first line in the tutorial file that is included in the object_detection API is '!pip install -U --pre tensorflow=="2.*"' when I run it in jupyter notebook.
The code also did not work when I installed TensorFlow 1.15. And it also still hangs on GPU when I convert the code to work with session.run.
		</comment>
		<comment id='11' author='McSlay' date='2020-05-12T07:18:10Z'>
		
it hangs in a library function

Which library function?  A Python stack trace from a hung process will be very useful.
Also, can you attach the logs from a run that hung?
Finally, does this reproduce on TF 2.2?
		</comment>
		<comment id='12' author='McSlay' date='2020-05-12T08:36:11Z'>
		&lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
 it hangs in the function "model(input_tensor)".
I made a stack dump for the code that is supplied with the question
&lt;denchmark-code&gt;File: "test.py", line 77, in &lt;module&gt;  run_inference_for_single_image(DETECTION_MODEL, IMAGE)
File: "test.py", line 32, in run_inference_for_single_image  model(input_tensor)
File: \lib\site-packages\tensorflow\python\eager\function.py", line 1605, in __call__  return self._call_impl(args, kwargs)
File: \lib\site-packages\tensorflow\python\eager\function.py", line 1645, in _call_impl  return self._call_flat(args, self.captured_inputs, cancellation_manager)
File: \lib\site-packages\tensorflow\python\eager\function.py", line 1746, in _call_flat  ctx, args, cancellation_manager=cancellation_manager))
File: \lib\site-packages\tensorflow\python\eager\function.py", line 598, in call  ctx=ctx)
File: \lib\site-packages\tensorflow\python\eager\execute.py", line 60, in quick_execute  inputs, attrs, num_outputs)
&lt;/denchmark-code&gt;

This is the output of when it hangs. It shows the "inference start" print (is printed just before calling the model function), and then it stops. After the model function it should print "inference end"
&lt;denchmark-code&gt;2020-04-24 11:30:16.579805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 11:30:18.916146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-24 11:30:18.941805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5
coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-24 11:30:18.946134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 11:30:18.951172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 11:30:18.954809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 11:30:18.957258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 11:30:18.961662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 11:30:18.965553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 11:30:18.978671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 11:30:18.980998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-24 11:30:18.982226: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-04-24 11:30:18.984167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5
coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-24 11:30:18.987291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 11:30:18.988809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 11:30:18.990303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 11:30:18.991792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 11:30:18.993320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 11:30:18.996960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 11:30:18.998497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 11:30:19.000191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-24 11:30:19.430864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 11:30:19.433076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-04-24 11:30:19.434566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-04-24 11:30:19.436400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6281 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[&lt;tf.Tensor 'image_tensor:0' shape=(None, None, None, 3) dtype=uint8&gt;]
inference start
2020-04-24 11:30:24.728554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 11:30:25.608426: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-04-24 11:30:25.625904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
&lt;/denchmark-code&gt;

It also hangs in TF 2.2. This was used to create the stackdump in a virtual environment
		</comment>
		<comment id='13' author='McSlay' date='2020-05-27T22:46:06Z'>
		Hi &lt;denchmark-link:https://github.com/McSlay&gt;@McSlay&lt;/denchmark-link&gt;

I believe this is the key line:
&lt;denchmark-code&gt;Relying on driver to perform ptx compilation. This message will be only logged once.
&lt;/denchmark-code&gt;

It means that TF is using the CUDA driver to JIT compiler PTX to SASS.  This takes a long time.
There is no easy way to out of this unfortunately.  TF ships with recompiled SASS for a specific set of compute capabilities, and if your GPU is not compatible with any of those we have to JIT compile.  The not-easy way out is to build TF from source and ask it to compile SASS for the compute capability for your GPU.
		</comment>
		<comment id='14' author='McSlay' date='2020-05-29T07:29:40Z'>
		Hi &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;

That's a shame, I will have to look into other solutions then.
Thank you for your help.
		</comment>
		<comment id='15' author='McSlay' date='2020-05-29T07:29:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39052&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39052&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>