<bug id='33942' author='OverLordGoldDragon' open_date='2019-11-02T22:32:04Z' closed_time='2020-03-03T08:03:59Z'>
	<summary>Stacking CNN wrecks reproducibility (even with seed &amp; CPU)</summary>
	<description>
REPRODUCIBLE:
ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
NOT REPRODUCIBLE:
ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

The difference amplifies substantially when using a larger model, and actual data instead of random noise - up to  (relative) within a single small epoch. Environment setup, considered sources, and full minimal reproducible example below. &lt;denchmark-link:https://stackoverflow.com/questions/58675856/why-does-stacking-cnn-wreck-reproducibility-even-with-seed-cpu?noredirect=1#comment103653213_58675856&gt;Relevant SO&lt;/denchmark-link&gt;

What is the problem, and how to fix it?
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

POSSIBLE SOURCES: ([x] = ruled out)

[x] TF2 vs. TF1; Keras 2.3.0+ vs. Keras 2.2.5 (tested both)
[x] Random seeds (numpy, tf, random, PYTHONHASHSEED)
[x] Data values / shuffling (same values, no shuffling)
[x] Weight initializations (same values)
[x] GPU usage (used CPU)
[x] CPU multithreading (used single thread; also see below's 'further')
[x] Numeric imprecision (used float64; further, extent of discrepancy too large for num. impr.)
[x] Bad CUDA install (all official guide tests passed, TF detects GPU &amp; CUDA)

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

ENVIRONMENT:

CUDA 10.0.130, cuDNN 7.6.0, Windows 10, GTX 1070
Python 3.7.4, Spyder 3.3.6, Anaconda 3.0 10/19
Anaconda Powershell Prompt terminal to set PYTHONHASHSEED and start Spyder

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

OBSERVATIONS:

float64 vs. float32 - no noticeable difference
CPU vs. GPU - no noticeable difference
Non-reproducible also for Conv1D
Reproducible for Dense replacing Conv; other layers not tested
For a larger model, which is still 'small', loss variance is substantial within a single epoch:

one_epoch_loss = [1.6814, 1.6018, 1.6577, 1.6789, 1.6878, 1.7022, 1.6689]
one_epoch_acc  = [0.2630, 0.3213, 0.2991, 0.3185, 0.2583, 0.2463, 0.2815]
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

CODE:
batch_shape = (32, 64, 64, 3)
num_samples = 1152

ipt = Input(batch_shape=batch_shape)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(ipt)
x   = Conv2D(6, (8, 8), strides=(2, 2), activation='relu')(x)
x   = Flatten()(x)
out = Dense(6, activation='softmax')(x)
model = Model(ipt, out)
model.compile('adam', 'sparse_categorical_crossentropy')

X = np.random.randn(num_samples, *batch_shape[1:])
y = np.random.randint(0, 6, (num_samples, 1))

reset_seeds()
model.fit(x_train, y_train, epochs=5, shuffle=False)
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Imports / setup:
import os
os.environ['PYTHONHASHSEED'] = '0'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import numpy as np
np.random.seed(1)
import random
random.seed(2)

import tensorflow as tf
session_conf = tf.ConfigProto(
      intra_op_parallelism_threads=1,
      inter_op_parallelism_threads=1)
sess = tf.Session(config=session_conf) # single-threading; TF1-only

def reset_seeds():
    np.random.seed(1)
    random.seed(2)
    if tf.__version__[0] == '2':
        tf.random.set_seed(3)
    else:
        tf.set_random_seed(3)
    print("RANDOM SEEDS RESET")
reset_seeds()

from keras.layers import Input, Dense, Conv2D, Flatten
from keras.models import Model
import keras.backend as K

K.set_floatx('float64')
	</description>
	<comments>
		<comment id='1' author='OverLordGoldDragon' date='2019-11-20T21:47:45Z'>
		&lt;denchmark-link:https://github.com/OverLordGoldDragon&gt;@OverLordGoldDragon&lt;/denchmark-link&gt;
 Can you please provide a simple standalone code to reproduce the issue? If you can, please create a colab gist or Jupyter notebook whichever is convenient to you. Can you please add more details on what you mean by

up to 30% difference in accuracy (relative) within a single small epoch

Thanks!
		</comment>
		<comment id='2' author='OverLordGoldDragon' date='2019-11-21T00:52:13Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Standalone code's in the original post, with random seeds set so you can reproduce the issue. The "30%" refers to the final bullet point under "OBSERVATIONS"; if needed, I can provide code to reproduce that as well - it's of a small-medium sized model w/ more conv layers.
Let me know if more info's needed - thanks
		</comment>
		<comment id='3' author='OverLordGoldDragon' date='2019-12-24T11:09:34Z'>
		The problem is rather severe; should I produce a more obvious example? Haven't had a chance to investigate this fully yet - did anyone look into it?
		</comment>
		<comment id='4' author='OverLordGoldDragon' date='2020-03-03T08:03:55Z'>
		It looks like the results is reproducible using tf-nightly. Closing this for now, but feel free to reopen it if it doesn't work on your end. Thanks!
		</comment>
		<comment id='5' author='OverLordGoldDragon' date='2020-03-03T08:04:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33942&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33942&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>