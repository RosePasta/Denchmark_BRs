<bug id='27200' author='freedomtan' open_date='2019-03-27T14:33:12Z' closed_time='2019-04-22T23:43:47Z'>
	<summary>[tflite] multithreaded DepthwiseConv returns wrong results on aarch64 platform</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): nope
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android Pie (Pixel 2) and Debian (Coral EdgeTPU Dev Board)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 2
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): recent master 8d1c139
Python version: N/A
Bazel version (if compiling from source): 0.24.0
GCC/Compiler version (if compiling from source): gcc 6 on Coral Dev Board, clang in Android NDK r17b
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
&lt;denchmark-code&gt;&gt; adb shell
walleye:/ $ cd /data/local/tmp
walleye:/data/local/tmp $ ./label_image_new_aarch64  -m mobilenet_v1_1.0_224_quant.tflite  -t 1                                                              
Loaded model mobilenet_v1_1.0_224_quant.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked 
average time: 66.784 ms 
0.419608: 907 Windsor tie
0.356863: 653 military uniform
0.0352941: 458 bow tie
0.027451: 668 mortarboard
0.0235294: 543 drumstick
walleye:/data/local/tmp $./label_image_new_aarch64  -m mobilenet_v1_1.0_224_quant.tflite  -t 2                                                              
Loaded model mobilenet_v1_1.0_224_quant.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked 
average time: 36.938 ms 
0.215686: 543 drumstick
0.129412: 594 harmonica
0.0470588: 700 panpipe
0.0470588: 559 flute
0.0235294: 773 safety pin
walleye:/data/local/tmp $./label_image_new_aarch64  -m mobilenet_v1_1.0_224_quant.tflite  -t 3                                                              
Loaded model mobilenet_v1_1.0_224_quant.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked 
average time: 32.779 ms 
0.592157: 797 ski mask
0.258824: 434 bathing cap
0.0156863: 728 planetarium
0.0117647: 736 poncho
0.00784314: 773 safety pin
walleye:/data/local/tmp $ ./label_image_new_aarch64  -m mobilenet_v1_1.0_224_quant.tflite  -t 4                                                              &lt;
Loaded model mobilenet_v1_1.0_224_quant.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked 
average time: 25.737 ms 
0.823529: 728 planetarium
0.0352941: 669 mosque
0.0156863: 434 bathing cap
0.0156863: 418 balloon
0.0117647: 611 jersey
walleye:/data/local/tmp $ 
&lt;/denchmark-code&gt;

Describe the expected behavior
2, 3, 4 threads (-t 2, -t 3, -t 4) are expected to return the same results as single-thread case.
Code to reproduce the issue
TFLite label_image_new_aarch64:
&lt;denchmark-code&gt;bazel build --config android_arm --cxxopt=-std=c++11  tensorflow/lite/examples/label_image:label_image  --config monolithic
&lt;/denchmark-code&gt;

label_image needs input image and labels file. I use
input_image:  &lt;denchmark-link:https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/examples/label_image/testdata/grace_hopper.bmp&gt;grace_hoper.bmp&lt;/denchmark-link&gt;

labels.txt: from &lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz&gt;mobilenet_v1_1.0_224_frozen.tgz&lt;/denchmark-link&gt;


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='freedomtan' date='2019-04-03T01:41:45Z'>
		Did you use implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly' , I  rebuild my project and got incorrect result recently but it works fine a few weeks ago,  I change that to version 1.13.1 and I got correct result but longer inference time, I think that's a bug in new version since it updates every day.
		</comment>
		<comment id='2' author='freedomtan' date='2019-04-03T01:43:00Z'>
		FYI, I got wrong results only when I use multiThreads
		</comment>
		<comment id='3' author='freedomtan' date='2019-04-03T01:59:36Z'>
		&lt;denchmark-link:https://github.com/buaadf&gt;@buaadf&lt;/denchmark-link&gt;
 I built from source code. I think what you got from  is the same problem. That is, source code changes intended to improve performance broke multithreaded results.
		</comment>
		<comment id='4' author='freedomtan' date='2019-04-03T08:50:58Z'>
		I have the same problem!
		</comment>
		<comment id='5' author='freedomtan' date='2019-04-05T17:46:54Z'>
		Reassigning to TFLite.
		</comment>
		<comment id='6' author='freedomtan' date='2019-04-10T07:10:23Z'>
		Any update? I also encounter the same issue on arm-64 linux. Threads 1, 4, 6 return different results. Single thread returns correct result.

./label_image --labels=labels.txt --image=dog.bmp --tflite_model=mobilenet_quant_v1_224.tflite --threads=1
Loaded model mobilenet_quant_v1_224.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked
average time: 242.961 ms
0.988235: 209 Labrador retriever
0.00784314: 208 golden retriever
0.00392157: 435 bath towel
0.00392157: 163 beagle


./label_image --labels=labels.txt --image=dog.bmp --tflite_model=mobilenet_quant_v1_224.tflite --threads=4
Loaded model mobilenet_quant_v1_224.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked
average time: 70.697 ms
0.172549: 751 quilt
0.145098: 895 wardrobe
0.0627451: 521 crib
0.0392157: 877 tub
0.0313726: 670 mosquito net


./label_image --labels=labels.txt --image=dog.bmp --tflite_model=mobilenet_quant_v1_224.tflite --threads=6
Loaded model mobilenet_quant_v1_224.tflite
resolved reporter
INFO: Initialized TensorFlow Lite runtime.
invoked
average time: 52.457 ms
0.392157: 521 crib
0.203922: 670 mosquito net
0.145098: 751 quilt
0.0901961: 832 studio couch
0.0901961: 565 four-poster

		</comment>
		<comment id='7' author='freedomtan' date='2019-04-10T23:38:11Z'>
		I tried to convert the .pb model as attached in the issue into tflite, but failed due to the ops "Dequantize". May I know how was this mobilenet_v1_1.0_224_quant.tflite generated?
		</comment>
		<comment id='8' author='freedomtan' date='2019-04-11T00:20:29Z'>
		&lt;denchmark-link:https://github.com/lu-wang-g&gt;@lu-wang-g&lt;/denchmark-link&gt;
 the  I tried is from this &lt;denchmark-link:http://download.tensorflow.org/models/mobilenet_v1_2018_08_02/mobilenet_v1_1.0_224_quant.tgz&gt;hosted model&lt;/denchmark-link&gt;
. There is no labels in this hosted model. So I have to get it elsewhere. Sorry for confusing you.
		</comment>
		<comment id='9' author='freedomtan' date='2019-04-22T23:43:46Z'>
		Thank you for reporting the issue and providing information to reproduce it! There is a fix to the bug, and the change has been submitted. Please check it.
		</comment>
		<comment id='10' author='freedomtan' date='2019-04-22T23:43:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27200&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27200&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>