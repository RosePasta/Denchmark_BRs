<bug id='24632' author='ageron' open_date='2018-12-30T16:10:30Z' closed_time='2019-03-05T22:32:45Z'>
	<summary>Interrupting tf.keras training while using the TensorBoard callback wreaks havoc</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OS X 10.13.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
VERSION="1.13.0-dev20181226" (this is the TF 2.0-preview)
GIT_VERSION="b'v1.12.0-5133-gc343196842'"
Python version:
3.6.6
Bazel version (if compiling from source):
N/A
GCC/Compiler version (if compiling from source):
N/A
CUDA/cuDNN version:
N/A
GPU model and memory:
N/A

Describe the current behavior
Using tf.keras in Jupyter (or a Python shell) with the TensorBoard callback, some problems occur if I interrupt training. These problems did not occur in TF 1.12:

I get an exception if I call fit() again on the same model:

&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.NotFoundError: Resource
localhost/logdir:logs/run1/N10tensorflow22SummaryWriterInterfaceE does not exist.
[Op:WriteScalarSummary] name: epoch_loss/
&lt;/denchmark-code&gt;

I can workaround this problem by recompiling the model.

I also get an exception if I interrupt training, then I delete the logs directory, then I try to use the TensorBoard callback on the same logs directory again:

&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.UnknownError: The events file logs/run1/events.out.tfevents.1546185456.macmix.local.v2 has disappeared.
	Failed to flush 1 events to logs/run1/events.out.tfevents.1546185456.macmix.local.v2
	Could not flush events file. [Op:FlushSummaryWriter]
&lt;/denchmark-code&gt;

This one is more severe: sometimes it recovers by itself after a while. Sometimes is doesn't and I cannot find any way to manually recover from this error, other than restarting the Jupyter kernel (or the Python shell).
Describe the expected behavior
I expect the TensorBoard callback to gracefully handle these issues, perhaps display a warning, but do not force a recompile or a kernel restart.
Code to reproduce the issue
import shutil
import numpy as np
import tensorflow as tf
from tensorflow import keras

X_train = np.random.rand(1000, 10)
y_train = np.random.rand(1000)
model = keras.models.Sequential([keras.layers.Dense(1)])
model.compile(loss="mse", optimizer="sgd")
tensorboard_cb = keras.callbacks.TensorBoard("logs/run1")
model.fit(X_train, y_train, epochs=1000, callbacks=[tensorboard_cb])
# NOTE: you must interrupt training (Ctrl-C) before it finishes

# For issue #1, try this:
model.fit(X_train, y_train, epochs=1000, callbacks=[tensorboard_cb])

# For issue #2, try this (you may need to interrupt and retry a few times):
shutil.rmtree("logs")
model = keras.models.Sequential([keras.layers.Dense(1)])
model.compile(loss="mse", optimizer="sgd")
tensorboard_cb = keras.callbacks.TensorBoard("logs/run1")
model.fit(X_train, y_train, epochs=1000, callbacks=[tensorboard_cb])

Here is a gist with the full session output:
&lt;denchmark-link:https://gist.github.com/ageron/1d430d4a7716c7a2bae44ee82c321f01&gt;https://gist.github.com/ageron/1d430d4a7716c7a2bae44ee82c321f01&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='ageron' date='2018-12-30T16:15:23Z'>
		Note: I checked, this issue does not occur with TF 1.12.
		</comment>
		<comment id='2' author='ageron' date='2019-01-07T21:01:46Z'>
		Hello &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
, In this issue &lt;denchmark-link:https://github.com/ageron&gt;@ageron&lt;/denchmark-link&gt;
 has outlined that for r2.0 (a) tf.Keras model training when interrupted by TensorBoard callback and then resume training generates an exception (b) interrupting training and deleting logs and invoking TensorBoard callback generates an exception. Thanks.
		</comment>
		<comment id='3' author='ageron' date='2019-01-25T05:21:41Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 are you working on TensorBoard integration? Can you take a look at this?
		</comment>
		<comment id='4' author='ageron' date='2019-01-25T08:35:21Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 Yep, will do
		</comment>
		<comment id='5' author='ageron' date='2019-01-28T19:37:29Z'>
		Hi &lt;denchmark-link:https://github.com/ageron&gt;@ageron&lt;/denchmark-link&gt;
, to clarify, this issue is occurring after you've 'd a cell in the Jupyter notebook?
		</comment>
		<comment id='6' author='ageron' date='2019-01-28T19:50:19Z'>
		Hi &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 ,
It's either in the Python shell (command line) after I press Ctrl-C during training, or in a Jupyter notebook after I interrupt the kernel during training.
Hope this helps.
		</comment>
		<comment id='7' author='ageron' date='2019-01-28T19:55:21Z'>
		I can confirm that I could reproduce the issue in a Python shell and in a Jupyter notebook, using the latest tf-nightly-2.0-preview (version '2.0.0-dev20190126', "b'v1.12.0-6726-g5522d670af'").
		</comment>
		<comment id='8' author='ageron' date='2019-02-12T23:52:02Z'>
		Thanks for the reports!
Issue 1 has the root cause &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25707&gt;#25707&lt;/denchmark-link&gt;
 which is actually independent of Keras.
Issue 2 is not strictly speaking the same problem, but the proposed solution to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25707&gt;#25707&lt;/denchmark-link&gt;
 would also fix issue 2, because it would mean each execution of the callback would create a new event file (the same as the 1.x behavior).
		</comment>
		<comment id='9' author='ageron' date='2019-03-05T22:32:44Z'>
		The root cause &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25707&gt;#25707&lt;/denchmark-link&gt;
 has been fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/826027dbd4277a2636fc2935ed245700fd01e7cd&gt;826027d&lt;/denchmark-link&gt;
, and propagated into the Keras callback by &lt;denchmark-link:https://github.com/wchargin&gt;@wchargin&lt;/denchmark-link&gt;
 in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/059ea3ba68db861e40d750eba688281011d2735f&gt;059ea3b&lt;/denchmark-link&gt;
.
Issue 1 should be completely fixed, and issue 2 should only occur if you delete the event files in the middle of training (without interrupting the keras callback, as described in the OP) while the writer is still open and then it tries to flush to the no-longer-existing file.  In that case I think it's reasonable to report the error and I believe that matches previous behavior.
		</comment>
	</comments>
</bug>