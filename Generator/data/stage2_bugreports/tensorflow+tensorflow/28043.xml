<bug id='28043' author='prclibo' open_date='2019-04-22T14:18:03Z' closed_time='2019-04-28T19:48:48Z'>
	<summary>Weird behavior using tf.Variable in a tf.data.experimental.map_and_batch callback function</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): 1.13.1 from conda
TensorFlow version (use command below): 1.13.1
Python version: 3.7.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

def foo(x):
    array = tf.Variable(lambda: tf.zeros(20, dtype=tf.float32),
            trainable=False, use_resource=True)
    ind = tf.reshape(x, [-1, 1])
    val = tf.reshape(tf.cast(x, tf.float32), [-1])

    array_assign = array.assign(tf.zeros_like(array))
    with tf.control_dependencies([array_assign]):
        array = array.scatter_nd_update(ind, tf.cast(val, dtype=tf.float32))

    return array

dataset = tf.data.Dataset.range(20)
# dataset = dataset.map(foo)
# dataset = dataset.batch(5)
dataset = dataset.apply(
        tf.data.experimental.map_and_batch(foo, 5, num_parallel_batches=1))

iterator = dataset.make_initializable_iterator()

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer)
    next_element = iterator.get_next()
    fetches = sess.run(next_element)
    print(fetches)
&lt;/denchmark-code&gt;

Describe the current behavior
If using normal map and batch, one get
&lt;denchmark-code&gt;[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
&lt;/denchmark-code&gt;

Describe the expected behavior
If using map_and_batch, one get changing results like:
&lt;denchmark-code&gt;[[0. 1. 2. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 2. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 2. 3. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
&lt;/denchmark-code&gt;

There should be always only one and non-duplicate non-zeros per-line.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Not sure if this is related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27507&gt;#27507&lt;/denchmark-link&gt;
 . On a &lt;denchmark-link:https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF&gt;Colab with tf-nightly&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27507&gt;#27507&lt;/denchmark-link&gt;
 seems fixed but this issue still reproduces.
	</description>
	<comments>
		<comment id='1' author='prclibo' date='2019-04-23T22:15:53Z'>
		&lt;denchmark-link:https://github.com/prclibo&gt;@prclibo&lt;/denchmark-link&gt;
 I got the following result
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
Could you try to run it in Google colab or upgrade your TF1.13.1 and run it. Please let me know how it progresses. Thanks!
		</comment>
		<comment id='2' author='prclibo' date='2019-04-23T23:25:10Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 No, on the above colab (&lt;denchmark-link:https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF&gt;https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF&lt;/denchmark-link&gt;
) the issue still reproduces (though seems less messy), with updated tf-nightly version:

Successfully installed google-pasta-0.1.5 tb-nightly-1.14.0a20190423 tf-estimator-nightly-1.14.0.dev2019042301 tf-nightly-1.14.1.dev20190423 wrapt-1.11.1

Which version are you using?
		</comment>
		<comment id='3' author='prclibo' date='2019-04-24T01:54:29Z'>
		&lt;denchmark-link:https://github.com/prclibo&gt;@prclibo&lt;/denchmark-link&gt;
 I had used TF1.13.1 as you mentioned TF1.13.1 in your issue template.
I just tried TF-nightly and the output is as follows
W0424 01:48:58.248569 139709344798592 deprecation.py:323] From :19: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.
Instructions for updating:
Use  followed by . Static tf.data optimizations will take care of using the fused implementation.
[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 2. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
The result is not what is expected but the map_and_batch is going to be deprecated (check the warning above). The suggested op is map followed by batch which is working well in tf-nightly.  What is the point in using deprecated op when you have better working ops that replaced the deprecated op. Please let me know what you think. Thanks!
		</comment>
		<comment id='4' author='prclibo' date='2019-04-24T03:29:02Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks for the tests. However I still reproduce it with separate  and  in 1.14.1-dev20190423 (). See the last cell in &lt;denchmark-link:https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF&gt;https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF&lt;/denchmark-link&gt;

Maybe you can share a successful Colab?
		</comment>
		<comment id='5' author='prclibo' date='2019-04-24T18:13:12Z'>
		&lt;denchmark-link:https://github.com/prclibo&gt;@prclibo&lt;/denchmark-link&gt;
 I have changed one line in your code

This is the output I get
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/2f3d68380a525f793bf63b7f13543c9e/test_tensorflow_27507.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='prclibo' date='2019-04-24T23:47:33Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 thanks, but setting  does not really solve the issue, right?
I would expect that when  each line in its output has only one element scattered and the element is different from each other lines. The order of line can be permuted or not depending on the threading implementation. But the issue is not solved for  right now.
		</comment>
		<comment id='7' author='prclibo' date='2019-04-26T17:37:01Z'>
		The behavior you see if expected because your foo function is using shared state -- the array variable will be shared by all invocations of the foo function because that's how resource variables in TensorFlow work. Furthermore, map_and_batch with num_parallel_batches with perform concurrent invocations of foo. That means that you will have multiple instances of foo all accessing (reading / writing) array at the same time, which explains the behavior you are seeing.
If you would like to achieve the "expected" behavior, use a constant instead of variable. As far as I can tell there is no good reason for you to need to be using a variable.
		</comment>
		<comment id='8' author='prclibo' date='2019-04-26T23:45:19Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Thanks. The reason of using a variable is that I failed to use a constant tensor in a  callback operated by . See the second cell in &lt;denchmark-link:https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF#scrollTo=JhIQnyNFYIR6&gt;https://colab.research.google.com/drive/1DzTvOJRXYUk0CSjvGa11ewmjTP7VJ1kF#scrollTo=JhIQnyNFYIR6&lt;/denchmark-link&gt;

Doing scattering onto a constant tf.zeros(20) causes AttributeError: 'Tensor' object has no attribute '_lazy_read'. Is there any workaround to solve this?
		</comment>
		<comment id='9' author='prclibo' date='2019-04-28T19:48:48Z'>
		You can achieve the desired the behavior using the following simpler program:
&lt;denchmark-code&gt;import tensorflow as tf

def foo(x):
  array = tf.one_hot(x, 20) * tf.cast(x, dtype=tf.float32)
  return array

dataset = tf.data.Dataset.range(20)
dataset = dataset.map(foo)
dataset = dataset.batch(5)

iterator = dataset.make_initializable_iterator()

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(iterator.initializer)
    next_element = iterator.get_next()
    fetches = sess.run(next_element)
    print(fetches)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='prclibo' date='2019-04-28T19:48:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28043&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28043&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>