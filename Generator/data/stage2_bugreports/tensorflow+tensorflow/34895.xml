<bug id='34895' author='jnsgrnborg' open_date='2019-12-06T10:49:11Z' closed_time='2019-12-12T18:54:01Z'>
	<summary>SavedModel format for tf.estimator class in Tensorflow 2.0</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac os mojave 10.14.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version (use command below):  2.0.0
Python version: 2.7.10
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
I'm moving to TF 2.0 with its very nice dataset functionalities, but I got stuck when I want to save the model in the SavedModel format.
I'm using the estimator class to do a linear regression, and after training this is how I'd set up the export in TF 1:
&lt;denchmark-code&gt;columns = [('hour', tf.int64),
           ('domain', tf.string),
           ('device_type', tf.string)]
feature_placeholders = {
 name: tf.placeholder(dtype, [1], name=name + "_placeholder")
 for name, dtype in columns
}
&lt;/denchmark-code&gt;

I have three features with different datatypes, and I use the placeholder method to concatenate them into a dict that is then served using the tf.estimator.export.build_raw_serving_input_receiver_fn() method, and finally exported using the estimator.export_saved_model to my model directory:
&lt;denchmark-code&gt;export_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(
    feature_placeholders)
estimator.export_saved_model(model_dir, export_input_fn)
&lt;/denchmark-code&gt;

All tutorials online uses this series of steps, but tf.placeholder() doesn't exist in TF 2.0, so how can I do this?
	</description>
	<comments>
		<comment id='1' author='jnsgrnborg' date='2019-12-12T18:53:57Z'>
		In 2.0, you can use tf.compat.v1.placeholder. We have &lt;denchmark-link:https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a&gt;moved to Keras as the primary high level API&lt;/denchmark-link&gt;
, and would encourage you to write your models using Keras if possible. Estimator is fundamentally tied to v1/Sessions, so if you must stay in the Estimator ecosystem, you will likely have to use some amount of compat.v1 functionality.
		</comment>
		<comment id='2' author='jnsgrnborg' date='2019-12-14T15:49:54Z'>
		Hey Karmel
Thanks for answering!
Currently I'm training in TF 2.0 and then serializing in TF 1.x. Seems to be working..
		</comment>
		<comment id='3' author='jnsgrnborg' date='2020-04-21T21:34:22Z'>
		&lt;denchmark-link:https://github.com/jnsgrnborg&gt;@jnsgrnborg&lt;/denchmark-link&gt;
  have you tried reverse ? training in TF 1.x and serializing in TF 2.0 ?
		</comment>
	</comments>
</bug>