<bug id='45317' author='idavidrein' open_date='2020-12-02T00:12:26Z' closed_time='2020-12-04T15:47:29Z'>
	<summary>tf.shape is broken when drop_remainder=True on TPUs</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.3.0
Python version: 3.7.7
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: n/a
GPU model and memory: n/a

Describe the current behavior
tf.shape gives incorrect tensor shapes when used with drop_remainder=False while batching a Dataset on TPUs.
Describe the expected behavior
tf.shape should always return the correct tensor shape regardless of the value of drop_remainder.

&lt;denchmark-link:https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing&gt;https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='idavidrein' date='2020-12-02T07:46:06Z'>
		I have tried in colab with TF 2.3 and was able to reproduce the issue. However in TF nightly i am seeing the error ().Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/1e772687b9d16778dfcdc51d2a9ff803/untitled556.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='idavidrein' date='2020-12-03T20:00:01Z'>
		Please remove with tpu_strategy.scope(): from your code, as you are already running through strategy.run.
This should run correctly:
&lt;denchmark-code&gt;@tf.function
def run(ds, strategy):
  def step(features):
    x = tf.concat([features['a'], features['b']], axis=0)
    return x, tf.shape(x)[0]
  return strategy.run(step, args=(next(ds),))

print(run(ds, tpu_strategy))
&lt;/denchmark-code&gt;

Also, when running on a TPU, please choose your batch size to be a multiple of the number of cores (8 in this case).
If you need to run tf-nightly in colab, besides installing Tensorflow  version in colab, you will also need to choose a corresponding Tensorflow version on TPU, please see &lt;denchmark-link:https://stackoverflow.com/questions/63180202/invalidargumenterror-while-initializing-ttpu/63271669#63271669&gt;here&lt;/denchmark-link&gt;
 for the commands.
		</comment>
		<comment id='3' author='idavidrein' date='2020-12-03T21:27:09Z'>
		
Please remove with tpu_strategy.scope(): from your code, as you are already running through strategy.run.
This should run correctly:
@tf.function
def run(ds, strategy):
  def step(features):
    x = tf.concat([features['a'], features['b']], axis=0)
    return x, tf.shape(x)[0]
  return strategy.run(step, args=(next(ds),))

print(run(ds, tpu_strategy))

Also, when running on a TPU, please choose your batch size to be a multiple of the number of cores (8 in this case).
If you need to run tf-nightly in colab, besides installing Tensorflow tf-nightly version in colab, you will also need to choose a corresponding Tensorflow version on TPU, please see here for the commands.

Hi, thank you for the tips! However, removing the scope() and changing the batch size doesn't seem to work unfortunately, as you can see here: &lt;denchmark-link:https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing&gt;https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='idavidrein' date='2020-12-04T00:14:05Z'>
		
Hi, thank you for the tips! However, removing the scope() and changing the batch size doesn't seem to work unfortunately, as you can see here: https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing

Looks like this issue was fixed in tf-nightly.
To test on tf-nightly, you can use the following code in colab:
&lt;denchmark-code&gt;!pip install tf-nightly
&lt;/denchmark-code&gt;

Restart the runtime and run:
&lt;denchmark-code&gt;!pip install cloud-tpu-client

import tensorflow as tf
from cloud_tpu_client import Client
print(tf.__version__)

Client().configure_tpu_version(tf.__version__, restart_type='ifNeeded')
&lt;/denchmark-code&gt;

After which the shape should work correctly.
Another thing that you can try for TF 2.3 is disabling dynamic batch size in strategy.run:
&lt;denchmark-code&gt;strategy.run(step, args=(next(ds),), options=tf.distribute.RunOptions(experimental_enable_dynamic_batch_size=False))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='idavidrein' date='2020-12-04T15:47:28Z'>
		&lt;denchmark-link:https://github.com/gagika&gt;@gagika&lt;/denchmark-link&gt;
 Yeah that works! Thanks for the help 
		</comment>
		<comment id='6' author='idavidrein' date='2020-12-04T15:47:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45317&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45317&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>