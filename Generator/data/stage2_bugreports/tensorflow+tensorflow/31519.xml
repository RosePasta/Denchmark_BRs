<bug id='31519' author='zwenju' open_date='2019-08-11T15:17:02Z' closed_time='2019-08-22T01:29:18Z'>
	<summary>TF 2.0  ft.GradientTape() gradient()  second gradient None</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Anaconda
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below): tensorflow 2.0b1
Python version:  3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
second gradient with input  is None
Describe the expected behavior
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import time
import math
import tensorflow as tf
import numpy as np
import tensorflow as keras
from tensorflow.keras import layers
from tensorflow import keras
from tensorflow.keras.utils import plot_model
from scipy . stats import multivariate_normal as normal

d = 2
batch_size = 3


def func(x):
    x = x*x
    x = keras.layers.Dense(d)(x)
    return x

Input  = keras.Input(shape = (d,), dtype = tf.float64, name = 'X' )
Output = func(Input)
model = keras.Model(inputs=Input, outputs=Output)



x_train = tf.random.uniform( (batch_size, d), minval=0, maxval=1, dtype=tf.float64, seed=1000)

for epoch in range (1):
    with tf.GradientTape() as t1:
        t1.watch(x_train)
        with tf.GradientTape() as t2:
            t2.watch(x_train)
            predictions = model( x_train )

        dy_dx = t2.gradient(predictions, x_train)
        print("dy_dx = ", dy_dx)
    dyy_dx = t1.gradient(dy_dx, x_train)

    print("dyy_dx = ", dyy_dx)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
W0811 23:13:04.473541 11804 ag_logging.py:145] Entity &lt;bound method TensorFlowOpLayer._defun_call of &lt;tensorflow.python.eager.function.TfMethodTarget object at 0x0000025C98A045F8&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: converting &lt;bound method TensorFlowOpLayer._defun_call of &lt;tensorflow.python.eager.function.TfMethodTarget object at 0x0000025C98A045F8&gt;&gt;: AssertionError:
WARNING: Entity &lt;bound method TensorFlowOpLayer._defun_call of &lt;tensorflow.python.eager.function.TfMethodTarget object at 0x0000025C98A045F8&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: converting &lt;bound method TensorFlowOpLayer._defun_call of &lt;tensorflow.python.eager.function.TfMethodTarget object at 0x0000025C98A045F8&gt;&gt;: AssertionError:
dy_dx =  tf.Tensor(
[[0.03395048 0.86635576]
[0.52642456 0.80100264]
[1.05554004 0.05975098]], shape=(3, 2), dtype=float64)
dyy_dx =  None
	</description>
	<comments>
		<comment id='1' author='zwenju' date='2019-08-13T09:54:19Z'>
		&lt;denchmark-link:https://github.com/zwenju&gt;@zwenju&lt;/denchmark-link&gt;
 ,
Hi,When tried executing the given code error  was faced.Thanks!
		</comment>
		<comment id='2' author='zwenju' date='2019-08-13T12:23:41Z'>
		Please , try the new code,  I have change neutron_network to func.  thanks
		</comment>
		<comment id='3' author='zwenju' date='2019-08-14T09:24:31Z'>
		&lt;denchmark-link:https://github.com/zwenju&gt;@zwenju&lt;/denchmark-link&gt;
,
Thank you for the code,when tried executing the given code i got the output as per the screenshot
&lt;denchmark-link:https://user-images.githubusercontent.com/52397990/63010108-667e2300-bea3-11e9-958e-b8a9a8e843f5.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='zwenju' date='2019-08-14T11:41:21Z'>
		Thank you,      dyy_dx = None  is  actually not the expected result.
Could you fix this bug ?
Thanks.
		</comment>
		<comment id='5' author='zwenju' date='2019-08-21T23:23:23Z'>
		This is fixed with latest version TF 2.0 nightly
Output in TF 2.0 nightly version 2.0.0-dev20190821
dy_dx =  tf.Tensor(
[[ 2.84032801 -0.34441594]
 [ 0.12755782 -0.69508436]
 [ 1.86527439 -0.02203789]], shape=(3, 2), dtype=float64)
dyy_dx =  tf.Tensor(
[[ 3.79678631 -0.80638027]
 [ 3.79678631 -0.80638027]
 [ 3.79678631 -0.80638027]], shape=(3, 2), dtype=float64)
		</comment>
		<comment id='6' author='zwenju' date='2019-08-22T01:29:18Z'>
		Great Thanks.
		</comment>
		<comment id='7' author='zwenju' date='2019-08-22T01:29:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31519&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31519&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>