<bug id='27627' author='csukuangfj' open_date='2019-04-08T09:58:04Z' closed_time='2019-06-20T22:12:08Z'>
	<summary>[doc/keras] `__init__` of `tf.keras.losses.BinaryCrossentropy` is not rendered correctly</summary>
	<description>

Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#class_binarycrossentropy

Describe the documentation issue
The __init__ function of tf.keras.losses.BinaryCrossentropy is not rendered correctly.
See the link here &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#methods&gt;https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy#methods&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='csukuangfj' date='2019-04-08T10:47:23Z'>
		You mean that in documentation __init__ is not described directly it is started from __call__?
		</comment>
		<comment id='2' author='csukuangfj' date='2019-04-08T11:50:47Z'>
		&lt;denchmark-link:https://github.com/shashvatshahi1998&gt;@shashvatshahi1998&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;
#### Args:

* &lt;b&gt;`from_logits`&lt;/b&gt;: Whether `output` is expected to be a logits tensor. By default,
    we consider that `output` encodes a probability distribution.
* &lt;b&gt;`label_smoothing`&lt;/b&gt;: If greater than `0` then smooth the labels.
* &lt;b&gt;`reduction`&lt;/b&gt;: Type of &lt;a href="../../../tf/losses/Reduction"&gt;&lt;code&gt;tf.losses.Reduction&lt;/code&gt;&lt;/a&gt; to apply to loss. Default value is
    `SUM_OVER_BATCH_SIZE`.
* &lt;b&gt;`name`&lt;/b&gt;: Optional name for the op.

&lt;h2 id="__init__"&gt;&lt;code&gt;__init__&lt;/code&gt;&lt;/h2&gt;

``` python
__init__(
    from_logits=False,
    label_smoothing=0,
    reduction=losses_impl.ReductionV2.SUM_OVER_BATCH_SIZE,
    name=None
)

---------
is obviously in its raw format.
---------
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='csukuangfj' date='2019-06-20T22:12:07Z'>
		Closing this issue since this is resolved. Feel free to reopen if have further questions. Thanks!
		</comment>
	</comments>
</bug>