<bug id='29531' author='Nitinsiwach' open_date='2019-06-07T13:17:05Z' closed_time='2019-07-16T18:52:19Z'>
	<summary>model.trainable=False and layer.trainable=False for each layer giving very different performance</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):source
TensorFlow version (use command below):1.3
Python version:2.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:10.1.105
GPU model and memory:m60, 8gb

for layer in base_model_seq.layers:
    layer.trainable=False
and
base_model_seq.trainable=False
are giving very different results. To my understanding both are the ways to achieve same behavior
Data pipeline: This remains exactly same in both the cases. Providing the code for reference
&lt;denchmark-code&gt;import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
img_height = 224
img_width = 224
from random_eraser import get_random_eraser
IMAGE_DIR = "./data/images"
traincsv = pd.read_csv('./data/train.csv')
testcsv = pd.read_csv('./data/test_ApKoW4T.csv')
traincsv['category'] = traincsv['category'].astype(str)
train_batch_size=32
val_batch_size = 32
test_batch_size = 32
seed = 43
traincsv = pd.read_csv('./data/train.csv')
testcsv = pd.read_csv('./data/test_ApKoW4T.csv')
traincsv['category'] = traincsv['category'].astype(str)
df_train,df_val = train_test_split(traincsv, stratify = traincsv.category, random_state=42, test_size=.1, shuffle=True)
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10,width_shift_range=0.3, height_shift_range=0.3, 
                                                            rescale=1./255, shear_range=0.0,zoom_range=0.3, horizontal_flip=True, fill_mode='nearest',
                                                            preprocessing_function=get_random_eraser(pixel_level=True,s_h=0.4))

val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_dataframe(df_train,directory = IMAGE_DIR,x_col='image',y_col='category',
           class_mode="categorical", target_size=(img_height, img_width), batch_size=train_batch_size,shuffle=True)

validation_generator = val_datagen.flow_from_dataframe(df_val,directory=IMAGE_DIR,x_col='image',y_col='category',
           class_mode="categorical", target_size=(img_height, img_width),batch_size=val_batch_size,shuffle=True)

steps_per_epoch = train_generator.n // 32
validation_steps =  validation_generator.n //32
&lt;/denchmark-code&gt;

Now the piece followed by ######... is the only part i change in running the two experiments but i get drastically different results
&lt;denchmark-code&gt;import tensorflow as tf

from __future__ import absolute_import, division, print_function

import os

import tensorflow as tf
from tensorflow import keras
print("TensorFlow version is ", tf.__version__)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from tensorflow.keras.applications import MobileNet, InceptionResNetV2
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.python.keras.applications import densenet_rootexposed
import tensorflow as tf

IMAGE_DIR = "./data/images"
img_height =224
img_width = 224
IMG_SHAPE = (img_height,img_width, 3)
def step_decay(epoch, lr):
    print(lr)
    drop = 0.96
    return lr*drop
lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)
callbacks = [lrate]
base_model_seq = keras.applications.densenet.DenseNet201(input_shape=IMG_SHAPE,
                                              include_top=False, 
                                                weights='imagenet')
#######################################This is the only part i change while training the models
base_model_seq.trainable=False
# for layer in base_model_seq.layers:
#     layer.trainable=False
#######################################
model_seq = tf.keras.Sequential([
  base_model_seq,
  keras.layers.Flatten(),
  keras.layers.Dropout(0.5),
  keras.layers.Dense(2048, activation='relu'),
  keras.layers.Dropout(0.5),
  keras.layers.BatchNormalization(),
  keras.layers.Dense(5, activation='softmax')
])


for layer in base_model_seq.layers:
    layer._name = layer._name + str("_1729")
print(len(model_seq.trainable_variables))


model_seq.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])

print('************************')
print(model_seq.summary())
epochs = 100

&lt;/denchmark-code&gt;

when i run it by freezing the model with base_model_seq.trainable=False the model starts with .8 val accuracy and rises up to .91 in first 20 epochs but when i run it by freezing the model with
 for layer in base_model_seq.layers: layer.trainable=False
The validation accuracy starts with .72 and reaches .82 in 20 epochs and then stalls there. I have repeated the experiment enough number of times to ensure this cannot be attributed to chance initialization. Please point me to the source of inconsistency in the approaches i have describes
	</description>
	<comments>
		<comment id='1' author='Nitinsiwach' date='2019-07-08T21:42:46Z'>
		&lt;denchmark-link:https://github.com/Nitinsiwach&gt;@Nitinsiwach&lt;/denchmark-link&gt;
 Is this resolved? I know you had opened another similar issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29535&gt;#29535&lt;/denchmark-link&gt;
. If it was not resolved, please provide a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='Nitinsiwach' date='2019-07-16T18:52:19Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='3' author='Nitinsiwach' date='2019-07-16T18:52:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29531&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29531&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>