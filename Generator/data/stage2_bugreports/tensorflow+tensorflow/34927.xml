<bug id='34927' author='wzzhu' open_date='2019-12-07T13:36:12Z' closed_time='2019-12-10T00:11:26Z'>
	<summary>Bad example in Sparse_Categorical_CrossEntropy</summary>
	<description>
&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;

Please provide a link to the documentation entry, for example:



tensorflow/tensorflow/python/keras/losses.py


         Line 493
      in
      1cf0898






     [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]]) 





&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

The example will cause errors:
cce = tf.keras.losses.SparseCategoricalCrossentropy()
loss = cce(
[0, 1, 2],
[[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])
print('Loss: ', loss.numpy())  # Loss: 0.3239
Need to change to
cce = tf.keras.losses.SparseCategoricalCrossentropy()
loss = cce(
[0, 1, 2],
tf.constant([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]]))
print('Loss: ', loss.numpy())  # Loss: 0.3239
In addition [.5, .89, .6] should be [0.05, 0.89, 0.06] to be consistent with similar example (
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy?hl=en&gt;https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy?hl=en&lt;/denchmark-link&gt;
). Thus Loss should be updated to 0.0945
	</description>
	<comments>
		<comment id='1' author='wzzhu' date='2019-12-08T17:02:49Z'>
		&lt;denchmark-link:https://github.com/wzzhu&gt;@wzzhu&lt;/denchmark-link&gt;
 I am not able to observe the error with the latest tf-nightly. Can you show the version of the tf you are using?
		</comment>
		<comment id='2' author='wzzhu' date='2019-12-09T01:14:58Z'>
		I first found the problem in Tensorflow 2.0 stable version. When I tried running with nightly (in colab), it still had errors:
!pip install tf-nightly-2.0-preview
import tensorflow as tf
cce = tf.keras.losses.SparseCategoricalCrossentropy()
loss = cce([0, 1, 2], [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])
print('Loss: ', loss.numpy())  # Loss: 0.3239
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in sparse_categorical_crossentropy(target, output, from_logits, axis)
4523   if not from_logits:
4524     if (isinstance(output, (ops.EagerTensor, variables_module.Variable)) or
-&gt; 4525         output.op.type != 'Softmax'):
4526       epsilon_ = constant_to_tensor(epsilon(), output.dtype.base_dtype)
4527       output = clip_ops.clip_by_value(output, epsilon, 1 - epsilon_)
AttributeError: 'list' object has no attribute 'op'
		</comment>
		<comment id='3' author='wzzhu' date='2019-12-09T01:58:55Z'>
		&lt;denchmark-link:https://github.com/wzzhu&gt;@wzzhu&lt;/denchmark-link&gt;
 tf-nightly-2.0-preview has not been updated even before 2.0 released as it has been switched to tf-nightly. The last version of tf-nightly-2.0-preview was released in 10/02:
&lt;denchmark-link:https://pypi.org/project/tf-nightly-2.0-preview/#history&gt;https://pypi.org/project/tf-nightly-2.0-preview/#history&lt;/denchmark-link&gt;

Please use tf-nightly instead.
		</comment>
		<comment id='4' author='wzzhu' date='2019-12-09T02:27:13Z'>
		Right, it was TensorFlow Ver:  2.0.0-dev20191002.
I tried tf-nightly and it works. Thanks.
But the numbers still need updating to as [.5, 0.89, .6] is logits instead of a prob distribution as in categorical crossentropy example which is [.05, .89, .06]
		</comment>
		<comment id='5' author='wzzhu' date='2019-12-09T11:04:14Z'>
		Could reproduce the issue with TF version 2.0. Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/amahendrakar/6019a161a256e9a461093b9ea53279fd/34927.ipynb&gt;Gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='wzzhu' date='2019-12-09T16:27:05Z'>
		&lt;denchmark-link:https://github.com/wzzhu&gt;@wzzhu&lt;/denchmark-link&gt;
 Looks like the docstring has been fixed in  commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/c7061962262c8cacc4017b352f32d2134216ca4a&gt;c706196&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='wzzhu' date='2019-12-10T00:11:26Z'>
		Closing this issue since its resolved. Thanks!
		</comment>
	</comments>
</bug>