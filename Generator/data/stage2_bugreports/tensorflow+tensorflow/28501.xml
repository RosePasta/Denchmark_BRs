<bug id='28501' author='BrikerMan' open_date='2019-05-08T03:17:29Z' closed_time='2019-06-13T02:59:08Z'>
	<summary>tf2.0, tf.keras Embedding layer behave different than tf1.13</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.6.7

from tensorflow import keras
import numpy as np

L = keras.layers

embedding_matrix = np.random.random((10, 5))

model = keras.Sequential([
    L.Embedding(input_dim=10, 
                output_dim=5,
                weights=[embedding_matrix],
                trainable=False)
])

model.compile('rmsprop', 'mse')

embedding_matrix[2] == model.predict([2])[0][0]
Describe the current behavior
embedding_matrix[2] is not equal to  model.predict([2])[0][0].
Describe the expected behavior
embedding_matrix[2] should equal to  model.predict([2])[0][0], those two equals on tf 1.13.1 version.
	</description>
	<comments>
		<comment id='1' author='BrikerMan' date='2019-05-14T18:22:56Z'>
		&lt;denchmark-link:https://github.com/BrikerMan&gt;@BrikerMan&lt;/denchmark-link&gt;
 I was not able to reproduce the reported behavior.  I executed the above code snippet in TF 1.13.1 and 2.0 alpha to receive identical results as given below:
array([False, False, False, False, False])
Can you please try executing your code in &lt;denchmark-link:https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true&gt;google colab&lt;/denchmark-link&gt;
 and confirm? Thanks!
		</comment>
		<comment id='2' author='BrikerMan' date='2019-05-15T04:02:56Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 I have tried it with colab, it should be equal when using 1.13.1.
I have changed the last line of my code and it works as expected.
&lt;denchmark-code&gt;model.predict([2])[0][0] == np.array(embedding_matrix[2], dtype=np.float32)
&lt;/denchmark-code&gt;

result is
# 1.13.1
array([ True,  True,  True,  True,  True])
# 2.0 alpha
array([False, False, False, False, False])
Here is demo colab: &lt;denchmark-link:https://colab.research.google.com/drive/1Y1ObMAg3H2O47on58t2hdirRUr6M172o&gt;https://colab.research.google.com/drive/1Y1ObMAg3H2O47on58t2hdirRUr6M172o&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='BrikerMan' date='2019-05-16T17:03:23Z'>
		Thanks for the report. (And excellent example!)
What's happening is that we don't pick up the initial weights in eager mode. (Which definitely needs to be fixed.) 


tensorflow/tensorflow/python/keras/engine/base_layer.py


         Line 683
      in
      f0836d2






 if not context.executing_eagerly(): 





We (the keras team) will triage and report back.
		</comment>
		<comment id='4' author='BrikerMan' date='2019-06-13T01:32:02Z'>
		&lt;denchmark-link:https://github.com/BrikerMan&gt;@BrikerMan&lt;/denchmark-link&gt;
 This appears to be fixed with latest TF 2.0 nightly (2.0.0-dev20190612) Can you please confirm?
		</comment>
		<comment id='5' author='BrikerMan' date='2019-06-13T02:58:56Z'>
		
@BrikerMan This appears to be fixed with latest TF 2.0 nightly (2.0.0-dev20190612) Can you please confirm?

Fixed, thanks~
		</comment>
		<comment id='6' author='BrikerMan' date='2019-06-13T02:59:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28501&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28501&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>