<bug id='41900' author='ml-0' open_date='2020-07-30T14:38:10Z' closed_time='2020-09-25T21:28:45Z'>
	<summary>TFLu r2.3: Broken memory allocation for micro interpreter object with TF_LITE_STATIC_MEMORY enabled</summary>
	<description>
Compiling TFLu r2.3 with TF_LITE_STATIC_MEMORY gives an incorrect memory allocation for the micro interpreter object.
System information

TFLu r2.3
OS Platform: Linux Ubuntu 16.04 or Windows 10 64 bit
Target: Cortex M4F

Current behavior
In my case the size of the network input data is
interpreter-&gt;input(0)-&gt;bytes = 1920
After calling for memory allocation
TfLiteStatus allocate_status = interpreter-&gt;AllocateTensors();
the memory address of the input data is
interpreter-&gt;input(0)-&gt;data = 0x8012174
and memory address of the input tensor structure is
interpreter-&gt;input(0) = 0x8012570
This gives only 1020 bytes memory space for the data which is 1920 btes. As a consequence, the input tensor structure is overwritten when copying the input data.
Expected behavior
After removing TF_LITE_STATIC_MEMORY from the CCFLAGS/CXXFLAGS the memory allocation leaves enough space between the data and the input tensor structure:
interpreter-&gt;input(0) = 0x80124d0
interpreter-&gt;input(0)-&gt;data = 0x80103c0

Using TFLu r2.2 with TF_LITE_STATIC_MEMORY does not show the problem. It gives correct memory layout. Starting with commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/fbf407383c93774d10bd7c45cd66788a070b0e07&gt;fbf4073&lt;/denchmark-link&gt;
 (mid of June '20) the memory layout is broken.
I'm not sure if this is a bug or if it is intended behavior and I better compile without TF_LITE_STATIC_MEMORY.
	</description>
	<comments>
		<comment id='1' author='ml-0' date='2020-08-06T21:13:59Z'>
		It looks like this may be related to some of our memory optimization efforts. I have filed an internal bug to track this and will update when we have a resolution.
		</comment>
		<comment id='2' author='ml-0' date='2020-08-07T06:46:06Z'>
		Thx for looking into this. As indicated in my bug description, temporary workarounds are

using r2.2
using r2.3 without TF_LITE_STATIC_MEMORY in the CCFLAGS/CXXFLAGS

		</comment>
		<comment id='3' author='ml-0' date='2020-09-25T21:28:44Z'>
		This is a case of our making changes that are not backwards compatible coupled with the fact that Tensorflow Lite Micro doesn't currently conform to the release cadence of the broader Tensorflow project.
My recommendation here is to use TFLM from source. Since we no longer support using TFLM without TF_LITE_STATIC_MEMORY (and have thus made it the default in our Makefile).
I'm going to close the current issue but please open a new one if you are seeing issues when building from source.
		</comment>
		<comment id='4' author='ml-0' date='2020-09-25T21:28:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41900&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41900&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ml-0' date='2020-09-29T13:48:49Z'>
		I just found the reason for the observation on my side: the application project includes header files from TFLM to instantiate the interpreter. I missed to define TF_LITE_STATIC_MEMORY when including such header files.
Is not a bug in TFLM. Sorry for the confusion.
		</comment>
		<comment id='6' author='ml-0' date='2020-10-05T14:24:20Z'>
		&lt;denchmark-link:https://github.com/ml-0&gt;@ml-0&lt;/denchmark-link&gt;
 Hi, I'm experiencing a similar issue. Could you clarify which header files you are referring to? thanks in advanced.
		</comment>
		<comment id='7' author='ml-0' date='2020-10-05T16:03:24Z'>
		I think what &lt;denchmark-link:https://github.com/ml-0&gt;@ml-0&lt;/denchmark-link&gt;
 is referring to is that any external code that includes TFLM headers should be built with , or have a  before the headers are included.
Apologies for not being very clear with my previous reply - what I was emphasizing is that using TFLM without TF_LITE_STATIC_MEMORY defined isn't really supported anymore, even on x86.
		</comment>
		<comment id='8' author='ml-0' date='2020-10-06T06:49:26Z'>
		Hi &lt;denchmark-link:https://github.com/COTASPAR&gt;@COTASPAR&lt;/denchmark-link&gt;
, my application project comes with its own Makefile (not part of TFLM) and links against the libtensorflow_microlite .a. To instantiate the TFLM interpreter I have to include
&lt;denchmark-code&gt;#include "tensorflow/lite/micro/kernels/micro_ops.h"
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/version.h" 
#include "tensorflow/lite/c/common.h"
&lt;/denchmark-code&gt;

As the last include (common.h) heavily uses TF_LITE_STATIC_MEMORY this macro has to be defined in the application project as well. If not, the application uses a different definition for TfLiteTensor as the library does.
This problem does not appear in all the examples that come with TFLM because they compile TFLM + the example code with the same settings (single Makefile).
&lt;denchmark-link:https://github.com/advaitjain&gt;@advaitjain&lt;/denchmark-link&gt;
 Do you see the chance to avoid such problems by inverting the definition of TF_LITE_STATIC_MEMORY? The code we should use does not require it and it has to be defined only for special purposes?
		</comment>
		<comment id='9' author='ml-0' date='2020-10-07T00:00:32Z'>
		Unfortunate as it is, its best to use TFLM with  TF_LITE_STATIC_MEMORY. It has basically become a way to separate the TFLM build graph from the TfLite build graph.
Without this define, the performance is degraded due to allocations of TfLiteTensors from the temp space at each Eval. More importantly, its not a path that we test or support anymore so there can definitely be bugs.
We would like to get to a point where TFLM does not need this additional define at all, but the code sharing with TfLite (via common.h as you pointed out and more) makes it something that will take some time to disentangle.
		</comment>
	</comments>
</bug>