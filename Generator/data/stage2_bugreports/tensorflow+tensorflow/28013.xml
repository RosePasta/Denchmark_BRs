<bug id='28013' author='hksonngan' open_date='2019-04-21T06:13:13Z' closed_time='2019-06-06T16:56:23Z'>
	<summary>[TF 2.0] tf.assert_equal funtion raise exception InternalError with unsigned 16, 32, 64</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab.google.com (linux)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: not test
TensorFlow installed from (source or binary): binary (nighty)
TensorFlow version (use command below): 2.0.0-dev20190420
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: NVIDIA-SMI 418.56 Driver Version: 410.79 CUDA Version: 10.0
GPU model and memory: Tesla T4


As documented function &lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/debugging/assert_equal&gt;assert_equal&lt;/denchmark-link&gt;
 accept any dtype. But it raises an exception InternalError with type: uint16, 32, 64. Test with CPU and GPU.

Not raises an exception InternalError with type: uint16, 32, 64.

import tensorflow as tf
from tensorflow.python.ops import bitwise_ops
from tensorflow.python.framework import dtypes
print(tf.__version__)
# tf.uint16, tf.uint32, tf.uint64
lhs = tf.constant([5, 0, 7, 11], dtype=tf.uint16)
rhs = tf.constant([5, 0, 7, 11], dtype=tf.uint16)
tf.assert_equal(lhs, rhs)
may be same other asser functions: raise exception with assert_greater
lhs = tf.constant([7], dtype=tf.uint16)
rhs = tf.constant([9], dtype=tf.uint16)
tf.assert_greater(lhs, rhs)
Other info / logs
LOGS

---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
&lt;ipython-input-17-b706d33af3c8&gt; in &lt;module&gt;()
     10   exp = tf.constant([0, 0, 3, 10], dtype=dtype)
     11   res = bitwise_ops.bitwise_and(lhs, rhs)
---&gt; 12   tf.assert_equal(res, exp) # TRUE

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py in assert_equal_v2(x, y, message, summarize, name)
    452       execution or if `x` and `y` are statically known.
    453   """
--&gt; 454   return assert_equal(x=x, y=y, summarize=summarize, message=message, name=name)
    455 
    456 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/check_ops.py in assert_equal(x, y, data, summarize, message, name)
    496 
    497     if context.executing_eagerly():
--&gt; 498       eq = math_ops.equal(x, y)
    499       condition = math_ops.reduce_all(eq)
    500       if not condition:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py in equal(x, y, name)
   3449       else:
   3450         message = e.message
-&gt; 3451       _six.raise_from(_core._status_to_exception(e.code, message), None)
   3452   # Add nodes to the TensorFlow graph.
   3453   try:

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InternalError: Could not find valid device for node.
Node: {{node Equal}}
All kernels registered for op Equal :
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT8, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_QINT8, DT_QUINT8, DT_QINT32, DT_BFLOAT16, DT_HALF]
  device='CPU'; T in [DT_BOOL]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_BOOL]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
 [Op:Equal]


	</description>
	<comments>
		<comment id='1' author='hksonngan' date='2019-04-23T21:03:36Z'>
		Thanks for trying TF 2.0 alpha. I was able to reproduce the behavior. Looks like data types uint16, uint32 and uint64 are not registered ops however data type uint8 was successful.
		</comment>
		<comment id='2' author='hksonngan' date='2019-04-23T21:25:47Z'>
		The uint dtypes are only supported in the xla backend.
		</comment>
		<comment id='3' author='hksonngan' date='2019-04-23T21:25:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28013&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28013&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='hksonngan' date='2019-06-06T01:14:48Z'>
		We should either add the kernel registration for these types or adjust the docs to match.
		</comment>
		<comment id='5' author='hksonngan' date='2019-06-06T16:33:50Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 we currently have ~no kernels registered for these types. Adding ~all kernels for these types would be quite a binary size hit. We should instead document somewhere that these types are not supported outside XLA.
		</comment>
		<comment id='6' author='hksonngan' date='2019-06-06T16:56:20Z'>
		Fair enough -- where to put such a notice? It's a general thing that I expect over time will change.
&lt;denchmark-link:https://github.com/lamberta&gt;@lamberta&lt;/denchmark-link&gt;
 do you have an idea?
		</comment>
		<comment id='7' author='hksonngan' date='2019-06-06T16:56:24Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28013&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28013&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>