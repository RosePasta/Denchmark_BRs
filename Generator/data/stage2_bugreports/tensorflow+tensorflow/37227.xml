<bug id='37227' author='ialdencoots' open_date='2020-03-02T10:20:54Z' closed_time='2020-06-01T07:35:57Z'>
	<summary>tf.expand_dims unable to read proper rank from input tensors</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Ubuntu 18.04.3 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
TensorFlow installed from (source or
binary): - TensorFlow version (use command below): docker tensorflow/tensorflow:2.1.0-gpu-py3
Python version: - Bazel
version (if compiling from source): Python 3.6.9
GCC/Compiler version (if compiling from
source):
CUDA/cuDNN version: - GPU model and memory: CUDA V10.1.243 - Nvidia Titan RTX

Describe the current behavior
I have a custom loss function that maps tf.expand_dims across a set of minibatches. When this loss is calculated as part of the model.fit function, the rank of the input tensor is not correctly read in the tf.expand_dims function call and I get the following exception:
ValueError: dim 2 not in the interval [-2, 1]. for 'ExpandDims' (op: 'ExpandDims') with input shapes: [?], [] and with computed input tensors: input[1] = &lt;2&gt;.
If I do not call tf.expand_dims and simply print the shape/rank of the input tensor, everything appears consistent. Furthermore, if the input dataset is simply iterated over and the batches are passed directly into the loss function, the exception is not raised.
Describe the expected behavior
An error is not raised
Standalone code to reproduce the issue
import numpy as np
import tensorflow as tf

from tensorflow.keras.losses import Loss

MINI_BATCH = 3
SPLITS = 2
BATCH = SPLITS * MINI_BATCH


class CustomLoss(Loss):
    def call(self, labels, outputs):

        @tf.function
        def fxn(inp):
            return tf.expand_dims(inp, 2)
        mapped = tf.map_fn(fxn, labels, dtype=tf.float32)
        return tf.reduce_sum(mapped)

def gen_batches():
    for _ in range(1000):
        outp = np.random.random((BATCH, 64))
        mask = np.random.random((SPLITS, MINI_BATCH, MINI_BATCH)) &gt; .5
        mask = tf.cast(mask, tf.float32)
        yield outp, mask


if __name__ == "__main__":
    # Toggle to run as training (throws exception) vs merely iterating and calculating loss
    AS_MODEL = True

    dataset = tf.data.Dataset.from_generator(gen_batches, (tf.float32, tf.float32), output_shapes=([BATCH, 64], [SPLITS, MINI_BATCH, MINI_BATCH]))
    loss = CustomLoss()

    if AS_MODEL:
        inputs = tf.keras.Input(shape=(64,))
        out = inputs + 1
        model = tf.keras.Model(inputs=inputs, outputs=out)
        opt = tf.keras.optimizers.Nadam(.0005)
        model.compile(optimizer=opt, loss=loss)

        # This throws exception
        model.fit(dataset, epochs=1)

    else:
        # This runs fine
        for data in dataset.__iter__():
            tf.print(loss(data[1], data[0])) 
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "deepsee/networks/av/attention/test.py", line 40, in &lt;module&gt;
    model.compile(optimizer=opt, loss=loss)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py", line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py", line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py", line 1652, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File "deepsee/networks/av/attention/test.py", line 17, in call
    mapped = tf.map_fn(fxn, labels, dtype=tf.float32)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py", line 268, in map_fn
    maximum_iterations=n)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py", line 2675, in while_loop
    back_prop=back_prop)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py", line 194, in while_loop
    add_control_dependencies=add_control_dependencies)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/while_v2.py", line 172, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/map_fn.py", line 257, in compute
    packed_fn_values = fn(packed_values)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py", line 497, in _initialize
    *args, **kwds))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    deepsee/networks/av/attention/test.py:16 fxn  *
        return tf.expand_dims(inp, 2)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:399 expand_dims_v2
        return gen_array_ops.expand_dims(input, axis, name)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py:2202 expand_dims
        "ExpandDims", input=input, dim=axis, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal
        op_def=op_def)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1786 __init__
        control_input_ops)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op
        raise ValueError(str(e))

    ValueError: dim 2 not in the interval [-2, 1]. for 'ExpandDims' (op: 'ExpandDims') with input shapes: [?], [] and with computed input tensors: input[1] = &lt;2&gt;.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='ialdencoots' date='2020-03-04T08:32:44Z'>
		I could replicate the issue with Tensorflow 2.1 on colab.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/216cc11e3d5417acb0ceeb3af8c50ead/untitled414.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='ialdencoots' date='2020-03-30T11:25:08Z'>
		Any updates regarding this issue?
		</comment>
		<comment id='3' author='ialdencoots' date='2020-05-31T04:56:06Z'>
		Apologies for the delay in response. This is fixed with TensorFlow version 2.2
Please give it a try. Thanks!
		</comment>
		<comment id='4' author='ialdencoots' date='2020-06-01T07:35:51Z'>
		Thanks, no issues now with 2.2
		</comment>
		<comment id='5' author='ialdencoots' date='2020-06-01T07:35:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37227&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37227&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>