<bug id='39775' author='gibiansky' open_date='2020-05-22T04:08:27Z' closed_time='2020-06-23T03:09:36Z'>
	<summary>Broken in v2.2.0: set_visible_devices() is used with tf.keras.mixed_precision</summary>
	<description>
If you use set_visible_devices with tf.keras.mixed_precision, you get a crash in v2.2.0.
This was fixed in this commit: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba&gt;f748283&lt;/denchmark-link&gt;

However, for some reason, in v2.2.0 the fix is applied in a way that is very broken and ineffective. On master this seems like this commit was applied correctly.
Specifically, on tag v2.2.0:
  device_attr_list = device_lib.list_local_devices()
  if not skip_local:
    _log_device_compatibility_check(policy_name, device_attr_list)
    return
On master:
  if not skip_local:
    device_attr_list = device_lib.list_local_devices()
    _log_device_compatibility_check(policy_name, device_attr_list)
    return
The whole point of skip_local is to avoid calling that function so moving this line renders that fix ineffective.
I'm a little confused how this happened, maybe a cherry pick gone wrong, but I thought I would put this issue here in case anyone hits this issue. I don't know if v2.2.0 can be fixed or we just have to wait for v2.3.0 (since master has the fix).
	</description>
	<comments>
		<comment id='1' author='gibiansky' date='2020-05-22T04:08:58Z'>
		If nothing needs to be done (because the fix is already on master and it's too late to fix v2.2.0), please feel free to close this issue.
		</comment>
		<comment id='2' author='gibiansky' date='2020-05-22T05:14:34Z'>
		&lt;denchmark-link:https://github.com/gibiansky&gt;@gibiansky&lt;/denchmark-link&gt;

Request you to share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='3' author='gibiansky' date='2020-05-22T14:58:55Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;$ python --version
Python 3.8.2
$ nvidia-smi
Fri May 22 14:55:49 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |
| N/A   33C    P0    37W / 300W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |
| N/A   31C    P0    36W / 300W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |
| N/A   34C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |
| N/A   36C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
$ cat test.py
import tensorflow as tf

print(tf.__version__)
print(tf.__git_version__)

devices = tf.config.list_physical_devices("GPU")
tf.config.experimental.set_visible_devices(devices[1], "GPU")
tf.keras.mixed_precision.experimental.set_policy("mixed_float16")
$ python test.py
2.2.0                                                                                                                                                                                                                      
v2.2.0-rc4-8-g2b96f3662b                                                                                                                                                                                                   
2020-05-22 14:54:03.085746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1                                                                               
2020-05-22 14:54:03.220530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.221673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       
pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.221763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.222822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:                                                                                                       
pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.222893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.223974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:                                                                                                       
pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.224043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.225141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:                                                                                                       
pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.225387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          
2020-05-22 14:54:03.227125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            
2020-05-22 14:54:03.228854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             
2020-05-22 14:54:03.229144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            
2020-05-22 14:54:03.231083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          
2020-05-22 14:54:03.232247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          
2020-05-22 14:54:03.236724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              
2020-05-22 14:54:03.236820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.237974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.239110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.240261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.241376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.242512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.243646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.244761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.245842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3                                                                                                
2020-05-22 14:54:03.246859: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA                                              
2020-05-22 14:54:03.275798: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300050000 Hz                                                                                                        
2020-05-22 14:54:03.277499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4708000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:                           
2020-05-22 14:54:03.277525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version                                                                                           
2020-05-22 14:54:03.391569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.392912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619d1dc11a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:                           
2020-05-22 14:54:03.392939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0                                                                    
2020-05-22 14:54:03.393122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.394229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       
pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.394278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          
2020-05-22 14:54:03.394301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            
2020-05-22 14:54:03.394323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             
2020-05-22 14:54:03.394345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            
2020-05-22 14:54:03.394365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          
2020-05-22 14:54:03.394386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          
2020-05-22 14:54:03.394400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              
2020-05-22 14:54:03.394461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.395606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.396677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 1                                                                                                         
2020-05-22 14:54:03.396718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          
2020-05-22 14:54:03.401843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                       
2020-05-22 14:54:03.401866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      1                                                                                                                                
2020-05-22 14:54:03.401879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N                                                                                                                                
2020-05-22 14:54:03.402669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.403797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.394229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                                       
pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                                                                                                   
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                                                                                                             
2020-05-22 14:54:03.394278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          
2020-05-22 14:54:03.394301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                                            
2020-05-22 14:54:03.394323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                                             
2020-05-22 14:54:03.394345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                                            
2020-05-22 14:54:03.394365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                                          
2020-05-22 14:54:03.394386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                                          
2020-05-22 14:54:03.394400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                                              
2020-05-22 14:54:03.394461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.395606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.396677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 1                                                                                                         
2020-05-22 14:54:03.396718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                          
2020-05-22 14:54:03.401843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                       
2020-05-22 14:54:03.401866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      1                                                                                                                                
2020-05-22 14:54:03.401879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   N                                                                                                                                
2020-05-22 14:54:03.402669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.403797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:03.404819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14865 MB memory) -&gt; physical GPU (device: 1, name: Tesla 
.0)                                                                   
2020-05-22 14:54:04.402216: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 0, reason: Invalid argument: device CUDA:0 not supported by XLA service
2020-05-22 14:54:04.402466: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 2, reason: Invalid argument: Invalid device ordinal value (2). Valid range is [0, 1].
2020-05-22 14:54:04.402591: I tensorflow/compiler/jit/xla_gpu_device.cc:161] Ignoring visible XLA_GPU_JIT device. Device number is 3, reason: Invalid argument: Invalid device ordinal value (3). Valid range is [0, 1].
2020-05-22 14:54:04.749691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.750812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                         
pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               
2020-05-22 14:54:04.750887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.751418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties:                         
pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               
2020-05-22 14:54:04.751484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.752587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties:                         
pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               
2020-05-22 14:54:04.752653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.753719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties:                         
pciBusID: 0000:00:1e.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0                                                                     
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 836.37GiB/s                                               
2020-05-22 14:54:04.753769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-05-22 14:54:04.753790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-05-22 14:54:04.753812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-05-22 14:54:04.753835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-05-22 14:54:04.753854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-05-22 14:54:04.753874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-05-22 14:54:04.753890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-05-22 14:54:04.753948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.755053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.755629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.756738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.757839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.758940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.759498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.760500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-22 14:54:04.761334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3                  
2020-05-22 14:54:04.761390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-22 14:54:04.761406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3                                            
2020-05-22 14:54:04.761419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y                                            
2020-05-22 14:54:04.761426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y                                            
2020-05-22 14:54:04.761435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y                                            
2020-05-22 14:54:04.761440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N                                            
Traceback (most recent call last):
  File "test.py", line 8, in &lt;module&gt;
    tf.keras.mixed_precision.experimental.set_policy("mixed_float16")
  File "/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py", line 551, in set_policy
    policy = Policy(policy)
  File "/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/policy.py", line 348, in __init__
    device_compatibility_check.log_device_compatibility_check(name,
  File "/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/keras/mixed_precision/experimental/device_compatibility_check.py", line 157, in log_device_compatibility_check
    device_attr_list = device_lib.list_local_devices()
  File "/home/experiments/new-data-control/env/lib/python3.8/site-packages/tensorflow/python/client/device_lib.py", line 43, in list_local_devices
    _convert(s) for s in _pywrap_device_lib.list_devices(serialized_config)
RuntimeError: TensorFlow device (GPU:0) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating mu
ltiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='gibiansky' date='2020-06-19T19:39:12Z'>
		/cc &lt;denchmark-link:https://github.com/reedwm&gt;@reedwm&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='gibiansky' date='2020-06-23T03:09:36Z'>
		As you noted, I embarrassingly tried and failed to fix this in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/f748283ee01059be52da5dada6e2157d9f6732ba&gt;f748283&lt;/denchmark-link&gt;
. This was broken even in master until fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/2730e4b0bcba80799ddc10f52081927848540f30&gt;2730e4b&lt;/denchmark-link&gt;
, but the latter commit did not make it into 2.2. The reason this happened is that I made a small refactor after manually testing the change before submitting it, but did not realize I accidentally broke the fix.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/38516#issuecomment-613712149&gt;This post&lt;/denchmark-link&gt;
 has a hacky workaround for 2.2.
		</comment>
		<comment id='6' author='gibiansky' date='2020-06-23T03:09:38Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39775&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39775&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='gibiansky' date='2020-07-18T08:19:47Z'>
		The proposed hack didn't work for me.
tensorflow version 2.2.0
cuda version 10.1
		</comment>
		<comment id='8' author='gibiansky' date='2020-07-27T18:16:11Z'>
		Make sure you run the hack before setting the Keras policy. If it still doesn't work, please share an example to reproduce the hack not working
		</comment>
		<comment id='9' author='gibiansky' date='2020-07-28T02:01:34Z'>
		Thanks.
I resolved the issue by updating NVidia driver version to NVIDIA-SMI 440.33.01
		</comment>
	</comments>
</bug>