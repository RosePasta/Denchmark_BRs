<bug id='40613' author='zldrobit' open_date='2020-06-19T13:39:32Z' closed_time='2020-07-01T15:48:39Z'>
	<summary>TFLite GPU Delegate with OpenCL backend produces wrong result</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 6 (Snapdragon 845)
TensorFlow installed from (source or binary): source (tag v2.1.1) and binary
TensorFlow version (use command below): v2.1.1
Python version: python 3.6.9
Bazel version (if compiling from source): bazel 0.29.1
GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
CUDA/cuDNN version:
from nvidia-smi:
NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2
from nvcc --version:
Cuda compilation tools, release 10.1, V10.1.243
no cuDNN
GPU model and memory:
RTX 2080 Ti 11G memory

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

Build environment information:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4803097/tf_env_bulid.txt&gt;tf_env_bulid.txt&lt;/denchmark-link&gt;

Execution evironment information:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4803099/tf_env_exec.txt&gt;tf_env_exec.txt&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

&lt;denchmark-code&gt;v2.1.0-33-g3ffdb91 2.1.1
&lt;/denchmark-code&gt;

Describe the current behavior
I used YOLOv3 (COCO dataset) TFLite model to detect obejcts,
while TFLite OpenCL GPU Delegate produces error result compared to TFLite CPU backend.
TFLite CPU:
&lt;denchmark-link:https://user-images.githubusercontent.com/3896992/85111276-aee63a00-b246-11ea-8723-f75cbf048fa4.jpg&gt;&lt;/denchmark-link&gt;

TFLite OpenCL GPU Delegate:
&lt;denchmark-link:https://user-images.githubusercontent.com/3896992/85111294-b279c100-b246-11ea-84a3-3af63af3b977.jpg&gt;&lt;/denchmark-link&gt;

Note the tie on Zidane is not detected with OpenCL GPU delegate.
At first, the detection problem is encountered on Oneplus 6T.
To ensure the problem is only with OpenCL GPU delegate and not with OpenGLES GPU delegate, I built both OpenCL and OpenGLES GPU delegate on Linux to double check the result.
Linux OpenCL:
&lt;denchmark-link:https://user-images.githubusercontent.com/3896992/85112848-e48c2280-b248-11ea-831d-7f19c68b1f66.jpg&gt;&lt;/denchmark-link&gt;

Linux OpenGLES:
&lt;denchmark-link:https://user-images.githubusercontent.com/3896992/85113251-9297cc80-b249-11ea-80ba-4e6610fad545.jpg&gt;&lt;/denchmark-link&gt;

Describe the expected behavior
TFLite OpenCL GPU Delegate output same result as TFLite CPU backend.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
One can use &lt;denchmark-link:https://github.com/zldrobit/onnx_tflite_yolov3/tree/reproduce-opencl&gt;https://github.com/zldrobit/onnx_tflite_yolov3/tree/reproduce-opencl&lt;/denchmark-link&gt;
 to reproduce
result from CPU, OpenCL and OpenGLES GPU delegate, with argument ,
 and  respectively.
The model can be downloaded from &lt;denchmark-link:https://drive.google.com/file/d/1iATViInSaPZWV7zH_YMAwMQK5XNDpdGl/view?usp=sharing&gt;https://drive.google.com/file/d/1iATViInSaPZWV7zH_YMAwMQK5XNDpdGl/view?usp=sharing&lt;/denchmark-link&gt;

A pre-bulit docker can be downloaded by
&lt;denchmark-code&gt;docker pull zldrobit/cudagl:opencl
&lt;/denchmark-code&gt;

Clone the git repo, download the model to weights/yolov3_coco.fp32.tflite, and run python3 tflite_detect.py. The results will be generated in the output folder.
PS: I am unable to provide a Colab notebook, due to the configuration diffculty of OpenCL and OpenGL on Colab environment. *.so are based on Tensorflow tag v2.1.1, and I only add initilization code and clean code (Once I have time, I will publish this build process ASAP).
PPS: I cannot run the OpenGLES GPU delegate on Oneplus 6T, the most critical error message may be
&lt;denchmark-code&gt;E/libEGL: call to OpenGL ES API with no current context (logged once per thread)

&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='zldrobit' date='2020-06-29T20:00:54Z'>
		Can you try building and running against the latest nightly/head version? I know we've resolved a number of accuracy issues over the last few months since the 2.1 release.
Also, it would be good to know which options you're enabling in the GPU delegate. Are you using relaxed precision? Are you using the Java or C APIs? Any other custom options? Thanks.
		</comment>
		<comment id='2' author='zldrobit' date='2020-07-01T02:19:23Z'>
		I built against the nightly version, and now the prediction with TFLite GPU delegate is correct.
Previously, I use both relaxed and strict precisions, but the prediction with neither of them is as expected.
I use Java API on Android, and Python API on Linux.
Thanks!
		</comment>
		<comment id='3' author='zldrobit' date='2020-07-01T15:48:38Z'>
		Thanks for confirming!
		</comment>
		<comment id='4' author='zldrobit' date='2020-07-01T15:48:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40613&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40613&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='zldrobit' date='2020-09-16T05:48:11Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;
 Is it possible for you to share your openCL Implementation on Adnroid Studio for the GPU delegate.
		</comment>
		<comment id='6' author='zldrobit' date='2020-09-16T09:40:32Z'>
		&lt;denchmark-link:https://github.com/dhruv-arcot&gt;@dhruv-arcot&lt;/denchmark-link&gt;
 , I just built tensorflow lite .so file with bazel in Ubuntu 18.04 using:
&lt;denchmark-code&gt;bazel build --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
&lt;/denchmark-code&gt;

Before that, I have to install mesa libs:
&lt;denchmark-code&gt;sudo apt-get install mesa-common-dev libegl1-mesa-dev libgles2-mesa-dev
&lt;/denchmark-code&gt;

Actually, the fastest way to get a OpenCL Implementation on Android is to use TFLite's AAR.
One can add
&lt;denchmark-code&gt;implementation 'org.tensorflow:tensorflow-lite:2.3.0'
implementation 'org.tensorflow:tensorflow-lite-gpu:2.3.0'
&lt;/denchmark-code&gt;

in the Android gradle dependency to download TFLite's AAR.
My only reason to manually build OpenCL and OpenGLES implementations for TFLite GPU delegate on x86 is to debug TFLite output results.
		</comment>
		<comment id='7' author='zldrobit' date='2020-09-17T01:45:17Z'>
		This is a question from a novice developer. I know that opengl or opencl can be delegated through gpu delegate in Android studio, how can I implement it?
For example in java api
// NEW: Prepare GPU delegate.
GpuDelegate delegate = new GpuDelegate();
Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);
// Set up interpreter.
Interpreter interpreter = new Interpreter(model, options);
// Run inference.
writeToInputTensor(inputTensor);
interpreter.run(inputTensor, outputTensor);
readFromOutputTensor(outputTensor);
// Clean up.
delegate.close();
Is opengl used in this code? If correct, how should I implement opencl?
		</comment>
		<comment id='8' author='zldrobit' date='2020-09-17T02:10:37Z'>
		&lt;denchmark-link:https://github.com/GwakEunSeong&gt;@GwakEunSeong&lt;/denchmark-link&gt;
 I don't know the details of the Java API, but IIRC, the logic whether the OpenCL backend is used or the OpenGL is hidden away from you.  If OpenCL is available, it'll try to use that; otherwise OpenGL.
		</comment>
		<comment id='9' author='zldrobit' date='2020-09-17T03:20:32Z'>
		&lt;denchmark-link:https://github.com/impjdi&gt;@impjdi&lt;/denchmark-link&gt;
 Thanks for answering. If you can use opencl internally in the gpu delegate, you are saying that it is available with opencl, otherwise it uses opengl, right?? If so, is there anything I need to configure in order to use opencl??
		</comment>
		<comment id='10' author='zldrobit' date='2020-09-17T12:21:02Z'>
		&lt;denchmark-link:https://github.com/GwakEunSeong&gt;@GwakEunSeong&lt;/denchmark-link&gt;
 it requires nothing to be configured in order to use opencl delegate.
		</comment>
		<comment id='11' author='zldrobit' date='2020-09-17T23:57:50Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;
 Thanks for answering!
		</comment>
		<comment id='12' author='zldrobit' date='2020-09-20T18:15:46Z'>
		&lt;denchmark-link:https://github.com/zldrobit&gt;@zldrobit&lt;/denchmark-link&gt;
 Thanks for the reply
&lt;denchmark-link:https://github.com/GwakEunSeong&gt;@GwakEunSeong&lt;/denchmark-link&gt;
 That was actually going to be my follow up, thanks for that as well.
		</comment>
	</comments>
</bug>