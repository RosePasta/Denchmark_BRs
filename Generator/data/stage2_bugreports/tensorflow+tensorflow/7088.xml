<bug id='7088' author='bazinac' open_date='2017-01-26T10:34:02Z' closed_time='2017-01-28T08:48:20Z'>
	<summary>Running optimized graph with two output nodes on android gives “Session was not created with a graph before Run()” error.</summary>
	<description>
Hi, please would you please be so kind and help me with one issue that prevents me from moving forward. I have graph with two output layers (final_result_orig – which is basically coming form retraining example,final_result_added – my custom layer) and I am unable to strip/optimize_on_inference it in order to run on android device (on pc it runs fine)
When I run:
bazel-bin/tensorflow/python/tools/optimize_for_inference 
–input=/tmp/output.pb 
–output=/tmp/optimized.pb 
–input_names=Mul 
–output_names=”final_result_orig,final_result_added”
Then in my android application, I get “Session was not created with a graph before Run()” error, and both final_result_orig and final_result_added are not found.
When I run:
bazel-bin/tensorflow/python/tools/optimize_for_inference 
–input=/tmp/output.pb 
–output=/tmp/optimized.pb 
–input_names=Mul 
–output_names=”final_result_orig”
It works fine, final_result_orig is available and works correctly, however final_result_added is obviously not found and not available for my app to use.
And when I run:
bazel-bin/tensorflow/python/tools/optimize_for_inference 
–input=/tmp/output.pb 
–output=/tmp/optimized.pb 
–input_names=Mul 
–output_names=”final_result_added”
It does not work as well with “Session was not created with a graph before Run()” error, and both final_result_orig and final_result_added are not found.
I do not understand what I am doing wrong – what could be wrong with “final_result_added”, as it works fine on PC and not android? Thank you very much.
&lt;denchmark-h:h2&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/5553&gt;#5553&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Environment info&lt;/denchmark-h&gt;

Ubuntu 16.04 + Android 6.0
	</description>
	<comments>
		<comment id='1' author='bazinac' date='2017-01-26T16:39:20Z'>
		&lt;denchmark-link:https://github.com/bazinac&gt;@bazinac&lt;/denchmark-link&gt;
 Are you using a recent version of TensorFlow? The loading code has been improved recently to give more descriptive errors when something goes wrong. I'd suggest syncing first and then seeing what it says.
		</comment>
		<comment id='2' author='bazinac' date='2017-01-26T23:03:52Z'>
		Unfortunatelly, after installing latest Tensorflow, I am strangely unable to even build optimize_for_inference script with
`Traceback (most recent call last):
File "/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/tools/optimize_for_inference.py", line 65, in 
from tensorflow.python.framework import dtypes
File "/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/init.py", line 72, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File "/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/init.py", line 61, in 
from tensorflow.python import pywrap_tensorflow
File "/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py", line 28, in 
_pywrap_tensorflow = swig_import_helper()
File "/home/poborak/SW/tensorflow-master/bazel-bin/tensorflow/python/tools/optimize_for_inference.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py", line 20, in swig_import_helper
import _pywrap_tensorflow
ImportError: No module named _pywrap_tensorflow
Failed to load the native TensorFlow runtime.
`
Note that otherwise tensorflow works properly, (i can even run "import tensorflow as tf" in python shell, everywhere else than in /tensorflow-master dir). I fought this whole evening and now I gave up and will hope that you somehow will be able to help me.  Otherwise, thanks for very good job with this project. It is fantastic that you make tool like tensorflow available to us.
		</comment>
		<comment id='3' author='bazinac' date='2017-01-26T23:15:27Z'>
		Perhaps &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/97&gt;#97&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1013&gt;#1013&lt;/denchmark-link&gt;
 are relevant here? Have you run ./configure? What Python version are you using?
My assumption is that you have a different version of tf installed that Python is finding when you import tf elsewhere, so that is probably misleading.
		</comment>
		<comment id='4' author='bazinac' date='2017-01-26T23:30:29Z'>
		I am using Python 3.5. I have tried to build tf from source, but it has failed to build Python wheel. I therefore opted to install latest (12.1) release using pip.
I then ran ./configure in downloaded copy od latest tensorflow-master and built optimize_for_inference (I am sorry to provide misleading info on my previous comment). Then this abovementioned error arises when I try to run built optimize_for_inference...
		</comment>
		<comment id='5' author='bazinac' date='2017-01-26T23:46:25Z'>
		It sounds like &lt;denchmark-link:https://github.com/andrewharp&gt;@andrewharp&lt;/denchmark-link&gt;
 is right. There are two versions in your system. I'm guessing that the best at this point is to go back and  tensorflow, then work through the issues building from source.
		</comment>
		<comment id='6' author='bazinac' date='2017-01-27T18:08:29Z'>
		I followed your hint and somehow managed to build from source. When I run it know, tensorflow is much more verbose and I can see that -
&lt;denchmark-code&gt;E/native: tensorflow_inference_jni.cc:146 Could not create TensorFlow graph: Invalid argument: No OpKernel was registered to support Op 'Pow' with these attrs.

[[Node: final_added_training_ops/final_result_added/pow = Pow[T=DT_FLOAT](final_added_training_ops/final_result_added/truediv, final_added_training_ops/final_result_added/pow/y)]]
&lt;/denchmark-code&gt;

I google out somewhere that this can be surpassed by adding necessary OpKernel to Android operator sets in BUILD file. But I don't understand what OpKernel I should add to Android operator set in case of Op 'Pow' and how do to so. Could you please tell me.
In addition to tf.sqrt I use also tf.reduce_mean, tf.truncated_normal...
Sorry for being so annoying lately :D
		</comment>
		<comment id='7' author='bazinac' date='2017-01-27T18:39:27Z'>
		On behalf of our users, thanks for helping us clarify things!
You should be able to add ops from there:
&lt;denchmark-link:https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/BUILD#L3378&gt;https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/BUILD#L3378&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='bazinac' date='2017-01-27T20:01:11Z'>
		Could you try that and let us know?
		</comment>
		<comment id='9' author='bazinac' date='2017-01-27T20:16:37Z'>
		It looks like cwise_op_pow.cc needs to be added to android_extended_ops_group1.
AFAIK there's no reason not to make this change -- we've just been adding ops as needed, so long as they actually compile for Android without adding undue size.
I think it would also be informative to list registered ops in the case one isn't found; is there an easy way to do that?
		</comment>
		<comment id='10' author='bazinac' date='2017-01-27T20:24:29Z'>
		It's actually already included in the Makefile build, so not including it for Bazel seems to be an oversight. Sending a CL to fix.
		</comment>
		<comment id='11' author='bazinac' date='2017-01-28T08:48:20Z'>
		Yay after adding "cwise_op_pow.cc", it works. Thank you guys!
		</comment>
	</comments>
</bug>