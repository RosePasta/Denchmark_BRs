<bug id='7876' author='ramnath-k' open_date='2017-02-25T07:37:53Z' closed_time='2018-10-31T18:06:05Z'>
	<summary>Import meta graph followed by save overwrites the previous checkpoints</summary>
	<description>
NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.
For general support from the community, see &lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;StackOverflow&lt;/denchmark-link&gt;
.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*): using CPU version of tensorflow 1.0.0
If installed from binary pip package, provide:

A link to the pip package you installed: pip install tensorflow
The output from python -c "import tensorflow; print(tensorflow.__version__)". 1.0.0

If installed from source, provide

The commit hash (git rev-parse HEAD)
The output of bazel version

&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

import tensorflow as tf

graph = tf.Graph()
with graph.as_default():
    initializer = tf.random_uniform_initializer(minval=-0.5, maxval=0.5, seed=42, dtype=tf.float32)
    var1 = tf.get_variable('var1', shape=(1,), dtype=tf.float32, initializer=initializer)
    saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=20)
    init_op = tf.global_variables_initializer()
    graph.finalize()

with tf.Session(graph=graph) as sess:
    sess.run(init_op)
    saver.save(sess, 'sample_graph', global_step=0)

graph = tf.Graph()
with tf.Session(graph=graph) as sess:
    saver = tf.train.import_meta_graph('sample_graph-0.meta')
    saver.restore(sess, './sample_graph-0')
    saver.save(sess, 'sample_graph', global_step=1)
    print(saver.last_checkpoints) # lists only ['sample_graph-1'] does not preserve the previous checkpoint sample_graph-0
Essentially I am checkpointing a graph and then importing it. On trying to save the next checkpoint, the saver overwrites the previous checkpoint in the checkpoint file (the actual meta, index and data files are not overwritten) and only the last saved checkpoint is present in the checkpoint file. Is this the intended behavior? Is there any way to preserve the checkpoints across multiple saves of the graph.
&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
	</description>
	<comments>
		<comment id='1' author='ramnath-k' date='2017-02-27T03:01:30Z'>
		Thanks for a clear issue report.
		</comment>
		<comment id='2' author='ramnath-k' date='2018-01-29T07:32:44Z'>
		&lt;denchmark-link:https://github.com/sherrym&gt;@sherrym&lt;/denchmark-link&gt;
 is this intended? Is the checkpoint still there but the checkpoint list is cleared since it's a new saver/graph?
		</comment>
		<comment id='3' author='ramnath-k' date='2018-10-30T12:38:14Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/sherrym&gt;@sherrym&lt;/denchmark-link&gt;
: It has been 273 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='4' author='ramnath-k' date='2018-10-31T16:09:29Z'>
		Is this still an issue ?
&lt;denchmark-link:https://github.com/sherrym&gt;@sherrym&lt;/denchmark-link&gt;
 - Could you please look into this ?
		</comment>
		<comment id='5' author='ramnath-k' date='2018-10-31T18:06:05Z'>
		Reassigning to Allen, Sherry has left the team.
I think what is happening is that the list of checkpoints is reset by import_meta_graph. The old checkpoints still exist on disk, but the index structure is overwritten by import_meta_graph.
We won't do any work on this before 2.0, and I'm concerned that we won't be able to really fix this since it would be a behavior change (and it's not clear that this is a bug -- import_meta_graph often does invalidate old checkpoints since you may add new variables).
I will close this issue. This should be much less of a problem in 2.0.
		</comment>
		<comment id='6' author='ramnath-k' date='2018-10-31T18:34:28Z'>
		There is a write_state Boolean argument to Saver.save, so you can prevent it from updating the Checkpoint file. And there is also Saver.set_last_checkpoints_with_time, which you can use along with tf.train.get_checkpoint_mtimes so that the Saver writes a correct-ish Checkpoint file instead of just not overwriting.
I do think the 2.x story will be better here. Still working out the details, but there should be a design review soon for importing SavedModels. I'll include an import-and-train workflow there.
		</comment>
	</comments>
</bug>