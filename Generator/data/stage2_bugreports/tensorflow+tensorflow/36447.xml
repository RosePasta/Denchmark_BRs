<bug id='36447' author='vicpara' open_date='2020-02-03T19:35:11Z' closed_time='2020-04-09T17:15:00Z'>
	<summary>Saving to file a model within TPUStrategy</summary>
	<description>
On Tensorflow 2.0 and 2.1, trying to save to file a TPU trained model or a model that was even created within the scope of a tf.distribute.experimental.TPUStrategy yields error below. Despite throwing an UnimplementedException the code does create a folder on disk with some content.
The reproducible code can be found in a collab notebook here:
&lt;denchmark-link:https://colab.research.google.com/drive/1DOkwNlzMLsg0wQZe41eq88XhEUqR9Amn&gt;https://colab.research.google.com/drive/1DOkwNlzMLsg0wQZe41eq88XhEUqR9Amn&lt;/denchmark-link&gt;

The exception and it's stack
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
&lt;ipython-input-7-b3a563716de1&gt; in &lt;module&gt;()
     48         print("1.4 ",err)
     49 
---&gt; 50     model.save("model-new.1")
     51 
     52     model.compile(

14 frames
/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1006     """
   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-&gt; 1008                     signatures, options)
   1009 
   1010   def save_weights(self, filepath, overwrite=True, save_format=None):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--&gt; 115                           signatures, options)
    116 
    117 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---&gt; 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

/tensorflow-2.1.0/python3.6/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    914   # SavedModel proto itself.
    915   utils_impl.get_or_create_variables_dir(export_dir)
--&gt; 916   object_saver.save(utils_impl.get_variables_path(export_dir))
    917   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,
    918                                               export_dir)

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/util.py in save(self, file_prefix, checkpoint_number, session)
   1166     file_io.recursive_create_dir(os.path.dirname(file_prefix))
   1167     save_path, new_feed_additions = self._save_cached_when_graph_building(
-&gt; 1168         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
   1169     if new_feed_additions:
   1170       feed_dict.update(new_feed_additions)

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/util.py in _save_cached_when_graph_building(self, file_prefix, object_graph_tensor)
   1114         or context.executing_eagerly() or ops.inside_function()):
   1115       saver = functional_saver.MultiDeviceSaver(named_saveable_objects)
-&gt; 1116       save_op = saver.save(file_prefix)
   1117       with ops.device("/cpu:0"):
   1118         with ops.control_dependencies([save_op]):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/functional_saver.py in save(self, file_prefix)
    228         # _SingleDeviceSaver will use the CPU device when necessary, but initial
    229         # read operations should be placed on the SaveableObject's device.
--&gt; 230         sharded_saves.append(saver.save(shard_prefix))
    231 
    232     with ops.control_dependencies(sharded_saves):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/functional_saver.py in save(self, file_prefix)
     67       for spec in saveable.specs:
     68         tensor_names.append(spec.name)
---&gt; 69         tensors.append(spec.tensor)
     70         tensor_slices.append(spec.slice_spec)
     71     with ops.device("cpu:0"):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/saveable_object.py in tensor(self)
     50   @property
     51   def tensor(self):
---&gt; 52     return self._tensor() if callable(self._tensor) else self._tensor
     53 
     54 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/saveable_object_util.py in f()
     89         def f():
     90           with ops.device(v.device):
---&gt; 91             x = v.read_value()
     92             # To allow variables placed on non-CPU devices to be checkpointed,
     93             # we copy them to CPU on the same machine first.

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py in read_value(self)
    633     """
    634     with ops.name_scope("Read"):
--&gt; 635       value = self._read_variable_op()
    636     # Return an identity so it can get placed on whatever device the context
    637     # specifies instead of the device where the variable is.

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py in _read_variable_op(self)
    611     variable_accessed(self)
    612     result = gen_resource_variable_ops.read_variable_op(self._handle,
--&gt; 613                                                         self._dtype)
    614     _maybe_set_handle_data(self._dtype, self._handle, result)
    615 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)
    477         pass  # Add nodes to the TensorFlow graph.
    478     except _core._NotOkStatusException as e:
--&gt; 479       _ops.raise_from_not_ok_status(e, name)
    480   # Add nodes to the TensorFlow graph.
    481   dtype = _execute.make_type(dtype, "dtype")

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + (" name: " + name if name is not None else "")
   6605   # pylint: disable=protected-access
-&gt; 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnimplementedError: File system scheme '[local]' not implemented (file: 'model-new.1/variables/variables_temp_17ffcf98334348fd8ef1e339869f0bfc')
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:ReadVariableOp]
System information
The error is reproduced in Collab so I'm skipping tf_env_collect.sh output.
	</description>
	<comments>
		<comment id='1' author='vicpara' date='2020-02-04T19:04:36Z'>
		You can/should use  a cloud storage bucket path. See &lt;denchmark-link:https://cloud.google.com/tpu/docs/troubleshooting#cannot_use_local_filesystem&gt;https://cloud.google.com/tpu/docs/troubleshooting#cannot_use_local_filesystem&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='vicpara' date='2020-02-11T06:50:48Z'>
		&lt;denchmark-link:https://github.com/vicpara&gt;@vicpara&lt;/denchmark-link&gt;
 Please let us know if the above comment helps resolve issue.
		</comment>
		<comment id='3' author='vicpara' date='2020-04-09T17:14:59Z'>
		Yes it does. Thanks.
		</comment>
		<comment id='4' author='vicpara' date='2020-04-09T17:15:01Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36447&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36447&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='vicpara' date='2020-07-11T20:35:19Z'>
		Hi, I'm using a TPU on Kaggle, and I have no write permission to the GS cloud storage bucket, only the local filesystem. Is there a way around that, so I can save to the local filesystem?
Thanks.
		</comment>
	</comments>
</bug>