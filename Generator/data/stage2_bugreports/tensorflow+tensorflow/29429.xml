<bug id='29429' author='mwin76' open_date='2019-06-05T07:10:26Z' closed_time='2019-08-21T22:16:27Z'>
	<summary>fit_generator and predict_generator ignores steps_per_epoch parameter when using sequence</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.13.1
Python version: 3.6.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0
GPU model and memory: TITAN

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Hi,
When running fit_generator (and predict_generator) with the steps_per_epoch parameter (and steps in predict) using a custom sequence, the whole dataset is used instead of the number of batches passed in the steps_per_epoch parameter.
According to the documentation:
steps_per_epoch: Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to the number of samples of your dataset divided by the batch size. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.
The code below works as expected in tensorflow 1.12.0 and 2.0.0a0 but not in 1.13.1
Seems like the 'convert_to_generator_like' function in file 'engine/training_generator.py' overrides the 'steps_per_epoch' parameter with len(data) without checking if it is not None in case of a sequence:
&lt;denchmark-code&gt;  if data_utils.is_generator_or_sequence(data) or isinstance(
      data, iterator_ops.EagerIterator):
    if isinstance(data, data_utils.Sequence):
      steps_per_epoch = len(data)
    return data, steps_per_epoch

&lt;/denchmark-code&gt;

Thanks
Describe the expected behavior
Code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
from tensorflow import keras
#import keras

INPUT_SIZE = 3
DENSE_OUTPUTS = 2
NUM_OF_SAMPLES = 1000
BATCH_SIZE = 2
NUM_OF_BATCHES = 5


class DummySequence(keras.utils.Sequence):

    def __len__(self):
        return NUM_OF_SAMPLES // BATCH_SIZE

    def __getitem__(self, index):
        data = [np.full(shape=(INPUT_SIZE,), fill_value=(index*BATCH_SIZE + i)) for i in range(BATCH_SIZE)]
        labels = [np.full(shape=(DENSE_OUTPUTS,), fill_value=(index*BATCH_SIZE + i))*INPUT_SIZE for i in range(BATCH_SIZE)]
        return np.stack(data), np.stack(labels)


class CountBatchesCallback(keras.callbacks.Callback):

    def __init__(self):
        super(CountBatchesCallback, self).__init__()

        self.batches = 0

    def on_batch_begin(self, batch, logs=None):
        self.batches += 1


x = keras.layers.Input(shape=(INPUT_SIZE,))
dense_layer = keras.layers.Dense(DENSE_OUTPUTS)
y = dense_layer(x)
model = keras.Model(x, y)

model.compile(optimizer="sgd", loss=keras.losses.mean_squared_error)

shapes = [v.shape for v in dense_layer.weights]
dense_layer.set_weights([np.full(shape=shapes[0], fill_value=1.0), np.full(shape=shapes[1], fill_value=0.0)])

seq = DummySequence()

steps = 5
batch_counter_callback = CountBatchesCallback()

print("running fit with {} steps".format(steps))
model.fit_generator(
    seq,
    epochs=1,
    steps_per_epoch=steps,
    callbacks=[batch_counter_callback]
)
print("batches processed: {}".format(batch_counter_callback.batches))

results = model.predict_generator(seq, steps=steps)
print("\npredict\nexpected number of results: {}.\nactual number of results: {}.\npredictions:\n{}".format(
    steps*BATCH_SIZE, len(results), results)
)

&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='mwin76' date='2019-08-21T22:16:27Z'>
		This is fixed with latest version of TF-Nightly.
Output in tf-nightly version '1.15.0-dev20190821' is printed below:
running fit with 5 steps
5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00
batches processed: 5

predict
expected number of results: 10.
actual number of results: 10.
predictions:
[[ 0.  0.]
 [ 3.  3.]
 [ 6.  6.]
 [ 9.  9.]
 [12. 12.]
 [15. 15.]
 [18. 18.]
 [21. 21.]
 [24. 24.]
 [27. 27.]]
		</comment>
		<comment id='2' author='mwin76' date='2019-08-21T22:16:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29429&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29429&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>