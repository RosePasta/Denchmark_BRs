<bug id='27841' author='pSolT' open_date='2019-04-14T20:30:10Z' closed_time='2019-04-19T23:37:51Z'>
	<summary>Cannot initialize two different models with the same checkpoint.</summary>
	<description>
I'm trying to use TF Slim ResNet-v1-101 pre-trained model to initialize two input branches of model, with different inputs (RGB features[0] and depth map features[1] respectively) to further combine them and feed their joint result to some spatial convolution layers. In order to achieve that, I create separate scope for each of the branches and initialize the models with pre-trained checkpoint, excluding the last fully connected layer (logits) :
System information

OS Platform and Distribution : Linux Ubuntu 16.04:
TensorFlow version 1.13:
Python version: 3.5
CUDA/cuDNN version: 10.1
GPU model and memory: GV100 32GB

Describe the current behavior
&lt;denchmark-code&gt;with tf.variable_scope("rgb_branch"):
    with tf.contrib.slim.arg_scope(resnet_v1.resnet_arg_scope()):
        rgb_logits, end_points = resnet_v1.resnet_v1_101(features[0], self.num_classes, is_training=is_training)        

        rgb_variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=['rgb_branch/resnet_v1_101/logits'])
                
        # strip scope name
        rgb_assignment_map = { rgb_variables_to_restore[0].name.split(':')[0] : rgb_variables_to_restore[0]}
        rgb_assignment_map.update({ v.name.split(':')[0].split('/', 1)[1] : v for v in rgb_variables_to_restore[1:] })
      
        tf.train.init_from_checkpoint(self.pre_trained_model_path, rgb_assignment_map)
        
        
with tf.variable_scope("depth_branch"):
    with tf.contrib.slim.arg_scope(resnet_v1.resnet_arg_scope()):     
        depth_logits, end_points = resnet_v1.resnet_v1_101(features[1], self.num_classes, is_training=is_training)

        depth_variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=['depth_branch/resnet_v1_101/logits'])
                
        depth_assignment_map = { depth_variables_to_restore[0].name.split(':')[0] : depth_variables_to_restore[0]}
        depth_assignment_map.update({ v.name.split(':')[0].split('/', 1)[1] : v for v in depth_variables_to_restore[1:] })
      
        tf.train.init_from_checkpoint(self.pre_trained_model_path, depth_assignment_map)
&lt;/denchmark-code&gt;

During the second initialization (the depth branch), TF complains about shape of the logits layer as if it was never removed:
ValueError: Shape of variable rgb_branch/resnet_v1_101/logits/biases:0 ((3,)) doesn't match with shape of tensor resnet_v1_101/logits/biases ([1000]) from checkpoint reader.
The problem doesn't occur when I initialize only one branch, and is tied only to the first of the branches defined - if I change the order of the branches, the above error would change to depth_branch/resnet_v1_101/logits/biases:0
Describe the expected behavior
Expected - have two separate graphs, both initialized by the same checkpoint
	</description>
	<comments>
		<comment id='1' author='pSolT' date='2019-04-19T23:37:51Z'>
		This issue is better asked on tensorflow/models repo. Please post it on models repo from &lt;denchmark-link:https://github.com/tensorflow/models/issues/new&gt;here&lt;/denchmark-link&gt;

You can also ask on &lt;denchmark-link:http://stackoverflow.com/questions/tagged/tensorflow&gt;StackOverflow&lt;/denchmark-link&gt;
 since it is not a bug or feature request. There is also a larger community that reads questions there.
Thanks!
		</comment>
		<comment id='2' author='pSolT' date='2019-04-19T23:37:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27841&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27841&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>