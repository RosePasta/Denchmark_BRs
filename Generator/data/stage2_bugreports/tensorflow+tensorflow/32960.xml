<bug id='32960' author='Risslock' open_date='2019-10-01T17:42:05Z' closed_time='2019-10-07T17:17:15Z'>
	<summary>Keras Nadam optmizer generates error when using MirroredStrategy</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18
TensorFlow installed from (source or binary): Tensorflow 2
TensorFlow version (use command below) : Tensorflow 2.0.0
Python version: Python 3.7
CUDA/cuDNN version: 10
GPU model and memory: 2 x Nvidia 1080 TI

Describe the current behavior
The training crashes with an error( ValueError: You must specify an aggregation method to update a MirroredVariable in Replica Context.) If the model is compiled with the optimizer Nadam (tf.keras.optimizers.Nadam) along with a MirroredStrategy.
Describe the expected behavior
Expect to be able to train with any optimizer from Keras' options.
	</description>
	<comments>
		<comment id='1' author='Risslock' date='2019-10-03T09:10:01Z'>
		In order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='Risslock' date='2019-10-03T19:22:16Z'>
		&lt;denchmark-code&gt;import tensorflow_datasets as tfds
import tensorflow as tf
tfds.disable_progress_bar()

import os
os.environ["CUDA_VISIBLE_DEVICES"]="1"

datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)

mnist_train, mnist_test = datasets['train'], datasets['test']

mirrored_strategy = tf.distribute.MirroredStrategy()

print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))

# You can also do info.splits.total_num_examples to get the total
# number of examples in the dataset.

num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples

BUFFER_SIZE = 100

BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync

def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
 
    return image, label

train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

with mirrored_strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Nadam(),
                  metrics=['accuracy'])
    model.summary()

model.fit(train_dataset, epochs=5)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='Risslock' date='2019-10-04T09:12:08Z'>
		I have tried on colab with TF version 2.0.0-rc2 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/7dbb1f1dd1ecc4a0fba0cc6792bdfb98/untitled247.ipynb&gt;here&lt;/denchmark-link&gt;
. However i am able to reproduce the issue with    and not seeing any issue if we use .Thanks!
		</comment>
		<comment id='4' author='Risslock' date='2019-10-07T17:17:15Z'>
		Hi this issue if fixed &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/1a1c0b6980f1648fe674de3e3b471e78a59143e1&gt;here&lt;/denchmark-link&gt;
, which unfortunately hasn't made its way into the latest release.  It should be there in the next release and already in the nightlies.
		</comment>
		<comment id='5' author='Risslock' date='2019-10-07T17:17:16Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32960&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32960&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>