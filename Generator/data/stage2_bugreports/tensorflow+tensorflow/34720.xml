<bug id='34720' author='xieydd' open_date='2019-11-30T14:42:35Z' closed_time='2020-02-06T16:34:21Z'>
	<summary>Bug in person_detection tf-lite example</summary>
	<description>
tf==1.15
I just follow the step in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/examples/person_detection/training_a_model.md&gt;person_detection example&lt;/denchmark-link&gt;
, after i get , when i want to generate , I get a error , can you see it  &lt;denchmark-link:https://github.com/dansitu&gt;@dansitu&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;Traceback (most recent call last):                                                                    
  File "get_tflite.py", line 32, in &lt;module&gt;                                                          
    tflite_quant_model = converter.convert()                                                          
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py", line 993, in conv
ert                                                                                                   
    inference_output_type)                                                                            
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py", line 239, in _cal
ibrate_quantize_model                                                                                 
    inference_output_type, allow_float)                                                               
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/calibrator.py", li
ne 75, in calibrate_and_quantize                                                                      
    self._calibrator.FeedTensor(calibration_sample)                                                   
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wr
ap_calibration_wrapper.py", line 112, in FeedTensor                                                   
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value) 
ValueError: Cannot set tensor: Dimension mismatch
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='xieydd' date='2019-12-02T23:31:46Z'>
		&lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
, can you take a look?
		</comment>
		<comment id='2' author='xieydd' date='2019-12-09T16:53:30Z'>
		I'm currently looking into this issue and I'll post an update soon.
		</comment>
		<comment id='3' author='xieydd' date='2019-12-09T18:24:39Z'>
		I was able to reproduce the issue. The reason that you're currently facing this issue is because of a &lt;denchmark-link:https://github.com/tensorflow/models/pull/7609/commits&gt;pending PR&lt;/denchmark-link&gt;
 to merge the greyscale changes. As a result of this, the current code does not utilize the  flag and the model only accepts RGB/color images. To verify this, you can visualize the  file by uploading it to &lt;denchmark-link:https://lutzroeder.github.io/netron/&gt;netron&lt;/denchmark-link&gt;
 to see the dimensions of the input which is: (batch=?, height=96, width=96, num_channels=3)
Note: Netron is a useful tool for visualizing many other model formats as well, source: https://github.com/lutzroeder/netron
Until the PR is merged, with a temporary fix, you can train a person_detection model that accepts color images by making two updates while converting the vww_96_grayscale_frozen.pb file to vww_96_grayscale_quantized.tflite as follows: (the 2 updates are mentioned in comments below)
&lt;denchmark-code&gt;import tensorflow as tf
import io
import PIL
import numpy as np

def representative_dataset_gen():
    record_iterator = tf.python_io.tf_record_iterator(path='coco/processed/val.record-00000-of-00010')
    count = 0
    for string_record in record_iterator:
        example = tf.train.Example()
        example.ParseFromString(string_record)
        image_stream = io.BytesIO(example.features.feature['image/encoded'].bytes_list.value[0])
        image = PIL.Image.open(image_stream)
        image = image.resize((96, 96))
        image = image.convert('RGB') # Update 1: Replace'L' with 'RGB' 
        array = np.array(image)
        # array = np.expand_dims(array, axis=2) # Update 2: Comment this line as with RGB, an extra dimension is 
                                                # already present to represent the num_channels with value=3
        array = np.expand_dims(array, axis=0)
        array = ((array / 127.5) - 1.0).astype(np.float32)
        yield([array])
        count += 1
        if count &gt; 300:
            break

converter = tf.lite.TFLiteConverter.from_frozen_graph('vww_96_grayscale_frozen.pb',
['input'], ['MobilenetV1/Predictions/Reshape_1'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen

tflite_quant_model = converter.convert()
open("vww_96_grayscale_quantized.tflite", "wb").write(tflite_quant_model)
&lt;/denchmark-code&gt;

The size of this model is ~260KB and not &lt;250KB as mentioned in the tutorial as this model accepts color images. Let us know if this works for you, and we'll post an update once we get the greyscale version checked in as well.
		</comment>
		<comment id='4' author='xieydd' date='2019-12-10T01:48:28Z'>
		&lt;denchmark-link:https://github.com/MeghnaNatraj&gt;@MeghnaNatraj&lt;/denchmark-link&gt;
 Thanks for your Detailed explanationï¼Œ i will try after the pr merged;
Now my compromise solution is:
&lt;denchmark-code&gt;delete the line # image = image.convert('L')
and # array = np.expand_dims(array, axis=2)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='xieydd' date='2019-12-19T20:33:04Z'>
		Sorry for the problems! I looked into the PR, and we did merge the changes through a separate mechanism, though the flag is now called  instead of :
&lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py#L133&gt;https://github.com/tensorflow/models/blob/master/research/slim/eval_image_classifier.py#L133&lt;/denchmark-link&gt;

Does specifying that help?
		</comment>
		<comment id='6' author='xieydd' date='2020-02-06T16:34:21Z'>
		Closing the issue as it is resolved.  Either a user can update the training instructions by replacing use_grayscale with input_grayscale OR the user can update the inference instructions by the solution posted earlier in this page.
		</comment>
		<comment id='7' author='xieydd' date='2020-02-06T16:34:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34720&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34720&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>