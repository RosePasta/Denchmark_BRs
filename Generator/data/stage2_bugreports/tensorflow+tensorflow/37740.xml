<bug id='37740' author='JonasRSV' open_date='2020-03-20T09:08:06Z' closed_time='2020-04-07T14:27:27Z'>
	<summary>AlreadyExistsError when using large tensors</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):
OS Platform and Distribution: Ubuntu 18.04.3 LTS and Ubuntu 16.04.6 LTS
TensorFlow installed from: pip
Python version: 3.6.8 and 3.7.5
CUDA/cuDNN version: Did not use GPU

Tensorflow version: 2.1.0
Describe the current behavior
The code casts
tensorflow.python.framework.errors_impl.AlreadyExistsError
Describe the expected behavior
It does not cast that error
Standalone code to reproduce the issue
Here's a minimal example I managed to make. The error only occurs if I use gradient-tape, if i remove the gradient tape the code runs perfectly. But I would like to be able to take the gradient.
import tensorflow as tf
import numpy as np


class C:
    def __init__(self):
        n = 2000
        self.ae = tf.Variable(np.eye(n), trainable=True, dtype=tf.float32)
        self.aa = tf.Variable(np.eye(n), trainable=True, dtype=tf.float32)
        self.fr = tf.Variable(0.5, trainable=True, dtype=tf.float32)

        self.kp = tf.Variable(np.zeros(n), trainable=False, dtype=tf.float32)

    @tf.function
    def loss_op(self, k: tf.Tensor, a: tf.Tensor, s: tf.Tensor):
        l = tf.constant(0.0)

        def loop_fn(i, k, l):
            p = tf.clip_by_value(k[a[i]], 0.01, 0.99)
            l = l - (s[i] * tf.math.log(p) + (1 - s[i]) * tf.math.log(1 - p))

            at = self.aa[a[i]]

            gk = (self.ae[a[i]] - k) * at
            lk = k * at

            k = tf.clip_by_value(
                k + s[i] * gk - (1 - s[i]) * self.fr * lk, 0.0, 1.0)
            return i + 1, k, l

        def loop_cond(i: tf.Tensor, _, __):
            return tf.logical_and(tf.greater_equal(s[i], 0), tf.less(i, 199))

        _, _, l = tf.while_loop(loop_cond, loop_fn, (0, k, l), back_prop=True)
        return l

    @tf.function
    def regularizer(self, tensor: tf.Tensor):
        return tf.reduce_sum(tf.math.log(tf.abs(tensor) + 1))

    @tf.function
    def train_op(self, a, s, opt):
        with tf.GradientTape() as tape:
            loss = self.loss_op(self.kp, a, s)

            aal = self.regularizer(self.aa)
            al = self.regularizer(self.ae)

            o = loss + 0.5 * (aal + al)

        train_vars = [self.ae, self.aa, self.fr]

        gradient = tape.gradient(o, train_vars)
        opt.apply_gradients(zip(gradient, train_vars))

        return loss

c = C()

o = tf.optimizers.Adam(learning_rate=1e-3)

a = np.arange(200, dtype=np.int32)
s = np.ones(200, dtype=np.float32)

c.train_op(a, s, o)
Here's a stack-trace if that is helpful
2020-03-20 09:56:30.208767: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/StatefulPartitionedCall_3/gradient
s/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE                                                                                            
2020-03-20 09:56:30.209510: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Already exists: Resource __per_step_0/StatefulPartitionedCall_
3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE                                                                                  
         [[{{node StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var}}]]
2020-03-20 09:56:30.209650: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2020-03-20 09:56:30.209813: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2020-03-20 09:56:30.219319: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
Traceback (most recent call last):
  File "error.py", line 69, in &lt;module&gt;
    c.train_op(a, s, o)
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1611, in _filtered_call
    self.captured_inputs)
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 545, in call
    ctx=ctx)
  File "/home/jonas/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File "&lt;string&gt;", line 3, in raise_from
tensorflow.python.framework.errors_impl.AlreadyExistsError:  Resource __per_step_0/StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
         [[{{node StatefulPartitionedCall_3/gradients/while_grad/while_grad/body/_193/gradients/AddN/tmp_var}}]] [Op:__inference_train_op_806]

Function call stack:
train_op
	</description>
	<comments>
		<comment id='1' author='JonasRSV' date='2020-03-20T09:19:15Z'>
		If i set n = 1898 inside the class it does not crash. But with n = 1899 it does crash
		</comment>
		<comment id='2' author='JonasRSV' date='2020-03-20T11:05:03Z'>
		&lt;denchmark-link:https://github.com/JonasRSV&gt;@JonasRSV&lt;/denchmark-link&gt;
,
I was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/79ad775a5f4c4a2c64d59bf5b3844e30/37740.ipynb&gt;TF 2.1&lt;/denchmark-link&gt;
. However, the issue seems to be resolved in &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/7e109fdb5282175b1c2c48c5fb8ad135/37740-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='3' author='JonasRSV' date='2020-03-20T11:23:15Z'>
		
@JonasRSV,
I was able to reproduce the issue with TF 2.1. However, the issue seems to be resolved in TF-nightly. Please find the attached gist. Thanks!

Yes, using tensorflow-nightly fixed the error. Thanks!
		</comment>
		<comment id='4' author='JonasRSV' date='2020-03-20T11:23:17Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37740&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37740&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='JonasRSV' date='2020-03-21T08:18:44Z'>
		The problem persists even with nightly. If i run the following code snippet from a jupyter notebook I get the same error for 3.6.8 and 3.7 (But only in jupyter notebooks so far)
Here are the jupyter version details:
&gt; jupyter --version
jupyter core     : 4.6.1
jupyter-notebook : 6.0.3
qtconsole        : 4.6.0
ipython          : 7.11.1
ipykernel        : 5.1.4
jupyter client   : 5.3.4
jupyter lab      : not installed
nbconvert        : 5.6.1
ipywidgets       : 7.5.1
nbformat         : 5.0.4
traitlets        : 4.3.3
import tensorflow as tf
import numpy as np

print(tf.__version__)


class C:
    def __init__(self):
        n = 8000
        self.pe = tf.Variable(np.eye(n), trainable=True, dtype=tf.float32)
        self.ne = tf.Variable(np.eye(n), trainable=True, dtype=tf.float32)
        self.kp = tf.Variable(np.zeros(n), trainable=True, dtype=tf.float32)

    @tf.function
    def loss_op(self, k: tf.Tensor, a: tf.Tensor, s: tf.Tensor):
        l = tf.constant(0.0)

        def loop_fn(i, k, l):
            p = tf.clip_by_value(k[a[i]], 0.01, 0.99)
            l = l - (s[i] * tf.math.log(p) + (1 - s[i]) * tf.math.log(1 - p))

            k = tf.clip_by_value(
                k + s[i] * self.pe[a[i]] + (1 - s[i]) * self.ne[a[i]], -30.0, 30.0)
            return i + 1, k, l

        def loop_cond(i: tf.Tensor, _, __):
            return tf.logical_and(tf.greater_equal(s[i], 0), tf.less(i, 199))

        _, _, l = tf.while_loop(loop_cond, loop_fn, (0, k, l), back_prop=True)
        return l

    @tf.function
    def regularizer(self, tensor: tf.Tensor):
        return tf.reduce_sum(tf.math.log(tf.abs(tensor) + 1))

    @tf.function
    def train_op(self, a, s, opt):
        with tf.GradientTape() as tape:
            loss = self.loss_op(self.kp, a, s)

            pel = self.regularizer(self.pe)
            nel = self.regularizer(self.ne)

            o = loss + 0.5 * (pel + nel)

        train_vars = [self.pe, self.ne, self.kp]

        gradient = tape.gradient(o, train_vars)
        opt.apply_gradients(zip(gradient, train_vars))

        self.pe.assign(tf.clip_by_value(self.pe, -30, 30))
        self.ne.assign(tf.clip_by_value(self.ne, -30, 30))
        self.kp.assign(tf.clip_by_value(self.kp, -30, 30))

        return loss


c = C()

o = tf.optimizers.Adam(learning_rate=1e-3)

a = np.arange(200, dtype=np.int32)
s = np.ones(200, dtype=np.float32)

c.train_op(a, s, o)
c.train_op(a, s, o)
		</comment>
		<comment id='6' author='JonasRSV' date='2020-03-30T07:44:03Z'>
		&lt;denchmark-link:https://github.com/JonasRSV&gt;@JonasRSV&lt;/denchmark-link&gt;
,
I was able to run the above code without any issues with TF-nightly. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/35581a7e1aacee4bca5070e141f653ea/37740-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='JonasRSV' date='2020-04-07T12:55:27Z'>
		&lt;denchmark-link:https://github.com/JonasRSV&gt;@JonasRSV&lt;/denchmark-link&gt;
,
Any updates regarding this issue? Thanks!
		</comment>
		<comment id='8' author='JonasRSV' date='2020-04-07T14:27:27Z'>
		Hey, I updated my version of jupyter and then it worked,
thanks!
		</comment>
		<comment id='9' author='JonasRSV' date='2020-04-07T14:27:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37740&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37740&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>