<bug id='31498' author='yi-ming-lin' open_date='2019-08-09T23:07:44Z' closed_time='2019-08-12T18:43:49Z'>
	<summary>TF2.0beta1 - Not JSON Serializable when using tf.keras.experimental.export_saved_model</summary>
	<description>
Most code is from one of the tensorflow 2.0 beta guides: &lt;denchmark-link:https://www.tensorflow.org/beta/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example&gt;Writing layers and models with TensorFlow Keras&lt;/denchmark-link&gt;

Describe the current behavior
TypeError: ('Not JSON Serializable:', b'\n\x06Square\x12\x06Square\x1a\x0fz_mean/Identity*\x07\n\x01T\x12\x020\x01')
Describe the expected behavior
Save model correctly.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras import layers

# Get training data.
(x_train, _), _ = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255

original_dim = 784
intermediate_dim = 64
latent_dim = 32

def sampling(inputs):
    z_mean, z_log_var = inputs
    batch = tf.shape(z_mean)[0]
    dim = tf.shape(z_mean)[1]
    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon    

# Define encoder model.
original_inputs = tf.keras.Input(shape=(original_dim,), name='encoder_input')
x = layers.Dense(intermediate_dim, activation='relu')(original_inputs)
z_mean = layers.Dense(latent_dim, name='z_mean')(x)
z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)
z = tf.keras.layers.Lambda(sampling)((z_mean, z_log_var))
encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name='encoder')

# Define decoder model.
latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')
x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)
outputs = layers.Dense(original_dim, activation='sigmoid')(x)
decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name='decoder')

# Define VAE model.
outputs = decoder(z)
vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name='vae')

# Add KL divergence regularization loss.
kl_loss = - 0.5 * tf.reduce_mean(
    z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)
vae.add_loss(kl_loss)

# Train.
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())
vae.fit(x_train, x_train, epochs=3, batch_size=64)

# Save model.
tf.keras.experimental.export_saved_model(vae, 'vae_functional_saved_model')
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-2-4eb0216166eb&gt; in &lt;module&gt;
----&gt; 1 tf.keras.experimental.export_saved_model(vae, 'vae_functional_saved_model')

~/.miniconda/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py in export_saved_model(model, saved_model_path, custom_objects, as_text, input_signature, serving_only)
    167 
    168   try:
--&gt; 169     _export_model_json(model, saved_model_path)
    170   except NotImplementedError:
    171     logging.warning('Skipped saving model JSON, subclassed model does not have '

~/.miniconda/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model.py in _export_model_json(model, saved_model_path)
    175 def _export_model_json(model, saved_model_path):
    176   """Saves model configuration as a json string under assets folder."""
--&gt; 177   model_json = model.to_json()
    178   model_json_filepath = os.path.join(
    179       saved_model_utils.get_or_create_assets_dir(saved_model_path),

~/.miniconda/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py in to_json(self, **kwargs)
   1447     model_config = self._updated_config()
   1448     return json.dumps(
-&gt; 1449         model_config, default=serialization.get_json_type, **kwargs)
   1450 
   1451   def to_yaml(self, **kwargs):

~/.miniconda/envs/tf2/lib/python3.7/json/__init__.py in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)
    236         check_circular=check_circular, allow_nan=allow_nan, indent=indent,
    237         separators=separators, default=default, sort_keys=sort_keys,
--&gt; 238         **kw).encode(obj)
    239 
    240 

~/.miniconda/envs/tf2/lib/python3.7/json/encoder.py in encode(self, o)
    197         # exceptions aren't as detailed.  The list call should be roughly
    198         # equivalent to the PySequence_Fast that ''.join() would do.
--&gt; 199         chunks = self.iterencode(o, _one_shot=True)
    200         if not isinstance(chunks, (list, tuple)):
    201             chunks = list(chunks)

~/.miniconda/envs/tf2/lib/python3.7/json/encoder.py in iterencode(self, o, _one_shot)
    255                 self.key_separator, self.item_separator, self.sort_keys,
    256                 self.skipkeys, _one_shot)
--&gt; 257         return _iterencode(o, 0)
    258 
    259 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,

~/.miniconda/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/serialization.py in get_json_type(obj)
     67     return dict(obj)
     68 
---&gt; 69   raise TypeError('Not JSON Serializable:', obj)

TypeError: ('Not JSON Serializable:', b'\n\x06Square\x12\x06Square\x1a\x0fz_mean/Identity*\x07\n\x01T\x12\x020\x01')
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='yi-ming-lin' date='2019-08-09T23:12:15Z'>
		The code seems working fine on with tf-nightly-gpu-1.15.0.dev20190809
		</comment>
		<comment id='2' author='yi-ming-lin' date='2019-08-12T00:03:51Z'>
		It also seems to work with tf-nightly-2.0-preview-2.0.0.dev20190811.
In this version tf.keras.experimental.export_saved_model is deprecated.
Please use `model.save(..., save_format="tf")` or `tf.keras.models.save_model(..., save_format="tf")`.
I think in earlier versions of TF, the serialization of TF objects returned a binary but keras uses a .json. So there was this problem. I don't know, but maybe
kl_loss = - 0.5 * tf.reduce_mean(
    z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)
vae.add_loss(kl_loss)
or
vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())
are the functions that caused this error in serialization. At that time, I've tried putting everything in Lambda layers to avoid the binary serialization.
Even though there are some warnings about loading / saving the optimizer when using this tf.keras.experimental there's no error and/or warning when using the model.save(..., save_format="tf") or tf.keras.models.save_model(..., save_format="tf"). Both with save_format='tf' or save_format='h5'
So it's a good idea to use at least this nightly version for TF and change the tf.keras.experimental to the non-deprecated versions if you want to use the 2.0 version.
		</comment>
		<comment id='3' author='yi-ming-lin' date='2019-08-12T18:43:49Z'>
		This is fixed with latest tf-2.0-nightly build  '2.0.0-dev20190812'.
		</comment>
		<comment id='4' author='yi-ming-lin' date='2019-08-12T18:43:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31498&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31498&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>