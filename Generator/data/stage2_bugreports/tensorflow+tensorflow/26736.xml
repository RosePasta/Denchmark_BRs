<bug id='26736' author='stakemura' open_date='2019-03-15T10:35:20Z' closed_time='2019-04-15T15:38:56Z'>
	<summary>tflite's TRANSPOSE_CONV is much slower than tfmobile ...</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Zenfone 5Z
TensorFlow installed from (source or binary):source
TensorFlow version (use command below): nightly build 20190314
Python version:3.6
Bazel version (if compiling from source):0.21.0
GCC/Compiler version (if compiling from source):5.4
CUDA/cuDNN version:not used
GPU model and memory:not used

Describe the current behavior
I measured performance of tf-mobile, tf-lite on Zenfone 5Z  / Snapdragon 845 / Android 8.0 by C++ benchmark model tool (arm64 build), and I find that the speed of tf-lite's TRANSPOSE_CONV is much slower than tf-mobile's one.
I used the attached custom model &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/2970561/models.zip&gt;models.zip&lt;/denchmark-link&gt;
  for benchmark .
The attached tflite is converted by toco_convert from the attached pb file.
Summary
The following table shows average computing time of 50 times predict.




Threads
Conv2D
TransposeConv2D
All




TFMobile
1
251.561 ms
35.585 ms
310.380 ms


TFMobile
4
190.228 ms
78.047 ms
295.469 ms


TFMobile
16
87.586 ms
20.264 ms
122.102 ms


TFLite
1
294.214 ms
562.609 ms
880.674 ms


TFLite
4
75.783 ms
560.368 ms
659.156 ms


TFLite
16
55.597 ms
561.441 ms
641.541 ms



TFMobile 1 threads In:1x256x256x3 Performance
benchmark_model --graph=/data/local/tmp/UpResnet5-X2-H256-W256-C3.pb --max_num_runs=50 --num_threads=1 --input_layer_shape="1,256,256,3"
&lt;denchmark-code&gt;native : benchmark_model.cc:469 Graph: [/data/local/tmp/UpResnet5-X2-H256-W256-C3.pb]
native : benchmark_model.cc:470 Init ops:
native : benchmark_model.cc:471 Input layers: [input:0]
native : benchmark_model.cc:472 Input shapes: [1,256,256,3]
native : benchmark_model.cc:473 Input types: [float]
native : benchmark_model.cc:474 Output layers: [output:0]
native : benchmark_model.cc:475 Target layers: []
native : benchmark_model.cc:476 Num runs: [50]
native : benchmark_model.cc:477 Inter-inference delay (seconds): [-1.0]
native : benchmark_model.cc:478 Inter-benchmark delay (seconds): [-1.0]
native : benchmark_model.cc:480 Num threads: [1]
native : benchmark_model.cc:481 Benchmark name: []
native : benchmark_model.cc:482 Output prefix: []
native : benchmark_model.cc:483 Show sizes: [0]
native : benchmark_model.cc:484 Warmup runs: [1]
native : benchmark_model.cc:251 Loading TensorFlow.
native : benchmark_model.cc:258 Got config, 0 devices
can't determine number of CPU cores: assuming 4
native : benchmark_model.cc:496 Initialized session in 0.03605s
native : benchmark_model.cc:327 Running benchmark for max 1 iterations, max -1 seconds without detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=1 curr=637203

native : benchmark_model.cc:327 Running benchmark for max 50 iterations, max 10 seconds without detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=30 first=616452 curr=309802 min=309536 max=618552 avg=342551 std=92067

native : benchmark_model.cc:327 Running benchmark for max 50 iterations, max 10 seconds with detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=33 first=310795 curr=311214 min=310428 max=311479 avg=310885 std=265

native : benchmark_model.cc:600 Average inference timings in us: Warmup: 637203, no stats: 342550, with stats: 310885
native : stat_summarizer.cc:85 ============================== Run Order ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	                    NoOp	            0.000	    0.014	    0.010	  0.003%	  0.003%	     0.000	        1	_SOURCE
native : stat_summarizer.cc:85 	                   Const	            0.017	    0.016	    0.009	  0.003%	  0.006%	     0.000	        1	Const
native : stat_summarizer.cc:85 	                   Const	            0.029	    0.005	    0.004	  0.001%	  0.007%	     0.000	        1	conv2d_transpose/strided_slice/stack
native : stat_summarizer.cc:85 	                   Const	            0.034	    0.004	    0.004	  0.001%	  0.009%	     0.000	        1	conv2d_transpose/strided_slice/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.040	    0.004	    0.004	  0.001%	  0.010%	     0.000	        1	conv2d_transpose/strided_slice/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.046	    0.003	    0.003	  0.001%	  0.011%	     0.000	        1	conv2d_transpose/strided_slice_1/stack
native : stat_summarizer.cc:85 	                   Const	            0.051	    0.003	    0.003	  0.001%	  0.012%	     0.000	        1	conv2d_transpose/strided_slice_1/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.055	    0.004	    0.003	  0.001%	  0.013%	     0.000	        1	conv2d_transpose/strided_slice_1/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.059	    0.003	    0.003	  0.001%	  0.014%	     0.000	        1	conv2d_transpose/strided_slice_2/stack
native : stat_summarizer.cc:85 	                   Const	            0.064	    0.004	    0.003	  0.001%	  0.015%	     0.000	        1	conv2d_transpose/strided_slice_2/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.069	    0.003	    0.003	  0.001%	  0.016%	     0.000	        1	conv2d_transpose/strided_slice_2/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.074	    0.003	    0.003	  0.001%	  0.017%	     0.000	        1	conv2d_transpose/mul/y
native : stat_summarizer.cc:85 	                   Const	            0.078	    0.004	    0.003	  0.001%	  0.018%	     0.000	        1	conv2d_transpose/mul_1/y
native : stat_summarizer.cc:85 	                   Const	            0.083	    0.004	    0.003	  0.001%	  0.019%	     0.000	        1	conv2d_transpose/stack/3
native : stat_summarizer.cc:85 	                   Const	            0.087	    0.003	    0.003	  0.001%	  0.020%	     0.000	        1	output/Minimum/y
native : stat_summarizer.cc:85 	                   Const	            0.092	    0.003	    0.003	  0.001%	  0.021%	     0.000	        1	output/y
native : stat_summarizer.cc:85 	                    _Arg	            0.096	    0.005	    0.003	  0.001%	  0.022%	     0.000	        1	_arg_input_0_0
native : stat_summarizer.cc:85 	               MirrorPad	            0.103	    2.747	    2.678	  0.863%	  0.884%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 	                   Const	            2.802	    0.007	    0.006	  0.002%	  0.886%	     0.000	        1	batch_normalization/beta/read/_0__cf__0
native : stat_summarizer.cc:85 	                   Const	            2.810	    0.004	    0.004	  0.001%	  0.887%	     0.000	        1	batch_normalization/gamma/read/_1__cf__1
native : stat_summarizer.cc:85 	                   Const	            2.815	    0.004	    0.004	  0.001%	  0.889%	     0.000	        1	batch_normalization/moving_mean/read/_2__cf__2
native : stat_summarizer.cc:85 	                   Const	            2.820	    0.004	    0.003	  0.001%	  0.890%	     0.000	        1	batch_normalization/moving_variance/read/_3__cf__3
native : stat_summarizer.cc:85 	                   Const	            2.825	    0.005	    0.003	  0.001%	  0.891%	     0.000	        1	batch_normalization_1/beta/read/_4__cf__4
native : stat_summarizer.cc:85 	                   Const	            2.830	    0.003	    0.003	  0.001%	  0.892%	     0.000	        1	batch_normalization_1/gamma/read/_5__cf__5
native : stat_summarizer.cc:85 	                   Const	            2.835	    0.004	    0.004	  0.001%	  0.893%	     0.000	        1	batch_normalization_1/moving_mean/read/_6__cf__6
native : stat_summarizer.cc:85 	                   Const	            2.840	    0.004	    0.003	  0.001%	  0.894%	     0.000	        1	batch_normalization_1/moving_variance/read/_7__cf__7
native : stat_summarizer.cc:85 	                   Const	            2.845	    0.006	    0.005	  0.002%	  0.896%	     0.000	        1	conv2d/Conv2D/ReadVariableOp/_8__cf__8
native : stat_summarizer.cc:85 	                  Conv2D	            2.852	   31.104	   31.094	 10.018%	 10.914%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	                    Relu	           33.975	    0.855	    0.864	  0.279%	 11.192%	     0.000	        1	activation/Relu
native : stat_summarizer.cc:85 	          FusedBatchNorm	           34.849	    8.088	    8.000	  2.577%	 13.770%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	                   Const	           42.882	    0.012	    0.012	  0.004%	 13.774%	     0.000	        1	conv2d_1/Conv2D/ReadVariableOp/_9__cf__9
native : stat_summarizer.cc:85 	                  Conv2D	           42.897	   57.605	   57.749	 18.606%	 32.379%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	          100.677	    6.175	    6.276	  2.022%	 34.401%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	                    Relu	          106.967	    0.854	    0.866	  0.279%	 34.680%	     0.000	        1	activation_1/Relu
native : stat_summarizer.cc:85 	                   Const	          107.846	    0.016	    0.015	  0.005%	 34.685%	     0.000	        1	conv2d_2/Conv2D/ReadVariableOp/_10__cf__10
native : stat_summarizer.cc:85 	                  Conv2D	          107.865	   57.759	   57.751	 18.607%	 53.291%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                     Add	          165.648	    1.811	    1.839	  0.592%	 53.884%	     0.000	        1	add
native : stat_summarizer.cc:85 	                   Const	          167.501	    0.013	    0.014	  0.005%	 53.889%	     0.000	        1	conv2d_3/Conv2D/ReadVariableOp/_11__cf__11
native : stat_summarizer.cc:85 	                  Conv2D	          167.521	  104.822	  104.968	 33.819%	 87.708%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	                    Relu	          272.521	    1.732	    1.741	  0.561%	 88.269%	     0.000	        1	activation_2/Relu
native : stat_summarizer.cc:85 	                   Shape	          274.272	    0.026	    0.024	  0.008%	 88.276%	     0.016	        1	conv2d_transpose/Shape
native : stat_summarizer.cc:85 	            StridedSlice	          274.303	    0.022	    0.024	  0.008%	 88.284%	     0.004	        1	conv2d_transpose/strided_slice
native : stat_summarizer.cc:85 	            StridedSlice	          274.335	    0.021	    0.009	  0.003%	 88.287%	     0.004	        1	conv2d_transpose/strided_slice_1
native : stat_summarizer.cc:85 	                     Mul	          274.349	    0.012	    0.011	  0.003%	 88.291%	     0.000	        1	conv2d_transpose/mul
native : stat_summarizer.cc:85 	            StridedSlice	          274.363	    0.008	    0.011	  0.003%	 88.294%	     0.004	        1	conv2d_transpose/strided_slice_2
native : stat_summarizer.cc:85 	                     Mul	          274.378	    0.005	    0.004	  0.001%	 88.295%	     0.000	        1	conv2d_transpose/mul_1
native : stat_summarizer.cc:85 	                    Pack	          274.385	    0.015	    0.016	  0.005%	 88.301%	     0.016	        1	conv2d_transpose/stack
native : stat_summarizer.cc:85 	                   Const	          274.407	    0.010	    0.009	  0.003%	 88.304%	     0.000	        1	conv2d_transpose/conv2d_transpose/ReadVariableOp/_12__cf__12
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          274.419	   35.577	   35.586	 11.465%	 99.769%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                 Minimum	          310.038	    0.359	    0.370	  0.119%	 99.888%	     0.000	        1	output/Minimum
native : stat_summarizer.cc:85 	                 Maximum	          310.415	    0.424	    0.338	  0.109%	 99.997%	     0.000	        1	output
native : stat_summarizer.cc:85 	                 _Retval	          310.759	    0.010	    0.010	  0.003%	100.000%	     0.000	        1	_retval_output_0_0
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 ============================== Top by Computation Time ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	                  Conv2D	          167.521	  104.822	  104.968	 33.819%	 33.819%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	          107.865	   57.759	   57.751	 18.607%	 52.426%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	           42.897	   57.605	   57.749	 18.606%	 71.032%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          274.419	   35.577	   35.586	 11.465%	 82.497%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                  Conv2D	            2.852	   31.104	   31.094	 10.018%	 92.515%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	           34.849	    8.088	    8.000	  2.577%	 95.092%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	          FusedBatchNorm	          100.677	    6.175	    6.276	  2.022%	 97.114%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	               MirrorPad	            0.103	    2.747	    2.678	  0.863%	 97.977%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 	                     Add	          165.648	    1.811	    1.839	  0.592%	 98.570%	     0.000	        1	add
native : stat_summarizer.cc:85 	                    Relu	          272.521	    1.732	    1.741	  0.561%	 99.131%	     0.000	        1	activation_2/Relu
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 ============================== Top by Memory Use ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          274.419	   35.577	   35.586	 11.465%	 11.465%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                  Conv2D	          167.521	  104.822	  104.968	 33.819%	 45.285%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	           34.849	    8.088	    8.000	  2.577%	 47.862%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	                  Conv2D	          107.865	   57.759	   57.751	 18.607%	 66.469%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	           42.897	   57.605	   57.749	 18.606%	 85.074%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	            2.852	   31.104	   31.094	 10.018%	 95.092%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	               MirrorPad	            0.103	    2.747	    2.678	  0.863%	 95.955%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 	          FusedBatchNorm	          100.677	    6.175	    6.276	  2.022%	 97.977%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	                   Shape	          274.272	    0.026	    0.024	  0.008%	 97.985%	     0.016	        1	conv2d_transpose/Shape
native : stat_summarizer.cc:85 	                    Pack	          274.385	    0.015	    0.016	  0.005%	 97.990%	     0.016	        1	conv2d_transpose/stack
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 Number of nodes executed: 52
native : stat_summarizer.cc:85 ============================== Summary by node type ==============================
native : stat_summarizer.cc:85 	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
native : stat_summarizer.cc:85 	                  Conv2D	        4	   251.561	    81.056%	    81.056%	 31753.344	        4
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	        1	    35.585	    11.466%	    92.522%	 15728.640	        1
native : stat_summarizer.cc:85 	          FusedBatchNorm	        2	    14.275	     4.600%	    97.121%	  6390.912	        2
native : stat_summarizer.cc:85 	                    Relu	        3	     3.469	     1.118%	    98.239%	     0.000	        3
native : stat_summarizer.cc:85 	               MirrorPad	        1	     2.677	     0.863%	    99.102%	   811.200	        1
native : stat_summarizer.cc:85 	                     Add	        1	     1.839	     0.593%	    99.694%	     0.000	        1
native : stat_summarizer.cc:85 	                 Minimum	        1	     0.369	     0.119%	    99.813%	     0.000	        1
native : stat_summarizer.cc:85 	                 Maximum	        1	     0.337	     0.109%	    99.922%	     0.000	        1
native : stat_summarizer.cc:85 	                   Const	       28	     0.126	     0.041%	    99.962%	     0.000	       28
native : stat_summarizer.cc:85 	            StridedSlice	        3	     0.041	     0.013%	    99.976%	     0.012	        3
native : stat_summarizer.cc:85 	                   Shape	        1	     0.024	     0.008%	    99.983%	     0.016	        1
native : stat_summarizer.cc:85 	                    Pack	        1	     0.016	     0.005%	    99.988%	     0.016	        1
native : stat_summarizer.cc:85 	                     Mul	        2	     0.014	     0.005%	    99.993%	     0.000	        2
native : stat_summarizer.cc:85 	                 _Retval	        1	     0.010	     0.003%	    99.996%	     0.000	        1
native : stat_summarizer.cc:85 	                    NoOp	        1	     0.009	     0.003%	    99.999%	     0.000	        1
native : stat_summarizer.cc:85 	                    _Arg	        1	     0.003	     0.001%	   100.000%	     0.000	        1
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 Timings (microseconds): count=33 first=310208 curr=310701 min=309938 max=310969 avg=310380 std=264
native : stat_summarizer.cc:85 Memory (bytes): count=33 curr=54684140(all same)
native : stat_summarizer.cc:85 52 nodes observed
native : stat_summarizer.cc:85 
&lt;/denchmark-code&gt;

TFMobile 16 threads In:1x256x256x3 Performance
benchmark_model --graph=/data/local/tmp/UpResnet5-X2-H256-W256-C3.pb --max_num_runs=50 --num_threads=16 --input_layer_shape="1,256,256,3"
&lt;denchmark-code&gt;native : benchmark_model.cc:469 Graph: [/data/local/tmp/UpResnet5-X2-H256-W256-C3.pb]
native : benchmark_model.cc:470 Init ops:
native : benchmark_model.cc:471 Input layers: [input:0]
native : benchmark_model.cc:472 Input shapes: [1,256,256,3]
native : benchmark_model.cc:473 Input types: [float]
native : benchmark_model.cc:474 Output layers: [output:0]
native : benchmark_model.cc:475 Target layers: []
native : benchmark_model.cc:476 Num runs: [50]
native : benchmark_model.cc:477 Inter-inference delay (seconds): [-1.0]
native : benchmark_model.cc:478 Inter-benchmark delay (seconds): [-1.0]
native : benchmark_model.cc:480 Num threads: [16]
native : benchmark_model.cc:481 Benchmark name: []
native : benchmark_model.cc:482 Output prefix: []
native : benchmark_model.cc:483 Show sizes: [0]
native : benchmark_model.cc:484 Warmup runs: [1]
native : benchmark_model.cc:251 Loading TensorFlow.
native : benchmark_model.cc:258 Got config, 0 devices
can't determine number of CPU cores: assuming 4
native : benchmark_model.cc:496 Initialized session in 0.036933s
native : benchmark_model.cc:327 Running benchmark for max 1 iterations, max -1 seconds without detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=1 curr=144572

native : benchmark_model.cc:327 Running benchmark for max 50 iterations, max 10 seconds without detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=50 first=121095 curr=120424 min=118295 max=159110 avg=123218 std=7596

native : benchmark_model.cc:327 Running benchmark for max 50 iterations, max 10 seconds with detailed stat logging, with -1s sleep between inferences
native : benchmark_model.cc:361 count=50 first=120234 curr=123678 min=117632 max=144145 avg=122647 std=4286

native : benchmark_model.cc:600 Average inference timings in us: Warmup: 144572, no stats: 123217, with stats: 122646
native : stat_summarizer.cc:85 ============================== Run Order ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	                    NoOp	            0.000	    0.012	    0.008	  0.006%	  0.006%	     0.000	        1	_SOURCE
native : stat_summarizer.cc:85 	                   Const	            0.015	    0.016	    0.009	  0.007%	  0.014%	     0.000	        1	Const
native : stat_summarizer.cc:85 	                   Const	            0.026	    0.004	    0.003	  0.003%	  0.016%	     0.000	        1	conv2d_transpose/strided_slice/stack
native : stat_summarizer.cc:85 	                   Const	            0.030	    0.004	    0.004	  0.003%	  0.019%	     0.000	        1	conv2d_transpose/strided_slice/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.035	    0.006	    0.004	  0.003%	  0.022%	     0.000	        1	conv2d_transpose/strided_slice/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.040	    0.005	    0.003	  0.003%	  0.025%	     0.000	        1	conv2d_transpose/strided_slice_1/stack
native : stat_summarizer.cc:85 	                   Const	            0.045	    0.004	    0.003	  0.003%	  0.027%	     0.000	        1	conv2d_transpose/strided_slice_1/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.049	    0.003	    0.003	  0.003%	  0.030%	     0.000	        1	conv2d_transpose/strided_slice_1/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.055	    0.003	    0.003	  0.002%	  0.033%	     0.000	        1	conv2d_transpose/strided_slice_2/stack
native : stat_summarizer.cc:85 	                   Const	            0.059	    0.004	    0.003	  0.002%	  0.035%	     0.000	        1	conv2d_transpose/strided_slice_2/stack_1
native : stat_summarizer.cc:85 	                   Const	            0.064	    0.004	    0.003	  0.002%	  0.037%	     0.000	        1	conv2d_transpose/strided_slice_2/stack_2
native : stat_summarizer.cc:85 	                   Const	            0.068	    0.004	    0.003	  0.002%	  0.040%	     0.000	        1	conv2d_transpose/mul/y
native : stat_summarizer.cc:85 	                   Const	            0.072	    0.003	    0.003	  0.002%	  0.042%	     0.000	        1	conv2d_transpose/mul_1/y
native : stat_summarizer.cc:85 	                   Const	            0.077	    0.003	    0.003	  0.002%	  0.044%	     0.000	        1	conv2d_transpose/stack/3
native : stat_summarizer.cc:85 	                   Const	            0.081	    0.004	    0.003	  0.002%	  0.046%	     0.000	        1	output/Minimum/y
native : stat_summarizer.cc:85 	                   Const	            0.085	    0.004	    0.003	  0.002%	  0.049%	     0.000	        1	output/y
native : stat_summarizer.cc:85 	                    _Arg	            0.089	    0.004	    0.003	  0.003%	  0.051%	     0.000	        1	_arg_input_0_0
native : stat_summarizer.cc:85 	               MirrorPad	            0.095	    1.112	    1.351	  1.107%	  1.158%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 	                   Const	            1.471	    0.006	    0.006	  0.005%	  1.163%	     0.000	        1	batch_normalization/beta/read/_0__cf__0
native : stat_summarizer.cc:85 	                   Const	            1.479	    0.005	    0.004	  0.003%	  1.166%	     0.000	        1	batch_normalization/gamma/read/_1__cf__1
native : stat_summarizer.cc:85 	                   Const	            1.485	    0.005	    0.004	  0.003%	  1.170%	     0.000	        1	batch_normalization/moving_mean/read/_2__cf__2
native : stat_summarizer.cc:85 	                   Const	            1.491	    0.005	    0.003	  0.003%	  1.172%	     0.000	        1	batch_normalization/moving_variance/read/_3__cf__3
native : stat_summarizer.cc:85 	                   Const	            1.496	    0.006	    0.004	  0.003%	  1.175%	     0.000	        1	batch_normalization_1/beta/read/_4__cf__4
native : stat_summarizer.cc:85 	                   Const	            1.501	    0.008	    0.004	  0.003%	  1.178%	     0.000	        1	batch_normalization_1/gamma/read/_5__cf__5
native : stat_summarizer.cc:85 	                   Const	            1.505	    0.007	    0.004	  0.003%	  1.181%	     0.000	        1	batch_normalization_1/moving_mean/read/_6__cf__6
native : stat_summarizer.cc:85 	                   Const	            1.511	    0.006	    0.003	  0.003%	  1.184%	     0.000	        1	batch_normalization_1/moving_variance/read/_7__cf__7
native : stat_summarizer.cc:85 	                   Const	            1.516	    0.006	    0.004	  0.003%	  1.187%	     0.000	        1	conv2d/Conv2D/ReadVariableOp/_8__cf__8
native : stat_summarizer.cc:85 	                  Conv2D	            1.522	    8.478	    8.902	  7.290%	  8.477%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	                    Relu	           10.455	    1.142	    1.071	  0.878%	  9.355%	     0.000	        1	activation/Relu
native : stat_summarizer.cc:85 	          FusedBatchNorm	           11.540	    3.001	    2.754	  2.256%	 11.611%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	                   Const	           14.332	    0.011	    0.012	  0.010%	 11.620%	     0.000	        1	conv2d_1/Conv2D/ReadVariableOp/_9__cf__9
native : stat_summarizer.cc:85 	                  Conv2D	           14.348	   23.520	   23.289	 19.073%	 30.694%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	           37.672	    2.232	    2.291	  1.877%	 32.570%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	                    Relu	           39.983	    0.692	    0.830	  0.680%	 33.250%	     0.000	        1	activation_1/Relu
native : stat_summarizer.cc:85 	                   Const	           40.828	    0.012	    0.012	  0.010%	 33.260%	     0.000	        1	conv2d_2/Conv2D/ReadVariableOp/_10__cf__10
native : stat_summarizer.cc:85 	                  Conv2D	           40.844	   23.039	   23.440	 19.197%	 52.457%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                     Add	           64.319	    2.242	    2.501	  2.048%	 54.505%	     0.000	        1	add
native : stat_summarizer.cc:85 	                   Const	           66.836	    0.012	    0.012	  0.010%	 54.515%	     0.000	        1	conv2d_3/Conv2D/ReadVariableOp/_11__cf__11
native : stat_summarizer.cc:85 	                  Conv2D	           66.854	   31.680	   31.959	 26.174%	 80.689%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	                    Relu	           98.846	    1.627	    1.682	  1.377%	 82.066%	     0.000	        1	activation_2/Relu
native : stat_summarizer.cc:85 	                   Shape	          100.543	    0.027	    0.026	  0.022%	 82.088%	     0.016	        1	conv2d_transpose/Shape
native : stat_summarizer.cc:85 	            StridedSlice	          100.576	    0.023	    0.021	  0.017%	 82.105%	     0.004	        1	conv2d_transpose/strided_slice
native : stat_summarizer.cc:85 	            StridedSlice	          100.605	    0.018	    0.007	  0.006%	 82.111%	     0.004	        1	conv2d_transpose/strided_slice_1
native : stat_summarizer.cc:85 	                     Mul	          100.617	    0.010	    0.012	  0.010%	 82.121%	     0.000	        1	conv2d_transpose/mul
native : stat_summarizer.cc:85 	            StridedSlice	          100.632	    0.007	    0.008	  0.007%	 82.127%	     0.004	        1	conv2d_transpose/strided_slice_2
native : stat_summarizer.cc:85 	                     Mul	          100.644	    0.003	    0.004	  0.003%	 82.131%	     0.000	        1	conv2d_transpose/mul_1
native : stat_summarizer.cc:85 	                    Pack	          100.651	    0.013	    0.015	  0.012%	 82.143%	     0.016	        1	conv2d_transpose/stack
native : stat_summarizer.cc:85 	                   Const	          100.672	    0.008	    0.009	  0.007%	 82.150%	     0.000	        1	conv2d_transpose/conv2d_transpose/ReadVariableOp/_12__cf__12
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          100.684	   19.043	   20.264	 16.596%	 98.746%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                 Minimum	          120.986	    1.088	    0.878	  0.719%	 99.465%	     0.000	        1	output/Minimum
native : stat_summarizer.cc:85 	                 Maximum	          121.874	    0.465	    0.634	  0.519%	 99.985%	     0.000	        1	output
native : stat_summarizer.cc:85 	                 _Retval	          122.517	    0.010	    0.019	  0.015%	100.000%	     0.000	        1	_retval_output_0_0
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 ============================== Top by Computation Time ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	                  Conv2D	           66.854	   31.680	   31.959	 26.174%	 26.174%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	           40.844	   23.039	   23.440	 19.197%	 45.371%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	           14.348	   23.520	   23.289	 19.073%	 64.444%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          100.684	   19.043	   20.264	 16.596%	 81.041%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                  Conv2D	            1.522	    8.478	    8.902	  7.290%	 88.331%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	           11.540	    3.001	    2.754	  2.256%	 90.587%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	                     Add	           64.319	    2.242	    2.501	  2.048%	 92.635%	     0.000	        1	add
native : stat_summarizer.cc:85 	          FusedBatchNorm	           37.672	    2.232	    2.291	  1.877%	 94.511%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	                    Relu	           98.846	    1.627	    1.682	  1.377%	 95.888%	     0.000	        1	activation_2/Relu
native : stat_summarizer.cc:85 	               MirrorPad	            0.095	    1.112	    1.351	  1.107%	 96.995%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 ============================== Top by Memory Use ==============================
native : stat_summarizer.cc:85 	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	          100.684	   19.043	   20.264	 16.596%	 16.596%	 15728.640	        1	conv2d_transpose/conv2d_transpose
native : stat_summarizer.cc:85 	                  Conv2D	           66.854	   31.680	   31.959	 26.174%	 42.770%	 12582.912	        1	conv2d_3/Conv2D
native : stat_summarizer.cc:85 	          FusedBatchNorm	           11.540	    3.001	    2.754	  2.256%	 45.026%	  6390.528	        1	batch_normalization/FusedBatchNorm
native : stat_summarizer.cc:85 	                  Conv2D	           40.844	   23.039	   23.440	 19.197%	 64.223%	  6390.144	        1	conv2d_2/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	           14.348	   23.520	   23.289	 19.073%	 83.296%	  6390.144	        1	conv2d_1/Conv2D
native : stat_summarizer.cc:85 	                  Conv2D	            1.522	    8.478	    8.902	  7.290%	 90.587%	  6390.144	        1	conv2d/Conv2D
native : stat_summarizer.cc:85 	               MirrorPad	            0.095	    1.112	    1.351	  1.107%	 91.693%	   811.200	        1	MirrorPad
native : stat_summarizer.cc:85 	          FusedBatchNorm	           37.672	    2.232	    2.291	  1.877%	 93.570%	     0.384	        1	batch_normalization_1/FusedBatchNorm
native : stat_summarizer.cc:85 	                    Pack	          100.651	    0.013	    0.015	  0.012%	 93.582%	     0.016	        1	conv2d_transpose/stack
native : stat_summarizer.cc:85 	                   Shape	          100.543	    0.027	    0.026	  0.022%	 93.604%	     0.016	        1	conv2d_transpose/Shape
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 Number of nodes executed: 52
native : stat_summarizer.cc:85 ============================== Summary by node type ==============================
native : stat_summarizer.cc:85 	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
native : stat_summarizer.cc:85 	                  Conv2D	        4	    87.586	    71.748%	    71.748%	 31753.344	        4
native : stat_summarizer.cc:85 	     Conv2DBackpropInput	        1	    20.264	    16.600%	    88.348%	 15728.640	        1
native : stat_summarizer.cc:85 	          FusedBatchNorm	        2	     5.045	     4.133%	    92.481%	  6390.912	        2
native : stat_summarizer.cc:85 	                    Relu	        3	     3.582	     2.934%	    95.415%	     0.000	        3
native : stat_summarizer.cc:85 	                     Add	        1	     2.500	     2.048%	    97.463%	     0.000	        1
native : stat_summarizer.cc:85 	               MirrorPad	        1	     1.351	     1.107%	    98.570%	   811.200	        1
native : stat_summarizer.cc:85 	                 Minimum	        1	     0.877	     0.718%	    99.288%	     0.000	        1
native : stat_summarizer.cc:85 	                 Maximum	        1	     0.634	     0.519%	    99.807%	     0.000	        1
native : stat_summarizer.cc:85 	                   Const	       28	     0.116	     0.095%	    99.903%	     0.000	       28
native : stat_summarizer.cc:85 	            StridedSlice	        3	     0.036	     0.029%	    99.932%	     0.012	        3
native : stat_summarizer.cc:85 	                   Shape	        1	     0.026	     0.021%	    99.953%	     0.016	        1
native : stat_summarizer.cc:85 	                 _Retval	        1	     0.018	     0.015%	    99.968%	     0.000	        1
native : stat_summarizer.cc:85 	                     Mul	        2	     0.015	     0.012%	    99.980%	     0.000	        2
native : stat_summarizer.cc:85 	                    Pack	        1	     0.014	     0.011%	    99.992%	     0.016	        1
native : stat_summarizer.cc:85 	                    NoOp	        1	     0.007	     0.006%	    99.998%	     0.000	        1
native : stat_summarizer.cc:85 	                    _Arg	        1	     0.003	     0.002%	   100.000%	     0.000	        1
native : stat_summarizer.cc:85 
native : stat_summarizer.cc:85 Timings (microseconds): count=50 first=119656 curr=123144 min=117106 max=143566 avg=122102 std=4282
native : stat_summarizer.cc:85 Memory (bytes): count=50 curr=54684140(all same)
native : stat_summarizer.cc:85 52 nodes observed
native : stat_summarizer.cc:85 
&lt;/denchmark-code&gt;

TFLite 1 threads In:1x256x256x3 Performance w/o NNAPI
benchmark_model --graph=/data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite --num_threads=1
&lt;denchmark-code&gt;STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite]
Input layers: []
Input shapes: []
Use nnapi : [0]
Allow fp16 : [0]
nnapi error: requires android sdk version to be at least 27
Loaded model /data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite
resolved reporter
Initialized session in 17.527ms
Running benchmark for at least 1 iterations and at least 0.5 seconds
count=1 curr=1058871

Running benchmark for at least 50 iterations and at least 1 seconds
count=50 first=885931 curr=881142 min=851668 max=903937 avg=880688 std=12426

============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	              MIRROR_PAD	            0.000	   11.161	   11.156	  1.267%	  1.267%	     0.000	        1	[MirrorPad]
	                 CONV_2D	           11.158	    9.939	   10.067	  1.143%	  2.410%	     0.000	        1	[activation/Relu]
	                     MUL	           21.226	    1.432	    1.521	  0.173%	  2.583%	     0.000	        1	[batch_normalization/FusedBatchNorm_mul_0]
	                     ADD	           22.748	    1.491	    1.520	  0.173%	  2.755%	     0.000	        1	[batch_normalization/FusedBatchNorm]
	                 CONV_2D	           24.269	   82.282	   82.912	  9.415%	 12.170%	     0.000	        1	[activation_1/Relu]
	                 CONV_2D	          107.182	   82.992	   82.822	  9.404%	 21.574%	     0.000	        1	[conv2d_2/Conv2D]
	                     ADD	          190.005	    1.450	    1.574	  0.179%	 21.753%	     0.000	        1	[add]
	                 CONV_2D	          191.579	  117.950	  118.416	 13.446%	 35.199%	     0.000	        1	[activation_2/Relu]
	          TRANSPOSE_CONV	          309.996	  569.173	  562.609	 63.884%	 99.083%	     0.000	        1	[conv2d_transpose/conv2d_transpose]
	                 MINIMUM	          872.607	    4.092	    4.072	  0.462%	 99.545%	     0.000	        1	[output/Minimum]
	                 MAXIMUM	          876.680	    3.955	    4.004	  0.455%	100.000%	     0.000	        1	[output]

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	          TRANSPOSE_CONV	          309.996	  569.173	  562.609	 63.884%	 63.884%	     0.000	        1	[conv2d_transpose/conv2d_transpose]
	                 CONV_2D	          191.579	  117.950	  118.416	 13.446%	 77.330%	     0.000	        1	[activation_2/Relu]
	                 CONV_2D	           24.269	   82.282	   82.912	  9.415%	 86.745%	     0.000	        1	[activation_1/Relu]
	                 CONV_2D	          107.182	   82.992	   82.822	  9.404%	 96.149%	     0.000	        1	[conv2d_2/Conv2D]
	              MIRROR_PAD	            0.000	   11.161	   11.156	  1.267%	 97.416%	     0.000	        1	[MirrorPad]
	                 CONV_2D	           11.158	    9.939	   10.067	  1.143%	 98.559%	     0.000	        1	[activation/Relu]
	                 MINIMUM	          872.607	    4.092	    4.072	  0.462%	 99.021%	     0.000	        1	[output/Minimum]
	                 MAXIMUM	          876.680	    3.955	    4.004	  0.455%	 99.476%	     0.000	        1	[output]
	                     ADD	          190.005	    1.450	    1.574	  0.179%	 99.655%	     0.000	        1	[add]
	                     MUL	           21.226	    1.432	    1.521	  0.173%	 99.827%	     0.000	        1	[batch_normalization/FusedBatchNorm_mul_0]

Number of nodes executed: 11
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	          TRANSPOSE_CONV	        1	   562.609	    63.884%	    63.884%	     0.000	        1
	                 CONV_2D	        4	   294.214	    33.408%	    97.292%	     0.000	        4
	              MIRROR_PAD	        1	    11.156	     1.267%	    98.559%	     0.000	        1
	                 MINIMUM	        1	     4.072	     0.462%	    99.021%	     0.000	        1
	                 MAXIMUM	        1	     4.004	     0.455%	    99.476%	     0.000	        1
	                     ADD	        2	     3.093	     0.351%	    99.827%	     0.000	        2
	                     MUL	        1	     1.521	     0.173%	   100.000%	     0.000	        1

Timings (microseconds): count=50 first=885917 curr=881128 min=851653 max=903921 avg=880674 std=12426
Memory (bytes): count=0
11 nodes observed


Average inference timings in us: Warmup: 1.05887e+06, Init: 17527, no stats: 880688
&lt;/denchmark-code&gt;

TFLite 16 threads In:1x256x256x3 Performance w/o NNAPI
benchmark_model --graph=/data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite --num_threads=16
&lt;denchmark-code&gt;STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Inter-run delay (seconds): [-1]
Num threads: [16]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite]
Input layers: []
Input shapes: []
Use nnapi : [0]
Allow fp16 : [0]
nnapi error: requires android sdk version to be at least 27
Loaded model /data/local/tmp/UpResnet5-X2-H256-W256-C3.tflite
resolved reporter
Initialized session in 17.382ms
Running benchmark for at least 1 iterations and at least 0.5 seconds
count=1 curr=814662

Running benchmark for at least 50 iterations and at least 1 seconds
count=50 first=632324 curr=652388 min=617231 max=683660 avg=641555 std=13138

============================== Run Order ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	              MIRROR_PAD	            0.000	   11.208	   11.343	  1.768%	  1.768%	     0.000	        1	[MirrorPad]
	                 CONV_2D	           11.344	   11.457	   11.713	  1.826%	  3.594%	     0.000	        1	[activation/Relu]
	                     MUL	           23.059	    2.024	    1.853	  0.289%	  3.883%	     0.000	        1	[batch_normalization/FusedBatchNorm_mul_0]
	                     ADD	           24.912	    1.510	    1.803	  0.281%	  4.164%	     0.000	        1	[batch_normalization/FusedBatchNorm]
	                 CONV_2D	           26.716	   11.487	   12.328	  1.922%	  6.085%	     0.000	        1	[activation_1/Relu]
	                 CONV_2D	           39.044	   11.615	   11.867	  1.850%	  7.935%	     0.000	        1	[conv2d_2/Conv2D]
	                     ADD	           50.912	    1.470	    1.421	  0.222%	  8.157%	     0.000	        1	[add]
	                 CONV_2D	           52.334	   19.418	   19.692	  3.069%	 11.226%	     0.000	        1	[activation_2/Relu]
	          TRANSPOSE_CONV	           72.027	  554.071	  561.442	 87.515%	 98.741%	     0.000	        1	[conv2d_transpose/conv2d_transpose]
	                 MINIMUM	          633.470	    4.022	    4.066	  0.634%	 99.374%	     0.000	        1	[output/Minimum]
	                 MAXIMUM	          637.537	    4.028	    4.014	  0.626%	100.000%	     0.000	        1	[output]

============================== Top by Computation Time ==============================
	             [node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
	          TRANSPOSE_CONV	           72.027	  554.071	  561.442	 87.515%	 87.515%	     0.000	        1	[conv2d_transpose/conv2d_transpose]
	                 CONV_2D	           52.334	   19.418	   19.692	  3.069%	 90.584%	     0.000	        1	[activation_2/Relu]
	                 CONV_2D	           26.716	   11.487	   12.328	  1.922%	 92.506%	     0.000	        1	[activation_1/Relu]
	                 CONV_2D	           39.044	   11.615	   11.867	  1.850%	 94.355%	     0.000	        1	[conv2d_2/Conv2D]
	                 CONV_2D	           11.344	   11.457	   11.713	  1.826%	 96.181%	     0.000	        1	[activation/Relu]
	              MIRROR_PAD	            0.000	   11.208	   11.343	  1.768%	 97.949%	     0.000	        1	[MirrorPad]
	                 MINIMUM	          633.470	    4.022	    4.066	  0.634%	 98.583%	     0.000	        1	[output/Minimum]
	                 MAXIMUM	          637.537	    4.028	    4.014	  0.626%	 99.209%	     0.000	        1	[output]
	                     MUL	           23.059	    2.024	    1.853	  0.289%	 99.498%	     0.000	        1	[batch_normalization/FusedBatchNorm_mul_0]
	                     ADD	           24.912	    1.510	    1.803	  0.281%	 99.778%	     0.000	        1	[batch_normalization/FusedBatchNorm]

Number of nodes executed: 11
============================== Summary by node type ==============================
	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
	          TRANSPOSE_CONV	        1	   561.441	    87.515%	    87.515%	     0.000	        1
	                 CONV_2D	        4	    55.597	     8.666%	    96.182%	     0.000	        4
	              MIRROR_PAD	        1	    11.343	     1.768%	    97.950%	     0.000	        1
	                 MINIMUM	        1	     4.065	     0.634%	    98.583%	     0.000	        1
	                 MAXIMUM	        1	     4.013	     0.626%	    99.209%	     0.000	        1
	                     ADD	        2	     3.223	     0.502%	    99.711%	     0.000	        2
	                     MUL	        1	     1.852	     0.289%	   100.000%	     0.000	        1

Timings (microseconds): count=50 first=632310 curr=652370 min=617213 max=683643 avg=641541 std=13137
Memory (bytes): count=0
11 nodes observed


Average inference timings in us: Warmup: 814662, Init: 17382, no stats: 641555
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='stakemura' date='2019-03-19T18:39:43Z'>
		Why are you running with 16 threads on a 4-core device? Can you run the numbers with just 1 thread?
		</comment>
		<comment id='2' author='stakemura' date='2019-03-22T04:13:36Z'>
		&lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
 Sorry for replying late.
I added the benchmark result with 1 and 4 threads.
The result shows that 16 threads is faster than 4 threads.
		</comment>
		<comment id='3' author='stakemura' date='2019-03-22T15:35:50Z'>
		Thanks &lt;denchmark-link:https://github.com/stakemura&gt;@stakemura&lt;/denchmark-link&gt;
, we're actively investigating the performance discrepancy internally. Stay tuned.
		</comment>
		<comment id='4' author='stakemura' date='2019-04-15T15:38:55Z'>
		A &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/5e52b70188ceffc28e4c6a92f2366245dd6be159#diff-2b45693b554369bde8c98e9a76b80036&gt;fix&lt;/denchmark-link&gt;
 for this just landed, and TransposeConv performance in TFLite (single-threaded) should now be comparable to TFMobile. Thanks for your patience.
		</comment>
		<comment id='5' author='stakemura' date='2019-04-15T15:38:58Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26736&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26736&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>