<bug id='27345' author='MMMarcy' open_date='2019-03-31T14:57:15Z' closed_time='2019-09-13T20:57:33Z'>
	<summary>[TF2.0] EstimatorV2 uses non existing export_savedmodel method</summary>
	<description>
Dear tensorflowers,
as per the title, EstimatorV2's exporter.py calls a method that has been removed. The fix is pretty easy, but I'm not sure about the implications of the change. See more below.
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code, but using estimators
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 4.19.20-1rodete1-amd64 #1 SMP Debian 4.19.20-1rodete1
TensorFlow installed from (source or binary): pip install --upgrade tensorflow==2.0.0alpha0
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.7.1

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

using tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec) results in AttributeError: 'EstimatorV2' object has no attribute 'export_savedmodel' being thrown.
2 small modifications to my local tensorflow_estimator/python/estimator/exporter.py file fix the issue. However, before submitting a PR i wanted to clarify that I had to:

Rename the method call to estimator.export_saved_model(...) and this poses no problem.
Remove the strip_default_attrs=self._strip_default_attrs keyword argument, but I have no idea what this entails. I assume that, since you can't specify this argument anymore, it defaults to the default policy in TF 1.X of stripping the GraphDef default attributes. If that's the case, is there any action required?

&lt;denchmark-h:h4&gt;Logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 473, in train_and_evaluate
    return executor.run()
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 613, in run
    return self.run_local()
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 714, in run_local
    saving_listeners=saving_listeners)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 359, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1139, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1173, in _train_model_default
    saving_listeners)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py", line 1452, in _train_with_estimator_spec
    any_step_done = True
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 856, in __exit__
    self._close_internal(exception_type)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py", line 889, in _close_internal
    h.end(self._coordinated_creator.tf_sess)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py", line 588, in end
    self._save(session, last_step)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow/python/training/basic_session_run_hooks.py", line 607, in _save
    if l.after_save(session, step):
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 519, in after_save
    self._evaluate(global_step_value)  # updates self.eval_result
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 539, in _evaluate
    self._evaluator.evaluate_and_export())
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 927, in evaluate_and_export
    is_the_final_export)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py", line 960, in _export_eval_result
    is_the_final_export=is_the_final_export))
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/exporter.py", line 420, in export
    is_the_final_export)
  File "/usr/local/google/home/msteiner/.pyenv/versions/3.7.1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/exporter.py", line 120, in export
    export_result = estimator.export_savedmodel(
AttributeError: 'EstimatorV2' object has no attribute 'export_savedmodel'
&lt;/denchmark-code&gt;

&lt;denchmark-h:h5&gt;Code&lt;/denchmark-h&gt;

I'm trying to adapt the &lt;denchmark-link:https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/cloudml-template&gt;CMLE template&lt;/denchmark-link&gt;
 to TF 2.0 . I avoided putting the input_fns and model_fns since the model trains and evals correctly. The only problem is during the export.
 train_input_fn = model_input.generate_input_fn(
      file_names_pattern=FLAGS.train_files,
      mode=tf.estimator.ModeKeys.TRAIN,
      num_epochs=FLAGS.num_epochs,
      batch_size=FLAGS.train_batch_size)

  eval_input_fn = model_input.generate_input_fn(
      file_names_pattern=FLAGS.eval_files,
      mode=tf.estimator.ModeKeys.EVAL,
      batch_size=FLAGS.eval_batch_size)



  if metadata.TASK_TYPE == "classification":
    estimator = model.create_classifier(config=run_config)
  elif metadata.TASK_TYPE == "regression":
    estimator = model.create_regressor(config=run_config)
  else:
    estimator = model.create_estimator(config=run_config)

  train_spec = tf.estimator.TrainSpec(
      train_input_fn,
      max_steps=int(train_steps),
  )

  # Export for the final prediction graph.
  exporter_default = tf.estimator.FinalExporter(
      'estimator',
      model_input.SERVING_FUNCTIONS[FLAGS.export_format](),
      as_text=False )

  eval_spec = tf.estimator.EvalSpec(
      eval_input_fn,
      steps=FLAGS.eval_steps,
      exporters=[exporter_default],  # This tells
      throttle_secs=FLAGS.eval_every_secs,
      start_delay_secs=0)

  # Main train and evaluate loop.
  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
Happy to provide any additional information!
	</description>
	<comments>
		<comment id='1' author='MMMarcy' date='2019-04-24T18:51:49Z'>
		&lt;denchmark-link:https://github.com/toby&gt;@toby&lt;/denchmark-link&gt;
 this is the PR for estimator exporter.  He need 2 clarification before.
		</comment>
		<comment id='2' author='MMMarcy' date='2019-04-26T17:05:38Z'>
		We already have export_saved_model, is there anything else needed here?
		</comment>
		<comment id='3' author='MMMarcy' date='2019-04-26T18:03:30Z'>
		Are you saving it was already fixed in a recent nightly ? If yes, I will give a try. Thanks
		</comment>
		<comment id='4' author='MMMarcy' date='2019-04-26T18:12:20Z'>
		Yes, please let me know once you try it using master version.
		</comment>
		<comment id='5' author='MMMarcy' date='2019-04-27T11:53:35Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 , I tried with the latest nightly tf-nightly-2.0-preview==2.0.0.dev20190426
and I get another crash but still related to exporter:
&lt;denchmark-code&gt;~/anaconda3/envs/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/exporter.py in export(***failed resolving arguments***)
    124         as_text=self._as_text,
    125         checkpoint_path=checkpoint_path,
--&gt; 126         strip_default_attrs=self._strip_default_attrs)
    127 
    128     return export_result

TypeError: '_HiddenTfApiAttribute' object is not callable
&lt;/denchmark-code&gt;

the crash seems related to the 2) points mention above by &lt;denchmark-link:https://github.com/MMMarcy&gt;@MMMarcy&lt;/denchmark-link&gt;
 :
"Remove the strip_default_attrs=self._strip_default_attrs keyword argument, but I have no idea what this entails. I assume that, since you can't specify this argument anymore, it defaults to the default policy in TF 1.X of stripping the GraphDef default attributes. If that's the case, is there any action required?"
so 1) seems to be fixed but not 2). Thanks
		</comment>
		<comment id='6' author='MMMarcy' date='2019-06-15T21:43:03Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 did you managed to run tf.estimator.LatestExporter with Estimator ? with nightly tf-nightly-2.0-preview==2.0.0.dev20190614 I have new errors:
&lt;denchmark-code&gt;~/anaconda3/envs/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)
    567       raise TypeError("Failed to convert object of type %s to Tensor. "
    568                       "Contents: %s. Consider casting elements to a "
--&gt; 569                       "supported type." % (type(values), values))
    570     tensor_proto.string_val.extend(str_values)
    571     return tensor_proto

TypeError: Failed to convert object of type &lt;class 'tensorflow.python.framework.dtypes.DType'&gt; to Tensor. Contents: &lt;dtype: 'float32'&gt;. Consider casting elements to a supported type.
&lt;/denchmark-code&gt;

Is there something to change with respect to TF 1.1.2 ?
&lt;denchmark-code&gt;# Create serving input function
def serving_input_receiver_fn():
    """Serving input_fn that builds features from placeholders#

    Returns
    -------
    tf.estimator.export.ServingInputReceiver
    """

    input_images = tf.Variable(tf.float32, [None, 784])
    features = {
        'dense_input': input_images}  # this is the dict that is then passed as "features" parameter to your model_fn
    receiver_tensors = {
        'dense_input': input_images}  # As far as I understand this is needed to map the input to a name you can retrieve later

    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)
&lt;/denchmark-code&gt;

I am not sure now if the issue is with my code or if the issue is still on the TF side. I look at the official doc and I couldn't an a example with TF 2.0 beta
		</comment>
		<comment id='7' author='MMMarcy' date='2019-06-17T20:49:12Z'>
		&lt;denchmark-link:https://github.com/tarrade&gt;@tarrade&lt;/denchmark-link&gt;
, I am assigning this to someone who's more familiar with this topic.
		</comment>
		<comment id='8' author='MMMarcy' date='2019-07-26T10:23:46Z'>
		Any status on this issue ? &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/MMMarcy&gt;@MMMarcy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;

I am wondering what is the status of the migration of tf.estimator to Tensorfloe 2.0. It seems few things are not working yet. Probably tf.estimator is/will be the last part migrationg to Tensorflow 2.0. For example in the official documentation, the example on tf.estimator is very very limited, still use compat.v1 module for some ops and don't save the model:
&lt;denchmark-link:https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator&gt;https://www.tensorflow.org/beta/tutorials/distribute/multi_worker_with_estimator&lt;/denchmark-link&gt;

I did a new test with the latest nightly tf-nightly-2.0-preview==2.0.0.dev20190725 and I still have issue:

I0726 12:01:23.221257 4583781824 estimator.py:2100] Saving 'checkpoint_path' summary for global step 10: results/Models/Mnist/tf_1_12/estimator/v3/ckpt/model.ckpt-10



TypeError                                 Traceback (most recent call last)
~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape, allow_broadcast)
534     try:
--&gt; 535       str_values = [compat.as_bytes(x) for x in proto_values]
536     except TypeError:
~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py in (.0)
534     try:
--&gt; 535       str_values = [compat.as_bytes(x) for x in proto_values]
536     except TypeError:
~/anaconda-release/conda-env/env_gcp_dl_2_0_nightly/lib/python3.6/site-packages/tensorflow_core/python/util/compat.py in as_bytes(bytes_or_text, encoding)
64     raise TypeError('Expected binary or unicode string, got %r' %
---&gt; 65                     (bytes_or_text,))
66
TypeError: Expected binary or unicode string, got tf.float32
During handling of the above exception, another exception occurred:

I managed to find where is the issue:
&lt;denchmark-code&gt;# Create serving input function
def serving_input_receiver_fn():
    """Serving input_fn that builds features from placeholders#

    Returns
    -------
    tf.estimator.export.ServingInputReceiver
    """
    input_images = tf.Variable(tf.float32, [None, 784]) #&lt;- it is crashing here
&lt;/denchmark-code&gt;

now I didn't find how this should be in TF 2.0. Normally we can still use gragh and tf.Variable. I couldn't find up to know anything in the doc of  tf.estimator.export.ServingInputReceiver or some official example.
Any idea or expert that could know that. I have no idea if this is a bug or if I should update the problematic line. Thanks
		</comment>
		<comment id='9' author='MMMarcy' date='2019-09-13T20:57:33Z'>
		The issue in the OP with the wrong use of export_savedmodel should be fixed in 1.14.
&lt;denchmark-link:https://github.com/tarrade&gt;@tarrade&lt;/denchmark-link&gt;
 That looks like a different bug, can you create a new issue with some code to reproduce the errors? Although from the code snippet, you should be creating a placeholder and not a variable. If you're using a variable, the initialization arguments are in a different order.
		</comment>
		<comment id='10' author='MMMarcy' date='2019-09-13T20:57:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27345&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27345&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='MMMarcy' date='2019-10-23T04:36:39Z'>
		Excuse me &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 but how do I create a placeholder in tensorflow 2.0 (module 'tensorflow' has no attribute 'placeholder') ?
I am trying to update my serving_input_receiver_fn code where I need to create a tf.estimator.export.TensorServingInputReceiver. I don't find any example to update anywhere :(
		</comment>
		<comment id='12' author='MMMarcy' date='2019-10-23T20:16:46Z'>
		@laetitiaoist Estimator still relies on graph-based code, so you would have to use tf.compat.v1.placeholder.
We're recommending that users switch to tf.Keras in the future, which has built-in support for eager mode.
		</comment>
		<comment id='13' author='MMMarcy' date='2019-10-23T23:51:24Z'>
		It would be great to have instructions on how to update from Estimator to Keras. I thought Estimator was supported in TF2...
For example how to save the top N models when evaluating? I only see "save_best_only" option .
		</comment>
		<comment id='14' author='MMMarcy' date='2019-10-24T00:38:51Z'>
		Estimator is supported in TF2, but the APIs for building the graph have been removed from the V2 API to keep the new API compatible with eager. You can continue to use Estimators but you'll have to use the compat.v1 for certain APIs like placeholder.
There are instructions here for updating your model to use the Keras API: &lt;denchmark-link:https://www.tensorflow.org/guide/migrate#converting_models&gt;https://www.tensorflow.org/guide/migrate#converting_models&lt;/denchmark-link&gt;

Do you mean in Keras' ModelCheckpoint class? Yes, there're currently isn't a way to specify the keep the top N checkpoints. Feel free to create a new issue asking for a feature request.
		</comment>
	</comments>
</bug>