<bug id='36642' author='tsuzukit' open_date='2020-02-11T01:14:20Z' closed_time='2020-06-08T00:54:36Z'>
	<summary>Throw an error when connecting inputs to weight-shared-embedding-layer more than 5 times.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colaboratory with Ubuntu 18.04.3 LTS (Bionic Beaver)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-0-ge5bf8de410 2.1.0
Python version: 3.6.9
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When inputs are connected to weight-shared-embedding-layer more than 5 times, tensorflow throws an error while training.
This behavior is not seen with below condition.

connections to weight-shared-embedding-layer are less than 4
using tensorflow version 1.15

Describe the expected behavior
Successfully train a model using weight-shared-embedding-layer connecting more than 5 inputs.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np

# changing this to 4 make train success
n_inputs = 5
dim_embedding = 10

inputs = []
for i in range(n_inputs):
  inputs.append(tf.keras.Input(shape=(1,), dtype='int32'))

embeds = []
shared_embed = tf.keras.layers.Embedding(n_input, dim_embedding)
for i in range(n_inputs):
  embed = shared_embed(inputs[i])
  flatten = tf.keras.layers.Flatten()(embed)
  embeds.append(flatten)

concat = tf.keras.layers.Concatenate(axis=1)(embeds)
output = tf.keras.layers.Dense(1)(concat)
model = tf.keras.Model(inputs=[inputs], outputs=[output])
model.summary()

model.compile(optimizer='adam', loss='mse')

# run
dummy_input = []
for i in range(n_shared_layers):
  dummy_input.append(np.random.randint(0, n_input, size=(1000, )))

dummy = np.arange(1000).reshape(1000, 1, 1)

model.fit(x=dummy_input, y=dummy, batch_size=32, epochs=1, verbose=1)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
&lt;denchmark-link:https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=13C17fSiwhAC&gt;https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=13C17fSiwhAC&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='tsuzukit' date='2020-02-11T23:19:02Z'>
		&lt;denchmark-link:https://github.com/tsuzukit&gt;@tsuzukit&lt;/denchmark-link&gt;
 Can you please provide a standalone code to reproduce the issue? Thanks!
		</comment>
		<comment id='2' author='tsuzukit' date='2020-02-12T07:35:56Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

As in original comment, I meant below as minimum standalone code to reproduce the issue.
If you run below in colab, you should be able to reproduce the issue.
This is the colab I used. &lt;denchmark-link:https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=13C17fSiwhAC&gt;https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=13C17fSiwhAC&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np

# changing this to 4 make train success
n_inputs = 5
dim_embedding = 10

inputs = []
for i in range(n_inputs):
  inputs.append(tf.keras.Input(shape=(1,), dtype='int32'))

embeds = []
shared_embed = tf.keras.layers.Embedding(n_input, dim_embedding)
for i in range(n_inputs):
  embed = shared_embed(inputs[i])
  flatten = tf.keras.layers.Flatten()(embed)
  embeds.append(flatten)

concat = tf.keras.layers.Concatenate(axis=1)(embeds)
output = tf.keras.layers.Dense(1)(concat)
model = tf.keras.Model(inputs=[inputs], outputs=[output])
model.summary()

model.compile(optimizer='adam', loss='mse')

# run
dummy_input = []
for i in range(n_shared_layers):
  dummy_input.append(np.random.randint(0, n_input, size=(1000, )))

dummy = np.arange(1000).reshape(1000, 1, 1)

model.fit(x=dummy_input, y=dummy, batch_size=32, epochs=1, verbose=1)
&lt;/denchmark-code&gt;

Pls let me know if you need any other info!
		</comment>
		<comment id='3' author='tsuzukit' date='2020-02-12T20:28:50Z'>
		&lt;denchmark-link:https://github.com/tsuzukit&gt;@tsuzukit&lt;/denchmark-link&gt;
 It is throwing the following error. May be it was lost during translation as I had clicked google translation. Thanks!
&lt;denchmark-code&gt;---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input-6-6b24491b8648&gt; in &lt;module&gt;()
      7 
      8 embeds = []
----&gt; 9 shared_embed = tf.keras.layers.Embedding(n_input, dim_embedding)
     10 for i in range(n_inputs):
     11   embed = shared_embed(inputs[i])

NameError: name 'n_input' is not defined
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='tsuzukit' date='2020-02-13T00:19:50Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

Ah, sorry there were typos in the code.
Again, below is complete runnable code along with Colaboratory link that I used.
&lt;denchmark-code&gt;import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np

# changing this to 4 make train success
n_inputs = 5
n_items = 1000
dim_embedding = 10

inputs = []
for i in range(n_inputs):
  inputs.append(tf.keras.Input(shape=(1,), dtype='int32'))

embeds = []
shared_embed = tf.keras.layers.Embedding(n_items, dim_embedding)
for i in range(n_inputs):
  embed = shared_embed(inputs[i])
  flatten = tf.keras.layers.Flatten()(embed)
  embeds.append(flatten)

concat = tf.keras.layers.Concatenate(axis=1)(embeds)
output = tf.keras.layers.Dense(1)(concat)
model = tf.keras.Model(inputs=[inputs], outputs=[output])
model.summary()

model.compile(optimizer='adam', loss='mse')

# run
dummy_inputs = []
for i in range(n_inputs):
  dummy_inputs.append(np.random.randint(0, n_inputs, size=(n_items, )))

dummy = np.arange(n_items).reshape(n_items, 1, 1)

model.fit(x=dummy_inputs, y=dummy, batch_size=32, epochs=1, verbose=1)
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=JuJ1C645yW3x&gt;https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=JuJ1C645yW3x&lt;/denchmark-link&gt;

thanks!
		</comment>
		<comment id='5' author='tsuzukit' date='2020-02-13T00:45:54Z'>
		Here is the complete error trace for our reference.
&lt;denchmark-code&gt;Train on 1000 samples
  32/1000 [..............................] - ETA: 5s
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/backprop.py in _num_elements(grad)
    626   if isinstance(grad, ops.IndexedSlices):
--&gt; 627     return functools.reduce(operator.mul, grad.values._shape_tuple(), 1)  # pylint: disable=protected-access
    628   raise ValueError("`grad` not a Tensor or IndexedSlices.")

TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'

The above exception was the direct cause of the following exception:

SystemError                               Traceback (most recent call last)
23 frames
SystemError: &lt;built-in function len&gt; returned a result with an error set

The above exception was the direct cause of the following exception:

SystemError                               Traceback (most recent call last)
/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/imperative_grad.py in imperative_grad(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)
     75       output_gradients,
     76       sources_raw,
---&gt; 77       compat.as_str(unconnected_gradients.value))

SystemError: PyEval_EvalFrameEx returned a result with an error set
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='tsuzukit' date='2020-03-07T08:52:46Z'>
		To add some confusion, but maybe some debugging assistance:
I'm also getting this error on v2.1.0-rc2-17-ge5bf8de410 in my personal code. But, I adapted some example code as an attempt to reproduce it and was unable to reproduce the error.
&lt;denchmark-link:https://colab.research.google.com/gist/JoshEZiegler/317daa870ba923512887f5db9c9706de/functional.ipynb&gt;Here&lt;/denchmark-link&gt;
 is working embedding sharing code.
&lt;denchmark-link:https://colab.research.google.com/drive/18qodVaGRJHlV0dXvIVGUQm6J5t35VeX5&gt;Here&lt;/denchmark-link&gt;
 is slightly changed code from above that doesn't work.
I can't see a difference between these two, but perhaps the comparison could be helpful?
		</comment>
		<comment id='7' author='tsuzukit' date='2020-03-07T18:27:01Z'>
		After some more debugging it looks like this code will run if dataset_size modulo batch_size is zero. Hopefully that's helpful! (Source: tried, in the above code, dataset_size=1280, batch_size=32, and dataset_size=1000, batch_size=10,100 which all worked)
		</comment>
		<comment id='8' author='tsuzukit' date='2020-06-06T06:20:34Z'>
		&lt;denchmark-link:https://github.com/tsuzukit&gt;@tsuzukit&lt;/denchmark-link&gt;
 Looks like this was resolved in recent . Can you please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/d399e888688f963a5ce850103e8ef98d/tf_shared_layer.ipynb?hl=ja&gt;gist here&lt;/denchmark-link&gt;
.
Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='9' author='tsuzukit' date='2020-06-06T13:45:50Z'>
		Hi, I've got this error with this nightly build
  File "/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 108, in _method_wrapper return method(self, *args, **kwargs) File "/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 1094, in fit epoch_logs = copy.copy(logs) UnboundLocalError: local variable 'logs' referenced before assignment
when I was trying to reproduce the issue
		</comment>
		<comment id='10' author='tsuzukit' date='2020-06-08T00:54:36Z'>
		Hi &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

Thanks for letting me know.
I have tested &lt;denchmark-link:https://colab.research.google.com/drive/1Ie1HgUz5jxsK5Nfbq8hU9YGykqWnRFN4?hl=ja#scrollTo=apd3gVJzyail&gt;same code&lt;/denchmark-link&gt;
 with  build.
It worked just fine!
		</comment>
		<comment id='11' author='tsuzukit' date='2020-06-08T00:54:38Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36642&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36642&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>