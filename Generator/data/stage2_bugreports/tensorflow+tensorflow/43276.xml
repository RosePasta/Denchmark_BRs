<bug id='43276' author='neel04' open_date='2020-09-16T18:54:02Z' closed_time='2020-10-12T18:45:51Z'>
	<summary>Model trains on GPU but not on TPU</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Mostly stock
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Colab)
TensorFlow installed from (source or binary): Pre-installed
TensorFlow version (use command below): 2.3.0
Python version: 3.x
Accelerator: TPU

Describe the current behavior
I am receiving this error:-
&lt;denchmark-code&gt;InvalidArgumentError: 9 root error(s) found.
  (0) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_233]]
  (1) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_209]]
  (2) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_173]]
  (3) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_185]]
  (4) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_197]]
  (5) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_245]]
  (6) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embedding_lookup/Reshape_1}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5]]
	 [[tpu_compile_succeeded_assert/_11288723609953746016/_5/_257]]
  (7) Invalid argument: {{function_node __inference_train_function_33888}} Compilation failure: Input to reshape is a tensor with 100 values, but the requested shape has 50
	 [[{{node gradient_tape/sequential_4/embedding_4/embed ... [truncated]
&lt;/denchmark-code&gt;

Which indicates that there is probably some error with the shapes of my model.
Describe the expected behavior
Expected the model to run, as it runs pretty well for considerable time on GPU but ALWAYS results in that error when using TPU. This means that the Model should train and run (since no error is received on GPU and does the training of the first Epoch)
Standalone code to reproduce the issue
Here is the model.fit block to initiate the training:-
&lt;denchmark-code&gt;# Directory where the checkpoints will be saved
checkpoint_dir = '/content/drive/My Drive/HashPro/checkpoints/'

checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}")

checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_prefix)

EPOCHS = 50

history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], steps_per_epoch=300)  # Comment to evaluate the model
&lt;/denchmark-code&gt;

Here is how my model looks like:-
&lt;denchmark-code&gt;
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (1, None, 8800)           158400    
_________________________________________________________________
dense_42 (Dense)             (1, None, 2500)           22002500  
_________________________________________________________________
dropout_23 (Dropout)         (1, None, 2500)           0         
_________________________________________________________________
dense_43 (Dense)             (1, None, 3500)           8753500   
_________________________________________________________________
dense_44 (Dense)             (1, None, 5500)           19255500  
_________________________________________________________________
dropout_24 (Dropout)         (1, None, 5500)           0         
_________________________________________________________________
dense_45 (Dense)             (1, None, 7500)           41257500  
_________________________________________________________________
dense_46 (Dense)             (1, None, 9500)           71259500  
_________________________________________________________________
batch_normalization_8 (Batch (1, None, 9500)           38000     
_________________________________________________________________
dropout_25 (Dropout)         (1, None, 9500)           0         
_________________________________________________________________
dense_47 (Dense)             (1, None, 7000)           66507000  
_________________________________________________________________
dense_48 (Dense)             (1, None, 7000)           49007000  
_________________________________________________________________
dropout_26 (Dropout)         (1, None, 7000)           0         
_________________________________________________________________
dense_49 (Dense)             (1, None, 1500)           10501500  
_________________________________________________________________
dense_50 (Dense)             (1, None, 500)            750500    
_________________________________________________________________
dropout_27 (Dropout)         (1, None, 500)            0         
_________________________________________________________________
activation_4 (Activation)    (1, None, 500)            0         
_________________________________________________________________
batch_normalization_9 (Batch (1, None, 500)            2000      
=================================================================
Total params: 289,492,900
Trainable params: 289,472,900
Non-trainable params: 20,000

&lt;/denchmark-code&gt;

Model block for building and applying TPU strategy to run it:-
&lt;denchmark-code&gt;def build_model(vocab_size, embedding_dim, mid_units, batch_size):
  model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),
  tf.keras.layers.Dense(2500, activation='relu'),
  tf.keras.layers.Dropout(0.15),
  tf.keras.layers.Dense(3500, activation='relu'),
  tf.keras.layers.Dense(5500, activation='relu'),
  tf.keras.layers.Dropout(0.15),

  tf.keras.layers.Dense(7500, activation='relu'),
  tf.keras.layers.Dense(9500, activation='relu'),
  tf.keras.layers.BatchNormalization(),
  tf.keras.layers.Dropout(0.15),
  tf.keras.layers.Dense(mid_units, activation='relu'),
  tf.keras.layers.Dense(mid_units, activation='relu'),
  tf.keras.layers.Dropout(0.15),

  tf.keras.layers.Dense(1500, activation='relu'),
  tf.keras.layers.Dense(500, activation='relu'),
  tf.keras.layers.Dropout(0.15),
  
  tf.keras.layers.Activation('softmax'),
  tf.keras.layers.BatchNormalization()
])
  return model

def loss(labels, logits):
  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)

with strategy.scope():
  model = build_model(
    vocab_size = len(vocab),
    embedding_dim=embedding_dim,
    mid_units=7000,
    batch_size=BATCH_SIZE)

  model.compile(optimizer='Adam', loss=loss)

#Let's see the model's organs!
model.summary()
&lt;/denchmark-code&gt;

TPU strategy and initialization code taken from the TensorFlow website and does not produce any error at all.

It seems to me that there might be a bug here, since if the model has some shape-related issue, then training on GPU would not have worked at all. But since it works, there might be a problem in that way I am using the TPU

If you want any more info. please comment below
	</description>
	<comments>
		<comment id='1' author='neel04' date='2020-09-17T05:54:38Z'>
		&lt;denchmark-link:https://github.com/neel04&gt;@neel04&lt;/denchmark-link&gt;

Request you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='2' author='neel04' date='2020-09-17T16:15:47Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 I have attached the  file for all the code, however, the dataset can't be provided by me. You can open the file in Colab and inspect it with a random English dataset. (Or perhaps just make a file with a couple of words and it would do good enough for reproducibility)
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5240535/code.zip&gt;code.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='neel04' date='2020-09-19T15:06:15Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 Any help please? I have to finish this project quick...
		</comment>
		<comment id='4' author='neel04' date='2020-09-21T13:30:50Z'>
		&lt;denchmark-link:https://github.com/neel04&gt;@neel04&lt;/denchmark-link&gt;
 Are you using  for input data? Can you try adding  when batching it?
		</comment>
		<comment id='5' author='neel04' date='2020-09-22T14:05:11Z'>
		&lt;denchmark-link:https://github.com/yixingfu&gt;@yixingfu&lt;/denchmark-link&gt;
 I am changing my Input pipeline at the moment :) So will try with that. In the new one, I am indeed using . Lets see how that turns out
		</comment>
		<comment id='6' author='neel04' date='2020-09-22T18:09:31Z'>
		Hi &lt;denchmark-link:https://github.com/neel04&gt;@neel04&lt;/denchmark-link&gt;
 please provide a simple example dataset that reproduces the error. That will greatly help us to identify what is causing this issue. Thanks!
		</comment>
		<comment id='7' author='neel04' date='2020-09-25T18:11:34Z'>
		Tried by feeding numpy arrays directly in the model, but am getting this error:-
&lt;denchmark-code&gt;
ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    &lt;ipython-input-10-cab6225c487c&gt;:33 loss  *
        return tf.keras.losses.categorical_crossentropy(label, logits, from_logits=False)    #removed sparse
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy
        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with
        raise ValueError("Shapes %s and %s are incompatible" % (self, other))

    ValueError: Shapes (None, 1) and (None, 40, 500) are incompatible


&lt;/denchmark-code&gt;

Anyone know how to fix this?
		</comment>
		<comment id='8' author='neel04' date='2020-09-28T17:34:32Z'>
		Hi &lt;denchmark-link:https://github.com/neel04&gt;@neel04&lt;/denchmark-link&gt;
 it's difficult to diagnose this issue just from the stack trace you provided above. Please provide a simple example dataset + code that reproduces the error and we can better help to troubleshoot.
		</comment>
		<comment id='9' author='neel04' date='2020-10-05T18:11:35Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='10' author='neel04' date='2020-10-12T18:45:50Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='11' author='neel04' date='2020-10-12T18:45:53Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43276&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43276&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>