<bug id='37506' author='anilsathyan7' open_date='2020-03-11T10:04:41Z' closed_time='2020-03-20T05:03:44Z'>
	<summary>Tensorflow hexagon tflite benchmark fails with quantized mobilenetv2</summary>
	<description>

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
TensorFlow installed from (source or binary): Source
TensorFlow version:  Build from: git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git
Python version: 3.6.9
Bazel version (if compiling from source): 2.0.0
GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
Device: Redmi Note 7 Pro (Hexagon 685 DSP),  Android 10.0; MIUI 11

Describe the current behavior
When i try to run the official quantized mobilenet v2 model in tflite benchmark  using hexagon delegate, it fails with the following error:-

adb shell /data/local/tmp/benchmark_model_tf15 --graph=/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite --enable_op_profiling=true --use_hexagon=true
adb: /opt/intel/intelpython27/lib/libcrypto.so.1.0.0: no version information available (required by adb)
STARTING!
Min num runs: [50]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [1]
Benchmark name: []
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite]
Input layers: []
Input shapes: []
Input value ranges: []
Use legacy nnapi : [0]
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [1]
Max profiling buffer entries: [1024]
CSV File to export profiling data to: []
Use gpu : [0]
Allow lower precision in gpu : [1]
Use Hexagon : [1]
Hexagon lib path : [/data/local/tmp]
Hexagon Profiling : [0]
Use nnapi : [0]
Use xnnpack : [0]
Loaded model /data/local/tmp/mobilenet_v2_1.0_224_quant.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: 65 nodes delegated out of 65 nodes.

Timestamp: Wed Mar 11 12:45:53 2020
Log
hexagon/src/newnode.c:413:node 2 (Quantize_int32_ref): bad input count 12
hexagon/src/newnode.c:763:node id=0x2 ctor fail

ERROR: Failed: Failed to prepare graph.
. STATE: FAILED_TO_PREPARE_GRAPH
ERROR: Node number 65 (TfLiteHexagonDelegate) failed to prepare.
ERROR: Restored previous execution plan after delegate application failure.
Failed to apply Hexagon delegate.
Benchmarking failed.

All the '.so' files were initially copied to path: /data/local/tmp on device and the delegate was successfully created. I tried adding 'use_nnapi'= true along with use_hexagon option ; but it does not make any difference.
I followed the instruction to build the hexagon delegate and libraries from the official documentation

bazel build --config=android_arm64 
tensorflow/lite/experimental/delegates/hexagon/hexagon_nn:libhexagon_interface.so
adb push bazel-bin/tensorflow/lite/experimental/delegates/hexagon/hexagon_nn/libhexagon_interface.so /data/local/tmp
adb push libhexagon_nn_skel*.so /data/local/tmp
(32 bit version gave an error, so i used arm64)

Hexagon library: &lt;denchmark-link:https://storage.cloud.google.com/download.tensorflow.org/tflite/hexagon_nn_skel_v1.14.run&gt;v1.14&lt;/denchmark-link&gt;

Model:&lt;denchmark-link:https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz&gt; mobilenet_v2_1.0_224_quant&lt;/denchmark-link&gt;

Also does the hexagon model execute a tflite generated by post-training quantization(full INT8) ?
When  i tried another  custom quantized model(post-training quantization) with int8 inputs and outputs, it shows :  INFO: Hexagon delegate: 0 nodes delegated out of 158 nodes.  and seems to fall back to CPU.
Describe the expected behavior
The benchmark model should run the quantized model without any problems.
Other info / logs
Android NDK: 20, Benchmark tool built from latest source with bazel 2.0
Here are the two models that i have tried to benchmark and the corresponding benchmark library files:-
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4317362/hexfiles.zip&gt;hexfiles.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='anilsathyan7' date='2020-03-16T19:42:53Z'>
		Hi,
I just used your reproduce instructions and worked for me. I think you might have out of sync environment.
Can you please retry with a fresh setup (git clone, download the files and repush them and retry).
Thanks
		</comment>
		<comment id='2' author='anilsathyan7' date='2020-03-16T19:44:36Z'>
		For the post training quantized model (int8 version) as you saw from the message 0 nodes delegated.
We don't support them at the moment, but they are coming soon - work in progress. Stay tuned.
Thanks
		</comment>
		<comment id='3' author='anilsathyan7' date='2020-03-16T19:44:47Z'>
		Did it work on same phone ??
Can you post the complete result of benchmark ??
So does that mean INT8 or UINT8 models  for hexagon delegate only works for quantization aware models(doc mentions something like symmetric quantization)?
		</comment>
		<comment id='4' author='anilsathyan7' date='2020-03-16T19:54:28Z'>
		I don't have the exact same phone sadly, but from the error message you got it shouldn't matter. (Unless you have other failure not included here).
Did you retry ?
Currently we only support uint8 (quantization aware training), the int8 post training quantization is coming soon - It's already work in progress.
		</comment>
		<comment id='5' author='anilsathyan7' date='2020-03-16T20:00:51Z'>
		Can you run this command and tell me the value.
adb shell cat /sys/devices/soc0/soc_id
		</comment>
		<comment id='6' author='anilsathyan7' date='2020-03-16T20:03:16Z'>
		Ok thanks, i will try a fresh build in colab itself and shall post the results...
Unfortunately, i don't have the device right  now . I will get back to you tomorrow
		</comment>
		<comment id='7' author='anilsathyan7' date='2020-03-16T20:08:14Z'>
		Thanks.
getting the soc_id will help me getting as close to the same environment.
Thanks
		</comment>
		<comment id='8' author='anilsathyan7' date='2020-03-19T19:09:46Z'>
		Hey, it worked this time with hexagon delegate !!!
I made a fresh build of benchmark tool and hexagon and it worked without any error.
The command you mentioned gave me value: 355.
However the opencl gpu delegate failed with corresponding float version of  model gave error: segmentation fault. on the latest benchmark model binary.
adb shell /data/local/tmp/benchmark_model --graph=/data/local/tmp/mobilenet_v2_1.0_224.tflite --enable_op_profiling=true --use_gpu=true
I was hoping to compare the hexagon delegate performance with gpu ...
Anyway, it worked with my old benchmark tool binary:
The hexagon delegate took 5.2 ms while gpu took 21.49 seconds...It's impressive !!!
Thanks
		</comment>
		<comment id='9' author='anilsathyan7' date='2020-03-20T05:03:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37506&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37506&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='anilsathyan7' date='2020-03-20T05:08:02Z'>
		Thanks for the update. Also, note that executing on the DSP (Hexagon) consumes less power that's another gain :)
21ms looks a lot for OpenCL GPU.
Please file a new issue if you're still having problems.
Thanks
		</comment>
	</comments>
</bug>