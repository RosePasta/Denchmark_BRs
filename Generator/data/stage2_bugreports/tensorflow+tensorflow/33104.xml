<bug id='33104' author='PeterStrom' open_date='2019-10-07T09:06:03Z' closed_time='2019-11-14T17:06:03Z'>
	<summary>Prediction on batch values vary with batch size.</summary>
	<description>
When I predict on batches, e.g. with predict_on_batch(), I get different predictions depending on the batch size I am using. The differnce is sometimes as early as on the 4th digit. At first I thought it was due to batch normalization, but then I tried with pretrained VGG16 which I believe do not include batch normalization. This holds on all system settings I have tired:
Ubuntu and Windows
TF 1.1, 1.4 and 2.0
Pre-trained on Imagenet and trained from scratch Inception V3
Pre-trained on Imagenet VGG16 (code bellow)
predict_on_batch(), flow_from_directory(), and flow_from_dataframe()
Since it is constistent on all systems I guess it is not a bug but a known artefact of TF. I have Googled och searched the repository but not found out why this happens.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf

model = tf.keras.applications.VGG16(input_shape=(224, 224, 3),
                                    include_top=True,
                                    weights='imagenet')

path = "path_to_some_image"  # Use any image you got.
img = tf.keras.preprocessing.image.load_img(path, target_size=(224, 224))

batch_size = 32  # Changing this to, say, 3 gives different predictions.
batch_holder = np.zeros((batch_size, 224, 224, 3))
for i in range(batch_size):
    batch_holder[i] = img

predictions = model.predict_on_batch(batch_holder)
print(predictions[:, 0])
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='PeterStrom' date='2019-10-07T13:18:52Z'>
		In addition, there is inconsistency within a batch even if it is full. For example having a batch size of 31 with 31 identical images will give a different result on the last prediction in the batch. Or having a batch size of 31 with 32 identical images will give different results on the two last predictions. Here is some sample code to reproduce the error. I did this on windows with tf 1.11, but it is still there for 1.14 and 2.0 as well, like &lt;denchmark-link:https://github.com/PeterStrom&gt;@PeterStrom&lt;/denchmark-link&gt;
 pointed out.
import numpy as np
import tensorflow as tf
import shutil
import os

model = tf.keras.applications.VGG16(input_shape=(224, 224, 3),
                                    include_top=True,
                                    weights='imagenet')

path = "path_to_img"  # Use any image you got.

# Create file structure needed for flow_from_directory() and copy image many times.
tmp_dir = os.path.join(os.getcwd(),"tempdir")
tmp_sub_dir = os.path.join(tmp_dir,"subdir")

if not os.path.isdir(tmp_dir):
    os.mkdir(tmp_dir)
if not os.path.isdir(tmp_sub_dir):
    os.mkdir(tmp_sub_dir)

_, img_ext = os.path.splitext(path)

num_copies=31 #32
for i in range(num_copies):
    shutil.copyfile(path,os.path.join(tmp_sub_dir,"copy"+str(i)+img_ext))


# Predict using flow_from_directory and print result
image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

batch_size = 31
img_generator = image_data_generator.flow_from_directory(tmp_dir,target_size=(224,224),batch_size=batch_size)

predictions = model.predict_generator(img_generator,steps=len(img_generator.filenames)/batch_size)
print(predictions[:, 0])
#shutil.rmtree(tmp_sub_dir)
		</comment>
		<comment id='2' author='PeterStrom' date='2019-10-08T10:29:09Z'>
		Could reproduce it with TF Version 2.0. Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/78927f8c619a6e62beffd9e5697987ca/33104.ipynb&gt;Gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='PeterStrom' date='2019-10-24T17:18:13Z'>
		&lt;denchmark-link:https://github.com/PeterStrom&gt;@PeterStrom&lt;/denchmark-link&gt;
 I can reproduce the issue but the change is only in 13th digit. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/4f0e6a1dea8e3ba43d3d36462b98653f/untitled598.ipynb&gt;gist here&lt;/denchmark-link&gt;
. I have tried with different batch size also. Thanks!
		</comment>
		<comment id='4' author='PeterStrom' date='2019-10-24T23:18:14Z'>
		&lt;denchmark-link:https://github.com/eobw&gt;@eobw&lt;/denchmark-link&gt;
 Similarly, I can reproduce the issue but the change is only in 10th digit. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/b8f0239c589f923af5cb2f5685eb60d8/33104.ipynb&gt;gist here&lt;/denchmark-link&gt;
. I am trying to understand, are you looking for even higher precision? Thanks!
		</comment>
		<comment id='5' author='PeterStrom' date='2019-11-14T17:06:03Z'>
		I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='6' author='PeterStrom' date='2019-11-14T17:06:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33104&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33104&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>