<bug id='42818' author='aniketSanap' open_date='2020-08-31T08:42:24Z' closed_time='2020-08-31T11:36:44Z'>
	<summary>TF2: Cannot convert EfficientDet-d0 to saved_model/TFlite</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux - Arch but also getting same issues on colab


TensorFlow installed from (source or binary):
Binary - Conda


TensorFlow version (use command below):
2.2/2.3


Python version:
3.7


CUDA/cuDNN version:
Running on CPU



I trained an efficientdet-d0 from &lt;denchmark-link:http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz&gt;http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz&lt;/denchmark-link&gt;
 on a custom dataset using the object detection API. I am able to use the trained model for inference without an issue. I am able to export this model in the format saved_model.pb using &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py&lt;/denchmark-link&gt;
 but  am getting the following error when I try to load the saved model:
&lt;denchmark-code&gt;FailedPreconditionError:  Error while reading resource variable EfficientDet-D0/bifpn/node_15/2_up_lvl_5/combine/bifpn_combine_weights_81607 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/EfficientDet-D0/bifpn/node_15/2_up_lvl_5/combine/bifpn_combine_weights_81607/N10tensorflow3VarE does not exist.
	 [[{{node StatefulPartitionedCall/EfficientDet-D0/bifpn/node_15/2_up_lvl_5/combine/Relu/ReadVariableOp}}]] [Op:__inference_signature_wrapper_35854]

Function call stack:
signature_wrapper
&lt;/denchmark-code&gt;

The error changes even if I run the same code again but it remains a FailedPreconditionError.
I have also tried saving the model I use during inference using &lt;denchmark-link:https://www.tensorflow.org/guide/saved_model#saving_a_custom_model&gt;the official documentation&lt;/denchmark-link&gt;
 but that is also not working and giving me this error:
&lt;denchmark-code&gt;KeyError: "Failed to add concrete function b'__inference___call___31522' to object based saved model as it captures tensor tf.Tensor(&lt;unprintable&gt;, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable)."
&lt;/denchmark-code&gt;

Finally, I am also unable to convert this model to TFLite as outlined &lt;denchmark-link:https://www.tensorflow.org/lite/convert/python_api#converting_a_concrete_function_&gt;here&lt;/denchmark-link&gt;
 as I am getting this error when I try to make an interpreter using:
&lt;denchmark-code&gt;interpreter = tf.lite.Interpreter(model_path=TFLITE_OUTPUT_PATH)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;ValueError: Model provided has model identifier 'tent', should be 'TFL3'
&lt;/denchmark-code&gt;

I am also unable to use &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py&lt;/denchmark-link&gt;
 to export to tflite as it requires a .ckpt file whereas I only have ckpt.index and ckpt.data files. Any advice on how I can convert my model to tflite (with any sort of quantization/pruning) will be appreciated.
	</description>
	<comments>
		<comment id='1' author='aniketSanap' date='2020-08-31T09:50:39Z'>
		&lt;denchmark-link:https://github.com/aniketSanap&gt;@aniketSanap&lt;/denchmark-link&gt;

I tried in colab with TF nightly version and was able to convert the model to tflite model with some warning messages. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/c2832e117a14c172c75146275381a8fc/untitled282.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='aniketSanap' date='2020-08-31T11:23:21Z'>
		Thanks for the quick reply! Unfortunately your solution cannot work for me as I have not been able to save the model in the saved_model format due to the errors I talked about in my post. I tried using tf-nightly to save my model from a concrete_function like so:
&lt;denchmark-code&gt;# This works!
output = model(img_tensor)

@tf.function
def test(x):
  return model(x)

detect_fn = test.get_concrete_function(img_tensor)
converter = tf.lite.TFLiteConverter.from_concrete_functions([detect_fn])
tflite_model = converter.convert()

with tf.io.gfile.GFile(TFLITE_OUTPUT_PATH, 'wb') as f:
  f.write(tflite_model)

# This does not work
interpreter = tf.lite.Interpreter(model_path=TFLITE_OUTPUT_PATH)
&lt;/denchmark-code&gt;

When I try to load the saved tflite model then I get the error. I have been able to replicate this behavior on tf2.2/2.3 and tf-nightly
As mentioned previously, the error that I get is:
&lt;denchmark-code&gt;ValueError: Model provided has model identifier 'tent', should be 'TFL3'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='aniketSanap' date='2020-08-31T11:36:44Z'>
		Actually adding the flags in your gist I was able to convert the model to TFLite
Thanks!
		</comment>
		<comment id='4' author='aniketSanap' date='2020-08-31T11:36:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42818&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42818&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>