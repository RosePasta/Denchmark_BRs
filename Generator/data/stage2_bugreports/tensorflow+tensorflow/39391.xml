<bug id='39391' author='abdulsamadzahir' open_date='2020-05-11T00:41:09Z' closed_time='2020-05-11T19:31:36Z'>
	<summary>Calling model.load_weights() on model built with Sequential API throws ValueError error - TensorFlow Save and loading APIs Guide</summary>
	<description>
System information

Have I written custom code: No. Following a TF Guide and adding a line of code mentioned in its comments - no custom code/implemention.
OS Platform and Distribution: Code is running on Google Colab from Google Chrome (Version 81.0.4044.129 (Official Build) (64-bit))
TensorFlow installed from (source or binary): Binary - TF is running in Google Colab
TensorFlow version: 2.2.0-dev20200508 (tf.version.GIT_VERSION = v1.12.1-31489-g6047d50555)
Python version: 3.6.9
Bazel version: NA
GCC/Compiler version: NA
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior
I am running the &lt;denchmark-link:https://www.tensorflow.org/guide/keras/save_and_serialize&gt;Save and loading APIs Guide&lt;/denchmark-link&gt;
 by TensorFlow and came across an error that should not be raised as per the documentation provided in the same Notebook.
I was exploring the behavior of model.load_weights('pretrained_ckpt') &lt;denchmark-link:https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/keras/save_and_serialize.ipynb#scrollTo=Zdnpw_6PEsAN&gt;in this part of the guide&lt;/denchmark-link&gt;
. The code cell contains the following:
&lt;denchmark-code&gt;# Example 2: Sequential model
# Recreate the pretrained model, and load the saved weights.
inputs = keras.Input(shape=(784,), name='digits')
x = keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)
x = keras.layers.Dense(64, activation='relu', name='dense_2')(x)
pretrained_model = keras.Model(inputs=inputs, outputs=x, name='pretrained')

# Sequential example:
model = keras.Sequential(
    [pretrained_model, keras.layers.Dense(5, name='predictions')])
model.summary()

pretrained_model.load_weights('pretrained_ckpt')

# Warning! Calling `model.load_weights('pretrained_ckpt')` won't throw an error,
# but will *not* work as expected. If you inspect the weights, you'll see that
# none of the weights will have loaded. `pretrained_model.load_weights()` is the
# correct method to call.
&lt;/denchmark-code&gt;

The comment at the end states that,

# Warning! Calling `model.load_weights('pretrained_ckpt')` won't throw an error

However, if I add a new code cell right after the mentioned cell with the following line, it throws an error.
model.load_weights('pretrained_ckpt') 
The error is:
&lt;denchmark-code&gt;WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.engine.training.Model object at 0x7f4335f43ac8&gt; and &lt;tensorflow.python.keras.layers.core.Dense object at 0x7f4334612748&gt;).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-22-d50d92a829e2&gt; in &lt;module&gt;()
----&gt; 1 model.load_weights('pretrained_ckpt')

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)
   1126     """
   1127     if not self.is_compatible_with(other):
-&gt; 1128       raise ValueError("Shapes %s and %s are incompatible" % (self, other))
   1129 
   1130   def most_specific_compatible_shape(self, other):

ValueError: Shapes (5,) and (64,) are incompatible
&lt;/denchmark-code&gt;

Why is this happening? Has something changed recently causing this to break?
Describe the expected behavior
As the comment states, the function call must not throw an error and return a function to be used.

# Warning! Calling `model.load_weights('pretrained_ckpt')` won't throw an error


Please see the sample code provided in the notebook linked below to reproduce the issue:
&lt;denchmark-link:https://colab.research.google.com/drive/1-ilxHnd2gdqG8NvrJ2dvj0hO_d4_gV7u?usp=sharing&gt;Google Colab Notebook&lt;/denchmark-link&gt;

Other info / logs
NA
	</description>
	<comments>
		<comment id='1' author='abdulsamadzahir' date='2020-05-11T11:14:07Z'>
		&lt;denchmark-link:https://github.com/abdulsamadzahir&gt;@abdulsamadzahir&lt;/denchmark-link&gt;

I am able to replicate this issue, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/f56a3468e8d049b18f058683845e03a0/untitled178.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Can you please refer to these links and  let us know if it helps.
&lt;denchmark-link:https://stackoverflow.com/questions/49703387/tensorflow-valueerror-shapes-1-and-are-incompatible/50180397&gt;link&lt;/denchmark-link&gt;

&lt;denchmark-link:https://stackoverflow.com/questions/47482082/tensorflow-error-raise-valueerrorshapes-s-and-s-are-not-compatible-self&gt;link1&lt;/denchmark-link&gt;

&lt;denchmark-link:https://stackoverflow.com/questions/54871922/value-error-shapes-are-incompatible-tensorflow-tfrecord&gt;link2&lt;/denchmark-link&gt;

&lt;denchmark-link:https://forum.opennmt.net/t/valueerror-tensor-s-shape-is-not-compatible-with-supplied-shape/3297&gt;link3&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='abdulsamadzahir' date='2020-05-11T19:31:28Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

Thanks for the links. I went through them and I'm afraid I could not use them. However, scrutinizing the lines, I can see why calling the  method would fail. Below is a brief explanation.
model is built using Sequential API and is based on pretrained_model followed by Dense(5) layer.
pretrained_model: Input((784,)) -&gt; Dense(64) -&gt; Dense(64)
model: [pretrained_model, Dense(5)] = Input((784,)) -&gt; Dense(64) -&gt; Dense(64) -&gt; Dense(5)
However, the save_weights() method is called on pretrained model which has the following architecture:
pretrained: Input((784,)) -&gt; Dense(64) -&gt; Dense(64)
Since model and pretrained have different architectures (and the extra layer in model does have weights), calling load_weights() method on model will/should pretty much throw an error.
So, basically, changing this line
model = keras.Sequential([pretrained_model, keras.layers.Dense(5, name='predictions')])
to this
model = keras.Sequential([pretrained_model])
allows the code to run without an error (&lt;denchmark-link:https://colab.research.google.com/drive/1-ilxHnd2gdqG8NvrJ2dvj0hO_d4_gV7u?usp=sharing&amp;authuser=2#scrollTo=99j72ke4EP8t&gt;Google Colab Notebook&lt;/denchmark-link&gt;
).
According to the remaining part of the comment, calling model.load_weights('pretrained_ckpt') should not have left the weights unchanged. But they do change.

# Warning! Calling model.load_weights('pretrained_ckpt') won't throw an error,
# but will not work as expected. If you inspect the weights, you'll see that
# none of the weights will have loaded. pretrained_model.load_weights() is the
# correct method to call.

The following assertion test did not throw an error which indicated the weights in model were actually updated.
&lt;denchmark-code&gt;for a, b in zip(pretrained.weights, model.weights):
  np.testing.assert_allclose(a.numpy(), b.numpy())
&lt;/denchmark-code&gt;

(Why are we comparing model.weights against pretrained.weights? Because the weights were saved from pretrained model by calling pretrained.save_weights('pretrained_ckpt'))
After a bit of digging, I realized that model is inheriting its weights from pretrained_model when building the model calling Sequential([pretrained_model]). Since pretrained_model weights were pre-loaded a few lines earlier with a call to pretrained_model.load_weights('pretrained_ckpt'), model ends up having the same weights as pretrained model and the assertion above will not throw any errors.
To actually verify that the model.load_weights('pretrained_ckpt') fails to change the weights in model, simply comment out pretrained_model.load_weights('pretrained_ckpt') line and watch everything fall apart.
I guess it was a case of unclear documentation where the writer had a different idea in mind and the writing did not convey that.
Note to any future readers:
The variable names in this example are very confusing. We have pretrained, pretrained_model, and model variables which are variables of type Model which means we have pretrained model, pretrained_model model and, of course, model model. This makes the last paragraphs a tad confusing, but I've done my best to ensure the variable names are correct.
		</comment>
		<comment id='3' author='abdulsamadzahir' date='2020-05-11T19:31:37Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39391&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39391&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>