<bug id='28115' author='jjnaude' open_date='2019-04-24T17:40:36Z' closed_time='2020-09-11T04:02:29Z'>
	<summary>compute_output_shape may return incorrect results due to broken cache implementation</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Docker image tensorflow/tensorflow:1.12.0-gpu-py3 running under Host on Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
Docker image tensorflow/tensorflow:1.12.0-gpu-py3
TensorFlow version (use command below):
tensorflow-gpu      1.12.0
Python version:
3.5.2
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
9.0 / 7
GPU model and memory:
GTX 1080

Describe the current behavior
When called repeatedly, compute_output_shape may return incorrect results due to a faulty caching implementation in keras.Network
Describe the expected behavior
compute_output_shape should always return correct results

The issue is traced to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/d7cd03f1398cd33fc8579ce336b602350ac99259/tensorflow/python/keras/engine/network.py#L902&gt;this&lt;/denchmark-link&gt;
 line, where the function generic_utils.object_list_uid is used to generate a cache key. This function just generates a unique identifier for a tuple by taking the object ids of all the components, converting them to strings and concatenating. Firstly, this will not generate cache hits if the function is called twice with the same parameter values, because the object ids will not be the same even though their values are. Far more seriously though, it is possible for the function to sporadically generate  false hits, since object ids are only guaranteed to be unique for objects existing at the same time.
The bug is hidden when all dimensions are 256 or lower, because of the &lt;denchmark-link:https://docs.python.org/3.5/c-api/long.html&gt;special way&lt;/denchmark-link&gt;
 that Python treats integer objects between -5 and 256.
The code below causes this to happen reliably on my machine.
If the maintainers agree with my diagnosis, I'll happily provide a pull request to fix it. Personally I think the cache should just be removed as it won't save a significant amount of computation in any sane code and has unbounded memory requirements in broken code, but if there are good reasons to retain it we can just key on the values of the tuple components, rather than their object ids.
&lt;denchmark-code&gt;import tensorflow as tf

input = tf.keras.layers.Input(shape = [None,None,3])
output = tf.keras.layers.Conv2D(filters=1,kernel_size=[1,1])(input)
model = tf.keras.Model(inputs=input,outputs=output)
# The model consists of a single 1x1 convolution. Therefore the spatial extent of the output is always trivially equal to
# the spatial extent of the input.

# We must start from 257 because, when creating ints between -5 and 256 Python returns references to singletons.
# Therefore there is a one-to-one mapping between int value and object-id in this range and the cache works as
# intended. Outside this range, no such guarantee is possible and the cache fails.
for x in range(257,300):
    shape=model.compute_output_shape([[1,x,x,3]])
    assert (shape[1]==x)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jjnaude' date='2019-04-26T18:26:22Z'>
		I can reproduce the issue with TF1.12.0 and TF1.13.1
Here is the error log . Thanks!
&lt;denchmark-code&gt;257
258
259
260
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
&lt;ipython-input-2-ade9f8af85b4&gt; in &lt;module&gt;()
     13   print(x)
     14   shape=model.compute_output_shape([[1,x,x,3]])
---&gt; 15   assert (shape[1]==x)

AssertionError: 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='jjnaude' date='2019-06-06T20:06:48Z'>
		Are there any updates on this issue?
I am experiencing it on Windows with TF1.14.1 and it happens with even small number of well!
Example:
&lt;denchmark-code&gt;for x in range(300):
    print(x)
    shape=model.compute_output_shape([[1,x,x,3]])
    assert (shape[1]==x)
    
0
1
Traceback (most recent call last):
  File "C:\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py", line 2963, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "&lt;ipython-input-10-6b87c5a54df0&gt;", line 4, in &lt;module&gt;
    assert (shape[1]==x)
AssertionError

&lt;/denchmark-code&gt;

Every help would be highly appreciated! Thanks!
		</comment>
		<comment id='3' author='jjnaude' date='2020-09-02T04:17:30Z'>
		&lt;denchmark-link:https://github.com/jjnaude&gt;@jjnaude&lt;/denchmark-link&gt;
 I can reproduce the issue with TF1.x but I don't think there will be any code changes in TF1.x unless there is any security related updates.
I cannot reproduce the issue in recent . Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/50647092d6edb5cc729882d23c16c92f/untitled25.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='jjnaude' date='2020-09-09T05:16:24Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='jjnaude' date='2020-09-11T04:02:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28115&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28115&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>