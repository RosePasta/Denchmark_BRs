<bug id='33034' author='kazimuth' open_date='2019-10-03T22:05:54Z' closed_time='2019-10-10T01:05:57Z'>
	<summary>Per-operation random seeds don't work in tensorflow 2.0</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
TensorFlow installed from (source or binary): anaconda
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: Python 3.7.4

Describe the current behavior
Minimal test script:
import tensorflow as tf

x = tf.random.uniform([1], seed=1)
y = tf.random.uniform([1], seed=1)
print("x == y?", bool(tf.reduce_all(x == y)))
print(x)
print(y)
Output:
&lt;denchmark-code&gt;x == y? False
tf.Tensor([0.2390374], shape=(1,), dtype=float32)
tf.Tensor([0.22267115], shape=(1,), dtype=float32)
&lt;/denchmark-code&gt;

Describe the expected behavior
The script should print x == y? True.
According to the &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/set_random_seed&gt;docs&lt;/denchmark-link&gt;
 on :

If the graph-level seed is not set, but the operation seed is set: A default graph-level seed and the specified operation seed are used to determine the random sequence.

This does work correctly when not executing eagerly.
	</description>
	<comments>
		<comment id='1' author='kazimuth' date='2019-10-04T08:25:42Z'>
		&lt;denchmark-link:https://github.com/kazimuth&gt;@kazimuth&lt;/denchmark-link&gt;
,
I could replicate the issue with TF 2.0.0.rc2. Please see the colab &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/847114c631edb377542a001d0c6714e5/untitled174.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='kazimuth' date='2019-10-04T10:48:04Z'>
		&lt;denchmark-link:https://github.com/kazimuth&gt;@kazimuth&lt;/denchmark-link&gt;
,
Thank you for the details and the reference. I think the behavior is expected, as per &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/set_random_seed&gt;the point&lt;/denchmark-link&gt;
,

If the graph-level seed is not set, but the operation seed is set: A default graph-level seed and the specified operation seed are used to determine the random sequence.

It is because, in Eager Execution, there will not be Graph Level Seed, as there will be no graph at all. So, they will be two independent Random Tensor Operations.
Please let me know your opinion about the same. Thanks.
		</comment>
		<comment id='3' author='kazimuth' date='2019-10-04T19:38:01Z'>
		I mean, that makes sense, but it's not really intuitive; it seems like the implementation details are getting in the way of the expected interface. Ideally it would be possible to set global and per-operation seeds in eager mode, whether or not there's a graph in the background.
In particular, as far as I can tell I can't write code with reproducible randomness right now if I'm running in eager mode; that makes reproducing experiments and writing tests harder.
		</comment>
		<comment id='4' author='kazimuth' date='2019-10-08T23:57:20Z'>
		The behavior is caused by the facts that eager runtime caches and reuses a kernel for an op if the op is called multiple times with the same arguments, and that  is a stateful op. In the line , a  kernel is used and its internal state changed; in the line , the same kernel is used again but its internal state has been changed. The two  will only produce identical numbers in eager mode if you put  before each of them. The updated docstring for  (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/random_seed.py#L191&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/random_seed.py#L191&lt;/denchmark-link&gt;
) explains those caveats. Alternatively you can use stateless random ops (&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/random/stateless_uniform&gt;https://www.tensorflow.org/api_docs/python/tf/random/stateless_uniform&lt;/denchmark-link&gt;
) or the new stateful random ops (&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/random/experimental/Generator&gt;https://www.tensorflow.org/api_docs/python/tf/random/experimental/Generator&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='5' author='kazimuth' date='2019-10-10T01:05:57Z'>
		Ohh, I see, so this is intentional behavior. If I rerun my test script, I get the same tensors every run, good. Okay, in that case, this isn't a bug. Thanks for the clarification!
		</comment>
		<comment id='6' author='kazimuth' date='2019-10-10T01:05:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33034&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33034&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='kazimuth' date='2020-06-17T14:23:11Z'>
		In Tensorflow 2.0 you can set random seed like this :
&lt;denchmark-code&gt;import tensorflow as tf
tf.random.set_seed(221)


from tensorflow import keras
from tensorflow.keras import layers


model = keras.Sequential( [ 
layers.Dense(2,name = 'one'),
layers.Dense(3,activation = 'sigmoid', name = 'two'),
layers.Dense(2,name = 'three')])

x = tf.random.uniform((12,12))
model(x)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='kazimuth' date='2020-07-23T20:24:13Z'>
		
In Tensorflow 2.0 you can set random seed like this :
import tensorflow as tf
tf.random.set_seed(221)


from tensorflow import keras
from tensorflow.keras import layers


model = keras.Sequential( [ 
layers.Dense(2,name = 'one'),
layers.Dense(3,activation = 'sigmoid', name = 'two'),
layers.Dense(2,name = 'three')])

x = tf.random.uniform((12,12))
model(x)


Are you sure  "tf.random.set_seed(221)" works in Tensorflow 2.0? One of my systems has Tensorflow 2.0 and the deep learning there pipeline always returns a different result. The same code in Tensorflow 2.2 always returns the same result.
		</comment>
	</comments>
</bug>