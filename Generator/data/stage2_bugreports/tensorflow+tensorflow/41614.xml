<bug id='41614' author='sharathts' open_date='2020-07-21T22:44:31Z' closed_time='2020-07-25T00:55:55Z'>
	<summary>Training with Keras mixed precision policy crashes.</summary>
	<description>
&lt;denchmark-link:https://github.com/DEKHTIARJonathan&gt;@DEKHTIARJonathan&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/nluehr&gt;@nluehr&lt;/denchmark-link&gt;
 for visibility.
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No - Followed stock example to write a CTL


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME="Ubuntu"
VERSION="18.04.3 LTS (Bionic Beaver)"


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No


TensorFlow installed from (source or binary):
container built on tensorflow/tensorflow:nightly-gpu


TensorFlow version (use command below):
v1.12.1-37099-g3873154276 2.4.0-dev20200721


Python version:
Python 3.6.9


CUDA/cuDNN version:
Cuda compilation tools, release 10.1, V10.1.243


GPU model and memory:
V100 32G


Describe the current behavior
Using mixed precision training with keras mixed precision policy, seems like nodes aren't being casted to FP16
&lt;denchmark-code&gt;  File "run_tf_squad.py", line 615, in &lt;module&gt;
    main()
  File "run_tf_squad.py", line 343, in main
    model = TFElectraForQuestionAnswering.from_pretrained(electra_model, config=config, cache_dir=args.cache_dir, args=args)
  File "/workspace/electra/modeling_utils.py", line 406, in from_pretrained
    model(model.dummy_inputs, training=False)  # build the network with dummy inputs
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 986, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/workspace/electra/modeling.py", line 811, in call
    input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, training=training
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 986, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/workspace/electra/modeling.py", line 278, in call
    hidden_states = self.embeddings([input_ids, position_ids, token_type_ids, inputs_embeds], training=training)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 986, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/workspace/electra/modeling.py", line 82, in call
    return self._embedding(inputs, training=training)
  File "/workspace/electra/modeling.py", line 107, in _embedding
    embeddings = inputs_embeds + position_embeddings + token_type_embeddings
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py", line 1126, in binary_op_wrapper
    return func(x, y, name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py", line 201, in wrapper
    return target(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py", line 1448, in _add_dispatch
    return gen_math_ops.add_v2(x, y, name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py", line 487, in add_v2
    _ops.raise_from_not_ok_status(e, name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py", line 6886, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File "&lt;string&gt;", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute AddV2 as input #1(zero-based) was expected to be a half tensor but is a float tensor [Op:AddV2]
&lt;/denchmark-code&gt;

Describe the expected behavior
Mixed-precision training should start without any issues.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;1) git clone https://github.com/sharathts/electra.git
2) cd electra
3) bash scripts/docker/build.sh
4) bash scripts/docker/launch.sh
5) python run_tf_squad.py --init_checkpoint=None --do_train --train_batch_size=16    --data_dir /workspace/electra/data/download/squad/v1.1  --do_lower_case --electra_model=google/electra-base-discriminator  --learning_rate=4e-4  --warmup_proportion 0.05  --weight_decay_rate 0.01  --layerwise_lr_decay 0.8  --seed=1  --num_train_epochs=2  --max_seq_length=384  --doc_stride=128  --beam_size 4  --joint_head True  --null_score_diff_threshold -5.6  --output_dir=results/   --amp  --cache_dir=/workspace/electra/data/download/squad/v1.1  --max_steps=-1
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Traceback has been provided in the "Expected behaviour" section.
	</description>
	<comments>
		<comment id='1' author='sharathts' date='2020-07-22T04:49:40Z'>
		&lt;denchmark-link:https://github.com/sharathts&gt;@sharathts&lt;/denchmark-link&gt;

Can you please share simple indented stand alone code to replicate the issue faced or a colab gist to analyse.
I see some similar issues:
please refer to &lt;denchmark-link:https://stackoom.com/question/3tkBY/InvalidArgumentError-%E6%97%A0%E6%B3%95%E8%AE%A1%E7%AE%97Mul%E4%B8%BA%E8%BE%93%E5%85%A5-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B-%E5%BA%94%E8%AF%A5%E6%98%AFint-%E5%BC%A0%E9%87%8F-%E4%BD%86%E6%98%AF%E6%B5%AE%E7%82%B9%E5%BC%A0%E9%87%8F-Op-Mul-%E5%90%8D%E7%A7%B0-mul&gt;link&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://stackoverflow.com/questions/54255431/invalidargumenterror-cannot-compute-matmul-as-input-0zero-based-was-expected&gt;link1&lt;/denchmark-link&gt;

also the tf version used is not the later version, support is available from 1.15 and 2.x
		</comment>
		<comment id='2' author='sharathts' date='2020-07-22T22:04:04Z'>
		Stand alone file to repro the issue above
&lt;denchmark-code&gt;
## NOTE: If keras policy declaration is moved after model = TFElectraEmbeddings(), code doesn't crash, but seems to simply run in FP32

import tensorflow as tf
def get_initializer(initializer_range=0.02):
    """Creates a `tf.initializers.truncated_normal` with the given range.
    Args:
        initializer_range: float, initializer range for stddev.
    Returns:
        TruncatedNormal initializer with stddev = `initializer_range`.
    """
    return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)
def shape_list(x):
    """Deal with dynamic shape in tensorflow cleanly."""
    static = x.shape.as_list()
    dynamic = tf.shape(x)
    return [dynamic[i] if s is None else s for i, s in enumerate(static)]
class TFElectraEmbeddings(tf.keras.layers.Layer):
    """Construct the embeddings from word, position and token_type embeddings.
    """
    def __init__(self):
        super().__init__()
        self.vocab_size = 30522
        self.embedding_size = 768
        self.initializer_range = 0.02
        self.max_position_embeddings = 384
        self.type_vocab_size = 2
        self.position_embeddings = tf.keras.layers.Embedding(
            self.max_position_embeddings,
            self.embedding_size,
            embeddings_initializer=get_initializer(self.initializer_range),
            name="position_embeddings",
        )
        self.token_type_embeddings = tf.keras.layers.Embedding(
            self.type_vocab_size,
            self.embedding_size,
            embeddings_initializer=get_initializer(self.initializer_range),
            name="token_type_embeddings",
        )
        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load
        # any TensorFlow checkpoint file
        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=1e-6, name="LayerNorm")
        self.dropout = tf.keras.layers.Dropout(0.1)
    def build(self, input_shape):
        """Build shared word embedding layer """
        with tf.name_scope("word_embeddings"):
            # Create and initialize weights. The random normal initializer was chosen
            # arbitrarily, and works well.
            self.word_embeddings = self.add_weight(
                "weight",
                shape=[self.vocab_size, self.embedding_size],
                initializer=get_initializer(self.initializer_range),
            )
        super().build(input_shape)
    def call(self, inputs, mode="embedding", training=True):
        """Get token embeddings of inputs.
        Args:
            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)
            mode: string, a valid value is one of "embedding" and "linear".
        Returns:
            outputs: (1) If mode == "embedding", output embedding tensor, float32 with
                shape [batch_size, length, embedding_size]; (2) mode == "linear", output
                linear tensor, float32 with shape [batch_size, length, vocab_size].
        Raises:
            ValueError: if mode is not valid.
        Shared weights logic adapted from
            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24
        """
        if mode == "embedding":
            return self._embedding(inputs, training=training)
    def _embedding(self, inputs, training=False):
        """Applies embedding based on inputs tensor."""
        input_ids, position_ids, token_type_ids, inputs_embeds = inputs
        if input_ids is not None:
            input_shape = shape_list(input_ids)
        else:
            input_shape = shape_list(inputs_embeds)[:-1]
        seq_length = input_shape[1]
        if position_ids is None:
            position_ids = tf.range(seq_length, dtype=tf.int32)[tf.newaxis, :]
        if token_type_ids is None:
            token_type_ids = tf.fill(input_shape, 0)
        if inputs_embeds is None:
            inputs_embeds = tf.gather(self.word_embeddings, input_ids)
        position_embeddings = self.position_embeddings(position_ids)
        token_type_embeddings = self.token_type_embeddings(token_type_ids)
        embeddings = inputs_embeds + position_embeddings + token_type_embeddings
        embeddings = self.LayerNorm(embeddings)
        embeddings = self.dropout(embeddings, training=training)
        return embeddings
# TensorFlow configuration
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(gpu, True)
policy = tf.keras.mixed_precision.experimental.Policy("mixed_float16", loss_scale="dynamic")
tf.keras.mixed_precision.experimental.set_policy(policy)
model = TFElectraEmbeddings()
input_ids = tf.convert_to_tensor([[1,2,3,4,5], [1,2,3,4,5]])
position_ids = None
token_type_ids = tf.convert_to_tensor([[0,0,1,1,1], [0,0,1,1,1]])
input_embeds = None
inputs = [input_ids, position_ids, token_type_ids, input_embeds]
embeddings = model(inputs)
print(embeddings)
&lt;/denchmark-code&gt;

RE: also the tf version used is not the later version, support is available from 1.15 and 2.x
I build on top of master but the issue is visible in TF 2.2.
		</comment>
		<comment id='3' author='sharathts' date='2020-07-23T09:21:00Z'>
		&lt;denchmark-link:https://github.com/sharathts&gt;@sharathts&lt;/denchmark-link&gt;

Did you happen to check the links shared.
		</comment>
		<comment id='4' author='sharathts' date='2020-07-23T17:33:06Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 the links you shared seems to be a completely different issue.
See Google Collab: &lt;denchmark-link:https://colab.research.google.com/drive/14bfKOShVFEb1i4m3RE3SiCaJ2uG6e4cm?usp=sharing&gt;https://colab.research.google.com/drive/14bfKOShVFEb1i4m3RE3SiCaJ2uG6e4cm?usp=sharing&lt;/denchmark-link&gt;

It works perfectly without the Keras Policy (as shown in the Collab). However it fails with the mixed_precision precision. This is not an expected behavior.
&lt;denchmark-link:https://github.com/reedwm&gt;@reedwm&lt;/denchmark-link&gt;
 FYI
		</comment>
		<comment id='5' author='sharathts' date='2020-07-25T00:55:55Z'>
		Thank you for filing the issue! The issue is caused by the fact tf.keras.layers.Embedding outputs a float32 tensor when mixed precision is used. Normally mixed precision layers output float16 tensors, as they cast their floating-point inputs to float16, but Embedding does not take floating-point inputs. Normally this isn't an issue, as the layer that consumes Embedding's output will cast to float16. However in this case, you directly call the + operator on the embedding output instead of passing it to another layer:
&lt;denchmark-code&gt;embeddings = inputs_embeds + position_embeddings + token_type_embeddings
&lt;/denchmark-code&gt;

You can fix this by casting the embedding outputs to float16:
&lt;denchmark-code&gt;embeddings = inputs_embeds + tf.cast(position_embeddings, tf.float16) + tf.cast(token_type_embeddings, tf.float16)
&lt;/denchmark-code&gt;

Alternatively, you can create an Add layer in the constructor or build and call it, which will automatically cast inputs to float16.
I'm considering making mixed precision Embedding layers output float16 tensors, since this behavior is clearly confusing. On the other hand, I'm hesitant to make a special case for Embedding when the general rule is "inputs and variables are casted". I'll make a decision by the time of the design doc.
		</comment>
		<comment id='6' author='sharathts' date='2020-07-25T00:55:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41614&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41614&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='sharathts' date='2020-07-28T04:33:39Z'>
		This works. Thank you!
		</comment>
	</comments>
</bug>