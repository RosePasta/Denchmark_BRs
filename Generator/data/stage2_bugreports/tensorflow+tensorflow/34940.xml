<bug id='34940' author='CaptainTrojan' open_date='2019-12-08T10:06:20Z' closed_time='2019-12-13T23:44:13Z'>
	<summary>Autograph issues with TF documented examples</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow) No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux 5.4.2-arch1-1 x86_64
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.0.0
Python version: 3.8.0
Bazel version (if compiling from source): 1.1.0
GCC/Compiler version (if compiling from source): 9.2.0
CUDA/cuDNN version: 10.1.168-4 / 7.6.5.32-1
GPU model and memory: Nvidia GTX 1050 Ti, 4096 Mb
Exact command to reproduce:
import tensorflow as tf

tf.autograph.set_verbosity(10, alsologtostdout=True)
@tf.function
def square_if_positive(x):
if x &gt; 0:
x = x * x
else:
x = 0
return x
print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))
print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

"OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function." pops up anywhere I try to use a conditional, not just this example.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

2019-12-08 10:56:40.479540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2019-12-08 10:56:41.527181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2019-12-08 10:56:41.543972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.544502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.455GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
2019-12-08 10:56:41.544518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2019-12-08 10:56:41.545902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2019-12-08 10:56:41.547153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2019-12-08 10:56:41.547367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2019-12-08 10:56:41.548737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2019-12-08 10:56:41.549551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2019-12-08 10:56:41.552590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-12-08 10:56:41.552690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.553243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.553652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2019-12-08 10:56:41.554122: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
2019-12-08 10:56:41.573643: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 3101990000 Hz
2019-12-08 10:56:41.573908: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561688dfa0c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-12-08 10:56:41.573927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-12-08 10:56:41.574088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.574746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.455GHz coreCount: 6 deviceMemorySize: 3.94GiB deviceMemoryBandwidth: 104.43GiB/s
2019-12-08 10:56:41.574774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2019-12-08 10:56:41.574795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2019-12-08 10:56:41.574808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2019-12-08 10:56:41.574820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2019-12-08 10:56:41.574832: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2019-12-08 10:56:41.574844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2019-12-08 10:56:41.574857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2019-12-08 10:56:41.574913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.575579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:41.576106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2019-12-08 10:56:41.576137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2019-12-08 10:56:42.040932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-08 10:56:42.040956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2019-12-08 10:56:42.040967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2019-12-08 10:56:42.041100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:42.041410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:42.041696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-12-08 10:56:42.041971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3386 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2019-12-08 10:56:42.043375: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56169a227030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2019-12-08 10:56:42.043385: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
Converted call: &lt;function square_if_positive at 0x7f4849b981f0&gt;
args: (&lt;tf.Tensor 'x:0' shape=() dtype=int32&gt;,)
kwargs: {}
Entity &lt;function square_if_positive at 0x7f4849b981f0&gt; is not cached for subkey (&lt;tensorflow.python.autograph.core.converter.ConversionOptions object at 0x7f4810de6d00&gt;, frozenset())
Converting &lt;function square_if_positive at 0x7f4849b981f0&gt;
Source code of &lt;function square_if_positive at 0x7f4849b981f0&gt;:
@tf.function
def square_if_positive(x):
if x &gt; 0:
x = x * x
else:
x = 0
return x
Error transforming entity &lt;function square_if_positive at 0x7f4849b981f0&gt;
WARNING: AutoGraph could not transform &lt;function square_if_positive at 0x7f4849b981f0&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.
Cause: Bad argument number for keyword: 1, expecting 2
Caught error in &lt;function square_if_positive at 0x7f4849b981f0&gt; (converted=False)
Traceback (most recent call last):
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py", line 539, in converted_call
converted_f = conversion.convert(target_entity, program_ctx)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 358, in convert
converted_entity_info = convert_with_cache(entity, program_ctx,
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 273, in convert_with_cache
nodes, converted_name, entity_info = convert_entity_to_ast(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 506, in convert_entity_to_ast
nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 705, in convert_func_to_ast
node = node_to_graph(node, context)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 735, in node_to_graph
node = converter.apply(node, context, function_scopes)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py", line 399, in apply
node = converter_module.transform(node, context)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 132, in transform
return FunctionBodyTransformer(ctx).visit(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py", line 345, in visit
return super(Base, self).visit(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py", line 480, in visit
result = super(Base, self).visit(node)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 114, in visit_FunctionDef
wrapped_body = templates.replace(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 270, in replace
node = ReplaceTransformer(replacements).visit(node)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 436, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 445, in generic_visit
new_node = self.visit(old_value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 436, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 201, in visit_Name
new_nodes = self._prepare_replacement(node, node.id)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 140, in _prepare_replacement
new_nodes = ast_util.copy_clean(repl, preserve_annos=self.preserved_annos)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 76, in copy_clean
return CleanCopier(preserve_annos).copy(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 54, in copy
new_fields[f] = self.copy(getattr(node, f))
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 41, in copy
return [self.copy(n) for n in node]
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 41, in 
return [self.copy(n) for n in node]
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 55, in copy
new_node = type(node)(**new_fields)
File "/usr/lib/python3.8/site-packages/gast/gast.py", line 10, in create_node
assert nbparam in (0, len(Fields)), 
AssertionError: Bad argument number for keyword: 1, expecting 2
WARNING:tensorflow:AutoGraph could not transform &lt;function square_if_positive at 0x7f4849b981f0&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output.
Cause: Bad argument number for keyword: 1, expecting 2
Traceback (most recent call last):
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py", line 539, in converted_call
converted_f = conversion.convert(target_entity, program_ctx)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 358, in convert
converted_entity_info = convert_with_cache(entity, program_ctx,
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 273, in convert_with_cache
nodes, converted_name, entity_info = convert_entity_to_ast(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 506, in convert_entity_to_ast
nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 705, in convert_func_to_ast
node = node_to_graph(node, context)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py", line 735, in node_to_graph
node = converter.apply(node, context, function_scopes)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py", line 399, in apply
node = converter_module.transform(node, context)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 132, in transform
return FunctionBodyTransformer(ctx).visit(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py", line 345, in visit
return super(Base, self).visit(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py", line 480, in visit
result = super(Base, self).visit(node)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/converters/function_scopes.py", line 114, in visit_FunctionDef
wrapped_body = templates.replace(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 270, in replace
node = ReplaceTransformer(replacements).visit(node)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 436, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 445, in generic_visit
new_node = self.visit(old_value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/ast.py", line 436, in generic_visit
value = self.visit(value)
File "/usr/lib/python3.8/ast.py", line 360, in visit
return visitor(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 201, in visit_Name
new_nodes = self._prepare_replacement(node, node.id)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/templates.py", line 140, in _prepare_replacement
new_nodes = ast_util.copy_clean(repl, preserve_annos=self.preserved_annos)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 76, in copy_clean
return CleanCopier(preserve_annos).copy(node)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 54, in copy
new_fields[f] = self.copy(getattr(node, f))
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 41, in copy
return [self.copy(n) for n in node]
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 41, in 
return [self.copy(n) for n in node]
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/ast_util.py", line 55, in copy
new_node = type(node)(**new_fields)
File "/usr/lib/python3.8/site-packages/gast/gast.py", line 10, in create_node
assert nbparam in (0, len(Fields)), 
AssertionError: Bad argument number for keyword: 1, expecting 2
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py", line 344, in _call_unconverted
return f(*args, **kwargs)
File "/home/michal/Projects/RLtat/the-mayor/l2tf.py", line 8, in square_if_positive
if x &gt; 0:
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py", line 760, in bool
self._disallow_bool_casting()
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py", line 525, in _disallow_bool_casting
self._disallow_when_autograph_enabled(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py", line 511, in _disallow_when_autograph_enabled
raise errors.OperatorNotAllowedInGraphError(
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
Traceback (most recent call last):
File "/home/michal/Projects/RLtat/the-mayor/l2tf.py", line 15, in 
print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in call
result = self._call(*args, **kwds)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py", line 615, in _call
self._initialize(args, kwds, add_initializers_to=initializers)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py", line 496, in _initialize
self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py", line 2375, in _get_concrete_function_internal_garbage_collected
graph_function, _, _ = self._maybe_define_function(args, kwargs)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py", line 2706, in _maybe_define_function
graph_function = self._create_graph_function(args, kwargs)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py", line 2586, in _create_graph_function
func_graph_module.func_graph_from_py_func(
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
func_outputs = python_func(*func_args, **func_kwargs)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
return weak_wrapped_fn().wrapped(*args, **kwds)
File "/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py", line 968, in wrapper
raise e.ag_error_metadata.to_exception(e)
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in converted code:
&lt;denchmark-code&gt;/home/michal/Projects/RLtat/the-mayor/l2tf.py:8 square_if_positive
    if x &gt; 0:
/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py:760 __bool__
    self._disallow_bool_casting()
/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py:525 _disallow_bool_casting
    self._disallow_when_autograph_enabled(
/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py:511 _disallow_when_autograph_enabled
    raise errors.OperatorNotAllowedInGraphError(

OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='CaptainTrojan' date='2019-12-09T05:38:19Z'>
		I have tried on colab with TF version 2.0  and i am not seeing any issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/ca061375db9e18e0334d60db7ae204ba/untitled442.ipynb&gt;here.&lt;/denchmark-link&gt;
 Thanks!
		</comment>
		<comment id='2' author='CaptainTrojan' date='2019-12-09T06:18:28Z'>
		I think this might be an issue with Python 3.8, as the Colab runtime uses Python 3.6.9.
		</comment>
		<comment id='3' author='CaptainTrojan' date='2019-12-09T21:32:31Z'>
		I've downgraded to python 3.7.4, downloaded TF binaries and the code is working properly. Does TF 2.0 simply not support python 3.8?
		</comment>
		<comment id='4' author='CaptainTrojan' date='2019-12-10T08:55:25Z'>
		Downgrading to python 3.7.4 and building from source with the same config as above works as well. The issue will most likely be with python 3.8.0.
Used ./configure:
Please specify the location of python. [Default is /usr/bin/python]:
Found possible Python library paths:
/usr/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3.7/site-packages]
Do you wish to build TensorFlow with XLA JIT support? [Y/n]:
XLA JIT support will be enabled for TensorFlow.
Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]:
No OpenCL SYCL support will be enabled for TensorFlow.
Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.
Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.
Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.
Could not find any cuda.h matching version '' in any subdirectory:
''
'include'
'include/cuda'
'include/*-linux-gnu'
'extras/CUPTI/include'
'include/cuda/CUPTI'
of:
'/opt/cuda/extras/CUPTI/lib64'
'/opt/cuda/lib64'
'/opt/cuda/nvvm/lib64'
'/usr'
'/usr/lib'
'/usr/lib/libfakeroot'
'/usr/lib32'
Asking for detailed CUDA configuration...
Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10.1]:
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]:
Please specify the TensorRT version you want to use. [Leave empty to default to TensorRT 6]:
Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 2.5.6
Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /opt/cuda/lib64,/opt/cuda/bin,/opt/cuda/include,/usr/include,/usr/lib,/usr/bin,/opt/tensorrt/include,/opt/tensorrt/bin,/opt/tensorrt/lib,/opt/cuda
Found CUDA 10.1 in:
/opt/cuda/lib64
/opt/cuda/include
Found cuDNN 7 in:
/usr/lib
/usr/include
Found TensorRT 6 in:
/opt/tensorrt/lib
/opt/tensorrt/include
Found NCCL 2 in:
/usr/lib
/usr/include
Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: &lt;denchmark-link:https://developer.nvidia.com/cuda-gpus&gt;https://developer.nvidia.com/cuda-gpus&lt;/denchmark-link&gt;
.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities &gt;= 3.5 [Default is: 6.1]:
Do you want to use clang as CUDA compiler? [y/N]:
nvcc will be used as CUDA compiler.
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc-8]:
Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native -Wno-sign-compare]: --config=opt
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.
Preconfigured Bazel build configs. You can use any of the below by adding "--config=&lt;&gt;" to your build command. See .bazelrc for more details.
--config=mkl            # Build with MKL support.
--config=monolithic     # Config for mostly static monolithic build.
--config=ngraph         # Build with Intel nGraph support.
--config=numa           # Build with NUMA support.
--config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
--config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
--config=noaws          # Disable AWS S3 filesystem support.
--config=nogcp          # Disable GCP support.
--config=nohdfs         # Disable HDFS support.
--config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished
		</comment>
		<comment id='5' author='CaptainTrojan' date='2019-12-10T22:24:23Z'>
		We can expect python 3.8 support with TF 2.2
See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-562663993&gt;#33374 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='CaptainTrojan' date='2019-12-10T22:37:37Z'>
		There is a compatibility issue with 3.8 in autograph itself that will be resolved in 2.2 as well: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34433&gt;#34433&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='CaptainTrojan' date='2019-12-13T23:44:13Z'>
		Great, thanks for clarifying.
		</comment>
		<comment id='8' author='CaptainTrojan' date='2019-12-13T23:44:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34940&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34940&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>