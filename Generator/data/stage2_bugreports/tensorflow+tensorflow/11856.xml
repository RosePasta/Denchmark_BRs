<bug id='11856' author='chihuahua' open_date='2017-07-28T18:48:30Z' closed_time='2017-08-25T17:08:13Z'>
	<summary>tf.variables_initializer seems broken.</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04
TensorFlow installed from (source or binary): The nightly wheel.
TensorFlow version (use command below): The nightly build that went out at 2AM on 7/28/2017: https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/
Python version: 2.7.13
Bazel version (if compiling from source): 0.5.3
CUDA/cuDNN version: 8.0
GPU model and memory: GTX 1080
Exact command to reproduce:

To reproduce, run this snippet in the python interpreter:
&lt;denchmark-code&gt;import tensorflow as tf
with tf.Session() as sess:
  v = tf.Variable(42, dtype=tf.int32)
  with tf.control_dependencies([tf.variables_initializer([v])]):
    result = tf.assign(v, v + 1)
  print(sess.run(result))
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Running the snippet above yields an exception:
&lt;denchmark-code&gt;Caused by op u'Variable/read', defined at:
  File "&lt;stdin&gt;", line 2, in &lt;module&gt;
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py", line 199, in __init__
    expected_shape=expected_shape)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variables.py", line 330, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name="read")
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py", line 1408, in identity
    _result = _op_def_lib.apply_op("Identity", input=input, name=name)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 328, in apply_op
    op_type_name, name, **keywords)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2619, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1205, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

FailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_INT32, _class=["loc:@Variable"], _device="/job:localhost/replica:0/task:0/cpu:0"](Variable)]]
&lt;/denchmark-code&gt;

It seems like tf.variables_initializer is broken - it does not initialize the variables passed to it.
This has caused a TensorBoard test (:summary_test) to fail today (TensorBoard runs tests on nightly TensorFlow).
&lt;denchmark-link:https://travis-ci.org/tensorflow/tensorboard/jobs/258655621&gt;https://travis-ci.org/tensorflow/tensorboard/jobs/258655621&lt;/denchmark-link&gt;

The test had been passing yesterday (on nightly built on 7/27).
	</description>
	<comments>
		<comment id='1' author='chihuahua' date='2017-07-28T18:57:35Z'>
		It seems like indenting print(sess.run(result)) one to the right does away with the exception. Like this:
&lt;denchmark-code&gt;import tensorflow as tf
with tf.Session() as sess:
  v = tf.Variable(42, dtype=tf.int32)
  with tf.control_dependencies([tf.variables_initializer([v])]):
    result = tf.assign(v, v + 1)
    print(sess.run(result))
&lt;/denchmark-code&gt;

However, it doesn't seem like that was necessary yesterday. And it would be nice if that were not necessary (to save one level of indentation for most of the function).
		</comment>
		<comment id='2' author='chihuahua' date='2017-07-28T19:06:10Z'>
		Actually ... indeed, that won't work because mostly likely, I'm not running the session within a control dependency block.
		</comment>
		<comment id='3' author='chihuahua' date='2017-07-28T19:09:20Z'>
		This also fails on 1.2.1 version of TensorFlow. The reason is that "v+1" is relying on  node which is created outside of  block (created during tf.Variable construction in  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/faf7c32ab27dad24d2d806a16d1371ecb4671fc8/tensorflow/python/ops/variables.py#L330&gt;this line&lt;/denchmark-link&gt;
), and therefore doesn't have proper control dependency. The following makes it pass. cc &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;result = tf.assign(v, v.read_value() + 1)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='chihuahua' date='2017-07-28T19:34:42Z'>
		Also swapping the variables with resource variables (using
get_variable(..., use_resource=True) to construct the variables) makes this
issue go away.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Jul 28, 2017 at 12:11 PM, Yaroslav Bulatov ***@***.*** &gt; wrote:
 This also fails on 1.2.1 version of TensorFlow. Theory -- "v+1" is relying
 on Variable/read node which is created outside of tf.control_dependencies
 block, and therefore doesn't have proper control dependency. The following
 makes it pass. cc @alextp &lt;https://github.com/alextp&gt;

 result = tf.assign(v, v.read_value() + 1)

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#11856 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxTXVWhHcR4WVrlkj0HlefurKvgpMks5sSjJhgaJpZM4Om9Cy&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='5' author='chihuahua' date='2017-07-28T20:09:53Z'>
		I think I still want a  instead of a resource one because the test uses a  op here: &lt;denchmark-link:https://github.com/tensorflow/tensorboard/blob/02f97383951f57dacb462fb6335f461f32ac7141/tensorboard/plugins/pr_curve/summary.py#L162&gt;https://github.com/tensorflow/tensorboard/blob/02f97383951f57dacb462fb6335f461f32ac7141/tensorboard/plugins/pr_curve/summary.py#L162&lt;/denchmark-link&gt;

And the scatter add seems to err when passed resource variables:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/usr/home/agent007/.cache/bazel/_bazel_agent007/e5cf4ac2d3d80f539d85c4d9419a6bd7/bazel-sandbox/68
677344569147791/execroot/org_tensorflow_tensorboard/bazel-out/local-fastbuild/bin/tensorboard/plugins/pr_curve/summa
ry_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/summary_test.py", line 48, in test1Class
    num_thresholds=10)
  File "/usr/home/agent007/.cache/bazel/_bazel_agent007/e5cf4ac2d3d80f539d85c4d9419a6bd7/bazel-sandbox/68
677344569147791/execroot/org_tensorflow_tensorboard/bazel-out/local-fastbuild/bin/tensorboard/plugins/pr_curve/summa
ry_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/summary.py", line 165, in op
    tp_buckets_v, bucket_indices, true_labels, use_locking=True)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"
, line 212, in scatter_add
    name=name)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_libr
ary.py", line 328, in apply_op
    op_type_name, name, **keywords)
  File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_libr
ary.py", line 641, in _apply_op_helper
    "(e.g.: a tf.Variable)") % (op_type_name, input_name))
TypeError: 'ScatterAdd' Op requires that input 'ref' be a mutable tensor (e.g.: a tf.Variable)
&lt;/denchmark-code&gt;

Is there a way to include that Variable/read op in the control dependency list? Thank you!
		</comment>
		<comment id='6' author='chihuahua' date='2017-07-28T20:13:16Z'>
		There's a resource_scatter_add op which can be used instead.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Jul 28, 2017 at 1:11 PM, Chi Zeng ***@***.***&gt; wrote:
 I think I still want to use a tf.Variable instead of a resource one
 because the test uses a ScatterAdd op here: https://github.com/tensorflow/
 tensorboard/blob/02f97383951f57dacb462fb6335f461f32ac7141/tensorboard/
 plugins/pr_curve/summary.py#L162

 And the scatter add seems to err when passed resource variables:

 Traceback (most recent call last):
   File "/usr/home/agent007/.cache/bazel/_bazel_agent007/e5cf4ac2d3d80f539d85c4d9419a6bd7/bazel-sandbox/68
 677344569147791/execroot/org_tensorflow_tensorboard/bazel-out/local-fastbuild/bin/tensorboard/plugins/pr_curve/summa
 ry_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/summary_test.py", line 48, in test1Class
     num_thresholds=10)
   File "/usr/home/agent007/.cache/bazel/_bazel_agent007/e5cf4ac2d3d80f539d85c4d9419a6bd7/bazel-sandbox/68
 677344569147791/execroot/org_tensorflow_tensorboard/bazel-out/local-fastbuild/bin/tensorboard/plugins/pr_curve/summa
 ry_test.runfiles/org_tensorflow_tensorboard/tensorboard/plugins/pr_curve/summary.py", line 165, in op
     tp_buckets_v, bucket_indices, true_labels, use_locking=True)
   File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"
 , line 212, in scatter_add
     name=name)
   File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_libr
 ary.py", line 328, in apply_op
     op_type_name, name, **keywords)
   File "/usr/home/agent007/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_libr
 ary.py", line 641, in _apply_op_helper
     "(e.g.: a tf.Variable)") % (op_type_name, input_name))
 TypeError: 'ScatterAdd' Op requires that input 'ref' be a mutable tensor (e.g.: a tf.Variable)

 Is there a way to include that Variable/read op in the control dependency
 list? Thank you!

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#11856 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxaWsTbZ1nJ27MWGHaXpFmphdCPM8ks5sSkB-gaJpZM4Om9Cy&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='7' author='chihuahua' date='2017-07-28T20:20:45Z'>
		It seems like resource_scatter_add is only supported internally for now? I don't see it in the tf. namespace, and the test is open-source.
		</comment>
		<comment id='8' author='chihuahua' date='2017-07-30T01:24:22Z'>
		I want to spend some time to fix this and move the read node into the dependency chain. Could someone please give me some guidance?
My alternative would be to rewrite a project to avoid scatter_add. That is a relatively big task. Furthermore, after a variable is "initialized", it seems reasonable for a user to assume that they can read from and update the variable.
		</comment>
		<comment id='9' author='chihuahua' date='2017-07-30T16:10:12Z'>
		&lt;denchmark-link:https://github.com/chihuahua&gt;@chihuahua&lt;/denchmark-link&gt;
 replacing the line with  will refer to the proper read node.
The issue is that the tensor is retrieved from  in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/faf7c32ab27dad24d2d806a16d1371ecb4671fc8/tensorflow/python/ops/variables.py#L367&gt;AsTensor&lt;/denchmark-link&gt;
 which is initialized during variable construction. For a more sweeping fix one might modify  to check whether you are inside any active context managers for control dependencies, and if so, create a new read node  rather than referring to the snapshot. That might get complicated (ie, what if someone is inside control dependency context referring to variable in a long loop? That explodes the graph)
		</comment>
		<comment id='10' author='chihuahua' date='2017-07-31T16:00:29Z'>
		I think it should be safe to always call read_value when you reference the
variable. Indeed I do this in resource variables which do not have this bug
and for which a scatter_add operation exists (resource_scatter_add). I do
not understand what's the remaining issue here.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sun, Jul 30, 2017 at 9:12 AM, Yaroslav Bulatov ***@***.***&gt; wrote:
 @chihuahua &lt;https://github.com/chihuahua&gt; replacing the line with tf.assign(v,
 v.read_value() + 1) will refer to the proper read node.

 The issue is that the tensor is retrieved from _snapshot in AsTensor
 &lt;https://github.com/tensorflow/tensorflow/blob/faf7c32ab27dad24d2d806a16d1371ecb4671fc8/tensorflow/python/ops/variables.py#L367&gt;
 which is initialized during variable construction. One might modify
 AsTensor to check whether you are inside any active context managers for
 control dependencies, and if so, create a new read node read_value rather
 than referring to the snapshot. That might get complicated (ie, what if
 someone is inside control dependency context referring to variable in a
 long loop? That explodes the graph)

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub
 &lt;#11856 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxf0HNbhFj4pMoZpNRxDLTJTDa_Kzks5sTKtjgaJpZM4Om9Cy&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='11' author='chihuahua' date='2017-07-31T16:15:16Z'>
		Does calling read_value append to the graph/invalidate graph cache?
		</comment>
		<comment id='12' author='chihuahua' date='2017-07-31T16:19:41Z'>
		Yes
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Jul 31, 2017 at 9:17 AM, Yaroslav Bulatov ***@***.***&gt; wrote:
 Does calling read_value append to the graph/invalidate graph cache?

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub
 &lt;#11856 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxRDSm3qNOfY-VGyhQLf5WjUQbiYYks5sTf4ygaJpZM4Om9Cy&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='13' author='chihuahua' date='2017-08-07T21:30:43Z'>
		Is this issue solved / irrelevant?
		</comment>
		<comment id='14' author='chihuahua' date='2017-08-07T21:40:23Z'>
		&lt;denchmark-link:https://github.com/chihuahua&gt;@chihuahua&lt;/denchmark-link&gt;
 IMHO this is a counter-intuitive property of graph-based system rather than a bug --
you always need to create a new graph node if you want constraints enforced by surrounding context managers to be enforced.
In your case,v reuses previously created graph node which doesn't know about your desired execution order, whereas  v.read_value() will create a new node which respects the control dependency
		</comment>
		<comment id='15' author='chihuahua' date='2017-08-08T19:08:06Z'>
		SGTM. Thank you!
I think it might be worth clarifying this in the tf.variable_initializer docs. Otherwise, it might be a bit unclear to some folks to use v.read_value.
And indeed, I have worked around this issue by avoiding scatter_add entirely.
		</comment>
	</comments>
</bug>