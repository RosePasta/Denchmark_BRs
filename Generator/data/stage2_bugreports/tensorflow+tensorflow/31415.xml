<bug id='31415' author='Uiuran' open_date='2019-08-07T14:50:02Z' closed_time='2020-02-19T07:03:13Z'>
	<summary>tools.graph_transforms.TransformGraph has no docs or example of usage</summary>
	<description>
Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.
The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs&gt;https://www.tensorflow.org/community/contribute/docs&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;

the provided wrapper function has no docs
&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

provide a docs such
examples of usage:
TransformGraph( graph.as_graph_def(), [], [], ['remove_nodes(op=loss/init)']) ...
&lt;denchmark-h:h3&gt;Clear description&lt;/denchmark-h&gt;

I wanna to use this method has a way to do specifics editions and graph redefinitions while building the model, from inside python, withou having to go to command line.
&lt;denchmark-h:h3&gt;Parameters defined&lt;/denchmark-h&gt;

I think how to use the parameters are exactly the problem, the README.md from the repository gives bazel example, but it dosnt work as it should in the wrapper
&lt;denchmark-h:h3&gt;Usage example&lt;/denchmark-h&gt;

this is my first try, i could not get the desirable result (strip init op from graph):
graph = tf.Graph()
with graph.as_default():

  with tf.variable_scope('signal_in'):
    signal_in = tf.placeholder(tf.float32, shape=(10,40,2,1))

  with tf.variable_scope('dascope1'):
    conv_linear = tf.keras.layers.Conv2D( 8, (8,2), padding='valid', name='conv_linear', use_bias=True, kernel_initializer=tf.initializers.lecun_normal(seed=137), bias_initializer=tf.initializers.lecun_normal(seed=137) )(signal_in)
  
  with tf.variable_scope('softmax'):
    logits = tf.contrib.layers.fully_connected(conv_linear, 2, activation_fn=None, normalizer_fn=None, normalizer_params=None, weights_initializer=tf.initializers.lecun_normal(seed=731), weights_regularizer=None, biases_initializer=tf.initializers.lecun_normal(seed=777), biases_regularizer=None, reuse=None, variables_collections=None, outputs_collections=None, trainable=True, scope='logit')
    softmax = tf.nn.softmax(logits,axis=0)            
    
  with tf.variable_scope('loss'):
    l_vec = tf.placeholder(tf.float32, shape=(10,2))
    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0)(l_vec, softmax)         
    minimize_op = tf.train.AdamOptimizer(learning_rate=0.05).minimize(loss)
    tf.global_variables_initializer()
then:
graphdef = tf.tools.graph_transforms.TransformGraph( graph.as_graph_def(), [], [], ['remove_nodes(op=loss/init)'])

with tf.Graph().as_default() as g:  
  tf.import_graph_def(graphdef,name = '')
  for op in g.get_operations():
    if op.name.split('/')[-1] == 'init':
      print('True')
returns True
So how to use this wrapper ? note that init op dosnt have any input output but only dependency arrows as input.
&lt;denchmark-h:h3&gt;Request visuals, if applicable&lt;/denchmark-h&gt;

Are there currently visuals? If not, will it clarify the content?
&lt;denchmark-h:h3&gt;Submit a pull request?&lt;/denchmark-h&gt;

Waiting for instructions of the community about the use of this function.
Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs&gt;https://www.tensorflow.org/community/contribute/docs&lt;/denchmark-link&gt;
 and the
docs style guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_style&gt;https://www.tensorflow.org/community/contribute/docs_style&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='Uiuran' date='2019-08-12T22:13:48Z'>
		Please fill the issue &lt;denchmark-link:https://github.com/keras-team/keras/issues/new?template=a--tensorflow-backend-users.md&gt;template&lt;/denchmark-link&gt;
. Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='Uiuran' date='2020-02-19T07:03:10Z'>
		&lt;denchmark-link:https://github.com/Uiuran&gt;@Uiuran&lt;/denchmark-link&gt;
 Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='3' author='Uiuran' date='2020-02-19T17:17:02Z'>
		There's an extensive "readme" in the source directory:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms&lt;/denchmark-link&gt;

But we can't add this to tensorflow.org as it is not considered an implementation detail and not part of the public API.
		</comment>
	</comments>
</bug>