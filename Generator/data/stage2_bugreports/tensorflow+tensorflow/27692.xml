<bug id='27692' author='markste-in' open_date='2019-04-09T18:15:00Z' closed_time='2019-05-26T20:21:41Z'>
	<summary>Converting Tensor to Numpy array extremely slow in TF 2.0</summary>
	<description>
Current Issue / Bug Report
I tried to convert a list of tensors to a numpy array.
This was no issue in Tensorflow 1.13.x but is now orders of magnitudes slower in Tensorflow 2.0.0-dev20190405
I linked a piece of code to reproduce the issue in Colab (no HW acceleration required) and to also show the difference in execution time between 1.13.x and 2.0.0/nightly
I tested the issue with
np.array(LIST_OF_TENSORS)
np.shape(LIST_OF_TENSORS)
System information
Colab w.o. HW acceleration and TF 2.0.0-dev20190405

&lt;denchmark-link:https://github.com/markste-in/colab/blob/master/bug_tensor_numpy.ipynb&gt;Code Example&lt;/denchmark-link&gt;

.
	</description>
	<comments>
		<comment id='1' author='markste-in' date='2019-04-18T21:43:46Z'>
		Wow, this is really bad. Thanks for bringing it up!
		</comment>
		<comment id='2' author='markste-in' date='2019-04-18T21:51:49Z'>
		The underlying issue, after running your repro through a profiler, seems to be that Tensor's array conversion is done through slicing instead of the fastpath.
		</comment>
		<comment id='3' author='markste-in' date='2019-04-18T21:54:06Z'>
		Interestingly, if you do np.array(tensor) there's no slowdown, it's only if you do np.array(list_of_tensors).
		</comment>
		<comment id='4' author='markste-in' date='2019-04-18T21:56:15Z'>
		&lt;denchmark-link:https://github.com/superbobry&gt;@superbobry&lt;/denchmark-link&gt;
 do you have any idea why converting a tensor to an ndarray goes through  and is fast while converting a list of tensors goes through  and is slow?
		</comment>
		<comment id='5' author='markste-in' date='2019-04-20T08:24:56Z'>
		Not sure, will have a look at &lt;denchmark-link:https://github.com/numpy/numpy/blob/15b092f5541e80d7c3d0108957406c6f8686aba0/numpy/core/src/multiarray/ctors.c#L1793&gt;PyArray_FromAny&lt;/denchmark-link&gt;
.
Also, here's a smaller reproducer:
t = tf.random.uniform([256])
%timeit np.array(t)
%timeit np.array([t])
100000 loops, best of 3: 5.21 Âµs per loop
10 loops, best of 3: 22.1 ms per loop
: I think this is happening because an  is a  (, ) so  is no different from the nested list case. Recursive copying logic is implemented in &lt;denchmark-link:https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/ctors.c#L435&gt;setArrayFromSequence&lt;/denchmark-link&gt;
. There is a &lt;denchmark-link:https://github.com/numpy/numpy/blob/master/numpy/core/src/multiarray/ctors.c#L453&gt;branch&lt;/denchmark-link&gt;
 special-casing ndarrays but any other object (including ) is copied via the  protocol.
The remaining question is why does the same code path work for 1.X.
Update 2: Actually, the reason it's fast in 1.X is because Tensor is not a Sequence so setArrayFromSequence does not recurse.
: The remaining bit is where does  come from in the profiler output. The answer is: &lt;denchmark-link:https://github.com/python/cpython/blob/a24107b04c1277e3c1105f98aff5bfa3a98b33a0/Objects/abstract.c#L1940&gt;PySequence_Fast&lt;/denchmark-link&gt;
 which (in the above example) converts a single-element tensor to a single-element list.
		</comment>
		<comment id='6' author='markste-in' date='2019-04-23T10:05:56Z'>
		I'll see if it's easy to generalize  to arbitrarily nested sequence of array-like objects. Sidenote: could we also be triggering &lt;denchmark-link:https://github.com/numpy/numpy/issues/8562&gt;numpy/numpy#8562&lt;/denchmark-link&gt;
?
In the meantime, I wonder if there is a way to detect np.array([t, t, t...]) calls and error or emit or warning?
		</comment>
		<comment id='7' author='markste-in' date='2019-04-23T17:51:55Z'>
		There seem to be two distinct issues:

PyArray_FromAny copies its argument to a list when it does not implement __array_interface__, that is exactly numpy/numpy#8562 and it does affect Tensor which only implements __array__.
setArrayFromSequence ignores __array_*__ and __array__ and copies its argument (again!) unless it's an array (or an array subtype).

I have sketched a fix for both issues. Will post an update once I do more testing.
		</comment>
		<comment id='8' author='markste-in' date='2019-04-25T10:36:58Z'>
		You can wrap each item in the list with np.array() first then wrap the whole list once again with np.array(). I know it does not looks good, but at least it works for now.
		</comment>
		<comment id='9' author='markste-in' date='2019-05-26T20:21:41Z'>
		The TF side of the fix has been merged. Closing the issue as the remaining part is on the NumPy side.
Note that  will continue to be slow until a new NumPy version is released with &lt;denchmark-link:https://github.com/numpy/numpy/pull/13399&gt;numpy/numpy#13399&lt;/denchmark-link&gt;
 incorporated.
		</comment>
		<comment id='10' author='markste-in' date='2019-05-26T20:21:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27692&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27692&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>