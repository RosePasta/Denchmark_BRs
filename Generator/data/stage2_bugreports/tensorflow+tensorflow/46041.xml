<bug id='46041' author='anavanab99' open_date='2020-12-29T13:47:35Z' closed_time='2021-01-13T09:48:32Z'>
	<summary>keras can't save model when useing featurecolumns embding</summary>
	<description>
`# -- coding: utf-8 --
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense
from tensorflow.keras import Input, Model
from tensorflow.keras import regularizers
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from tensorflow.keras.layers import TimeDistributed
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau, LearningRateScheduler
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import Input, Dense, Multiply
from tensorflow.keras.layers import DenseFeatures
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import *
import numpy as np
import os
&lt;denchmark-h:h1&gt;模型细节有关的设置&lt;/denchmark-h&gt;

dnn_activation = 'tanh'
dropout_rate = 0.5
dnn_l1 = 0.01
dnn_l2 = 0.01
data_use_num = 1
data_2pre_num = 1
pred_label = 'pred_d'
weights_path = 'model_dir/jarvis_super'
batch_size = 1
lr = 0.01
use_feature_columns = True
def lrs(epoch):
if epoch &lt; 5:
learning_rate = lr
elif epoch &lt; 10:
learning_rate = lr / 3
elif epoch &lt; 20:
learning_rate = lr / 10
else:
learning_rate = lr / 100
print('learning rate : {}'.format(learning_rate))
return learning_rate
def get_model(shape_deep, shape_times, pred_num):
##############################################################
if use_feature_columns:
&lt;denchmark-code&gt;    feature_columns, feature_layer_inputs = feature_columns_list(
        numeric_column_list=['30day_press_dnn', '60day_press_dnn', '5day_press', ], buckets_column_list=[])

    feature_columns2, feature_layer_inputs2 = feature_columns_list(
        numeric_column_list=['30day_press', '60day_press', ], buckets_column_list=[])

    feature_layer = DenseFeatures(feature_columns)
    input_deep = feature_layer(feature_layer_inputs)
    ##############################################################
    ###############input_layer
    feature_layer = DenseFeatures(feature_columns2)
    input_times = feature_layer(feature_layer_inputs2)

else:
    input_deep = tf.keras.Input(shape=(3), name='input_deep_list')
    input_times = tf.keras.Input(shape=(2), name='input_times_list')

dnn1 = (keras.layers.Dense(units=500, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                           activity_regularizer=regularizers.l1(dnn_l1))(input_deep))
# dnn1 = keras.layers.LayerNormalization(axis=1)(dnn1)
dnn1 = tf.keras.layers.Dropout(dropout_rate)(dnn1)

#######################
dnn2 = (keras.layers.Dense(units=400, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                           activity_regularizer=regularizers.l1(dnn_l1))(dnn1))
# dnn2 = keras.layers.LayerNormalization(axis=1)(dnn2)
dnn2 = tf.keras.layers.Dropout(dropout_rate)(dnn2)

###############################
dnn3 = (keras.layers.Dense(units=200, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                           activity_regularizer=regularizers.l1(dnn_l1))(dnn2))
concat = (keras.layers.concatenate([input_deep, dnn3]))
# dnn3 = keras.layers.BatchNormalization(axis=1)(concat)
dnn3 = tf.keras.layers.Dropout(dropout_rate)(concat)

###########################################
dnn4 = (keras.layers.Dense(units=150, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                           activity_regularizer=regularizers.l1(dnn_l1), name='dnn4')(dnn3))

################时间变量结构

attention_probs_time = (keras.layers.Dense(units=input_deep.shape[1], activation='softmax', )(input_times))
dnn_time1 = Multiply()([input_deep, attention_probs_time])

dnn_time1 = (keras.layers.Dense(units=500, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                                activity_regularizer=regularizers.l1(dnn_l1))(dnn_time1))
# dnn_time1 = keras.layers.LayerNormalization(axis=1)(dnn_time1)
dnn_time1 = tf.keras.layers.Dropout(dropout_rate)(dnn_time1)

#######################
dnn_time2 = (keras.layers.Dense(units=400, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                                activity_regularizer=regularizers.l1(dnn_l1))(dnn_time1))
# dnn_time2 = keras.layers.LayerNormalization(axis=1)(dnn_time2)
dnn_time2 = tf.keras.layers.Dropout(dropout_rate)(dnn_time2)

###############################
dnn_time3 = (keras.layers.Dense(units=200, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                                activity_regularizer=regularizers.l1(dnn_l1))(dnn_time2))
concat = (keras.layers.concatenate([input_deep, dnn_time3]))
# dnn_time3 = keras.layers.LayerNormalization(axis=1)(concat)
dnn_time3 = tf.keras.layers.Dropout(dropout_rate)(concat)

###########################################
# tf.keras.layers.SpatialDropout3D(
dnn_time4 = (keras.layers.Dense(units=150, activation=dnn_activation, kernel_regularizer=regularizers.l2(dnn_l2),
                                activity_regularizer=regularizers.l1(dnn_l1))(dnn_time3))

############################################
finall_concat = keras.layers.concatenate([dnn4, dnn_time4])

x = Dense(128, activation="relu")(finall_concat)
x = BatchNormalization()(x)

outputs = Dense(1, name='outputs')(x)

input_deep_list = []
if use_feature_columns:
    for v in feature_layer_inputs.values():
        print(v)
        input_deep_list.append(v)

    input_times_list = []
    for v in feature_layer_inputs2.values():
        input_times_list.append(v)
    print(input_deep_list, input_times_list)
else:
    input_times_list = input_times
    input_deep_list = input_deep
model = Model(inputs=[input_deep_list, input_times_list], outputs=outputs)
return model
&lt;/denchmark-code&gt;

def feature_columns_list(numeric_column_list, buckets_column_list):
feature_columns = []
feature_layer_inputs = {}
&lt;denchmark-code&gt;for header in numeric_column_list:
    print(header)
    day_press=tf.feature_column.numeric_column(header)
    day_press_buket = tf.feature_column.bucketized_column(day_press, [1,100,1000])#这里因为没有嵌入dnn 所已要去掉
    day_press_emb = tf.feature_column.embedding_column(categorical_column=day_press_buket,dimension=8)
    feature_columns.append(day_press_emb)

    feature_layer_inputs[header] = tf.keras.Input(shape=(1,), name=header)  ######所有单个的都用这个

return feature_columns, feature_layer_inputs
&lt;/denchmark-code&gt;

def feature_columns_list2(numeric_column_list, buckets_column_list):
feature_columns = []
feature_layer_inputs = {}
&lt;denchmark-code&gt;for header in numeric_column_list:
    print(header)
    numeric_column = tf.feature_column.numeric_column(header)
    feature_columns.append(numeric_column)
    feature_layer_inputs[header] = tf.keras.Input(shape=(1,), name=(header + 'time'))  ######所有单个的都用这个
return feature_columns, feature_layer_inputs
&lt;/denchmark-code&gt;

df1 = np.random.random((100, 3))
df2 = np.random.random((100, 2))
y_train = np.random.random((100, 1))
list1 = ['30day_press_dnn', '60day_press_dnn',  '5day_press', ]
list2 = ['30day_press', '60day_press', ]
df1 = pd.DataFrame(df1, columns=list1)
df2 = pd.DataFrame(df2, columns=list2)
y_train = pd.DataFrame(y_train, columns=['pred'])
dataset1 = tf.data.Dataset.from_tensor_slices((dict(df1), dict(df2)))
dataset2 = tf.data.Dataset.from_tensor_slices(y_train)
train_dataset = tf.data.Dataset.zip((dataset1, dataset2))
train_dataset = train_dataset.batch(96, drop_remainder=True)
if name == 'main':
model = get_model(shape_deep=(1,), shape_times=(1,), pred_num=1)
# model.summary()
&lt;denchmark-code&gt;plateau = LearningRateScheduler(lrs)

checkpoint = ModelCheckpoint(weights_path,
                             monitor='val_loss',
                             verbose=0,
                             mode='max',
                             save_best_only=True)
early_stopping = EarlyStopping(monitor='val_loss', patience=15, mode='max')
opt = Adam(lr=lr)
model.compile(
    loss='mse',
    optimizer=opt,
)  # metrics='loss'
model.fit(train_dataset, epochs=10, callbacks=[checkpoint, plateau],  # #plateau   early_stopping
          shuffle=False,  # 时间序列为什么要打乱  是写错里吗？ #另外x是否应该为38000*300 行？
          batch_size=1, verbose=2)
model.save('model.h5')
&lt;/denchmark-code&gt;

Please` make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
TensorFlow installed from (source or binary):conda install
TensorFlow version (use command below):tensorflow 2.3.0-gpu
Python version:python 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:10.1
GPU model and memory: gpu 2080s   8g

When I use keras to save the model, if I don't use embedding in feature columns_ The column model can be saved normally, but if embedding is used_ The model after column training cannot be saved. The error is as follows:
Traceback (most recent call last):
File "/home/zy/Project_save/BTC_project/code_program/keras_bug.py", line 212, in 
model.save('model.h5')
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1979, in save
signatures, options)
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py", line 131, in save_model
model, filepath, overwrite, include_optimizer)
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 119, in save_model_to_hdf5
save_weights_to_hdf5_group(model_weights_group, model_layers)
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 640, in save_weights_to_hdf5_group
param_dset = g.create_dataset(name, val.shape, dtype=val.dtype)
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/h5py/_hl/group.py", line 139, in create_dataset
self[name] = dset
File "/home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/h5py/_hl/group.py", line 373, in setitem
h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)
File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
File "h5py/h5o.pyx", line 202, in h5py.h5o.link
RuntimeError: Unable to create link (name already exists)
You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='anavanab99' date='2020-12-30T08:26:30Z'>
		&lt;denchmark-link:https://github.com/anavanab99&gt;@anavanab99&lt;/denchmark-link&gt;

Request you try with Latest stable TF version 2.4 or nightly version and see if the issue still persists. If you still face the issue then please share colab link or simple standalone code with proper indentation to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='2' author='anavanab99' date='2021-01-06T08:48:29Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='anavanab99' date='2021-01-13T09:48:31Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='4' author='anavanab99' date='2021-01-13T09:48:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46041&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46041&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>