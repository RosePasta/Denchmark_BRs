<bug id='32725' author='ArtemisZGL' open_date='2019-09-23T07:33:49Z' closed_time='2019-09-27T08:07:51Z'>
	<summary>run interpreter.invoke() just show Aborted (core dumped)</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information
-(yes) Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
-(Linux Ubuntu 16.04) OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
(conda) TensorFlow installed from (source or binary):
(1.13.1 and 1.14) TensorFlow version (use command below):
(3.6.8) Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When I use tf version 1.13.1 to convert pb to tflite, it shows dim not matched error, but when I use 1.14 to convert, it succeeds to save the tflite file. But when I use the test code in the tf doc, it just shows core dumped.
Describe the expected behavior
i want to use the tflite file in android, however, i even can't use it in python
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
code generated the tflite file
&lt;denchmark-code&gt;import tensorflow as tf

graph_def_file = "../model/resnet18/weights-89-0.952.pb"
input_arrays = ["input"]
output_arrays = ["lambda_1/l2_normalize"]

converter = tf.lite.TFLiteConverter.from_frozen_graph(
  graph_def_file, input_arrays, output_arrays, input_shapes={"input" : [1, 257, 400,1]})
tflite_model = converter.convert()
open("../model/resnet18/converted_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

code to test in python(from doc)
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path="/home/dm/Desktop/VGG-Speaker-Recognition/model/resnet18/converted_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print(input_details)
print(output_details)
# Test model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
print(input_data.shape)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
converted with 1.13.1
&lt;denchmark-code&gt; ture_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA  
2019-09-23 14:33:07.069746: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz  
2019-09-23 14:33:07.072588: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x564ecd24a790 executing computations on platform Host. Devices:  
2019-09-23 14:33:07.072658: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;  
Ignore 'tcmalloc: large alloc' warnings.  
Traceback (most recent call last):  
  File "pb-to-tflite.py", line 9, in &lt;module&gt;  
    tflite_model = converter.convert()  
  File "/home/dm/anaconda3/envs/s-t3/lib/python3.6/site- 
 packages/tensorflow/lite/python/lite.py", line 455, in convert  
    **converter_kwargs)  
  File "/home/dm/anaconda3/envs/s-t3/lib/python3.6/site- 
 packages/tensorflow/lite/python/convert.py", line 442, in toco_convert_impl  
    input_data.SerializeToString())  
  File "/home/dm/anaconda3/envs/s-t3/lib/python3.6/site-packages/tensorflow/lite/python/convert.py", line 205, in toco_convert_protos  
    "TOCO failed. See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.  
2019-09-23 14:33:21.269591: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 529 operators, 854 arrays (0 quantized)  
2019-09-23 14:33:21.275653: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 527 operators, 849 arrays (0 quantized)  
2019-09-23 14:33:21.283483: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 527 operators, 849 arrays (0 quantized)  
2019-09-23 14:33:21.330461: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:117] Check failed: dim_x == dim_y (512 vs. 10)Dimensions must match  
Aborted (core dumped) 
&lt;/denchmark-code&gt;

converted by 1.14
&lt;denchmark-code&gt;2019-09-23 14:38:45.285133: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize  
2019-09-23 14:38:45.285519: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 440 nodes (-112), 631 edges (-112), time = 213.324ms.  
2019-09-23 14:38:45.285580: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 440 nodes (0), 631 edges (0), time = 54.184ms.  
&lt;/denchmark-code&gt;

and when I use the code above to test ,it just shows
&lt;denchmark-code&gt; [{'name': 'input', 'index': 95, 'shape': array([  1, 257, 400,   1], dtype=int32), 'dtype': &lt;class 'numpy.float32'&gt;, 'quantization': (0.0, 0)}]  
[{'name': 'lambda_1/l2_normalize', 'index': 96, 'shape': array([  1, 512], dtype=int32), 'dtype': &lt;class 'numpy.float32'&gt;, 'quantization': (0.0, 0)}]  
(1, 257, 400, 1)  
Aborted (core dumped)  
&lt;/denchmark-code&gt;

and I could use netron to open the generated tflite file
&lt;denchmark-link:https://i.stack.imgur.com/zlSAn.png&gt;the network structure it shows&lt;/denchmark-link&gt;

here is the code of this model
&lt;denchmark-link:https://github.com/WeidiXie/VGG-Speaker-Recognition&gt;https://github.com/WeidiXie/VGG-Speaker-Recognition&lt;/denchmark-link&gt;

could somebody give me some help?
	</description>
	<comments>
		<comment id='1' author='ArtemisZGL' date='2019-09-24T02:54:39Z'>
		by selecting different graph node as the output , i found maybe is the "sub" node making this error, i defined my own trainable variable in keras, and sub them to calculate the residual, is there any way to fixed this problem?
&lt;denchmark-link:https://user-images.githubusercontent.com/31615877/65477728-c9f36b80-deb9-11e9-949c-849de9df7cd3.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='ArtemisZGL' date='2019-09-25T08:46:52Z'>
		i try to avoid to use broadcast, but still not work, and i also try to use tf.get_variable() to replace keras add_weight() in self-define layer, but not work again
		</comment>
		<comment id='3' author='ArtemisZGL' date='2019-09-27T03:17:36Z'>
		I also have the same issue
		</comment>
		<comment id='4' author='ArtemisZGL' date='2019-09-27T08:07:51Z'>
		i found the reason of my problem is because when two tensors subtract using broadcast. but if the tensor dim is smaller than 5, this problem will not occur. Once the tensor dim is larger than 4, it can't use broadcast or will be broken. But when i try to use tf.tile to avoid using broadcast, the tflite will move this tile node from the graph, may be it's where the reason from.
		</comment>
		<comment id='5' author='ArtemisZGL' date='2019-09-27T08:07:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32725&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32725&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='ArtemisZGL' date='2019-12-04T03:38:56Z'>
		the same issue, is there any solution?
		</comment>
	</comments>
</bug>