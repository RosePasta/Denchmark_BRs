<bug id='27012' author='shenyichen105' open_date='2019-03-22T02:27:02Z' closed_time='2019-03-22T22:49:00Z'>
	<summary>tflite depthwise_conv2d produces different(wrong) results</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): pip install tensorflow
TensorFlow version (use command below): 1.12.0
Python version: 2.7.12
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CUDA 9 cuDNN 7.1
GPU model and memory:GTX 1080

So I was trying to use tflite converter to convert a pretrained model. When I use the same input to do inference by both tflite interpreter and native tensorflow I observed vastly different outputs . The difference is caused by the tfLite depthwise2d operator converted from the original  tf.nn.conv2d operator.  So I constructed a mini example to explain the problem:
import numpy as np
import tensorflow as tf

#construct a fake weight coeffecients
np.random.seed(0)
weight_array= np.random.uniform(-1,1, size=(1,3,1,9)).astype("float32")

#construct a simple graph involving conv2d
tf.reset_default_graph()
input_1 = tf.placeholder(dtype=tf.float32, shape=[1,1,600,1])
weights = tf.constant(weight_array)
weights = tf.quantization.fake_quant_with_min_max_args(weights, np.min(weight_array), np.max(weight_array))
out = tf.nn.conv2d(input_1, weights, [1,2,2,1], "SAME")
out_1 = tf.nn.relu6(out)
q_out = tf.quantization.fake_quant_with_min_max_args(out_1, 0, 6)

#convert the graph to tflite in unit8 quantized inference mode
with tf.Session() as sess:
    converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [input_1], [q_out])
    converter.inference_type = tf.contrib.lite.constants.QUANTIZED_UINT8
    converter.inference_input_type = tf.contrib.lite.constants.QUANTIZED_UINT8
    input_arrays = converter.get_input_arrays()
    converter.quantized_input_stats = {input_arrays[0] : (128, 1)} 
    tflite_model = converter.convert()

#define a dummy input
input_sig = np.ones([1,1,600,1])
input_data = input_sig.astype("uint8")

#inference using tflite interpreter
interpreter = tf.contrib.lite.Interpreter(model_content=tflite_model)
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_index = input_details[0]['index']
output_index = output_details[0]['index']

interpreter.allocate_tensors()
interpreter.set_tensor(input_index, input_data)
interpreter.invoke()
#get tflite int8 output
tf_lite_output = interpreter.get_tensor(output_index)

scale = output_details[0]['quantization'][0] #scale factor for quantized output
weight_scale =  interpreter._get_tensor_details(0)['quantization'][0] #scale factor for quantized weights
zero_point = output_details[0]['quantization'][1] #the point for quantized output maps to float 0 

#get tensorflow float32 output from fake quantized node
with tf.Session() as sess:
    tf_output = sess.run(q_out,  {input_1: input_sig})

#compare, they should be at least close, but nope
print tf_lite_output[0][0][0] 
print tf_output[0][0][0]/ scale + zero_point #converted to uint8 output using the quantization information in the output_details
Describe the current behavior
tflite output gives:
[  0,   0,   0,   0,   0,   0, 255,   0,   0]
after converting to uint8 by sc, tensorflow model gives:
[18. 74. 52. 35. 27.  0.  0.  4. 37.]
Describe the expected behavior
I believe those two results should give a very similar result when fed with identical inputs. I also checked that the quantized weight matches with the output from fake quantization node after scaling using the weight_scale. I also manually calculated the operation defined in the graph and produced a result close to what tensorflow model gives. Is there a reason that tflite computation behaves completely different than the native tensorflow ?
	</description>
	<comments>
		<comment id='1' author='shenyichen105' date='2019-03-22T22:49:00Z'>
		Actually found the solution. Changed converter.quantized_input_stats = {input_arrays[0] : (128, 1)}  to converter.quantized_input_stats = {input_arrays[0] : (0, 1)}  and then tf and tflite gave almost same outputs.  Although I am pretty suprised that the output is that sensitive input stats.
		</comment>
		<comment id='2' author='shenyichen105' date='2019-03-22T22:49:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27012&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27012&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='shenyichen105' date='2019-06-12T09:39:30Z'>
		hi shenyichen,
Why do you feed same input to Tf and Tflite ?
I expected Tflite to get quantized input. But i see you are feeding the same input.
Are you simulating same float models for both ?
		</comment>
	</comments>
</bug>