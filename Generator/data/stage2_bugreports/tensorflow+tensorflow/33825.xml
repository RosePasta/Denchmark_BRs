<bug id='33825' author='nickoala' open_date='2019-10-29T14:30:39Z' closed_time='2019-11-25T19:24:11Z'>
	<summary>Using metric SparseTopKCategoricalAccuracy on an RNN results in rank mismatch</summary>
	<description>
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. The code is given below to reproduce the issue.


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04


TensorFlow installed from (source or binary):
Binary, using pip


TensorFlow version:
v2.0.0-rc2-26-g64c3d38 2.0.0


Python version:
3.6


CUDA/cuDNN version:
10.1 / 7.6.2


GPU model and memory:
GeForce GTX 1070 / 8GB


Describe the current behavior
When I compile an RNN model with the metric SparseTopKCategoricalAccuracy(), the following error results. No error occurs if I use SparseCategoricalAccuracy() instead.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 1610, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 3 for 'metrics/sparse_top_k_categorical_accuracy/in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [?,?,10], [?,?], [].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "report.py", line 12, in &lt;module&gt;
    metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy()])
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 366, in compile
    masks=self._prepare_output_masks())
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 2063, in _handle_metrics
    target, output, output_mask))
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 2014, in _handle_per_output_metrics
    metric_fn, y_true, y_pred, weights=weights, mask=mask)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1067, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py", line 193, in __call__
    replica_local_fn, *args, **kwargs)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py", line 1135, in call_replica_local_fn
    return fn(*args, **kwargs)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py", line 176, in replica_local_fn
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py", line 75, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py", line 581, in update_state
    matches = self._fn(y_true, y_pred, **self._fn_kwargs)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py", line 2805, in sparse_top_k_categorical_accuracy
    nn.in_top_k(y_pred, math_ops.cast(y_true, 'int32'), k), K.floatx())
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py", line 4843, in in_top_k
    return gen_nn_ops.in_top_kv2(predictions, targets, k, name=name)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py", line 5043, in in_top_kv2
    "InTopKV2", predictions=predictions, targets=targets, k=k, name=name)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py", line 793, in _apply_op_helper
    op_def=op_def)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 548, in create_op
    compute_device)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 3429, in _create_op_internal
    op_def=op_def)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 1773, in __init__
    control_input_ops)
  File "/home/pi/venv/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 2 but is rank 3 for 'metrics/sparse_top_k_categorical_accuracy/in_top_k/InTopKV2' (op: 'InTopKV2') with input shapes: [?,?,10], [?,?], [].
&lt;/denchmark-code&gt;

Describe the expected behavior
I expect no error. I suppose SparseTopKCategoricalAccuracy() can be used in exactly the same way as SparseCategoricalAccuracy().
Code to reproduce the issue
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

model = tf.keras.Sequential([
    layers.Embedding(input_dim=1000, output_dim=64),
    layers.LSTM(128, return_sequences=True),
    layers.Dense(10, activation='softmax')])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=[tf.keras.metrics.SparseTopKCategoricalAccuracy()])

data = np.random.randint(0, 1000, (32, 10))  # batch_size=32, seq_length=10
labels = np.random.randint(0, 10, (32, 10))

model.fit(data, labels, epochs=1, batch_size=32)
Other info / logs
I use this custom metric to get around the problem:
class InTopK(tf.keras.metrics.Mean):
    def __init__(self, k, name='in_top_k', **kwargs):
        super(InTopK, self).__init__(name=name, **kwargs)
        self._k = k

    def update_state(self, y_true, y_pred, sample_weight=None):
        matches = tf.nn.in_top_k(
            # flatten tensors
            tf.reshape(tf.cast(y_true, tf.int32), [-1]),
            tf.reshape(y_pred, [-1, y_pred.shape[-1]]),
            k=self._k)

        return super(InTopK, self).update_state(
            matches, sample_weight=sample_weight)
	</description>
	<comments>
		<comment id='1' author='nickoala' date='2019-10-30T06:36:27Z'>
		I have tried on colab with TF version 2.0 ,2.1.0-dev20191029 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/33f418bcd6dfd460f37114fa31dd99ad/untitled315.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='nickoala' date='2019-11-21T17:48:14Z'>
		I have submitted a fix for this now, please try it out and let us know if things look good. Thank you!
		</comment>
		<comment id='3' author='nickoala' date='2019-11-25T19:24:11Z'>
		&lt;denchmark-link:https://github.com/nickoala&gt;@nickoala&lt;/denchmark-link&gt;
 Looks like the fix by &lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
 resolved the issue. I ran your code with  and I cannot reproduce the issue. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/7a0d7006ed71f30a7f65a97e754d5a36/untitled315.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
I am closing this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!
		</comment>
		<comment id='4' author='nickoala' date='2019-11-25T19:24:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33825&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33825&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='nickoala' date='2019-11-26T08:01:30Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
, thank you very much. I am satisfied with the fix. Thanks for the work.
		</comment>
	</comments>
</bug>