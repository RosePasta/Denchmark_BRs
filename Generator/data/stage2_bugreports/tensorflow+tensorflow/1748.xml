<bug id='1748' author='elanmart' open_date='2016-04-02T15:05:39Z' closed_time='2016-06-06T20:51:06Z'>
	<summary>Optimizers incompatible with sampling -- missing docs?</summary>
	<description>
Hi,
perhaps Tensorflow docs should mention that 5 out of 7 available optimizers will not work with sampling losses? For now, they fail with mysterious messages.
The following script will fail for Momentum, AdaGrad, AdaDelta, RMSProp and FTRL.
Also, where should I look if I'd like to implement my own optimizers for GPU?
import tensorflow as tf
import numpy.random as nr
import numpy as np

# config 
num_classes = 10000
num_sampled = 512
num_true = 32
activation_dim = 512
batch_sz = 16

# "model" setup
activations = tf.placeholder(tf.float32, shape=(None, activation_dim))
labels = tf.placeholder(tf.int64, shape=(None, num_true))

nce_W = tf.Variable(tf.truncated_normal((num_classes, activation_dim)))
nce_b = tf.Variable(tf.truncated_normal((num_classes, )))

nce_loss = tf.reduce_mean(
                tf.nn.nce_loss(nce_W, nce_b, 
                               activations, labels, 
                               num_sampled, num_classes, num_true))

# optimizer setup
global_step   = tf.Variable(1)
initial_alpha = tf.Variable(0.1)
alpha         = tf.Variable(0.01)

optimizer = tf.train.FtrlOptimizer(alpha)

# fetches
step = optimizer.minimize(nce_loss, global_step=global_step, name='sgd_step') 
init = tf.initialize_all_variables()

# synthetic data
X = nr.randn(batch_sz, activation_dim).astype(np.float32)
y = nr.randint(0, num_classes, (batch_sz, num_true)).astype(np.int64)

with tf.Session() as sess:
    sess.run(init)
    sess.run(step, feed_dict={activations:X, labels:y})
The error message is:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
StatusNotOK                               Traceback (most recent call last)
StatusNotOK: Invalid argument: Cannot assign a device to node 'Variable_1/read': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
     [[Node: Variable_1/read = Identity[T=DT_FLOAT, _class=["loc:@Variable_1"]](Variable_1)]]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='elanmart' date='2016-04-07T01:53:30Z'>
		Does pinning the variables to CPU make this work? i.e.
with tf.device("/cpu:0"):
  nce_W = …
  nce_b = …
		</comment>
		<comment id='2' author='elanmart' date='2016-06-06T20:51:06Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 I assume this is fixed now, in that we don't do improper placement, but I'm not sure all sparse optimizers are supported on GPU, which is perhaps another bug which I believe we already have an issue for.
		</comment>
	</comments>
</bug>