<bug id='33028' author='hollowgalaxy' open_date='2019-10-03T17:26:44Z' closed_time='2019-10-03T22:09:04Z'>
	<summary>tf keras progbar callback is not displayed during keras.fit() when verbose=0.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):binary (conda install tensorflow-gpu==1.14.0)
TensorFlow version (use command below): 1.14.0
Python version: Python 3.7.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10
GPU model and memory: nvidia 1080, 8GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Attempting to use progbar as a callback to model.fit() fails.
Describe the expected behavior
If runing model.fit() with progbar callback and verbosity=0 should be identical to verbosity=1 and no progbar callback
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
current output:
&lt;denchmark-code&gt;import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf

print('tf_version:', tf.__version__, 'gpu available:', tf.test.is_gpu_available())
model = tf.keras.applications.ResNet50()


print('compiling model')
model.compile(optimizer='SGD', loss=tf.keras.losses.categorical_crossentropy)

print('running fit function')
x = tf.data.Dataset.from_tensors(tf.zeros([16]+model.input.shape.as_list()[1:]))
y = tf.data.Dataset.from_tensors(tf.zeros([16]+model.output.shape.as_list()[1:]))
print('x:', x, '\ny', y)
model.fit(tf.data.Dataset.zip((x,y)).repeat().shuffle(buffer_size=1),
          steps_per_epoch=10,
          verbose=0,
          callbacks=[tf.keras.callbacks.ProgbarLogger('steps')])
print('done')
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
running the code above recreates the problem.
&lt;denchmark-code&gt;tf_version: 1.14.0 gpu available: True
WARNING: Logging before flag parsing goes to stderr.
W1003 10:20:49.769316 140195608012544 deprecation.py:506] From /home/hackerman/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
compiling model
running fit function
x: &lt;DatasetV1Adapter shapes: (16, 224, 224, 3), types: tf.float32&gt; 
y &lt;DatasetV1Adapter shapes: (16, 1000), types: tf.float32&gt;
done
&lt;/denchmark-code&gt;

expected output (reproduced by commenting out callback, and setting verbose to 1):
&lt;denchmark-code&gt;tf_version: 1.14.0 gpu available: True
WARNING: Logging before flag parsing goes to stderr.
W1003 10:21:47.987383 140242665334528 deprecation.py:506] From /home/hackerman/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
compiling model
running fit function
x: &lt;DatasetV1Adapter shapes: (16, 224, 224, 3), types: tf.float32&gt; 
y &lt;DatasetV1Adapter shapes: (16, 1000), types: tf.float32&gt;
10/10 [==============================] - 6s 592ms/step - loss: 0.0000e+00
done
&lt;/denchmark-code&gt;

bonus bug (if keeping callback and setting verbosity to 1):
&lt;denchmark-code&gt;tf_version: 1.14.0 gpu available: True
WARNING: Logging before flag parsing goes to stderr.
W1003 10:23:10.488721 140225721059072 deprecation.py:506] From /home/hackerman/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
compiling model
running fit function
x: &lt;DatasetV1Adapter shapes: (16, 224, 224, 3), types: tf.float32&gt; 
y &lt;DatasetV1Adapter shapes: (16, 1000), types: tf.float32&gt;
10/10 [==============================] - 6s 597ms/step - loss: 0.0000e+00
10/10 [==============================] - 6s 597ms/step - loss: 0.0000e+00
done
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hollowgalaxy' date='2019-10-03T20:42:15Z'>
		Was able to reproduce this issue. Here's my github &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/7396f9add006cd8fe1f0ce1a943e643e/untitled167.ipynb&gt;gist&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='hollowgalaxy' date='2019-10-03T22:00:14Z'>
		&lt;denchmark-link:https://github.com/hollowgalaxy&gt;@hollowgalaxy&lt;/denchmark-link&gt;
  is intended to suppress all output
		</comment>
		<comment id='3' author='hollowgalaxy' date='2019-10-03T22:03:21Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 If both the call back is provided and verbose is set to 1, the progress is displayed twice. Isn't it a bug?
&lt;denchmark-code&gt;tf_version: 1.14.0 gpu available: True
WARNING: Logging before flag parsing goes to stderr.
W1003 10:23:10.488721 140225721059072 deprecation.py:506] From /home/hackerman/anaconda3/envs/py36/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
compiling model
running fit function
x: &lt;DatasetV1Adapter shapes: (16, 224, 224, 3), types: tf.float32&gt; 
y &lt;DatasetV1Adapter shapes: (16, 1000), types: tf.float32&gt;
10/10 [==============================] - 6s 597ms/step - loss: 0.0000e+00
10/10 [==============================] - 6s 597ms/step - loss: 0.0000e+00
done

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='hollowgalaxy' date='2019-10-03T22:09:05Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33028&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33028&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='hollowgalaxy' date='2019-10-03T22:50:07Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 Hm I see what you're saying.
The ProgBarLogger callback is automatically added when you set verbose != 0. Users shouldn't need to add this to their fit call manually. Arguably we could check to see if a ProgBarLogger callback already exists before automatically adding, but as this doesn't crash anything and just duplicates the outputs I'm OK with leaving it like this for now. Please feel free to submit a PR though!
		</comment>
		<comment id='6' author='hollowgalaxy' date='2019-10-03T22:50:30Z'>
		
verbose=0 is intended to suppress all output

&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
  thats not true. I can print stuff while  with a custom callback. The bug, I'm pointing out is that using  with  doesn't get printed.
&lt;denchmark-code&gt;import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf

print('tf_version:', tf.__version__, 'gpu available:', tf.test.is_gpu_available())
import datetime

# copied from https://www.tensorflow.org/guide/keras/custom_callback
class MyCustomCallback(tf.keras.callbacks.Callback):

  def on_train_batch_begin(self, batch, logs=None):
    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))

  def on_train_batch_end(self, batch, logs=None):
    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))

  def on_test_batch_begin(self, batch, logs=None):
    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))

  def on_test_batch_end(self, batch, logs=None):
    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))
    

model = tf.keras.applications.ResNet50()    
print('compiling model')
model.compile(optimizer='SGD', loss=tf.keras.losses.categorical_crossentropy)

print('running fit function')
x = tf.data.Dataset.from_tensors(tf.zeros([1]+model.input.shape.as_list()[1:]))
y = tf.data.Dataset.from_tensors(tf.zeros([1]+model.output.shape.as_list()[1:]))
print('x:', x, '\ny', y)
model.fit(tf.data.Dataset.zip((x,y)).repeat().shuffle(buffer_size=1),
          steps_per_epoch=2,
          verbose=0,
          callbacks=[MyCustomCallback()])
print('done')
&lt;/denchmark-code&gt;

returns the following
&lt;denchmark-code&gt;tf_version: 1.14.0 gpu available: False
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5
102858752/102853048 [==============================] - 1s 0us/step
compiling model
running fit function
x: &lt;DatasetV1Adapter shapes: (1, 224, 224, 3), types: tf.float32&gt; 
y &lt;DatasetV1Adapter shapes: (1, 1000), types: tf.float32&gt;
Training: batch 0 begins at 22:45:37.495002
Training: batch 0 ends at 22:45:43.157376
Training: batch 1 begins at 22:45:43.158103
Training: batch 1 ends at 22:45:44.163262
done
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='hollowgalaxy' date='2019-10-03T22:51:38Z'>
		In addition, how can one use tf.keras.callbacks.ProgbarLogger when the goal is to override it?
		</comment>
		<comment id='8' author='hollowgalaxy' date='2019-10-03T23:24:14Z'>
		&lt;denchmark-link:https://github.com/hollowgalaxy&gt;@hollowgalaxy&lt;/denchmark-link&gt;
 You could set verbose=0 in  and then override  to ignore the  setting in your overridden version:



tensorflow/tensorflow/python/keras/callbacks.py


         Line 739
      in
      58b283f






 def on_train_begin(self, logs=None): 





		</comment>
	</comments>
</bug>