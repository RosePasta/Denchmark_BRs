<bug id='836' author='digitalsword' open_date='2016-01-22T01:27:07Z' closed_time='2017-06-16T19:16:32Z'>
	<summary>tensorboard not able to read large event file (~600MB)</summary>
	<description>
I am training a network on 4 GPUs. The event file is too large to be parsed by tensorboard. How can I increase the limit?
&lt;denchmark-code&gt;RNING:tensorflow:IOError [Errno 2] No such file or directory: '/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/TAG' on path /home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://0.0.0.0:6006)
[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
Exception in thread Thread-2:
Traceback (most recent call last):
  File "/home/pc/anaconda2/lib/python2.7/threading.py", line 801, in __bootstrap_inner
    self.run()
  File "/home/pc/anaconda2/lib/python2.7/threading.py", line 1073, in run
    self.function(*self.args, **self.kwargs)
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/event_accumulator.py", line 242, in Update
    self.Reload()
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/event_accumulator.py", line 175, in Reload
    for event in self._generator.Load():
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/impl/directory_watcher.py", line 82, in Load 
    for event in self._loader.Load():
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/summary/impl/event_file_loader.py", line 53, in Load 
    event.ParseFromString(self._reader.record())
DecodeError: Error parsing message
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='digitalsword' date='2016-01-23T11:51:25Z'>
		So big file,
the protocol Buffers are not designed to handle large messages.
I am not sure about this solution but try to edit CodedInputStream::SetTotalBytesLimit() in /src/google/protobuf/io/coded_stream_inl.h
the Doc is here
&lt;denchmark-link:https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.io.coded_stream#CodedInputStream.SetTotalBytesLimit.details&gt;https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.io.coded_stream#CodedInputStream.SetTotalBytesLimit.details&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='digitalsword' date='2016-01-23T12:34:53Z'>
		look at this
&lt;denchmark-link:https://github.com/BVLC/caffe/issues/279&gt;BVLC/caffe#279&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='digitalsword' date='2016-01-29T22:20:28Z'>
		Do you know why your protobuf is so big? Is it storing a very large GraphDef? Also, can you share the events file that is causing this issue?
		</comment>
		<comment id='4' author='digitalsword' date='2016-02-01T16:42:13Z'>
		&lt;denchmark-link:https://github.com/danmane&gt;@danmane&lt;/denchmark-link&gt;
 I was training an RNN on 4 GPUs. The weights was defined on CPU. Then I got a large graph. I am not sure if I am using RNN correctly in this multiple-GPU case. Do you know how to train RNN on 4 GPUs? I was using rnn_cell.BasicLSTMCell and rnn_cell.MultiRNNCell() to create an RNN.
		</comment>
		<comment id='5' author='digitalsword' date='2016-02-09T19:29:10Z'>
		I'm not sure about RNN usage, sorry. (Maybe &lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
 can advise or point in the right direction.)
It would be helpful to find out what message is so large that it's violating the protobuf message size limit - that would let us determine whether we should increase the message size limit, or if we should find a way to prevent such large messages from getting generated in the first place. Can you dig into the protobuf and find what it is, or send us the event file?
		</comment>
		<comment id='6' author='digitalsword' date='2017-05-10T09:01:35Z'>
		I got the same problem with a 230MB event file. I copied the event file to another VM with larger memory, then opened Tensorboard without any problem.
		</comment>
		<comment id='7' author='digitalsword' date='2017-06-16T19:16:32Z'>
		I have migrated this issue to &lt;denchmark-link:https://github.com/tensorflow/tensorboard/issues/49&gt;tensorflow/tensorboard#49&lt;/denchmark-link&gt;
 because TensorBoard has moved to a new repository (outside of tensorflow/tensorflow). Lets continue discussion there, and sorry about how this issue is still open.
		</comment>
	</comments>
</bug>