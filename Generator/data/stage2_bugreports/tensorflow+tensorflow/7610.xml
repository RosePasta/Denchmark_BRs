<bug id='7610' author='undertherain' open_date='2017-02-17T06:05:16Z' closed_time='2018-02-22T19:21:15Z'>
	<summary>3D convolutions unnaturally slow on CPU</summary>
	<description>
3D convolutions on CPU seem unnaturally slow.
I can't use GPU due to memory limit, so I'm looking at CPU execution.
2D convolutions in TensorFlow seem to be well-optimized, all CPU cores are used, performance is just few times below GPU.
With 3D convolutions - the difference is orders of magnitude.
Also, I've compared with Theano. Theano 3D convolutions run on single core but still are 10 times faster.
Strangely, TF uses all cores on CPU with 3Dconv,  so there must be some bug or extreme inefficiency in implementation.
With the same small test model (just couple of 3d conv layers) I get 1 second epoch time on GPU (both TF and Theano, theano just a bit faster), 5 seconds on CPU Theano single threaded, and 50 seconds with (seemingly) multi-threded TF
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

I've tried different TF versions from 0.12 to 1.00, installed from pip. Latest one from &lt;denchmark-link:https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-linux_x86_64.whl&gt;https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-linux_x86_64.whl&lt;/denchmark-link&gt;

The OS is CentOS Linux release 7.2.1511 (Core) , kernel 3.10.0-327.18.2.el7.x86_64
I'm using Keras back-end, so I can't be 100% sure if the problem is not in the way Keras translates Convolution3D call into TF primitives, but it does not seem likely.
cheers
Alex
	</description>
	<comments>
		<comment id='1' author='undertherain' date='2017-02-17T16:43:58Z'>
		cc &lt;denchmark-link:https://github.com/daeyun&gt;@daeyun&lt;/denchmark-link&gt;
 who added conv3d_transpose
(ps: who maintains core/kernels/conv_3d.h  ?)
		</comment>
		<comment id='2' author='undertherain' date='2017-02-17T16:45:25Z'>
		&lt;denchmark-link:https://github.com/mjanusz&gt;@mjanusz&lt;/denchmark-link&gt;
 might know, I think he implemented / uses Conv3D, possibly even on CPU.
		</comment>
		<comment id='3' author='undertherain' date='2017-02-20T10:59:03Z'>
		Eigen's conv3d is not optimized to the same level as conv2d, but the speed you are observing seems to be particularly bad. I will take a look at this.
		</comment>
		<comment id='4' author='undertherain' date='2017-02-28T21:44:59Z'>
		I can confirm this problem exists. I've experienced an unnatural 100X factor between a latest mac and a gpu machine. On other tasks I got used to seeing 5-20X at most with 2d convolutions and matrix multiplications.
		</comment>
		<comment id='5' author='undertherain' date='2017-06-16T18:43:30Z'>
		&lt;denchmark-link:https://github.com/mjanusz&gt;@mjanusz&lt;/denchmark-link&gt;
 Did you get a chance to look at this?
		</comment>
		<comment id='6' author='undertherain' date='2017-07-06T12:54:07Z'>
		Building from sources (MKL enabled) seems to help a lot with this issue. Compared to the pip binary, almost 10x faster.
		</comment>
		<comment id='7' author='undertherain' date='2017-07-06T12:58:00Z'>
		&lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 Yes. The commit a999474 fixes a regression that should provide a 3x-5x speedup, depending on the exact configuration. The next step to improve performance is to write a contraction mapper in eigen_cuboid_convolutions.h, but I haven't had the chance to do that yet.
		</comment>
		<comment id='8' author='undertherain' date='2017-10-10T03:37:59Z'>
		Observing the same problem here on macOS with CPU. Unnaturally slow and extreme memory requirements (50-100x more compared to conv2d).
		</comment>
		<comment id='9' author='undertherain' date='2017-12-20T19:28:31Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='undertherain' date='2018-01-04T19:14:42Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='undertherain' date='2018-01-23T23:11:36Z'>
		A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.
		</comment>
		<comment id='12' author='undertherain' date='2018-02-07T13:49:11Z'>
		Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='13' author='undertherain' date='2018-02-08T00:54:24Z'>
		&lt;denchmark-link:https://github.com/mjanusz&gt;@mjanusz&lt;/denchmark-link&gt;
 Are you still planning on writing a contraction mapper in eigen_cuboid_convolutions.h? I am keeping this issue open for tracking purposes in case you do.
		</comment>
		<comment id='14' author='undertherain' date='2018-02-22T13:08:13Z'>
		Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='15' author='undertherain' date='2018-02-22T19:21:15Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>