<bug id='30234' author='siavash-khodadadeh' open_date='2019-06-28T18:36:33Z' closed_time='2019-07-17T22:39:11Z'>
	<summary>How to calculate gradients for meta learning loop?</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): TF 2.0.0-dev20190628
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CUDA 10.0
GPU model and memory:

Describe the current behavior
I want to compute the gradients of a loss function with respect to a model (in order to do meta-learning) and use those gradients to define the same model with new weights. I get None as the values of the model when  I use Input layers.
Describe the expected behavior
I was expecting it to work the same whether I define my input layer as an Input layer or as tf.random.uniform() tensor.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input


with tf.GradientTape() as t:
    model = tf.keras.models.Sequential(
        (
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Conv2D(filters=64, kernel_size=3, activation='relu'),
            Flatten(),
            Dense(10, activation='softmax'),
        )
    )

    train_inputs = Input(shape=(28, 28, 1))
    train_labels = Input(shape=(10, ))

    # train_inputs = tf.random.uniform(shape=(1, 28, 28, 1), dtype=tf.float32)
    # train_labels = tf.random.uniform(shape=(1, 10), dtype=tf.float32)

    train_outputs = model(train_inputs)
    loss = tf.losses.categorical_crossentropy(train_labels, train_outputs)

d_weights = t.gradient(loss, model.trainable_weights)
print(d_weights)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
If I uncomment those two lines d_weights is calculated and printed. When they are commented I get this error:
2019-06-28 14:27:30.352043: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-28 14:27:30.386438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2208000000 Hz
2019-06-28 14:27:30.387394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2f99b30 executing computations on platform Host. Devices:
2019-06-28 14:27:30.387417: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): , 
Traceback (most recent call last):
File "/home/siavash/programming/meta-learning-framework/models.py", line 27, in 
d_weights = t.gradient(loss, model.trainable_weights)
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py", line 1001, in gradient
unconnected_gradients=unconnected_gradients)
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py", line 76, in imperative_grad
compat.as_str(unconnected_gradients.value))
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py", line 666, in _ones
return _fast_fill(value, shape, dtype)
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py", line 621, in _fast_fill
constant_op.constant(shape, dtype=dtypes.int32),
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py", line 246, in constant
allow_broadcast=True)
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py", line 254, in _constant_impl
t = convert_to_eager_tensor(value, ctx, dtype)
File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py", line 115, in convert_to_eager_tensor
return ops.EagerTensor(value, handle, device, dtype)
ValueError: TypeError: object of type 'Tensor' has no len()
	</description>
	<comments>
		<comment id='1' author='siavash-khodadadeh' date='2019-07-01T11:48:34Z'>
		I am able to reproduce the issue on Colab with Tensorflow 2.0.0-dev20190628. Thanks!
		</comment>
		<comment id='2' author='siavash-khodadadeh' date='2019-07-17T22:39:10Z'>
		This is sadly not something we can feasibly fix. Keras is not compatible with meta learning because TF variable assignments, used during the training process, are not differentiable.
To do meta learning in TF use the lower level operations (no layers and no optimizers) and write your own training loop; this way you can make your training loop itself differentiable.
		</comment>
		<comment id='3' author='siavash-khodadadeh' date='2019-07-17T22:39:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30234&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30234&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='siavash-khodadadeh' date='2019-07-18T15:23:01Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 Thank you for your response.
So the gradient tape should be used when there is real data flowing in the model and it cannot be used when we just define models with keras since there is no computation happened. Is my understanding right?
Actually, I am a little confused about gradient tape and why it should not work in this example.
		</comment>
		<comment id='5' author='siavash-khodadadeh' date='2019-07-18T15:58:29Z'>
		The issue here is not about the gradient tape; it also happens with tf.gradients. The issue is around tf.variable, and how operations on tf.variables are not differentiable.
So for example in the following code snippet
v  = tf.Variable(1.0)
x = tf.convert_to_tensor(2.0)
with tf.GradientTape() as t:
  t.watch(x)
  v.assign_add(x)
  loss = v * v
assert t.gradient(loss, x) is None
and the gradient is None because TF doesn't track assignments to tf.Variables to their source operations, because state in variables is stored outside the graph. To get the gradient to be not None you need to replace the tf.Variable with a normal tensor.
		</comment>
		<comment id='6' author='siavash-khodadadeh' date='2019-07-18T16:58:33Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 Thank you for clarifying this. I see what was the reason now.
		</comment>
	</comments>
</bug>