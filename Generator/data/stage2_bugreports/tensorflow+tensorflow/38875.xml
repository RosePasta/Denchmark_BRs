<bug id='38875' author='jarednielsen' open_date='2020-04-24T17:03:21Z' closed_time='2020-04-30T22:24:32Z'>
	<summary>Passing tf.keras.Model as tf.function argument does not create concrete function</summary>
	<description>
System information

Have I written custom code: Yes
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0
Python version: 3.7.5

Describe the current behavior
Passing a tf.keras.Model or tf.keras.Optimizer as argument into tf.function does not create a concrete function. I expect that it would, since function tracing works as it should if the model/optimizer is a global variable.
Standalone code to reproduce the issue
import tensorflow as tf

class MyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()

    def call(self, inputs):
        return 2 * inputs

@tf.function
def step_model(model, inputs):
    return model(inputs)

@tf.function
def step(inputs):
    return model(inputs)

inputs = tf.convert_to_tensor(1, dtype=tf.float32)
model = MyModel()
# This works as expected
print(f"step() = {step(inputs)}") # 2.0
print(f"step() concrete functions: {step._list_all_concrete_functions_for_serialization()}") # [&lt;tensorflow.python.eager.function.ConcreteFunction object at 0x13a2c0510&gt;]
# This does not, no concrete function is saved
print(f"step_model() = {step_model(model, inputs)}") # 2.0
print(f"step_model() concrete functions: {step_model._list_all_concrete_functions_for_serialization()}") # []
Output:
step() = 2.0
step() concrete functions: [&lt;tensorflow.python.eager.function.ConcreteFunction object at 0x133788410&gt;]
step_model() = 2.0
step_model() concrete functions: []
It appears that passing a tf.keras.Model as an argument into tf.function is not supported, as tracing fails. In a different use case, this error appears:
INFO:tensorflow:Unsupported signature for serialization: ((&lt;tensorflow.python.framework.func_graph.UnknownArgument object at 0x13a2c0510&gt;))
My use case requires limiting usage of global variables, since there are several models running simultaneously and they need to be garbage collected efficiently. How can I pass a model as a function argument into a tf.function?
	</description>
	<comments>
		<comment id='1' author='jarednielsen' date='2020-04-25T12:44:47Z'>
		working well on my system.
Try calling class name in super, this might work.
		</comment>
		<comment id='2' author='jarednielsen' date='2020-04-27T07:23:55Z'>
		Was able to reproduce the issue with TF v2.1, &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/522cba9b7938d89254fa81cf07272114/38875.ipynb&gt;TF v2.2.0-rc3&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/67ad4261f2903c039227577c93f55081/38875-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='3' author='jarednielsen' date='2020-04-30T22:24:32Z'>
		This is a known issue. The problem is that we cannot introspect inside a model and generate a single TF graph which is agnostic to the details of the model (which is what it would mean to serialize a concrete function which can take the model as an argument), mostly because we cannot represent function pointers in tf graph now.
Instead I recommend you do something like
&lt;denchmark-code&gt;def get_model_fn(model):
  @tf.function
  def fn(data):
    return model(data)
  return fn
&lt;/denchmark-code&gt;

and then call get_model_fn on all the models you want, to ensure the model gets properly captured.
		</comment>
		<comment id='4' author='jarednielsen' date='2020-04-30T22:24:35Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38875&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38875&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='jarednielsen' date='2020-04-30T22:24:50Z'>
		cc &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='jarednielsen' date='2020-05-01T15:24:00Z'>
		Another option is to make step_model a method of MyModel (methods are special cased, so the "self" argument doesn't have to be translated to encodable argument):
&lt;denchmark-code&gt;class MyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()

    def call(self, inputs):
        return 2 * inputs

    @tf.function
    def step_model(self, inputs):
        return self(inputs)

inputs = tf.convert_to_tensor(1, dtype=tf.float32)
model = MyModel()

print(f"step_model() = {model.step_model(inputs)}") # 2.0
print(f"step_model() concrete functions: {model.step_model._list_all_concrete_functions_for_serialization()}") # [&lt;tensorflow.python.eager.function.ConcreteFunction object at 0x7fd9cc231b00&gt;]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='jarednielsen' date='2020-05-01T18:35:11Z'>
		Thanks for the suggestions. The reason I'm passing in a model is I'm working with BERT-based architectures and will often compare two models when running the same training script. How does BERT-base compare against ALBERT-base, for example? This precludes creating the step_model() model argument, though that is useful information. &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 That is an interesting idea, I'll give it a spin.
Hope you are able to find a fix for the underlying issue! Would love an update if that happens.
		</comment>
		<comment id='8' author='jarednielsen' date='2020-12-17T16:25:06Z'>
		The solution works only if you call the model itself, but not if you want to access the weights for example. In Reinforcement Learning DQN Algorithm, you need to regularly update the "target" model with the weights of the "inline" model... In that case, the solution concretely doesn't work! Any idea, how to pass the model to a function for such a purpose? (You can pass the model via the function closure, either by setting it into a variable in the global scope or by nesting the tf.function into an outer function, or by packing everything into a class... but in all three cases, you loose the "functional" design)
		</comment>
	</comments>
</bug>