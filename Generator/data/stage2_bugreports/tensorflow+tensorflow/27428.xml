<bug id='27428' author='AtlantixJJ' open_date='2019-04-02T13:59:54Z' closed_time='2019-04-05T20:13:38Z'>
	<summary>Tensorflow 2.0.0 multiple GPU output zero for non-root GPU</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No.
TensorFlow installed from (source or binary):
Source.
TensorFlow version (use command below):
v2.0.0-alpha0-0-g2c319fb415 2.0.0-alpha0
Python version:
3.7
Bazel version (if compiling from source):
0.23.0
GCC/Compiler version (if compiling from source):
GCC 4.8
CUDA/cuDNN version:
CUDA 10.0, cuDNN 7
GPU model and memory:
A simple model can reproduce.

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
When I run the tf_env_collect.sh script, tensorflow just hangs there forever. I couldn't even kill it. What the hell is going on?
(base) âžœ  ~ ./tfenv.sh 
Collecting system information...
2019-04-02 22:07:13.977020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-02 22:07:15.731652: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x56368643d070 executing computations on platform CUDA. Devices:
2019-04-02 22:07:15.731716: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 22:07:15.731733: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (1): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 22:07:15.731751: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (2): TITAN X (Pascal), Compute Capability 6.1
2019-04-02 22:07:15.731765: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (3): TITAN X (Pascal), Compute Capability 6.1
2019-04-02 22:07:15.731780: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (4): TITAN X (Pascal), Compute Capability 6.1
2019-04-02 22:07:15.731795: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (5): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 22:07:15.731810: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (6): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 22:07:15.757870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299805000 Hz
2019-04-02 22:07:15.761353: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x563686573540 executing computations on platform Host. Devices:
2019-04-02 22:07:15.761414: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-04-02 22:07:15.762076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:08:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 22:07:15.762510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:09:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 22:07:15.762924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 2 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:82:00.0
totalMemory: 11.91GiB freeMemory: 11.76GiB
2019-04-02 22:07:15.763343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 3 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:85:00.0
totalMemory: 11.91GiB freeMemory: 11.76GiB
2019-04-02 22:07:15.763634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 4 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:86:00.0
totalMemory: 11.91GiB freeMemory: 5.41GiB
2019-04-02 22:07:15.764061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 5 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:89:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 22:07:15.764483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 6 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:8a:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 22:07:15.770500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6
2019-04-02 22:07:15.770587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
Describe the current behavior
Run the test code below. For GPU 0 the behavior is normal, but for GPU 1 the output becomes zero.
Describe the expected behavior
The output of GPU 1 should be the same as GPU 0.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
run python test.py.
import tensorflow as tf
import numpy as np
import os

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1"

def linear(name, input, output_dim, reuse=False):
    with tf.variable_scope(name, reuse=reuse):
        w = tf.get_variable("weight", shape=[input.get_shape()[-1], output_dim], initializer=tf.orthogonal_initializer)
        b = tf.get_variable("bias", [output_dim], initializer=tf.constant_initializer(.0))

        x = tf.matmul(input, w) + b
        with tf.device("/device:CPU:0"):
            x = tf.Print(x, [tf.reduce_sum(tf.abs(w)), tf.reduce_sum(tf.abs(b))], name + "/weight_bias: ")
    
    return x

def tower(x, reuse=False):
    rec_tensor = []
    rec_name = []
    x = linear("fc1", x, 10, reuse)
    rec_tensor.append(x); rec_name.append("fc1")
    x = linear("fc2", x, 1, reuse)
    rec_tensor.append(x); rec_name.append("fc2")
    return x, rec_tensor, rec_name

x = tf.placeholder(tf.float32, [None, 3])
x_data = np.random.rand(5, 3)
feed_dict = {x: x_data}
ys = []
rec_xs = []
rec_names = []

for i in range(2):
    with tf.device(tf.DeviceSpec(device_type="GPU", device_index=i)):
        y_, v_, n_ = tower(x, i&gt;0)
        ys.append(y_)
        rec_xs.append(v_)
        rec_names.append(n_)

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.allow_soft_placement = False
sess = tf.Session(config=config)

sess.run(tf.global_variables_initializer())

print("=&gt; Check forward")
for i in range(2):
    print("=&gt; Check GPU %d" % i)
    for j in range(len(rec_xs[i])):
        t = sess.run(rec_xs[i][j], feed_dict)[0]
        l1norm = np.sum(np.abs(t))
        print("=&gt; %s: %.5f" % (rec_names[i][j], l1norm))
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
My running log of test.py:
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0402 21:57:00.129247 139765947877184 deprecation.py:506] From /home/atlantix/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py:883: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0402 21:57:00.150027 139765947877184 deprecation.py:323] From test.py:15: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.
Instructions for updating:
Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:
```python
    sess = tf.Session()
    with sess.as_default():
        tensor = tf.range(10)
        print_op = tf.print(tensor)
        with tf.control_dependencies([print_op]):
          out = tf.add(tensor, tensor)
        sess.run(out)
    ```
Additionally, to use tf.print in python 2.7, users must make sure to import
the following:

  `from __future__ import print_function`

2019-04-02 21:57:00.195153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-04-02 21:57:00.626301: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55bf73aa0640 executing computations on platform CUDA. Devices:
2019-04-02 21:57:00.626354: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 21:57:00.626368: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (1): GeForce GTX TITAN X, Compute Capability 5.2
2019-04-02 21:57:00.649925: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299805000 Hz
2019-04-02 21:57:00.653093: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x55bf73a9fad0 executing computations on platform Host. Devices:
2019-04-02 21:57:00.653157: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-04-02 21:57:00.653809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:08:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 21:57:00.654269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 1 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:09:00.0
totalMemory: 11.93GiB freeMemory: 11.81GiB
2019-04-02 21:57:00.654961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0, 1
2019-04-02 21:57:00.655060: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-04-02 21:57:01.477672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-02 21:57:01.477727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 1 
2019-04-02 21:57:01.477757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N Y 
2019-04-02 21:57:01.477767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 1:   Y N 
2019-04-02 21:57:01.478354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11422 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:08:00.0, compute capability: 5.2)
2019-04-02 21:57:01.478791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11422 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0, compute capability: 5.2)
2019-04-02 21:57:01.487682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
=&gt; Check forward
=&gt; Check GPU 0
2019-04-02 21:57:01.527837: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
fc1/weight_bias: [8.01475811][0]
=&gt; fc1: 1.84453
fc1/weight_bias: [8.01475811][0]
fc2/weight_bias: [2.51356649][0]
=&gt; fc2: 0.19745
=&gt; Check GPU 1
fc1/weight_bias: [8.01475811][0]
=&gt; fc1: 0.00000
fc1/weight_bias: [8.01475811][0]
fc2/weight_bias: [2.51356649][0]
=&gt; fc2: 0.00000
&lt;/denchmark-code&gt;

As for my GPUs, the driver version is 410.104, installed according to official instructions.
Hope it helps.
Could anybody help me ASAP? I am almost crazy with TF's multiple GPU.
Thank you very much!
	</description>
	<comments>
		<comment id='1' author='AtlantixJJ' date='2019-04-04T04:06:21Z'>
		why are you trying to use v2.0.0-alpha0-0-g2c319fb415 2.0.0-alpha0. if your code seems to be TF 1
		</comment>
		<comment id='2' author='AtlantixJJ' date='2019-04-04T04:43:12Z'>
		I am writing code like this because I want to see what the math operation is as clearly as possible. As for using TF2, it is just following up with the latest version.
		</comment>
		<comment id='3' author='AtlantixJJ' date='2019-04-04T16:26:45Z'>
		I can confirm you're not using the version of TF you claim to be using. The current 1.x nightly shows v1.12.0-11729-g98c3cfbf74 1.14.1-dev20190404 as the version string while you have the one from the 2.x alpha.
It also looks like your cuda installation is borked somehow. Have you tried using an nvidia provided docker image?
		</comment>
		<comment id='4' author='AtlantixJJ' date='2019-04-05T01:16:31Z'>
		I have tried nightly build and it seems to work:
=&gt; Check forward
=&gt; Check GPU 0
2019-04-04 17:40:19.590663: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1284] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-04-04 17:40:19.591831: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
fc1/weight_bias: [8.02037048][0]
=&gt; fc1: 2.59844
fc1/weight_bias: [8.02037048][0]
fc2/weight_bias: [2.84391737][0]
=&gt; fc2: 0.13365
=&gt; Check GPU 1
fc1/weight_bias: [8.02037048][0]
=&gt; fc1: 2.59844
fc1/weight_bias: [8.02037048][0]
fc2/weight_bias: [2.84391737][0]
=&gt; fc2: 0.13365
		</comment>
		<comment id='5' author='AtlantixJJ' date='2019-04-05T20:13:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27428&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27428&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>