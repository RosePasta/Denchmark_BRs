<bug id='34038' author='SumNeuron' open_date='2019-11-06T09:57:14Z' closed_time='2019-12-13T00:44:42Z'>
	<summary>TF 2.0 distribution strategy throws invalid argument error</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): somewhat
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): DGX
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/z
TensorFlow installed from (source or binary): docker image
TensorFlow version (use command below): 2.0
Python version: 3.6
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version:  10.1
GPU model and memory:  Telsa V100-SXM2

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 

From the &lt;denchmark-link:https://www.tensorflow.org/guide/gpu#with_tfdistributestrategy&gt;docs&lt;/denchmark-link&gt;
:
tf.debugging.set_log_device_placement(True)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
  inputs = tf.keras.layers.Input(shape=(1,))
  predictions = tf.keras.layers.Dense(1)(inputs)
  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)
  model.compile(loss='mse',
                optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))
I adapted this (I hope correctly for multiple gpus)
gpus = tf.config.experimental.list_physical_devices('GPU')
gpus_to_use = gpus[-3:]

if gpus:
    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
    try:
        tf.config.experimental.set_visible_devices(gpus_to_use, 'GPU')
        for gpu in gpus_to_use:
            tf.config.experimental.set_memory_growth(gpu, True)        
            gb = 1024
            tf.config.experimental.set_virtual_device_configuration(
                gpu,
                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*gb)]
            )
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
    except RuntimeError as e:
        # Virtual devices must be set before GPUs have been initialized
        print(e)
which prints 8 Physical GPUs, 3 Logical GPUs as expected
Then, calling just this line:
strategy = tf.distribute.MirroredStrategy()
throws:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-18-2f6e99f3473c&gt; in &lt;module&gt;
----&gt; 1 strategy = tf.distribute.MirroredStrategy()

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, devices, cross_device_ops)
    354   def __init__(self, devices=None, cross_device_ops=None):
    355     extended = MirroredExtended(
--&gt; 356         self, devices=devices, cross_device_ops=cross_device_ops)
    357     super(MirroredStrategy, self).__init__(extended)
    358 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, container_strategy, devices, cross_device_ops)
    394                      "any local devices.")
    395     self._cross_device_ops = cross_device_ops
--&gt; 396     self._initialize_strategy(devices)
    397 
    398     # TODO(b/128995245): Enable last partial batch support in graph mode.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_strategy(self, devices)
    408         "No duplicates allowed in `devices` argument: %s" % (devices,))
    409     if _is_device_list_local(devices):
--&gt; 410       self._initialize_local(devices)
    411     else:
    412       self._initialize_multi_worker(devices)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_local(self, devices)
    418     self._input_workers = input_lib.InputWorkers(self._device_map)
    419     self._inferred_cross_device_ops = None if self._cross_device_ops else (
--&gt; 420         cross_device_ops_lib.choose_the_best(devices))
    421     self._host_input_device = numpy_dataset.SingleDevice("/cpu:0")
    422 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py in choose_the_best(devices, session_config)
   1194   """
   1195   requested_devices = set([device_util.canonicalize(d) for d in devices])
-&gt; 1196   machine_devices = device_lib.list_local_devices(session_config=session_config)
   1197   using_devices = set()
   1198   for d in machine_devices:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/device_lib.py in list_local_devices(session_config)
     39   return [
     40       _convert(s)
---&gt; 41       for s in pywrap_tensorflow.list_devices(session_config=session_config)
     42   ]

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py in list_devices(session_config)
   2247     return ListDevicesWithSessionConfig(session_config.SerializeToString())
   2248   else:
-&gt; 2249     return ListDevices()
   2250 
   2251 

InvalidArgumentError: device CUDA:0 not supported by XLA service
	while setting up XLA_GPU_JIT device number 0
&lt;/denchmark-code&gt;

Describe the expected behavior
It just works as in the docs
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
See above. Docker image tensorflow/tensorflow:2.0.0-gpu-py3-jupyter with nvidia-docker
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='SumNeuron' date='2019-11-28T13:57:40Z'>
		Hi guys, I have the same issue only using:
import tensorflow as tf

gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_visible_devices(gpus[0:2], 'GPU')

strategy = tf.distribute.MirroredStrategy()
		</comment>
		<comment id='2' author='SumNeuron' date='2019-12-13T00:44:42Z'>
		I just verified and I believe this is resolved in the nightly and the fix should be available in 2.1.0. Please let me know if you are able to still reproduce with the nightly or the 2.1.0-rc1 release.
		</comment>
		<comment id='3' author='SumNeuron' date='2019-12-13T00:44:44Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34038&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34038&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>