<bug id='42065' author='dtch1997' open_date='2020-08-05T15:04:35Z' closed_time='2020-08-11T04:35:03Z'>
	<summary>tensorflow.lite.python.convert.ConverterError: &amp;lt;unknown&amp;gt;:0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Tensorflow version: 2.3.0
TensorFlow installed from (source or binary): Binary (Anaconda)

Command used to run the converter or code if youâ€™re using the Python API
&lt;denchmark-code&gt;converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir,signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
quantized_model = converter.convert()
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;2020-08-05 14:53:54.038060: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:56.073223: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-05 14:53:58.130905: I tensorflow/stream_executor/cuda/cuda_gpu_exec
utor.cc:982] successful NUMA node read from SysFS had negative value (-1), 
but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.131826: I tensorflow/core/common_runtime/gpu/gpu_device
.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryB
andwidth: 223.96GiB/s
2020-08-05 14:53:58.131898: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.134264: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:53:58.136456: I tensorflow/stream_executor/platform/default/d
so_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:53:58.136904: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:53:58.139311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:53:58.140510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:53:58.145672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:53:58.145878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.146748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.147536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:53:58.147999: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-08-05 14:53:58.158009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz
2020-08-05 14:53:58.158281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558637af4d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-05 14:53:58.158342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-05 14:53:58.207301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.208313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558637b08a60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-05 14:53:58.208367: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2020-08-05 14:53:58.208657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.209465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-08-05 14:53:58.209534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.209670: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:53:58.209798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:53:58.209882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:53:58.209990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:53:58.210115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:53:58.210180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:53:58.210338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.211290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.212074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:53:58.212147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:53:58.765400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 14:53:58.765463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-08-05 14:53:58.765635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-08-05 14:53:58.766139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.767126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:53:58.767958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2020-08-05 14:54:09.899095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.899586: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2020-08-05 14:54:09.899811: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-08-05 14:54:09.900545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.900959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7
coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s
2020-08-05 14:54:09.901027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-05 14:54:09.901113: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-05 14:54:09.901170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-05 14:54:09.901247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-05 14:54:09.901349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-05 14:54:09.901427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-05 14:54:09.901501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-08-05 14:54:09.901648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.902096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.902468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-08-05 14:54:09.902524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-05 14:54:09.902550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-08-05 14:54:09.902571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-08-05 14:54:09.902728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.903208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-05 14:54:09.903590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10618 MB memory) -&gt; physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2020-08-05 14:54:10.067218: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-08-05 14:54:10.067284: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 2978 nodes (2644), 3263 edges (2922), time = 94.971ms.
2020-08-05 14:54:10.067309: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 1.906ms.
2020-08-05 14:54:13.144913: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-08-05 14:54:13.144989: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc("Func/StatefulPartitionedCall/input/_0"): error: requires all operands and results to have compatible element types
Traceback (most recent call last):
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py", line 196, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: &lt;unknown&gt;:0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types
&lt;unknown&gt;:0: note: loc("Func/StatefulPartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {device = ""} : (tensor&lt;1x?x?x3x!tf.quint8&gt;) -&gt; tensor&lt;1x?x?x3xui8&gt;


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "scratch.py", line 8, in &lt;module&gt;
    quantized_model = converter.convert()
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 1076, in convert
    return super(TFLiteConverterV2, self).convert()
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 899, in convert
    return super(TFLiteFrozenGraphConverterV2,
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/lite.py", line 629, in convert
    result = _toco_convert_impl(
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py", line 569, in toco_convert_impl
    data = toco_convert_protos(
  File "/opt/conda/envs/tf-detect/lib/python3.8/site-packages/tensorflow/lite/python/convert.py", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: &lt;unknown&gt;:0: error: loc("Func/StatefulPartitionedCall/input/_0"): requires all operands and results to have compatible element types
&lt;unknown&gt;:0: note: loc("Func/StatefulPartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {device = ""} : (tensor&lt;1x?x?x3x!tf.quint8&gt;) -&gt; tensor&lt;1x?x?x3xui8&gt;

&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5029227/model.zip&gt;model.zip&lt;/denchmark-link&gt;


Model architecture is SSD-Mobilenet V2 with input size of 96x96, created by Object Detection API
Model exported according to &lt;denchmark-link:https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model&gt;instructions&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='dtch1997' date='2020-08-05T15:04:56Z'>
		The fix from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/41877&gt;#41877&lt;/denchmark-link&gt;
 did not resolve this
		</comment>
		<comment id='2' author='dtch1997' date='2020-08-06T13:01:10Z'>
		+1
		</comment>
		<comment id='3' author='dtch1997' date='2020-08-06T17:26:31Z'>
		&lt;denchmark-link:https://github.com/dtch1997&gt;@dtch1997&lt;/denchmark-link&gt;

Please provide complete code to replicate the issue faced or if possible share a colab gist to replicate the issue reported.
		</comment>
		<comment id='4' author='dtch1997' date='2020-08-10T21:19:49Z'>
		&lt;denchmark-link:https://github.com/dtch1997&gt;@dtch1997&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/korabelnikov&gt;@korabelnikov&lt;/denchmark-link&gt;
 can you install  and try again? And also update the input shape?
Specifically this solution posted here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/42114#issuecomment-671593386&gt;#42114 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='dtch1997' date='2020-08-11T04:35:03Z'>
		Thanks! It worked after I installed tf-nightly.
		</comment>
		<comment id='6' author='dtch1997' date='2020-09-01T21:24:40Z'>
		Issue still exists for TF version 2.3.0 and EfficientDet model. Is anyone facing the same problem?
		</comment>
		<comment id='7' author='dtch1997' date='2020-09-03T18:09:12Z'>
		&lt;denchmark-link:https://github.com/smohan10&gt;@smohan10&lt;/denchmark-link&gt;
 We are tracking TFLite support for these models &lt;denchmark-link:https://github.com/tensorflow/models/issues/9033&gt;here&lt;/denchmark-link&gt;
. SSD-only for now, EfficientDet is work-in-progress.
		</comment>
	</comments>
</bug>