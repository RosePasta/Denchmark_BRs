<bug id='6586' author='danbergeland' open_date='2016-12-31T23:24:20Z' closed_time='2017-03-03T02:28:43Z'>
	<summary>Crash in  Jupyter Notebook with conv2d - stream-&amp;gt;parent()-&amp;gt;GetConvolveAlgorithms(&amp;algorithms)</summary>
	<description>
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

I have googled for the issue on several fronts and found nothing close since the Windows release.
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System:
Windows 7-64bit.  Intel i3-6100 (64-bit), 8 gb DDR4, nVidia GTX 750 ti 2gb,
nVidia GPU driver: 369.30
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
CUDA v8.0
cuDNN 5.1
jupyter notebook messages when importing tensorflow:
successfully loaded:
cublas64_80.dll
cudnn64_5.dll
cufft64_80.dll
nvcuda.dll
curand64_80.dll
Found device 0 with properties:
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.1105
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.65GiB
DMA:0
0: Y
Creating TensorFlow device ...
If installed from binary pip package, provide:

A link to the pip package you installed:
I used the default: pip install tensorflow as described on their website.
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.12.0-rc0

&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

I built and tested this jupyter notebook WITHOUT gpu support.  It already builds and runs correctly (as in, have trained and optimized a network).  Now I'm trying to get it to work with gpu to speed it up.
Here's the step in the notebook that causes the issue.  Prior to this, tensorFlow is imported successfully as tf.  This is the first session it's running.  the 'training_operation' uses conv2d.
`
##run Training
with tf.Session() as sess:
sess.run(tf.global_variables_initializer())
num_examples = len(X_train)
&lt;denchmark-code&gt;print("Training...")
print()
for i in range(EPOCHS):
    X_train, y_train = shuffle(X_train, y_train)
    for offset in range(0, num_examples, BATCH_SIZE):
        end = offset + BATCH_SIZE
        batch_x, batch_y = X_train[offset:end], y_train[offset:end]
        sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})
        
    validation_accuracy = evaluate(X_validation, y_validation)
    print("EPOCH {} ...".format(i+1))
    print("Validation Accuracy = {:.3f}".format(validation_accuracy))
    print()
    
saver.save(sess, './lenetTrafficSign')
print("Model saved")`
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

I saw a similar issue in a pre-windows version that suggested it had something to do with memory.
I tried adding the following before the tensorflow session:
config = tf.ConfigProto() config.gpu_options.per_process_gpu_memory_fraction = 0.4 with tf.Session() as sess: sess.run(tf.global_variables_initializer())
It did not resolve the issue.
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
The error is as follows, when trying to run the session:
&lt;denchmark-link:https://cloud.githubusercontent.com/assets/7866171/21579570/f25e4a0c-cf7d-11e6-8136-1f8b681e3dcd.png&gt;&lt;/denchmark-link&gt;

The plain text at the last three lines are:
cuda_event.cc:49]Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED
gpu_event_mgr.cc:190] Unexpected Event Status: 1
cuda_dnn.cc:305] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
conv_ops.cc:532] Check failed: stream-&gt;parent()-&gt;GetConvolveAlgorithms(&amp;algorithms)
A few seconds after the script crashes, the screen goes black and the video driver resets.
	</description>
	<comments>
		<comment id='1' author='danbergeland' date='2017-01-04T01:27:05Z'>
		Can you provide a reproducible example? (ie, the model) This error can happen when you give 0 dimensions to conv2d
		</comment>
		<comment id='2' author='danbergeland' date='2017-01-04T02:57:28Z'>
		I'm sure it's not the issue.  The code works fine on Windows using CPU.  Since I've posted this, I've installed Ubuntu and the same code, with no changes, runs just fine on tensorflow with GPU support.
		</comment>
		<comment id='3' author='danbergeland' date='2017-01-04T22:07:55Z'>
		I have the exact same problem on a MacBook using its internal GPU (macOS 10.12, Xcode 8.2 overridden by Command Line Tools 7.3.1). I have CUDA 8.0, cuDNN 5.1, and Tensorflow 0.12.1 installed via pip install tensorflow-gpu.
The first error is either CUDNN_STATUS_INTERNAL_ERROR or CUDNN_STATUS_NOT_INITIALIZED. In the latter case, an additional message error retrieving driver version: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got "" is output. Tensorflow is imported normally, but Python crashes when I run a session that uses convolutional neural networks (CNN).
Additionally, I tried compiling Tensorflow from the source, but the same error persists. I also tried uninstalling CUDA 8.0 and installing CUDA 7.5, and reinstalled cuDNN and Tensorflow. The problem persists. This is very annoying.
		</comment>
		<comment id='4' author='danbergeland' date='2017-01-06T00:50:04Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 this seems to be Windows-specific. Any ideas?
		</comment>
		<comment id='5' author='danbergeland' date='2017-01-06T01:17:20Z'>
		Can you try upgrading TensorFlow to the latest release version (0.12.1) and upgrading your drivers to the latest version (376.33, as far as I can tell), then see if the problem persists?
		</comment>
		<comment id='6' author='danbergeland' date='2017-01-06T01:18:35Z'>
		&lt;denchmark-link:https://github.com/ymfa&gt;@ymfa&lt;/denchmark-link&gt;
 It sounds like you might be experiencing a different problem with the Mac OS GPU support. Can you please open a separate issue?
		</comment>
		<comment id='7' author='danbergeland' date='2017-01-06T19:44:01Z'>
		Is it possible this is the same issue as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6509&gt;#6509&lt;/denchmark-link&gt;
 ?
		</comment>
		<comment id='8' author='danbergeland' date='2017-02-06T21:25:49Z'>
		This seems to be related to the issue as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6509&gt;#6509&lt;/denchmark-link&gt;
 as &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 mentioned.

I had the same problem then I changed the tf.one_hot() to a custom solution as mentioned by @name-name in #6509, the problem went away. May be it might work for this.

		</comment>
		<comment id='9' author='danbergeland' date='2017-02-06T22:18:49Z'>
		You can also upgrade your TF version to 1.0.0rc1 to resolve the problem.
		</comment>
		<comment id='10' author='danbergeland' date='2017-03-03T02:28:41Z'>
		It's tied to the tf.one_hot() issue.
		</comment>
		<comment id='11' author='danbergeland' date='2019-02-05T17:36:13Z'>
		
It's tied to the tf.one_hot() issue.

&lt;denchmark-link:https://github.com/danbergeland&gt;@danbergeland&lt;/denchmark-link&gt;
 did you solve the problem ?
		</comment>
		<comment id='12' author='danbergeland' date='2019-02-05T19:24:42Z'>
		&lt;denchmark-link:https://github.com/ricardobnjunior&gt;@ricardobnjunior&lt;/denchmark-link&gt;
  I believe it was resolved with release version 1.0.  I no longer have this setup to verify, as this was 2 years ago.
		</comment>
	</comments>
</bug>