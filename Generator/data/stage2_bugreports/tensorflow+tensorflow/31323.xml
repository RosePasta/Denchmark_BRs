<bug id='31323' author='bjornsing' open_date='2019-08-04T19:03:14Z' closed_time='2020-03-30T10:15:56Z'>
	<summary>Passing a callable learning_rate to Adam optimizer does not work as documented</summary>
	<description>
tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
TensorFlow installed from (source or binary): binary through pip3
TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
Python version: sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)
Bazel version (if compiling from source): n/a
GCC/Compiler version (if compiling from source): n/a
CUDA/cuDNN version: 10.0.130_410.48 / 10.0-linux-x64-v7.4.2.24
GPU model and memory: GeForce GTX 1080 with 7598 MB memory

Describe the current behavior
The Adam optimizer does not seem to keep calling the supplied learning_rate callable. It seems like it's being called once or a few times, but then a "cached" value is repeatedly used in updates.
Describe the expected behavior
According to the &lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers/Adam&gt;documentation&lt;/denchmark-link&gt;
 it should be possible to pass a "callable that takes no arguments and returns the actual value to use" as learning_rate to tf.keras.optimizers.Adam(), and this "can be useful for changing these values across different invocations of optimizer functions".
My expectation was that the Adam optimizer would keep calling the supplied callable at each update (i.e. from within apply_gradients()).
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION)

import sys
print(sys.version_info)

tf_a = tf.Variable(1.0)
print('Variable tf_a initialized to {}.'.format(tf_a.numpy()))

lr = 0.1
def get_lr():
    global lr
    return lr

tf_opt = tf.keras.optimizers.Adam(learning_rate=get_lr)

@tf.function
def train_step():
    with tf.GradientTape() as tf_tape:
        tf_loss = tf_a**2
        
    tf_gradients = tf_tape.gradient(tf_loss, [tf_a])

    tf_opt.apply_gradients(zip(tf_gradients, [tf_a]))

print('After one step with learning rate {}... '.format(get_lr()), end='')
train_step()
print('Variable tf_a is {}.'.format(tf_a.numpy()))

lr = 0.0

for _ in range(10):
    print('After another step, now with learning rate {}... '.format(get_lr()), end='')
    train_step()
    print('Variable tf_a is {}.'.format(tf_a.numpy()))
&lt;/denchmark-code&gt;

The code above produces the following output on my system:
&lt;denchmark-code&gt;v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
sys.version_info(major=3, minor=5, micro=6, releaselevel='final', serial=0)
Variable tf_a initialized to 1.0.
After one step with learning rate 0.1... Variable tf_a is 0.8999971747398376.
After another step, now with learning rate 0.0... Variable tf_a is 0.8004083633422852.
After another step, now with learning rate 0.0... Variable tf_a is 0.7015821933746338.
After another step, now with learning rate 0.0... Variable tf_a is 0.6039347052574158.
After another step, now with learning rate 0.0... Variable tf_a is 0.5079591274261475.
After another step, now with learning rate 0.0... Variable tf_a is 0.41423195600509644.
After another step, now with learning rate 0.0... Variable tf_a is 0.3234161138534546.
After another step, now with learning rate 0.0... Variable tf_a is 0.23625943064689636.
After another step, now with learning rate 0.0... Variable tf_a is 0.1535806804895401.
After another step, now with learning rate 0.0... Variable tf_a is 0.07624538242816925.
After another step, now with learning rate 0.0... Variable tf_a is 0.005127914249897003.
&lt;/denchmark-code&gt;

As you can see tf_a keeps changing at a fast pace. My expectation was that after setting the learning rate to 0.0 updates would no-longer change tf_a.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='bjornsing' date='2019-08-05T11:55:35Z'>
		Could reproduce the issue with TF Version 2.0.0 beta. Gist is attached in this file, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3467436/LR_Issue_31323.ipynb.zip&gt;LR_Issue_31323.ipynb.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='bjornsing' date='2019-08-09T15:13:13Z'>
		It looks like things get completely different behavior w/ and w/o tf.function
		</comment>
		<comment id='3' author='bjornsing' date='2019-08-09T16:02:43Z'>
		I don't think this is particularly an optimizer problem, it seems that function wouldn't respect callables,
i.e., the simplest code to reproduce that:
lr = 0.1
def get_lr():
  global lr
  return lr
@tf.function
def train_step():
  val = get_lr()
  return val
print('After one step with learning rate {}... '.format(get_lr()))
print('return value is {}'.format(train_step()))

lr = 0.0

for _ in range(10):
    print('After another step, now with learning rate {}... '.format(get_lr()))
    print('return value is {}'.format(train_step()))
		</comment>
		<comment id='4' author='bjornsing' date='2019-08-09T16:06:02Z'>
		The output to above code is:
After one step with learning rate 0.1...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
After another step, now with learning rate 0.0...
return value is 0.10000000149011612
		</comment>
		<comment id='5' author='bjornsing' date='2019-08-24T15:27:22Z'>
		is there a workaround for this ? I just stumbled upon the same problem..
EDIT: For people with the same issue: optimizer.learning_rate.assign(0.0) seems to do the trick for @tf.functions
		</comment>
		<comment id='6' author='bjornsing' date='2020-03-17T17:58:08Z'>
		&lt;denchmark-link:https://github.com/bjornsing&gt;@bjornsing&lt;/denchmark-link&gt;
 I think this was resolved in . I tried the above &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 code and the output is as follows. It returns updated learning rate as 0.0.
After one step with learning rate 0.1...
return value is Tensor("PartitionedCall:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_1:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_2:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_3:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_4:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_5:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_6:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_7:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_8:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_9:0", shape=(), dtype=float32)
After another step, now with learning rate 0.0...
return value is Tensor("PartitionedCall_10:0", shape=(), dtype=float32)
Please close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='7' author='bjornsing' date='2020-03-18T09:06:10Z'>
		Thanks &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 !
		</comment>
		<comment id='8' author='bjornsing' date='2020-03-30T10:15:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31323&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31323&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='bjornsing' date='2020-06-11T08:28:41Z'>
		
I don't think this is particularly an optimizer problem, it seems that function wouldn't respect callables,
i.e., the simplest code to reproduce that:
lr = 0.1
def get_lr():
  global lr
  return lr
@tf.function
def train_step():
  val = get_lr()
  return val
print('After one step with learning rate {}... '.format(get_lr()))
print('return value is {}'.format(train_step()))

lr = 0.0

for _ in range(10):
    print('After another step, now with learning rate {}... '.format(get_lr()))
    print('return value is {}'.format(train_step()))

I tried &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 's code with latest  and , and it seems the problem is still unresovled.
		</comment>
	</comments>
</bug>