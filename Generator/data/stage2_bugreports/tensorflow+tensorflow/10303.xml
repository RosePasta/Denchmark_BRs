<bug id='10303' author='blake-varden' open_date='2017-05-30T21:37:53Z' closed_time='2017-06-14T03:56:30Z'>
	<summary>TensorflowDebugger does not dump Stack/Pack/Concat nodes</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 14.04
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
1.1
Bazel version (if compiling from source):
CUDA/cuDNN version:
8.0/5.1.5
GPU model and memory:
Titan X Pascal
Exact command to reproduce:

&lt;denchmark-code&gt;import sys
import tensorflow as tf
from tensorflow.python import debug as tf_debug

base = tf.ones([10], dtype=tf.float32, name='base')
stacked = tf.stack([base, base], name='stacked')
concat = tf.concat([[base], [base]], axis=0, name='concat')

session = tf.Session()
session = tf_debug.LocalCLIDebugWrapperSession(session)

with session.as_default():
    res = session.run([ stacked, concat])
print res
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When using the TensorflowDebugger with stacked/concated, the stacked/concated nodes do not appear in the set of dumped nodes once a run has completed.  In addition nodes that fed into these nodes are not dumped.
	</description>
	<comments>
		<comment id='1' author='blake-varden' date='2017-05-31T00:00:38Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 : Mind taking a look?
		</comment>
		<comment id='2' author='blake-varden' date='2017-05-31T00:36:46Z'>
		&lt;denchmark-link:https://github.com/blake-varden&gt;@blake-varden&lt;/denchmark-link&gt;
 This is not a bug. The reason why you see no data dumped is because every node is constant folded in the graph set up by your code.  defines a TF constant. So all the downstream tensors like  and  are effectively constant. TF's graph optimization knows that and folds all nodes into one for each fetched tensor.
If you replace tf.ones with a tf.Variable, you'll see the data dumped:
import numpy as np
import tensorflow as tf
from tensorflow.python import debug as tf_debug

base = tf.Variable(np.ones([10]), dtype=tf.float32, name="base")
stacked = tf.stack([base, base], name='stacked')
concat = tf.concat([[base], [base]], axis=0, name='concat')

session = tf.Session()
session.run(tf.global_variables_initializer())

session = tf_debug.LocalCLIDebugWrapperSession(session)
res = session.run([ stacked, concat])
This behavior is documented in a relatively obscure place:
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tfdbg/watch_graph&gt;https://www.tensorflow.org/api_docs/python/tfdbg/watch_graph&lt;/denchmark-link&gt;


N.B.: 1. Under certain circumstances, the Tensor may not get actually watched (e.g., if the node of the Tensor is constant-folded during runtime).

For more on constant folding in TF, see:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L83&lt;/denchmark-link&gt;

and
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/OptimizerOptions&gt;https://www.tensorflow.org/api_docs/python/tf/OptimizerOptions&lt;/denchmark-link&gt;

TFDBG is working as intended as I just checked in the tensorflow/tensorflow:nightly docker image.
		</comment>
		<comment id='3' author='blake-varden' date='2017-05-31T00:42:32Z'>
		Re-opening the issue as a doc bug. I plan to add a Q&amp;A item for this behavior.
		</comment>
	</comments>
</bug>