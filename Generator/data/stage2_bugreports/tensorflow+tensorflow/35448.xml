<bug id='35448' author='dhakrasp' open_date='2019-12-27T12:36:39Z' closed_time='2020-01-02T17:25:35Z'>
	<summary>tf.keras.layers.Reshape not working as expected</summary>
	<description>
System information

Ubuntu 18.043 LTS
TensorFlow installed using pip
TensorFlow version '2.0.0' (CPU version)
Python version 3.6.9

Describe the current behavior
The sample code show below give following (partial) output and exception:
&lt;denchmark-code&gt;(400, 100)
(2, 200, 100)
Lambda reshape worked!
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-54-e2fee5681321&gt; in &lt;module&gt;
     12 print(out_1.shape)
     13 print('Lambda reshape worked!')
---&gt; 14 reshape_layer(inp)

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    889           with base_layer_utils.autocast_context_manager(
    890               self._compute_dtype):
--&gt; 891             outputs = self.call(cast_inputs, *args, **kwargs)
    892           self._handle_activity_regularization(inputs, outputs)
    893           self._set_mask_metadata(inputs, outputs, input_masks)

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py in call(self, inputs)
    469   def call(self, inputs):
    470     return array_ops.reshape(inputs,
--&gt; 471                              (array_ops.shape(inputs)[0],) + self.target_shape)
    472 
    473   def get_config(self):

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in reshape(tensor, shape, name)
    129     A `Tensor`. Has the same type as `tensor`.
    130   """
--&gt; 131   result = gen_array_ops.reshape(tensor, shape, name)
    132   tensor_util.maybe_set_static_shape(result, shape)
    133   return result

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in reshape(tensor, shape, name)
   8104       try:
   8105         return reshape_eager_fallback(
-&gt; 8106             tensor, shape, name=name, ctx=_ctx)
   8107       except _core._SymbolicException:
   8108         pass  # Add nodes to the TensorFlow graph.

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in reshape_eager_fallback(tensor, shape, name, ctx)
   8142   _attrs =
 ("T", _attr_T, "Tshape", _attr_Tshape)
   8143   _result = _execute.execute(b"Reshape", 1, inputs=_inputs_flat, attrs=_attrs,
-&gt; 8144                              ctx=_ctx, name=name)
   8145   _execute.record_gradient(
   8146       "Reshape", _inputs_flat, _attrs, _result, name)

~/code/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---&gt; 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~/code/venv/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Input to reshape is a tensor with 40000 values, but the requested shape has 8000000 [Op:Reshape]
&lt;/denchmark-code&gt;

Describe the expected behavior
Defined Reshape layer should reshape the input of shape (400, 100) to a tensor of shape (2, 200, 100)
Wrapping tf.reshape in a Lambda layer is working as an alternative solution
Code to reproduce the issue
from tensorflow.keras.layers import Reshape, Lambda
import tensorflow as tf

max_len = 200
char_hidden_dim = 50
reshape_layer = Reshape((max_len, 2 * char_hidden_dim,))
lambda_reshape_layer = Lambda(lambda x: tf.reshape(x, shape=[-1, max_len, 2 * char_hidden_dim]))

n_samples = 400
dim = 100
inp = np.zeros((n_samples, dim), dtype=np.float32)
print(inp.shape)

out_1 = lambda_reshape_layer(inp)
print(out_1.shape)
print('Lambda reshape worked!')
reshape_layer(inp)
Do I have a flawed understanding of the Reshape layer or can someone confirm that it is indeed a bug?
Please help :)
	</description>
	<comments>
		<comment id='1' author='dhakrasp' date='2019-12-28T04:38:30Z'>
		&lt;denchmark-link:https://github.com/dhakrasp&gt;@dhakrasp&lt;/denchmark-link&gt;
 This is not a bug.
First, the Reshape layer would not change your "batch size",  which is 400 in your example.
Second, the total element number in each sample should keep the same.  Your "inp" has too few element. See the modified example.
&lt;denchmark-code&gt;max_len = 200
char_hidden_dim = 50
reshape_layer = Reshape((max_len, 4 * char_hidden_dim))
lambda_reshape_layer = Lambda(
  lambda x: tf.reshape(x, shape=[-1, max_len, 2 * char_hidden_dim])
)

n_samples = 400
dim = 100
inp = np.zeros((1, n_samples, dim), dtype=np.float32)
print(inp.shape)

out_1 = lambda_reshape_layer(inp)
print(out_1.shape)
print('Lambda reshape worked!')
print(reshape_layer(inp).shape)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='dhakrasp' date='2019-12-30T05:17:26Z'>
		&lt;denchmark-link:https://github.com/SummerRainET2008&gt;@SummerRainET2008&lt;/denchmark-link&gt;
 ,
Understood the design and functionality of Reshape. I assumed it would change the batch_size too.
The reason to change the batch_size was that while feeding the character level inputs I was appending the character level inputs of multiple words (the actual i/p to the model).
e.g.
1 batch = 2 sentences
1 sentence = 200 words
1 word = 50 characters
1 char = 50 dim vector
Initial input --&gt;
2 x 200 x 50 x 50
~=400 x 50 x 50
This is the input to a Char-BiLSTM
Output of Char-BiLSTM --&gt;
400 x 100
~= 2 x 200 x 100
Is my Lambda layer the correct way implement this? If not, could you suggest a solution?
		</comment>
		<comment id='3' author='dhakrasp' date='2019-12-31T10:16:29Z'>
		Could able to reproduce the issue with Tf 2.0. Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/9e3195f0cf0bf39c5a0b225f798248a5/untitled334.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='dhakrasp' date='2020-01-02T17:25:35Z'>
		This question is better asked on &lt;denchmark-link:http://stackoverflow.com/questions/tagged/tensorflow&gt;StackOverflow&lt;/denchmark-link&gt;
 since it is not a bug or feature request. There is also a larger community that reads questions there.
Thanks!
		</comment>
		<comment id='5' author='dhakrasp' date='2020-01-02T17:25:37Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35448&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35448&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>