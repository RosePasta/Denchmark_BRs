<bug id='31114' author='wosiu' open_date='2019-07-28T15:14:58Z' closed_time='2019-11-19T16:42:06Z'>
	<summary>TFLite No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int)</summary>
	<description>
System information

OS Platform and Distribution: Android 5.1.1, API 22
Mobile device: Xiaomi Redmi 3
TensorFlow installed from: official binary
TensorFlow version : tensorflow-lite:1.14.0

Describe the current behavior
Tensorflow-lite 1.13.1 works fine on all devices I tested. Whereas tensorflow-lite 1.14.0 is broken for Xiaomi Redmi 3 (Android 5.1.1, API 22), other devices are ok.
I get a runtime error when Interpreter is created.
Describe the expected behavior
No error.
Code to reproduce the issue
&lt;denchmark-code&gt;interpreter = new Interpreter(tfliteModel, null);
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;W/linker: /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6ffffffe arg 0x2020
    /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6fffffff arg 0x3
E/art: dlopen("/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so", RTLD_LAZY) failed: dlopen failed: cannot locate symbol "__register_atfork" referenced by "/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so"...
W/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol "__register_atfork" referenced by "/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so"...
W/linker: /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6ffffffe arg 0x2020
    /data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so: unused DT entry: type 0x6fffffff arg 0x3
E/art: dlopen("/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so", RTLD_LAZY) failed: dlopen failed: cannot locate symbol "__register_atfork" referenced by "/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so"...
W/System.err: TensorFlowLite: failed to load native library: dlopen failed: cannot locate symbol "__register_atfork" referenced by "/data/app/eu.yesse.readerdemo.debug-2/lib/arm64/libtensorflowlite_jni.so"...
E/art: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)
D/AndroidRuntime: Shutting down VM
E/AndroidRuntime: FATAL EXCEPTION: main
    Process: eu.yesse.readerdemo.debug, PID: 12710
    java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)
        at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.&lt;init&gt;(NativeInterpreterWrapper.java:58)
        at org.tensorflow.lite.Interpreter.&lt;init&gt;(Interpreter.java:224)
        at eu.yesse.reader.commons.internal.detector.BlockingCornersClassSingleDetector.&lt;init&gt;(BlockingCornersClassSingleDetector.java:76)
        at eu.yesse.reader.commons.internal.detector.BlockingCornersClassMultiDetector.&lt;init&gt;(BlockingCornersClassMultiDetector.java:25)
        at eu.yesse.reader.commons.shared.detector.AsyncCornersClassMultiDetectorImpl.&lt;init&gt;(AsyncCornersClassMultiDetectorImpl.java:36)
        at eu.yesse.reader.tempregdoc.internal.TempRegDocReaderManager.createDetector(TempRegDocReaderManager.java:79)
        at eu.yesse.reader.tempregdoc.internal.TempRegDocReaderManager.&lt;init&gt;(TempRegDocReaderManager.java:48)
        at eu.yesse.reader.TempRegDocReader.getReader(TempRegDocReader.java:20)
        at eu.yesse.readerdemo.activities.TempRegDocActivity.onCreate(TempRegDocActivity.java:24)
        at android.app.Activity.performCreate(Activity.java:6093)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1106)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2295)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2404)
        at android.app.ActivityThread.access$900(ActivityThread.java:154)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1315)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:135)
        at android.app.ActivityThread.main(ActivityThread.java:5296)
        at java.lang.reflect.Method.invoke(Native Method)
        at java.lang.reflect.Method.invoke(Method.java:372)
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:912)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:707)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='wosiu' date='2019-07-29T06:55:43Z'>
		Did you solve it?
Firebase crashlytics reports this issue for Android 5 users of my app
I added Tensorflow like this:
&lt;denchmark-code&gt;implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
&lt;/denchmark-code&gt;

Fatal Exception: java.lang.UnsatisfiedLinkError No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)
		</comment>
		<comment id='2' author='wosiu' date='2019-07-29T10:44:25Z'>
		
Did you solve it?

&lt;denchmark-link:https://github.com/anonym24&gt;@anonym24&lt;/denchmark-link&gt;
 nope :( I guess we can't do much about it without a fix in tf. BTW I guess you should not put both  and  in your gradle file at the same time (?). But that's not the issue here anyway...
From crashlitics: does the crash affects only Android 5. and all of them?
		</comment>
		<comment id='3' author='wosiu' date='2019-07-29T11:07:25Z'>
		&lt;denchmark-link:https://github.com/wosiu&gt;@wosiu&lt;/denchmark-link&gt;
 yes, we need them both: &lt;denchmark-link:https://www.tensorflow.org/lite/performance/gpu&gt;https://www.tensorflow.org/lite/performance/gpu&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/8851301/62043870-2fa0df80-b20a-11e9-9c14-d56096189366.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='wosiu' date='2019-07-29T13:37:34Z'>
		&lt;denchmark-link:https://github.com/wosiu&gt;@wosiu&lt;/denchmark-link&gt;

in my case, yes (only Android 5):
&lt;denchmark-link:https://user-images.githubusercontent.com/8851301/62052901-29692e00-b21f-11e9-8b3a-fee666ab05f1.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='wosiu' date='2019-08-07T01:21:21Z'>
		&lt;denchmark-link:https://github.com/liyunlu0618&gt;@liyunlu0618&lt;/denchmark-link&gt;
 are there any updates on that?
		</comment>
		<comment id='6' author='wosiu' date='2019-08-23T10:07:11Z'>
		I also encounter this problem, I resolve this by reconfigure my ndk abifilter settings. My project originally was only built for 'armeabi' architecture. When I add any other abi options, it works like a charm. However, I'm still confused because on the tutorial page of Tensorflow Lite, it says that the library support all kinds of architecture(which should include armeabi). Or is it because arm support was removed in ndk r17? Hope someone can help me to find a workaround for tflite to run on armeabi devices.
		</comment>
		<comment id='7' author='wosiu' date='2019-09-06T03:02:54Z'>
		Did anyone find solution for this? I am also facing the same issue.
I tested in Oneplus3.
2019-09-06 08:28:18.799 15233-15233/ai.fritz.tflitedemo E/ritz.tflitedem: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)
2019-09-06 08:28:18.802 15233-15233/ai.fritz.tflitedemo E/AndroidRuntime: FATAL EXCEPTION: main
Process: ai.fritz.tflitedemo, PID: 15233
java.lang.UnsatisfiedLinkError: No implementation found for long org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(int) (tried Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter and Java_org_tensorflow_lite_NativeInterpreterWrapper_createErrorReporter__I)
at org.tensorflow.lite.NativeInterpreterWrapper.createErrorReporter(Native Method)
Gradle:
implementation 'org.tensorflow:tensorflow-lite:0.1.2-nightly'
implementation 'org.tensorflow:tensorflow-lite:0.1'
implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly'
		</comment>
		<comment id='8' author='wosiu' date='2019-09-19T14:03:39Z'>
		Any update on this? I'm also facing the same issue on 1.14.0
		</comment>
		<comment id='9' author='wosiu' date='2019-09-21T15:53:08Z'>
		I'm also got this crash
		</comment>
		<comment id='10' author='wosiu' date='2019-09-23T10:15:16Z'>
		I had a similar issue from NDK, namely that arm64 Android 5.x devices failed to load the shared library libtensorflowlite.so because of __register_atfork being missing.
The problem is that for at least arm64, __register_atfork usage is somehow generated in the shared library, but &lt;denchmark-link:https://android.googlesource.com/platform/bionic/+/master/android-changes-for-ndk-developers.md&gt;this function is introduced in Android 6&lt;/denchmark-link&gt;
. As suggested in the link, I tried compiling with lower NDK target API level, but this didn't seem to help. I also tried searching for "atfork" in tensorflow lite's source code, but couldn't find any.
Workaround for at least NDK users: Disassembling libtensorflowlite.so left an impression that __register_atfork is only called while reporting errors, so at least theoretically it shouldn't be called in production anyway. The workaround was thus to introduce fake __register_atfork() declaration and definition in cpp and h files, so that linker wouldn't complain anymore. So I put
&lt;denchmark-code&gt;extern "C" {
    int __register_atfork(void (*prepare) (void), void (*parent) (void), void (*child) (void), void *__dso_handle);
}
&lt;/denchmark-code&gt;

into tensorflow/lite/util.h, and
&lt;denchmark-code&gt;#include &lt;cassert&gt;
extern "C" {
    int __register_atfork(void (*prepare) (void), void (*parent) (void), void (*child) (void), void *__dso_handle) {
        assert(0 &amp;&amp; "Using dummy __register_atfork(). This is dangerous, so asserting.");
        return 0; // Avoid warning
    }
}
&lt;/denchmark-code&gt;

into tensorflow/lite/util.cc (the exact files aren't important, the definition just has to be compiled and linked to libtensorflowlite.so) and recompiled. After that neural networks seem to work fine on all devices. I guess something similar should work for JNI users as well.
		</comment>
		<comment id='11' author='wosiu' date='2019-10-19T12:40:38Z'>
		I had the same issue. I fixed it by adding
&lt;denchmark-code&gt;ndk {
            abiFilters "armeabi-v7a", "x86"
        }
&lt;/denchmark-code&gt;

to the defaultConfig in app/build.gradle file.
		</comment>
		<comment id='12' author='wosiu' date='2019-10-19T13:31:31Z'>
		&lt;denchmark-link:https://github.com/kongaskristjan&gt;@kongaskristjan&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/FunmiKesa&gt;@FunmiKesa&lt;/denchmark-link&gt;
 - big thanks for investigating and sharing that! Said that, I feel propsed changes are more like workarounds and not solutions. It still would be nice to have a fix inside the tensorflow lib.
		</comment>
		<comment id='13' author='wosiu' date='2019-10-31T10:08:21Z'>
		Any updates on this? It's still happening on 1.15.0! This seems like a critical bug to me, tflite instantly crashes on some devices.
I will bump my minApi to 23 for a while, and later revert to 21 when this gets fixed :)
EDIT: Excluding 64bit architectures as some of you are doing is not a viable solution, Google Play store enforces all apps to support 64bit since 1st of August 2019: &lt;denchmark-link:https://android-developers.googleblog.com/2019/01/get-your-apps-ready-for-64-bit.html&gt;https://android-developers.googleblog.com/2019/01/get-your-apps-ready-for-64-bit.html&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='wosiu' date='2019-11-15T22:05:47Z'>
		Hi all, apologies for the delayed response, just now seeing this issue.
We set our Android NDK API level to 18 when building, but it's possible there's something wrong with the config and it's assuming API 23. I'll take a look.
		</comment>
		<comment id='15' author='wosiu' date='2019-11-19T16:42:06Z'>
		This is fixed in the latest nightly, and we'll try to pull the fix in to the 2.1 release (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/34419&gt;#34419&lt;/denchmark-link&gt;
). Thanks again for your patience.
		</comment>
		<comment id='16' author='wosiu' date='2019-11-19T16:42:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31114&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31114&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='wosiu' date='2019-11-19T17:19:11Z'>
		Hi &lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
 , thanks for the fix. Just to understand how we can resolve this issue on android, would we be able to pull in the nightly build of TFL in gradle and have this fixed
&lt;denchmark-code&gt;dependencies: {
     implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
}
&lt;/denchmark-code&gt;

or do we have to also reconvert our models to TFL using the nightly build?
		</comment>
		<comment id='18' author='wosiu' date='2019-11-19T17:22:21Z'>
		&lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
 are you going to backport the fix to 1.* version?
		</comment>
		<comment id='19' author='wosiu' date='2019-11-19T17:31:53Z'>
		There won't be any backport, however, you can safely use the latest 2.x or nightly version with both 1.X and 2.X TF models.
		</comment>
		<comment id='20' author='wosiu' date='2019-11-19T22:03:02Z'>
		Hello &lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
, please show me what I need to put in gradle.build to use latest fix
		</comment>
		<comment id='21' author='wosiu' date='2019-11-19T22:33:01Z'>
		&lt;denchmark-link:https://github.com/runnableapps&gt;@runnableapps&lt;/denchmark-link&gt;

Answer:
&lt;denchmark-code&gt;dependencies: {
     implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
}
&lt;/denchmark-code&gt;

or wait for 2.1 release.
		</comment>
		<comment id='22' author='wosiu' date='2019-11-21T10:12:53Z'>
		implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
does not fix crash
		</comment>
		<comment id='23' author='wosiu' date='2019-11-21T17:30:55Z'>
		You might need to &lt;denchmark-link:https://stackoverflow.com/questions/23025433/how-to-clear-gradle-cache&gt;clear your gradle cache&lt;/denchmark-link&gt;
. I've manually inspected the &lt;denchmark-link:https://bintray.com/google/tensorflow/tensorflow-lite#files/org%2Ftensorflow%2Ftensorflow-lite%2F0.0.0-nightly&gt;nightly build&lt;/denchmark-link&gt;
 and verified that  is no longer referenced. There might be another issue with your usage, in which case please attach the log from adb.
		</comment>
		<comment id='24' author='wosiu' date='2019-12-21T11:25:12Z'>
		Got the same problem with org.tensorflow:tensorflow-lite:2.0.0
Device T8-PLUS, Android 5.1
		</comment>
		<comment id='25' author='wosiu' date='2019-12-26T18:21:07Z'>
		&lt;denchmark-link:https://github.com/alexeyvasilyev&gt;@alexeyvasilyev&lt;/denchmark-link&gt;
 the fix did not make it into 2.0, but it will be in the upcoming 2.1 release (expected to be finalized soon). In the meantime, please try the nightly build.
		</comment>
		<comment id='26' author='wosiu' date='2020-01-09T11:45:02Z'>
		&lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
 Thanks. Lets hope nightly build can sort out this issue in android 5.
		</comment>
		<comment id='27' author='wosiu' date='2020-01-09T18:06:28Z'>
		The 2.1 release is now available (org.tensorflow:tensorflow-lite:2.1.0), please give it a try.
		</comment>
		<comment id='28' author='wosiu' date='2020-01-10T05:07:22Z'>
		I confirm - 2.1.0 works on the device I originally issued the problem with :) Big thanks to all contributors! 🥇
		</comment>
	</comments>
</bug>