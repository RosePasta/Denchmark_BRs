<bug id='41133' author='bondhugula' open_date='2020-07-06T19:25:54Z' closed_time='2020-07-08T03:16:49Z'>
	<summary>[TF/MLIR] Graph pruning / canonicalization pass doesn't eliminate some dead constant nodes</summary>
	<description>
This is with the tensorflow trunk at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/e13ff2da43ab00dba94dd00d87a876b2a03f48e7&gt;e13ff2d&lt;/denchmark-link&gt;
 (Jul 6).
This is a reduced test case where both nodes/operations in the graph are supposed to be dead (results unused and not side-effecting), but neither the -tf-executor-graph-pruning nor the -canonicalize pass gets rid of them. However, if one of them is removed, -canonicalize is able to eliminate the other. Similar patterns are often DCE'd by -tf-executor-graph-pruning in the presence of other larger islands.
&lt;denchmark-code&gt;module {
  func @main() attributes {tf.entry_function = {control_outputs = "", inputs = "", outputs = ""}} {
    tf_executor.graph {
      %outputs, %control = tf_executor.island wraps "tf.Const"() {value = dense&lt;1&gt; : tensor&lt;1xi32&gt;} : () -&gt; tensor&lt;1xi32&gt;
      %outputs_0, %control_1 = tf_executor.island wraps "tf.Const"() {value = dense&lt;100&gt; : tensor&lt;1xi32&gt;} : () -&gt; tensor&lt;1xi32&gt;
      tf_executor.fetch
    }
    return
  }
}
&lt;/denchmark-code&gt;

To reproduce, run:
&lt;denchmark-code&gt;$ tf-opt -tf-executor-graph-pruning -canonicalize test_case.mlir
&lt;/denchmark-code&gt;

OS: CentOS 8 x86-64.
TF built from sources with GCC 8.3.1 and with --linkopt='-fuse-ld=lld'.
	</description>
	<comments>
		<comment id='1' author='bondhugula' date='2020-07-08T03:16:49Z'>
		Because if you import a graphdef without any fetch the pruning would just eliminate the entire graph, we rather not do anything: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/transforms/graph_pruning.cc#L90-L94&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/tensorflow/transforms/graph_pruning.cc#L90-L94&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='bondhugula' date='2020-07-08T03:16:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41133&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41133&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='bondhugula' date='2020-07-08T11:02:08Z'>
		On a narrow note, why would it be incorrect to eliminate everything here? Not having a fetch is still defined behavior, right? (I'm thinking about the multiple functions case - one of them could just be empty and completely removed. )
		</comment>
		<comment id='4' author='bondhugula' date='2020-07-10T03:34:03Z'>
		It'd may be correct for a tf function that does not return anything, but at the same time we're trying to move away from the executor dialect for TF2 and functions.
		</comment>
		<comment id='5' author='bondhugula' date='2020-07-12T21:41:40Z'>
		
It'd may be correct for a tf function that does not return anything, but at the same time we're trying to move away from the executor dialect for TF2 and functions.

I see. What would the new entry point then be when converting/importing from TF Graphdef?
		</comment>
		<comment id='6' author='bondhugula' date='2020-07-12T22:10:03Z'>
		Mainly SavedModel I think for loading from file.
When running online we're working on having the tracing tf.function directly build MLIR in the first place without going through the Graph data structure.
		</comment>
		<comment id='7' author='bondhugula' date='2020-07-13T09:18:08Z'>
		Please do keep the translation to tf.executor (convert_graph_def python binding) until the in-memory replacement (tracing tf.function) is available. Thanks!
		</comment>
		<comment id='8' author='bondhugula' date='2020-07-13T18:53:31Z'>
		SavedModel are style storing GraphDef (and will continue for a while): so the conversion to tf.executor will stay there for a while!
		</comment>
	</comments>
</bug>