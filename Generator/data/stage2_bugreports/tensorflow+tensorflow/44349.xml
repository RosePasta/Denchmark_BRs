<bug id='44349' author='SimonLBSoerensen' open_date='2020-10-27T13:11:51Z' closed_time='2020-11-02T07:50:32Z'>
	<summary>Model does not learn when using the GPU</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution: Linux Ubuntu 18.04.5 LTS (Bionic Beaver)
TensorFlow installed from: Conda
TensorFlow version: 2.2.0
Python version: 3.6.9
CUDA/cuDNN version: 10.1.243 / 7.6.5
GPU model and memory: RTX 3090 (24,265 MiB) (driver: 455.32.00)

&lt;denchmark-h:h3&gt;Describe the current behavior&lt;/denchmark-h&gt;

When using tensorflow with the CPU (tensorflow) the model achieves a test accuracy of +0.90 but when running the same code with the GPU (tensorflow-gpu) the model achieves a test accuracy of ~0.10. So it seems like the CPU version learns while the GPU version does not. The same problem is present when running another simple example code with keras.
&lt;denchmark-h:h3&gt;Describe the expected behavior&lt;/denchmark-h&gt;

I would expect the two version to have around the same test accuracy in the end. Or at least it would learn with the GPU version.
&lt;denchmark-h:h3&gt;Code to reproduce the issue&lt;/denchmark-h&gt;

I'm using the following code:
# Code from: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/tensorflow_v2/notebooks/3_NeuralNetworks/convolutional_network.ipynb

import tensorflow as tf
from tensorflow.keras import Model, layers
import numpy as np

print(tf.__version__)
print(tf.config.list_physical_devices('GPU'))

# MNIST dataset parameters.
num_classes = 10 # total classes (0-9 digits).

# Training parameters.
learning_rate = 0.001
training_steps = 200
batch_size = 128
display_step = 10

# Network parameters.
conv1_filters = 32 # number of filters for 1st conv layer.
conv2_filters = 64 # number of filters for 2nd conv layer.
fc1_units = 1024 # number of neurons for 1st fully-connected layer.


# Prepare MNIST data.
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# Convert to float32.
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)
# Normalize images value from [0, 255] to [0, 1].
x_train, x_test = x_train / 255., x_test / 255.

# Use tf.data API to shuffle and batch data.
train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)

# Create TF Model.
class ConvNet(Model):
    # Set layers.
    def __init__(self):
        super(ConvNet, self).__init__()
        # Convolution Layer with 32 filters and a kernel size of 5.
        self.conv1 = layers.Conv2D(32, kernel_size=5, activation=tf.nn.relu)
        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2.
        self.maxpool1 = layers.MaxPool2D(2, strides=2)

        # Convolution Layer with 64 filters and a kernel size of 3.
        self.conv2 = layers.Conv2D(64, kernel_size=3, activation=tf.nn.relu)
        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2.
        self.maxpool2 = layers.MaxPool2D(2, strides=2)

        # Flatten the data to a 1-D vector for the fully connected layer.
        self.flatten = layers.Flatten()

        # Fully connected layer.
        self.fc1 = layers.Dense(1024)
        # Apply Dropout (if is_training is False, dropout is not applied).
        self.dropout = layers.Dropout(rate=0.5)

        # Output layer, class prediction.
        self.out = layers.Dense(num_classes)

    # Set forward pass.
    def call(self, x, is_training=False):
        x = tf.reshape(x, [-1, 28, 28, 1])
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.dropout(x, training=is_training)
        x = self.out(x)
        if not is_training:
            # tf cross entropy expect logits without softmax, so only
            # apply softmax when not training.
            x = tf.nn.softmax(x)
        return x

# Build neural network model.
conv_net = ConvNet()


# Cross-Entropy Loss.
# Note that this will apply 'softmax' to the logits.
def cross_entropy_loss(x, y):
    # Convert labels to int 64 for tf cross-entropy function.
    y = tf.cast(y, tf.int64)
    # Apply softmax to logits and compute cross-entropy.
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)
    # Average loss across the batch.
    return tf.reduce_mean(loss)

# Accuracy metric.
def accuracy(y_pred, y_true):
    # Predicted class is the index of highest score in prediction vector (i.e. argmax).
    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))
    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)

# Stochastic gradient descent optimizer.
optimizer = tf.optimizers.Adam(learning_rate)


# Optimization process.
def run_optimization(x, y):
    # Wrap computation inside a GradientTape for automatic differentiation.
    with tf.GradientTape() as g:
        # Forward pass.
        pred = conv_net(x, is_training=True)
        # Compute loss.
        loss = cross_entropy_loss(pred, y)

    # Variables to update, i.e. trainable variables.
    trainable_variables = conv_net.trainable_variables

    # Compute gradients.
    gradients = g.gradient(loss, trainable_variables)

    # Update W and b following gradients.
    optimizer.apply_gradients(zip(gradients, trainable_variables))


# Run training for the given number of steps.
for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):
    # Run the optimization to update W and b values.
    run_optimization(batch_x, batch_y)

    if step % display_step == 0:
        pred = conv_net(batch_x)
        loss = cross_entropy_loss(pred, batch_y)
        acc = accuracy(pred, batch_y)
        print("step: %i, loss: %f, accuracy: %f" % (step, loss, acc))


# Test model on validation set.
pred = conv_net(x_test)
print("Test Accuracy: %f" % accuracy(pred, y_test))
&lt;denchmark-h:h3&gt;Other info / logs&lt;/denchmark-h&gt;

The output from the CPU version:
&lt;denchmark-code&gt;2.2.0
[]
2020-10-27 13:57:03.982255: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-10-27 13:57:04.003444: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 4149920000 Hz
2020-10-27 13:57:04.004916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556240ba48c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-27 13:57:04.004927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-27 13:57:04.004979: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
step: 10, loss: 1.765925, accuracy: 0.859375
step: 20, loss: 1.604248, accuracy: 0.906250
step: 30, loss: 1.642668, accuracy: 0.882812
step: 40, loss: 1.594136, accuracy: 0.937500
step: 50, loss: 1.557037, accuracy: 0.953125
step: 60, loss: 1.549416, accuracy: 0.937500
step: 70, loss: 1.530980, accuracy: 0.976562
step: 80, loss: 1.546553, accuracy: 0.937500
step: 90, loss: 1.518947, accuracy: 0.968750
step: 100, loss: 1.525878, accuracy: 0.953125
step: 110, loss: 1.492367, accuracy: 0.992188
step: 120, loss: 1.498649, accuracy: 0.984375
step: 130, loss: 1.515978, accuracy: 0.960938
step: 140, loss: 1.522711, accuracy: 0.976562
step: 150, loss: 1.496059, accuracy: 0.976562
step: 160, loss: 1.501745, accuracy: 0.976562
step: 170, loss: 1.488870, accuracy: 0.984375
step: 180, loss: 1.504619, accuracy: 0.992188
step: 190, loss: 1.480513, accuracy: 1.000000
step: 200, loss: 1.489994, accuracy: 0.984375
Test Accuracy: 0.976200

Process finished with exit code 0
&lt;/denchmark-code&gt;

The output from the GPU version:
&lt;denchmark-code&gt;2.2.0
2020-10-27 13:52:51.391410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-10-27 13:52:51.424025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.424711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2020-10-27 13:52:51.424829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-27 13:52:51.425678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-27 13:52:51.426660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-10-27 13:52:51.426788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-10-27 13:52:51.427656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-10-27 13:52:51.428145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-10-27 13:52:51.430066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-27 13:52:51.430149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.430858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.431506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2020-10-27 13:52:51.654160: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-10-27 13:52:51.659773: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 4149920000 Hz
2020-10-27 13:52:51.661105: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b3ed5bed50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-27 13:52:51.661115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-27 13:52:51.661262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.661963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:21:00.0 name: GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.86GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s
2020-10-27 13:52:51.661986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-27 13:52:51.661992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-27 13:52:51.661997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-10-27 13:52:51.662002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-10-27 13:52:51.662007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-10-27 13:52:51.662012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-10-27 13:52:51.662017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-27 13:52:51.662051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.662717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.663356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-10-27 13:52:51.663379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-27 13:52:51.720749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-27 13:52:51.720769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-10-27 13:52:51.720775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-10-27 13:52:51.720899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.721550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.722176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-27 13:52:51.722790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21939 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6)
2020-10-27 13:52:51.723983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b3ee94ec90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-27 13:52:51.723991: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 3090, Compute Capability 8.6
2020-10-27 13:52:52.629936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-27 13:52:54.157774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
step: 10, loss: 2.302645, accuracy: 0.101562
step: 20, loss: 2.302479, accuracy: 0.101562
step: 30, loss: 2.302398, accuracy: 0.125000
step: 40, loss: 2.302354, accuracy: 0.164062
step: 50, loss: 2.301157, accuracy: 0.140625
step: 60, loss: 2.301878, accuracy: 0.140625
step: 70, loss: 2.302341, accuracy: 0.109375
step: 80, loss: 2.303088, accuracy: 0.039062
step: 90, loss: 2.302307, accuracy: 0.085938
step: 100, loss: 2.302237, accuracy: 0.125000
step: 110, loss: 2.302458, accuracy: 0.125000
step: 120, loss: 2.301577, accuracy: 0.171875
step: 130, loss: 2.301929, accuracy: 0.109375
step: 140, loss: 2.302793, accuracy: 0.101562
step: 150, loss: 2.302621, accuracy: 0.125000
step: 160, loss: 2.302866, accuracy: 0.078125
step: 170, loss: 2.301470, accuracy: 0.164062
step: 180, loss: 2.301091, accuracy: 0.156250
step: 190, loss: 2.302170, accuracy: 0.132812
step: 200, loss: 2.302764, accuracy: 0.117188
Test Accuracy: 0.113500

Process finished with exit code 0
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='SimonLBSoerensen' date='2020-10-28T07:28:58Z'>
		&lt;denchmark-link:https://github.com/SimonLBSoerensen&gt;@SimonLBSoerensen&lt;/denchmark-link&gt;

I have tried with TF 2.3-gpu and i am seeing no issue with accuracy. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/47669fc7e28ef2b3a4c5171834a64f5d/untitled93.ipynb?authuser=1&gt;here&lt;/denchmark-link&gt;
.Please, verify once and close the issue. Thanks!
		</comment>
		<comment id='2' author='SimonLBSoerensen' date='2020-11-02T07:50:31Z'>
		With that version of TF, the GPU was not discovered, so it trained on the CPU.
It is training on the RTX 3090 now. But this is by using CUDA 11.1, cuDNN 8.0.4.30 and TensorRT-7.2.1.6 with TF 2.5.0 by compiling TF as shown here &lt;denchmark-link:https://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3&gt;https://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://medium.com/@amsokol.com/how-to-build-and-install-tensorflow-2-0-1aab4eaa4c1a&gt;https://medium.com/@amsokol.com/how-to-build-and-install-tensorflow-2-0-1aab4eaa4c1a&lt;/denchmark-link&gt;

As I can see it, the RTX 3090 also needed CUDA 11 and cuDNN 8 to be working: &lt;denchmark-link:https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html#cudnn-cuda-hardware-versions&gt;https://docs.nvidia.com/deeplearning/cudnn/support-matrix/index.html#cudnn-cuda-hardware-versions&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='SimonLBSoerensen' date='2020-11-02T07:50:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44349&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44349&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='SimonLBSoerensen' date='2020-11-27T00:10:22Z'>
		&lt;denchmark-link:https://github.com/SimonLBSoerensen&gt;@SimonLBSoerensen&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

When I used shuffle='batch' for mnist dataset with .hdf5 file, the learning output was same as yours. I used tensorflow 2.5.0 with RTX 3090. However, I transfered my code to colab, it has no relationship with hardware. After I read your issue, I installed tensorflow 2.3.0 and ran my code again, I got the same output results. So, please look at my issues post below and hopefully you can find bugs for tensorflow 2 + keras. Thanks
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/45197&gt;#45197&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='SimonLBSoerensen' date='2020-11-27T07:57:33Z'>
		I used TensorFlow 2.5.0 when compiling with CUDA 11.1, cuDNN 8.0.4.30 and TensorRT-7.2.1.6.
It did not work when I used the pip version of 2.5.0
		</comment>
		<comment id='6' author='SimonLBSoerensen' date='2020-11-27T08:08:09Z'>
		&lt;denchmark-link:https://github.com/SimonLBSoerensen&gt;@SimonLBSoerensen&lt;/denchmark-link&gt;

I used
pip install tf-nightly-gpu==2.5.0.dev20201108
to install tensorflow 2.5.0 with CUDA 11.1 on Ubuntu 20.04
I think somehow there are bugs when combining tensorflow v2 and keras together. Before I used keras only with tensorflow v1as a backend, everything was good.
		</comment>
	</comments>
</bug>