<bug id='6687' author='infwinston' open_date='2017-01-06T09:11:05Z' closed_time='2017-06-16T18:15:48Z'>
	<summary>Cannot run a distributed training example with tensorflow v0.12.1</summary>
	<description>
Hi,
I was trying to run a distributed tensorflow &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py&gt;example&lt;/denchmark-link&gt;
 in the official repository with v0.12.1 (current latest release).
I can run asynchronous version without problems, but when I turned on  tag, some errors occurred.
(Please check the following logs in details)
This example code can be ran successfully with v0.12.0, so I guess there might be some modification from 0.12.0 to 0.12.1?
Could someone check if that's the case? Thanks.
&lt;denchmark-h:h3&gt;What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?&lt;/denchmark-h&gt;

I haven't found others reported this issue as tensorflow v0.12.1 just released,
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System:
Ubuntu 14.04
Installed version of CUDA and cuDNN:
CUDA 7.5, cuDNN 5.1
&lt;denchmark-code&gt;&gt; ls -l /usr/local/cuda/lib/libcud*
-rw-r--r-- 1 root root 189170 Oct 25 22:51 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Oct 25 22:51 /usr/local/cuda/lib/libcudart.so -&gt; libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Oct 25 22:51 /usr/local/cuda/lib/libcudart.so.7.5 -&gt; libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Oct 25 22:51 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Oct 25 22:51 /usr/local/cuda/lib/libcudart_static.a
&lt;/denchmark-code&gt;

If installed from source, provide

The commit hash (git rev-parse HEAD)
4d924e7 (Release 0.12.1)
The output of bazel version

&lt;denchmark-code&gt;Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:11 2016 (1481136431)
Build timestamp: 1481136431
Build timestamp as int: 1481136431
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

I simply used this example &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py&gt;mnist_replica.py&lt;/denchmark-link&gt;
 in tensorflow repository.
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

First I launched the parameter server
&lt;denchmark-code&gt;export CUDA_VISIBLE_DEVICES=0; python mnist_replica.py --ps_hosts="localhost:50000" --worker_hosts="localhost:50001" --job_name="ps" --task_index=0 --num_gpus=1 --sync_replicas=True
&lt;/denchmark-code&gt;

and then launched the worker with sync_replicas=True tag
&lt;denchmark-code&gt;export CUDA_VISIBLE_DEVICES=1; python mnist_replica.py --ps_hosts="localhost:50000" --worker_hosts="localhost:50001" --job_name="worker" --task_index=0 --num_gpus=2 --train_steps=100 --sync_replicas=True
&lt;/denchmark-code&gt;

but I got some errors here
&lt;denchmark-code&gt;...
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K40m, pci bus id: 0000:2b:00.0)
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; localhost:50000}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:197] Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; localhost:50001, 1 -&gt; localhost:50002}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:50002
Traceback (most recent call last):
  File "mnist_replica.py", line 281, in &lt;module&gt;
    tf.app.run()
  File "local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File "mnist_replica.py", line 186, in main
    train_step = opt.minimize(cross_entropy, global_step=global_step)
  File "local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py", line 279, in minimize
    name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/training/sync_replicas_optimizer.py", line 751, in apply_gradients
    array_ops.reshape(self._replica_id, (1,)),
  File "local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py", line 2448, in reshape
    name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 503, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py", line 360, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='infwinston' date='2017-01-07T02:27:30Z'>
		Hm, can't reproduce...any idea what could be different about your setup? Here's what I tried
&lt;denchmark-code&gt;source activate tf12.2
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp35-cp35m-linux_x86_64.whl
pip install -I --upgrade setuptools
pip install --upgrade $TF_BINARY_URL

git fetch
git tag -l
git checkout tags/0.12.1 -b 0.12.1
find . -name "mnist_replica*"

cd ~/tensorflow.git/tensorflow/tensorflow/tools/dist_test/python
# python mnist_replica.py
source activate tf12.2
export CUDA_VISIBLE_DEVICES=1; python mnist_replica.py --ps_hosts="localhost:50000" --worker_hosts="localhost:50001" --job_name="ps" --task_index=0 --num_gpus=1 --sync_replicas=True

cd ~/tensorflow.git/tensorflow/tensorflow/tools/dist_test/python
source activate tf12.2
export CUDA_VISIBLE_DEVICES=2; python mnist_replica.py --ps_hosts="localhost:50000" --worker_hosts="localhost:50001" --job_name="worker" --task_index=0 --num_gpus=2 --train_steps=100 --sync_replicas=True

&lt;/denchmark-code&gt;

at the end it finishes with
&lt;denchmark-code&gt;
1483755958.593979: Worker 0: training step 94 done (global step: 92)
1483755958.599673: Worker 0: training step 95 done (global step: 93)
1483755958.604453: Worker 0: training step 96 done (global step: 94)
1483755958.609369: Worker 0: training step 97 done (global step: 95)
1483755958.614092: Worker 0: training step 98 done (global step: 96)
1483755958.619020: Worker 0: training step 99 done (global step: 97)
1483755958.624015: Worker 0: training step 100 done (global step: 98)
1483755958.629047: Worker 0: training step 101 done (global step: 99)
1483755958.633775: Worker 0: training step 102 done (global step: 100)
Training ends @ 1483755958.633824
Training elapsed time: 0.946386 s
After 100 training step(s), validation cross entropy = 1463.93
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='infwinston' date='2017-01-07T11:45:18Z'>
		Thanks for your quick reply.
Earlier I used the 0.12.1 version with gpu support which was built by myself (since my cuda version is 7.5).
To make the situation simple, I tried to use the pre-built CPU version by the following instructions
&lt;denchmark-code&gt;source vir-tf/bin/activate
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp27-none-linux_x86_64.whl
pip install --ignore-installed --upgrade $TF_BINARY_URL
&lt;/denchmark-code&gt;

and then ran
&lt;denchmark-code&gt;export CUDA_VISIBLE_DEVICES=0; python mnist_replica.py --ps_hosts="localhost:50000" --worker_hosts="localhost:50001" --job_name="worker" --task_index=0 --num_gpus=1 --train_steps=100 --sync_replicas=True
&lt;/denchmark-code&gt;

Unfortunately, the same error occurred.
&lt;denchmark-code&gt;I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:211] Started server with target: grpc://localhost:50001
Traceback (most recent call last):
  File "mnist_replica.py", line 281, in &lt;module&gt;
    tf.app.run()
  File "local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File "mnist_replica.py", line 186, in main
    train_step = opt.minimize(cross_entropy, global_step=global_step)
  File "local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py", line 279, in minimize
    name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/training/sync_replicas_optimizer.py", line 751, in apply_gradients
    array_ops.reshape(self._replica_id, (1,)),
  File "local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py", line 2448, in reshape
    name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 503, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File "local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py", line 360, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
&lt;/denchmark-code&gt;

However, when I did the same things on another machine, it turns out to behave normal...
Now I have no ideas why it failed on a specific machine...
I also found that someone faced similar errors &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/3208&gt;#3208&lt;/denchmark-link&gt;
 but under different situations.
What do you think of the possible reasons that cause the errors?
Thanks.
		</comment>
		<comment id='3' author='infwinston' date='2017-01-07T18:35:57Z'>
		&lt;denchmark-link:https://github.com/sherrym&gt;@sherrym&lt;/denchmark-link&gt;
 there seems to be some issue that turns up in a variety of circumstances e.g. here and &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/3208&gt;#3208&lt;/denchmark-link&gt;
 which results in this unhelpful error message. Any thoughts on making it easier to debug?
		</comment>
		<comment id='4' author='infwinston' date='2017-01-07T18:42:22Z'>
		My reading of the error message is that  was , so the code executed  which gives this error. &lt;denchmark-link:https://github.com/jmchen-g&gt;@jmchen-g&lt;/denchmark-link&gt;
 -- do you have any idea why  would be none in  ?
		</comment>
		<comment id='5' author='infwinston' date='2017-01-07T18:55:38Z'>
		Generally I think this would be more human-readable if  checking occurred few levels up, at , ie &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/eb56a8af24695bf8258addf28b0c53fbabff72e6/tensorflow/python/framework/op_def_library.py#L289&gt;here&lt;/denchmark-link&gt;
. Since  is a Python-only thing, this could be a check for None at the top level of  which prints which value was none and which op.
		</comment>
		<comment id='6' author='infwinston' date='2017-01-27T02:22:38Z'>
		I'm facing the same issue when trying to use the same example from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py&gt;here&lt;/denchmark-link&gt;
.
Asynchronous works but setting sync_replicas to True results in the same error like this:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "mnist_replica.py", line 293, in &lt;module&gt;
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File "mnist_replica.py", line 195, in main
    train_step = opt.minimize(cross_entropy, global_step=global_step)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 279, in minimize
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/sync_replicas_optimizer.py", line 751, in apply_gradients
    array_ops.reshape(self._replica_id, (1,)),
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py", line 2448, in reshape
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 503, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/constant_op.py", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py", line 360, in make_tensor_proto
    raise ValueError("None values not supported.")
ValueError: None values not supported.
&lt;/denchmark-code&gt;

I am running in CPU only mode on Ubuntu 16.04 with tensorflow 0.12.1 and Python 2.7.12. I'm facing the same issue with Python3 as well as on Ubuntu 14.04.
		</comment>
		<comment id='7' author='infwinston' date='2017-06-16T18:15:48Z'>
		Looks like in v 1.0 this issue was fixed?
Closing this issue.
		</comment>
		<comment id='8' author='infwinston' date='2017-12-03T22:58:48Z'>
		Having this issue in 1.3.0...
		</comment>
	</comments>
</bug>