<bug id='45211' author='skribm9' open_date='2020-11-26T16:43:20Z' closed_time='2020-12-11T21:09:41Z'>
	<summary>Tensor data is stored in BE format on s390x in flatbuffer model in a certain scenario</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.3.1
Python version: 3.6.9
Bazel version (if compiling from source): 3.4.1
GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04
CUDA/cuDNN version: N/A
GPU model and memory: N/A


 test is failing on s390x.
On debugging a little, I found that during the building of flatbuffer model, the data is first represented in Big Endian format, then we flat it to a  in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/d5b2156e4e5367cc336d26fbbac3a6e76781de05/tensorflow/compiler/mlir/lite/flatbuffer_export.cc#L638&gt;flatbuffer_export.cc&lt;/denchmark-link&gt;
.
This data , in some cases, is directly stored in a vector of bytes and inserted into a flatbuffer in . As flatbuffer only support Little Endian format, this TC fails as FileCheck on mlir file expects the data in LE format.
The code that is causing the issue in CreateVector function is:
&lt;denchmark-code&gt;      if (sizeof(T) == 1) {
        PushBytes(reinterpret_cast&lt;const uint8_t *&gt;(v), len);
&lt;/denchmark-code&gt;

If the sizeof(T) is greater than 1, then the data is reversed before storing it into a vector of bytes, i.e., the data gets stored in LE format in flatbuffer model.
&lt;denchmark-code&gt;      } else {
        for (auto i = len; i &gt; 0; ) {
          PushElement(v[--i]);
        }
&lt;/denchmark-code&gt;

As the flatbuffer only support LE format, it seems that the data must be byte-swapped into LE format from BE before storing is into the vector of bytes. But, since I am not sure of the functionality being tested here, maybe we can update the expected result in mlir file from // CHECK-NEXT:     data: [ 1, 0, 0, 0 ] to // CHECK-NEXT:     data: [ 0, 0, 0, 1 ].
Please suggest what would be the best way to proceed here. There are multiple compiler related test cases which have similar failure errors.
Describe the expected behavior
The tensor data must be stored in LE format in flatbuffer model.
Standalone code to reproduce the issue
To reproduce the issue, please use this command:
bazel --host_jvm_args="-Xms1024m" --host_jvm_args="-Xmx2048m" test --host_javabase="@local_jdk//:jdk" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only  -c dbg --copt=-O -c opt --copt=-g --strip never --color=yes --curses=yes --test_output=errors --verbose_failures -- //tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer:tfl_while_op.mlir.test
Other info / logs
	</description>
	<comments>
		<comment id='1' author='skribm9' date='2020-11-26T17:24:55Z'>
		&lt;denchmark-link:https://github.com/skribm9&gt;@skribm9&lt;/denchmark-link&gt;

Please share a simple stand alone code or if possible share a colab gist with error reported.
		</comment>
		<comment id='2' author='skribm9' date='2020-11-26T18:58:08Z'>
		Hi &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 There is no separate code change done. The issue can be reproduced by compiling Tensorflow 2.3.1 code on s390x. I came across this issue on running bazel test for .
Simple stand-alone code to reproduce the issue:
&lt;denchmark-code&gt;bazel --host_jvm_args="-Xms1024m" --host_jvm_args="-Xmx2048m" test --host_javabase="@local_jdk//:jdk" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only --test_output=errors --verbose_failures -- //tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer:tfl_while_op.mlir.test
&lt;/denchmark-code&gt;

On running this test,  I found that this is where issue is introduced:
 if (sizeof(T) == 1) { condition of CreateVector function(mentioned below).
The function causing the issue is in bazel-bin/external/flatbuffers/_virtual_includes/flatbuffers/flatbuffers/flatbuffers.h file.
&lt;denchmark-code&gt;  /// @brief Serialize an array into a FlatBuffer `vector`.
  /// @tparam T The data type of the array elements.
  /// @param[in] v A pointer to the array of type `T` to serialize into the
  /// buffer as a `vector`.
  /// @param[in] len The number of elements to serialize.
  /// @return Returns a typed `Offset` into the serialized data indicating
  /// where the vector is stored.
  template&lt;typename T&gt; Offset&lt;Vector&lt;T&gt;&gt; CreateVector(const T *v, size_t len) {
    // If this assert hits, you're specifying a template argument that is
    // causing the wrong overload to be selected, remove it.
    AssertScalarT&lt;T&gt;();
    StartVector(len, sizeof(T));
    // clang-format off
    #if FLATBUFFERS_LITTLEENDIAN
      PushBytes(reinterpret_cast&lt;const uint8_t *&gt;(v), len * sizeof(T));
    #else
      if (sizeof(T) == 1) {
        **PushBytes(reinterpret_cast&lt;const uint8_t *&gt;(v), len);**
       } else {
        for (auto i = len; i &gt; 0; ) {
          PushElement(v[--i]);
        }

      }
    #endif
    // clang-format on
    return Offset&lt;Vector&lt;T&gt;&gt;(EndVector(len));
  }
&lt;/denchmark-code&gt;

If I check further in PushBytes function, I can see that data is being directly copied using:
&lt;denchmark-code&gt;  void push(const uint8_t *bytes, size_t num) {
    if (num &gt; 0) { memcpy(make_space(num), bytes, num); }
  }
&lt;/denchmark-code&gt;

I tried using PushElement function instead of PushBytes but it corrupts the flatbuffer model. I also tried some other ways to convert data in LE format before pushing in vector but I couldn't come up with a proper and safe solution.
		</comment>
		<comment id='3' author='skribm9' date='2020-11-27T14:23:29Z'>
		Please find the log file attached for reference. I have deleted additional logs that I added for debugging purpose.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5608225/tfl_while_op.log&gt;tfl_while_op.log&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='skribm9' date='2020-12-11T21:09:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45211&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45211&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='skribm9' date='2020-12-11T21:12:16Z'>
		Issue is a duplicate to #&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/45009&gt;#45009&lt;/denchmark-link&gt;
. It seems that  in general are not converted to LE format while storing in flatbuffer vector and this is affecting multiple Test cases.
		</comment>
	</comments>
</bug>