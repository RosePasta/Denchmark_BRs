<bug id='40355' author='ruixin-bao' open_date='2020-06-10T15:25:18Z' closed_time='2020-06-17T22:19:34Z'>
	<summary>//tensorflow/python/tpu:tpu_test and //tensorflow/python/tpu:datasets_test test case failure</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
TensorFlow installed from (source or binary): both source and binary
TensorFlow version (use command below): v2.2.0-0-g2b96f3662b 2.2.0
Python version: 3.6.9
Bazel version (if compiling from source): 2.0.0
GCC/Compiler version (if compiling from source): 7.5.0
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
Test case failure for both test.
For //tensorflow/python/tpu:datasets_test, it fails with:

RuntimeError: /job:coordinator/replica:0/task:0/device:CPU:0 unknown device.
See test log for datasets_test test.log

For //tensorflow/python/tpu:tpu_test, it fails with:

RuntimeError: Attempting to capture an EagerTensor without building a function.
See test log for tpu_test test.log

Describe the expected behavior
Both test cases should pass.
Standalone code to reproduce the issue
For , I copied the test case into &lt;denchmark-link:https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing&gt;here&lt;/denchmark-link&gt;

For , I copied a portion of the test (till the code section that triggers error as shown in the test log) &lt;denchmark-link:https://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing&gt;here&lt;/denchmark-link&gt;

You can also run this via bazel test (with no_oss tag removed) if you build TensorFlow from source.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The test logs have been attached to the current behaviour above.  I think there are also two things worth to note

Both test cases can pass when eager execution is disabled (via ops.disable_eager_execution()), #33747 is a different error but could be related. I learned disabling eager execution from there.
When looking into datasets_test, the unknown device failure was due to a function call of LookupDevice, looks like the device for the context is not in device_map_. see below:

&lt;denchmark-code&gt;(gdb) p device_map_
$8 = std::unordered_map with 8 elements = {[{static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3234 "XLA_CPU:0", length_ = 9}] = 0x374f740, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3223 "/device:XLA_CPU:0XLA_CPU:0", length_ = 17}] = 0x374f740, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x36f31ec "/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0", length_ = 37}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f3211 "/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0", length_ = 13}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807,
    ptr_ = 0x36f31c0 "/job:localhost/replica:0/task:0/device:CPU:0/job:localhost/replica:0/task:0/cpu:0/device:CPU:0CPU:0/device:XLA_CPU:0XLA_CPU:0", length_ = 44}] = 0x1b88f10, [{
    static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x36f321e "CPU:0/device:XLA_CPU:0XLA_CPU:0", length_ = 5}] = 0x1b88f10, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x3754ad0 "/job:localhost/replica:0/task:0/device:XLA_CPU:0", length_ = 48}] = 0x374f740, [{static npos = 18446744073709551615,
    static kMaxSize = 9223372036854775807, ptr_ = 0x3754b10 "/job:localhost/replica:0/task:0/xla_cpu:0", length_ = 41}] = 0x374f740}

(gdb) p name
$9 = {static npos = 18446744073709551615, static kMaxSize = 9223372036854775807, ptr_ = 0x7fffc2f3e300 "/job:coordinator/replica:0/task:0/device:CPU:0", length_ = 46}

2       breakpoint     keep y   0x00007fffd0e10665 in tensorflow::StaticDeviceMgr::LookupDevice(absl::string_view, tensorflow::Device**) const at tensorflow/core/common_runtime/device_mgr.cc:112
        breakpoint already hit 1 time
&lt;/denchmark-code&gt;

Thanks,
Ruixin
	</description>
	<comments>
		<comment id='1' author='ruixin-bao' date='2020-06-11T13:13:55Z'>
		&lt;denchmark-link:https://github.com/ruixin-bao&gt;@ruixin-bao&lt;/denchmark-link&gt;

Please provide with simple standalone code for us to replicate the issue faced.
		</comment>
		<comment id='2' author='ruixin-bao' date='2020-06-11T14:38:54Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
,
Hi, maybe you miss the colab link I shared above? Under Standalone code to reproduce the issue.
For , it is &lt;denchmark-link:https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing&gt;https://colab.research.google.com/drive/1aC8gfkgDfMCbS11JBGxuLFVVwkumSvka?usp=sharing&lt;/denchmark-link&gt;

For , it is
&lt;denchmark-link:https://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing&gt;https://colab.research.google.com/drive/1V97nYdLkzxrJ2QI9g-OmzkIz-lA0fnoK?usp=sharing&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ruixin-bao' date='2020-06-15T18:26:12Z'>
		I am able to replicate the issue, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/371fd98344a1f5bc91fbe1f56a0ac709/untitled231.ipynb&gt;gist here&lt;/denchmark-link&gt;
, for &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/38dc956a07304844e5a5dea39555c5c0/untitled231.ipynb&gt;dataset&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='ruixin-bao' date='2020-06-16T00:08:59Z'>
		These two tests are actually explicitly disabled in open source, hence the no_oss tags.
In datasets_test.py, the failing test testArbitraryReaderFuncFromDatasetGenerator fails because the Cloud TPU environment does not support generator-based datasets that runs on the TPU workers.
I have not looked into why the tpu_test.py fails, but I assume it would be for a similar reason.
		</comment>
		<comment id='5' author='ruixin-bao' date='2020-06-16T18:09:23Z'>
		Hi,
&lt;denchmark-link:https://github.com/frankchn&gt;@frankchn&lt;/denchmark-link&gt;
, thank you for the information.

These two tests are actually explicitly disabled in open source, hence the no_oss tags.

Wondering if you mind elaborating a bit further? I was building tensorflow from source on both s390x and intel (so I can use intel results as reference), and was running the entire test suite. Specifically, I am wondering the following:

seems like tests with no_oss tag is not too important? If I build tensorflow from source to run tests locally and see tests with no_oss tag fail, is it safe to ignore them?
what would be the recommended test_tag_filters if I want to run the complete test suite. I originally used --test_tag_filters=-gpu,-benchmark-test,-v1only, but seems like -no_oss  should be added  to test_tag_filters as well?


In datasets_test.py, the failing test testArbitraryReaderFuncFromDatasetGenerator fails because the Cloud TPU environment does not support generator-based datasets that runs on the TPU workers.

Thanks for the explanation.
Best,
Ruixin
		</comment>
		<comment id='6' author='ruixin-bao' date='2020-06-16T21:39:42Z'>
		Yes, tests with no_oss means that the test may fail or timeout in the open source build for one reason or another, so it should be safe to ignore those.
You may want to look at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/configure.py#L1173&gt;https://github.com/tensorflow/tensorflow/blob/master/configure.py#L1173&lt;/denchmark-link&gt;
 to see what tags we apply. Looks like you might want  in addition to 
		</comment>
		<comment id='7' author='ruixin-bao' date='2020-06-17T22:19:34Z'>
		Thank you for your help and clarification. I think I got the information I needed, will close this issue :).
		</comment>
		<comment id='8' author='ruixin-bao' date='2020-06-17T22:19:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40355&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40355&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>