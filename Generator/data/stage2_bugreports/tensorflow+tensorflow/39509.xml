<bug id='39509' author='lissyx' open_date='2020-05-13T13:53:19Z' closed_time='2020-06-02T19:03:53Z'>
	<summary>Invalid results when running TFLite + ruy computation within a NodeJS v11+ addon on ARMv7</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, libdeepspeech.so: mozilla/DeepSpeech#2952
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Buster, Armbian Buster
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): r2.2, master
TensorFlow version (use command below): r2.2, master
Python version: N/A
Bazel version (if compiling from source): 2.0.0
GCC/Compiler version (if compiling from source): GCC 6.5.0 (RPi toolchain integrated in TensorFlow), GCC 7.2.1 (Linaro toolchain custom-added to TensorFlow
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Model computation differs when running the library inside a nodejs process (v11.0.0+), on ARMv7 hardware
Describe the expected behavior
Model computation should be the same
Standalone code to reproduce the issue
Reproduction environment is complicated for now (need to build libdeepspeech, the nodejs addon, install and run and compare to non nodejs), working on a much smaller one as of now.
How much simple would this needs to be? Our setup is a bit complicated.
Our model uses floats as input, so we need EvalHybrid to use the threaded-enabled fast-path enabled by -DTFLITE_WITH_RUY_GEMV.
Building for Android:
&lt;denchmark-code&gt;PYTHON_BIN_PATH=/usr/bin/python PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages TF_ENABLE_XLA=0 TF_NEED_OPENCL_SYCL=0 TF_NEED_CUDA=0 TF_NEED_ROCM=0 TF_NEED_MPI=0 TF_DOWNLOAD_CLANG=0 CC_OPT_FLAGS="-march=native -Wno-sign-compare" TF_SET_ANDROID_WORKSPACE=1 ANDROID_NDK_HOME=$HOME/Documents/codaz/Mozilla/DeepSpeech/Android/android-ndk-r18b/ ANDROID_NDK_API_LEVEL=21 ANDROID_SDK_HOME=$HOME/Documents/codaz/Mozilla/DeepSpeech/Android/SDK/ ANDROID_API_LEVEL=27 ANDROID_BUILD_TOOLS_VERSION=28.0.3 ./configure &amp;&amp; bazel clean &amp;&amp; bazel build -s --verbose_failures --workspace_status_command="bash native_client/bazel_workspace_status_cmd.sh" --config=monolithic --config=android --config=android_arm --define=runtime=tflite --action_env ANDROID_NDK_API_LEVEL=21 --cxxopt=-std=c++11 --copt=-D_GLIBCXX_USE_C99 //native_client:libdeepspeech.so
&lt;/denchmark-code&gt;

Running on Android (Nokia 1.3, QM215 Cortex-A53 SoC):
&lt;denchmark-code&gt;DRX:/data/local/tmp $ LD_LIBRARY_PATH=$(pwd)/ ./deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav                                                                                                                                                                                                                                                                                    
TensorFlow: v2.2.0-rc3-31-ga6cee0345c
DeepSpeech: v0.7.0-30-gbb716efe
INFO: Initialized TensorFlow Lite runtime.
audio_format=1
num_channels=1
sample_rate=16000 (desired=16000)
bits_per_sample=16
res.buffer_size=93594
she had your dark suit in greasy wash water all year
&lt;/denchmark-code&gt;

Building for RPi3:
&lt;denchmark-code&gt;PYTHON_BIN_PATH=/usr/bin/python PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages TF_ENABLE_XLA=0 TF_NEED_OPENCL_SYCL=0 TF_NEED_CUDA=0 TF_NEED_ROCM=0 TF_NEED_MPI=0 TF_DOWNLOAD_CLANG=0 CC_OPT_FLAGS="-march=native -Wno-sign-compare" TF_SET_ANDROID_WORKSPACE=0 ./configure &amp;&amp; bazel clean &amp;&amp; bazel build -s --verbose_failures --workspace_status_command="bash native_client/bazel_workspace_status_cmd.sh" --config=monolithic --crosstool_top=@local_config_arm_compiler//:toolchain --cpu=armeabi --define=raspberry_pi_with_neon=true --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --copt=-march=armv7-a --copt=-mfloat-abi=hard --copt=-mfpu=neon-fp-armv8 --copt=-DRASPBERRY_PI --copt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-mno-unaligned-access --define=tensorflow_mkldnn_contraction_kernel=0 --define=runtime=tflite --copt=-funsafe-math-optimizations --copt=-ftree-vectorize --copt=-pipe --copt=-DTFLITE_WITH_RUY_GEMV --define=tflite_with_ruy=true -c opt --copt=-pthread --linkopt=-lpthread //native_client:libdeepspeech.so
&lt;/denchmark-code&gt;

Running (C++ binary) on RPi3:
&lt;denchmark-code&gt;$ ./deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav
TensorFlow: v2.2.0-rc3-31-ga6cee0345c
DeepSpeech: v0.7.0-30-gbb716efe
she had your dark suit in greasy wash water all year
&lt;/denchmark-code&gt;

Running (NodeJS binding) on RPi3:
&lt;denchmark-code&gt;$ ./node ~/node_modules/.bin/deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav
Loading model from file model_ldc93s1_16-2000.tflite
TensorFlow: v2.2.0-rc3-31-ga6cee0345c
DeepSpeech: v0.7.0-30-gbb716efe
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate: 0x3287d98
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate(int64_t): 52985240
Loaded model in 0.004686s.
Running inference.
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate(int64_t): 52985240
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate: 0x3287d98
she h yyour drk suit in greasy wash waer all year
Inference took 2.038s for 2.925s audio file.
&lt;/denchmark-code&gt;

Other info / logs
I have tested many hypothesis:

changing toolchain to gcc 6.5.0 bundled by tensorflow (we use a different one by default)
re-writing the nodejs swig-generated wrapper with n-api, in a very basic form
repro on master (commit 5be613e)
repro on master with newer ruy (commit 808ff748e0c7dc746a413fe45fa022d63e6253e8)
bisected tensorflow: first repro is when tflite + ruy get the ability to run threads (commit be369f5)
bisected nodejs, issue first arises in https://github.com/nodejs/node/pull/21983/commits (obviously, hard to actionate)
repro with different model size (if input size is not a multiple of 4, works, we do not use threads somehow because of 


tensorflow/tensorflow/lite/kernels/internal/optimized/neon_tensor_utils.cc


         Line 1210
      in
      2b96f36






 if (m_rows % 4 == 0 &amp;&amp; result_stride == 1) { 




)
same code, same nodejs version runs fine on ARM64 (Armbian on S905X), also excluded the SoC itself and the distro (repro under Armbian on S905X when running multilib armv7, repro on RPi3 and RPi4)
unable to reproduce and to get indication of any weird thing happening when running under valgrind on other platforms (valgrind on armv7/raspbian seems broken, valgrind on armv7/armbian dies because of unsupported instruction produced by vfmaq_f32 in eigen)
disabling kNeon path in ruy but keeping threads, the computation works
disabling threads with kNeon enabled works
obviously verified that the input of the model is correct (dumped mfcc vectors, input states and output logits, and verified they were different only under nodejs runtime)

input here: https://github.com/lissyx/DeepSpeech/blob/bb716efe1ead50fc822d4f5faf0f2fa757adb2d5/native_client/tflitemodelstate.cc#L293-L299
output here: https://github.com/lissyx/DeepSpeech/blob/bb716efe1ead50fc822d4f5faf0f2fa757adb2d5/native_client/tflitemodelstate.cc#L308-L316
verified dumping the vector values (and verified as well the copy function)
we run several pass for the audio file, per small timesteps of 320ms, the very first output is already broken


no problem with the python bindings, java (android), even running concurrent threads (c++)
obviously tried debug build with no optimization at all
model trained on r1.15 and used on r2.2 (we produced a r2.2-trained one and there was the same issue)

Current questions I am unable to reply

is running under NodeJS exposing a bug that we have everywhere but that does not manifest?
v8 used by NodeJS is using both threads and NEON instructions, when ruy's ARM code is also using threads and NEON in hand-written ASM?

	</description>
	<comments>
		<comment id='1' author='lissyx' date='2020-05-13T14:02:33Z'>
		This should include the audio file and model (smallest I could get) reproducing &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4622361/data_issue_39509.zip&gt;data_issue_39509.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='lissyx' date='2020-05-13T14:21:10Z'>
		This should allow running on Android &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4622455/android_build.zip&gt;android_build.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='lissyx' date='2020-05-13T14:24:05Z'>
		This should allow  on rpi3/raspbian buster (nodejs v11.0.0 will use the napi wrapper) &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4622471/deepspeech-0.7.0.tar.gz&gt;deepspeech-0.7.0.tar.gz&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='lissyx' date='2020-05-13T14:25:56Z'>
		This should allow running on Linux/ARMv7 (Raspbian Buster), pure C++ &lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4622483/linux_build.zip&gt;linux_build.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='lissyx' date='2020-05-21T04:55:11Z'>
		Removing myself from the reviewer list since I am not familiar with nodejs.
		</comment>
		<comment id='6' author='lissyx' date='2020-05-26T14:44:03Z'>
		
Removing myself from the reviewer list since I am not familiar with nodejs.

Even if unfamiliar with nodejs (I am not as well), could someone share ideas on how to properly and consistently verify what happens during computation? There's several layers of C++ templating finishing in asm code, and I still fail to verify where in the chain does the discrepency happens.
		</comment>
		<comment id='7' author='lissyx' date='2020-05-28T13:26:30Z'>
		Update: I might have correct values by adding one RUY_MAKE_ZERO(q7);
This change removed it, and there's no explanation: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/2359c4e45e1226e4a9d4072c2b7753b5ae731f44&gt;2359c4e&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='lissyx' date='2020-05-28T14:43:01Z'>
		PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/39951&gt;#39951&lt;/denchmark-link&gt;
 is a tentative fix on the r2.2 branch. I'm unsure of what would be the recommended way to fix it further:

should it be only fixed on master
on master, should it be a patch on top of ruy, or should the fix be directly in ruy repo

		</comment>
		<comment id='9' author='lissyx' date='2020-05-28T14:50:25Z'>
		PR against upstream ruy: &lt;denchmark-link:https://github.com/google/ruy/pull/69&gt;google/ruy#69&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='lissyx' date='2020-05-28T14:57:57Z'>
		And I could verify the patch on current tensorflow master to also fix the issue:
&lt;denchmark-code&gt;pi@gateway:~/ds $ LD_LIBRARY_PATH=$(pwd)/ ./deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav ; LD_LIBRARY_PATH=$(pwd)/ ./node ~/node_modules/.bin/deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav 
TensorFlow: 1.15.0-rc1-21531-gea8e87c8e9
DeepSpeech: v0.7.0-93-g2d5a963b
she had your dark suit in greasy wash water all year
Loading model from file model_ldc93s1_16-2000.tflite
TensorFlow: 1.15.0-rc1-21531-gea8e87c8e9
DeepSpeech: v0.7.0-93-g2d5a963b
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate: 0x1b8be80
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate(int64_t): 28884608
Loaded model in 0.003122s.
Running inference.
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate(int64_t): 28884608
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate: 0x1b8be80
she h yyour drk suit in greasy wash waer all year
Inference took 1.993s for 2.925s audio file.
pi@gateway:~/ds $ LD_LIBRARY_PATH=$(pwd)/ ./deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav ; LD_LIBRARY_PATH=$(pwd)/ ./node ~/node_modules/.bin/deepspeech --model model_ldc93s1_16-2000.tflite --audio LDC93S1_pcms16le_1_16000.wav 
TensorFlow: 1.15.0-rc1-21531-gea8e87c8e9
DeepSpeech: v0.7.0-93-g2d5a963b
she had your dark suit in greasy wash water all year
Loading model from file model_ldc93s1_16-2000.tflite
TensorFlow: 1.15.0-rc1-21531-gea8e87c8e9
DeepSpeech: v0.7.0-93-g2d5a963b
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate: 0x1593d80
static napi_value__* DeepSpeechNAPI::CreateModel(napi_env, napi_callback_info) ModelSate(int64_t): 22625664
Loaded model in 0.003206s.
Running inference.
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate(int64_t): 22625664
static napi_value__* DeepSpeechNAPI::SpeechToText(napi_env, napi_callback_info) ModelSate: 0x1593d80
she had your dark suit in greasy wash water all year
Inference took 2.006s for 2.925s audio file.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='lissyx' date='2020-05-28T15:52:58Z'>
		Thanks for the ruy PR. Merging it at the moment. We will also need to update TensorFlow's references to the ruy repo to point to this new commit. I'll take care of this in a few hours.
		</comment>
		<comment id='12' author='lissyx' date='2020-05-28T15:55:18Z'>
		Perfect, I was just asking about that on tensorflow side.
		</comment>
		<comment id='13' author='lissyx' date='2020-06-02T10:02:43Z'>
		&lt;denchmark-link:https://github.com/bjacob&gt;@bjacob&lt;/denchmark-link&gt;
 Gentle ping: I see some commit to  that moves to 1b313682ef8b8fc8ed08719c610d1c3503b016bf, should I assume this is not yet uptodate with the fix?
		</comment>
		<comment id='14' author='lissyx' date='2020-06-02T11:10:17Z'>
		&lt;denchmark-link:https://github.com/google/ruy/commit/1b313682ef8b8fc8ed08719c610d1c3503b016bf&gt;1b313682&lt;/denchmark-link&gt;
 is a 27-days-old commit.
I am preparing the update, it will update to &lt;denchmark-link:https://github.com/google/ruy/commit/1a8b7eabd5039cd1423b3e22e6d7241d261576dc&gt;1a8b7eab&lt;/denchmark-link&gt;
.
I hope for it to be merged today.
		</comment>
		<comment id='15' author='lissyx' date='2020-06-02T18:29:33Z'>
		It's merged now:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/6faecb105eecdf444ea7b4875fbb226e21556066&gt;6faecb1&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='lissyx' date='2020-06-02T19:03:52Z'>
		Awesome, thanks a lot!
		</comment>
		<comment id='17' author='lissyx' date='2020-06-02T19:03:55Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39509&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39509&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='lissyx' date='2020-06-03T01:54:45Z'>
		Unfortunately, the update got rolled back again. Maybe tomorrow...
		</comment>
	</comments>
</bug>