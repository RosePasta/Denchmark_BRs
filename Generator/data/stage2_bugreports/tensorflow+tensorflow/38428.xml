<bug id='38428' author='gaebor' open_date='2020-04-10T10:17:36Z' closed_time='2020-04-13T18:33:53Z'>
	<summary>batch_jacobian incorrect</summary>
	<description>
System information

Have I written custom code: yes
OS Platform and Distribution

Windows 10, Anaconda Python 3.7.6, tensorflow 2.1.0
Debian GNU/Linux 8.11 (jessie), Anaconda Python 3.7.3, tensorflow 2.0.0



Standalone code to reproduce the issue
import numpy, tensorflow
x = tensorflow.Variable([[1], [1]], dtype="float64")
with tensorflow.GradientTape(persistent=True) as t:
    with tensorflow.GradientTape() as tt:
        obj = x[0]**2 + x[1]**2 + x[0]*x[1]
    dx = tt.gradient(obj, x)
print(t.batch_jacobian(dx, x).numpy())
output is
[[[3.]]

 [[3.]]]
which is not  as &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/GradientTape#batch_jacobian&gt;stated here&lt;/denchmark-link&gt;
.
It is more like [gradient(sum(y), x[i]) for i in range(x.shape[0])], same as gradient of gradient:
import numpy, tensorflow
x = tensorflow.Variable([1, 1], dtype="float64")
with tensorflow.GradientTape(persistent=True) as t:
    with tensorflow.GradientTape() as tt:
        obj = x[0]**2 + x[1]**2 + x[0]*x[1]
    dx = tt.gradient(obj, x)
print(t.jacobian(dx, x).numpy())
print(t.gradient(dx, x).numpy())
output is
[[2. 1.]
 [1. 2.]]
[3. 3.]
which is perfectly fine
Other info / logs

f(x,y) = x^2+y^2+x y
df/dx = 2x+y
df/dy = 2y+x
ddf/dxdx = 2
ddf/dxdy = 1
ddf/dydy = 2

What I want is the diag(Hessian) without calculating full Hessian.
	</description>
	<comments>
		<comment id='1' author='gaebor' date='2020-04-13T07:04:15Z'>
		Could able to reproduce the issue with Tf2.2rc2 and Tf2.1.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/eb4009fce6fa8027c150363d52b51ca0/untitled500.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks
		</comment>
		<comment id='2' author='gaebor' date='2020-04-13T18:33:52Z'>
		As per documentation of batch_jacobian, the function requires the following:
"target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n]. target[i,...] should only depend on source[i,...]."
In your case, the dependence requirement is not met.
		</comment>
		<comment id='3' author='gaebor' date='2020-04-13T18:33:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38428&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38428&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>