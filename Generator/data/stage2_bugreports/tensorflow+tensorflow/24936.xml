<bug id='24936' author='harrysalmon' open_date='2019-01-15T15:18:02Z' closed_time='2021-01-20T17:09:17Z'>
	<summary>High memory usage of tensorflow.python.ops.lookup_ops.index_table_from_file compared to vocabulary_file size on disc</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

OSX Mojave 10.14.2
2.3 GHz Intel Core i5
8 GB 2133 MHz LPDDR3
Number of Processors: 1
Total Number of Cores: 2


TensorFlow installed from (source or binary):

pip installed into anaconda virtual env


TensorFlow version (use command below): v1.11.0-rc2-4-gc19e29306c 1.11.0
Python version: Python 3.6.6 :: Anaconda, Inc.
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): c++ (GCC) 4.8.5
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Note: while the example code is python, this problem also exists once the graph is deserialised and appears to be language independent.
This issue originates from trying to serve a Tensorflow model containing tensorflow.python.ops.lookup_ops.index_table_from_file to check the occurrence of a word in a vocabulary. The memory usage of the model when making predictions increases to ~8x the size of the vocabulary on disc (350MB vocab on disc, 3GB+ total memory usage when running).
The cause of this seems to be the size of the hash table created when initialising index_table_from_file. Using the debugger, the memory increase occurs on initialisation.
Describe the expected behavior
Memory usage on the same order as it's on disc usage.
Code to reproduce the issue
This generates and saves an 84MB file
Running the following opens a Tensorflow debug session.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
import string
import random
from tensorflow.python.ops.lookup_ops import index_table_from_file
from tensorflow.python import debug as tf_debug

lookup_table_filename = "./lookup_table.csv"
data_filename = './vocab_feature.npz'

def generate_data():
    """creates the required datafiles"""
    letters = [i for i in string.ascii_letters]
    vocab = set([
        i + i + j + j + k + k + l + l
        for i in letters
        for j in letters
        for k in letters
        for l in letters
    ])
    
    positive_vocab = set(random.sample(vocab, 1000000))
    with open(lookup_table_filename, 'w') as f:
        f.write('\n'.join(positive_vocab))
        f.write('\n')
        f.write('\n'.join(map(str, range(10**7))))
        f.write('\n')

    vocab_feature = np.random.choice(list(vocab), size=1000, replace=True)
    np.savez(file=data_filename, vocab_feature=vocab_feature)

# Run the first time
generate_data()

vocab_feature = np.load(data_filename)['vocab_feature']
lookup_table = index_table_from_file(
    vocabulary_file=lookup_table_filename,
    default_value=-1,
    num_oov_buckets=0,
    vocab_size=None,
    name='vocab_table',
    key_dtype=tf.string  
)
text = tf.placeholder(dtype=tf.string, shape=[None, ])
index = lookup_table.lookup(text)
sess = tf.Session()
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.run(tf.tables_initializer())
# sess.run(tf.global_variables_initializer())
np_index = sess.run(index, feed_dict={text: vocab_feature})
sess.close()
print(np_index)
&lt;/denchmark-code&gt;

Other info / logs
Things I've tried
I have attempted to change the parallelism threads via ConfigProto to see if this reduces the memory usage but without improvement.
	</description>
	<comments>
		<comment id='1' author='harrysalmon' date='2021-01-20T17:09:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24936&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24936&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>