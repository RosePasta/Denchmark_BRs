<bug id='10651' author='ghost(ghost)' open_date='2017-06-12T15:04:18Z' closed_time='2017-06-16T07:37:44Z'>
	<summary>Different results using tf.train.batch and tf.train.shuffle_batch</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Custom code:
Yes
OS Platform and Distribution:
Linux Ubuntu 16.04
TensorFlow installed from:
binary
TensorFlow version (use command below):
v1.1.0-rc0-61-g1ec6ed5
CUDA/cuDNN version:
CUDA 8 and cuDNN 5.1
GPU model and memory:
GTX Titan X (Maxwell) with 12GB of RAM

Hello,
I am currently working on sequential data with variable length and would like to build a dynamic graph with respect to the "time" of the sequence. Because tf.train.shuffle_batch does not handle dynamic padding, the only official solution is to work with tf.train.batch. To assert the problem, I am preprocessing the data before batching to get sequences with constant length in order to be able to use shuffle_batch and tf.train.batch to compare them. So, the only difference between the two compared pipelines is the swap between tf.train.batch and tf.train.shuffle_batch. Problem : the results drop significantly at test time using tf.train.batch instead of tf.train.shuffle_batch.
&lt;denchmark-link:https://user-images.githubusercontent.com/13334577/27040041-1c421dfc-4f90-11e7-8fea-ded0f5edc1a3.png&gt;&lt;/denchmark-link&gt;

My database is self made and I believe properly shuffled initially : the database is cross subject and all occurrences of a user are shuffled using Python's random.shuffle (the size of the lists is small enough for the pseudo random to be relevant), then added to the TFRecords.
Queue randomization doesn't seem to be the problem either : using standy66's workaround showed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/5147&gt;#5147&lt;/denchmark-link&gt;
 doesn't change the outcome of the tf.train.batch pipeline.
Should we expect different behaviors from these two functions (except for the random queue shuffling) or is this behavior abnormal?
Thanks,
Quentin
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2017-06-16T00:03:40Z'>
		That looks like a bug in  your code to me, as I expect the two to be different. It's hard to say without  a reproducible test case.  Please try to to simplify your  problem to something you can post so we can help you further. You might also try on StackOverflow. &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
, any thoughts?
		</comment>
		<comment id='2' author='ghost(ghost)' date='2017-06-16T03:34:43Z'>
		I am unfortunately not familiar with this code at all.  I think &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 might know more but is on vacation right now.  I could imagine that if you are making multiple passes over the data, then shuffling will present a different order of examples on the second epoch, and so a static shuffling of the dataset may still be different.  But I agree with &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 that there is not enough information here to really explain why it might be different, and that shuffle_batch and batch shouldn't be different except for the shuffling property.
		</comment>
		<comment id='3' author='ghost(ghost)' date='2017-06-16T07:37:36Z'>
		Thank you for your answers, sorry to bother you but after some thoughts, as &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
 said, the only difference I see might be the fact that by using tf.train.batch, the database stays the same through the epochs. With a small database such as mine, do you think this can affect the model quality? About a bug in my code for that example, that would seem unlikely, as the swap between batch and shuffle_batch really is the only change between the two examples. As of now I don't see a way to condensate the problem ta make it reproducible, I will look into the two functions and come back if I find an explanation other than the "static" database. Thanks again.
		</comment>
		<comment id='4' author='ghost(ghost)' date='2017-06-16T16:24:13Z'>
		One way to validate this might be to manually replicate your database with shuffling several times (since the dataset is small this shouldn't be too bad), and see whether tf.train.batch is still worse than tf.train.shuffle_batch on the original dataset.
		</comment>
	</comments>
</bug>