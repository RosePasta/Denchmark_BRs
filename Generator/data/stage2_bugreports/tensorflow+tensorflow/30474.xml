<bug id='30474' author='Dobiasd' open_date='2019-07-08T05:57:13Z' closed_time='2019-07-13T02:44:27Z'>
	<summary>[TF2.0] Bug allowing misuse of the batch dimension of a convolution layer</summary>
	<description>
tensorflow-1.14.0 rightfully complains about the following minimal example with ValueError: could not broadcast input array from shape (20,6,6,32) into shape (10,6,6,32).
tensorflow==2.0.0-beta1 however happily runs it and prints (20, 6, 6, 32).
import numpy as np
import tensorflow.keras.backend as k
from tensorflow.keras.layers import Input, Conv2D, Lambda
from tensorflow.keras.models import Model

def custom_reshape(inputs):
    return k.reshape(inputs, (-1, 8, 8, 3))

inputs = Input(shape=(8, 8, 6))
x = Lambda(custom_reshape)(inputs)
x = Conv2D(32, (3, 3))(x)
model = Model(inputs=inputs, outputs=x)
model.compile(loss='mean_squared_error', optimizer='nadam')
print(model.summary())
batch_size = 10
result = model.predict(np.ones((batch_size, 8, 8, 6)), batch_size=batch_size)
print(result.shape)
As &lt;denchmark-link:https://groups.google.com/a/tensorflow.org/forum/#!topic/testing/txsgcR3cubQ&gt;per discussion&lt;/denchmark-link&gt;
 this seems to be a bug in TF 2.0.
	</description>
	<comments>
		<comment id='1' author='Dobiasd' date='2019-07-09T13:01:30Z'>
		I am able to reproduce the issue on Colab with Tensorflow 1.14.0 and works as expected with 2.0.0.beta1.
		</comment>
		<comment id='2' author='Dobiasd' date='2019-07-09T13:22:24Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;


I am able to reproduce the issue on Colab with Tensorflow 1.14.0 and works as expected with 2.0.0.beta1.

You mean the other way around, right? I.e., the ValueError we get with 1.14.0 should be the correct behavior, while not raising this exception in 2.0.0-beta1 seems to be the problem.
		</comment>
		<comment id='3' author='Dobiasd' date='2019-07-10T08:10:35Z'>
		
@gadagashwini

I am able to reproduce the issue on Colab with Tensorflow 1.14.0 and works as expected with 2.0.0.beta1.

You mean the other way around, right? I.e., the ValueError we get with 1.14.0 should be the correct behavior, while not raising this exception in 2.0.0-beta1 seems to be the problem.

Yes &lt;denchmark-link:https://github.com/Dobiasd&gt;@Dobiasd&lt;/denchmark-link&gt;
 I could able to get the  with Tensorflow  and no exception with Tensorflow .Thanks!
		</comment>
		<comment id='4' author='Dobiasd' date='2019-07-13T02:44:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30474&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30474&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='Dobiasd' date='2019-07-13T23:57:32Z'>
		&lt;denchmark-link:https://github.com/Dobiasd&gt;@Dobiasd&lt;/denchmark-link&gt;
 With tf-nightly-2.0-preview the code seems to work correctly:
...
...
Traceback (most recent call last):
  File "p.py", line 16, in &lt;module&gt;
    result = model.predict(np.ones((batch_size, 8, 8, 6)), batch_size=batch_size)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training.py", line 872, in predict
    use_multiprocessing=use_multiprocessing)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py", line 717, in predict
    callbacks=callbacks)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py", line 395, in model_iteration
    aggregator.aggregate(batch_outs, batch_start, batch_end)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py", line 308, in aggregate
    result.aggregate(batch_element, batch_start, batch_end)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/keras/engine/training_utils.py", line 233, in aggregate
    batch_element.shape, self.results.shape))
ValueError: Mismatch between expected batch size and model output batch size. Output shape = (20, 6, 6, 32), expected output shape = shape (10, 6, 6, 32)
ubuntu@ubuntu:/v# python
Python 2.7.15+ (default, Nov 27 2018, 23:36:35) 
[GCC 7.3.0] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; tf.version.VERSION
'2.0.0-dev20190713'
&gt;&gt;&gt; tf.version.GIT_VERSION
'v1.12.1-6246-g5d4a6cee73'
&gt;&gt;&gt; 
		</comment>
		<comment id='6' author='Dobiasd' date='2019-07-14T05:02:10Z'>
		&lt;denchmark-link:https://github.com/yongtang&gt;@yongtang&lt;/denchmark-link&gt;


With tf-nightly-2.0-preview the code seems to work correctly

Thanks for the confirmation. I guess this was to be expected since &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/37fcf0a0e04b2014864936397c25e6c398135772&gt;the fix&lt;/denchmark-link&gt;
 includes an explicit test for this. 
		</comment>
	</comments>
</bug>