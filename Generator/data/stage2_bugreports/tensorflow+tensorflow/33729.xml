<bug id='33729' author='nbro' open_date='2019-10-25T18:32:34Z' closed_time='2020-06-08T06:59:46Z'>
	<summary>TypeError: An op outside of the function building code is being passed a Graph tensor</summary>
	<description>
System information

Have I written custom code: Yes.
OS Platform and Distribution: Mac OS Catalina: 10.15 (19A602)
TensorFlow installed from: binary
TensorFlow version: 2.0.0
Python version: 3.7.4
GPU model and memory: Intel Iris Pro 1536 MB

Describe the current behavior
I am getting the error

tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [&lt;tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32&gt;]

After having gotten the exception

TypeError: An op outside of the function building code is being passed a Graph tensor

See the detailed traceback below.
Describe the expected behavior
No error.
Code to reproduce the issue
&lt;denchmark-code&gt;from __future__ import print_function

import tensorflow as tf
import tensorflow_probability as tfp

# tf.compat.v1.disable_eager_execution()

def get_bayesian_model(input_shape=None, num_classes=10):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Input(shape=input_shape))
    model.add(tfp.layers.Convolution2DFlipout(6, kernel_size=5, padding="SAME", activation=tf.nn.relu))
    model.add(tf.keras.layers.Flatten())
    model.add(tfp.layers.DenseFlipout(84, activation=tf.nn.relu))
    model.add(tfp.layers.DenseFlipout(num_classes))
    return model

def get_mnist_data(normalize=True):
    img_rows, img_cols = 28, 28
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

    if tf.keras.backend.image_data_format() == 'channels_first':
        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
        input_shape = (1, img_rows, img_cols)
    else:
        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
        input_shape = (img_rows, img_cols, 1)

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')

    if normalize:
        x_train /= 255
        x_test /= 255

    return x_train, y_train, x_test, y_test, input_shape


def train():
    # Hyper-parameters.
    batch_size = 128
    num_classes = 10
    epochs = 1

    # Get the training data.
    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()

    # Get the model.
    model = get_bayesian_model(input_shape=input_shape, num_classes=num_classes)

    # Prepare the model for training.
    model.compile(optimizer=tf.keras.optimizers.Adam(), loss="sparse_categorical_crossentropy",
                  metrics=['accuracy'])

    # Train the model.
    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)
    model.evaluate(x_test, y_test, verbose=0)


if __name__ == "__main__":
    train()
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;WARNING:tensorflow:From /Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:104: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.add_weight` method instead.
2019-10-25 20:38:32.504579: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-10-25 20:38:32.517426: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe25e59f290 executing computations on platform Host. Devices:
2019-10-25 20:38:32.517438: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
Train on 60000 samples
Traceback (most recent call last):
  128/60000 [..............................] - ETA: 7:32  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py", line 61, in quick_execute
    num_outputs)
TypeError: An op outside of the function building code is being passed
a "Graph" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: conv2d_flipout/divergence_kernel:0

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nbro/Desktop/my_project/my_module.py", line 63, in &lt;module&gt;
    train()
  File "/Users/nbro/Desktop/my_project/my_module.py", line 58, in train
    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 728, in fit
    use_multiprocessing=use_multiprocessing)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 324, in fit
    total_epochs=epochs)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 123, in run_one_epoch
    batch_outs = execution_function(iterator)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py", line 86, in execution_function
    distributed_function(input_fn))
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 457, in __call__
    result = self._call(*args, **kwds)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 520, in _call
    return self._stateless_fn(*args, **kwds)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1823, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1141, in _filtered_call
    self.captured_inputs)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 1224, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 511, in call
    ctx=ctx)
  File "/Users/nbro/Desktop/my_project/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py", line 75, in quick_execute
    "tensors, but found {}".format(keras_symbolic_tensors))
tensorflow.python.eager.core._SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [&lt;tf.Tensor 'conv2d_flipout/divergence_kernel:0' shape=() dtype=float32&gt;]
&lt;/denchmark-code&gt;

The problem is apparently related to the layer tfp.layers.Convolution2DFlipout. I know that if I use tf.compat.v1.disable_eager_execution() after having imported TensorFlow, I do not get the mentioned error anymore, but I would like to use TensorFlow's eager execution, avoid sessions or placeholders.
I opened the same issue here: &lt;denchmark-link:https://github.com/tensorflow/probability/issues/620&gt;tensorflow/probability#620&lt;/denchmark-link&gt;
.
	</description>
	<comments>
		<comment id='1' author='nbro' date='2019-10-29T10:44:59Z'>
		&lt;denchmark-link:https://github.com/nbro&gt;@nbro&lt;/denchmark-link&gt;

I tried reproducing the issue. However i am seeing different errorPlease, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/1665e31f72a3207226543fb8d3589723/untitled313.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='nbro' date='2019-10-29T13:43:16Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 If I run your notebook, yes, I get the error you're describing. However, locally, with the specifications I mentioned above, I still get the error I mentioned above.
Please, to reproduce my error, use the following dependencies
&lt;denchmark-code&gt;Package                Version
---------------------- -------
absl-py                0.8.1  
astor                  0.8.0  
cloudpickle            1.1.1  
decorator              4.4.1  
gast                   0.2.2  
google-pasta           0.1.7  
grpcio                 1.24.3 
h5py                   2.10.0 
Keras-Applications     1.0.8  
Keras-Preprocessing    1.1.0  
Markdown               3.1.1  
numpy                  1.17.3 
opt-einsum             3.1.0  
pip                    10.0.1 
protobuf               3.10.0 
setuptools             39.1.0 
six                    1.12.0 
tensorboard            2.0.0  
tensorflow             2.0.0  
tensorflow-estimator   2.0.1  
tensorflow-probability 0.8.0  
termcolor              1.1.0  
Werkzeug               0.16.0 
wheel                  0.33.6 
wrapt                  1.11.2 
&lt;/denchmark-code&gt;

I only had to install TensorFlow 2 (without GPU support, but the fact you're getting a different error in the notebook is not due to the fact you are installing TF with GPU support, given that I tried to install TensorFlow without GPU in the notebook, and I am still getting your error) and TensorFlow Probability with the following requirements.txt file inside an empty virtual environment (which contained only the usual setuptools and wheel packages)
&lt;denchmark-code&gt;tensorflow==2.0.0
tensorflow-probability
&lt;/denchmark-code&gt;

The other dependencies you see above have been installed recursively. You should also try to use Python 3.7 (given that I am using it, and I don't have Python 3.6 installed, which is the Python version used in the notebook), but I don't think this is the problem. Furthermore, you should try to use Mac OS X (with the specific version above), but I also don't think this is the problem.
		</comment>
		<comment id='3' author='nbro' date='2019-12-06T17:06:51Z'>
		If I set the parameter  to  when calling , that is, , I do not get this error anymore.  There's a very related (if not the same) issue: &lt;denchmark-link:https://github.com/tensorflow/probability/issues/519&gt;tensorflow/probability#519&lt;/denchmark-link&gt;
, which I've found  having discovered that I could set  to avoid the error. There's also this related issue &lt;denchmark-link:https://github.com/tensorflow/addons/issues/428&gt;tensorflow/addons#428&lt;/denchmark-link&gt;
.
What is experimental_run_tf_function exactly supposed to do? Why does experimental_run_tf_function=False solve this issue?
The answer to this question is  given in &lt;denchmark-link:https://github.com/tensorflow/probability/issues/519#issuecomment-527337880&gt;tensorflow/probability#519 (comment)&lt;/denchmark-link&gt;
, but I would appreciate a detailed description of this argument and why it solves this issue.
This issue can also be avoided by setting kernel_divergence_fn of the Convolution2DFlipout layer to None, but this may create an undesirable effect. In fact, this sets the divergence between the posterior and prior to None and does not add anything to the losses field.
DenseFlipout does not seem to cause this issue, but only probabilistic convolution layers.
		</comment>
		<comment id='4' author='nbro' date='2020-04-22T22:52:56Z'>
		I think that this issue is related to the DEFAULT value of the parameter kernel_divergence_fn of tfp.layers.Convolution2DFlipout. In fact, if you set it to Noneor you create a custom function that returns the KL divergence, then this issue doesn't occur anymore, even without experimental_run_tf_function=False.
As far as I understand,  would go back to the previous way of TensorFlow of handling computation (i.e. using multiple paths). &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py&gt;Here's the relevant code for TF 2.1&lt;/denchmark-link&gt;
, which I haven't yet investigated. Honestly, I still don't get how and why this affects this particular issue with  (but e.g. not the other Bayesian layers).
If I set run_eagerly=True in the compile method before calling fit (and without using experimental_run_tf_function=False), I get another error

NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array.

However, if I set run_eagerly=True with the following version of TF and TFP (which are currently the nightly versions)
&lt;denchmark-code&gt;tf-nightly             2.2.0.dev20200422  
tfp-nightly            0.11.0.dev20200422 
&lt;/denchmark-code&gt;

I don't get the error above, but the loss is always 0.0, although the same loss is (apparently) correctly displayed as a matric.
		</comment>
		<comment id='5' author='nbro' date='2020-05-18T22:32:13Z'>
		Can this be closed since the error is not seen in tf-nightly version? Thanks!
		</comment>
		<comment id='6' author='nbro' date='2020-05-19T00:19:57Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 I wouldn't close this until the new stable version is released.
		</comment>
		<comment id='7' author='nbro' date='2020-06-08T06:59:46Z'>
		TF 2.2 final version has released and this works successfully. Please give it a try. Thanks!
		</comment>
		<comment id='8' author='nbro' date='2020-06-08T06:59:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33729&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33729&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>