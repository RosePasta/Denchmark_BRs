<bug id='16146' author='gcampax' open_date='2018-01-16T06:47:31Z' closed_time='2020-01-24T21:23:42Z'>
	<summary>Documentation for GridLSTMCell is lacking and does not match the paper</summary>
	<description>
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

The documentation for tf.contrib.rnn.GridLSTMCell cites the paper "Grid Long Short-Term Memory", by Kalchbrenner et al.
The paper describes an architecture, called the 2D Grid LSTM, to replace a stack of LSTM cells. In a 2D Grid LSTM, 2 state components are passed from one layer to the next vertically.
In Tensorflow RNN parlance, one would expect both the state and the output of the cell to be an LSTMStateTuple, which would allow seamless integration with a MultiRNNCell.
In the current implementation, instead it appears that the vertical unrolling is done internally to the GridLSTMCell.
I say it appears, because I can't quite make sense of the arguments and their documentation: specifically, there is a required "num_frequency_block" argument whose meaning is quite obscure.
Looking at the implementation also did not help me understand what value is actually expected in that parameter, and the related parameters.
Note that the above mentioned paper does not talk about frequencies anywhere.
Would it be possible to expand on the documentation for the cell, as well as provide a code example on how to replicate the 2D Grid LSTM from the paper?
	</description>
	<comments>
		<comment id='1' author='gcampax' date='2018-01-16T19:01:28Z'>
		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce
		</comment>
		<comment id='2' author='gcampax' date='2018-01-16T19:05:37Z'>
		None of that is relevant, because this is a documentation issue, but sure:
Have I written custom code: n/a
OS Platform and Distribution: n/a
TensorFlow installed from: n/a
TensorFlow version: 1.4 (but master has the same problem)
Bazel version: n/a
CUDA/cuDNN version: n/a
GPU model and memory:  n/a
Exact command to reproduce: n/a
		</comment>
		<comment id='3' author='gcampax' date='2018-01-23T23:03:33Z'>
		The original poster has replied to this issue after the stat:awaiting response label was applied.
		</comment>
		<comment id='4' author='gcampax' date='2018-01-30T23:18:24Z'>
		Sadly, we don't have an active maintainer for that code.
Maybe &lt;denchmark-link:https://github.com/MarkDaoust&gt;@MarkDaoust&lt;/denchmark-link&gt;
 has a suggestion for documentation, but as it stands, this part of the code in contrib comes "as is".
		</comment>
		<comment id='5' author='gcampax' date='2018-02-08T01:58:08Z'>
		I think I have an exampe use GridLSTMCell that belongs to contrib.grid_rnn and doesn't use the frequence_blocks argument:
&lt;denchmark-code&gt;class GridRNNTest(tf.test.TestCase):
    def setUp(self):
        self.num_features = 1
        self.time_steps = 1
        self.batch_size = 1
        tf.reset_default_graph()
        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])
        self.cell = grid_rnn_cell.Grid1LSTMCell(num_units=8)

    def test_simple_grid_rnn(self):
        self.input_layer = tf.unstack(self.input_layer, self.time_steps, 1)
        rnn.static_rnn(self.cell, self.input_layer, dtype=tf.float32)

class BidirectionalGridRNNTest(tf.test.TestCase):
    def setUp(self):
        self.num_features = 1
        self.time_steps = 1
        self.batch_size = 1
        tf.reset_default_graph()
        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])
        self.cell_fw = grid_rnn_cell.Grid1LSTMCell(num_units=8)
        self.cell_bw = grid_rnn_cell.Grid1LSTMCell(num_units=8)

    def test_simple_bidirectional_grid_rnn(self):
        self.input_layer = tf.unstack(self.input_layer, self.time_steps, 1)
        rnn.static_bidirectional_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='gcampax' date='2018-06-04T07:03:02Z'>
		Umm  so is anyone working on this? Can I work on it...?
		</comment>
		<comment id='7' author='gcampax' date='2018-06-04T07:09:07Z'>
		I don’t think anyone is right now. You can take a shot at it.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, 4 Jun 2018 at 3:06 PM Jae Duk Seo ***@***.***&gt; wrote:
 Umm so is anyone working on this? Can I work on it...?

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#16146 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AMp2w80CvfzIrievYhD6yOHak7YUgqXSks5t5NxkgaJpZM4RfUcV&gt;
 .



		</comment>
	</comments>
</bug>