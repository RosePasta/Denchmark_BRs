<bug id='38067' author='Arktius' open_date='2020-03-31T06:52:28Z' closed_time='2020-04-04T08:01:46Z'>
	<summary>Custom Loss: Order of arguments</summary>
	<description>
I've found a little mistake in the documentation. On the following website, the order of y_true and y_pred are reversed:
&lt;denchmark-link:https://www.tensorflow.org/tutorials/customization/custom_training&gt;https://www.tensorflow.org/tutorials/customization/custom_training&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;def loss(predicted_y, target_y):
  return tf.reduce_mean(tf.square(predicted_y - target_y))
&lt;/denchmark-code&gt;

It's usually the other way around:
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/losses/&gt;https://www.tensorflow.org/api_docs/python/tf/keras/losses/&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;keras.losses.mean_squared_error(y_true, y_pred)
&lt;/denchmark-code&gt;

It makes no difference for MSE since this loss is symmetric. It does make a difference for MMSE (Masked MSE) where random values of the target are mapped to zero.
	</description>
	<comments>
		<comment id='1' author='Arktius' date='2020-03-31T21:57:24Z'>
		&lt;denchmark-link:https://github.com/Arktius&gt;@Arktius&lt;/denchmark-link&gt;
 I don't think this is going to matter as much as we are using MSE as loss function here.
		</comment>
		<comment id='2' author='Arktius' date='2020-04-01T04:45:24Z'>
		That's what I've already written. But people want to know how to write their own custom loss and if the loss is not symmetric, it does matter.
		</comment>
		<comment id='3' author='Arktius' date='2020-04-01T07:29:56Z'>
		Code:
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from tensorflow import math, dtypes
from tensorflow import float32 as f32 
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Input
import random
import numpy as np # linear algebra

rseed=10
np.random.seed(rseed)
random.seed(rseed)
tf.compat.v1.set_random_seed(rseed)
    
def MMSE( preds,targets, mask_value=0.0):
    tf.print('\npred',preds)
    tf.print('target',targets)
    mask = dtypes.cast(tf.not_equal(targets,0),f32) 
    num_rating = math.reduce_sum(mask) #count ratings
    loss = math.reduce_sum(math.square(mask*(preds - targets))) / num_rating 
    return loss

def MMSE2( targets,preds, mask_value=0.0):
    tf.print('\npred',preds)
    tf.print('target',targets)    
    mask = dtypes.cast(tf.not_equal(targets,0),f32) 
    num_rating = math.reduce_sum(mask) #count ratings
    loss = math.reduce_sum(math.square(mask*(preds - targets))) / num_rating 
    return loss

input_dim = Input(shape = (3, ))
model = Sequential()
model.add(Dense(3,input_dim=3))
model.add(Dense(3))
model.compile(optimizer = Adam(lr=0.01),loss=[MMSE]) 
            
data  = tf.math.round(tf.random.normal(shape=[5,3]))
history = model.fit(data,data, epochs = 1, batch_size = 5,verbose=0, shuffle=False) 
print(history.history)



np.random.seed(rseed)
random.seed(rseed)
tf.compat.v1.set_random_seed(rseed)

input_dim = Input(shape = (3, ))
model = Sequential()
model.add(Dense(3,input_dim=3))
model.add(Dense(3))
model.compile(optimizer = Adam(lr=0.01),loss=[MMSE2]) 
            
data  = tf.math.round(tf.random.normal(shape=[5,3]))
history = model.fit(data,data, epochs = 1, batch_size = 5,verbose=0, shuffle=False) 


print(history.history)
&lt;/denchmark-code&gt;

Results:
&lt;denchmark-code&gt;pred [[0 -2 0]
 [-1 -1 1]
 [-1 -1 0]
 [1 -1 1]
 [0 -1 -1]]
target [[0.785157084 -0.0453303158 1.38228703]
 [-0.0399211645 0.472007155 1.34690034]
 [0.533699632 0.0738710314 1.13373435]
 [-0.322163254 0.278934747 0.46171847]
 [0.966199279 -0.420801282 0.477977633]]
{'loss': [1.431638240814209]}

pred [[0.785157084 -0.0453303158 1.38228703]
 [-0.0399211645 0.472007155 1.34690034]
 [0.533699632 0.0738710314 1.13373435]
 [-0.322163254 0.278934747 0.46171847]
 [0.966199279 -0.420801282 0.477977633]]
target [[0 -2 0]
 [-1 -1 1]
 [-1 -1 0]
 [1 -1 1]
 [0 -1 -1]]
{'loss': [1.5207717418670654]}
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='Arktius' date='2020-04-04T04:15:02Z'>
		&lt;denchmark-link:https://github.com/Arktius&gt;@Arktius&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/MarkDaoust&gt;@MarkDaoust&lt;/denchmark-link&gt;
 , please close this issue since the PR is merged.
		</comment>
		<comment id='5' author='Arktius' date='2020-04-04T14:20:36Z'>
		Tip when submitting a PR that closes a bug.
If you put:
&lt;denchmark-code&gt;fixes: tensorflow/tensorflow#38067
&lt;/denchmark-code&gt;

In the commit message or PR description it will auto-close the bug on merge.
		</comment>
	</comments>
</bug>