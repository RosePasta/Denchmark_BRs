<bug id='33718' author='Vooblin' open_date='2019-10-25T11:52:11Z' closed_time='2020-09-05T13:58:26Z'>
	<summary>[TFLite, Converter] BERT conversion error in later version</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): Yes
TensorFlow version (use command below): firsrt git version: 9edecf8, second git verison: f9c7eb4
Python version: 3.6.8
Bazel version (if compiling from source): 0.26.1
GCC/Compiler version (if compiling from source): GCC 8.3.0
CUDA/cuDNN version: No
GPU model and memory: No


When I convert BERT from tensorflow/models to tflite format by tensorflow that was built at commit with hash &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/9edecf8e2391d73e506878da92951a902da0719b&gt;9edecf8&lt;/denchmark-link&gt;
, it works. But when I do the same by tensorflow that was built at later commit with hash &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/f9c7eb414595fd70162521de914e70c9c6620d21&gt;f9c7eb4&lt;/denchmark-link&gt;
, it doesn't work. The error in logs (Unsupported operation: Einsum).
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

import json
import os

from absl import app
from absl import flags

from official.nlp.bert_models import classifier_model
from official.nlp.bert_modeling import BertConfig

flags.DEFINE_string('output_dir', default=None, help='Directory for tflite models')
flags.DEFINE_string('config_path', default=None, help='Path to config file')

FLAGS = flags.FLAGS
def convert_bert(model, output_dir):
  if not os.path.exists(output_dir):
    os.mkdir(output_dir)
  converter = tf.lite.TFLiteConverter.from_keras_model(model)
  tflite_model = converter.convert()
  output_path = os.path.join(output_dir, 'bert.tflite')
  with open(output_path, "wb") as f:
    f.write(tflite_model)

def main(_):
  output_dir = FLAGS.output_dir
  config_path = FLAGS.config_path
  with open(config_path, 'r') as f:
    config = json.load(f)
  model = classifier_model(BertConfig.from_dict(config), tf.float32, 2, 128)[0]
  convert_bert(model, output_dir)

if _name_ == '_main_':
  app.run(main)
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;2019-10-25 11:49:08.546343: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3100000000 Hz
2019-10-25 11:49:08.548499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x434ae80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2019-10-25 11:49:08.548520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2019-10-25 11:49:11.490358: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-25 11:49:11.490631: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-25 11:49:11.503750: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize
2019-10-25 11:49:11.503785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2019-10-25 11:49:11.503790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   function_optimizer: function_optimizer did nothing. time = 0ms.
2019-10-25 11:49:17.635192: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2019-10-25 11:49:17.635327: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2019-10-25 11:49:20.802742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812] Optimization results for grappler item: graph_to_optimize
2019-10-25 11:49:20.802785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (-299), 1515 edges (-396), time = 1677.46204ms.
2019-10-25 11:49:20.802790: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814]   constant_folding: Graph size after: 1225 nodes (0), 1515 edges (0), time = 496.749ms.
Traceback (most recent call last):
  File "convert_bert.py", line 39, in &lt;module&gt;
    app.run(main)
  File "/workspace/.local/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/workspace/.local/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "convert_bert.py", line 36, in main
    convert_bert(model, output_dir)
  File "convert_bert.py", line 22, in convert_bert
    tflite_model = converter.convert()
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py", line 464, in convert
    **converter_kwargs)
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py", line 452, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py", line 203, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2019-10-25 11:49:24.764527: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764589: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764632: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764641: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764659: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764690: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764698: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764713: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764734: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764741: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764756: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764768: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764784: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764791: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764798: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764806: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764815: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764821: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764837: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764849: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764871: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764877: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764885: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764895: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764901: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.764918: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Einsum
2019-10-25 11:49:24.790537: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 716 operators, 1029 arrays (0 quantized)
2019-10-25 11:49:24.802635: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 716 operators, 1029 arrays (0 quantized)
2019-10-25 11:49:24.816756: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 564 operators, 862 arrays (0 quantized)
2019-10-25 11:49:24.829191: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 564 operators, 862 arrays (0 quantized)
2019-10-25 11:49:24.841886: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.854403: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.866851: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 5: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.879295: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 6: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.891707: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.900833: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 563 operators, 860 arrays (0 quantized)
2019-10-25 11:49:24.915554: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2032640 bytes, theoretical optimal value: 1179648 bytes.
2019-10-25 11:49:24.917162: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 107896686
2019-10-25 11:49:24.930715: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum.
Traceback (most recent call last):
  File "/workspace/.local/bin//toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/workspace/.local/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/workspace/.local/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/workspace/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, FULLY_CONNECTED, GATHER, MEAN, MUL, NEG, POW, RESHAPE, RSQRT, SOFTMAX, SQUARED_DIFFERENCE, SQUEEZE, STRIDED_SLICE, SUB, TANH. Here is a list of operators for which you will need custom implementations: Einsum
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Vooblin' date='2019-10-29T23:06:02Z'>
		Hi,
This is because Einsum op is not supported in TF Lite. Is it possible to replace this op with other op in the model?
		</comment>
		<comment id='2' author='Vooblin' date='2019-10-30T10:28:34Z'>
		Hi!
I understand why this error appeared and it's okay that einsum isn't supported. But I noticed that when I do the same with the earlier tensorflow version, this error doesn't appear. So as I understand, before now TFLiteConverter has converted einsum not as one operation, but as several operations. But now TFLiteConverter tries to convert einsum as one operation not having appropriate supporting. So is it okay that such changes were made?
		</comment>
		<comment id='3' author='Vooblin' date='2019-10-31T17:53:51Z'>
		Hi,
Did you pass -enable_select_tf_ops when converting the model before? tf.Einsum is a supported flex op, maybe it's working before because you enable flex mode?
What's the tflite version that you use before that could convert the einsum op (i'm not aware of any transformation passes that in tflite converter to break the ops into several simple ops, so it sounds a bit interesting)
		</comment>
		<comment id='4' author='Vooblin' date='2019-11-01T10:08:24Z'>
		I didn't use any additional flags, I used exactly the code that in "Code to reproduce the issue" section in issue.
I used "latest-devel-py3" tensorflow docker container. So the hash of last commit in this docker was &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/9edecf8e2391d73e506878da92951a902da0719b&gt;9edecf8&lt;/denchmark-link&gt;
. Tensorflow was built from source with default options.
		</comment>
		<comment id='5' author='Vooblin' date='2019-11-04T17:51:46Z'>
		Hi,
Do you have an example to demonstrate that the 'einsum' op is actually converted to series of basic ops? Like what ops are there before/after the conversion?
		</comment>
		<comment id='6' author='Vooblin' date='2019-11-07T10:09:59Z'>
		Now I can only demonstrate sequence of operation of one einsum in tflite model gotten by tflite_benchmark. I'll send the same information about model before conversion only on the next week:
&lt;denchmark-code&gt;                       TRANSPOSE	           53.024	    1.136	    1.103	  0.038%	  1.867%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose]
	               TRANSPOSE	           54.128	    0.788	    0.782	  0.027%	  1.894%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose_1]
	               TRANSPOSE	           54.910	    0.928	    0.932	  0.032%	  1.926%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum_1/transpose]
	                 RESHAPE	           55.842	    0.049	    0.048	  0.002%	  1.928%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/reshape_a/reshape]
	                   SLICE	           55.891	    0.015	    0.014	  0.000%	  1.928%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_a/slice]
	                   SLICE	           55.906	    0.009	    0.009	  0.000%	  1.928%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_a/slice]
	                   SLICE	           55.915	    0.005	    0.005	  0.000%	  1.929%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_a/slice]
	                   SLICE	           55.921	    0.006	    0.006	  0.000%	  1.929%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_a/slice]
	                   SLICE	           55.927	    0.007	    0.007	  0.000%	  1.929%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_a/slice]
	                   SLICE	           55.934	    0.005	    0.005	  0.000%	  1.929%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_a/slice]
	                   SLICE	           55.939	    0.006	    0.006	  0.000%	  1.929%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_a/slice]
	                   SLICE	           55.946	    0.006	    0.006	  0.000%	  1.930%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_a/slice]
	                   SLICE	           55.952	    0.006	    0.006	  0.000%	  1.930%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_a/slice]
	                   SLICE	           55.958	    0.005	    0.005	  0.000%	  1.930%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_a/slice]
	                   SLICE	           55.963	    0.006	    0.006	  0.000%	  1.930%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_a/slice]
	                   SLICE	           55.969	    0.005	    0.005	  0.000%	  1.930%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_a/slice]
	                 RESHAPE	           55.975	    0.058	    0.059	  0.002%	  1.932%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/reshape_b/reshape]
	                   SLICE	           56.034	    0.005	    0.005	  0.000%	  1.933%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/slice]
	               TRANSPOSE	           56.039	    0.008	    0.009	  0.000%	  1.933%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/reshape/transpose]
	                   SLICE	           56.048	    0.005	    0.005	  0.000%	  1.933%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/slice]
	               TRANSPOSE	           56.053	    0.008	    0.007	  0.000%	  1.933%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/reshape/transpose]
	                   SLICE	           56.061	    0.005	    0.005	  0.000%	  1.933%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/slice]
	               TRANSPOSE	           56.066	    0.007	    0.007	  0.000%	  1.934%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/reshape/transpose]
	                   SLICE	           56.074	    0.005	    0.005	  0.000%	  1.934%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/slice]
	               TRANSPOSE	           56.079	    0.008	    0.007	  0.000%	  1.934%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/reshape/transpose]
	                   SLICE	           56.087	    0.005	    0.005	  0.000%	  1.934%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/slice]
	               TRANSPOSE	           56.092	    0.007	    0.008	  0.000%	  1.935%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/reshape/transpose]
	                   SLICE	           56.100	    0.005	    0.005	  0.000%	  1.935%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/slice]
	               TRANSPOSE	           56.106	    0.008	    0.007	  0.000%	  1.935%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/reshape/transpose]
	                   SLICE	           56.114	    0.006	    0.006	  0.000%	  1.935%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/slice]
	               TRANSPOSE	           56.120	    0.008	    0.007	  0.000%	  1.935%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/reshape/transpose]
	                   SLICE	           56.128	    0.004	    0.005	  0.000%	  1.936%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/slice]
	               TRANSPOSE	           56.133	    0.007	    0.007	  0.000%	  1.936%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/reshape/transpose]
	                   SLICE	           56.140	    0.005	    0.005	  0.000%	  1.936%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/slice]
	               TRANSPOSE	           56.145	    0.008	    0.007	  0.000%	  1.936%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/reshape/transpose]
	                   SLICE	           56.153	    0.005	    0.005	  0.000%	  1.936%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/slice]
	               TRANSPOSE	           56.158	    0.008	    0.007	  0.000%	  1.937%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/reshape/transpose]
	                   SLICE	           56.166	    0.005	    0.004	  0.000%	  1.937%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/slice]
	               TRANSPOSE	           56.171	    0.008	    0.007	  0.000%	  1.937%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/reshape/transpose]
	                   SLICE	           56.179	    0.004	    0.005	  0.000%	  1.937%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/slice]
	               TRANSPOSE	           56.184	    0.008	    0.007	  0.000%	  1.938%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/reshape/transpose]
	                 RESHAPE	           56.192	    0.004	    0.004	  0.000%	  1.938%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0/slice_b/reshape]
	         FULLY_CONNECTED	           56.196	    0.249	    0.238	  0.008%	  1.946%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b0]
	                 RESHAPE	           56.434	    0.004	    0.004	  0.000%	  1.946%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1/slice_b/reshape]
	         FULLY_CONNECTED	           56.438	    0.223	    0.199	  0.007%	  1.953%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b1]
	                 RESHAPE	           56.638	    0.003	    0.004	  0.000%	  1.953%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2/slice_b/reshape]
	         FULLY_CONNECTED	           56.642	    0.204	    0.199	  0.007%	  1.960%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b2]
	                 RESHAPE	           56.841	    0.004	    0.005	  0.000%	  1.960%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3/slice_b/reshape]
	         FULLY_CONNECTED	           56.847	    0.195	    0.197	  0.007%	  1.967%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b3]
	                 RESHAPE	           57.044	    0.004	    0.004	  0.000%	  1.967%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4/slice_b/reshape]
	         FULLY_CONNECTED	           57.049	    0.194	    0.197	  0.007%	  1.974%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b4]
	                 RESHAPE	           57.246	    0.003	    0.004	  0.000%	  1.974%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5/slice_b/reshape]
	         FULLY_CONNECTED	           57.250	    0.207	    0.201	  0.007%	  1.981%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b5]
	                 RESHAPE	           57.451	    0.005	    0.006	  0.000%	  1.981%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6/slice_b/reshape]
	         FULLY_CONNECTED	           57.457	    0.201	    0.197	  0.007%	  1.988%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b6]
	                 RESHAPE	           57.655	    0.005	    0.005	  0.000%	  1.988%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7/slice_b/reshape]
	         FULLY_CONNECTED	           57.660	    0.197	    0.199	  0.007%	  1.995%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b7]
	                 RESHAPE	           57.859	    0.005	    0.005	  0.000%	  1.995%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8/slice_b/reshape]
	         FULLY_CONNECTED	           57.865	    0.197	    0.200	  0.007%	  2.002%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b8]
	                 RESHAPE	           58.066	    0.003	    0.004	  0.000%	  2.002%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9/slice_b/reshape]
	         FULLY_CONNECTED	           58.070	    0.215	    0.197	  0.007%	  2.009%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b9]
	                 RESHAPE	           58.267	    0.004	    0.004	  0.000%	  2.009%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10/slice_b/reshape]
	         FULLY_CONNECTED	           58.272	    0.197	    0.197	  0.007%	  2.016%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b10]
	                 RESHAPE	           58.469	    0.004	    0.004	  0.000%	  2.016%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11/slice_b/reshape]
	         FULLY_CONNECTED	           58.473	    0.195	    0.195	  0.007%	  2.023%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul_b11]
	                    PACK	           58.669	    0.125	    0.127	  0.004%	  2.027%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/MatMul/pack]
	               TRANSPOSE	           58.797	    1.180	    1.195	  0.041%	  2.068%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/transpose_2]
	                     MUL	           59.992	    0.136	    0.148	  0.005%	  2.073%	     0.000	        1	[model_1/bert_model/encoder/layer_0/self_attention/einsum/Reshape_2]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='Vooblin' date='2020-02-01T00:10:53Z'>
		i don't see where in the tflite code base einsum is replaced by a sequence of other ops. is it possible that the model you generated before doesn't have einsum at all?
		</comment>
		<comment id='8' author='Vooblin' date='2020-09-04T05:30:39Z'>
		&lt;denchmark-link:https://github.com/Vooblin&gt;@Vooblin&lt;/denchmark-link&gt;

Could you please update as per above comment, if this is not an issue anymore please feel free to move this issue to closed status.
		</comment>
		<comment id='9' author='Vooblin' date='2020-09-05T13:58:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33718&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33718&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>