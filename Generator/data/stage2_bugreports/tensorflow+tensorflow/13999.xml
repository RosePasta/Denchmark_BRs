<bug id='13999' author='Mahdizade' open_date='2017-10-26T14:25:34Z' closed_time='2017-10-30T23:42:45Z'>
	<summary>Memory Leak While Reading from TFRecord</summary>
	<description>
&lt;denchmark-h:h3&gt;Problem&lt;/denchmark-h&gt;

As I mentioned in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6599&gt;my previous issue&lt;/denchmark-link&gt;
, I have memory leak in my code. Finally I can write a sample code that can reproduce the problem.
&lt;denchmark-h:h3&gt;Source code&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import os
import random

import psutil
import tensorflow as tf


def get_tf_example(inputs, outputs):
    example = tf.train.Example(features=tf.train.Features(feature={
        'inputs': tf.train.Feature(int64_list=tf.train.Int64List(value=inputs)),
        'outputs': tf.train.Feature(int64_list=tf.train.Int64List(value=outputs))
        }))
    return example.SerializeToString()


def memory():
    pid = os.getpid()
    py = psutil.Process(pid)
    memory_use = py.memory_info()[0]/2.**30
    print('memory use:', memory_use)


def main():
    tfrecord_file = tf.python_io.TFRecordWriter('data.tfrecord')
    for i in range(10000):
        random_numbers = [random.randint(0, 100) for _ in range(10)]
        without_an_element = filter(lambda e: e != 100, random_numbers)
        tf_example = get_tf_example(random_numbers, without_an_element)
        tfrecord_file.write(tf_example)
    tfrecord_file.close()

    filename_queue = tf.train.string_input_producer(['data.tfrecord'])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    features = tf.parse_single_example(
        serialized_example,
        features={
            'inputs': tf.FixedLenFeature(10, dtype=tf.int64),
            'outputs': tf.VarLenFeature(dtype=tf.int64)
        })
    images, labels = tf.train.shuffle_batch([features['inputs'], features['outputs']], batch_size=100, capacity=200,
                                            min_after_dequeue=100)
    sess = tf.Session()

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)

    for i in range(10000):
        _ = sess.run(images)
        if (i+1) % 100 == 0:
            memory()

    coord.request_stop()
    coord.join(threads)


if __name__ == '__main__':
    main()
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;('memory use:', 0.1137542724609375)
('memory use:', 0.11678314208984375)
('memory use:', 0.11930084228515625)
('memory use:', 0.12792205810546875)
('memory use:', 0.13238525390625)
('memory use:', 0.135406494140625)
('memory use:', 0.13817596435546875)
('memory use:', 0.14484786987304688)
('memory use:', 0.1512603759765625)
('memory use:', 0.15402984619140625)
('memory use:', 0.15654754638671875)
('memory use:', 0.16101455688476562)
('memory use:', 0.17060470581054688)
('memory use:', 0.17287063598632812)
('memory use:', 0.17589187622070312)
('memory use:', 0.18036270141601562)
('memory use:', 0.18872833251953125)
('memory use:', 0.19124221801757812)
('memory use:', 0.19401168823242188)
('memory use:', 0.19848251342773438)
('memory use:', 0.20489883422851562)
('memory use:', 0.20936203002929688)
('memory use:', 0.21213150024414062)
('memory use:', 0.21490097045898438)
('memory use:', 0.22327041625976562)
('memory use:', 0.22988128662109375)
('memory use:', 0.232147216796875)
('memory use:', 0.23491668701171875)
('memory use:', 0.23967361450195312)
('memory use:', 0.2477874755859375)
('memory use:', 0.2508087158203125)
('memory use:', 0.2528228759765625)
('memory use:', 0.2577934265136719)
('memory use:', 0.2661628723144531)
('memory use:', 0.2686767578125)
('memory use:', 0.27144622802734375)
('memory use:', 0.2759132385253906)
('memory use:', 0.2823295593261719)
('memory use:', 0.28704833984375)
('memory use:', 0.2895660400390625)
('memory use:', 0.2940330505371094)
('memory use:', 0.30095672607421875)
('memory use:', 0.30516815185546875)
('memory use:', 0.30768585205078125)
('memory use:', 0.3126564025878906)
('memory use:', 0.31687164306640625)
('memory use:', 0.3235435485839844)
('memory use:', 0.32605743408203125)
('memory use:', 0.3305244445800781)
('memory use:', 0.3332939147949219)
('memory use:', 0.3397102355957031)
('memory use:', 0.34417724609375)
('memory use:', 0.3529624938964844)
('memory use:', 0.3552284240722656)
('memory use:', 0.36199188232421875)
('memory use:', 0.3664588928222656)
('memory use:', 0.37117767333984375)
('memory use:', 0.373443603515625)
('memory use:', 0.3801116943359375)
('memory use:', 0.38458251953125)
('memory use:', 0.3892974853515625)
('memory use:', 0.3923187255859375)
('memory use:', 0.3982391357421875)
('memory use:', 0.40125274658203125)
('memory use:', 0.4074211120605469)
('memory use:', 0.410186767578125)
('memory use:', 0.4146575927734375)
('memory use:', 0.41912078857421875)
('memory use:', 0.4257926940917969)
('memory use:', 0.4280548095703125)
('memory use:', 0.4310760498046875)
('memory use:', 0.4372406005859375)
('memory use:', 0.44196319580078125)
('memory use:', 0.446929931640625)
('memory use:', 0.44919586181640625)
('memory use:', 0.45586395263671875)
('memory use:', 0.4581298828125)
('memory use:', 0.46504974365234375)
('memory use:', 0.467315673828125)
('memory use:', 0.4739875793457031)
('memory use:', 0.47650146484375)
('memory use:', 0.48291778564453125)
('memory use:', 0.485687255859375)
('memory use:', 0.4921112060546875)
('memory use:', 0.49462127685546875)
('memory use:', 0.5015411376953125)
('memory use:', 0.5038070678710938)
('memory use:', 0.5085296630859375)
('memory use:', 0.5129928588867188)
('memory use:', 0.5174598693847656)
('memory use:', 0.522430419921875)
('memory use:', 0.5246963500976562)
('memory use:', 0.5313644409179688)
('memory use:', 0.5355796813964844)
('memory use:', 0.5404815673828125)
('memory use:', 0.5429954528808594)
('memory use:', 0.5494194030761719)
('memory use:', 0.5541419982910156)
('memory use:', 0.5586051940917969)
('memory use:', 0.5611228942871094)
&lt;/denchmark-code&gt;

I can't find the reason. Many thanks for your consideration.
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


OS Platform and Distribution: Linux Ubuntu 14.04
TensorFlow installed from: binary
TensorFlow version: ('v1.3.0-rc2-20-g0787eee', '1.3.0')
Python version: 2.7.6
CUDA/cuDNN version: NA
GPU model and memory: NA

	</description>
	<comments>
		<comment id='1' author='Mahdizade' date='2017-10-26T22:01:24Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 would you take a look or assign to whomever is supporting queue-based inputs?
		</comment>
		<comment id='2' author='Mahdizade' date='2017-10-26T22:21:08Z'>
		Interestingly, the leak seems to be plugged if you replace the line:
        _ = sess.run(images)
...with the following line:
        _ = sess.run([images, labels])
I suspect it is not a coincidence that labels is a tf.SparseTensor, because tf.train.shuffle_batch() handles these by storing them in a buffer, replacing them with a key (to pass through the batch queue), and then removing them from the buffer when the key is emitted from the batch queue.
Perhaps if you don't use the value, the remove-from-buffer code doesn't get triggered?
Assigning to &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
, since he knows that part of the code best.
		</comment>
		<comment id='3' author='Mahdizade' date='2017-10-26T22:23:11Z'>
		Eugene: perhaps we need all the returned tensors to carry a control dependency on the _restore_sparse ops here?



tensorflow/tensorflow/python/training/input.py


         Line 555
      in
      e9d2b60






 return tensors if received_sequence else tensors[0] 





		</comment>
		<comment id='4' author='Mahdizade' date='2017-10-27T15:19:50Z'>
		&lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 great idea!  a long term fix is to use Variants here, but I'll make the change you suggested.
		</comment>
		<comment id='5' author='Mahdizade' date='2017-10-31T10:00:43Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/mrry&gt;@mrry&lt;/denchmark-link&gt;
 is there any way to fix this without update tf code? I use aliyun's pai running the code, and it's tf version is 1.2 that i can't change it.
		</comment>
		<comment id='6' author='Mahdizade' date='2017-10-31T14:40:43Z'>
		You may be able to patch my pr into your tf installation
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Oct 31, 2017, 3:03 AM 方桂锴 ***@***.***&gt; wrote:
 @ebrevdo &lt;https://github.com/ebrevdo&gt; @mrry &lt;https://github.com/mrry&gt; is
 there any way to fix this without update tf code? I use aliyun's pai
 running the code, and it's tf version is 1.2 that i can't change it.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#13999 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtim-mJqZtSx5vg4w-jc6FocCBOdolTks5sxvBqgaJpZM4QHqTE&gt;
 .



		</comment>
		<comment id='7' author='Mahdizade' date='2017-11-01T12:39:07Z'>
		Tried the fix in my app and it seems to solve the problem.
		</comment>
	</comments>
</bug>