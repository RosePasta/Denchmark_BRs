<bug id='38223' author='hahadashi' open_date='2020-04-04T18:09:56Z' closed_time='2020-04-13T14:14:47Z'>
	<summary>TF2.0 frozen ckpt model or h5 model to pb model appear wrong</summary>
	<description>

freeze the graph reference from the below code
from keras import backend as K
import tensorflow as tf

def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):
    """
    Freezes the state of a session into a pruned computation graph.

    Creates a new computation graph where variable nodes are replaced by
    constants taking their current value in the session. The new graph will be
    pruned so subgraphs that are not necessary to compute the requested
    outputs are removed.
    @param session The TensorFlow session to be frozen.
    @param keep_var_names A list of variable names that should not be frozen,
                          or None to freeze all the variables in the graph.
    @param output_names Names of the relevant graph outputs.
    @param clear_devices Remove the device directives from the graph for better portability.
    @return The frozen graph definition.
    """
    from tensorflow.python.framework.graph_util import convert_variables_to_constants
    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))
        output_names = output_names or []
        output_names += [v.op.name for v in tf.global_variables()]
        # Graph -&gt; GraphDef ProtoBuf
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = ""
        frozen_graph = convert_variables_to_constants(session, input_graph_def,
                                                      output_names, freeze_var_names)
        return frozen_graph


frozen_graph = freeze_session(K.get_session(),
                              output_names=[out.op.name for out in model.outputs]

tf.train.write_graph(frozen_graph, "model", "tf_model.pb", as_text=False)

hi，i use your demo complete frozen the ckpt model(checkpoint = tf.train.Checkpoint(myAwesomeModel=me), checkpoint.restore(tf.train.latest_checkpoint('examples'    ))) or h5 model (model.load_weights('model_enc.h5'))to pb model。after i run ckpt model and pb model，i find their result is different。and the result of ckpt model  is right。i check the pb model parmas， and find some op variable parmas is initial value，like “bias” is vector contain zero，“layer normal beta”  is vector contain zero eg.  i think it is  wrong to restore model, hope your give me some advice,thx
	</description>
	<comments>
		<comment id='1' author='hahadashi' date='2020-04-06T11:41:41Z'>
		&lt;denchmark-link:https://github.com/hahadashi&gt;@hahadashi&lt;/denchmark-link&gt;
, I tried reproducing the issue with Tf 2.0 but received different error.
Please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/9b25d752b3d77347cc8d727c54e96d1a/untitled488.ipynb&gt;gist&lt;/denchmark-link&gt;
 and provide the more information to analyze the issue. Thanks
		</comment>
		<comment id='2' author='hahadashi' date='2020-04-09T09:41:35Z'>
		
@hahadashi, I tried reproducing the issue with Tf 2.0 but received different error.
Please take a look at the gist and provide the more information to analyze the issue. Thanks

thx your response。 i use this way，have sovled problem，may be it is because of when i rebuild the model and i made  a minor mistake
		</comment>
		<comment id='3' author='hahadashi' date='2020-04-09T09:47:31Z'>
		
@hahadashi, I tried reproducing the issue with Tf 2.0 but received different error.
Please take a look at the gist and provide the more information to analyze the issue. Thanks

but i meet  a new problem。if i use pb model by c++ env，i try to inference by batch。 i set the same inputs，but these outputs are difference。have you try inference by bctch？if i set batch is one，the result is right
		</comment>
		<comment id='4' author='hahadashi' date='2020-04-13T11:44:22Z'>
		&lt;denchmark-link:https://github.com/hahadashi&gt;@hahadashi&lt;/denchmark-link&gt;
, Can you raise the new issue with all the information asked in Template. Thanks
		</comment>
		<comment id='5' author='hahadashi' date='2020-04-13T14:14:47Z'>
		
@hahadashi, Can you raise the new issue with all the information asked in Template. Thanks

OK，thx your response!
		</comment>
		<comment id='6' author='hahadashi' date='2020-04-13T14:14:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38223&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38223&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>