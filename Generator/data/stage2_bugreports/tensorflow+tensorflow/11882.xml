<bug id='11882' author='jnjaby' open_date='2017-07-30T10:11:36Z' closed_time='2019-08-06T21:56:33Z'>
	<summary>conv2d_transpose produce different results on GPU</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;

== cat /etc/issue ===============================================
Linux ST 4.2.0-42-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/49&gt;#49&lt;/denchmark-link&gt;
~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION="14.04.4 LTS, Trusty Tahr"
VERSION_ID="14.04"
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux ST 4.2.0-42-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/49&gt;#49&lt;/denchmark-link&gt;
~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
msgpack-numpy (0.4.1)
numpy (1.13.1)
protobuf (3.2.0)
tensorflow (0.10.0)
tensorflow-gpu (1.0.0)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.0.0
tf.GIT_VERSION = v1.0.0-rc2-15-g47bba63-dirty
tf.COMPILER_VERSION = v1.0.0-rc2-15-g47bba63-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
== env ==========================================================
LD_LIBRARY_PATH /home/abc/torch/install/lib:/usr/lib/x86_64-linux-gnu:/home/abc/torch/install/lib:/usr/local/cuda/lib64:/usr/local/cuda/lib64:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:/usr/local/cuda/lib64::/usr/local/computecpp/lib:/data/software/gurobi652/linux64/lib
DYLD_LIBRARY_PATH /home/abc/torch/install/lib:/home/abc/torch/install/lib:/home/abc/code/torch/torch/install/lib:
== nvidia-smi ===================================================
Sun Jul 30 17:45:45 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |
|  0%   53C    P2    47W / 260W |   7909MiB /  8112MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1308    G   /usr/bin/X                                     357MiB |
|    0      2590    G   compiz                                         229MiB |
|    0      3254    G   ...el-token=CBAE43C38254E155E78826C3F38F0092    99MiB |
|    0      9480    C   python                                        1039MiB |
|    0     10432    C   /usr/bin/python                               5895MiB |
|    0     20408    C   /usr/bin/python                                283MiB |
|    0     28024    G   /usr/local/MATLAB/R2015a/bin/glnxa64/MATLAB      2MiB |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so.8.0
/usr/local/lib/python2.7/dist-packages/torch/lib/libcudart.so
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/MATLAB/R2017a/bin/glnxa64/libcudart.so.8.0.44
/usr/local/MATLAB/R2015a/bin/glnxa64/libcudart.so.6.5.14
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I am trying to use tf.nn.conv2d_transpose but it produces different results every time on GPU. However, the result would be the same when switching the device to CPU. It seems like a bug. Please check the toy model below for more details.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)

with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.get_variable("weight", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    bias = tf.get_variable("bias", initializer=np.zeros(1, dtype=np.float32))	

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv = tf.nn.bias_add(conv, bias)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
np.array_equal(sess.run(conv), sess.run(conv))
Out[2]: False
	</description>
	<comments>
		<comment id='1' author='jnjaby' date='2017-07-31T05:41:22Z'>
		&lt;denchmark-link:https://github.com/zheng-xq&gt;@zheng-xq&lt;/denchmark-link&gt;
, Do you have any thoughts on this. I made a slightly more elaborate test case that computes relative error between the gpu and cpu version and two runs of the cpu version. &lt;denchmark-link:https://github.com/jnjaby&gt;@jnjaby&lt;/denchmark-link&gt;
's fear that gpu is not deterministic seems due to non-determinism in reduction (probably), because I only see 1e-5 error between two runs on the gpu. But I see a ~5770. relative  error between the gpu vs cpu. Could you please take a look:
import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)

with tf.device("/cpu:0"):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.get_variable("weight_cpu", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    bias = tf.get_variable("bias_cpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_cpu = tf.nn.bias_add(conv, bias)


with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.get_variable("weight_gpu", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    bias = tf.get_variable("bias_gpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_gpu = tf.nn.bias_add(conv, bias)


sess = tf.Session()
sess.run(tf.global_variables_initializer())
cpu_a=sess.run(conv_cpu)
gpu_a=sess.run(conv_gpu)
gpu_b=sess.run(conv_gpu)

def rel_error(a,ref):
  return np.max(np.abs((ref-a)/ref))
print ('relerror gpu_a vs cpu %f relerror gpu_b vs cpu 2 %f'%(rel_error(gpu_a, cpu_a), rel_error(gpu_b, cpu_a)))
print ('relerror gpu_a vs. gpu_b %f '%(rel_error(gpu_a, gpu_b)))
		</comment>
		<comment id='2' author='jnjaby' date='2017-07-31T06:28:00Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 because the weight initialized by CPU and GPU are different. I try to initialize weights with another . That really confuses.
import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)
weight_ = np.random.randn(9, 9, 1, 56)

with tf.device("/cpu:0"):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.constant(weight_, dtype=tf.float32, name="weight_cpu")
    bias = tf.get_variable("bias_cpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_cpu = tf.nn.bias_add(conv, bias)


with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    weight = tf.constant(weight_, dtype=tf.float32, name="weight_gpu")
    bias = tf.get_variable("bias_gpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_gpu = tf.nn.bias_add(conv, bias)


sess = tf.Session()
sess.run(tf.global_variables_initializer())
cpu_a=sess.run(conv_cpu)
gpu_a=sess.run(conv_gpu)
gpu_b=sess.run(conv_gpu)

def rel_error(a,ref):
  return np.max(np.abs((ref-a)/ref))

print ('relerror gpu_a vs cpu %f \nrelerror gpu_b vs cpu  %f'%(rel_error(gpu_a, cpu_a), rel_error(gpu_b, cpu_a)))
print ('relerror gpu_a vs. gpu_b %f '%(rel_error(gpu_a, gpu_b)))

print (np.array_equal(sess.run(conv_cpu), sess.run(conv_cpu)))
print (np.array_equal(sess.run(conv_gpu), sess.run(conv_gpu)))
		</comment>
		<comment id='3' author='jnjaby' date='2017-07-31T18:02:05Z'>
		I would agree with first making the initialization the same. One common way is to random initialize the weights in numpy, and use that in both paths.
		</comment>
		<comment id='4' author='jnjaby' date='2017-07-31T22:57:08Z'>
		This version shows no relative error between any of the implementations, so I am thinking there is no bug
import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)

weight = np.random.uniform(-1.,1., (9,9,1,56)).astype(np.float32)
bias = np.random.uniform(-.1,.1, (1)).astype(np.float32)


with tf.device("/cpu:0"):
    bottom = tf.constant(conv_, dtype=tf.float32)
    #weight = tf.get_variable("weight_cpu", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    #bias = tf.get_variable("bias_cpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_cpu = tf.nn.bias_add(conv, bias)


with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    #weight = tf.get_variable("weight_gpu", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))
    #bias = tf.get_variable("bias_gpu", initializer=np.zeros(1, dtype=np.float32))

    conv = tf.nn.conv2d_transpose(bottom, weight, [10, 19, 19, 1], [1, 3, 3, 1], padding='SAME')
    conv_gpu = tf.nn.bias_add(conv, bias)


sess = tf.Session()
sess.run(tf.global_variables_initializer())
cpu_a=sess.run(conv_cpu)
gpu_a=sess.run(conv_gpu)
gpu_b=sess.run(conv_gpu)
		</comment>
		<comment id='5' author='jnjaby' date='2017-08-01T01:55:33Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 The last case is consistent. I make another test case output  and  respectively, showing different result between  and . Commonly, however, the weights should remain the same after initialization. So let's clarify the questions:

Where is the non-determinism produced, Tensorflow or other libraries of GPU?
What is the difference between constant Tensor and variable Tensor?

import tensorflow as tf
import numpy as np

np.random.seed(1234)
conv_ = np.random.randn(10, 7, 7, 56)
weight = np.random.uniform(-1.,1., (9,9,1,56)).astype(np.float32)

with tf.device('/gpu:0'):
    bottom = tf.constant(conv_, dtype=tf.float32)
    biases = tf.get_variable("bias_gpu", initializer=np.zeros(1, dtype=np.float32))

    weight_con = tf.constant(weight, dtype=tf.float32)
    weight_var = tf.get_variable("weight_gpu", [9, 9, 1, 56], initializer=tf.random_normal_initializer(0, 0.001))

    conv_con = tf.nn.conv2d_transpose(bottom, weight_con, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')
    conv_var = tf.nn.conv2d_transpose(bottom, weight_var, [10, 19, 19, 1],[1, 3, 3, 1],padding='SAME')

    conv_con = tf.nn.bias_add(conv_con, biases)
    conv_var = tf.nn.bias_add(conv_var, biases)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

print (np.array_equal(sess.run(conv_con), sess.run(conv_con)))
print (np.array_equal(sess.run(conv_var), sess.run(conv_var)))
		</comment>
		<comment id='6' author='jnjaby' date='2017-08-28T03:16:28Z'>
		&lt;denchmark-link:https://github.com/zheng-xq&gt;@zheng-xq&lt;/denchmark-link&gt;
, are you able to answer &lt;denchmark-link:https://github.com/jnjaby&gt;@jnjaby&lt;/denchmark-link&gt;
's questions above? Thanks!
		</comment>
		<comment id='7' author='jnjaby' date='2017-08-28T18:06:40Z'>
		There are some known differences between CPU and GPU convolutions. Yang is working with Benoit to resolve them.
		</comment>
		<comment id='8' author='jnjaby' date='2018-01-03T19:31:28Z'>
		Any updates here? I keep having to switch back and forth between an old version of TensorFlow and the current one. Is addressing this a priority for the team?
		</comment>
		<comment id='9' author='jnjaby' date='2018-01-30T21:21:40Z'>
		Please refer to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/14601#issuecomment-361734250&gt;#14601 (comment)&lt;/denchmark-link&gt;
 for updates. Once we are using the updated version of eigen, you can verify if the bug is fixed.
		</comment>
		<comment id='10' author='jnjaby' date='2018-02-25T21:03:52Z'>
		I could be wrong, but I as of today, I don't think this issue has been addressed in the nightly wheel available over here: &lt;denchmark-link:http://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-mac/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly-1.head-py3-none-any.whl&gt;http://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-mac/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly-1.head-py3-none-any.whl&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='jnjaby' date='2018-04-09T02:16:24Z'>
		Sorry for bothering you, but are there any updates now? Thanks very much! &lt;denchmark-link:https://github.com/yzhwang&gt;@yzhwang&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/benoitsteiner&gt;@benoitsteiner&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='jnjaby' date='2019-08-06T21:56:33Z'>
		Please check with the latest version of TensorFlow. Feel free to reopen if the issues still persists.
		</comment>
		<comment id='13' author='jnjaby' date='2019-08-06T21:56:35Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=11882&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=11882&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>