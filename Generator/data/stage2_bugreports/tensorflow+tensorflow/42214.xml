<bug id='42214' author='MannyKai' open_date='2020-08-11T02:51:29Z' closed_time='2020-08-21T10:54:08Z'>
	<summary>TfLiteFlexDelegate invoke failed！</summary>
	<description>
System information

OS Platform and Distribution : MacOS TFLiteConverter -&gt;TFLiteModel
&amp;&amp; Android TF C++ library with FlexDelegate
TensorFlow installed from (source or binary): Source
TensorFlow version (or github SHA if from source): tf-nightly 2.4.0
Python version: 3.7
CPU version

TfliteConverter part
We have a deeplabv3+ model with resnetv2-101 base-architecture, and we have successfully converted it to tflite model based on tf-nightly 2.4 version。here is the python code：
&lt;denchmark-code&gt;   model = tf.saved_model.load(saved_model_dir)

  concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]

  concrete_func.inputs[0].set_shape([1, 257, 257, 3])

  converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])

  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]

  converter.allow_custom_ops = True

  converter.experimental_new_converter = True

  tflite_model = converter.convert()

  open('model_tflite.tflite', 'wb').write(tflite_model)

&lt;/denchmark-code&gt;

Then we build TF C++ library with FlexDelegate, and we got libtensorflow_flex.so.
Here is the C++ test code :
&lt;denchmark-code&gt;   TfLiteModel *model = TfLiteModelCreate(modelPath);

    options = TfLiteInterpreterOptionsCreate();
	
    TfLiteInterpreterOptionsSetNumThreads(options, 4);

    interpreter = TfLiteInterpreterCreate(model, options);

    TfLiteStatus status = TfLiteInterpreterAllocateTensors(interpreter);

    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);

    TfLiteStatus cpystatus = TfLiteTensorCopyFromBuffer(input_tensor, inputData, input_tensor-&gt;bytes);

    TfLiteStatus status = TfLiteInterpreterInvoke(interpreter);
&lt;/denchmark-code&gt;

But we will get an error when executing the invoke：
&lt;denchmark-code&gt;2020-08-11 10:17:44.612 14278-15583/com.kimguo.tensorflow2 I/tflite: Initialized TensorFlow Lite runtime.
2020-08-11 10:17:44.621 14278-15583/com.kimguo.tensorflow2 I/tflite: Created TensorFlow Lite delegate for select TF ops.
2020-08-11 10:17:44.623 14278-14278/com.kimguo.tensorflow2 E/GraphicExt: GraphicExtModuleLoader::CreateGraphicExtInstance false
2020-08-11 10:17:44.625 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::connect(this=0xe3eac000,api=1)
2020-08-11 10:17:44.626 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 5 nodes delegated out of 241 nodes with 3 partitions.
2020-08-11 10:17:44.630 14278-14307/com.kimguo.tensorflow2 D/mali_winsys: EGLint new_window_surface(egl_winsys_display *, void *, EGLSurface, EGLConfig, egl_winsys_surface **, EGLBoolean) returns 0x3000
2020-08-11 10:17:44.631 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::setBufferCount(this=0xe3eac000,bufferCount=3)
2020-08-11 10:17:44.633 14278-14307/com.kimguo.tensorflow2 D/Surface: Surface::allocateBuffers(this=0xe3eac000)
2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.
2020-08-11 10:17:44.709 14278-15583/com.kimguo.tensorflow2 I/tflite: TfLiteFlexDelegate delegate: 2 nodes delegated out of 9 nodes with 2 partitions.
2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 W/native: op_kernel.cc:1772 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
2020-08-11 10:17:44.823 14278-15583/com.kimguo.tensorflow2 E/tflite: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_0)
    	 (while executing 'TensorArrayScatterV3' via Eager)
2020-08-11 10:17:44.824 14278-15583/com.kimguo.tensorflow2 E/tflite: Node number 241 (TfLiteFlexDelegate) failed to invoke.
&lt;/denchmark-code&gt;

There are some flex operators in our model，such as “FlexTensorArrayV3”，“FlexTensorArrayScatterV3”,
“FlexTensorArraySizeV3”，“FlexTensorArrayGatherV3”.. and I can find them from allowlisted_flex_ops.cc.  They can be well “Allocate”, But when "invoke", this error will be prompted，Does anyone have a problem like this？。
	</description>
	<comments>
		<comment id='1' author='MannyKai' date='2020-08-11T08:12:07Z'>
		&lt;denchmark-link:https://github.com/MannyKai&gt;@MannyKai&lt;/denchmark-link&gt;

I am unable to replicate the issue faced due to indentation error in code shared, can you please provide a colab gist with the error for us to analyse.
		</comment>
		<comment id='2' author='MannyKai' date='2020-08-11T11:10:43Z'>
		
@MannyKai
I am unable to replicate the issue faced due to indentation error in code shared, can you please provide a colab gist with the error for us to analyse.

The code is whole test code。
Does tensorflow lite c library support flex op well ？
		</comment>
		<comment id='3' author='MannyKai' date='2020-08-11T16:26:16Z'>
		&lt;denchmark-link:https://github.com/MannyKai&gt;@MannyKai&lt;/denchmark-link&gt;

Please refer to &lt;denchmark-link:https://www.tensorflow.org/lite/guide/ops_select#c&gt;this link&lt;/denchmark-link&gt;
 and let us know if it helps.
		</comment>
		<comment id='4' author='MannyKai' date='2020-10-27T08:25:47Z'>
		I compiled benchmark_model_plus_flex and ran into the same issue. I was trying to benchmark the following model:
&lt;denchmark-link:http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz&gt;http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz&lt;/denchmark-link&gt;

converted into TFLite format with the following code:
def do_convert(saved_model, output_file):
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model)
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,
        tf.lite.OpsSet.SELECT_TF_OPS,
    ]
    model = converter.convert()
    with open(output_file, "wb") as f:
        f.write(model)
The exact error is
&lt;denchmark-code&gt;native : op_kernel.cc:1763 OP_REQUIRES failed at tensor_array_ops.cc:1035 : Not found: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_774)
ERROR: Container __per_step_0 does not exist. (Could not find resource: __per_step_0/_tensor_arraysTensorArrayV3_774)
         (while executing 'TensorArrayScatterV3' via Eager)
ERROR: Node number 276 (TfLiteFlexDelegate) failed to invoke.
&lt;/denchmark-code&gt;

and the command line is
./benchmark_model_plus_flex --graph=ssd_mobilenet_v1_coco_2018_01_28.tflite
I compiled TF master branch (was &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/4625f1d87f17537a8d50dc68a213d2da875c12ce&gt;4625f1d&lt;/denchmark-link&gt;
) using SDK 30.0.2 and NDK r21d.
Any help?
		</comment>
	</comments>
</bug>