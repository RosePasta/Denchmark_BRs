<bug id='20452' author='sleighsoft' open_date='2018-07-01T10:29:15Z' closed_time='2018-07-26T17:30:55Z'>
	<summary>Keras TimeDistributed with Input and no batch_size fails</summary>
	<description>
OS: Windows 10 &amp; Ubuntu 16.04 tested
Tensorflow 1.8
Python 3.6.5
The following code shows the problem.
When using Input with a batch_size everything works fine, but without it it fails.
I assumed that when setting the batch_size in batch_shape to None or using shape instead that the batch_size would then be dynamic.
from tensorflow.python.keras.layers import Input, Lambda, TimeDistributed
from tensorflow.python.keras import backend as K


i_batch = Input(batch_shape=(32, 18, 64, 512))
i_batch_none_error = Input(batch_shape=(None, 18, 64, 512))
i_error = Input(shape=(18, 64, 512))


def reduce_sum(x):
  return K.sum(x, axis=-2)


sumpool = Lambda(reduce_sum, output_shape=(512,))
# Computes correct shape (?, 18, 512)
print(TimeDistributed(sumpool, name='t')(i_batch))

# Both throw warnings
# Computes incorrect shape (?, 18, 64, 512)
print(TimeDistributed(sumpool, name='t')(i_batch_none_error))
# Computes incorrect shape (?, 18, 64, 512)
print(TimeDistributed(sumpool, name='t')(i_error))
	</description>
	<comments>
		<comment id='1' author='sleighsoft' date='2018-07-01T18:36:20Z'>
		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow installed from
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce
		</comment>
		<comment id='2' author='sleighsoft' date='2018-07-16T01:14:24Z'>
		&lt;denchmark-link:https://github.com/sleighsoft&gt;@sleighsoft&lt;/denchmark-link&gt;
 I could not reproduce the issue. With the code snippet that you have shared here is the output I got:
&lt;denchmark-code&gt;Tensor("t/transpose_1:0", shape=(32, 18, 512), dtype=float32)
Tensor("t_1/Reshape_1:0", shape=(?, 18, 512), dtype=float32)
Tensor("t_2/Reshape_1:0", shape=(?, 18, 512), dtype=float32)
&lt;/denchmark-code&gt;

Are you still seeing the issue?
		</comment>
		<comment id='3' author='sleighsoft' date='2018-07-26T09:06:27Z'>
		I have this issue when running it under tensorflow-gpu==1.8.0.
I tried it with the most recent tf-nightly==1.10.0.dev20180609 and there it works.
		</comment>
		<comment id='4' author='sleighsoft' date='2018-07-26T17:30:55Z'>
		Thank you for checking. Closing the issue now as it seems to have been fixed.
		</comment>
		<comment id='5' author='sleighsoft' date='2018-07-27T11:56:19Z'>
		I have not tried it with the GPU version. It is an assumption that it is fixed there as well
		</comment>
		<comment id='6' author='sleighsoft' date='2018-07-27T15:23:09Z'>
		Please feel free to re-open the issue if you see it again.
		</comment>
	</comments>
</bug>