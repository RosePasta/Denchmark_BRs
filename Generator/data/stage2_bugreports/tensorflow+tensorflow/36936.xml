<bug id='36936' author='milongo' open_date='2020-02-20T16:52:54Z' closed_time='2020-04-27T21:08:45Z'>
	<summary>Does passing 'training' flag to tf.keras.Sequential do anything?</summary>
	<description>
&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;

&lt;denchmark-link:https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function&gt;https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function&lt;/denchmark-link&gt;

Please provide a link to the documentation entry, for example:
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/Sequential&gt;https://www.tensorflow.org/api_docs/python/tf/keras/Sequential&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/Model&gt;https://www.tensorflow.org/api_docs/python/tf/keras/Model&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

It is unclear whether the Sequential class makes use a 'training' flag fed into it during training/inference, as the tutorial above implies.
&lt;denchmark-h:h3&gt;Clear description&lt;/denchmark-h&gt;

When building a custom model subclassing from tf.keras.Model, the standard signature for writing the call is as follows: def call(self, inputs, training=None, mask=None):
If my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything, as documentation from the class doesn't mention this flag.
Looking at the customization tutorial above, however, the flag is passed into a Sequential model that does not include layers whose behavior change during training/inference. So I don't know if that flag is doing anything.
&lt;denchmark-h:h3&gt;Correct links&lt;/denchmark-h&gt;

Is the link to the source code correct?
&lt;denchmark-h:h3&gt;Parameters defined&lt;/denchmark-h&gt;

Are all parameters defined and formatted correctly?
&lt;denchmark-h:h3&gt;Returns defined&lt;/denchmark-h&gt;

Are return values defined?
&lt;denchmark-h:h3&gt;Raises listed and defined&lt;/denchmark-h&gt;

Are the errors defined? For example,
&lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises&gt;https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Usage example&lt;/denchmark-h&gt;

Is there a usage example?
See the API guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_ref&gt;https://www.tensorflow.org/community/contribute/docs_ref&lt;/denchmark-link&gt;

on how to write testable usage examples.
&lt;denchmark-h:h3&gt;Request visuals, if applicable&lt;/denchmark-h&gt;

Are there currently visuals? If not, will it clarify the content?
&lt;denchmark-h:h3&gt;Submit a pull request?&lt;/denchmark-h&gt;

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs&gt;https://www.tensorflow.org/community/contribute/docs&lt;/denchmark-link&gt;
,
docs API guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_ref&gt;https://www.tensorflow.org/community/contribute/docs_ref&lt;/denchmark-link&gt;
 and the
docs style guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_style&gt;https://www.tensorflow.org/community/contribute/docs_style&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='milongo' date='2020-02-21T13:38:39Z'>
		
If my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything

Any training boolean flag passed to a Sequential model will be passed to each and every of its layers, which will trigger training-only behaviours if any is implemented. Typically, one will have dropout applied conditionally on this flag, in which case passing it will indeed have an effect.
Note that using the default keras training loop (i.e. the fit method) will automatically pass this flag along (while it will be set to False in evaluate and predict).
		</comment>
		<comment id='2' author='milongo' date='2020-02-21T14:19:58Z'>
		Thank you for your answer. Can you please point me towards a source code file where I can see this behavior? Perhaps the docs should include this information as well since it's not very clear in my opinion.
		</comment>
		<comment id='3' author='milongo' date='2020-02-24T08:53:37Z'>
		You can see in the definition of  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/sequential.py#L269&gt;here&lt;/denchmark-link&gt;
 that it expects a  flag, and that it will indeed be passed to any sublayer whose  signature includes that keyword.
As for the use of  itself, you can notably read about it &lt;denchmark-link:https://www.tensorflow.org/guide/keras/custom_layers_and_models#privileged_training_argument_in_the_call_method&gt;here&lt;/denchmark-link&gt;
 in the Keras guide :)
		</comment>
		<comment id='4' author='milongo' date='2020-02-26T08:35:01Z'>
		&lt;denchmark-link:https://github.com/milongo&gt;@milongo&lt;/denchmark-link&gt;
, Does the &lt;denchmark-link:https://github.com/pandrey-fr&gt;@pandrey-fr&lt;/denchmark-link&gt;
's comment help in resolving your issue?
		</comment>
		<comment id='5' author='milongo' date='2020-02-26T15:59:52Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/pandrey-fr&gt;@pandrey-fr&lt;/denchmark-link&gt;
's comments do answer my questions, but I still feel the documentation for  should include the  flag somewhere in the arguments i.e.
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#arguments_21&gt;https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#arguments_21&lt;/denchmark-link&gt;
 and make it explicit that the flag is passed to subsequent layers and made use of  those layers have it defined in their behavior, whether they're custom or not.
		</comment>
		<comment id='6' author='milongo' date='2020-02-26T16:27:29Z'>
		&lt;denchmark-link:https://github.com/milongo&gt;@milongo&lt;/denchmark-link&gt;
 To be clear, the flag is passed  as part of ,  and . The fact that a model's call may accept a  argument is documented &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/Model&gt;here&lt;/denchmark-link&gt;
 :

If you subclass Model, you can optionally have a training argument (boolean) in call, which you can use to specify a different behavior in training and inference:

The fact that  instances may accept it (and will receive it if so) is part of their API, as indicated &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#__call__&gt;here&lt;/denchmark-link&gt;
.
That being said, it may be worth to augment the existing documentation of Sequential as you suggest it.
		</comment>
		<comment id='7' author='milongo' date='2020-02-26T21:09:08Z'>
		&lt;denchmark-link:https://github.com/pandrey-fr&gt;@pandrey-fr&lt;/denchmark-link&gt;
 what is the behavior if the model is called in a custom training loop? Such as the following:
&lt;denchmark-code&gt;    for epoch in range(epochs):
        for step, (x_batch, y_batch) in enumerate(train_dataset):

            if epoch &gt; mlp.warm_up:
                for layer in mlp.mean.layers:
                    layer.trainable = False
                for layer in mlp.variance.layers:
                    layer.trainable = True
            with tf.GradientTape() as tape:
                output = mlp(x_batch)
                loss = loss_fn(y_batch, output)
            grads = tape.gradient(loss, mlp.trainable_weights)
            optimizer.apply_gradients(zip(grads, mlp.trainable_weights))
            mean_preds, _ = output
&lt;/denchmark-code&gt;

Here, mlp is a custom class subclassed from tf.keras.Model, whose's call function is as follows:
&lt;denchmark-code&gt;    def call(self, inputs, training=None, mask=None):

        mean_predictions = []
        variance_predictions = []
        for idx in range(self.num_models):
            mean_predictions.append(self.mean[idx](inputs))
            variance_predictions.append(self.variance[idx](inputs))
        mean_stack = tf.stack(mean_predictions)
        variance_stack = tf.stack(variance_predictions)

        return mean_stack, variance_stack
&lt;/denchmark-code&gt;

You can see that I do not bother to pass the training flag anywhere.
(For clarity, mlp has two sets of ensembles, one in self.mean and another in self.variance, where each ensemble is defined as a list of tf.keras.Sequential modules):
&lt;denchmark-code&gt;self.mean = [
            tf.keras.Sequential([
                layers.Dense(512, activation='relu', input_shape=(self.input_dim,)),
                layers.Dropout(0.5),
                layers.Dense(256, activation='relu'),
                layers.Dropout(0.5),
                layers.Dense(self.output_dim)
            ])
            for _ in range(self.num_models)
        ]
&lt;/denchmark-code&gt;

Interestingly enough, my models train just fine, so I'm guessing the default internal value for the flag is training=True, even if the headers have it as training=None. I.e. somewhere, that flag's value is actually set to True.
		</comment>
		<comment id='8' author='milongo' date='2020-02-27T08:08:40Z'>
		As far as I know, if you do not pass training=True explicitly, your model should run without dropout. This may not be prejudicial to training, but if you meant to make use of it it would probably be worth it to pass the flag within your custom training loop.
		</comment>
		<comment id='9' author='milongo' date='2020-02-27T15:03:31Z'>
		Ahh I think you are correct. Passing the flag explicitly drastically affected training.
Thank you!
I could close this now, but what about the documentation issues I mentioned?
		</comment>
		<comment id='10' author='milongo' date='2020-02-27T15:09:19Z'>
		You are welcome; I am glad this was helpful. Regarding documentation, perhaps &lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 could assign the arbitration to a tensorflower; otherwise, maybe you could submit a PR to the tensorflow-docs repository?
		</comment>
		<comment id='11' author='milongo' date='2020-03-18T22:24:07Z'>
		&lt;denchmark-link:https://github.com/milongo&gt;@milongo&lt;/denchmark-link&gt;
 Are you planning to create any PR to update the docs? Thanks!
		</comment>
		<comment id='12' author='milongo' date='2020-04-10T01:06:16Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='13' author='milongo' date='2020-04-20T20:08:42Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='14' author='milongo' date='2020-04-27T21:08:43Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
	</comments>
</bug>