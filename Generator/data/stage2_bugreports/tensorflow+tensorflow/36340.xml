<bug id='36340' author='fcunilim' open_date='2020-01-30T16:32:18Z' closed_time='2020-03-04T10:05:17Z'>
	<summary>100-line Tensorflow code and Keras equivalent do not produce the same result, Tensorflow result does not converge, why?</summary>
	<description>
I am doing experiments with a basic GAN, the code of which is provided for both TF (I use version 1.15.2, using TF 2.x-style API) and Keras (2.2.5), below.
The GAN learns to generate 2D points fitting a 2D curve, f(x) = x^2. Every point is considered as a 2D vector 'individual', (x,y).
The following 2 python programs compile and run out-of-the-box, and are meant to produce exactly the same result. However, the TF version does not converge properly at all.
I tried everything I could to understand what's going wrong, to no avail. Obviously, there is something that I miss.
The TF version is largely inspired from the official GAN tutorial located here: &lt;denchmark-link:https://www.tensorflow.org/tutorials/generative/dcgan&gt;https://www.tensorflow.org/tutorials/generative/dcgan&lt;/denchmark-link&gt;

I also provide the code in 2 pastebin links (for your convenience):
Keras version: &lt;denchmark-link:https://pastebin.com/N26e3hWh&gt;https://pastebin.com/N26e3hWh&lt;/denchmark-link&gt;

Tensorflow version: &lt;denchmark-link:https://pastebin.com/9ebmSyJB&gt;https://pastebin.com/9ebmSyJB&lt;/denchmark-link&gt;

Keras version:
&lt;denchmark-code&gt;import numpy as np
from numpy import hstack
from numpy import zeros
from numpy import ones
from numpy.random import rand
from numpy.random import randn
from keras.models import Sequential
from keras.layers import Dense
import keras.backend as K
from matplotlib import pyplot

class GanPointGraph_Keras(object):
    
    def __init__(self):
        self.latent_dim = 5
        self.discriminator = self.define_discriminator()
        self.generator = self.define_generator(self.latent_dim)
        self.gan_model = self.define_gan(self.generator, self.discriminator)

    def define_discriminator(self, n_inputs=2):
        model = Sequential()
        model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        print(K.eval(model.optimizer.lr))
        return model
    
    def define_generator(self, latent_dim, n_outputs=2):
        model = Sequential()
        model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))
        model.add(Dense(n_outputs, activation='linear'))
        return model
    
    def define_gan(self, generator, discriminator):
        discriminator.trainable = False
        model = Sequential()
        model.add(generator)
        model.add(discriminator)
        model.compile(loss='binary_crossentropy', optimizer='adam')
        return model
    
    def generate_latent_points(self, n):
        x_input = randn(self.latent_dim * n)
        x_input = x_input.reshape(n, self.latent_dim)
        return x_input
    
    def generate_fake_samples(self, n):
        x_input = self.generate_latent_points(n)
        X = self.generator.predict(x_input)
        return X

    def generate_real_samples(self, n):
        X1 = rand(n) - 0.5
        X2 = X1 * X1
        X1 = X1.reshape(n, 1)
        X2 = X2.reshape(n, 1)
        X = hstack((X1, X2))    
        return X
    
    def train(self):
        n_batch = 128
        half_batch = int(n_batch / 2)
        x_real = self.generate_real_samples(half_batch)
        y_real = ones((half_batch, 1))
        x_fake = self.generate_fake_samples(half_batch)
        y_fake = zeros((half_batch, 1))
        self.discriminator.train_on_batch(x_real, y_real)
        self.discriminator.train_on_batch(x_fake, y_fake)
        x_gan = self.generate_latent_points(n_batch)
        y_gan = ones((n_batch, 1))
        self.gan_model.train_on_batch(x_gan, y_gan)

if __name__ == "__main__":
    g = GanPointGraph_Keras();

    for epoch in range(10000):
        print('Epoch', epoch)
        g.train()
        if epoch % 1000 == 0:
            g_objects = g.generate_fake_samples(100)
            r_objects = g.generate_real_samples(100)
 
            pyplot.clf()
            pyplot.title('Keras iteration ' + str(epoch))
            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')
            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')
            pyplot.show()
&lt;/denchmark-code&gt;

Tensorflow version:
&lt;denchmark-code&gt;import tensorflow as tf
tf.enable_eager_execution() # if using TF 1.15.x
from tensorflow.keras import layers

import numpy as np
from numpy.random import rand
from numpy import hstack

from matplotlib import pyplot

class GanPointGraph(object):

    def __init__(self):
        self.latent_dim = 5
        self.generator = self.make_generator()
        self.discriminator = self.make_discriminator()
        
        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)        
        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        
    def make_generator(self):
        model = tf.keras.Sequential()
        model.add(layers.Dense(15, activation='relu', input_dim=self.latent_dim))
        model.add(layers.Dense(2))
        return model
      
    def make_discriminator(self):
        model = tf.keras.Sequential()
        model.add(layers.Dense(25, activation='relu', input_dim=2))
        model.add(layers.Dense(1, activation='sigmoid')) # (-infinity, infinity) -&gt; (0, 1)
        return model
    
    def generator_loss(self, fake_output):
        #return self.cross_entropy(tf.ones_like(fake_output), fake_output)
        return tf.reduce_mean(tf.math.log(1-fake_output))

    def discriminator_loss(self, real_output, fake_output):
        #real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)
        #fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)
        #total_loss = real_loss + fake_loss
        #return total_loss
        loss_real = tf.reduce_mean(-tf.math.log(real_output))
        loss_fake = tf.reduce_mean(-tf.math.log(1-fake_output))
        D_loss = loss_real + loss_fake
        return D_loss

    def generate_real_samples(self, n):
        X1 = rand(n) - 0.5
        X2 = X1 * X1
        X1 = X1.reshape(n, 1)
        X2 = X2.reshape(n, 1)
        x_train = hstack((X1, X2))
        return x_train
    
    def generate_fake_samples(self, n):
        z_sample = np.random.normal(0, 1.0, size=[n, self.latent_dim]).astype(np.float32)
        return self.generator(z_sample, training=False).numpy()
    
    def train(self):
        images = self.generate_real_samples(128);
        noise = tf.random.normal([images.shape[0], self.latent_dim])
        
        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            generated_images = self.generator(noise, training=True)
            
            real_output = self.discriminator(images, training=True)
            fake_output = self.discriminator(generated_images, training=True)
            
            gen_loss = self.generator_loss(fake_output)
            disc_loss = self.discriminator_loss(real_output, fake_output)
        
        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)
        
        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))
        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))
    
if __name__ == "__main__":
    g = GanPointGraph();
    
    for epoch in range(10000):
        print('Epoch', epoch)
        g.train()
        if epoch % 1000 == 0:
            g_objects = g.generate_fake_samples(100)
            r_objects = g.generate_real_samples(100)
 
            pyplot.clf()
            pyplot.title('Tensorflow iteration ' + str(epoch))
            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')
            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')
            pyplot.show()
&lt;/denchmark-code&gt;

If you run the above programs, you will see that the Keras version converges quite reliably. The GAN learns to fit the example points quite nicely. Generate points slowly project onto the curve, and come close to it after about 4000 epochs.
The TF version just "dances around" the solution, producing quite bad results, even after a high number of epochs. It never really converges. The movement it does is quite funny, navigating on the left, then on the right, and on the left again, and so on. Sometimes, it seems that it starts to fit the curve, but it quickly goes away unfortunately.
What am I doing wrong in Tensorflow? Obviously, there is something that I am missing.
Please note:

the layers for both versions are the same (initalizers may both be set to 'he_uniform', this does not change the outcome of the test)
the learning rate is the same (0.001 for both Keras and Tensorflow Adam optimizers)
I tried with TF 1.15.0 and 1.15.2 runtimes, same result.
all samples I have tried on my computer seem to work fine.

I am using Windows x64 and Python 3.6.8 (just the regular Python distribution, not Anaconda).
Help would be immensely appreciated as I would like to migrate from Keras to Tensorflow.
Many thanks in advance.
	</description>
	<comments>
		<comment id='1' author='fcunilim' date='2020-01-31T06:08:17Z'>
		I have tried on colab with TF version 1.15  and was able to reproduce the issue.Please, find the gist for &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/529137515280fa62e9c448c1b08af051/untitled611.ipynb&gt;Keras&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/253009155c80160420e3b804ee3c5162/untitled612.ipynb&gt;Tensorflow keras&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='fcunilim' date='2020-02-02T18:12:22Z'>
		I believe I made some important progress.
If I change the Adam optimizer settings to , convergence is  good.
(These settings are used for instance in this page: &lt;denchmark-link:https://towardsdatascience.com/dcgans-generating-dog-images-with-tensorflow-and-keras-fb51a1071432&gt;https://towardsdatascience.com/dcgans-generating-dog-images-with-tensorflow-and-keras-fb51a1071432&lt;/denchmark-link&gt;
)
When using the default Adam parameters (learning_rate=0.001, beta_1=0.9), convergence is almost never achieved.
I am a bit puzzled here, as with Keras or Tensorflow 1.x, convergence is (in most cases) achieved with the same default parameters (learning rate=0.001, beta_1=0.9).
Has the Adam optimizer implementation changed between TF 1.x and 2.x? (on a side note, are there any known implementation differences between Keras and TF2.x-Keras?)
		</comment>
		<comment id='3' author='fcunilim' date='2020-03-04T10:05:14Z'>
		Hi &lt;denchmark-link:https://github.com/fcunilim&gt;@fcunilim&lt;/denchmark-link&gt;
 :
Thanks for reporting this. The original Keras Adam is not correct, i.e., the step changes non-deterministically, and it was fixed. The tf.keras Adam has been the correct version. It seems that in this particular case the correct version behaves worse given the learning rate, which is not surprising for GAN models. Sorry for the confusion though!
		</comment>
		<comment id='4' author='fcunilim' date='2020-03-04T10:05:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36340&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36340&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='fcunilim' date='2020-03-10T14:16:40Z'>
		Thank you!

Le mer. 4 mars 2020 à 11:05, tanzhenyu &lt;notifications@github.com&gt; a écrit :
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


 Hi @fcunilim &lt;https://github.com/fcunilim&gt; :
 Thanks for reporting this. The original Keras Adam is not correct, i.e.,
 the step changes non-deterministically, and it was fixed. The tf.keras Adam
 has been the correct version. It seems that in this particular case the
 correct version behaves worse given the learning rate, which is not
 surprising for GAN models. Sorry for the confusion though!

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#36340?email_source=notifications&amp;email_token=AONNO3W37XB4ZTWHRFXTG3LRFYRWDA5CNFSM4KNZB6I2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOENXEYLA#issuecomment-594431020&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AONNO3RLMRUELXMMTTZAZY3RFYRWDANCNFSM4KNZB6IQ&gt;
 .



		</comment>
	</comments>
</bug>