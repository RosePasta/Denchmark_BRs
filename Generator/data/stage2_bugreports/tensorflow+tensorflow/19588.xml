<bug id='19588' author='huangynn' open_date='2018-05-28T06:53:00Z' closed_time='2018-06-29T04:38:48Z'>
	<summary>Using Dataset api with Estimator in MirroredStrategy,  Non-DMA-safe string tensor error</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos
TensorFlow installed from (source or binary): pip install tensorflow-gpu
TensorFlow version (use command below):1.8.0
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):4.8.5
CUDA/cuDNN version: 9.0
GPU model and memory:GeForce GTX 1080Ti * 4
Exact command to reproduce:

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Using mutilple gpu by MirroredStrategy, Get ' Non-DMA-safe string tensor may not be copied from/to a GPU.' error
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/12636388/40601170-a716ad26-6286-11e8-9fb1-7b5d1b6c6545.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/12636388/40601198-c0ad1f36-6286-11e8-956c-3023fcc86292.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/12636388/40601204-c6ecdaf8-6286-11e8-96cd-588ef276f5b4.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/12636388/40601209-cbc60c16-6286-11e8-8dd0-6b54df3ab8fe.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='huangynn' date='2018-06-01T03:22:52Z'>
		I meet the same problem &lt;denchmark-link:https://github.com/skye&gt;@skye&lt;/denchmark-link&gt;
  in using object detection apis
		</comment>
		<comment id='2' author='huangynn' date='2018-06-04T22:34:51Z'>
		Can you provide code to repro the problem?
		</comment>
		<comment id='3' author='huangynn' date='2018-06-04T22:45:54Z'>
		Rohan/Priya: I'm guessing this is what happens when a tf.string tensor goes through prefetch_to_devices(), but unclear whether it should be handled in the client program (e.g. by splitting out strings from the prefetched dataset) or in the FunctionBufferingResource (e.g. by allowing some outputs to be "host memory" only).
		</comment>
		<comment id='4' author='huangynn' date='2018-06-05T00:39:54Z'>
		def get_inputs(mode, csv_file, batch_size, label_list, preprocess):
iterator_initializer_hook = IteratorInitializerHook()
def inputs():
is_training = mode==estimator.ModeKeys.TRAIN
ds = tf.data.TextLineDataset(csv_file).skip(1)
&lt;denchmark-code&gt;    def classification_parse_line(line):
        columns = ['img','label']
        img_name, label = tf.decode_csv(
            line, 
            record_defaults = [[''],['']]) 
        # assume every pic is rgb
        image_decoded = tf.image.decode_png(
            tf.read_file(img_name),
            channels=3)
        image = preprocess(image_decoded)
        """image = image_preprocessing_fn(
            image, 
            image_size,
            image_size)"""
        return image,label
    
    cpu_num = multiprocessing.cpu_count()
    ds = ds.apply(
        tf.contrib.data.map_and_batch(
            classification_parse_line,
            batch_size=batch_size,
            num_parallel_batches=cpu_num))   
    ds = ds.prefetch(None)
    iterator = ds.make_initializable_iterator()

    iterator_initializer_hook.iterator_initializer_func = lambda sess: sess.run(iterator.initializer)
    return ds

return iterator_initializer_hook, inputs
&lt;/denchmark-code&gt;

distribution = tf.contrib.distribute.MirroredStrategy()
config = tf.estimator.RunConfig(
model_dir=args.model_dir,
tf_random_seed=912,
save_summary_steps=args.save_summary_steps,
save_checkpoints_steps=args.save_interval_steps,
keep_checkpoint_max=5*get_num_replicas(),
train_distribute=distribution,
session_config=session_config
)
classifier = tf.estimator.Estimator(
my_model,
config=config,
params=params)
for epoch in range(args.num_epochs):
logger.info('Starting epoch %d / %d' % (
epoch + 1, args.num_epochs))
classifier.train(
train_ds,
hooks=[train_ds_hook])
classifier.evaluate(
val_ds,
hooks=[val_ds_hook])
		</comment>
		<comment id='5' author='huangynn' date='2018-06-05T00:41:20Z'>
		Nothing special, its just common code with MirroredStrategy.
If replace MirroredStrategy with OneDeviceStrategy, everything went well
		</comment>
		<comment id='6' author='huangynn' date='2018-06-19T18:43:39Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='7' author='huangynn' date='2018-06-19T20:59:54Z'>
		As Derek mentioned, currently we don't have a mechanism for specifying if some outputs should be in host memory and we assume (to a large extent) that they'd be in device memory. Strings can't be in device memory, hence the bug. I shall work on having a dynamic method of identifying which outputs should be allocated on the host / device. Stay tuned for a fix in a bit.
		</comment>
		<comment id='8' author='huangynn' date='2018-06-28T05:19:18Z'>
		&lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 can this issue be closed now that your fix has been merged?
		</comment>
	</comments>
</bug>