<bug id='24221' author='eliorc' open_date='2018-12-07T15:38:18Z' closed_time='2019-02-22T22:48:31Z'>
	<summary>`tf.estimator.Estimator` methods `.evaluate`/`.train` calls deplete CPU RAM</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Null
TensorFlow installed from (source or binary): pip install tensorflow-gpu
TensorFlow version (use command below): v1.10.0-0-g656e7a2b34 1.10.0
Python version: 3.6.7
Bazel version (if compiling from source): Null
GCC/Compiler version (if compiling from source): Null
CUDA/cuDNN version: cudNN 7.4.1
GPU model and memory: NVIDIA GTX 1070 8GB

Describe the current behavior
While using a tf.estimator.Estimator class, each separate call of .train/.evaluate results on extra CPU RAM permanent usage. In my use case, every time I call .evaluate I get another 200MB RAM allocated on my CPU (even though I'm training on the GPU) RAM, which then never gets free. This ultimately results in MemoryError since after a few training/validation rounds the RAM gets full.
Describe the expected behavior
Memory used by these methods should be released when done.
Code to reproduce the issue
&lt;denchmark-code&gt;EXAMPLE_TYPE = Tuple[str, List[int], List[int], List[int], int]
DATASET_TYPE = List[EXAMPLE_TYPE]

class ExampleGenerator:
    def __init__(self, train: DATASET_TYPE, validation: DATASET_TYPE):
        self._data = {
            'train': train,
            'validation': validation,
        }

    def generate(self, source: str, shuffle: bool = False) -&gt; Generator[
        EXAMPLE_TYPE, None, None]:
        """
        Yields examples

        :param source: Source to generate from (train/validation)
        :return: Example
        """

        if shuffle:
            random.shuffle(self._data[source])

        for example in self._data[source]:
            yield example

def input_fn(example_generator: ExampleGenerator, source: str, batch_size: int):
    dataset = tf.data.Dataset.from_generator(generator=lambda: example_generator.generate(source, shuffle=True),
                                             output_types=(tf.string, tf.int32, tf.int32, tf.int32, tf.int32),
                                             output_shapes=(
                                                 tf.TensorShape([]), tf.TensorShape([None]), tf.TensorShape([None]),
                                                 tf.TensorShape([None]), tf.TensorShape([])))

    # Shuffle, repeat, and batch the examples.
    dataset = dataset.padded_batch(batch_size,
                                   padded_shapes=([], [None], [None], [None], []))

    dataset = dataset.prefetch(buffer_size=batch_size)

    iterator = dataset.make_one_shot_iterator()

    eid, text, pos, dep, label = iterator.get_next()

    return {'eid': eid, 'text': text, 'text_pos': pos, 'text_dep': dep}, label

def model(...):
    ...

for _ in range(params['epochs']):
    classifier.train(input_fn=lambda: input_fn(example_generator, source='train', batch_size=params['batch_size']))
    classifier.evaluate(input_fn=lambda: input_fn(example_generator, source='validation', batch_size=params['batch_size']))
&lt;/denchmark-code&gt;

To figure out why I get MemoryErrors, I have used the Python interactive mode, and called .evaluate(...) and .train(...) while observing RAM usage, after each call, another 200MB RAM got occupied on the CPU RAM, eventually depleting all available RAM.
	</description>
	<comments>
		<comment id='1' author='eliorc' date='2019-02-08T18:42:49Z'>
		Apologies for the delay in response. Can you please build against latest version of TF and test again.
Note that TF 1.13.0-rc0 comes pre-built cuda 10 binaries, thus you may have to upgrade your cuda version. Thanks!
		</comment>
		<comment id='2' author='eliorc' date='2019-02-22T22:48:31Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='3' author='eliorc' date='2019-02-23T09:07:48Z'>
		I'll try to run the code again and monitor its RAM when I'll have time, bit busy
		</comment>
	</comments>
</bug>