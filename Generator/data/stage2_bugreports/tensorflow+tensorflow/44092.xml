<bug id='44092' author='HarryAA' open_date='2020-10-16T16:01:07Z' closed_time='2021-01-08T19:22:06Z'>
	<summary>Loss of shape information when using dilation_rate != 1 in Conv layers</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"


Running TF 2.3.0 in colab I have come across an issue very similar to the one fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29542&gt;#29542&lt;/denchmark-link&gt;
 . The difference however being that I have an extra dimension that is undefined at layer construction time. With a dilation rate = 1 the Conv2D layer in the following code produces an output shape as expected (None, None, 512, 64). However, for layers with a dilation rate &gt; 1, the "width" dimension shape information is lost and the result is (None, None, None, 64).
&lt;denchmark-code&gt;import tensorflow as tf

class DenseBlock(tf.keras.Model):
  def __init__(self, input_size, depth=5, in_channels=64):
    super(DenseBlock, self).__init__(name='')
    self.depth = depth
    self.in_channels = in_channels
    self.pad = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 1)))
    self.twidth = 2
    self.kernel_size = (self.twidth, 3)
    for i in range(self.depth):
      dil = 2**i
      pad_length = self.twidth + (dil-1)*(self.twidth-1)-1
      setattr(self, 'pad{}'.format(i+1), tf.keras.layers.ZeroPadding2D(((pad_length, 0), (1, 1))))
      setattr(self, 'conv{}'.format(i+1), tf.keras.layers.Conv2D(filters=self.in_channels, kernel_size=self.kernel_size, dilation_rate=(dil, 1)))
      setattr(self, 'norm{}'.format(i+1), tf.keras.layers.LayerNormalization())
      setattr(self, 'prelu{}'.format(i+1), tf.keras.layers.PReLU(shared_axes=[1, 2]))

  def call(self, input_tensor):
    skip = input_tensor
    for i in range(self.depth):
      print('Dilation rate', 2**i)
      x = getattr(self, 'pad{}'.format(i+1))(skip)
      print(x.shape)
      x = getattr(self, 'conv{}'.format(i+1))(x)
      print(x.shape)
      x = getattr(self, 'norm{}'.format(i+1))(x)
      x = getattr(self, 'prelu{}'.format(i+1))(x)
      skip = tf.concat((x, skip), axis=3)
    return x

input = tf.keras.layers.Input(shape=(None, 512, 64))
x = DenseBlock(512, 5, 64)(input)
&lt;/denchmark-code&gt;

Describe the expected behavior
I believe that the behaviour for dilation rate &gt; 1 should match that of the case where dilation rate = 1.

Here is a &lt;denchmark-link:https://colab.research.google.com/drive/11wATlQbeahUHQE63RFsMFl6EV598j1sm?usp=sharing&gt;link&lt;/denchmark-link&gt;
 to a colab notebook that reproduces the issue
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The cell output is:
&lt;denchmark-code&gt;2.3.0
Dilation rate 1
(None, None, 514, 64)
(None, None, 512, 64)
Dilation rate 2
(None, None, 514, 128)
(None, None, None, 64)
Dilation rate 4
(None, None, 514, 192)
(None, None, None, 64)
Dilation rate 8
(None, None, 514, 256)
(None, None, None, 64)
Dilation rate 16
(None, None, 514, 320)
(None, None, None, 64)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='HarryAA' date='2020-10-19T08:43:45Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/8dd49ffe9df3f1551d4f3f7a09941b7f/44092.ipynb&gt;TF v2.3&lt;/denchmark-link&gt;
 and &lt;denchmark-link:dilation_rate&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='2' author='HarryAA' date='2021-01-08T19:22:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44092&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44092&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>