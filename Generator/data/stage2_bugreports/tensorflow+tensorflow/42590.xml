<bug id='42590' author='rosssketchup' open_date='2020-08-22T23:58:29Z' closed_time='2020-08-25T15:09:37Z'>
	<summary>Cannot assign a device for operation when using multiple embedding columns</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script
provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux, Amazon Deep Learning Image, Amazon Linux 2
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
happens on a mobile device:
No
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
2.3
Python version:
3.7.7
Bazel version (if compiling from source):
N/A
GCC/Compiler version (if compiling from source):
N/A
CUDA/cuDNN version:
CUDA Version: 11.0
GPU model and memory:
NVIDIA Tesla M60 - 16 GB (Amazon EC2 g3s.xlarge - single GPU)
Exact command to reproduce:
python repro.py

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When using the functional API with Keras with more than one embedding input, I get device placement issues. The actual error is:

tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation functional_1/first_embed_layer/test_embedding/test_embedding_weights/embedding_lookup_sparse/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node functional_1/first_embed_layer/test_embedding/test_embedding_weights/embedding_lookup_sparse/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0]

I've found several workarounds:

Instead of using the functional API, use keras.model.Sequential() with a single DenseFeatures layer containing both of my embedding columns (I was trying to avoid this because I can't find an easy way to pull out the weights of only one of the columns when doing it this way, without searching by dimension size).
Run it without a GPU. Also not ideal because of the slow down.

I also tried doing a single DenseFeatures layer with both of my embedding columns using the functional API, but that results in the same placement errors. For some reason not using the functional API fixes it.
A minimal example from my code that repros the problem reliably:
&lt;denchmark-code&gt;import tensorflow as tf

def create_model():
  test_input = tf.keras.Input(shape=(None,), dtype='string', name='test')
  test2_input = tf.keras.Input(shape=(None,), dtype='string', name='test2')
  feature_layer_inputs = {}
  feature_layer_inputs['test'] = test_input
  feature_layer_inputs['test2'] = test2_input

  vocab_list = ['This', 'That', 'Thing']
  feature_col = tf.feature_column.categorical_column_with_vocabulary_list(
      key='test', vocabulary_list=vocab_list,
      num_oov_buckets=0)
  embed_col = tf.feature_column.embedding_column(
      categorical_column=feature_col, dimension=4, combiner='mean')
  first_embed_layer = tf.keras.layers.DenseFeatures(
      feature_columns=[embed_col], name="first_embed_layer")

  second_vocab_list = ['a', 'b', 'c']
  feature_col_two = tf.feature_column.categorical_column_with_vocabulary_list(
      key='test2', vocabulary_list=second_vocab_list,
      num_oov_buckets=0)
  embed_col_two = tf.feature_column.embedding_column(
      categorical_column=feature_col_two, dimension=4, combiner='mean')
  second_embed_layer = tf.keras.layers.DenseFeatures(
      feature_columns=[embed_col_two], name="second_embed_layer")
  
  x = first_embed_layer(feature_layer_inputs)
  y = second_embed_layer(feature_layer_inputs)
  x = tf.keras.layers.concatenate([x, y])
  
  hidden_layer = tf.keras.layers.Dense(units=35, use_bias=False,
      name="user-embeddings-layer")(x)

  model = tf.keras.Model(
    inputs=[v for v in feature_layer_inputs.values()],
    outputs=[hidden_layer]
  )

  model.compile(optimizer=tf.keras.optimizers.Adagrad(lr=.01),
                # loss=loss_func,
                loss="sparse_categorical_crossentropy",
                metrics=['accuracy'])
  return model

in_tensor = tf.constant(['This', 'That'])
other_tensor = tf.constant(['a', 'b'])

features = {
  'test': in_tensor,
  'test2': other_tensor,
}
y = tf.constant([1, 2])

model = create_model()
history = model.fit(x=features, y=y,
                    epochs=10, shuffle=False, 
                    batch_size=1,
                    verbose=1,
                    callbacks=[])
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rosssketchup' date='2020-08-24T04:45:54Z'>
		&lt;denchmark-link:https://github.com/rosssketchup&gt;@rosssketchup&lt;/denchmark-link&gt;

I am able to replicate this issue on GPU, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/805b5d56c0a2da6c69fb008635156ab1/untitled385.ipynb&gt;gist here&lt;/denchmark-link&gt;
, i do not observe any slowness when GPU is not used.
		</comment>
		<comment id='2' author='rosssketchup' date='2020-08-24T15:12:03Z'>
		It won't be slow with that toy data, but I don't think I'd want to run my full dataset with a CPU.
Updating what I said in the bug, I actually can't get my own code to work with the Sequential API. I get the same colocation errors, even though it seemed to work with the toy example above.
I also get: Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class 'dict'&gt; input: Consider rewriting this model with the Functional API.
So I guess I really should be using the Functional API.
		</comment>
		<comment id='3' author='rosssketchup' date='2020-08-25T00:51:05Z'>
		We are moving away from feature columns in favor of Keras Preprocessing Layers starting in 2.3
		</comment>
		<comment id='4' author='rosssketchup' date='2020-08-25T02:39:01Z'>
		Good to know, so the proper way to do this would be using several instances of keras.layers.Embedding?
I liked the feature columns because dealing with combining/averaging and out of vocabulary values seemed easier. With raw keras, I have to use globalaveragepooling1d and manual masking. But if that's the proper way to go, then I'll switch to using that.
Thanks
		</comment>
		<comment id='5' author='rosssketchup' date='2020-08-25T03:20:18Z'>
		
Good to know, so the proper way to do this would be using several instances of keras.layers.Embedding?
I liked the feature columns because dealing with combining/averaging and out of vocabulary values seemed easier. With raw keras, I have to use globalaveragepooling1d and manual masking. But if that's the proper way to go, then I'll switch to using that.
Thanks

Yes that is the proper way. I think shared embedding column + keras doesn't work today?
Re manual masking -- if you're using ragged tensor, I think for many use cases you don't need masking at all
		</comment>
		<comment id='6' author='rosssketchup' date='2020-08-25T14:52:01Z'>
		Ok great, and good point, I didn't even think of using Ragged Tensors. I'm using variable length string arrays as input, and you're right, Ragged Tensors would remove the need for masking.
I will give it a shot. I think we can close this issue as won't fix if the feature columns are being deprecated.
Thanks for the help.
		</comment>
		<comment id='7' author='rosssketchup' date='2020-08-25T15:09:37Z'>
		Closing per comments above.
		</comment>
		<comment id='8' author='rosssketchup' date='2020-08-25T15:09:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42590&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42590&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>