<bug id='34339' author='anshkumar' open_date='2019-11-16T12:54:12Z' closed_time='2019-12-02T08:13:54Z'>
	<summary>TensorRT not working due to eager execution</summary>
	<description>
I'm trying to convert my saved model to tensorRT but I'm failing due to following error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py", line 911, in __init__
    assert context.executing_eagerly()
AssertionError
&lt;/denchmark-code&gt;

Here, is my code
&lt;denchmark-code&gt;from tensorflow.python.compiler.tensorrt import trt_convert

conversion_params = trt_convert.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt_convert.TrtPrecisionMode.FP16, max_batch_size=1, max_workspace_size_bytes=8000000000)

trt_converter = trt_convert.TrtGraphConverterV2(input_saved_model_dir='/home/xavier2/apple_trt_l1/nonRT',  conversion_params=conversion_params)
&lt;/denchmark-code&gt;

Here are my specs:
Tensorflow version: 1.14.0
Platform: NVIDIA Jetson AGX Xavier developer kit
Python: 3.6.8
	</description>
	<comments>
		<comment id='1' author='anshkumar' date='2019-11-18T06:21:29Z'>
		&lt;denchmark-link:https://github.com/anshkumar&gt;@anshkumar&lt;/denchmark-link&gt;
 ,
Hi, looks like the issue is fixed in TF version-2.0. Can you try running the code in 2.0? kindly find the gist of &lt;denchmark-link:https://colab.sandbox.google.com/gist/oanush/76966638dba18670472226ba0dac6607/34339.ipynb&gt;colab&lt;/denchmark-link&gt;
 for your reference. Thanks!
		</comment>
		<comment id='2' author='anshkumar' date='2019-11-20T07:12:27Z'>
		My platform is NVIDIA Jetson AGX Xavier; tensorflow is provided by nvidia. The list of version provided by them is &lt;denchmark-link:https://developer.download.nvidia.com/compute/redist/jp/v42/tensorflow-gpu/&gt;here&lt;/denchmark-link&gt;
. NVIDIA does not provide Tensorflow-2.0 for Jetson.
		</comment>
		<comment id='3' author='anshkumar' date='2019-11-26T23:09:06Z'>
		TrtGraphConverterV2 only converts TF 2.0 SavedModels as shown &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/compiler/tensorrt/trt_convert.py#L851&gt;here&lt;/denchmark-link&gt;

Are you using Tensorflow 2.0 Saved model or Tensorflow 1.14 saved model? If you are using a saved model that is other than 2.0 then this throws an error.
		</comment>
		<comment id='4' author='anshkumar' date='2019-12-02T08:13:54Z'>
		Yes I was using Tensorflow lower than 2.0. Using following command I'm able to convert properly,
trt_converter = trt_convert.TrtGraphConverter(input_saved_model_dir='/home/xavier3/single_model', precision_mode="FP16", is_dynamic_op=True)
		</comment>
		<comment id='5' author='anshkumar' date='2019-12-02T08:13:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34339&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34339&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='anshkumar' date='2020-05-08T18:02:09Z'>
		Hi,
I am facing the same issue with tensorflow==2.1.0+nv20.4
		</comment>
		<comment id='7' author='anshkumar' date='2020-05-09T02:51:57Z'>
		Ran into same issue after fresh install of Jetpack 4.4 on Jetson Nano  which contains tensorflow==2.1.0+nv20.4. Loaded and built pycuda and got the same error. After looking into code, found the exception was due to tf.executing_eagerly() == False.
##-- Work around --
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
....
....
tf.compat.v1.enable_eager_execution()
print('Using Tensorflow version: {0}'.format(tf.version.VERSION))
print(tf.executing_eagerly())
Was able to execute trt.TrtGraphConverterV2 on keras models
&lt;denchmark-h:h2&gt;I was under the impression that all TF 2.x versions ran with executing_eagerly == TRUE as default. When I import tensorflow 2.1.0+nv20.4 it seems that execute_eagerly is initialized as false in JP 4.4&lt;/denchmark-h&gt;




import tensorflow as tf
2020-05-08 22:22:59.965357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2
2020-05-08 22:23:07.427738: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7
2020-05-08 22:23:07.474677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7
print(tf.executing_eagerly())
False



&lt;denchmark-h:h2&gt;When I do the same thing on JP 4.3 with tensorflow 2.1.0+nv20.3.tf2&lt;/denchmark-h&gt;

Python 3.6.9 (default, Apr 18 2020, 01:56:04)
[GCC 8.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.



import tensorflow as tf
2020-05-08 22:47:32.666516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-05-08 22:47:37.064950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-05-08 22:47:37.067243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
print(tf.executing_eagerly())
True



&lt;denchmark-h:h3&gt;Anyone have any thoughts ? Or is this a bug&lt;/denchmark-h&gt;

		</comment>
	</comments>
</bug>