<bug id='32709' author='iperov' open_date='2019-09-21T10:59:36Z' closed_time='2019-09-23T16:36:02Z'>
	<summary>out of memory flood on the simplest op</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win7 x64
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0rc1
Python version: 3.7.4
CUDA/cuDNN version: 10.0, 3.7.5
GPU model and memory: GTX 1060, 6GB

Describe the current behavior
&lt;denchmark-code&gt;import tensorflow as tf
x = [[2.]]
m = tf.matmul(x, x)
&lt;/denchmark-code&gt;

results infinite flood:
&lt;denchmark-code&gt;2019-09-21 14:55:58.537800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.540800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.543800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.546800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.549800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.552800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.555800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.566800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.569800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
2019-09-21 14:55:58.572800: I tensorflow/stream_executor/cuda/cuda_driver.cc:830
] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: ou
t of memory
&lt;/denchmark-code&gt;

Describe the expected behavior
expected to work properly
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
x = [[2.]]
m = tf.matmul(x, x)
&lt;/denchmark-code&gt;

Other logs
&lt;denchmark-code&gt;2019-09-21 14:58:51.205800: I tensorflow/stream_executor/platform/default/dso_lo
ader.cc:44] Successfully opened dynamic library cudart64_100.dll
&gt;&gt;&gt; tf.constant(1)
2019-09-21 14:58:54.148800: I tensorflow/stream_executor/platform/default/dso_lo
ader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-09-21 14:58:54.220800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
618] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
2019-09-21 14:58:54.226800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
618] Found device 1 with properties:
name: GeForce GT 730 major: 3 minor: 5 memoryClockRate(GHz): 0.9015
pciBusID: 0000:03:00.0
2019-09-21 14:58:54.229800: I tensorflow/stream_executor/platform/default/dlopen
_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-09-21 14:58:54.239800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
731] Ignoring visible gpu device (device: 1, name: GeForce GT 730, pci bus id: 0
000:03:00.0, compute capability: 3.5) with core count: 2. The minimum required c
ount is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROC
ESSOR_COUNT.
2019-09-21 14:58:54.245800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
746] Adding visible gpu devices: 0
2019-09-21 14:58:54.248800: I tensorflow/core/platform/cpu_feature_guard.cc:142]
 Your CPU supports instructions that this TensorFlow binary was not compiled to
use: AVX2
2019-09-21 14:58:54.308800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
618] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
2019-09-21 14:58:54.312800: I tensorflow/stream_executor/platform/default/dlopen
_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-09-21 14:58:54.319800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
746] Adding visible gpu devices: 0
2019-09-21 14:58:55.057800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-21 14:58:55.061800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
165]      0
2019-09-21 14:58:55.064800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
178] 0:   N
2019-09-21 14:58:55.071800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1
304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 wit
h 4675 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bu
s id: 0000:01:00.0, compute capability: 6.1)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='iperov' date='2019-09-23T06:08:09Z'>
		&lt;denchmark-link:https://github.com/iperov&gt;@iperov&lt;/denchmark-link&gt;
 ,
Tried running the code in colab for tf-2.0rc1 did not face any error, please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/oanush/f92701b1542fca43d2d1f66b0f262077/32709.ipynb&gt;gist&lt;/denchmark-link&gt;
 of the colab. kindly share us the gist if the issue is replicating.Thanks!
		</comment>
		<comment id='2' author='iperov' date='2019-09-23T06:24:31Z'>
		&lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;
  did you try it with cudnn 7.5.0 ?
I installed 7.4.1 and all is fine.
		</comment>
		<comment id='3' author='iperov' date='2019-09-23T06:25:15Z'>
		also problem in windows, not in linux colab.
Read System information.
		</comment>
		<comment id='4' author='iperov' date='2019-09-23T15:49:32Z'>
		Are you using the GPU device only for this compute task?
Seems like an issue in your GPU, not in TensorFlow
		</comment>
		<comment id='5' author='iperov' date='2019-09-23T16:03:22Z'>
		&lt;denchmark-link:https://github.com/mihaimaruseac&gt;@mihaimaruseac&lt;/denchmark-link&gt;
 are you troll?
issue in my GPU?? srsly?? I thought developers of tensorflow are a bit smarter.
this is simple task to reproduce the bug.
This bug is reproduced only with cudnn 7.5.0 on windows, but 7.4.1 works fine.
		</comment>
		<comment id='6' author='iperov' date='2019-09-23T16:11:19Z'>
		No, not a troll. Please always assume good intent as I was basing my question on &lt;denchmark-link:https://stackoverflow.com/questions/34514324/error-using-tensorflow-with-gpu/34514932#34514932&gt;https://stackoverflow.com/questions/34514324/error-using-tensorflow-with-gpu/34514932#34514932&lt;/denchmark-link&gt;

That being said, can you also post output of nvidia-smi, on both 7.5.0 and 7.4.1, before and after running your script?
		</comment>
		<comment id='7' author='iperov' date='2019-09-23T16:25:22Z'>
		
nvidia-smi, on both 7.5.0 and 7.4.1

nvidia-smi does not depend on cudnn.
cudnn is only the one dll that loaded by python environment.
I can pass to it any version I want. So 7.5.0 has bug, but 7.4.1 - has not.
		</comment>
		<comment id='8' author='iperov' date='2019-09-23T16:26:59Z'>
		It doesn't depend on cudnn but it also shows the state of the GPU so we can detect if there is a memory leak.
		</comment>
		<comment id='9' author='iperov' date='2019-09-23T16:36:02Z'>
		I don't know why, but bug is no more reproducable :(
		</comment>
		<comment id='10' author='iperov' date='2019-09-23T16:36:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32709&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32709&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='iperov' date='2019-09-23T16:37:09Z'>
		So it turns out it was the state of your system.
		</comment>
		<comment id='12' author='iperov' date='2019-09-23T16:37:37Z'>
		or the hidden bug of tf
		</comment>
		<comment id='13' author='iperov' date='2019-09-23T16:40:39Z'>
		Doubtful to be a hidden bug of TF (as it seems to always happen on your issues) but if it reproduces again please post full details and debug how much memory your GPU still has available.
		</comment>
	</comments>
</bug>