<bug id='36383' author='guillaumelorre28' open_date='2020-01-31T17:45:35Z' closed_time='2020-02-04T09:38:29Z'>
	<summary>TimeDistributed does not work with mixed precision training</summary>
	<description>
Please go to Stack Overflow for help and support:
&lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;https://stackoverflow.com/questions/tagged/tensorflow&lt;/denchmark-link&gt;

If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.1.0
Python version: 3.6
Bazel version (if compiling from source): X
GCC/Compiler version (if compiling from source): X
CUDA/cuDNN version: on CPU
GPU model and memory: X
Exact command to reproduce:

import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds
from tensorflow.keras.mixed_precision import experimental as mixed_precision


policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)


def preprocess(ex):
    image = tf.cast(tf.expand_dims(ex['image'], axis=0), tf.float32) / 255.
    image = tf.image.resize(image, [224, 224])

    return image, ex['label']


data = tfds.load(name='imagenette/full-size', split="train", data_dir="/home/glorre/tensorflow_datasets",
                 shuffle_files=True).repeat()
data = data.map(preprocess).batch(5)

image = keras.Input(shape=[1, 224, 224, 3], name="seq")
features = keras.layers.TimeDistributed(
    keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)

features = keras.layers.Lambda(lambda x: tf.squeeze(x, axis=[1]))(features)

logits = keras.layers.Dense(10)(features)
logits = keras.layers.Activation('linear', dtype='float32')(logits)

model = keras.Model(inputs=image, outputs=logits)

optimizer_1 = keras.optimizers.Adam(0.01)
loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer=optimizer_1, loss=loss)

model.summary()

model.fit(data, epochs=10, steps_per_epoch=10)
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

TimeDistributed layer raises an input shape error when used with mixed precision.
It works fine without mixed precision
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Traceback (most recent call last):
File "/home/glorre/Code2/test_mixed_precision/mixed_precision.py", line 25, in 
keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 807, in call
self._set_mask_metadata(inputs, outputs, input_masks)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 1937, in _set_mask_metadata
output_masks = self.compute_mask(inputs, previous_mask)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/wrappers.py", line 324, in compute_mask
output_mask = self.layer.compute_mask(inner_inputs, inner_mask)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 509, in compute_mask
output_tensors = self._run_internal_graph(inputs, mask=mask)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 891, in _run_internal_graph
output_tensors = layer(computed_tensors, **kwargs)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 737, in call
self.name)
File "/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py", line 177, in assert_input_compatibility
str(x.shape.as_list()))
ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 1, 224, 224, 3]
Process finished with exit code 1
	</description>
	<comments>
		<comment id='1' author='guillaumelorre28' date='2020-02-03T09:41:20Z'>
		i am able to replicate the issue, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/533d87b190fe8a0f011c20bc829efab7/untitled21.ipynb&gt;gist&lt;/denchmark-link&gt;
 here.
		</comment>
		<comment id='2' author='guillaumelorre28' date='2020-02-03T18:02:31Z'>
		&lt;denchmark-link:https://github.com/guillaumelorre28&gt;@guillaumelorre28&lt;/denchmark-link&gt;
 I cannot reproduce the issue. Can you please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/e67d90d6542a8f3b7f1303b47fc70941/untitled21.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
When the code was ran without a GPU then it will throw a warning as follows and runs very slowly as mentioned in the warning.
&lt;denchmark-code&gt;WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING
The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.
If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='guillaumelorre28' date='2020-02-04T09:38:29Z'>
		Thanks it works fine with tf-nightly (I had the issue in tensorflow 2.1.0)
		</comment>
		<comment id='4' author='guillaumelorre28' date='2020-02-04T09:38:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36383&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36383&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>