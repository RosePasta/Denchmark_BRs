<bug id='8571' author='zakizhou' open_date='2017-03-21T04:02:58Z' closed_time='2017-09-05T04:09:07Z'>
	<summary>shape of state in the output of dynamic_rnn is undetermined</summary>
	<description>
short code:
&lt;denchmark-code&gt;sequence_lengths, (sequences, labels) = bucket_by_sequence_length(
                                              input_length=sequence_length,
                                              tensors=[sequence, label],
                                              batch_size=72,
                                              bucket_boundaries=[80, 160, 240, 320, 400],
                                              dynamic_pad=True)
lstm_cell = core_rnn_cell.BasicLSTMCell(num_units=56)
lookup = tf.nn.embedding_lookup(......)
_, state = tf.nn.dynamic_rnn(
                      cell=lstm_cell,
                      inputs=lookup,
                      sequence_length=sequence_lengths,
                      dtype=tf.float32)
&lt;/denchmark-code&gt;

then state.h and state.c should be of shape [72, 56], but actually the first dim(batch_size) is undetermined in program, is it a bug?
	</description>
	<comments>
		<comment id='1' author='zakizhou' date='2017-03-22T22:59:07Z'>
		CC &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 for comments
		</comment>
		<comment id='2' author='zakizhou' date='2017-03-23T00:24:54Z'>
		What is the shape of lookup?
		</comment>
		<comment id='3' author='zakizhou' date='2017-03-23T02:37:34Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 does it matter? let's say embedding matrix is of shape [vocab_size=90000, embed_size=500], so lookup will be of shape [72, unkown, 500], output should be [72, unknown, 56], state.h should be [72, 56]
		</comment>
		<comment id='4' author='zakizhou' date='2017-03-23T02:58:25Z'>
		can you confirm lookup is shape [72, unknown, 500]?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Mar 22, 2017 at 7:37 PM, Jie Zhou ***@***.***&gt; wrote:
 @ebrevdo &lt;https://github.com/ebrevdo&gt; does it matter? let's say embedding
 matrix is of shape [vocab_size=90000, embed_size=500], so lookup will be of
 shape [72, unkown, 500], output should be [72, unknown, 56], state.h should
 be [72, 56]

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#8571 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtimzfXEmN2UUFq-eea9GWs9sXt3nPQks5rodsDgaJpZM4MjTwm&gt;
 .



		</comment>
		<comment id='5' author='zakizhou' date='2017-03-23T03:11:51Z'>
		&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.contrib.rnn import core_rnn_cell
class Option(object):
    def __init__(self, filename, batch_size):
        self.sequences, self.labels, self.sequence_lengths = produce_input(filename=filename, batch_size=batch_size)
        self.vocab_size = 90000
        self.embedding_size = 500
        self.hidden_units = 56
        self.num_classes = 2



option = Option('train', 72)
embedding = tf.get_variable(name='embedding',
                            shape=[option.vocab_size, option.embedding_size],
                            initializer=tf.truncated_normal_initializer(stddev=0.05),
                            dtype=tf.float32)
lookup = tf.nn.embedding_lookup(embedding, option.sequences)
lstm_cell = core_rnn_cell.BasicLSTMCell(num_units=option.hidden_units, state_is_tuple=True)
output, state = tf.nn.dynamic_rnn(cell=lstm_cell,
                                  inputs=lookup,
                                  sequence_length=option.sequence_lengths,
                                  dtype=tf.float32)
output
Out[6]: 
&lt;tf.Tensor 'rnn/transpose:0' shape=(72, ?, 56) dtype=float32&gt;
lookup
Out[7]: 
&lt;tf.Tensor 'embedding_lookup:0' shape=(72, ?, 500) dtype=float32&gt;
state
Out[8]: 
LSTMStateTuple(c=&lt;tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 56) dtype=float32&gt;, h=&lt;tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 56) dtype=float32&gt;)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='zakizhou' date='2017-06-16T20:39:02Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 What's the status of this issue?
		</comment>
		<comment id='7' author='zakizhou' date='2017-06-16T22:17:31Z'>
		I think this is fixed in tf 1.2... OP can you confirm?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Jun 16, 2017 1:40 PM, "Geoffrey Irving" ***@***.***&gt; wrote:
 @ebrevdo &lt;https://github.com/ebrevdo&gt; What's the status of this issue?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#8571 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtim1bnJBGaW_RNRGN4k3WMBwCEKMO9ks5sEugSgaJpZM4MjTwm&gt;
 .



		</comment>
		<comment id='8' author='zakizhou' date='2017-09-03T20:32:37Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 Hi, I'm having the same problem with the shape of the state being undetermined when using a dynamic_rnn.
I'm using tensorflow version 1.2.1.
       (outputs,final_state) =( tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell, cell_bw=encoder_cell, inputs=encoder_inputs_embedded, sequence_length=encoder_inputs_length, dtype=tf.float32, time_major=True) )
Encoder_inputs_embedded is the following:
Tensor("embedding_lookup:0", shape=(8, 11, 20), dtype=float32)
while final_state is the following:
(LSTMStateTuple(c=&lt;tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32&gt;, h=&lt;tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32&gt;, h=&lt;tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32&gt;))
		</comment>
		<comment id='9' author='zakizhou' date='2017-09-04T15:38:01Z'>
		What about in tf 1.3?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sep 3, 2017 1:33 PM, "Alex Fabbri" ***@***.***&gt; wrote:
 Hi, I'm having the same problem with the shape of the state being
 undetermined when using a dynamic_rnn.
 I'm using tensorflow version 1.2.1.
 (outputs,final_state) =( tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,
 cell_bw=encoder_cell, inputs=encoder_inputs_embedded,
 sequence_length=encoder_inputs_length, dtype=tf.float32, time_major=True)
 )
 Encoder_inputs_embedded is the following:
 Tensor("embedding_lookup:0", shape=(8, 11, 20), dtype=float32) while
 final_state is the following:
 (LSTMStateTuple(c=&lt;tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_2:0'
 shape=(?, 20) dtype=float32&gt;, h=&lt;tf.Tensor 'bidirectional_rnn/fw/fw/while/Exit_3:0'
 shape=(?, 20) dtype=float32&gt;), LSTMStateTuple(c=&lt;tf.Tensor
 'bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32&gt;,
 h=&lt;tf.Tensor 'bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20)
 dtype=float32&gt;))

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#8571 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABtimwjPP56wsPLfP8KHXoeQh_cJ1W2dks5sew0EgaJpZM4MjTwm&gt;
 .



		</comment>
		<comment id='10' author='zakizhou' date='2017-09-04T17:20:34Z'>
		I just tried it on tf 1.3, and it worked. Thanks :)
		</comment>
		<comment id='11' author='zakizhou' date='2017-09-05T04:09:07Z'>
		Great!
		</comment>
	</comments>
</bug>