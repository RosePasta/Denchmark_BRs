<bug id='19611' author='boeseMilch' open_date='2018-05-29T08:06:47Z' closed_time='2019-01-11T04:26:07Z'>
	<summary>performance bug in Conv3d_transpose causes it to be a factor &amp;gt;100 slower than equivalent computations</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): This only concerns a nativ tensorflow function
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tested on Arch Linux, OS X and Windows 8
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.5, 1.7 &amp; 1.8 (cpu)
Python version: 2.7.14 and 3.6.5
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: CPU-only issue
GPU model and memory: CPU-only issue
Exact command to reproduce: tf.conv3d_transpose

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

tf.conv3d_transpose is a factor &gt;100 slower than other operations doing the same or an equivalent computation when working with tensorflow on cpu. This was previously reported in Issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/10535&gt;#10535&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7610&gt;#7610&lt;/denchmark-link&gt;
 , but none have provided a minimal example and both were closed due to inactivity.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Minimal example that shows how much slower conv3d_transposed is compared to einsum doing the same computation and to the conv3d forward computation:
&lt;denchmark-code&gt;import tensorflow as tf
import time

batch_size = 200
inp = tf.ones((batch_size,28,28,1,1))
filter_conv = tf.ones((28,28,1,1,50))
filter_fc = tf.ones((28,28,1,1,50))
lat = tf.ones((batch_size,1,1,1,50))

sess = tf.InteractiveSession()
t0 = time.time()
# takes 47sec on my machine
sess.run(tf.nn.conv3d_transpose(lat, filter_conv, inp.shape,[1,1,1,1,1],padding='VALID'))
delta_t = time.time() - t0
print("time it takes for conv3d_transpose:", delta_t)
t0 = time.time()
# takes .04sec on my machine
sess.run(tf.einsum("ijclm,abclm-&gt;iabcj",lat,filter_fc)) 
delta_t = time.time() - t0
print("time it takes with einsum to do the same computation:", delta_t)
t0 = time.time()
# takes .01sec on my machine
sess.run(tf.nn.conv3d(inp, filter_conv, [1,1,1,1,1],padding='VALID'))
delta_t = time.time() - t0
print("time it takes to apply conv3d:", delta_t)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='boeseMilch' date='2018-07-12T14:10:06Z'>
		I'm seeing extreme slowdown for 3D convolutions on CPU as well. I'm going through Keras Conv3D, but I suspect it's the same issue. Is there any workaround identified for this for the time being?
		</comment>
		<comment id='2' author='boeseMilch' date='2018-07-23T10:23:40Z'>
		
I'm seeing extreme slowdown for 3D convolutions on CPU as well. I'm going through Keras Conv3D, but I suspect it's the same issue. Is there any workaround identified for this for the time being?

Yes it might be the same issue. It should only be present in the gradients though, because these use the adjoint of conv3d.
I am unfortunately not aware of any workaround.
		</comment>
		<comment id='3' author='boeseMilch' date='2018-09-14T03:57:44Z'>
		&lt;denchmark-link:https://github.com/ckdotca&gt;@ckdotca&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/boeseMilch&gt;@boeseMilch&lt;/denchmark-link&gt;
  I've submitted couple of changes that should make Conv3D performance much better on CPU (I'd expect something like ~5x, maybe ~10x in some cases). One of them is custom kernels for backprop input and filter: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/e183b8d0328d7398cb6ffc530d1ae8fdbd2111c0&gt;e183b8d&lt;/denchmark-link&gt;

New kernels allocate quite large temporary buffers, so you might see increased peak memory usage. It's possible to fallback on original Eigen kernels using kernel_label_map (see 


tensorflow/tensorflow/python/framework/ops.py


         Line 3311
      in
      8cb0558






 def _kernel_label_map(self, op_to_kernel_label_map): 




), old kernels registered with a "eigen_tensor" label.
I'd be super interested to know how much this helps in your specific case.
		</comment>
		<comment id='4' author='boeseMilch' date='2019-01-11T00:40:17Z'>
		Hi &lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;
 &amp; &lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
 , please advise if we can consider this issue resolved and hence close it. Thanks.
		</comment>
		<comment id='5' author='boeseMilch' date='2019-01-11T04:26:07Z'>
		I think it's a solved issue.
		</comment>
		<comment id='6' author='boeseMilch' date='2019-01-11T18:58:36Z'>
		Thank you &lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>