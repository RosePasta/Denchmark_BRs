<bug id='37440' author='evgal' open_date='2020-03-09T10:57:07Z' closed_time='2020-05-02T03:00:23Z'>
	<summary>AutoGraph error with FOR loop in Keras loss</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, x64
TensorFlow installed from (source or binary): Binary (pip)
TensorFlow version (use command below): TF 2.1.0 as well as TF 2.2.0 (2.2.0.dev20200304)
Python version: 3.7
CUDA/cuDNN version: 10.1 / 7.6
GPU model and memory: Bug appears on several computers with different GPU

Describe the current behavior
Error "tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over tf.Tensor is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function." when using a FOR loop over a Tensor dimension in a custom Keras loss in AutoGraph mode.
Notice that when running eagerly, the bug does not appear.
Notice also that using a similar FOR loop in a custom Keras model works both in AutoGraph and Eager modes. The bug is specific to Keras Loss.
As expected, replacing the loop with a call to tf.map_fn works correctly.
Describe the expected behavior
The behavior should be the same as running eagerly, without any error.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Custom loss with a FOR loop. Raises an error in AutoGraph mode. 
# A similar FOR loop in a Keras model works as expected.
class CustomLoss(keras.losses.Loss):
	def call(self, y_true, y_pred):
		x = y_true + y_pred
		for i in tf.range(tf.shape(y_true)[0]): # The error is reaised here.
			x += 1
		return tf.reduce_mean(x)

if __name__ == "__main__" :
	data = np.random.random((1000, 3)).astype(np.float32)
	
	inputs = tf.keras.Input(shape=(1000,3))
	outputs = tf.keras.layers.Dense(3)(inputs)
	model = tf.keras.Model(inputs=inputs, outputs=outputs)
	
	model.compile(loss=CustomLoss()) # does NOT work
	# model.compile(loss=CustomLoss(), run_eagerly = True) # works
	
	model.fit(x=data, y=data)
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Log in attachment.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4306163/log.txt&gt;log.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='evgal' date='2020-03-09T12:43:36Z'>
		I have tried on colab with TF nightly and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/4f9dbb6a4b25213e7aec3edbe830f75f/untitled722.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks
		</comment>
		<comment id='2' author='evgal' date='2020-03-09T15:22:56Z'>
		I just noticed that the same bug also appears even if the loss is a simple callable instead of a subclass of keras.losses.Loss.
		</comment>
		<comment id='3' author='evgal' date='2020-03-09T17:16:55Z'>
		&lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
 AutoGraph is not applied in custom losses, I believe. Should we add it, for consistency with the Layer behavior?
		</comment>
		<comment id='4' author='evgal' date='2020-03-09T17:21:26Z'>
		Yes, i think it's a good idea to explore autographing custom Loss/Metric.
		</comment>
		<comment id='5' author='evgal' date='2020-03-10T07:53:29Z'>
		Your answer seems surprising to me. I expected that the whole training loop was AutoGraphed in the fit method, thus including any custom loss.
Thanks for your feedback.
		</comment>
		<comment id='6' author='evgal' date='2020-03-10T12:49:29Z'>
		This is a fair point. The training loop is indeed autographed. However, AutoGraph does not descend into internal TensorFlow APIs, and Keras is considered an internal API (it's part of the tensorflow module). In other places, like Keras layers, tf.data, etc., the internal APIs applies AutoGraph to all user-supplied functions. We need to do something consistent here.
So from that perspective, this can be considered a bug.
On the long term, the hope is to let AutoGraph step inside internal TF modules and remove issues like these, but we're not there yet.
		</comment>
		<comment id='7' author='evgal' date='2020-03-11T13:31:40Z'>
		Note that this might be a regression, though it's unclear how - has this loss been working in the past?
		</comment>
		<comment id='8' author='evgal' date='2020-03-11T15:45:20Z'>
		I cannot know as I only recently moved to TF 2.
		</comment>
		<comment id='9' author='evgal' date='2020-04-24T11:30:34Z'>
		Same issue is unfortunately also present with metrics on the last nightly build:
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow import keras

class CustomMetric(keras.metrics.Metric):
	def __init__(self):
		super(CustomMetric, self).__init__()
		self._metric = self.add_weight(name='metric', initializer='zeros', shape=())
	
	def update_state(self, y_pred, y_true, sample_weights=None):
		batchSize = tf.shape(y_pred)[0]
		for b in range(batchSize):
			self._metric.assign_add(1.0)
	
	def result(self):
		return self._metric
	
	def reset_states(self):
		self._metric.assign(0.0)

if __name__ == "__main__" :
	data = np.random.random((1000, 3)).astype(np.float32)
	
	inputs = tf.keras.Input(shape=(1000, 3))
	outputs = tf.keras.layers.Dense(3)(inputs)
	model = tf.keras.Model(inputs=inputs, outputs=outputs)
	
	model.compile(loss="mse", metrics=CustomMetric()) #Does NOT WORK
	# model.compile(loss="mse", metrics=CustomMetric(), run_eagerly=True) #WORKS
	
	model.fit(x=data, y=data)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='evgal' date='2020-05-02T03:00:25Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37440&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37440&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>