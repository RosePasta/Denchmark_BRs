<bug id='18376' author='AndRossi' open_date='2018-04-10T08:05:20Z' closed_time='2018-05-16T00:03:46Z'>
	<summary>Tensorflow MNIST Estimator: does the training batch size affect the graph expected input?</summary>
	<description>
Hello Tensorflow team,
First of all let me thank you for your amazing job. Tensorflow is one of the greatest Deep Learning frameworks out there.
I am opening this issue because I am experiencing  something weird after following the MNIST tutorial with the new Estimator high level interface.
The training and evaluation worked fine, but visualizing the model graph on Tensorboard there is something weird: the input shape that the model requires is 100 x 784.
I thought I would see ?x784 there, because even if I did use 100 as a batch size in training, in the model function it is explicitly specified that the amount of samples in the input is variable:
input_layer = tf.reshape(features["x"], [-1, 28, 28, 1], name="input_layer")
Here is a screenshot from Tensorboard: as you can see in the right box, expected input size is 100x784.
&lt;denchmark-link:https://user-images.githubusercontent.com/6909990/38542816-285b9dc4-3ca3-11e8-99ac-dafb8b3822f3.png&gt;&lt;/denchmark-link&gt;

At first I thought this was a Tensorboard issue, but after some testing I don't think so anymore.
First of all I tried to test my model changing the amount of input samples using the Estimator interface:

I tried to use the estimator.train and estimator.evaluate methods on the same model with different batch sizes (e.g. 50).
I tried to use the estimator.predict method passing a single sample at a time.

In these cases, everything worked fine.
After that, I have frozen my model using the "freeze_graph" script in the TensorFlow tools, and I have tried to load the frozen model into a GraphDef and to run it in a session.
This is the code I have used:
import tensorflow as tf
import cv2
import numpy as np

with tf.gfile.GFile("/path/to/my/frozen/model.pb", "rb") as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())

with tf.Graph().as_default() as graph:
    tf.import_graph_def(graph_def, name="prefix")

    for op in graph.get_operations():
        print(op.name)

    # so far it worked: i was able to print the operation of the MNIST model

    x = graph.get_tensor_by_name('prefix/input_layer:0')
    y = graph.get_tensor_by_name('prefix/softmax_tensor:0')

    with tf.Session(graph=graph) as sess:
        img = cv2.imread("/path/to/a/mnist/like/image.png", cv2.IMREAD_GRAYSCALE)
        img = np.asarray(1-img/255, dtype=np.float32)
        img = np.reshape(img, (28, 28, 1))

        y_out = sess.run(y, feed_dict={x: [img]})
        print(y_out)
I got this error: ValueError: Cannot feed value of shape (1, 28, 28, 1) for Tensor 'prefix/input_layer:0', which has shape '(100, 28, 28, 1)'
So, I feel that I get problems if I try to use this model without passing through the Estimator interface.
This worries me a lot, because in production I do need to freeze, optimize and convert my models to run them on TensorFlow Lite. So I won't be using the Estimator interface to perform prediction (but I still would like to employ it during training and evaluation).
&lt;denchmark-h:h3&gt;Environment&lt;/denchmark-h&gt;

: Yes, but only for testing purposes. My model was trained with this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/examples/tutorials/layers/cnn_mnist.py&gt;MNIST tutorial code&lt;/denchmark-link&gt;

: MacOS High Sierra 10.13.3
: pip
: 1.7
: N/A
: N/A
: N/A
: N/A
	</description>
	<comments>
		<comment id='1' author='AndRossi' date='2018-04-12T10:17:15Z'>
		An update on this issue.
I have asked the same question on StackOverflow too (&lt;denchmark-link:https://stackoverflow.com/questions/49740247/tensorflow-mnist-estimator-batch-size-affects-the-graph-expected-input/49780607#49780607&gt;here it is&lt;/denchmark-link&gt;
), and I got the advice to use &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/placeholder_with_default&gt;tf.placeholder_with_default&lt;/denchmark-link&gt;
 in addition to tf.reshape.
In fact, tf.reshape does not seem to discard shape information for tensors when using value -1.
Using a placeholder there seems to solve my problem :)
So, firstly, do you suggest me to use a placeholder in this way? Are there any contraindications I should be aware of?
Secondly, I suggest you to add this to your &lt;denchmark-link:https://www.tensorflow.org/tutorials/layers&gt;MNIST tutorial&lt;/denchmark-link&gt;
 :) .
In fact, after learning how tf.reshape really works, the description about it in the tutorial is quite misleading:

Note that we've indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features["x"], holding the size of all other dimensions constant. This allows us to treat batch_size as a hyperparameter that we can tune. For example, if we feed examples into our model in batches of 5, features["x"] will contain 3,920 values (one value for each pixel in each image), and input_layer will have a shape of [5, 28, 28, 1]. Similarly, if we feed examples in batches of 100, features["x"] will contain 78,400 values, and input_layer will have a shape of [100, 28, 28, 1].

Maybe you can add a more detailed footnote there?
Thank you :)
		</comment>
		<comment id='2' author='AndRossi' date='2018-05-01T01:26:14Z'>
		Thanks!
I think using  seems reasonable, but may be a bit confusing for the basic tutorial.
&lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
 Do you have thoughts on whether we should update the tutorial or how to better update the comment, since you replied to the SO question?
		</comment>
		<comment id='3' author='AndRossi' date='2018-05-01T16:04:58Z'>
		The comment looks true to me; the graph building code works for any batch dimension. features["x"] is the thing that should have an unknown batch dimension, not some reshape down the line. And you get that by using export_savedmodel with placeholders (or, if not using Estimator, by setting features["x"] to a placeholder manually).
		</comment>
		<comment id='4' author='AndRossi' date='2018-05-02T07:55:36Z'>
		Hi &lt;denchmark-link:https://github.com/allenlavoie&gt;@allenlavoie&lt;/denchmark-link&gt;
, thanks for addressing this issue.
Can you please give me more details about your answer?  The part I don't get is this:

features["x"] is the thing that should have an unknown batch dimension, not some reshape down the line

In the MNIST tutorial code, this is the model function:
&lt;denchmark-code&gt;def cnn_model_fn(features, labels, mode):
  """Model function for CNN."""
  # Input Layer
  input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

&lt;/denchmark-code&gt;

So features (and thus features["x"]) is a parameter of the model function.
According to the tutorial, the reshape is what sets the batch dimension as unknown.
I thought that was the reason why it is the very first operation performed in the model function
How can I make features["x"] have an unknown batch dimension since the beginning?
I'm a bit confused :(
		</comment>
		<comment id='5' author='AndRossi' date='2018-05-02T16:13:15Z'>
		 comes from the , in this case . Generally for export placeholders with unknown batch dimensions are provided by the &lt;denchmark-link:https://www.tensorflow.org/programmers_guide/saved_model#using_savedmodel_with_estimators&gt;serving_input_receiver_fn&lt;/denchmark-link&gt;
.
So maybe the MNIST tutorial should cover or at least link to something about export? It's a reasonable feature request (but not something I'll have time to work on in the foreseeable future).
		</comment>
		<comment id='6' author='AndRossi' date='2018-05-16T00:03:46Z'>
		We currently don't have anybody working on this. It would be great if you could help us by working on this and submitting a PR. Let us know if you need further clarification. Thanks!
		</comment>
	</comments>
</bug>