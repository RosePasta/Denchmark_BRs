<bug id='44387' author='sainttail' open_date='2020-10-28T15:43:30Z' closed_time='2020-10-29T18:24:09Z'>
	<summary>Tensorflow keras `save_weights` and `load_weights` produce random evaluation result on some dataset</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10 and Mac OS 10.15.7
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip install tensorflow
TensorFlow version (use command below): 2.3.1
Python version: Window 10 (3.7.4), Mac OS (3.8.5)
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: Has CUDA only on Window 10 (CUDA 10.1, cuDNN 7.6.5)
GPU model and memory: MSI GeForce GTX1080 8GB

Describe the current behavior
When save_weights and load_weights on keras model, seem to work fine in the same python session with training.
But after stop that python session and try calling load_weights on a new python session, some dataset produce a random evaluation result.
Describe the expected behavior
Evaluation result after load_weights should be the same across python session

&lt;denchmark-link:https://github.com/sainttail/tensorflow-load-weights-problem&gt;This &lt;/denchmark-link&gt;
is the full standalone reproducible problem when  each time get you a random evaluation loss and accuracy
	</description>
	<comments>
		<comment id='1' author='sainttail' date='2020-10-29T08:22:28Z'>
		Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/e6a008f2b0bb5ae45560a89a3f840802/44387.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='sainttail' date='2020-10-29T18:24:09Z'>
		&lt;denchmark-link:https://github.com/sainttail&gt;@sainttail&lt;/denchmark-link&gt;
 This is duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/43954&gt;#43954&lt;/denchmark-link&gt;

This is not an issue with  but the user code. I checked weights, labels, and features. There is no change in weight and labels after loading the model but there is a change in features. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/36fbef60353b521b76b01afdf242a199/44387.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
I am showing the difference in features before saving and after loading the weights. Please note that I restarted runtime as you mentioned.
&lt;denchmark-code&gt;After training model, loss: 0.9711138010025024, accuracy: 0.5186440944671631
test_features
[[-0.49808972  0.41190585 -0.27875089 ... -0.9401052   0.57645319
  -1.15568602]
 [-0.49808972  0.41190585 -0.27875089 ...  0.04428938  0.57645319
  -0.1313082 ]
 [ 0.70921448 -2.42566817 -0.27875089 ...  0.04428938  0.57645319
  -0.1313082 ]
 ...
 [ 0.70921448  0.41190585 -0.27875089 ...  0.04428938  0.57645319
  -0.1313082 ]
 [ 0.70921448  0.41190585  3.58440841 ...  0.04428938  0.57645319
  -2.18006385]
 [-1.70539393  0.41190585  3.58440841 ... -1.92449978  0.57645319
  -2.18006385]]


Restored model, loss: 1.0805716514587402, accuracy: 0.4203389883041382
test features
[[ 0.41190585  0.57645319 -0.49808972 ... -1.15568602 -0.27875089
  -0.9401052 ]
 [ 0.41190585  0.57645319 -0.49808972 ... -0.1313082  -0.27875089
   0.04428938]
 [-2.42566817  0.57645319  0.70921448 ... -0.1313082  -0.27875089
   0.04428938]
 ...
 [ 0.41190585  0.57645319  0.70921448 ... -0.1313082  -0.27875089
   0.04428938]
 [ 0.41190585  0.57645319  0.70921448 ... -2.18006385  3.58440841
   0.04428938]
 [ 0.41190585  0.57645319 -1.70539393 ... -2.18006385  3.58440841
  -1.92449978]]
&lt;/denchmark-code&gt;

As there is a change in features that were input to the model, evaluation metrics are changed.
I am closing this issue as this is not a bug or performance related to TensorFlow. Please feel free to reopen if I am mistaken. Thanks!
		</comment>
		<comment id='3' author='sainttail' date='2020-10-29T18:24:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44387&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44387&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='sainttail' date='2020-10-30T04:58:16Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks, for helping me. I've never once thought that the same code produce different feature values.
		</comment>
		<comment id='5' author='sainttail' date='2020-10-31T20:43:58Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Hello, I've some trouble with LSTM layer model saving and loading. After loading the whole model from other python file weights of the LSTM layer is being different from the saving session.
I've asked for it in one of the  issue topics. But could not find any workaround yet. I've just seen the &lt;denchmark-link:https://github.com/keras-team/keras/issues/14240#issue-718065369&gt;keras-team/keras#14240 (comment)&lt;/denchmark-link&gt;
 topic then decide to ask under this topic as well.
Here is my issue which I described: &lt;denchmark-link:https://github.com/keras-team/keras/issues/4875#issuecomment-719030257&gt;keras-team/keras#4875 (comment)&lt;/denchmark-link&gt;

You can see the weight differences between different python files right after training and after loading: &lt;denchmark-link:https://github.com/keras-team/keras/issues/4875#issuecomment-719905493&gt;keras-team/keras#4875 (comment)&lt;/denchmark-link&gt;

Just for a recap, my setup is:

Python 3.8.6
Keras 2.4.3
TensorFlow 2.3.1
Windows10 and using PowerShell

&lt;denchmark-h:h3&gt;UPDATE:&lt;/denchmark-h&gt;

Information for upcoming newbies like me
I should have applied normalization to my test-set in my second python file that's why I was getting wrong results.
		</comment>
		<comment id='6' author='sainttail' date='2020-10-31T23:04:46Z'>
		&lt;denchmark-link:https://github.com/namcho&gt;@namcho&lt;/denchmark-link&gt;
 Can you please create a new issue with a simple standalone code to reproduce the issue? It will help the community and helps us to track the issue better. Thanks!
		</comment>
	</comments>
</bug>