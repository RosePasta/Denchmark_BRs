<bug id='6452' author='ghost(ghost)' open_date='2016-12-22T02:51:20Z' closed_time='2017-01-17T19:18:55Z'>
	<summary>Nvidia GTX 960: Abnormal Memory Usage</summary>
	<description>
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu 16.04
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
-rw-r--r-- 1 root root   558720 Dec 17 21:39 libcudadevrt.a
lrwxrwxrwx 1 root root       16 Dec 17 21:39 libcudart.so -&gt; libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Dec 17 21:39 libcudart.so.8.0 -&gt; libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Dec 17 21:39 libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Dec 17 21:39 libcudart_static.a
lrwxrwxrwx 1 root root       13 Dec 18 16:34 libcudnn.so -&gt; libcudnn.so.5
lrwxrwxrwx 1 root root       17 Dec 18 16:34 libcudnn.so.5 -&gt; libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 78065952 Dec 18 16:34 libcudnn.so.5.0.5
-rwxr-xr-x 1 root root 79337624 Dec 18 16:34 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Dec 18 16:34 libcudnn_static.a
&lt;denchmark-h:h3&gt;If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)&lt;/denchmark-h&gt;

Just any neural network model. Strangely enough CIFAR functioned fine.
I used images of size 1750 * 1750.
&lt;denchmark-h:h3&gt;What other attempted solutions have you tried?&lt;/denchmark-h&gt;

I ran it on CPU and there was no issue at all other than the slow training speed.
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
Unfortunately because the memory leak crashes my computer within seconds, I can only give a rough example. It roughly says" GPU has failed to allocate ~~ around 8 GB of ram. The GTX 960 on my machine only has 4 GB of ram. I'm not sure why 8 GB was suddenly gobbled up at once.
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2016-12-28T22:58:44Z'>
		Could you provide a specific model command line that did not work well, just so some concreate example to try and reproduce. Thanks!
		</comment>
		<comment id='2' author='ghost(ghost)' date='2016-12-28T23:14:46Z'>
		The main and process portion should contain a workable example. If you download the code, all you need is to provide images in a format similar to CIFAR10 but with 1750 * 1750 images. Before running main.py, you may want to reconfigure the directory names, as they are for my personal PC(I should fix it).
The code can be found here:
&lt;denchmark-link:https://github.com/StructML/Neural-Network-Prostate&gt;https://github.com/StructML/Neural-Network-Prostate&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='ghost(ghost)' date='2017-01-03T18:35:51Z'>
		If you are not using tcmalloc, you should definitely try that first. It also might be the case that you are not using queues and instead trying to load all data on the GPU? How many images are you loading into memory. 8 GB of GPU memory would allow you to load 233 images (i.e. 17501750sizeof(float)*3 bytes per image). Also, please reask this on stack overflow since it involves your custom code rather than a supported demo.
		</comment>
		<comment id='4' author='ghost(ghost)' date='2017-01-17T19:18:55Z'>
		Closing due to lack of recent activity. We will reopen when additional information becomes available. Thanks!
		</comment>
		<comment id='5' author='ghost(ghost)' date='2017-01-17T19:20:06Z'>
		(A change that makes jemalloc the default allocator that may help with this problem will be released soon.) &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
, when will this be available?
		</comment>
		<comment id='6' author='ghost(ghost)' date='2017-01-17T19:54:25Z'>
		Note that it won't help for GPU memory allocation.
My guess is that you're using a large batch size. If you do the calculation &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 mentioned, you can estimate a lower bound for memory usage.
		</comment>
	</comments>
</bug>