<bug id='30596' author='braindotai' open_date='2019-07-11T11:04:51Z' closed_time='2019-08-02T09:25:38Z'>
	<summary>Very bad performance using Gradient Tape</summary>
	<description>
System information
Have I written custom code: Yes
OS Platform and Distribution: Ubuntu 18.04.2
TensorFlow installed from (source or binary): binary pip
TensorFlow version (use command below): 2.0.0-beta1
Python version: 3.6.8
CUDA/cuDNN version: 10.0/7
GPU model and memory: Tesla K80
I'm trying to learn Tensorflow 2.0, so I build a toy model and trained it using keres .fit
method, everything worked well.
But when I tried to implement the training loop from scratch, the training is happening very very slowly. Keras .fit method trained the model in 1 min 41 secs while the training code I've written taking more than 8 mins to train!!!
Below is my model definition:
model = tf.keras.Sequential()
model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.AveragePooling2D())
model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
model.add(layers.AveragePooling2D())
model.add(layers.Flatten())
model.add(layers.Dense(units = 120, activation = 'relu'))
model.add(layers.Dense(units = 84, activation = 'relu'))
model.add(layers.Dense(units = 10, activation = 'softmax'))
Below I'm defining loss, optimizer and accuracy:
optimizer = tf.keras.optimizers.Adam()
objective = tf.keras.losses.SparseCategoricalCrossentropy()
metric = tf.keras.metrics.SparseCategoricalAccuracy()
And Below is my training loop:
%%time
with tf.device('gpu:0'):
    for epoch in range(20):
        cumulative_loss = 0.0
        metric.reset_states()
        for images, labels in dataset:
            with tf.GradientTape() as tape:
                predictions = model(images, training=True)
                loss = objective(labels, predictions)

            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))

            cumulative_loss += loss
            metric.update_state(labels, predictions)

        print("Epoch: {} Loss: {} Accuracy: {}".format(epoch, cumulative_loss.numpy()/(batch + 1), metric.result()))
I'm runnig my notebook in Google Colab
	</description>
	<comments>
		<comment id='1' author='braindotai' date='2019-07-12T07:15:39Z'>
		Hey, this is just a wild guess, but maybe you need to wrap your train loop inside a tf.function?
		</comment>
		<comment id='2' author='braindotai' date='2019-07-12T10:19:29Z'>
		Looks like the code is incomplete.Can you please provide full code snippet to reproduce it on our environment.Thanks!
		</comment>
		<comment id='3' author='braindotai' date='2019-07-12T14:38:29Z'>
		Here is the full code.
import tensorflow as tf
from tensorflow.keras import layers
import time

print(tf.test.is_gpu_available()) # prints True
print(tf.__version__) # prints '2.0.0-beta1'

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

x_train.shape, x_test.shape

x_train = tf.cast(x_train, tf.float32)
x_train = tf.expand_dims(x_train, axis = 3)/255.0
y_train = tf.cast(y_train, tf.float32)

x_test = tf.cast(x_test, tf.float32)
x_test = tf.expand_dims(x_test, axis = 3)/255.0
y_test = tf.cast(y_test, tf.float32)

print('x_train.shape:', x_train.shape) # x_train.shape: (60000, 28, 28, 1)
print('y_train.shape:', y_train.shape) # y_train.shape: (60000,)

print('x_test.shape:', x_test.shape) # x_test.shape: (10000, 28, 28, 1)
print('y_test.shape:', y_test.shape) # y_test.shape: (10000,)

dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
dataset = dataset.shuffle(60000).batch(64)

print(dataset) # &lt;BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.float32)&gt;

#checking shape of features and labels
for x, y in dataset.take(1): # take(1) takes first batch of the datase
    print(x.shape) # (64, 28, 28, 1)
    print(y.shape) # (64,)

#counting number of batches
for batch, (features, labels) in enumerate(dataset):
    pass
print('batches:', batch + 1) # batches: 938

model = tf.keras.Sequential()
model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.AveragePooling2D())
model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
model.add(layers.AveragePooling2D())
model.add(layers.Flatten())
model.add(layers.Dense(units = 120, activation = 'relu'))
model.add(layers.Dense(units = 84, activation = 'relu'))
model.add(layers.Dense(units = 10, activation = 'softmax'))

optimizer = tf.keras.optimizers.Adam()
objective = tf.keras.losses.SparseCategoricalCrossentropy()
metric = tf.keras.metrics.SparseCategoricalAccuracy()

start = time.time()

with tf.device('gpu:0'):
    for epoch in range(20):
        cumulative_loss = 0.0
        metric.reset_states()
        for images, labels in dataset:
            with tf.GradientTape() as tape:
                predictions = model(images, training=True)
                loss = objective(labels, predictions)

            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))

            cumulative_loss += loss
            metric.update_state(labels, predictions)

        print("Epoch: {} Loss: {} Accuracy: {}".format(epoch, cumulative_loss.numpy()/(batch + 1), metric.result()))
print(f'Took: {(time.time() - start)/60.0:.5f}')
		</comment>
		<comment id='4' author='braindotai' date='2019-07-12T14:55:52Z'>
		
Hey, this is just a wild guess, but maybe you need to wrap your train loop inside a tf.function?

Yes, I've tested it, and that didn't improve the performance at all!!!! And it's still nowhere near as tf.keras's .fit() method,
I've compared the same code using @tf.function with other frameworks: MXNet and Pytorch, and both of them are way faster than Tensorflow, MXNet is about 8x, and Pytorch is about 7.5x.
I am pretty sure that I am doing something wrong with my Tensorflow code. Please help me out.
		</comment>
		<comment id='5' author='braindotai' date='2019-07-13T17:21:42Z'>
		Please somebody help
		</comment>
		<comment id='6' author='braindotai' date='2019-07-15T08:20:30Z'>
		

Hey, this is just a wild guess, but maybe you need to wrap your train loop inside a tf.function?



Yes, I've tested it, and that didn't improve the performance at all!!!!

This is odd. I replicated your issue on my system, and while I see a huge difference between model.fit and the manual training loop, wrapping the latter using tf.function does decrease its runtime...
The code I used, based on yours (and reducing the number of epochs to 10 for pure convenience):
&lt;denchmark-code&gt;def training():
    # Note: I did not specify to use the GPU, but on my system it does by default.
    for epoch in range(10):
        cumulative_loss = 0.0
        metric.reset_states()
        for images, labels in dataset:
            with tf.GradientTape() as tape:
                predictions = model(images, training=True)
                loss = objective(labels, predictions)
 
            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))

            cumulative_loss += loss
            metric.update_state(labels, predictions)
        tf.print(f'Epoch: {epoch}')
        tf.print(cumulative_loss / (batch + 1))
        tf.print(metric.result())


def fit_model():
    model.compile(optimizer, objective, [metric])
    model.fit(dataset, epochs=10)


def timeit(func):
    def timed():
        start = time.time()
        func()
        print(f'Took: {(time.time() - start):.5f}')
    return timed

# Timings will, of course, vary depending on the computer.
timeit(training)()               # 123 seconds
timeit(tf.function(training))()  # 58 seconds
timeit(fit_model)()              # 33 seconds
&lt;/denchmark-code&gt;

Now, that being said, there is still a significant difference between GradientTape-based and keras-wrapped fitting runtimes, and I do not know what can be done about it. To me it really feels like the logical and sad consequence of using Eager execution, but hopefully someone can prove me wrong and point out an optimization trick that will help you...
		</comment>
		<comment id='7' author='braindotai' date='2019-07-15T16:34:08Z'>
		I wasn't using tf.print, after using it I got an almost 1.9x speed up from @tf.function vs without @tf.function. But still far behind than tf.keras's .fit, which surprisingly also works as eager execution according to Tensorflow Team.
Anyway hoping to see some performance improvement for tf.GradientTape soon
		</comment>
		<comment id='8' author='braindotai' date='2019-07-16T19:10:43Z'>
		&lt;denchmark-link:https://github.com/robieta&gt;@robieta&lt;/denchmark-link&gt;
 do you know what could be happening here to make the fit version different from the manual version, with tf.function turned on?
		</comment>
		<comment id='9' author='braindotai' date='2019-07-17T04:53:49Z'>
		I'm not able to reproduce the rank order. (I'm running on a P100, so more powerful than a K80 but in the same ballpark. I'm also using tf.enable_v2_behavior rather than the beta install, but I don't think that should matter.) I see 14 ms / step for pure eager, 2.5 ms / step after wrapping the train step in a tf.function, and 4 ms / step with model.fit. (Expected since custom training loop is more barebones than model.fit) Can you try the following?
&lt;denchmark-code&gt;@tf.function
def train_step(images, labels, metric):
  with tf.GradientTape() as tape:
      predictions = model(images, training=True)
      loss = objective(labels, predictions)

  grads = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))

  metric.update_state(labels, predictions)
  return loss

overall_st = time.time()
with tf.device('gpu:0'):
    # # Uncomment for model.fit version
    # model.compile(loss=objective, optimizer=optimizer)
    # model.fit(dataset, epochs=20)
    # """
    for epoch in range(20):
        start = time.time()
        cumulative_loss = 0.0
        metric.reset_states()
        for i, [images, labels] in enumerate(dataset):
            cumulative_loss += train_step(images, labels, metric)

        print("Epoch: {} Loss: {} Accuracy: {}".format(epoch, cumulative_loss.numpy()/(batch + 1), metric.result()))
        print('{:.5f} ms / step'.format((time.time() - start) * 1000 / (i + 1)))
    # """
print("overall time: {:.1f} sec".format(time.time() - overall_st))
&lt;/denchmark-code&gt;

P.S. I appreciate the use of fstrings. (Even if I had to remove it because I'm on an older python version.)
		</comment>
		<comment id='10' author='braindotai' date='2019-07-23T07:06:42Z'>
		Sorry for late reply, &lt;denchmark-link:https://github.com/robieta&gt;@robieta&lt;/denchmark-link&gt;
 thanks, it worked. And as of now I'm getting better performance using tf.function(55.secs) as compared to tf.keras .fit(64.8 secs), probably because .fit does some initialization before training starts.
But unfortunately in eager execution (without tf.function) its taking 270 secs.
And if we compare this result with MXNet and Pytorch, it turns out Tensorflow eager execution is over 8x slower than MXNet and 7.5x slower than Pytorch.
I've no problem using tf.function but there are some tricky parts over using it, that I don't like, for instance my version of train function definition using tf.function doesn't work, while your's works like champ.
As of now I've got the working solution so I'm closing the issue after next reply, but it'd be great if eager execution is a bit faster than what it is.
Thanks for help.
		</comment>
		<comment id='11' author='braindotai' date='2019-08-02T09:25:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30596&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30596&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='braindotai' date='2020-01-26T18:33:33Z'>
		
Sorry for late reply, @robieta thanks, it worked. And as of now I'm getting better performance using tf.function(55.secs) as compared to tf.keras .fit(64.8 secs), probably because .fit does some initialization before training starts.
But unfortunately in eager execution (without tf.function) its taking 270 secs.
And if we compare this result with MXNet and Pytorch, it turns out Tensorflow eager execution is over 8x slower than MXNet and 7.5x slower than Pytorch.
I've no problem using tf.function but there are some tricky parts over using it, that I don't like, for instance my version of train function definition using tf.function doesn't work, while your's works like champ.
As of now I've got the working solution so I'm closing the issue after next reply, but it'd be great if eager execution is a bit faster than what it is.
Thanks for help.

Hi, I was also training a tf.keras model. The loss reduced very quickly when calling model.fit but it plateaued very quickly when I updated the weights manually using tf.GradientTape(). Could I know how you figured out the reason? I created a &lt;denchmark-link:https://colab.research.google.com/drive/1aIRqi_x-YGAFtZCWL4gkOPkW_8sSlZ_N&gt;reproducible example&lt;/denchmark-link&gt;
 in Colab. Could you have a look? It would take 2 minutes to reproduce.
		</comment>
		<comment id='13' author='braindotai' date='2020-01-27T15:57:55Z'>
		Please file a separate bug for your problem.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sun, Jan 26, 2020 at 10:33 AM Xiaokang Wang ***@***.***&gt; wrote:
 Sorry for late reply, @robieta &lt;https://github.com/robieta&gt; thanks, it
 worked. And as of now I'm getting better performance using
 tf.function(55.secs) as compared to tf.keras .fit(64.8 secs), probably
 because .fit does some initialization before training starts.
 But unfortunately in eager execution (without tf.function) its taking 270
 secs.
 And if we compare this result with MXNet and Pytorch, it turns out
 Tensorflow eager execution is over 8x slower than MXNet and 7.5x slower
 than Pytorch.
 I've no problem using tf.function but there are some tricky parts over
 using it, that I don't like, for instance my version of train function
 definition using tf.function doesn't work, while your's works like champ.
 As of now I've got the working solution so I'm closing the issue after
 next reply, but it'd be great if eager execution is a bit faster than what
 it is.

 Thanks for help.

 Hi, I was also training a tf.keras model. The loss reduced very quickly
 when calling model.fit but it plateaued very quickly when I updated the
 weights manually using tf.GradientTape(). Could I know how you figured out
 the reason?

 —
 You are receiving this because you were assigned.
 Reply to this email directly, view it on GitHub
 &lt;#30596?email_source=notifications&amp;email_token=AAABHRKRVI5GO3CNNJL57QLQ7XJQHA5CNFSM4IBANHP2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEJ52S6Q#issuecomment-578529658&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AAABHRLIJW7NCL3LPFGQW2TQ7XJQHANCNFSM4IBANHPQ&gt;
 .


-- 
 - Alex

		</comment>
	</comments>
</bug>