<bug id='25787' author='BenjaminChoou' open_date='2019-02-15T16:48:35Z' closed_time='2019-03-15T20:32:01Z'>
	<summary>Warning or error about incompatible device when I use tf.nn.rnn_cell.DropoutWrapper on multiple GPUs</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.11.0 and 1.12.0
Python version: 3.6.5
Bazel version (if compiling from source): 0.15.0
GCC/Compiler version (if compiling from source): 4.8
CUDA/cuDNN version: 9.0/7.3.0
GPU model and memory: nvidia 1080ti, 11GB


I write a very simple 2 layers LSTM model working on 2 GPUs. The model has no specific meaning, and I just want to test LSTM network. I randomly generalize some data as inputs, and take reduced sum of logits as loss. Then I compute the gradients and loss. I would get some warnings like below. And the same situation happens when I run &lt;denchmark-link:https://github.com/tensorflow/nmt/tree/tf-1.4&gt;TensorFlow Neural Machine Translation Tutorial&lt;/denchmark-link&gt;
, which is the reason why I tested this simple code.
&lt;denchmark-code&gt;WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' (defined at test.py:103) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:94) which had an incompatible device '/device:GPU:1'.

Node-device colocations active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation:
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:994&gt;
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:354&gt;
No device assignments were active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation.

No node-device colocations were active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation.
Device assignments active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation:
  with tf.device(/gpu:1): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1390&gt;
WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' (defined at test.py:103) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:94) which had an incompatible device '/device:GPU:1'.
&lt;/denchmark-code&gt;

If I don't set allow_soft_placement=True, I would get error.
&lt;denchmark-code&gt;InvalidArgumentError (see above for traceback): Cannot colocate nodes 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' and 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div: Cannot merge devices with incompatible ids: '/device:GPU:1' and '/device:GPU:0'
	 [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const}} = Const[_class=["loc:@rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2", "loc:@rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div"], dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [] values: -1&gt;, _device="/device:GPU:0"]()]]
&lt;/denchmark-code&gt;

Describe the expected behavior
get no warning or make sure that this situation would affect result or performance.
Code to reproduce the issue
The warning only emerges when I use tf.nn.rnn_cell.DropoutWrapper.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
from tensorflow.python.layers import core as layers_core


data_x = np.random.standard_normal([100, 5, 1000])

single_cell_0 = tf.nn.rnn_cell.LSTMCell(1000, forget_bias=1)
single_cell_0 = tf.nn.rnn_cell.DropoutWrapper(cell=single_cell_0, input_keep_prob=0.8, seed=285)
single_cell_0 = tf.contrib.rnn.DeviceWrapper(single_cell_0, "/gpu:0")

single_cell_1 = tf.nn.rnn_cell.LSTMCell(1000, forget_bias=1)
single_cell_1 = tf.nn.rnn_cell.DropoutWrapper(cell=single_cell_1, input_keep_prob=0.8, seed=285)
single_cell_1 = tf.contrib.rnn.DeviceWrapper(single_cell_1, "/gpu:1")

cell = tf.contrib.rnn.MultiRNNCell([single_cell_0, single_cell_1])

target_input = tf.placeholder(dtype=tf.float32, shape=[None, 5, 1000], name="input")

output, final_state = tf.nn.dynamic_rnn(cell,
                                        target_input,
                                        dtype=tf.float32,
                                        time_major=True)
output = tf.reshape(output, [-1, 5000])
with tf.device("/gpu:2"):
    logits = layers_core.Dense(100, use_bias=False, name="output_projection")(output)
    loss = tf.reduce_sum(logits)

params = tf.trainable_variables()
for param in params:
    print("  %s, %s, %s" % (param.name, str(param.get_shape()), param.op.device))
grad = tf.gradients(loss, params, colocate_gradients_with_ops=True)

config_proto = tf.ConfigProto(
    log_device_placement=False,
    allow_soft_placement=False)
config_proto.gpu_options.allow_growth = True
with tf.Session(config=config_proto) as sess:
    sess.run(tf.global_variables_initializer())
    g, l = sess.run([grad, loss], {target_input: data_x})
    print(g, l)
&lt;/denchmark-code&gt;

Other info / logs
Full info with warning
&lt;denchmark-code&gt;  rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0, (2000, 4000), /device:GPU:0
  rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0, (4000,), /device:GPU:0
  rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0, (2000, 4000), /device:GPU:1
  rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0, (4000,), /device:GPU:1
  output_projection/kernel:0, (5000, 100), /device:GPU:2
WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' (defined at test.py:103) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:94) which had an incompatible device '/device:GPU:1'.

Node-device colocations active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation:
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:994&gt;
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:354&gt;
No device assignments were active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation.

No node-device colocations were active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation.
Device assignments active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation:
  with tf.device(/gpu:1): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1390&gt;
WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' (defined at test.py:103) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:94) which had an incompatible device '/device:GPU:1'.

Node-device colocations active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' creation:
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:994&gt;
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:354&gt;
No device assignments were active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' creation.

No node-device colocations were active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation.
Device assignments active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation:
  with tf.device(/gpu:1): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1390&gt;
2019-02-16 00:15:18.804994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:18:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:15:19.010291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:3b:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:15:19.227656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:86:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:15:19.408641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:af:00.0
totalMemory: 10.91GiB freeMemory: 10.36GiB
2019-02-16 00:15:19.415867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0, 1, 2, 3
2019-02-16 00:15:20.680526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-16 00:15:20.680570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 1 2 3 
2019-02-16 00:15:20.680576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N Y Y Y 
2019-02-16 00:15:20.680595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   Y N Y Y 
2019-02-16 00:15:20.680599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 2:   Y Y N Y 
2019-02-16 00:15:20.680603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 3:   Y Y Y N 
2019-02-16 00:15:20.681368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10390 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:18:00.0, compute capability: 6.1)
2019-02-16 00:15:20.682959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10398 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:3b:00.0, compute capability: 6.1)
2019-02-16 00:15:20.684307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10398 MB memory) -&gt; physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
2019-02-16 00:15:20.685688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10013 MB memory) -&gt; physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:af:00.0, compute capability: 6.1)
&lt;/denchmark-code&gt;

Full info with error, no allow_soft_placement=True.
&lt;denchmark-code&gt;  rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0, (2000, 4000), /device:GPU:0
  rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0, (4000,), /device:GPU:0
  rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0, (2000, 4000), /device:GPU:1
  rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0, (4000,), /device:GPU:1
  output_projection/kernel:0, (5000, 100), /device:GPU:2
WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' (defined at test.py:102) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:93) which had an incompatible device '/device:GPU:1'.

Node-device colocations active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation:
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:994&gt;
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:354&gt;
No device assignments were active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' creation.

No node-device colocations were active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation.
Device assignments active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation:
  with tf.device(/gpu:1): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1390&gt;
WARNING:tensorflow:Tried to colocate op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' (defined at test.py:102) having device '/device:GPU:0' with op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' (defined at test.py:93) which had an incompatible device '/device:GPU:1'.

Node-device colocations active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' creation:
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:994&gt;
  with tf.colocate_with(rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:354&gt;
No device assignments were active during op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/f_acc' creation.

No node-device colocations were active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation.
Device assignments active during op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div' creation:
  with tf.device(/gpu:1): &lt;/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1390&gt;
2019-02-16 00:36:24.357307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:18:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:36:24.561462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:3b:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:36:24.760426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 2 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:86:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2019-02-16 00:36:24.941042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 3 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:af:00.0
totalMemory: 10.91GiB freeMemory: 10.36GiB
2019-02-16 00:36:24.948169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0, 1, 2, 3
2019-02-16 00:36:26.126392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-16 00:36:26.126439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 1 2 3 
2019-02-16 00:36:26.126446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N Y Y Y 
2019-02-16 00:36:26.126451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 1:   Y N Y Y 
2019-02-16 00:36:26.126455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 2:   Y Y N Y 
2019-02-16 00:36:26.126459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 3:   Y Y Y N 
2019-02-16 00:36:26.127293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10390 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:18:00.0, compute capability: 6.1)
2019-02-16 00:36:26.128911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10398 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:3b:00.0, compute capability: 6.1)
2019-02-16 00:36:26.130298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10398 MB memory) -&gt; physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
2019-02-16 00:36:26.131678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10013 MB memory) -&gt; physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:af:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1292, in _do_call
    return fn(*args)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1275, in _run_fn
    self._extend_graph()
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1312, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot colocate nodes 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' and 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div: Cannot merge devices with incompatible ids: '/device:GPU:1' and '/device:GPU:0'
	 [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const}} = Const[_class=["loc:@rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2", "loc:@rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div"], dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [] values: -1&gt;, _device="/device:GPU:0"]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test.py", line 109, in &lt;module&gt;
    sess.run(tf.global_variables_initializer())
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 887, in run
    run_metadata_ptr)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1110, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1286, in _do_run
    run_metadata)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1308, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot colocate nodes 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' and 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div: Cannot merge devices with incompatible ids: '/device:GPU:1' and '/device:GPU:0'
	 [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const}} = Const[_class=["loc:@rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2", "loc:@rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div"], dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [] values: -1&gt;, _device="/device:GPU:0"]()]]

Caused by op 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const', defined at:
  File "test.py", line 102, in &lt;module&gt;
    grad = tf.gradients(loss, params, colocate_gradients_with_ops=True)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 596, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 776, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 398, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 776, in &lt;lambda&gt;
    lambda: grad_fn(op, *out_grads))
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py", line 972, in _RealDivGrad
    grad * math_ops.realdiv(math_ops.realdiv(-x, y), y), ry), sy))
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 5100, in neg
    "Neg", x=x, name=name)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3272, in create_op
    op_def=op_def)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1805, in __init__
    self._control_flow_post_processing()
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1816, in _control_flow_post_processing
    self._control_flow_context.AddOp(self)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2471, in AddOp
    self._AddOpInternal(op)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2492, in _AddOpInternal
    real_x = self.AddValue(x)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2424, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 1136, in GetRealValue
    history_value = cur_grad_state.AddForwardAccumulator(cur_value)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 998, in AddForwardAccumulator
    max_size = constant_op.constant(-1, dtypes.int32)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 213, in constant
    name=name).outputs[0]
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3272, in create_op
    op_def=op_def)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1768, in __init__
    self._traceback = tf_stack.extract_stack()

...which was originally created as op 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div', defined at:
  File "test.py", line 93, in &lt;module&gt;
    time_major=True)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py", line 664, in dynamic_rnn
    dtype=dtype)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py", line 868, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 3274, in while_loop
    return_same_structure)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2994, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2929, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 3243, in &lt;lambda&gt;
    body = lambda i, lv: (i + 1, orig_body(*lv))
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py", line 836, in _time_step
    (output, new_state) = call_cell()
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py", line 822, in &lt;lambda&gt;
    call_cell = lambda: cell(input_t, state)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 233, in __call__
    return super(RNNCell, self).__call__(inputs, state)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/layers/base.py", line 364, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 769, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1484, in call
    cur_inp, new_state = cell(cur_inp, cur_state)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1391, in __call__
    return self._cell(inputs, state, scope=scope)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1279, in __call__
    self._input_keep_prob)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1260, in _dropout
    *[shallow_filtered_substructure, values])
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1053, in _enumerated_map_structure_up_to
    enumerated_fn, *args, **kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 643, in map_structure_up_to
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 643, in &lt;listcomp&gt;
    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1049, in enumerated_fn
    r = map_fn(ix[0], *inner_args, **inner_kwargs)
  File "/home/mjzhou/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 1255, in dropout
    v, keep_prob=keep_prob, seed=self._gen_seed(salt_prefix, i))

InvalidArgumentError (see above for traceback): Cannot colocate nodes 'gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const' and 'rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div: Cannot merge devices with incompatible ids: '/device:GPU:1' and '/device:GPU:0'
	 [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div_grad/Neg/Const}} = Const[_class=["loc:@rnn/while/rnn/multi_rnn_cell/cell_0/lstm_cell/mul_2", "loc:@rnn/while/rnn/multi_rnn_cell/cell_1/dropout/div"], dtype=DT_INT32, value=Tensor&lt;type: int32 shape: [] values: -1&gt;, _device="/device:GPU:0"]()]]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='BenjaminChoou' date='2019-03-13T02:01:49Z'>
		Thank you so much for the detailed report!
From a quick look, it seems that the check was dropped in the following commit.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/f8f17cebcc89921b5f1a204dab1f9fdb47b120c1&gt;f8f17ce&lt;/denchmark-link&gt;

The commit is part of TensorFlow 1.13 release. Could you give it a try with 1.13 to see if that resolves the issue?
		</comment>
		<comment id='2' author='BenjaminChoou' date='2019-03-15T20:32:01Z'>
		Closing this issue but let us know if this is still an issue with TensorFlow 1.13 or later release.
		</comment>
		<comment id='3' author='BenjaminChoou' date='2019-03-16T06:12:05Z'>
		
Closing this issue but let us know if this is still an issue with TensorFlow 1.13 or later release.


Thank you so much for the detailed report!
From a quick look, it seems that the check was dropped in the following commit.
f8f17ce
The commit is part of TensorFlow 1.13 release. Could you give it a try with 1.13 to see if that resolves the issue?

Thank you. Similar warnings don't exist with TF 1.13.1.
		</comment>
	</comments>
</bug>