<bug id='22723' author='PeganovAnton' open_date='2018-10-04T10:17:11Z' closed_time='2018-10-23T11:38:26Z'>
	<summary>bug: tf.train.Saver.save() fails if 2 tf.contrib.cudnn_rnn.cudnnLSTM instances passed to saver are built with build() method</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;



Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.5 LTS


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy): N/A


TensorFlow installed from (source or binary): binary


TensorFlow version (use command below): v1.10.1-0-g4dcfddc5d1 1.10.1


Python version: 3.6.0


Bazel version (if compiling from source): N/A


CUDA/cuDNN version:
CUDA Version 9.0.176
cudnn: 7.1.4


GPU model and memory:
NVIDIA GeForce GTX 1080 Ti
11GB


Exact command to reproduce:
python test.py


&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Description
If 2 instances of tensorflow.contrib.cudnn_rnn.CudnnLSTM are built via build() method they can not be saved together in a checkpoint.
Bug borders
If instances are built implicitly in __call__(), no exceptions are thrown. Next code executes OK.
import os
import tensorflow as tf
from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM
inp = tf.zeros([10, 32, 100])
lstm1 = CudnnLSTM(1, 128)
lstm2 = CudnnLSTM(2, 256)
lstm1(inp)
lstm2(inp)
saver = tf.train.Saver()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    save_path = os.path.join('test_cudnn_lstm_save', '1')
    if not os.path.exists(save_path):
        os.makedirs(os.path.join(save_path))
    saver.save(sess, save_path)
Also if only 1 instance is built using build() or if only 1 instance is passed to saver in var_list (see ex—Åerpt below), save op is executed without exceptions.
saver = tf.train.Saver([lstm1.saveable])
Relevance
I ran into this problem when tried to train my net on several GPUs. Shared CudnnLSTM params are built on CPU, while computations are made on GPUs.
Thank you in advance for any help!
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Code to reproduce the bug
import os
import tensorflow as tf
from tensorflow.contrib.cudnn_rnn import CudnnLSTM as CudnnLSTM
inp = tf.zeros([10, 32, 100])
lstm1 = CudnnLSTM(1, 128)
lstm2 = CudnnLSTM(2, 256)
lstm1.build(inp.shape)
lstm2.build(inp.shape)
saver = tf.train.Saver()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    save_path = os.path.join('test_cudnn_lstm_save', '1')
    if not os.path.exists(save_path):
        os.makedirs(os.path.join(save_path))
    saver.save(sess, save_path)
Here is a traceback
&lt;denchmark-code&gt;2018-10-04 12:59:46.556727: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-10-04 12:59:46.635329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-04 12:59:46.635669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 10.92GiB freeMemory: 10.01GiB
2018-10-04 12:59:46.635682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-10-04 12:59:46.841898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-04 12:59:46.841930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-10-04 12:59:46.841937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-10-04 12:59:46.842099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9673 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-10-04 12:59:47.465382: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at save_restore_v2_ops.cc:134 : Invalid argument: Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
Traceback (most recent call last):
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1278, in _do_call
    return fn(*args)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1263, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1350, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, transpose/_3, concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, transpose_1/_9, transpose_2/_11, concat_11/_13, concat_17/_15)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test.py", line 17, in &lt;module&gt;
    saver.save(sess, save_path)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1620, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 877, in run
    run_metadata_ptr)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1100, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1272, in _do_run
    run_metadata)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1291, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, transpose/_3, concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, transpose_1/_9, transpose_2/_11, concat_11/_13, concat_17/_15)]]

Caused by op 'save/SaveV2', defined at:
  File "test.py", line 11, in &lt;module&gt;
    saver = tf.train.Saver()
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1281, in __init__
    self.build()
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1293, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1330, in _build
    build_save=build_save, build_restore=build_restore)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 775, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 275, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 193, in save_op
    tensors)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py", line 1687, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 454, in new_func
    return func(*args, **kwargs)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3155, in create_op
    op_def=op_def)
  File "/home/anton/dpenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1717, in __init__
    self._traceback = tf_stack.extract_stack()

InvalidArgumentError (see above for traceback): Adding duplicate key: rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, cudnn_lstm/opaque_kernel/_1, transpose/_3, concat_5/_5, cudnn_lstm_1/opaque_kernel/_7, transpose_1/_9, transpose_2/_11, concat_11/_13, concat_17/_15)]]
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='PeganovAnton' date='2018-10-05T01:24:35Z'>
		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Bazel version
Mobile device
		</comment>
		<comment id='2' author='PeganovAnton' date='2018-10-05T11:37:19Z'>
		&lt;denchmark-link:https://github.com/tensorflowbutler&gt;@tensorflowbutler&lt;/denchmark-link&gt;
 Required fields are filled
		</comment>
		<comment id='3' author='PeganovAnton' date='2018-10-17T15:53:35Z'>
		Thanks for reporting, this is a problem. TF should automatically create different namespace for the vars.
At present, as a workaround, you can create a separate variable scope
with tf.variable_scope('rnn1'):
  lstm1 = CudnnLSTM(1, 128)
with tf.variable_scope('rnn2'):
  lstm2 = CudnnLSTM(2, 256)
Btw we'll eventually support all cudnn layers under tf.keras.layers, but that requires some time for migrating and testing, just as a FYI.
		</comment>
		<comment id='4' author='PeganovAnton' date='2018-10-17T16:33:42Z'>
		&lt;denchmark-link:https://github.com/protoget&gt;@protoget&lt;/denchmark-link&gt;
 Thank you very much for advice!
		</comment>
		<comment id='5' author='PeganovAnton' date='2018-10-17T16:50:51Z'>
		&lt;denchmark-link:https://github.com/PeganovAnton&gt;@PeganovAnton&lt;/denchmark-link&gt;
 Hi, feel free to close this issue if resolved. Thanks !
		</comment>
	</comments>
</bug>