<bug id='36748' author='Randryn0' open_date='2020-02-14T11:30:48Z' closed_time='2020-03-21T01:02:52Z'>
	<summary>Ubuntu 18.04 with RTX 2070 SUPER with tensorflow 1.13, Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRO</summary>
	<description>
System information

Have I written custom code : No
OS: Linux 5.3.0-28 18.04.1-Ubuntu
TensorFlow installed from pip3
TensorFlow version: tried 13.1 and 13.2
Python version: Python 3.6.9
Bazel: /
GCC/Compiler: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4.2
GPU model and memory: GeForce RTX 2070 SUPER, 8GB


I downloaded the &lt;denchmark-link:https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd&gt;MNIST "tensorflow without a PhD example"&lt;/denchmark-link&gt;
 from git and tried to run one of the examples with

after downloading tensorflow and tensorflow gpu with
.

I have not altered the code in any way and could successfully run it on the CPU. I assumed it would work without problems with the GPU, too, after I installed proprietary NVidia drivers (435) and the CUDA and cuDNN libraries.
There was a &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727&gt;workaround in a different issue relating to the same problem&lt;/denchmark-link&gt;
 but this did not fix the issue for me.
Code to reproduce the issue
Just clone the repository above and run the code from the "tensorflow-mnist-tutorial" directory.
Other info / logs
This is the output:
&lt;denchmark-code&gt;$ python3 mnist_3.1_convolutional_bigger_dropout.py 
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
INFO:tensorflow:Tensorflow version 1.13.2
Tensorflow version 1.13.2
2020-02-14 11:56:04.391977: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x16d9470 executing computations on platform CUDA. Devices:
2020-02-14 11:56:04.392023: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5
2020-02-14 11:56:04.412696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600105000 Hz
2020-02-14 11:56:04.413472: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1718880 executing computations on platform Host. Devices:
2020-02-14 11:56:04.413512: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2020-02-14 11:56:04.413749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.815
pciBusID: 0000:03:00.0
totalMemory: 7.79GiB freeMemory: 7.56GiB
2020-02-14 11:56:04.413786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:04.414980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:04.415008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:04.415022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:04.415176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
2020-02-14 11:56:08.593018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:08.593064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:08.593075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:08.593087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:08.593176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From mnist_3.1_convolutional_bigger_dropout.py:88: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From mnist_3.1_convolutional_bigger_dropout.py:95: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

2020-02-14 11:56:10.165980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:10.166030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:10.166039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:10.166049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:10.166133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
2020-02-14 11:56:10.651240: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2020-02-14 11:56:11.534908: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-02-14 11:56:11.581923: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Exception in Tkinter callback
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1334, in _do_call
    return fn(*args)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node Conv2D}}]]
         [[{{node convert_image}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.6/tkinter/__init__.py", line 1705, in __call__
    return self.func(*args)
  File "/usr/lib/python3.6/tkinter/__init__.py", line 749, in callit
    func(*args)
  File "/usr/lib/python3/dist-packages/matplotlib/backends/backend_tkagg.py", line 95, in _on_timer
    TimerBase._on_timer(self)
  File "/usr/lib/python3/dist-packages/matplotlib/backend_bases.py", line 1383, in _on_timer
    ret = func(*args, **kwargs)
  File "/usr/lib/python3/dist-packages/matplotlib/animation.py", line 1542, in _step
    still_going = Animation._step(self, *args)
  File "/usr/lib/python3/dist-packages/matplotlib/animation.py", line 1277, in _step
    self._draw_next_frame(framedata, self._blit)
  File "/usr/lib/python3/dist-packages/matplotlib/animation.py", line 1296, in _draw_next_frame
    self._draw_frame(framedata)
  File "/usr/lib/python3/dist-packages/matplotlib/animation.py", line 1814, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
  File "/home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py", line 364, in animate_step
    compute_step(n, request_test_data_update, request_data_update)
  File "mnist_3.1_convolutional_bigger_dropout.py", line 131, in training_step
    feed_dict={X: batch_X, Y_: batch_Y, pkeep: 1.0, step: i})
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 929, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1328, in _do_run
    run_metadata)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node Conv2D (defined at mnist_3.1_convolutional_bigger_dropout.py:78) ]]
         [[node convert_image (defined at /home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py:62) ]]

Caused by op 'Conv2D', defined at:
  File "mnist_3.1_convolutional_bigger_dropout.py", line 78, in &lt;module&gt;
    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 1026, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py", line 3300, in create_op
    op_def=op_def)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node Conv2D (defined at mnist_3.1_convolutional_bigger_dropout.py:78) ]]
         [[node convert_image (defined at /home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py:62) ]]
&lt;/denchmark-code&gt;

By the way, there was a helpful table showing which tensorflow version required what python version, gcc compiler, bazel version and cuDNN/CUDA version. What happened to that?
Cheers
	</description>
	<comments>
		<comment id='1' author='Randryn0' date='2020-02-18T09:23:25Z'>
		I also now tested this with TensorFlow 1.4 and Cuda 10.0 and tried cuDNN 7.4.2 and cuDNN 7.6.5 and the same problem happens.
[edit]
I also ran watch -n 1 'nvidia-smi' and it seems that, for some reason, the memory usage reaches the maximum available memory of the card, which is strange.
&lt;denchmark-code&gt;Every 1,0s: nvidia-smi                                                                                   ail-Test4: Tue Feb 18 10:32:06 2020

Tue Feb 18 10:32:06 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 207...  Off  | 00000000:03:00.0  On |                  N/A |
|  0%   29C    P2    43W / 215W |   7973MiB /  7977MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1071      G   /usr/lib/xorg/Xorg                            78MiB |
|    0      1271      G   /usr/bin/gnome-shell                          69MiB |
|    0      4885      C   python3                                     7813MiB |
+-----------------------------------------------------------------------------+

&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='Randryn0' date='2020-02-18T11:26:52Z'>
		Alright, I think I found a working configuration. I installed tensorflow 1.11 and am using cuda 9.0 with cuDNN 7.4.2 and it seems to be working. I tried both the MNIST examples and the Superman vs Batman logo classificator mentioned above.
[edit]
This problem still occurs sometimes, though. So far I cannot figure out why. Sometimes when that happens I get a segmentation fault.
The segmentation fault happens in the Batman vs Superman logo classifier I linked above, in predict.py. It just says
&lt;denchmark-code&gt;2020-02-18 15:26:39.896608: E tensorflow/stream_executor/cuda/cuda_dnn.cc:353] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

and that's it. [edit] And just to clarify: while training a model I can use it to validate a set of pictures to see what results they are giving me but when loading the model from disk and trying to do the same I get the segmentation fault.
[edit]
Just for testing I installed tensorflow 1.12 without changing the version of cuda and cuDNN and here I also get the CUDNN_STATUS_INTERNAL_ERROR that started this issue in the first place.
		</comment>
		<comment id='3' author='Randryn0' date='2020-02-18T23:12:35Z'>
		Can you please try by killing all active python sessions/jupyter notebook.
You need exit() all python interpreters.
Start new python instance and add following lines on top mnist_3.1_convolutional_bigger_dropout.py  script.
import tensorflow as tf
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)

# rest of mnist_3.1_convolutional_bigger_dropout.py code
		</comment>
		<comment id='4' author='Randryn0' date='2020-02-19T14:58:14Z'>
		Hey, I actually had tried that before and it didn't work but I did the mistake of trying to put it into my code. When I put the code that you mentioned before ANYTHING else in my code it seems to work.
Could you please tell me what it does and do you know what the underlying problem is?
Thank you very much!
[edit]
Interestingly enough adding that piece of code to my routines also gets rid of the segmentation fault with tensorflow 1.11 error that I have mentioned above, at least as far I can see.
		</comment>
		<comment id='5' author='Randryn0' date='2020-03-21T01:02:52Z'>
		Glad it worked for you. By default, TensorFlow maps nearly all of the GPU memory. In some cases it is desirable for the process to only allocate a subset of the available memory, or to only grow the memory usage as is needed by the process. Thanks!
		</comment>
		<comment id='6' author='Randryn0' date='2020-03-21T01:02:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36748&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36748&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>