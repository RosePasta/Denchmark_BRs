<bug id='26811' author='TahaK' open_date='2019-03-17T21:17:34Z' closed_time='2019-08-02T06:11:27Z'>
	<summary>[TF2.0] Bug when saving weights with custom layers</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
docker image from tensorflow/tensorflow:2.0.0a0-gpu-jupyter
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
git version 'v1.12.0-9492-g2c319fb415'
tensorflow version '2.0.0-alpha0'
Python version:
2.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
cuda version 415.27
GPU model and memory:
GTX 1080Ti


If custom layers are used weights of the model cannot be saved using model.save_weights() or exported to the savedmethod. I am using the code provided in the Custom Layer code provided in the documentation at &lt;denchmark-link:https://www.tensorflow.org/alpha/guide/keras/custom_layers_and_models#you_can_optionally_enable_serialization_on_your_layers&gt;https://www.tensorflow.org/alpha/guide/keras/custom_layers_and_models#you_can_optionally_enable_serialization_on_your_layers&lt;/denchmark-link&gt;

Describe the expected behavior
The model to save its weights properly
Code to reproduce the issue
import numpy as np
import tensorflow as tf
layers = tf.keras.layers
keras = tf.keras

# From documentation until the next comment
class Linear(layers.Layer):

    def __init__(self, units=32, **kwargs):
        super(Linear, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(shape=(input_shape[-1], self.units),
                                 initializer='random_normal',
                                 trainable=True)
        self.b = self.add_weight(shape=(self.units,),
                                 initializer='random_normal',
                                 trainable=True)

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b

    def get_config(self):
        config = super(Linear, self).get_config()
        config.update({'units': self.units})
        return config
    

layer = Linear(10)
config = layer.get_config()
print(config)
new_layer = Linear.from_config(config)

# Creating a layer and saving its weights
data = np.random.random((1000, 10))
labels = np.random.random((1000, 10))
inputs = keras.Input((10,))
outputs = layer(inputs)
model = keras.Model(inputs, outputs)
config = model.get_config()
print(config)
print(model.summary())
model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(data, labels, batch_size=10, epochs=1)

model.save_weights("temp/layers_weights")
Other info / logs
&lt;denchmark-code&gt;{'units': 10, 'dtype': None, 'trainable': True, 'name': 'linear_5'}
{'layers': [{'class_name': 'InputLayer', 'config': {'dtype': 'float32', 'batch_input_shape': (None, 10), 'name': 'input_5', 'sparse': False}, 'inbound_nodes': [], 'name': 'input_5'}, {'class_name': 'Linear', 'config': {'units': 10, 'dtype': 'float32', 'trainable': True, 'name': 'linear_5'}, 'inbound_nodes': [['input_5', 0, 0, {}]], 'name': 'linear_5'}], 'input_layers': ['input_5', 0, 0], 'output_layers': ['linear_5', 0, 0], 'name': 'model_4'}
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 10)]              0         
_________________________________________________________________
linear_5 (Linear)            (None, 10)                110       
=================================================================
Total params: 110
Trainable params: 110
Non-trainable params: 0
_________________________________________________________________
None
1000/1000 [==============================] - 1s 523us/sample - loss: 37.3735 - accuracy: 0.1060

------------------------------------------------------------
AttributeError             Traceback (most recent call last)
&lt;ipython-input-7-32331e9dcd27&gt; in &lt;module&gt;()
     47 model.fit(data, labels, batch_size=10, epochs=1)
     48 
---&gt; 49 model.save_weights("temp/layers_weights")

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/network.pyc in save_weights(self, filepath, overwrite, save_format)
   1409              'saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.')
   1410             % (optimizer,))
-&gt; 1411       self._trackable_saver.save(filepath, session=session)
   1412       # Record this checkpoint so it's visible from tf.train.latest_checkpoint.
   1413       checkpoint_management.update_checkpoint_state_internal(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/util.pyc in save(self, file_prefix, checkpoint_number, session)
    976     save_path, new_feed_additions = self._save_cached_when_graph_building(
    977         file_prefix=file_prefix_tensor,
--&gt; 978         object_graph_tensor=object_graph_tensor)
    979     if new_feed_additions:
    980       feed_dict.update(new_feed_additions)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/util.pyc in _save_cached_when_graph_building(self, file_prefix, object_graph_tensor)
    916     (named_saveable_objects, graph_proto,
    917      feed_additions) = self._gather_saveables(
--&gt; 918          object_graph_tensor=object_graph_tensor)
    919     if (self._last_save_object_graph != graph_proto
    920         # When executing eagerly, we need to re-create SaveableObjects each time

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/util.pyc in _gather_saveables(self, object_graph_tensor)
    882     """Wraps _serialize_object_graph to include the object graph proto."""
    883     (named_saveable_objects, graph_proto,
--&gt; 884      feed_additions) = self._graph_view.serialize_object_graph()
    885     if object_graph_tensor is None:
    886       with ops.device("/cpu:0"):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/graph_view.pyc in serialize_object_graph(self)
    379     trackable_objects, path_to_root = self._breadth_first_traversal()
    380     return self._serialize_gathered_objects(
--&gt; 381         trackable_objects, path_to_root)
    382 
    383   def frozen_saveable_objects(self, object_map=None, to_graph=None):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/graph_view.pyc in _serialize_gathered_objects(self, trackable_objects, path_to_root, object_map)
    335     object_names = object_identity.ObjectIdentityDictionary()
    336     for obj, path in path_to_root.items():
--&gt; 337       object_names[obj] = _object_prefix_from_path(path)
    338     node_ids = object_identity.ObjectIdentityDictionary()
    339     for node_id, node in enumerate(trackable_objects):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/graph_view.pyc in _object_prefix_from_path(path_to_root)
     62   return "/".join(
     63       (_escape_local_name(trackable.name)
---&gt; 64        for trackable in path_to_root))
     65 
     66 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/graph_view.pyc in &lt;genexpr&gt;((trackable,))
     62   return "/".join(
     63       (_escape_local_name(trackable.name)
---&gt; 64        for trackable in path_to_root))
     65 
     66 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/tracking/graph_view.pyc in _escape_local_name(name)
     55   # edges traversed to reach the variable, so we escape forward slashes in
     56   # names.
---&gt; 57   return (name.replace(_ESCAPE_CHAR, _ESCAPE_CHAR + _ESCAPE_CHAR)
     58           .replace(r"/", _ESCAPE_CHAR + "S"))
     59 

AttributeError: 'NoneType' object has no attribute 'replace'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='TahaK' date='2019-03-18T09:23:11Z'>
		The weights need to be saved in HDF5 format:
model.save_weights('path_to_my_weights.h5')
		</comment>
		<comment id='2' author='TahaK' date='2019-03-18T11:14:12Z'>
		Saving in h5 format also result in an error.
import numpy as np
import tensorflow as tf
layers = tf.keras.layers
keras = tf.keras

# From documentation until the next comment
class Linear(layers.Layer):

    def __init__(self, units=32, **kwargs):
        super(Linear, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        self.w = self.add_weight(shape=(input_shape[-1], self.units),
                                 initializer='random_normal',
                                 trainable=True)
        self.b = self.add_weight(shape=(self.units,),
                                 initializer='random_normal',
                                 trainable=True)

    def call(self, inputs):
        return tf.matmul(inputs, self.w) + self.b

    def get_config(self):
        config = super(Linear, self).get_config()
        config.update({'units': self.units})
        return config
    

layer = Linear(10)
config = layer.get_config()
print(config)
new_layer = Linear.from_config(config)

# Creating a layer and saving its weights
data = np.random.random((1000, 10))
labels = np.random.random((1000, 10))
inputs = keras.Input((10,))
outputs = layer(inputs)
model = keras.Model(inputs, outputs)
config = model.get_config()
print(config)
print(model.summary())
model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(data, labels, batch_size=10, epochs=2)
model.save_weights("temp/layers_weights_inh5format",save_format="h5")
stacktrace below
&lt;denchmark-code&gt;{'units': 10, 'dtype': None, 'trainable': True, 'name': 'linear_4'}
{'layers': [{'class_name': 'InputLayer', 'config': {'dtype': 'float32', 'batch_input_shape': (None, 10), 'name': 'input_5', 'sparse': False}, 'inbound_nodes': [], 'name': 'input_5'}, {'class_name': 'Linear', 'config': {'units': 10, 'dtype': 'float32', 'trainable': True, 'name': 'linear_4'}, 'inbound_nodes': [['input_5', 0, 0, {}]], 'name': 'linear_4'}], 'input_layers': ['input_5', 0, 0], 'output_layers': ['linear_4', 0, 0], 'name': 'model_4'}
Model: "model_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 10)]              0         
_________________________________________________________________
linear_4 (Linear)            (None, 10)                110       
=================================================================
Total params: 110
Trainable params: 110
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/2
1000/1000 [==============================] - 1s 550us/sample - loss: 40.7062 - accuracy: 0.1070
Epoch 2/2
1000/1000 [==============================] - 0s 432us/sample - loss: 41.0578 - accuracy: 0.1070

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-5-e5a7e605e04a&gt; in &lt;module&gt;()
     46               metrics=['accuracy'])
     47 model.fit(data, labels, batch_size=10, epochs=2)
---&gt; 48 model.save_weights("temp/layers_weights_inh5format",save_format="h5")

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/network.pyc in save_weights(self, filepath, overwrite, save_format)
   1393     if save_format == 'h5':
   1394       with h5py.File(filepath, 'w') as f:
-&gt; 1395         hdf5_format.save_weights_to_hdf5_group(f, self.layers)
   1396     else:
   1397       if context.executing_eagerly():

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.pyc in save_weights_to_hdf5_group(f, layers)
    691     save_attributes_to_hdf5_group(g, 'weight_names', weight_names)
    692     for name, val in zip(weight_names, weight_values):
--&gt; 693       param_dset = g.create_dataset(name, val.shape, dtype=val.dtype)
    694       if not val.shape:
    695         # scalar

/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.pyc in create_dataset(self, name, shape, dtype, data, **kwds)
    137             dset = dataset.Dataset(dsid)
    138             if name is not None:
--&gt; 139                 self[name] = dset
    140             return dset
    141 

/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.pyc in __setitem__(self, name, obj)
    369 
    370             if isinstance(obj, HLObject):
--&gt; 371                 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)
    372 
    373             elif isinstance(obj, SoftLink):

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5o.pyx in h5py.h5o.link()

RuntimeError: Unable to create link (name already exists)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='TahaK' date='2019-03-18T18:12:26Z'>
		&lt;denchmark-link:https://github.com/TahaK&gt;@TahaK&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
, I have tried this myself and yes this issue is reproducible.
As per my observation this issue occurred in keras aswell &lt;denchmark-link:https://github.com/keras-team/keras/issues/6844&gt;keras-team/keras#6844&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='TahaK' date='2019-03-19T09:05:40Z'>
		Would you mind passing a name for each weight? like this
self.w = self.add_weight(name='w',
                         shape=(input_shape[-1], self.units),
		</comment>
		<comment id='5' author='TahaK' date='2019-03-19T09:16:26Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 It seems a bug of getter:(

Can we let name become a required field for add_weight?
&gt;&gt;&gt; class A(keras.layers.Layer):
...   def __init__(self):
...     super(A, self).__init__()
...     self.weight_without_name = self.add_weight(shape=(3, 4))
...     self.default_weight = self.add_weight()
...
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.weight_without_name
&lt;tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=
array([[-0.09872711, -0.7932683 , -0.42732993, -0.9035983 ],
       [-0.50050485,  0.37918067,  0.09857702,  0.56991994],
       [ 0.7190112 ,  0.27319026, -0.29729384, -0.16420442]],
      dtype=float32)&gt;
&gt;&gt;&gt; a.default_weight
&lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-1.3627009&gt;
		</comment>
		<comment id='6' author='TahaK' date='2019-03-19T10:36:15Z'>
		
Would you mind passing a name for each weight? like this
self.w = self.add_weight(name='w',
                         shape=(input_shape[-1], self.units),

Yes passing a name solves the problem. I can save and load weights now, great!
		</comment>
		<comment id='7' author='TahaK' date='2019-08-02T06:11:27Z'>
		Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/ccf2b7a935d13a91fe5b4180277000eb/tf_26811.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!
		</comment>
		<comment id='8' author='TahaK' date='2019-08-02T06:11:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26811&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26811&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='TahaK' date='2019-12-24T10:59:54Z'>
		

Would you mind passing a name for each weight? like this
self.w = self.add_weight(name='w',
                         shape=(input_shape[-1], self.units),

Yes passing a name solves the problem. I can save and load weights now, great!

So, why passing a name works?
I use tf.saved_model.save to save my model and encounter the same error, will it work by passing a name?
		</comment>
		<comment id='10' author='TahaK' date='2020-03-03T16:11:05Z'>
		


Would you mind passing a name for each weight? like this
self.w = self.add_weight(name='w',
                         shape=(input_shape[-1], self.units),

Yes passing a name solves the problem. I can save and load weights now, great!

So, why passing a name works?
I use tf.saved_model.save to save my model and encounter the same error, will it work by passing a name?

It's related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36650&gt;#36650&lt;/denchmark-link&gt;
, see especially the last comment: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36650#issuecomment-585517731&gt;#36650 (comment)&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>