<bug id='40224' author='sandeepjana' open_date='2020-06-06T16:42:24Z' closed_time='2020-12-13T05:50:45Z'>
	<summary>'fused' argument of BatchNormalization is not saved in the model</summary>
	<description>
Batch normalization layer's fused argument is not part of the saved model h5/json.
Tested with TF version: 2.1.0 (CPU), Python 3.7.7
&lt;denchmark-code&gt;from tensorflow.keras import layers
from tensorflow.keras.models import Model

x = layers.Input((32, 32))
m = Model(x, layers.BatchNormalization(fused=False)(x))
print('fused' in m.to_json())
&lt;/denchmark-code&gt;

Output: False.
Expected output is True.
I found this issue when trying to get equal predictions in different versions of tensorflow.
I made a model with batch normalization layers. I tested the model in TF 1.12 and TF 2.1.0 (both are CPU versions, if that matters) with the same input. I got almost same predictions but differing in 4 or 5th decimal. Difference may become larger if the model is deeper. Once I manually added "fused" : false in the model json, the predictions became exactly same, at least after batch norm layer.
Fixing this issue can help during sanity check of the model, for the developers like me who work with different TF versions simultaneously.
	</description>
	<comments>
		<comment id='1' author='sandeepjana' date='2020-06-08T07:35:31Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/097019fc33cd11a9261eb368b0db4377/40224.ipynb&gt;TF v2.2&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/5ff8e0e7695d09abc816b7d2b4b812e1/40224-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='2' author='sandeepjana' date='2020-09-02T19:00:27Z'>
		any updates on this issue?
		</comment>
		<comment id='3' author='sandeepjana' date='2020-10-12T23:10:39Z'>
		&lt;denchmark-link:https://github.com/sandeepjana&gt;@sandeepjana&lt;/denchmark-link&gt;
 For your code snippet, the  arg has been set as  in the layer, why is it expected to be ?
		</comment>
		<comment id='4' author='sandeepjana' date='2020-12-13T05:50:45Z'>
		&lt;denchmark-link:https://github.com/sandeepjana&gt;@sandeepjana&lt;/denchmark-link&gt;
  Could you please check the above comment and let us know if the issue persists still.
Closing this issue as of now since it was the intended behavior. Thanks!
		</comment>
		<comment id='5' author='sandeepjana' date='2020-12-13T05:50:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40224&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40224&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>