<bug id='2127' author='rshin' open_date='2016-04-27T08:11:28Z' closed_time='2016-05-17T22:06:25Z'>
	<summary>tf.nn.dynamic_rnn fails when batch_size is 0</summary>
	<description>
&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: Ubuntu 15.10
Installed version of CUDA and cuDNN:
&lt;denchmark-code&gt;-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -&gt; libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so -&gt; libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so.4 -&gt; libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn_static.a
&lt;/denchmark-code&gt;

Commit hash: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/8d310bfcffcd46418d68dd535fb0fbcfee74b8a0&gt;8d310bf&lt;/denchmark-link&gt;

&lt;denchmark-h:h3&gt;Steps to reproduce&lt;/denchmark-h&gt;

Run the following test case:
&lt;denchmark-code&gt;import tensorflow as tf

outputs, state = tf.nn.dynamic_rnn(
  tf.nn.rnn_cell.BasicRNNCell(1),
  tf.zeros((0, 1, 1)),
  dtype=tf.float32)

with tf.Session() as sess:
  initializer = tf.random_uniform_initializer(-0.1, 0.1)
  tf.initialize_all_variables().run()
  print sess.run([state])
&lt;/denchmark-code&gt;

When TensorFlow is compiled with -c dbg, this fails with the following message:
&lt;denchmark-code&gt;python: external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124: Eigen::internal::TensorIntDivisor&lt;T, div_gt_one&gt;::TensorIntDivisor(T) [with T = long int; bool div_gt_one = false]: Assertion `divider &gt; 0' failed.
&lt;/denchmark-code&gt;

Using gdb, we get the following backtrace:
&lt;denchmark-code&gt;(gdb) bt
#0  0x00007ffff7826267 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:55
#1  0x00007ffff7827eca in __GI_abort () at abort.c:89
#2  0x00007ffff781f03d in __assert_fail_base (fmt=0x7ffff7980fe8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n", assertion=assertion@entry=0x7fffeb82f7fe "divider &gt; 0",
    file=file@entry=0x7fffeb82f738 "external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h", line=line@entry=124,
    function=function@entry=0x7fffeb860080 &lt;Eigen::internal::TensorIntDivisor&lt;int, false&gt;::TensorIntDivisor(int)::__PRETTY_FUNCTION__&gt; "Eigen::internal::TensorIntDivisor&lt;T, div_gt_one&gt;::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]") at assert.c:92
#3  0x00007ffff781f0f2 in __GI___assert_fail (assertion=0x7fffeb82f7fe "divider &gt; 0", file=0x7fffeb82f738 "external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h", line=124,
    function=0x7fffeb860080 &lt;Eigen::internal::TensorIntDivisor&lt;int, false&gt;::TensorIntDivisor(int)::__PRETTY_FUNCTION__&gt; "Eigen::internal::TensorIntDivisor&lt;T, div_gt_one&gt;::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]") at assert.c:101
#4  0x00007fffe9173cf5 in Eigen::internal::TensorIntDivisor&lt;int, false&gt;::TensorIntDivisor (this=0x7fff3dff9e40, divider=0)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124
#5  0x00007fffe9793fd5 in Eigen::TensorEvaluator&lt;Eigen::TensorSlicingOp&lt;Eigen::DSizes&lt;long, 3&gt; const, Eigen::DSizes&lt;long, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 3, 1, int&gt;, 16&gt; const&gt; const, Eigen::GpuDevice&gt;::TensorEvaluator (this=0x7fff3dff9f20, op=..., device=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:352
#6  0x00007fffe979370a in Eigen::TensorEvaluator&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 3, 1, int&gt;, 16&gt;, Eigen::TensorSlicingOp&lt;Eigen::DSizes&lt;long, 3&gt; const, Eigen::DSizes&lt;long, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 3, 1, int&gt;, 16&gt; const&gt; const&gt; const, Eigen::GpuDevice&gt;::TensorEvaluator (this=0x7fff3dff9f00, op=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:106
#7  0x00007fffe97930b3 in Eigen::internal::TensorExecutor&lt;Eigen::TensorAssignOp&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 3, 1, int&gt;, 16&gt;, Eigen::TensorSlicingOp&lt;Eigen::DSizes&lt;long, 3&gt; const, Eigen::DSizes&lt;long, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 3, 1, int&gt;, 16&gt; const&gt; const&gt; const, Eigen::GpuDevice, false&gt;::run (expr=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:233
#8  0x00007fffe9792bd2 in Eigen::TensorDevice&lt;Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 3, 1, int&gt;, 16&gt;, Eigen::GpuDevice&gt;::operator=&lt;Eigen::TensorSlicingOp&lt;Eigen::DSizes&lt;long, 3&gt; const, Eigen::DSizes&lt;long, 3&gt; const, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 3, 1, int&gt;, 16&gt; const&gt; &gt; (this=0x7fff3dffa040, other=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35
#9  0x00007fffe9792570 in tensorflow::functor::Split&lt;Eigen::GpuDevice, float&gt;::operator() (this=0x7fff3dffa1e0, d=..., output=..., input=..., slice_indices=..., slice_sizes=...)
    at tensorflow/core/kernels/split_lib_gpu.cu.cc:37
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp&lt;Eigen::GpuDevice, float&gt;::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
#11 0x00007fffeaf8e561 in tensorflow::BaseGPUDevice::Compute (this=0x2ba8110, op_kernel=0xe44040, context=0x7fff3dffab20) at tensorflow/core/common_runtime/gpu/gpu_device.cc:388
#12 0x00007fffeb1b22eb in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0xdf4290, tagged_node=..., scheduled_usec=0) at tensorflow/core/common_runtime/executor.cc:1092
#13 0x00007fffeb1bdbeb in std::_Mem_fn&lt;void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)&gt;::operator()&lt;tensorflow::(anonymous namespace)::ExecutorState::TaggedNode&amp;, long long&amp;, void&gt; (this=0x7fff200008c0, __object=0xdf4290) at /usr/include/c++/4.9/functional:569
#14 0x00007fffeb1bd03e in std::_Bind&lt;std::_Mem_fn&lt;void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt;(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt;::__call&lt;void, 0ul, 1ul, 2ul&gt;(&lt;unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7&gt;, std::_Index_tuple&lt;0ul, 1ul, 2ul&gt;) (this=0x7fff200008c0, __args=&lt;unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7&gt;)
    at /usr/include/c++/4.9/functional:1264
#15 0x00007fffeb1bb69a in std::_Bind&lt;std::_Mem_fn&lt;void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt;(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt;::operator()&lt;, void&gt;(void) (this=0x7fff200008c0) at /usr/include/c++/4.9/functional:1323
#16 0x00007fffeb1b98b6 in std::_Function_handler&lt;void(), std::_Bind&lt;std::_Mem_fn&lt;void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt;(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)&gt; &gt;::_M_invoke(const std::_Any_data &amp;) (__functor=...) at /usr/include/c++/4.9/functional:2039
#17 0x00007fffe8e4788c in std::function&lt;void ()&gt;::operator()() const (this=0x7fff3dffadd0) at /usr/include/c++/4.9/functional:2439
#18 0x00007fffeb450454 in tensorflow::thread::ThreadPool::Impl::WorkerLoop (this=0x2bb28f0) at tensorflow/core/lib/core/threadpool.cc:196
#19 0x00007fffeb44fe95 in tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, tensorflow::ThreadOptions const&amp;, std::string const&amp;, int)::{lambda()#1}::operator()() const ()
    at tensorflow/core/lib/core/threadpool.cc:123
#20 0x00007fffeb45086d in std::_Function_handler&lt;void(), tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&amp;, const string&amp;, int)::&lt;lambda()&gt; &gt;::_M_invoke(const std::_Any_data &amp;) (
    __functor=...) at /usr/include/c++/4.9/functional:2039
#21 0x00007fffe8e4788c in std::function&lt;void ()&gt;::operator()() const (this=0x2bb4c48) at /usr/include/c++/4.9/functional:2439
#22 0x00007fffeb471f5e in std::_Bind_simple&lt;std::function&lt;void ()&gt; ()&gt;::_M_invoke&lt;&gt;(std::_Index_tuple&lt;&gt;) (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1700
#23 0x00007fffeb471ea3 in std::_Bind_simple&lt;std::function&lt;void ()&gt; ()&gt;::operator()() (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1688
#24 0x00007fffeb471e20 in std::thread::_Impl&lt;std::_Bind_simple&lt;std::function&lt;void ()&gt; ()&gt; &gt;::_M_run() (this=0x2bb4c30) at /usr/include/c++/4.9/thread:115
#25 0x00007fffdc3bc030 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#26 0x00007ffff7bc26aa in start_thread (arg=0x7fff3dffb700) at pthread_create.c:333
#27 0x00007ffff78f7e9d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

(gdb) f 10
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp&lt;Eigen::GpuDevice, float&gt;::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
753           functor::Split&lt;Device, T&gt;()(ctx-&gt;eigen_device&lt;Device&gt;(), tensor_value_i_t,
(gdb) p this-&gt;name()
$1 = (const std::string &amp;) @0xdc49e0: {static npos = &lt;optimized out&gt;, _M_dataplus = {&lt;std::allocator&lt;char&gt;&gt; = {&lt;__gnu_cxx::new_allocator&lt;char&gt;&gt; = {&lt;No data fields&gt;}, &lt;No data fields&gt;},
    _M_p = 0x2bee918 "RNN/TensorArrayUnpack"}}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='rshin' date='2016-04-27T19:05:58Z'>
		Thanks for the detailed report.
		</comment>
		<comment id='2' author='rshin' date='2016-04-27T19:41:11Z'>
		tensorflow/core/kernels/tensor_array_ops.cc:753 is the key line from the stack trace.  &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 is the author, but is on vacation at the moment.  Other calls to functor::Split() can be found at tensorflow/core/kernels/split_op.cc:172 and tensorflow/core/kernels/unpack_op.cc:86.  Looks like &lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
 might have some familiarity.
		</comment>
		<comment id='3' author='rshin' date='2016-04-27T21:00:27Z'>
		The Split kernel assumes its inputs are nonempty, and TensorArrayUnpackOp doesn't check this.  It should.
		</comment>
		<comment id='4' author='rshin' date='2016-05-16T16:58:36Z'>
		&lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
: Would you have time to look at this, now you're back? (Or did it get fixed in the mean time?)
		</comment>
		<comment id='5' author='rshin' date='2016-05-17T22:06:25Z'>
		Looks like it was fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/b7f7fe26fd2e15978d84a1f02e983faf7324a131&gt;b7f7fe2&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>