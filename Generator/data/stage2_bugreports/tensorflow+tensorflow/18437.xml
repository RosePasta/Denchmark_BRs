<bug id='18437' author='sehgal-abhishek' open_date='2018-04-11T23:06:55Z' closed_time='2018-08-02T22:23:15Z'>
	<summary>Converting TensorFlow frozen and inference model to lite fails with "Check failed: array-&amp;gt;has_shape"</summary>
	<description>

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OS X High Sierra
TensorFlow installed from (source or binary):
Source
TensorFlow version (use command below):
'v1.7.0-rc1-1018-g7a0def60d4' 1.7.0-rc1
Python version:
3.5.5
Bazel version (if compiling from source):
0.10.1
GCC/Compiler version (if compiling from source):
Apple LLVM version 9.1.0 (clang-902.0.39.1)
CUDA/cuDNN version:
NA
GPU model and memory:
NA
Exact command to reproduce:
bazel-bin/tensorflow/contrib/lite/toco/toco 
--input_file=frozen.pb 
--input_format=TENSORFLOW_GRAPHDEF 
--output_format=TFLITE 
--output_file=frozen.lite 
--input_array=Inputs/Input 
--output_array=Outputs/Prediction 
--input_shape=1,28,28,1 
--inference_type=FLOAT
-Error Message
F tensorflow/contrib/lite/toco/tooling_util.cc:831] Check failed: array-&gt;has_shape()

I have created a TensorFlow model which classifies MNIST image data. The model is then frozen and optimized for inference. These models I can benchmark as well. But when converting to TensorFlow lite, the toco command fails with the above mentioned error message.
I have summarized the graph as well for both frozen and inference model.
The frozen model has the same size of (1,28,28,1) but the inference has a size of (None). I am using a placeholder when creating the model for the Input.
	</description>
	<comments>
		<comment id='1' author='sehgal-abhishek' date='2018-04-23T18:50:51Z'>
		&lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
 could you take a look?
		</comment>
		<comment id='2' author='sehgal-abhishek' date='2018-04-25T18:59:14Z'>
		That's a strange error. Could you make sure the input and output arrays have the correct names in your command line?
		</comment>
		<comment id='3' author='sehgal-abhishek' date='2018-04-26T16:33:53Z'>
		The Input and Output arrays have the correct name. I'm using tf.gather in my graph which I guess might be  causing the problem as an unsupported node.
		</comment>
		<comment id='4' author='sehgal-abhishek' date='2018-04-26T17:00:50Z'>
		It looks like this code has been changed recently so I can't pinpoint exactly where the CHECK is. It seems to be this line: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/tooling_util.cc#L841&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/tooling_util.cc#L841&lt;/denchmark-link&gt;

That indicates a problem with the model, or a unreasonable assumption by TOCO.
		</comment>
		<comment id='5' author='sehgal-abhishek' date='2018-04-26T19:05:07Z'>
		Yeah that's what I was guessing. But I read the docs and it said tf.gather was not supported so I guess it won't be able to convert it.
I just wanted to double check, does the input the lite models need to be a fixed number? e.g. the model is saved as Input [?, 28, 28, 1] but for lite conversion does it need to be [1,28,28,1]?
Thank you for looking into this issue.
		</comment>
		<comment id='6' author='sehgal-abhishek' date='2018-04-26T21:59:23Z'>
		Support for tf.gather has been added recently.
You can resize the input tensor before inference. Call ResizeInputTensor().
		</comment>
		<comment id='7' author='sehgal-abhishek' date='2018-04-29T14:39:44Z'>
		I have been having a similar issue.  All of the operations are supported, but conversion to .tflite fails because the input tensor has an input dimension of type None (to allow an arbitrary number of input datapoints)
From the &lt;denchmark-link:https://www.tensorflow.org/versions/master/mobile/tflite/devguide&gt;tflite dev guide&lt;/denchmark-link&gt;
, you can convert your model to FlatBuf like so:
&lt;denchmark-code&gt;import tensorflow as tf

img = tf.placeholder(name="img", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name="out")

with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open("converteds_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

However, if our input can be of arbitrary size, (e.g. our input x is of shape [None, 784]), then we get Error: TypeError: __int__ returned non-int (type NoneType).
I posted a &lt;denchmark-link:https://stackoverflow.com/questions/50028868/tensorflow-lite-toco-convert-for-arbitrary-sized-input-tensor&gt;SO question&lt;/denchmark-link&gt;
, but have no answers yet.
A M(not)WE could be:
&lt;denchmark-code&gt;import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

graph_mnist = tf.Graph()

with graph_mnist.as_default():
    with tf.name_scope('data'):
        inputs = tf.placeholder(tf.float32, [None, 784], name='inputs')
        targets = tf.placeholder(tf.float32, [None, 10], name='targets')
    with tf.name_scope('parameters'):
        weights = tf.Variable(tf.zeros([784, 10]), name='weights')
        biases = tf.Variable(tf.zeros([10]), name='biases')
    with tf.name_scope('model'):
        outputs = tf.matmul(inputs, weights) + biases
    with tf.name_scope('error'):
        error = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=targets))
    with tf.name_scope('train'):
        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(error)
    with tf.name_scope('accuracy'):
        accuracy = tf.reduce_mean(tf.cast(
                tf.equal(tf.argmax(outputs, 1), tf.argmax(targets, 1)), tf.float32))
    with tf.name_scope('init'):
        init_op = tf.global_variables_initializer()

sess = tf.Session(graph=graph_mnist)
sess.run(init_op)

for _ in range(200):
    batch = mnist.train.next_batch(100)
    _, batch_error = sess.run(
        [train_step, error],
        feed_dict={inputs: batch[0], targets: batch[1]})
        
        
def get_error_and_accuracy(xx, yy_):
    err = 0
    acc = 0
    err += sess.run(error, feed_dict={inputs: xx, targets: yy_})
    acc += sess.run(accuracy, feed_dict={inputs: xx, targets: yy_})
    return err, acc

print('Train data: Error={0:.2f} Accuracy={1:.2f}'
    .format(*get_error_and_accuracy(mnist.train.images, mnist.train.labels)))
print('Valid data: Error={0:.2f} Accuracy={1:.2f}'
    .format(*get_error_and_accuracy(mnist.test.images, mnist.test.labels)))
    
    
tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [inputs], [outputs])
open("converteds_model.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

How would one convert a model like this to the .tflite format?
		</comment>
		<comment id='8' author='sehgal-abhishek' date='2018-05-14T18:59:50Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='9' author='sehgal-abhishek' date='2018-05-29T19:04:58Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='sehgal-abhishek' date='2018-05-30T15:11:05Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='sehgal-abhishek' date='2018-06-14T18:50:06Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='12' author='sehgal-abhishek' date='2018-06-29T18:56:01Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 60 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='13' author='sehgal-abhishek' date='2018-07-14T18:40:14Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 75 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='14' author='sehgal-abhishek' date='2018-07-29T18:33:39Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
: It has been 90 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='15' author='sehgal-abhishek' date='2018-08-02T22:23:15Z'>
		&lt;denchmark-link:https://github.com/Wheest&gt;@Wheest&lt;/denchmark-link&gt;
 this seems like a separate issue. You should use a fixed batch size. In the future you should create a new issue.
I think &lt;denchmark-link:https://github.com/andrehentz&gt;@andrehentz&lt;/denchmark-link&gt;
 resolved the original issue, so closing this now.
		</comment>
	</comments>
</bug>