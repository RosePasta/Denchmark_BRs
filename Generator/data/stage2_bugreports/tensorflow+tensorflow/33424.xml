<bug id='33424' author='koenhelwegen' open_date='2019-10-16T12:18:13Z' closed_time='2019-10-31T13:17:04Z'>
	<summary>Loading optimizer variables from checkpoint not working in tf.keras</summary>
	<description>
System information

Custom code
Ubuntu 18
TensorFlow version 2.0.0
Python version 3.7

Describe the current behavior
Restoring a checkpoint with saved optimizer variables is not working.
Describe the expected behavior
When saving a checkpoint using tf.keras.callbacks.ModelCheckpoint(..., save_weights_only=False), restoring the checkpoint should also recover the optimizer variables.
Code to reproduce the issue
model = get_model()
model.fit(
    train_images,
    train_labels,
    epochs=1,
    callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_weights_only=False)]
)
w0 = model.trainable_weights[0].numpy()
opt_w0 = model.optimizer.weights[1].numpy()

tf.keras.backend.clear_session()

# this throws an error when `save_weights_only=True`. If `save_weights_only=False` it doesn't restore optimizer variables
model = tf.keras.models.load_model(model_path)

# this throws an error when `save_weights_only=False`.
model = get_model()
model.load_weights(model_path)

w1 = model.trainable_weights[0].numpy()
try:
    opt_w1 = model.optimizer.weights[1].numpy()
except:
    opt_w1 = None
    
print(f'Weights correctly loaded: {np.all(w0 == w1)}') 
print(f'Optimizer weights correctly loaded: {np.all(opt_w0 == opt_w1) if opt_w1 is not None else False}') 
Outputs
save_weights_only=True with tf.keras.load_model():
&lt;denchmark-code&gt;OSError: SavedModel file does not exist at: /tmp/m79804149/model/{saved_model.pbtxt|saved_model.pb}
&lt;/denchmark-code&gt;

save_weights_only=False with tf.keras.load_model():
&lt;denchmark-code&gt;Train on 60000 samples
59136/60000 [============================&gt;.] - ETA: 0s - loss: 0.4933 - accuracy: 0.8269INFO:tensorflow:Assets written to: /tmp/m41299667/model/assets
60000/60000 [==============================] - 3s 55us/sample - loss: 0.4923 - accuracy: 0.8273
Weights correctly loaded: True
Optimizer weights correctly loaded: False
&lt;/denchmark-code&gt;

save_weights_only=True with model.load_weights() (expected behaviour):
&lt;denchmark-code&gt;Train on 60000 samples
60000/60000 [==============================] - 3s 50us/sample - loss: 0.4945 - accuracy: 0.8266
Weights correctly loaded: True
Optimizer weights correctly loaded: False
&lt;/denchmark-code&gt;

save_weights_only=False with model.load_weights():
&lt;denchmark-code&gt;OSError: Unable to open file (file read failed: time = Wed Oct 16 13:16:20 2019
, filename = '/tmp/m88520022/model', file descriptor = 79, errno = 21, error message = 'Is a directory', buf = 0x7ffd683b9c80, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='koenhelwegen' date='2019-10-17T06:59:16Z'>
		&lt;denchmark-link:https://github.com/koenhelwegen&gt;@koenhelwegen&lt;/denchmark-link&gt;
,
As per the description in &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint#arguments&gt;doc&lt;/denchmark-link&gt;
, is True only model weights will be saved else full model is saved. Please let me know if i misunderstood your issue. Thanks!
		</comment>
		<comment id='2' author='koenhelwegen' date='2019-10-17T08:52:18Z'>
		Yes, so I would like to set save_weights_only=False, but then loading the model fails or optimizer variables are not loaded (see 2nd and 4th output above).
		</comment>
		<comment id='3' author='koenhelwegen' date='2019-10-18T10:08:35Z'>
		&lt;denchmark-link:https://github.com/koenhelwegen&gt;@koenhelwegen&lt;/denchmark-link&gt;
, Will it be possible to provide the complete code to replicate the issue. Thanks!
		</comment>
		<comment id='4' author='koenhelwegen' date='2019-10-18T13:45:34Z'>
		Sure, here you go:
import tensorflow as tf
from tensorflow import keras
import numpy as np
import os

def get_model():
    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(128, activation=tf.nn.relu),
        keras.layers.Dense(10, activation=tf.nn.softmax)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

def get_model_path():
    model_dir = '/tmp/m' + str(np.random.randint(0, 1000000))
    os.makedirs(model_dir)
    model_path = os.path.join(model_dir, 'model')
    return model_path

def attempt_save_and_reload(model_path, restore_method="model.load_weights()", save_weights_only=False,):
    assert restore_method in ["model.load_weights()", "tf.keras.models.load_model()"]
    
    fashion_mnist = keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
    train_images = train_images / 255.0
    test_images = test_images / 255.0
    
    tf.keras.backend.clear_session()
    
    model = get_model()
    model.fit(
        train_images,
        train_labels,
        epochs=1,
        callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath=model_path, save_weights_only=save_weights_only)]
    )
    w0 = model.trainable_weights[0].numpy()
    opt_w0 = model.optimizer.weights[1].numpy()

    tf.keras.backend.clear_session()

    # this throws an error when `save_weights_only=True`. If `save_weights_only=False` it doesn't restore optimizer variables
    if restore_method == "tf.keras.models.load_model()":
        model = tf.keras.models.load_model(model_path)

    # this throws an error when `save_weights_only=False`.
    elif restore_method == "model.load_weights()":
        model = get_model()
        model.load_weights(model_path)

    w1 = model.trainable_weights[0].numpy()
    try:
        opt_w1 = model.optimizer.weights[1].numpy()
    except:
        opt_w1 = None

    print(f'Weights correctly loaded: {np.all(w0 == w1)}') 
    print(f'Optimizer weights correctly loaded: {np.all(opt_w0 == opt_w1) if opt_w1 is not None else False}')
    
if __name__ == '__main__':
    for restore_method in ["model.load_weights()", "tf.keras.models.load_model()"]:
        print('Restore method: ', restore_method)
        model_path = get_model_path()
        try:
            attempt_save_and_reload(model_path, restore_method)
        except Exception as e:
            print('Exception raised: \n', e)
        print()
Output for me:
&lt;denchmark-code&gt;Restore method:  model.load_weights()
Train on 60000 samples
59392/60000 [============================&gt;.] - ETA: 0s - loss: 0.5015 - accuracy: 0.8250INFO:tensorflow:Assets written to: /tmp/m2539/model/assets
60000/60000 [==============================] - 3s 53us/sample - loss: 0.5008 - accuracy: 0.8252
Exception raised: 
 Unable to open file (file read failed: time = Fri Oct 18 14:43:23 2019
, filename = '/tmp/m2539/model', file descriptor = 79, errno = 21, error message = 'Is a directory', buf = 0x7ffe7d545130, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)

Restore method:  tf.keras.models.load_model()
Train on 60000 samples
59104/60000 [============================&gt;.] - ETA: 0s - loss: 0.5011 - accuracy: 0.8255INFO:tensorflow:Assets written to: /tmp/m183568/model/assets
60000/60000 [==============================] - 3s 56us/sample - loss: 0.5003 - accuracy: 0.8257
Weights correctly loaded: True
Optimizer weights correctly loaded: False
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='koenhelwegen' date='2019-10-21T09:48:20Z'>
		Could reproduce the issue with Tf 2.0.0. Please see the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/1dcfd9ad579df7586d62a0176a11feb6/untitled215.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='koenhelwegen' date='2019-10-22T12:17:01Z'>
		&lt;denchmark-link:https://github.com/koenhelwegen&gt;@koenhelwegen&lt;/denchmark-link&gt;
,
There are couple of Observations from your code.

For you to Load the Model using tf.keras.models.load_model(), model should be saved using the command, model.save as shown in this link but you are using Call Backs.
Once the Model is Saved using model.save and loaded using tf.keras.models.load_model(), the way we are extracting the Weights using the code, model.optimizer.weights[1].numpy() might not be correct. That might be the reason for Optimizer weights correctly loaded: False.

Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/85a439b4d65c592280f009f48e97436b/33424_loading_optimizer_vars.ipynb#scrollTo=KyaLvV9wUGPN&gt;Gist&lt;/denchmark-link&gt;
 in which, the  are Same, when using  and   but different when using  and , which might be expected, as per point (2) above.
Please let me know your thought about the same. Thanks!
		</comment>
		<comment id='7' author='koenhelwegen' date='2019-10-31T13:17:04Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 thanks for your response!
It seems that what I need is to use the .h5 model format. If model_path in my code above points to a .h5 file both weights and optimizer variables are restored correctly. This works fine with tf.keras.callbacks.ModelCheckpoint(model_path, save_weights_only=False) on both single and multi-gpu.
I looked at your gist and it seems that you are not resetting the model between calling model.save_weights() and model.load_weights(). If I insert a model = get_model() optimizer variables are not restored (which I suppose is expected, as save and load functions explicitly target weights). The SavedModel format seems broken to me, but I'm happy to rely on the .h5 format for now.
		</comment>
		<comment id='8' author='koenhelwegen' date='2019-10-31T13:17:06Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33424&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33424&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='koenhelwegen' date='2019-12-05T18:54:26Z'>
		This appears to be an issue when trying to use ModelCheckpoint with distributed models. Specifically, the ModelCheckpoint callback only supports h5 format, but the h5 format cannot save the distribution strategy properly for resuming training later. Using "with strategy.scope(): load_model(XXX)" doesn't work either. One partial (but not good) workaround would be to rebuild the model, then set its weights from a saved checkpoint. This restores the scope as desired, but loses the optimizer state.
		</comment>
		<comment id='10' author='koenhelwegen' date='2020-03-02T02:56:32Z'>
		From this post, I've understood that by model.save(file.h5), and loading the model again solves the problem of loading of the Optimizer weights.
However, this contradicts with my case:
Code to Reproduce:
&lt;denchmark-code&gt;def get_model():
    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(128, activation=tf.nn.relu),
        keras.layers.Dense(10, activation=tf.nn.softmax)
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model = get_model()

steps_per_epoch = round(len(train_labels))//BATCH_SIZE
val_steps = 20

baseline_history = model.fit(
    train_data.repeat(),
    epochs=60,
    steps_per_epoch = steps_per_epoch,
    callbacks = [cp_callback],
    validation_data=val_data.repeat(),
    validation_steps=val_steps,
    verbose=1
    )


model.save('model_03Mar.h5')


resampled_model = tf.keras.models.load_model("model_03Mar.h5")

fine_tune_oversample_epochs = 30
initial_epoch = 30
total_epochs =  initial_epoch + fine_tune_oversample_epochs

resampled_steps_per_epoch =int(np.ceil(2.0*neg/BATCH_SIZE))

resampled_history = resampled_model.fit(
    resampled_ds.repeat(),
    initial_epoch = 30,
    epochs=total_epochs,
    steps_per_epoch=resampled_steps_per_epoch,
    validation_data=val_data.repeat(),
    validation_steps = 20
)
&lt;/denchmark-code&gt;

Outcome:

W0302 10:16:43.084619 140023726221120 hdf5_format.py:192] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.

&lt;denchmark-code&gt;Train for 194 steps, validate for 20 steps
Epoch 31/60
194/194 [==============================] - 96s 495ms/step - loss: 0.0151 - tp: 3102.0000 - fp: 13.0000 - tn: 3078.0000 - fn: 15.0000 - accuracy: 0.9955 - precision: 0.9958 - recall: 0.9952 - auc: 0.9997 - val_loss: 0.5462 - val_tp: 56.0000 - val_fp: 36.0000 - val_tn: 522.0000 - val_fn: 22.0000 - val_accuracy: 0.9088 - val_precision: 0.6087 - val_recall: 0.7179 - val_auc: 0.8619

&lt;/denchmark-code&gt;

And then training continues, I am not able to understand why the optimizer weights are not loaded.
		</comment>
	</comments>
</bug>