<bug id='27789' author='lwander' open_date='2019-04-12T15:36:14Z' closed_time='2020-01-29T01:32:21Z'>
	<summary>The text generation tutorial doesn't seem to be passing along hidden state while generating text</summary>
	<description>
System information

TensorFlow version: tensorflow-gpu==1.10.1
Doc Link: https://www.tensorflow.org/tutorials/sequences/text_generation#the_prediction_loop

Describe the documentation issue
I followed the text generation tutorial, and trained my model until it achieved a cross entropy loss of ~0.5 after 30 epochs; however, the generated text was mostly garbage. Reading the code linked in the section above, I saw:
      # We pass the predicted word as the next input to the model
      # along with the previous hidden state
      input_eval = tf.expand_dims([predicted_id], 0)
which doesn't make sense to me. The comment says we're passing along the hidden state (which maybe the model is doing for us?) but the only text that's passed along is the last predicted character. After modifying the text generation function to pass to the model last at most seq_length generated characters, the output text started to look like actual Shakespeare/English.
My question is: is the model supposed to implicitly propagate hidden state, (and I've done something wrong following the tutorial), or is the tutorial accidentally omitting the part where we pass along the last set of generated text?

Note: Since I'm running tensorflow 1.10, and the tutorial seems to require 1.13 I had to replace the loss function with tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits). I don't think that change is related, but is it possible that tf 1.10 doesn't propagate the hidden state in the model?

We welcome contributions by users. Will you be able to update submit a PR (use the doc style guide) to fix the doc Issue?
I'm happy to contribute my code changes to the tutorial, but want to make sure I'm understanding what's going wrong first.
	</description>
	<comments>
		<comment id='1' author='lwander' date='2019-04-16T19:40:58Z'>
		For running locally, tutorial requires TF &gt;=1.11 You can also use google colab to execute this tutorial. It hosts TF 1.13.1 by default.
		</comment>
		<comment id='2' author='lwander' date='2019-04-16T20:18:37Z'>
		Does this mean the behavior of
      predictions = model(input_eval)
changes between tensorflow 1.10 &amp; 1.11? Namely, does the GRU cell not pass forward hidden state in tensorflow 1.10?
		</comment>
		<comment id='3' author='lwander' date='2019-04-19T03:47:48Z'>
		The stateful RNN behavior hasn't been update/change for long time, the hidden state is attached to the model instance, and is just as initial state when the new input is coming.
The line of input_eval is just using the previous output and make it the new input. As long as the model.reset_state() is not called, the hidden state will always be attached to the model, and been updated when the calculation is performed.
		</comment>
		<comment id='4' author='lwander' date='2019-04-19T12:24:10Z'>
		Yeah, that's what I had assumed, which is why I was so surprised at how different the results were when explicitly passing past characters into the model vs. only passing the last generated character.  model.reset_state() is only called once before we start feeding the model any characters.
Trained to a loss of ~0.5, and with a temperature of 1.0
here is what the code generates without any modifications:
&lt;denchmark-code&gt;ROMEO:
SIERING thed.
Foro yo an whizeve wick.

CLo he ost.
DUERESUSthoupinaio micore helell ghacheer ofismyo hin inghisicalir whice SI st thire aree f byondeminie, hindathe prd t'
RDurrin ve if aft wea IORWhis dat, aile boomeceanant ighea bustad, che Katauind, d wendowhelld lde chiom dwotasis whench we he
&lt;/denchmark-code&gt;

here is what the code generates with the modification described above:
&lt;denchmark-code&gt;ROMEO:
Good Paulina,
Who hast deep a sinner to the crown?

KING RICHARD III:
Nor newt before him, we have comes consorn.

KING HENRY VI:
Then know, I'll tell thee for thy sacred blood rich groat;
And when thou fail'st--as God again; my brother's son
It rawn his convent and dispatch with him.
&lt;/denchmark-code&gt;

Is there any way I can inspect the models hidden state?
		</comment>
		<comment id='5' author='lwander' date='2019-04-19T16:34:14Z'>
		Since the model is built with return_sequence=True, it should intake sequences and output sequences. So when you ask model to generate new test, the input should be previously generated words or sequences, not just the last char it previous generated.
To exam the hidden state of the model, specially for the GRU layer, you can get the state by gru_layer.states.
		</comment>
		<comment id='6' author='lwander' date='2019-04-19T16:34:56Z'>
		Also adding Mark who works on documentation.
		</comment>
		<comment id='7' author='lwander' date='2019-04-19T16:55:26Z'>
		
Since the model is built with return_sequence=True, it should intake sequences and output sequences. So when you ask model to generate new test, the input should be previously generated words or sequences, not just the last char it previous generated.

If I remove return_sequences=true from the GRU layer, should the tutorial work as shown? (I'll try that right now).

To exam the hidden state of the model, specially for the GRU layer, you can get the state by gru_layer.states.

Sorry, I don't exactly follow, where is gru_layer defined?
		</comment>
		<comment id='8' author='lwander' date='2019-04-19T16:59:15Z'>
		Removing return_sequences=True causes a dimension mismatch:
&lt;denchmark-code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding (Embedding)        (64, None, 256)           16640
_________________________________________________________________
cu_dnngru (CuDNNGRU)         (64, 1024)                3938304
_________________________________________________________________
dense (Dense)                (64, 65)                  66625
=================================================================
Total params: 4,021,569
Trainable params: 4,021,569
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "shakespeare.py", line 88, in train
    history = model.fit(dataset.repeat(), epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py", line 1348, in fit
    validation_steps=validation_steps)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py", line 1040, in fit_loop
    do_validation=do_validation)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py", line 284, in iterator_fit_loop
    model, x, y, sample_weights=sample_weights, training=True)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py", line 794, in _process_single_batch
    training=training)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_eager.py", line 155, in _model_loss
    targets[i], outs[i], weights, mask=mask)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_utils.py", line 437, in weighted
    score_array = fn(y_true, y_pred)
  File "shakespeare.py", line 70, in loss
    return tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py", line 2053, in sparse_softmax_cross_entropy_with_logits
    (labels_static_shape.ndims, logits.get_shape().ndims))
ValueError: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).
&lt;/denchmark-code&gt;

Note, I'm using sparse_softmax_cross_entropy_with_logits due to my TF version being 1.10
		</comment>
		<comment id='9' author='lwander' date='2019-04-22T16:53:53Z'>
		The return_sequence is definitely needed, otherwise it will return the output with last timestep instead of all timesteps.
For gru_layer, you created it within the build_model, you can access the model.layers which should contain all the layers in the model, and gru layer should be one of them.
		</comment>
		<comment id='10' author='lwander' date='2020-01-29T01:32:21Z'>
		This tutorial was rewritten from scratch for 2.0 and seems to train and generate text correctly.  I'm closing this, but please file a new issue if you see any other issue.  Thanks!
		</comment>
	</comments>
</bug>