<bug id='31202' author='esslushy' open_date='2019-07-31T15:56:06Z' closed_time='2019-08-15T18:49:11Z'>
	<summary>Documentation is missing explanation of how to write custom loss functions for the keras api</summary>
	<description>
&lt;denchmark-h:h2&gt;URL(s) with the issue:&lt;/denchmark-h&gt;

&lt;denchmark-link:https://www.tensorflow.org/beta/guide/keras/training_and_evaluation#specifying_a_loss_metrics_and_an_optimizer&gt;https://www.tensorflow.org/beta/guide/keras/training_and_evaluation#specifying_a_loss_metrics_and_an_optimizer&lt;/denchmark-link&gt;

&lt;denchmark-h:h2&gt;Description of issue (what needs changing):&lt;/denchmark-h&gt;

Documentation is missing how to write custom loss functions and how to use the keras.losses.Loss class to write a loss function that takes more inputs than just y_true and y_pred despite the portion saying it will show how to write custom losses and metrics. Currently it shows how to write custom metrics and in layer loss only.
&lt;denchmark-h:h3&gt;Clear description&lt;/denchmark-h&gt;

People can use this method to implement loss function not implemented in tensorflow or their own variations of loss functions. It also allows ports of loss functions without a keras.losses exposure such as tf.nn.weighted_cross_entropy_with_logits to be implemented in a model.compile use case without the need to write a custom training loop.
&lt;denchmark-h:h3&gt;Correct links&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h3&gt;Parameters defined&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h3&gt;Returns defined&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h3&gt;Raises listed and defined&lt;/denchmark-h&gt;

N/A
&lt;denchmark-h:h3&gt;Usage example&lt;/denchmark-h&gt;

There is no documentation, but a good example would be porting a loss function from tensorflow.nn to be used in a class extending keras.losses.Loss and showing how to use a user written function without the keras.losses.Loss class.
&lt;denchmark-h:h3&gt;Request visuals, if applicable&lt;/denchmark-h&gt;

No visuals are there, but a portion of code similar to the custom metric code shown would be a good visual.
A custom loss function I wrote in python follows:
&lt;denchmark-code&gt;class WeightedBinaryCrossEntropy(keras.losses.Loss):
    """
    pos_weight: Scalars the effec on loss by the positive class by whatever is passed into it.
    weight: Scalars all the loss. Can be used to increase scalar of negative weight only by passing 1/weight to pos_weight. 
            To affect pos_weight even more after this multiply in the other scalar you had in mind for it
    """
    def __init__(self, pos_weight, weight, from_logits=False, reduction=keras.losses.Reduction.AUTO, name='weighted_binary_crossentropy'):
        super(WeightedBinaryCrossEntropy, self).__init__(reduction=reduction, name=name)
        self.pos_weight = pos_weight
        self.weight = weight
        self.from_logits = from_logits

    def call(self, y_true, y_pred):
        if not self.from_logits:
            with tf.name_scope('Weighted_Cross_Entropy'):
                # Manually calculated the weighted cross entropy. Formula is qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x)) where z are labels, x is logits, and q is the weight.
                # Since the values passed are from sigmoid (assumably in this case) sigmoid(x) will be replaces with y_pred
                x_1 = y_true * self.pos_weight * -tf.math.log(y_pred + 1e-6) # qz * -log(sigmoid(x)) 1e-6 is added as an epsilon to stop passing a zero into the log
                x_2 = (1 - y_true) * -tf.math.log(1 - y_pred + 1e-6) # (1 - z) * -log(1 - sigmoid(x)). Epsilon is added to prevent passing a zero into the log
                return tf.add(x_1, x_2) * self.weight # Must be negative as it is maximized when passed to optimizers
        # Use built in function
        return tf.nn.weighted_cross_entropy_with_logits(y_true, y_pred, self.pos_weight) * self.weight
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Submit a pull request?&lt;/denchmark-h&gt;

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs&gt;https://www.tensorflow.org/community/contribute/docs&lt;/denchmark-link&gt;
 and the
docs style guide: &lt;denchmark-link:https://www.tensorflow.org/community/contribute/docs_style&gt;https://www.tensorflow.org/community/contribute/docs_style&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='esslushy' date='2019-07-31T17:24:34Z'>
		&lt;denchmark-link:https://github.com/esslushy&gt;@esslushy&lt;/denchmark-link&gt;
 Are you planning to submit a PR to improve the documentation with examples of custom loss function? Thanks!
		</comment>
		<comment id='2' author='esslushy' date='2019-07-31T18:25:31Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Sure I can do that. I just was unsure if I should in case I misunderstood how the losses api was suppose to be shown. I will work on a PR. Thanks for the response.
		</comment>
		<comment id='3' author='esslushy' date='2019-07-31T21:11:31Z'>
		&lt;denchmark-link:https://github.com/esslushy&gt;@esslushy&lt;/denchmark-link&gt;
 I know you already know what you need to do. There was a recent &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30711&gt;issue&lt;/denchmark-link&gt;
 regarding custom metric which might help you. Thanks!
		</comment>
		<comment id='4' author='esslushy' date='2019-07-31T21:59:07Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 thanks for the issue regarding the metrics and for responding so quickly. I have submit a &lt;denchmark-link:https://github.com/tensorflow/docs/pull/892&gt;pull request&lt;/denchmark-link&gt;
 for the change. Thanks for all the help. Have a great day.
		</comment>
		<comment id='5' author='esslushy' date='2019-08-15T18:49:11Z'>
		&lt;denchmark-link:https://github.com/esslushy&gt;@esslushy&lt;/denchmark-link&gt;
 Automatically closing this out since I understand it to be resolved by the &lt;denchmark-link:https://github.com/tensorflow/docs/pull/892&gt;tensorflow/docs#892&lt;/denchmark-link&gt;
 (merged already), but please let me know if I'm mistaken.Thanks!
		</comment>
	</comments>
</bug>