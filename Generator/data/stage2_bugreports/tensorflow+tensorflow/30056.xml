<bug id='30056' author='scotthong' open_date='2019-06-23T04:01:17Z' closed_time='2020-04-17T18:31:24Z'>
	<summary>multi-gpu training: tf.compat.v1.scatter_sub() operation throws exception</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Extended from the stock example
https://www.tensorflow.org/beta/tutorials/distribute/keras
Working example is attached to this bug report


OS Platform and Distribution

Linux Ubuntu 16.04


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

No


TensorFlow installed from (source or binary):

Binary


TensorFlow version (use command below):

2.0.0-beta1


Python version:

Python 3.5.2


Bazel version (if compiling from source):

N/A (0.23.2)


GCC/Compiler version (if compiling from source):

N/A (5.4.0 20160609)


CUDA/cuDNN version:

10.0.130/7.4.1


GPU model and memory:

4x Titan Xp (12Gb) (Standalong, no SLI connections)



Describe the current behavior
&lt;denchmark-code&gt;tf.compat.v1.scatter_sub does not support multi-gpu training.

    AttributeError: 'Tensor' object has no attribute '_lazy_read'

    is thrown in the tf.compat.v1.scatter_sub() operation.

There is no equivalent scatter_* operations in tf.compat.v2 module.
&lt;/denchmark-code&gt;

Describe the expected behavior
tf.compat.v1.scatter_sub or equivalent scatter_* operations should support multi-gpu training.
Code to reproduce the issue

The script attached is used to train a model using multiple GPUs.


The code is modified from the stock example for quick experiment.

https://www.tensorflow.org/beta/tutorials/distribute/keras



Other info / logs
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0622 23:56:34.418763 140543953778432 cross_device_ops.py:1164] Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:1,/job:localhost/replica:0/task:0/device:GPU:0
Number of devices: 2
Traceback (most recent call last):
  File "center_loss_mnist.py", line 326, in &lt;module&gt;
    run(0.0001)
  File "center_loss_mnist.py", line 259, in run
    final_output, side_output = my_model(main_input, aux_input)
  File "center_loss_mnist.py", line 119, in my_model
    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py", line 662, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py", line 169, in wrapper
    raise e.ag_error_metadata.to_exception(type(e))
AttributeError: in converted code:

    center_loss_mnist.py:179 call  *
        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/state_ops.py:535 scatter_sub
        return ref._lazy_read(gen_resource_variable_ops.resource_scatter_sub(  # pylint: disable=protected-access
    /usr/local/lib/python3.5/dist-packages/tensorflow/python/distribute/values.py:381 __getattr__
        return getattr(self.get(), name)

    AttributeError: 'Tensor' object has no attribute '_lazy_read'
&lt;/denchmark-code&gt;

** Run the script using the following command
&lt;denchmark-code&gt;export CUDA_VISIBLE_DEVICES="0"
python3 center_loss_mnist.py
&lt;/denchmark-code&gt;

** Save the following script as "center_loss_mnist.py"
from datetime import datetime
from tensorflow.keras import backend as K
from tensorflow.keras import initializers
from tensorflow.keras import losses
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Layer
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.layers import PReLU
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
import math
import numpy as np
import os
import shutil
import tensorflow as tf

### parameters
batch_size = 64
epochs = 10
weight_decay = 0.0005

def init_gpus(soft_device_placement=True, log_device_placement=False, create_virtual_devices=False, memory_limit=4096):

    tf.config.set_soft_device_placement(soft_device_placement)    
    tf.debugging.set_log_device_placement(log_device_placement)

    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        # If there is only one GPU, create two logical virtual devices for developing
        # on a machine with only one GPU installed
        try:
            # Create 2 virtual GPUs on each physical GPU with the given memory_limit GPU memory
            if create_virtual_devices and len(gpus) == 1:
                tf.config.experimental.set_virtual_device_configuration(
                    gpus[0],
                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),
                     tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]
                )

            else:
                # Currently, memory growth needs to be the same across GPUs
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)

        except RuntimeError as e:
            # Memory growth must be set before GPUs have been initialized
            print(e)

        # print out physical and logical GPUs
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")

    else:
        print("No visible GPU is detected...")

def prelu(x, name='default'):
    if name == 'default':
        return PReLU(alpha_initializer=initializers.Constant(value=0.25))(x)
    else:
        return PReLU(alpha_initializer=initializers.Constant(value=0.25), name=name)(x)

def center_loss(y_true, y_pred):
    """Center loss based on the paper "A Discriminative Feature Learning Approach for Deep Face Recognition"
       (http://ydwen.github.io/papers/WenECCV16.pdf)
       Lc = 1/2 sum(|| xi - ci||)
    """
    return 0.5 * K.sum(y_pred, axis=0)

### model
def my_model(x, labels):
    # x = BatchNormalization()(x)
    #
    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=32, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    #
    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=64, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    #
    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', kernel_regularizer=l2(weight_decay))(x)
    x = BatchNormalization()(x)
    x = prelu(x)

    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)
    x = Dropout(0.25)(x)
    #
    x = Flatten()(x)
    x = Dense(2, kernel_regularizer=l2(weight_decay))(x)
    x = prelu(x, name='side_out')
    #
    main = Dense(10, activation='softmax', name='main_out', kernel_regularizer=l2(weight_decay))(x)
    side = CenterLossLayer(alpha=0.5, name='centerlosslayer')([x, labels])
    return main, side

# Function for decaying the learning rate.
# You can define any decay function you need.
def lr_schedule(epoch):
    if epoch &lt;= 5:
        learning_rate = 1e-3

    elif epoch &lt;= 10:
        learning_rate = 1e-4

    else:
        learning_rate = 1e-5

    tf.summary.scalar('learning_rate', data=learning_rate, step=epoch)
    return learning_rate

class CenterLossLayer(Layer):

    def __init__(self, alpha=0.5, **kwargs):
        super().__init__(**kwargs)
        self.alpha = alpha

    def build(self, input_shape):
        self.centers = self.add_weight(
            name='centers',
            shape=(10, 2),
            initializer='uniform',
            trainable=False
        )

        super().build(input_shape)

    def call(self, x):
        """This is where the layer's logic lives.
        Arguments:
            inputs: Input tensor, or list/tuple of input tensors.
            **kwargs: Additional keyword arguments.
        Returns:
            A tensor or list/tuple of tensors.
        """
        features = x[0]
        labels = K.reshape(x[1], [-1])

        # get the tensor as specified in the label
        # the centers might repeate depending on the label index
        centers_batch = K.gather(self.centers, labels)

        unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)
        appear_times = K.gather(unique_count, unique_idx)
        appear_times = K.reshape(appear_times, [-1, 1])
        #
        # center_loss_alfa default 0.5
        delta_centers = centers_batch - features
        delta_centers = delta_centers / tf.cast((1 + appear_times), tf.float32)
        delta_centers = self.alpha * delta_centers

        # scatter_sub does not support multi-gpu training, there is no equivalent operation 
        new_centers = tf.compat.v1.scatter_sub(self.centers, x[1], delta_centers)

        self.add_update((self.centers, new_centers), x)
        self.result = K.sum(K.square(features - centers_batch), axis=1, keepdims=True)
        return self.result

    def compute_output_shape(self, input_shape):
        return K.int_shape(self.result)

def empty_dir(folder):
    """
    Empty a folder recursively.
    """
    for file in os.listdir(folder):
        file_path = os.path.join(folder, file)
        if os.path.isfile(file_path):
            print("Remove file: {}".format(file_path))
            os.remove(file_path)
        else:
            empty_dir(file_path)
            print("Remove folder: {}".format(file_path))
            os.rmdir(file_path)

def build_empty_dir(folder, root_dir=os.getcwd()):
    base_dir = os.path.join(root_dir, folder)
    os.makedirs(base_dir, exist_ok=True)
    empty_dir(os.path.join(root_dir, folder))

    return base_dir

"""
unset CUDA_VISIBLE_DEVICES

export CUDA_VISIBLE_DEVICES="0"
python3 center_loss_mnist.py
"""

### run model
def run(lambda_centerloss):

    init_gpus(
        log_device_placement=False,
        create_virtual_devices=True
    )
    
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())
    strategy = tf.distribute.MirroredStrategy()
    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

    ### get data
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    # normalize to 0..1
    x_train, x_test = x_train/255, x_test/255
    x_train = np.float32(x_train);
    x_test  = np.float32(x_test)

    y_train = np.int32(y_train)
    y_test = np.int32(y_test)

    # reshape to matrix
    x_train = x_train.reshape((-1, 28, 28, 1))
    x_test = x_test.reshape((-1, 28, 28, 1))

    ### compile
    main_input = Input((28, 28, 1))
    aux_input = Input((), dtype='int32')

    # Training using Multi-GPUs
    # 
    # tf.compat.v1.scatter_sub does not support multi-gpus training
    # with strategy.scope():
    #
    # The following exception with be thrown.
    #
    # AttributeError: 'Tensor' object has no attribute '_lazy_read'

    # comment out the following line for the training to run successfully
    with strategy.scope():
        final_output, side_output = my_model(main_input, aux_input)
        model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])
        model.compile(
            optimizer='adam',
            loss=[losses.sparse_categorical_crossentropy, center_loss],
            metrics=['accuracy'],
            loss_weights=[1, lambda_centerloss]
        )
        model.summary()

    ### create the log directory
    log_dir = '/tmp/logs/' + datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')
    build_empty_dir(log_dir)

    # Initialize the file_writer for logging summary
    # create the file_writer to save events for Tensorboard
    summary_log_dir = log_dir + '/train'
    file_writer = tf.summary.create_file_writer(summary_log_dir)
    file_writer.set_as_default()    

    tb_callback = TensorBoard(log_dir=log_dir)

    # https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/LearningRateScheduler
    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)

    ### fit
    dummy1 = np.zeros((x_train.shape[0], 1), dtype=int)
    dummy2 = np.zeros((x_test.shape [0], 1), dtype=int)

    #
    print('model.input[0].shape = ', model.input[0].shape)
    print('model.get_layer(\'side_out\').output.shape = ', model.get_layer('side_out').output.shape)
    #
    model.fit(
        [x_train, y_train],     # inputs =[main_input, aux_input]
        [y_train, dummy1 ],     # outputs=[final_output, side_output]
        batch_size=batch_size,
        epochs=epochs,
        verbose=1,
        validation_data=([x_test, y_test], [y_test, dummy2]),
        callbacks=[tb_callback, lr_callback]
    )
    # validation
    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('main_out').output)
    reduced_model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer=tf.keras.optimizers.Adam(),
        metrics=['accuracy']
    )
    # evaluate
    eval_loss, eval_acc = reduced_model.evaluate(
        x=x_test,
        y=y_test,
        batch_size=batch_size
    )
    print('\nEval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))
    ### run training and val sets
    reduced_model = Model(inputs=model.input[0], outputs=model.get_layer('side_out').output)

    feats = reduced_model.predict(x_train)

    ### done
    K.clear_session()
    return

###
if __name__ == '__main__':
    run(0.0001)
	</description>
	<comments>
		<comment id='1' author='scotthong' date='2019-06-23T04:10:47Z'>
		The script will run successfully without using the "with stragety.scopt():" with the following changes:
Change from:
&lt;denchmark-code&gt;    with strategy.scope():
        final_output, side_output = my_model(main_input, aux_input)
        model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])
        model.compile(
            optimizer='adam',
            loss=[losses.sparse_categorical_crossentropy, center_loss],
            metrics=['accuracy'],
            loss_weights=[1, lambda_centerloss]
        )
        model.summary()
&lt;/denchmark-code&gt;

To:
&lt;denchmark-code&gt;    # with strategy.scope():
    final_output, side_output = my_model(main_input, aux_input)
    model = Model(inputs=[main_input, aux_input], outputs=[final_output, side_output])
    model.compile(
        optimizer='adam',
        loss=[losses.sparse_categorical_crossentropy, center_loss],
        metrics=['accuracy'],
        loss_weights=[1, lambda_centerloss]
    )
    model.summary()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='scotthong' date='2019-06-27T12:54:37Z'>
		I have reproduced the issue in Colab using TF-GPU 2.0.0-beta1.Thanks!
		</comment>
		<comment id='3' author='scotthong' date='2019-08-30T14:18:56Z'>
		FYI The same issue is present in tensorflow 1.14 as well. It comes from the usage of scatter_sub in multi-gpu MirroredStrategy.
While you guys fix the issue is there a workaround for this that we can use ?
Thanks
		</comment>
		<comment id='4' author='scotthong' date='2019-09-12T00:47:04Z'>
		Is there a chance to resolve this in final release of 1.15 ?
		</comment>
		<comment id='5' author='scotthong' date='2019-09-12T05:38:04Z'>
		This issue is still there, and will not be fixed in 1.15 since that has already been cut. One person had started working on it, but the fix got delayed due to some other issues.
You can try 2 workarounds:

if the tensors you're trying to subtract are not too big, you can try to convert them to dense and just subtract regularly using assign_sub etc. This may have some performance implications
You can implement this yourself using merge_call/reduce/update, something like this (this is exactly how we are going to implement this within mirrored variable as well)

&lt;denchmark-code&gt;def dist_scatter_sub(v, *args, **kwargs):
  def merge_fn(strategy, value, *other_args, **other_kwargs):
          agg_val = strategy.extended.reduce_to(distribute.ReduceOp.SUM, value, v)
          fn = lambda var, *a, **kw: var.scatter_sub(*a, **kw)
          return strategy.extended.update(
              v, f, args=(agg_val,) + other_args, kwargs=other_kwargs)

  return tf.distribute.get_replica_context().merge_call(merge_fn, args=args, kwargs=kwargs)

dist_scatter_sub(v, delta)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='scotthong' date='2020-04-17T18:31:23Z'>
		This issue should have been fixed in tf 2.2. You can just call the "scatter_*" method on the variable. tf.compat.v1.scatter_sub wouldn't work though.
		</comment>
		<comment id='7' author='scotthong' date='2020-04-17T18:31:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30056&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30056&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>