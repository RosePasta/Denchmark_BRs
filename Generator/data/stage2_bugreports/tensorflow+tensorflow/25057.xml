<bug id='25057' author='CatEek' open_date='2019-01-20T18:26:49Z' closed_time='2019-05-15T22:03:02Z'>
	<summary>tensorflow mirroredstrategy takes forever to start training</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.12
Python version: 3.6
CUDA/cuDNN version: 9.0/7.3
GPU model and memory: 1080ti


tf.Estimator using mirrored strategy takes forever to start training. Details are provided here &lt;denchmark-link:https://stackoverflow.com/questions/54125722/tensorflow-mirroredstrategy-takes-forever-to-initialize&gt;https://stackoverflow.com/questions/54125722/tensorflow-mirroredstrategy-takes-forever-to-initialize&lt;/denchmark-link&gt;

After asking the question I additionaly tried different versions of tf/cuda, no changes. Also I was finally able to see the start of the training, It took about 40 minutes!
Describe the expected behavior
The same model starts training in a couple of minutes without distribute strategy
When using much simpler model, like ResNet50 mirrored strategy also lags at startup compared to single GPU, but nevertheless training starts in a couple of minutes. What may be the problem with mirrored strategy?
	</description>
	<comments>
		<comment id='1' author='CatEek' date='2019-01-26T21:14:38Z'>
		A little update. I upgraded to 1.13 rc0, built from source. Simple model(e.g. ResNet) still working like a charm on a single GPU. With MirroredStrategy it still start training in only about 2-3 minutes, with a substantial lag(40-80 sec) on training step 0, but then it goes ok, GPU utilization around 90%.
But with a large model, mentioned in the link above, training gets consistently terminated because of protobuf limit of 2GB.
		</comment>
		<comment id='2' author='CatEek' date='2019-01-28T23:15:48Z'>
		How many GPUs are you using? If your current problem is because of protobuf limit, there is no short-term fix for now.
		</comment>
		<comment id='3' author='CatEek' date='2019-01-29T08:21:35Z'>
		&lt;denchmark-link:https://github.com/yuefengz&gt;@yuefengz&lt;/denchmark-link&gt;
 I'm trying to use 4. But even with 2 I'm encountering the same problem, though it takes less time. Do you mean that model from official tensorflow repo isn't compatible with estimator api, or MirrorredStrategy, or both?  Could you please point me in the right direction?
		</comment>
		<comment id='4' author='CatEek' date='2019-05-03T01:04:18Z'>
		The stackoverflow link does not work anymore. Can you please provide the details here again? Which model are you trying to run? You mentioned it is from official tensorflow repo?
		</comment>
		<comment id='5' author='CatEek' date='2019-05-03T05:41:17Z'>
		I used this model &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py&gt;https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_resnet_v2.py&lt;/denchmark-link&gt;

I've tried changing layer objects from contrib to Keras, or Layers API, and also used it as is.
run_config = tf.estimator.RunConfig(train_distribute=tf.distribute.MirroredStrategy(),                                                                                             save_checkpoints_steps=1000,
keep_checkpoint_max=5
)
model = tf.estimator.Estimator(model_fn=model_fn,
config=run_config,
Without tf.distribute.MirroredStrategy() it runs normal, otherwise it just hangs before training starts. It doesn't throw any errors. I've tried using single batch, so data size isn't an issue. Please let me know if you need any additional information
		</comment>
		<comment id='6' author='CatEek' date='2019-05-03T06:22:39Z'>
		Can you show me your model_fn for the estimator? We recently ran into a similar issue because there was an unnecessary control dependency in the model_fn which was causing the graph to blow up. I am wondering if that is the same case in your model_fn.
		</comment>
		<comment id='7' author='CatEek' date='2019-05-05T03:33:13Z'>
		I've removed some non-relevant lines
&lt;denchmark-code&gt;def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):
  """Builds the 35x35 resnet block."""
  with tf.variable_scope(scope, 'Block35', [net], reuse=reuse):
    with tf.variable_scope('Branch_0'):
      tower_conv = tf.contrib.layers.conv2d(net, 32, 1, scope='Conv2d_1x1')
    with tf.variable_scope('Branch_1'):
      tower_conv1_0 = tf.contrib.layers.conv2d(net, 32, 1, scope='Conv2d_0a_1x1')
      tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1_0, 32, 3, scope='Conv2d_0b_3x3')
    with tf.variable_scope('Branch_2'):
      tower_conv2_0 = tf.contrib.layers.conv2d(net, 32, 1, scope='Conv2d_0a_1x1')
      tower_conv2_1 = tf.contrib.layers.conv2d(tower_conv2_0, 48, 3, scope='Conv2d_0b_3x3')
      tower_conv2_2 = tf.contrib.layers.conv2d(tower_conv2_1, 64, 3, scope='Conv2d_0c_3x3')
    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_1, tower_conv2_2])
    up = tf.contrib.layers.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None, activation_fn=None, scope='Conv2d_1x1')
    net += scale * up
    if activation_fn:
      net = activation_fn(net)
  return net


def block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):
  """Builds the 17x17 resnet block."""
  with tf.variable_scope(scope, 'Block17', [net], reuse=reuse):
    with tf.variable_scope('Branch_0'):
      tower_conv = tf.contrib.layers.conv2d(net, 192, 1, scope='Conv2d_1x1')
    with tf.variable_scope('Branch_1'):
      tower_conv1_0 = tf.contrib.layers.conv2d(net, 128, 1, scope='Conv2d_0a_1x1')
      tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1_0, 160, [1, 7], scope='Conv2d_0b_1x7')
      tower_conv1_2 = tf.contrib.layers.conv2d(tower_conv1_1, 192, [7, 1], scope='Conv2d_0c_7x1')
    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])
    up = tf.contrib.layers.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None, activation_fn=None, scope='Conv2d_1x1')
    net += scale * up
    if activation_fn:
      net = activation_fn(net)
  return net


def block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):
  """Builds the 8x8 resnet block."""
  with tf.variable_scope(scope, 'Block8', [net], reuse=reuse):
    with tf.variable_scope('Branch_0'):
      tower_conv = tf.contrib.layers.conv2d(net, 192, 1, scope='Conv2d_1x1')
    with tf.variable_scope('Branch_1'):
      tower_conv1_0 = tf.contrib.layers.conv2d(net, 192, 1, scope='Conv2d_0a_1x1')
      tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1_0, 224, [1, 3], scope='Conv2d_0b_1x3')
      tower_conv1_2 = tf.contrib.layers.conv2d(tower_conv1_1, 256, [3, 1], scope='Conv2d_0c_3x1')
    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])
    up = tf.contrib.layers.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None, activation_fn=None, scope='Conv2d_1x1')
    net += scale * up
    if activation_fn:
      net = activation_fn(net)
  return net


def inception_resnet_v2(inputs, is_training=True, dropout_keep_prob=0.8, reuse=None, scope='InceptionResnetV2'):
  """Creates the Inception Resnet V2 model.
  Args:
    inputs: a 4-D tensor of size [batch_size, height, width, 3].
    num_classes: number of predicted classes.
    is_training: whether is training or not.
    dropout_keep_prob: float, the fraction to keep before final layer.
    reuse: whether or not the network and its variables should be reused. To be
      able to reuse 'scope' must be given.
    scope: Optional variable_scope.
  Returns:
    logits: the logits outputs of the model.
    end_points: the set of end_points from the inception model.
  """

  with tf.variable_scope(scope, 'InceptionResnetV2', [inputs], reuse=reuse):
    with tf.contrib.framework.arg_scope([tf.contrib.layers.dropout], is_training=is_training):
      with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d]):
        # 149 x 149 x 32
        net = tf.contrib.layers.conv2d(inputs, 32, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
        # 147 x 147 x 32
        net = tf.contrib.layers.conv2d(net, 32, 3, padding='VALID', scope='Conv2d_2a_3x3')
        # 147 x 147 x 64
        net = tf.contrib.layers.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')
        # 73 x 73 x 64
        net = tf.contrib.layers.max_pool2d(net, 3, stride=2, padding='VALID', scope='MaxPool_3a_3x3')
        # 73 x 73 x 80
        net = tf.contrib.layers.conv2d(net, 80, 1, padding='VALID', scope='Conv2d_3b_1x1')
        # 71 x 71 x 192
        net = tf.contrib.layers.conv2d(net, 192, 3, padding='VALID', scope='Conv2d_4a_3x3')
        # 35 x 35 x 192
        net = tf.contrib.layers.max_pool2d(net, 3, stride=2, padding='VALID', scope='MaxPool_5a_3x3')

        # 35 x 35 x 320
        with tf.variable_scope('Mixed_5b'):
          with tf.variable_scope('Branch_0'):
            tower_conv = tf.contrib.layers.conv2d(net, 96, 1, scope='Conv2d_1x1')
          with tf.variable_scope('Branch_1'):
            tower_conv1_0 = tf.contrib.layers.conv2d(net, 48, 1, scope='Conv2d_0a_1x1')
            tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1_0, 64, 5, scope='Conv2d_0b_5x5')
          with tf.variable_scope('Branch_2'):
            tower_conv2_0 = tf.contrib.layers.conv2d(net, 64, 1, scope='Conv2d_0a_1x1')
            tower_conv2_1 = tf.contrib.layers.conv2d(tower_conv2_0, 96, 3, scope='Conv2d_0b_3x3')
            tower_conv2_2 = tf.contrib.layers.conv2d(tower_conv2_1, 96, 3, scope='Conv2d_0c_3x3')
          with tf.variable_scope('Branch_3'):
            tower_pool = tf.contrib.layers.avg_pool2d(net, 3, stride=1, padding='SAME', scope='AvgPool_0a_3x3')
            tower_pool_1 = tf.contrib.layers.conv2d(tower_pool, 64, 1, scope='Conv2d_0b_1x1')
          net = tf.concat(axis=3, values=[tower_conv, tower_conv1_1, tower_conv2_2, tower_pool_1])

        net = slim.repeat(net, 10, block35, scale=0.17, activation_fn=activation_fn)


        # 17 x 17 x 1024
        with tf.variable_scope('Mixed_6a'):
          with tf.variable_scope('Branch_0'):
            tower_conv = tf.contrib.layers.conv2d(net, 384, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
          with tf.variable_scope('Branch_1'):
            tower_conv1_0 = tf.contrib.layers.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')
            tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1_0, 256, 3, scope='Conv2d_0b_3x3')
            tower_conv1_2 = tf.contrib.layers.conv2d(tower_conv1_1, 384, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
          with tf.variable_scope('Branch_2'):
            tower_pool = tf.contrib.layers.max_pool2d(net, 3, stride=2, padding='VALID', scope='MaxPool_1a_3x3')
          net = tf.concat(axis=3, values=[tower_conv, tower_conv1_2, tower_pool])

        net = slim.repeat(net, 20, block17, scale=0.10, activation_fn=activation_fn)


        with tf.variable_scope('Mixed_7a'):
          with tf.variable_scope('Branch_0'):
            tower_conv = tf.contrib.layers.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')
            tower_conv_1 = tf.contrib.layers.conv2d(tower_conv, 384, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
          with tf.variable_scope('Branch_1'):
            tower_conv1 = tf.contrib.layers.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')
            tower_conv1_1 = tf.contrib.layers.conv2d(tower_conv1, 288, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
          with tf.variable_scope('Branch_2'):
            tower_conv2 = tf.contrib.layers.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')
            tower_conv2_1 = tf.contrib.layers.conv2d(tower_conv2, 288, 3, scope='Conv2d_0b_3x3')
            tower_conv2_2 = tf.contrib.layers.conv2d(tower_conv2_1, 320, 3, stride=2, padding='VALID', scope='Conv2d_1a_3x3')
          with tf.variable_scope('Branch_3'):
            tower_pool = tf.contrib.layers.max_pool2d(net, 3, stride=2, padding='VALID', scope='MaxPool_1a_3x3')
          net = tf.concat(axis=3, values=[tower_conv_1, tower_conv1_1, tower_conv2_2, tower_pool])

        net = tf.contrib.layers.repeat(net, 9, block8, scale=0.20)
        net = block8(net, activation_fn=None)
        print(net.shape)

        net = tf.contrib.layers.conv2d(net, 1536, 1, scope='Conv2d_7b_1x1')
        print(net.shape)
        #net = tf.contrib.layers.conv2d(net, 1536, 1, scope='Conv2d_7b_1x1')
        net = tf.contrib.layers.avg_pool2d(net, net.get_shape()[1:3], padding='VALID')
        net = tf.layers.flatten(net)
        net = tf.contrib.layers.dropout(net, dropout_keep_prob, is_training=is_training)

        logits = tf.layers.dense(inputs=net, units=28, name='out')
        predictions = {
          'classes': tf.argmax(input=logits, axis=1),
          'probabilities': tf.nn.softmax(logits, name='softmax_tensor')
        }
        
        predictions = {
          'classes': tf.cast(tf.greater(tf.sigmoid(logits), 0.3), tf.int64),
          'probabilities': tf.sigmoid(logits, name='sigm_tensor'),
        }
        
  return logits, predictions


def inception_resnet_v2_arg_scope(weight_decay=0.000005,
                                  batch_norm_decay=0.9997,
                                  batch_norm_epsilon=0.001):
  """Yields the scope with the default parameters for inception_resnet_v2.
  Args:
    weight_decay: the weight decay for weights variables.
    batch_norm_decay: decay for the moving average of batch_norm momentums.
    batch_norm_epsilon: small float added to variance to avoid dividing by zero.
  Returns:
    a arg_scope with the parameters needed for inception_resnet_v2.
  """
  # Set weight_decay for weights in conv2d and fully_connected layers.
  with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d],
                                      weights_regularizer=tf.contrib.layers.l2_regularizer(weight_decay),
                                      biases_regularizer=tf.contrib.layers.l2_regularizer(weight_decay)):

    batch_norm_params = {'decay': batch_norm_decay, 'epsilon': batch_norm_epsilon}
    # Set activation_fn and parameters for batch_norm.
    with tf.contrib.framework.arg_scope([tf.contrib.layers.conv2d],
                                        activation_fn=tf.nn.relu,
                                        normalizer_fn=None,
                                        normalizer_params=batch_norm_params) as scope:
      return scope

def model_fn(features, labels, mode):
  
  if_train = (mode == tf.estimator.ModeKeys.TRAIN)
  input_layer = tf.cast(tf.reshape(features, [-1, 299, 299, 3]), tf.float32)

  with tf.variable_scope('InceptionResnetV2'):
    logits = irnv2(input_layer)

  predictions = tf.argmax(input=logits, axis=1)
  probabilities = tf.nn.softmax(logits, name='softmax')

  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
    
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.GradientDescentOptimizer(0.01)
    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
      train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
    
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

  return tf.estimator.EstimatorSpec(mode=mode, loss=loss)


session_config = tf.ConfigProto(allow_soft_placement=True)
distr = tf.distribute.MirroredStrategy()
run_config = tf.estimator.RunConfig(train_distribute=distr,
                                    save_checkpoints_steps=1000,
                                    keep_checkpoint_max=5
                                    )


irn = tf.estimator.Estimator(model_fn=model_fn,
                             config=run_config,
                             model_dir,
                             )

irn.train(input_fn=tr_input_fn)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='CatEek' date='2019-05-06T04:11:49Z'>
		Thanks. Can you try changing these couple lines in the model_fn:
original:
&lt;denchmark-code&gt;with tf.control_dependencies(update_ops):
      train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
&lt;/denchmark-code&gt;

suggestion:
&lt;denchmark-code&gt;minimize_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
train_op = tf.group(minimize_op, updates_op)
&lt;/denchmark-code&gt;

This has been a pattern recommended by TF docs but we are trying to change it as it is not needed, and can cause unnecessary control dependencies.
		</comment>
		<comment id='9' author='CatEek' date='2019-05-14T12:39:01Z'>
		&lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
, Thank you for your help!  I'm sorry for delayed response, I was away. I changed

to

and it worked! However. it still takes about 3 minutes, according to tf logging, for training to start. Is it expected behavior?
		</comment>
		<comment id='10' author='CatEek' date='2019-05-15T22:03:02Z'>
		That's great. I think 3 mins is in the expected range. Will close this ticket. thanks
		</comment>
		<comment id='11' author='CatEek' date='2019-05-15T22:03:03Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=25057&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=25057&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>