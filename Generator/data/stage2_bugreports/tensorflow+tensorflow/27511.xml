<bug id='27511' author='bguillouet' open_date='2019-04-04T15:07:54Z' closed_time='2019-04-19T16:40:32Z'>
	<summary>[TF==2.0.0-alpha0] Memory leak with tf.keras.models.load_model</summary>
	<description>
System information

Have I written custom code? Yes
OS Platform and Distribution  (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.3
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Docker_image tensorflow/tensorflow:2.0.0a0-py3-jupyter
TensorFlow version : 2.0.0a0-py3-jupyter
Python version:  3.5
Using only CPU

Describe the current behavior
I have a memory leak when I load several keras model with load_model function previously save with model.save.
Here is what I obtain when i load 20 times a model (the same model for the example).
The output is obtain with the memory profiler library. https://pypi.org/project/memory-profiler/ (see code below)
First Iteration:
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    14    229.5 MiB    229.5 MiB   @profile
    15                             def load_model_keras(model_dir):
    16    232.5 MiB      2.9 MiB       K.clear_session()
    17    252.9 MiB     20.4 MiB       model = load_model(model_dir)
    18    252.9 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

After 20 iterations:
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    14    539.9 MiB    539.9 MiB   @profile
    15                             def load_model_keras(model_dir):
    16    539.9 MiB      0.0 MiB       K.clear_session()
    17    566.4 MiB     26.5 MiB       model = load_model(model_dir)
    18    566.4 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

Describe the expected behavior
I do not have this problem with tensorflow==1.13.1
Here is what I obtain with this version and the behavior I expect to have.
First Iterations :
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    14    210.7 MiB    210.7 MiB   @profile
    15                             def load_model_keras(model_dir):
    16    214.2 MiB      3.4 MiB       K.clear_session()
    17    239.8 MiB     25.6 MiB       model = load_model(model_dir)
    18    239.8 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

After 20 iteration :
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    14    257.9 MiB    257.9 MiB   @profile
    15                             def load_model_keras(model_dir):
    16    257.9 MiB      0.0 MiB       K.clear_session()
    17    259.0 MiB      1.1 MiB       model = load_model(model_dir)
    18    259.0 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

Code to reproduce the issue
&lt;denchmark-code&gt;import os
import tensorflow as tf
from tensorflow.keras.models import load_model
import tensorflow.keras.backend as K
from memory_profiler import profile
model_dir = "MODEL_PATH.h5"

@profile
def load_model_keras(model_dir):
    K.clear_session()
    model = load_model(model_dir)
    return model

for i in range(100):
    print(i)
    load_model_keras(model_dir)

&lt;/denchmark-code&gt;

Other info / logs
I also tried to put within the function :

model=None
del model
gc.collect() (import gc)

with no effect
	</description>
	<comments>
		<comment id='1' author='bguillouet' date='2019-04-05T10:11:29Z'>
		&lt;denchmark-link:https://github.com/bguillouet&gt;@bguillouet&lt;/denchmark-link&gt;
 Can you please provide the colab python link so that we can reproduce the bug as .h5 is not available currently here
		</comment>
		<comment id='2' author='bguillouet' date='2019-04-05T11:14:21Z'>
		Hi,
You can reproduce the bug with any ".h5" model.
Here is an example with a Resnet50 model from keras. Here is the code on colab &lt;denchmark-link:https://colab.research.google.com/drive/1Uafi1hSqaHaEXpYyi8LFVXdK2gTQQVEs&gt;https://colab.research.google.com/drive/1Uafi1hSqaHaEXpYyi8LFVXdK2gTQQVEs&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import os
wd = os.getcwd()

import tensorflow as tf
print(tf.__version__)
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import ResNet50
import tensorflow.keras.backend as K
from memory_profiler import profile

model = ResNet50(weights='imagenet')
model_dir = wd+"/model.h5"
model.save(model_dir)


@profile
def load_model_keras(model_dir):
    K.clear_session()
    model = load_model(model_dir)
    return model

for i in range(20):
    print(i)
    load_model_keras(model_dir)
&lt;/denchmark-code&gt;

I didn't get the memory_profiler output on colab but here are the output on my laptop.
tensorflow 1.13.1
First iteration
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    22    480.1 MiB    480.1 MiB   @profile
    23                             def load_model_keras(model_dir):
    24    399.8 MiB      0.0 MiB       K.clear_session()
    25    750.4 MiB    350.6 MiB       model = load_model(model_dir)
    26    750.4 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

20 iterations
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    22    830.9 MiB    830.9 MiB   @profile
    23                             def load_model_keras(model_dir):
    24    830.9 MiB      0.0 MiB       K.clear_session()
    25    840.1 MiB      9.2 MiB       model = load_model(model_dir)
    26    840.1 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

tensorflow 2.0.0-aplha
First iteration
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    22    535.1 MiB    535.1 MiB   @profile
    23                             def load_model_keras(model_dir):
    24    535.1 MiB      0.1 MiB       K.clear_session()
    25    684.0 MiB    148.9 MiB       model = load_model(model_dir)
    26    684.0 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

20 iterations
&lt;denchmark-code&gt;Line #    Mem usage    Increment   Line Contents
================================================
    22   3350.5 MiB   3350.5 MiB   @profile
    23                             def load_model_keras(model_dir):
    24   3350.5 MiB      0.0 MiB       K.clear_session()
    25   3502.3 MiB    151.7 MiB       model = load_model(model_dir)
    26   3502.3 MiB      0.0 MiB       return model
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='bguillouet' date='2019-04-18T18:05:30Z'>
		Thanks for reporting this. I believe the issue is with K.clear_session(), which clears the default graph. In 1.x, Keras uses the default tf graph, but in 2.0 Keras manages its own graph. So the clear session call isn't actually clearing the keras graph and models are accumulating there and preventing memory from being freed. It should be a simple fix to make clear_session clears the right graph in 2.0.
		</comment>
		<comment id='4' author='bguillouet' date='2019-04-19T16:40:32Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/5956c7e9c44e23cd1a006df872ae468201fdb600#diff-e329ed6b8d30dca9a441689005047035&gt;5956c7e#diff-e329ed6b8d30dca9a441689005047035&lt;/denchmark-link&gt;
 should fix the issue. I tested on the latest  and observed that memory is no longer increasing.
This also means that our keras tests for 2.0 haven't been properly independent, since 


tensorflow/tensorflow/python/keras/keras_parameterized.py


         Line 39
      in
      2fe0e52






 keras.backend.clear_session() 




 wasn't actually clearing the graph in 2.0. So we might also pick up some testing robustness for free as well. All in all, this has been a tremendously useful bug report. Thanks so much!
		</comment>
		<comment id='5' author='bguillouet' date='2019-04-19T16:40:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=27511&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=27511&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='bguillouet' date='2019-11-01T17:51:16Z'>
		I have TensorFlow version 2.0.0 and Keras 2.3.1, but still having the same problem.
		</comment>
	</comments>
</bug>