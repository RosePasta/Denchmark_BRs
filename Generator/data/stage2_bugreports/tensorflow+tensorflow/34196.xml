<bug id='34196' author='shkarupa-alex' open_date='2019-11-12T10:57:16Z' closed_time='2020-08-25T21:31:24Z'>
	<summary>Keras fails to combine predicted variable-sized sequences</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.12.1-17764-gae26958 2.1.0-dev20191111
Python version: Google Colab py3
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): No
CUDA/cuDNN version: Google Colab
GPU model and memory: Google Colab

Describe the current behavior
Exception raised (from numpy concatenate) when predicting sequence labels with variable sequence length batches.
Describe the expected behavior
There should be no error, as in fit/evaluate methods work fine.

&lt;denchmark-link:https://colab.research.google.com/drive/1IPIkj5PlUWKCpuTm9NWM5BLO_suL5VI3&gt;https://colab.research.google.com/drive/1IPIkj5PlUWKCpuTm9NWM5BLO_suL5VI3&lt;/denchmark-link&gt;

Other info / logs
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-23-e5e9890a3d75&gt; in &lt;module&gt;()
----&gt; 1 model.predict(get_dataset(labels=False))

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
    972         max_queue_size=max_queue_size,
    973         workers=workers,
--&gt; 974         use_multiprocessing=use_multiprocessing)
    975 
    976   def reset_metrics(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
    497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
--&gt; 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
    499 
    500 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
    473               mode=mode,
    474               training_context=training_context,
--&gt; 475               total_epochs=1)
    476           cbks.make_logs(model, epoch_logs, result, mode)
    477 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    185 
    186   # End of an epoch.
--&gt; 187   aggregator.finalize()
    188   return aggregator.results
    189 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in finalize(self)
    349   def finalize(self):
    350     for result in self.results:
--&gt; 351       result.finalize()
    352     self.results = [i.results for i in self.results]
    353     self.results = nest.pack_sequence_as(self._structure, self.results)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in finalize(self)
    187 
    188     else:
--&gt; 189       self.results = np.concatenate(self.results, axis=0)
    190 
    191     if isinstance(self.results, ops.EagerTensor):

&lt;__array_function__ internals&gt; in concatenate(*args, **kwargs)

ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 7 and the array at index 1 has size 9
	</description>
	<comments>
		<comment id='1' author='shkarupa-alex' date='2019-11-13T08:34:31Z'>
		I have tried on colab with TF version 2.0 ,2.1.0-dev20191111 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/19ccefa635122accffea177617bfc459/untitled358.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='shkarupa-alex' date='2020-05-07T09:42:48Z'>
		Issue still here with tf-nightly, but exception stack changed
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-16-e5e9890a3d75&gt; in &lt;module&gt;()
----&gt; 1 model.predict(get_dataset(labels=False))

11 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     92       raise ValueError('{} is not supported in multi-worker mode.'.format(
     93           method.__name__))
---&gt; 94     return method(self, *args, **kwargs)
     95 
     96   return tf_decorator.make_decorator(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1394             callbacks.on_predict_batch_end(end_step, {'outputs': batch_outputs})
   1395       callbacks.on_predict_end()
-&gt; 1396     all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
   1397     return tf_utils.to_numpy_or_python_type(all_outputs)
   1398 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure_up_to(shallow_tree, func, *inputs, **kwargs)
   1129       lambda _, *values: func(*values),  # Discards the path arg.
   1130       *inputs,
-&gt; 1131       **kwargs)
   1132 
   1133 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in map_structure_with_tuple_paths_up_to(shallow_tree, func, *inputs, **kwargs)
   1225                     in _yield_flat_up_to(shallow_tree, inputs[0], is_seq)]
   1226   results = [func(*args, **kwargs) for args in zip(flat_path_list,
-&gt; 1227                                                    *flat_value_lists)]
   1228   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,
   1229                           expand_composites=expand_composites)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in &lt;listcomp&gt;(.0)
   1224   flat_path_list = [path for path, _
   1225                     in _yield_flat_up_to(shallow_tree, inputs[0], is_seq)]
-&gt; 1226   results = [func(*args, **kwargs) for args in zip(flat_path_list,
   1227                                                    *flat_value_lists)]
   1228   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in &lt;lambda&gt;(_, *values)
   1127   return map_structure_with_tuple_paths_up_to(
   1128       shallow_tree,
-&gt; 1129       lambda _, *values: func(*values),  # Discards the path arg.
   1130       *inputs,
   1131       **kwargs)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in concat(tensors, axis)
   1882   if isinstance(tensors[0], ragged_tensor.RaggedTensor):
   1883     return ragged_concat_ops.concat(tensors, axis=axis)
-&gt; 1884   return array_ops.concat(tensors, axis=axis)
   1885 
   1886 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    178     """Call target, and fall back on dispatchers if there is a TypeError."""
    179     try:
--&gt; 180       return target(*args, **kwargs)
    181     except (TypeError, ValueError):
    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py in concat(values, axis, name)
   1628           dtype=dtypes.int32).get_shape().assert_has_rank(0)
   1629       return identity(values[0], name=name)
-&gt; 1630   return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
   1631 
   1632 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in concat_v2(values, axis, name)
   1196       return _result
   1197     except _core._NotOkStatusException as e:
-&gt; 1198       _ops.raise_from_not_ok_status(e, name)
   1199     except _core._FallbackException:
   1200       pass

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6810   message = e.message + (" name: " + name if name is not None else "")
   6811   # pylint: disable=protected-access
-&gt; 6812   six.raise_from(core._status_to_exception(e.code, message), None)
   6813   # pylint: enable=protected-access
   6814 

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [5,6,1] vs. shape[2] = [5,10,1] [Op:ConcatV2] name: concat
		</comment>
		<comment id='3' author='shkarupa-alex' date='2020-06-17T20:20:18Z'>
		&lt;denchmark-link:https://github.com/shkarupa-alex&gt;@shkarupa-alex&lt;/denchmark-link&gt;
,
Seems like the error has been fixed in stable version of TF v2.2. I was able to run the code without any issues with TF v2.2, please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a07d17dcda435b1b3dcb48730a27e8fa/34196-2-2.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='shkarupa-alex' date='2020-06-18T12:46:24Z'>
		
@shkarupa-alex,
Seems like the error has been fixed in stable version of TF v2.2. I was able to run the code without any issues with TF v2.2, please find the gist of it here. Thanks!

Nope.
Issue is still present in tf-nightly (see link to colab in issue head).
		</comment>
		<comment id='5' author='shkarupa-alex' date='2020-07-29T09:27:09Z'>
		I have tried in colab with TF version 2.3, nightly version() and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/f4fb7a0cbee6adca8d6525eb9eb434cd/untitled195.ipynb#scrollTo=b70Y0hpr4d6I&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='6' author='shkarupa-alex' date='2020-08-25T21:31:24Z'>
		&lt;denchmark-link:https://github.com/shkarupa-alex&gt;@shkarupa-alex&lt;/denchmark-link&gt;
 Thanks for the issue! In order to combine Tensors of different shapes, your Model will need to output RaggedTensors. You can do this by adding a Layer at the end of your Model to convert each Tensor to a RaggedTensor. The Dense layer currently at the end of the Model is outputting regular Tensors, and to concat these for , only the 0-axis can have different shapes
		</comment>
		<comment id='7' author='shkarupa-alex' date='2020-08-25T21:31:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34196&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34196&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>