<bug id='26174' author='reuben' open_date='2019-02-27T14:58:12Z' closed_time='2019-09-16T15:39:18Z'>
	<summary>TFLite Mfcc op has inconsistent requirements with standard Mfcc op</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, here's the code to reproduce: https://gist.github.com/reuben/57bee91669a5bd2717c32cf406ca951d
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.13.0-rc2-5-g6612da8951 1.13.1
Python version: 3.6.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: curl https://gist.githubusercontent.com/reuben/57bee91669a5bd2717c32cf406ca951d/raw/6b81d28d00ff3ec73ab1bcc6a698366bbe3dcb51/test_tflite_mfcc.py | python

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

The Mfcc op in tensorflow.contrib.framework.python.ops.audio_ops (a.k.a. contrib_audio) enforces the shape of the sample rate parameter to be rank 0. The TFLite Mfcc op enforces the sample rate parameter to be rank 1. Converting a model with an Mfcc op in it results in a TFLite model that fails in the preparation step.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

If you try to pass a sample rate of rank 1 to the contrib_audio op:
&lt;denchmark-code&gt;python3 test_tflite.py
2019-02-27 11:50:41.627337: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1659, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 0 but is rank 1 for 'Mfcc' (op: 'Mfcc') with input shapes: [1,1,257], [1].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test_tflite.py", line 13, in &lt;module&gt;
    mfccs = contrib_audio.mfcc(spectrogram, [16000], dct_coefficient_count=13)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/ops/gen_audio_ops.py", line 454, in mfcc
    dct_coefficient_count=dct_coefficient_count, name=name)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 788, in _apply_op_helper
    op_def=op_def)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3300, in create_op
    op_def=op_def)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1823, in __init__
    control_input_ops)
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1662, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 0 but is rank 1 for 'Mfcc' (op: 'Mfcc') with input shapes: [1,1,257], [1].
&lt;/denchmark-code&gt;

If you pass a sample rate of rank 0, and then try to convert and use the TFLite model:
&lt;denchmark-code&gt;python3 test_tflite.py
2019-02-27 11:50:27.082848: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
session run works
toco_from_protos /var/folders/k1/7sbxsmm52n59_fpj0v65fmk40000gn/T/tmp_vtx0s5o /var/folders/k1/7sbxsmm52n59_fpj0v65fmk40000gn/T/tmp7v9bbo3t /var/folders/k1/7sbxsmm52n59_fpj0v65fmk40000gn/T/tmpilazyufw /var/folders/k1/7sbxsmm52n59_fpj0v65fmk40000gn/T/tmp9e1513n8
Traceback (most recent call last):
  File "test_tflite.py", line 30, in &lt;module&gt;
    interpreter.allocate_tensors()
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py", line 73, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File "/Users/rmorais/.local/share/virtualenvs/DeepSpeech-HmF6CP0D/lib/python3.6/site-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py", line 106, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/mfcc.cc:75 NumDimensions(inputRate) != 1 (0 != 1)Node number 2 (Mfcc) failed to prepare.
&lt;/denchmark-code&gt;

And here's the source of the testing script just in case:
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
import sys
import tempfile

from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio


with tf.Session() as sess:
    input_ph = tf.placeholder(tf.float32, [512])
    samples = tf.reshape(input_ph, [512, 1])
    spectrogram = contrib_audio.audio_spectrogram(samples, window_size=512, stride=320, magnitude_squared=True)
    mfccs = contrib_audio.mfcc(spectrogram, 16000, dct_coefficient_count=13)

    sess.run([mfccs], feed_dict={input_ph: np.random.random([512])})
    print('session run works')

    converter = tf.lite.TFLiteConverter(sess.graph_def, input_tensors=[input_ph], output_tensors=[mfccs])
    converter.allow_custom_ops = True
    tflite_model = converter.convert()

with tempfile.NamedTemporaryFile(delete=False) as fout:
    temp_name = fout.name
    fout.write(tflite_model)
    fout.flush()

try:
    # Load TFLite model and allocate tensors.
    interpreter = tf.lite.Interpreter(model_path=temp_name)
    interpreter.allocate_tensors()
    print('tflite model prepare works')

    # Get input and output tensors.
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Test model on random input data.
    for inp in input_details:
        input_data = np.array(np.random.random_sample(inp['shape']), dtype=np.float32)
        interpreter.set_tensor(inp['index'], input_data)

    interpreter.invoke()
    output_data = interpreter.get_tensor(output_details[0]['index'])
    print(output_data)
finally:
    try:
        os.remove(temp_name)
    except:
        pass
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='reuben' date='2019-02-27T16:51:46Z'>
		&lt;denchmark-link:https://github.com/andrewharp&gt;@andrewharp&lt;/denchmark-link&gt;
 pinging since you wrote the TFLite Mfcc op. Is there another way of converting the op to TFLite that I'm missing? As far as I can tell, because of the different behavior w.r.t. the sample rate parameter, there's no way to convert a TF graph to a TFLite model with an Mfcc op in it.
		</comment>
		<comment id='2' author='reuben' date='2019-02-28T19:03:18Z'>
		FWIW, I've changed the test here to check if there's 0 dimensions instead of 1 and things have been working fine: 


tensorflow/tensorflow/lite/kernels/mfcc.cc


         Line 75
      in
      e6d0741






 TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1); 





diff --git a/tensorflow/lite/kernels/mfcc.cc b/tensorflow/lite/kernels/mfcc.cc
index f5b0212728..ff4a6d2e2c 100644
--- a/tensorflow/lite/kernels/mfcc.cc
+++ b/tensorflow/lite/kernels/mfcc.cc
@@ -72,7 +72,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

   TF_LITE_ENSURE_EQ(context, NumDimensions(inputWav), 3);
-  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1);
+  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 0);

   TF_LITE_ENSURE_EQ(context, output-&gt;type, kTfLiteFloat32);
   TF_LITE_ENSURE_EQ(context, inputWav-&gt;type, output-&gt;type);
		</comment>
		<comment id='3' author='reuben' date='2019-03-15T04:04:30Z'>
		
FWIW, I've changed the test here to check if there's 0 dimensions instead of 1 and things have been working fine:
tensorflow/tensorflow/lite/kernels/mfcc.cc
Line 75 in e6d0741
TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1);
diff --git a/tensorflow/lite/kernels/mfcc.cc b/tensorflow/lite/kernels/mfcc.cc
index f5b0212728..ff4a6d2e2c 100644
--- a/tensorflow/lite/kernels/mfcc.cc
+++ b/tensorflow/lite/kernels/mfcc.cc
@@ -72,7 +72,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

   TF_LITE_ENSURE_EQ(context, NumDimensions(inputWav), 3);
-  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1);
+  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 0);

   TF_LITE_ENSURE_EQ(context, output-&gt;type, kTfLiteFloat32);
   TF_LITE_ENSURE_EQ(context, inputWav-&gt;type, output-&gt;type);

When the code can be merged to the master branch?
		</comment>
		<comment id='4' author='reuben' date='2019-05-29T11:44:03Z'>
		&lt;denchmark-link:https://github.com/rryan&gt;@rryan&lt;/denchmark-link&gt;
 ping. Can you let me know if this patch makes sense? I'll can make a PR.
		</comment>
		<comment id='5' author='reuben' date='2019-05-30T01:18:23Z'>
		We tried to convert the model to tflite (from the speech recognition sample) with this script:
&lt;denchmark-link:https://github.com/aselle/tensorflow/blob/7e71aa528111cd73cabc9fefdbb68422e35c16ce/tensorflow/examples/speech_commands/conv_only.py&gt;https://github.com/aselle/tensorflow/blob/7e71aa528111cd73cabc9fefdbb68422e35c16ce/tensorflow/examples/speech_commands/conv_only.py&lt;/denchmark-link&gt;

By the way, it would be nice to have the python code of the converter used for the android tflite version!)
It works perfectly for audio sample of 1 second but it fails for 2 seconds with the same kind of error as the initial post:
NumDimensions(inputRate) != 1 ( 0 != 1)Node number 1 (Mfcc) failed to prepare.
Is this fix the solution?
(we've changed the shape of the input from 16000,1 to 32000,1 and 32000,2 but we get the error above)
		</comment>
		<comment id='6' author='reuben' date='2019-06-07T15:55:36Z'>
		&lt;denchmark-link:https://github.com/reuben&gt;@reuben&lt;/denchmark-link&gt;
, I can confirm your patch fixed the issue. I was able to rebuild and convert  to TFLite! I am still looking into how to correctly use  input. Currently, it is hard-coded in the  call. I suppose we can declare it as a placeholder and feed it to sess.run() but I haven't had success with that while converting it to TFLite yet. Will be glad to hear if you have tried anything there.
I am also curious to see where is tensorflow headed with MFCCs. There's some discussion on this thread &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/11339#issuecomment-345741527&gt;#11339 (comment)&lt;/denchmark-link&gt;
 about retiring  and making  compatible to convert to TFLite. Nevertheless, this patch definitely seems worth merging. Or it will be nice if someone can shed some light on why is the expected dimensions of   so we can feed it the right shape of inputs.
		</comment>
		<comment id='7' author='reuben' date='2019-06-26T11:35:30Z'>
		
FWIW, I've changed the test here to check if there's 0 dimensions instead of 1 and things have been working fine:



tensorflow/tensorflow/lite/kernels/mfcc.cc


         Line 75
      in
      e6d0741






 TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1); 





diff --git a/tensorflow/lite/kernels/mfcc.cc b/tensorflow/lite/kernels/mfcc.cc
index f5b0212728..ff4a6d2e2c 100644
--- a/tensorflow/lite/kernels/mfcc.cc
+++ b/tensorflow/lite/kernels/mfcc.cc
@@ -72,7 +72,7 @@ TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {
   TfLiteTensor* output = GetOutput(context, node, kOutputTensor);

   TF_LITE_ENSURE_EQ(context, NumDimensions(inputWav), 3);
-  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 1);
+  TF_LITE_ENSURE_EQ(context, NumDimensions(inputRate), 0);

   TF_LITE_ENSURE_EQ(context, output-&gt;type, kTfLiteFloat32);
   TF_LITE_ENSURE_EQ(context, inputWav-&gt;type, output-&gt;type);

Hello,
Did you find a solution to this problem? My app crashes giving the same error. It isn't able to load the model. I tried the same solution but the error remained.
		</comment>
		<comment id='8' author='reuben' date='2019-06-26T16:05:30Z'>
		Yes, that patch is the solution :)
		</comment>
		<comment id='9' author='reuben' date='2019-06-26T16:06:03Z'>
		We've been using it in our packages ever since I ran into this issue without problems.
		</comment>
		<comment id='10' author='reuben' date='2019-06-26T16:38:55Z'>
		I tried that patch. Replaced the 1 with 0. It didn't seem to work. Am I missing something?
		</comment>
		<comment id='11' author='reuben' date='2019-06-26T17:51:47Z'>
		
I tried that patch. Replaced the 1 with 0. It didn't seem to work. Am I missing something?

Tensorflow Lite Interpreter is compiled code. Hope you are rebuilding Tensorflow from source (&lt;denchmark-link:https://www.tensorflow.org/install/source&gt;https://www.tensorflow.org/install/source&lt;/denchmark-link&gt;
) after making the code change.
		</comment>
		<comment id='12' author='reuben' date='2019-06-27T04:45:55Z'>
		I guess that's what I was missing. So I have to start from "Build the pip package" onwards?
		</comment>
		<comment id='13' author='reuben' date='2019-06-27T06:40:32Z'>
		

I tried that patch. Replaced the 1 with 0. It didn't seem to work. Am I missing something?

Tensorflow Lite Interpreter is compiled code. Hope you are rebuilding Tensorflow from source (https://www.tensorflow.org/install/source) after making the code change.

I changed 1 to 0 and rebuilt it. It didn't work. Where do I make the following change??
--- a/tensorflow/lite/kernels/mfcc.cc
+++ b/tensorflow/lite/kernels/mfcc.cc
I don't find this line in the code. Maybe this is the reason why the error still exists?
		</comment>
		<comment id='14' author='reuben' date='2019-06-27T11:04:11Z'>
		This patch does not affect training, it only changes the TFLite interpreter, so whatever you're using to load a trained .tflite file, that's what you need to modify and recompile. If you're using the Python interpreter API, then yeah, you need to rebuild and reinstall the pip package.
		</comment>
		<comment id='15' author='reuben' date='2019-06-27T11:15:21Z'>
		I'm trying to use an pretrained tflite just to see how the app works well. I did the rebuilding but to no effect. The model doesn't load but keeps giving the same error
		</comment>
		<comment id='16' author='reuben' date='2019-07-01T04:36:35Z'>
		May I know what command did you execute for compilation after making that change. I don't seem to be getting the solution.
		</comment>
		<comment id='17' author='reuben' date='2019-09-16T14:19:50Z'>
		&lt;denchmark-link:https://github.com/jdduke&gt;@jdduke&lt;/denchmark-link&gt;
 Looks like &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d5cc8288d939b522982738370facd456a0a643ba&gt;d5cc828&lt;/denchmark-link&gt;
 fixed this?
		</comment>
		<comment id='18' author='reuben' date='2019-09-16T15:38:40Z'>
		Ah yes, thanks for flagging, should be fixed (by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d5cc8288d939b522982738370facd456a0a643ba&gt;d5cc828&lt;/denchmark-link&gt;
).
		</comment>
		<comment id='19' author='reuben' date='2019-09-16T15:39:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26174&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26174&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>