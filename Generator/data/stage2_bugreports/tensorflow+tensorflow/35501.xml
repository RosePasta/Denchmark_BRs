<bug id='35501' author='jlherren' open_date='2019-12-30T16:23:14Z' closed_time='2020-01-07T02:32:25Z'>
	<summary>cuDNN-based LSTM implementation not used when eager execution is disabled</summary>
	<description>
System information
OS: Debian 10, x64
GPU: GeForce GTX 1060 6GB
Python: 3.7.3
TensorFlow: 2.0.0 installed from source (git tag v2.0.0)
Bazel: 0.26.1
GCC: 6.5.0
CUDA: 10.1
cuDNN: 7.6.4
Sample code
import numpy
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Input, LSTM

# uncommenting this causes performance issues
# tf.compat.v1.disable_eager_execution()

i = Input(shape=(1024, 32))
o = LSTM(units=32)(i)
m = Model(i, o)

m.compile('sgd', 'mse')
m.fit(numpy.zeros((512, 1024, 32)), numpy.zeros((512, 32)))
Output with eager execution enabled
&lt;denchmark-code&gt;Train on 512 samples
2019-12-30 17:06:25.988147: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_with_fallback_2026_2206' and '__inference___backward_cudnn_lstm_with_fallback_2026_2206_specialized_for_StatefulPartitionedCall_at___inference_distributed_function_2818' both implement 'lstm_c56c9d1d-36f6-4e94-9410-ecd020c8700a' but their signatures do not match.
512/512 [==============================] - 2s 3ms/sample - loss: 0.0000e+00
&lt;/denchmark-code&gt;

Output with eager execution disabled
&lt;denchmark-code&gt;WARNING:tensorflow:From /home/&lt;user&gt;/virtualenvs/tensorflow-2.0.0/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Train on 512 samples
512/512 [==============================] - 8s 15ms/sample - loss: 0.0000e+00
&lt;/denchmark-code&gt;


Note how the runtime is very significantly slower when eager execution is disabled. It seems that the cuDNN-based implementation of LSTM is not used whenever eager execution is disabled, as is seen &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent_v2.py#L1066&gt;on this line in the code&lt;/denchmark-link&gt;
 where  ends up being . This seems wrong to me, as there's no reason not to use  cuDNN in that situation.
The warning about the skipped optimization is discussed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30263&gt;#30263&lt;/denchmark-link&gt;
 and apparently can be ignored, as per qlzh727's comment.
	</description>
	<comments>
		<comment id='1' author='jlherren' date='2019-12-31T04:57:32Z'>
		Issue is replicating on colab with Tf 2.0.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/e90360e2ec49aaa0c58a91b9a8154470/untitled332.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='jlherren' date='2020-01-07T02:32:22Z'>
		Hi &lt;denchmark-link:https://github.com/jlherren&gt;@jlherren&lt;/denchmark-link&gt;
.
Thanks for reporting this issue. In short, this is actually by design that when eager mode is disabled.
When eager mode is disabled, all the code will be run with session, which is same as v1 code. Since the new LSTM implementation uses TF function, under the hood it is a op that invoke a function graph. In the v1 session runtime, the input/output of an op can't be modified between different runs, unless the session is cleared. In LSTM's case, this means the code will break if the model is first invoked with model.predict() and then model.fit(), since predict() will only create the forward path, and fit() will create backward path after that. The backward path will cause the LSTM function op to produce extra output/states for backprop, which violate the immutable input/output rule.
This is why we disable the function approach when code will be run under session mode. You can find more details in this change &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/0cdf2250b7276ff3cd2fad9bd44c917cbb760bd5&gt;0cdf225&lt;/denchmark-link&gt;
.
I am closing this issue as "working as intended". Feel free to reopen it if you feel otherwise.
		</comment>
		<comment id='3' author='jlherren' date='2020-01-07T02:32:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35501&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35501&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='jlherren' date='2020-06-09T02:35:14Z'>
		To avoid confusing users, the documentation for GRU &amp; LSTM should be updated to describe this limitation.
&lt;denchmark-link:https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/layers/GRU&gt;https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/layers/GRU&lt;/denchmark-link&gt;

&lt;denchmark-link:https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/layers/LSTM&gt;https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/layers/LSTM&lt;/denchmark-link&gt;

The above pages do not list eager-mode as a requirement for using cuDNN. They only mention activation, recurrent_activation etc as if those are the only requirements.
		</comment>
	</comments>
</bug>