<bug id='46135' author='wenfengyu' open_date='2021-01-04T08:49:05Z' closed_time='2021-01-09T15:32:16Z'>
	<summary>When activation='tanh' is used, the training gradient no drop</summary>
	<description>

TensorFlow installed from (source or binary): pip install tensorflow==2.4.0rc4
TensorFlow version (use command below): 2.4.0rc4
Python version: 3.8
CUDA/cuDNN version: CUDA11.0/cuDNN8.0.4
GPU model and memory: NVIDIA RTX3070 8G
OS version: windows 10

ISSUE:  When activation='tanh' is used, the training gradient no drop. the follow test code from: &lt;denchmark-link:https://www.tensorflow.org/tutorials/generative/dcgan&gt;https://www.tensorflow.org/tutorials/generative/dcgan&lt;/denchmark-link&gt;

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from tensorflow.keras import layers,Model
import time
from IPython import display
import tensorflow as tf
class ResNet(Model):
def init(self):
super(ResNet, self).init()
self.d1=layers.Dense(77256, use_bias=False, input_shape=(100,))
self.b1=layers.BatchNormalization()
self.a1=layers.LeakyReLU()
self.r1=layers.Reshape((7, 7, 256))
self.c1=layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)
self.r2=layers.Reshape((7, 7, 128))
self.c2=layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)
self.r3=layers.Reshape((14, 14, 64))
self.c3=layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False)
self.r4=layers.Reshape((28, 28, 1))
&lt;denchmark-code&gt;def call(self, inputs):
    x=self.d1(inputs)
    x=self.b1(x)
    x=self.a1(x)
    x=self.r1(x)
    x=self.c1(x)
    assert Model.output_shape == (None, 7, 7, 128)
    x=self.b1(x)
    x=self.a1(x)
    x=self.c2(x)
    
    x=self.b1(x)
    x=self.a1(x)
    x=self.c3(x)
    x=tf.math.sinh(x)/tf.math.cosh(x)
    
    return x
&lt;/denchmark-code&gt;

def make_generator_model():
model = tf.keras.Sequential()
model.add(layers.Dense(77256, use_bias=False, input_shape=(100,)))
model.add(layers.BatchNormalization())
model.add(layers.LeakyReLU())
&lt;denchmark-code&gt;model.add(layers.Reshape((7, 7, 256)))
assert model.output_shape == (None, 7, 7, 256) # 注意：batch size 没有限制

model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
assert model.output_shape == (None, 7, 7, 128)
model.add(layers.BatchNormalization())
model.add(layers.LeakyReLU())

model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
assert model.output_shape == (None, 14, 14, 64)
model.add(layers.BatchNormalization())
model.add(layers.LeakyReLU())

model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
assert model.output_shape == (None, 28, 28, 1)

return model
&lt;/denchmark-code&gt;

def make_discriminator_model():
model = tf.keras.Sequential()
model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',
input_shape=[28, 28, 1]))
model.add(layers.LeakyReLU())
model.add(layers.Dropout(0.3))
&lt;denchmark-code&gt;model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
model.add(layers.LeakyReLU())
model.add(layers.Dropout(0.3))

model.add(layers.Flatten())
model.add(layers.Dense(1))

return model
&lt;/denchmark-code&gt;

def discriminator_loss(real_output, fake_output):
real_loss = cross_entropy(tf.ones_like(real_output), real_output)
fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
total_loss = real_loss + fake_loss
return total_loss
def generator_loss(fake_output):
return cross_entropy(tf.ones_like(fake_output), fake_output)
@tf.function
def train_step(images):
noise = tf.random.normal([BATCH_SIZE, noise_dim])
&lt;denchmark-code&gt;with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
  generated_images = generator(noise, training=True)

  real_output = discriminator(images, training=True)
  fake_output = discriminator(generated_images, training=True)

  gen_loss = generator_loss(fake_output)
  disc_loss = discriminator_loss(real_output, fake_output)

gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
&lt;/denchmark-code&gt;

def train(dataset, epochs):
for epoch in range(epochs):
start = time.time()
&lt;denchmark-code&gt;for image_batch in dataset:
  train_step(image_batch)

display.clear_output(wait=True)
generate_and_save_images(generator,
                         epoch + 1,
                         seed)


if (epoch + 1) % 15 == 0:
  checkpoint.save(file_prefix = checkpoint_prefix)

print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))
&lt;/denchmark-code&gt;

display.clear_output(wait=True)
generate_and_save_images(generator,
epochs,
seed)
def generate_and_save_images(model, epoch, test_input):
predictions = model(test_input, training=False)
fig = plt.figure(figsize=(4,4))
for i in range(predictions.shape[0]):
plt.subplot(4, 4, i+1)
plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
plt.axis('off')
plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
&lt;denchmark-h:h1&gt;plt.show()&lt;/denchmark-h&gt;

def display_image(epoch_no):
return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))
config = tf.compat.v1.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
session = tf.compat.v1.Session(config=config)
(train_images, train_labels), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5 # 将图片标准化到 [-1, 1] 区间内
BUFFER_SIZE = 60000
BATCH_SIZE = 256
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
generator =make_generator_model()
noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)
plt.imshow(generated_image[0, :, :, 0], cmap='gray')
plt.show()
discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
generator_optimizer = tf.keras.optimizers.Adam(1e-2)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-2)
checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
discriminator_optimizer=discriminator_optimizer,
generator=generator,
discriminator=discriminator)
EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16
seed = tf.random.normal([num_examples_to_generate, noise_dim])
train(train_dataset, EPOCHS)
checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))
anim_file = 'dcgan.gif'
with imageio.get_writer(anim_file, mode='I') as writer:
filenames = glob.glob('image*.png')
filenames = sorted(filenames)
last = -1
for i,filename in enumerate(filenames):
frame = 2*(i**0.5)
if round(frame) &gt; round(last):
last = frame
else:
continue
image = imageio.imread(filename)
writer.append_data(image)
image = imageio.imread(filename)
writer.append_data(image)
import IPython
if IPython.version_info &gt; (6,2,0,''):
display.Image(filename=anim_file)
try:
from google.colab import files
except ImportError:
pass
else:
files.download(anim_file)
	</description>
	<comments>
		<comment id='1' author='wenfengyu' date='2021-01-07T16:19:07Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;

Unable to replicate due to "runtime disconnected error"
		</comment>
		<comment id='2' author='wenfengyu' date='2021-01-08T00:23:12Z'>
		Hyperbolic tangent activation functions (tanh) often suffer from vanishing gradient problem, You may want to try using ReLU activation function in this case.
		</comment>
		<comment id='3' author='wenfengyu' date='2021-01-08T07:31:33Z'>
		This model can't use ReLU in last Conv2DTranspose layer,   this test code from &lt;denchmark-link:https://www.tensorflow.org/tutorials/generative/dcgan&gt;https://www.tensorflow.org/tutorials/generative/dcgan&lt;/denchmark-link&gt;
.  Now I use custom tanh function instead of activation='tanh' temporarily solve this problem.
		</comment>
		<comment id='4' author='wenfengyu' date='2021-01-08T07:33:24Z'>
		BTW,  I use pytorch recreate this model code. it's work is normal, so I guess activation='tanh' in tensorflow2.4 have issue
		</comment>
		<comment id='5' author='wenfengyu' date='2021-01-09T15:32:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46135&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46135&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>