<bug id='42004' author='idofr' open_date='2020-08-03T12:20:23Z' closed_time='2020-12-18T11:04:07Z'>
	<summary>KeyError on concrete_functions while loading a model</summary>
	<description>
System information

Have I written custom code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b
Python version: 3.7.7
CUDA/cuDNN version: 10.0 / 7.6
GPU model and memory: Nvidia Quadro P1000, 4GB

Describe the current behavior
When loading a SavedModel object, function_deserialization.py#265 (concrete_function_objects.append(concrete_functions[concrete_function_name])) throws a KeyError exception caused from looking for a concrete function which is not in the SavedModel (was not serialised). In my case the missing functions are called

__inference_my_model_layer_call_fn_37929
__inference_my_model_layer_call_fn_38165
All other concrete functions are successfully located and recovered.

The call traces back to saved_model/load.py at line 604. Yet when I debug the values in object_graph_proto I can't see these missing keys, meaning they're added at a later phase.
I also tried changing the original code line to
        try:
            concrete_function_objects.append(concrete_functions[concrete_function_name])
        except KeyError:
            print(
                f'from saved_model/function_deserialization.py: couldnt find concrete function {concrete_function_name}'
            )
            continue
        print(
            f'from saved_model/function_deserialization.py: found concrete function {concrete_function_name}'
        )
It indeed shows that only these two functions are not found while all other ones are there. Also by doing that I can use the model for testing and inference, i.e. I see no limited functionality at the moment.
Notice there are two similarly-named functions in concrete_functions called

__inference_my_model_layer_call_and_return_conditional_losses_35962
__inference_my_model_layer_call_and_return_conditional_losses_37693

I guess there are two functions there as one originates from the training function and the other is related to the cross validation function.
My MyModel object extends Keras' Model class and contains a series of Models and Layers which are called in the call function. MyModel doesn't have any paramters or variables of its own. The last object in the series (an object extending Layer) also uses self.add_loss in its call function.
Describe the expected behavior
Model should load and work properly.
Standalone code to reproduce the issue
Not easy to do since the model structure is rather complicated.
Other info / logs Include any logs or source code that would be helpful to
The output without my workaround:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "test.py", line 148, in &lt;module&gt;
    main()
  File "test.py", line 107, in main
    model = tf.keras.models.load_model(model_path)
  File "tensorflow\python\keras\saving\save.py", line 190, in load_model
    return saved_model_load.load(filepath, compile)
  File "tensorflow\python\keras\saving\saved_model\load.py", line 116, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File "tensorflow\python\saved_model\load.py", line 604, in load_internal
    export_dir)
  File "tensorflow\python\keras\saving\saved_model\load.py", line 188, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File "tensorflow\python\saved_model\load.py", line 123, in __init__
    self._load_all()
  File "tensorflow\python\keras\saving\saved_model\load.py", line 212, in _load_all
    super(KerasObjectLoader, self)._load_all()
  File "tensorflow\python\saved_model\load.py", line 134, in _load_all
    self._load_nodes()
  File "tensorflow\python\saved_model\load.py", line 264, in _load_nodes
    node, setter = self._recreate(proto, node_id)
  File "tensorflow\python\keras\saving\saved_model\load.py", line 233, in _recreate
    obj, setter = super(KerasObjectLoader, self)._recreate(proto, node_id)
  File "tensorflow\python\saved_model\load.py", line 370, in _recreate
    return factory[kind]()
  File "tensorflow\python\saved_model\load.py", line 359, in &lt;lambda&gt;
    "function": lambda: self._recreate_function(proto.function),
  File "tensorflow\python\saved_model\load.py", line 398, in _recreate_function
    proto, self._concrete_functions), setattr
  File "tensorflow\python\saved_model\function_deserialization.py", line 265, in recreate_function
    concrete_function_objects.append(concrete_functions[concrete_function_name])
KeyError: '__inference_my_model_layer_call_fn_37929'
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='idofr' date='2020-08-03T14:23:25Z'>
		Can you share a very minimal/dummy but runnable code to reproduce this?
		</comment>
		<comment id='2' author='idofr' date='2020-08-04T10:55:09Z'>
		No very easily. The model is rather complicated. Dismantling it to the level where I can provide a minimal example would take hours.
		</comment>
		<comment id='3' author='idofr' date='2020-08-04T11:33:18Z'>
		Are these custom objects?
		</comment>
		<comment id='4' author='idofr' date='2020-08-04T11:38:44Z'>
		Well.. yes. They are either implementations of keras.layers.Layer or, in the case of multiple layers with a shared semantic meaning, an implementation of keras's Model object, grouping layers together.
For example, imagine an encoder decoder framework for something like VAE. The encoder and decoder are Models and the sampling layer is the custom layer in the middle. The entire thing is then wrapped in a MyModel Model class
		</comment>
		<comment id='5' author='idofr' date='2020-08-04T11:49:16Z'>
		Have you correctly loaded custom objects? e.g.:
&lt;denchmark-code&gt;with CustomObjectScope({'AttentionLayer': AttentionLayer}): 
    model = load_model('my_model.h5')
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='idofr' date='2020-08-04T12:07:52Z'>
		No
Where is this documented?
What does it do?
For what types of objects do i need this?
		</comment>
		<comment id='7' author='idofr' date='2020-08-04T13:00:38Z'>
		It Is documented in many places but I suggest  &lt;denchmark-link:https://keras.io/guides/serialization_and_saving/&gt;https://keras.io/guides/serialization_and_saving/&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='idofr' date='2020-08-04T13:59:02Z'>
		The explanations and examples in this page only use the  scope if loading from config. Not when using the native  function.
Also, it refers the reader to &lt;denchmark-link:https://keras.io/guides/serialization_and_saving/save_and_serialize.ipynb#custom-objects&gt;this&lt;/denchmark-link&gt;
 page which doesn't exist
		</comment>
		<comment id='9' author='idofr' date='2020-08-04T14:50:01Z'>
		&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/utils/CustomObjectScope?hl=en#used-in-the-notebooks&gt;https://www.tensorflow.org/api_docs/python/tf/keras/utils/CustomObjectScope?hl=en#used-in-the-notebooks&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='idofr' date='2020-08-05T10:35:52Z'>
		Ok, so this wasn't the solution, but it set me in the right direction, so many thanks üëç
After doing the following changes to the code, this now seems to work

All Model implementations, except for the "main model wrapper thingy", were changes to Layer objects.
All custom implementations (both the Layers and the Model) were given a get_config function.

I'm not sure which of these did the trick, but my money is on the first point.
Anyway it's working now so many thanks.
P.s.
I still don't really like the way this works. It's not properly documented anyway. Some places just vaguely say that "it's a good practice to implement get_config", but I didn't see any proper explanations.
Furthermore, there's no proper explanation on when a Layer should be used and when a Model would be better.
Finally, even when trying to write the get_config function, no documentation tells you what it should include.
		</comment>
		<comment id='11' author='idofr' date='2020-08-05T10:44:46Z'>
		/cc &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 about evaluate doc improvements margins
		</comment>
		<comment id='12' author='idofr' date='2020-08-05T10:53:23Z'>
		&lt;denchmark-link:https://github.com/idofr&gt;@idofr&lt;/denchmark-link&gt;
 To speed-up a little bit the process I suggest you to open a new documentation ticket mentioning this one at &lt;denchmark-link:https://github.com/keras-team/keras-io&gt;https://github.com/keras-team/keras-io&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='idofr' date='2020-08-10T19:30:48Z'>
		&lt;denchmark-link:https://github.com/idofr&gt;@idofr&lt;/denchmark-link&gt;
 Please update as per above comment
		</comment>
		<comment id='14' author='idofr' date='2020-08-11T15:19:27Z'>
		What is there to update? you can see exactly that I opened a ticket in keras-io and that the ticket has the status 'open'
		</comment>
		<comment id='15' author='idofr' date='2020-12-11T10:27:51Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='16' author='idofr' date='2020-12-18T11:04:03Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='17' author='idofr' date='2020-12-18T11:04:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42004&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42004&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>