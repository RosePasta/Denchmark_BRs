<bug id='42890' author='HaraBeron' open_date='2020-09-02T10:02:28Z' closed_time='2020-09-03T21:40:26Z'>
	<summary>load_model not properly working in TF 2.3.0</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
TensorFlow installed from (source or binary): Colab TF 2.3.0 vs TF 2.2.0
TensorFlow version (use command below): Colab TF 2.3.0 vs TF 2.2.0
Python version: Colab Python
GPU model and memory: Colab GPU

When I used TF 2.2.0 in colab I was able to fit, save and load a model. So I run my code, fit my model:
&lt;denchmark-link:https://user-images.githubusercontent.com/68148852/91966779-9bf5e880-ed12-11ea-8ec3-7e499a5024eb.png&gt;&lt;/denchmark-link&gt;

and check again with model.evaluate:
&lt;denchmark-link:https://user-images.githubusercontent.com/68148852/91966830-ac0dc800-ed12-11ea-9ab8-68c2b84cb218.png&gt;&lt;/denchmark-link&gt;

Everything as expected. Then I save the model and load it back again and I check it again with model.evaluate and same accuracy is shown. Everything fine. However, the same code does not work in TF 2.3.0. See my code below. If this code is run by default TF 2.3.0 is used in colab and it does not work. The accuracy of the loaded model loadedmodel.evaluate(x_test_r,test_labels) is not the same:
&lt;denchmark-link:https://user-images.githubusercontent.com/68148852/91966880-c051c500-ed12-11ea-9b72-3c57fffc5646.png&gt;&lt;/denchmark-link&gt;

It is completely wrong (approx .098... vs supposed 0.99... when I run it). When I add !pip install tensorflow==2.2.0 to my code and run the same code in my colab again (note that the runtime has to be restarted) then with the 2.2.0 version it does work.
(When I save the model in TF 2.2.0 (where evaluate works and correct accuracy is shown) and then load it in TF 2.3.0, it does not work. model.evaluate shows a wrong accuracy.)
Standalone code to reproduce the issue
&lt;denchmark-code&gt;#!pip install tensorflow==2.2.0
import tensorflow as tf
import os
import PIL
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import tensorflow_hub as hub

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import keras_preprocessing
from keras_preprocessing import image

from tensorflow.python.keras.utils.version_utils import training
from tensorflow.keras.optimizers import RMSprop

print(tf.__version__)

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

x_trainf = train_images.astype('float32') / 255.0
x_testf = test_images.astype('float32') / 255.0

x_train_r = x_trainf.reshape(x_trainf.shape[0], 28, 28, 1)
x_test_r = x_testf.reshape(x_testf.shape[0], 28, 28, 1)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) 
model.add(tf.keras.layers.MaxPooling2D(pool_size=2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(10))

model.compile(optimizer='adam',
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(x_train_r, 
          train_labels, batch_size=32,  
          epochs=10,
          validation_data=(x_test_r,test_labels))

model.evaluate(x_test_r,test_labels)

model.save('/tmp/loaddatamnist.h5')

loadedmodel=tf.keras.models.load_model('/tmp/loaddatamnist.h5')
loadedmodel.evaluate(x_test_r,test_labels)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='HaraBeron' date='2020-09-02T11:37:15Z'>
		&lt;denchmark-link:https://github.com/HaraBeron&gt;@HaraBeron&lt;/denchmark-link&gt;

I have tried in colab with TF nightly version(2.4.0-dev20200902) and i am not seeing any issue. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/4cb33851aa5e54ab42b787f9734773f2/untitled297.ipynb&gt;here&lt;/denchmark-link&gt;
.Please, verify once and close the issue. Thanks!
		</comment>
		<comment id='2' author='HaraBeron' date='2020-09-02T11:51:55Z'>
		Thanks for your fast response and having a look into this issue.
I was not talking about TF nightly version 2.4.0-... I was talking about TF 2.2.0 and TF 2.3.0 and there the issue exists and this is what most users are using. They do not use nightly version.
When you run your colab without the first line, so without !pip install tf-nightly. Then TF 2.3.0 is used and then the same issue occurs. I run your code without this line and the issue as described occurs.
In detail:
When I run your code (with just 2 epochs) I get an val_accuracy of 0.9881 when I use model.evaluate it gives the same 0.988099. Then I save and load the model and run model.evaluate again. This should give the same value, however it doesn't. It gives a wrong value of 0.099.
So the issue does exist.
		</comment>
		<comment id='3' author='HaraBeron' date='2020-09-02T12:02:15Z'>
		Here is a screenshot of your colab when I run it (not with TF 2.4. nightly, but without any modifications, so usual import tf and then by default TF 2.3.0 is used):
&lt;denchmark-link:https://user-images.githubusercontent.com/68148852/91978231-13804380-ed24-11ea-8718-c5863a101cec.png&gt;&lt;/denchmark-link&gt;

There you can see the issue (here in this case it was not 0.099, but 0.1, still a wrong value). It is without the tf nightly. It is TF 2.3.0.
When you add !pip install tensorflow==2.2.0 instead of the tf nightly and then run it (you maybe have to restart the runtime), you can see, that it does work. Here is a screenshot:
&lt;denchmark-link:https://user-images.githubusercontent.com/68148852/91978716-e54f3380-ed24-11ea-96e9-97ba9d3e5519.png&gt;&lt;/denchmark-link&gt;

So again: It works in TF 2.2.0, but not in TF 2.3.0.
		</comment>
		<comment id='4' author='HaraBeron' date='2020-09-02T12:12:39Z'>
		&lt;denchmark-link:https://github.com/HaraBeron&gt;@HaraBeron&lt;/denchmark-link&gt;

I tried in TF 2.3 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/ea2d084ee5d54411a0dbb545b13ca7e6/untitled295.ipynb&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='5' author='HaraBeron' date='2020-09-02T17:14:04Z'>
		I don't know if the compiled status it is recovered. Please try to recompile after reloading:
&lt;denchmark-code&gt;loadedmodel=tf.keras.models.load_model('/tmp/test.h5')
loadedmodel.compile(optimizer='adam',
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
loadedmodel.evaluate(x_test_r,test_labels)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='HaraBeron' date='2020-09-02T21:08:28Z'>
		&lt;denchmark-link:https://github.com/HaraBeron&gt;@HaraBeron&lt;/denchmark-link&gt;
 This is a know bug with . In earlier TF versions  was correctly inferred from the  function. In this case,  need to be inferred as  but in the current version it is not working as expected.
Everything works as expected If you replace accuracy with sparse_categorical_accuracy in model.compile as shown below.
&lt;denchmark-code&gt;model.compile(optimizer='adam',
              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['sparse_categorical_accuracy'])
&lt;/denchmark-code&gt;

Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/933388973689f871e75248e022e33800/untitled295.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
We will track the progress of this bug in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/42045&gt;this issue&lt;/denchmark-link&gt;
.
Please verify once and close the issue. We will track the progress of this bug in the above mentioned issue.
I will also comment when everything is working as intended. Thanks!
		</comment>
		<comment id='7' author='HaraBeron' date='2020-09-02T21:12:21Z'>
		&lt;denchmark-link:https://github.com/HaraBeron&gt;@HaraBeron&lt;/denchmark-link&gt;
 This is not completely fixed in the recent . Recompiling and loading as mentioned by &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 works as expected. Please take a look at the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/f4e29da076c58ab8d0504142ee8b211a/untitled295.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='8' author='HaraBeron' date='2020-09-03T21:40:26Z'>
		This is resolved in recent tf-nightly. Please feel free to reopen if you notice the issue.
This is available in stable TF2.4 in the near future. Thanks!
		</comment>
		<comment id='9' author='HaraBeron' date='2020-09-03T21:40:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42890&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42890&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>