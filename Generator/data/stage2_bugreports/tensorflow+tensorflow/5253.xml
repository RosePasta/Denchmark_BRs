<bug id='5253' author='xingmingjie' open_date='2016-10-28T05:01:09Z' closed_time='2016-10-28T06:45:48Z'>
	<summary>Let user to choice whether to do bazel clean during configure</summary>
	<description>
Currently running the configure will do 'bazel clean --expunge' by default.  It is OK for the first time to run configure.  But when I need to rerun the configure (because some errors occur, I will retry), I have to spend much time to download files from internet again each time during to the execution of 'bazel clean --expunge'.
So, should we let user to choice whether to do bazel clean during configure?
	</description>
	<comments>
		<comment id='1' author='xingmingjie' date='2016-10-28T05:55:09Z'>
		&lt;denchmark-link:https://github.com/jart&gt;@jart&lt;/denchmark-link&gt;

I have also been puzzled by that. It prevents using the cache, and doesn't really belong in a configure script. You can use sed s/bazel.clean/true/ &lt;configure|bash as a workaround.
		</comment>
		<comment id='2' author='xingmingjie' date='2016-10-28T06:45:48Z'>
		The  and  need to happen unfortunately to work around bugs in Bazel. There's issues relating to cache invalidation on remote repositories. There's also issues relating to passing environment variables to repository rules. CC: &lt;denchmark-link:https://github.com/davidzchen&gt;@davidzchen&lt;/denchmark-link&gt;

It'd probably be better if we didn't have an option to disable the clean and fetch. We want to guarantee that builds work, even if that means things go a little slower. We're going to be improving the state of the build real soon though. We're actually planning to make the configure script optional. I think the Bazel team is doing amazing work helping to make that happen.
Thanks for bringing this to our attention. Feel free to post any other questions you might have and I'll be happy to answer them.
		</comment>
		<comment id='3' author='xingmingjie' date='2016-10-28T06:46:53Z'>
		One other note, if you're 100% certain you want to roll the dice by disabling the clean and fetch, it shouldn't be too difficult to comment out those lines in the configure script.
		</comment>
		<comment id='4' author='xingmingjie' date='2016-10-28T17:20:30Z'>
		If you have a link to the issue, please post here and/or in the code.
		</comment>
		<comment id='5' author='xingmingjie' date='2016-10-28T18:57:16Z'>
		It's possible that the related issues are &lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/1022&gt;bazelbuild/bazel#1022&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/1595&gt;bazelbuild/bazel#1595&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/974&gt;bazelbuild/bazel#974&lt;/denchmark-link&gt;
. There was another one, but I'm having trouble digging it up.
Also here is an explanation that &lt;denchmark-link:https://github.com/davidzchen&gt;@davidzchen&lt;/denchmark-link&gt;
 gave me a week ago regarding the necessity of fetch.

The reason why we fetch in the configure script is because the way the script
passes values to the cuda_configure workspace rule is via environment variables
(see comment at the top of cuda_configure.bzl).
The configure script exports these environment variables before calling bazel
fetch, which will set up external repositories, such as @local_config_cuda,
according to the values provided by the user. However, if we do not do this,
when the user runs bazel fetch/build after running ./configure, then
cuda_configure will use the environment variables in the user's shell, which
would not contain any of the values set by ./configure.
That is, with this change, even if the user runs ./configure to enabling
building with CUDA, when the user subsequently runs bazel build, the build will
fail because @local_config_cuda would have been configured without GPU support.
It might be more ideal to be able to pass values to Skylark repository rules
via command line flags. For example, something like the following would build
with CUDA support enabled, and cuda_configure would look for the cuda
installation in a set of standard install locations:
bazel build --enable_cuda //tensorflow/...

If the user would like to specify a custom cuda install location, then she
would be able to do so with another flag:
bazel build --enable_cuda --cuda_toolkit_path=/opt/local //tensorflow/...

If adding arbitrary flags is not feasible, then perhaps we can use an approach
similar to the kubernetes vars:
bazel build --vars=enable_cuda=true,cuda_toolkit_path=/opt/local //tensorflow/...

These are hypothetical examples, and I haven't scoped out the work that would
be required to implement this feature. However, with the way things are set up
currently, removing the fetch from the configure script would cause the build
to fail.

We're also working hard to pay off the technical debt in TensorFlow that is contributing to this broader problem. For example, we recently committed &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/1dba78b997dc49df9df663a838e0bacd6602f5b8&gt;1dba78b&lt;/denchmark-link&gt;
 which removes SWIG from the configure script. So we're one step closer to having a hermetically sealed build.
Once the Bazel bugs are fixed, and once TensorFlow is fully hermetically sealed, bazel clean will become a command that no one will ever need to run again.
		</comment>
		<comment id='6' author='xingmingjie' date='2016-10-28T19:28:52Z'>
		Nice, thanks!
		</comment>
		<comment id='7' author='xingmingjie' date='2016-11-03T12:18:14Z'>
		&lt;denchmark-link:https://github.com/bazelbuild/bazel/issues/2033&gt;bazelbuild/bazel#2033&lt;/denchmark-link&gt;

If I try to build tensorflow on NFS, it's necessary to provide  for  to work properly
		</comment>
		<comment id='8' author='xingmingjie' date='2016-11-08T03:09:30Z'>
		FYI &lt;denchmark-link:https://github.com/damienmg&gt;@damienmg&lt;/denchmark-link&gt;
 is working on &lt;denchmark-link:https://bazel-review.googlesource.com/c/6697/3/site/designs/_posts/2016-10-18-repository-invalidation.md&gt;improvements&lt;/denchmark-link&gt;
 to Bazel's Skylark remote repositories to both improve its caching and invalidation and make it possible to pass environment variables to workspace rules, which will enable us to implement the kind of interface I suggested in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/5253#issuecomment-257000911&gt;@jart's comment&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>