<bug id='24778' author='GothamCityPro' open_date='2019-01-08T20:13:33Z' closed_time='2020-01-02T17:50:27Z'>
	<summary>SetDefaultDevice doesn't seem to work; Multiple Tensorflow Session on Separate GPU's Cannot Seem to Speed up Inference</summary>
	<description>
I am trying to speed up Tensorflow inference by creating multiple Sessions, with each Session loading its own graph on its own GPU. When I ran this same model for a batch of 10 images on a single GPU, it took about 2700 ms. I was hoping I can run 2 batches, one per GPU and process 20 images in the same time frame. Instead, the run time actually took about 5300 ms. So it seems like I was not able to get the speed up I was hoping for.
I am running Tensorflow 1.7 with 2 Quadro GV100's. I did not get any error messages running my code. Below is my code:
&lt;denchmark-code&gt;auto options = SessionOptions();
options.config.mutable_gpu_options()-&gt;set_visible_device_list("0,1");

NewSession(options, &amp;m_session[0]);
NewSession(options, &amp;m_session[1]);

GraphDef graph_def0;
graph::SetDefaultDevice("/device:GPU:0", &amp;graph_def0);
ReadBinaryProto(Env::Default(), graphPath, &amp;graph_def0);
m_session[0]-&gt;Create(graph_def0);

GraphDef graph_def1;
graph::SetDefaultDevice("/device:GPU:1", &amp;graph_def1);
ReadBinaryProto(Env::Default(), graphPath, &amp;graph_def1);
m_session[1]-&gt;Create(graph_def1);

//list0 and list1 are list of images, CallSessionRun()'s 2nd arg is index into m_session
std::future&lt;std::vector&lt;std::vector&lt;tf_detection&gt;&gt;&gt; fut0 = std::async([&amp;]()-&gt;std::vector&lt;std::vector&lt;tf_detection&gt;&gt;{
	auto detections = CallSessionRun(list0, 0);
	return detections;
});

std::future&lt;std::vector&lt;std::vector&lt;tf_detection&gt;&gt;&gt; fut1 = std::async([&amp;]()-&gt;std::vector&lt;std::vector&lt;tf_detection&gt;&gt;{
	auto detections = CallSessionRun(list1, 1);
	return detections;
});

auto ans0 = fut0.get();
auto ans1 = fut1.get();
&lt;/denchmark-code&gt;

graph::SetDefaultDevice is supposed to dedicate a GPU for a graph and calling m_session[i]-&gt;run() in std::async is supposed to utilize each session concurrently. But it didn't seem to work. Am I missing something?
The fact that the run time stays pretty much the same seems to suggest that graph::SetDefaultDevice() does not work and I am only using 1 GPU instead of 2.
Thank you very much for your help in advance!
	</description>
	<comments>
		<comment id='1' author='GothamCityPro' date='2019-01-10T00:41:28Z'>
		Hi &lt;denchmark-link:https://github.com/asimshankar&gt;@asimshankar&lt;/denchmark-link&gt;
 &amp; &lt;denchmark-link:https://github.com/azaks2&gt;@azaks2&lt;/denchmark-link&gt;
 , this is a recurrent query from users, i.e. allocation of sessions to GPUs and whether device assignment works on older TensorFlow releases. Please advise. Thanks.
		</comment>
		<comment id='2' author='GothamCityPro' date='2019-03-29T01:14:55Z'>
		Hi, &lt;denchmark-link:https://github.com/GothamCityPro&gt;@GothamCityPro&lt;/denchmark-link&gt;
 , have you solved this problem? if yes, could you share the solution with me?
		</comment>
		<comment id='3' author='GothamCityPro' date='2019-05-24T08:31:23Z'>
		when I call set_visible_device_list("0"), the 8 gpu card in my machine were stiil used for the tensorflow? why?  Does set_visible_device_list really work ? thank you!
		</comment>
		<comment id='4' author='GothamCityPro' date='2019-05-29T23:26:20Z'>
		&lt;denchmark-link:https://github.com/GothamCityPro&gt;@GothamCityPro&lt;/denchmark-link&gt;
 one possibility is that we should call   reading the graph:
&lt;denchmark-code&gt;ReadBinaryProto(Env::Default(), graphPath, &amp;graph_def0);
graph::SetDefaultDevice("/device:GPU:0", &amp;graph_def0);
&lt;/denchmark-code&gt;

could you try again with that fixed?
		</comment>
		<comment id='5' author='GothamCityPro' date='2020-01-02T17:50:27Z'>
		Closing because of lack of activity.  If you want this reopened please try &lt;denchmark-link:https://github.com/aaroey&gt;@aaroey&lt;/denchmark-link&gt;
 's &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24778#issuecomment-497144222&gt;advice&lt;/denchmark-link&gt;
 first and see if that helps.
		</comment>
		<comment id='6' author='GothamCityPro' date='2020-01-02T17:50:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24778&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24778&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>