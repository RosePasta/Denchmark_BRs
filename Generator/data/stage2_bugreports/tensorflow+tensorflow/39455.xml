<bug id='39455' author='John-8704' open_date='2020-05-12T12:02:43Z' closed_time='2020-05-13T18:43:29Z'>
	<summary>Custom layer return AttributeError during model saving</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): conda install tensorflow
TensorFlow version (CPU) : 2.1.0
Python version: 3.7.7

Describe the current behavior
I was working on a model and I used this below custom attention layer, After training for few epochs I tried to save my model and I'm getting an attribute error (pasted below) which I think is related to the custom attention layer.
Here is the custom attention layer used:
&lt;denchmark-code&gt;    class AttentionWeightedAverage(Layer):

        def __init__(self, return_attention=False, **kwargs):
            self.init = initializers.get('uniform')
            self.supports_masking = True
            self.return_attention = return_attention
            super(AttentionWeightedAverage, self).__init__(** kwargs)
    
        def build(self, input_shape):
            self.input_spec = [InputSpec(ndim=3)]
            assert len(input_shape) == 3
    
            self.w = self.add_weight(shape=(input_shape[2], 1),
                                     name='{}_w'.format(self.name),
                                     initializer=self.init, trainable=True)
            super(AttentionWeightedAverage, self).build(input_shape)
    
        def call(self, h, mask=None):
            h_shape = K.shape(h)
            d_w, T = h_shape[0], h_shape[1]
            
            logits = K.dot(h, self.w)  # w^T h
            logits = K.reshape(logits, (d_w, T))
            alpha = K.exp(logits - K.max(logits, axis=-1, keepdims=True))  # exp
            
            # masked timesteps have zero weight
            if mask is not None:
                mask = K.cast(mask, K.floatx())
                alpha = alpha * mask
            
            alpha = alpha / (K.sum(alpha, axis=1, keepdims=True) + K.epsilon()) # softmax
            r = K.sum(h * K.expand_dims(alpha), axis=1)  # r = h*alpha^T
            h_star = K.tanh(r)  # h^* = tanh(r)
            if self.return_attention:
                return [h_star, alpha]
            return h_star
    
        def get_output_shape_for(self, input_shape):
            return self.compute_output_shape(input_shape)
    
        def compute_output_shape(self, input_shape):
            output_len = input_shape[2]
            if self.return_attention:
                return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]
            return (input_shape[0], output_len)
    
        def compute_mask(self, input, input_mask=None):
            if isinstance(input_mask, list):
                return [None] * len(input_mask)
            else:
                return None
&lt;/denchmark-code&gt;

Here is my sample architecture used:
&lt;denchmark-code&gt;        inputs = Input((shape,))
        x = Embedding(input_dim=1000, output_dim=10,
                      mask_zero=True)(inputs)
        x = Bidirectional(LSTM(10, return_sequences=True))(x)
        weights, _ = AttentionWeightedAverage(return_attention=True)(x)
        outputs = Dense(self.n_classes, activation='softmax')(weights)
        my_model= Model([inputs], [outputs])
&lt;/denchmark-code&gt;

After training I used my_model.save('save_models') and I got this below error, I'm posting the entire traceback related to the error,
&lt;denchmark-code&gt;    Traceback (most recent call last):
      File "classifiers/main.py", line 26, in &lt;module&gt;
        main()
      File "classifiers/main.py", line 18, in main
        clf.model.save(f'./classifiers/saved_models/{args.model_name}')
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\engine\network.p
        signatures, options)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\save.py",
        signatures, options)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        save_lib.save(model, filepath, signatures, options)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\saved_model\save.py", 
        checkpoint_graph_view)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\saved_model\signature_
        functions = saveable_view.list_functions(saveable_view.root)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\saved_model\save.py", 
        self._serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\engine\base_laye
        .list_functions_for_serialization(serialization_cache))
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        fns = self.functions_to_serialize(serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        serialization_cache).functions_to_serialize)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        serialization_cache))
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        original_fns = _replace_child_layer_functions(layer, serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        serialization_cache).functions)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        '{}_layer_call_and_return_conditional_losses'.format(layer.name))
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        self.add_trace(*self._input_signature)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        fn.get_concrete_function(*args, **kwargs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\saving\saved_mod
        return super(LayerCall, self).get_concrete_function(*args, **kwargs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\def_function.py"
        self._initialize(args, kwargs, add_initializers_to=initializers)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\def_function.py"
        *args, **kwds))
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\function.py", li
        graph_function, _, _ = self._maybe_define_function(args, kwargs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\function.py", li
        graph_function = self._create_graph_function(args, kwargs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\function.py", li
        capture_by_value=self._capture_by_value),
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\framework\func_graph.p
        func_outputs = python_func(*func_args, **func_kwargs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\eager\def_function.py"
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
        return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\classifiers\blstm_attention.py", line 43, in 
    call
        logits = K.dot(h, self.w)  # w^T h
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\backend.py", line 1653, in dot
        if ndim(x) is not None and (ndim(x) &gt; 2 or ndim(y) &gt; 2):
      File "C:\Users\user\miniconda3\envs\user\lib\site-packages\tensorflow_core\python\keras\backend.py", line 1202, in ndim
        dims = x.shape._dims
    AttributeError: 'list' object has no attribute 'shape'
&lt;/denchmark-code&gt;

Describe the expected behavior
It suppose to save the model.
Standalone code to reproduce the issue
Here's a sample colab to reproduce the similar error,
&lt;denchmark-link:https://colab.research.google.com/drive/1RDcJwpVbT6JR8_LA52r1nHPSK0w1HuY7?usp=sharing&gt;https://colab.research.google.com/drive/1RDcJwpVbT6JR8_LA52r1nHPSK0w1HuY7?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='John-8704' date='2020-05-13T05:39:13Z'>
		&lt;denchmark-link:https://github.com/John-8704&gt;@John-8704&lt;/denchmark-link&gt;

You can save the model to a HDFS file.().Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/a26906d13a67cc4ef5e391874ff65900/untitled883.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='John-8704' date='2020-05-13T06:26:54Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 But it doesn't save custom layers unlike tensorflow SavedModel format? Also I'm not sure if  format saves optimizer state for resuming training later on.
		</comment>
		<comment id='3' author='John-8704' date='2020-05-13T14:32:02Z'>
		&lt;denchmark-link:https://github.com/John-8704&gt;@John-8704&lt;/denchmark-link&gt;
 During , code is running some shape checking on a list (specifically here ) and throwing an error as there is no  attribute for  object.  I changed one line in  function from
self.input_spec = [tf.keras.layers.InputSpec(ndim=3)]
to
self.input_spec = tf.keras.layers.InputSpec(ndim=3) 
After that change, model.save was working as expected. Thanks
Please verify once and close the issue. &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/b2ccfa5bdccbbf9b9722ff358ad77a95/text_classification.ipynb&gt;Here&lt;/denchmark-link&gt;
 is a gist for your reference. Thanks!
		</comment>
		<comment id='4' author='John-8704' date='2020-05-13T18:43:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39455&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39455&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>