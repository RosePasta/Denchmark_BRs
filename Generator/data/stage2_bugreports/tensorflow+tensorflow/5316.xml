<bug id='5316' author='tobegit3hub' open_date='2016-11-01T02:18:23Z' closed_time='2016-11-03T01:59:57Z'>
	<summary>Invalid argument when accessing HDFS</summary>
	<description>
We have installed pseudo-distributed HDFS in local and use the default port, 9000. We follow the example code from https://github.com/tensorflow/tensorflow/issues/2218 but it throws InvalidArgumentError.
Our code looks like this and it works if we change to local filesystem.
&lt;denchmark-code&gt;hdfs_path = "hdfs://127.0.0.1:9000/cancer_train.csv.tfrecords"
filename_queue = tf.train.string_input_producer(
    tf.train.match_filenames_once(hdfs_path),
    num_epochs=epoch_number)
label, features = read_and_decode(filename_queue)
batch_labels, batch_features = tf.train.shuffle_batch(
    [label, features],
    batch_size=batch_size,
    num_threads=thread_number,
    capacity=capacity,
    min_after_dequeue=min_after_dequeue)
&lt;/denchmark-code&gt;

And the error log looks like this.
&lt;denchmark-code&gt;hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
hdfsGetPathInfo(): constructNewObjectOfPath error:
java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:126)
        at org.apache.hadoop.fs.Path.&lt;init&gt;(Path.java:134)
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: hdfs://127.0.0.1:9000
Traceback (most recent call last):
  File "./hdfs.py", line 237, in &lt;module&gt;
    sess.run(init_op)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 717, in run
    run_metadata_ptr)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 915, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 965, in _do_run
    target_list, options, run_metadata)
  File "/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: hdfs://127.0.0.1:9000
         [[Node: matching_filenames/MatchingFiles = MatchingFiles[_device="/job:localhost/replica:0/task:0/cpu:0"](matching_filenames/MatchingFiles/pattern)]]
         [[Node: matching_filenames_1/Assign/_6 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send
_device_incarnation=1, tensor_name="edge_117_matching_filenames_1/Assign", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System: CentOS 7.0
TensorFlow: 0.11.0rc1
&lt;denchmark-h:h3&gt;Logs or other output that would be helpful&lt;/denchmark-h&gt;

(If logs are large, please upload as attachment or provide link).
	</description>
	<comments>
		<comment id='1' author='tobegit3hub' date='2016-11-01T16:38:28Z'>
		&lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
, could you take a quick a look at this please?
		</comment>
		<comment id='2' author='tobegit3hub' date='2016-11-03T01:59:57Z'>
		This is now fixed internally and will be pushed during the next sync. In the meanwhile, a workaround is to put your data somewhere in a subdirectory so it's not in your HDFS root.
		</comment>
		<comment id='3' author='tobegit3hub' date='2016-11-03T04:22:40Z'>
		Thanks &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
 and that works for me.
I'm sure if it supports kerberos now and can &lt;denchmark-link:https://github.com/jhseu&gt;@jhseu&lt;/denchmark-link&gt;
 help to verify that?
		</comment>
		<comment id='4' author='tobegit3hub' date='2016-11-03T07:36:46Z'>
		We have tested and confirm that it doesn't support HDFS with kerberos. I'm gonna open another issue to track that if you don't mind. Hope Google would help to work for it :)
		</comment>
	</comments>
</bug>