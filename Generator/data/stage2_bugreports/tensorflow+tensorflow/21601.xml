<bug id='21601' author='leandro-gracia-gil' open_date='2018-08-14T10:13:14Z' closed_time='2019-06-17T20:16:39Z'>
	<summary>Enqueuing tensors by value with tf.add no longer works on 1.10</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (see snippet below)
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): v1.10.0-0-g656e7a2 1.10.0
Python version: 3.5.2
Bazel version (if compiling from source): 0.16.0
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 9.2
GPU model and memory:
Exact command to reproduce: See below.

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

There seems to be a possible regression affecting the use of tf.add to enqueue tensors by value instead of by reference within a same device. Check the following snippet.
import tensorflow as tf

with tf.Session() as sess:
  v = tf.get_variable('v', shape=(), dtype=tf.int32)
  sess.run(v.assign(123))
  q = tf.FIFOQueue(10, tf.int32)
  sess.run(q.enqueue(tf.add(v, 0)))
  sess.run(v.assign(456))
  print(sess.run(q.dequeue()))
In previous versions of TensorFlow (last checked was probably 1.8) the above snippet returned 123 since the value of the variable was copied when enqueued thanks to the use of tf.add. However, on TensorFlow 1.10 the snippet returns 456 if using a tf.Session block and 123 if using a tf.InteractiveSession. Enabling or disabling GPU with CUDA_VISIBLE_DEVICES does not seem to affect.
Is this an intentional change of behavior? If so, is there any new or better way to enqueue tensors by value instead of by reference?
	</description>
	<comments>
		<comment id='1' author='leandro-gracia-gil' date='2018-08-16T07:23:18Z'>
		An update on this. It seems that the core problem is not in the behavior of tf.add or enqueuing, but rather in underlying optimizations regarding constant tensors. If in the snippet above I replace the enqueue line with this, it works fine:
sess.run(q.enqueue(tf.add(v, tf.placeholder_with_default(0, ()))))
I've also found a different scenario where this problem manifests: in shape deduction for ranges.
For example:
z = tf.zeros((), tf.int32)
tf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(2)]) in 1.10, returned TensorShape([Dimension(None)]) in 10.8

z = tf.placeholder_with_default(z, z.shape)
tf.range(0, 2 + z).shape  # Returns TensorShape([Dimension(None)])
So, it seems like using tf.placeholder_with_default is a viable solution for my immediate problem, but this is nevertheless exposing a behavioral change with possible subtle implications (like the enqueue case), and an API behavior inconsistency between tf.Session and tf.InteractiveSession. I leave up to you to decide what to do regarding this bug.
		</comment>
		<comment id='2' author='leandro-gracia-gil' date='2019-06-17T20:16:00Z'>
		alextp@ rmlarsen@ can either of you comment on this? Thanks.
		</comment>
		<comment id='3' author='leandro-gracia-gil' date='2019-06-17T20:16:38Z'>
		These problems disappear if you use resource variables, so closing as obsolete, as resource variables become default in tfv2.
		</comment>
		<comment id='4' author='leandro-gracia-gil' date='2019-06-17T20:16:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=21601&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=21601&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>