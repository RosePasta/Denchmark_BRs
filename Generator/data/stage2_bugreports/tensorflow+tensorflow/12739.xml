<bug id='12739' author='ghost(ghost)' open_date='2017-09-01T02:39:41Z' closed_time='2017-11-08T22:33:02Z'>
	<summary>TF 1.3 keras TimeDistributed wrapper issue - rnn() got an unexpected keyword argument 'input_length'</summary>
	<description>
When I use TimeDistributed  wrapper from keras I'm getting unexpected keyword argument 'input_length'
&lt;denchmark-h:h1&gt;System Info:&lt;/denchmark-h&gt;

Windows 10
TF 1.3.0
Python 3.5
Code :
import json

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.contrib.keras import layers
from tensorflow.contrib.keras.python.keras.layers.wrappers import TimeDistributed
from tensorflow.python.estimator.inputs import numpy_io

MAX_NB_WORDS = 200000
MAX_SEQUENCE_LENGTH = 25
EMBEDDING_DIM = 300
VALIDATION_SPLIT = 0.1
TEST_SPLIT = 0.1
RNG_SEED = 13371447
NB_EPOCHS = 25
DROPOUT = 0.1
BATCH_SIZE = 32

tf.logging.set_verbosity(tf.logging.INFO)

Q1_TRAINING_DATA_FILE = 'gen/q1_train.npy'
Q2_TRAINING_DATA_FILE = 'gen/q2_train.npy'
LABEL_TRAINING_DATA_FILE = 'gen/label_train.npy'
NB_WORDS_DATA_FILE = 'gen/nb_words.json'
with open(NB_WORDS_DATA_FILE, 'r') as f:
    nb_words = json.load(f)['nb_words']


def model_fn(features, labels, mode, params):
    input_data = features['x']

    Q1_Data = input_data[:, 0]
    Q2_Data = input_data[:, 1]

    q1 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q1_Data)
    q1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)
    q1 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q1)

    q2 = layers.Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)(Q2_Data)
    q2 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q2)
    q2 = layers.Lambda(lambda x: tf.reduce_max(x, axis=1, keep_dims=False))(q2)

    merged = layers.concatenate([q1, q2])
    # merged = layers.Flatten()(merged)
    merged = layers.Dense(200, activation='relu')(merged)
    merged = tf.layers.dropout(merged, rate=DROPOUT)
    merged = layers.Dense(200, activation='relu')(merged)
    merged = tf.layers.dropout(merged, rate=DROPOUT)
    merged = layers.Dense(200, activation='relu')(merged)
    merged = tf.layers.dropout(merged, rate=DROPOUT)
    merged = layers.Dense(200, activation='relu')(merged)
    merged = tf.layers.dropout(merged, rate=DROPOUT)

    predictions = layers.Dense(1)(merged)

    predictions = tf.reshape(predictions, [-1])

    train_op = None
    eval_metric_ops = None

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(
            mode=mode,
            predictions={"duplicate": predictions})

    loss = tf.losses.sigmoid_cross_entropy(labels, predictions)
    optimizer = tf.train.AdamOptimizer()
    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())

    eval_metric_ops = {
        "accuracy": tf.metrics.accuracy(labels, predictions)
    }

    print(predictions)

    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metric_ops)


print('\n')
print('Loading Numpy inputs')
q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))
q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))
labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))

X = np.stack((q1_data, q2_data), axis=1)
y = labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)

print('\n')
print('Preparing Numpy Input_Fn for both train and test')
train_input_fn = numpy_io.numpy_input_fn(x={'x': X_train}, y=y_train, shuffle=True, batch_size=BATCH_SIZE,
                                         num_epochs=None)

test_input_fn = numpy_io.numpy_input_fn(x={'x': X_test}, y=y_test, shuffle=False, batch_size=BATCH_SIZE, num_epochs=1)

nn = tf.estimator.Estimator(model_fn=model_fn, params=None, model_dir='build/')

print('\n')
print('Training...............')
nn.train(input_fn=train_input_fn, steps=100)

print('\n')
print('Training Complete, Evaluating............')
ev = nn.evaluate(input_fn=test_input_fn)
print("Loss: %s" % ev["loss"])
print("Accuracy: %s" % ev["accuracy"])
Exception:
Traceback (most recent call last):
File "D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py", line 103, in 
nn.train(input_fn=train_input_fn, steps=100)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\python\estimator\estimator.py", line 241, in train
loss = self._train_model(input_fn=input_fn, hooks=hooks)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\python\estimator\estimator.py", line 630, in _train_model
model_fn_lib.ModeKeys.TRAIN)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\python\estimator\estimator.py", line 615, in _call_model_fn
model_fn_results = self._model_fn(features=features, **kwargs)
File "D:/PlayGround/Git/Coding2Fun/Blog/DeepLearning/Quora-NLP/model.py", line 38, in model_fn
q1 = tf.contrib.keras.layers.TimeDistributed(layers.Dense(EMBEDDING_DIM, activation='relu'))(q1)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\keras\python\keras\engine\topology.py", line 396, in call
output = super(Layer, self).call(inputs, **kwargs)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\python\layers\base.py", line 450, in call
outputs = self.call(inputs, *args, **kwargs)
File "D:\Programs\Anaconda\envs\tensorflow\lib\site-packages\tensorflow\contrib\keras\python\keras\layers\wrappers.py", line 208, in call
unroll=False)
TypeError: rnn() got an unexpected keyword argument 'input_length'
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2017-09-04T01:32:03Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 It looks like a bug fix to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/contrib/keras/python/keras/layers/wrappers.py&gt;wrappers.py&lt;/denchmark-link&gt;
 made in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/fa83a270c943317da6b07a3d093c224be0827bd9&gt;fa83a27&lt;/denchmark-link&gt;
 might need to be cherry-picked onto r1.3.
		</comment>
		<comment id='2' author='ghost(ghost)' date='2017-11-08T22:33:02Z'>
		This has been fixed in the new release.
		</comment>
	</comments>
</bug>