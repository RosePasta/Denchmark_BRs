<bug id='28868' author='2649' open_date='2019-05-20T17:11:07Z' closed_time='2019-08-05T03:57:27Z'>
	<summary>tf.summary.image does not work with keras layers in tf 2.0 due to EagerExecution issues</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Official tf docker
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):No
TensorFlow version (use command below):2.0.0-alpha0
Python version: 3.5
CUDA/cuDNN version: 10.1
GPU model and memory:Titan V

I use tf.keras subclassing, but when I want to track the some images in my network, the error at the bottom of the post occurs. Initially,  I think the reason for the error is, that tf.summary.image becomes a normal Tensor as input, but needs an eagerTensor. If I create a random tensor in the summary function and evaluate the type it is an eagerTensor, but if I use a Tensor from a keras.layers.Layer class it evaluates to a normal Tensor and throws the error (you can try it in your code).
First I thought that the tf.dataset returns a non-eager tensor, but if I use a numpy array as input, the same error occurs as well. So the error might be caused by the keras.layer.Layer class.
The error occurs on GPU and CPU.
Working example
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

inp_arr_without_ds = np.random.rand(2, 200, 200, 3)

inp_arr_4_ds = np.random.rand(2, 2, 200, 200, 3)
tf_ds = tf.data.Dataset.from_tensor_slices((inp_arr_4_ds, inp_arr_4_ds))
tf_ds = tf_ds.map(lambda x, y: (x, y)).repeat(10).shuffle(10)

class random_model(tf.keras.Model):
    
    def __init__(self, name):
        super(random_model, self).__init__(name=name)
        self.conv_1 = tf.keras.layers.Conv2D(3, [3, 3], padding="same")
        self.tf_board_writer = tf.summary.create_file_writer("test")
        self.img_callback = [tf.keras.callbacks.LambdaCallback(on_epoch_end=self.save_img)]
        
    def call(self, inputs):
        self.initialized_layer = self.conv_1(inputs)
        return self.initialized_layer
    
    def save_img(self, epochs, logs):
        with self.tf_board_writer.as_default():
            # Does not work: type: class 'tensorflow.python.framework.ops.Tensor' 
            tf.summary.image("image", self.initialized_layer, step=epochs)
            
            # Does work type: class 'tensorflow.python.framework.ops.EagerTensor'
            #tf.summary.image("image", tf.random.uniform([2, 200, 200, 3]), step=epochs) 
            
    def compile_model(self):
        self.compile(tf.optimizers.Adam(0.001), tf.losses.mean_absolute_error)
    
    def fit_model_with_ds(self, ds):
        self.fit(ds, callbacks=self.img_callback)
        
    def fit_model_with_array(self, x, y):
        self.fit(x, y, callbacks=self.img_callback)

print(tf.__version__)        

# Both do not work
non_ds_model = random_model("non_ds") 
non_ds_model.compile_model()
non_ds_model.fit_model_with_array(inp_arr_without_ds, inp_arr_without_ds)
            
tf_ds_model = random_model("tf_ds")
tf_ds_model.compile_model()
tf_ds_model.fit_model_with_ds(tf_ds)
&lt;/denchmark-code&gt;


Error Message

&lt;denchmark-code&gt;&gt; 2.0.0-alpha0
&gt; 
&gt; ---------------------------------------------------------------------------
&gt; TypeError                                 Traceback (most recent call last)
&gt; &lt;ipython-input-25-0b5a4b30a43a&gt; in &lt;module&gt;
&gt;      39 non_ds_model = random_model("non_ds")
&gt;      40 non_ds_model.compile_model()
&gt; ---&gt; 41 non_ds_model.fit_model_with_array(inp_arr_without_ds, inp_arr_without_ds)
&gt;      42 
&gt;      43 tf_ds_model = random_model("tf_ds")
&gt; 
&gt; &lt;ipython-input-25-0b5a4b30a43a&gt; in fit_model_with_array(self, x, y)
&gt;      32 
&gt;      33     def fit_model_with_array(self, x, y):
&gt; ---&gt; 34         self.fit(x, y, callbacks=self.img_callback)
&gt;      35 
&gt;      36 print(tf.__version__)
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
&gt;     871           validation_steps=validation_steps,
&gt;     872           validation_freq=validation_freq,
&gt; --&gt; 873           steps_name='steps_per_epoch')
&gt;     874 
&gt;     875   def evaluate(self,
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
&gt;     406     if mode == ModeKeys.TRAIN:
&gt;     407       # Epochs only apply to `fit`.
&gt; --&gt; 408       callbacks.on_epoch_end(epoch, epoch_logs)
&gt;     409     progbar.on_epoch_end(epoch, epoch_logs)
&gt;     410 
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)
&gt;     288     logs = logs or {}
&gt;     289     for callback in self.callbacks:
&gt; --&gt; 290       callback.on_epoch_end(epoch, logs)
&gt;     291 
&gt;     292   def on_train_batch_begin(self, batch, logs=None):
&gt; 
&gt; &lt;ipython-input-25-0b5a4b30a43a&gt; in save_img(self, epochs, logs)
&gt;      20         with self.tf_board_writer.as_default():
&gt;      21             # Does not work: type: class 'tensorflow.python.framework.ops.Tensor'
&gt; ---&gt; 22             tf.summary.image("image", self.initialized_layer, step=epochs)
&gt;      23 
&gt;      24             # Does work type: class 'tensorflow.python.framework.ops.EagerTensor'
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorboard/plugins/image/summary_v2.py in image(name, data, step, max_outputs, description)
&gt;      71     encoded_images = tf.map_fn(tf.image.encode_png, limited_images,
&gt;      72                                dtype=tf.string,
&gt; ---&gt; 73                                name='encode_each_image')
&gt;      74     # Workaround for map_fn returning float dtype for an empty elems input.
&gt;      75     encoded_images = tf.cond(
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/map_fn.py in map_fn(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)
&gt;     226                                      dynamic_size=False,
&gt;     227                                      infer_shape=True)
&gt; --&gt; 228         for elem in elems_flat]
&gt;     229     # Unpack elements
&gt;     230     elems_ta = [
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/map_fn.py in &lt;listcomp&gt;(.0)
&gt;     226                                      dynamic_size=False,
&gt;     227                                      infer_shape=True)
&gt; --&gt; 228         for elem in elems_flat]
&gt;     229     # Unpack elements
&gt;     230     elems_ta = [
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/tensor_array_ops.py in __init__(self, dtype, size, dynamic_size, clear_after_read, tensor_array_name, handle, flow, infer_shape, element_shape, colocate_with_first_write_call, name)
&gt;    1036         element_shape=element_shape,
&gt;    1037         colocate_with_first_write_call=colocate_with_first_write_call,
&gt; -&gt; 1038         name=name)
&gt;    1039 
&gt;    1040     self._implementation.parent = weakref.ref(self)
&gt; 
&gt; /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/tensor_array_ops.py in __init__(***failed resolving arguments***)
&gt;     742     if isinstance(size, ops.EagerTensor):
&gt;     743       size = size.numpy()
&gt; --&gt; 744     self._tensor_array = [None for _ in range(size)]
&gt;     745 
&gt;     746   @property
&gt; 
&gt; TypeError: 'Tensor' object cannot be interpreted as an integer
&gt; 

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='2649' date='2019-05-21T06:46:53Z'>
		&lt;denchmark-link:https://github.com/2649&gt;@2649&lt;/denchmark-link&gt;
 Ran the provided code, it says NameError: name 'map_ds' is not defined. Please provide full reproducible code to investigate it further.
		</comment>
		<comment id='2' author='2649' date='2019-05-21T07:47:57Z'>
		&lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;
 Sorry, my bad. This was an old variable. Now you can run it.
		</comment>
		<comment id='3' author='2649' date='2019-05-21T08:40:41Z'>
		&lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;
 I investigated the problem further and when you evaluate  in every function, only the  function evaluates to . I am not sure if this is expected or not?
I also checked all tf.keras.base_layer descendant and their dynamic attribute, which all evaluate to False. When I set it to True for every instance via the **kwargs it throws the following error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-40-7c7316d7e638&gt; in &lt;module&gt;
     43 # Both do not work
     44 non_ds_model = random_model("non_ds")
---&gt; 45 non_ds_model.compile_model()
     46 non_ds_model.fit_model_with_array(inp_arr_without_ds, inp_arr_without_ds)
     47 

&lt;ipython-input-40-7c7316d7e638&gt; in compile_model(self)
     31 
     32     def compile_model(self):
---&gt; 33         self.compile(tf.optimizers.Adam(0.001), tf.losses.mean_absolute_error, target_tensor=tf.random.uniform([2, 200, 200, 3]))
     34 
     35     def fit_model_with_ds(self, ds):

/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    454     self._setattr_tracking = False  # pylint: disable=protected-access
    455     try:
--&gt; 456       result = method(self, *args, **kwargs)
    457     finally:
    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    278     self.sample_weight_mode = sample_weight_mode
    279     self._compile_weighted_metrics = weighted_metrics
--&gt; 280     if self.run_eagerly and target_tensors is not None:
    281       raise ValueError(
    282           'target_tensors argument is not supported when '

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in run_eagerly(self)
    506     else:
    507       if not context.executing_eagerly():
--&gt; 508         raise ValueError('Your model contains layers that can only be '
    509                          'successfully run in eager execution (layers '
    510                          'constructed with `dynamic=True`). '

ValueError: Your model contains layers that can only be successfully run in eager execution (layers constructed with `dynamic=True`). You must enable eager execution with `tf.enable_eager_execution()`.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='2649' date='2019-05-21T11:44:24Z'>
		&lt;denchmark-link:https://github.com/2649&gt;@2649&lt;/denchmark-link&gt;
 Able to reproduce the issue with th provided code.
TypeError: 'Tensor' object cannot be interpreted as an integer
		</comment>
		<comment id='5' author='2649' date='2019-07-31T14:09:17Z'>
		Any ideas?
		</comment>
		<comment id='6' author='2649' date='2019-07-31T23:25:49Z'>
		&lt;denchmark-link:https://github.com/2649&gt;@2649&lt;/denchmark-link&gt;
 I think there is some issue with your callback code that is giving the error. If I remove the callback function from  then there is no error. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/98cea0e3381567496b1dad4228fe4601/tf28868_keras_layers.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='2649' date='2019-08-01T10:48:06Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Yes this is correct. I already pointed it out in the first post. The tf 2.0 documentation recommends to use  to log image files. This function excepts an eager tensor. However, when you use keras to train your model,  it will build a static graph and the summary will throw the mentioned error.
		</comment>
		<comment id='8' author='2649' date='2019-08-05T03:57:27Z'>
		Thanks for reporting.
This is by design. tf.keras in 2.0 automatically wrap the call in tf.function (to accelerate computation), so output is symbolic tensor, which then you used for callbacks.
To make this work, there are two approaches:

use the regular model fit with Tensorboard callback, or tf.print (whichever works in your case)
compile the model with run_eagerly=True, so that output is EagerTensor instead of symbolic tensor.

		</comment>
		<comment id='9' author='2649' date='2019-08-05T03:57:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28868&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28868&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='2649' date='2019-08-05T08:13:04Z'>
		This issue is not resolved for me. I use the regular fit function with the tensorboard callback, but I still get the same error. Setting the run_eagerly parameter also does not help. I use the output from a convolutional layer as input to the image summary operation.
Is there anything else I should be aware of to make this work?
		</comment>
		<comment id='11' author='2649' date='2019-08-05T08:30:46Z'>
		I just switched from the keras compile and fit method to a custom training loop with gradient tape and wrap the computational parts in a . These are only few more lines of code, but you are very flexible. I'm very satisfied with this functionality. In between the  calls you can use the  api, because it returns eager tensors. I used this &lt;denchmark-link:https://www.tensorflow.org/beta/tutorials/generative/cvae&gt;tutorial&lt;/denchmark-link&gt;
.
But I can understand, that the keras training procedure is not suited for eager summary, because the focus is different.
		</comment>
		<comment id='12' author='2649' date='2019-08-05T15:15:18Z'>
		@mlippie If there is something not working with model.fit and callback, can you file another bug and include your code snippet?
		</comment>
		<comment id='13' author='2649' date='2019-09-07T14:39:57Z'>
		Hi &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
,
I tested with tensorflow-gpu 2.0.0-rc0 and still have this problem while using  with a  of a model

I follow the &lt;denchmark-link:https://www.tensorflow.org/tensorboard/r2/tensorboard_in_notebooks&gt;Using TensorBoard in Notebooks&lt;/denchmark-link&gt;
 . You can check &lt;denchmark-link:https://colab.research.google.com/drive/1HIe4EnwOomI0tC9vsVUcMX-zdbpV0QFU&gt;this notebook file&lt;/denchmark-link&gt;

In &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32034&gt;#32034&lt;/denchmark-link&gt;
 , I mentioned there was the easiest way to log image in keras layer using tensorflow version tf.1x
Now in tf.2x , everything is changed so I can't find the easist way to log image while training in tensorboard.
		</comment>
		<comment id='14' author='2649' date='2020-05-08T22:13:52Z'>
		@shaolinkhoa
Have you solved this problem?
		</comment>
		<comment id='15' author='2649' date='2020-05-09T12:41:58Z'>
		&lt;denchmark-link:https://github.com/fengyang0317&gt;@fengyang0317&lt;/denchmark-link&gt;

I'm sorry, I couldn't, therefore, I'm using Pytorch now.
		</comment>
		<comment id='16' author='2649' date='2020-05-13T17:32:16Z'>
		This issue should not be closed. Still experiencing this exact issue and the suggestions by &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 are not fixes.
		</comment>
		<comment id='17' author='2649' date='2020-05-15T18:40:10Z'>
		Still experiencing this issue in TF2.1 and TF2.2
		</comment>
		<comment id='18' author='2649' date='2020-05-29T20:08:50Z'>
		Just ran into this issue, tf.summary.image seems to not work with symbolic tensors. I'm trying to display output from a layer in my network.
		</comment>
	</comments>
</bug>