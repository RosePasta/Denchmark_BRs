<bug id='34989' author='zhangjh915' open_date='2019-12-10T09:08:54Z' closed_time='2019-12-17T02:28:30Z'>
	<summary>Dataset from TFRecord has unknown shapes.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 8
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0
Python version: 3.7.4
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0
GPU model and memory: 1080Ti 12G * 4

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
I follow the &lt;denchmark-link:https://www.tensorflow.org/tutorials/load_data/tfrecord&gt;tf2.0 tutorial&lt;/denchmark-link&gt;
 to generate and read the dataset into tf.Dataset. However, the read serialized record data has unknown shapes and unable to call  to use mirror strategy.
Note that I can load data normally using
for f0, f1, f2, f3 in train_dataset:
for single GPU training.
Describe the expected behavior
The loaded tf.Dataset should have correct shapes and be able to be distributed using strategy.experimental_distribute_dataset. The features all have fixed shapes, but I don't know how to define them.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;raw_train_dataset = tf.data.TFRecordDataset('path/to/the/record')

def read_tfrecord(serialized_example):
    feature_description = {
        'feature0': tf.io.FixedLenFeature([], tf.string),
        'feature1': tf.io.FixedLenFeature([], tf.string),
        'feature2': tf.io.FixedLenFeature([], tf.string),
        'feature3': tf.io.FixedLenFeature([], tf.string)
    }

    example = tf.io.parse_single_example(serialized_example, feature_description)
    f0 = tf.io.parse_tensor(example['feature0'], tf.uint8)
    f1 = tf.io.parse_tensor(example['feature1'], tf.float32)
    f2 = tf.io.parse_tensor(example['feature2'], tf.int16)
    f3 = tf.io.parse_tensor(example['feature3'], tf.uint8)

    return f0, f1, f2, f3

train_dataset = raw_train_dataset.map(read_tfrecord)
train_dataset = strategy.experimental_distribute_dataset(train_dataset)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Before running the last line of code, the printed train_dataset is
&lt;MapDataset shapes: (&lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;, &lt;unknown&gt;), types: (tf.uint8, tf.float32, tf.int16, tf.uint8)&gt;.
And after running the last line to distribute the dataset for mirror strategy, it raises an error ValueError: Cannot take the length of shape with unknown rank..
	</description>
	<comments>
		<comment id='1' author='zhangjh915' date='2019-12-11T06:01:30Z'>
		&lt;denchmark-link:https://github.com/zhangjh915&gt;@zhangjh915&lt;/denchmark-link&gt;

Looks like code is incomplete.Can you please help us with the simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='zhangjh915' date='2019-12-11T06:35:26Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 Thanks for the reply. I have created a toy program to reproduce the same issue as follows.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

# generate toy data
F0 = np.random.randint(2000, size=(100,20,1)).astype('uint8')
F1 = np.random.randint(1500, size=(100,3,5)).astype('float32')
F2 = np.random.randint(1600, size=(100,4,4)).astype('int16')
F3 = np.random.randint(2000, size=(100,20,1)).astype('uint8')

# this part is based on the tensorflow tutorial.
def _bytes_feature(value):
    """Returns a bytes_list from a string / byte."""""
    if isinstance(value, type(tf.constant(0))):
        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def serialize_example(feature0, feature1, feature2, feature3):
    """
    Creates a tf.Example message ready to be written to a file.
    """
    # Create a dictionary mapping the feature name to the tf.Example-compatible
    # data type.
    feature0 = tf.io.serialize_tensor(feature0)
    feature1 = tf.io.serialize_tensor(feature1)
    feature2 = tf.io.serialize_tensor(feature2)
    feature3 = tf.io.serialize_tensor(feature3)
    feature = {
               'feature0': _bytes_feature(feature0),
               'feature1': _bytes_feature(feature1),
               'feature2': _bytes_feature(feature2),
               'feature3': _bytes_feature(feature3)
              }

    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
    return example_proto.SerializeToString()

def tf_serialize_example(f0, f1, f2, f3):
    tf_string = tf.py_function(
            serialize_example,
            (f0, f1, f2, f3),
            tf.string
            )
    return tf.reshape(tf_string, ())

train_dataset = tf.data.Dataset.from_tensor_slices((F0,F1,F2,F3))
serialized_train_dataset = train_dataset.map(tf_serialize_example)

def generator_train():
    for features in train_dataset:
        yield serialize_example(*features)

serialized_train_dataset = tf.data.Dataset.from_generator(
        generator_train, output_types=tf.string, output_shapes=())

# write data into tfrecord, please modify the path
writer_train = tf.data.experimental.TFRecordWriter('/tfrecord_path/sample.tfrecord')
writer_train.write(serialized_train_dataset)

# read saved tfrecord
raw_train_dataset = tf.data.TFRecordDataset('/tfrecord_path/sample.tfrecord')

# this part is based on the tutorial as well
def read_tfrecord(serialized_example):
    feature_description = {
            'feature0': tf.io.FixedLenFeature([], tf.string),
            'feature1': tf.io.FixedLenFeature([], tf.string),
            'feature2': tf.io.FixedLenFeature([], tf.string),
            'feature3': tf.io.FixedLenFeature([], tf.string)
            }

    example = tf.io.parse_single_example(serialized_example, feature_description)
    f0 = tf.io.parse_tensor(example['feature0'], tf.uint8)
    f1 = tf.io.parse_tensor(example['feature1'], tf.float32)
    f2 = tf.io.parse_tensor(example['feature2'], tf.int16)
    f3 = tf.io.parse_tensor(example['feature3'], tf.uint8)

    return f0, f1, f2, f3

train_dataset = raw_train_dataset.map(read_tfrecord)
print(train_dataset)  # here the shapes would be printed out as &lt;unknown&gt;
strategy = tf.distribute.MirroredStrategy()
train_dataset = strategy.experimental_distribute_dataset(train_dataset)  # it will raise error here
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='zhangjh915' date='2019-12-11T08:32:31Z'>
		I have tried on colab with TF version 2.0,2.1.0-rc0 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/572ac2bf82b49dcc57cbad82a0ca0e35/untitled463.ipynb&gt;here.&lt;/denchmark-link&gt;
 Thanks!
		</comment>
		<comment id='4' author='zhangjh915' date='2019-12-16T18:25:46Z'>
		&lt;denchmark-link:https://github.com/aaudiber&gt;@aaudiber&lt;/denchmark-link&gt;
 could you please take a look
		</comment>
		<comment id='5' author='zhangjh915' date='2019-12-16T21:11:07Z'>
		Hi &lt;denchmark-link:https://github.com/zhangjh915&gt;@zhangjh915&lt;/denchmark-link&gt;
,
The shapes are unknown because the  function can't statically determine the shape of the parsed tensor. If you know the shape, you can use &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/ensure_shape?version=stable&gt;ensure_shape&lt;/denchmark-link&gt;
 to help with shape inference.
&lt;denchmark-code&gt;tensor = tf.ensure_shape(tensor, shape)
&lt;/denchmark-code&gt;

In your code it would look like
&lt;denchmark-code&gt;    f0 = tf.ensure_shape(tf.io.parse_tensor(example['feature0'], tf.uint8), ())
    f1 = tf.ensure_shape(tf.io.parse_tensor(example['feature1'], tf.float32), ())
    f2 = tf.ensure_shape(tf.io.parse_tensor(example['feature2'], tf.int16), ())
    f3 = tf.ensure_shape(tf.io.parse_tensor(example['feature3'], tf.uint8), ())
&lt;/denchmark-code&gt;

Setting the shapes reveals the real problem; that &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy?version=stable#experimental_distribute_dataset&gt;experimental_distribute_dataset&lt;/denchmark-link&gt;
 expects the input dataset to be batched.
The docs for experimental_distribute_dataset mention this.

We will assume that the input dataset is batched by the global batch size. With this assumption, we will make a best effort to divide each batch across all the replicas (one or more workers).

		</comment>
		<comment id='6' author='zhangjh915' date='2019-12-17T02:28:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34989&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34989&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='zhangjh915' date='2020-09-23T07:07:36Z'>
		I'm not sure this must be filed as a separate issue:
If using TFRecords to store training data is to be simple and robust, having to manually serialize and parse tensors is already getting our hands quite dirty with the code. Using tf.ensure_shape every time as suggested by &lt;denchmark-link:https://github.com/zhangjh915&gt;@zhangjh915&lt;/denchmark-link&gt;
 only worsens this. Will the whole functionality of saving and loading datasets get a major revamp to take care of such checks automatically and overall, make the process of loading and saving datasets simpler?
		</comment>
		<comment id='8' author='zhangjh915' date='2020-09-23T17:29:43Z'>
		&lt;denchmark-link:https://github.com/dinesh110598&gt;@dinesh110598&lt;/denchmark-link&gt;
 I like the idea of improving type/shape inference so that users don't need to specify types/shapes if they don't want to. However, this doesn't seem possible for TFRecords since they can contain arbitrary bytes. If we want to automatically infer types/shapes, we need a new format that stores type/shape information at the start of the file.
		</comment>
	</comments>
</bug>