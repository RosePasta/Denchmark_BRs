<bug id='10408' author='Caselles' open_date='2017-06-02T21:55:39Z' closed_time='2019-09-06T04:38:06Z'>
	<summary>Memory leak</summary>
	<description>
I have a memory leak with TensorFlow. I refered to &lt;denchmark-link:https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session&gt;https://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-session&lt;/denchmark-link&gt;
 to address my issue, and I followed the advices of the answer, that seemed to have solved the problem. However it does not work here.
In order to recreate the memory leak, I have created a simple example. First, I use this function (that I got here : &lt;denchmark-link:https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python&gt;https://stackoverflow.com/questions/276052/how-to-get-current-cpu-and-ram-usage-in-python&lt;/denchmark-link&gt;
) to check the memory use of the python process :
&lt;denchmark-code&gt;def memory():
    import os
    import psutil
    pid = os.getpid()
    py = psutil.Process(pid)
    memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think
    print('memory use:', memoryUse)
&lt;/denchmark-code&gt;

Then, everytime I call the build_model function, the use of memory increases.
Here is the build_model function that has a memory leak :
&lt;denchmark-code&gt;def build_model():

    '''Model'''

    tf.reset_default_graph()


    with tf.Graph().as_default(), tf.Session() as sess:
        tf.contrib.keras.backend.set_session(sess)

        labels = tf.placeholder(tf.float32, shape=(None, 1))
        input = tf.placeholder(tf.float32, shape=(None, 1))

        x = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense1')(input)
        x1 = tf.contrib.keras.layers.Dropout(0.5)(x)
        x2 = tf.contrib.keras.layers.Dense(30, activation='relu', name='dense2')(x1)
        y = tf.contrib.keras.layers.Dense(1, activation='sigmoid', name='dense3')(x2)


        loss = tf.reduce_mean(tf.contrib.keras.losses.binary_crossentropy(labels, y))

        train_step = tf.train.AdamOptimizer(0.004).minimize(loss)

        #Initialize all variables
        init_op = tf.global_variables_initializer()
        sess.run(init_op)

        sess.close()

    tf.reset_default_graph()

    return 
&lt;/denchmark-code&gt;

I would have thought that using the block with tf.Graph().as_default(), tf.Session() as sess: and then closing the session and calling tf.reset_default_graph would clear all the memory used by TensorFlow. Apparently it does not.
The memory leak can be recreated as following :
&lt;denchmark-code&gt;memory()
build_model()
memory()
build_model()
memory()
&lt;/denchmark-code&gt;

The output of this is (for my computer) :
&lt;denchmark-code&gt;memory use: 0.1794891357421875
memory use: 0.184417724609375
memory use: 0.18923568725585938
&lt;/denchmark-code&gt;

Clearly we can see that all the memory used by TensorFlow is not freed afterwards. Why?
I hope I made myself clear.
	</description>
	<comments>
		<comment id='1' author='Caselles' date='2017-06-03T00:22:56Z'>
		Would you be able to plot memory usage over a thousand iterations? That will help us rule out the possibility that the memory usage is caused by modules being loaded, or garbage collector fanciness. It would also be great if you could narrow down the number of APIs being called.
		</comment>
		<comment id='2' author='Caselles' date='2017-06-03T13:01:53Z'>
		&lt;denchmark-link:https://cloud.githubusercontent.com/assets/19774802/26753716/0e980254-486d-11e7-9ac8-4f57150b7815.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/jart&gt;@jart&lt;/denchmark-link&gt;
 Here you go. As you can see, the memory usage goes up in a linear way, which is exactly the problem.
About the number of APIs being called, do you refer to Keras by saying that ? I only use tf.contrib.keras, which is part of tensorflow. Hence I only use tensorflow here.
		</comment>
		<comment id='3' author='Caselles' date='2017-06-03T20:37:33Z'>
		&lt;denchmark-link:https://github.com/Caselles&gt;@Caselles&lt;/denchmark-link&gt;
 Excellent. Thank you.
&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 There appears to be some type of memory leak in Keras.
		</comment>
		<comment id='4' author='Caselles' date='2017-06-05T15:43:08Z'>
		Early tests seems to show that
_GRAPH_LEARNING_PHASES is not cleared so there is tons of tensors that get kept.
Changing to def reset_uids(): global _GRAPH_UID_DICTS global _GRAPH_LEARNING_PHASES _GRAPH_UID_DICTS = {} _GRAPH_LEARNING_PHASES = {}
Seems to resolve the problem.

memory use: 0.13166046142578125
memory use: 0.13190841674804688
memory use: 0.13220977783203125
memory use: 0.13220977783203125
memory use: 0.13220977783203125
memory use: 0.13220977783203125
memory use: 0.13220977783203125
memory use: 0.13220977783203125

Will do a PR on keras, it will then get merged into TF I guess?
		</comment>
		<comment id='5' author='Caselles' date='2017-06-05T16:12:18Z'>
		This is actually fixed in keras master branch.
&lt;denchmark-link:https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L82&gt;https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L82&lt;/denchmark-link&gt;

So waiting for the merge will fix the problem.
		</comment>
		<comment id='6' author='Caselles' date='2017-06-05T17:42:23Z'>
		&lt;denchmark-link:https://github.com/Dref360&gt;@Dref360&lt;/denchmark-link&gt;
 this is fixed in TF master: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/keras/python/keras/backend.py#L288&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/keras/python/keras/backend.py#L288&lt;/denchmark-link&gt;

Does this resolve the problem?
		</comment>
		<comment id='7' author='Caselles' date='2017-06-05T17:50:10Z'>
		K.clear_session is never called. maybe K.set_session should do a clear_session?
		</comment>
		<comment id='8' author='Caselles' date='2017-06-05T18:56:02Z'>
		Before posting this issue, I tried calling K.clear_session(), but my tensorflow version was 1.1... Never lucky. By upgrading to 1.2 and calling K.clear_session(), the problem was solved. Thank you very much üëç
		</comment>
		<comment id='9' author='Caselles' date='2017-06-05T19:02:42Z'>
		Independently of clear_session, I would expect the use of graph scopes to prevent this behavior. What's the status of that?
		</comment>
		<comment id='10' author='Caselles' date='2017-06-06T14:16:45Z'>
		The graph is not cleared. Maybe because we still have a reference to it so the GC doesn't collect?
If you print list(_GRAPH_LEARNING_PHASES.values())[1].graph.get_operations() you can see that the operations are still there.
		</comment>
		<comment id='11' author='Caselles' date='2017-06-11T10:26:39Z'>
		So the use of graph scopes will not prevent this behavior. Is this planned to be solved ?
&lt;denchmark-link:https://github.com/Dref360&gt;@Dref360&lt;/denchmark-link&gt;
 : Would you have a workaround to clear the operations still in the graph ? I would like  to clear all the operations in the graph, but only those that are created within the  block.
&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jart&gt;@jart&lt;/denchmark-link&gt;
 : Can you provide a solution for this problem ?
		</comment>
		<comment id='12' author='Caselles' date='2017-06-12T17:50:58Z'>
		The solution is to make learning phases part of a graph collection, I believe. Potentially the same may also be true of layer name UIDs, which also keeps graph references.
Last time we tried this it caused a useless warning upon graph serialization which annoyed/scared users. We will also have to figure out how to remove that warning.
		</comment>
		<comment id='13' author='Caselles' date='2017-06-12T18:05:55Z'>
		Ok thank you. Would you have a workaround for now ? In order to clear only the operations within the with tf.Graph().as_default(), tf.Session() as sess: block.
		</comment>
		<comment id='14' author='Caselles' date='2017-06-12T18:10:24Z'>
		Add K.clear_session() at the end of your block (inside the block).
		</comment>
		<comment id='15' author='Caselles' date='2017-06-13T17:55:16Z'>
		Problem is, I'm trying to run two model at the same time in a website. Hence, calling K.clear_session in the code clears operations that are used elsewhere. So this creates a bug. I really need to be able to specify the operations that I want to clear. Could you be a little more precise on how I could do that ?
		</comment>
		<comment id='16' author='Caselles' date='2017-06-13T18:27:48Z'>
		There are only two possibilities:
1) you no longer use the graph. In that case `clear_session` destroys it,
and that is what you want.
2) you are still using the graph. In that case you cannot garbage-collect
it. And you don't have a "memory leak".
&lt;denchmark-link:#&gt;‚Ä¶&lt;/denchmark-link&gt;


On 13 June 2017 at 11:01, Syzygy ***@***.***&gt; wrote:
 Problem is, I'm trying to run two model at the same time in a website.
 Hence, calling K.clear_session in the code clears operations that are
 used elsewhere. So this creates a bug. I really need to be able to specify
 the operations that I want to clear. Could you be a little more precise on
 how I could do that ?

 ‚Äî
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#10408 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AArWb8x5Gi6WMApi-ZjfF8000k-dLIhSks5sDs5mgaJpZM4Nu1dH&gt;
 .



		</comment>
		<comment id='17' author='Caselles' date='2017-06-13T19:58:11Z'>
		I'm sorry for not saying that earlier but calling K.clear_session() within the tf.Graph().as_default(), tf.Session() as sess: yields an error :
IndexError                                Traceback (most recent call last)
 in ()
----&gt; 1 build_model()
 in build_model()
31
32         K.set_session(sess)
---&gt; 33         K.clear_session()
34
35     tf.reset_default_graph()
/Users/Syzygy/anaconda/lib/python3.5/contextlib.py in exit(self, type, value, traceback)
75                 value = type()
76             try:
---&gt; 77                 self.gen.throw(type, value, traceback)
78                 raise RuntimeError("generator didn't stop after throw()")
79             except StopIteration as exc:
/Users/Syzygy/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in get_controller(self, default)
3626     finally:
3627       if self._enforce_nesting:
-&gt; 3628         if self.stack[-1] is not default:
3629           raise AssertionError(
3630               "Nesting violated for default stack of %s objects"
IndexError: list index out of range
		</comment>
		<comment id='18' author='Caselles' date='2017-06-29T18:42:21Z'>
		has there been any progress on this issue? I have the exact same problem, and exact same error while calling clear_session. I'm using the latest keras and tensorflow version.
		</comment>
		<comment id='19' author='Caselles' date='2017-10-23T20:33:02Z'>
		I have a very similar issue causing memory leak, but I'm only using tensorflow without keras. Here's the minimal code:
import tensorflow as tf
import numpy as np
for i in range(30):
tf.Session().enter()
tf.constant(np.random.random((800,500,500,1)))
tf.get_default_session().close()
tf.reset_default_graph()
When executing the loop the memory used keeps going up. How can I actually delete the old large constants and free the memory?
I'm using tensorflow 1.2 with python 3.4 on ubuntu 14.04
		</comment>
		<comment id='20' author='Caselles' date='2018-05-25T08:13:40Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 Perhaps, everyone is in trouble with this bug. Do not forget.
		</comment>
		<comment id='21' author='Caselles' date='2018-06-03T10:57:57Z'>
		I am getting the same issue with multiple models prediction, either in sequential or in parallel execution. The memory doesn't seem to free the memory after use.
		</comment>
		<comment id='22' author='Caselles' date='2018-07-23T08:06:43Z'>
		I recently resolved my model's "memory leak" issue, it turns out to be a counter-paradigm of how to construct and run the model(i.e various TensorOps)...
I mistakenly added &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/train/cosine_decay_restarts&gt;cosine_decay_restarts&lt;/denchmark-link&gt;
 ops in every iteration of the training, something like:
&lt;denchmark-code&gt;while ... :
    ....
    dlr = tf.train.cosine_decay_restarts(
            learning_rate=LEARNING_RATE,
            global_step=cur_step,
            first_decay_steps=LR_DECAY_STEPS,
            t_mul=1.0,
            m_mul=1.0,
            alpha=LEARNING_RATE_ALPHA
        )
    lr = sess.run([dlr], feed_dict={cur_step: bno-DECAYED_LR_START})[0]
    ...
    #train the model using the decayed learning rate
&lt;/denchmark-code&gt;

And the training python process would get killed by the OOM killer at some point.
My instincts told me I shouldn't re-construct the train.cosine_decay_restarts in every loop, so after this simple remedy, the "memory leak" issue was gone...
&lt;denchmark-code&gt;dlr = tf.train.cosine_decay_restarts(
    learning_rate=LEARNING_RATE,
    global_step=cur_step,
    first_decay_steps=LR_DECAY_STEPS,
    t_mul=1.0,
    m_mul=1.0,
    alpha=LEARNING_RATE_ALPHA
)
...
while ... :
    ...
    lr = sess.run([dlr], feed_dict={cur_step: bno-DECAYED_LR_START})[0]
    ...
    #train the model using the decayed learning rate
&lt;/denchmark-code&gt;

So maybe everybody could make a coarse check of whether you are re-constructing the model in every loop...
		</comment>
		<comment id='23' author='Caselles' date='2018-08-09T14:01:28Z'>
		Hello,
I am also having a problem with memory leak on running label image logic in a loop
I use Tensorflow r1.0.1 and opencv 2.4.9
I am not sure yet if memory leak is opencv related or tensorflow related.
In some posts, seems that capture.read() can lead to memory leak(opencv related),  in other posts could be because of operators initialization inside loop(tensorflow related)
Below part of my code, I would appreciate if smo can check the code inside the loop in case there is smth obvious I should change to avoid memory leak, thank you in advance
`with tf.Session('',graph=graph, config=tf.ConfigProto(inter_op_parallelism_threads=1,intra_op_parallelism_threads=1)) as sess:
ret, frame = cap.read()
file_name = '...png'
if frame is not None:
&lt;denchmark-code&gt;  cv2.imwrite(file_name,frame)

 input_name = "file_reader"

 output_name = "normalized"

 file_reader = tf.read_file(file_name, input_name)

 if file_name.endswith(".png"):

  image_reader = tf.image.decode_png(file_reader, channels = 3, name='png_reader')

 float_caster = tf.cast(image_reader, tf.float32)

 dims_expander = tf.expand_dims(float_caster, 0)


 resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])

 normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])

 t = sess.run(normalized)

 results = sess.run(output_operation.outputs[0],
                  {input_operation.outputs[0]: t})

 results = np.squeeze(results)

 top_k = results.argsort()[-1:][::-1]

 labels = load_labels(label_file)
&lt;/denchmark-code&gt;

...
`
I am going to upgrade also opencv now in my system. Do you think I should upgrade also Tensorflow version. To be honest, I would keep same version of tensorflow in order to use .pb graph already generated because I am not sure if my .pb will be compatible with newer versions.
Any suggestions to overcome memory leak problem and find what really causes this will be very helpful.
Thank you,
		</comment>
		<comment id='24' author='Caselles' date='2018-10-31T04:41:37Z'>
		I have the same issue. Just by running the same code again, the memory doesn't seem to get freed by clear_session. Below is my code. Please help!
`import keras
from keras.applications.vgg16 import VGG16
vgg16_model = VGG16()
model = Sequential()
for layer in vgg16_model.layers[:-1]:
model.add(layer)
model.summary()
for layer in model.layers:
layer.trainable = False
model.add(Dense(2,activation='softmax'))
model.summary()
K.clear_session()
K.reset_uids()`
		</comment>
		<comment id='25' author='Caselles' date='2019-05-06T00:35:01Z'>
		
Problem is, I'm trying to run two model at the same time in a website. Hence, calling K.clear_session in the code clears operations that are used elsewhere. So this creates a bug. I really need to be able to specify the operations that I want to clear. Could you be a little more precise on how I could do that ?

Dear sir. How did you resovle your issue? I have the same issue.  Thx.  &lt;denchmark-link:https://github.com/Caselles&gt;@Caselles&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='Caselles' date='2019-05-06T03:02:08Z'>
		You might find some useful info here: &lt;denchmark-link:https://stackoverflow.com/questions/44327803/memory-leak-with-tensorflow&gt;https://stackoverflow.com/questions/44327803/memory-leak-with-tensorflow&lt;/denchmark-link&gt;

		</comment>
		<comment id='27' author='Caselles' date='2019-05-07T00:31:45Z'>
		Dear sir. Thank you for your reply. As you can see, calling K.clear_session in the code clears all graphs, however, I just want to clear one of them. Thx. &lt;denchmark-link:https://github.com/Caselles&gt;@Caselles&lt;/denchmark-link&gt;

		</comment>
		<comment id='28' author='Caselles' date='2019-07-27T04:45:31Z'>
		Leaving this here so I remember to come back Monday and write out a work-around for the memory leak inside a loop issue using Keras.
		</comment>
		<comment id='29' author='Caselles' date='2019-08-28T22:06:18Z'>
		&lt;denchmark-link:https://github.com/Caselles&gt;@Caselles&lt;/denchmark-link&gt;
 Is this still an issue? I tried you code with  and could not reproduce the issue. I have used  and . The memory usage is almost constant.
&lt;denchmark-code&gt;for i in range(1000):
  memory()
  K.get_session()
  build_model()
  K.clear_session()
  memory()
  K.get_session()
  build_model()
  K.clear_session()
&lt;/denchmark-code&gt;

Output is
&lt;denchmark-code&gt;memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7448959350585938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
memory use: 0.7444076538085938
&lt;/denchmark-code&gt;

Please let me know what you think? Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/1445ddf65ab642ffb7e502e6260f5482/tf_10408_keras_runtime.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='30' author='Caselles' date='2019-09-06T04:38:05Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='31' author='Caselles' date='2019-09-06T04:38:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=10408&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=10408&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>