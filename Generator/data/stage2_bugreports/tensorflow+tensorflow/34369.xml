<bug id='34369' author='songs18' open_date='2019-11-18T07:35:21Z' closed_time='2020-07-15T12:40:28Z'>
	<summary>TF2 Warning :  Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.</summary>
	<description>
When i compute grads by tf.GradientTape, console presents  a warning : Sets are not currently considered sequences, but this may change in future, so consider avoiding using them. My code is like this
import tensorflow as tf
import numpy as np
import logging

logging.basicConfig(format='%(message)s', level=logging.INFO)

input = np.array([[0.1, 0], [0, 0.1]], np.float32)
target = np.array([1, 0], np.float32)


class layer(tf.Module):
    def __init__(self):
        super(layer, self).__init__()
        with self.name_scope:
            self.w1 = tf.Variable(tf.ones([2, 2]), name='w1')

    @tf.Module.with_name_scope
    def __call__(self, x):
        return tf.nn.tanh(x * self.w1)


def get_loss(pred, y_):
    return tf.losses.binary_crossentropy(pred, y_)


def get_opti():
    return tf.optimizers.SGD()


my_layer = layer()

optimizer = get_opti()

for _ in range(2):
    for x_, y_ in zip(input, target):
        with tf.GradientTape() as tape:
            pred = my_layer(x_)

            loss = get_loss(pred, y_)
        grads = tape.gradient(loss, my_layer.trainable_variables )
        optimizer.apply_gradients(zip(grads, my_layer.trainable_variables ))


print('-----------')
print(my_layer.w1.numpy())
&lt;denchmark-link:https://user-images.githubusercontent.com/47944452/69391681-8a58cc80-0d0e-11ea-9b73-f35742116387.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='songs18' date='2019-11-19T05:54:49Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, Please provide the complete code and the Tensorflow version. Thanks!
		</comment>
		<comment id='2' author='songs18' date='2019-11-19T08:23:10Z'>
		Duplicate of #
The code is very simple, it contains just single hidden layer. In the following code, train_x refers input x, ground_truth is the correct label. I am doing a classification task.
` with tf.GradientTape() as tape:
pred,w = model(train_x)
loss_pred = compute_loss(ground_truth, pred)
&lt;denchmark-code&gt;    grads = tape.gradient(loss_pred, model.trainable_variables)

     optimizer.apply_gradients(zip(grads, model.trainable_variables))`
&lt;/denchmark-code&gt;

The version of tensorflow  is v2.0.0.
Note: When i use v2.0.0 release version, there is no warning, but i update it to the lastest version, it appears the W:
2019-11-19 15:55:58.350407: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
I looked the util.cc in tensorflow source code, it is likely the parameter of the tape.gradient() input could change in future. But i don't know how to write the compute gradient code is the best way.
Thanks!
		</comment>
		<comment id='3' author='songs18' date='2019-11-20T08:56:28Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, Just to verify, Did you update the latest version using
 ?
		</comment>
		<comment id='4' author='songs18' date='2019-11-20T09:45:44Z'>
		my tensorflow is actually the lastest version, i tried -U, the warning remains.
		</comment>
		<comment id='5' author='songs18' date='2019-11-21T08:47:08Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, Can you add the complete code which generates this warning? It's hard to say whether it's important without knowing what you were trying to do. It will indeed help us to move faster. Thanks!
		</comment>
		<comment id='6' author='songs18' date='2019-11-22T01:58:14Z'>
		To run any tf2 script will reproduce the warning, so i do not provide the whole code but just the exact code snippet, if you need the whole code, i can provide a simple verison.
import tensorflow as tf
import numpy as np
import logging

logging.basicConfig(format='%(message)s', level=logging.INFO)

input = np.array([[0.1, 0], [0, 0.1]], np.float32)
target = np.array([1, 0], np.float32)


class layer(tf.Module):
    def __init__(self):
        super(layer, self).__init__()
        with self.name_scope:
            self.w1 = tf.Variable(tf.ones([2, 2]), name='w1')

    @tf.Module.with_name_scope
    def __call__(self, x):
        return tf.nn.tanh(x * self.w1)


def get_loss(pred, y_):
    return tf.losses.binary_crossentropy(pred, y_)


def get_opti():
    return tf.optimizers.SGD()


my_layer = layer()

optimizer = get_opti()

for _ in range(2):
    for x_, y_ in zip(input, target):
        with tf.GradientTape() as tape:
            pred = my_layer(x_)

            loss = get_loss(pred, y_)
        grads = tape.gradient(loss, my_layer.trainable_variables )
        optimizer.apply_gradients(zip(grads, my_layer.trainable_variables ))


print('-----------')
print(my_layer.w1.numpy())
&lt;denchmark-link:https://user-images.githubusercontent.com/47944452/69391681-8a58cc80-0d0e-11ea-9b73-f35742116387.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='songs18' date='2019-11-22T02:04:28Z'>
		From the warning info, the code can work now, but cannot promise in future, i want to write right code which meet the tf recommends, unfortunately, i do not get help from tf website, i want to know how to write code to eliminate the warning.
Thanks!
		</comment>
		<comment id='8' author='songs18' date='2019-11-27T11:13:05Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, Thanks for the code, I tried replicating the reported issue but looks like code is not intended correctly. Please take a look at &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/08de511173260cc94e849e9a0ea1e5bc/untitled273.ipynb&gt;gist&lt;/denchmark-link&gt;
 and modify accordingly. Thanks!
		</comment>
		<comment id='9' author='songs18' date='2019-11-30T06:47:08Z'>
		Thanks for your patient, unfortunately, i can not open the gist link as i am in China and i cannot use Google any service, i post my snippet in &lt;denchmark-link:https://gitee.com/songhaohao2018/codes/01nbm4guh5dtlx8opy7fi31&gt;Gitee&lt;/denchmark-link&gt;
 which is one webiset like github in China.
		</comment>
		<comment id='10' author='songs18' date='2019-12-03T10:44:53Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, The warnings are about Tensorflow support for AVX instruction sets.
&lt;denchmark-code&gt;TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.
Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.
&lt;/denchmark-code&gt;

For more read &lt;denchmark-link:https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements&gt;here&lt;/denchmark-link&gt;
. Your code is good to go, warnings can be ignored. Thanks!
		</comment>
		<comment id='11' author='songs18' date='2019-12-03T11:42:20Z'>
		Thanks. I read the page, unfortunately, i do not understand how AVX causes the warning, could you provide a detailed explain? What is the relationship between AVX and the warning?
		</comment>
		<comment id='12' author='songs18' date='2019-12-05T11:10:16Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
, If you use pip version of tensorflow, which means it's already compiled and you are just installing it. When you download it from repository and trying to build, you should build it with CPU AVX support. If you ignore it, you will get the warning every time when you run on cpu.
If you don't want to get these warnings, You can turn it off by setting os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'.
		</comment>
		<comment id='13' author='songs18' date='2019-12-12T01:04:33Z'>
		Thanks.
I know that AVX could cause the warning ' Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',  and my question is not this one.
'Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them'  occured during computing derivative and applying gradient, how AVX cuase this warning? Is there any relationship between AVX and computing derivative and applying gradient?
Thanks for your long time patient and help !!
		</comment>
		<comment id='14' author='songs18' date='2020-04-15T03:55:22Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
 解决了吗?
		</comment>
		<comment id='15' author='songs18' date='2020-05-03T07:55:23Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 any explanation on why the warning is there??
		</comment>
		<comment id='16' author='songs18' date='2020-05-19T05:57:34Z'>
		I can trace the warning down to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/module/module.py#L338&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/module/module.py#L338&lt;/denchmark-link&gt;
 where we pass in a set() to nest.flatten which triggers the warning. I don't think this is something you need to really worry about. Assigning to Tom who wrote tf.Module
		</comment>
		<comment id='17' author='songs18' date='2020-06-22T06:13:50Z'>
		I'm seeing the same error in TF2.2 in Python 3.7 on MacOS.
&lt;denchmark-code&gt;2020-06-21 23:12:15.321826: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /Users/.../anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.

&lt;/denchmark-code&gt;

Error depends on this line.  The error dissappears when this line is commented.
model.save(os.path.join(run_dir, f'model_{run_dirname}_keras_best'), save_format='tf') 
I agree that the error is probably not harmful, but it is annoying.
		</comment>
		<comment id='18' author='songs18' date='2020-07-14T14:17:42Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;

I ran the code on tf nightly and do not see nay warnings,please have a look at the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/99b833665239d84bc2568930506699ec/untitled268.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Could you please confirm and let us know.
		</comment>
		<comment id='19' author='songs18' date='2020-07-15T01:00:45Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

This issue occurred at tensorflow  v2.0.0.
I see you installed tf-nightly-2.4.0.dev20200714 in the given gist.
		</comment>
		<comment id='20' author='songs18' date='2020-07-15T01:05:50Z'>
		I am still seeing it on 2.3.0-rc0 and on a recent 2.4-nightly as well.
Here is the full error message from a run last night with 2.3.0-rc0.
Personally, I can't tell if this is one error or two that overlap.
&lt;denchmark-code&gt;WARNING:tensorflow:From /Users/.../anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-07-12 22:57:22.189856: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /Users/.../anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.

&lt;/denchmark-code&gt;

I will note that it is impossible for me to tell where this error message is coming from.  It does seem to show up as soon as I execute model.fit(...).
		</comment>
		<comment id='21' author='songs18' date='2020-07-15T08:10:52Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;

I have verified on colab for 2.0 as well, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/85d4d135c772ddcdb7d01a0537dbcad2/untitled265.ipynb&gt;gist here&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/kevinashaw&gt;@kevinashaw&lt;/denchmark-link&gt;

Can you please let us know where are you seeing these warnings.
		</comment>
		<comment id='22' author='songs18' date='2020-07-15T08:26:30Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

As best I can tell if occurs during the  operation.
In particular, it occurs between the start of the operation and before the first  statement.
Tensorflow graph messages are always cryptic since it is almost impossible to tell where in the graph the error occurred.
		</comment>
		<comment id='23' author='songs18' date='2020-07-15T12:40:24Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/kevinashaw&gt;@kevinashaw&lt;/denchmark-link&gt;

Thanks.
After a few months, I reviewed the code again and found the problem.
This warning occurs when the shape of the model output does not match with the ground_truth labels. Although it can be broadcasted.
However, the warning given is obscure and it can be better described.
		</comment>
		<comment id='24' author='songs18' date='2020-07-15T12:40:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34369&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34369&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='25' author='songs18' date='2020-07-15T21:02:40Z'>
		&lt;denchmark-link:https://github.com/songs18&gt;@songs18&lt;/denchmark-link&gt;
: Thank you for the hint about broadcasting.
Interestingly, I think this has to do with my use of tf.squeeze() at the end of my model.  I wanted to remove the channels-dimension after some 1x1 CNNs, such that (None, 155, 1) would be reduced to (None, 155) and I choose (reasonably) to use tf.squeeze() however it apparently returns a shape of [None].  While the model would still train, this caused much confusion and i think this was forcing TF to broadcast into the target vector, since it did not know the true shape of the output tensor.
&lt;denchmark-code&gt;__________________________________________________________________________________________________
L08_1x1CNN (Conv1D)             (None, 155, 1)       601         L07_Dropout[0][0]                
__________________________________________________________________________________________________
tf_op_layer_L09_Squeeze (Tensor [None]               0           L08_1x1CNN[0][0]                 
__________________________________________________________________________________________________
tf_op_layer_QrsTarget (TensorFl [None]               0           tf_op_layer_L09_Squeeze[0][0]    
==================================================================================================
&lt;/denchmark-code&gt;

		</comment>
		<comment id='26' author='songs18' date='2020-09-24T14:37:02Z'>
		Does anyone else think it's weird that &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 is on here asking people to post their entire codebase, has no code or repos in their repo, etc..? Is there any way to block these kinds of scammers from being able to post on these kinds of repos. Luckily the OP is smart enough to know that this person was trying to get their codebase, but others may not be so wary and post things that are not necessary to fix issues.
		</comment>
	</comments>
</bug>