<bug id='32496' author='grwlf' open_date='2019-09-13T13:20:08Z' closed_time='2019-11-16T01:34:17Z'>
	<summary>[r2.0.0-rc1] Converting to TFLite format: &amp;lt;type == kTfLiteInt32/64 condition&amp;gt; was not true. ONE_HOT failed to prepare</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 2.0.0-rc1 commit 59bf33
Python version: 3.6.8
Bazel version (if compiling from source): 0.26.1
GCC/Compiler version (if compiling from source): 7.4.0
CUDA/cuDNN version: 10.0.130
GPU model and memory: NVidia 1080Ti / 11G

Describe the current behavior
Conversion of TF2.0 function containing reshape and one_hot ops to TFLite format fails with the following RuntimeError. Source code of the program is listed in the Code section below.
&lt;denchmark-code&gt;---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-2-ec9775ede022&gt; in &lt;module&gt;
----&gt; 1 run()

~/mironov/hbtest/tflite_one_hot_bug_v2.py in run()
     25
     26   interpreter = tf.lite.Interpreter(model_path=model_file)
---&gt; 27   interpreter.allocate_tensors()
     28
     29 if __name__ == '__main__':

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
    242   def allocate_tensors(self):
    243     self._ensure_safe()
--&gt; 244     return self._interpreter.AllocateTensors()
    245
    246   def _safe_to_run(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)                                                                                         
    104
    105     def AllocateTensors(self):
--&gt; 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
    107
    108     def Invoke(self):

RuntimeError: tensorflow/lite/kernels/one_hot.cc:141 op_context.indices-&gt;type == kTfLiteInt32 || op_context.indices-&gt;type == kTfLiteInt64 was not true.Node number 3 (ONE_HOT) failed to prepare.
&lt;/denchmark-code&gt;

Describe the expected behavior
converter.convert()  finishes without errors
Code to reproduce the issue
File: tflite_one_hot_bug_v2.py
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

@tf.function(input_signature=[
    tf.TensorSpec(shape=[10,10], dtype=tf.int32, name='inp0')])
def model(inp0):
  res = tf.reshape(inp0, [100])
  res = tf.one_hot(res, depth=10)
  print(res.shape)
  return res

def run():
  def _representative_dataset_gen():
    for i in range(10):
      yield [np.random.random_integers(0, 9, size=[10,10]).astype('int32')]

  cfunc = model.get_concrete_function()
  converter = tf.lite.TFLiteConverter.from_concrete_functions([cfunc])
  converter.representative_dataset = _representative_dataset_gen
  converter.optimizations = [tf.lite.Optimize.DEFAULT]

  tflite_model = converter.convert()
  model_file = "/tmp/tflite_one_hot_bug_v2.tflite"
  open(model_file, "wb").write(tflite_model)

  interpreter = tf.lite.Interpreter(model_path=model_file)
  interpreter.allocate_tensors()

if __name__ == '__main__':
  run()
&lt;/denchmark-code&gt;

Other info / logs
N/A
	</description>
	<comments>
		<comment id='1' author='grwlf' date='2019-09-13T23:49:49Z'>
		Hey! As you can see from the error, types other than int32/int64 are not currently supported yet for the one_hot op.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/one_hot.cc#L140&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/one_hot.cc#L140&lt;/denchmark-link&gt;

If it's a index type supported in TF, I suggest you take a look since we won't have immediate cycles to look into this.
		</comment>
		<comment id='2' author='grwlf' date='2019-11-16T01:34:17Z'>
		Closing per last comment.
		</comment>
		<comment id='3' author='grwlf' date='2019-11-16T01:34:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32496&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32496&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>