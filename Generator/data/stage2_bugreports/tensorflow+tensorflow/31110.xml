<bug id='31110' author='linhx13' open_date='2019-07-28T12:20:58Z' closed_time='2020-01-28T21:12:47Z'>
	<summary>keras model fit() crash with large batch_size and 0 validation_split</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tf-gpu 1.13.1
Python version: 3.6.2
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10/7.4.1
GPU model and memory: GTX 1080Ti, 10G

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Raise an error when fitting tf.keras model when the training dataset size less then batch_size and validation_split is 0.0.
If using a batch_size less then dataset size or setting validation_split, the fitting is good.
Using original keras, fitting is good in any case.
Error is :
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "crf_tf.py", line 123, in &lt;module&gt;
    model.fit(x, y, batch_size=16, epochs=50, validation_split=0.0)
  File "/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 880, in fit
    validation_steps=validation_steps)
  File "/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py", line 329, in model_iteration
    batch_outs = f(ins_batch)
  File "/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py", line 3076, in __call__
    run_metadata=self.run_metadata)
  File "/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
  File "/opt/userhome/ichongxiang/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Can not squeeze dim[0], expected a dimension of 1, got 2
         [[{{node metrics/crf_accuracy/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_bool_Squeeze}}]]
         [[{{node crf/cond/Maximum}}]]
&lt;/denchmark-code&gt;

Describe the expected behavior
Fit successfully.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K
# import keras
# from keras import backend as K
import numpy as np


class CRF(keras.layers.Layer):

    def __init__(self, num_tags, **kwargs):
        super(CRF, self).__init__(**kwargs)
        self.num_tags = num_tags
        self.input_spec = keras.layers.InputSpec(min_ndim=3)
        self.supports_masking = True

    def get_config(self):
        config = {
            'num_tags': self.num_tags,
        }
        base_config = super(CRF, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

    def build(self, input_shape):
        assert len(input_shape) == 3
        if input_shape[-1] is None:
            raise ValueError('The last dimension of the inputs to `CRF` '
                             'should be defined. Found `None`.')
        if input_shape[-1] != self.num_tags:
            raise ValueError('The last dimension of the input shape must be equal to output'
                             ' shape. Use a linear layer if needed.')
        self.transitions = self.add_weight(name='transitions',
                                           shape=[self.num_tags,
                                                  self.num_tags],
                                           initializer="glorot_uniform",
                                           trainable=True)
        self.built = True

    def call(self, inputs, mask=None):
        seq_lens = get_seq_lens(inputs, mask)
        viterbi_sequence, _ = tf.contrib.crf.crf_decode(inputs,
                                                        self.transitions,
                                                        seq_lens)
        outputs = K.one_hot(viterbi_sequence, self.num_tags)
        return K.in_train_phase(inputs, outputs)

    def compute_output_shape(self, input_shape):
        return input_shape[:2] + (self.num_tags,)

    def compute_mask(self, inputs, mask=None):
        if mask is not None:
            return K.any(mask, axis=1)
        return mask


def get_seq_lens(inputs, mask=None):
    if mask is not None:
        return K.sum(K.cast(mask, dtype='int32'), axis=-1)
    else:
        shape = K.int_shape(inputs)
        return K.ones(shape[:-1], dtype='int32') * shape[-1]


def crf_loss(y_true, y_pred):
    crf, idx = y_pred._keras_history[:2]
    inputs = crf.get_input_at(idx)
    mask = crf.get_input_mask_at(idx)
    seq_lens = get_seq_lens(inputs, mask)
    y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')
    log_likelihood, crf.transitions = \
        tf.contrib.crf.crf_log_likelihood(y_pred,
                                          y_true,
                                          seq_lens,
                                          transition_params=crf.transitions)
    return K.mean(-log_likelihood)


def crf_accuracy(y_true, y_pred):
    crf, idx = y_pred._keras_history[:2]
    inputs = crf.get_input_at(idx)
    mask = crf.get_input_mask_at(idx)
    seq_lens = get_seq_lens(inputs, mask)
    viterbi_sequence, _ = tf.contrib.crf.crf_decode(inputs,
                                                    crf.transitions,
                                                    seq_lens)
    y_true = K.cast(K.argmax(y_true, -1), dtype='int32')
    judge = K.cast(K.equal(viterbi_sequence, y_true), K.floatx())
    if mask is None:
        return K.mean(judge)
    else:
        mask = K.cast(mask, K.floatx())
        return K.sum(judge * mask) / K.sum(mask)


num_words = 20
num_features = 100
num_tags = 5

inputs = keras.layers.Input(shape=(None,))
embedding = keras.layers.Embedding(10, num_features, mask_zero=True)(inputs)
scores = keras.layers.TimeDistributed(keras.layers.Dense(num_tags))(embedding)
crf = CRF(num_tags)
outputs = crf(scores)
model = keras.models.Model(inputs, outputs)

model.summary()

x = np.array([[1, 2, 3, 4, 0, 0], [4, 5, 6, 0, 0, 0]])
y = np.array([[1, 3, 4, 2, 0, 0], [2, 1, 3, 0, 0, 0]])
y = np.eye(num_tags)[y]

print(x)
print(x.shape)
print(y)
print(y.shape)

model.compile(optimizer="adam",
              loss=crf_loss,
              metrics=[crf_accuracy])

model.fit(x, y, batch_size=16, epochs=50, validation_split=0.0)
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='linhx13' date='2019-07-29T10:52:25Z'>
		Issue replicating with TF version-gpu 1.13, please find the gist of &lt;denchmark-link:https://colab.sandbox.google.com/drive/1JHRJCgGmImIasATBbxnxaMFZuXCrysLv#scrollTo=Qw6wX1NdWhB8&gt;Colab&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='linhx13' date='2019-07-29T12:29:19Z'>
		
Issue replicating with TF version-gpu 1.13, please find the gist of Colab. Thanks!

@anush-o Thanks, but your gist is private access only(
		</comment>
		<comment id='3' author='linhx13' date='2020-01-09T23:43:27Z'>
		Please find updated &lt;denchmark-link:https://colab.sandbox.google.com/gist/ymodak/c1d83748736e87fdacb7c1da4c0632c3/github31110.ipynb&gt;Gist&lt;/denchmark-link&gt;
 using TF 1.15
		</comment>
		<comment id='4' author='linhx13' date='2020-01-28T21:12:47Z'>
		&lt;denchmark-link:https://github.com/linhx13&gt;@linhx13&lt;/denchmark-link&gt;
 Thank you for the issue. From the gist it looks like the issue is independent of validation_split=0, batch_size. I removed your custom loss and metric to make sure that the model works first and there are errors in the model. It would be great if you can provide a minimal repro, if there is still an issue here. Closing for now, please feel free to reopen if required.
		</comment>
		<comment id='5' author='linhx13' date='2020-01-28T21:12:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31110&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31110&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>