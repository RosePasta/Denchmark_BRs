<bug id='11398' author='thiell' open_date='2017-07-09T19:02:06Z' closed_time='2017-12-21T02:33:34Z'>
	<summary>slow cifar10_multi_gpu_train.py stock example and 'Ignoring device specification /device:GPU' warning</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no, using stock example scripts from cifar10
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.2 LTS inside singularity container using docker image tensorflow:latest-gpu
TensorFlow installed from (source or binary): docker://tensorflow/tensorflow:latest-gpu (unmodified)
TensorFlow version (use command below):

&lt;denchmark-code&gt;Singularity tensorflow.img:~&gt; python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
('v1.2.0-5-g435cdfc', '1.2.1')
&lt;/denchmark-code&gt;


Python version: Python 2.7.12
Bazel version (if compiling from source):
CUDA/cuDNN version: cuda 8
GPU model and memory: 2 x K80, 12GB each
Exact command to reproduce:

&lt;denchmark-code&gt;$ python $CIFAR10_DIR/cifar10_multi_gpu_train.py --num_gpus=2 \
                                                 --batch_size=64 \
                                                 --log_device_placement=false \
                                                 --max_steps=10000
&lt;/denchmark-code&gt;

As a comparison, this one is faster:
&lt;denchmark-code&gt;$ python $CIFAR10_DIR/cifar10_train.py --batch_size=128 \
                                       --log_device_placement=false \
                                       --max_steps=10000
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

We have multiGPU systems (8 GPUs with P2P capability) and would like to take advantage of this for faster training but using the stock example cifar10, TensorFlow is even slower when using 2 GPUs than when using a single GPU (cifar10_train.py). I tried several batch sizes with no luck. The python process seems CPU bound when using 2 GPUs, so the GPU SMs are far from being busy (~20% usage).
Also, I can see the following warnings:
&lt;denchmark-code&gt;2017-07-09 18:44:15.097496: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-07-09 18:44:15.097562: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Trace from run:
&lt;denchmark-code&gt;2017-07-09 18:44:13.905522: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:13.905565: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:13.905573: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-09 18:44:14.479331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:06:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-09 18:44:14.821091: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x48f93a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-07-09 18:44:14.823728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 1 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:07:00.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-07-09 18:44:14.827006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 1
2017-07-09 18:44:14.827019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y Y
2017-07-09 18:44:14.827039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y Y
2017-07-09 18:44:14.827053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Tesla K80, pci bus id: 0000:06:00.0)
2017-07-09 18:44:14.827061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: Tesla K80, pci bus id: 0000:07:00.0)
2017-07-09 18:44:15.097496: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-07-09 18:44:15.097562: I tensorflow/core/common_runtime/simple_placer.cc:675] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-07-09 18:44:20.249834: step 0, loss = 4.68 (53.2 examples/sec; 2.407 sec/batch)
2017-07-09 18:44:21.645904: step 10, loss = 4.62 (4843.2 examples/sec; 0.026 sec/batch)
2017-07-09 18:44:22.487916: step 20, loss = 4.49 (2954.3 examples/sec; 0.043 sec/batch)
2017-07-09 18:44:23.351235: step 30, loss = 4.30 (2900.9 examples/sec; 0.044 sec/batch)
2017-07-09 18:44:24.264403: step 40, loss = 4.39 (2565.3 examples/sec; 0.050 sec/batch)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='thiell' date='2017-07-10T21:20:58Z'>
		Can you try to put 'num_gpus',2 manually in the file cifar10_multi_gpu_train.py found at  line 59: ?
&lt;denchmark-code&gt;
tf.app.flags.DEFINE_integer('num_gpus', 2,
--
  | """How many GPUs to use.""")


&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='thiell' date='2017-07-11T20:49:21Z'>
		I have the same problem, even after setting the DEFINE_integer flag manually.
		</comment>
		<comment id='3' author='thiell' date='2017-07-11T23:08:41Z'>
		Did You tried various options to set GPU manually listed here ?&lt;denchmark-link:https://www.tensorflow.org/tutorials/using_gpu&gt;https://www.tensorflow.org/tutorials/using_gpu&lt;/denchmark-link&gt;

You may try  in various setting of Python 3.6, cuDNN, native installation for GPU and see what errors you are getting?
For reference pasting an actual code involved behind your errors:
A non-primary context 0x48f93a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
Source Code ,
&lt;denchmark-code&gt;former_context = CUDADriver::CurrentContextOrDie();
--
  | res = cuDevicePrimaryCtxRetain(&amp;new_context, device);
  | if (former_context != nullptr) {
  | if (former_context == new_context) {
  | VLOG(2) &lt;&lt; "The primary context " &lt;&lt; former_context
  | &lt;&lt; " exists before initializing the StreamExecutor.";
  | } else {
  | LOG(WARNING) &lt;&lt; "A non-primary context " &lt;&lt; former_context
  | &lt;&lt; " exists before initializing the StreamExecutor. We "
  | "haven't verified StreamExecutor works with that.";
  | }
  | }

&lt;/denchmark-code&gt;

Another error
&lt;denchmark-code&gt;Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
&lt;/denchmark-code&gt;

Source Code,
&lt;denchmark-code&gt;if (DeviceNameUtils::HasSomeDetails(source_parsed_name) &amp;&amp;
--
  | DeviceNameUtils::HasSomeDetails(dest_parsed_name)) {
  | // Add a log saying that we are ignoring a specified device
  | // for 'dst' if the two names were incompatible.
  | if (!DeviceNameUtils::AreCompatibleDevNames(source_parsed_name,
  | dest_parsed_name)) {
  | LOG(INFO) &lt;&lt; "Ignoring device specification "
  | &lt;&lt; DeviceNameUtils::ParsedNameToString(dest_parsed_name)
  | &lt;&lt; " for node '" &lt;&lt; dst-&gt;name()
  | &lt;&lt; "' because the input edge from '" &lt;&lt; src-&gt;name()
  | &lt;&lt; "' is a reference connection and already has a device "
  | "field set to "
  | &lt;&lt; DeviceNameUtils::ParsedNameToString(source_parsed_name);
  |  
  | // Make 'dst' colocated with the source
  | dst_root.device_name = source_parsed_name;
  | }

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='thiell' date='2017-07-18T22:38:48Z'>
		I tried using Python 3 with docker://tensorflow/tensorflow:nightly-gpu-py3 but the Python version is only 3.5.2 there and the performance with 2 GPUs doesn't seem better than when using 1 GPU. I still have the following warning that you noted:
&lt;denchmark-code&gt;2017-07-18 22:27:02.253830: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4eba8a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
&lt;/denchmark-code&gt;

Note: I tried using Default and also Exclusive Process GPU compute modes.
So no luck so far...
		</comment>
		<comment id='5' author='thiell' date='2017-08-20T22:37:52Z'>
		Hello everyone,
Regarding the warning:
tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4eba8a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
I'm having the same warning with 2 GPUs, windows 10, python 2.5.3, all installed through Anaconda. I never thought such warning is problematic more than reporting something "I don't understand". I put a question regards it in &lt;denchmark-link:https://stackoverflow.com/questions/45760388/what-is-the-reason-of-getting-the-warning-havent-verified-streamexecutor&gt;what-is-the-reason-of-getting-the-warning-havent-verified-streamexecutor&lt;/denchmark-link&gt;
. Still waiting.
I am writing here just to share my similar experience, and hoping that if &lt;denchmark-link:https://github.com/thiell&gt;@thiell&lt;/denchmark-link&gt;
 has already solved the issue and share his thoughts.
Best wishes,
Alderasus Ghaliamus
		</comment>
		<comment id='6' author='thiell' date='2017-08-28T03:09:28Z'>
		&lt;denchmark-link:https://github.com/poxvoculi&gt;@poxvoculi&lt;/denchmark-link&gt;
, are you able to take a look?
		</comment>
		<comment id='7' author='thiell' date='2017-08-28T18:16:04Z'>
		I think there are two problems being reported, correct me if I misunderstand.

The warning reported above by @Alderasus and @Thiel.  I see that a change was submitted to cuda_driver.cc on Aug 7 that changed this warning, claiming that the old one included false positive warnings.

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/c67e2c911c9a76942c25a76d37f0568a755010e6&gt;c67e2c9&lt;/denchmark-link&gt;

Perhaps you could retry with a more recent version of TF to see whether you're still getting a warning.

thiel@ is experiencing slower performance with 2 GPUs than with 1 for cifar10_multi_gpu_train.py.  I'm not familiar with this program, but maybe @nealwu is.   Are you seeing both GPUs being used (e.g. using nvidia-smi, or looking at the device assignments in the logged .pbtxt showing the graph)?  If the python part of the process is indeed the bottleneck, can you tell which part, e.g. input preprocessing?

		</comment>
		<comment id='8' author='thiell' date='2017-08-28T21:25:19Z'>
		&lt;denchmark-link:https://github.com/poxvoculi&gt;@poxvoculi&lt;/denchmark-link&gt;
 Thanks for looking at these issues. Both GPUs were used but SM usage% was about half lower than with a single GPU, making the whole thing slower I guess. Scaling across multiple GPUs is VERY important these days. I will give it a try if again I can find some time.
		</comment>
		<comment id='9' author='thiell' date='2017-08-28T23:55:33Z'>
		Hi &lt;denchmark-link:https://github.com/thiell&gt;@thiell&lt;/denchmark-link&gt;
, I'd recommend taking a look at the &lt;denchmark-link:https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator&gt;cifar10_estimator&lt;/denchmark-link&gt;
 example instead. The cifar10_multi_gpu_train.py example is out of date, and based on what I've heard from others, it may not work correctly.
		</comment>
		<comment id='10' author='thiell' date='2017-12-20T19:10:14Z'>
		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='thiell' date='2017-12-21T02:33:33Z'>
		Closing this. We recommend looking at the newer &lt;denchmark-link:https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10_estimator&gt;cifar10_estimator&lt;/denchmark-link&gt;
 example.
		</comment>
	</comments>
</bug>