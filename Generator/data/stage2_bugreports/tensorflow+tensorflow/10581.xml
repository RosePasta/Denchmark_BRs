<bug id='10581' author='JcmeLs' open_date='2017-06-09T03:10:44Z' closed_time='2017-06-12T06:08:36Z'>
	<summary>Run quantize_graph error</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
OS X EI Caption 10.11.6
TensorFlow installed from (source or binary):
binary (pip install)
TensorFlow version (use command below):
TensorFlow 1.2.0-rc1 CPU Only
Bazel version (if compiling from source):
Build label: 0.4.5-homebrew
Build target: bazel-out/local-
opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 13:37:54 2017 (1489671474)
Build timestamp: 1489671474
Build timestamp as int: 1489671474
CUDA/cuDNN version:
CPU Only

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Because of the buffers holding the model weight values are 77MB in size, the memory needed to load these into the app can put a lot of pressure on RAM in Android even before the model is run.
So, I need to further compress the model and round the weights,Even at the expense of accuracy.
So I build /tensorflow/tools/quantization/quantize_graph.There are something wrongs when I run quantize_graph .
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Source code:
&lt;denchmark-code&gt;bazel-bin/tensorflow/tools/quantization/quantize_graph \
–input=/Users/liba/Desktop/OptimizeCTNModel.pb \
–output=/Users/liba/Desktop/RoundedCTNModel.pb \ 
–output_node_names=output/outputs \
–mode=weights_rounded
&lt;/denchmark-code&gt;

log:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py", line 1301, in &lt;module&gt;
    app.run()
  File "/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/tools/quantization/quantize_graph.py", line 1267, in main
    data = f.read()
  File "/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/lib/io/file_io.py", line 125, in read
    pywrap_tensorflow.ReadFromStream(self._read_buf, length, status))
  File "/Users/liba/anaconda/lib/python2.7/contextlib.py", line 24, in __exit__
    self.gen.next()
  File "/Users/liba/Desktop/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: .

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='JcmeLs' date='2017-06-09T10:11:18Z'>
		This  tool is outdated. You may try the new  tool:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#eight-bit-calculations&gt;https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms#eight-bit-calculations&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='JcmeLs' date='2017-06-09T16:58:03Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 This seems like a bad error message even if the tool is deprecated.  Could you take a look?
		</comment>
		<comment id='3' author='JcmeLs' date='2017-06-12T02:39:38Z'>
		&lt;denchmark-link:https://github.com/Androbin&gt;@Androbin&lt;/denchmark-link&gt;
  I try.But it have a error.
log:
&lt;denchmark-code&gt;ZHANGSH7-MP:tensorflow liba$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph =/Users/liba/Desktop/OptimizeCTNModel.pb --out_graph =/Users/liba/DesktoRouddndedOptimizeCTodel.pb  --inputs = 'inputs/X' --outputs = 'output/outputs' --transforms = 'strip_unused_nodes（type = float，shape =“1,256,256,1”）fold_constants（ignore_errors = true) fold_batch_norms fold_old_batch_norms round_weights（num_steps = 256）'
2017-06-12 10:36:01.153946: E tensorflow/tools/graph_transforms/transform_graph.cc:164] Unknown argument --in_graph.
usage: bazel-bin/tensorflow/tools/graph_transforms/transform_graph
Flags:
	--in_graph=""                    	string	input graph file name
	--out_graph=""                   	string	output graph file name
	--inputs=""                      	string	inputs
	--outputs=""                     	string	outputs
	--transforms=""                  	string	list of transforms
	--output_as_text=false           	bool	whether to write the graph in text protobuf format

Transforms are:
add_default_attributes
backport_concatv2
backport_tensor_array_v3
fold_batch_norms
fold_constants
fold_old_batch_norms
freeze_requantization_ranges
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
insert_logging
merge_duplicate_nodes
obfuscate_names
quantize_nodes
quantize_weights
remove_attribute
remove_device
remove_nodes
rename_attribute
rename_op
rewrite_quantized_stripped_model_for_hexagon
round_weights
set_device
sort_by_execution_order
sparsify_gather
strip_unused_nodes
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='JcmeLs' date='2017-06-12T06:08:36Z'>
		It can't work!Thanks.
		</comment>
		<comment id='5' author='JcmeLs' date='2017-10-17T12:26:39Z'>
		Hello,
&lt;denchmark-link:https://github.com/JcmeLs&gt;@JcmeLs&lt;/denchmark-link&gt;
 Can you please tell me the solution you found of the above problem?
		</comment>
	</comments>
</bug>