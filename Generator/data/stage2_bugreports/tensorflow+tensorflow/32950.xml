<bug id='32950' author='vivekvekariya' open_date='2019-10-01T12:39:06Z' closed_time='2020-04-03T18:05:21Z'>
	<summary>Tensorflow 2.0 AdaDelta Optimizer</summary>
	<description>
Please go to Stack Overflow for help and support:
&lt;denchmark-link:https://stackoverflow.com/questions/tagged/tensorflow&gt;https://stackoverflow.com/questions/tagged/tensorflow&lt;/denchmark-link&gt;

If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

You can collect some of this information using our environment capture script:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&lt;/denchmark-link&gt;

You can obtain the TensorFlow version with:
python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
	</description>
	<comments>
		<comment id='1' author='vivekvekariya' date='2019-10-01T12:47:17Z'>
		I was using Keras to train my neural network, With Loss function as "Mean Square Error" and optimizer as "AdaDelta". Neural Network trained on MNIST dataset for 5 epochs was giving test accuracy of 92.5%.
Using same set of layers, loss function, optimizer and initialization methods, my neural network model in tensorflow 2.0 is giving output of just 15%.
With other optimizers in TF2 gradient descent is working proper giving test accuracy of more than 90% on MNIST dataset.
I am wondering why is the problem only with AdaDelta? Am I missing some seeds or parameters to be feed to optimizer?
		</comment>
		<comment id='2' author='vivekvekariya' date='2019-10-01T12:51:35Z'>
		&lt;denchmark-link:https://github.com/vivekvekariya&gt;@vivekvekariya&lt;/denchmark-link&gt;
 Can you provide a snippet for both your Keras &amp; TF2.0 training? Would be easier to debug.
		</comment>
		<comment id='3' author='vivekvekariya' date='2019-10-02T15:31:12Z'>
		I have used weight initializer as below-
keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)
This is tf 2.0 implementation-
&lt;denchmark-link:https://user-images.githubusercontent.com/38262106/66058292-68c33c00-e53a-11e9-8c08-79cca0d32bcb.png&gt;&lt;/denchmark-link&gt;

This is Keras Implementation with tf1 as backend-
&lt;denchmark-link:https://user-images.githubusercontent.com/38262106/66058293-695bd280-e53a-11e9-92f0-30da3b317e91.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='vivekvekariya' date='2019-10-02T20:36:55Z'>
		&lt;denchmark-link:https://github.com/vivekvekariya&gt;@vivekvekariya&lt;/denchmark-link&gt;
 Can you please provide a github gist of this issue. Thanks!
		</comment>
		<comment id='5' author='vivekvekariya' date='2019-10-03T14:03:58Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;

Kindly find link to my github gist on this issue:
&lt;denchmark-link:https://gist.github.com/vivekvekariya/19d0b5a1af104d6cbac7425aa85bf408&gt;https://gist.github.com/vivekvekariya/19d0b5a1af104d6cbac7425aa85bf408&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='vivekvekariya' date='2019-10-09T20:32:00Z'>
		&lt;denchmark-link:https://github.com/vivekvekariya&gt;@vivekvekariya&lt;/denchmark-link&gt;
 Thanks for your input. I tried running mnist example against adadelta and adam and yes 'adadelta' has much worse performance compared to adam (as you can see &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/bcb1ead49a720ac75fbc38522dca6106/beginner.ipynb&gt;here&lt;/denchmark-link&gt;
) and this is explained &lt;denchmark-link:https://www.reddit.com/r/MachineLearning/comments/3y84hr/how_does_adam_compare_to_adadelta/&gt;here&lt;/denchmark-link&gt;
. Please correct me if you think otherwise.
		</comment>
		<comment id='7' author='vivekvekariya' date='2019-10-10T05:51:59Z'>
		I'm getting a similar issue. I'm training a model to approximate Q value in Reinforcement Learning using AdamOptimizer.
In tensorflow 1.14, TD error starts from 9.0 and continues to drop.
However, in tensorflow 2.0, TD error starts from 9.0 but continues to increase and stabilizes around 25 for some reasons.
		</comment>
		<comment id='8' author='vivekvekariya' date='2019-10-10T17:24:06Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 I think you meant to tag &lt;denchmark-link:https://github.com/vivekvekariya&gt;@vivekvekariya&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='vivekvekariya' date='2019-10-14T18:12:50Z'>
		
I was using Keras to train my neural network, With Loss function as "Mean Square Error" and optimizer as "AdaDelta". Neural Network trained on MNIST dataset for 5 epochs was giving test accuracy of 92.5%.
Using same set of layers, loss function, optimizer and initialization methods, my neural network model in tensorflow 2.0 is giving output of just 15%.
With other optimizers in TF2 gradient descent is working proper giving test accuracy of more than 90% on MNIST dataset.
I am wondering why is the problem only with AdaDelta? Am I missing some seeds or parameters to be feed to optimizer?

May I ask if you tried optimizers like tf.keras.optimizers.Adam and tf.compat.v1.train.AdamOptimizer? I have a project showing different result using tf.compat.v1.train.AdamOptimizer.
		</comment>
		<comment id='10' author='vivekvekariya' date='2019-10-16T17:43:50Z'>
		&lt;denchmark-link:https://github.com/Nephalen&gt;@Nephalen&lt;/denchmark-link&gt;
 Can you please try it with different data sets like flowers, cifar and see if the issue still persists. I have tried it on Mnist and I didn't notice any error as mentioned above.
		</comment>
		<comment id='11' author='vivekvekariya' date='2019-10-16T18:49:49Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 I've tested on another supervised data set and it was similar.
The problem is, the project I'm working on is not supervised learning, as I mentioned above. For that reinforcement learning model, the training processes between TF &lt;=1.14 and TF &gt;=1.15 are vastly different.
There is another post stating a similar issue but I'm not sure whether its poster tested on TF 1.15 yet. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33003#issue-501769956&gt;link&lt;/denchmark-link&gt;

I couldn't find any documentation mentioning any update to the optimizers. My guess is whatever the reason behind this is not intended.
		</comment>
		<comment id='12' author='vivekvekariya' date='2019-10-17T15:04:08Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 I think I figure out the reason for my problem. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33471#issue-508537917&gt;link&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='vivekvekariya' date='2019-10-17T17:26:13Z'>
		As mentioned in issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33471&gt;#33471&lt;/denchmark-link&gt;
, Yes in TF 1.14 it shows 0 but in TF 1.15rc3 and TF 2.0 its showing 100. I think this is clearly a bug
Here are my github gists &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/1fd2d4e745b093af63325bfbd7dbefb7/untitled198.ipynb&gt;Tf 1.14&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/edf243d59c16cbe5709754d8d346636e/untitled199.ipynb&gt;TF 1.15rc3&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/0fefab16eefe321e944f7fe528376765/untitled197.ipynb&gt;TF2.0&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='vivekvekariya' date='2019-10-17T17:55:40Z'>
		We changed the default learning rate in 2.0. Can you double check and see if you're using the same learning rate?
		</comment>
		<comment id='15' author='vivekvekariya' date='2019-10-17T19:43:21Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 I'm terribly sorry for the confusion. What I meant above was I figured out the cause of higher loss in my project and created another issue. It seems to be the result of incorrect weight update. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33471#issue-508537917&gt;#33471&lt;/denchmark-link&gt;

And just for the record, I explicitly kept learning rate constant across experiments.
		</comment>
		<comment id='16' author='vivekvekariya' date='2020-04-03T18:05:19Z'>
		&lt;denchmark-link:https://github.com/Nephalen&gt;@Nephalen&lt;/denchmark-link&gt;
 I see. It looks like a different issue and resolved then.
&lt;denchmark-link:https://github.com/vivekvekariya&gt;@vivekvekariya&lt;/denchmark-link&gt;
 I think this is due to different default learning rate, can you explicitly change the code to:
opt = tf.keras.optimizers.Adadelta(learning_rate=1.0, ...)
model.compile(opt, ...)
Closing it for now. Let us know if any other issues come up.
		</comment>
		<comment id='17' author='vivekvekariya' date='2020-04-03T18:05:24Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32950&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32950&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>