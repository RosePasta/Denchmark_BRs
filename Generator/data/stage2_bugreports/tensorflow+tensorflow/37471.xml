<bug id='37471' author='moberweger' open_date='2020-03-10T08:54:55Z' closed_time='2020-03-11T10:11:48Z'>
	<summary>TFLite allocate tensors fails: (CONCATENATION) failed to prepare</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
Python version: 3.6.9
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Creating a tf.keras model and exporting it to tflite causes an error when trying to allocate the tensors for inference. The error is:

RuntimeError: tensorflow/lite/kernels/concatenation.cc:68 t-&gt;dims-&gt;size != t0-&gt;dims-&gt;size (0 != 4)Node number 3 (CONCATENATION) failed to prepare.

Describe the expected behavior
The exported model should load without error.
Standalone code to reproduce the issue
Colab gist reproducing the error can be found &lt;denchmark-link:https://colab.research.google.com/gist/moberweger/9dca6edfdabf996a57dab42ffe044666/untitled0.ipynb#scrollTo=2-Tz7Z1KnVZk&gt;here&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Concatenate, Add
from tensorflow.keras.models import Model

if __name__ == '__main__':
    print(tf.version.GIT_VERSION, tf.version.VERSION)
    test_images = np.random.randn(8, 388, 420, 1)

    # model
    m_input = Input(shape=test_images.shape[1:])
    d1 = Conv2D(8, 3, dilation_rate=1, padding='same', use_bias=False)(m_input)
    d2 = Conv2D(8, 3, dilation_rate=2, padding='same', use_bias=False)(m_input)
    d16 = Conv2D(8, 3, dilation_rate=16, padding='same', use_bias=False)(m_input)
    add1 = Add()([d2, d16])
    m_output = Concatenate()([d1, d2, add1])

    model = Model(inputs=m_input, outputs=m_output)
    model.summary()
    model.compile(optimizer='rmsprop', loss='mse')
    pred = model.predict(test_images)
    print(pred.shape)

    # conversion
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open("model.tflite", "wb") as fp:
        fp.write(tflite_model)

    # inference
    interpreter = tf.lite.Interpreter(model_path="model.tflite")
    input_details = interpreter.get_input_details()
    interpreter.allocate_tensors()
    print("DONE")
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-3-4adc506bd32d&gt; in &lt;module&gt;()
     31     interpreter = tf.lite.Interpreter(model_path="model.tflite")
     32     input_details = interpreter.get_input_details()
---&gt; 33     interpreter.allocate_tensors()
     34     print("DONE")

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
    245   def allocate_tensors(self):
    246     self._ensure_safe()
--&gt; 247     return self._interpreter.AllocateTensors()
    248 
    249   def _safe_to_run(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
    108 
    109     def AllocateTensors(self):
--&gt; 110         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
    111 
    112     def Invoke(self):

RuntimeError: tensorflow/lite/kernels/concatenation.cc:68 t-&gt;dims-&gt;size != t0-&gt;dims-&gt;size (0 != 4)Node number 3 (CONCATENATION) failed to prepare.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='moberweger' date='2020-03-11T09:18:31Z'>
		&lt;denchmark-link:https://github.com/moberweger&gt;@moberweger&lt;/denchmark-link&gt;

Running your code on nightly does not throw any error,please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/05700439ae5c12ea117a518f7a434d3a/37471.ipynb&gt;gist here&lt;/denchmark-link&gt;

Would you please check this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34345&gt;link&lt;/denchmark-link&gt;
 for reference
		</comment>
		<comment id='2' author='moberweger' date='2020-03-11T10:11:47Z'>
		Thanks &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  works with nightly, so I am closing this one.
		</comment>
		<comment id='3' author='moberweger' date='2020-03-11T10:11:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37471&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37471&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>