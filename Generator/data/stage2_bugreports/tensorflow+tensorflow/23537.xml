<bug id='23537' author='mingyr' open_date='2018-11-05T23:22:03Z' closed_time='2018-11-09T18:12:04Z'>
	<summary>Failed to obtain tensors of correct batch size</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Red hat 7.3
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1.10
Python version: 2.7.5
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 9.0
GPU model and memory: P5000, 16G

The following code is just retrieving specific digits from mnist of specified batch size. But the returned tensor is just of one sample:
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
import sonnet as snt

class Input(snt.AbstractModule):
    def __init__(self, batch_size, name = "input"):
        super(Input, self).__init__(name = name)

        mnist = tf.keras.datasets.mnist

        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()

        train_filter = np.where((Y_train == 0 ) | (Y_train == 1))
        test_filter = np.where((Y_test == 0) | (Y_test == 1))

        X_train, Y_train = X_train[train_filter], Y_train[train_filter]
        X_test, Y_test = X_test[test_filter], Y_test[test_filter]

        print(X_train.shape)
        print(Y_train.shape)

        with self._enter_variable_scope():
            self._db_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))
            self._db_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))

            self._db_train.repeat(-1)
            self._db_test.repeat(-1)

            self._db_train.batch(batch_size)
            self._db_test.batch(batch_size)

            # self._db_train.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))
            # self._db_test.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))

            self._it_train = self._db_train.make_one_shot_iterator()
            self._it_test = self._db_test.make_one_shot_iterator()


    def _build(self, is_training = True):

        if is_training:
            inputs, labels = self._it_train.get_next()
        else:
            inputs, labels = self._it_test.get_next()

        return inputs, labels

def test():
    input_ = Input(32)

    inputs, labels = input_()

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

        inputs_val, labels_val = sess.run([inputs, labels])


        print(inputs_val.shape)
        print(labels_val.shape)


if __name__ == "__main__":
    test()

&lt;/denchmark-code&gt;

The output of the above code snippet is as follows:
&lt;denchmark-code&gt;(12665, 28, 28)
(12665,)
(28, 28)
()

&lt;/denchmark-code&gt;

Note I deleted something irrelevant.
	</description>
	<comments>
		<comment id='1' author='mingyr' date='2018-11-09T18:12:04Z'>
		This question is better asked on &lt;denchmark-link:http://stackoverflow.com/questions/tagged/tensorflow&gt;StackOverflow&lt;/denchmark-link&gt;
 since it is not a bug or feature request. There is also a larger community that reads questions there.
If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new&gt;issue template&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='mingyr' date='2018-11-10T11:49:46Z'>
		Actually I have posted it on StackOverflow but no one gives some suggestions. &lt;denchmark-link:https://stackoverflow.com/questions/53153933/failed-to-obtain-tensors-of-correct-batch-size&gt;https://stackoverflow.com/questions/53153933/failed-to-obtain-tensors-of-correct-batch-size&lt;/denchmark-link&gt;

It is okay if it is ranked as not a defeat since I have found some workaround.
Thanks
		</comment>
	</comments>
</bug>