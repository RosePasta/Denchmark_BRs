<bug id='38645' author='jostheim' open_date='2020-04-17T17:42:38Z' closed_time='2020-04-17T22:54:10Z'>
	<summary>Issue with Tensorshape and Datasets</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Linux Ubuntu 18.04

Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

N/A

TensorFlow installed from (source or binary):

binary (pip)

TensorFlow version (use command below):

v2.1.0-rc2-17-ge5bf8de
2.1.0

Python version:

3.7.7

Bazel version (if compiling from source):

N/A

GCC/Compiler version (if compiling from source):

N/A

CUDA/cuDNN version:

10.1

GPU model and memory:

GTX 1080 Ti, 11 GB
You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
I am trying to use tf.Dataset with generators, I am getting the following very strange error trying to build tf.TensorShape:
&lt;denchmark-code&gt;TypeError: in converted code:

    &lt;ipython-input-86-05d6b5f23a20&gt;:11 None  *
        ds = ds.interleave(lambda gen_idx: tf.data.Dataset.from_generator(gen_wrapper,
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py:744 from_generator
        output_types, tensor_shape.as_shape, output_shapes)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py:471 map_structure_up_to
        results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py:471 &lt;listcomp&gt;
        results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:1211 as_shape
        return TensorShape(shape)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:771 __init__
        self._dims = [as_dimension(d) for d in dims_iter]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:771 &lt;listcomp&gt;
        self._dims = [as_dimension(d) for d in dims_iter]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:716 as_dimension
        return Dimension(value)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:200 __init__
        None)
    &lt;string&gt;:3 raise_from
        

    TypeError: Dimension value must be integer or None or have an __index__ method, got TensorShape([1])
&lt;/denchmark-code&gt;

Describe the expected behavior
The ints I pass into TensorShape should be recognized as ints and not throw an error.
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;def gen(): 
  for i in itertools.count(1): 
    yield (i, [1] * i) 
ds = tf.data.Dataset.from_tensor_slices(list(range(24)))
ds = ds.interleave(lambda gen_idx: tf.data.Dataset.from_generator(gen,
                                                                  output_types=(tf.float32),
                                                                  args=(gen_idx,),
                                                                  output_shapes=(tf.TensorShape([]), tf.TensorShape([None]))),
                   cycle_length=24,
                   block_length=1,
                   num_parallel_calls=24)
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='jostheim' date='2020-04-17T22:54:09Z'>
		Still not sure why this doesn't work, but I worked around it.
		</comment>
		<comment id='2' author='jostheim' date='2020-04-17T22:54:11Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38645&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38645&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='jostheim' date='2020-07-10T03:58:03Z'>
		&lt;denchmark-link:https://github.com/jostheim&gt;@jostheim&lt;/denchmark-link&gt;
 How did you work around the problem? I'm seeing the same thing in one (but not the other) of a dataset from generator
		</comment>
		<comment id='4' author='jostheim' date='2020-07-10T04:08:55Z'>
		&lt;denchmark-link:https://github.com/timothyjlaurent&gt;@timothyjlaurent&lt;/denchmark-link&gt;
 I made a callback where I run evaluate using a Sequence and manually stick the metrics into tensorboard
&lt;denchmark-code&gt;class ValidationCallback(keras.callbacks.Callback):

    def __init__(self, validation_gen, prefix, file_writer):
        super(ValidationCallback, self).__init__()
        config = get_config()
        self.config = config
        self.validation_gen = validation_gen
        self.prefix = prefix
        self.file_writer = file_writer

    def on_batch_end(self, batch, logs=None):
        if batch % 1000 == 0 and batch != 0:
            logger.info('')
            logger.info(f'learning_rate {keras.backend.eval(self.model.optimizer._decayed_lr(tf.float32))}')
            logger.info('')

    def on_epoch_end(self, epoch, logs=None):
        # with a Sequential model
        metrics = self.model.evaluate(self.validation_gen,
                                      verbose=1,
                                      use_multiprocessing=False if self.config['train'].as_bool('use_dataset') else True,
                                      workers=int(self.config['train']['num_workers']) if not self.config['train'].as_bool('use_dataset') else 1)
        with self.file_writer.as_default():
            for name, metric in zip(self.model.metrics_names, metrics):
                logger.info('metric name {} prefix {}'.format(name, self.prefix))
                tf.summary.scalar('{}_{}'.format(self.prefix, name), metric, step=epoch)
                logs['{}_{}'.format(self.prefix, name)] = metric
        logger.info('flushing file writer')
&lt;/denchmark-code&gt;

Some of that stuff is for my particular use case, but that is the basic gist. For file_writer
&lt;denchmark-code&gt;file_writer = tf.summary.create_file_writer(tensorboard_directory + "/metrics")
&lt;/denchmark-code&gt;

I hope this helps!
		</comment>
	</comments>
</bug>