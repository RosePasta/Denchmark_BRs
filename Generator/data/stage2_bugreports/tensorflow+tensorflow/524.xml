<bug id='524' author='sguada' open_date='2015-12-16T16:45:01Z' closed_time='2016-06-06T20:24:08Z'>
	<summary>More descriptive error message when op is not defined for GPU or CPU</summary>
	<description>
When trying to use MaxPoolWithArgmax I got the following error:
InvalidArgumentError: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs
[[Node: MaxPoolWithArgmax_5 = MaxPoolWithArgmax&lt;denchmark-link:random_normal_4&gt;Targmax=DT_INT64, ksize=[1, 3, 3, 1], padding="SAME", strides=[1, 2, 2, 1]&lt;/denchmark-link&gt;
]]
Which doesn't tell me that the op is available in GPU but not in CPU.
	</description>
	<comments>
		<comment id='1' author='sguada' date='2015-12-16T17:10:45Z'>
		I second this as well -- someting that would clearly define gpu compatibility would be great. If the documentation had it, that would be even better.
On the docs, we could just assume all ops are gpu compatible, but if they are marked as "CPU only", it would help!!!
		</comment>
		<comment id='2' author='sguada' date='2015-12-16T17:13:44Z'>
		The op may be defined on GPU, but just not for those specific set of attributes (e.g., it could have been the case that it was defined for Targmax=DT_INT32).
It would be too cryptic of an error message to enumerate all possible registrations for that Op (which might be tens of kernels) in the error message.
In addition, it's totally legal for an op to be defined on GPU, but the binary to not include it, so even if we put something in the docs, it wouldn't be right.
I agree that we could do a better job here, but it'll take some care to make sure we don't spam the error message with content that nobody can read.
		</comment>
		<comment id='3' author='sguada' date='2015-12-16T17:19:27Z'>
		Maybe it is enough to change the error by adding the information which
placement was requested:
InvalidArgumentError: No OpKernel was registered to support Op
'MaxPoolWithArgmax' for device '/gpu:0' with these attrs
[[Node: MaxPoolWithArgmax_5 = MaxPoolWithArgmaxTargmax=DT_INT64, ksize=[1,
3, 3, 1], padding="SAME", strides=[1, 2, 2, 1] http://random_normal_4/]]
On Wed, Dec 16, 2015 at 9:15 AM Vijay Vasudevan &lt;denchmark-link:mailto:notifications@github.com&gt;notifications@github.com&lt;/denchmark-link&gt;

wrote:

The op may be defined on GPU, but just not for those specific set of
attributes (e.g., it could have been the case that it was defined for
Targmax=DT_INT32).
It would be too cryptic of an error message to enumerate all possible
registrations for that Op (which might be tens of kernels) in the error
message.
In addition, it's totally legal for an op to be defined on GPU, but the
binary to not include it, so even if we put something in the docs, it
wouldn't be right.
I agree that we could do a better job here, but it'll take some care to
make sure we don't spam the error message with content that nobody can read.
â€”
Reply to this email directly or view it on GitHub
#524 (comment)
.

		</comment>
		<comment id='4' author='sguada' date='2016-01-21T17:42:26Z'>
		Newbie question: how do I get a list of all registered opkernels?  If it's easy, the error message could advise the user on how to peruse the list.  It would then become obvious to the user that, e.g., the op they wanted wasn't registered for the gpu...
		</comment>
		<comment id='5' author='sguada' date='2016-02-27T05:23:22Z'>
		Can anyone help me with this No opkernel registered error: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1269&gt;#1269&lt;/denchmark-link&gt;
 . Following from the main.cc in label_image example and looking into the android demo tensorflow_jni.cc, I see that the android demo is directly reading the RGB values and putting it into an input tensor, whereas the label_image example builds a graphdef builder and runs several ops to derive to its input tensor. Could this difference be the reason for that error?
		</comment>
		<comment id='6' author='sguada' date='2016-06-06T18:45:06Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
: Martin's suggested fix seems reasonable.  Should we assign this to someone or give some more details are and mark it contributions welcome?
		</comment>
		<comment id='7' author='sguada' date='2016-06-06T19:05:10Z'>
		I believe we have fixed the error message to be much more helpful, but someone would have to verify ;)
		</comment>
		<comment id='8' author='sguada' date='2016-06-06T20:08:24Z'>
		It doesn't look like we fixed it: 


tensorflow/tensorflow/core/common_runtime/simple_placer.cc


         Line 514
      in
      e9953ee






 if (member-&gt;supported_device_types.empty()) { 





		</comment>
		<comment id='9' author='sguada' date='2016-06-06T20:24:08Z'>
		That codepath only gets hit if there are no kernels at all that support that op.  There is no placement specified, and no kernels registered.  I think the situation &lt;denchmark-link:https://github.com/sguada&gt;@sguada&lt;/denchmark-link&gt;
 has been fixed, you're pointing at a different error path.
		</comment>
		<comment id='10' author='sguada' date='2016-06-06T20:37:28Z'>
		&lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
: Assigning to you since you seem to be the C++ runtime czar.  Feel free to reassign.
		</comment>
		<comment id='11' author='sguada' date='2016-06-06T20:38:07Z'>
		Oops, sorry, missed your comment.  Never mind.
		</comment>
		<comment id='12' author='sguada' date='2017-05-29T01:58:28Z'>
		I am using TF1.1. I found this op have no CPU kernel for either Targmax=tf.int32 or Targmax=tf.int64. For GPU (CUDA8 on a Titan X), it has kernel for Targmax=tf.int64, but no kernel for Targmax=tf.int32
		</comment>
		<comment id='13' author='sguada' date='2017-05-30T15:38:39Z'>
		Did you find the error message to be bad? If so, can you paste the error message here, and how you would have improved it?
If your comment is about the absence of the kernel registration, please open a separate issue (or send a PR).
		</comment>
		<comment id='14' author='sguada' date='2017-06-03T03:30:45Z'>
		&lt;denchmark-link:https://github.com/jacksonloper&gt;@jacksonloper&lt;/denchmark-link&gt;
 You can find a list of opcodes available in the makefile build from here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/tf_op_files.txt&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/makefile/tf_op_files.txt&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>