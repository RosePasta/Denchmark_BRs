<bug id='35413' author='olegmyrk' open_date='2019-12-26T02:53:11Z' closed_time='2020-01-28T21:36:34Z'>
	<summary>vgg19.preprocess_input doesn't work in TF2.1 autograph mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc1-58-g9837ece 2.1.0-rc2 (python3 -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)")
Python version: Python 3.6.8
CUDA/cuDNN version: Driver Version: 440.33.01, CUDA Version: 10.2, cuDNN 7.6.2
GPU model and memory: Tesla V100-SXM2-16GB

Describe the current behavior
Running
&lt;denchmark-code&gt;tensorflow.keras.applications.vgg19.preprocess_input
&lt;/denchmark-code&gt;

inside @tf.function results in exception:
&lt;denchmark-code&gt;TypeError: An op outside of the function building code is being passed
a "Graph" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: VGGLoss/Const:0
&lt;/denchmark-code&gt;


Should work the same as in tf1.x
&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/develop/vgg19_keras.py#L15&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/develop/vgg19_keras.py#L15&lt;/denchmark-link&gt;



&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L631&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L631&lt;/denchmark-link&gt;


&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L776&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L776&lt;/denchmark-link&gt;


&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L784&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/SPADE.py#L784&lt;/denchmark-link&gt;

This is the line that fails:
&lt;denchmark-code&gt;x_vgg, y_vgg = self.vgg(preprocess_input(x)), self.vgg(preprocess_input(y))
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/vgg19_keras.py#L15&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/vgg19_keras.py#L15&lt;/denchmark-link&gt;

I also tried to patch the code for preprocess_input myself
&lt;denchmark-link:https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/vgg19_keras.py#L62&gt;https://github.com/olegmyrk/SPADE-Tensorflow/blob/85b5fd7943296561dc3d54557fec5346c2adea58/vgg19_keras.py#L62&lt;/denchmark-link&gt;

It somewhat works but judging by the scale of the VGG loss some input normalization is off.
Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "main.py", line 134, in &lt;module&gt;
    main()
  File "main.py", line 121, in main
    gan.train()
  File "/app/home/ubuntu/SPADE-Tensorflow.tf2/SPADE.py", line 1180, in train
    build()
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1611, in _filtered_call
    self.captured_inputs)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 545, in call
    ctx=ctx)
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 76, in quick_execute
    raise e
  File "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 61, in quick_execute
    num_outputs)
TypeError: An op outside of the function building code is being passed
a "Graph" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: VGGLoss/Const:0
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='olegmyrk' date='2019-12-27T00:01:20Z'>
		&lt;denchmark-link:https://github.com/olegmyrk&gt;@olegmyrk&lt;/denchmark-link&gt;
 I am using tf-nightly and I am not running into any error. Please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/7464f8e197fb9f2917f07639ce819aa8/style_transfer.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='olegmyrk' date='2019-12-27T06:10:02Z'>
		Here is the smallest code that can reproduce the bug in v2.1.0-rc1-58-g9837ece 2.1.0-rc2:
&lt;denchmark-code&gt;import numpy as np 
import tensorflow as tf 
 
dataset1 = tf.data.Dataset.from_tensor_slices(([np.zeros((1,224,224,3),np.float32)]))
 
@tf.function 
def run1(x): 
  with tf.name_scope("preprocess_input"):
    return tf.keras.applications.vgg19.preprocess_input(x)
 
for x in dataset1: 
  result = run1(x) 
  print(result)

dataset2 = tf.data.Dataset.from_tensor_slices(([np.zeros((1,224,224,3),np.float32)])) 
 
@tf.function 
def run2(x): 
  return tf.keras.applications.vgg19.preprocess_input(x)
 
for x in dataset2: 
  result = run2(x) 
  print(result)
&lt;/denchmark-code&gt;

It is different from what my codes does but results in the same error:
&lt;denchmark-code&gt;TypeError: An op outside of the function building code is being passed
a "Graph" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: preprocess_input/Const:0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='olegmyrk' date='2020-01-10T00:02:33Z'>
		I am not running into any error using tf-nightly. Please find my gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/315b4908917a55858f0f0ef03f219bbf/untitled270.ipynb&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='olegmyrk' date='2020-01-10T04:02:17Z'>
		Fails in TF 2.1.0:
&lt;denchmark-link:https://colab.research.google.com/gist/olegmyrk/7b3254a35f0a104fe83f1f60bf693ac0/untitled0.ipynb&gt;https://colab.research.google.com/gist/olegmyrk/7b3254a35f0a104fe83f1f60bf693ac0/untitled0.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='olegmyrk' date='2020-01-10T22:30:49Z'>
		&lt;denchmark-link:https://github.com/olegmyrk&gt;@olegmyrk&lt;/denchmark-link&gt;
 I agree its failing in TF 2.1.0 but it has been fixed in the nightly version. Please find my gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/d3ec266927b357929cc2d2dc88e322a8/copy-of-untitled0.ipynb&gt;here&lt;/denchmark-link&gt;
. It bug fix will be shown in the next stable version. Thanks!
		</comment>
		<comment id='6' author='olegmyrk' date='2020-01-28T21:36:36Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35413&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35413&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>