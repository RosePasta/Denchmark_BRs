<bug id='38369' author='helenabdr' open_date='2020-04-08T22:42:30Z' closed_time='2020-04-29T17:52:21Z'>
	<summary>AttributeError: 'Tensor' object has no attribute '_in_graph_mode'</summary>
	<description>
I am having an error: 'Tensor' object has no attribute '_in_graph_mode'. I've debugged the code, and I think it's in this GradientTape function, but I don't know why. If anyone knows, please help me! :)
System information

TensorFlow version: 2.0 - '2.2.0-dev20200407'
OS Platform and Distribution: Linux Mint
Python version: Python 3.7.4

Describe the current behavior
I am trying to minimize a function using opt = tf.keras.optimizers.Adam() and I am getting a TypeError when I apply opt.apply_gradients.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;
def explain(
      self,
      validation_data,
      model,
      class_index,
      layer_name=None,
      colormap=cv2.COLORMAP_VIRIDIS,
      image_weight=0.7,
      _grid=True
  ):


# Returns: numpy.ndarray: Grid of all the inverted image or 4D array (batch_size, height, width, channels)
     
      tf.executing_eagerly()
      images, _ = validation_data

      if layer_name is None:
          layer_name = self.infer_target_layer(model)
      
      inverted_image = InvertedImage.get_optimize_image(
          images, model, class_index, layer_name
      )

      if _grid:
          return grid_display(inverted_image)
      else:
          return inverted_image

@staticmethod
def infer_target_layer(model):
 
     # Returns: str: Name of the target layer

      for layer in reversed(model.layers):
          # Select closest 4D layer to the end of the network.
          if len(layer.output_shape) == 4 and layer.name.count('conv') &gt; 0:
              return layer.name

      raise ValueError(
          "Model does not seem to contain 4D layer. Inverted image cannot be applied."
      )

@tf.function
def get_optimize_image(images, model, class_index, layer_name):
 
      grad_model = tf.keras.models.Model(
          [model.inputs], [model.get_layer(layer_name).output]
      )

      opt = tf.keras.optimizers.SGD(learning_rate=1-4, momentum=0.9)
      dtype = model.get_layer(layer_name).output.dtype
      tensor_image = tf.convert_to_tensor(images)

      opt_img = tf.Variable(1e-1 * tf.random.normal((tensor_image.shape[0], tensor_image.shape[1], tensor_image.shape[2], tensor_image.shape[3])), trainable=True)

      steps = 50
      for i in range(steps):
           with tf.GradientTape() as tape:
              
              inverted_feature = tf.cast(opt_img, dtype)
              content_feature = tf.cast(images, dtype)
                  
              conv_inverted_outputs = grad_model(inverted_feature)
              conv_content_outputs = grad_model(content_feature)
          
              loss = InvertedImage.get_loss(conv_content_outputs, conv_inverted_outputs, content_feature, inverted_feature)
              #print("Initial loss: {:.3f}".format(loss))

          grad = tape.gradient(loss, [conv_inverted_outputs, conv_content_outputs])
          print(grad)
          processed_grads = [g for g in grad]
          opt.apply_gradients(zip(processed_grads, [conv_inverted_outputs, conv_content_outputs]))

return opt_img
&lt;/denchmark-code&gt;

Loss function
&lt;denchmark-code&gt;def get_loss(conv_content_outputs, conv_inverted_outputs, content_feature, inverted_feature):
        euclidian = tf.norm(conv_content_outputs - conv_inverted_outputs, ord='euclidean') / tf.norm(conv_content_outputs, ord='euclidean')
        reg_alpha = 1e-7 * tf.math.reduce_sum(tf.norm(inverted_feature, ord=6))
        total_variation = 1e-8 * tf.math.reduce_sum(tf.image.total_variation(content_feature+inverted_feature))

        return euclidian + reg_alpha + total_variation 
&lt;/denchmark-code&gt;

Traceback
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/usr/local/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/local/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/helena/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/new_ptvsd/wheels/ptvsd/__main__.py", line 45, in &lt;module&gt;
    cli.main()
  File "/home/helena/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/new_ptvsd/wheels/ptvsd/../ptvsd/server/cli.py", line 361, in main
    run()
  File "/home/helena/.vscode/extensions/ms-python.python-2020.2.64397/pythonFiles/lib/python/new_ptvsd/wheels/ptvsd/../ptvsd/server/cli.py", line 203, in run_file
    runpy.run_path(options.target, run_name="__main__")
  File "/usr/local/lib/python3.7/runpy.py", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "/usr/local/lib/python3.7/runpy.py", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "/usr/local/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/helena/Documents/LAR_Celesc/lar-computer-vision/objdet-api/test_inverted_image.py", line 20, in &lt;module&gt;
    data, model, class_index=tabby_cat_class_index, layer_name="block5_conv3"
  File "/home/helena/Documents/LAR_Celesc/lar-computer-vision/objdet-api/tf_explain/core/inverted_image.py", line 54, in explain
    images, model, class_index, layer_name
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in __call__
    result = self._call(*args, **kwds)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 497, in _initialize
    *args, **kwds))
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File "/home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in converted code:
    /home/helena/Documents/LAR_Celesc/lar-computer-vision/objdet-api/tf_explain/core/inverted_image.py:125 get_optimize_image  *
        opt.apply_gradients(grads_and_vars)
    /home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:434 apply_gradients
        self._create_slots(var_list)
    /home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/gradient_descent.py:100 _create_slots
        self.add_slot(var, "momentum")
    /home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:574 add_slot
        var_key = _var_key(var)
    /home/helena/Documents/LAR_Celesc/larenv/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:1065 _var_key
        if var._in_graph_mode:

    AttributeError: 'Tensor' object has no attribute '_in_graph_mode'

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='helenabdr' date='2020-04-09T05:09:05Z'>
		&lt;denchmark-link:https://github.com/helenabdr&gt;@helenabdr&lt;/denchmark-link&gt;
, Please provide the complete standalone code to reproduce the issue. Thanks
		</comment>
		<comment id='2' author='helenabdr' date='2020-04-19T17:07:03Z'>
		&lt;denchmark-link:https://github.com/helenabdr&gt;@helenabdr&lt;/denchmark-link&gt;
,
please update on the above comment
		</comment>
		<comment id='3' author='helenabdr' date='2020-04-19T17:30:31Z'>
		
@helenabdr,
please update on the above comment
@Saduf2019, this is the complete code that I am using.

		</comment>
		<comment id='4' author='helenabdr' date='2020-04-20T07:36:13Z'>
		&lt;denchmark-link:https://github.com/helenabdr&gt;@helenabdr&lt;/denchmark-link&gt;

i ran the code shared by you and face &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/294176cf5f322c2bde08fea72527d888/38369.ipynb&gt;this error&lt;/denchmark-link&gt;
, please share a colab gist or code such that we can replicate the issue faced by you.
		</comment>
		<comment id='5' author='helenabdr' date='2020-04-21T00:26:28Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

You're right, here's Colab's link:&lt;denchmark-link:https://colab.research.google.com/drive/1QILUHXwpCbLpNh79pDGYxuhnwd1pplrR&gt;https://colab.research.google.com/drive/1QILUHXwpCbLpNh79pDGYxuhnwd1pplrR&lt;/denchmark-link&gt;
 . But I managed to fix the error, changing the Gradient Tape, but another error appeared as I described in the notebook. Thanks :)
		</comment>
		<comment id='6' author='helenabdr' date='2020-04-22T15:53:37Z'>
		&lt;denchmark-link:https://github.com/helenabdr&gt;@helenabdr&lt;/denchmark-link&gt;

i have tried to replicate the code shared in nightly and face &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/00a761f99042a9511654abced38d746b/38776.ipynb&gt;this error&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='helenabdr' date='2020-04-22T18:30:02Z'>
		
@helenabdr
i have tried to replicate the code shared in nightly and face this error

&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

Yes, now there is another error :/. But if you remove  from the code, it will run. Not perfectly or for something useful, but it will execute.
		</comment>
		<comment id='8' author='helenabdr' date='2020-04-29T02:32:53Z'>
		The error message did not get saved in the colab - could you copy it here? At a glance, I recommend creating the model and the optimizer outside the tf.function. You will definitely get errors because tf.function doesn't let you create variables inside it (and whenever you create a new model object, it creates a new set of variables).
		</comment>
		<comment id='9' author='helenabdr' date='2020-04-29T13:17:49Z'>
		Just dropping by to say that I encountered this issue as well,and I'm using 2.2.0rc3. I'll try to put together a reproduceable snippet/colab later today
		</comment>
		<comment id='10' author='helenabdr' date='2020-04-29T13:18:54Z'>
		&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 Here is the error trace and &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/38d375eed6af5933282c8907def34971/project1.ipynb&gt;here&lt;/denchmark-link&gt;
 is the colab gist.
&lt;denchmark-code&gt;_________________________________________________________________
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-6-f1109448c319&gt; in &lt;module&gt;()
     18     # Compute InvertedImage on VGG16
     19     grid = explainer.explain(
---&gt; 20         data, model, class_index=tabby_cat_class_index, layer_name="block5_conv3"
     21     )
     22     plt.figure(figsize=(10,10))

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    &lt;ipython-input-4-9f3866d1d8a5&gt;:93 get_optimize_image  *
        grad_model = tf.keras.models.Model(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:205 __init__  **
        self._init_batch_counters()
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:456 _method_wrapper
        result = method(self, *args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:212 _init_batch_counters
        self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:261 __call__
        return cls._variable_v2_call(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:255 _variable_v2_call
        shape=shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:66 getter
        return captured_getter(captured_previous, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:622 invalid_creator_scope
        "tf.function-decorated function tried to create "

    ValueError: tf.function-decorated function tried to create variables on non-first call.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='helenabdr' date='2020-04-29T15:47:41Z'>
		The problem is in the following line of code:
&lt;denchmark-code&gt;          opt.apply_gradients(zip(processed_grads, [conv_inverted_outputs, conv_content_outputs]))
&lt;/denchmark-code&gt;

Here conv_inverted_inputs and conv_content_outputs are not tf.Variable, and TF cannot apply optimizer updates on things which are not tf.Variables.
That said the error message could be better. &lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 can you work on the error message, by maybe checking for tensors earlier?
		</comment>
		<comment id='12' author='helenabdr' date='2020-04-29T17:48:56Z'>
		
The problem is in the following line of code:
          opt.apply_gradients(zip(processed_grads, [conv_inverted_outputs, conv_content_outputs]))

Here conv_inverted_inputs and conv_content_outputs are not tf.Variable, and TF cannot apply optimizer updates on things which are not tf.Variables.
That said the error message could be better. @tanzhenyu can you work on the error message, by maybe checking for tensors earlier?

Hi &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 , I fixed this error by changing to the following code:
opt.apply_gradients(zip(grad, grad_model.trainable_variables))
O link the updated link is &lt;denchmark-link:https://colab.research.google.com/drive/1QILUHXwpCbLpNh79pDGYxuhnwd1pplrR&gt;here&lt;/denchmark-link&gt;
, as &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 mentioned. But as said earlier, if you remove @tf.function from the code, it will run.
		</comment>
		<comment id='13' author='helenabdr' date='2020-04-29T17:52:21Z'>
		This is a well-documented limitation where you're not allowed to unconditionally create new keras models (including new variables) inside a tf.function.
		</comment>
		<comment id='14' author='helenabdr' date='2020-04-29T17:52:22Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38369&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38369&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='helenabdr' date='2020-04-29T18:15:37Z'>
		
The error message did not get saved in the colab - could you copy it here? At a glance, I recommend creating the model and the optimizer outside the tf.function. You will definitely get errors because tf.function doesn't let you create variables inside it (and whenever you create a new model object, it creates a new set of variables).

&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
, I don't know if I understood correctly. Should I set   outside ?
		</comment>
		<comment id='16' author='helenabdr' date='2020-04-29T18:39:37Z'>
		&lt;denchmark-link:https://github.com/helenabdr&gt;@helenabdr&lt;/denchmark-link&gt;
 yes, and pass it as argument to the function. Although for a simple, stateless optimizer like SGD it might not be necessary. But definitely do that with the model.
		</comment>
	</comments>
</bug>