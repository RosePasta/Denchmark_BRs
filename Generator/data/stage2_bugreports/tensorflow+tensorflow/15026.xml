<bug id='15026' author='hhao89' open_date='2017-12-01T06:39:42Z' closed_time='2018-01-24T20:13:33Z'>
	<summary>tensorflow 1.4 tf.keras gives different result compared with using keras directly</summary>
	<description>
I have tensorflow 1.4, when running the following code, the accuracy is different (78% vs. 34.90%) when I import Sequential, Dense, and model_from_json directly from keras (uncomment first 3 lines) compared with import from tensorflow.python.keras. Why is the big discrepancy?
(the data pima-indians-diabetes.csv is available at &lt;denchmark-link:http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data&gt;http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data&lt;/denchmark-link&gt;
)
#from keras.models import Sequential
#from keras.layers import Dense
#from keras.models import model_from_json
from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.models import Sequential, model_from_json
import numpy
import os
&lt;denchmark-h:h1&gt;fix random seed for reproducibility&lt;/denchmark-h&gt;

numpy.random.seed(7)
&lt;denchmark-h:h1&gt;load pima indians dataset&lt;/denchmark-h&gt;

dataset = numpy.loadtxt("pima-indians-diabetes.csv", delimiter=",")
&lt;denchmark-h:h1&gt;split into input (X) and output (Y) variables&lt;/denchmark-h&gt;

X = dataset[:,0:8]
Y = dataset[:,8]
&lt;denchmark-h:h1&gt;create model&lt;/denchmark-h&gt;

model = Sequential()
model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))
&lt;denchmark-h:h1&gt;Compile model&lt;/denchmark-h&gt;

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
&lt;denchmark-h:h1&gt;Fit the model&lt;/denchmark-h&gt;

model.fit(X, Y, epochs=150, batch_size=10, verbose=0)
&lt;denchmark-h:h1&gt;evaluate the model&lt;/denchmark-h&gt;

scores = model.evaluate(X, Y, verbose=0)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
&lt;denchmark-h:h1&gt;serialize model to JSON&lt;/denchmark-h&gt;

model_json = model.to_json()
with open("model.json", "w") as json_file:
json_file.write(model_json)
&lt;denchmark-h:h1&gt;serialize weights to HDF5&lt;/denchmark-h&gt;

model.save_weights("model.h5")
print("Saved model to disk")
	</description>
	<comments>
		<comment id='1' author='hhao89' date='2017-12-01T11:18:47Z'>
		I have no idea, but note that tf.keras is a tensorflow-specific re-implementation of the Keras API. AFAIK the two implementations are very different.
		</comment>
		<comment id='2' author='hhao89' date='2017-12-01T18:17:09Z'>
		&lt;denchmark-link:https://github.com/bchu&gt;@bchu&lt;/denchmark-link&gt;
 The re-implementation is expected to achieve the same functionality as keras, though the implementation is different. I actually tried on multiple datasets, the resulting accuracies of the two are very different  (78% vs. 34.90%; 98% vs. 50%).
		</comment>
		<comment id='3' author='hhao89' date='2017-12-02T11:59:57Z'>
		seems critical if it's true. cc &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='hhao89' date='2017-12-22T07:34:26Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='5' author='hhao89' date='2018-01-05T19:08:12Z'>
		Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='6' author='hhao89' date='2018-01-08T22:47:11Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 Do you have any update on this?
		</comment>
		<comment id='7' author='hhao89' date='2018-01-08T22:59:15Z'>
		No. Can anybody reproduce, with the same code/model, but with a different dataset?
		</comment>
		<comment id='8' author='hhao89' date='2018-01-24T19:58:28Z'>
		Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='9' author='hhao89' date='2018-01-24T20:13:33Z'>
		Unless anybody can share a script to reproduce the issue, this is a user error.
I can attest that the following model behaves in the same way on test data in tf.keras and external Keras:
model = Sequential()
model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))
However you may see differences due to the randomness of different initialization runs. Note that using "uniform" as initialization increases variance across runs.
		</comment>
		<comment id='10' author='hhao89' date='2019-06-30T02:33:53Z'>
		Dear &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 , I got a similar issue by using your method(tensorFlow 1.14.0, keras 2.2.4).  Here is my code.
&lt;denchmark-h:h3&gt;Source code(pure keras import)：&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Source code(tf.keras import):&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;from tensorflow import keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;commom parts:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import numpy as np
import random as rn
import tensorflow as tf

np.random.seed(2019)
rn.seed(2019)
tf.compat.v1.set_random_seed(2019)


batch_size = 128
num_classes = 10
epochs = 12

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 strides=(1, 1),
                 padding='valid',
                 dilation_rate=(1, 1), 
                 use_bias=True, 
                 kernel_initializer='glorot_uniform',
                 bias_initializer='zeros',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3),
                strides=(1, 1),
                 padding='valid',
                 dilation_rate=(1, 1), 
                 use_bias=True, 
                 kernel_initializer='glorot_uniform',
                 bias_initializer='zeros', 
                 activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Result(pure keras)：&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Epoch 1/12
60000/60000 [==============================] - 10s 161us/step - loss: 0.2684 - acc: 0.9177 - val_loss: 0.0599 - val_acc: 0.9812
Epoch 2/12
60000/60000 [==============================] - 6s 95us/step - loss: 0.0893 - acc: 0.9731 - val_loss: 0.0408 - val_acc: 0.9859
Epoch 3/12
60000/60000 [==============================] - 6s 92us/step - loss: 0.0658 - acc: 0.9797 - val_loss: 0.0344 - val_acc: 0.9884
Epoch 4/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0534 - acc: 0.9843 - val_loss: 0.0315 - val_acc: 0.9888
Epoch 5/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0471 - acc: 0.9859 - val_loss: 0.0297 - val_acc: 0.9903
Epoch 6/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0431 - acc: 0.9869 - val_loss: 0.0273 - val_acc: 0.9910
Epoch 7/12
60000/60000 [==============================] - 6s 94us/step - loss: 0.0379 - acc: 0.9881 - val_loss: 0.0258 - val_acc: 0.9911
Epoch 8/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0338 - acc: 0.9896 - val_loss: 0.0253 - val_acc: 0.9917
Epoch 9/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0282 - val_acc: 0.9911
Epoch 10/12
60000/60000 [==============================] - 6s 94us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0262 - val_acc: 0.9920
Epoch 11/12
60000/60000 [==============================] - 6s 93us/step - loss: 0.0275 - acc: 0.9910 - val_loss: 0.0253 - val_acc: 0.9918
Epoch 12/12
60000/60000 [==============================] - 6s 92us/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0273 - val_acc: 0.9916
Test loss: 0.02725972963081831
Test accuracy: 0.9916

&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Result(tf.keras):&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;Epoch 1/12
60000/60000 [==============================] - 7s 118us/sample - loss: 2.2976 - acc: 0.1186 - val_loss: 2.2629 - val_acc: 0.3077
Epoch 2/12
60000/60000 [==============================] - 4s 70us/sample - loss: 2.2391 - acc: 0.2488 - val_loss: 2.1936 - val_acc: 0.5507
Epoch 3/12
60000/60000 [==============================] - 4s 70us/sample - loss: 2.1677 - acc: 0.3645 - val_loss: 2.0994 - val_acc: 0.6332
Epoch 4/12
60000/60000 [==============================] - 4s 70us/sample - loss: 2.0664 - acc: 0.4451 - val_loss: 1.9656 - val_acc: 0.6864
Epoch 5/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.9266 - acc: 0.5110 - val_loss: 1.7900 - val_acc: 0.7180
Epoch 6/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.7591 - acc: 0.5528 - val_loss: 1.5817 - val_acc: 0.7464
Epoch 7/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.5767 - acc: 0.5961 - val_loss: 1.3670 - val_acc: 0.7686
Epoch 8/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.4031 - acc: 0.6257 - val_loss: 1.1722 - val_acc: 0.7870
Epoch 9/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.2534 - acc: 0.6560 - val_loss: 1.0119 - val_acc: 0.8047
Epoch 10/12
60000/60000 [==============================] - 4s 70us/sample - loss: 1.1304 - acc: 0.6804 - val_loss: 0.8855 - val_acc: 0.8194
Epoch 11/12
60000/60000 [==============================] - 4s 71us/sample - loss: 1.0355 - acc: 0.6964 - val_loss: 0.7891 - val_acc: 0.8317
Epoch 12/12
60000/60000 [==============================] - 4s 70us/sample - loss: 0.9585 - acc: 0.7164 - val_loss: 0.7156 - val_acc: 0.8390
Test loss: 0.7156027168273926
Test accuracy: 0.839

&lt;/denchmark-code&gt;

It has a different result. Any resolution？ &lt;denchmark-link:https://github.com/hhao89&gt;@hhao89&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bchu&gt;@bchu&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/shivaniag&gt;@shivaniag&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='hhao89' date='2019-07-22T14:39:16Z'>
		&lt;denchmark-link:https://github.com/wangyexiang&gt;@wangyexiang&lt;/denchmark-link&gt;
 The gap of performance between tf.keras and external keras in your example is because of the default learning rate of Adadelta. tf.keras uses 1e-3 while keras uses 1.0. Once you use 1.0 in tf.keras, you can still achieve the same performance obtained by external keras.
ref1: &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta&gt;https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta&lt;/denchmark-link&gt;

ref2: &lt;denchmark-link:https://keras.io/optimizers/&gt;https://keras.io/optimizers/&lt;/denchmark-link&gt;

Notebook: &lt;denchmark-link:https://colab.research.google.com/drive/1UI-QlfR6_sCmJu5XY8yH3397OM7EGXon&gt;https://colab.research.google.com/drive/1UI-QlfR6_sCmJu5XY8yH3397OM7EGXon&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='hhao89' date='2019-07-24T10:40:27Z'>
		
Once you use 1.0 in tf.keras, you can still achieve the same performance obtained by external keras.

I see. Thank you very much.  &lt;denchmark-link:https://github.com/WindQAQ&gt;@WindQAQ&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='hhao89' date='2019-12-04T16:24:02Z'>
		Hi, I get difference as well with the same model, but one done with Keras and the other with TensorFlow.
I check the default parameter (for the loss), but until now, I do not have found an explanation.
Maybe using "tf.compat.v1.RMSPropOptimizer"  is not the same than using optimizer="rmsprop" within model.compile (for keras) ?
		</comment>
	</comments>
</bug>