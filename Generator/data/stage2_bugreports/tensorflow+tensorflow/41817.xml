<bug id='41817' author='caffeine-lab' open_date='2020-07-28T11:14:32Z' closed_time='2020-08-11T15:21:08Z'>
	<summary>TPU Error: Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: Socket closed</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
https://www.kaggle.com/ratthachat/flickr-image-captioning-tpu-tf2-glove


TensorFlow installed from (source or binary): installed source


TensorFlow version (use command below): 2.2


Python version: 3.7


Describe the current behavior
I was running the provided code from Kaggle on a Google cloud TPU.
Hardware: v3-8
It was training fine till when I had 500000 Images. but the moment I increase the amount of data to 1 million. at almost the end of 1st epoch, I am getting the following error. I am new to TPUs so any help will be appreciated.
Traceback (most recent call last):
File "flickr-image-captioning-tpu-tf2-glove.py", line 178, in 
for (batch, inputs) in tqdm_notebook(enumerate(train_dist_dataset)): # by .repeat() this will indefinitely run
File "/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py", line 218, in iter
for obj in super(tqdm_notebook, self).iter(*args, **kwargs):
File "/usr/local/lib/python3.7/dist-packages/tqdm/std.py", line 1129, in iter
for obj in iterable:
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py", line 296, in next
return self.get_next()
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py", line 328, in get_next
global_has_value, replicas = _get_next_as_optional(self, self._strategy)
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py", line 192, in _get_next_as_optional
iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py", line 1150, in get_next_as_list
strict=True,
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
return func(*args, **kwargs)
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 1204, in cond
if pred:
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py", line 884, in bool
return bool(self._numpy())
File "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py", line 929, in _numpy
six.raise_from(core._status_to_exception(e.code, e.message), None)
File "", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnavailableError: Socket closed
Additional GRPC error information:
{"created":"@1595426699.706157313","description":"Error received from peer ipv4:10.255.26.210:8470","file":"external/com_github_grpc_grpc/src/core/lib/surface/call.cc","file_line":1056,"grpc_message":"Socket closed","grpc_status":14}
2020-07-22 14:05:01.237755: W tensorflow/core/distributed_runtime/eager/remote_tensor_handle_data.cc:76] Unable to destroy remote tensor handles. If you are running a tf.function, it usually indicates some op in the graph gets an error: Socket closed
Additional GRPC error information:
{"created":"@1595426699.706157313","description":"Error received from peer ipv4:10.255.26.210:8470","file":"external/com_github_grpc_grpc/src/core/lib/surface/call.cc","file_line":1056,"grpc_message":"Socket closed","grpc_status":14}
Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='caffeine-lab' date='2020-07-28T14:07:29Z'>
		&lt;denchmark-link:https://github.com/caffeine-lab&gt;@caffeine-lab&lt;/denchmark-link&gt;

Cold you please share stand alone code with dependencies to replicate this issue or if possible share a colab gist with the error faced.
With respect to the error faced please find similar issues below:
&lt;denchmark-link:https://www.kaggle.com/dimitreoliveira/bug-report-unavailableerror-socket-closed&gt;link&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36136#issuecomment-627731715&gt;link1&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='caffeine-lab' date='2020-08-04T14:22:58Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='caffeine-lab' date='2020-08-11T15:21:07Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='4' author='caffeine-lab' date='2020-08-11T15:21:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41817&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41817&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>