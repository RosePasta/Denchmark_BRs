<bug id='40258' author='kalaluthien' open_date='2020-06-08T02:58:07Z' closed_time='2020-06-08T07:00:41Z'>
	<summary>TFLiteConverter: failed to convert `tf.cast` (from `uint8` to `float32`)</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482)
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
Failed to convert tf model to tflite model when using tf.cast to convert tf.uint8 to tf.float32.
Because MLIR-based converter refuses uint8 input. (But tflite's CAST ops support conversion of uint8 to float32!)
I need to convert input with uint8 to float32 in order to feed integer input to float models in order to exploit same interface with other interger quantized models.
(actually float models = post-training float models but this is not a concern)
Describe the expected behavior
Success to convert Input tensor with integer type to float type.

&lt;denchmark-link:https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482&gt;https://gist.github.com/kalaluthien/1cb86948d8f8e58260a1ee81ca6f8482&lt;/denchmark-link&gt;

Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/usr/local/bin/toco_from_protos", line 8, in &lt;module&gt;
    sys.exit(main())
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.6/dist-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56, in execute
    enable_mlir_converter)
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py:497:13: error: 'tfl.cast' op operand #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer values, but got 'tensor&lt;1x14x14x3x!tf.quint8&gt;'
            *args, **kwds))
            ^
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='kalaluthien' date='2020-06-08T03:10:17Z'>
		Could you try the conversion with tf-nightly?
		</comment>
		<comment id='2' author='kalaluthien' date='2020-06-08T03:53:59Z'>
		&lt;denchmark-link:https://github.com/abattery&gt;@abattery&lt;/denchmark-link&gt;
 Thanks for your advice! The conversion has succeed.
I need to use (Customized TFLite Interpreter Wrapper) which based on tensorflow 2.1.0. But TFLite does not guarantee forward compatibility (as I know), so I need to check the tf2.2-converted_model can be used as-is for my specific case.
		</comment>
		<comment id='3' author='kalaluthien' date='2020-06-08T07:00:41Z'>
		It works. Thanks!
		</comment>
		<comment id='4' author='kalaluthien' date='2020-06-08T07:00:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40258&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40258&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='kalaluthien' date='2020-06-27T18:12:08Z'>
		I am still getting this error with tf-nightly (2.5.0.dev20200627):
&lt;denchmark-code&gt;input = tf.keras.layers.Input(shape=(360,360,3), dtype=tf.uint8, name='image')
output = tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32))(input)
model = tf.keras.models.Model(inputs=input, outputs=output)
model.summary()
model.save(MODEL_DIR)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
converter.allow_custom_ops = True
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.target_spec.supported_types = [tf.uint8, tf.float32]
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
image (InputLayer)           [(None, 360, 360, 3)]     0         
_________________________________________________________________
lambda (Lambda)              (None, 360, 360, 3)       0         
=================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0

2020-06-27 11:07:26.172512: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 6 nodes (3), 5 edges (3), time = 0.624ms.
2020-06-27 11:07:26.172527: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.015ms.
I0627 11:07:26.183743 140661122586432 lite.py:620] Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False
2020-06-27 11:07:26.185712: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-06-27 11:07:26.185744: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc("Func/PartitionedCall/input/_0"): error: requires all operands and results to have compatible element types
Traceback (most recent call last):
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py", line 199, in toco_convert_protos
    enable_mlir_converter)
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/wrap_toco.py", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: &lt;unknown&gt;:0: error: loc("Func/PartitionedCall/input/_0"): requires all operands and results to have compatible element types
&lt;unknown&gt;:0: note: loc("Func/PartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {device = ""} : (tensor&lt;?x360x360x3x!tf.quint8&gt;) -&gt; tensor&lt;?x360x360x3xui8&gt;


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./tf2lite.py", line 28, in &lt;module&gt;
    app.run(main)
  File "/home/alok/.local/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/home/alok/.local/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "./tf2lite.py", line 25, in main
    tflite_model = converter.convert()
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py", line 1072, in convert
    return super(TFLiteConverterV2, self).convert()
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py", line 896, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py", line 629, in convert
    **converter_kwargs)
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py", line 574, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/alok/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py", line 202, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: &lt;unknown&gt;:0: error: loc("Func/PartitionedCall/input/_0"): requires all operands and results to have compatible element types
&lt;unknown&gt;:0: note: loc("Func/PartitionedCall/input/_0"): see current operation: %1 = "tf.Identity"(%arg0) {device = ""} : (tensor&lt;?x360x360x3x!tf.quint8&gt;) -&gt; tensor&lt;?x360x360x3xui8&gt;

&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>