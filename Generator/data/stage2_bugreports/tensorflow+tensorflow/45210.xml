<bug id='45210' author='Sidong-Wei' open_date='2020-11-26T16:00:48Z' closed_time='2021-01-06T20:24:26Z'>
	<summary>Tensor shape signature is not parsed safely with `ParseTensors` of TF Lite InterpreterBuilder on Big Endian machines</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 2.3.1
Python version: 3.8.5
Bazel version (if compiling from source): 3.1.0
GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Currently, InterpreterBuilder is retrieving the shape_signature field of a flatbuffer tensor in the following way:
&lt;denchmark-code&gt;    size_t dims_signature_rank = 0;
    const int* dims_signature_data = nullptr;
    if (tensor-&gt;shape_signature()) {
      dims_signature_rank = tensor-&gt;shape_signature()-&gt;size();
      dims_signature_data = tensor-&gt;shape_signature()-&gt;data();
    }
&lt;/denchmark-code&gt;

The type of tensor-&gt;shape_signature() is a flatbuffer int array (flatbuffers::Vector), and accessing it using data() method is not safe as the data is always stored in Little Endian format, which will break for Big Endian machines. So whenever this optional shape_signature field is set in a TF Lite model, the interpreter will break on Big Endian machines.
To access the data correctly, we should use the Get() method of the flatbuffer array. There actually is a handy function defined in InterpreterBuilder already, FlatBufferIntArrayToVector, which is used for retrieving the tensor-&gt;shape() field as follow:
&lt;denchmark-code&gt;std::vector&lt;int&gt; dims = FlatBufferIntArrayToVector(tensor-&gt;shape());
&lt;/denchmark-code&gt;

This helper function definitely could work for tensor-&gt;shape_signature() as well because they both are integer array fields. The only issue is that currently, we are expecting two variables dims_signature_rank and dims_signature_data in the SetTensorParametersReadWrite function that we need to call later rather than an std::vector.
I have also tried some other methods to use Get() to retrieve the data, but it is a bit tricky as we need the shape signature data to live long enough for the SetTensorParametersReadWrite to finish writing the data into tensor.dims_signature field. To avoid making lot of changes and introducing new variables, I wonder if we could change the SetTensorParametersReadWrite function signature to make it accept one dims_signature vector instead of one size variable and one data variable. This could work because in tensorflow/lite/core/subgraph.h, the expected input arguement is like this:
&lt;denchmark-code&gt;inline TfLiteStatus SetTensorParametersReadWrite(
      int tensor_index, TfLiteType type, const char* name,
      const std::vector&lt;int&gt;&amp; dims, TfLiteQuantization quantization,
      bool is_variable = false, const size_t rank_dims_signature = 0,
      const int* dims_signature = nullptr) {
    return SetTensorParametersReadWrite(tensor_index, type, name, dims.size(),
                                        dims.data(), quantization, is_variable,
                                        rank_dims_signature, dims_signature);
  }
  TfLiteStatus SetTensorParametersReadWrite(
      int tensor_index, TfLiteType type, const char* name, const size_t rank,
      const int* dims, TfLiteQuantization quantization,
      bool is_variable = false, const size_t rank_dims_signature = 0,
      const int* dims_signature = nullptr);
&lt;/denchmark-code&gt;

Here we are using a reference to the dims vector and pass its size and data respectively to the function so that it will outlive the function call - the exact same thing could be done for dims_signature as well. If we get rid of dims_signature_rank and dims_signature_data and pass on a vector of dims_signature, we only need to make changes to these two places.
If such solution could work I will likely start a PR to it. Otherwise, please let me know if there are some other convenient ways to fix the parsing of shape_signature, thanks.
Describe the expected behavior
The shape_signature field should be parsed correctly on Big Endian machine.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;bazel test --host_javabase="@local_jdk//:jdk" --cache_test_results=no --build_tests_only --test_output=errors -- //tensorflow/lite/python:lite_v2_test
&lt;/denchmark-code&gt;

This test will fail on Big Endian machines.
Other info / logs
	</description>
	<comments>
		<comment id='1' author='Sidong-Wei' date='2020-12-09T08:48:09Z'>
		It's tricky to fix it here since I can't find Big Endian machines.
Please feel free to send a PR. I can review it.
		</comment>
		<comment id='2' author='Sidong-Wei' date='2020-12-09T16:17:44Z'>
		Thanks for the reply, I will test it using the approach I mentioned and send a PR shortly.
		</comment>
		<comment id='3' author='Sidong-Wei' date='2020-12-10T02:53:56Z'>
		Maybe we'd better use &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/45009&gt;#45009&lt;/denchmark-link&gt;
 for further discussion.
		</comment>
		<comment id='4' author='Sidong-Wei' date='2021-01-06T20:24:26Z'>
		Close issue as PR has been merged.
		</comment>
		<comment id='5' author='Sidong-Wei' date='2021-01-06T20:24:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45210&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45210&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>