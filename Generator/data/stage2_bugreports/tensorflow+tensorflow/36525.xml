<bug id='36525' author='artemmavrin' open_date='2020-02-07T04:24:48Z' closed_time='2020-02-27T01:19:49Z'>
	<summary>BinaryElementWiseOp::Operate template argument not used and can cause unnecessary errors</summary>
	<description>
System information

Have I written custom code: yes
OS Platform and Distribution: macOS 10
TensorFlow installed from: binary
TensorFlow version: 2.1
Python version: 3.7.2

Describe the current behavior
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/framework/numeric_op.h#L67-L109&gt;BinaryElementWiseOp&lt;/denchmark-link&gt;
 expects child classes to define an  method, which is used in the  method to perform the class's operation. This  method has an  template parameter  which represents the dimension of the inputs and output.



tensorflow/tensorflow/core/framework/numeric_op.h


        Lines 84 to 107
      in
      c7a0fc0






 // Dispatch to the descendant's Operate() function. 



 switch (a.dims()) { 



 #define NDIM_CASE(NDIMS)                                                       \ 



 case NDIMS: {                                                                \ 



 static_cast&lt;CHILD*&gt;(this)-&gt;template Operate&lt;NDIMS&gt;(context, a, b, output); \ 



 break;                                                                     \ 



   } 



 



 NDIM_CASE(0); 



 NDIM_CASE(1); 



 NDIM_CASE(2); 



 NDIM_CASE(3); 



 NDIM_CASE(4); 



 NDIM_CASE(5); 



 NDIM_CASE(6); 



 NDIM_CASE(7); 



 NDIM_CASE(8); 



 #undef NDIM_CASE 



 



 default: 



         context-&gt;SetStatus(errors::InvalidArgument( 



 "We only handle up to Tensor::dims() up to 8, not ", a.dims())); 



 break; 



     } 





However, this template parameter is not used by any BinaryElementWiseOp subclass; all subclasses currently call an OperateNoTemplate() method from inside Operate(). For example, ReLU:



tensorflow/tensorflow/core/kernels/relu_op.h


        Lines 66 to 79
      in
      c7a0fc0






 void OperateNoTemplate(OpKernelContext* context, const Tensor&amp; g, 



 const Tensor&amp; a, Tensor* output); 



 



 // INPUTS: 



 //   g (gradients): backpropagated gradients 



 //   a (inputs): either the inputs that were passed to ReluOp(), or its 



 //               outputs (using either one yields the same result here). 



 // OUTPUT: 



 //   gradients to backprop 



 template &lt;int NDIMS&gt; 



 void Operate(OpKernelContext* context, const Tensor&amp; g, const Tensor&amp; a, 



              Tensor* output) { 



 OperateNoTemplate(context, g, a, output); 



 } 





This leads to seemingly unnecessary errors like in the following Python code:
import tensorflow as tf

x = tf.reshape(0.0, [1] * 9)  # Too many dimensions for ReluGradOp
x = tf.Variable(x)
with tf.GradientTape() as tape:
  tape.watch(x)
  y = tf.nn.relu(x)

tape.gradient(y, x)  # tensorflow.python.framework.errors_impl.InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 9 [Op:ReluGrad]
The full list of BinaryElementWiseOp subclasses I was able to find is

ReluGradOp
Relu6GradOp
LeakyReluGradOp
EluGradOp
SeluGradOp
SoftsignGradOp
SoftplusGradOp
FakeQuantWithMinMaxArgsGradientOp

All of them follow the Operate() calling OperateNoTemplate() pattern. It seems like BinaryElementWiseOp and its subclasses can be refactored by removing the NDIMS template argument from Operate() and moving the contents of each subclass's OperateNoTemplate() method into the corresponding Operate() method.
	</description>
	<comments>
		<comment id='1' author='artemmavrin' date='2020-02-27T01:19:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36525&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>