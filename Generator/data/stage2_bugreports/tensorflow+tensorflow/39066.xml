<bug id='39066' author='raghavgurbaxani' open_date='2020-05-01T02:23:30Z' closed_time='2020-07-23T02:52:07Z'>
	<summary>Float 16 quantization error</summary>
	<description>
Hi
I get the following error -
"tflite.py", line 5, in &lt;module&gt; converter.target_spec.supported_types = [tf.lite.constants.FLOAT16] AttributeError: module 'tensorflow_core._api.v2.lite' has no attribute 'constants'
while trying the following code to quantize my .pb file to float 16
&lt;denchmark-code&gt;import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('out/')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.lite.constants.FLOAT16]
tflite_quant_model = converter.convert()
&lt;/denchmark-code&gt;

Tensorflow version 2.1.0, OS - Mac
	</description>
	<comments>
		<comment id='1' author='raghavgurbaxani' date='2020-05-01T21:14:45Z'>
		There are details on compatibility between  in 1.X to 2.0 available &lt;denchmark-link:https://www.tensorflow.org/lite/convert/1x_compatibility#liteconstants&gt;here&lt;/denchmark-link&gt;
.
Something like the following should work:
&lt;denchmark-code&gt;import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('out/')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_quant_model = converter.convert()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='raghavgurbaxani' date='2020-05-01T21:31:08Z'>
		Thank you for your response &lt;denchmark-link:https://github.com/gargn&gt;@gargn&lt;/denchmark-link&gt;
 . I tried the following code above and get the following error -
&lt;denchmark-code&gt; File "tflite.py", line 13, in &lt;module&gt;
    tflite_quanit_model = converter.convert()
  File "/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py", line 418, in convert
    raise ValueError("This converter can only convert a single "
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
$ python3 tflite.py 
2020-05-01 14:30:08.503886: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-01 14:30:08.522133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa891dc1140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-01 14:30:08.522153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File "tflite.py", line 5, in &lt;module&gt;
    tflite_quant_model = converter.convert()
  File "/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py", line 418, in convert
    raise ValueError("This converter can only convert a single "
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
&lt;/denchmark-code&gt;

Could you please help with this ?
P.S. I tried the steps at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34350&gt;#34350&lt;/denchmark-link&gt;

but when I try  print(saved_model_obj.signatures.keys()) I get KeysView(_SignatureMap({})) which suggests I cannot use concrete_func = saved_model_obj.signatures['serving_default'].
Can you suggest how do I go about this ?
The model that I am using can be found here - &lt;denchmark-link:https://github.com/argman/EAST/issues/296&gt;argman/EAST#296&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='raghavgurbaxani' date='2020-05-04T18:30:51Z'>
		&lt;denchmark-link:https://github.com/gargn&gt;@gargn&lt;/denchmark-link&gt;
  any update ?
		</comment>
		<comment id='4' author='raghavgurbaxani' date='2020-06-04T02:55:11Z'>
		same bug to me
Traceback (most recent call last): File "int_optimize_convert.py", line 7, in &lt;module&gt; converter.inference_type = tf.lite.constants.QUANTIZED_UINT8 AttributeError: module 'tensorflow._api.v2.lite' has no attribute 'constants'
		</comment>
		<comment id='5' author='raghavgurbaxani' date='2020-06-05T05:24:16Z'>
		&lt;denchmark-link:https://github.com/raghavgurbaxani&gt;@raghavgurbaxani&lt;/denchmark-link&gt;

Is this still an issue
		</comment>
		<comment id='6' author='raghavgurbaxani' date='2020-06-09T15:22:59Z'>
		Hi,
at first I had the same issue than I tried
converter = tf.lite.TFLiteConverter.from_saved_model('/path/to/saved/model')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_model = converter.convert()
and it worked perfectly. TF version: 2.3.0-dev20200608
		</comment>
		<comment id='7' author='raghavgurbaxani' date='2020-06-16T15:41:57Z'>
		&lt;denchmark-link:https://github.com/raghavgurbaxani&gt;@raghavgurbaxani&lt;/denchmark-link&gt;

Please update if this is still an issue.
		</comment>
		<comment id='8' author='raghavgurbaxani' date='2020-06-22T15:46:21Z'>
		Moving this to closed status as it works in 2.3-dev as informed.
		</comment>
		<comment id='9' author='raghavgurbaxani' date='2020-06-22T15:46:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39066&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39066&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='raghavgurbaxani' date='2020-06-24T16:55:51Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/stefano555&gt;@stefano555&lt;/denchmark-link&gt;
  it does not work for me . I tried with tf-nightly==2.3.0-dev20200608
But I still get the error -
&lt;denchmark-code&gt;File "try_fp16.py", line 2, in &lt;module&gt;
    converter = tf.lite.TFLiteConverter.from_saved_model('out/')
  File "/home/ahi/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py", line 980, in from_saved_model
    raise ValueError("Only support a single signature key.")
ValueError: Only support a single signature key.
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  can you help ?
		</comment>
		<comment id='11' author='raghavgurbaxani' date='2020-06-24T22:40:09Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  could you reopen the issue , I am still unable to get it to work.
I also tried replacing 'from_saved_model' to  'from_keras_model' with the keras model here
&lt;denchmark-link:https://drive.google.com/file/d/1hfIzGuQn-xApDYiucMDZvOCosyAVwvku/view&gt;https://drive.google.com/file/d/1hfIzGuQn-xApDYiucMDZvOCosyAVwvku/view&lt;/denchmark-link&gt;

and I get the issue
&lt;denchmark-code&gt; self._keras_model.save(temp_dir, save_format="tf")
AttributeError: 'str' object has no attribute 'save'
&lt;/denchmark-code&gt;

Both keras and tensorflow options do not work. :(
		</comment>
		<comment id='12' author='raghavgurbaxani' date='2020-07-09T01:06:49Z'>
		&lt;denchmark-link:https://github.com/raghavgurbaxani&gt;@raghavgurbaxani&lt;/denchmark-link&gt;
 May be something not right with the shared model. When I tried to load the model, code is throwing the following error. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/ab88f7074ef586b0b496f9b0f4e0f4a9/untitled953.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Can you please share model building code? Thanks!
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-4-ee9580594b88&gt; in &lt;module&gt;()
      1 import tensorflow as tf
----&gt; 2 model = tf.keras.models.load_model('/content/EAST_IC15_13_model.h5')
      3 converter = tf.lite.TFLiteConverter.from_keras_model(model)
      4 converter.optimizations = [tf.lite.Optimize.DEFAULT]
      5 converter.target_spec.supported_types = [tf.float16]

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    173     model_config = f.attrs.get('model_config')
    174     if model_config is None:
--&gt; 175       raise ValueError('No model found in config file.')
    176     model_config = json.loads(model_config.decode('utf-8'))
    177     model = model_config_lib.model_from_config(model_config,

ValueError: No model found in config file.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='13' author='raghavgurbaxani' date='2020-07-16T01:55:19Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='14' author='raghavgurbaxani' date='2020-07-23T02:52:05Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='15' author='raghavgurbaxani' date='2020-07-23T02:52:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39066&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39066&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>