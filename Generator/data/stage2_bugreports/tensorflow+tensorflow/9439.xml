<bug id='9439' author='vrenkens' open_date='2017-04-25T13:27:38Z' closed_time='2017-04-25T16:17:53Z'>
	<summary>small error in DynamicAttentionWrapper</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Not relevant

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Not relevant

TensorFlow installed from (source or binary):

Not relevant

TensorFlow version (use command below):

1.1

Bazel version (if compiling from source):

Not relevant

CUDA/cuDNN version:

Not relevant

GPU model and memory:

Not relevant

Exact command to reproduce:

Not relevant
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

line 465 in tensorflow/tensorflow/contrib/seq2seq/python/ops/dynamic_attention_wrapper.py says
'''
if not callable(cell_input_fn):.
'''
I think it should say
'''
if not callable(probability_fn):
'''
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

None
	</description>
	<comments>
		<comment id='1' author='vrenkens' date='2017-04-25T15:04:21Z'>
		The attention wrapper has been rewritten in master branch, there is no dynamic_attention_wrapper.py any more.
Anyway, I think this typo was fixed in commit &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/0557e8f90c1a2f027f4561c70558c6c836138058&gt;0557e8f&lt;/denchmark-link&gt;
. You can update your TensorFlow and check it.
		</comment>
		<comment id='2' author='vrenkens' date='2017-04-25T16:17:53Z'>
		&lt;denchmark-link:https://github.com/vrenkens&gt;@vrenkens&lt;/denchmark-link&gt;
, thanks for submitting this, but it looks like it is already fixed. Closing for now. Let us know if upgrading doesn't resolve your issues.
		</comment>
	</comments>
</bug>