<bug id='30367' author='murphyk' open_date='2019-07-03T18:02:44Z' closed_time='2019-08-07T18:31:51Z'>
	<summary>tf.test.is_gpu_available() raises error instead of returning False</summary>
	<description>
System information
python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"
v1.12.1-5259-ge703239 2.0.0-dev20190629
nvcc --version
&lt;denchmark-code&gt;nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130
&lt;/denchmark-code&gt;

Describe the current behavior
The code snippet below raises an error instead
of printing something
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow import keras
print("tf version {}".format(tf.__version__))
if tf.test.is_gpu_available():
    print(tf.test.gpu_device_name())
else:
    print("TF cannot find GPU")
&lt;/denchmark-code&gt;

Produces
&lt;denchmark-code&gt;tf version 2.0.0-dev20190629
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
&lt;ipython-input-8-b9f80ad1b5e1&gt; in &lt;module&gt;
     10 from tensorflow import keras
     11 print("tf version {}".format(tf.__version__))
---&gt; 12 if tf.test.is_gpu_available():
     13     print(tf.test.gpu_device_name())
     14 else:

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/test_util.py in is_gpu_available(cuda_only, min_cuda_compute_capability)
   1388 
   1389   try:
-&gt; 1390     for local_device in device_lib.list_local_devices():
   1391       if local_device.device_type == "GPU":
   1392         if (min_cuda_compute_capability is None or

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/device_lib.py in list_local_devices(session_config)
     39   return [
     40       _convert(s)
---&gt; 41       for s in pywrap_tensorflow.list_devices(session_config=session_config)
     42   ]

~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py in list_devices(session_config)
   2203     return ListDevicesWithSessionConfig(session_config.SerializeToString())
   2204   else:
-&gt; 2205     return ListDevices()
   2206 
   2207 

InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable

&lt;/denchmark-code&gt;

Describe the expected behavior
It should print "GeForce RTX 2080 with Max-Q Design"
(as PyTorch does).
Code to reproduce the issue
See above
	</description>
	<comments>
		<comment id='1' author='murphyk' date='2019-07-04T10:02:50Z'>
		&lt;denchmark-link:https://github.com/murphyk&gt;@murphyk&lt;/denchmark-link&gt;
 I executed the code on Colab with Tensorflow-gpu 2.0.0.dev20190703. Can you test once and let us know is this still an issue. Thanks!
		</comment>
		<comment id='2' author='murphyk' date='2019-07-04T14:55:08Z'>
		On my personal ubuntu 16 laptop, python 3.7. with cuda 10.0, pytorch 1.0,
tf 2.0 and jax installed,  I executed the script below
and only got errors with TF


 nvidia-smi
Thu Jul  4 07:51:10 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1
  |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr.
ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute
M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  On   | 00000000:01:00.0 Off |
 N/A |
| N/A   34C    P8     5W /  N/A |    486MiB /  7952MiB |      4%
 Default |
+-------------------------------+----------------------+----------------------+


+-----------------------------------------------------------------------------+
| Processes:                                                       GPU
Memory |
|  GPU       PID   Type   Process name                             Usage
   |
|=============================================================================|
|    0      1449      G   /usr/lib/xorg/Xorg
181MiB |
|    0      1642      G   /usr/bin/gnome-shell
106MiB |
|    0      2039      G   ...quest-channel-token=4691931010505848148
 80MiB |
|    0      3514      C   /home/murphyk/miniconda3/bin/python
 111MiB |
+-----------------------------------------------------------------------------+


import jax
import jax.numpy as np
from jax import grad, jacfwd, jacrev, jit, vmap
from jax.experimental import optimizers
print("jax version {}".format(jax.__version__))
from jax.lib import xla_bridge
print("jax backend {}".format(xla_bridge.get_backend().platform))

import torch
import torchvision
print("torch version {}".format(torch.__version__))
if torch.cuda.is_available():
    print(torch.cuda.get_device_name(0))
    print("current device {}".format(torch.cuda.current_device()))
else:
    print("Torch cannot find GPU")

import tensorflow as tf
from tensorflow import keras
print("tf version {}".format(tf.__version__))
if tf.test.is_gpu_available():
    print(tf.test.gpu_device_name())
else:
    print("TF cannot find GPU")



jax version 0.1.39
jax backend gpu
torch version 1.1.0
GeForce RTX 2080 with Max-Q Design
current device 0
tf version 2.0.0-dev20190629
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


---------------------------------------------------------------------------InternalError
                            Traceback (most recent call
last)&lt;ipython-input-4-b432327d0c41&gt; in &lt;module&gt;     40 from tensorflow
import keras     41 print("tf version {}".format(tf.__version__))---&gt;
42 if tf.test.is_gpu_available():     43
print(tf.test.gpu_device_name())     44 else:
~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/test_util.py
in is_gpu_available(cuda_only, min_cuda_compute_capability)   1388
1389   try:-&gt; 1390     for local_device in
device_lib.list_local_devices():   1391       if
local_device.device_type == "GPU":   1392         if
(min_cuda_compute_capability is None or
~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/client/device_lib.py
in list_local_devices(session_config)     39   return [     40
_convert(s)---&gt; 41       for s in
pywrap_tensorflow.list_devices(session_config=session_config)     42
]
~/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py
in list_devices(session_config)   2203     return
ListDevicesWithSessionConfig(session_config.SerializeToString())
2204   else:-&gt; 2205     return ListDevices()   2206    2207
InternalError: CUDA runtime implicit initialization on GPU:0 failed.
Status: unknown error
On Thu, Jul 4, 2019 at 3:09 AM gadagashwini ***@***.***&gt; wrote:
 @murphyk &lt;https://github.com/murphyk&gt; I executed the code on Colab with
 Tensorflow-gpu 2.0.0.dev20190703. Can you test once and let us know is this
 still an issue. Thanks!

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#30367?email_source=notifications&amp;email_token=ABDK6EARNDUPJAIWQMZXN2LP5XD55A5CNFSM4H5IJX32YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZG655Q#issuecomment-508423926&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/ABDK6EH5SL5O3GOC2UKXWMLP5XD55ANCNFSM4H5IJX3Q&gt;
 .



		</comment>
		<comment id='3' author='murphyk' date='2019-08-01T19:11:53Z'>
		&lt;denchmark-link:https://github.com/murphyk&gt;@murphyk&lt;/denchmark-link&gt;
 I think this is not related to  and it is more related to your GPU.
Are you running any other codes in parallel (when you ran  ) that are holding  as busy?
Your error says
. Thanks!
		</comment>
		<comment id='4' author='murphyk' date='2019-08-07T18:31:51Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='5' author='murphyk' date='2019-08-07T18:31:53Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30367&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30367&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>