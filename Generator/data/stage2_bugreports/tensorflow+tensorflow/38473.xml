<bug id='38473' author='netw0rkf10w' open_date='2020-04-12T15:39:40Z' closed_time='2020-04-13T20:55:14Z'>
	<summary>tf.data.Dataset.map() uses only 1 cpu</summary>
	<description>
System information

Have I written custom code: No
OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow installed from: binary
TensorFlow version: v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2
Python version: 3.7.5
CUDA/cuDNN version: 10.1.1/7.6.5
GPU model and memory: GTX 1080 Ti.

Describe the current behavior
When checking with the top command during training, only 1 CPU is used.
Describe the expected behavior
Multiple CPUs should be used.
Standalone code to reproduce the issue
You can take the code from the &lt;denchmark-link:https://www.tensorflow.org/tutorials/images/segmentation&gt;official TensorFlow tutorial on image segmentation&lt;/denchmark-link&gt;
.
For a more convincing experiment, replace the two lines:
train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test = dataset['test'].map(load_image_test)
with e.g.
train = dataset['train'].map(load_image_train, num_parallel_calls=4)
test = dataset['test'].map(load_image_test, num_parallel_calls=4)
	</description>
	<comments>
		<comment id='1' author='netw0rkf10w' date='2020-04-13T19:15:20Z'>
		tf.data.Dataset.map with num_parallel_calls is known to execute computation in parallel and the instructions provided here are not sufficient to reproduce the issue.
Please provide a minimal example that can be used to reproduce the issue. As a side note, instead of using top, I recommend using sar to measure CPU utilization.
		</comment>
		<comment id='2' author='netw0rkf10w' date='2020-04-13T19:31:34Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 I can certainly provide a stand-alone script for that, but just to make sure I didn't get it right:

In TensorFlow: top shows only 1 process, but htop shows multiple threads.
In PyTorch, top shows multiple processes for the same training.

So, I guess tf.data.Dataset.map also does it in parallel, but by using threads instead of different processes? Sorry if the question is stupid, I am not so familiar with these things.
		</comment>
		<comment id='3' author='netw0rkf10w' date='2020-04-13T20:00:05Z'>
		tf.data indeed uses multi-threading as it has lower overhead compared to multi-processing.
		</comment>
		<comment id='4' author='netw0rkf10w' date='2020-04-13T20:55:13Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Thanks for the confirmation. Let me close this issue.
		</comment>
		<comment id='5' author='netw0rkf10w' date='2020-04-13T20:55:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38473&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38473&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>