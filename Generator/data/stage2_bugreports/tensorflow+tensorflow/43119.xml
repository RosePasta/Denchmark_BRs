<bug id='43119' author='sharnoff' open_date='2020-09-10T18:31:53Z' closed_time='2020-09-17T16:37:15Z'>
	<summary>Segfault on absurdly large shuffle buffer for `make_csv_dataset`</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch linux kernel 5.8.7 (primary), Ubuntu 18.04 (container)
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): (git) v2.3.0-rc2-23-gb36436b087 (tf version) 2.3.0
Python version: 3.8.5
CUDA/cuDNN version: n/a
GPU model and memory: N/A -- run on a CPU

Describe the current behavior
Under certain (admittedly abnormal) shuffle buffer sizes, attempting to use the returned dataset fails with a segfault.
Standalone code to reproduce the issue
With a CSV with ~300 pieces of data per entry, the following snippet causes a segfault:
# Given:
#   ABSURDLY_LARGE_NUMBER = &lt;around 2×10^17&gt;
#   YOUR_CSV_PATH = &lt;somewhere you put your csv file&gt;
#   LABEL_COLUMN = &lt;label column from the csv&gt;
#   INPUT_COLUMNS = &lt;list of columns from the csv, len() around 300&gt;

import tensorflow as tf

# Helper function to get a dataset
def get_dataset(file_path, **kwargs):
    return tf.data.experimental.make_csv_dataset(
        file_path,
        batch_size=1,
        num_epochs=1,
        label_name=LABEL_COLUMN,
        select_columns=[LABEL_COLUMN] + INPUT_COLUMNS, # Around 300 entries
        header=True,
        shuffle=True,
        shuffle_buffer_size=ABSURDLY_LARGE_NUMBER, # &lt;- SOURCE OF ERROR
        **kwargs)

# Used later, with some model constructed with the keras `Sequential` API

model.evaluate(get_dataset(YOUR_CSV_PATH))
&lt;denchmark-link:https://gist.github.com/sharnoff/5dc5000fca80a2ab0f78b2786b75c2eb&gt;Full standalone example&lt;/denchmark-link&gt;

There might be (justified) responses like:

Well sure - a segfault should be expected if you're going to be doing silly things like this!

And that's perhaps fair, but bugs are often only dumb in hindsight, and this was a result of rapid modification of a script over time - pieces get left in that you might not expect.
&lt;denchmark-h:h2&gt;Possible cause&lt;/denchmark-h&gt;

[disclaimer] This is purely speculation; I'm basing this on the bits of information I found after
Because the maximum value of a 64-bit unsigned integer is around 2×10^19, and the requested buffer size was around 2×10^17, the size of an individual piece of data (at around 300 inputs) would have been enough to trigger overflow in the allocation size where it might not have been caught initially.
The segfault may have also been a result of the size of the requested allocation for the shuffle buffer.
When running inside GDB, an internal error was generated, reading:
&lt;denchmark-code&gt;../../gdb/utils.c:684: internal-error: virtual memory exhausted: can't allocate 5506620787261440008 bytes.
A problem internal to GDB has been detected, further debugging may prove unreliable
&lt;/denchmark-code&gt;

While an internal bug in GDB is a completely separate topic, the indication of the requested allocation size may be helpful here.
&lt;denchmark-h:h2&gt;Possible source&lt;/denchmark-h&gt;

(with the extensive help of a friend) I managed to track a possible source for a bad allocation down to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/shuffle_dataset_op.cc#L146&gt;these&lt;/denchmark-link&gt;
 two &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/shuffle_dataset_op.cc#L351&gt;lines&lt;/denchmark-link&gt;
, where an invalid allocation might be attempted. I believe these could be sources of the segfault (though there may be more)
	</description>
	<comments>
		<comment id='1' author='sharnoff' date='2020-09-11T05:39:39Z'>
		&lt;denchmark-link:https://github.com/sharnoff&gt;@sharnoff&lt;/denchmark-link&gt;

Looks like code is incomplete.Please, share colab link or simple standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='sharnoff' date='2020-09-11T07:08:36Z'>
		Thanks for the response - I've added &lt;denchmark-link:https://gist.github.com/sharnoff/5dc5000fca80a2ab0f78b2786b75c2eb&gt;the link&lt;/denchmark-link&gt;
 to the issue
		</comment>
		<comment id='3' author='sharnoff' date='2020-09-11T10:29:59Z'>
		&lt;denchmark-link:https://github.com/sharnoff&gt;@sharnoff&lt;/denchmark-link&gt;

I tried reproducing the in colab with TF version 2.3.0 and i see session is getting crashed. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/0518f4ae9de1da6640bcafda5a17a7cb/untitled336.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='sharnoff' date='2020-09-17T16:37:14Z'>
		This is "working as intended". tf.data does not guard against user choosing absurdly large values that run the underlying machine out of memory.
This is no different than say in C++ trying to create a vector that is absurdly large.
		</comment>
		<comment id='5' author='sharnoff' date='2020-09-17T16:37:17Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43119&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43119&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='sharnoff' date='2020-09-19T12:40:21Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 While I appreciate that this behavior might be expected in C++ (more at the end), Python  have protection against this. For example, below is the output I get in the Python interpreter with a similar type of error:
&lt;denchmark-code&gt;&gt;&gt;&gt; x = [None] * (1000**4)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
MemoryError
&lt;/denchmark-code&gt;

I understand that, in practice, this type of error only occurs through the user being dumb. But I don't belive that segfaults should be expected behavior for python code -- they make code particularly difficult to debug. Crucially, the majority of Tensorflow users are not fluent in C++ or other systems languages.
Finally, on the topic of this being expected behavior, it's worth noting that the C++ standard library  has protection against bad allocations -- a feature that is intentionally absent in abseil's implementation of . See &lt;denchmark-link:https://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique&gt;https://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique&lt;/denchmark-link&gt;
:

Exceptions
May throw std::bad_alloc or any exception thrown by the constructor of T. If an exception is thrown, this function has no effect.

		</comment>
	</comments>
</bug>