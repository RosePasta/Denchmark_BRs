<bug id='42441' author='PaulPauls' open_date='2020-08-17T22:01:56Z' closed_time='2020-08-24T18:36:26Z'>
	<summary>Erroneously triggering tf.function retracing warnings when rapidly creating new TF models.</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04, Google Colab
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): occurs in v2.3.0 and tf-nightly v2.4.0a20200817; NOT in v2.2.0
Python version: 3.7.7

Related Issues

#34025
#38561

Describe the current behavior
The function retracing warning (see below) is triggered constantly when creating multiple independent models. Similar bugs occured recently in the above mentioned issues, though while those occur when doing rapid predictions on the same model does this bug occur solely when creating and predicting multiple new models rapidly (which is necessary e.g. for TF evolutionary frameworks). The tf.function retracing warning is triggered after the creation of the first 5 models. The bug occurs in v2.3.0 and todays tf-nightly, though not in v2.2.0. I attempted workarounds mentioned in previous issues (setting experimental_relax_shapes to True, disabling eager execution and setting step to 1), though none worked. I also attempted to provide fixed input shape and batch_size as mentioned in the warning message, though this was also unsuccessful.
While I am no expert in tf.function does it seem to me that the counter to trigger the warning seems to be a global variable and not seperate for each model, therefore triggering the warning that excessive retracings for the current model occured even though it was only fast consecutive initial retracing for each one of multiple models. Just a hunch though.
Exact warning message:

WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function..predict_function at 0x7f3c67c45a60&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

Standalone code to reproduce the issue
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf

x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

for i in range(50):
    tf.print(f'Model {i}...')

    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Dense(units=2))
    model.add(tf.keras.layers.Dense(units=1))

    prediction = model.predict(x)
&lt;/denchmark-code&gt;

Google colab reproducing code: &lt;denchmark-link:https://colab.research.google.com/drive/1QLFNCDWw37x6kP2AajB4g3Lidn1oLRx7?usp=sharing&gt;https://colab.research.google.com/drive/1QLFNCDWw37x6kP2AajB4g3Lidn1oLRx7?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='PaulPauls' date='2020-08-18T09:07:50Z'>
		&lt;denchmark-link:https://github.com/PaulPauls&gt;@PaulPauls&lt;/denchmark-link&gt;

I have tried in colab with TF 2.3.0 and nightly version() and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/e1a45329766517a33e5783fd40d3a750/untitled259.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='PaulPauls' date='2020-08-18T18:54:45Z'>
		Hi &lt;denchmark-link:https://github.com/PaulPauls&gt;@PaulPauls&lt;/denchmark-link&gt;
, to clarify, for your use case you  expecting retracing to happen on each pass through the loop? This is because you're using a different model each time, correct? If so, it seems different to me compared the issues you've linked to, where they were trying to prevent extra retraces from happening on each pass through the loop. So I'm not sure the warnings are too unexpected since most of the time you would want to prevent excessive retracing.
Have you tried using model.predict_step() instead of model.predict? predict is a high-level end point that manages its own tf.function, so I think you're seeing the warning because you're falling into case (1). predict_step is just the logic of an inference step and shouldn't trigger the warning.
		</comment>
		<comment id='3' author='PaulPauls' date='2020-08-18T21:33:52Z'>
		Hi &lt;denchmark-link:https://github.com/nikitamaia&gt;@nikitamaia&lt;/denchmark-link&gt;
, thank you for your response. I am no expert in function retracing, though my understanding is that due to the functional way TF allows for model creation does TF also retrace the whole model graph the first time it is called to ensure that it is correctly generated. I therefore  expect retracing to happen once for each model when it is predicting for the first time - that is correct.
However, because I consider this normal behaviour am I confused from the warning. If functionally each model works fine and is not retraced multiple times and TF only displays this warning because it keeps track of model retracings globally (and not per model), then everything is resolved from my side. I do disagree with the decision to track model retracing globally and not per model (as it triggers the unnecessary warning when multiple models are created in a short time, even though everything is in order), though this then would be a deliberate developer decision and not a bug. I however would suggest to adjust the warning message accordingly, as the warning references a single model instance for which the warning is displayed and doesn't refer to global tracking of model retracings (therefore making me think something went wrong with my models).
I did link the related issues as according to the warning message I assumed that somehow through the creation of multiple models in a short time multiple function retracings occured for a single model. This would make the problem similar to the ones discussed in the related issues. At the time it was only a possible assumption that TF tracks function retracings globally.
And using predict_step() instead of predict(steps=1) did indeed work, thank you!
		</comment>
		<comment id='4' author='PaulPauls' date='2020-08-24T18:36:25Z'>
		Closing this issue now since a workaround was found.
		</comment>
		<comment id='5' author='PaulPauls' date='2020-08-24T18:36:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42441&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42441&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='PaulPauls' date='2020-11-04T07:12:45Z'>
		tf2.1.0: predict --&gt; predict_on_batch
		</comment>
	</comments>
</bug>