<bug id='39315' author='MaratZakirov' open_date='2020-05-08T14:00:58Z' closed_time='2020-12-21T00:20:19Z'>
	<summary>Failed to convert .pb file to rflite</summary>
	<description>
System information
Ubuntu 16.04
TensorFlow 2.1.0 installed from anaconda
Command used to run the converter or code if youâ€™re using the Python API
&lt;denchmark-code&gt;    import tensorflow as tf

    import numpy as np
    import torch

    def load_pb(path_to_pb):
        with tf.compat.v1.gfile.GFile(path_to_pb, 'rb') as f:
            graph_def = tf.compat.v1.GraphDef()
            graph_def.ParseFromString(f.read())
        with tf.compat.v1.Graph().as_default() as graph:
            tf.compat.v1.import_graph_def(graph_def, name='')
        return graph, graph_def

    tf_graph, graph_def = load_pb('./model120.pb')
    sess = tf.compat.v1.Session(graph=tf_graph)

    # Show tensor names in graph
    for op in tf_graph.get_operations():
        print(op.values())

    output_tensor = tf_graph.get_tensor_by_name('test_output:0')
    input_tensor = tf_graph.get_tensor_by_name('test_input:0')

    dummy_input = np.zeros(shape=(1, 3, 672, 672)).astype(np.float32)

    output = sess.run(output_tensor, feed_dict={input_tensor: dummy_input})

    print('&gt;==============================&lt;')
    print(output.shape)
    print(output)
    print('&lt;==============================&gt;')

    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/model120.pb', ['test_input'], ['test_output'])
    tflite_model = converter.convert()
    open("model120.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/marat/OCR/yolo3/torch2tflite.py", line 93, in &lt;module&gt;
    tflite_model = converter.convert()
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py", line 1007, in convert
    **converter_kwargs)
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py", line 203, in toco_convert_protos
    raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-05-08 16:44:59.629678: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib
2020-05-08 16:44:59.629746: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib
2020-05-08 16:44:59.629754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-05-08 16:45:00.211158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-05-08 16:45:00.216250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407935000 Hz
2020-05-08 16:45:00.216513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb58a38390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-08 16:45:00.216527: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-08 16:45:00.218143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-05-08 16:45:00.220636: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-05-08 16:45:00.220672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: saturn
2020-05-08 16:45:00.220678: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: saturn
2020-05-08 16:45:00.220727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0
2020-05-08 16:45:00.220762: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0
2020-05-08 16:45:00.220768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0
2020-05-08 16:45:00.240198: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If
2020-05-08 16:45:00.240265: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)
Fatal Python error: Aborted

Current thread 0x00007fc41d0f2700 (most recent call first):
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 56 in execute
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py", line 250 in _run_main
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py", line 299 in run
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py", line 40 in run
  File "/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 93 in main
  File "/home/marat/anaconda3/envs/cexp/bin/toco_from_protos", line 8 in &lt;module&gt;
Aborted (core dumped)
&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-code&gt;https://drive.google.com/open?id=12CN_l_VlAFFCt28lWvF9xqVfRAxY1M8b
&lt;/denchmark-code&gt;

Failure details
No information at all about exact converter failure reason
&lt;denchmark-code&gt;2020-05-08 16:54:52.542355: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)
Fatal Python error: Aborted
&lt;/denchmark-code&gt;

Its seems thath problem with this code com from pytorch F.interpolate 
	</description>
	<comments>
		<comment id='1' author='MaratZakirov' date='2020-05-09T07:29:38Z'>
		Hi Jaesung, seems to be related with control flow issue - can you take a look?
&lt;denchmark-code&gt;2020-05-08 16:45:00.240198: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='MaratZakirov' date='2020-05-11T10:02:50Z'>
		Hi MaratZakirov,
Could you convert the model with tf.enable_control_flow_v2()? &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2&gt;https://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='MaratZakirov' date='2020-05-12T09:41:30Z'>
		Hi &lt;denchmark-link:https://github.com/abattery&gt;@abattery&lt;/denchmark-link&gt;
 , thank you for answer

with tf.enable_control_flow_v2()

Did you mean tf.compat.v1.enable_control_flow_v2() ?
This:
&lt;denchmark-code&gt;    with tf.compat.v1.enable_control_flow_v2():
        converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/model120.pb', ['test_input'], ['test_output'])
        tflite_model = converter.convert()
        open("model120.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

Gives:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/home/marat/OCR/yolo3/torch2tflite.py", line 93, in &lt;module&gt;
    with tf.compat.v1.enable_control_flow_v2():
AttributeError: __enter__
&lt;/denchmark-code&gt;

I also tried to save *.pb (GraphDef file) to saved_model and permanently getting same result, same tflite file in terms of "executability".
It is seems that F.interpolate(x, scale_factor=2, mode='nearest') which yolo3 has kills process of transformation to tflite. I made module with only that operation and TF dies
		</comment>
		<comment id='4' author='MaratZakirov' date='2020-05-18T01:19:40Z'>
		The line, "tf.compat.v1.enable_control_flow_v2()" should be appeared before creating the graph.
		</comment>
		<comment id='5' author='MaratZakirov' date='2020-05-19T08:38:55Z'>
		
The line, "tf.compat.v1.enable_control_flow_v2()" should be appeared before creating the graph.
This is does not help either, see minimalistic example

&lt;denchmark-code&gt;import torch
import torch.nn.functional as F
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

class SimpleNet(torch.nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()

    def forward(self, x):
        x = F.interpolate(x, scale_factor=2, mode='nearest')
        return x

img_tensor = torch.zeros(1, 3, 128, 128)

if 1:
    model = SimpleNet().eval()
    dummy_output = model(img_tensor)
    print(dummy_output.detach().cpu().numpy().shape, dummy_output.detach().cpu().numpy())
    torch.onnx.export(model, img_tensor, './dummy.onnx', input_names=['test_input'], output_names=['test_output'])

if 1:
    import onnx
    import tensorflow.compat.v1 as tf
    tf.compat.v1.enable_control_flow_v2()
    from onnx_tf.backend import prepare
    model_onnx = onnx.load('./dummy.onnx')
    tf_rep = prepare(model_onnx)
    tf_rep.export_graph('./dummy.pb')

if 1:
    import tensorflow as tf

    def load_pb(path_to_pb):
        with tf.compat.v1.gfile.GFile(path_to_pb, 'rb') as f:
            graph_def = tf.compat.v1.GraphDef()
            graph_def.ParseFromString(f.read())
        with tf.compat.v1.Graph().as_default() as graph:
            tf.compat.v1.import_graph_def(graph_def, name='')
        return graph, graph_def

    tf_graph, graph_def = load_pb('./dummy.pb')
    sess = tf.compat.v1.Session(graph=tf_graph)

    # Show tensor names in graph
    for op in tf_graph.get_operations():
        print(op.values())

    output_tensor = tf_graph.get_tensor_by_name('test_output:0')
    input_tensor = tf_graph.get_tensor_by_name('test_input:0')

    dummy_input = img_tensor.numpy()

    output = sess.run(output_tensor, feed_dict={input_tensor: dummy_input})

    print('TF output')
    print(output.shape)
    print(output)

    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/dummy.pb', ['test_input'], ['test_output'])
    tflite_model = converter.convert()
    open("model120.tflite", "wb").write(tflite_model)
&lt;/denchmark-code&gt;

I print *.pb files (by using
&lt;denchmark-code&gt; for n in sess.graph.get_operations():
     print(n)
&lt;/denchmark-code&gt;

in both cases (w/ tf.compat.v1.enable_control_flow_v2() and w/o) and found that files are just the same.
See &lt;denchmark-link:https://drive.google.com/open?id=1QqA8N-Jzi8tT2ZR5nV_LL6IByOjEwN3g&gt;dummy.pb&lt;/denchmark-link&gt;

and &lt;denchmark-link:https://drive.google.com/open?id=1K0yk1MdLqrgskE-WF4PIE1uCoAON2Wlu&gt;dummy.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='MaratZakirov' date='2020-12-13T07:10:20Z'>
		&lt;denchmark-link:https://github.com/MaratZakirov&gt;@MaratZakirov&lt;/denchmark-link&gt;
 I think this was resolved in . I couldn't reproduce the issue. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/5538e8a959ff169e96467c6f7dca3837/untitled.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='7' author='MaratZakirov' date='2020-12-20T08:03:59Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='MaratZakirov' date='2020-12-21T00:20:18Z'>
		I am closing this issue. Please feel free to reopen if the issue persists again. Thanks!
		</comment>
		<comment id='9' author='MaratZakirov' date='2020-12-21T00:20:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39315&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39315&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>