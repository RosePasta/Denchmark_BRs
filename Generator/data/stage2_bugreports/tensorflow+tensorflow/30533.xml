<bug id='30533' author='ElPapi42' open_date='2019-07-09T15:12:32Z' closed_time='2019-10-15T16:53:12Z'>
	<summary>[TF2.0] trainable=True on tf.keras.Embedding result in "constant folding failed: Invalid argument: Unsupported type: 21"</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): tensorflow-gpu==2.0.0-beta1
Python version: 3.7.3
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): No
CUDA/cuDNN version: CUDA 10.0.130_411.31 / cuDNN 7.5.1.10
GPU model and memory: GTX 1060 6GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When enabling training on Embedding layer using keras subclassed model, an error is raised during model.fit():
2019-07-09 11:00:33.231719: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
This has a huge impact on training speed, that scales with the amount of data, in my full code, each epoch take more than 1 minute to complete(dataset of 869 tokenized strings, for train an encoder/decoder model), the code for reproduce this error dont have a noticeable impact because there is only one sample, already tokenized.
The error only is showed when an Embedding layer with trainable=True, is followed by an LSTM/GRU layer
Describe the expected behavior
LSTM/GRU supporting zero masking, and having no impact of training speed
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

class lstm(tf.keras.Model):
    def __init__(self):
        super(lstm, self).__init__()

        self.embedding = tf.keras.layers.Embedding(300, 2, mask_zero=True, trainable=True)
        self.encoder = tf.keras.layers.LSTM(2, return_sequences=True, return_state=False)

    def call(self, inputs):
        output = self.embedding(inputs)
        output = self.encoder(output)
        return output[0]

input_questions = np.array([[5, 12, 13, 189, 10, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)
output = np.array([[-0.00299482, 0.00096033]])

dataset = tf.data.Dataset.from_tensor_slices((input_questions, output)).shuffle(2).batch(1)

model = lstm()
model.compile(tf.keras.optimizers.Adadelta(1.0), tf.keras.losses.MeanSquaredError())
model.fit(dataset, epochs=10, verbose=2)
for sample, target in dataset.take(1):
    model(sample)
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
What the minimal code example above show in the console for me
&lt;denchmark-code&gt;2019-07-09 11:10:25.468004: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library nvcuda.dll                                                                                                      2019-07-09 11:10:26.569016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:    name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.733                                                    pciBusID: 0000:01:00.0                                                                                                  2019-07-09 11:10:26.588454: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                                                                                    2019-07-09 11:10:26.604012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0      2019-07-09 11:10:26.619218: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2                                                                       2019-07-09 11:10:26.643472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties:    name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.733                                                    pciBusID: 0000:01:00.0                                                                                                  2019-07-09 11:10:26.670895: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.                                                                                    2019-07-09 11:10:26.688869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0      2019-07-09 11:10:28.438683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:                                                                                            2019-07-09 11:10:28.466078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0                             2019-07-09 11:10:28.480348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N                             2019-07-09 11:10:28.500656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4712 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)  
                                                                              
Epoch 1/10                                                                                                             

WARNING: Logging before flag parsing goes to stderr.                                                                    
W0709 11:10:30.293739 15940 deprecation.py:323] From C:\ProgramData\Anaconda3\envs\tf2.0-gpu\lib\site-packages\tensorflow\python\keras\backend.py:3868: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.                                                                             
Instructions for updating:                                                                                              
Use tf.where in 2.0, which has the same broadcast rule as np.where                                                      

2019-07-09 11:10:38.997986: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21                                                                                        

2019-07-09 11:10:39.653444: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21      
                                                                                  
1/1 - 13s - loss: 1.5416e-05                                                                                            
Epoch 2/10                                                                                                              
1/1 - 1s - loss: 1.1537e-05                                                                                             
Epoch 3/10                                                                                                              
1/1 - 1s - loss: 8.7570e-06                                                                                             
Epoch 4/10                                                                                                              
1/1 - 1s - loss: 6.8737e-06                                                                                             
Epoch 5/10                                                                                                              
1/1 - 1s - loss: 5.6433e-06                                                                                             
Epoch 6/10                                                                                                              
1/1 - 1s - loss: 4.8554e-06                                                                                             
Epoch 7/10                                                                                                              
1/1 - 1s - loss: 4.3538e-06                                                                                             
Epoch 8/10                                                                                                              
1/1 - 1s - loss: 4.0314e-06                                                                                             
Epoch 9/10                                                                                                              
1/1 - 1s - loss: 3.8191e-06                                                                                             
Epoch 10/10                                                                                                             
1/1 - 1s - loss: 3.6735e-06                                                                                             

Press any key to continue . . .  
&lt;/denchmark-code&gt;

Edit 01: i think is somewhat ralated to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29525#issuecomment-509154149&gt;this&lt;/denchmark-link&gt;
 on &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29525&gt;#29525&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='ElPapi42' date='2019-07-09T21:24:32Z'>
		I manage to throw out some warnings, leaving exclusively:
2019-07-09 17:19:34.150417: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
The training speed impact of this error is still there, and the unique way i found for disable it completely is making trainable=False on the layer constructor:
self.embedding = tf.keras.layers.Embedding(300, 2, trainable=False)
here is the new code:
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

class lstm(tf.keras.Model):
    def __init__(self):
        super(lstm, self).__init__()

        self.masking = tf.keras.layers.Masking()
        self.embedding = tf.keras.layers.Embedding(300, 2, trainable=True)
        self.encoder = tf.keras.layers.LSTM(2, "sigmoid", return_sequences=True, return_state=False)

    def call(self, inputs):
        output = self.masking(inputs)
        output = self.embedding(output)
        output = self.encoder(output)
        return output[0]

input_questions = np.array([[5, 12, 13, 189, 10, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)
output = np.array([[-0.00299482, 0.00096033]])

dataset = tf.data.Dataset.from_tensor_slices((input_questions, output)).shuffle(2).batch(1)

model = lstm()
model.compile(tf.keras.optimizers.Adadelta(1.0), tf.keras.losses.MeanSquaredError())
model.fit(dataset, epochs=10, verbose=2)
for sample, target in dataset.take(1):
    model(sample)

&lt;/denchmark-code&gt;

As you can see, now instead of use mask_zeros=True in the Embedding layer constructor, i leave it false (as default), and use the tf.keras.layers.Masking, this give me the masking feature without any errors. The only one still there is the topic of the Issue.
		</comment>
		<comment id='2' author='ElPapi42' date='2019-07-10T08:19:43Z'>
		&lt;denchmark-link:https://github.com/ElPapi42&gt;@ElPapi42&lt;/denchmark-link&gt;
 I tried reproducing the issue and i do not see any errors while fitting the model. Please, see &lt;denchmark-link:https://colab.sandbox.google.com/drive/11g3kQiNYk4XTzp4h550-gPGCbUdemGGR#scrollTo=ewDZ7_374EJO&gt;https://colab.sandbox.google.com/drive/11g3kQiNYk4XTzp4h550-gPGCbUdemGGR#scrollTo=ewDZ7_374EJO&lt;/denchmark-link&gt;
 for your reference.Thanks!
		</comment>
		<comment id='3' author='ElPapi42' date='2019-07-10T12:16:53Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 I tried reproducing the issue too, the reported warnings can be found in the collab runtime logs
		</comment>
		<comment id='4' author='ElPapi42' date='2019-07-10T23:02:50Z'>
		
@ElPapi42 I tried reproducing the issue and i do not see any errors while fitting the model. Please, see https://colab.sandbox.google.com/drive/11g3kQiNYk4XTzp4h550-gPGCbUdemGGR#scrollTo=ewDZ7_374EJO for your reference.Thanks!

I dont have access to the link, request an account with access permisions
		</comment>
		<comment id='5' author='ElPapi42' date='2019-07-11T07:10:47Z'>
		&lt;denchmark-link:https://user-images.githubusercontent.com/51902062/61029611-0cd49580-a3d9-11e9-93a7-608bef26a063.png&gt;&lt;/denchmark-link&gt;

Please, see screenshot.Thanks!
		</comment>
		<comment id='6' author='ElPapi42' date='2019-07-11T08:07:31Z'>
		
@ravikyram I tried reproducing the issue too, the reported warnings can be found in the collab runtime logs

&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 Please look at the runtime logs. The fact that this kind of issue will only show up in logs when ran in collab has already been noted in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30263&gt;#30263&lt;/denchmark-link&gt;
 - and this is an actual issue, reported on multiple occasions but seemingly unsolved as of now...
		</comment>
		<comment id='7' author='ElPapi42' date='2019-07-11T20:50:37Z'>
		Adding Eugene who is the expert of grappler.
		</comment>
		<comment id='8' author='ElPapi42' date='2019-07-11T22:00:38Z'>
		&lt;denchmark-link:https://github.com/rmlarsen&gt;@rmlarsen&lt;/denchmark-link&gt;
 rings any bells?
		</comment>
		<comment id='9' author='ElPapi42' date='2019-07-19T10:52:25Z'>
		Any advance on this? its really annoying
		</comment>
		<comment id='10' author='ElPapi42' date='2019-07-19T13:11:11Z'>
		
I manage to throw out some warnings, leaving exclusively:
2019-07-09 17:19:34.150417: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21
The training speed impact of this error is still there, and the unique way i found for disable it completely is making trainable=False on the layer constructor:
self.embedding = tf.keras.layers.Embedding(300, 2, trainable=False)
here is the new code:
import tensorflow as tf
import numpy as np

class lstm(tf.keras.Model):
    def __init__(self):
        super(lstm, self).__init__()

        self.masking = tf.keras.layers.Masking()
        self.embedding = tf.keras.layers.Embedding(300, 2, trainable=True)
        self.encoder = tf.keras.layers.LSTM(2, "sigmoid", return_sequences=True, return_state=False)

    def call(self, inputs):
        output = self.masking(inputs)
        output = self.embedding(output)
        output = self.encoder(output)
        return output[0]

input_questions = np.array([[5, 12, 13, 189, 10, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)
output = np.array([[-0.00299482, 0.00096033]])

dataset = tf.data.Dataset.from_tensor_slices((input_questions, output)).shuffle(2).batch(1)

model = lstm()
model.compile(tf.keras.optimizers.Adadelta(1.0), tf.keras.losses.MeanSquaredError())
model.fit(dataset, epochs=10, verbose=2)
for sample, target in dataset.take(1):
    model(sample)

As you can see, now instead of use mask_zeros=True in the Embedding layer constructor, i leave it false (as default), and use the tf.keras.layers.Masking, this give me the masking feature without any errors. The only one still there is the topic of the Issue.

I discover something, in the code above, i make sigmoid the activation of the lstm for get rid of:
2019-07-19 09:01:52.787220: W tensorflow/core/grappler/optimizers/implementation_selector.cc:199] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_395_571' and '__inference___backward_cudnn_lstm_395_571_specialized_for_Adadelta_gradients_lstm_lstm_1_StatefulPartitionedCall_grad_StatefulPartitionedCall_at___inference_keras_scratch_graph_1552' both implement 'lstm_ca0befc9-b0cc-4e66-adc9-7da601846478' but their signatures do not match
activation="sigmoid" avoid use the cdnn implementation of the LSTM layer. Playing around with the code i notice that leaving activation="tanh" (allowing cDDN implementation), suppress the error Unsupported Type 21, but creates a new one related to the signatures, the one that push me before to make activation="sigmoid" on lstm layer
here is the new code, that not produce Unsupported Type 21 error
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

class lstm(tf.keras.Model):
    def __init__(self):
        super(lstm, self).__init__()

        self.masking = tf.keras.layers.Masking()
        self.embedding = tf.keras.layers.Embedding(300, 2, trainable=True)
        self.encoder = tf.keras.layers.LSTM(2, "tanh", return_sequences=True, return_state=False)

    def call(self, inputs):
        output = self.masking(inputs)
        output = self.embedding(output)
        output = self.encoder(output)
        return output[0]

input_questions = np.array([[5, 12, 13, 189, 10, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).astype(float)
output = np.array([[-0.00299482, 0.00096033]])

dataset = tf.data.Dataset.from_tensor_slices((input_questions, output)).shuffle(2).batch(1)

model = lstm()
model.compile(tf.keras.optimizers.Adadelta(1.0), tf.keras.losses.MeanSquaredError())
model.fit(dataset, epochs=10, verbose=2)
for sample, target in dataset.take(1):
    model(sample)
&lt;/denchmark-code&gt;

This can point that the Unsupported Type 21 error is produced on the Standard LSTM/GRU implementation of Tensorflow
The problem with the new error is that tells skip the optimization completely, and that sounds bad
PD: as you can see, the embedding layer has trainable=True and Unsupported type 21 is not showing
		</comment>
		<comment id='11' author='ElPapi42' date='2019-07-19T14:34:35Z'>
		Obviously the Unsupported Type 21 Error is something that must be checked, there is something broke
		</comment>
		<comment id='12' author='ElPapi42' date='2019-07-19T18:56:07Z'>
		This was fixed in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/24174643a75e819b8ce01fd70d45d03616e50071&gt;2417464&lt;/denchmark-link&gt;
, should be in nightly build
		</comment>
		<comment id='13' author='ElPapi42' date='2019-07-19T18:57:30Z'>
		For the implementation selector problems I think there is work in progress by &lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='14' author='ElPapi42' date='2019-07-19T19:07:51Z'>
		Can you give the pip command for install tf2.0 nightly build?
		</comment>
		<comment id='15' author='ElPapi42' date='2019-07-25T11:54:42Z'>
		any advances on this issue?
		</comment>
		<comment id='16' author='ElPapi42' date='2019-08-04T16:35:34Z'>
		Any patches or solutions ? please we need some help . thank per advance
		</comment>
		<comment id='17' author='ElPapi42' date='2019-08-04T21:42:17Z'>
		
This was fixed in 2417464, should be in nightly build

pip install tf-nightly-gpu-2.0-preview or pip install tf-nightly-2.0-preview (depending whether you want GPU support or not ; you could also want and get a nightly build of tf 1.15 instead)
That being said, the fix that was deployed three weeks ago merely avoids the warning message (which saves a little time and avoids wary print outs), but I believe the underlying issue has not been fixed yet (hopefully this is indeed work in progress).
		</comment>
		<comment id='18' author='ElPapi42' date='2019-10-08T17:02:51Z'>
		&lt;denchmark-link:https://github.com/ElPapi42&gt;@ElPapi42&lt;/denchmark-link&gt;
 Is this still an issue? Can you check with  and let us know whether the issue persists with latest TF version. I ran with  and don't see any constant folding error. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/6ebdf409b24e112f7979fc0e31d5ee8e/untitled541.ipynb&gt;gist here&lt;/denchmark-link&gt;
 Thanks!
		</comment>
		<comment id='19' author='ElPapi42' date='2019-10-15T15:32:06Z'>
		I think this was solved, but i dont have time to check right now. The project where this appeared is in an unusable state right now, must work on it for test.
		</comment>
		<comment id='20' author='ElPapi42' date='2019-10-15T16:53:12Z'>
		I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='21' author='ElPapi42' date='2019-10-15T16:53:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30533&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30533&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>