<bug id='952' author='caisq' open_date='2016-02-01T18:16:05Z' closed_time='2016-02-03T17:18:49Z'>
	<summary>Error in //tensorflow/core:ops_array_grad_test</summary>
	<description>
On a machine with a GPU, under the GPU configuration, I ran the command: bazel test -c opt --config=cuda //tensorflow/core:ops_array_grad_test
and I got the following error (see highlight in bold font)
&lt;denchmark-h:h2&gt;exec ${PAGER:-/usr/bin/less} "$0" || exit 1&lt;/denchmark-h&gt;

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcurand.so.7.0. LD_LIBRARY_PATH:
I tensorflow/stream_executor/cuda/cuda_rng.cc:333] Unable to load cuRAND DSO.
Running main() from test_main.cc
[==========] Running 4 tests from 1 test case.
[----------] Global test environment set-up.
[----------] 4 tests from ArrayGradTest
[ RUN      ] ArrayGradTest.PackGrad
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2785
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 3.62GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x704a80000 extends to 0x7ec261000
[       OK ] ArrayGradTest.PackGrad (481 ms)
[ RUN      ] ArrayGradTest.UnpackGrad
I tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
[       OK ] ArrayGradTest.UnpackGrad (2 ms)
[ RUN      ] ArrayGradTest.ConcatGrad
I tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)

[[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
**W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c21f10 Compute status: Not found: 
[[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
[[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]

[[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
[[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]
[[Node: dx/_9 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_18_dx", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"&lt;/denchmark-link&gt;
]]
**W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c224b0 Compute status: Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;

**         [[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
[[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]
[[Node: dx/_11 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_20_dx", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"&lt;/denchmark-link&gt;
]]

[[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
[[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]
[[Node: dx/_13 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_22_dx", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"&lt;/denchmark-link&gt;
]]

[[Node: n8 = ZerosLike&lt;denchmark-link:n0&gt;T=DT_INT32&lt;/denchmark-link&gt;
]]
[[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]
[[Node: dx/_9 = _Recv&lt;denchmark-link:&gt;client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_18_dx", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"&lt;/denchmark-link&gt;
]])
external/bazel_tools/tools/test/test-setup.sh: line 51:  9618 Aborted                 (core dumped)
	</description>
	<comments>
		<comment id='1' author='caisq' date='2016-02-01T18:29:14Z'>
		Your particular problem is that the ZerosLikeOp kernel defined in constant_op.cc is only registered for float and double (contant_op.cc:234/235), instead it should be registered for all numeric types.
If you can write a fix, that would be awesome.
There's a larger issue here that should be cleaned up. We have at least three different zeros_like implementations lying around: One zeros_like in array_ops.py, one ZerosLikeOp in constant_op.cc, and one ZerosLike method in control_flow_ops.py's ControlFlowState (that last one may be legitimate, but should be refactored to use ZerosLikeOp). Assigning &lt;denchmark-link:https://github.com/sherrym&gt;@sherrym&lt;/denchmark-link&gt;
 for triage on that issue.
		</comment>
		<comment id='2' author='caisq' date='2016-02-05T18:28:51Z'>
		It appears that although the change set fixed the ZerosLikeOp-not-defined-for-GPU issue, the test
bazel test -c opt --config=cuda //tensorflow/core:ops_array_grad_test
still fails, with a seg fault:

[       OK ] ArrayGradTest.PackGrad (505 ms)
[ RUN      ] ArrayGradTest.UnpackGrad
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
[       OK ] ArrayGradTest.UnpackGrad (3 ms)
[ RUN      ] ArrayGradTest.ConcatGrad
I tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)
external/bazel_tools/tools/test/test-setup.sh: line 51: 20332 Segmentation fault      (core dumped) "$@"

		</comment>
		<comment id='3' author='caisq' date='2016-02-05T19:54:11Z'>
		&lt;denchmark-link:https://github.com/zffchen78&gt;@zffchen78&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>