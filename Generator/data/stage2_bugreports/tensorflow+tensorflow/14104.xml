<bug id='14104' author='helange23' open_date='2017-10-30T18:44:32Z' closed_time='2018-01-05T04:26:49Z'>
	<summary>tf.scatter_add causes error in loop</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, it's below.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0
Python version:  3.5
Bazel version (if compiling from source):
CUDA/cuDNN version: no CUDA
GPU model and memory: no GPU
Exact command to reproduce:

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I found very strange behavior of tf.scatter_add: I created a tf.while_loop that creates a Tensor wrapped inside a tf.Variable. If I don't add something to the Variable outside the loop, tensorflow causes an error telling me that the Variable is not mutable.
I asked the on StackOverflow and was told to create a bug report.
&lt;denchmark-link:https://stackoverflow.com/questions/46935216/tf-scatter-add-causes-error-in-loop?noredirect=1#comment80914069_46935216&gt;https://stackoverflow.com/questions/46935216/tf-scatter-add-causes-error-in-loop?noredirect=1#comment80914069_46935216&lt;/denchmark-link&gt;

Uncommenting the commented line removes the error. But I don't think this is intended behavior.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

import tensorflow as tf
m = 25
batch_num = 32
num_bus = 50
C = tf.zeros((m, batch_num, num_bus, m),tf.float64)
C = tf.Variable(C)
c = tf.ones((batch_num, num_bus, m), tf.float64)
#C = tf.scatter_add(C,0,c)
k = tf.constant(1)
stop_cond = lambda k,C: k&lt;m
def construct_C(k, C):
upd_c = c+1
C = tf.scatter_add(C,k,upd_c)
return k+1,C
k,C = tf.while_loop(stop_cond,construct_C, (k,C))
sess = tf.Session()
sess.run(tf.global_variables_initializer())
C1 = sess.run(C)
	</description>
	<comments>
		<comment id='1' author='helange23' date='2017-10-31T05:13:52Z'>
		Thank you so much for taking the time to file an issue as &lt;denchmark-link:https://github.com/ebrevdo&gt;@ebrevdo&lt;/denchmark-link&gt;
 requested. I shall now punt this tf.while_loop API issue to him.
		</comment>
		<comment id='2' author='helange23' date='2017-10-31T06:17:09Z'>
		This is a case of tf.Variable being handled differently from a ref tensor by while_loop.  Thanks for reporting it.
		</comment>
		<comment id='3' author='helange23' date='2017-12-20T19:16:27Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='4' author='helange23' date='2018-01-04T19:13:39Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='5' author='helange23' date='2018-01-05T04:26:49Z'>
		Looking more carefully; I see that you're expecting the mutable variable C in the body of construct_C.  But Variables are not like regular tensors; you cannot pass them through a tf.while_loop in this way.  Instead what you want to do is:
def construct_C(k):
  with tf.control_dependencies([tf.scatter_add(C, k, upd_c)]):
    return k + 1

then later:

with tf.control_dependencies([tf.while_loop(stop_cond, construct_C, [tf.constant(1)]):
  constructed_C_value = tf.identity(C)  # or C.read_value(), i think
the reason is that C, as a Variable, exists outside of regular flow control.  you can mutate it as you see fit.  We do provide some sugar, like C1 = tf.scatter_add(C, ...), but all this does is creates a control dependency to update the variable pointed to by both C and C1, to be executed when you access C1.  This kind of sugar doesn't propagate through tf.while_loop; but the example I gave above should work just fine.
		</comment>
	</comments>
</bug>