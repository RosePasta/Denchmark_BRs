<bug id='27819' author='stellaluminary' open_date='2019-04-13T14:25:05Z' closed_time='2019-12-02T20:31:05Z'>
	<summary>Tensorflow 2.0.0 gpu Performance Issue on RTX 2060, win 10</summary>
	<description>
Hi I'm not used to write English so Please Understand my situation.
Actually My proplem is not quite sure about performance problem or just myself problem.
But No Solution appear in my circumstance include searching stackover-flow or googling.
And also in my country quite many of them is saying same issue about it.
And Yeah i do almost everything concern this problem searching googling or blogs or sites
So I decide to ask u to help me out.
My problem is I Change my GPU device NVIDIA GTX1050 TI to RTX 2060.
And i ran 1050 ti in tensorflow gpu well enough but when i change my GPU and unistall CUDA 9 before version and reinstall CUDA 10 and reinstall matching cudnn also
Cause As u know CUDA 10 is the only choice of RTX Series.
But After Changing my GPU and CUDA, cudnn, My GPU performance is too low to confuse to using it. Yeah It's working But TOO LOW PERFORMANCE!
Actually I usually jupyter notebook in anaconda env system and my sub env 1 is tensorflow 2.0.0 alpha and sub env 2 is tensorflow 1.13.
But When i build conv model and train images,  Both tensorflow version of gpu is too low under 15% And CPU usage is almost 100%, RAM 60~70%
Usually GPU use 5 ~ 10%.
When i use 1050 ti, GPU performance is almost 80 to 90% high
And I know tensorflow recommend docker Linux only but Even though I install All of these gpu concern program and other needed program.
So i sincerely ask tensorflow Is this Right Performance or My OS problem or some other probelm
I want to be clear Answer about it.
And Even if tensorflow 2.0 is not fit on windows 10, Why my another env tensorflow 1.13 version of GPU is also low and CPU is almost 100% right now
and Here is the image that Run tensorflow 2.0 tutorial about GPU
And My GPU is Fine Device proof png file is upload
Thank you for reading my nonsence skill of eng writing.
&lt;denchmark-link:https://user-images.githubusercontent.com/43261434/56080846-32391e00-5e41-11e9-95cb-476a0404cf2d.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/43261434/56080864-572d9100-5e41-11e9-9e8c-271faf53645f.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/43261434/56080973-a0321500-5e42-11e9-9176-ae339b5caf26.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/43261434/56080974-a0321500-5e42-11e9-836c-6b42dfd85cc3.png&gt;&lt;/denchmark-link&gt;

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Anaconda
TensorFlow version (use command below): Tensorflow 2.0.0
Python version: 3.6.8
Bazel version (if compiling from source): None
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CUDA 10, cuDNN 7.5(2.21.2019 for CUDA 10)
GPU model and memory: RTX 2060 Emtec &amp; 6G RAM(Edited)
CPU : intel i5-8400
Computer RAM - 8G

	</description>
	<comments>
		<comment id='1' author='stellaluminary' date='2019-04-13T21:17:13Z'>
		The CUDA10 is not just for NVIDIA Turing/Volta GPUs.it's work well on NVIDIA Geforce GTX1080TI.
If you plan to evaluate your GPU DL performance, use tensorflow/benchmark.In addition, why does your RTX2060 have 8GB of video memory, which seems wrong?
		</comment>
		<comment id='2' author='stellaluminary' date='2019-04-15T04:18:40Z'>
		
The CUDA10 is not just for NVIDIA Turing/Volta GPUs.it's work well on NVIDIA Geforce GTX1080TI.
If you plan to evaluate your GPU DL performance, use tensorflow/benchmark.In addition, why does your RTX2060 have 8GB of video memory, which seems wrong?

Sorry about Wrongly Writing GPU RAM Memory. I Miss Understand Which is my computer ram.
And Thank you apply my Message.
However I searched internet and i can't find tf 2.0-alpha version of tensorflow / benchmark In windows. SO if you recommend any other method please leave a message
		</comment>
		<comment id='3' author='stellaluminary' date='2019-04-23T17:44:27Z'>
		&lt;denchmark-link:https://github.com/stellaluminary&gt;@stellaluminary&lt;/denchmark-link&gt;
 I can see benchmark tests for master branch &lt;denchmark-link:https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks&gt;here&lt;/denchmark-link&gt;
 and the results are &lt;denchmark-link:https://www.tensorflow.org/guide/performance/benchmarks&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='stellaluminary' date='2019-10-27T16:23:20Z'>
		i have a same issue did you solve it ?
		</comment>
		<comment id='5' author='stellaluminary' date='2019-12-02T16:05:12Z'>
		Same here.
Every possible check says GPU is working, but calculations are very slow (much slower than on Google Colab) and Task Manager shows CPU working on 30% and GPU almost 0%.
		</comment>
		<comment id='6' author='stellaluminary' date='2019-12-02T20:31:04Z'>
		Sorry for the long delay. &lt;denchmark-link:https://github.com/stellaluminary&gt;@stellaluminary&lt;/denchmark-link&gt;
, my guess this is caused by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652&gt;#18652&lt;/denchmark-link&gt;
. In summary, the program will take a long time to start computing as it has to JIT compile PTX code. Once it successfully runs the first GPU op, it means the compilation is done and everything should run quickly. We already include the compiled code for GTX 1050 Ti's (by compiling for compute capability 6.1), but not for RTX 2060 (which has compute capability 7.5) which is why the program must JIT compile it at the start.
It is highly recommended to run the ops/model once before starting the timer, which is called a warmup run. The first run of the model will take longer, both due to the PTX compilation and for several other reasons. We are working on reducing this startup time, but the first run will likely always be a little bit slower than the rest.
Closing this issue as it seems to be a dupe of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/18652&gt;#18652&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/auliarananana&gt;@auliarananana&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/Anamitr&gt;@Anamitr&lt;/denchmark-link&gt;
, if you have performance issues, I recommend opening a new issue with code to reproduce the issue. You can also comment here if you have any questions.
		</comment>
		<comment id='7' author='stellaluminary' date='2019-12-02T20:31:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27819&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27819&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='stellaluminary' date='2019-12-08T22:10:02Z'>
		Reproduced on Ubuntu 18.04, no such an issue.
		</comment>
	</comments>
</bug>