<bug id='3628' author='pavelgonchar' open_date='2016-08-03T18:06:26Z' closed_time='2018-08-19T00:15:14Z'>
	<summary>Unable to import frozen graph with batchnorm</summary>
	<description>
Error when loading the frozen graph with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/88d9bc16d6a16e5b660cda548b74944f27ddcd1b/tensorflow/contrib/layers/python/layers/layers.py&gt;tensorflow.contrib.layers.python.layers.batch_norm&lt;/denchmark-link&gt;


&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py&gt;freeze_graph.py&lt;/denchmark-link&gt;
  doesn't seem to store moving_mean and moving_variance properly
	</description>
	<comments>
		<comment id='1' author='pavelgonchar' date='2016-08-03T22:52:43Z'>
		An ugly way to get it working:
manually replace the wrong node definitions in the frozen graph
RefSwitch --&gt; Switch + add '/read' to the input names
AssignSub --&gt; Sub + remove use_locking attributes 
		</comment>
		<comment id='2' author='pavelgonchar' date='2016-08-04T16:11:22Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 Do you know how freeze_graph.py handle conditional assignments?
		</comment>
		<comment id='3' author='pavelgonchar' date='2016-09-02T16:29:38Z'>
		&lt;denchmark-link:https://github.com/sguada&gt;@sguada&lt;/denchmark-link&gt;
 Any update with this? Without this fixed I don't think exporting a frozen graph (for use in C++) is possible when using Batch Norm.
		</comment>
		<comment id='4' author='pavelgonchar' date='2016-09-07T09:02:03Z'>
		I also have the same problem. &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='pavelgonchar' date='2016-09-09T20:46:04Z'>
		I think I have the same issue.  Pasting my output below in case it helps:
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/Users/pkmital/.pyenv/versions/3.4.0/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    354             # pylint: disable=protected-access
--&gt; 355             op._add_input(source_tensor, dtype=input_type)
    356             # pylint: enable=protected-access

/Users/pkmital/.pyenv/versions/3.4.0/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/ops.py in _add_input(self, tensor, dtype)
   1333             "Cannot convert a tensor of type %s to an input of type %s"
-&gt; 1334             % (tensor.dtype.name, dtype.name))
   1335     self._inputs.append(tensor)

TypeError: Cannot convert a tensor of type float32 to an input of type float32_ref

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-48-371a235edd1f&gt; in &lt;module&gt;()
----&gt; 1 tf.import_graph_def(net['graph_def'])
      2 g = tf.get_default_graph()
      3 [op.name for op in g.get_operations()]

/Users/pkmital/.pyenv/versions/3.4.0/Python.framework/Versions/3.4/lib/python3.4/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    357           except TypeError as te:
    358             raise ValueError(_InvalidNodeMessage(
--&gt; 359                 node, 'Input tensor %r %s' % (input_name, te)))
    360 
    361       # pylint: disable=protected_access

ValueError: graph_def is invalid at node 'encoder/0/bn/ExponentialMovingAverage/AssignMovingAvg': Input tensor 'encoder/0/bn/encoder/0/bn/moments/moments_1/mean/ExponentialMovingAverage:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
You can also try the model for yourself here: &lt;denchmark-link:https://s3.amazonaws.com/cadl/models/celeb_vaegan.tfmodel&gt;https://s3.amazonaws.com/cadl/models/celeb_vaegan.tfmodel&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='pavelgonchar' date='2016-09-29T10:53:33Z'>
		Bump
		</comment>
		<comment id='7' author='pavelgonchar' date='2016-12-19T23:20:49Z'>
		This is hitting me too; it's a bad bug that makes it hard to use BatchNorm in production settings.
		</comment>
		<comment id='8' author='pavelgonchar' date='2016-12-21T13:17:07Z'>
		I'm also experiencing this. It seems that moving_averages._zero_debias() uses scopes in a peculiar way.
For example, if you pass assign_moving_average a variable created within a variable scope, e.g with name "scope1/var", then _zero_debias() creates its variables "biased" and "local_step" within the variable scope "scope1/var", but because we're already within the scope "scope1" the variables end up with names "scope1/scope1/var/biased" etc.
This may not be the problem, but it seems like something that needs tidying up!
		</comment>
		<comment id='9' author='pavelgonchar' date='2017-01-12T12:01:59Z'>
		&lt;denchmark-link:https://github.com/pavelgonchar&gt;@pavelgonchar&lt;/denchmark-link&gt;
 Your suggestion didn't work for me:
# read graph definition
f = tf.python.platform.gfile.FastGFile(model_path)
gd = graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())

# fix nodes
for node in graph_def.node:
  if node.op == 'RefSwitch':
    node.op = 'Switch'
    for index in xrange(len(node.input)):
      node.input[index] = node.input[index] + '/read'
  elif node.op == 'AssignSub':
    node.op = 'Sub'
    if 'use_locking' in node.attr: del node.attr['use_locking']

# import graph into session
tf.import_graph_def(graph_def, name='')
Error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py", line 357, in import_graph_def
    % (input_name,)))
ValueError: graph_def is invalid at node u'conv1/BatchNorm/cond/AssignMovingAvg/Switch': Input tensor 'conv1/BatchNorm/cond/pred_id/read:0' not found in graph_def..
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='pavelgonchar' date='2017-01-12T12:09:02Z'>
		&lt;denchmark-link:https://github.com/pavelgonchar&gt;@pavelgonchar&lt;/denchmark-link&gt;
  This has worked for me:
# read graph definition
f = tf.python.platform.gfile.FastGFile(model_path)
gd = graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())

# fix nodes
for node in graph_def.node:
  if node.op == 'RefSwitch':
    node.op = 'Switch'
    for index in xrange(len(node.input)):
      if 'moving_' in node.input[index]:
        node.input[index] = node.input[index] + '/read'
  elif node.op == 'AssignSub':
    node.op = 'Sub'
    if 'use_locking' in node.attr: del node.attr['use_locking']

# import graph into session
tf.import_graph_def(graph_def, name='')
I've only changed the inputs related to the "moving_variance" and "moving_mean".
		</comment>
		<comment id='11' author='pavelgonchar' date='2017-01-12T12:15:52Z'>
		The full script I use to convert a checkpoint model to a protobuf graph is below, in case more people using batch norm layers find it useful.
"""
Convert model.ckpt to model.pb
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
from tensorflow.python.framework import graph_util

# create a session
sess = tf.Session()

# import best model
saver = tf.train.import_meta_graph('model.ckpt.meta') # graph
saver.restore(sess, 'model.ckpt') # variables

# get graph definition
gd = sess.graph.as_graph_def()

# fix batch norm nodes
for node in gd.node:
  if node.op == 'RefSwitch':
    node.op = 'Switch'
    for index in xrange(len(node.input)):
      if 'moving_' in node.input[index]:
        node.input[index] = node.input[index] + '/read'
  elif node.op == 'AssignSub':
    node.op = 'Sub'
    if 'use_locking' in node.attr: del node.attr['use_locking']

# generate protobuf
converted_graph_def = graph_util.convert_variables_to_constants(sess, gd, ["logits_set"])
tf.train.write_graph(converted_graph_def, '/path/to/save/', 'model.pb', as_text=False)
		</comment>
		<comment id='12' author='pavelgonchar' date='2017-01-23T23:25:21Z'>
		&lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
 is that still true of recent versions of TF?
&lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 in case we have to cherry-pick.
&lt;denchmark-link:https://github.com/zheng-xq&gt;@zheng-xq&lt;/denchmark-link&gt;
 FYI.
		</comment>
		<comment id='13' author='pavelgonchar' date='2017-01-23T23:45:48Z'>
		&lt;denchmark-link:https://github.com/drpngx&gt;@drpngx&lt;/denchmark-link&gt;
 I use TensorFlow 0.12.0rc0. I can check the exact commit tomorrow if you need that information.
		</comment>
		<comment id='14' author='pavelgonchar' date='2017-01-23T23:58:52Z'>
		Thanks!
		</comment>
		<comment id='15' author='pavelgonchar' date='2017-02-06T14:55:19Z'>
		The script &lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
 provided failed for me on an ExponentialMovingAverage node; I added  just like , then it worked.
		</comment>
		<comment id='16' author='pavelgonchar' date='2017-02-13T10:14:25Z'>
		Might this issue be related to / the same as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/4044&gt;#4044&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='17' author='pavelgonchar' date='2017-02-15T23:53:53Z'>
		I am running TensorFlow 0.12. I tried the solution provided by &lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/sunsided&gt;@sunsided&lt;/denchmark-link&gt;
, but it didn't solve the problem. I still get this error:
ValueError: graph_def is invalid at node 'InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/cond/AssignMovingAvg/Switch': Input tensor 'InceptionResnetV1/Conv2d_1a_3x3/BatchNorm/moving_mean:0' Cannot convert a tensor of type float32 to an input of type float32_ref.
		</comment>
		<comment id='18' author='pavelgonchar' date='2017-03-10T04:41:36Z'>
		&lt;denchmark-link:https://github.com/drpngx&gt;@drpngx&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/gunan&gt;@gunan&lt;/denchmark-link&gt;
 - I think the state machine got confused here.  &lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
 replied with his version but no tensorflower picked up the ball.
		</comment>
		<comment id='19' author='pavelgonchar' date='2018-08-09T12:54:18Z'>
		Nagging Assignees &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/suharshs&gt;@suharshs&lt;/denchmark-link&gt;
: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='20' author='pavelgonchar' date='2018-08-19T00:15:14Z'>
		Closing since &lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
 's solution seems to work.
In general the best route is to create a separate eval graph with is_training=False for batchnorm, freeze the training checkpoint into that graph.
Thanks!
		</comment>
		<comment id='21' author='pavelgonchar' date='2018-09-03T03:11:52Z'>
		&lt;denchmark-link:https://github.com/barbolo&gt;@barbolo&lt;/denchmark-link&gt;
  I used the API tf.layers . I printed the operation in my net. I didn't found RefSwitch, So I can't resolve the question through your suggestion. The error ValueError: graph_def is invalid at node 'conv1/kernel/Assign': Input tensor 'conv1/kernel:0' Cannot convert a tensor of type float32 to an input of type float32_ref. Please Do you any suggestion?
conv1/kernel/Initializer/random_uniform/shape
conv1/kernel/Initializer/random_uniform/min
conv1/kernel/Initializer/random_uniform/max
conv1/kernel/Initializer/random_uniform/RandomUniform
conv1/kernel/Initializer/random_uniform/sub
conv1/kernel/Initializer/random_uniform/mul
conv1/kernel/Initializer/random_uniform
conv1/kernel
conv1/kernel/Assign
conv1/kernel/read
conv1/bias/Initializer/zeros
conv1/bias
conv1/bias/Assign
conv1/bias/read
conv1/dilation_rate
conv1/Conv2D
conv1/BiasAdd
conv1/Relu
batch_normalization/gamma/Initializer/ones
batch_normalization/gamma
batch_normalization/gamma/Assign
batch_normalization/gamma/read
batch_normalization/beta/Initializer/zeros
batch_normalization/beta
batch_normalization/beta/Assign
batch_normalization/beta/read
batch_normalization/moving_mean/Initializer/zeros
batch_normalization/moving_mean
batch_normalization/moving_mean/Assign
batch_normalization/moving_mean/read
batch_normalization/moving_variance/Initializer/ones
batch_normalization/moving_variance
batch_normalization/moving_variance/Assign
batch_normalization/moving_variance/read
batch_normalization/cond/Switch
batch_normalization/cond/switch_t
batch_normalization/cond/switch_f
batch_normalization/cond/pred_id
batch_normalization/cond/Const
batch_normalization/cond/Const_1
batch_normalization/cond/FusedBatchNorm/Switch
batch_normalization/cond/FusedBatchNorm/Switch_1
batch_normalization/cond/FusedBatchNorm/Switch_2
batch_normalization/cond/FusedBatchNorm
batch_normalization/cond/FusedBatchNorm_1/Switch
batch_normalization/cond/FusedBatchNorm_1/Switch_1
batch_normalization/cond/FusedBatchNorm_1/Switch_2
batch_normalization/cond/FusedBatchNorm_1/Switch_3
batch_normalization/cond/FusedBatchNorm_1/Switch_4
batch_normalization/cond/FusedBatchNorm_1
batch_normalization/cond/Merge
batch_normalization/cond/Merge_1
batch_normalization/cond/Merge_2
batch_normalization/ExpandDims/input
batch_normalization/ExpandDims/dim
batch_normalization/ExpandDims
batch_normalization/ExpandDims_1/input
batch_normalization/ExpandDims_1/dim
batch_normalization/ExpandDims_1
batch_normalization/Reshape/shape
batch_normalization/Reshape
batch_normalization/Select
batch_normalization/Squeeze
batch_normalization/AssignMovingAvg/read
batch_normalization/AssignMovingAvg/Sub
batch_normalization/AssignMovingAvg/Mul
batch_normalization/AssignMovingAvg
batch_normalization/AssignMovingAvg_1/read
batch_normalization/AssignMovingAvg_1/Sub
batch_normalization/AssignMovingAvg_1/Mul
batch_normalization/AssignMovingAvg_1
		</comment>
		<comment id='22' author='pavelgonchar' date='2018-10-13T05:04:04Z'>
		&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 this is still a problem. severely limits the ability to put models in production with batch norm (which are most models...)
		</comment>
		<comment id='23' author='pavelgonchar' date='2018-10-23T10:25:44Z'>
		same problem here, I trained my model and tried to import the frozen graph with batch norm nodes:
following the Complete Traceback :
`---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
c:\users\shivam.agarwal\pycharmprojects\audioapi\venv\lib\site-packages\tensorflow\python\framework\importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
417         results = c_api.TF_GraphImportGraphDefWithResults(
--&gt; 418             graph._c_graph, serialized, options)  # pylint: disable=protected-access
419         results = c_api_util.ScopedTFImportGraphDefResults(results)
InvalidArgumentError: Node 'Test_Net/convolution/normalize_input/Test_Net/convolution/normalize_input/mean/ExponentialMovingAverage/read' expects to be colocated with unknown node 'Test_Net/convolution/normalize_input/mean'
During handling of the above exception, another exception occurred:
ValueError                                Traceback (most recent call last)
 in ()
----&gt; 1 read_graph_proto(as_constants=True)
 in read_graph_proto(proto_dir, batch_number, as_constants, new_filename_queue)
25                     tf.import_graph_def(graph_def=graph_def)
26             else:
---&gt; 27                 tf.import_graph_def(graph_def=graph_def)
28             print([node for node in self.session.graph_def.node])
29     else:
c:\users\shivam.agarwal\pycharmprojects\audioapi\venv\lib\site-packages\tensorflow\python\util\deprecation.py in new_func(*args, **kwargs)
452                 'in a future version' if date is None else ('after %s' % date),
453                 instructions)
--&gt; 454       return func(*args, **kwargs)
455     return tf_decorator.make_decorator(func, new_func, 'deprecated',
456                                        _add_deprecated_arg_notice_to_docstring(
c:\users\shivam.agarwal\pycharmprojects\audioapi\venv\lib\site-packages\tensorflow\python\framework\importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
420       except errors.InvalidArgumentError as e:
421         # Convert to ValueError for backwards compatibility.
--&gt; 422         raise ValueError(str(e))
423
424     # Create _DefinedFunctions for any imported functions.
ValueError: Node 'Test_Net/convolution/normalize_input/Test_Net/convolution/normalize_input/mean/ExponentialMovingAverage/read' expects to be colocated with unknown node 'Test_Net/convolution/normalize_input/mean'
`
How can I sort out this ? I have been stuck since months now because of this one issue.
		</comment>
		<comment id='24' author='pavelgonchar' date='2018-11-28T14:51:54Z'>
		Same problem
I trined GooglNet model and get the error when importing a frozen graph
ValueError: Input 0 of node save/Assign_41 was passed float from auxiliary_classifier_1/classifier/biases/Adam_1:0 incompatible with expected float_ref. 
None of the answers I found on the net do not answer this specific situation, where the problem is in the save op and Adam optimizer
		</comment>
		<comment id='25' author='pavelgonchar' date='2018-12-05T08:23:23Z'>
		
@barbolo I used the API tf.layers . I printed the operation in my net. I didn't found RefSwitch, So I can't resolve the question through your suggestion. The error ValueError: graph_def is invalid at node 'conv1/kernel/Assign': Input tensor 'conv1/kernel:0' Cannot convert a tensor of type float32 to an input of type float32_ref. Please Do you any suggestion?
conv1/kernel/Initializer/random_uniform/shape
conv1/kernel/Initializer/random_uniform/min
conv1/kernel/Initializer/random_uniform/max
conv1/kernel/Initializer/random_uniform/RandomUniform
conv1/kernel/Initializer/random_uniform/sub
conv1/kernel/Initializer/random_uniform/mul
conv1/kernel/Initializer/random_uniform
conv1/kernel
conv1/kernel/Assign
conv1/kernel/read
conv1/bias/Initializer/zeros
conv1/bias
conv1/bias/Assign
conv1/bias/read
conv1/dilation_rate
conv1/Conv2D
conv1/BiasAdd
conv1/Relu
batch_normalization/gamma/Initializer/ones
batch_normalization/gamma
batch_normalization/gamma/Assign
batch_normalization/gamma/read
batch_normalization/beta/Initializer/zeros
batch_normalization/beta
batch_normalization/beta/Assign
batch_normalization/beta/read
batch_normalization/moving_mean/Initializer/zeros
batch_normalization/moving_mean
batch_normalization/moving_mean/Assign
batch_normalization/moving_mean/read
batch_normalization/moving_variance/Initializer/ones
batch_normalization/moving_variance
batch_normalization/moving_variance/Assign
batch_normalization/moving_variance/read
batch_normalization/cond/Switch
batch_normalization/cond/switch_t
batch_normalization/cond/switch_f
batch_normalization/cond/pred_id
batch_normalization/cond/Const
batch_normalization/cond/Const_1
batch_normalization/cond/FusedBatchNorm/Switch
batch_normalization/cond/FusedBatchNorm/Switch_1
batch_normalization/cond/FusedBatchNorm/Switch_2
batch_normalization/cond/FusedBatchNorm
batch_normalization/cond/FusedBatchNorm_1/Switch
batch_normalization/cond/FusedBatchNorm_1/Switch_1
batch_normalization/cond/FusedBatchNorm_1/Switch_2
batch_normalization/cond/FusedBatchNorm_1/Switch_3
batch_normalization/cond/FusedBatchNorm_1/Switch_4
batch_normalization/cond/FusedBatchNorm_1
batch_normalization/cond/Merge
batch_normalization/cond/Merge_1
batch_normalization/cond/Merge_2
batch_normalization/ExpandDims/input
batch_normalization/ExpandDims/dim
batch_normalization/ExpandDims
batch_normalization/ExpandDims_1/input
batch_normalization/ExpandDims_1/dim
batch_normalization/ExpandDims_1
batch_normalization/Reshape/shape
batch_normalization/Reshape
batch_normalization/Select
batch_normalization/Squeeze
batch_normalization/AssignMovingAvg/read
batch_normalization/AssignMovingAvg/Sub
batch_normalization/AssignMovingAvg/Mul
batch_normalization/AssignMovingAvg
batch_normalization/AssignMovingAvg_1/read
batch_normalization/AssignMovingAvg_1/Sub
batch_normalization/AssignMovingAvg_1/Mul
batch_normalization/AssignMovingAvg_1

Hi, I have met the same problem with you. Did you solved it?
		</comment>
		<comment id='26' author='pavelgonchar' date='2018-12-05T10:27:09Z'>
		&lt;denchmark-link:https://github.com/XiaodanLi001&gt;@XiaodanLi001&lt;/denchmark-link&gt;
 since I started using TensorFlow Estimator API I never had this problem again.
However, there is still a trick. You do must define your training op within  context, like the snippet bellow, because although the batch_norm layers allocates some variables, they are not trainable, but updatable. So you do need to ensure that they are being updated at every training step.
I hope it helps
 # You DO must get this collection in order to perform updates on batch_norm variables
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
    train_op = optimizer.minimize(
    loss=total_loss, global_step=tf.train.get_global_step())
OBS: I use tf.layers too.
		</comment>
		<comment id='27' author='pavelgonchar' date='2019-03-20T03:20:25Z'>
		
This is hitting me too; it's a bad bug that makes it hard to use BatchNorm in production settings.

yeah , Fuck tensorflow !!!
		</comment>
		<comment id='28' author='pavelgonchar' date='2019-03-21T03:09:32Z'>
		I solved this problem by using the tf.layers.batch_normalization rather the tf.contrib.layers.batch_norm.
		</comment>
		<comment id='29' author='pavelgonchar' date='2019-03-21T03:35:50Z'>
		&lt;denchmark-h:h1&gt;fix batch norm nodes&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;    for node in input_graph_def.node:
        if node.op == 'RefSwitch':
            node.op = 'Switch'
            for index in range(len(node.input)):
                if 'moving_' in node.input[index] and "Switch" not in node.input[index]:
                    node.input[index] = node.input[index] + '/read'
        elif node.op == 'AssignSub':
            node.op = 'Sub'
            if 'use_locking' in node.attr: del node.attr['use_locking']
        elif node.op == 'AssignAdd':
            node.op = 'Add'
            if 'use_locking' in node.attr: del node.attr['use_locking']
&lt;/denchmark-code&gt;

i add "if 'moving_' in node.input[index] and "Switch" not in node.input[index]:" and i have solved my problem, thanks!
		</comment>
		<comment id='30' author='pavelgonchar' date='2019-05-06T06:58:43Z'>
		&lt;denchmark-code&gt;with tf.Session() as sess:
    saved_model_dir = "saved_model_dir_signature"
    meta_graph_def = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], '')
    for node in sess.graph_def.node:
      if node.op == 'RefEnter':
        node.op = 'Enter'
        for index in range(len(node.input)):
          if 'moving_' in node.input[index]:
            node.input[index] = node.input[index] + '/read'
      if node.op == 'RefSwitch':
        node.op = 'Switch'
        for index in range(len(node.input)):
          if 'moving_' in node.input[index]:
            node.input[index] = node.input[index] + '/read'
      elif node.op == 'AssignSub':
        node.op = 'Sub'
        if 'use_locking' in node.attr: del node.attr['use_locking']
      elif node.op == 'AssignAdd':
        node.op = 'Add'
        if 'use_locking' in node.attr: del node.attr['use_locking']
&lt;/denchmark-code&gt;

How can i modify the graph_def in session? if i do it in this way, the model saved by sess didn't change from RefSwitch to Switch.
Can someone tell me how to modify the graph_def in sess? thanks.
		</comment>
		<comment id='31' author='pavelgonchar' date='2019-08-09T04:05:57Z'>
		
The full script I use to convert a checkpoint model to a protobuf graph is below, in case more people using batch norm layers find it useful.
"""
Convert model.ckpt to model.pb
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
from tensorflow.python.framework import graph_util

# create a session
sess = tf.Session()

# import best model
saver = tf.train.import_meta_graph('model.ckpt.meta') # graph
saver.restore(sess, 'model.ckpt') # variables

# get graph definition
gd = sess.graph.as_graph_def()

# fix batch norm nodes
for node in gd.node:
  if node.op == 'RefSwitch':
    node.op = 'Switch'
    for index in xrange(len(node.input)):
      if 'moving_' in node.input[index]:
        node.input[index] = node.input[index] + '/read'
  elif node.op == 'AssignSub':
    node.op = 'Sub'
    if 'use_locking' in node.attr: del node.attr['use_locking']

# generate protobuf
converted_graph_def = graph_util.convert_variables_to_constants(sess, gd, ["logits_set"])
tf.train.write_graph(converted_graph_def, '/path/to/save/', 'model.pb', as_text=False)

not bad
		</comment>
		<comment id='32' author='pavelgonchar' date='2019-09-07T11:02:26Z'>
		
The full script I use to convert a checkpoint model to a protobuf graph is below, in case more people using batch norm layers find it useful.
"""
Convert model.ckpt to model.pb
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf
from tensorflow.python.framework import graph_util

# create a session
sess = tf.Session()

# import best model
saver = tf.train.import_meta_graph('model.ckpt.meta') # graph
saver.restore(sess, 'model.ckpt') # variables

# get graph definition
gd = sess.graph.as_graph_def()

# fix batch norm nodes
for node in gd.node:
  if node.op == 'RefSwitch':
    node.op = 'Switch'
    for index in xrange(len(node.input)):
      if 'moving_' in node.input[index]:
        node.input[index] = node.input[index] + '/read'
  elif node.op == 'AssignSub':
    node.op = 'Sub'
    if 'use_locking' in node.attr: del node.attr['use_locking']

# generate protobuf
converted_graph_def = graph_util.convert_variables_to_constants(sess, gd, ["logits_set"])
tf.train.write_graph(converted_graph_def, '/path/to/save/', 'model.pb', as_text=False)

Hi.
I don't have gpu and i can't run it.can you help me?
		</comment>
		<comment id='33' author='pavelgonchar' date='2020-03-11T17:40:25Z'>
		Just an idea, since freeze works only with simple mathematical operations we can convert the important part of the graphs including batch norm to simple mathematical operation and freeze the graph
		</comment>
		<comment id='34' author='pavelgonchar' date='2020-07-24T07:19:27Z'>
		Traceback (most recent call last):
File "convert_TFLite.py", line 90, in 
convert_from_savedModel(savedModelDir, TFLiteFile, quan=True, integerOnly=True)
File "convert_TFLite.py", line 50, in convert_from_savedModel
TFLiteModel = converter.convert()
File "/usr/local/lib/python3.5/dist-packages/tensorflow/lite/python/lite.py", line 459, in convert
self._funcs[0], lower_control_flow=False))
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/convert_to_constants.py", line 707, in convert_variables_to_constants_v2_as_graph
frozen_func = _construct_concrete_function(func, graph_def, converted_inputs)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/convert_to_constants.py", line 406, in _construct_concrete_function
new_output_names)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/wrap_function.py", line 633, in function_from_graph_def
wrapped_import = wrap_function(_imports_graph_def, [])
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/wrap_function.py", line 611, in wrap_function
collections={}),
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py", line 981, in func_graph_from_py_func
func_outputs = python_func(*func_args, **func_kwargs)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/wrap_function.py", line 86, in call
return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/wrap_function.py", line 92, in wrapped
return fn(*args, **kwargs)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/wrap_function.py", line 631, in _imports_graph_def
importer.import_graph_def(graph_def, name="")
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
return func(*args, **kwargs)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py", line 405, in import_graph_def
producer_op_list=producer_op_list)
File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py", line 501, in _import_graph_def_internal
raise ValueError(str(e))
ValueError: Input 0 of node conv21/pointwise/BatchNorm/cond/Assign/Switch was passed float from conv21/pointwise/BatchNorm/moving_mean:0 incompatible with expected float_ref.
when I use "tf.lite.TFLiteConverter.from_saved_model()" to convert checkpoint to tflite，I got above err about BatchNorm, please help me, ths.
		</comment>
	</comments>
</bug>