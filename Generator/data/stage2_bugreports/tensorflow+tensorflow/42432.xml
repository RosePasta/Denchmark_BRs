<bug id='42432' author='eladc4' open_date='2020-08-17T13:30:08Z' closed_time='2020-08-19T07:32:47Z'>
	<summary>TFLiteConverter fails when converting a quantized model trained with distributed strategy</summary>
	<description>
most of the code is taken from tensorflow tutorials
running on Linux 18.04
TF version: v2.3.0-rc2-23-gb36436b087 2.3.0 (installed with pip)
python 3.7
CUDA 10.1
after training a quantized model, i'm trying to to convert to TFLite but it fails. same code with quant_enable=False works fine
Standalone code to reproduce the issue
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Input, Model, regularizers, models, optimizers, losses
import tensorflow_model_optimization as tfmot
from functools import partial
from pathlib import Path
from models.network_factory import get_network
def get_model():
conv_params = {'padding': 'same', 'use_bias': False, 'strides': 2,
'kernel_regularizer': regularizers.l2(0.01)}
&lt;denchmark-code&gt;inputs = Input(shape=(32, 32, 3))
x = layers.Conv2D(16, 3, **conv_params)(inputs)
x = layers.BatchNormalization()(x)
x = layers.ReLU()(x)
x = layers.Conv2D(32, 3, **conv_params)(x)
x = layers.BatchNormalization()(x)
x = layers.ReLU()(x)
x = layers.Conv2D(64, 3, **conv_params)(x)
x = layers.BatchNormalization()(x)
x = layers.ReLU()(x)
x = layers.Flatten()(x)
x = layers.Dropout(0.7)(x)
x = layers.Dense(10, kernel_regularizer=regularizers.l2(0.01))(x)
return Model(inputs=inputs, outputs=x, name="SimpleNet")
&lt;/denchmark-code&gt;

def apply_quantization_to_layer(layer):
# default quantization
if type(layer) in [layers.Conv2D, layers.DepthwiseConv2D,
layers.Dense, layers.BatchNormalization,
layers.Add, layers.ReLU]:
return tfmot.quantization.keras.quantize_annotate_layer(layer)
return layer
def quantize_model(in_model, clone_fn=apply_quantization_to_layer):
annotated_model = models.clone_model(in_model, clone_function=partial(clone_fn))
with tfmot.quantization.keras.quantize_scope():
quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)
return quant_aware_model
quant_enable = True
strategy = tf.distribute.MirroredStrategy()
print(f"\nnumber of GPUs: {strategy.num_replicas_in_sync}\n")
with strategy.scope():
model = get_model()
model.summary()
&lt;denchmark-code&gt;# Quantize the model.
if quant_enable:
    # raise Exception("need to debug distributed training with quantization")
    model = quantize_model(model)

model.compile(optimizer=optimizers.Adam(),
              loss=losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
&lt;/denchmark-code&gt;

num_replicas_in_sync = strategy.num_replicas_in_sync
batch_size, val_batch_size = 5, 5
ds_train = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(100)],
[np.random.randint(10) for _ in range(100)]))
ds_train = ds_train.batch(batch_size)
ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)
ds_test = tf.data.Dataset.from_tensor_slices(([np.random.normal(size=(32, 32, 3)) for _ in range(20)],
[np.random.randint(10) for _ in range(20)]))
ds_test = ds_test.batch(val_batch_size)
ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)
history = model.fit(ds_train, epochs=4, validation_data=ds_test, verbose=1)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = False
tflite_model = converter.convert()
	</description>
	<comments>
		<comment id='1' author='eladc4' date='2020-08-18T11:31:42Z'>
		&lt;denchmark-link:https://github.com/eladc4&gt;@eladc4&lt;/denchmark-link&gt;
,
On running the code with TF v2.3, I am facing an error stating .
However, the issue seems to be resolved with the latest TF-nightly, as I was able to convert the model without any issues. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/6e113688e93a5f8aaea0ca52d12c2fea/42432-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='eladc4' date='2020-08-19T07:32:47Z'>
		that's the error i get, so i guess i'll be solved in TF 2.4
thanks!
		</comment>
		<comment id='3' author='eladc4' date='2020-08-19T07:32:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42432&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42432&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>