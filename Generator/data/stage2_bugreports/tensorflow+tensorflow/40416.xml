<bug id='40416' author='UcefMountacer' open_date='2020-06-12T16:38:34Z' closed_time='2020-10-23T20:34:15Z'>
	<summary>TFLite model not working with png images</summary>
	<description>
Hello,
I have trained a semantic segmentation model using VGG16 and unet. The model displayed good results before (irrelevant of image type).
When I converted the model to tflite, I noticed that it does not work with png files. Here is an example :
&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84525079-57424e80-acdb-11ea-9ac1-d1f1c2269b2f.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84525095-61fce380-acdb-11ea-9f92-f012c0c75ade.png&gt;&lt;/denchmark-link&gt;

When trying with a jpg however, the results seem fine compared to the original model. An example:
&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84525036-44c81500-acdb-11ea-9371-9015339cf568.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84525018-3e399d80-acdb-11ea-92ad-f65261f10e1a.png&gt;&lt;/denchmark-link&gt;

Hope someone have the answer because I do the same preprocessing to both images. And the original model as I said work fine with both types.
ðŸ˜ƒðŸ˜ƒðŸ˜ƒ
	</description>
	<comments>
		<comment id='1' author='UcefMountacer' date='2020-06-12T18:16:10Z'>
		Can you provide a Google Colab gist reproducing the problem? can you try to compare the performance on the same image but with different encoding(.png and .jpg)? also, check out how many channels of the png images are you passing through the model? .jpg have only 3 channels but png by default have 4, maybe you trained your model only on 3-channel images and when the models perceive 4-channels, that screw everything.
		</comment>
		<comment id='2' author='UcefMountacer' date='2020-06-13T01:25:12Z'>
		No I did print the dimensions every time. Both are the same. Here is a code part:
&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84556792-5cc48680-ad25-11ea-93fa-30cd19e20196.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84556799-6cdc6600-ad25-11ea-9b2d-1fbd4422fad2.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/47783157/84556807-78c82800-ad25-11ea-94c3-cf2331dadd7c.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='UcefMountacer' date='2020-06-15T05:28:50Z'>
		&lt;denchmark-link:https://github.com/UcefMountacer&gt;@UcefMountacer&lt;/denchmark-link&gt;
,
In order to expedite the trouble-shooting process, could you please provide the  file or the Python Notebook you are running along with all the supporting files. Thanks!
		</comment>
		<comment id='4' author='UcefMountacer' date='2020-06-15T05:29:22Z'>
		Also, please mention the TensorFlow version you are using. Thanks!
		</comment>
		<comment id='5' author='UcefMountacer' date='2020-06-20T16:02:23Z'>
		Hi &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
,
Sorry for the late response.
I am using the 2.2.0 version
The code I use to run the result that I have shown you is this (in TXT) :
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4808180/main_code.txt&gt;main_code.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='UcefMountacer' date='2020-06-29T21:55:16Z'>
		&lt;denchmark-link:https://github.com/UcefMountacer&gt;@UcefMountacer&lt;/denchmark-link&gt;
 It looks like the preprocessed input in case of png file is not the same as jpg. Could you try comparing (maybe elementwise) the  tensors you get from a jpg vs png file after this line:
&lt;denchmark-code&gt;image = imagenet_utils.preprocess_input(image.astype(np.float32), data_format='channels_last', mode='torch')
&lt;/denchmark-code&gt;

I am guessing that the value of image elements isn't what the model was trained with, in case of png source.
		</comment>
		<comment id='7' author='UcefMountacer' date='2020-10-23T20:34:15Z'>
		Update :
Sorry It took me so much time to get back on the project. I verified and there is problem not only with the tflite model, but with the original keras model. So the problem was necessarily because of preprocessing. After debugging, I found that using matplotlib to read images is not good (Yes, I don't know why I went in that direction). Using img = PIL.Image.open(path) and using np.array(img) solved the problem.
I guess this issue should be closed but another issue is risen with matplotlib.
Thanks to you all
ðŸ¤™
		</comment>
		<comment id='8' author='UcefMountacer' date='2020-10-23T20:34:17Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40416&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40416&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>