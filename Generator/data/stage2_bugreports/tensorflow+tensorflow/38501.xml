<bug id='38501' author='alxwdm' open_date='2020-04-13T14:46:52Z' closed_time='2020-05-21T10:26:27Z'>
	<summary>tf.estimator graph_saver.restore() error when calling train_and_evalute method</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Google Colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: no
TensorFlow installed from (source or
binary): Provided by Colab
TensorFlow version (use command below): 2.1.0
Python version: Python 3.6
Bazel version (if compiling from source): not relevant
GCC/Compiler version (if compiling from
source): not relevant
CUDA/cuDNN version: CUDA V10.1.243
GPU model and memory: GPU deactivated

Describe the current behavior
After evaluation, the train_and_evaluate method of the tf.estimator API throws an error when the Saver restores the checkpoints after exporting the model using tf.estimator.Exporter. It seems that the estimator calls the restore() method with too many arguments. See logs for details.
Describe the expected behavior
Until a few days ago, my (unchanged) code worked without any errors. So I guess some change in tensorflow/tf.estimator within the last days caused the issue to come up. Back then, the estimator was able to train, evaluate, export and then continue training without problems.

Here is a link to a &lt;denchmark-link:https://colab.research.google.com/drive/1KHqAMZGqngMvQntyTqnj7boa4OZPPoi1&gt;Colab Notebook&lt;/denchmark-link&gt;
 to reproduce the issue
Other info / logs
&lt;denchmark-code&gt;INFO:tensorflow:Finished evaluation at 2020-04-13-14:15:37
INFO:tensorflow:Saving dict for global step 2821: accuracy = 1.0, global_step = 2821, loss = 0.2742786
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2821: /content/simple/model.ckpt-2821
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-128-30df9d6a3d21&gt; in &lt;module&gt;()
----&gt; 1 tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

23 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    471         '(with task id 0).  Given task id {}'.format(config.task_id))
    472 
--&gt; 473   return executor.run()
    474 
    475 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in run(self)
    611         config.task_type != run_config_lib.TaskType.EVALUATOR):
    612       logging.info('Running training and evaluation locally (non-distributed).')
--&gt; 613       return self.run_local()
    614 
    615     # Distributed case.

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in run_local(self)
    712         max_steps=self._train_spec.max_steps,
    713         hooks=train_hooks,
--&gt; 714         saving_listeners=saving_listeners)
    715 
    716     eval_result = listener_for_eval.eval_result or _EvalResult(

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    372 
    373       saving_listeners = _check_listeners_type(saving_listeners)
--&gt; 374       loss = self._train_model(input_fn, hooks, saving_listeners)
    375       logging.info('Loss for final step: %s.', loss)
    376       return self

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1162       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1163     else:
-&gt; 1164       return self._train_model_default(input_fn, hooks, saving_listeners)
   1165 
   1166   def _train_model_default(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1196       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
   1197                                              hooks, global_step_tensor,
-&gt; 1198                                              saving_listeners)
   1199 
   1200   def _train_model_distributed(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)
   1495       any_step_done = False
   1496       while not mon_sess.should_stop():
-&gt; 1497         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
   1498         any_step_done = True
   1499     if not any_step_done:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
    776         feed_dict=feed_dict,
    777         options=options,
--&gt; 778         run_metadata=run_metadata)
    779 
    780   def run_step_fn(self, step_fn):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1281             feed_dict=feed_dict,
   1282             options=options,
-&gt; 1283             run_metadata=run_metadata)
   1284       except _PREEMPTION_ERRORS as e:
   1285         logging.info(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, *args, **kwargs)
   1382         raise six.reraise(*original_exc_info)
   1383       else:
-&gt; 1384         raise six.reraise(*original_exc_info)
   1385 
   1386 

/usr/local/lib/python3.6/dist-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--&gt; 693             raise value
    694         finally:
    695             value = None

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, *args, **kwargs)
   1367   def run(self, *args, **kwargs):
   1368     try:
-&gt; 1369       return self._sess.run(*args, **kwargs)
   1370     except _PREEMPTION_ERRORS:
   1371       raise

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1448               results=outputs[hook] if hook in outputs else None,
   1449               options=options,
-&gt; 1450               run_metadata=run_metadata))
   1451     self._should_stop = self._should_stop or run_context.stop_requested
   1452 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)
    599       if self._timer.should_trigger_for_step(global_step):
    600         self._timer.update_last_triggered_step(global_step)
--&gt; 601         if self._save(run_context.session, global_step):
    602           run_context.request_stop()
    603 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py in _save(self, session, step)
    625     should_stop = False
    626     for l in self._listeners:
--&gt; 627       if l.after_save(session, step):
    628         logging.info(
    629             "A CheckpointSaverListener requested that training be stopped. "

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in after_save(***failed resolving arguments***)
    517       return True
    518     if self._timer.should_trigger_for_step(global_step_value):
--&gt; 519       self._evaluate(global_step_value)  # updates self.eval_result
    520       if not self._continuous_eval_listener.after_eval(self.eval_result):
    521         logging.info('Exiting evaluation, as requested by '

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in _evaluate(self, global_step_value)
    537     self._timer.update_last_triggered_step(global_step_value)
    538     self.eval_result, self.export_results = (
--&gt; 539         self._evaluator.evaluate_and_export())
    540     if self.eval_result.status != _EvalStatus.EVALUATED:
    541       #  This is unexpected; should never happen.

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in evaluate_and_export(self)
    930           self._max_training_steps if self._max_training_steps else False)
    931       export_results = self._export_eval_result(eval_result,
--&gt; 932                                                 is_the_final_export)
    933 
    934       if is_the_final_export:

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in _export_eval_result(self, eval_result, is_the_final_export)
    963                 checkpoint_path=eval_result.checkpoint_path,
    964                 eval_result=eval_result.metrics,
--&gt; 965                 is_the_final_export=is_the_final_export))
    966       return export_results
    967 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/exporter.py in export(self, estimator, export_path, checkpoint_path, eval_result, is_the_final_export)
    466     export_result = self._saved_model_exporter.export(
    467         estimator, export_path, checkpoint_path, eval_result,
--&gt; 468         is_the_final_export)
    469 
    470     self._garbage_collect_exports(export_path)

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/exporter.py in export(***failed resolving arguments***)
    118         assets_extra=self._assets_extra,
    119         as_text=self._as_text,
--&gt; 120         checkpoint_path=checkpoint_path)
    121 
    122     return export_result

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in export_saved_model(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)
    737         as_text=as_text,
    738         checkpoint_path=checkpoint_path,
--&gt; 739         strip_default_attrs=True)
    740 
    741   def experimental_export_all_saved_models(

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _export_all_saved_models(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)
    860             builder, input_receiver_fn_map, checkpoint_path,
    861             save_variables, mode=ModeKeys.PREDICT,
--&gt; 862             strip_default_attrs=strip_default_attrs)
    863         save_variables = False
    864 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _add_meta_graph_for_mode(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)
    967         if check_variables:
    968           try:
--&gt; 969             graph_saver.restore(session, checkpoint_path)
    970           except errors.NotFoundError as e:
    971             msg = ('Could not load all requested variables from checkpoint. '

TypeError: restore() takes 2 positional arguments but 3 were given
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='alxwdm' date='2020-04-14T07:20:28Z'>
		&lt;denchmark-link:https://github.com/alxwdm&gt;@alxwdm&lt;/denchmark-link&gt;
, I tried to replicate the issue but getting different error, please take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/b00e3863ed74ffc604f2f3598632532b/untitled503.ipynb&gt;gist&lt;/denchmark-link&gt;
 and help us to reproduce the issue. Thanks
		</comment>
		<comment id='2' author='alxwdm' date='2020-04-14T08:25:06Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
: I had to add a call to  after  (sorry, this piece of code is a little confusing). Now the error as described above should appear.
In the meantime, I have looked around and I have something interesting. The file estimator.py in Colab (/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py) is different from the file estimator.py currently found in Github. I made some changes to the Colab version in the directory above and the error disappeared.

First of all, estimator.py in Colab has some missing imports compared to the current version on Github:
import tensorflow as tf
from tensorflow.python.training.tracking import graph_view
from tensorflow.python.training.tracking import util as trackable_util
And then, before the line that causes the error (976), I changed the code to:
        graph_saver = tf.compat.v1.train.Saver( var_list=graph_view.ObjectGraphView( estimator_spec.scaffold.saver).frozen_saveable_objects(), sharded=True)
and uncommented
 #graph_saver = (estimator_spec.scaffold.saver or  tf.compat.v1.train.Saver(sharded=True))
Then there is no error as described above. In the "original" version in Github, there is an additional if isinstance(estimator_spec.scaffold.saver, ...) ..., but I left this part out when I fixed the error.

In order to re-import tensorflow_estimator, I restarted the Colab runtime and added an extra import command import tensorflow_estimator.
		</comment>
		<comment id='3' author='alxwdm' date='2020-05-07T09:43:09Z'>
		&lt;denchmark-link:https://github.com/alxwdm&gt;@alxwdm&lt;/denchmark-link&gt;

can you please share a simple stand alone code to replicate the above issue or if possible share a colab gist with the error for us to analyse.
		</comment>
		<comment id='4' author='alxwdm' date='2020-05-14T09:44:18Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='alxwdm' date='2020-05-21T10:26:24Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='alxwdm' date='2020-05-21T10:26:28Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38501&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38501&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>