<bug id='38082' author='feranick' open_date='2020-03-31T17:15:29Z' closed_time='2020-04-03T18:02:25Z'>
	<summary>'TFLiteConverter' object has no attribute 'experimental_new_quantizer' - TF 2.2.0-rc2</summary>
	<description>
System information

Have I written custom code: See below.
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or
binary): source
TensorFlow version (use command below): 2.2.0-rc2
Python version: 3.6.9
Bazel version (if compiling from source): 2.0.0
GCC/Compiler version : XCode 11.4
CUDA/cuDNN version: - GPU model and memory: 10.2, GTX1080ti

Describe the current behavior
Using the current code:
converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(dP.model_name)  converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] converter.representative_dataset = representative_dataset_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_input_type = tf.uint8 converter.inference_output_type = tf.uint8 tflite_quant_model = converter.convert()
I get the following error and crash using TF 2.2.0-rc2:
tflite_quant_model = converter.convert() File "/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py", line 1094, in convert result, inference_input_type, inference_output_type) File "/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py", line 267, in _calibrate_quantize_model inference_output_type, allow_float, self.experimental_new_quantizer) File "/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py", line 944, in __getattribute__ return object.__getattribute__(self, name) AttributeError: 'TFLiteConverter' object has no attribute 'experimental_new_quantizer'
Describe the expected behavior
NOTE: This error is specific to TF 2.2.0-rc2. All works well with TF 2.2.0-rc1.
	</description>
	<comments>
		<comment id='1' author='feranick' date='2020-03-31T17:25:04Z'>
		The issue seems to be related to this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/e6895b3648595080143e8f5dd6f56c16e7852e91&gt;commit&lt;/denchmark-link&gt;
. In particular, line 267:
 inference_output_type, allow_float, self.experimental_new_quantizer)
has not been updated to the new private API. Should it be?:
 inference_output_type, allow_float, self._experimental_new_quantizer)
		</comment>
		<comment id='2' author='feranick' date='2020-04-01T16:28:54Z'>
		Good catch. The cherry picked cl was not include all the changes. Let me fix it now.
		</comment>
		<comment id='3' author='feranick' date='2020-04-01T18:35:06Z'>
		Created a fix here: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/38139&gt;#38139&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='feranick' date='2020-04-03T18:02:24Z'>
		Tested with fix, and all is working now. Since the fix has been merged, I close this bug.
		</comment>
		<comment id='5' author='feranick' date='2020-04-03T18:02:26Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38082&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38082&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>