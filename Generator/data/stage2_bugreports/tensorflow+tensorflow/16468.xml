<bug id='16468' author='bhack' open_date='2018-01-26T20:52:39Z' closed_time='2019-08-29T16:06:51Z'>
	<summary>Keras multi input and estimator</summary>
	<description>
If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.

Why input layers are renamed with _1 suffix?
Why TB display a _2 suffixed parallel sub-graph?

I've attached a snippet runnable on &lt;denchmark-link:http://colab.research.google.com/&gt;colab&lt;/denchmark-link&gt;
 and the TB rendered image.
&lt;denchmark-code&gt;from tensorflow import keras as ks
import numpy as np
from IPython.display import clear_output, Image, display, HTML

def strip_consts(graph_def, max_const_size=32):
    """Strip large constant values from graph_def."""
    strip_def = tf.GraphDef()
    for n0 in graph_def.node:
        n = strip_def.node.add() 
        n.MergeFrom(n0)
        if n.op == 'Const':
            tensor = n.attr['value'].tensor
            size = len(tensor.tensor_content)
            if size &gt; max_const_size:
                tensor.tensor_content = "&lt;stripped %d bytes&gt;"%size
    return strip_def

def show_graph(graph_def, max_const_size=32):
    """Visualize TensorFlow graph."""
    if hasattr(graph_def, 'as_graph_def'):
        graph_def = graph_def.as_graph_def()
    strip_def = strip_consts(graph_def, max_const_size=max_const_size)
    code = """
        &lt;script src="//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js"&gt;&lt;/script&gt;
        &lt;script&gt;
          function load() {{
            document.getElementById("{id}").pbtxt = {data};
          }}
        &lt;/script&gt;
        &lt;link rel="import" href="https://tensorboard.appspot.com/tf-graph-basic.build.html" onload=load()&gt;
        &lt;div style="height:600px"&gt;
          &lt;tf-graph-basic id="{id}"&gt;&lt;/tf-graph-basic&gt;
        &lt;/div&gt;
    """.format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))

    iframe = """
        &lt;iframe seamless style="width:1200px;height:620px;border:0" srcdoc="{}"&gt;&lt;/iframe&gt;
    """.format(code.replace('"', '&amp;quot;'))
    display(HTML(iframe))

class ExampleHook(tf.train.SessionRunHook):
    def __init__(self):
        print('Starting the session.')
        return

    def begin(self):
        g = tf.get_default_graph()
        show_graph(g)
        print('Starting the session.')
        
        #for op in tf.get_default_graph().get_operations():
          #print(str(op.name) )
        
my_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"input_rgb": np.array(np.random.rand(5,5,3).astype(np.float32)), "input_gray": np.array(np.random.rand(5,5,1).astype(np.float32)), 
       "input_mix": np.array(np.random.rand(5,5,1).astype(np.float32))},
    y= np.array(np.random.rand(5,5,1)),
      batch_size=1,
      num_epochs=1,
      shuffle=False)

input_rgb = ks.layers.Input(shape=(1,5, 5, 3), name="input_rgb")
input_gray = ks.layers.Input(shape=(1,5, 5, 1), name="input_gray")
input_mix = ks.layers.Input(shape=(1,5, 5, 1), name="input_mix")
rgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name="rbg_gray")
x = ks.layers.Dense(1, activation='relu',name="Dense_1")(rgb_gray)
x = ks.layers.Dense(1, activation='softmax',name="softmax")(x)
model = ks.models.Model(
        inputs=[input_rgb, input_gray, input_mix],
        outputs=[x])
model.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())


est = ks.estimator.model_to_estimator(
            keras_model=model)

model.summary()
print(model.input_names)
pred = list(est.predict(
    input_fn=my_input_fn,
    predict_keys=None,
    hooks=[ExampleHook()],
))
&lt;/denchmark-code&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/1710528/35459923-5eca90b8-02e2-11e8-8248-764671141850.png&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='bhack' date='2018-01-26T22:04:05Z'>
		/cc &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='bhack' date='2018-01-26T22:18:46Z'>
		&lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
 would you have any thoughts on this?
		</comment>
		<comment id='3' author='bhack' date='2018-01-30T01:04:21Z'>
		Seems to be related to how keras creates the graph? The _2 suffixed parallel sub-graph is presented without creating the estimator.
		</comment>
		<comment id='4' author='bhack' date='2018-01-30T01:14:16Z'>
		&lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
 Do you have the testing code without the estimator?
		</comment>
		<comment id='5' author='bhack' date='2018-01-30T01:17:20Z'>
		I tried show_graph(tf.get_default_graph()) without creating an estimator.
		</comment>
		<comment id='6' author='bhack' date='2018-01-30T01:29:46Z'>
		Ok but _1 inputs are created by the estimator.
		</comment>
		<comment id='7' author='bhack' date='2018-01-30T19:15:52Z'>
		Yea, looks like they were added when clone_model was called during inference. &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 any idea?
		</comment>
		<comment id='8' author='bhack' date='2018-02-10T18:23:41Z'>
		Can we target this before 1.6 will be finalized?
		</comment>
		<comment id='9' author='bhack' date='2018-03-07T19:50:04Z'>
		Is this related to other kind of issues? See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/14504#issuecomment-367986842&gt;#14504 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='bhack' date='2018-03-10T14:51:36Z'>
		Have you really enough bandwidth to support multiple high level apis in shape? Ref. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/16182&gt;#16182&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='bhack' date='2018-03-23T19:21:07Z'>
		Any news?
		</comment>
		<comment id='12' author='bhack' date='2018-04-12T17:50:01Z'>
		Are you still interested or can I close this?
		</comment>
		<comment id='13' author='bhack' date='2018-04-14T12:13:10Z'>
		&lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 How we can improve as community to handle this cases? I really belive that we need to find a &lt;denchmark-link:https://github.com/kubernetes/kubernetes/milestone/38&gt;Kubernetes like approach&lt;/denchmark-link&gt;
. I know that the majority of the dev flow is executed behind the scenes internally and published regularly in brust PR. But I think that we need to adopt an approach like k8s where you can label estimated milestone for github issues.
		</comment>
		<comment id='14' author='bhack' date='2018-04-14T12:16:15Z'>
		P.s. Users ping and bot nagging assignee are quite ugly without a sprint planning outlook.
		</comment>
		<comment id='15' author='bhack' date='2018-04-16T15:06:36Z'>
		&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 I described our current plans around community recently at the Dev Summit, &lt;denchmark-link:https://www.youtube.com/watch?v=nH6owuKfCbw&gt;here's my talk&lt;/denchmark-link&gt;
. I'll set aside the discussion about governance models for now, and see if I can chase down what's going on with this issue. Obviously this does matter to us, and we are always looking to see how we can be better.
		</comment>
		<comment id='16' author='bhack' date='2018-04-16T15:56:20Z'>
		&lt;denchmark-link:https://github.com/ewilderj&gt;@ewilderj&lt;/denchmark-link&gt;
 Yes I saw you talk but anything specific about having an outlook over the internal planning about external (dev/users) issues.
I mention you here cause it is just an example where we are going over and over production releases without having a tentative outlook label/milestone. We have there repository full of these examples.
So notify you on this or on another one is quite the same, especially for bugs on API that are no more in contrib.
Of course I want to start to use again this API but I think that the general problem is most important that a single bug and also if I am sure that the team is trying to do the best(effort) work we need to improve communication especially where all the the WIP is in an internal repository.
		</comment>
		<comment id='17' author='bhack' date='2018-04-16T16:11:20Z'>
		I'm talking with the team here about if there's anything we can do to better flag what's going on externally. And I do appreciate you keeping bringing this to my attention. We are in a unique position as a project precisely because we do open source the same code we use internally, hence a natural predisposition to some internal tools and practices. There's a considerable effort made to bridge these gaps and still lots of places we can do better: you've identified an important one.
In general, rationalizing the high level API situation is something we are working on. We are going to shortly refresh the roadmap again (on a quarterly cadence now, vs the previous yearly) which may not be at the fine detail level you need but is a start. Recently we started sharing the release branching dates with the SIG Build group, and now in future we'll do it to the developers@ mailing list.
		</comment>
		<comment id='18' author='bhack' date='2018-04-27T17:06:20Z'>
		Also it seems that it impact with tf.name_scope("branch"):.
I.e. In the above example with tf.name_scope("branch"):  will be ignored for Tensorboard grouping. Instead directly workaround every name with name=branch/layername is working for TB grouping.
		</comment>
		<comment id='19' author='bhack' date='2018-04-30T21:10:12Z'>
		&lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
  Can you explain what is the impact of this? Are _2 suffixed parallel sub-graph layers allocating memory?
		</comment>
		<comment id='20' author='bhack' date='2018-04-30T22:47:03Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 If in these &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/estimator.py#L296-L298&gt;two lines&lt;/denchmark-link&gt;
 you are cloning the model  who will remove the graph that &lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
  visualize in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/16468#issuecomment-361443964&gt;#16468 (comment)&lt;/denchmark-link&gt;
 without the model to estimator conversion?
		</comment>
		<comment id='21' author='bhack' date='2018-04-30T23:05:55Z'>
		Also are _1 input suffixs generated by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/estimator.py#L109&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/_impl/keras/estimator.py#L109&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='22' author='bhack' date='2018-05-01T12:45:38Z'>
		I've also tried the to visualize the official &lt;denchmark-link:https://keras.io/getting-started/functional-api-guide/#more-examples&gt;Shared vision model&lt;/denchmark-link&gt;
.
&lt;denchmark-code&gt;digit_input = ks.Input(shape=(27, 27, 1))
x = ks.layers.Conv2D(64, (3, 3))(digit_input)
x = ks.layers.Conv2D(64, (3, 3))(x)
x = ks.layers.MaxPooling2D((2, 2))(x)
out = ks.layers.Flatten()(x)

vision_model = ks.Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = ks.Input(shape=(27, 27, 1))
digit_b = ks.Input(shape=(27, 27, 1))

# The vision model will be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = ks.layers.concatenate([out_a, out_b])
out = ks.layers.Dense(1, activation='sigmoid')(concatenated)

classification_model = ks.Model([digit_a, digit_b], out)
&lt;/denchmark-code&gt;

And seems that there is still an external branch
&lt;denchmark-link:https://user-images.githubusercontent.com/1710528/39473072-5572d272-4d4d-11e8-88a8-1bde5d9fabc5.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='23' author='bhack' date='2018-05-03T17:02:55Z'>
		The layer_2 suffix of the parallel subgraph in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/16468#issue-292028082&gt;#16468 (comment)&lt;/denchmark-link&gt;
 seems solved with TF 1.8 but still has  _1 suffix for Inputs and the last example has still an external branch to the model.
		</comment>
		<comment id='24' author='bhack' date='2018-05-03T20:59:01Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 Is there anything that I could do to improve this investigation?
		</comment>
		<comment id='25' author='bhack' date='2018-05-16T12:21:33Z'>
		Gently ping
		</comment>
		<comment id='26' author='bhack' date='2018-06-25T23:47:11Z'>
		&lt;denchmark-link:https://github.com/tanzhenyu&gt;@tanzhenyu&lt;/denchmark-link&gt;
 As it seems that you are playing in the  league can you take a look at this old boy?
		</comment>
		<comment id='27' author='bhack' date='2018-06-25T23:51:55Z'>
		Okay. Marked.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Jun 25, 2018 at 4:50 PM bhack ***@***.***&gt; wrote:
 @tanzhenyu &lt;https://github.com/tanzhenyu&gt; As it seems that you are
 playing in the model_to_estimator league can you take a look at this old
 boy?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#16468 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AOhAwbssX8mzXdWlyuAK6_C_e4SQC-wSks5uAXdLgaJpZM4Ru3NQ&gt;
 .


-- 
-Zhenyu

		</comment>
		<comment id='28' author='bhack' date='2018-07-19T17:21:49Z'>
		&lt;denchmark-link:https://github.com/yifeif&gt;@yifeif&lt;/denchmark-link&gt;
 probably there is something in common with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/9545&gt;#9545&lt;/denchmark-link&gt;
 but I'am not sure that is a TB only bug cause the profiler give me duplicated memory consumption. What do you think?
		</comment>
		<comment id='29' author='bhack' date='2019-08-29T16:06:51Z'>
		This is a stale issue. Please check the issue with latest TensorFlow. If the issue still persists in the newer version of TF, please feel free to reopen it by providing details about the issue and a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='30' author='bhack' date='2019-08-29T16:06:52Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=16468&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=16468&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>