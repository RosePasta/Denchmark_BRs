<bug id='38622' author='drezap' open_date='2020-04-17T07:08:28Z' closed_time='2020-05-10T17:09:55Z'>
	<summary>tf.custom_gradient expects an additional output when declaring temp Variable()</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 29
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de
Python version: Python 3.7.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Thanks in advance for your time.
I'm attempting to implement a custom loss function. It requires storage of a temporary variable, and custom gradient. For many reasons, numerical stability and flexibility, I'd like to just implement the gradient by hand. The model here is just a foo/bar model.
It seems it’s related to this issue: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31945&gt;#31945&lt;/denchmark-link&gt;

I'm also happy to open a PR.
However, I haven't been able to get the patch suggested to work, because I can't build from source via some Bazel issue.
Any references are appreciated.
I've also tried to implement the loss function as a subclass of type Loss, but was unsuccessful.
Thanks for all of the hard work that goes into this project.
Describe the expected behavior
Run model via EagerExecution. When using GradientTape() to evaluate gradients, I'm getting error: ValueError: not enough values to unpack (expected 2, got 1). The loss function is only a function of one input, and thus only has one partial derivative, wrt to that input.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.layers import Layer
import numpy as np

class Linear(Layer):
  """y = w.x + b"""

  def __init__(self, units=32):
      super(Linear, self).__init__()
      self.units = units

  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)

  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b


@tf.custom_gradient
def loss_fn(x):
    r = tf.Variable(tf.zeros([100]), dtype = tf.float32)
    ## create r
    def grad(df, variables = None):
        return [df * 2 * tf.reduce_sum(r)]
    
    return tf.pow(tf.norm(r), 2), grad

M = 100
m = np.arange(0, M)
x = [[m / M]]

linear_layer = Linear(10)

optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)

dataset = tf.data.Dataset.from_tensor_slices(x)

for step, x in enumerate(dataset):
    
    with tf.GradientTape() as tape:
        logits = linear_layer(x)
        loss = loss_fn(x)

    gradients = tape.gradient(loss, linear_layer.trainable_weights)
    optimizer.apply_gradients(zip(gradients, linear_layer.trainable_weights))
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='drezap' date='2020-04-21T15:10:36Z'>
		&lt;denchmark-link:https://github.com/drezap&gt;@drezap&lt;/denchmark-link&gt;
 I tried to reproduce the issue but  i am facing different error. Please find the gist &lt;denchmark-link:https://colab.research.google.com/gist/saikumarchalla/9ea522c31dd28140ae98549c42e8b3cf/untitled.ipynb&gt;here&lt;/denchmark-link&gt;
.
In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='drezap' date='2020-04-23T07:33:16Z'>
		&lt;denchmark-link:https://github.com/saikumarchalla&gt;@saikumarchalla&lt;/denchmark-link&gt;
 Whoops! Here:
Thanks for your time!
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.keras.layers import Layer
import numpy as np

class Linear(Layer):
  """y = w.x + b"""

  def __init__(self, units=32):
      super(Linear, self).__init__()
      self.units = units

  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)

  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b


@tf.custom_gradient
def loss_fn(x):
    r = tf.Variable(tf.zeros([100]), dtype = tf.float32)
    ## create r
    def grad(df, variables = None):
        return [df * 2 * tf.reduce_sum(r)]
    
    return tf.pow(tf.norm(r), 2), grad

M = 100
m = np.arange(0, M)
x = [[m / M]]

linear_layer = Linear(10)

optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)

dataset = tf.data.Dataset.from_tensor_slices(x)

for step, x in enumerate(dataset):
    
    with tf.GradientTape() as tape:
        logits = linear_layer(x)
        loss = loss_fn(x)

    gradients = tape.gradient(loss, linear_layer.trainable_weights)
    optimizer.apply_gradients(zip(gradients, linear_layer.trainable_weights))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='drezap' date='2020-04-24T04:26:25Z'>
		I could be able to replicate the issue on colab.Please find the gist &lt;denchmark-link:https://colab.research.google.com/gist/saikumarchalla/207a8bd425cf07e0f746cb32f012759c/untitled26.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!.
		</comment>
		<comment id='4' author='drezap' date='2020-04-24T05:53:38Z'>
		That’s exactly the error I’m getting.

“not enough values to unpack...”
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Friday, April 24, 2020, saikumarchalla ***@***.***&gt; wrote:
 I could be replicate the issue on colab.Please find the gist here
 &lt;https://colab.research.google.com/gist/saikumarchalla/207a8bd425cf07e0f746cb32f012759c/untitled26.ipynb&gt;
 .Thanks!.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#38622 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ACY543BC62OCG73OUT5VOWDROEIIBANCNFSM4MKQHG4A&gt;
 .


-- 
Best,

Andre Zapico

		</comment>
		<comment id='5' author='drezap' date='2020-04-24T06:52:31Z'>
		&lt;denchmark-link:https://github.com/saikumarchalla&gt;@saikumarchalla&lt;/denchmark-link&gt;

more generally, the question is "how to implement custom loss function that requires storage of a temp tf.Variable, iteration, and a custom gradient".
I could get custom loss functions that were trivial to "compile" with some models (this dummy one, and helpful friend on the TF forum's model), for example using tf.mean() and other simple functions, which i guess is using TF's autodiff.
What I'd like to do, is add some exception that "ignores" TF's autodiff for the function body, and only takes into account the custom gradient I've implemented. The body will be complex and could blow out memory, and be unstable. And is probably no good with autodiff, via intuition.
However, when I've tried to add custom gradients, won't "compile". Temp variable, won't "compile".
I haven't investigated debugging the problem.
		</comment>
		<comment id='6' author='drezap' date='2020-04-29T03:59:14Z'>
		any progress on this?
		</comment>
		<comment id='7' author='drezap' date='2020-04-29T05:08:22Z'>
		&lt;denchmark-link:https://github.com/drezap&gt;@drezap&lt;/denchmark-link&gt;
 Can you please explain little more about this loss functions ()? There is a  function inside loss function with two arguments and the return of  has  without any arguments. Input  was also not used at all.
&lt;denchmark-code&gt;@tf.custom_gradient
def loss_fn(x):
    r = tf.Variable(tf.zeros([100]), dtype = tf.float32)
    ## create r
    def grad(df, variables = None):
        return [df * 2 * tf.reduce_sum(r)]
    
    return tf.pow(tf.norm(r), 2), grad
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='drezap' date='2020-04-29T06:07:56Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

Yeah, happy to, thank you.
The loss function implementation has 3 caveats:

storage of a temporary variable,
requires that I have nested for loops
accumulation.

No work arounds.
I haven't been able to get a model to run, using TF's datatypes, with an implementation of this loss function. If I have a long input sequence, I'm anticipating any expression graph generated would blow out memory, which is an additional reason I'd like to implement it myself.
If this still isn't clear, can I please email you a python implementation of the loss function? I'd just ask that you not publicize it.
TLDR:

There is a grad function inside loss function


How do I include my own gradients for a loss function, and include this in a model?

If this isn't possible with the current modeling language, I'm willing to go as far as implementing C code within a compiled model, or something like that.
		</comment>
		<comment id='9' author='drezap' date='2020-04-29T07:12:50Z'>
		Mind if I just email you the loss function?

It should make it clear
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wednesday, April 29, 2020, Vishnuvardhan Janapati &lt; ***@***.***&gt; wrote:
 @drezap &lt;https://github.com/drezap&gt; Can you please explain little more
 about this loss functions (loss_fn)? There is a grad function inside loss
 function with two arguments and the return of loss_fn has grad without
 any arguments. Input x was also not used at all.

 @tf.custom_gradient
 def loss_fn(x):
     r = tf.Variable(tf.zeros([100]), dtype = tf.float32)
     ## create r
     def grad(df, variables = None):
         return [df * 2 * tf.reduce_sum(r)]

     return tf.pow(tf.norm(r), 2), grad

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#38622 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/ACY543AIS2BRXZSJ4HPMNGLRO6Y5PANCNFSM4MKQHG4A&gt;
 .


-- 
Best,

Andre Zapico

		</comment>
		<comment id='10' author='drezap' date='2020-04-30T16:08:04Z'>
		May be this issue is similar to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/36168&gt;this @custom_gradient&lt;/denchmark-link&gt;
 issue.
		</comment>
		<comment id='11' author='drezap' date='2020-05-10T17:09:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38622&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38622&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>