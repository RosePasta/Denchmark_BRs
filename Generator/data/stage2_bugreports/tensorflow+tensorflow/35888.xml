<bug id='35888' author='Peter-Devine' open_date='2020-01-15T05:42:25Z' closed_time='2020-02-04T22:16:52Z'>
	<summary>Loaded model fails on inference</summary>
	<description>
System information

TF version 2.1.0, and I have also has this error on TF 2.2.0-dev20200114
Python 3.7

Describe the current behavior

Similar to #35527, when I save and then load my model, it fails upon actually using the model, citing the inputs being different to what was expected.
When I run my code (see below) I get the following error:

&lt;denchmark-code&gt;ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (3 total):
    * (&lt;tf.Tensor 'inputs:0' shape=(1, 10) dtype=int32&gt;, &lt;tf.Tensor 'inputs_1:0' shape=(1, 10) dtype=int32&gt;)
    * False
    * None
  Keyword arguments: {}

Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='attention_mask')]
    * True
    * None
  Keyword arguments: {}

Option 2:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='attention_mask')]
    * False
    * None
  Keyword arguments: {}

Option 3:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/1')]
    * True
    * None
  Keyword arguments: {}

Option 4:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/1')]
    * False
    * None
  Keyword arguments: {}
&lt;/denchmark-code&gt;


My reasoning for making this issue when #35527 already exists is that my code to reproduce the issue is more succinct and so should hopefully be easier to troubleshoot.

Describe the expected behavior

The model should load and behave in the exact same manner in which it was saved (I.e. not crash when doing inference on data). This is currently not the case.

Code to reproduce the issue
&lt;denchmark-code&gt;

############# Create a model using TF and the popular transformers NLP package ###########

class TagModelCreator:

    def __init__(self, language_model):
        self.language_model = language_model

    def create(self, num_classes, max_seq_len, get_token_type_ids=False):

        input_modules = []
        
        input_modules.append(tf.keras.layers.Input(shape=(max_seq_len), dtype='int32', name='input_ids'))
        input_modules.append(tf.keras.layers.Input(shape=(max_seq_len), dtype="int32", name='attention_mask'))

        lang_layer = self.language_model(input_modules)
        linear_layer = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_classes, name='classifier'))(lang_layer[0])
        model = tf.keras.Model(inputs=input_modules, outputs=linear_layer)

        return model

from transformers import TFAutoModel

model_name = "bert-base-uncased"
language_model = TFAutoModel.from_pretrained(model_name)
tagging_model_creator = TagModelCreator(language_model)
arbitrary_class_num = 2
arbitrary_sequence_length = 10
tagging_model = tagging_model_creator.create(arbitrary_class_num, arbitrary_sequence_length)




######### Create some spoof data to see how the model handles the data ####################

def data_generator():
    yield (([0]*arbitrary_sequence_length, [1]*arbitrary_sequence_length))

input_types = ((tf.int32, tf.int32))
input_shape = ((tf.TensorShape([None]), tf.TensorShape([None])))

tf_dataset = tf.data.Dataset.from_generator(data_generator, input_types, input_shape).batch(7)






######### Use the spoof data on the model, to confirm that it does inference on the data without errors########

for example_input in tf_dataset:
    test_output = tagging_model(example_input)
    break

print(test_output)
print("Inference is done correctly BEFORE re-loading the model")






######## Save and reload the model #################

tf.keras.models.save_model(model=tagging_model,
                                       filepath="test_model_save.tf",
                                       save_format="tf",
                                       include_optimizer=True
                                      )

reloaded_model = tf.keras.models.load_model(filepath="test_model_save.tf")






####### Try to repeat the inference as above #########
for example_input in tf_dataset:
    test_output = reloaded_model(example_input)
    break
&lt;/denchmark-code&gt;

Other info / logs
The full output of the above code, including printouts and the error stack trace is
&lt;denchmark-code&gt;tf.Tensor(
[[[-0.6191008  -0.12756673]
  [-0.89110005  0.06499487]
  [-0.8666591  -0.02111167]
  [-0.8456675  -0.08551306]
  [-0.853022   -0.15643758]
  [-0.8632274  -0.20486367]
  [-0.8571876  -0.24682882]
  [-0.8400811  -0.2774819 ]
  [-0.8864943  -0.32766515]
  [-0.8612056  -0.3529073 ]]], shape=(1, 10, 2), dtype=float32)
Inference is done correctly BEFORE re-loading the model
WARNING:tensorflow:From C:\Users\Peter\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Assets written to: test_model_save.tf\assets
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-1-9d120ebc3322&gt; in &lt;module&gt;
     80 ####### Try to repeat the inference as above #########
     81 for example_input in tf_dataset:
---&gt; 82     test_output = reloaded_model(example_input)
     83     break
     84 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\engine\base_layer.py in __call__(self, inputs, *args, **kwargs)
    820           with base_layer_utils.autocast_context_manager(
    821               self._compute_dtype):
--&gt; 822             outputs = self.call(cast_inputs, *args, **kwargs)
    823           self._handle_activity_regularization(inputs, outputs)
    824           self._set_mask_metadata(inputs, outputs, input_masks)

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py in return_outputs_and_add_losses(*args, **kwargs)
     57     inputs = args[inputs_arg_index]
     58     args = args[inputs_arg_index + 1:]
---&gt; 59     outputs, losses = fn(inputs, *args, **kwargs)
     60     layer.add_loss(losses, inputs)
     61     return outputs

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py in wrap_with_training_arg(*args, **kwargs)
    111         training,
    112         lambda: replace_training_and_call(True),
--&gt; 113         lambda: replace_training_and_call(False))
    114 
    115   # Create arg spec for decorated function. If 'training' is not defined in the

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\utils\tf_utils.py in smart_cond(pred, true_fn, false_fn, name)
     57         pred, true_fn=true_fn, false_fn=false_fn, name=name)
     58   return smart_module.smart_cond(
---&gt; 59       pred, true_fn=true_fn, false_fn=false_fn, name=name)
     60 
     61 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\framework\smart_cond.py in smart_cond(pred, true_fn, false_fn, name)
     54       return true_fn()
     55     else:
---&gt; 56       return false_fn()
     57   else:
     58     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py in &lt;lambda&gt;()
    111         training,
    112         lambda: replace_training_and_call(True),
--&gt; 113         lambda: replace_training_and_call(False))
    114 
    115   # Create arg spec for decorated function. If 'training' is not defined in the

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py in replace_training_and_call(training)
    106     def replace_training_and_call(training):
    107       set_training_arg(training, training_arg_index, args, kwargs)
--&gt; 108       return wrapped_call(*args, **kwargs)
    109 
    110     return tf_utils.smart_cond(

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--&gt; 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    604       # In this case we have not created variables on the first call. So we can
    605       # run the first trace but we should fail if variables are created.
--&gt; 606       results = self._stateful_fn(*args, **kwds)
    607       if self._created_variables:
    608         raise ValueError("Creating variables on a non-first call to a function"

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2360     """Calls a graph function specialized to the inputs."""
   2361     with self._lock:
-&gt; 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-&gt; 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--&gt; 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\saved_model\function_deserialization.py in restored_function_body(*args, **kwargs)
    260         .format(_pretty_format_positional(args), kwargs,
    261                 len(saved_function.concrete_functions),
--&gt; 262                 "\n\n".join(signature_descriptions)))
    263 
    264   concrete_function_objects = []

ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (3 total):
    * (&lt;tf.Tensor 'inputs:0' shape=(1, 10) dtype=int32&gt;, &lt;tf.Tensor 'inputs_1:0' shape=(1, 10) dtype=int32&gt;)
    * False
    * None
  Keyword arguments: {}

Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='attention_mask')]
    * True
    * None
  Keyword arguments: {}

Option 2:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='attention_mask')]
    * False
    * None
  Keyword arguments: {}

Option 3:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/1')]
    * True
    * None
  Keyword arguments: {}

Option 4:
  Positional arguments (3 total):
    * [TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, 10), dtype=tf.int32, name='inputs/1')]
    * False
    * None
  Keyword arguments: {}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Peter-Devine' date='2020-01-16T04:11:28Z'>
		&lt;denchmark-link:https://github.com/Peter-Devine&gt;@Peter-Devine&lt;/denchmark-link&gt;
 ,
When tried executing the given code, i faced the error in the &lt;denchmark-link:https://colab.sandbox.google.com/gist/oanush/12ce101e13f8ca657b2eee85c78ee6b3/35888.ipynb&gt;gist&lt;/denchmark-link&gt;
 provided.Please provide us the complete code to replicate the issue.Thanks!
		</comment>
		<comment id='2' author='Peter-Devine' date='2020-01-16T23:32:49Z'>
		Sorry, you need to install the  package from Huggingface (&lt;denchmark-link:https://github.com/huggingface/transformers&gt;https://github.com/huggingface/transformers&lt;/denchmark-link&gt;
)
I.e. in the first cell, run the following code:
&lt;denchmark-code&gt;pip install transformers==2.3.0
&lt;/denchmark-code&gt;

Also, why is your second cell the following?
&lt;denchmark-code&gt;import sklearn
import sys
from sklearn.pipeline import Pipeline, FeatureUnion
from Transformers import TextTransformer
&lt;/denchmark-code&gt;

You do not need this cell to run the code that I sent.
Thanks
		</comment>
		<comment id='3' author='Peter-Devine' date='2020-01-24T22:24:29Z'>
		I got similar issue. Here is my code to reproduce the error.
&lt;denchmark-code&gt;input_ = tf.keras.Input(shape=[10, 30, 32])
block = tf.keras.layers.Dense(128)
rnn_block = tf.keras.layers.GRU(128, return_sequences=False)

x = block(input_)
x = tf.unstack(x, axis=1)
x_stacks = tf.TensorArray(tf.float32, size=10, element_shape=[None, 128])

tf.while_loop(lambda i, x_i: tf.less(i, 10), lambda i, x_i: [i + 1, x_i.write(i, rnn_block(x[i]))],
              loop_vars=[0, x_stacks])
x_stacks = x_stacks.stack()
x_stacks = tf.transpose(x_stacks, [1, 0, 2])

model = tf.keras.Model(inputs=[input_], outputs=[x_stacks])

model.save("/tmp", save_format="tf")
del model

model = tf.keras.models.load_model("/tmp")
&lt;/denchmark-code&gt;

Error Traces:
2020-01-24 14:19:44.856990: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.init (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
Traceback (most recent call last):
File "/home/andy/Projects/Python/milo/tf_analyst/exp.py", line 106, in 
model_load()
File "/home/andy/Projects/Python/milo/tf_analyst/exp.py", line 98, in model_load
model = tf.keras.models.load_model("/tmp")
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py", line 150, in load_model
return saved_model_load.load(filepath, compile)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 89, in load
model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py", line 552, in load_internal
export_dir)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 119, in init
self._finalize()
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py", line 157, in _finalize
created_layers={layer.name: layer for layer in node.layers})
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1903, in reconstruct_from_config
process_node(layer, node_data)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 1851, in process_node
output_tensors = layer(input_tensors, **kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py", line 773, in call
outputs = call_fn(cast_inputs, *args, **kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py", line 59, in return_outputs_and_add_losses
outputs, losses = fn(inputs, *args, **kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 568, in call
result = self._call(*args, **kwds)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 615, in _call
self._initialize(args, kwds, add_initializers_to=initializers)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 497, in _initialize
*args, **kwds))
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2389, in _get_concrete_function_internal_garbage_collected
graph_function, _, _ = self._maybe_define_function(args, kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2703, in _maybe_define_function
graph_function = self._create_graph_function(args, kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py", line 2593, in _create_graph_function
capture_by_value=self._capture_by_value),
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py", line 978, in func_graph_from_py_func
func_outputs = python_func(*func_args, **func_kwargs)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py", line 439, in wrapped_fn
return weak_wrapped_fn().wrapped(*args, **kwds)
File "/home/andy/Applications/anaconda/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py", line 262, in restored_function_body
"\n\n".join(signature_descriptions)))
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
Positional arguments (1 total):
* Tensor("inputs:0", shape=(None, 10, 30, 128), dtype=float32)
Keyword arguments: {}
Expected these arguments to match one of the following 1 option(s):
Option 1:
Positional arguments (1 total):
* [TensorSpec(shape=(None, 10, 30, 128), dtype=tf.float32, name='inputs/0')]
Keyword arguments: {}
		</comment>
		<comment id='4' author='Peter-Devine' date='2020-01-28T10:29:49Z'>
		i also got the problem. code is here.
tf.__version__ '2.0.0' 
class MyModel(tf.keras.Model):
   def __init__(self,num_classes=10):
       super().__init__()
   #define my layers here
        inputs=tf.keras.Input(shape=(28,28))
        self.x0=tf.keras.layers.Flatten()
        self.x1=tf.keras.layers.Dense(512,activation='relu',name='d1')
        self.x2=tf.keras.layers.Dropout(0.2)
        self.predictions=tf.keras.layers.Dense(10,activation=tf.nn.softmax,name='d2')
    def call(self,inputs):
        x=self.x0(inputs)
        x=self.x1(x)
        x=self.x2(x)
        return self.predictions(x)
#load data
mnist=tf.keras.datasets.mnist
(trainx,trainy),(testx,testy)=mnist.load_data()
epochs=10
batchsize=32
train_x,test_x=tf.cast(trainx/255.,tf.float32),tf.cast(testx/255.,tf.float32)
train_y,test_y=tf.cast(trainy,tf.int64),tf.cast(testy,tf.int64)
batch_size=32
buffer_size=10000
epochs=2
train_dataset=tf.data.Dataset.from_tensor_slices((train_x,train_y)).batch(32).shuffle(10000)
train_dataset=train_dataset.map(lambda x,y:(tf.image.flip_left_right(x),y))
train_dataset=train_dataset.repeat()
test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size).shuffle(10000)
train_dataset=test_dataset.repeat()
steps_per_epoch=len(train_x)//batch_size 
#train model model5=MyModel() optimiser=tf.keras.optimizers.Adam() model5.compile(optimizer=optimiser,loss='sparse_categorical_crossentropy', metrics = ['accuracy']) model5.fit(train_dataset,epochs=epochs,steps_per_epoch=steps_per_epoch)
when i save the model it works.
model5.save('./model_name.tf')
INFO:tensorflow:Assets written to: ./model_name.tf\assets
but when i try to load the saved model,
from tensorflow.keras.models import load_model 
model6=load_model('./model_name.tf')it raise exception:
`
ValueError                                Traceback (most recent call last)
 in 
1 from tensorflow.keras.models import load_model
----&gt; 2 model6=load_model('./model_name.tf')
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\saving\save.py in load_model(filepath, custom_objects, compile)
148   if isinstance(filepath, six.string_types):
149     loader_impl.parse_saved_model(filepath)
--&gt; 150     return saved_model_load.load(filepath, compile)
151
152   raise IOError(
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py in load(path, compile)
84   # TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.
85   # TODO(kathywu): Add code to load from objects that contain all endpoints
---&gt; 86   model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
87
88   if isinstance(model, RevivedModel) and compile:
D:\anaconda\lib\site-packages\tensorflow_core\python\saved_model\load.py in load_internal(export_dir, tags, loader_cls)
539       loader = loader_cls(object_graph_proto,
540                           saved_model_proto,
--&gt; 541                           export_dir)
542       root = loader.get(0)
543     root.tensorflow_version = meta_graph_def.meta_info_def.tensorflow_version
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py in init(self, *args, **kwargs)
101   def init(self, *args, **kwargs):
102     super(KerasObjectLoader, self).init(*args, **kwargs)
--&gt; 103     self._finalize()
104
105   def _finalize(self):
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\load.py in _finalize(self)
130           # Since this revived object is technically a subclassed model (even if
131           # the original model is functional/sequential), inputs should be set.
--&gt; 132           node._set_inputs(inputs)
133       if isinstance(node, RevivedLayer):
134         if hasattr(node.keras_api, 'layer_regularization_losses'):
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\training.py in _set_inputs(self, inputs, outputs, training)
2707           kwargs['training'] = training
2708       try:
-&gt; 2709         outputs = self(inputs, **kwargs)
2710       except NotImplementedError:
2711         # This Model or a submodel is dynamic and hasn't overridden
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in call(self, inputs, *args, **kwargs)
840                     not base_layer_utils.is_in_eager_or_tf_function()):
841                   with auto_control_deps.AutomaticControlDependencies() as acd:
--&gt; 842                     outputs = call_fn(cast_inputs, *args, **kwargs)
843                     # Wrap Tensors in outputs in tf.identity to avoid
844                     # circular dependencies.
D:\anaconda\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\utils.py in return_outputs_and_add_losses(*args, **kwargs)
55     inputs = args[inputs_arg_index]
56     args = args[inputs_arg_index + 1:]
---&gt; 57     outputs, losses = fn(inputs, *args, **kwargs)
58     layer.add_loss(losses, inputs)
59     return outputs
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\def_function.py in call(self, *args, **kwds)
455
456     tracing_count = self._get_tracing_count()
--&gt; 457     result = self._call(*args, **kwds)
458     if tracing_count == self._get_tracing_count():
459       self._call_counter.called_without_tracing()
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
501       # This is the first call of call, so we have to initialize.
502       initializer_map = object_identity.ObjectIdentityDictionary()
--&gt; 503       self._initialize(args, kwds, add_initializers_to=initializer_map)
504     finally:
505       # At this point we know that the initialization is complete (or less
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
406     self._concrete_stateful_fn = (
407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 408             *args, **kwds))
409
410     def invalid_creator_scope(*unused_args, **unused_kwds):
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
1846     if self.input_signature:
1847       args, kwargs = None, None
-&gt; 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
1849     return graph_function
1850
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
2148         graph_function = self._function_cache.primary.get(cache_key, None)
2149         if graph_function is None:
-&gt; 2150           graph_function = self._create_graph_function(args, kwargs)
2151           self._function_cache.primary[cache_key] = graph_function
2152         return graph_function, args, kwargs
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
2039             arg_names=arg_names,
2040             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2041             capture_by_value=self._capture_by_value),
2042         self._function_attributes,
2043         # Tell the ConcreteFunction to clean up its graph once it goes out of
D:\anaconda\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
913                                           converted_func)
914
--&gt; 915       func_outputs = python_func(*func_args, **func_kwargs)
916
917       # invariant: func_outputs contains only Tensors, CompositeTensors,
D:\anaconda\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
356         # wrapped allows AutoGraph to swap in a converted function. We give
357         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 358         return weak_wrapped_fn().wrapped(*args, **kwds)
359     weak_wrapped_fn = weakref.ref(wrapped_fn)
360
D:\anaconda\lib\site-packages\tensorflow_core\python\saved_model\function_deserialization.py in restored_function_body(*args, **kwargs)
260         .format(_pretty_format_positional(args), kwargs,
261                 len(saved_function.concrete_functions),
--&gt; 262                 "\n\n".join(signature_descriptions)))
263
264   concrete_function_objects = []
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
Positional arguments (2 total):
* Tensor("inputs:0", shape=(None, 28, 28), dtype=float32)
* Tensor("training:0", shape=(), dtype=bool)
Keyword arguments: {}
Expected these arguments to match one of the following 4 option(s):
Option 1:
Positional arguments (2 total):
* TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')
* True
Keyword arguments: {}
Option 2:
Positional arguments (2 total):
* TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')
* False
Keyword arguments: {}
Option 3:
Positional arguments (2 total):
* TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_1')
* True
Keyword arguments: {}
Option 4:
Positional arguments (2 total):
* TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='input_1')
* False
Keyword arguments: {}
`
		</comment>
		<comment id='5' author='Peter-Devine' date='2020-02-04T22:16:52Z'>
		Thanks for reporting this bug, this should be fixed in the latest nightly.
(also, you can you triple ``` to format multiple lines of code)
		</comment>
		<comment id='6' author='Peter-Devine' date='2020-02-04T22:16:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35888&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35888&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>