<bug id='33074' author='bfmat' open_date='2019-10-06T00:19:26Z' closed_time='2020-09-25T06:27:59Z'>
	<summary>tf.keras accepts incorrect CNN input shapes from tf.data.Dataset when eager execution is disabled</summary>
	<description>
System information

Have I written custom code: Yes
OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1.14.0
Python version: 3.7
Device: CPU

Describe the current behavior
I am using a tf.data.Dataset to train a tf.keras model. My CNN input layer size is (72, 96, 1). I find that if I input a tensor with size (96, 72, 1) (note the reversed dimensions), training completes successfully. However, if I enable eager execution, a ValueError is produced as expected.
Describe the expected behavior
A ValueError should be produced in response to the incorrect input shape, whether or not eager execution is enabled.
Code to reproduce the issue
NOTE: With the code below, there is no error message. However, uncomment the tf.enable_eager_execution() line and you will get a ValueError.
&lt;denchmark-code&gt;#!/usr/bin/env python3
  
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

# UNCOMMENT THIS LINE AND YOU WILL GET AN ERROR
# tf.enable_eager_execution()

def tf_dataset():

    def data_gen():
        while True:
            yield np.random.rand(72, 96, 1), np.random.rand(18)

    types = (tf.float64, tf.float64)
    shapes = (tf.TensorShape([None, None, None]), tf.TensorShape([None]))
    dataset = tf.data.Dataset.from_generator(data_gen, types, output_shapes=shapes)
    dataset = dataset.batch(16)
    return dataset

dataset = tf_dataset()

model = tf.keras.Sequential()
# Notice how the input dimensions are mismatched
model.add(layers.InputLayer((96, 72, 1)))
model.add(layers.Conv2D(filters=32, kernel_size=4, strides=4, activation='relu'))
model.add(layers.Conv2D(filters=32, kernel_size=4, strides=4, activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(18, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy')
print(model.summary())
model.fit(dataset, steps_per_epoch=1, epochs=1)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='bfmat' date='2019-10-07T10:41:17Z'>
		I could reproduce the issue with TF1.14.0 on colab. Please see the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/47a1e1726b762a876c0fc29c00e440b9/untitled182.ipynb&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='bfmat' date='2019-10-07T10:49:53Z'>
		&lt;denchmark-link:https://github.com/bfmat&gt;@bfmat&lt;/denchmark-link&gt;
, I tried with TF 1.15.0rc1 but i didn't see ValueError with or without Eager execution. Please take a look at colab &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/ebbbb7296a5830c3ee0b852c4ec4db6e/untitled183.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='bfmat' date='2019-10-07T13:15:56Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
, thanks for creating the gist! I re-ran it with TensorFlow 2.0 as well, and no error is raised.
It is worth noting that if I change the data shape to (72, 128) instead of (72, 96), an error is raised as expected. However, if I use (72, 97), no error is raised, which is worrying, considering that the tensor size is incorrect as well as the shape.
		</comment>
		<comment id='4' author='bfmat' date='2019-10-09T09:30:50Z'>
		&lt;denchmark-link:https://github.com/bfmat&gt;@bfmat&lt;/denchmark-link&gt;
,
I could execute with shape (72,128) as well, successfully. Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/591ca795c780d0fcd8ddc88247b5c699/untitled183.ipynb&gt;Gist&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='5' author='bfmat' date='2019-10-11T07:08:24Z'>
		&lt;denchmark-link:https://github.com/bfmat&gt;@bfmat&lt;/denchmark-link&gt;
,
Can you please refer the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/591ca795c780d0fcd8ddc88247b5c699/untitled183.ipynb&gt;Gist&lt;/denchmark-link&gt;
 and please let us know if your issue still persists. Thanks!
		</comment>
		<comment id='6' author='bfmat' date='2019-10-11T16:28:13Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 The Gist exhibits the issue. What I meant is that if you leave the input layer at (96, 72), and set the data shape to (72, 128), it raises an error. However, if you set the data shape to (72, 97) while still leaving the input layer at (96, 72), no error is raised.
		</comment>
		<comment id='7' author='bfmat' date='2019-10-14T09:24:36Z'>
		&lt;denchmark-link:https://github.com/bfmat&gt;@bfmat&lt;/denchmark-link&gt;
,
The error,  is being triggered when .
The error disappears if the Shape of the Data and the Shape of the Input Layer is the same. For example, Shapes of Input Layer and that of Data is (72, 128, 1), the Code runs without any Error, both for Eager Execution and Graph Mode execution.
Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/bd539ba720fd6d38cc48bf84cc68e075/untitled183.ipynb&gt;Gist&lt;/denchmark-link&gt;
.
As per my understanding, it is the intended behavior to expect same shape for Input Layer and that for the Data. Please let me know your opinion regarding the same. Thanks!
		</comment>
		<comment id='8' author='bfmat' date='2019-10-29T16:36:20Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflowbutler&gt;@tensorflowbutler&lt;/denchmark-link&gt;
 Apologies for the delay. Yes, it is still an issue. In the gist posted most recently, the input and data shapes are both . No error is expected in this case. The problem is that, when eager execution is disabled,  error is raised when, for instance, the data shape is  while the input shape is .
		</comment>
		<comment id='9' author='bfmat' date='2019-11-25T09:30:24Z'>
		To add to this issue from keras perspective, maybe it helps finding out the error.
TF version: 1.14.0
Keras version 2.2.4
I have a model with input shape as:
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;Layer (type)                 Output Shape              Param #&lt;/denchmark-h&gt;

input_1 (InputLayer)         (None, 1024, 1024, 3)     0
I'm feeding this model those three inputs of different sizes :
&lt;denchmark-code&gt;    ri_teacher1 = self.model1([ri_larger])
    ri_teacher2 = self.model1([ri_small])
    ri_teacher3 = self.model1([ri])
&lt;/denchmark-code&gt;

print out from the inputs:
ri_larger Tensor("lambda_11/Tile:0", shape=(?, 1024, 512, 4), dtype=float32)
ri_small Tensor("lambda_10/AvgPool:0", shape=(?, 256, 256, 3), dtype=float32)
ri Tensor("conv2d_45/Relu:0", shape=(?, 512, 512, 4), dtype=float32)
None of those raise an error and training proceeds...while it is expected it should raise an error since the input shape is (?,1024,1024,3), but I am feeding it (?,1024,512,4), (?,256,256,3) and (?,512,512,4) respectively.
This is using Keras with TF backend
		</comment>
		<comment id='10' author='bfmat' date='2020-04-06T19:15:00Z'>
		I think we should error out. The fact that:

it doesn't put any warning in model.fit
it puts warning in model.call
is a little bit troubling. Here's where it swallows the error:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/network.py#L958-L964
Reassigning to author of that function.

		</comment>
		<comment id='11' author='bfmat' date='2020-09-25T06:27:59Z'>
		&lt;denchmark-link:https://github.com/bfmat&gt;@bfmat&lt;/denchmark-link&gt;
   Closing this issue since we're only making critical bug fixes to graph-mode code. Please feel free to reopen the issue if necessary.Thanks!
		</comment>
		<comment id='12' author='bfmat' date='2020-09-25T06:28:01Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33074&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33074&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>