<bug id='24033' author='oscarriddle' open_date='2018-11-29T03:50:53Z' closed_time='2019-03-08T05:34:15Z'>
	<summary>[TF1.12][graph_transforms] The INT8 performance test of graph_transforms for inceptionv3 model, GPU utilization extremely low.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.12
Python version: 2.7
Bazel version (if compiling from source): 0.15
GCC/Compiler version (if compiling from source): 4.9.3
CUDA/cuDNN version: 9.0/7.0.5
GPU model and memory: TitanXP

Describe the current behavior
I prepared an inception v3 model and try to quantify it by the tool "graph_transforms".
This is my conversion command:
bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=frozen_graph.pb --out_graph=out_graph.pb --inputs='Placeholder:0' --outputs='InceptionV3/Logits/SpatialSqueeze:0' --transforms='add_default_attributes strip_unused_nodes(type=float, shape="16,299,299,3") remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes sort_by_execution_order'
Then I evaluated the accuracy loss by test dataset which is consists of ~80k images. The result shows the accuracy decreased from 70.1% to 64.03%.
Then I try to evaluate the GPU performance by repeatedly run a batch of images, and the GPU utilization is extremely low and the speed is very slow.
&lt;denchmark-code&gt;$ nvidia-smi dmon -i 0
# gpu   pwr  temp    sm   mem   enc   dec  mclk  pclk
# Idx     W     C     %     %     %     %   MHz   MHz
    0    59    35     2     0     0     0  5508  1430
    0    59    35     0     0     0     0  5508  1430
    0    59    36     2     0     0     0  5508  1430
    0    59    36     0     0     0     0  5508  1430
    0    59    36     2     0     0     0  5508  1430
    0    59    36     2     0     0     0  5508  1430
    0    59    36     0     0     0     0  5508  1430
    0    59    36     3     0     0     0  5508  1430
    0    59    36     0     0     0     0  5508  1430
    0    59    36     2     0     0     0  5508  1430
    0    59    36     0     0     0     0  5508  1430
    0    60    36     2     0     0     0  5508  1430
    0    59    36     4     0     0     0  5508  1430
    0    59    36     0     0     0     0  5508  1430
    0    60    36     3     0     0     0  5508  1430
    0    59    37     0     0     0     0  5508  1430
    0    59    37     2     0     0     0  5508  1430
    0    59    37     2     0     0     0  5508  1430
    0    59    36     2     0     0     0  5508  1430
    0    59    37     3     0     0     0  5508  1430
    0    59    37     0     0     0     0  5508  1430
    0    59    37     3     0     0     0  5508  1430
    0    59    37     0     0     0     0  5508  1430
    0    59    37     2     0     0     0  5508  1430
    0    59    37     4     0     0     0  5508  1430
&lt;/denchmark-code&gt;

There shall exists some bugs in this tool, which is related to the GPU utilization.
Any idea will be welcome.
	</description>
	<comments>
		<comment id='1' author='oscarriddle' date='2018-12-05T09:06:46Z'>
		Below is the GPU utilization info when running on original frozen model.
&lt;denchmark-code&gt;$ nvidia-smi dmon -i 0
# gpu   pwr  temp    sm   mem   enc   dec  mclk  pclk
# Idx     W     C     %     %     %     %   MHz   MHz
    0   237    63    82    32     0     0  5508  1822
    0   204    63    85    34     0     0  5508  1809
    0   258    64    81    31     0     0  5508  1809
    0   213    64    83    33     0     0  5508  1847
    0   263    64    85    34     0     0  5508  1797
    0   277    65    85    35     0     0  5508  1822
    0   179    65    83    33     0     0  5508  1835
    0   233    65    84    34     0     0  5508  1835
    0   217    66    83    33     0     0  5508  1809
    0   262    66    85    33     0     0  5508  1797
    0   205    66    84    33     0     0  5508  1797
    0   250    67    84    33     0     0  5508  1809
    0   236    67    83    32     0     0  5508  1771
    0   208    67    83    32     0     0  5508  1771
    0   230    67    85    33     0     0  5508  1771
    0   250    67    84    33     0     0  5508  1797
    0   208    68    83    32     0     0  5508  1784
    0   213    68    83    32     0     0  5508  1784
    0   249    68    83    32     0     0  5508  1771
    0   255    69    85    34     0     0  5508  1797
    0   240    69    82    32     0     0  5508  1809
    0   172    69    83    32     0     0  5508  1771
    0   254    69    85    33     0     0  5508  1784
    0   184    69    82    31     0     0  5508  1771
    0   260    70    85    33     0     0  5508  1809
    0   190    70    85    34     0     0  5508  1809

&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='oscarriddle' date='2019-03-08T04:51:54Z'>
		Is this issue still relevant? There has been no activity since early December.
		</comment>
	</comments>
</bug>