<bug id='37103' author='MeghnaNatraj' open_date='2020-02-26T20:53:08Z' closed_time='2020-03-27T07:34:41Z'>
	<summary>Add support for more keras.metrics.* to accept from_logits argument.</summary>
	<description>
System information

Have I written custom code: Yes
OS Platform and Distribution: Linux
CUDA/cuDNN version: CUDA Version: 10.1
GPU model and memory: GeForce GTX 1080


Currently, in &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/metrics/&gt;keras.metrics&lt;/denchmark-link&gt;
, all the metrics for binary classification only accept values in the range [0, 1]. This is an issue as all the models in TF2.x tutorials output logits (ranges from [-inf, +inf]) and AVOID using an activation in the last layer such as  (ranges from [0, 1])
Current (preferred way): keras.layers.Dense(1)                                  # Output range is [-inf, +inf]
Before (deprecated):      keras.layers.Dense(1, activation='sigmoid') # Output range is [0,1]
Now, if my model outputs values in the range [-inf, +inf] as per the current preferred way, I CANNOT use any of the following metrics as they all expect values in the range [0, 1]
&lt;denchmark-code&gt;1. keras.metrics.Precision(name='precision')
2. keras.metrics.BinaryAccuracy(name='accuracy')
3. keras.metrics.Recall(name='recall')
4. keras.metrics.AUC(name='auc')
5. keras.metrics.TruePositives(name='tp')
6. keras.metrics.FalsePositives(name='fp')
7. keras.metrics.TrueNegatives(name='tn')
8. keras.metrics.FalseNegatives(name='fn')
&lt;/denchmark-code&gt;

However, tf.keras.metrics.BinaryCrossentropy is the only metric that accepts both range [-inf, inf] and range[0,1] and this is used in all tutorials.
The issue is that I want to use all the 8 metrics mentioned above during training, but I cannot.
Describe the expected behavior
Provide an option to have a from_logits=True argument in the 8 metrics given above (and other metrics as well)
Standalone code to reproduce the issue
Pip Install: TensorFlow 2.x and Numpy
&lt;denchmark-code&gt;! pip install tensorflow numpy
&lt;/denchmark-code&gt;

Code
&lt;denchmark-code&gt;# INITIALIZE

import tensorflow as tf
import numpy as np
# define dataset
dataset = np.array([[6,148,72,35,0,33.6,0.627,50,1],
[1,85,66,29,0,26.6,0.351,31,0],
[8,183,64,0,0,23.3,0.672,32,1],
[1,89,66,23,94,28.1,0.167,21,0],
[0,137,40,35,168,43.1,2.288,33,1]])
# split into input (X) and output (y) variables
X = dataset[:,0:8]
y = dataset[:,8]
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# WORKS: Model output is in range [0, 1]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1, activation='sigmoid')])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;# DOES NOT WORK: Model output is in range [-inf, inf]
# define the keras model
model = tf.keras.models.Sequential([tf.keras.layers.Dense(12, input_dim=8, activation='relu'),
                                    tf.keras.layers.Dense(1)])
# compile the keras model
model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=[tf.keras.metrics.Accuracy(name='accuracy'),
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.TruePositives(name='tp')])
# fit the keras model on the dataset
model.fit(X, y, epochs=10, batch_size=10, verbose=0)
.
.
.
.
.
.
.
InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [predictions must be &lt;= 1] [Condition x &lt;= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
	 [[metrics/tp/assert_greater_equal/Assert/AssertGuard/pivot_f/_31/_61]]
  (1) Invalid argument:  assertion failed: [predictions must be &lt;= 1] [Condition x &lt;= y did not hold element-wise:] [x (sequential_8/dense_17/BiasAdd:0) = ] [[22.0911655][62.7297783][35.2793274]...] [y (metrics/precision/Cast_3/x:0) = ] [1]
	 [[{{node metrics/precision/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_12253]

Function call stack:
distributed_function -&gt; distributed_function
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='MeghnaNatraj' date='2020-02-27T07:35:01Z'>
		ðŸ†™
		</comment>
		<comment id='2' author='MeghnaNatraj' date='2020-02-27T10:53:53Z'>
		Was able to reproduce the issue. Please find the Gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/amahendrakar/e1bc35457bf6ffc7c991d9a518a74a04/37103.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='MeghnaNatraj' date='2020-03-06T12:01:24Z'>
		ðŸ†™
Temporarily I solved using &lt;denchmark-link:https://github.com/netrack/keras-metrics&gt;keras-metric&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='MeghnaNatraj' date='2020-03-27T03:05:14Z'>
		This is fixed with tf-nightly version '2.2.0-dev20200325'. Thanks!
		</comment>
		<comment id='5' author='MeghnaNatraj' date='2020-03-27T07:34:41Z'>
		Thank you!
		</comment>
		<comment id='6' author='MeghnaNatraj' date='2020-03-27T07:34:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37103&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37103&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='MeghnaNatraj' date='2020-04-15T22:22:43Z'>
		ðŸ‘‹ I was able to reproduce the original issue in both 2.2.0-dev20200325 and 2.2.0.dev20200415 nightly builds. I'm especially interested in the conversation around keras.metrics.AUC accepting logits.
&lt;denchmark-link:https://colab.research.google.com/drive/133fqw4-USGEvQXkI1uIm8cN-jBOMUmeh#scrollTo=864VzT-b44pw&gt;https://colab.research.google.com/drive/133fqw4-USGEvQXkI1uIm8cN-jBOMUmeh#scrollTo=864VzT-b44pw&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='MeghnaNatraj' date='2020-08-06T12:59:34Z'>
		Is it working for you guys? I just tried out the same test script with TF 2.3, installing with pip under WIN10 x64 and I get the same error:
tensorflow.python.framework.errors_impl.InvalidArgumentError:  assertion failed: [predictions must be &gt;= 0] [Condition x &gt;= y did not hold element-wise:] [x (sequential/dense_1/BiasAdd:0) = ] [[-40.4073257][-30.1479664][-27.2313709]...] [y (Cast_4/x:0) = ] [0] [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_1165]
I tried also with the docker image tensorflow/tensorflow:2.3.0-gpu and still getting errors
		</comment>
		<comment id='9' author='MeghnaNatraj' date='2020-08-08T06:43:28Z'>
		&lt;denchmark-link:https://github.com/adamp87&gt;@adamp87&lt;/denchmark-link&gt;
,
Could you please submit a new issue from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;this link&lt;/denchmark-link&gt;
 and fill in the template, so that we can track the issue there. Thanks!
		</comment>
	</comments>
</bug>