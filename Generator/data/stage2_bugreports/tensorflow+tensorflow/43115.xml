<bug id='43115' author='bchetioui' open_date='2020-09-10T16:30:09Z' closed_time='2020-12-22T20:57:58Z'>
	<summary>tf.signal.ifft returns results with different dtypes for subsequent calls with the same parameter</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10.4
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.12.1-40510-ga32c74ae8f 2.4.0-dev20200829
Python version: Python 3.8.3
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
When calling tf.signal.ifft with an operand with a complex128 dtype several times, the first call returns a complex128 array as expected, but all subsequent calls return a complex64 array.
Describe the expected behavior
tf.signal.ifft should always return an array with the same type as its input per the documentation; more importantly, it should be consistent across calls.
Standalone code to reproduce the issue
import numpy as np
import tensorflow as tf

operand = np.ones((2, 2), dtype=np.complex128)
print(tf.signal.ifft(operand).dtype)
print(tf.signal.ifft(operand).dtype)
	</description>
	<comments>
		<comment id='1' author='bchetioui' date='2020-09-11T02:51:00Z'>
		For me It works with tf-nightly and:
&lt;denchmark-code&gt;print(tf.signal.ifft([operand]).dtype)
print(tf.signal.ifft([operand]).dtype)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='bchetioui' date='2020-09-11T03:04:45Z'>
		for me it is:
2020-09-11 11:01:58.434235: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-09-11 11:01:58.458559: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80984b9190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-11 11:01:58.458578: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
tf.complex64
you need rebuild TensorFlow with the appropriate compiler flags. Because this TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
		</comment>
		<comment id='3' author='bchetioui' date='2020-09-11T03:22:33Z'>
		&lt;denchmark-link:https://github.com/TuringEmmy&gt;@TuringEmmy&lt;/denchmark-link&gt;
 try with &lt;denchmark-link:https://pypi.org/project/tf-nightly-cpu/&gt;https://pypi.org/project/tf-nightly-cpu/&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='bchetioui' date='2020-09-14T05:54:29Z'>
		&lt;denchmark-link:https://github.com/TuringEmmy&gt;@TuringEmmy&lt;/denchmark-link&gt;

Please update as per above comment.
Is there any particular reason for using older version of tf [1.13] when there are later versions available, would you want to upgrade  to latest version and let us know if you still face issues.
		</comment>
		<comment id='5' author='bchetioui' date='2020-09-14T07:05:39Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;

I assume you mean me, as &lt;denchmark-link:https://github.com/TuringEmmy&gt;@TuringEmmy&lt;/denchmark-link&gt;
 is not the original author of the issue.
I am using the TF nightly build ; isn't that (one of) the most recent TF2 builds? Nevertheless, I upgraded to , the latest version I was able to get through pip, and the issue is still here.

For me It works with tf-nightly and:
print(tf.signal.ifft([operand]).dtype)
print(tf.signal.ifft([operand]).dtype)


&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 This indeed works, but the behavior is still different across calls without the brackets. Any insight why?
		</comment>
		<comment id='6' author='bchetioui' date='2020-12-22T20:57:38Z'>
		Closing this issue since its resolved. Feel free to reopen if necessary. Thanks!
		</comment>
		<comment id='7' author='bchetioui' date='2020-12-22T20:57:59Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43115&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43115&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>