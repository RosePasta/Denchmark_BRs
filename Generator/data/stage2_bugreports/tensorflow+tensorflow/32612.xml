<bug id='32612' author='somedadaism' open_date='2019-09-18T08:19:18Z' closed_time='2019-12-16T19:38:11Z'>
	<summary>Keras can not load custom Loss functions.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): pip install
TensorFlow version (use command below): 2.0.0-beta1
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: Cuda 10.0
GPU model and memory: RTX 2080 Titan

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
If overloading the loss function in tf.keras.losses.Loss the created model can be compiled, trained and saved but not loaded.
Describe the expected behavior
Custom loss function should be loadable.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
&lt;denchmark-code&gt;import tensorflow as tf

print(tf.__version__)
class MyCustomLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred):
        return 1.



a = tf.keras.layers.Input(shape=(32,))
b = tf.keras.layers.Dense(32)(a)
model = tf.keras.models.Model(inputs=a, outputs=b)

model.compile('sgd', MyCustomLoss())
model.save('/tmp/model.h5')
model_new = tf.keras.models.load_model('/tmp/model.h5', custom_objects={'MyCustomLoss': MyCustomLoss}))
&lt;/denchmark-code&gt;

Output:
&lt;denchmark-code&gt;2.0.0-beta1
2019-09-18 10:10:54.994663: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-09-18 10:10:55.075823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:65:00.0
2019-09-18 10:10:55.077214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:b3:00.0
2019-09-18 10:10:55.077363: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-18 10:10:55.078368: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-18 10:10:55.079236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-18 10:10:55.079453: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-18 10:10:55.080500: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-18 10:10:55.081301: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-18 10:10:55.083761: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-18 10:10:55.089032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-09-18 10:10:55.089311: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-09-18 10:10:55.420058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d766e0 executing computations on platform CUDA. Devices:
2019-09-18 10:10:55.420103: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-09-18 10:10:55.420116: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
2019-09-18 10:10:55.442162: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3300000000 Hz
2019-09-18 10:10:55.444231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ef370 executing computations on platform Host. Devices:
2019-09-18 10:10:55.444265: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-09-18 10:10:55.445930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:65:00.0
2019-09-18 10:10:55.447265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:b3:00.0
2019-09-18 10:10:55.447316: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-18 10:10:55.447336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-09-18 10:10:55.447352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-09-18 10:10:55.447369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-09-18 10:10:55.447385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-09-18 10:10:55.447402: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-09-18 10:10:55.447419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-09-18 10:10:55.452337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2019-09-18 10:10:55.452385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-09-18 10:10:55.455253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-18 10:10:55.455270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2019-09-18 10:10:55.455279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2019-09-18 10:10:55.455286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2019-09-18 10:10:55.458601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9913 MB memory) -&gt; physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)
2019-09-18 10:10:55.460320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10311 MB memory) -&gt; physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File "/home/ragnar/projects/mbda/mbda_infrared/sandbox.py", line 19, in &lt;module&gt;
    model_new = tf.keras.models.load_model('/tmp/model.h5')
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py", line 137, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py", line 178, in load_model_from_hdf5
    training_config, custom_objects))
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/saving_utils.py", line 222, in compile_args_from_training_config
    loss_config = losses.get(loss_config)
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/losses.py", line 1124, in get
    return deserialize(identifier)
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/losses.py", line 1113, in deserialize
    printable_module_name='loss function')
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py", line 181, in deserialize_keras_object
    config, module_objects, custom_objects, printable_module_name)
  File "/home/ragnar/projects/mbda/mbda_infrared/venv/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py", line 166, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown loss function: MyCustomLoss

Process finished with exit code 1
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='somedadaism' date='2019-09-18T08:33:31Z'>
		I have tried on colab with TF version 2.0 beta1,2.0.0-rc0, 2.0.0-rc1 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/cae08a626511eaab7fa6b4eda8f80405/untitled199.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='somedadaism' date='2019-09-18T08:37:53Z'>
		I also tested 2.0.0-rc1 and the issue persists.
&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 If there is a label for 2.0.0-rc1, can we also add it?
		</comment>
		<comment id='3' author='somedadaism' date='2019-09-18T08:59:08Z'>
		The same problem also exists for classes implementing tf.keras.metrics.Metric.
		</comment>
		<comment id='4' author='somedadaism' date='2019-09-18T21:32:02Z'>
		&lt;denchmark-link:https://github.com/somedadaism&gt;@somedadaism&lt;/denchmark-link&gt;
 Can you save the model before compiling with  function. Then load the saved model and compile with  function as shown below. Thanks!
&lt;denchmark-code&gt;import tensorflow as tf

print(tf.__version__)
class MyCustomLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred):
        return 1.



a = tf.keras.layers.Input(shape=(32,))
b = tf.keras.layers.Dense(32)(a)
model = tf.keras.models.Model(inputs=a, outputs=b)
model.save('./model.h5') # save first and then compile
model.compile('sgd', MyCustomLoss())

# load the model
model_new = tf.keras.models.load_model('./model.h5')
model_new.compile('sgd', MyCustomLoss())
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='somedadaism' date='2019-09-20T12:44:10Z'>
		This does only work for this simple toy example. But if I want to fit the model and then save and the reload it will not work. I know how to workaround this thing myself but the intended way is not working for me. The same problem also exists for classes implementing tf.keras.metrics.Metric.
&lt;denchmark-code&gt;import tensorflow as tf

print(tf.__version__)
class MyCustomLoss(tf.keras.losses.Loss):
    def __init__(self):
        super().__init__()

    def call(self, y_true, y_pred):
        return 1.



a = tf.keras.layers.Input(shape=(32,))
b = tf.keras.layers.Dense(32)(a)
model = tf.keras.models.Model(inputs=a, outputs=b)
model.compile('sgd', MyCustomLoss()) # first compile, then fit, then save is the normal order.
model.fit(some_data, epochs=1) 
model.save('./model.h5') # I can not save any earlier!!!
# load the model
model_new = tf.keras.models.load_model('./model.h5')
model_new.compile('sgd', MyCustomLoss())
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='somedadaism' date='2019-09-21T23:27:08Z'>
		&lt;denchmark-link:https://github.com/somedadaism&gt;@somedadaism&lt;/denchmark-link&gt;
 Custom functions are not compatible.
model.save before model.compile works for small toy example and big model also.
When you load the saved model, load the model using tf.keras.models.load_model and then compile.
Please try this even for the above example or any other big model and let us know if you have any issue there.
If you don't have any custom function, then follow define model, then compile model, then save the model, and then reload the model. Thanks!
		</comment>
		<comment id='7' author='somedadaism' date='2019-09-22T00:35:09Z'>
		By simple toy example I meant my code was so minimal that your workaround would work for it but not for the standard usecase. It is not related to the model size. The difference is that usually you also fit the model. I had updated the code in my last post to show how save before compile usually does not make sense. Can you have a second look at my last code snippet?
I think Custom Loss Functions and Metrics should be supported. Can you fix this so keras works as expected?
		</comment>
		<comment id='8' author='somedadaism' date='2019-09-23T18:25:40Z'>
		&lt;denchmark-link:https://github.com/somedadaism&gt;@somedadaism&lt;/denchmark-link&gt;
 I haven't tried  as  but I tried it as   like
&lt;denchmark-code&gt;# Custom Loss1 (for example) 
@tf.function() 
def customLoss1(yTrue,yPred):
  return tf.reduce_mean(yTrue-yPred) 
&lt;/denchmark-code&gt;

In this way you can save the model as usual (create model, compile, fit, save) and load the model using load_model with custom_objects like
new_model=tf.keras.models.load_model("./model.h5",custom_objects={'customLoss1':customLoss1,'customLoss2':customLoss2})
Please check entire gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/04028d08660378ee7c2cef2b9c3bb2e9/custom_metric.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='9' author='somedadaism' date='2019-09-23T19:29:36Z'>
		Hello, thank you for your effort. I know also how to workaround for the loss function. My favorite workaround for now is to use load_model(path, compile=False). If it was only the loss functions this whole issue could be solved by just using normal functions as you propose. The fundamental problem is that the subclasses of tf.keras.metrics.Metric does not work either for presumably the same reason. Subclasses of this class can not be replaced by simple functions because metrics can be stateful. If I implement my own stateful metrics in the style of, for an example tf.keras.metrics.mIoU there is no alternative to this but if I save the model I can not load it anymore (or if I use my workaround I loose the optimizer state.) For this reason I think that a fix is necessary for the issue although there are workarounds that work in many cases.
		</comment>
		<comment id='10' author='somedadaism' date='2019-09-26T10:12:43Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 Can you give me a rough estimation for the timeframe to expect for the fix of the issue? (codebase I will deliver to a client depends on it.)
		</comment>
		<comment id='11' author='somedadaism' date='2019-10-05T10:38:47Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Are there any updates on the issue?
		</comment>
		<comment id='12' author='somedadaism' date='2019-10-18T08:45:14Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 The solution proposed by @ thierryherrmann  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/33229&gt;here&lt;/denchmark-link&gt;
 is good, but only if the inputs to the loss object are not tensors. Otherwise, a serialization exception is generated.
We could try to convert the tensor into a numpy array inside , as it is done by the  class. Unfortunately, that does not work either. It seems Keras is not well integrated with eager execution. (Side note: having access to the  class would lead to much cleaner solutions).
I have created a gist &lt;denchmark-link:https://colab.research.google.com/gist/humcasma/d7d00d6d31c4cca623c1140f050e8f94/problem_loading_custom_loss.ipynb&gt;here&lt;/denchmark-link&gt;
 with different attempts to solve the problem.
		</comment>
		<comment id='13' author='somedadaism' date='2019-12-16T19:38:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32612&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32612&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>