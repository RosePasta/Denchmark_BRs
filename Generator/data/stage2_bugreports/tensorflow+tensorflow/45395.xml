<bug id='45395' author='fsx950223' open_date='2020-12-04T06:23:45Z' closed_time='2020-12-14T07:56:31Z'>
	<summary>Invalid argument: During Variant Host-&amp;gt;Device Copy: non-DMA-copy attempted of tensor type: string</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):2.4.0rc3
Python version: 3.6.9
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: cuda11.0
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

import os
import re
import shutil
import string
import tensorflow as tf

from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras import preprocessing
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

print(tf.__version__)

url = "https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"

dataset = tf.keras.utils.get_file("aclImdb_v1.tar.gz", url,
                                    untar=True, cache_dir='.',
                                    cache_subdir='')

dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')

os.listdir(dataset_dir)

train_dir = os.path.join(dataset_dir, 'train')
os.listdir(train_dir)

sample_file = os.path.join(train_dir, 'pos/1181_9.txt')
with open(sample_file) as f:
  print(f.read())

remove_dir = os.path.join(train_dir, 'unsup')
shutil.rmtree(remove_dir)

batch_size = 32
seed = 42

raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/train', 
    batch_size=batch_size, 
    validation_split=0.2, 
    subset='training', 
    seed=seed)

for text_batch, label_batch in raw_train_ds.take(1):
  for i in range(3):
    print("Review", text_batch.numpy()[i])
    print("Label", label_batch.numpy()[i])

raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/train', 
    batch_size=batch_size, 
    validation_split=0.2, 
    subset='validation', 
    seed=seed)

raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/test', 
    batch_size=batch_size)

def custom_standardization(input_data):
  lowercase = tf.strings.lower(input_data)
  stripped_html = tf.strings.regex_replace(lowercase, '&lt;br /&gt;', ' ')
  return tf.strings.regex_replace(stripped_html,
                                  '[%s]' % re.escape(string.punctuation),
                                  '')

max_features = 10000
sequence_length = 250

vectorize_layer = TextVectorization(
    standardize=custom_standardization,
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length)

# Make a text-only dataset (without labels), then call adapt
train_text = raw_train_ds.map(lambda x, y: x)
vectorize_layer.adapt(train_text)

def vectorize_text(text, label):
  text = tf.expand_dims(text, -1)
  return text, label

train_ds = raw_train_ds.map(vectorize_text)
val_ds = raw_val_ds.map(vectorize_text)
test_ds = raw_test_ds.map(vectorize_text)

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

embedding_dim = 16

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
  model = tf.keras.Sequential([
    vectorize_layer,
    layers.Embedding(max_features + 1, embedding_dim),
    layers.Dropout(0.2),
    layers.GlobalAveragePooling1D(),
    layers.Dropout(0.2),
    layers.Dense(1)])
  model.compile(loss=losses.BinaryCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(1e-3),
                metrics=tf.metrics.BinaryAccuracy(threshold=0.0))

epochs = 10
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs)
Describe the current behavior
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "official/nlp/bert/fasttext.py", line 71, in &lt;module&gt;
    tfa.callbacks.AverageModelCheckpoint(update_weights=False, filepath=os.path.join(MODEL_DIR, 'ckpt_moving_average'))])
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py", line 828, in __call__
    result = self._call(*args, **kwds)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py", line 956, in _call
    filtered_flat_args)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py", line 560, in call
    ctx=ctx)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.
  (0) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
         [[ConstantFoldingCtrl/cond/else/_1/cond/StatefulPartitionedCall/cond_2/switch_pred/_432_0/_293]]
  (1) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
         [[cond/else/_1/cond/StatefulPartitionedCall/cond/then/_410/cond/OptionalGetValue/_196]]
  (2) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host-&gt;Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
0 successful operations.
0 derived errors ignored. [Op:__inference_fn_with_cond_4681]

Function call stack:
fn_with_cond -&gt; fn_with_cond -&gt; fn_with_cond
&lt;/denchmark-code&gt;

Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='fsx950223' date='2020-12-11T21:13:54Z'>
		Hi &lt;denchmark-link:https://github.com/fsx950223&gt;@fsx950223&lt;/denchmark-link&gt;
, I ran this code in 2.3 and in nightly and did not face any errors. Additionally, the stack trace you have provided seems to be from a different issue? I don't see where your code is referencing Bert.
		</comment>
		<comment id='2' author='fsx950223' date='2020-12-11T23:54:48Z'>
		I ran the code in 2.4rc3, the code is not reference bert.
		</comment>
		<comment id='3' author='fsx950223' date='2020-12-11T23:59:29Z'>
		The first line of the stack trace you have provided says File "official/nlp/bert/fasttext.py", line 71, in &lt;module&gt;. As I do not see Bert in your code I was wondering why it shows up in the stack trace.
I did not see an issue in nightly. Can you please try your code with nightly? I will try with 2.4rc3
[Update: I have tested with 2.4rc3 and do not see any errors there either.]
		</comment>
		<comment id='4' author='fsx950223' date='2020-12-12T00:20:40Z'>
		I write the code under bert folder.
I will check again later.
		</comment>
		<comment id='5' author='fsx950223' date='2020-12-14T07:56:31Z'>
		Unfortunately, I can't reproduce the bug on the public dataset. I met the bug in my dataset pipeline, but I can't open-source it. I avoid the bug by moving vectorize_layer from model to dataset.
		</comment>
		<comment id='6' author='fsx950223' date='2020-12-14T07:56:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45395&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/45395&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>