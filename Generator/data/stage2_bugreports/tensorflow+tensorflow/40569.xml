<bug id='40569' author='StriderDM35' open_date='2020-06-18T11:00:02Z' closed_time='2020-08-24T18:25:46Z'>
	<summary>AttributeError: 'Tensor' object has no attribute 'numpy'</summary>
	<description>
System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution: Windows 10
TensorFlow installed from (source or binary):
TensorFlow version: 2.0.0
Python version: 3.6
GPU model and memory: NVIDIA 4GB GTX970
My code is giving me the error 'AttributeError: 'Tensor' object has no attribute 'numpy'' in the bolded line, with the comments "Error occurs here".
I want to perform selective search on the feature mappings generated by the convolutional layers in my CNN model. However, it appears that cv2 functions do not accept tensors, and thus I wish to convert the tensors to numpy arrays. However, when I attempt to do the conversion using the numpy() or tf.py_function() functions, I will get the attribute error as shown above.
Is this error occuring because I am calling numpy() within the model which is using @tf.function? Is there any other way to perform this operation?
Thank you.
Here is my code:
&lt;denchmark-code&gt;class seq_model(object):
    def __init__(self):
        print("Using SEQUENTIAL model")

    def input(self):
        #Create CNN model
        input_size = (28, 28, 1)
        inputs = Input(shape = input_size)
        return inputs

    def selective_search(self, input_stack):
        cv2.setUseOptimized(True)
        cv2.setNumThreads(4)
        total_ROI = 0
        ROI_img_list = []
        select_search = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()

        input_shape = input_stack.get_shape().as_list()
        print("input_shape = ", input_shape)
        no_of_channel = input_shape[3]
        for i in range(no_of_channel):
            if input_shape[0] == None:
                img_tensor = input_stack[-1,:,:,i]

                **img = img_tensor.numpy()** #Error occurs at this line

                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) #Ensure 3 channels
            select_search.setBaseImage(img)
            select_search.switchToSelectiveSearchQuality()
            rects = select_search.process()
            numShowRects = 100
            img_copy = img.copy()
            boundary_list = []
            for j, rect in enumerate(rects):
                if (j &lt; numShowRects):
                    x, y, w, h = rect
                    cv2.rectangle(img_copy, (x,y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)
                    boundary = [x, x+w, y, y+h]
                    boundary_list.append(boundary)
                else:
                    break
            num_region = len(boundary_list)
            label = label_stack[i]
            for k in range(num_region):
                corner = boundary_list[k]
                x1 = corner[0]
                x2 = corner[1]
                y1 = corner[2]
                y2 = corner[3]
                ROI_img = img[y1:y2, x1:x2]
                ROI_img = cv2.cvtColor(ROI_img, cv2.COLOR_RGB2GRAY)
                ROI_img_reshaped = np.empty(CNN_input_shape)
                ROI_img_reshaped = cv2.resize(ROI_img, (y2-y1, x2-x1))
                ROI_img_list.append(ROI_img_reshaped)
            total_ROI += num_region #Obtain total number of ROI images
            ROI_stack = np.empty((total_ROI, 28, 28, 1))

        return ROI_stack

    def spatial_pyramid_pooling(self, input, levels):
        #Levels refers to the list of pooling regions to use. 
        #The length of the list is the number of pooling regions.
        #Each int in the list is the number of regions in that pool. 
        #For example [1,2,4] would be 3 regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map
        input_shape = input.get_shape().as_list()
        pyramid = []
        outputs = []
        num_rows = input_shape[1]
        num_cols = input_shape[2]
        row_length = [K.cast(num_rows, 'float32') / i for i in levels] #Returns a Keras tensor of float32 type
        col_length = [K.cast(num_cols, 'float32') / i for i in levels]
        tf.print(row_length) #[4,8,16]
        tf.print(col_length) #[4,8,16]

        for pool_num, num_pool_regions in enumerate(levels): #pool_num is the index, num_pool_regions is the actual value
            for jy in range(num_pool_regions):
                for ix in range(num_pool_regions):
                    x1 = ix * col_length[pool_num]
                    x2 = ix * col_length[pool_num] + col_length[pool_num]
                    y1 = jy * row_length[pool_num]
                    y2 = jy * row_length[pool_num] + row_length[pool_num]

                    x1 = K.cast(K.round(x1), 'int32')
                    x2 = K.cast(K.round(x2), 'int32')
                    y1 = K.cast(K.round(y1), 'int32')
                    y2 = K.cast(K.round(y2), 'int32')

                    if input_shape[0] == None:
                        new_shape = [-1, y2 - y1, x2 - x1, input_shape[3]]

                    x_crop = input[:, y1:y2, x1:x2, :]
                    xm = Reshape(new_shape)(x_crop)
                    pooled_val = K.max(xm, axis = (1, 2)) #Obtain maximum value from cropped image
                    #print("pooled_val = ", np.shape(pooled_val))
                    outputs.append(pooled_val)    

        outputs = concatenate(outputs, axis = 1)
        #print("SHAPE = ", np.shape(outputs)) #(None, 112, 64)
        return outputs

    def conv_model(self, no_of_class = 10):
        kernel_size = (3,3)
        pad = 'same'
        activation = 'selu'
        kernel = 'lecun_normal'
        filters = 64

        self.initial_input = self.input()

        c1 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(self.initial_input)
        b1 = BatchNormalization()(c1) 
        p1 = MaxPooling2D()(b1)

        c2 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(p1)
        b2 = BatchNormalization()(c2) 

        roi = self.selective_search(b2)
        spp = self.spatial_pyramid_pooling(roi, levels = [3,2,1])

        f = Flatten()(spp)
        bf = BatchNormalization()(f)

        bf_shape = bf.get_shape().as_list()
        dense_num = bf_shape[1] #Changes the dense layer automatically

        d1 = Dense(dense_num, activation = 'selu', kernel_initializer = kernel)(bf)
        db1 = BatchNormalization()(d1)
        d2 = Dense(10, activation = 'softmax')(db1)

        model = Model(inputs = [self.initial_input], outputs = [d2])

        return model

get_model = seq_model()
model = get_model.conv_model()
print(model.summary())

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='StriderDM35' date='2020-06-18T12:08:12Z'>
		&lt;denchmark-link:https://github.com/StriderDM35&gt;@StriderDM35&lt;/denchmark-link&gt;

I tried in colab and i am seeing the error message(NameError: name 'Input' is not defined).Request you to share colab link or simple standalone file sode with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='StriderDM35' date='2020-06-18T12:10:49Z'>
		
@StriderDM35
I tried in colab and i am seeing the error message(NameError: name 'Input' is not defined).Request you to share colab link or simple standalone file sode with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!

My apologies, &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
. I had forgotten to include the libraries used for my code. Please include the libraries below:
&lt;denchmark-code&gt;import os
import glob
import numpy as np
import matplotlib.pyplot as plt
import cv2

import keras
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model, load_model, Sequential, model_from_json, load_model
from tensorflow.keras.layers import Input, BatchNormalization, Activation, Flatten, Dense, LeakyReLU, Reshape
from tensorflow.keras.layers import concatenate
from tensorflow.python.keras.layers.core import Lambda, Dropout
from tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D
from tensorflow.python.keras.layers.pooling import MaxPooling2D, AveragePooling2D
from tensorflow.python.keras.layers.merge import Concatenate, Add
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.optimizers import *
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

class seq_model(object):
    def __init__(self):
        print("Using SEQUENTIAL model")

    def input(self):
        #Create CNN model
        input_size = (28, 28, 1)
        inputs = Input(shape = input_size)
        return inputs

    def selective_search(self, input_stack):
        cv2.setUseOptimized(True)
        cv2.setNumThreads(4)
        total_ROI = 0
        ROI_img_list = []
        select_search = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()

        input_shape = input_stack.get_shape().as_list()
        print("input_shape = ", input_shape)
        no_of_channel = input_shape[3]
        for i in range(no_of_channel):
            if input_shape[0] == None:
                img_tensor = input_stack[-1,:,:,i]

                **img = img_tensor.numpy()** #Error occurs at this line

                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) #Ensure 3 channels
            select_search.setBaseImage(img)
            select_search.switchToSelectiveSearchQuality()
            rects = select_search.process()
            numShowRects = 100
            img_copy = img.copy()
            boundary_list = []
            for j, rect in enumerate(rects):
                if (j &lt; numShowRects):
                    x, y, w, h = rect
                    cv2.rectangle(img_copy, (x,y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)
                    boundary = [x, x+w, y, y+h]
                    boundary_list.append(boundary)
                else:
                    break
            num_region = len(boundary_list)
            label = label_stack[i]
            for k in range(num_region):
                corner = boundary_list[k]
                x1 = corner[0]
                x2 = corner[1]
                y1 = corner[2]
                y2 = corner[3]
                ROI_img = img[y1:y2, x1:x2]
                ROI_img = cv2.cvtColor(ROI_img, cv2.COLOR_RGB2GRAY)
                ROI_img_reshaped = np.empty(CNN_input_shape)
                ROI_img_reshaped = cv2.resize(ROI_img, (y2-y1, x2-x1))
                ROI_img_list.append(ROI_img_reshaped)
            total_ROI += num_region #Obtain total number of ROI images
            ROI_stack = np.empty((total_ROI, 28, 28, 1))

        return ROI_stack

    def spatial_pyramid_pooling(self, input, levels):
        #Levels refers to the list of pooling regions to use. 
        #The length of the list is the number of pooling regions.
        #Each int in the list is the number of regions in that pool. 
        #For example [1,2,4] would be 3 regions with 1, 2x2 and 4x4 max pools, so 21 outputs per feature map
        input_shape = input.get_shape().as_list()
        pyramid = []
        outputs = []
        num_rows = input_shape[1]
        num_cols = input_shape[2]
        row_length = [K.cast(num_rows, 'float32') / i for i in levels] #Returns a Keras tensor of float32 type
        col_length = [K.cast(num_cols, 'float32') / i for i in levels]
        tf.print(row_length) #[4,8,16]
        tf.print(col_length) #[4,8,16]

        for pool_num, num_pool_regions in enumerate(levels): #pool_num is the index, num_pool_regions is the actual value
            for jy in range(num_pool_regions):
                for ix in range(num_pool_regions):
                    x1 = ix * col_length[pool_num]
                    x2 = ix * col_length[pool_num] + col_length[pool_num]
                    y1 = jy * row_length[pool_num]
                    y2 = jy * row_length[pool_num] + row_length[pool_num]

                    x1 = K.cast(K.round(x1), 'int32')
                    x2 = K.cast(K.round(x2), 'int32')
                    y1 = K.cast(K.round(y1), 'int32')
                    y2 = K.cast(K.round(y2), 'int32')

                    if input_shape[0] == None:
                        new_shape = [-1, y2 - y1, x2 - x1, input_shape[3]]

                    x_crop = input[:, y1:y2, x1:x2, :]
                    xm = Reshape(new_shape)(x_crop)
                    pooled_val = K.max(xm, axis = (1, 2)) #Obtain maximum value from cropped image
                    #print("pooled_val = ", np.shape(pooled_val))
                    outputs.append(pooled_val)    

        outputs = concatenate(outputs, axis = 1)
        #print("SHAPE = ", np.shape(outputs)) #(None, 112, 64)
        return outputs

    def conv_model(self, no_of_class = 10):
        kernel_size = (3,3)
        pad = 'same'
        activation = 'selu'
        kernel = 'lecun_normal'
        filters = 64

        self.initial_input = self.input()

        c1 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(self.initial_input)
        b1 = BatchNormalization()(c1) 
        p1 = MaxPooling2D()(b1)

        c2 = Conv2D(filters, kernel_size, padding = pad, activation = activation, kernel_initializer = kernel)(p1)
        b2 = BatchNormalization()(c2) 

        roi = self.selective_search(b2)
        spp = self.spatial_pyramid_pooling(roi, levels = [3,2,1])

        f = Flatten()(spp)
        bf = BatchNormalization()(f)

        bf_shape = bf.get_shape().as_list()
        dense_num = bf_shape[1] #Changes the dense layer automatically

        d1 = Dense(dense_num, activation = 'selu', kernel_initializer = kernel)(bf)
        db1 = BatchNormalization()(d1)
        d2 = Dense(10, activation = 'softmax')(db1)

        model = Model(inputs = [self.initial_input], outputs = [d2])

        return model

get_model = seq_model()
model = get_model.conv_model()
print(model.summary())

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='StriderDM35' date='2020-06-18T12:44:05Z'>
		I have tried in colab with TF versions 2.2 ,nightly versions and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/707519c3eb063d7973ca773bf70dbcf1/untitled47.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='4' author='StriderDM35' date='2020-07-06T14:23:57Z'>
		&lt;denchmark-link:https://github.com/StriderDM35&gt;@StriderDM35&lt;/denchmark-link&gt;
 Please take a look at this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27519&gt;issue&lt;/denchmark-link&gt;
  especially this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27519#issuecomment-566528842&gt;comment&lt;/denchmark-link&gt;
 and let me know if it helps!
		</comment>
		<comment id='5' author='StriderDM35' date='2020-07-07T03:30:47Z'>
		Hi, &lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
. I have checked my code using the issue that you mentioned and noticed that the img that raised the error is also returning &lt;class 'tensorflow.python.framework.ops.Tensor'&gt;.
However, neither "model.run_eagerly = True" nor "tf.config.experimental_run_functions_eagerly(True)" solved the issue.
		</comment>
		<comment id='6' author='StriderDM35' date='2020-08-10T17:24:19Z'>
		&lt;denchmark-link:https://github.com/StriderDM35&gt;@StriderDM35&lt;/denchmark-link&gt;
 The issue here is that you are trying to convert  to a numpy array which is called while a graph is executed i.e., eager execution disabled (img_tensor.numpy() only works when eager execution is enabled) and that is the reason why you are noticing this error.
		</comment>
		<comment id='7' author='StriderDM35' date='2020-08-17T17:27:31Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='StriderDM35' date='2020-08-24T18:25:43Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='9' author='StriderDM35' date='2020-08-24T18:25:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40569&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40569&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>