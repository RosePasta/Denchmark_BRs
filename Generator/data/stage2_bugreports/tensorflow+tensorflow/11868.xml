<bug id='11868' author='jjallaire' open_date='2017-07-29T11:54:27Z' closed_time='2017-08-29T20:26:17Z'>
	<summary>keras resnet50 example yields different predictions than in stand-alone keras</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No (using example from Keras documentation here: https://keras.io/applications/#classify-imagenet-classes-with-resnet50
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.12.6
TensorFlow installed from (source or binary): Binary (CPU Version)
TensorFlow version (use command below): ('v1.2.0-5-g435cdfc', '1.2.1')
Python version: 2.7 (OS X system version)
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:

from tensorflow.contrib.keras.python.keras.applications.resnet50 import ResNet50
from tensorflow.contrib.keras.python.keras.preprocessing import image
from tensorflow.contrib.keras.python.keras.applications.resnet50 import preprocess_input, decode_predictions

import numpy as np

model = ResNet50(weights='imagenet')

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = model.predict(x)

print('Predicted:', decode_predictions(preds, top=3)[0])
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

The above code yields the following output:
('Predicted:', [(u'n02098286', u'West_Highland_white_terrier', 1.0), 
                (u'n15075141', u'toilet_tissue', 0.0), 
                (u'n02319095', u'sea_urchin', 0.0)])
However, the same code run using Stand-alone Keras yields this:
('Predicted:', [(u'n02504013', u'Indian_elephant', 0.91937912), 
                (u'n01871265', u'tusker', 0.070962951), 
                (u'n02504458', u'African_elephant', 0.0095201703)])
Note: to reproduce under stand-alone Keras substitute this code for the imports at the top:
from keras.applications.resnet50 import ResNet50
from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions
Also note that you need the 'elephant.jpg' file in the working directory to reproduce. You can find that file here: &lt;denchmark-link:https://github.com/rstudio/keras/blob/master/docs/articles/elephant.jpg&gt;https://github.com/rstudio/keras/blob/master/docs/articles/elephant.jpg&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='jjallaire' date='2017-07-29T13:33:29Z'>
		Observed the same behavior with ('v1.3.0-rc1-447-g4b50313', '1.2.1-rc1')
		</comment>
		<comment id='2' author='jjallaire' date='2017-07-29T21:37:44Z'>
		I have noticed this issue for long. See &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/11160&gt;#11160&lt;/denchmark-link&gt;
. The predefined weights seem to be essentially random in tf.contrib.keras and issues do not seem to get much attention.  After some time trying to port my keras models to tf.contrib.keras, I have moved to tf-slim models/api which is excellent.
		</comment>
		<comment id='3' author='jjallaire' date='2017-07-31T01:56:51Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
, could you take a look, please. Thanks!
		</comment>
		<comment id='4' author='jjallaire' date='2017-07-31T05:30:25Z'>
		&lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
 I won't have time to look into these issues for at least a week or so. Can we find someone else? Currently every single issue related to Keras is routed to me personally, which isn't scalable.
		</comment>
		<comment id='5' author='jjallaire' date='2017-08-01T12:16:45Z'>
		There is no significant change in the resnet script, but several tf-keras layers have been refactored in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/35253fa89c5f8af25e3d84f76980729569091a6c&gt;here&lt;/denchmark-link&gt;
. Thus, I tested the four individual layers mainly used in the resnet, and found something weird in  as follows:
import keras
import tensorflow as tf
import numpy as np

x = np.random.random((1, 6, 6, 3))
x1 = keras.layers.Input((6, 6, 3))
x2 = tf.contrib.keras.layers.Input((6, 6, 3))

layers1 = [
    keras.layers.Conv2D(10, (5, 5))(x1),
    keras.layers.BatchNormalization()(x1),
    keras.layers.MaxPooling2D()(x1),
    keras.layers.AveragePooling2D()(x1)
]

layers2 = [
    tf.contrib.keras.layers.Conv2D(10, (5, 5))(x2),
    tf.contrib.keras.layers.BatchNormalization()(x2),
    tf.contrib.keras.layers.MaxPooling2D()(x2),
    tf.contrib.keras.layers.AveragePooling2D()(x2)
]

for (k, t) in zip(layers1, layers2):
    model1 = keras.models.Model(x1, k)
    model2 = tf.contrib.keras.models.Model(x2, t)
    y1 = model1.predict(x)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        y2 = model2.predict(x)
    print("%s: %.3f" % (t.name, np.sum((y1 - y2) ** 2)))
The results are:
&lt;denchmark-code&gt;conv2d/BiasAdd:0: 9.476
batch_normalization/batchnorm/add_1:0: 0.000
max_pooling2d/MaxPool:0: 0.000
average_pooling2d/AvgPool:0: 0.000
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='jjallaire' date='2017-08-09T06:52:03Z'>
		I examined each of the layers in ResNet50 and found a slight difference between  layers of keras and tf-keras. Would you please check this comment &lt;denchmark-link:https://github.com/aselle&gt;@aselle&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
?
import keras
import tensorflow as tf
import numpy as np

from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions
img = image.load_img('elephant.png', target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

resnet1 = keras.applications.ResNet50(weights='imagenet')
resnet2 = tf.contrib.keras.applications.ResNet50(weights='imagenet')

for i in range(1, 3):
    model1 = keras.models.Model(inputs=resnet1.input, outputs=resnet1.layers[i].output)
    model2 = tf.contrib.keras.models.Model(inputs=resnet2.input, outputs=resnet2.layers[i].output)
    y1 = model1.predict(x)
    y2 = model2.predict(x)
    print("- %s -" % model1.layers[-1].name)
    print("Residual sum: %.3f" % np.sum((y1 - y2) ** 2))
    print("Keras weights: %s" % model1.layers[-1].weights)
    print("TF-Keras weights: %s" % model2.layers[-1].weights)
The results are:
- conv1 -
Residual sum: 0.000
Keras weights: [&lt;tf.Variable 'conv1/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt;, &lt;tf.Variable 'conv1/bias:0' shape=(64,) dtype=float32_ref&gt;]
TF-Keras weights: [&lt;tf.Variable 'conv1/kernel_1:0' shape=(7, 7, 3, 64) dtype=float32_ref&gt;, &lt;tf.Variable 'conv1/bias_1:0' shape=(64,) dtype=float32_ref&gt;]
- bn_conv1 -
Residual sum: 9147763.000
Keras weights: [&lt;tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/moving_mean:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/moving_variance:0' shape=(64,) dtype=float32_ref&gt;]
TF-Keras weights: [&lt;tf.Variable 'bn_conv1/beta_1:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/gamma_1:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/moving_mean_1:0' shape=(64,) dtype=float32_ref&gt;, &lt;tf.Variable 'bn_conv1/moving_variance_1:0' shape=(64,) dtype=float32_ref&gt;]
While the gamma is defined first in original keras, the beta is done first in tf keras. This order is important because the load_weights() of keras API checks shapes of symbolic and numpy tensors according to the order. In order words, pretrained variables are stored as [gamma, beta] format but tf-keras reads them as [beta, gamma] without error due to the same shape. The load_weights() doesn't check tensor names.
I listed up two concise solutions as follows:

Swapping the two self.add_variable calls for gamma and beta in tensorflow/python/layers/normalization.py: I think this might be the best if the swapping doesn't break someone's code.
Adding self.trainable_weights = self.trainable_weights[::-1] after layer building in tensorflow/contrib/keras/python/keras/layers/normalization.py: This seems to be a patchwork but no one's codes will break.
Which one of these looks better?

		</comment>
		<comment id='7' author='jjallaire' date='2017-08-29T20:26:17Z'>
		This has been fixed last week and will soon appear in GitHub.
		</comment>
		<comment id='8' author='jjallaire' date='2017-10-23T07:58:51Z'>
		I just checkout the latest tree with
git fetch -a
git checkout master
git pull
But, I still cannot find the fix for issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/11868&gt;#11868&lt;/denchmark-link&gt;
. Can you please double-check if it was merged to GitHub ?
Thanks!
counterexample: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/13562&gt;#13562&lt;/denchmark-link&gt;
 is visible.
		</comment>
	</comments>
</bug>