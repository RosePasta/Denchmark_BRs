<bug id='28552' author='vgoklani' open_date='2019-05-09T13:39:42Z' closed_time='2019-05-21T18:45:33Z'>
	<summary>W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.</summary>
	<description>
This is running on tensorflow v2 alpha on a GPU (NVIDIA RTX 2080ti)
This message keeps showing up in the logs, and I'm not sure how to dig further. Training has been very slow, and I'm guessing that it's because of this:
&lt;denchmark-code&gt;W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.
&lt;/denchmark-code&gt;

This error occurs when I call the model.fit function:
&lt;denchmark-code&gt;def get_model():
    model_input = Input(shape=input_shape[1:], name="input_layer")
    x = Conv2D(32, (3, 10), padding="same", name="layer1a")(model_input)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPool2D()(x)

    x = Conv2D(32, (3, 10), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPool2D()(x)

    x = Conv2D(32, (3, 10), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPool2D()(x)

    x = Conv2D(32, (3, 10), padding="same")(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPool2D()(x)

    x = Flatten()(x)
    x = Dense(64)(x)
    x = BatchNormalization()(x)
    x = Activation("relu")(x)
    model_output = Dense(number_classes, activation='softmax')(x)
    model = Model(inputs=model_input, outputs=model_output)
    model.compile(loss="categorical_crossentropy", optimizer="sgd")
    return model

model = get_model()

model.fit(train_dataset, steps_per_epoch=total_size // args.batch_size, epochs=args.epochs, validation_data=validation_dataset, validation_steps=500)
&lt;/denchmark-code&gt;

where both train_dataset and validation_dataset are instances of tf.data:
&lt;denchmark-code&gt;def preprocess(self, x):
	image, target = _parse_function_train(x)
	image = tf.image.convert_image_dtype(image, tf.float32)
	image = tf.image.resize_with_pad(image, target_height=self.image_height, target_width=self.image_width)
	return image, target

def get_datasets(self):
	self.data["train_curated"] = tf.data.TFRecordDataset("train_curated.tfrecords")
	dataset = self.data["train_curated"].shuffle(args.train_curated_count)
	validation_size = int(args.validation_size_split_ratio * args.train_curated_count)

	validation_dataset = dataset.take(validation_size)
	validation_dataset = validation_dataset.map(self.preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)
	validation_dataset = validation_dataset.shuffle(validation_size)
	validation_dataset = validation_dataset.cache()
	validation_dataset = validation_dataset.repeat()
	validation_dataset = validation_dataset.batch(args.batch_size)
	validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

	train_dataset = dataset.skip(validation_size)
	train_dataset = train_dataset.map(self.preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)
	train_dataset = train_dataset.shuffle(args.train_curated_count - validation_size)
	train_dataset = train_dataset.repeat()
	train_dataset = train_dataset.batch(args.batch_size)
	train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

	return train_dataset, validation_dataset
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='vgoklani' date='2019-05-12T15:59:58Z'>
		I'm running into the same issue. I think it has to do with the tf.data.Dataset.shuffle method. Haven't found a fix just yet, because as you said, it works, it just throws this warning and runs fairly slow.
		</comment>
		<comment id='2' author='vgoklani' date='2019-05-13T08:22:43Z'>
		&lt;denchmark-link:https://github.com/vgoklani&gt;@vgoklani&lt;/denchmark-link&gt;
 In order to expedite the trouble-shooting process, please provide a minimum code snippet to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='3' author='vgoklani' date='2019-05-13T14:34:49Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 thank you for looking into this -- encountered the same when testing pix2pix on tf-gpu 2.0 &lt;denchmark-link:https://www.tensorflow.org/alpha/tutorials/generative/pix2pix&gt;https://www.tensorflow.org/alpha/tutorials/generative/pix2pix&lt;/denchmark-link&gt;
. Used  and have no other tf versions active.
Can also verify &lt;denchmark-link:https://github.com/Atrus619&gt;@Atrus619&lt;/denchmark-link&gt;
 comment on shuffle: when  is commented, no error appears.
		</comment>
		<comment id='4' author='vgoklani' date='2019-05-14T11:54:50Z'>
		I meet the same trouble
		</comment>
		<comment id='5' author='vgoklani' date='2019-05-19T11:14:19Z'>
		Same here, model takes ages to train
		</comment>
		<comment id='6' author='vgoklani' date='2019-05-21T17:41:56Z'>
		I am getting the same error on TensorFlow 1.13.1 using the MNIST dataset from tensorflow-datasets (1.0.2).
		</comment>
		<comment id='7' author='vgoklani' date='2019-05-21T18:45:33Z'>
		Note that even though this warning is unexpected, it should have no effect on performance and will be removed in future versions of TensorFlow to avoid confusion.
		</comment>
		<comment id='8' author='vgoklani' date='2019-05-21T18:45:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28552&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28552&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='vgoklani' date='2019-07-31T09:09:21Z'>
		I got a same error and it may be related to parallel calls used in map().
So I shuffle the dataset before map it, then it works correctly.
		</comment>
		<comment id='10' author='vgoklani' date='2019-08-19T12:52:21Z'>
		I had the same error when I used TF 1.14 installed using conda. However, when I remove it and install it using pip, the error is gone and the training in about 4 times faster.
		</comment>
	</comments>
</bug>