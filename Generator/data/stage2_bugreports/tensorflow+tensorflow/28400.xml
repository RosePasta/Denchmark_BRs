<bug id='28400' author='Madder' open_date='2019-05-04T18:53:34Z' closed_time='2019-06-23T09:07:14Z'>
	<summary>[Regression] Conv1D output shape is lost when dilation_rate != 1.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom simple Keras sequential model with Conv1D dilated layers.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): Works in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410 but fails in tf-nightly-gpu-2.0-preview==2.0.0.dev20190504.
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10.0 (installed via conda)
GPU model and memory: Turing (2080 Ti)

Describe the current behavior
The output shape is not inferred correctly anymore for a Keras Conv1D with dilation_rate != 1 (it is ok when dilation_rate = 1). Shape inference used to work as expected in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410.
Describe the expected behavior
Please revert to the behaviour available in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410
Code to reproduce the issue
CORRECT behaviour with a dilation_rate=1:
&lt;denchmark-code&gt;model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 1, padding='causal',
                           kernel_regularizer=tfk.regularizers.l2(0.01), input_shape=(2560, 8)),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Softmax(),
])

model.summary()
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_26 (Conv1D)           (None, 2560, 24)          408       
_________________________________________________________________
re_lu_23 (ReLU)              (None, 2560, 24)          0         
_________________________________________________________________
dense_3 (Dense)              (None, 2560, 10)          250       
_________________________________________________________________
softmax_2 (Softmax)          (None, 2560, 10)          0         
=================================================================
Total params: 658
Trainable params: 658
Non-trainable params: 0
_________________________________________________________________
&lt;/denchmark-code&gt;

Shape inference FAILS with a dilation_rate=2 (or &gt;1): The second dimension of the output shape's is lost,
&lt;denchmark-code&gt;model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',
                           kernel_regularizer=tfk.regularizers.l2(0.01), input_shape=(2560, 8)),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Softmax(),
])

model.summary()
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_27 (Conv1D)           (None, None, 24)          408       
_________________________________________________________________
re_lu_24 (ReLU)              (None, None, 24)          0         
_________________________________________________________________
dense_4 (Dense)              (None, None, 10)          250       
_________________________________________________________________
softmax_3 (Softmax)          (None, None, 10)          0         
=================================================================
Total params: 658
Trainable params: 658
Non-trainable params: 0
&lt;/denchmark-code&gt;

Please note that the behaviour in 20190410 was correct independently of the dilation_rate.
Other info / logs
This causes more issues downstream as one can't concatenate or sum outputs w.r.t the axis with the unknown shape.
	</description>
	<comments>
		<comment id='1' author='Madder' date='2019-05-06T11:00:16Z'>
		&lt;denchmark-link:https://github.com/Madder&gt;@Madder&lt;/denchmark-link&gt;
 In order to expedite the trouble-shooting process, please provide whole code snippet to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='Madder' date='2019-05-06T11:17:17Z'>
		Hi &lt;denchmark-link:https://github.com/muddham&gt;@muddham&lt;/denchmark-link&gt;
 : Complete code snipped to reproduce the issue:
&lt;denchmark-code&gt;import tensorflow as tf
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',
                           kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(2560, 8)),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Softmax(),
])

model.summary()
&lt;/denchmark-code&gt;

Output in  tf-nightly-gpu-2.0-preview==2.0.0.dev20190504 (and  tf-nightly-gpu-2.0-preview==2.0.0.dev20190505):
&lt;denchmark-code&gt;Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, None, 24)          408       
_________________________________________________________________
re_lu_1 (ReLU)               (None, None, 24)          0         
_________________________________________________________________
dense_1 (Dense)              (None, None, 10)          250       
_________________________________________________________________
softmax_1 (Softmax)          (None, None, 10)          0         
=================================================================
Total params: 658
Trainable params: 658
Non-trainable params: 0
_________________________________________________________________
&lt;/denchmark-code&gt;

Output in  tf-nightly-gpu-2.0-preview==2.0.0.dev20190410 (output shape inferred correctly):
&lt;denchmark-code&gt;Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 2560, 24)          408       
_________________________________________________________________
re_lu (ReLU)                 (None, 2560, 24)          0         
_________________________________________________________________
dense (Dense)                (None, 2560, 10)          250       
_________________________________________________________________
softmax (Softmax)            (None, 2560, 10)          0         
=================================================================
Total params: 658
Trainable params: 658
Non-trainable params: 0
_________________________________________________________________
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='Madder' date='2019-05-06T14:18:57Z'>
		&lt;denchmark-link:https://github.com/Madder&gt;@Madder&lt;/denchmark-link&gt;
 Able to reproduce the issue in in tf-nightly-gpu-2.0-preview==2.0.0.dev20190504 and tf-nightly-gpu-2.0-preview==2.0.0.dev20190505.
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;Layer (type)                 Output Shape              Param #&lt;/denchmark-h&gt;

conv1d (Conv1D)              (None, None, 24)          408
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

re_lu (ReLU)                 (None, None, 24)          0
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

dense (Dense)                (None, None, 10)          250
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h1&gt;softmax (Softmax)            (None, None, 10)          0&lt;/denchmark-h&gt;

Total params: 658
Trainable params: 658
Non-trainable params: 0
		</comment>
		<comment id='4' author='Madder' date='2019-05-25T08:53:27Z'>
		Please note that this bug is also reproduced in the just released Tensorflow 1.14 rc0 when eager execution is enabled:
&lt;denchmark-code&gt;import tensorflow as tf
tf.enable_eager_execution()

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',
                           kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(2560, 8)),
    tf.keras.layers.ReLU(),
    tf.keras.layers.Dense(10),
    tf.keras.layers.Softmax(),
])

model.summary()
&lt;/denchmark-code&gt;

The axis=1 length is lost again similarly to the issue in tf2 nightly:
&lt;denchmark-code&gt;Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, None, 24)          408       
_________________________________________________________________
re_lu_1 (ReLU)               (None, None, 24)          0         
_________________________________________________________________
dense_1 (Dense)              (None, None, 10)          250       
_________________________________________________________________
softmax_1 (Softmax)          (None, None, 10)          0         
=================================================================
Total params: 658
Trainable params: 658
Non-trainable params: 0
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='Madder' date='2019-06-08T08:01:06Z'>
		Please note that this bug is still present in Tensorflow 2.0 Beta0
		</comment>
		<comment id='6' author='Madder' date='2019-06-13T06:48:04Z'>
		Able to reproduce the issue in tensorflow==2.0.0-beta0
		</comment>
		<comment id='7' author='Madder' date='2019-06-23T09:04:39Z'>
		This affects all conv layers, I believe. This is probably a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29843&gt;#29843&lt;/denchmark-link&gt;
. That issue has some debugging I've done, the error seems to be in .
		</comment>
		<comment id='8' author='Madder' date='2019-06-23T09:07:14Z'>
		I'm closing this as a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29542&gt;#29542&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='Madder' date='2019-06-23T09:07:16Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28400&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28400&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>