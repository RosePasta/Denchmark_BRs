<bug id='26262' author='skiler07' open_date='2019-03-01T17:56:27Z' closed_time='2019-03-20T20:56:20Z'>
	<summary>TF Boosted Trees doesn't consume the tf.Dataset as expected (incorrect checksum for freed object - object was probably modified after being freed)</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs/CloudML
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.13.1
Python version: 2.7
CPU training

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
The model doesn't consume the dataset object properly.
My input_fn is:
&lt;denchmark-code&gt;def build_training_input_fn(file_pattern, train=False):
    """Creates an input function reading from transformed data.
    Args:
      transformed_examples: Base filename of examples.
    Returns:
      The input function for training or valid.
    """

    def parse_record(record):
        transformed_metadata = metadata_io.read_metadata(
            os.path.join(
                'gs://path_to_bucket/transform',
                transform_fn_io.TRANSFORMED_METADATA_DIR))
        transformed_feature_spec = transformed_metadata.schema.as_feature_spec()

        transformed_features = tf.parse_single_example(record, transformed_feature_spec)
        cols_to_remove = {'label_key'}
        transformed_labels = transformed_features.pop('label_key')
        transformed_features = {key: value for (key, value) in transformed_features.items() if
                                key not in cols_to_remove}
        return transformed_features, transformed_labels

    def input_fn(train=train):
        """Input function for training and valid."""
        files = tf.data.Dataset.list_files(file_pattern=file_pattern)
        dataset = files.apply(
            tf.data.experimental.parallel_interleave(
                lambda filename: tf.data.TFRecordDataset(filename),
                cycle_length=32,
                block_length=1,
                sloppy=True,
            ))
        if train:
            dataset = dataset.repeat(None)

        dataset = dataset.apply(tf.data.experimental.map_and_batch(
            map_func=parse_record, batch_size=64, drop_remainder=False,
            num_parallel_batches=16))

        return dataset

    return input_fn
&lt;/denchmark-code&gt;

I train the model using:
&lt;denchmark-code&gt;    classifier = tf.estimator.BoostedTreesClassifier()
    input_fn_train = build_training_input_fn(file_pattern=train_directory, train=True)
    classifier.train(input_fn=input_fn_train)
&lt;/denchmark-code&gt;

Describe the expected behavior
The model should consume the dataset provided by the train_input_fn and build trees.
Code to reproduce the issue
Unfortunately, I'm unable to share this.
Other info / logs
When training on CloudML, the error is: The replica master 0 exited with a non-zero status of 11(SIGSEGV).
Locally, I get:
&lt;denchmark-code&gt;WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
python(71585,0x700009986000) malloc: *** error for object 0x7fe0d6f99e00: incorrect checksum for freed object - object was probably modified after being freed.
*** set a breakpoint in malloc_error_break to debug
&lt;/denchmark-code&gt;

As a side note, if I simply yield the data using the snippet below, I get the OutOfRangeError error as expected.
&lt;denchmark-code&gt;    dataset = input_fn_eval()
    next_val = dataset.make_one_shot_iterator().get_next()
    with tf.Session() as sess:
        while True:
            try:
                x, y = sess.run(next_val)
                print(x)
                sleep(0)
                # predictions = classifier.predict(input_fn=(x, y))
                # print([i for i in predictions])
            except tf.errors.OutOfRangeError as e:
                print(e)
                print('Expected Behaiviour')
                break
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='skiler07' date='2019-03-01T21:32:10Z'>
		&lt;denchmark-link:https://github.com/skiler07&gt;@skiler07&lt;/denchmark-link&gt;
 Could you create a simple code (not your proprietary) to reproduce the bug? Also provide fill trace of error log. Thanks!
		</comment>
		<comment id='2' author='skiler07' date='2019-03-04T11:46:18Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I shall spend some time to make it reproducible. With regards to the error logs, there are no logs. I get C level errors with no trace.
		</comment>
		<comment id='3' author='skiler07' date='2019-03-20T20:56:20Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!
		</comment>
		<comment id='4' author='skiler07' date='2019-03-20T20:56:21Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26262&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26262&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>