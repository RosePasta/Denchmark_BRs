<bug id='38167' author='mfouesneau' open_date='2020-04-02T15:05:01Z' closed_time='2020-04-24T07:08:07Z'>
	<summary>make_csv_dataset ValueError: Received a feature column from TensorFlow v1</summary>
	<description>
System information

OS Platform and Distribution: Mac Os 10.14.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:
TensorFlow installed from (source or
binary): pip install
TensorFlow version (use command below):  2.1.0 (v2.1.0-rc2-17-ge5bf8de410 2.1.0)
Python version: 3.6

Describe the current behavior
When trying to train a DNNRegressor using a dataset from make_csv_dataset, I obtain a very strange error message:
ValueError: Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.
Describe the expected behavior
I was expecting that this would work directly.
Standalone code to reproduce the issue
def train_input_fn():
    df = tf.data.experimental.make_csv_dataset(
        file_pattern, batch_size, column_names=None, column_defaults=None,
        label_name=label_name[0], select_columns=column_names, field_delim=',',
        use_quote_delim=True,
        na_value='', header=True, num_epochs=None, shuffle=True,
        shuffle_buffer_size=10000, shuffle_seed=None,
        prefetch_buffer_size=None,
        num_parallel_reads=None, sloppy=False,
        num_rows_for_inference=100,
        compression_type=None, ignore_errors=False
        )
    df_batches = (
        df.cache().repeat().shuffle(500)
        .prefetch(tf.data.experimental.AUTOTUNE))
    return df_batches

tf.keras.backend.set_floatx('float32')

nfeat = len(feature_names)
ncovs = nfeat * (nfeat + 1) // 2
model = tf.estimator.DNNRegressor([ncovs, ],
                                  # feature_names,
                                  # activation_fn = tf.nn.relu,
                                  dropout=0.3,
                                  optimizer="Adam",
                                  weight_column='weights'
                                  )

history = model.train(train_input_fn, steps=40000)
I do not understand how to make this work honestly. I cannot find a end-to-end minimal example that uses a CSV input data file that is too large to fit in memory.
	</description>
	<comments>
		<comment id='1' author='mfouesneau' date='2020-04-03T06:20:49Z'>
		&lt;denchmark-link:https://github.com/mfouesneau&gt;@mfouesneau&lt;/denchmark-link&gt;
,
In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also a sample of the csv file you are using. Thanks!
		</comment>
		<comment id='2' author='mfouesneau' date='2020-04-09T11:42:35Z'>
		I believe one key is to use
feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]
instead of a list of strings here.
Here is the code
'''
Trying to train DNN regressor with batch mode
'''
import tensorflow as tf
import tf_csv_dataset as tfcsv

# Which file
file_pattern = 'make_models/models_20190510.csv'
# batch size for reading
batch_size = 100_000

# Load the interface to the data.
ds = tfcsv.make_csv_dataset(
    file_pattern, batch_size, column_names=None, column_defaults=None,
    label_name=None, select_columns=None, field_delim=',',
    use_quote_delim=True,
    na_value='', header=True, num_epochs=None, shuffle=True,
    shuffle_buffer_size=10000, shuffle_seed=None,
    prefetch_buffer_size=None,
    num_parallel_reads=None, sloppy=False,
    num_rows_for_inference=100,
    compression_type=None, ignore_errors=False
    )


def show_batch(dataset):
    """ Show the batch content """
    for batch in dataset.take(1):
        try:
            keys = []
            values = []
            for key, value in batch.items():
                print("{:20s}: {}".format(key, value.numpy()))
                keys.append(key)
                values.append(value)
            return dict(zip(keys, values))

        except AttributeError:
            keys = []
            values = []
            features, labels = batch
            for key, value in features.items():
                print("{:20s}: {}".format(key, value.numpy()))
                keys.append(key)
                values.append(value)
            print("{:20s}: {}".format("labels", labels))
            return dict(zip(keys, values)), labels


column_names = [key for key in [batch.items() for batch in ds.take(1)]]
column_names = [k[0] for k in column_names[0] if k[0] != '']


feature_names = 'logL logT logg Z A0 R0'.split()
label_name = [k for k in column_names if k not in feature_names]

print("Features: {}".format(feature_names))
print("Label: {}".format(label_name))


# Load the interface to the data.
ds = tfcsv.make_csv_dataset(
    file_pattern, batch_size, column_names=None, column_defaults=None,
    label_name=label_name, select_columns=column_names, field_delim=',',
    use_quote_delim=True,
    na_value='', header=True, num_epochs=None, shuffle=True,
    shuffle_buffer_size=10000, shuffle_seed=None,
    prefetch_buffer_size=None,
    num_parallel_reads=None, sloppy=False,
    num_rows_for_inference=100,
    compression_type=None, ignore_errors=False
    )


def pack(features, label):
    return tf.stack(list(features.values()), axis=-1), label


def train_input_fn():
    df = tfcsv.make_csv_dataset(
        file_pattern, batch_size,
        label_name=label_name,
        select_columns=column_names, field_delim=',',
        use_quote_delim=True,
        )
    df_batches = (
        df.cache().prefetch(tf.data.experimental.AUTOTUNE))
    return df_batches


tf.keras.backend.set_floatx('float32')

feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]
nfeat = len(feature_names)
ncovs = nfeat * (nfeat + 1) // 2
model = tf.estimator.DNNRegressor([ncovs, ],
                                  feature_columns,
                                  # activation_fn = tf.nn.relu,
                                  dropout=0.3,
                                  optimizer="Adam",
                                  )
history = model.train(train_input_fn, steps=40000)
		</comment>
		<comment id='3' author='mfouesneau' date='2020-04-09T11:45:32Z'>
		Just to be clearer, my goal is to train a DNN regressor with multidimensional labels in batch mode to be able to handle large training sets.
Maybe my approach is not the most adapted, but I cannot find an example with batch training with csv datasets. I have a different approach if my training set is small and fits in memory.
		</comment>
		<comment id='4' author='mfouesneau' date='2020-04-09T18:26:01Z'>
		&lt;denchmark-link:https://github.com/mfouesneau&gt;@mfouesneau&lt;/denchmark-link&gt;
,
Could you please share the  file you are using in the code. I was unable to reproduce the issue reported here due to the missing files. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a99616465c7f7d967fe4b5b85b978fb6/38167.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='5' author='mfouesneau' date='2020-04-16T17:31:24Z'>
		
@mfouesneau,
Could you please share the models_20190510.csv file you are using in the code. I was unable to reproduce the issue reported here due to the missing files. Please find the gist of it here. Thanks!

Any updates regarding this? Thanks!
		</comment>
		<comment id='6' author='mfouesneau' date='2020-04-24T07:08:07Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='7' author='mfouesneau' date='2020-04-24T07:08:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38167&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38167&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>