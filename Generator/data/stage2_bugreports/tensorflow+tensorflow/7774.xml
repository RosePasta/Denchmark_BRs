<bug id='7774' author='jetW' open_date='2017-02-22T11:50:21Z' closed_time='2017-05-16T02:01:48Z'>
	<summary>after type 'run' in tensorflow debugger, the terminal reappears and stucks</summary>
	<description>
My program can run and show some traing results, but for a classification question, the accuracies of training set and validation set both keep at around 0.5 for 40 epoches.
So I want to use tensorflow debugger to watch what the variables are.
When I type 'run' and push enter, it jump out of the debugger and the terminal reshows, then the terminal screen stuck at below.
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.835
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.28GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
the nvidia-smi results is below:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 0000:01:00.0      On |                  N/A |
|  0%   43C    P2    53W / 200W |   1857MiB /  8105MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      1011    G   /usr/lib/xorg/Xorg                             300MiB |
|    0      1802    G   compiz                                         133MiB |
|    0      3362    G   .../Enabled/MarkNonSecureAs/show-non-secure-    99MiB |
|    0     14422    C   python                                        1321MiB |
+-----------------------------------------------------------------------------+
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

any suggestion for solve the problem?
	</description>
	<comments>
		<comment id='1' author='jetW' date='2017-02-22T20:47:50Z'>
		&lt;denchmark-link:https://github.com/jetW&gt;@jetW&lt;/denchmark-link&gt;
 Does your graph contain any tf.while loops? If so, it may get stuck because of a bug in tfdbg in version 1.0.0 that causes the debugger to freeze on certain while loops. This bug has been fixed in master/HEAD. Maybe you can try our &lt;denchmark-link:https://github.com/tensorflow/tensorflow/#installation&gt;nightly builds&lt;/denchmark-link&gt;
, or wait for the next release for the fix.
		</comment>
		<comment id='2' author='jetW' date='2017-02-23T11:29:33Z'>
		The graph does not have tf.while. I may wait for the next release. Thank you!
		</comment>
		<comment id='3' author='jetW' date='2017-03-13T22:08:51Z'>
		Has the tf.while loop freeze in tfdbg been fixed in any new builds?
		</comment>
		<comment id='4' author='jetW' date='2017-04-24T19:54:42Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 Has this problem been resolved?
I'm having a similar problem when using tfdbg. My network is returning nan after 1 optimization step, so I'm trying to resolve what's going on. My problem is same as above: "when I type 'run' and push enter, it jump out of the debugger and the terminal reshows, then the terminal screen stuck at below." There are no errors or warnings of any kind. Also, if I use the invoke_stepper, it freezes during some while steps indefinitely (or at least several hours until I cut it off). In particular, it freezes on steps that look like bilstm1/bilstm1/bidirectional_rnn_1/fw/fw/while/layer_norm_basic_lstm_cell/state_1/batchnorm/sub/Enter
I definitely have while loops from tf.nn.bidirectional_dynamic_rnn and tf.map_fn, but I set parallel_iterations=1 for all of those calls. I read as well that there are some bugs with while loops on gpu's, so I have tried running all ops with tf.device("/cpu:0"): as well with the same results.
Any ideas I can try to get tfdbg to work in this situation?
I am using the nightly build of tensorflow_gpu-1.1.0rc2-cp35-cp35m-win_amd64.whl (Build &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/149&gt;#149&lt;/denchmark-link&gt;
 (Apr 19, 2017 2:25:00 AM) which is the last stable build)
		</comment>
		<comment id='5' author='jetW' date='2017-04-24T20:34:54Z'>
		There have been a few bug fixes for tfdbg related to while loops in the past several weeks. &lt;denchmark-link:https://github.com/fredtony&gt;@fredtony&lt;/denchmark-link&gt;
 , can you please let me know what version of TensorFlow you are using?
		</comment>
		<comment id='6' author='jetW' date='2017-04-25T15:10:25Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 I a using 1.1.0-rc2. I have the nightly build (Build &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/149&gt;#149&lt;/denchmark-link&gt;
 (Apr 19, 2017 2:25:00 AM) which is the last stable build). Revision &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/ed6bb758dabc612234e9afd38bdaeb1b84e09955&gt;ed6bb75&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='jetW' date='2017-04-25T15:25:22Z'>
		&lt;denchmark-link:https://github.com/fredtony&gt;@fredtony&lt;/denchmark-link&gt;
 Thanks for the info. I was under the impression that this PR (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/99559a3455d7c3b3663968a55bf56801743201d0&gt;99559a3&lt;/denchmark-link&gt;
) should have resolve a previous problem related to tf.while_loop. This commit is in both the master and r1.1 branches. But there might be other corner cases not covered here.
Can you provide some sample code (and some fake data) to reproduce the issue?
		</comment>
	</comments>
</bug>