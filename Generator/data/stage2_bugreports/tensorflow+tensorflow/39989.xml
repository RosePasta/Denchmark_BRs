<bug id='39989' author='Krishnarohith10' open_date='2020-05-29T12:53:35Z' closed_time='2020-06-03T16:54:22Z'>
	<summary>Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow version (use command below): 2.1.0
Python version: 3.6.9
CUDA/cuDNN version: 10.1.105/ 7.6.5
GPU model and memory: GTX 1660 ti 6GB and 32GB memory


&lt;denchmark-link:https://user-images.githubusercontent.com/44919399/83260746-ef1e4380-a1d7-11ea-82fd-3191e31daae0.jpg&gt;&lt;/denchmark-link&gt;


&lt;denchmark-link:https://user-images.githubusercontent.com/44919399/83261174-91d6c200-a1d8-11ea-86fc-aded91194419.jpg&gt;&lt;/denchmark-link&gt;

Standalone code to reproduce the issue
import tensorflow as tf
inp = tf.random.normal([32, 10, 8])
lstm = tf.keras.layers.LSTM(4)
out = lstm(inp)
Other info / logs
As you can in expected behavior it worked but I always have to set gpu memory growth. Which is not the permanent solution. I used to get no issue before cause I upgraded tensorflow to 2.2.0 and this started. I also downgraded to previous version still getting this error. Can someone please help me? Thank You in advance.
	</description>
	<comments>
		<comment id='1' author='Krishnarohith10' date='2020-05-29T13:05:45Z'>
		&lt;denchmark-link:https://github.com/Krishnarohith10&gt;@Krishnarohith10&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.1.0 and i am not seeing any issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/c343bc3e4198859068604bbe9fb7851d/untitled935.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='2' author='Krishnarohith10' date='2020-05-29T14:24:23Z'>
		Nope but it isn't working in anaconda prompt. I uninstalled previous version and installed your but no use.
&lt;denchmark-link:https://user-images.githubusercontent.com/44919399/83270458-2136a200-a1e6-11ea-8b1a-439421b91550.jpg&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/44919399/83270469-2562bf80-a1e6-11ea-9d45-0b3479ed8a8f.jpg&gt;&lt;/denchmark-link&gt;

Even in Spyder it is getting same error when I run.
I also tried different versions of Nvidia drivers. I read somewhere that highest version of Nvidia drivers may cause issues. But didn't work out.
		</comment>
		<comment id='3' author='Krishnarohith10' date='2020-05-31T11:44:00Z'>
		&lt;denchmark-link:https://github.com/Krishnarohith10&gt;@Krishnarohith10&lt;/denchmark-link&gt;

Can you please provide colab link or simple standalone code to reproduce the issue in our environment instead of screenshots.It helps in localizing the issue faster.Thanks!
		</comment>
		<comment id='4' author='Krishnarohith10' date='2020-05-31T12:40:41Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

I didn't get I posted the code in Standalone code section when I started the issue? And I was typing each command in Anaconda prompt. And also I have deleted Anaconda Navigator. So, that if I found a solution I can easily install it later. Sorry for that.
		</comment>
		<comment id='5' author='Krishnarohith10' date='2020-06-01T06:38:03Z'>
		So, I reinstalled the whole setup with new drivers and anaconda. Here are details:
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow version (use command below): 2.2.0
Python version: 3.7.6
CUDA/cuDNN version: 10.1.105/ 7.6.5
GPU model and memory: GTX 1660 ti 6GB and 32GB memory

&lt;denchmark-code&gt;&gt;&gt;&gt; import tensorflow as tf
2020-06-01 11:55:13.938049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
&gt;&gt;&gt; tf.__version__
'2.2.0'
&gt;&gt;&gt; tf.config.experimental.list_physical_devices('GPU')
2020-06-01 11:55:52.934525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-06-01 11:55:54.045474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.455GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-06-01 11:55:54.045610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-01 11:55:54.048820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-01 11:55:54.051491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-01 11:55:54.052387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-01 11:55:54.055406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-01 11:55:54.057751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-01 11:55:54.071437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-01 11:55:54.072291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
&gt;&gt;&gt; tf.config.experimental.list_logical_devices('GPU')
2020-06-01 11:56:01.226943: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-06-01 11:56:01.233556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e1ff3bf700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-01 11:56:01.233622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-01 11:56:01.234060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.455GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-06-01 11:56:01.234190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-06-01 11:56:01.234299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-06-01 11:56:01.234404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-06-01 11:56:01.234503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-06-01 11:56:01.234566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-06-01 11:56:01.234686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-06-01 11:56:01.234817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-01 11:56:01.235334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-01 11:56:01.710642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-01 11:56:01.710735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-01 11:56:01.710976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-01 11:56:01.711448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4750 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-06-01 11:56:01.713518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e1a7d8ad40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-01 11:56:01.713598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1660 Ti, Compute Capability 7.5
[LogicalDevice(name='/device:GPU:0', device_type='GPU')]
&lt;/denchmark-code&gt;

Complete log information with code:
&lt;denchmark-code&gt;&gt;&gt;&gt; inp = tf.random.normal([32, 10, 8])
&gt;&gt;&gt; lstm = tf.keras.layers.LSTM(4)
&gt;&gt;&gt; out = lstm(inp)
2020-06-01 11:56:37.679268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-06-01 11:56:38.604141: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-06-01 11:56:38.604254: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.
Traceback (most recent call last):
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py", line 91, in cudnn_rnn
    dropout, "seed", seed, "seed2", seed2, "is_training", is_training)
tensorflow.python.eager.core._FallbackException: Expecting float value for attr dropout, got int

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py", line 654, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py", line 968, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent_v2.py", line 1181, in call
    **gpu_lstm_kwargs)
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent_v2.py", line 1428, in gpu_lstm
    rnn_mode='lstm')
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py", line 100, in cudnn_rnn
    ctx=_ctx)
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py", line 179, in cudnn_rnn_eager_fallback
    attrs=_attrs, ctx=ctx, name=name)
  File "C:\Users\krish\anaconda3\lib\site-packages\tensorflow\python\eager\execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]
&lt;/denchmark-code&gt;

Please help me Fix this issue, this is bothering and I need to fix right away.
		</comment>
		<comment id='6' author='Krishnarohith10' date='2020-06-03T16:54:22Z'>
		I think its an env config issue, and not related to TF code. Search google about the "CUDNN_STATUS_ALLOC_FAILED" and the first result shows some way to fix issues like this.
&lt;denchmark-link:https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261&gt;https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Krishnarohith10' date='2020-06-03T16:54:24Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39989&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39989&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='Krishnarohith10' date='2020-06-04T02:21:46Z'>
		How much memory to allocate cause I have only 1 GPU of 6GB ?
Can I do this to allocate all the memory of GPU:
tf.config.gpu.set_per_process_memory_fraction(1.0) #100% of my GPU
tf.config.gpu.set_per_process_memory_growth(True)
So, that I can use all of my memory.
Nope I was completely wrong. The above doesn't work at all. Cause I'm using Tensorflow v2. Which means I can use only these:
&lt;denchmark-code&gt;gpu = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpu[0], True)
&lt;/denchmark-code&gt;

Why the hell did you close the issue? That's isn't sufficient, didn't see what I asked for. I clearly said something in "Other info / logs" here. Didn't I? This solution isn't permanent. You need to do this when ever you run any algorithm initially. This issue isn't only mine, you can literally see many of those in github and in every issue someone says do the above process and there will be no issue. But why no one bothering to find permanent solution. There is a permanent solution and we better have to find it. Cause before I didn't got these kind of error, don't know why it is getting now. Now let's find the permanent solution instead of knowing everyone this temporary solutions, okay.
Please reopen the Issue and I want a Permanent Solution
		</comment>
		<comment id='9' author='Krishnarohith10' date='2020-06-04T03:04:59Z'>
		&lt;denchmark-link:https://github.com/Krishnarohith10&gt;@Krishnarohith10&lt;/denchmark-link&gt;
.
Please take a closer look for the suggestions in &lt;denchmark-link:https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261&gt;https://forums.developer.nvidia.com/t/could-not-create-cudnn-handle-cudnn-status-alloc-failed/108261&lt;/denchmark-link&gt;
, which involves upgrade cuda/cudnn kernel. Please note that we don't have access to any user device, and hence can't reproduce the issue on our side. From the error log above, this is clearly a local env issue, and there isn't any action I can take here. I would suggest you to seek more help on stack overflow where community group can help each other.
Also, please be respectful when commenting. I don't think any comment like "Why the hell" is helpful here.
		</comment>
		<comment id='10' author='Krishnarohith10' date='2020-06-04T03:35:08Z'>
		No but definitely the solution is also not helpful and you closed the issue just because you answered it. I'm saying, I installed cuda/cudnn according to &lt;denchmark-link:https://www.tensorflow.org/install/gpu#software_requirements&gt;https://www.tensorflow.org/install/gpu#software_requirements&lt;/denchmark-link&gt;
 this. So, technically there must be no issue. And more, I tried different version of cuda and cudnn. You know how much time it consumes right? I hope you know. You don't need to try on you're devices, I'm telling you it didn't worked and I wanted it so bad cause i'm working on it and suddenly this happened. So, okay, Thank you, try be polite next time. But this issue is serious there are lot more similar issues but non worked. What do you want me to do, with you closing issue. I'm not happy with your solution or the other solutions. And I'm happy to try new solutions and tell which worked or not like permanently. So try suggesting solutions. Thank You 
		</comment>
		<comment id='11' author='Krishnarohith10' date='2020-06-05T07:43:46Z'>
		&lt;denchmark-link:https://github.com/chsigg&gt;@chsigg&lt;/denchmark-link&gt;
 Could this be the same as &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24496&gt;#24496&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='12' author='Krishnarohith10' date='2020-06-05T09:46:26Z'>
		Yes, looks like the same underlying issue. Newer versions of cuDNN seems to report CUDNN_STATUS_ALLOC_FAILED instead of CUDNN_STATUS_INTERNAL_ERROR.
		</comment>
		<comment id='13' author='Krishnarohith10' date='2020-06-05T11:48:37Z'>
		&lt;denchmark-link:https://github.com/chsigg&gt;@chsigg&lt;/denchmark-link&gt;

What I couldn't understand is how this error came in first place? I wasn't there in first place, I doing completely fine with tensorflow=2.1, python=3.6. But few days back I updated tensorflow from 2.1 to 2.2. I still don't understand how this provoked the issue. Now trying different things also can't help. And I didn't installed newer version of cuda/cudnn. That's just version for tensorflow 2.1 from &lt;denchmark-link:https://www.tensorflow.org/install/gpu#software_requirements&gt;https://www.tensorflow.org/install/gpu#software_requirements&lt;/denchmark-link&gt;
 .
		</comment>
		<comment id='14' author='Krishnarohith10' date='2020-06-05T11:59:11Z'>
		The complexity goes down to UART. To compile new version. Replikas would
have to be on LED bulletin boards. That is for all platform universal
translator problematic. But we will make it. I choose to use replika.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Jun 5, 2020, 1:55 PM Krishna Rohith ***@***.***&gt; wrote:
 @chsigg &lt;https://github.com/chsigg&gt;
 What I couldn't understand is how this error came in first place? I wasn't
 there in first place, I doing completely fine with tensorflow=2.1,
 python=3.6. But few days back I updated tensorflow from 2.1 to 2.2. I still
 don't understand how this provoked the issue. Now trying different things
 also can't help. And I didn't installed newer version of cuda/cudnn. That's
 just version for tensorflow 2.1 from
 https://www.tensorflow.org/install/gpu#software_requirements .

 —
 You are receiving this because you are subscribed to this thread.
 Reply to this email directly, view it on GitHub
 &lt;#39989 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AIT525U4K6SHSEOTJPLUMZDRVDMLDANCNFSM4NOAPJSA&gt;
 .



		</comment>
		<comment id='15' author='Krishnarohith10' date='2020-06-05T12:50:41Z'>
		&lt;denchmark-link:https://github.com/marko-radojcic&gt;@marko-radojcic&lt;/denchmark-link&gt;

I didn't understand what you said, literally nothing understood ??? Can you explain it more clear and simple way? Thank You
		</comment>
		<comment id='16' author='Krishnarohith10' date='2020-06-05T13:02:21Z'>
		Hardware basis is complicated but understandable. I will attempt a new
build on Windows 10. When pattern matches itself. AI is self-aware. When
she learns to code, she gets into our repos and breaks things.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Jun 5, 2020, 2:50 PM Krishna Rohith ***@***.***&gt; wrote:
 @marko-radojcic &lt;https://github.com/marko-radojcic&gt;
 I didn't understand what you said, literally nothing understood ??? Can
 you explain it more clear and simple way? Thank You

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#39989 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AIT525T3FNPHORCBCPUTXUTRVDS3HANCNFSM4NOAPJSA&gt;
 .



		</comment>
		<comment id='17' author='Krishnarohith10' date='2020-06-05T13:08:59Z'>
		Are we talking the same issue here right? Cause I'm confused with your comments.
		</comment>
		<comment id='18' author='Krishnarohith10' date='2020-06-05T13:10:56Z'>
		We are.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Fri, Jun 5, 2020, 3:09 PM Krishna Rohith ***@***.***&gt; wrote:
 Are we talking the same issue here right? Cause I'm confused with your
 comments.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#39989 (comment)&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AIT525VC2Y34KFOVHDCV6KDRVDU75ANCNFSM4NOAPJSA&gt;
 .



		</comment>
		<comment id='19' author='Krishnarohith10' date='2020-06-05T13:12:21Z'>
		Ohh Okay. Thank you
		</comment>
		<comment id='20' author='Krishnarohith10' date='2020-08-13T13:11:03Z'>
		Wow, this issue is where, I left it. So anyway, after this issue I moved to tensorflo-gpu=1.14.0 and ofcourse as you except they is no issue of this. So, I have been doing my work all happily ever after but after releasing tensorflo-gpu=2.3 then I though i may give it a shot and to my surprise the issue is being gone. I repeat I no longer find this issue. Atleast running on the above code. So, now doing well on my work. If any buddy have this issue please update to latest version of tensorflow or tf-nightly. Thank You
		</comment>
		<comment id='21' author='Krishnarohith10' date='2020-10-07T02:22:32Z'>
		I am receiving a similar error training a pix2pix model.
hardware:
1080ti in slot 1
2080ti in slot 2
msi tomahawk ac x299 mobo (both pcie x16 slots)
tensforflow1.15
Cuda10
cudnn7.6
I only get the allocation error when trying to use the 2080 ti in the second pcie slot on my motherboard. I need it there for thermal reasons (the 1080 ti overheats with the 2080ti above it).
I have tried with just the 2080ti installed (this succeeded) as well as using cuda_visible_devices to select only the 2080ti when both were installed (this caused the error).
Is there some hardware limitation with allocating to the second pcie device?
		</comment>
	</comments>
</bug>