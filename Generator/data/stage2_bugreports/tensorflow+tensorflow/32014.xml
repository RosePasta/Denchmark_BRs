<bug id='32014' author='zhen8838' open_date='2019-08-27T15:55:55Z' closed_time='2020-08-27T06:25:47Z'>
	<summary>TF 1.14 : assgin Variable in loss function can't update value ?</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution: Linux Ubuntu 18.04
TensorFlow installed from : binary
TensorFlow version :  tensorflow-gpu 1.14.0
Python version: python 3.7.1
CUDA/cuDNN version: CUDA 10.1 cuDNN 7.5
GPU model and memory: GTX 2060 6G

Question
I customize the loss function in tf. keras and use a variable to output part of the loss to metric. What puzzles me is that in normal custom metrics, direct assgin variables give the correct output, but in loss functions, I have to call the assgin operator to get the normal output.
Describe the current behavior
now code :
import tensorflow as tf
import tensorflow.keras as k
import tensorflow.keras.layers as kl
import tensorflow.keras.metrics as km
from tensorflow.keras.datasets import fashion_mnist

tfcfg = tf.ConfigProto()
tfcfg.gpu_options.allow_growth = True
sess = tf.Session(config=tfcfg)
k.backend.set_session(sess)

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))
y_train = k.utils.to_categorical(y_train, 10)
y_test = k.utils.to_categorical(y_test, 10)


model = k.Sequential([
    kl.Conv2D(32, 3, 1, input_shape=[28, 28, 1]),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Conv2D(64, 3, 1),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Conv2D(128, 3, 1),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.LeakyReLU(),
    kl.Flatten(),
    kl.Dense(512),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Dense(10)
])


class Metric_HIGH_COST(km.Metric):
    def __init__(self, name=None, dtype=None, **kwargs):
        super().__init__(name=name, dtype=dtype, **kwargs)
        self.ce = self.add_weight('ce', initializer=tf.zeros_initializer)

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.ce.assign(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)))

    def result(self):
        return self.ce


class Metric_LOW_COST(km.Metric):
    def __init__(self, cross_entropy: tf.Variable, name='CE', dtype=None):
        """ yolo landmark error metric

        Parameters
        ----------
        MeanMetricWrapper : [type]

        landmark_error : ResourceVariable
            a variable from yoloalign loss
        name : str, optional
            by default 'LE'
        dtype : [type], optional
            by default None
        """
        super().__init__(name=name)
        self.ce = cross_entropy

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.ce

    def result(self):
        return self.ce.read_value()


class Myloss(k.losses.Loss):
    def __init__(self, name=None):
        super().__init__(name=name)
        self.ce = tf.get_variable('ce', (), tf.float32, tf.zeros_initializer)  # type:tf.RefVariable

    def call(self, y_true, y_pred):
        ce_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))

        # ! method 1 got zero output :
        self.ce.assign(ce_loss)
        return ce_loss

        # ! method 2 get correct output :
        # return ce_loss + 0 * self.ce.assign(ce_loss)


myloss = Myloss()
high_cost_metric = Metric_HIGH_COST('high_cost_ce')
low_cost_metric = Metric_LOW_COST(myloss.ce, 'low_cost_ce')

sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

model.compile(k.optimizers.Adam(), [myloss], [high_cost_metric, low_cost_metric])

model.fit(x_train, y_train, 100, 10)
output low_cost_ce  always 0:
11700/60000 [====&gt;.........................] - ETA: 24s - loss: 175.2779 - high_cost_ce: 67.9055 - low_cost_ce: 0.0000e+00
Describe the expected behavior
new code:
import tensorflow as tf
import tensorflow.keras as k
import tensorflow.keras.layers as kl
import tensorflow.keras.metrics as km
from tensorflow.keras.datasets import fashion_mnist

tfcfg = tf.ConfigProto()
tfcfg.gpu_options.allow_growth = True
sess = tf.Session(config=tfcfg)
k.backend.set_session(sess)

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))
y_train = k.utils.to_categorical(y_train, 10)
y_test = k.utils.to_categorical(y_test, 10)


model = k.Sequential([
    kl.Conv2D(32, 3, 1, input_shape=[28, 28, 1]),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Conv2D(64, 3, 1),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Conv2D(128, 3, 1),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.LeakyReLU(),
    kl.Flatten(),
    kl.Dense(512),
    kl.BatchNormalization(),
    kl.LeakyReLU(),
    kl.Dense(10)
])


class Metric_HIGH_COST(km.Metric):
    def __init__(self, name=None, dtype=None, **kwargs):
        super().__init__(name=name, dtype=dtype, **kwargs)
        self.ce = self.add_weight('ce', initializer=tf.zeros_initializer)

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.ce.assign(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)))

    def result(self):
        return self.ce


class Metric_LOW_COST(km.Metric):
    def __init__(self, cross_entropy: tf.Variable, name='CE', dtype=None):
        """ yolo landmark error metric

        Parameters
        ----------
        MeanMetricWrapper : [type]

        landmark_error : ResourceVariable
            a variable from yoloalign loss
        name : str, optional
            by default 'LE'
        dtype : [type], optional
            by default None
        """
        super().__init__(name=name)
        self.ce = cross_entropy

    def update_state(self, y_true, y_pred, sample_weight=None):
        self.ce

    def result(self):
        return self.ce.read_value()


class Myloss(k.losses.Loss):
    def __init__(self, name=None):
        super().__init__(name=name)
        self.ce = tf.get_variable('ce', (), tf.float32, tf.zeros_initializer)  # type:tf.RefVariable

    def call(self, y_true, y_pred):
        ce_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))

        # ! method 1 got zero output :
        # self.ce.assign(ce_loss)
        # return ce_loss

        # ! method 2 get correct output :
        return ce_loss + 0 * self.ce.assign(ce_loss)


myloss = Myloss()
high_cost_metric = Metric_HIGH_COST('high_cost_ce')
low_cost_metric = Metric_LOW_COST(myloss.ce, 'low_cost_ce')

sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])

model.compile(k.optimizers.Adam(), [myloss], [high_cost_metric, low_cost_metric])

model.fit(x_train, y_train, 100, 10)
11500/60000 [====&gt;.........................] - ETA: 24s - loss: 172.6385 - high_cost_ce: 85.5574 - low_cost_ce: 171.8945     
&lt;denchmark-h:h4&gt;Why do you have to call the assgin operator in the loss function to update variables?Is this a bug?&lt;/denchmark-h&gt;

	</description>
	<comments>
		<comment id='1' author='zhen8838' date='2019-08-28T09:42:06Z'>
		&lt;denchmark-link:https://github.com/zhen8838&gt;@zhen8838&lt;/denchmark-link&gt;
, Will it be possible to provide the code without importing tensorflow.python. Applicable to all imports.   When i tried replicating the issue i received the following error

Thanks!
		</comment>
		<comment id='2' author='zhen8838' date='2019-08-28T09:57:09Z'>
		
@zhen8838, Will it be possible to provide the code without importing tensorflow.python. Applicable to all imports. When i tried replicating the issue i received the following error
AttributeError: module 'tensorflow' has no attribute 'python'
Thanks!

Sorry , I have update the code. now you can run above code in tf1.14
		</comment>
		<comment id='3' author='zhen8838' date='2019-08-28T10:03:29Z'>
		I don't know why. In my computer can use import tensorflow.python as tf, but in some people's computers got error AttributeError: module 'tensorflow' has no attribute 'python'. I'm very sorry that this problem has wasted your time.
		</comment>
		<comment id='4' author='zhen8838' date='2019-08-28T10:18:17Z'>
		&lt;denchmark-link:https://github.com/zhen8838&gt;@zhen8838&lt;/denchmark-link&gt;
, Thanks for updating the code.
&lt;denchmark-code&gt;import tensorflow.python.keras as k
import tensorflow.python.keras.layers as kl
from tensorflow.python.keras.utils import losses_utils
import tensorflow.python.keras.metrics as km
from tensorflow.python.keras.datasets import fashion_mnist
&lt;/denchmark-code&gt;

Could you please change these imports also.
Thanks!
		</comment>
		<comment id='5' author='zhen8838' date='2019-08-28T10:38:47Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 The code has been updated. Please let me know if you have any questions.
		</comment>
		<comment id='6' author='zhen8838' date='2019-08-28T11:36:48Z'>
		&lt;denchmark-link:https://github.com/zhen8838&gt;@zhen8838&lt;/denchmark-link&gt;
, Thanks for your update. I could replicate the reported issue. Please take a look at colab gist of &lt;denchmark-link:https://colab.research.google.com/drive/1BaY8cvaNbX02jWeVyVZY22ITxld_Js4c&gt;current behavior&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://colab.research.google.com/drive/12MdBxthmu7Urnd8UUuYheXvYXYNnh_EF&gt;expected behavior&lt;/denchmark-link&gt;
.
Thanks!
		</comment>
		<comment id='7' author='zhen8838' date='2020-08-13T04:53:17Z'>
		&lt;denchmark-link:https://github.com/zhen8838&gt;@zhen8838&lt;/denchmark-link&gt;
 I think parts of the code need to be updated. Can you please check this &lt;denchmark-link:https://www.tensorflow.org/guide/keras/train_and_evaluate&gt;guide&lt;/denchmark-link&gt;
 and update custom metric and custom loss.
Please feel free to close the issue if this was already resolved for you. Thanks!
		</comment>
		<comment id='8' author='zhen8838' date='2020-08-20T05:27:36Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='9' author='zhen8838' date='2020-08-27T06:25:44Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='10' author='zhen8838' date='2020-08-27T06:25:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32014&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32014&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>