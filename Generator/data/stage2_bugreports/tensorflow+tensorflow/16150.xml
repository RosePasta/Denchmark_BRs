<bug id='16150' author='iliTheFallen' open_date='2018-01-16T08:30:16Z' closed_time='2018-09-28T21:35:06Z'>
	<summary>Tensorflow Debugger with Multithreading</summary>
	<description>
&lt;denchmark-h:h2&gt;System information&lt;/denchmark-h&gt;


OS Platform: Ubuntu 14.04
TensorFlow installed from source : GPU-Version 1.14 branch
cuDNN: 7.0
Python version: 3.4

--
I'm using tf.Estimator together with numpy_input_fn. Moreover, I set all num_threads to 1. However, tfdbg somehow doesn't get along well with child threads auto-created by new estimator API.
Here is how I defined Estimator:
&lt;denchmark-code&gt;def do_train(tr_data, vl_data):

    # Create Estimator
    sess_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
    sess_conf.gpu_options.allow_growth = True
    config = tf.estimator.RunConfig(model_dir=FLAGS.model_dir,  # CheckpointSaverHook
                                    save_checkpoints_steps=100,  # CheckpointSaverHook
                                    log_step_count_steps=10,  # SummarySaverHook
                                    session_config=sess_conf)
    music_classifier = tf.estimator.Estimator(model_fn,
                                              config=config,
                                              params={'max_seq': tr_data.max_seq})
    # Prepare input data
    tr_input_fn = tf.estimator.inputs.numpy_input_fn(
        {'input_ph': tr_data.data, 'seq_len_ph': tr_data.seq_len},
        batch_size=FLAGS.batch_size,
        num_epochs=FLAGS.num_epochs,
        num_threads=1,
        shuffle=True
    )
    # Extra Hooks
    logging_hook = tf.train.LoggingTensorHook(
        tensors={'probabilities': 'probs_tensor'},
        every_n_iter=10
    )
    debugging_hook = tf_debug.LocalCLIDebugHook(thread_name_filter="MainThread$", dump_root="./dump")
    # Train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
&lt;/denchmark-code&gt;

Although the code runs fine; whenever I run it in debug mode, it fails at executing run command on tfdbg command line. Following is the exception I got:
&lt;denchmark-code&gt;2018-01-16 10:25:26.587936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-01-16 10:25:26.588715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.6705
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.38GiB
2018-01-16 10:25:26.588732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-01-16 10:25:41.373907: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
Traceback (most recent call last):
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1323, in _do_call
    return fn(*args)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1302, in _run_fn
    status, run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=["loc:@rnn/while/TensorArrayReadV3"], _device="/job:localhost/replica:0/task:0/device:CPU:0"](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.4/runpy.py", line 170, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.4/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 202, in &lt;module&gt;
    tf.app.run(main=main)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 191, in main
    do_train(tr_data, vl_data)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 169, in do_train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 521, in run
    run_metadata=run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 892, in run
    run_metadata=run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 967, in run
    raise six.reraise(*original_exc_info)
  File "/usr/local/lib/python3.4/dist-packages/six.py", line 693, in reraise
    raise value
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 952, in run
    return self._sess.run(*args, **kwargs)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 1024, in run
    run_metadata=run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 827, in run
    return self._sess.run(*args, **kwargs)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 889, in run
    run_metadata_ptr)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1317, in _do_run
    options, run_metadata)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/client/session.py", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=["loc:@rnn/while/TensorArrayReadV3"], _device="/job:localhost/replica:0/task:0/device:CPU:0"](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]

Caused by op 'rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3', defined at:
  File "/usr/lib/python3.4/runpy.py", line 170, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.4/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 202, in &lt;module&gt;
    tf.app.run(main=main)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 191, in main
    do_train(tr_data, vl_data)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 169, in do_train
    music_classifier.train(tr_input_fn, hooks=[debugging_hook])
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py", line 711, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/estimator/estimator.py", line 694, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/music_modeling.py", line 116, in model_fn
    initializer=tf.glorot_normal_initializer())  # [BSxMTxOS], [BSxSS]
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py", line 253, in dynamic_msa_rnn
    dtype=tf.float32)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py", line 614, in dynamic_rnn
    dtype=dtype)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py", line 777, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2816, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2640, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2590, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py", line 760, in _time_step
    skip_conditionals=True)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py", line 236, in _rnn_step
    new_output, new_state = call_cell()
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py", line 748, in &lt;lambda&gt;
    call_cell = lambda: cell(input_t, state)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/rnn_cell_impl.py", line 183, in __call__
    return super(RNNCell, self).__call__(inputs, state)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/layers/base.py", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py", line 204, in call
    ms_analyzer = self._extract_features(inputs)
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py", line 151, in _extract_features
    sub_sig = self._gen_sub_sig(inputs)  # BSxTxIN
  File "/home/ilithefallen/Documents/phdStudies/coding/temizelRepo/MultiScaleRNN/model/tf_msa_rnn.py", line 105, in _gen_sub_sig
    self.__ta_signal = self.__ta_signal.write(self.__time, inputs)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/util/tf_should_use.py", line 107, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/tensor_array_ops.py", line 310, in write
    name=name)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/gen_data_flow_ops.py", line 5038, in _tensor_array_write_v3
    flow_in=flow_in, name=name)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 2956, in create_op
    op_def=op_def)
  File "/home/ilithefallen/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): TensorArray ta_signal_0: Tried to write to index 2434 but array is not resizeable and size is: 2434
     [[Node: rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_FLOAT, _class=["loc:@rnn/while/TensorArrayReadV3"], _device="/job:localhost/replica:0/task:0/device:CPU:0"](rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter, rnn/while/rnn/msarnn_cell/Identity/Enter/_259, rnn/while/TensorArrayReadV3, rnn/while/rnn/msarnn_cell/TensorArrayWrite/TensorArrayWriteV3/Enter_1, ^rnn/while/rnn/msarnn_cell/cond/Merge/_263)]]
&lt;/denchmark-code&gt;

Thank you for your support in advance.
	</description>
	<comments>
		<comment id='1' author='iliTheFallen' date='2018-01-16T19:01:37Z'>
		Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code
OS Platform and Distribution
TensorFlow version
Bazel version
CUDA/cuDNN version
GPU model and memory
Exact command to reproduce
		</comment>
		<comment id='2' author='iliTheFallen' date='2018-01-17T06:10:18Z'>
		
OS Platform and Distribution: Ubuntu 14.04 LTE
TensorFlow version: 1.14
Bazel version: 0.9.0
CUDA/cuDNN version: 8.0/7.0.5
GPU model and memory: GeForce GTX1060 - 6070MB
Exact command to reproduce: python3.4 -m music_modeling --debug

Thank you for support again.
		</comment>
		<comment id='3' author='iliTheFallen' date='2018-01-30T23:20:23Z'>
		Thanks for the detailed report!
&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;
 any idea what's going on?
		</comment>
		<comment id='4' author='iliTheFallen' date='2018-08-01T20:43:35Z'>
		Is this still happening with the latest version?
		</comment>
		<comment id='5' author='iliTheFallen' date='2018-08-31T19:29:10Z'>
		It has been 29 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='6' author='iliTheFallen' date='2018-09-15T18:33:33Z'>
		It has been 44 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='7' author='iliTheFallen' date='2018-09-28T21:35:06Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
	</comments>
</bug>