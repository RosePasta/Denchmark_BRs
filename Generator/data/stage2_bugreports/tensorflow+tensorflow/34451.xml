<bug id='34451' author='bersbersbers' open_date='2019-11-20T13:10:20Z' closed_time='2019-12-13T00:28:41Z'>
	<summary>'accuracy' and tf.metrics.get('accuracy') produce different results</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see below
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE
TensorFlow installed from (source or binary): pip binary within pyenv
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: 3.7.5

Describe the current behavior
The same model behaves differently whether one uses 'accuracy' or tf.keras.metrics.get('accuracy') (see below).
Describe the expected behavior
They should behave identically.
Code to reproduce the issue
&lt;denchmark-code&gt;"""Bug."""
# import keras
import numpy as np
import tensorflow.keras as keras

X = np.empty([10, 224, 224, 3])
Y = np.empty([10, 2])

MODEL = keras.applications.vgg16.VGG16(weights=None, classes=2)

MODEL.compile(optimizer=keras.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
MODEL.fit(X, Y, epochs=10)

MODEL.compile(optimizer=keras.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=[keras.metrics.get('accuracy')])
MODEL.fit(X, Y, epochs=10)
&lt;/denchmark-code&gt;

Example output:
&lt;denchmark-code&gt;Train on 10 samples
Epoch 1/10

10/10 [==============================] - 4s 389ms/sample - loss: inf - accuracy: 0.9000
Epoch 2/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 3/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 4/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 5/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 6/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 7/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 8/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 9/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Epoch 10/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.9000
Train on 10 samples
Epoch 1/10

10/10 [==============================] - 1s 131ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 2/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 3/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 4/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 5/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 6/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 7/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 8/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 9/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
Epoch 10/10

10/10 [==============================] - 0s 8ms/sample - loss: nan - accuracy: 0.0000e+00
&lt;/denchmark-code&gt;


Closely related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34088&gt;#34088&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='bersbersbers' date='2019-11-20T19:48:06Z'>
		&lt;denchmark-link:https://github.com/bersbersbers&gt;@bersbersbers&lt;/denchmark-link&gt;
 This has been fixed in the latest version of tf-nightly. Please find my gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/caca35bfc6f28afa2c3744951bd826b1/untitled247.ipynb&gt;here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='bersbersbers' date='2019-11-20T20:13:57Z'>
		I believe this is not fixed. Your gist clearly shows this output, with different accuracy values reported:
&lt;denchmark-code&gt;...
Epoch 10/10
10/10 [==============================] - 19s 2s/sample - loss: 0.0000e+00 - accuracy: 1.0000
Train on 10 samples
Epoch 1/10
10/10 [==============================] - 20s 2s/sample - loss: 0.0000e+00 - accuracy: 0.0000e+00
Epoch 2/10
...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='bersbersbers' date='2019-11-25T13:01:51Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 this has not been fixed, please see my answer above.
		</comment>
		<comment id='4' author='bersbersbers' date='2019-12-02T19:22:28Z'>
		&lt;denchmark-link:https://github.com/bersbersbers&gt;@bersbersbers&lt;/denchmark-link&gt;
 Thank you for the issue. There are 3 metric accuracy functions:

Accuracy: This just checks the equality of y_true and y_pred.
Binary accuracy: This converts y_pred to 0 or 1 based on a threshold and then compares with y_true.
Categorical_accuracy: This checks the equality of class index of the max y_pred with the class index of the max y_true value

When you say keras.metrics.get('accuracy') you get the accuracy function. But if you pass the string accuracy, we infer between binary_accuracy/categorical_accuracy functions based on the shape of the model output.
Please let me know if you have any questions or concerns with this.
Thank you!
		</comment>
		<comment id='5' author='bersbersbers' date='2019-12-03T05:32:38Z'>
		
When you say keras.metrics.get('accuracy') you get the accuracy function. But if you pass the string accuracy, we infer between binary_accuracy/categorical_accuracy functions based on the shape of the model output.
Please let me know if you have any questions or concerns with this.

I believe it cannot be expected from a user to know all this, given that neither the behavior of "accuracy" (why is "accuracy" different from the accuracy() function?) nor that of keras.metrics.get (what is it supposed to be doing?) is documented. From the code, the latter simply calls deserialize(str(identifier)), and I have never before seen a (de)serializer (designed to) modify the behavior of an object.
		</comment>
		<comment id='6' author='bersbersbers' date='2019-12-03T18:41:20Z'>
		I agree that this needs more documentation. get does not have the behavior described above, compile API does. get will just return the deserialized version. Hence, when you give keras.metrics.get('accuracy') it will just return the accuracy function.
		</comment>
		<comment id='7' author='bersbersbers' date='2019-12-13T00:28:41Z'>
		I have updated the compile API docs to address this, will be in the next nightly. Thank you!
		</comment>
		<comment id='8' author='bersbersbers' date='2019-12-13T00:28:44Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34451&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34451&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='bersbersbers' date='2020-06-28T22:06:39Z'>
		wow, this change from "accuracy" to "binary_accuracy" made me think that my model trained in tf 2.1 was performing really poorly in tf 2.2. as i looked closer i realized the performance was the same, but "accuracy" was computed differently. it might have been better to have a warning when using "accuracy" in tf 2.2 saying that the definition will change, then in tf 2.3 actually changing it... or anything else to help introduce the change to folks.
		</comment>
	</comments>
</bug>