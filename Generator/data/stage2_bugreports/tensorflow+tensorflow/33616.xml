<bug id='33616' author='mattc-eostar' open_date='2019-10-22T17:12:36Z' closed_time='2020-08-10T13:21:06Z'>
	<summary>TFLiteConverter StridedSlice Error for Transformer Example Notebook</summary>
	<description>
System information

Linux Ubuntu 18.04.2
Installed from binary
TensorFlow version 2.0.0

Provide the text output from tflite_convert
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
&lt;ipython-input-82-0b556551beac&gt; in &lt;module&gt;()
      3 
      4 converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
----&gt; 5 tflite_model = converter.convert()

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py in convert(self)
    444         input_tensors=input_tensors,
    445         output_tensors=output_tensors,
--&gt; 446         **converter_kwargs)
    447 
    448     if self._is_calibration_quantize():

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    447       input_data.SerializeToString(),
    448       debug_info_str=debug_info_str,
--&gt; 449       enable_mlir_converter=enable_mlir_converter)
    450   return data
    451 

~/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--&gt; 200       raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
2019-10-22 12:59:50.304931: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 915 operators, 1487 arrays (0 quantized)
2019-10-22 12:59:50.337611: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 915 operators, 1487 arrays (0 quantized)
2019-10-22 12:59:50.397450: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size &lt;= num_input_axes (4 vs. 2)StridedSlice op requires no more than 2 start indices
Fatal Python error: Aborted

Current thread 0x00007f2d4bb1e740 (most recent call first):
  File "/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 52 in execute
  File "/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py", line 251 in _run_main
  File "/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/absl/app.py", line 300 in run
  File "/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py", line 40 in run
  File "/home/mattc/anaconda3/envs/main/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py", line 89 in main
  File "/home/mattc/anaconda3/envs/main/bin/toco_from_protos", line 10 in &lt;module&gt;
Aborted (core dumped)
&lt;/denchmark-code&gt;

Any other info / logs
I am following this notebook: &lt;denchmark-link:https://www.tensorflow.org/tutorials/text/transformer&gt;https://www.tensorflow.org/tutorials/text/transformer&lt;/denchmark-link&gt;

I am interested in doing NMT on an Android device with TFLite. The NMT Attention notebook uses an LSTM which is not supported yet for TF Lite conversion so I am looking into this approach that only uses Attention, Embeddings, and Dense layers in hope that it is convertible.
I haven't edited the code from that notebook at all, but created a new inference concrete function and am trying to convert it. I am getting this vague error about the StridedSlice op.
Looking for some guidance on what I can do from here.
tf.random.set_seed(1234)

eval_step_signature = [
    tf.TensorSpec(shape=(BATCH_SIZE, 64), dtype=tf.int64),
    tf.TensorSpec(shape=(BATCH_SIZE, 26), dtype=tf.int64),
]

@tf.function(input_signature=eval_step_signature)
def eval_step(inp, tar):

    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar)
    
    predictions, _ = transformer(inp, tar, 
                                 True, 
                                 enc_padding_mask, 
                                 combined_mask, 
                                 dec_padding_mask)
    return predictions

ckpt.f = eval_step
to_save = ckpt.f.get_concrete_function()

converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
tflite_model = converter.convert()
Thank you!
	</description>
	<comments>
		<comment id='1' author='mattc-eostar' date='2019-11-26T18:27:40Z'>
		I have also encountered the same problem. Looks like it is from create_padding_mask function.
		</comment>
		<comment id='2' author='mattc-eostar' date='2020-07-07T22:12:50Z'>
		Hi &lt;denchmark-link:https://github.com/mattc-eostar&gt;@mattc-eostar&lt;/denchmark-link&gt;
 ,
I could resolve the issue with:
ckpt.f = eval_step
to_save = ckpt.f.get_concrete_function()

converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
Thank you.
		</comment>
		<comment id='3' author='mattc-eostar' date='2020-07-27T12:07:09Z'>
		&lt;denchmark-link:https://github.com/mattc-eostar&gt;@mattc-eostar&lt;/denchmark-link&gt;

Can you please check and confirm whether your issue was resolved by adding below 2 lines of code before converting
&lt;denchmark-code&gt;converter = tf.lite.TFLiteConverter.from_concrete_functions([to_save])
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
&lt;/denchmark-code&gt;

Please, close this thread if your issue was resolved.Thanks!
		</comment>
		<comment id='4' author='mattc-eostar' date='2020-08-03T12:22:57Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='5' author='mattc-eostar' date='2020-08-10T13:21:04Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='6' author='mattc-eostar' date='2020-08-10T13:21:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33616&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33616&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>