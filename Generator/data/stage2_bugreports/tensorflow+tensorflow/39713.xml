<bug id='39713' author='dreamPoet' open_date='2020-05-20T12:23:17Z' closed_time='2020-07-12T01:34:17Z'>
	<summary>Does tensorflow 1.15.0 support int8 tflite convertion? Wrong accurary.</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
TensorFlow installed from (source or binary): pip install tensorflow-gpu==1.15
TensorFlow version (or github SHA if from source): 1.15.0

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;
converter=tf.lite.TFLiteConverter.from_frozen_graph(pb_path,input_arrays=input_tensor_name
                                                   ,output_arrays=class_tensor_name
                                                   ,input_shapes=input_tensor_shape)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
converter.representative_dataset=representative_data_gen

tflite_model=converter.convert()
 
 
with open('owntempuint.tflite','wb') as f:
    f.write(tflite_model)

&lt;/denchmark-code&gt;

Failure details
If the conversion is successful, but the generated model is wrong,
state what is wrong:
The int8 model produced successfully, however, the accuracy is very low, while from the same .pb model whose accuracy is about 0.51, float tflite model achieve 0.47 accuracy, the int8 tflite model only has 0.04 with the same input.
	</description>
	<comments>
		<comment id='1' author='dreamPoet' date='2020-05-20T22:30:52Z'>
		&lt;denchmark-link:https://github.com/dreamPoet&gt;@dreamPoet&lt;/denchmark-link&gt;

I ran the code shared and face a different error, please provide with complete code such that we can replicate the issue.
Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/25d7a8784b7190e680df4f5b2272de10/untitled195.ipynb&gt;gist here&lt;/denchmark-link&gt;
 of error faced.
		</comment>
		<comment id='2' author='dreamPoet' date='2020-05-21T13:31:18Z'>
		I think the error you showed was because you use tf2.0 which discards the .pb model.
I can provide some codes producing tflite from .h5 model, which also have problem when producing int8 model.
&lt;denchmark-link:https://github.com/dreamPoet/tflearning/&gt;https://github.com/dreamPoet/tflearning/&lt;/denchmark-link&gt;

These codes are written based on the official tutorial, as the validation set was produced randomly, every time the print information will be different, sample print info was like:

Raw model accuracy: 85.938%
Quant TF Lite accuracy: 84.375%
INT8 Quant TF Lite accuracy: 18.750%

As u can see, the INT8 input and output version tflite has very low accuracy.
		</comment>
		<comment id='3' author='dreamPoet' date='2020-06-06T00:11:17Z'>
		The gist error can be fixed by changing the tf.lite.TFLiteConverter.from_frozen_graph to tf.compat.v1.lite.TFLiteConverter.from_frozen_graph
Could you also share the code where you compute the inference? The one caveat with models that have  and  set to  or  is this -- you need to manually map (aka quantize) the float inputs to integer inputs for inference on your device. To understand how this can be done -- refer to the equation provided &lt;denchmark-link:https://www.tensorflow.org/lite/performance/quantization_spec&gt;here&lt;/denchmark-link&gt;
, and it's equivalent code in python &lt;denchmark-link:https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/core/task/model_util_test.py#L89-L113&gt;here&lt;/denchmark-link&gt;
 which compares a keras model's output with it's integer-only TFLite model's output . (I hope this makes sense -- if not I can provide more details)
		</comment>
		<comment id='4' author='dreamPoet' date='2020-07-12T01:34:17Z'>
		Closing issue due to user inactivity. Feel free to re-open it if the issue persists.
		</comment>
		<comment id='5' author='dreamPoet' date='2020-07-12T01:34:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39713&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39713&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>