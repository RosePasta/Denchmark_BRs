<bug id='36005' author='uchua' open_date='2020-01-17T22:38:56Z' closed_time='2020-04-24T14:49:21Z'>
	<summary>Compiling tf.keras.Model with hub.KerasLayer fails in distributed scope</summary>
	<description>
System information

Have I written custom code: Yes
OS Platform and Distribution: Debian 9.11 (Google Cloud tf2-latest-gpu image)
TensorFlow installed from: Preinstalled on Google Cloud image
TensorFlow version: v2.1.0-rc2-17-ge5bf8de
Python version: 3.5.3
CUDA/cuDNN version: N/A
GPU model and memory: None (Using Google Cloud TPU v3-8)

Describe the current behavior
When compiling a tf.keras.Model that includes a hub.KerasLayer (tensorflow hub), it fails to compile in a distribution strategy scope:
&lt;denchmark-code&gt;ValueError                                Traceback (most recent call last)
&lt;ipython-input-23-7b06371889c9&gt; in &lt;module&gt;
     16         optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
     17         loss=tf.keras.losses.binary_crossentropy,
---&gt; 18         metrics=["accuracy"]
     19     )

1 frames
/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--&gt; 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    469                 'with strategy.scope():\n'
    470                 '  model=_create_model()\n'
--&gt; 471                 '  model.compile(...)'% (v, strategy))
    472 
    473   @trackable.no_automatic_dependency_tracking

ValueError: Variable (&lt;tf.Variable 'bert/embeddings/word_embeddings:0' shape=(119547, 768) dtype=float32&gt;) was not created in the distribution strategy scope of (&lt;tensorflow.python.distribute.tpu_strategy.TPUStrategy object at 0x7f4df23cddd8&gt;). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
&lt;/denchmark-code&gt;

Describe the expected behavior
Model should be able to compile.
Code to reproduce the issue
Code used to create scope:
TPU_ADDRESS = "grpc://" + "10.0.0.2:8470"

with tf.compat.v1.Session(TPU_ADDRESS) as session:
    print('TPU devices:')
    pprint.pprint(session.list_devices())

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)
try:
    tf.config.experimental_connect_to_cluster(resolver)
except tf.errors.UnimplementedError as uie:
    print(uie, "This appears to be caused by the TPU already being connected. Ignoring.", sep='\n')
tf.tpu.experimental.initialize_tpu_system(resolver)
tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)
Code used to compile model:
with tpu_strategy.scope():
    in_id = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), name="input_ids", dtype=np.int32)
    in_mask = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), name="input_masks", dtype=np.int32)
    in_segment = tf.keras.layers.Input(shape=(MAX_SEQ_LENGTH,), name="segment_ids", dtype=np.int32)
    bert_inputs = {"input_ids": in_id, "input_mask": in_mask, "segment_ids": in_segment}

    bert_layer = hub.KerasLayer(BERT_MODEL_HUB, signature="tokens", output_key="pooled_output")(bert_inputs)
    bert_layer.trainable = True

    dense = tf.keras.layers.Dense(256, activation='relu')(bert_layer)
    pred = tf.keras.layers.Dense(len(unique_labels), activation='sigmoid')(dense)

    model = tf.keras.Model(inputs=bert_inputs, outputs=pred)

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
        loss=tf.keras.losses.binary_crossentropy,
        metrics=["accuracy"]
    )

Previously opened issue with TF Hub here: &lt;denchmark-link:https://github.com/tensorflow/hub/issues/469&gt;tensorflow/hub#469&lt;/denchmark-link&gt;

Google Cloud TPU v3-8 is running TPU Software 2.1
	</description>
	<comments>
		<comment id='1' author='uchua' date='2020-01-20T18:09:27Z'>
		I get almost the same error message when trying to use an ALBERT model with a GPU through a one device strategy:
&lt;denchmark-code&gt;ValueError: Variable (&lt;tf.Variable 'bert/embeddings/word_embeddings:0' shape=(30000, 128) dtype=float32&gt;) was not created in the distribution strategy scope of (&lt;tensorflow.python.distribute.one_device_strategy.OneDeviceStrategyV1 object at 0x7f50cac42f60&gt;). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.
with strategy.scope():
  model=_create_model()
  model.compile(...)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='uchua' date='2020-01-21T04:05:32Z'>
		Could you refer to this piece of code example? &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/official/nlp/bert_models.py#L370&gt;https://github.com/tensorflow/models/blob/master/official/nlp/bert_models.py#L370&lt;/denchmark-link&gt;

You need to make hub.KerasLayer trainable
		</comment>
		<comment id='3' author='uchua' date='2020-01-21T16:42:30Z'>
		
Could you refer to this piece of code example? https://github.com/tensorflow/models/blob/master/official/nlp/bert_models.py#L370
You need to make hub.KerasLayer trainable

In my code above I use these two lines to make the layer trainable:
bert_layer = hub.KerasLayer(BERT_MODEL_HUB, signature="tokens", output_key="pooled_output")(bert_inputs)
bert_layer.trainable = True
However, I have also tried it this way:
bert_layer = hub.KerasLayer(BERT_MODEL_HUB, signature="tokens", output_key="pooled_output", trainable=True)(bert_inputs)
Both methods result in the same error.
		</comment>
		<comment id='4' author='uchua' date='2020-02-04T15:01:21Z'>
		Is there any update on this? Just wanted to check in being as it's been two weeks now.
		</comment>
		<comment id='5' author='uchua' date='2020-02-04T19:32:09Z'>
		Can you try these tf2 hub modules here: &lt;denchmark-link:https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/1&gt;https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/1&lt;/denchmark-link&gt;
?
The Albert modules from the TF2 model code are publishing soon.
The example here: &lt;denchmark-link:https://github.com/tensorflow/models/blob/master/official/nlp/bert_models.py#L370&gt;https://github.com/tensorflow/models/blob/master/official/nlp/bert_models.py#L370&lt;/denchmark-link&gt;

should work for TF 2.1
		</comment>
		<comment id='6' author='uchua' date='2020-02-06T23:34:04Z'>
		&lt;denchmark-link:https://github.com/saberkun&gt;@saberkun&lt;/denchmark-link&gt;
 the new models do seem to work. I was just able to load and train a model using this TF hub model loaded as a : &lt;denchmark-link:https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1&gt;https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1&lt;/denchmark-link&gt;
.
The example link you posted gives me a 404 error however.
So is the bug just an issue of lacking backwards compatibility?
		</comment>
		<comment id='7' author='uchua' date='2020-02-07T01:31:05Z'>
		I don't think we support loading TF1 hub model from TF2, maybe someone from TF hub team can confirm.
		</comment>
		<comment id='8' author='uchua' date='2020-02-07T15:30:00Z'>
		&lt;denchmark-link:https://github.com/rxsang&gt;@rxsang&lt;/denchmark-link&gt;
 it loooks like it should be possible based on this: &lt;denchmark-link:https://www.tensorflow.org/hub/migration_tf2&gt;https://www.tensorflow.org/hub/migration_tf2&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='uchua' date='2020-04-24T14:49:21Z'>
		&lt;denchmark-link:https://github.com/uchua&gt;@uchua&lt;/denchmark-link&gt;
 Looks like issue is resolved. Please feel free to reopen the issue if you still have a concern. Thanks!
		</comment>
		<comment id='10' author='uchua' date='2020-04-24T14:49:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36005&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36005&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>