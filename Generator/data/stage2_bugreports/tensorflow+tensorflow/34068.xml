<bug id='34068' author='durandg12' open_date='2019-11-07T12:00:42Z' closed_time='2020-01-27T23:00:56Z'>
	<summary>TF2 keras.models.load_model fails with custom metrics (both h5 and tf format)</summary>
	<description>

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
TensorFlow installed from (source or binary): pip install tensorflow==2.0.0-beta1
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

Describe the current behavior
I have a custom metric in my model and using  with  after saving it results in an error in almost all cases, whereas I use the  argument according to &lt;denchmark-link:https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/models/load_model&gt;the documentation&lt;/denchmark-link&gt;
.
I tried to pass my custom metric with two strategies: by passing a custom function custom_accuracy to the tf.keras.Model.compile method, or by subclassing the MeanMetricWrapper class and giving an instance of my subclass named CustomAccuracy to tf.keras.Model.compile.
I also tried the two different saving format available: h5 and tf. Here are my results:

with tf format:

with custom function:
fail with ValueError message Unknown metric function:custom_accuracy
with subclassed metric:
fail with ValueError message Unknown metric function: CustomAccuracy


with h5 format:

with custom function:
success
with subclassed metric:
fail with TypeError message must be str, not ABCMeta



Note that given the complete error logs (see below), the error with h5 format and subclassed metric is in fact the same as the error with the tf format. The TypeError occurs when the code tries to raise the ValueError.
Describe the expected behavior
This should not fail in any case, except if I am using the custom_objects argument wrong. The documentation could be a little expanded on that matter by the way.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

from tensorflow.python.keras.metrics import MeanMetricWrapper
from tensorflow.python.keras.metrics import accuracy

def custom_accuracy(y_true, y_pred):
    return accuracy(y_true, y_pred)

class CustomAccuracy(MeanMetricWrapper):

    def __init__(self, **kwargs):
        super(CustomAccuracy, self).__init__(custom_accuracy, **kwargs)
        
def make_model():
    inp = tf.keras.Input(shape=(2,))
    x = tf.keras.layers.Dense(4)(inp)
    return tf.keras.Model(inp, x)


for save_format in ['tf', 'h5']:
    
    print("\nTrying with save_format='{}':\n".format(save_format))
    
    model_with_function = make_model()
    model_with_function.compile(loss='mse', metrics=[custom_accuracy])
    model_with_function.save('/tmp/model_with_function' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_function' + '.' + save_format, 
                                               custom_objects={'custom_accuracy': custom_accuracy}, 
                                               compile=True)
        print("model_with_function loaded with the following metrics:")
        print(new_model.metrics)
    except Exception as e:
        print("model_with_function not loaded with the following error:")
        print(type(e))
        print(e)
        
    model_with_subclass = make_model()
    model_with_subclass.compile(loss='mse', metrics=[CustomAccuracy()])
    model_with_subclass.save('/tmp/model_with_subclass' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + save_format, 
                                               custom_objects={'CustomAccuracy': CustomAccuracy}, 
                                               compile=True)
        print("model_with_subclass loaded with the following metrics:")
        print(new_model.metrics)
    except Exception as e:
        print("model_with_subclass not loaded with the following error:")
        print(type(e))
        print(e)
&lt;/denchmark-code&gt;

Other info / logs
The logs are the same in the 3 error cases (to get them with the code above, just add raiseat the end of the except blocks):
&lt;denchmark-code&gt;&lt;ipython-input-14-ac0a72b492dc&gt; in &lt;module&gt;
     48         new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + save_format, 
     49                                                custom_objects={'CustomAccuracy': CustomAccuracy},
---&gt; 50                                                compile=True)
     51         print("model_with_function loaded with the following metrics:")
     52         print(new_model.metrics)

/path/to/tensorflow_core/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    148   if isinstance(filepath, six.string_types):
    149     loader_impl.parse_saved_model(filepath)
--&gt; 150     return saved_model_load.load(filepath, compile)
    151 
    152   raise IOError(

/path/to/tensorflow_core/python/keras/saving/saved_model/load.py in load(path, compile)
     91     if model._training_config is not None:  # pylint: disable=protected-access
     92       model.compile(**saving_utils.compile_args_from_training_config(
---&gt; 93           model._training_config))  # pylint: disable=protected-access
     94 
     95   return model

/path/to/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--&gt; 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/path/to/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    354     with K.get_graph().as_default():
    355       # Save all metric attributes per output of the model.
--&gt; 356       self._cache_output_metric_attributes(metrics, weighted_metrics)
    357 
    358       # Set metric attributes on model.

/path/to/tensorflow_core/python/keras/engine/training.py in _cache_output_metric_attributes(self, metrics, weighted_metrics)
   1899         output_shapes.append(output.shape.as_list())
   1900     self._per_output_metrics = training_utils.collect_per_output_metric_info(
-&gt; 1901         metrics, self.output_names, output_shapes, self.loss_functions)
   1902     self._per_output_weighted_metrics = (
   1903         training_utils.collect_per_output_metric_info(

/path/to/tensorflow_core/python/keras/engine/training_utils.py in collect_per_output_metric_info(metrics, output_names, output_shapes, loss_fns, is_weighted)
    811     metrics_dict = OrderedDict()
    812     for metric in metrics:
--&gt; 813       metric_name = get_metric_name(metric, is_weighted)
    814       metric_fn = get_metric_function(
    815           metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])

/path/to/tensorflow_core/python/keras/engine/training_utils.py in get_metric_name(metric, weighted)
    985       return metric
    986 
--&gt; 987     metric = metrics_module.get(metric)
    988     return metric.name if hasattr(metric, 'name') else metric.__name__
    989   else:

/path/to/tensorflow_core/python/keras/metrics.py in get(identifier)
   2855 def get(identifier):
   2856   if isinstance(identifier, dict):
-&gt; 2857     return deserialize(identifier)
   2858   elif isinstance(identifier, six.string_types):
   2859     return deserialize(str(identifier))

/path/to/tensorflow_core/python/keras/metrics.py in deserialize(config, custom_objects)
   2849       module_objects=globals(),
   2850       custom_objects=custom_objects,
-&gt; 2851       printable_module_name='metric function')
   2852 
   2853 

/path/to/tensorflow_core/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    178     config = identifier
    179     (cls, cls_config) = class_and_config_for_serialized_keras_object(
--&gt; 180         config, module_objects, custom_objects, printable_module_name)
    181 
    182     if hasattr(cls, 'from_config'):

/path/to/tensorflow_core/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    163     cls = module_objects.get(class_name)
    164     if cls is None:
--&gt; 165       raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
    166   return (cls, config['config'])
    167 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='durandg12' date='2019-11-08T09:16:02Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;

I tried reproducing the code in colab using TF 2.0 beta1, TF 2.0 and i am seeing different error messages. Kindly , provide minimal stand alone reproducible code,it  helps us in localizing the issue faster.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/1780a9fe7e8d0e39cf52ba6e973d22e6/untitled342.ipynb&gt;here.&lt;/denchmark-link&gt;
 Thanks!
		</comment>
		<comment id='2' author='durandg12' date='2019-11-12T09:49:36Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

I have looked at your gist.
The error messages in your gist for tf2.0.0 are exactly the same as mine.
There is also a deprecation warning that I have too but that I hadn't copied in my first message because it didn't seem relevant.
For tf2.0.0-beta1 the error message is effectively different but it comes from the compile method because I call it without an optimizer argument. I have added optimizer='adam' in my compile call and now the output is the same for 2.0.0 and 2.0.0-beta1. So the code now looks like this:
&lt;denchmark-code&gt;import tensorflow as tf

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

from tensorflow.python.keras.metrics import MeanMetricWrapper
from tensorflow.python.keras.metrics import accuracy

def custom_accuracy(y_true, y_pred):
    return accuracy(y_true, y_pred)

class CustomAccuracy(MeanMetricWrapper):

    def __init__(self, **kwargs):
        super(CustomAccuracy, self).__init__(custom_accuracy, **kwargs)
        
def make_model():
    inp = tf.keras.Input(shape=(2,))
    x = tf.keras.layers.Dense(4)(inp)
    return tf.keras.Model(inp, x)


for save_format in ['tf', 'h5']:
    
    print("\nTrying with save_format='{}':\n".format(save_format))
    
    model_with_function = make_model()
    model_with_function.compile(optimizer='adam', loss='mse', metrics=[custom_accuracy])
    model_with_function.save('/tmp/model_with_function' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_function' + '.' + save_format, 
                                               custom_objects={'custom_accuracy': custom_accuracy}, 
                                               compile=True)
        print("model_with_function loaded with the following metrics:")
        print(new_model.metrics)
    except Exception as e:
        print("model_with_function not loaded with the following error:")
        print(type(e))
        print(e)
        
    model_with_subclass = make_model()
    model_with_subclass.compile(optimizer='adam', loss='mse', metrics=[CustomAccuracy()])
    model_with_subclass.save('/tmp/model_with_subclass' + '.' + save_format, 
                             save_format=save_format)
    
    try:
        new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + save_format, 
                                               custom_objects={'CustomAccuracy': CustomAccuracy}, 
                                               compile=True)
        print("model_with_function loaded with the following metrics:")
        print(new_model.metrics)
    except Exception as e:
        print("model_with_function not loaded with the following error:")
        print(type(e))
        print(e)
&lt;/denchmark-code&gt;

I think that my code was already minimal as it just:

created the simplest custom accuracy possible
created the simplest MLP possible
compiled the MLP with the custom accuracy
saved the MLP
loaded the MLP

I don't know how I can make it simpler. Except if you want the same piece of code but without the print calls and without the try and except blocks. In this case here it is:
&lt;denchmark-code&gt;import tensorflow as tf

from tensorflow.python.keras.metrics import MeanMetricWrapper
from tensorflow.python.keras.metrics import accuracy

def custom_accuracy(y_true, y_pred):
    return accuracy(y_true, y_pred)

class CustomAccuracy(MeanMetricWrapper):

    def __init__(self, **kwargs):
        super(CustomAccuracy, self).__init__(custom_accuracy, **kwargs)
        
def make_model():
    inp = tf.keras.Input(shape=(2,))
    x = tf.keras.layers.Dense(4)(inp)
    return tf.keras.Model(inp, x)

SAVE_FORMAT = 'h5'
#SAVE_FORMAT = 'tf'

model_with_function = make_model()
model_with_function.compile(optimizer='adam', loss='mse', metrics=[custom_accuracy])
model_with_function.save('/tmp/model_with_function' + '.' + SAVE_FORMAT, 
                         save_format=SAVE_FORMAT)


new_model = tf.keras.models.load_model('/tmp/model_with_function' + '.' + SAVE_FORMAT, 
                                           custom_objects={'custom_accuracy': custom_accuracy}, 
                                           compile=True)

    
#model_with_subclass = make_model()
#model_with_subclass.compile(loss='mse', metrics=[CustomAccuracy()])
#model_with_subclass.save('/tmp/model_with_subclass' + '.' + SAVE_FORMAT, 
#                         save_format=SAVE_FORMAT)
#
#new_model = tf.keras.models.load_model('/tmp/model_with_subclass' + '.' + SAVE_FORMAT, 
#                                           custom_objects={'CustomAccuracy': CustomAccuracy}, 
#                                           compile=True)
&lt;/denchmark-code&gt;

but you have to manually comment or uncomment some parts if you want to observe all four cases.
Ironically, adding an optimizer for tf2.0.0-beta1 makes the code less minimal.
		</comment>
		<comment id='3' author='durandg12' date='2019-11-12T10:51:20Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;

Thanks for the detailed explanation. After adding  in compile call i am able to reproduce the same error message in both  TF 2.0.0 and 2.0.0-beta1. Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/17024d04ca0bc9a7e28cec4244715c7a/untitled355.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='4' author='durandg12' date='2019-11-13T23:40:24Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
 Thanks for the detailed report. As of now there is no solution available. There are some workarounds suggested &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32612&gt;here&lt;/denchmark-link&gt;
. There is a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/33229&gt;#33229&lt;/denchmark-link&gt;
 to resolve an issue similar to this issue. Please follow the PR and test it once it is approved and released in . Thanks!
		</comment>
		<comment id='5' author='durandg12' date='2019-11-22T16:23:00Z'>
		I have reviewed the issue you linked. It seems to be the same problem indeed. I had also found the workaround of loading without compile but as &lt;denchmark-link:https://github.com/somedadaism&gt;@somedadaism&lt;/denchmark-link&gt;
 said &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32612#issuecomment-534248672&gt;this post&lt;/denchmark-link&gt;
 it is not satisfying.
So right now the best workaround is to use a custom function and pass it to the compilemethod and not subclassing MeanMetricWrapper. But this only worked with h5format and not tfformat, for which I don't find a satisfying workaround.
&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 I did not try the PR yet, I am not sure how to do it. Am I supposed to create a new virualenv and install  in it? How do I know when the PR is approved and released?
		</comment>
		<comment id='6' author='durandg12' date='2019-11-22T18:45:25Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
 If you have a solution to an issue in Tensorflow, you can raise PR by going &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pulls&gt;here&lt;/denchmark-link&gt;
. You can edit related TF source code with your solution, test it locally, then checkit into PR. Tensorflow Team will review it and responds. If everything is looking good, then it will be approved and then merged into TF source code. &lt;denchmark-link:https://www.tensorflow.org/community/contribute&gt;This&lt;/denchmark-link&gt;
 is a very good resource to start contributing. Hope this helps. Thanks!
		</comment>
		<comment id='7' author='durandg12' date='2019-11-28T11:16:44Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 my question was more focused on your last sentence, as I know what is a PR in general. My question is how do I do this:

Please follow the PR and test it once it is approved and released in tf-nightly

I see that the PR is actually awaiting review so it is not approved yet. Once it is approved, what steps do I need to follow? Can you confirm that I just have to set a new virtual env up, run pip install tf-nightly, and then try my example code?
		</comment>
		<comment id='8' author='durandg12' date='2019-12-02T18:33:22Z'>
		Once it is approved, you don't need to do anything. After approval, it will be merged into tf-nightly.  During the approval process, Reviewer will guide you through the steps if any required. Thanks!
		</comment>
		<comment id='9' author='durandg12' date='2019-12-06T23:24:33Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
 As of now &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/33229&gt;#33229&lt;/denchmark-link&gt;
 was approved but not merged. Once it is merged, you can use  to test it. Thanks!
		</comment>
		<comment id='10' author='durandg12' date='2019-12-16T20:04:13Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
 Can you try  tomorrow as the related PR merged. Please let us know whether it solved your issue or not. Thanks!
		</comment>
		<comment id='11' author='durandg12' date='2019-12-18T23:29:31Z'>
		&lt;denchmark-link:https://github.com/durandg12&gt;@durandg12&lt;/denchmark-link&gt;
 Looks like  is working for both the cases when the model is saved in 'h5` format. &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/95b9d359762b766dba337e0cfa0c248b/untitled355.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the gist. Thanks!
Both the cases are still failing when the model was saved in tf format. Thanks!
		</comment>
		<comment id='12' author='durandg12' date='2019-12-19T17:55:44Z'>
		I have seen your gist, and after installing tf-nightly I have been able to replicate it on my laptop, thank you.
The only small difference I see is that locally I have an additional warning:
WARNING: Logging before flag parsing goes to stderr.
		</comment>
		<comment id='13' author='durandg12' date='2020-01-24T21:14:40Z'>
		This is fixed latest tf-nightly version '2.2.0-dev20200123'. Thanks!
		</comment>
		<comment id='14' author='durandg12' date='2020-01-27T23:00:58Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34068&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34068&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='durandg12' date='2020-02-04T14:22:27Z'>
		I have tested and the issue is indeed fixed.
But we shall note that the tfmode still raises a warning :
&lt;denchmark-code&gt;WARNING:tensorflow:From /path/to/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1809: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='16' author='durandg12' date='2020-10-06T00:42:52Z'>
		Hello! Was this ever solved for saving/loading custom metrics in SavedModel format opposed to .h5?
		</comment>
	</comments>
</bug>