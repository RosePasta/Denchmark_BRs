<bug id='30711' author='dekromp' open_date='2019-07-15T14:18:06Z' closed_time='2019-07-19T10:47:57Z'>
	<summary>Keras custom metrics raises error when update_state returns an op.</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.4
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.14.0
Python version: 3.6
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: -
GPU model and memory: -

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
I am trying to build a custom metric for Keras, which worked with tensorflow 1.12. Now after upgrading to python 1.14 I get the error shown below.  I am returning the result of tf.group in the update_state method of the metric which is of course an Op. What puzzles me is that tensorflow.python.keras.utils.metric_utils.update_confusion_matrix_variables which is used by many of the other builtin metrics like Precision, does the exact same thing. To make sure that the error is not caused by my own implementation I copied the implementation of tf.keras.metrics.Precision into my own file and tried to run it. It get the same error, however when I substitute this "custom" metric with the builtin, it works. The code to reproduce this is shown below.
Describe the expected behavior*
The custom metric should work as expected.
Code to reproduce the issue
import tensorflow as tf
from tensorflow.python.keras.metrics import Metric
from tensorflow.python.keras.utils import metrics_utils
import tensorflow.keras.backend as K
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import init_ops
import numpy as np
from tensorflow.python.keras.utils.generic_utils import to_list


class Precision(Metric):
    """This is a 1:1 copy of the code in tensorflow.python.keras.metrics."""
    def __init__(self,
                 thresholds=None,
                 top_k=None,
                 class_id=None,
                 name=None,
                 dtype=None):

        super(Precision, self).__init__(name=name, dtype=dtype)
        self.init_thresholds = thresholds
        self.top_k = top_k
        self.class_id = class_id

        default_threshold = 0.5 if top_k is None else metrics_utils.NEG_INF
        self.thresholds = metrics_utils.parse_init_thresholds(
            thresholds, default_threshold=default_threshold)
        self.true_positives = self.add_weight(
            'true_positives',
            shape=(len(self.thresholds),),
            initializer=init_ops.zeros_initializer)
        self.false_positives = self.add_weight(
            'false_positives',
            shape=(len(self.thresholds),),
            initializer=init_ops.zeros_initializer)

    def update_state(self, y_true, y_pred, sample_weight=None):
        return metrics_utils.update_confusion_matrix_variables({
            metrics_utils.ConfusionMatrix.TRUE_POSITIVES: self.true_positives,
            metrics_utils.ConfusionMatrix.FALSE_POSITIVES: self.false_positives},
            y_true,
            y_pred,
            thresholds=self.thresholds,
            top_k=self.top_k,
            class_id=self.class_id,
            sample_weight=sample_weight)

    def result(self):
        result = math_ops.div_no_nan(
            self.true_positives,
            self.true_positives + self.false_positives)
        return result[0] if len(self.thresholds) == 1 else result

    def reset_states(self):
        num_thresholds = len(to_list(self.thresholds))
        K.batch_set_value(
            [(v, np.zeros((num_thresholds,))) for v in self.variables])

    def get_config(self):
        config = {
            'thresholds': self.init_thresholds,
            'top_k': self.top_k,
            'class_id': self.class_id
        }
        base_config = super(Precision, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


if __name__ == '__main__':
    x = tf.keras.Input((10,))
    y_hat = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    model = tf.keras.models.Model(inputs=[x], outputs=[y_hat])
    model.compile(
        optimizer=tf.keras.optimizers.SGD(0.01),
        loss='binary_crossentropy',
        metrics=[Precision()])
    # However the builtin metric works:
    # model.compile(
    #     optimizer=tf.keras.optimizers.SGD(0.01),
    #     loss='binary_crossentropy',
    #     metrics=[tf.keras.metrics.Precision()])

    X = np.random.uniform(-1, 1, size=(100, 10)).astype(np.float32)
    y = np.random.choice([0, 1], size=(100,)).astype(np.float32)
    model.fit(X, y)
Other info / logs
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 676, in convert
    x = ops.convert_to_tensor_or_composite(x)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1479, in convert_to_tensor_or_composite
    value=value, dtype=dtype, name=name, as_ref=False)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1518, in internal_convert_to_tensor_or_composite
    accept_composite_tensors=True)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1224, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 6696, in _operation_conversion_error
    (op.name, dtype, name, as_ref))
TypeError: Can't convert Operation 'group_deps' to Tensor (target dtype=None, name=None, as_ref=False)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "metrics_bug.py", line 75, in &lt;module&gt;
    metrics=[Precision()])
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 330, in compile
    masks=self._prepare_output_masks())
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 2170, in _handle_metrics
    target, output, output_mask))
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 2118, in _handle_per_output_metrics
    mask)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 2094, in _call_metric_fn
    strategy=self._distribution_strategy)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py", line 1054, in call_replica_local_fn
    return fn(*args, **kwargs)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py", line 873, in call_metric_function
    return metric_fn(y_true, y_pred, sample_weight=weights)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py", line 170, in __call__
    update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/keras/utils/metrics_utils.py", line 73, in decorated
    update_op = update_state_fn(*args, **kwargs)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 414, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 357, in _initialize
    *args, **kwds))
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1349, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1652, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1545, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 720, in func_graph_from_py_func
    expand_composites=True)
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 515, in map_structure
    structure[0], [func(*x) for x in entries],
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/util/nest.py", line 515, in &lt;listcomp&gt;
    structure[0], [func(*x) for x in entries],
  File "/Users/denis/anaconda2/envs/dev-p36/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py", line 682, in convert
    (str(python_func), type(x)))
TypeError: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of &lt;function Function._defun_with_scope.&lt;locals&gt;.wrapped_fn at 0xb34ec5d08&gt;, found return value of type &lt;class 'tensorflow.python.framework.ops.Operation'&gt;, which is not a Tensor.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='dekromp' date='2019-07-16T07:55:26Z'>
		Same error in my custom metric on yesterday nightly build of tf-2.0
		</comment>
		<comment id='2' author='dekromp' date='2019-07-16T11:19:42Z'>
		&lt;denchmark-link:https://github.com/dekromp&gt;@dekromp&lt;/denchmark-link&gt;
 ,
I tried reproducing the issue with TF 1.14 and i didn't get any error.
please take a look at Gist of &lt;denchmark-link:https://colab.research.google.com/drive/1BUqCQgo2nuH9VQZyn4m1K6-1ANqLVWcA&gt;Colab link&lt;/denchmark-link&gt;
 .Thanks!
		</comment>
		<comment id='3' author='dekromp' date='2019-07-16T11:31:12Z'>
		
@dekromp ,
I tried reproducing the issue with TF 1.14 and i didn't get any error.
please take a look at Gist of Colab link .Thanks!

Your link is private.
		</comment>
		<comment id='4' author='dekromp' date='2019-07-16T19:49:37Z'>
		@anush-o
Hi anush-o, thanks for looking into this. I made a small error in my code example above (which I fixed now). The code was still using tf.keras.metrics.Precision instead of Precision (Sorry for that). You should be able to reproduce the error now. In the meantime I tried the above snippet on another computer (Ubuntu 16.04) with a fresh conda environment and get the same error.
		</comment>
		<comment id='5' author='dekromp' date='2019-07-18T09:40:01Z'>
		I was able to replicate the issue with TF version 1.14. Thanks!
		</comment>
		<comment id='6' author='dekromp' date='2019-07-18T17:53:44Z'>
		&lt;denchmark-link:https://github.com/dekromp&gt;@dekromp&lt;/denchmark-link&gt;
 You can remove return statements and group ops from custom metrics. It is not required. Built in metrics have a different requirement because of an issue with TPUs. Once that is fixed we will remove the return from update_state from built-in metrics as well.
Thank you!
		</comment>
		<comment id='7' author='dekromp' date='2019-07-19T10:47:57Z'>
		&lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;

That did the trick. Thanks for helping out.
		</comment>
		<comment id='8' author='dekromp' date='2019-07-19T10:48:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30711&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30711&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>