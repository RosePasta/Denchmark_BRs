<bug id='25707' author='nfelt' open_date='2019-02-12T23:44:53Z' closed_time='2019-02-28T19:54:52Z'>
	<summary>summary v2 create_file_writer() behavior leads to incorrect resource deletion</summary>
	<description>
This is a tracking bug for the known issue that the V2 summary API's create_file_writer() logic behaves unexpectedly in regards to the underlying resource lifecycle management.  This typically manifests as users seeing errors like tensorflow.python.framework.errors_impl.NotFoundError: Resource localhost/logdir:./log/N10tensorflow22SummaryWriterInterfaceE does not exist. [Op:WriteScalarSummary] name: epoch_loss/
Users can encounter this in 1.x when using tf.contrib.summary.create_file_writer() in eager mode, or in 2.0 as tf.summary.create_file_writer(), or via wrapper APIs like the Keras TensorBoard callback.
Example issues: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24632&gt;#24632&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25524&gt;#25524&lt;/denchmark-link&gt;

The root cause is that create_file_writer(logdir) returns a SummaryWriter python object backed by a C++ SummaryWriterInterface resource, but the mapping is not 1:1, which violates other assumptions about resource management under eager mode.  In particular, two SummaryWriter instances created for the same logdir by default will both attempt to reference the same named resource.  (Sharing by logdir was intended to be a mechanism for using one eventfile per logdir akin to tf.summary.FileWriterCache in 1.x, which makes TensorBoard better behaved.)
This is a problem when one of the SummaryWriters is deleted (aka loses its last remaining reference), because it will unconditionally attempt to delete the named resource it was created with.  If a resource with that same name is referenced by any other SummaryWriters, those ones will now emit the above NotFoundError when attempting to use them.  Note that this happens even if the deleted SummaryWriter was properly close()'d before the new one was created, because the logdir name sharing means that it new writer's resource has the same name as the old one.
The correct fix is changing the resource names to be unique so that the mapping from SummaryWriter object &lt;-&gt; SummaryWriterInterface resource is 1:1 as designed.  This will likely require other workarounds for the one-eventfile-per-logdir problem.
Minimal repro:
import tempfile
import tensorflow as tf

if tf.__version__.startswith('2.'):
  create_file_writer = tf.summary.create_file_writer
else:
  tf.enable_eager_execution()
  create_file_writer = tf.contrib.summary.create_file_writer

dir = tempfile.mkdtemp('shared-writer-bug')
w = create_file_writer(dir)
w.close()  # succeeds, deletes old resource
# 1) new SummaryWriter created w/ new resource (but same name)
# 2) reassigning w deletes old SummaryWriter along w/ new resource (BUG)
w = create_file_writer(dir)
w.close()  # raises NotFoundError; new resource has been incorrectly deleted
	</description>
	<comments>
		<comment id='1' author='nfelt' date='2019-02-21T15:58:47Z'>
		Is there a workaround while the bug is being resolved?
UPDATE: opened a new bug &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25976&gt;#25976&lt;/denchmark-link&gt;
 as I had a issue with the same error, but different reason
		</comment>
		<comment id='2' author='nfelt' date='2019-02-26T20:17:11Z'>
		Reopening to track propagating this fix into the TF 2.0 Keras TensorBoard callback, which will fix the user issues reported in the original description above.
		</comment>
		<comment id='3' author='nfelt' date='2019-02-28T19:54:51Z'>
		Closed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/059ea3ba68db861e40d750eba688281011d2735f&gt;059ea3b&lt;/denchmark-link&gt;
.
		</comment>
	</comments>
</bug>