<bug id='26889' author='bSolt' open_date='2019-03-19T16:30:28Z' closed_time='2019-06-24T17:19:14Z'>
	<summary>tf.keras.fit not working with my model, doesn't feed the output target to placeholder tensor</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I have custom code to build an image classifier network with the tf.keras API
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04 (Linux Mint)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 'v1.13.1-0-g6612da8951' 1.13.1 
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: release 10.0, V10.0.130 cuDNN: 7.4.2
GPU model and memory: GeForce GTX 1070

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
When I try to use model.fit_generator or model.fit_on_batch, I get the following error:
&gt;&gt;&gt; for x,y in training_gen:
...     break
... 
&gt;&gt;&gt; model.train_on_batch(x,y)
WARNING:tensorflow:From /home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1188, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File "/home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py", line 3076, in __call__
    run_metadata=self.run_metadata)
  File "/home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
  File "/home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 528, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'dense_1_target' with dtype float and shape [?,?]
  [[{{node dense_1_target}}]]
  [[{{node metrics/acc/Mean_2}}]]
Here's the details about the model: It's a custom classifier which uses &lt;denchmark-link:https://arxiv.org/abs/1610.02357&gt;xception&lt;/denchmark-link&gt;
 as the feature detector and a custom feedforward network for a classifier.
&gt;&gt;&gt; model.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
xception (Model)             (None, 8, 8, 2048)        20861480  
_________________________________________________________________
Classifier (Sequential)      (None, 1)                 540929    
=================================================================
Total params: 21,402,409
Trainable params: 540,929
Non-trainable params: 20,861,480
_________________________________________________________________
&gt;&gt;&gt; classifier.summary()
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 8, 8, 256)         524544    
_________________________________________________________________
flatten (Flatten)            (None, 16384)             0         
_________________________________________________________________
dropout (Dropout)            (None, 16384)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 16385     
=================================================================
Total params: 540,929
Trainable params: 540,929
Non-trainable params: 0
_________________________________________________________________
The two models are combined with the following code:
ef build_full_model(feature_detector, classifier):
  model = tf.keras.models.Sequential()
  #First get the features from ptdnn
  model.add(feature_detector)
  # for layer in feature_detector.layers:
  #   layer.trainable=False
  #   model.add(layer)
  #Then classify
  model.add(classifier)  
  # for layer in classifier.layers:
  #   model.add(layer)
  #feature_detector should not be trainable if fine_tuning_layers==0
  feature_detector.trainable=False

  # Display layer information for reference
  print('[ASSEMBLE] Full Model Architecture:')
  model.summary()

  # classifier options including metrics and loss function
  classifier.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-4),
                loss='binary_crossentropy',
                metrics=['acc',recall,f1])
  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),
                loss='binary_crossentropy',
                metrics=['acc',recall,f1])

  print('[ASSEMBLE] Models compiled successfully')
  return model
The issue seems to occur no matter what the input values are. It seems to me that my inputs x and y (coming from my generator) are the correct shape:
&gt;&gt;&gt; print(x.shape,y.shape)
(32, 256, 256, 3) (32,)
For the sake of completeness, the training data generator is set to read in images from a directory with some augmentation:
# anonymous function for rotating 90 degrees randomly
  random_90 = lambda im: np.rot90(im,k=np.random.choice(4))
  #define the settings for loading in images including value rescale, 
  #  and random alterations such as scaling, zooming, and flipping
  augmented_gen = ImageDataGenerator(
    rescale=1./255,
    zoom_range=0.1,
    cval=0,
    horizontal_flip=True,
    vertical_flip = True,
    preprocessing_function=random_90,
    )
training_gen = augmented_gen.flow_from_directory(
    train_dir,
    target_size=(256, 256),
    batch_size=32,
    class_mode='binary'
    )
Describe the expected behavior
I expect the keras API to be able to train my model as is. Presumably this means that the placeholder Tensor should be populated correctly dense_1_target`  in "/home/hepcats/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
This should be able to reproduce my issue:
import tensorflow as tf
import numpy as np

# get xception
inshape = (256,256,3)
ptdnn = tf.keras.applications.Xception(
	weights='imagenet',
  	include_top=False,
  	input_shape=inshape)
# build classifier
classifier = tf.keras.models.Sequential(name='Classifier')
  # The classifier input is dense, or fully connected
classifier.add(tf.keras.layers.Dense(256, activation='relu',
  input_shape=feature_shape[1:]))
  # The flatten layer reduces the dimensions of the output
classifier.add(tf.keras.layers.Flatten())
  # Dropout layer prevents overfitting
classifier.add(tf.keras.layers.Dropout(0.5))
  # Output layer is a single neuron sigmoid
classifier.add(tf.keras.layers.Dense(1, activation='sigmoid'))

#Assemble composite model
model = tf.keras.models.Sequential()
  #First get the features from ptdnn
model.add(ptdnn)
  #Then classify
model.add(classifier)  
  #feature_detector should not be trainable if fine_tuning_layers==0
ptdnn.trainable=False

  # Display layer information for reference
print('[ASSEMBLE] Full Model Architecture:')
model.summary()

  # classifier options including metrics and loss function
classifier.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-4),
                loss='binary_crossentropy',
                metrics=['acc'])
model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),
                loss='binary_crossentropy',
                metrics=['acc'])

# try to fit on random data 
batch_size=1
model.train_on_batch(np.random.rand(batch_size,256,256,3),np.random.rand(batch_size,))
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
My models use manually defined metrics for recall and F1 score:
def recall(y_true, y_pred):
    """Recall metric.

    Only computes a batch-wise average of recall.

    Computes the recall, a metric for multi-label classification of
    how many relevant items are selected.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision(y_true, y_pred):
    """Precision metric.

    Only computes a batch-wise average of precision.

    Computes the precision, a metric for multi-label classification of
    how many selected items are relevant.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1(y_true, y_pred):
    """ F1 metric.
    The F1 metric is the harmonic mean of precision and recall
    """
    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    return 2*((p*r)/(p+r+K.epsilon()))
	</description>
	<comments>
		<comment id='1' author='bSolt' date='2019-03-19T20:21:07Z'>
		I figured out the exact issue and a workaround. The issue is that keras wasn't copying over the target values for the output of model into the output of classifier. This can be easily fixed by changing the structure of the model so that this step is unnecessary. I only had to change the build_full_model() function to do so. Here is the updated code:
def build_full_model(feature_detector, classifier):
  model = tf.keras.models.Sequential()
  #First get the features from ptdnn
  model.add(feature_detector)
  #Then classify
!  #model.add(classifier)  
!  for layer in classifier.layers:
!    model.add(layer)
  #feature_detector should not be trainable if fine_tuning_layers==0
  feature_detector.trainable=False

  # Display layer information for reference
  print('[ASSEMBLE] Full Model Architecture:')
  model.summary()

  # classifier options including metrics and loss function
  classifier.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-4),
                loss='binary_crossentropy',
                metrics=['acc',recall,f1])
  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),
                loss='binary_crossentropy',
                metrics=['acc',recall,f1])

  print('[ASSEMBLE] Models compiled successfully')
  return model
The change is on the lines with exclamation marks. Basically I just had to unroll the classifier model into the full model. I still think that the keras API was handling the original situation incorrectly, and should have been able to assign values to dense_1 target. Perhaps the issue could also be solved by introduction another layer after Classifier, but I am unsure how this would work.
		</comment>
		<comment id='2' author='bSolt' date='2019-03-20T09:37:28Z'>
		This seems to be a copy of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/26927&gt;#26927&lt;/denchmark-link&gt;
 and a TF 2.0 version of this problem &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/26738&gt;#26738&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='3' author='bSolt' date='2019-06-21T22:12:57Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/659c981a3556c6424237eacd0bf4cdc86f228f16&gt;659c981&lt;/denchmark-link&gt;
 should fix this issue. Please give it a try in the next nightly and let me know if it works as expected.
Thank you!
		</comment>
		<comment id='4' author='bSolt' date='2019-06-24T17:19:13Z'>
		The fix was verified by &lt;denchmark-link:https://github.com/foxik&gt;@foxik&lt;/denchmark-link&gt;
 in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/26738&gt;#26738&lt;/denchmark-link&gt;
 . Thank you!
		</comment>
		<comment id='5' author='bSolt' date='2019-06-24T17:19:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26889&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26889&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>