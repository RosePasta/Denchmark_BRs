<bug id='43162' author='auchtopus' open_date='2020-09-11T21:22:52Z' closed_time='2020-09-16T16:44:07Z'>
	<summary>custom xception input size broadcasting incorrectly</summary>
	<description>
&lt;denchmark-h:h2&gt;System information:&lt;/denchmark-h&gt;

Red Hat Enterprise Linux Server release 7.7 (Maipo)
Tensorflow: tensorflow gpu 2.1
GPU: Nvidia V100
Python: 3.6.10
GCC: 7.3.0
CUDA: 10.1 (I think)
Running through slurm
&lt;denchmark-h:h2&gt;The Error log:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;ValueError: could not broadcast input array from shape (850,550,3) into shape (850,550,3,3)
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;model.summary()&lt;/denchmark-h&gt;

This model is the stock xception with a custom top (global max, dense layer, and softmax) used for image classification.
&lt;denchmark-code&gt;__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_2 (InputLayer)            [(None, 850, 550, 3) 0
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, 424, 274, 32) 864         input_2[0][0]
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, 424, 274, 32) 128         block1_conv1[0][0]
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, 424, 274, 32) 0           block1_conv1_bn[0][0]

...
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Relevant Code&lt;/denchmark-h&gt;

A runnable colab gist can be found &lt;denchmark-link:https://colab.research.google.com/gist/auchtopus/3fdb4fdecd4a4754d10951e942ecddd1/issue_43162.ipynb&gt;here&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;!git clone https://github.com/auchtopus/flowering_toy_dataset
import numpy as np
import pandas as pd
import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.applications import Xception
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Flatten, Dense, Input, GlobalAvgPool2D
from tensorflow.keras import optimizers
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import matplotlib.pyplot as plt
import random
import os
import time
from datetime import datetime
from IPython.display import SVG
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


# verify gpus
print(tensorflow.config.list_physical_devices('GPU'))


FAST_RUN = False
IMAGE_HEIGHT=850
IMAGE_WIDTH=550
IMAGE_CHANNELS=3
IMAGE_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)

input_tensor_def = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))  # unused for now


NAME = f"{datetime.today().strftime('%Y-%m-%d')}-xception_850_flowering_keras_xception"


model_core = Xception(weights = None, include_top = False, input_shape = IMAGE_SIZE)

model_head = model_core.output
model_head = GlobalAvgPool2D()(model_head)
model_head = Flatten()(model_head)
model_head = Dense(512, activation = 'relu')(model_head)
model_head = Dense(256, activation = 'relu')(model_head)
model_head = Dense(2, activation = 'softmax')(model_head)

model = Model(inputs = model_core.input, outputs = model_head)

model.compile(Adam(lr=.00005), loss='categorical_crossentropy', metrics=['accuracy'])

print(model.summary())

earlystop = EarlyStopping(patience=20)


filepath=f"/content/model/model.hdf5"
if not os.path.isdir(f"/content/model"):
  os.makedirs(f"/content/model")
checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

callbacks = [earlystop, checkpoint]


# hard coded for now, replace later
nb_train_samples = 20
# nb_validation_samples = 
batch_size=4

train_path = '/content/flowering_toy_dataset/images'
# valid_path = '/content/NEVP_phenology_unscored_20191206/images'
train_datagen = ImageDataGenerator(
    rotation_range=15,
    rescale=1./255,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
)
train_generator = train_datagen.flow_from_directory(
    train_path, target_size=IMAGE_SIZE, class_mode='categorical', classes=['flowering', 'not_flowering'], batch_size=batch_size)

# validation_datagen = ImageDataGenerator(rescale=1./255)
# validation_generator = validation_datagen.flow_from_directory(
#     valid_path, target_size=IMAGE_SIZE, class_mode='categorical', classes=['Flowering', 'Not_Flowering'], batch_size=batch_size)

# print(nb_validation_samples//batch_size)

epochs=3 if FAST_RUN else 500
history = model.fit_generator(
    train_generator,
    epochs=epochs,
    steps_per_epoch=nb_train_samples//batch_size,
    callbacks=callbacks
)

&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;My thoughts&lt;/denchmark-h&gt;

I feel like normally with broadcasting errors, it's generally related to the sizes of the images, or it fails to broadcast from a 3-dim input tensor to the 4-dim (batch, height ,width,channels) tensor. However, here, it just seems like the code has forgotten about the existence of the batch dimension and confused height for batches, width for height, and channels for both width and channels. I have double checked my code, but to my (admittedly very limited) knowledge, everything looks okay.
	</description>
	<comments>
		<comment id='1' author='auchtopus' date='2020-09-11T22:08:19Z'>
		Can you edit your example to have very minimal but runnable example to reproduce this?
		</comment>
		<comment id='2' author='auchtopus' date='2020-09-11T22:35:44Z'>
		
Can you edit your example to have very minimal but runnable example to reproduce this?

Updated!
		</comment>
		<comment id='3' author='auchtopus' date='2020-09-13T09:54:15Z'>
		It Is still depending on filesystem input. Can you have something minimal that we could just copy, paste and run?
		</comment>
		<comment id='4' author='auchtopus' date='2020-09-14T05:34:33Z'>
		&lt;denchmark-link:https://github.com/auchtopus&gt;@auchtopus&lt;/denchmark-link&gt;

I ran the code shared and face the error shared in the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/dbd8ab4a67543c6216979c49eda7ca92/untitled410.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
PLease share simple stand alone code such that we could replicate the issue or is possible share a colab gist with the issue reported.
		</comment>
		<comment id='5' author='auchtopus' date='2020-09-14T06:16:13Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 where can I host toy versions of the requisite image directories? Should I just make a public git repo with 25 images of each category (20 train, 5 test)? Or is there a better solution?
		</comment>
		<comment id='6' author='auchtopus' date='2020-09-16T06:44:56Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 I've updated the code!
A runnable colab can be found &lt;denchmark-link:https://colab.research.google.com/drive/16JidHSw5vE2FJ_c_5KbE5mDzpJR8SYRR?usp=sharing&gt;here&lt;/denchmark-link&gt;

The error log:
&lt;denchmark-code&gt;
Found 20 images belonging to 2 classes.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1799: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`Model.fit_generator` is deprecated and '

---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

&lt;ipython-input-5-ea94dcc78bee&gt; in &lt;module&gt;()
     96     epochs=epochs,
     97     steps_per_epoch=nb_train_samples//batch_size,
---&gt; 98     callbacks=callbacks
     99 )

7 frames

/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py in _get_batches_of_transformed_samples(self, index_array)
    238                 x = self.image_data_generator.apply_transform(x, params)
    239                 x = self.image_data_generator.standardize(x)
--&gt; 240             batch_x[i] = x
    241         # optionally save augmented images to disk for debugging purposes
    242         if self.save_to_dir:

ValueError: could not broadcast input array from shape (850,550,3) into shape (850,550,3,3)

&lt;/denchmark-code&gt;

This error is not localized to 2.1.0 as 2.4.0 is also throwing this error.
		</comment>
		<comment id='7' author='auchtopus' date='2020-09-16T13:00:52Z'>
		Your problem is target_size:

target_size: Either None (default to original size) or tuple of ints (img_height, img_width).

		</comment>
		<comment id='8' author='auchtopus' date='2020-09-16T16:44:07Z'>
		Thanks so much! I forgot to check the data generator, and thought the error was contained entirely in the model specification.
		</comment>
		<comment id='9' author='auchtopus' date='2020-09-16T16:44:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43162&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43162&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>