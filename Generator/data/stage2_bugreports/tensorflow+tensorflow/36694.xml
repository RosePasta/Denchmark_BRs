<bug id='36694' author='aGiant' open_date='2020-02-12T12:14:08Z' closed_time='2020-10-02T16:42:13Z'>
	<summary>Different gradient results for same custom loss function in Tensorflow 2.0</summary>
	<description>
Tensorflow 2.0 &amp; Python 3.7
&lt;denchmark-code&gt;def custom_loss2(output2, label2):
    loss_value = K.mean(binary_crossentropy(label2, output2)) 
    return loss_value
def EWC_loss(new_weights, old_weights, fisher_matrix, rate):
    sum_w = 0
    for v in range(len(fisher_matrix)):
        sum_w += tf.reduce_sum(tf.multiply(fisher_matrix[v], tf.square(new_weights[v] - old_weights[v]))) 
    return sum_w*rate
&lt;/denchmark-code&gt;

Two different trains, the same results were expected but two very different results came out.
First one, just let rate = 0.5
&lt;denchmark-code&gt;del optimizer
del tape
optimizer = tf.keras.optimizers.SGD()
ewc_model = tf.keras.models.clone_model(model)
old_weights = model.trainable_variables.copy()
for epoch in range(num_epochs):
    with tf.GradientTape() as tape:
        out = ewc_model(features_t)
        new_weights = ewc_model.trainable_variables.copy()
        ewc_loss = EWC_loss(new_weights, old_weights, fisher_matrix, 0.5)
        loss = ewc_loss + custom_loss2(out, labels_2_t)
        grad = tape.gradient(loss, ewc_model.trainable_variables)
        optimizer.apply_gradients(grads_and_vars=zip(grad, ewc_model.trainable_variables))
    if (epoch+1)%100 == 0:
        print("epch: {}, loss: {}".format(epoch, loss.numpy()))
        print(ewc_loss.numpy(), loss.numpy())
&lt;/denchmark-code&gt;

In case II, just put the factor out and let rate = 1.0 but put 0.5 to ewc_loss:
&lt;denchmark-code&gt;del optimizer
del tape
optimizer = tf.keras.optimizers.SGD()
ewc_model = tf.keras.models.clone_model(model)
old_weights = model.trainable_variables.copy()
for epoch in range(num_epochs):
    with tf.GradientTape() as tape:
        out = ewc_model(features_t)
        new_weights = ewc_model.trainable_variables.copy()
        ewc_loss = 0.5*EWC_loss(new_weights, old_weights, fisher_matrix, 1.0)
        loss = ewc_loss + custom_loss2(out, labels_2_t)
        grad = tape.gradient(loss, ewc_model.trainable_variables)
        optimizer.apply_gradients(grads_and_vars=zip(grad, ewc_model.trainable_variables))
    if (epoch+1)%100 == 0:
        print("epch: {}, loss: {}".format(epoch, loss.numpy()))
        print(ewc_loss.numpy(), loss.numpy())
&lt;/denchmark-code&gt;

Tests were with random samples, but the same for those test codes described above.
We evaluated the model using two test sets, loss = custom_loss2(prd, labels_2).
The first case returned:
&lt;denchmark-code&gt;tf.Tensor(14.144677747478463, shape=(), dtype=float64)
tf.Tensor(14.254150624518838, shape=(), dtype=float64)
&lt;/denchmark-code&gt;

but the case II returned:
&lt;denchmark-code&gt;tf.Tensor(0.15645654679566814, shape=(), dtype=float64)
tf.Tensor(0.263113701303186, shape=(), dtype=float64)
&lt;/denchmark-code&gt;

Can anyone identify this issue? If the gradient was wrong, then the risk of applying tf.GradientTape() is very high using custom loss function.
	</description>
	<comments>
		<comment id='1' author='aGiant' date='2020-02-13T05:50:43Z'>
		&lt;denchmark-link:https://github.com/aGiant&gt;@aGiant&lt;/denchmark-link&gt;
, I tried replicating the issue, but getting different error.
Please take a look at &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/bc099589a92797d7f66dedad888e0433/untitled392.ipynb&gt;gist&lt;/denchmark-link&gt;
 and provide more information to reproduce issue. Thanks!
		</comment>
		<comment id='2' author='aGiant' date='2020-02-13T08:21:49Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;

For the first run, just delete optimizer and tape like
&lt;denchmark-code&gt;# del optimizer
# del tape
&lt;/denchmark-code&gt;

Model was defined as:
&lt;denchmark-code&gt;# Input layer, one hidden layer
input_layer = Input(batch_shape=(None, 20))
dense_1 = Dense(1028)(input_layer)
output_2 = Dense(1, activation="sigmoid")(dense_1)
model = Model(inputs=input_layer, outputs= output_2)
print(model.summary())
&lt;/denchmark-code&gt;

Data was generated by
&lt;denchmark-code&gt;n_sample = 1000
fix = np.array([range(n_sample),]*20).transpose()
features = np.cos(fix + np.random.rand(n_sample,20))
labels_2 = np.cos(np.array([range(n_sample),]*1).transpose() + np.random.rand(n_sample,1))
labels_2 = np.array([labels_2&gt;=0]).astype(float)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='aGiant' date='2020-02-14T12:59:20Z'>
		
@aGiant, I tried replicating the issue, but getting different error.
Please take a look at gist and provide more information to reproduce issue. Thanks!

now the error was re-produced: &lt;denchmark-link:https://colab.research.google.com/gist/aGiant/7893ade6d21be98bebbeb91f69fc0b84/untitled392.ipynb&gt;https://colab.research.google.com/gist/aGiant/7893ade6d21be98bebbeb91f69fc0b84/untitled392.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='aGiant' date='2020-04-03T13:32:26Z'>
		I have tried on colab with TF version 2.2.0-rc2 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/e790680dd021f39d1daa0a8826c2a1ea/untitled765.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='5' author='aGiant' date='2020-04-03T16:56:16Z'>
		&lt;denchmark-link:https://github.com/aGiant&gt;@aGiant&lt;/denchmark-link&gt;
 This small mismatch in the results is due to cloning model. When you use clone a model, it instantiate a model and it creates new weights. &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model&gt;check here&lt;/denchmark-link&gt;
. Print weights for each of those two cases, you can see different weights.

Model cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers.

If you want exactly same results but wants to clone model, then you can use set_weights as follows.
ewc_model.set_weights(model.get_weights()) # add this line to use exactly same weights 
I did exactly as mentioned above and got exactly same results from both the cases. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/25e15063ea6700582e37a51945a27f11/untitled765.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Please close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='6' author='aGiant' date='2020-04-05T15:15:41Z'>
		
@aGiant This small mismatch in the results is due to cloning model. When you use clone a model, it instantiate a model and it creates new weights. check here. Print weights for each of those two cases, you can see different weights.

Model cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers.

If you want exactly same results but wants to clone model, then you can use set_weights as follows.
ewc_model.set_weights(model.get_weights()) # add this line to use exactly same weights 
I did exactly as mentioned above and got exactly same results from both the cases. Please check the gist here.
Please close the issue if this was resolved for you. Thanks!

Many thanks for your reply!
Yes, I saw the solution there and explained the results.
But the task is not to use the same weights but to get the almost the same convergent from any initial start points. In the end, the difference (abs error) between the two approaches should small enough, i.e. &lt;= 1e-6. But the re-production from &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/e790680dd021f39d1daa0a8826c2a1ea/untitled765.ipynb&gt;https://colab.research.google.com/gist/ravikyram/e790680dd021f39d1daa0a8826c2a1ea/untitled765.ipynb&lt;/denchmark-link&gt;
, error = 0.11463253099176529 &gt;&gt;1e-6.
Maybe, it's because of the SGD.
		</comment>
		<comment id='7' author='aGiant' date='2020-04-06T04:10:52Z'>
		&lt;denchmark-link:https://github.com/aGiant&gt;@aGiant&lt;/denchmark-link&gt;
 In my experience I have never seen&lt;&lt;1e-6 difference when complex custom_loss functions are used. There could be many reasons why it is .  It could be due to the custom_loss or random_weights generated at the cloning inference, or SGD, or random_samples, or data size, or numerical error etc. Thanks!
Hope this helps you. Thanks!
		</comment>
		<comment id='8' author='aGiant' date='2020-04-06T08:37:41Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

Here is another test using SGD with error &lt;= 1e-6 with many different initial start points and they all got the same error delta within the same epochs = 22.
&lt;denchmark-link:https://user-images.githubusercontent.com/25084782/78538987-24b73980-77f2-11ea-9144-9f56e16c8650.png&gt;&lt;/denchmark-link&gt;

With tensorflow 2.0, with SGD, same data, same setting till error&lt;=1e-6, it took 151 Â± n, with different initial start points, I got different epoch...
&lt;denchmark-link:https://user-images.githubusercontent.com/25084782/78539005-2b45b100-77f2-11ea-829c-2c555112a07f.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='aGiant' date='2020-09-30T01:10:45Z'>
		&lt;denchmark-link:https://github.com/aGiant&gt;@aGiant&lt;/denchmark-link&gt;
 Looks like this was resolved in recent . The losses from two approaches are same. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/7e5689d9d23203acd54f266b8e88a35d/untitled765.ipynb&gt;gist here&lt;/denchmark-link&gt;
 and let us know whether it is resolved for you or not.
Please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='10' author='aGiant' date='2020-10-02T16:42:13Z'>
		Closing this issue as this was resolved in tf-nightly. Please let us know if you face the error again, we can reopen the issue. Thanks!
		</comment>
		<comment id='11' author='aGiant' date='2020-10-02T16:42:15Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36694&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36694&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>