<bug id='39625' author='fengyang0317' open_date='2020-05-17T14:22:19Z' closed_time='2020-06-08T07:51:28Z'>
	<summary>tensorflow.python.distribute.cross_device_utils.build_collective_gather does not support TPU</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2.0
Python version: 3.7

Describe the current behavior
throw an error
Describe the expected behavior
collect tensors like running on GPUs
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import os

import tensorflow as tf
from tensorflow.python.distribute import cross_device_utils

if 'COLAB_TPU_ADDR' in os.environ:
  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
    tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
  tf.config.experimental_connect_to_cluster(resolver)
  tf.tpu.experimental.initialize_tpu_system(resolver)
  strategy = tf.distribute.experimental.TPUStrategy(resolver)
else:
  strategy = tf.distribute.MirroredStrategy()


def all_gather(context, x):
  num = context.num_replicas_in_sync
  ck = cross_device_utils.CollectiveKeys()
  x = cross_device_utils.build_collective_gather([x], num, ck)
  return x[0]


@tf.function
def step_fn():
  context = tf.distribute.get_replica_context()
  v = tf.zeros([1], tf.int32) + context.replica_id_in_sync_group
  d = all_gather(context, v)
  return d

ret = strategy.run(step_fn)
print(ret)
&lt;/denchmark-code&gt;

Other info / logs Include any logs or source code that would be helpful to
&lt;denchmark-code&gt;TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:896 replicated_fn  *
        result[0] = fn(*replica_args, **replica_kwargs)
    &lt;ipython-input-1-6f3a04d9c55b&gt;:27 step_fn  *
        d = all_gather(context, v)
    &lt;ipython-input-1-6f3a04d9c55b&gt;:19 all_gather  *
        x = cross_device_utils.build_collective_gather([x], num, ck)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_utils.py:421 build_collective_gather  **
        group_key = collective_keys.get_group_key_of_tensors(input_tensors)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_utils.py:319 get_group_key_of_tensors
        return self.get_group_key(devices)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_utils.py:299 get_group_key
        names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/cross_device_utils.py:299 &lt;listcomp&gt;
        names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])

    TypeError: %d format: a number is required, not NoneType
&lt;/denchmark-code&gt;

On a two GPUs machine, the output would be
&lt;denchmark-code&gt;PerReplica:{
  0: tf.Tensor([0 1], shape=(2,), dtype=int32),
  1: tf.Tensor([0 1], shape=(2,), dtype=int32)
}
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='fengyang0317' date='2020-06-08T07:51:28Z'>
		This API is only intended for GPUs and CPUs. If you want to do an allgather for TPUs, you can use this function: 


tensorflow/tensorflow/python/tpu/ops/tpu_ops.py


         Line 45
      in
      4e7ce79






 def all_to_all(x, 





We are planning to provide an API for allgather in the Strategy class so you don't need to use non exported functionality.
		</comment>
		<comment id='2' author='fengyang0317' date='2020-06-08T07:51:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39625&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39625&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>