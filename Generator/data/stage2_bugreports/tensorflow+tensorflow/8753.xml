<bug id='8753' author='hqqxyy' open_date='2017-03-27T13:40:46Z' closed_time='2017-04-28T13:58:05Z'>
	<summary>TFDBG 'PyFunc' is not found in partition graphs.</summary>
	<description>
When using tensorflow debugger, the program crashes with the following message :

Traceback (most recent call last):
File "farn_train.py", line 470, in 
train()
File "farn_train.py", line 448, in train
_, loss_value = sess.run([train_op, loss])
File "/home/qiqi/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/framework.py", line 470, in run
run_end_resp = self.on_run_end(run_end_req)
File "/home/qiqi/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py", line 275, in on_run_end
self._dump_root, partition_graphs=partition_graphs)
File "/home/qiqi/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py", line 524, in init
self._load_partition_graphs(partition_graphs, validate)
File "/home/qiqi/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py", line 782, in _load_partition_graphs
self._validate_dump_with_graphs()
File "/home/qiqi/anaconda2/lib/python2.7/site-packages/tensorflow/python/debug/lib/debug_data.py", line 928, in _validate_dump_with_graphs
datum.node_name)
ValueError: Node name 'PyFunc' is not found in partition graphs.

&lt;denchmark-h:h3&gt;Environment info&lt;/denchmark-h&gt;

Operating System:
Ubuntu 14.04
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):

rw-r--r-- 1 root root   560184 10月 31 11:03 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 10月 31 11:03 /usr/local/cuda/lib64/libcudart.so -&gt; libcudart.so.8.0
lrwxrwxrwx 1 root root       19 10月 31 11:03 /usr/local/cuda/lib64/libcudart.so.8.0 -&gt; libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 10月 31 11:03 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 10月 31 11:03 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 11月  5 08:55 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 11月  5 08:55 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 11月  5 08:55 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 11月  5 08:55 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:


A link to the pip package you installed:
https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl


The output from python -c "import tensorflow; print(tensorflow.__version__)".
'1.0.1'


	</description>
	<comments>
		<comment id='1' author='hqqxyy' date='2017-03-28T03:28:08Z'>
		&lt;denchmark-link:https://github.com/hqqxyy&gt;@hqqxyy&lt;/denchmark-link&gt;
 It would be most helpful if you could provide a code to reproduce this issue. Thanks.
		</comment>
		<comment id='2' author='hqqxyy' date='2017-03-28T06:55:44Z'>
		&lt;denchmark-link:https://github.com/caisq&gt;@caisq&lt;/denchmark-link&gt;

Hi, I try to reproduce this issue in the mnist example. It also wrong in line 928 of debug_data.py. But it is wrong with

ValueError: Node name 'accuracy/correct_prediction/ArgMax/dimension' is not found in partition graphs.

My code is as follows, I only change the mnist example's data_reader with tf.train.batch
&lt;denchmark-code&gt;# Copyright 2016 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""Demo of the tfdbg curses CLI: Locating the source of bad numerical values.

The neural network in this demo is larged based on the tutorial at:
  tensorflow/examples/tutorials/mnist/mnist_with_summaries.py

But modifications are made so that problematic numerical values (infs and nans)
appear in nodes of the graph during training.
"""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import sys
import numpy as np

import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.python import debug as tf_debug


IMAGE_SIZE = 28
HIDDEN_SIZE = 500
NUM_LABELS = 10
RAND_SEED = 42


def test_pyfunc(x):
    return x


def main(_):
    # Import data

    with tf.Graph().as_default():
        mnist = input_data.read_data_sets(FLAGS.data_dir,
                                          one_hot=True,
                                          fake_data=FLAGS.fake_data)

        # def feed_dict(train):
        #   if train or FLAGS.fake_data:
        #     xs, ys = mnist.train.next_batch(FLAGS.train_batch_size,
        #                                     fake_data=FLAGS.fake_data)
        #   else:
        #     xs, ys = mnist.test.images, mnist.test.labels
        #
        #   return {x: xs, y_: ys}

        images, labels = mnist.train.images, mnist.train.labels

        def get_image_label():
            ind = np.random.randint(len(images))
            return images[ind].astype(np.float32), labels[ind].astype(np.float32)

        image_tensor, label_tensor, = tf.py_func(get_image_label, [], [tf.float32, tf.float32])
        image_tensor.set_shape((IMAGE_SIZE ** 2, ))
        label_tensor.set_shape((NUM_LABELS, ))

        x, y_ = tf.train.batch([image_tensor, label_tensor],
                               batch_size=FLAGS.train_batch_size,
                               num_threads=2)


        # Create the MNIST neural network graph.

        # # Input placeholders.
        # with tf.name_scope("input"):
        #   x = tf.placeholder(
        #       tf.float32, [None, IMAGE_SIZE * IMAGE_SIZE], name="x-input")
        #   y_ = tf.placeholder(tf.float32, [None, NUM_LABELS], name="y-input")


        def weight_variable(shape):
            """Create a weight variable with appropriate initialization."""
            initial = tf.truncated_normal(shape, stddev=0.1, seed=RAND_SEED)
            return tf.Variable(initial)

        def bias_variable(shape):
            """Create a bias variable with appropriate initialization."""
            initial = tf.constant(0.1, shape=shape)
            return tf.Variable(initial)

        def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):
            """Reusable code for making a simple neural net layer."""
            # Adding a name scope ensures logical grouping of the layers in the graph.
            with tf.name_scope(layer_name):
                # This Variable will hold the state of the weights for the layer
                with tf.name_scope("weights"):
                    weights = weight_variable([input_dim, output_dim])
                with tf.name_scope("biases"):
                    biases = bias_variable([output_dim])
                with tf.name_scope("Wx_plus_b"):
                    preactivate = tf.matmul(input_tensor, weights) + biases

                activations = act(preactivate)
                return activations

        hidden = nn_layer(x, IMAGE_SIZE**2, HIDDEN_SIZE, "hidden")
        y = nn_layer(hidden, HIDDEN_SIZE, NUM_LABELS, "softmax", act=tf.nn.softmax)

        with tf.name_scope("cross_entropy"):
            # The following line is the culprit of the bad numerical values that appear
            # during training of this graph. Log of zero gives inf, which is first seen
            # in the intermediate tensor "cross_entropy/Log:0" during the 4th run()
            # call. A multiplication of the inf values with zeros leads to nans,
            # which is first in "cross_entropy/mul:0".
            #
            # You can use clipping to fix this issue, e.g.,
            #   diff = y_ * tf.log(tf.clip_by_value(y, 1e-8, 1.0))

            diff = y_ * tf.log(y)
            with tf.name_scope("total"):
                cross_entropy = -tf.reduce_mean(diff)

        with tf.name_scope("train"):
            train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(
                cross_entropy)

        with tf.name_scope("accuracy"):
            with tf.name_scope("correct_prediction"):
                correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
            with tf.name_scope("accuracy"):
                accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        sess = tf.Session(config=tf.ConfigProto(
            allow_soft_placement=True))
        sess.run(tf.global_variables_initializer())

        if FLAGS.debug:
            sess = tf_debug.LocalCLIDebugWrapperSession(sess, ui_type=FLAGS.ui_type)
            sess.add_tensor_filter("has_inf_or_nan", tf_debug.has_inf_or_nan)

        tf.train.start_queue_runners(sess=sess)

        # Add this point, sess is a debug wrapper around the actual Session if
        # FLAGS.debug is true. In that case, calling run() will launch the CLI.
        for i in range(FLAGS.max_steps):
            acc = sess.run(accuracy)
            print("Accuracy at step %d: %s" % (i, acc))

            sess.run(train_step)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.register("type", "bool", lambda v: v.lower() == "true")
    parser.add_argument(
        "--max_steps",
        type=int,
        default=10,
        help="Number of steps to run trainer.")
    parser.add_argument(
        "--train_batch_size",
        type=int,
        default=100,
        help="Batch size used during training.")
    parser.add_argument(
        "--learning_rate",
        type=float,
        default=0.025,
        help="Initial learning rate.")
    parser.add_argument(
        "--data_dir",
        type=str,
        default="/tmp/mnist_data",
        help="Directory for storing data")
    parser.add_argument(
        "--ui_type",
        type=str,
        default="curses",
        help="Command-line user interface type (curses | readline)")
    parser.add_argument(
        "--fake_data",
        type="bool",
        nargs="?",
        const=True,
        default=False,
        help="Use fake MNIST data for unit testing")
    parser.add_argument(
        "--debug",
        type="bool",
        nargs="?",
        const=True,
        default=False,
        help="Use debugger to track down bad values during training")
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='hqqxyy' date='2017-03-30T20:17:59Z'>
		&lt;denchmark-link:https://github.com/hqqxyy&gt;@hqqxyy&lt;/denchmark-link&gt;
 , the reason for the weirdness you are seeing is because your session is used in a multi-threaded way, which is not amenable to command-line interface debugging. Particularly, you do,
tf.train.start_queue_runners(sess=sess)
after you wrap sess with LocalCLIDebugWrapperSession.
So the program will try to launch the debugger CLI from at least 3 threads (two for your queue runners and one for your main thread that runs the train_step op).
To workaround this problem, you can call start_queue_runners first, and then wrap the sess, e.g.,
tf.train.start_queue_runners(sess=sess)

if FLAGS.debug:
    sess = tf_debug.LocalCLIDebugWrapperSession(sess, ui_type=FLAGS.ui_type)
    sess.add_tensor_filter("has_inf_or_nan", tf_debug.has_inf_or_nan)
This will let the debugger CLI run only on the main (training) thread. This solution assumes that you don't want to debug the data queue threads. But you do want to debug those, let me know and I can provide more info.
I'll leave this bug open for now to remind myself to provide better documentation for this sort of issues.
		</comment>
		<comment id='4' author='hqqxyy' date='2017-04-28T13:58:05Z'>
		Update: LocalCLIDebugWrapperSesion now has a new keyword argument that allows you to make the debugger CLI active only on selected threads. It is called thread_name_filter. For example, the following line will make the debugger CLI launch only for session.run() calls on the main thread.
sess = tf_debug.LocalCLIDebugWrapperSession(sess, thread_name_filter="MainThread$")
For more details, please see doc at:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/eb6d9d9685c0a4be542522acf5cb3f6226a7858a#diff-1c3529a3243c362193b85b6689aa24d3&gt;eb6d9d9#diff-1c3529a3243c362193b85b6689aa24d3&lt;/denchmark-link&gt;

This is not available in 1.1, but will be in 1.2.
		</comment>
	</comments>
</bug>