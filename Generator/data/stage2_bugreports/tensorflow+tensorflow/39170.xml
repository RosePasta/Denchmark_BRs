<bug id='39170' author='rposts' open_date='2020-05-04T23:09:58Z' closed_time='2020-06-05T16:45:17Z'>
	<summary>"shuffle_and_repeat_fusion" optimizer content incorrect on s390x arch (big-endian)</summary>
	<description>

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): - s390x Ubuntu 18.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below):  v2.2.0-rc4-0-g70087ab4f4 2.2.0-rc4
Python version: Python 3.6.9
Bazel version (if compiling from source): Build label: 2.0.0- (@non-git)
Build target: bazel-out/s390x-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
GCC/Compiler version (if compiling from source): gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
When running Tensorflow test cases on s390x, several hundred testcase fail with the following error:
/==========================/
[ RUN      ]
...
ShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion_test_mode_eager_tfapiversion_2
2020-04-30 19:20:21.809298: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at optimize_dataset_op.cc:66 : Internal: Tried to register a dataset optimizer that doesn't exist:
/==========================/
Describe the expected behavior
"shuffle_and_repeat_fusion" optimizer should be correctly identified on s390x
Standalone code to reproduce the issue
On s390x system, run the following test case:
"python tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py"
The problem seems to occur when tensorflow/core/kernels/data/optimize_dataset_op.cc tries to OptimizeDatasetOp::MakeDataset for "shuffle_and_repeat_fusion" optimizer.  On s390x arch, optimization content is incorrect:
On s390x:
/================================/
(gdb) p optimizations
$3 = std::vector of length 1, capacity 1 = {{tstr_ = {u = {smll = {size = 0 '\000',
str = "\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\266;"}, large = { size = 101, cap = 47, ptr = 0x3b63b60 "shuffle_and_repeat_fusion"}, offset = {size = 0, offset = 101, count = 0}, view = {size = 101, ptr = 0x2f &lt;error: Cannot access memory at address 0x2f&gt;}, raw = { raw = "\000\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\266;"}}}}}
/================================/
On x86:
/===============================/
(gdb) p optimizations
$65 = {tstr_ = {u = {smll = {size = 101 'e',
str = "\000\000\000\000\000\000\000/\000\000\000\000\000\000\000\250\202\004\000\000\000"}, large = {size = 101, cap = 47, ptr = 0x482a860 "shuffle_and_repeat_fusion"}, offset = {size = 101, offset = 0, count = 47}, view = { size = 101, ptr = 0x2f &lt;error: Cannot access memory at address 0x2f&gt;}, raw = { raw = "e\000\000\000\000\000\000\000/\000\000\000\000\000\000\000\250\202\004\000\000\000"}}}}
/===============================/
As we can see, size  is incorrectly extracted on s390x.  It is very likely that optimization contents need to be endian sensitive.  Specifically positioning of "000e" looks suspect.
I looked at shuffle_and_repeat_fusion.cc to get an idea but couldn't nail down where this is set.
Any pointers appreciated.
Thanks.
	</description>
	<comments>
		<comment id='1' author='rposts' date='2020-05-05T10:37:30Z'>
		&lt;denchmark-link:https://github.com/rposts&gt;@rposts&lt;/denchmark-link&gt;

Can you please share simple stand alone code for us to replicate your issue, or if possible share a colab gist for us to analyse the issue faced
		</comment>
		<comment id='2' author='rposts' date='2020-05-05T12:53:07Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 , please see the stripped down version of test case:
&lt;denchmark-code&gt;from tensorflow.python.data.kernel_tests import test_base
from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.platform import test

class ShuffleAndRepeatFusionTest(test_base.DatasetTestBase):

  def testShuffleAndRepeatFusion(self):
    dataset = dataset_ops.Dataset.range(10)
    get_next = self.getNext(dataset)

if __name__ == "__main__":
  test.main()
&lt;/denchmark-code&gt;

When get_next line is executed, following error is thrown on s390x:
&lt;denchmark-code&gt;root@3cefe6d659f6:/home/tensorflow# python tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py
Running tests under Python 3.6.9: /usr/bin/python
[ RUN      ] ShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion
2020-05-05 12:35:25.925871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:106] Failed to find bogomips or clock in /proc/cpuinfo; cannot determine CPU frequency
2020-05-05 12:35:25.931876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x414fe030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-05-05 12:35:25.931914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-05-05 12:35:25.940079: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at optimize_dataset_op.cc:66 : Internal: Tried to register a dataset optimizer that doesn't exist:
[  FAILED  ] ShuffleAndRepeatFusionTest.testShuffleAndRepeatFusion
[ RUN      ] ShuffleAndRepeatFusionTest.test_session
[  SKIPPED ] ShuffleAndRepeatFusionTest.test_session
======================================================================
ERROR: testShuffleAndRepeatFusion (__main__.ShuffleAndRepeatFusionTest)
testShuffleAndRepeatFusion (__main__.ShuffleAndRepeatFusionTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "tensorflow/python/data/experimental/kernel_tests/optimization/shuffle_and_repeat_fusion_test.py", line 25, in testShuffleAndRepeatFusion
    get_next = self.getNext(dataset)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/kernel_tests/test_base.py", line 109, in getNext
    iterator = iter(dataset)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py", line 404, in __iter__
    return iterator_ops.OwnedIterator(self)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py", line 595, in __init__
    self._create_iterator(dataset)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py", line 601, in _create_iterator
    dataset = dataset._apply_options()
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py", line 375, in _apply_options
    graph_rewrite_configs)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py", line 4365, in __init__
    **self._flat_structure)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py", line 3690, in optimize_dataset
    _ops.raise_from_not_ok_status(e, name)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py", line 6653, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File "&lt;string&gt;", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: **Tried to register a dataset optimizer that doesn't exist:  [Op:OptimizeDataset]**

----------------------------------------------------------------------
Ran 2 tests in 0.029s

FAILED (errors=1, skipped=1)
&lt;/denchmark-code&gt;

In this case default optimizers are included and as you can see, shuffle_and_repeat_fusion entry in the post parse of OptimizeDatasetOp::MakeDatasetappears to be off which ultimately leads to Tried to register a dataset optimizer that doesn't exist: error:
&lt;denchmark-code&gt;(gdb) p optimizations[0]
$3 = {tstr_ = {u = {smll = {size = 80 'P', str = "map_and_batch_fusion\000\000"}, large = {
        size = 5795395430760148580, cap = 6873163133832683366,
        ptr = 0x7573696f6e000000 &lt;error: Cannot access memory at address 0x7573696f6e000000&gt;}, offset = {
        size = 1349345648, offset = 1600220772, count = 1600282996}, view = {size = 5795395430760148580,
        ptr = 0x5f62617463685f66 &lt;error: Cannot access memory at address 0x5f62617463685f66&gt;}, raw = {
        raw = "Pmap_and_batch_fusion\000\000"}}}}
(gdb) p optimizations[1]
$4 = {tstr_ = {u = {smll = {size = 64 '@', str = "noop_elimination\000\000\000\000\000\000"}, large = {
        size = 4642770790282913132, cap = 7596844069246232943,
        ptr = 0x6e00000000000000 &lt;error: Cannot access memory at address 0x6e00000000000000&gt;}, offset = {
        size = 1080979311, offset = 1885300076, count = 1768778094}, view = {size = 4642770790282913132,
        ptr = 0x696d696e6174696f &lt;error: Cannot access memory at address 0x696d696e6174696f&gt;}, raw = {
        raw = "@noop_elimination\000\000\000\000\000\000"}}}}
(gdb) p optimizations[2]
$5 = {tstr_ = {u = {smll = {size = 0 '\000',
        str = "\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\265\063"}, large = {
        size = 101, cap = 47, ptr = 0x3b53300 "shuffle_and_repeat_fusion"}, offset = {size = 0, offset = 101,
        count = 0}, view = {size = 101, ptr = 0x2f &lt;error: Cannot access memory at address 0x2f&gt;}, raw = {
        raw = "\000\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\265\063"}}}}

&lt;/denchmark-code&gt;

Please let me know if you need more information.
Thanks.
		</comment>
		<comment id='3' author='rposts' date='2020-05-06T05:05:25Z'>
		&lt;denchmark-link:https://github.com/rposts&gt;@rposts&lt;/denchmark-link&gt;

I ran the code shared by you and face a difference error, please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/8b2af10eb69b36123c9f389447566384/untitled163.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='rposts' date='2020-05-06T13:54:27Z'>
		This appears to be a colab issue : &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17702&gt;#17702&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='rposts' date='2020-05-06T20:39:14Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 - I tried this in colab and no longer complains about the error you encountered
&lt;denchmark-code&gt;import tensorflow as tf
from tensorflow.python.data.kernel_tests import test_base
from tensorflow.python.data.ops import dataset_ops
from tensorflow.python.platform import test
tf.compat.v1.app.flags.DEFINE_string('f', '', 'kernel')
class ShuffleAndReplaceFusion(test_base.DatasetTestBase):
  def testShuffleAndRepeatFusion(self):
    dataset = dataset_ops.Dataset.range(10)
    get_next = self.getNext(dataset)

if __name__ == "__main__":
  test.main()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='rposts' date='2020-05-07T05:35:02Z'>
		&lt;denchmark-link:https://github.com/rposts&gt;@rposts&lt;/denchmark-link&gt;

I ran the above code and face the error as per &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/a7a090504bafa81d2c761e501dd15061/untitled167.ipynb&gt;this gist&lt;/denchmark-link&gt;
, please confirm.
		</comment>
		<comment id='7' author='rposts' date='2020-05-07T12:15:43Z'>
		Yes - that is correct.  However, the problem here is not that this stripped down version of testcase fails, but that shuffle_and_repeat_fusion optimizer content that is retrieved on s390x is incorrect. This content appears to be in little-endian format and needs to be corrected for big-endian.
I wonder how dataset_ops optimization section is built.  Is this a static value that is obtained from pre-existing dataset?  If so, where does it come from.  I looked at dataset_ops.py but couldn't spot a section where these optimizations are built.
		</comment>
		<comment id='8' author='rposts' date='2020-05-12T02:16:49Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/experimental/ops/optimization_options.py#L215-L257&gt;Here&lt;/denchmark-link&gt;
 is the method that computes which static optimizations to use. In particular,  is treated identically to  and , which makes me think that this is not related to  but to the "last" optimization. To double check that, try reordering the  list and see if the problem still occurs for .
		</comment>
		<comment id='9' author='rposts' date='2020-05-12T12:56:15Z'>
		Thanks &lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 . I already tried that to no avail.  Here are my changes and the resulting output after rebuilding TF and reinstalling the wheel.
&lt;denchmark-code&gt;diff --git a/tensorflow/python/data/experimental/ops/optimization_options.py b/tensorflow/python/data/experimental/ops/optimization_options.py
index 5db4db91c1..8ef3ccfa40 100644
--- a/tensorflow/python/data/experimental/ops/optimization_options.py
+++ b/tensorflow/python/data/experimental/ops/optimization_options.py
@@ -222,10 +222,10 @@ class OptimizationOptions(options.OptionsBase):
         "map_and_batch_fusion",
         "map_and_filter_fusion",
         "map_parallelization",
+        "shuffle_and_repeat_fusion",
         "map_fusion",
         "noop_elimination",
         "parallel_batch",
-        "shuffle_and_repeat_fusion",
     ]
     for optimization in all_optimizations:
       if getattr(self, optimization):
@@ -235,9 +235,9 @@ class OptimizationOptions(options.OptionsBase):
       # The following optimizations are turned on by default, unless the user
       # explicitly disables them.
       optimizations_to_disable = [
+          "shuffle_and_repeat_fusion",
           "map_and_batch_fusion",
           "noop_elimination",
-          "shuffle_and_repeat_fusion",
       ]
       for optimization in optimizations_to_disable:
         if getattr(self, optimization) is not False:
&lt;/denchmark-code&gt;

Optimizations:
&lt;denchmark-code&gt;(gdb) p optimizations[0]
$4 = {tstr_ = {u = {smll = {size = 80 'P', str = "map_and_batch_fusion\000\000"}, large = {
        size = 5795395430760148580, cap = 6873163133832683366,
        ptr = 0x7573696f6e000000 &lt;error: Cannot access memory at address 0x7573696f6e000000&gt;}, offset = {
        size = 1349345648, offset = 1600220772, count = 1600282996}, view = {size = 5795395430760148580,
        ptr = 0x5f62617463685f66 &lt;error: Cannot access memory at address 0x5f62617463685f66&gt;}, raw = {
        raw = "Pmap_and_batch_fusion\000\000"}}}}
(gdb) p optimizations[1]
$5 = {tstr_ = {u = {smll = {size = 64 '@', str = "noop_elimination\000\000\000\000\000\000"}, large = {
        size = 4642770790282913132, cap = 7596844069246232943,
        ptr = 0x6e00000000000000 &lt;error: Cannot access memory at address 0x6e00000000000000&gt;}, offset = {
        size = 1080979311, offset = 1885300076, count = 1768778094}, view = {size = 4642770790282913132,
        ptr = 0x696d696e6174696f &lt;error: Cannot access memory at address 0x696d696e6174696f&gt;}, raw = {
        raw = "@noop_elimination\000\000\000\000\000\000"}}}}
(gdb) p optimizations[2]
$6 = {tstr_ = {u = {smll = {size = 0 '\000',
        str = "\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\265.\260"}, large = {
        size = 101, cap = 47, ptr = 0x3b52eb0 "shuffle_and_repeat_fusion"}, offset = {size = 0, offset = 101,
        count = 0}, view = {size = 101, ptr = 0x2f &lt;error: Cannot access memory at address 0x2f&gt;}, raw = {
        raw = "\000\000\000\000\000\000\000e\000\000\000\000\000\000\000/\000\000\000\000\003\265.\260"}}}}
&lt;/denchmark-code&gt;

I am beginning to suspect the way  are built -   &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc#L51&gt;here &lt;/denchmark-link&gt;
  for   contain this value:
&lt;denchmark-code&gt;  ["shuffle_and_repeat_fusion"] = {&lt;std::_Maybe_unary_or_binary_function&lt;tensorflow::grappler::CustomGraphOptimizer*&gt;&gt; = {&lt;No data fields&gt;}, &lt;std::_Function_base&gt; = {static _M_max_size = 16, static _M_max_align = 8, _M_functor = {
        _M_unused = {_M_object = 0x1ddd698, _M_const_object = 0x1ddd698, _M_function_pointer = 0x1ddd698,
          _M_member_pointer = (void (std::_Undefined_class::*)(std::_Undefined_class * const)) 0x1ddd698},
        _M_pod_data = "\000\000\000\000\001\335\326\230\000\000\000\000\000\000\000"},
      _M_manager = 0x3fff417c080 &lt;std::_Function_base::_Base_manager&lt;tensorflow::grappler::(anonymous namespace)::&lt;lambda()&gt; &gt;::_M_manager(std::_Any_data &amp;, const std::_Any_data &amp;, std::_Manager_operation)&gt;},
    _M_invoker = 0x3fff417c0b8 &lt;std::_Function_handler&lt;tensorflow::grappler::CustomGraphOptimizer*(), tensorflow::grappler::(anonymous namespace)::&lt;lambda()&gt; &gt;::_M_invoke(const std::_Any_data &amp;)&gt;}}

&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='rposts' date='2020-05-12T19:04:25Z'>
		I think I found the problem ... On big-endian system  is not being calculated correctly for "large" strings. &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/platform/ctstring_internal.h#L184&gt;This &lt;/denchmark-link&gt;
always gets executed under small string size assumption.
Now I need to figure out where the fix needs to go.
		</comment>
		<comment id='11' author='rposts' date='2020-05-13T12:39:21Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 - it seems like problem also exist on x86 arch wrt . However, I suspect it does not surface due to endiness of the architecture.
If I am comprehending the code correctly then formation of TF_TString_Raw raw for shuffle_and_repeat_fusion is incorrect.  [TF_TString_Raw](


tensorflow/tensorflow/core/platform/ctstring_internal.h


         Line 101
      in
      53b0f6f






 typedef struct TF_TString_Raw {  // NOLINT 




) is defined to hold 24 uint8_t type but the length of shuffle_and_repeat_fusion is 25 and causes a sort of "spill" which is problematic on s390x as the [raw[0]](


tensorflow/tensorflow/core/platform/ctstring_internal.h


         Line 139
      in
      53b0f6f






 extern inline TF_TString_Type TF_TString_GetType(const TF_TString *str) { 




) character is expected to hold the TF_TString_Type.  On x86 str-&gt;u.raw.raw[0] manages to retain the string type marker which causes the test cases to pass.  However, if you compare the raw string contents of shuffle_and_repeat_fusion on x86 to other optimizers then you will notice that raw contents are incorrect.  For example:
&lt;denchmark-code&gt;raw = "Pmap_and_batch_fusion\000\377\377"  &lt;--- This is for map_and_batch_fusion optimizer
raw = "e\000\000\000\000\000\000\000/\000\000\000\000\000\000\000`\250\202\004\000\000\000" &lt;--- This is for shuffle_and_repeat_fusion optimizer
&lt;/denchmark-code&gt;

In my case I have "fixed" this discrepancy by extending the raw array size to 32 bytes:
&lt;denchmark-code&gt;diff --git a/tensorflow/core/platform/ctstring_internal.h b/tensorflow/core/platform/ctstring_internal.h
index 5f9d88d536..cfa58a66ad 100644
--- a/tensorflow/core/platform/ctstring_internal.h
+++ b/tensorflow/core/platform/ctstring_internal.h
@@ -99,7 +99,7 @@ typedef struct TF_TString_View {  // NOLINT
 } TF_TString_View; typedef struct TF_TString_Raw {  // NOLINT
-  uint8_t raw[24];
+  uint8_t raw[32];
 } TF_TString_Raw; typedef union TF_TString_Union {  // NOLINT
&lt;/denchmark-code&gt;

Do you think this change makes sense?
Thanks.
		</comment>
		<comment id='12' author='rposts' date='2020-05-14T21:52:07Z'>
		adding &lt;denchmark-link:https://github.com/gharibian&gt;@gharibian&lt;/denchmark-link&gt;
 as he is more familiar with TensorFlow strings
		</comment>
		<comment id='13' author='rposts' date='2020-05-14T22:04:20Z'>
		
Do you think this change makes sense?

No, extending to 32bytes is not an appropriate solution as it would increase the string struct overhead by 33%.  We need to look into why s390x is computing a 25byte struct.  Let me see if I can get access to a s390x machine so that I can recreate the issue.
		</comment>
		<comment id='14' author='rposts' date='2020-05-15T11:54:27Z'>
		&lt;denchmark-link:https://github.com/gharibian&gt;@gharibian&lt;/denchmark-link&gt;
 - I think we may have found the source of these issues.  appears to be using macros incorrectly when determining the endiness.  Following changes have addressed our issues and brought down failures down to 65 as of now:
&lt;denchmark-code&gt;diff --git a/tensorflow/core/platform/ctstring_internal.h b/tensorflow/core/platform/ctstring_internal.h
index 5f9d88d536..69338e6e4b 100644
--- a/tensorflow/core/platform/ctstring_internal.h
+++ b/tensorflow/core/platform/ctstring_internal.h
@@ -145,7 +145,7 @@ extern inline TF_TString_Type TF_TString_GetType(const TF_TString *str) {
 // and always byte-swapping on big endian, resulting in a simple 'bswap'+'shr'
 // (for architectures that have a bswap op).
 static inline size_t TF_TString_ToActualSizeT(size_t size) {
-#ifdef TF_TSTRING_LITTLE_ENDIAN
+#if TF_TSTRING_LITTLE_ENDIAN
   return size &gt;&gt; 2;
 #else   // TF_TSTRING_LITTLE_ENDIAN
   // 0xFF000000 or 0xFF00000000000000 depending on platform
@@ -157,7 +157,7 @@ static inline size_t TF_TString_ToActualSizeT(size_t size) { static inline size_t TF_TString_ToInternalSizeT(size_t size,
                                                 TF_TString_Type type) {
-#ifdef TF_TSTRING_LITTLE_ENDIAN
+#if TF_TSTRING_LITTLE_ENDIAN
   return (size &lt;&lt; 2) | type;
 #else   // TF_TSTRING_LITTLE_ENDIAN
   // 0xFF000000 or 0xFF00000000000000 depending on platform
&lt;/denchmark-code&gt;

		</comment>
		<comment id='15' author='rposts' date='2020-05-15T16:37:52Z'>
		That is definitely a bug, please feel free to submit that patch.  I'm currently blocked on getting bazel bootstrapped on s390x.  In parallel, I'm trying to run the ctstring tests outside of TF on s390x in order to surface any other potential issues..
		</comment>
		<comment id='16' author='rposts' date='2020-05-15T16:40:42Z'>
		Thank you.  We will proceed with PR.
		</comment>
		<comment id='17' author='rposts' date='2020-06-02T19:58:48Z'>
		
Thank you. We will proceed with PR.

Hi Rishi,
Any update on getting the 'cstring_internal.h' fix PR? I'd like to get it in as it is a legitimate bug.  Otherwise, I can submit the change on my end and credit you.  Please let me know.
		</comment>
		<comment id='18' author='rposts' date='2020-06-02T20:05:00Z'>
		Hi &lt;denchmark-link:https://github.com/gharibian&gt;@gharibian&lt;/denchmark-link&gt;
 - we are trying to get master built on s390x before submitting the PR but master build is causing issues.  Please go ahead and submit the PR and credit &lt;denchmark-link:https://github.com/cdavoudian&gt;@cdavoudian&lt;/denchmark-link&gt;
.  Thanks so much!
		</comment>
		<comment id='19' author='rposts' date='2020-06-05T16:45:17Z'>
		Closing - fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/206dc37a33bf34a1a79dd56e19fb7b1c6cdf5dc6&gt;206dc37&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='20' author='rposts' date='2020-06-05T16:45:19Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39170&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39170&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>