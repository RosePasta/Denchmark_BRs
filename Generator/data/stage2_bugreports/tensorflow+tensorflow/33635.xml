<bug id='33635' author='srihari-humbarwadi' open_date='2019-10-23T10:49:27Z' closed_time='2019-11-21T18:50:41Z'>
	<summary>Adding regularization losses to models after they are built does not show up in model.losses</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
TensorFlow version (use command below): 2.0
Python version: 3.6

Describe the current behavior
For a prebuilt model, for example, keras_applications models and other models if they are already built, manually adding regularization to layers does not show up in model.losses
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
print('TensorFlow', tf.__version__)

'''
Case 1: Simple model without any regularization
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu')(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu')(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None)(x)
model_a = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

assert model_a.losses == []


'''
Case 2: Simple model with regularization added
        during layer creation
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu',
                          kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu', 
                          kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None, 
                                     kernel_regularizer=tf.keras.regularizers.l2(l=1e-5))(x)
model_b = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

assert model_b.losses != []


'''
Case 3: For a prebuilt model, for example, keras_applications models
        and other models if they are already built, manually adding regularization
        to layers does not show up in model.losses
'''
input_layer = tf.keras.Input(shape=[10])
x = tf.keras.layers.Dense(units=16, activation='relu')(input_layer)
x = tf.keras.layers.Dense(units=16, activation='relu')(x)
output_layer = tf.keras.layers.Dense(units=4, activation=None)(x)
model_c = tf.keras.Model(inputs=[input_layer], outputs=[output_layer])

for layer in model_c.layers:
    if hasattr(layer, 'kernel_regularizer'):
        setattr(layer, 'kernel_regularizer', tf.keras.regularizers.l2(l=1e-5))
        
for layer in model_c.layers:
    if hasattr(layer, 'kernel_regularizer'):
        assert getattr(layer, 'kernel_regularizer').l2 == np.array([1e-5], dtype='float32')
        
assert model_c.losses == []
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='srihari-humbarwadi' date='2019-10-23T11:03:00Z'>
		The only workaround i found was this
&lt;denchmark-code&gt;model = tf.keras.applications.ResNet50()
for layer in model.layers:
    if hasattr(layer, 'kernel_regularizer'):
        setattr(layer, 'kernel_regularizer', tf.keras.regularizers.l2(l=1e-5))
        
for layer in model.layers:
    if hasattr(layer, 'kernel_regularizer'):
        assert getattr(layer, 'kernel_regularizer').l2 == np.array([1e-5], dtype='float32')
        
assert model.losses == []
model.save_weights('resnet50.h5', save_format='h5')

new_model = tf.keras.models.model_from_json(model.to_json())
# new_model would have random weights
new_model.load_weights('resnet50.h5')
assert new_model.losses != [] #works fine
&lt;/denchmark-code&gt;

Is there a cleaner way to do this?
&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='srihari-humbarwadi' date='2019-10-24T06:03:07Z'>
		I could reproduce the issue with Tf 2.0.
Please see the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/c48b5c0f69ac9428879296a0ffe73440/untitled222.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='srihari-humbarwadi' date='2019-11-11T08:05:35Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 any updates?
		</comment>
		<comment id='4' author='srihari-humbarwadi' date='2019-11-21T18:50:35Z'>
		In general, we wouldn't advise checking and setting the regularizer manually. Please use the add_loss API instead: &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#add_loss&gt;https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#add_loss&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='srihari-humbarwadi' date='2019-11-21T18:50:42Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33635&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33635&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>