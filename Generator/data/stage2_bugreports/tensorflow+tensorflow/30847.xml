<bug id='30847' author='michaelbenayoun' open_date='2019-07-18T16:12:29Z' closed_time='2020-04-18T07:35:22Z'>
	<summary>DistributedDataset iteration fails with data of type string</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.5 LTS
TensorFlow installed from (source or binary): conda
TensorFlow version (use command below): 1.14.0
Python version: 3.6.8
CUDA/cuDNN version: 10.0
GPU model and memory: 8 x Tesla P100-PCIE-16GB

Describe the current behavior
I have noticed an issue while iterating over a DistributedDataset (using a tf.distribute.MirroredStrategy) that contains data of type string, with eager execution enabled.
Iterating works perfectly well, but a RuntimeError is raised once the end of the dataset is reached (cf logs below).
Describe the expected behavior
The exception is never raised if the dataset does not contain string data, iteration stops and the rest of the code is executed.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
tf.enable_eager_execution()
print('TensorFlow version: {}'.format(tf.__version__))

raw = tf.random.uniform([256, 20], maxval=10, dtype=tf.int32)

strategy = tf.distribute.MirroredStrategy()
print('Number of replicas: {}'.format(strategy.num_replicas_in_sync))

dataset_1 = tf.data.Dataset.from_tensor_slices(raw)
dataset_1 = dataset_1.batch(64)

dataset_2 = tf.data.Dataset.from_tensors(['This is a test']).repeat(256).batch(64)

dist_dataset_1 = strategy.experimental_distribute_dataset(dataset_1)
dist_dataset_2 = strategy.experimental_distribute_dataset(dataset_2)

print('Iterating over datataset_2')
for i, example in enumerate(dataset_2):
    print('Batch #{}'.format(i))

print('Iterating over distributed dataset_1')
for i, example in enumerate(dist_dataset_1):
    print('Batch #{}'.format(i))
    
print('Iterating over distributed datataset_2')
for i, example in enumerate(dist_dataset_2):
    print('Batch #{}'.format(i))
&lt;/denchmark-code&gt;

Other info / logs
&lt;denchmark-code&gt;TensorFlow version: 1.14.0
Number of replicas: 8
Iterating over datataset_2
Batch #0
Batch #1
Batch #2
Batch #3
Iterating over distributed dataset_1
Batch #0
Batch #1
Batch #2
Batch #3
Iterating over distributed datataset_2
Batch #0
Batch #1
Batch #2
Batch #3
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-18-730d6b0450e9&gt; in &lt;module&gt;
     25 
     26 print('Iterating over distributed datataset_2')
---&gt; 27 for i, example in enumerate(dist_dataset_2):
     28     print('Batch #{}'.format(i))

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in __next__(self)
    225   def __next__(self):
    226     try:
--&gt; 227       return self.get_next()
    228     except errors.OutOfRangeError:
    229       raise StopIteration

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in get_next(self, name)
    254       return data
    255 
--&gt; 256     global_has_value, replicas = _get_next_as_optional(self, self._strategy)
    257     results = []
    258     for i, worker in enumerate(self._input_workers.worker_devices):

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in _get_next_as_optional(iterator, strategy, name)
    160     with ops.device(worker):
    161       worker_has_value, next_element = (
--&gt; 162           iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access
    163       # Collective all-reduce requires explict devices for inputs.
    164       with ops.device("/cpu:0"):

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in get_next_as_list(***failed resolving arguments***)
    719               data.has_value(),
    720               lambda: data.get_value(),
--&gt; 721               lambda: _dummy_tensor_fn(data.value_structure))
    722           result.append(real_data)
    723           # pylint: enable=cell-var-from-loop

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--&gt; 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py in cond(pred, true_fn, false_fn, strict, name, fn1, fn2)
   1955         result = true_fn()
   1956       else:
-&gt; 1957         result = false_fn()
   1958       if not strict:
   1959         result = _UnpackIfSingleton(result)

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in &lt;lambda&gt;()
    719               data.has_value(),
    720               lambda: data.get_value(),
--&gt; 721               lambda: _dummy_tensor_fn(data.value_structure))
    722           result.append(real_data)
    723           # pylint: enable=cell-var-from-loop

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in _dummy_tensor_fn(value_structure)
    637   for feature_shape, feature_type in zip(value_structure._flat_shapes,
    638                                          value_structure._flat_types):
--&gt; 639     result.append(create_dummy_tensor(feature_shape, feature_type))
    640 
    641   if isinstance(value_structure, structure.NestedStructure):

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/distribute/input_lib.py in create_dummy_tensor(feature_shape, feature_type)
    630 
    631     # Create the dummy tensor.
--&gt; 632     dummy_tensor = array_ops.zeros(tensor_shape.TensorShape(dims), feature_type)
    633     return dummy_tensor
    634 

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in zeros(shape, dtype, name)
   1869         # Create a constant if it won't be very big. Otherwise create a fill op
   1870         # to prevent serialized GraphDefs from becoming too large.
-&gt; 1871         output = _constant_if_small(zero, shape, dtype, name)
   1872         if output is not None:
   1873           return output

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in _constant_if_small(value, shape, dtype, name)
   1827   try:
   1828     if np.prod(shape) &lt; 1000:
-&gt; 1829       return constant(value, shape=shape, dtype=dtype, name=name)
   1830   except TypeError:
   1831     # Happens when shape is a Tensor, list with Tensor elements, etc.

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    244   """
    245   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--&gt; 246                         allow_broadcast=True)
    247 
    248 

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    252   ctx = context.context()
    253   if ctx.executing_eagerly():
--&gt; 254     t = convert_to_eager_tensor(value, ctx, dtype)
    255     if shape is None:
    256       return t

~/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
    113     return t
    114   else:
--&gt; 115     return ops.EagerTensor(value, handle, device, dtype)
    116 
    117 

RuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:0. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='michaelbenayoun' date='2019-07-19T20:40:33Z'>
		Can you explain the behavior you would expect? I am not sure I understand
		</comment>
		<comment id='2' author='michaelbenayoun' date='2019-07-22T13:28:24Z'>
		I expect to be able to iterate over a dataset containing strings without having an exception being raised once the last batch has been seen (as it is happening without distribution of the dataset).
		</comment>
		<comment id='3' author='michaelbenayoun' date='2019-09-10T03:33:38Z'>
		same problem with mine.
i am using a dataset that contains a string tensor as one of the inputs of the model.
the stirng tensor input is not a part of training, but it is necessary to be in the dataset for writing predictions to file. and i am using distribute strategy.
everytime when it reaches the end of the dataset, it shows a RuntimeError.
i am using tensorflow-gpu 1.14.0, python 3.7.3, Ubuntu 18.04 and 3 GPUs of TITAN Xp
here is my test code:
import os
from tensorflow.compat.v1 import enable_eager_execution
from tensorflow.data import Dataset
from tensorflow.distribute import MirroredStrategy
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.models import Model

enable_eager_execution()

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

strategy = MirroredStrategy()
n = strategy.num_replicas_in_sync
print('Number of replicas: {}'.format(n))

dataset = Dataset.from_tensors(({'input_1': ['This is a string'],
                                 'input_2': [1., 2., 3., 2.]},
                                {'output': [3.]})).repeat(256).shuffle(8).batch(2 * n)

with strategy.scope():
    input_1 = Input(shape=(1,), dtype='string', name='input_1')
    input_2 = Input(shape=(4,), name='input_2')
    output = Dense(1, name='output')(input_2)
    model = Model([input_1, input_2], [output], name='my_model')
    model.compile(optimizer='adam', metrics=['accuracy'],
                  loss='sparse_categorical_crossentropy')

model.fit(dataset, epochs=2)
model.evaluate(dataset)
and here is the logs:
&lt;denchmark-code&gt;Number of replicas: 3
Epoch 1/2
WARNING: Logging before flag parsing goes to stderr.
W0910 04:38:57.874752 140676243105536 deprecation.py:323] From /home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1220: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
41/43 [===========================&gt;..] - ETA: 0s - loss: nan - acc: 0.0000e+00Traceback (most recent call last):
  File "draft.py", line 34, in &lt;module&gt;
    model.fit(dataset, epochs=2)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 649, in fit
    validation_freq=validation_freq)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_distributed.py", line 143, in fit_distributed
    steps_name='steps_per_epoch')
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py", line 273, in model_iteration
    actual_inputs = ins() if callable(ins) else ins
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py", line 483, in get_distributed_inputs
    model, inputs, targets, sample_weights, mode)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py", line 580, in _prepare_feed_values
    inputs, targets, sample_weights = _get_input_from_iterator(inputs, model)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/distribute/distributed_training_utils.py", line 547, in _get_input_from_iterator
    next_element = iterator.get_next()
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 256, in get_next
    global_has_value, replicas = _get_next_as_optional(self, self._strategy)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 162, in _get_next_as_optional
    iterator._iterators[i].get_next_as_list(new_name))  # pylint: disable=protected-access
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 721, in get_next_as_list
    lambda: _dummy_tensor_fn(data.value_structure))
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py", line 1957, in cond
    result = false_fn()
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 721, in &lt;lambda&gt;
    lambda: _dummy_tensor_fn(data.value_structure))
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 639, in _dummy_tensor_fn
    result.append(create_dummy_tensor(feature_shape, feature_type))
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/input_lib.py", line 632, in create_dummy_tensor
    dummy_tensor = array_ops.zeros(tensor_shape.TensorShape(dims), feature_type)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 1871, in zeros
    output = _constant_if_small(zero, shape, dtype, name)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 1829, in _constant_if_small
    return constant(value, shape=shape, dtype=dtype, name=name)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
    allow_broadcast=True)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 254, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/home/xiefangyuan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 115, in convert_to_eager_tensor
    return ops.EagerTensor(value, handle, device, dtype)
RuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:2. Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:2.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='michaelbenayoun' date='2019-09-10T04:44:45Z'>
		This seems related to the handling of last partial batch in distributed datasets. we will take a look
		</comment>
		<comment id='5' author='michaelbenayoun' date='2019-10-30T17:30:08Z'>
		I encounter the same error in Tensorflow 2.0. Any update?
		</comment>
		<comment id='6' author='michaelbenayoun' date='2019-11-18T20:06:52Z'>
		Same issue in Tensorflow 2.0.
		</comment>
		<comment id='7' author='michaelbenayoun' date='2020-01-06T22:48:33Z'>
		Same issue here. I'm breaking the loop before the last iteration. Any elegant solution to this?
Tensorflow version: 2.0.0
Python version: 3.7.5
		</comment>
		<comment id='8' author='michaelbenayoun' date='2020-02-06T17:39:47Z'>
		Is there a known workaround for this?
		</comment>
		<comment id='9' author='michaelbenayoun' date='2020-02-06T21:02:33Z'>
		Workaround:
If you are okay with not training on the partial batch, you can drop the remainder:
batched_dataset = dataset.batch(batch_size, drop_remainder=True)
		</comment>
		<comment id='10' author='michaelbenayoun' date='2020-04-17T23:26:03Z'>
		Unfortunately in TF 2.1, bsaund's workaround does not work for me nor does this appear to have anything to do with the string data type:
import tensorflow as tf
print('Tensorflow version:', tf.__version__)

strategy = tf.distribute.MirroredStrategy()
n = strategy.num_replicas_in_sync
print('Number of replicas: {}'.format(n))

dataset = tf.data.Dataset.from_tensors(({#'input_1': ['This is a string'],
                                 'input_2': [1., 2., 3., 2.]},
                                {'output': [3.]})).repeat(256).shuffle(8).batch(2 * n, drop_remainder=True)

with strategy.scope():
#     input_1 = tf.keras.layers.Input(shape=(1,), dtype='string', name='input_1')
    input_2 = tf.keras.layers.Input(shape=(4,), name='input_2')
    output = tf.keras.layers.Dense(1, name='output')(input_2)
    model = tf.keras.models.Model([#input_1,
                                   input_2], [output], name='my_model')
    model.compile(optimizer='adam', metrics=['accuracy'],
                  loss='sparse_categorical_crossentropy')

model.fit(dataset, epochs=2)
model.evaluate(dataset)
&lt;denchmark-code&gt;Tensorflow version: 2.1.0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
Number of replicas: 2
Train for 64 steps
Epoch 1/2
 0/64 [..............................] - ETA: 0s
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-13-3ea23ab1aecc&gt; in &lt;module&gt;
     19                   loss='sparse_categorical_crossentropy')
     20 
---&gt; 21 model.fit(dataset, epochs=2)
     22 model.evaluate(dataset)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--&gt; 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    327                 training_data_iter._initializer  # pylint: disable=pointless-statement
    328               else:
--&gt; 329                 training_data_iter = iter(training_dataset)
    330 
    331             training_result = run_one_epoch(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in __iter__(self)
    563 
    564     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,
--&gt; 565                                                     self._input_workers)
    566     iterator = DistributedIterator(self._input_workers, worker_iterators,
    567                                    self._strategy)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in _create_iterators_per_worker(worker_datasets, input_workers)
   1009       worker_devices = input_workers.compute_devices_for_worker(i)
   1010       iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,
-&gt; 1011                                               worker_devices)
   1012       iterators.append(iterator)
   1013   return iterators

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, worker, devices)
    862     self._worker = worker
    863     self._devices = devices
--&gt; 864     self._make_iterator()
    865 
    866   def _make_iterator(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/input_lib.py in _make_iterator(self)
    868     with ops.device(self._worker):
    869       self._iterator = multi_device_iterator_ops.MultiDeviceIterator(
--&gt; 870           self._dataset, self._devices)
    871 
    872   def get_next(self, device, name=None):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in __init__(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device)
    290                                     self._incarnation_id,
    291                                     self._prefetch_buffer_size,
--&gt; 292                                     self._experimental_slack)
    293         if context.executing_eagerly():
    294           self._device_iterators.append(dataset_ops.make_one_shot_iterator(ds))

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in _create_device_dataset(prototype_ds, incarnation_id, prefetch_buffer_size, experimental_slack)
    200       ds = dataset_ops.PrefetchDataset(ds, prefetch_buffer_size, slack_period=1)
    201     else:
--&gt; 202       ds = ds.prefetch(prefetch_buffer_size)
    203   # TODO(jsimsa): Enable auto-tuning and optimizations when supported for
    204   # non-CPU devices.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in prefetch(self, buffer_size)
   1011       Dataset: A `Dataset`.
   1012     """
-&gt; 1013     return PrefetchDataset(self, buffer_size)
   1014 
   1015   @staticmethod

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in __init__(self, input_dataset, buffer_size, slack_period)
   4114         buffer_size, dtype=dtypes.int64, name="buffer_size")
   4115 
-&gt; 4116     with ops.colocate_with(input_dataset._variant_tensor.device):
   4117         variant_tensor = gen_dataset_ops.prefetch_dataset(
   4118             input_dataset._variant_tensor,  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in colocate_with(op, ignore_existing)
   5118 # only API for those uses to avoid deprecation warning.
   5119 def colocate_with(op, ignore_existing=False):
-&gt; 5120   return _colocate_with_for_gradient(op, None, ignore_existing=ignore_existing)
   5121 
   5122 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in _colocate_with_for_gradient(op, gradient_uid, ignore_existing)
   5098     if op is not None:
   5099       if not hasattr(op, "device"):
-&gt; 5100         op = internal_convert_to_tensor_or_indexed_slices(op)
   5101       return device(op.device)
   5102     else:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py in internal_convert_to_tensor_or_indexed_slices(value, dtype, name, as_ref)
    316     return value
    317   else:
--&gt; 318     return ops.convert_to_tensor(value, dtype=dtype, name=name, as_ref=as_ref)
    319 
    320 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1312 
   1313     if ret is None:
-&gt; 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315 
   1316     if ret is NotImplemented:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    315                                          as_ref=False):
    316   _ = as_ref
--&gt; 317   return constant(v, dtype=dtype, name=name)
    318 
    319 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in constant(value, dtype, shape, name)
    256   """
    257   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--&gt; 258                         allow_broadcast=True)
    259 
    260 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    264   ctx = context.context()
    265   if ctx.executing_eagerly():
--&gt; 266     t = convert_to_eager_tensor(value, ctx, dtype)
    267     if shape is None:
    268       return t

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     94       dtype = dtypes.as_dtype(dtype).as_datatype_enum
     95   ctx.ensure_initialized()
---&gt; 96   return ops.EagerTensor(value, ctx.device_name, dtype)
     97 
     98 

RuntimeError: Can't copy Tensor with type string to device /job:localhost/replica:0/task:0/device:GPU:0.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='11' author='michaelbenayoun' date='2020-04-18T07:35:22Z'>
		Apologies for the delay here, fixing this took a while, but this has been fixed as of end of Feb. It should not happen in tf-nightly or the TF 2.2 rcs. Please re-open if you still see it there.
		</comment>
		<comment id='12' author='michaelbenayoun' date='2020-04-18T07:35:23Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30847&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30847&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='michaelbenayoun' date='2020-04-29T17:42:22Z'>
		&lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 Can you please give reference of commit that fixes the issue?
		</comment>
		<comment id='14' author='michaelbenayoun' date='2020-04-29T23:39:14Z'>
		There were a series of commits that build up to this. from what i can tell, this was the last one: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/97cdd4d16a81a349696f10451b7d564bfa99664f#diff-afbab14e6c4bbefd105d7ad3a3b67b7b&gt;97cdd4d#diff-afbab14e6c4bbefd105d7ad3a3b67b7b&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>