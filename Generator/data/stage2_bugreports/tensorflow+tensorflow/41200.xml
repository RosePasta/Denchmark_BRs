<bug id='41200' author='RomanGirin' open_date='2020-07-08T14:48:25Z' closed_time='2020-09-17T11:49:43Z'>
	<summary>Usage model's intermediate layer output in custom loss causes OOM</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.2 ('tf.version.GIT_VERSION, tf.version.VERSION' output: v2.2.0-rc4-8-g2b96f3662b 2.2.0)
Python version: 3.7.5
CUDA/cuDNN version: 10.1
GPU model and memory: RTX 2080 Ti


Usage model's intermediate layer output in custom loss function causes OOM.
I found the issue working on some custom loss function, but report the issue using much simplified toy example (the code is below). The code is based on this example &lt;denchmark-link:https://www.tensorflow.org/guide/eager#variables_and_optimizers&gt;https://www.tensorflow.org/guide/eager#variables_and_optimizers&lt;/denchmark-link&gt;
 (conceptually I only added  in loss function, details are below)
It crashes with error (full script's output is attached):

Describe the expected behavior
The below code runs ok if in the line...
 error = model(inputs) - targets + x  # dummy operation just to use intermediate layer in loss 
...you remove + x like this
 error = model(inputs) - targets
So it feels like the root cause is usage intermediate tensor in my loss function. I need to reference intermediate model layer output in custom loss function and being able to train model.
Standalone code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf

input = tf.keras.Input(shape=(1,))
x = tf.keras.layers.Dense(1)(input)

model = tf.keras.Model(inputs=input, outputs=x)

# A toy dataset of points around 3 * x + 2
NUM_EXAMPLES = 2000
training_inputs = tf.random.normal([NUM_EXAMPLES])
noise = tf.random.normal([NUM_EXAMPLES])
training_outputs = training_inputs * 3 + 2 + noise


def loss(model, inputs, targets):
  error = model(inputs) - targets + x  # dummy operation just to use intermediate layer in loss (but conceptually it's case from a real project as many useful losses need reference some intermediate model's layers outputs)
  return tf.reduce_mean(tf.square(error))


def grad(model, inputs, targets):
  with tf.GradientTape() as tape:
    loss_value = loss(model, inputs, targets)
  return tape.gradient(loss_value, model.trainable_variables)


optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)

steps = 300
for i in range(steps):
  grads = grad(model, training_inputs, training_outputs)
  optimizer.apply_gradients(zip(grads, model.trainable_variables))

&lt;/denchmark-code&gt;


&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4891146/scriptoutput.txt&gt;scriptoutput.txt&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='RomanGirin' date='2020-07-08T18:51:10Z'>
		&lt;denchmark-link:https://github.com/RomanGirin&gt;@RomanGirin&lt;/denchmark-link&gt;
,
Please try &lt;denchmark-link:https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth&gt;limiting GPU&lt;/denchmark-link&gt;
 memory growth and check if you are still facing the same issue. Thanks!
		</comment>
		<comment id='2' author='RomanGirin' date='2020-07-09T10:07:24Z'>
		&lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
  thank you for the reply!
First of all, do you agree that it's a bug or am I creating the loss function violating some TF's concepts? if I create the loss in wrong way conceptually, please, let me know how to fix it.
Limiting GPU memory usage didn't help - the same error but much earlier during the model's training.
		</comment>
		<comment id='3' author='RomanGirin' date='2020-07-26T15:03:54Z'>
		I'm experiencing a similar issue with a custom center loss implementation, as I explain in &lt;denchmark-link:https://stackoverflow.com/questions/63099178/adding-custom-loss-to-keras-model-causes-oom-error&gt;this stackoverflow question&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='4' author='RomanGirin' date='2020-08-05T09:34:37Z'>
		Any updates on this?
		</comment>
		<comment id='5' author='RomanGirin' date='2020-08-12T19:06:42Z'>
		&lt;denchmark-link:https://github.com/RomanGirin&gt;@RomanGirin&lt;/denchmark-link&gt;
 Tried reproducing this issue but ran into an other error. Please take a look at it &lt;denchmark-link:https://colab.research.google.com/gist/gowthamkpr/7d7724873335ec5afc03395293910c54/untitled.ipynb&gt;here&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='RomanGirin' date='2020-08-14T13:28:07Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
  Thank you for the reply! I got the same error running the code on tf-nightly-gpu on colab.
I also debug the code locally on tf-nightly-gpu. In loss_value variable I have
KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.math.reduce_mean/Mean:0', description="created by layer 'tf.math.reduce_mean'")
I got the exception on the same line as it noted on your stacktrace. In deed, 'KerasTensor' object has no attribute '_id' :) Don't know how to fix it.
Error is different but it caused by usage of "x" in the loss function (the same "+ x" part marked above). Without "+ x" the code runs on TF 2.2. and tf-nightly-gpu, but I need to use intermediate layer in loss function in a similar way as it is in this simplified code.
Still have no clue how to get the code running neither on TF 2.2 (getting OOM error reported above) nor on tf-nightly-gpu.
The issue remains. Any help is appreciated!
		</comment>
		<comment id='7' author='RomanGirin' date='2020-09-04T03:44:04Z'>
		&lt;denchmark-link:https://github.com/RomanGirin&gt;@RomanGirin&lt;/denchmark-link&gt;
 The shape of model(inputs) and  targets is not compatible without adding the intermediate layer. I think this is not the correct implementation of loss function. I think this is not a bug, this is an implementation problem.
		</comment>
		<comment id='8' author='RomanGirin' date='2020-09-07T23:00:57Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
  yes, you are right! thank you a lot!!! I've added slicing in corresponding parts to get correct shapes and now it works on TF version 2.3.
Two remaining issues are:
the first, on  tf-nightly-gpu I still get the same error as you mentioned &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/41200#issuecomment-673055970&gt;#41200 (comment)&lt;/denchmark-link&gt;

and the second, in corrected script which learns the toy network without errors now (thanks to you) I added accuracy validation logic and again facing an error (on TF 2.3) if I use intermediate layers output:
Traceback (most recent call last): File "C:/PyProjects/TF_Issue/main.py", line 53, in &lt;module&gt; hits += tf.reduce_sum(tf.where((output - target_batch + x_slice) &lt; 0.01, 1, 0)).numpy() AttributeError: 'Tensor' object has no attribute 'numpy'
Here is the script (I marked the line which causes the error).  Without usage of intermediate layer it works.
Please, note these two lines in the script below:
&lt;denchmark-code&gt;  hits += tf.reduce_sum(tf.where((output - target_batch + x_slice) &lt; 0.01, 1, 0)).numpy() # this line causes the error
  # hits += tf.reduce_sum(tf.where(output - target_batch &lt; 0.01, 1, 0)).numpy() # if x_slice is omitted script works fine
&lt;/denchmark-code&gt;

comment the first one and uncomment the second to get the script working.
I checked tensors shapes, of course.
Here is the script itself:
&lt;denchmark-code&gt;import tensorflow as tf

batch_size = 128

input = tf.keras.Input(shape=(None, 1))
x = tf.keras.layers.Dense(1)(input)
output = tf.keras.layers.Dense(1)(x)

model = tf.keras.Model(inputs=input, outputs=output)

# A toy dataset of points around 3 * x + 2
NUM_EXAMPLES = 2000
inputs = tf.random.normal([NUM_EXAMPLES])
noise = tf.random.normal([NUM_EXAMPLES])
outputs = inputs * 3 + 2 + noise

training_inputs = tf.reshape(inputs[:1500], (1500, 1))
training_outputs = tf.reshape(outputs[:1500], (1500, 1))
training_inputs = tf.data.Dataset.from_tensor_slices(training_inputs).batch(batch_size)
training_outputs = tf.data.Dataset.from_tensor_slices(training_outputs).batch(batch_size)
test_inputs = tf.reshape(inputs[1500:], (500, 1))
test_outputs = tf.reshape(outputs[1500:], (500, 1))
test_inputs = tf.data.Dataset.from_tensor_slices(test_inputs).batch(batch_size)
test_outputs = tf.data.Dataset.from_tensor_slices(test_outputs).batch(batch_size)


def loss(model, inputs, targets):
  outputs = model(inputs)
  output = outputs[:, 0]  # take the first output (in general model can have several outputs)
  global x
  x_slice = x[:, 0]
  error = output - targets + x_slice
  return tf.reduce_mean(tf.square(error))


optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
epoch = 3
for i in range(epoch):
  for input_batch, target_batch in zip(training_inputs, training_outputs):
    with tf.GradientTape() as tape:
      loss_value = loss(model, input_batch, target_batch)
      grads = tape.gradient(loss_value, model.trainable_variables)
      optimizer.apply_gradients(zip(grads, model.trainable_variables))
  print('epoch #:', i)


hits = 0
total = 0
for input_batch, target_batch in zip(test_inputs, test_outputs):
  outputs = model(input_batch)
  output = outputs[:, 0]  # take the first output (in general model can have several outputs)
  x_slice = x[:, 0]
  hits += tf.reduce_sum(tf.where((output - target_batch + x_slice) &lt; 0.01, 1, 0)).numpy() # this line causes the error
  # hits += tf.reduce_sum(tf.where(output - target_batch &lt; 0.01, 1, 0)).numpy() # if x_slice is omitted script works fine
  total += input_batch.shape[0]

print(hits)
print('Accuracy: ', hits/total)
&lt;/denchmark-code&gt;

Any ideas how to fix the issues?
		</comment>
		<comment id='9' author='RomanGirin' date='2020-09-10T19:30:28Z'>
		&lt;denchmark-link:https://github.com/RomanGirin&gt;@RomanGirin&lt;/denchmark-link&gt;
 Please create a new issue as the first issue has been resolved. Thank you!
		</comment>
		<comment id='10' author='RomanGirin' date='2020-09-17T11:49:43Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/43293&gt;#43293&lt;/denchmark-link&gt;

ok, done!
		</comment>
		<comment id='11' author='RomanGirin' date='2020-09-17T11:49:45Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41200&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41200&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='RomanGirin' date='2020-09-20T12:06:14Z'>
		In case it'll be useful for someone else. In further digging  I found the key misconcept in the example above: 
I use the term 'SymbolicTensor' as it explained in &lt;denchmark-link:https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html&gt;https://blog.tensorflow.org/2019/01/what-are-symbolic-and-imperative-apis.html&lt;/denchmark-link&gt;
 and discussed here &lt;denchmark-link:https://stackoverflow.com/questions/59707065/what-are-symbolic-tensors-in-tensorflow-and-keras&gt;https://stackoverflow.com/questions/59707065/what-are-symbolic-tensors-in-tensorflow-and-keras&lt;/denchmark-link&gt;

So reconsidered (and hopefully fixed) script is:
&lt;denchmark-code&gt;
import tensorflow as tf

batch_size = 128

input = tf.keras.Input(shape=(1,))
x = tf.keras.layers.Dense(1)(input)
output = tf.keras.layers.Dense(1)(x)

# usage of intermediate layer in eager calcs requires to create model
# which outputs the layer's output
# you cannot just use in eager calculations SymbolicTensor (which is created when model
# defined with Keras Functional API)
intermediate_model = tf.keras.Model(inputs=input, outputs=x)

model = tf.keras.Model(inputs=input, outputs=output)

# A toy dataset of points around 3 * x + 2
inputs = tf.random.normal([2000])
noise = tf.random.normal([2000])
outputs = inputs * 3 + 2 + noise

training_inputs = tf.reshape(inputs[:1500], (1500, 1))
training_outputs = tf.reshape(outputs[:1500], (1500, 1))
training_inputs = tf.data.Dataset.from_tensor_slices(training_inputs).batch(batch_size)
training_outputs = tf.data.Dataset.from_tensor_slices(training_outputs).batch(batch_size)
test_inputs = tf.reshape(inputs[1500:], (500, 1))
test_outputs = tf.reshape(outputs[1500:], (500, 1))
test_inputs = tf.data.Dataset.from_tensor_slices(test_inputs).batch(batch_size)
test_outputs = tf.data.Dataset.from_tensor_slices(test_outputs).batch(batch_size)


def loss(model, inputs, targets):
  outputs = model(inputs)
  x = intermediate_model(inputs)  # note that shared with the 'main' model layer are used in forward pass twice which is 'recorded' with tf.GradientTape()
  error = outputs - targets + x
  return tf.reduce_mean(tf.square(error))


optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
epoch = 300
for i in range(epoch):
  for input_batch, target_batch in zip(training_inputs, training_outputs):
    with tf.GradientTape() as tape:
      loss_value = loss(model, input_batch, target_batch)
      grads = tape.gradient(loss_value, model.trainable_variables)
      optimizer.apply_gradients(zip(grads, model.trainable_variables))
  print('epoch #:', i)

&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>