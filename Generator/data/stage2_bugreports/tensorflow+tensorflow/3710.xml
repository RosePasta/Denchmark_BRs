<bug id='3710' author='zeis' open_date='2016-08-09T14:11:04Z' closed_time='2016-10-09T02:32:16Z'>
	<summary>function.Defun can't be applied to tf.Variable</summary>
	<description>
I need to specify a custom gradient for my custom_op() function. I've written the following example.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.python.framework import function

def custom_op_grad(op, grad):
    return grad

@function.Defun(x=tf.float32, python_grad_func=custom_op_grad)
def custom_op(x):
    exp = tf.exp(x)
    constant = tf.constant(1., dtype=tf.float32)
    add1 = tf.add(constant, exp)
    log = tf.log(add1)
    return log

x = tf.Variable(np.array(np.arange(6)).reshape(3, 2), dtype=tf.float32)

sess = tf.Session()
sess.run(tf.initialize_all_variables())

x = tf.identity(x)

grad = tf.gradients(custom_op(x), [x])[0]

res = sess.run(grad)

print(res)

sess.close()
&lt;/denchmark-code&gt;

If I run the above example as it is I get the following result:
&lt;denchmark-code&gt;[[ 1.  1.]
 [ 1.  1.]
 [ 1.  1.]]
&lt;/denchmark-code&gt;

If I comment out the @function.Defun(...) decorator (with I use to specify a custom gradient function) I get a different result:
&lt;denchmark-code&gt;[[ 0.5         0.7310586 ]
 [ 0.88079709  0.95257413]
 [ 0.98201376  0.99330717]]
&lt;/denchmark-code&gt;

That is strange because custom_op_grad(op, grad) just returns grad, which I guess should be the same as the gradient calculated in the second case.
Moreover, if I keep the decorator I also need to do this: x = tf.identity(x). If I comment out this line, I get the following error and I don't understand why:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "custom_op3.py", line 42, in &lt;module&gt;
    grad = tf.gradients(custom_op(x), [x])[0]
  File "/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py", line 528, in __call__
    return call_function(self._definition, *args, **kwargs)
  File "/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py", line 267, in call_function
    compute_shapes=False)
  File "/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2285, in create_op
    raise TypeError("Input #%d is not a tensor: %s" % (idx, a))
TypeError: Input #0 is not a tensor: &lt;tensorflow.python.ops.variables.Variable object at 0x10eb7d710&gt;
&lt;/denchmark-code&gt;

I'm using the GitHub version of TensofFlow.
	</description>
	<comments>
		<comment id='1' author='zeis' date='2016-08-09T16:06:55Z'>
		If you comment out the Defun, it's computing the gradient of softplus correctly.  Your gradient function is wrong, since softplus isn't the identity function and doesn't have derivative 1, but computes what I'd expect given its implementation.
The fact that you can't apply a Defun to a variable is a bug.  &lt;denchmark-link:https://github.com/andydavis1&gt;@andydavis1&lt;/denchmark-link&gt;
: Could you take a look?
		</comment>
		<comment id='2' author='zeis' date='2016-08-16T16:51:16Z'>
		Sorry that you are having this issue. We are working on a fix, after which you will be able to pass a Variable as a function argument (without using the Identify).
		</comment>
		<comment id='3' author='zeis' date='2016-09-19T03:36:03Z'>
		Your custom_op(x) is effectively computing element-wise y = log(1+e^x) for x in the inputs. By definition, tf.gradients(y, x) computes, since grad_ys=None by default, dy_i/dx_i = e^x / (1 + e^x)  = sigmoid(x). Since your test is giving x = [0, 1, 2, 3, 4, 5]. So,
[[ 0.5         0.7310586 ]
[ 0.88079709  0.95257413]
[ 0.98201376  0.99330717]]
is correct.
When you specify custom_op_grad(x, grad) = grad, effectively, you are telling the backprop algorithm to pass through the error. Since grad_ys=None, effectively, these are 1.0.
		</comment>
		<comment id='4' author='zeis' date='2017-01-12T10:31:07Z'>
		If I run that sample code, I get
&lt;denchmark-code&gt;ValueError: Unknown keyword arguments: ['x']
&lt;/denchmark-code&gt;

When I remove x= in the Defun call, this exception is gone.
But then I get:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'custom_op_d6da5a2c'
&lt;/denchmark-code&gt;

Is there something broken again?
		</comment>
	</comments>
</bug>