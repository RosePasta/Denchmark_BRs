<bug id='28799' author='tejal567' open_date='2019-05-17T12:03:50Z' closed_time='2020-08-17T07:29:46Z'>
	<summary>TypeError: 'Not JSON Serializable' while doing tf.keras.Model.save and using keras variable in loss_weights in tf.keras.Model.compile</summary>
	<description>
System information

Have I written custom code: NA
OS Platform and Distribution: Ubuntu 16.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.12.0
Python version: 3.5.2
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: release 9.0, V9.0.176
GPU model and memory: Tesla K80, 12 GB

Describe the current behavior
When I try to save my model using model.save() where model is a tf.keras.Model instance, it throws a TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32&gt;) .
I am using a tf.keras.backend.variable() in loss_weights in model.compile.
Optimizer: tf.keras.optimizers.Adam
Interestingly, when I try to save my model weights only using model.save_weights where model is a tf.keras.Model instance, it works fine, NO ERROR.
Describe the expected behavior
It should not throw any type of error during training.
Code to reproduce the issue
import tensorflow as tf
import numpy as np
import os
import sys
input_layer = tf.keras.layers.Input(shape=([4,3]), batch_size=1)
layer1 = tf.keras.layers.Dense(20)(input_layer)
layer2 = tf.keras.layers.Dense(1,name="output1")(layer1)
layer3 = tf.keras.layers.Dense(1,name="output2")(layer1)
model = tf.keras.Model(inputs=input_layer, outputs=[layer2,layer3])
alpha = tf.keras.backend.variable(0.25)
model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss={"output1":tf.keras.metrics.binary_crossentropy,"output2":tf.keras.metrics.binary_crossentropy},loss_weights=[1.0,alpha])
# model.fit() is skipped just to get straight to error.
model.save("./weights.h5")
Just execute this code as it is, It will throw same error!!
Other info / logs
Traceback (most recent call last):
File "main_latest.py", line 45, in 
max_queue_size=10)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py", line 2177, in fit_generator
initial_epoch=initial_epoch)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py", line 216, in fit_generator
callbacks.on_epoch_end(epoch, epoch_logs)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py", line 214, in on_epoch_end
callback.on_epoch_end(epoch, logs)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py", line 601, in on_epoch_end
self.model.save(filepath, overwrite=True)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py", line 1363, in save
save_model(self, filepath, overwrite, include_optimizer)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py", line 134, in save_model
default=serialization.get_json_type).encode('utf8')
File "/usr/lib/python3.5/json/init.py", line 237, in dumps
**kw).encode(obj)
File "/usr/lib/python3.5/json/encoder.py", line 198, in encode
chunks = self.iterencode(o, _one_shot=True)
File "/usr/lib/python3.5/json/encoder.py", line 256, in iterencode
return _iterencode(o, 0)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/util/serialization.py", line 64, in get_json_type
raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32&gt;)
&lt;denchmark-link:https://user-images.githubusercontent.com/14198246/57926377-b8290880-78c8-11e9-92fa-d03803a27123.PNG&gt;&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='tejal567' date='2019-05-17T12:06:06Z'>
		Similar Issue (Open): &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28010&gt;#28010&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='tejal567' date='2019-05-20T14:32:21Z'>
		&lt;denchmark-link:https://github.com/tejal567&gt;@tejal567&lt;/denchmark-link&gt;
 Please provide reproducible full code to investigate this issue. After I ran this code it says : NameError: name 'get_model' is not defined
		</comment>
		<comment id='3' author='tejal567' date='2019-05-21T11:09:40Z'>
		import tensorflow as tf
import numpy as np
import os
import sys
input_layer = tf.keras.layers.Input(shape=([4,3]), batch_size=1)
layer1 = tf.keras.layers.Dense(20)(input_layer)
layer2 = tf.keras.layers.Dense(1,name="output1")(layer1)
layer3 = tf.keras.layers.Dense(1,name="output2")(layer1)
model = tf.keras.Model(inputs=input_layer, outputs=[layer2,layer3])
alpha = tf.keras.backend.variable(0.25)
model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss={"output1":tf.keras.metrics.binary_crossentropy, "output2":tf.keras.metrics.binary_crossentropy}, loss_weights=[1.0,alpha])
# model.fit() is skipped just to get straight to error.
model.save("./weights.h5")
Just execute this code as it is, It will throw same error!!
		</comment>
		<comment id='4' author='tejal567' date='2019-05-21T11:58:14Z'>
		&lt;denchmark-link:https://github.com/tejal567&gt;@tejal567&lt;/denchmark-link&gt;
 Able to reproduce the issue with the provided code.
TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32&gt;)
		</comment>
		<comment id='5' author='tejal567' date='2019-06-19T03:40:46Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 Can you please have a look at it
		</comment>
		<comment id='6' author='tejal567' date='2019-06-19T03:44:20Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 awaiting for your response, please have a look at it
		</comment>
		<comment id='7' author='tejal567' date='2019-07-18T15:48:32Z'>
		&lt;denchmark-link:https://github.com/fchollet&gt;@fchollet&lt;/denchmark-link&gt;
 Is there a fix for this?
		</comment>
		<comment id='8' author='tejal567' date='2019-09-18T10:52:10Z'>
		this error also appears when I try to save a transformer model using tensorflow 2.0
code link: &lt;denchmark-link:https://github.com/bryanlimy/tf2-transformer-chatbot&gt;https://github.com/bryanlimy/tf2-transformer-chatbot&lt;/denchmark-link&gt;

how i try to save the model:
model.save('hnosa.model')
and
  tf.keras.models.save_model( model, filepath, overwrite=True, include_optimizer=True, save_format=None )
this error appears:
Traceback (most recent call last):
File "&lt;ipython-input-1-ce3301d571a9&gt;", line 1, in &lt;module&gt; runfile('C:/Users/alhno/DS/tf2-transformer-chatbot-master/main.py', wdir='C:/Users/alhno/DS/tf2-transformer-chatbot-master')
File "C:\Users\alhno\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 827, in runfile execfile(filename, namespace)
File "C:\Users\alhno\Anaconda3\lib\site-packages\spyder_kernels\customize\spydercustomize.py", line 110, in execfile exec(compile(f.read(), filename, 'exec'), namespace)
File "C:/Users/alhno/DS/tf2-transformer-chatbot-master/main.py", line 163, in &lt;module&gt; main(hparams)
File "C:/Users/alhno/DS/tf2-transformer-chatbot-master/main.py", line 128, in main model.save('hnosa.model')
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\network.py", line 1213, in save saving.save_model(self, filepath, overwrite, include_optimizer, save_format)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\keras\saving\save.py", line 106, in save_model saved_model.save(model, filepath, overwrite, include_optimizer)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\keras\saving\saved_model.py", line 1492, in save save_lib.save(model, filepath)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\saved_model\save.py", line 849, in save saveable_view, asset_info.asset_index)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\saved_model\save.py", line 604, in _serialize_object_graph _write_object_proto(obj, obj_proto, asset_file_def_index)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\saved_model\save.py", line 643, in _write_object_proto metadata=obj._tracking_metadata)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py", line 2705, in _tracking_metadata metadata = json.loads(super(Model, self)._tracking_metadata)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py", line 2213, in _tracking_metadata return json.dumps(metadata, default=serialization.get_json_type)
File "C:\Users\alhno\Anaconda3\lib\json\__init__.py", line 238, in dumps **kw).encode(obj)
File "C:\Users\alhno\Anaconda3\lib\json\encoder.py", line 199, in encode chunks = self.iterencode(o, _one_shot=True)
File "C:\Users\alhno\Anaconda3\lib\json\encoder.py", line 257, in iterencode return _iterencode(o, 0)
File "C:\Users\alhno\Anaconda3\lib\site-packages\tensorflow\python\util\serialization.py", line 69, in get_json_type raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', b'\n?transformer/encoder/tf_op_layer_mul/encoder/tf_op_layer_mul/mul\x12\x03Mul\x1a\x12embedding/Identity\x1a\x05mul/y*\x07\n\x01T\x12\x020\x01')
		</comment>
		<comment id='9' author='tejal567' date='2019-09-18T18:52:08Z'>
		&lt;denchmark-link:https://github.com/vsatyakumar&gt;@vsatyakumar&lt;/denchmark-link&gt;
 Currently, you can't use tensorflow variables objects in the compiled args. I'll see if there is a fix for this. For now, a workaround would be to save the uncompiled version of the model, then manually re-compile once its loaded.
&lt;denchmark-link:https://github.com/hno1993&gt;@hno1993&lt;/denchmark-link&gt;
 I believe if you wrapped the encoder ops (shown below) as a custom layer, the serialization would work.
&lt;denchmark-code&gt; embeddings = tf.keras.layers.Embedding(hparams.vocab_size,
                                         hparams.d_model)(inputs)
  embeddings *= tf.math.sqrt(tf.cast(hparams.d_model, tf.float32))
  embeddings = PositionalEncoding(hparams)(embeddings)

  outputs = tf.keras.layers.Dropout(hparams.dropout)(embeddings)
&lt;/denchmark-code&gt;

Your code may be buggy if you're running in eager mode, since tf.keras.layers.Embedding(...)(inputs) would immediately evaluate the variables in the Embedding layer to constant values.
		</comment>
		<comment id='10' author='tejal567' date='2019-09-18T19:30:46Z'>
		&lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
, thanks for the suggestion. However, this doesn't help since saving model weights (checkpoints) during training fails aswell.
		</comment>
		<comment id='11' author='tejal567' date='2019-09-18T19:41:25Z'>
		Are you saving just the weights or the model? If just the weights, then model.save_weights should suffice.
		</comment>
		<comment id='12' author='tejal567' date='2019-09-18T21:24:25Z'>
		&lt;denchmark-link:https://github.com/hno1993&gt;@hno1993&lt;/denchmark-link&gt;
 I see you're using Conda to manage your packages, which may mean your Tensorflow installation doesn't contain all the latest fixes.
That error should be fixed by &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/39bc7bcf94983261a3ee8a72802f5de056728a9c#diff-8eb7e20502209f082d0cb15119a50413&gt;39bc7bc#diff-8eb7e20502209f082d0cb15119a50413&lt;/denchmark-link&gt;
.
Try using the latest RC or nightly.
		</comment>
		<comment id='13' author='tejal567' date='2019-10-10T22:57:05Z'>
		&lt;denchmark-link:https://github.com/tejal567&gt;@tejal567&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/d96b3a426058b99a212a4ec256ff76f6/untitled560.ipynb&gt;Here is the gist&lt;/denchmark-link&gt;
 with the workaround mentioned by &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
 . There is a limitation of what can be part of compile.
Please close the issue if this was resolved for you. thanks!
		</comment>
		<comment id='14' author='tejal567' date='2019-10-11T06:56:58Z'>
		Not resolved for me. So can we say that as of now there is no way of saving a model (model.save()) compiled using variables (tf.keras.backend.variable) in loss_weights ? &lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='tejal567' date='2019-10-11T19:49:16Z'>
		&lt;denchmark-link:https://github.com/tejal567&gt;@tejal567&lt;/denchmark-link&gt;
 Correct. If you have a solution, you could contribute by raising Pull-requests(PR) to change the codes. Thanks!
		</comment>
		<comment id='16' author='tejal567' date='2020-02-09T16:58:51Z'>
		I would like to add that It is not just throwing this error when trying to save the model at the end of an epoch, the loss_weights do nothing to the total loss. My loss weights for two output network is {'out1': alpha, 'out2': 1-alpah} and alpha begins with 0 and ends to 1 by using some update equation which depends on the epoch number and by using callback of course. So the loss for 'out1' should be zero for the first epoch , but both losses are working without any multiplication with the loss_weights. The only solution for me is to build a custom loss function and it works fine, but I still need this issue to be fixed because you want to use the build-in keras losses and sometimes it is hard to build the same loss by yourself. So is there fix in a near future for this?
		</comment>
		<comment id='17' author='tejal567' date='2020-08-15T14:45:49Z'>
		I also had this problem when i use checkpoint. btw ,my loss is customLsyer
the error log:
WARNING:tensorflow:From /Users/mkd/Project/PythonProjects/search_query_intention/model/DssmRNN_ali.py:368: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version. Instructions for updating: Please use Model.fit, which supports generators. WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5&gt;) Epoch 1/2 WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss. WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss. WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss. WARNING:tensorflow:Gradients do not exist for variables ['Variable:0'] when minimizing the loss. 2020-08-15 22:36:19.344394: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started. 1/1000 [..............................] - ETA: 0s - loss: 1440.2056 - cosine_accuracy: 0.8320 - catclass_accuracy: 0.0000e+002020-08-15 22:36:19.432737: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19 2020-08-15 22:36:19.448521: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19/KDM.local.trace.json.gz 2020-08-15 22:36:19.463320: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.834 ms 2020-08-15 22:36:19.471340: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19Dumped tool data for overview_page.pb to logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19/KDM.local.overview_page.pb Dumped tool data for input_pipeline.pb to logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19/KDM.local.input_pipeline.pb Dumped tool data for tensorflow_stats.pb to logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19/KDM.local.tensorflow_stats.pb Dumped tool data for kernel_stats.pb to logs/bigru_sample_twins_char_term_test/train/plugins/profile/2020_08_15_22_36_19/KDM.local.kernel_stats.pb 1000/1000 [==============================] - ETA: 0s - loss: 489.9940 - cosine_accuracy: 0.6109 - catclass_accuracy: 0.32022020-08-15 22:37:10.213564: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them. WARNING:tensorflow:From /Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. Traceback (most recent call last): File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 3331, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-2-4f1fee32864f&gt;", line 1, in &lt;module&gt; runfile('/Users/mkd/Project/PythonProjects/search_query_intention/bigru_multi_in_and_out_ali_test.py', wdir='/Users/mkd/Project/PythonProjects/search_query_intention') File "/Users/mkd/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.7288.30/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py", line 197, in runfile pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script File "/Users/mkd/Library/Application Support/JetBrains/Toolbox/apps/PyCharm-P/ch-0/193.7288.30/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile exec(compile(contents+"\n", file, 'exec'), glob, loc) File "/Users/mkd/Project/PythonProjects/search_query_intention/bigru_multi_in_and_out_ali_test.py", line 98, in &lt;module&gt; callbacks=callback_list, workers=1, use_multiprocessing=False, shuffle=True) File "/Users/mkd/Project/PythonProjects/search_query_intention/model/DssmRNN_ali.py", line 368, in train shuffle=shuffle File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 324, in new_func return func(*args, **kwargs) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1479, in fit_generator initial_epoch=initial_epoch) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 66, in _method_wrapper return method(self, *args, **kwargs) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 876, in fit callbacks.on_epoch_end(epoch, epoch_logs) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py", line 365, in on_epoch_end callback.on_epoch_end(epoch, logs) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py", line 1177, in on_epoch_end self._save_model(epoch=epoch, logs=logs) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py", line 1214, in _save_model self.model.save(filepath, overwrite=True) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py", line 1052, in save signatures, options) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py", line 138, in save_model signatures, options) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/save.py", line 78, in save save_lib.save(model, filepath, signatures, options) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py", line 951, in save obj, export_dir, signatures, options, meta_graph_def) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py", line 1037, in _build_meta_graph asset_info.asset_index) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py", line 697, in _serialize_object_graph saveable_view.function_name_map) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py", line 737, in _write_object_proto metadata=obj._tracking_metadata) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py", line 2742, in _tracking_metadata return self._trackable_saved_model_saver.tracking_metadata File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py", line 54, in tracking_metadata return json_utils.Encoder().encode(self.python_properties) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py", line 44, in encode return super(Encoder, self).encode(_encode_tuple(obj)) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/json/encoder.py", line 199, in encode chunks = self.iterencode(o, _one_shot=True) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/json/encoder.py", line 257, in iterencode return _iterencode(o, 0) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/keras/saving/saved_model/json_utils.py", line 41, in default return serialization.get_json_type(obj) File "/Users/mkd/miniconda3/envs/python36/lib/python3.6/site-packages/tensorflow/python/util/serialization.py", line 76, in get_json_type raise TypeError('Not JSON Serializable:', obj) TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.5&gt;)
`
class CustomMultiLossLayer_test(Layer):
def init(self, nb_outputs=2, n_class=1000, **kwargs):
self.nb_outputs = nb_outputs
self.n_class = n_class
self.bin_acc = BinaryAccuracy(name="bin_acc")
self.spc_acc = CategoricalAccuracy(name="nor_acc")
super(CustomMultiLossLayer_test, self).init(**kwargs)
&lt;denchmark-code&gt;def build(self, input_shape=None):
    self.log_vars = []

    for i in range(self.nb_outputs):
        self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,),
                                          initializer=Constant(0.), trainable=True)]
    super(CustomMultiLossLayer_test, self).build(input_shape)

def multi_loss(self, ys_true, ys_pred):
    assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs
    yc_ture = ys_true[0]
    yl_ture = ys_true[1]
    yc_pred = ys_pred[0]
    yl_pred = ys_pred[1]
    loss = 0
    cos_acc = 0
    cat_acc = 0
    # cosine loss
    precision = K.exp(-self.log_vars[0][0])
    loss += K.sum(
        precision * K.binary_crossentropy(yc_ture, yc_pred) + self.log_vars[0][0], -1)
    # cat loss
    precision = K.exp(-self.log_vars[1][0])
    loss += K.sum(
        precision * K.categorical_crossentropy(yl_ture, yl_pred) + self.log_vars[1][0], -1)
    # cosine acc
    _ = self.bin_acc.update_state(yc_ture, yc_pred)
    cos_acc += self.bin_acc.result()
    # cat acc
    _ = self.spc_acc.update_state(yl_ture, yl_pred)
    cat_acc += self.spc_acc.result()

    return K.mean(loss), K.mean(cos_acc), K.mean(cat_acc)

def call(self, inputs, **kwargs):
    ys_true = inputs[:self.nb_outputs]
    ys_pred = inputs[self.nb_outputs:]
    loss, cos_acc, cat_acc = self.multi_loss(ys_true, ys_pred)
    self.add_loss(loss, inputs=inputs)
    self.add_metric(cos_acc, name="cosine_accuracy", aggregation='mean')
    self.add_metric(cat_acc, name="catclass_accuracy", aggregation='mean')
    return ys_true[0]

def get_config(self, ):
    config = {"nb_outputs": self.nb_outputs, "bin_acc": self.bin_acc,
              "nor_acc": self.spc_acc, "n_class": self.n_class}
    base_config = super(CustomMultiLossLayer_test, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))
&lt;/denchmark-code&gt;

`
		</comment>
		<comment id='18' author='tejal567' date='2020-08-17T07:29:46Z'>
		I think enough has been said about this issue
		</comment>
		<comment id='19' author='tejal567' date='2020-08-17T07:29:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28799&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28799&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='20' author='tejal567' date='2020-09-10T06:34:19Z'>
		Is the problem solved？I meet the same problem when saving a model with custom layer（in this layer ,I use the add_weight function）,the tensorflow vesion is 2.0.0
		</comment>
		<comment id='21' author='tejal567' date='2020-09-15T19:54:35Z'>
		Was the issue solved? I dont get the feel of the solution
		</comment>
		<comment id='22' author='tejal567' date='2020-10-02T02:56:17Z'>
		
Not resolved for me. So can we say that as of now there is no way of saving a model (model.save()) compiled using variables (tf.keras.backend.variable) in loss_weights ? @jvishnuvardhan

Recently I also meet this problem .Because it says tf.Variables can't be json serializable so i just let key variable V(for example) be V.numpy() as parameters' input and it can help.Maybe making it not be type of tf.Variable will matter.
		</comment>
		<comment id='23' author='tejal567' date='2020-10-02T03:09:57Z'>
		
System information

Have I written custom code: NA
OS Platform and Distribution: Ubuntu 16.04 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.12.0
Python version: 3.5.2
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: release 9.0, V9.0.176
GPU model and memory: Tesla K80, 12 GB

Describe the current behavior
When I try to save my model using model.save() where model is a tf.keras.Model instance, it throws a TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32&gt;) .
I am using a tf.keras.backend.variable() in loss_weights in model.compile.
Optimizer: tf.keras.optimizers.Adam
Interestingly, when I try to save my model weights only using model.save_weights where model is a tf.keras.Model instance, it works fine, NO ERROR.
Describe the expected behavior
It should not throw any type of error during training.
Code to reproduce the issue
import tensorflow as tf
import numpy as np
import os
import sys
input_layer = tf.keras.layers.Input(shape=([4,3]), batch_size=1)
layer1 = tf.keras.layers.Dense(20)(input_layer)
layer2 = tf.keras.layers.Dense(1,name="output1")(layer1)
layer3 = tf.keras.layers.Dense(1,name="output2")(layer1)
model = tf.keras.Model(inputs=input_layer, outputs=[layer2,layer3])
alpha = tf.keras.backend.variable(0.25)
model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss={"output1":tf.keras.metrics.binary_crossentropy,"output2":tf.keras.metrics.binary_crossentropy},loss_weights=[1.0,alpha])
# model.fit() is skipped just to get straight to error.
model.save("./weights.h5")
Just execute this code as it is, It will throw same error!!
Other info / logs
Traceback (most recent call last):
File "main_latest.py", line 45, in
max_queue_size=10)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py", line 2177, in fit_generator
initial_epoch=initial_epoch)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_generator.py", line 216, in fit_generator
callbacks.on_epoch_end(epoch, epoch_logs)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py", line 214, in on_epoch_end
callback.on_epoch_end(epoch, logs)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/callbacks.py", line 601, in on_epoch_end
self.model.save(filepath, overwrite=True)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py", line 1363, in save
save_model(self, filepath, overwrite, include_optimizer)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py", line 134, in save_model
default=serialization.get_json_type).encode('utf8')
File "/usr/lib/python3.5/json/init.py", line 237, in dumps
**kw).encode(obj)
File "/usr/lib/python3.5/json/encoder.py", line 198, in encode
chunks = self.iterencode(o, _one_shot=True)
File "/usr/lib/python3.5/json/encoder.py", line 256, in iterencode
return _iterencode(o, 0)
File "/home/tejal/.local/lib/python3.5/site-packages/tensorflow/python/util/serialization.py", line 64, in get_json_type
raise TypeError('Not JSON Serializable:', obj)
TypeError: ('Not JSON Serializable:', &lt;tf.Variable 'Variable:0' shape=() dtype=float32&gt;)


add .numpy() after alpha ,like the flowing:
model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),loss={"output1":tf.keras.metrics.binary_crossentropy,"output2":tf.keras.metrics.binary_crossentropy},loss_weights=[1.0,alpha.numpy()])
		</comment>
		<comment id='24' author='tejal567' date='2020-10-02T03:12:40Z'>
		replacing alpha with alpha.numpy() will be ok in my computer.
		</comment>
		<comment id='25' author='tejal567' date='2020-12-06T08:58:42Z'>
		I encountered this issue in my project and have fixed it with &lt;denchmark-link:https://github.com/Janesefor&gt;@Janesefor&lt;/denchmark-link&gt;
's solution.
The reason for this is that I was using tf function when building the model:
&lt;denchmark-code&gt;num_identity = tf.cast(tf.math.ceil(num_input_channels * split), tf.int32)
&lt;/denchmark-code&gt;

Append .numpy() at the end like this:
&lt;denchmark-code&gt;num_identity = tf.cast(tf.math.ceil(num_input_channels * split), tf.int32).numpy()
&lt;/denchmark-code&gt;

Then the model could be saved as saved_model format.
		</comment>
	</comments>
</bug>