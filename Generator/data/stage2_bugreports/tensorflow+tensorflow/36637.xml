<bug id='36637' author='charmasaur' open_date='2020-02-10T23:41:36Z' closed_time='2020-02-12T18:33:33Z'>
	<summary>expm grad can fail on TF2 when eager execution is disabled</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.2
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
Python version: 3.7.3

Describe the current behavior
Evaluating the gradient of a tf.linalg.expm operation can fail with the following exception when eager execution is disabled:
&lt;denchmark-code&gt;Node 'gradients_1/matrix_exponential_1/while_grad/matrix_exponential_1/while_grad': Connecting to invalid output 6 of source node matrix_exponential_1/while which has 6 outputs.
&lt;/denchmark-code&gt;

Calling tf.compat.v1.experimental.output_all_intermediates(True) at the start of the session fixes the issue.
The issue only seems to happen if the gradient op gets added after the Session has already evaluated something.
Describe the expected behavior
No exception should be thrown.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
tf.compat.v1.disable_eager_execution()
session = tf.compat.v1.Session()
x = tf.constant([[1., 0.], [0., -1.]], dtype=tf.float32)
y = tf.linalg.expm(x)
session.run(y)
session.run(tf.gradients(y, x))
&lt;/denchmark-code&gt;

Also see gist here: &lt;denchmark-link:https://colab.research.google.com/drive/1N5KeUBXJAmpict_lofiREHyE1QUcSDUl&gt;https://colab.research.google.com/drive/1N5KeUBXJAmpict_lofiREHyE1QUcSDUl&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='charmasaur' date='2020-02-11T11:32:51Z'>
		Was able to reproduce the issue. Please find the Gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/amahendrakar/b2adc534c82c405ca62b378842e531c3/36637.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='charmasaur' date='2020-02-11T19:15:40Z'>
		&lt;denchmark-link:https://github.com/charmasaur&gt;@charmasaur&lt;/denchmark-link&gt;
 As mentioned in the error, if you make necessary changes this should work.
&lt;denchmark-code&gt;import tensorflow as tf
tf.compat.v1.disable_eager_execution()
tf.compat.v1.experimental.output_all_intermediates(True)
session = tf.compat.v1.Session()
x = tf.constant([[1., 0.], [0., -1.]], dtype=tf.float32)
y = tf.linalg.expm(x)
session.run(y)
session.run(tf.gradients(y, x))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='charmasaur' date='2020-02-11T21:39:06Z'>
		Yup, that fixes the issue for me too.
		</comment>
		<comment id='4' author='charmasaur' date='2020-02-12T18:33:32Z'>
		Great. I am gonna close this issue then. To understand the cause of this error please read the following &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/experimental/output_all_intermediates&gt;doc&lt;/denchmark-link&gt;
. Thanks.
If you have any more questions please post them on stack overflow. Thanks!
		</comment>
		<comment id='5' author='charmasaur' date='2020-02-12T18:33:35Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36637&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36637&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='charmasaur' date='2020-02-12T22:45:36Z'>
		OK, but presumably the fact that tf.compat.v1.experimental.output_all_intermediates(True) is necessary means that there's still something to be fixed here. Surely using that function isn't the intended long-term solution for people who want to calculate gradients of expm?
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/compat/v1/experimental/output_all_intermediates&gt;https://www.tensorflow.org/api_docs/python/tf/compat/v1/experimental/output_all_intermediates&lt;/denchmark-link&gt;
 also says that if we see this effect we should file an issue, which again suggests to me that there's some underlying issue to fix here.
edit: I should add that this isn't a problem for me (it was easy enough simply to rework the code to build the entire graph before using the Session), but I filed in the issue because I assumed that the error indicated some underlying issue that needs to be fixed.
		</comment>
	</comments>
</bug>