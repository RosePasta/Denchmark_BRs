<bug id='25454' author='thebeancounter' open_date='2019-02-02T09:45:33Z' closed_time='2019-02-19T23:37:48Z'>
	<summary>multi gpu model error when trying to create model</summary>
	<description>
Please see also SO question about &lt;denchmark-link:https://stackoverflow.com/questions/54440168/tf-python-keras-utils-multi-gpu-model-error-on-initializing&gt;this&lt;/denchmark-link&gt;

I am using python 3 with tensorflow and multiple gpu configuration, I try to use the &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/utils/multi_gpu_model&gt;following example&lt;/denchmark-link&gt;
 to init the multi gpu model, I create a model, It's fine, compiling, running and training, but When I try to add this before the model compilation:
&lt;denchmark-code&gt;from tensorflow.python.keras.utils import multi_gpu_model
model = multi_gpu_model(model, gpus=2, cpu_merge=False)
&lt;/denchmark-code&gt;

I get this error

TypeError: int() argument must be a string or a number, not
'TensorShape'

Note I am using tf with eager eval
I found &lt;denchmark-link:https://github.com/keras-team/keras/issues/11408&gt;this&lt;/denchmark-link&gt;
 reffering to use keras.utils.multi_gpu_model instead of tf.python.keras.utils.multi_gpu_model But when I do that I get this error instead:
What am i missing here?

line 217, in multi_gpu_model
with tf.device(x.device): AttributeError: 'DeferredTensor' object has no attribute 'device'

the code for the model is
&lt;denchmark-code&gt;model = Sequential()
model.add(Flatten(input_shape=(128, 128, 3)))
model.add(Dense(100, activation="sigmoid"))
model.add(Dense(100, activation="sigmoid"))
&lt;/denchmark-code&gt;

Thanks
	</description>
	<comments>
		<comment id='1' author='thebeancounter' date='2019-02-03T09:10:06Z'>
		update: could this be a gpu id issue? when I try to create a multi_gpu_model without specifing the gpus count with the following code:
&lt;denchmark-code&gt;model = multi_gpu_model(model)
&lt;/denchmark-code&gt;

I get the following error:

ValueError: To call multi_gpu_model with gpus=3, we expect the
following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1',
'/gpu:2']. However this machine only has: ['/cpu:0', '/xla_cpu:0',
'/xla_gpu:0', '/gpu:0', '/gpu:1']. Try reducing gpus

I only have 2 gpus, they are connected to pci ports # 1 and 2 (I cant change that, I don't have the proper space on the board needed to connect them to port 0), does it make any sense that when specifying 2 GPUs, tf will try to get GPU 0 and GPU 1? Can I specify otherwise?
		</comment>
		<comment id='2' author='thebeancounter' date='2019-02-05T01:21:34Z'>
		&lt;denchmark-link:https://github.com/thebeancounter&gt;@thebeancounter&lt;/denchmark-link&gt;
 Can you check the detailed description and an example on keras website &lt;denchmark-link:https://keras.io/utils/&gt;here&lt;/denchmark-link&gt;
. Please let me know how it progresses. I will try to run it tomorrow on my desktop with GPU. Thanks
		</comment>
		<comment id='3' author='thebeancounter' date='2019-02-19T19:28:28Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='4' author='thebeancounter' date='2019-02-19T23:37:48Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='5' author='thebeancounter' date='2019-04-19T09:17:56Z'>
		It looks like Keras only sees one of the GPUs.
Make sure that all GPUs are accessible.you can use device_lib with TensorFlow.
You can check all device list using following code:
from tensorflow.python.client import device_lib
device_lib.list_local_devices()
		</comment>
		<comment id='6' author='thebeancounter' date='2020-07-18T21:43:25Z'>
		
You can check all device list using following code:
from tensorflow.python.client import device_lib
device_lib.list_local_devices()

I am getting this. it seems like only one gpu is accessible. What to do then?
&lt;denchmark-code&gt;&gt;&gt;&gt; from tensorflow.python.client import device_lib
&gt;&gt;&gt; device_lib.list_local_devices()
2020-07-19 03:09:14.714310: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-07-19 03:09:15.553561: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce MX250 major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 2.00GiB freeMemory: 1.62GiB
2020-07-19 03:09:15.557185: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -&gt; (device: 0, name: GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1)
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 12818861576623973213
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 1506609971
locality {
  bus_id: 1
}
incarnation: 1957363585754623730
physical_device_desc: "device: 0, name: GeForce MX250, pci bus id: 0000:01:00.0, compute capability: 6.1"
]
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>