<bug id='34021' author='tmartin293' open_date='2019-11-05T22:07:28Z' closed_time='2020-03-21T16:51:58Z'>
	<summary>Unable to save TensorFlow Keras LSTM model to SavedModel format</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip installed
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0
Python version: 3.7.1
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Unable to save TensorFlow Keras LSTM model to SavedModel format for exporting to Google Cloud and Google AI platform.
Error message: ValueError: Attempted to save a function b'__inference_lstm_2_layer_call_fn_36083' which references a symbolic Tensor Tensor("dropout/mul_1:0", shape=(None, 1280), dtype=float32) that is not a simple constant. This is not supported.
Describe the expected behavior
LSTM model would be saved in the SavedModel format to be exported into a Google Cloud bucket to work with Google's AI platform.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`import tensorflow as tf
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tqdm
import datetime
from sklearn.preprocessing import LabelBinarizer
model = tf.keras.Sequential([
tf.keras.layers.Masking(mask_value=0.),
tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),
tf.keras.layers.Dense(256, activation='relu'),
tf.keras.layers.Dropout(0.5),
tf.keras.layers.Dense(len(LABELS), activation='softmax')
])
model.compile(loss='categorical_crossentropy',
optimizer='rmsprop',
metrics=['accuracy', 'top_k_categorical_accuracy'])
test_file = 'C:/.../testlist01.txt'
train_file = 'C:/.../trainlist01.txt'
with open(test_file) as f:
test_list = [row.strip() for row in list(f)]
with open(train_file) as f:
train_list = [row.strip() for row in list(f)]
train_list = [row.split(' ')[0] for row in train_list]
def make_generator(file_list):
def generator():
np.random.shuffle(file_list)
for path in file_list:
full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')
&lt;denchmark-code&gt;        label = os.path.basename(os.path.dirname(path))
        features = np.load(full_path)

        padded_sequence = np.zeros((SEQUENCE_LENGTH, 1280))
        padded_sequence[0:len(features)] = np.array(features)

        transformed_label = encoder.transform([label])
        yield padded_sequence, transformed_label[0]
return generator
&lt;/denchmark-code&gt;

train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),
output_types=(tf.float32, tf.int16),
output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)
valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),
output_types=(tf.float32, tf.int16),
output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)
model.fit(train_dataset, epochs=17, validation_data=valid_dataset)
BASE_DIRECTORY = 'C:\...\saved_model\LSTM\1\';
tf.saved_model.save(model, BASE_DIRECTORY)
`
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='tmartin293' date='2019-11-06T06:26:17Z'>
		&lt;denchmark-link:https://github.com/tmartin293&gt;@tmartin293&lt;/denchmark-link&gt;

Request you to share the supporting files and code with proper indentation to reproduce the issue in our environment. Thanks!
		</comment>
		<comment id='2' author='tmartin293' date='2019-11-06T07:46:02Z'>
		Project code based on previous LSTM project for activity recognition using UCF101 dataset:
&lt;denchmark-link:https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter08/ch8_nb1_action_recognition.ipynb&gt;https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/blob/master/Chapter08/ch8_nb1_action_recognition.ipynb&lt;/denchmark-link&gt;

Dataset: &lt;denchmark-link:https://www.crcv.ucf.edu/data/UCF101.php&gt;https://www.crcv.ucf.edu/data/UCF101.php&lt;/denchmark-link&gt;

Code:
&lt;denchmark-code&gt;import tensorflow as tf
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tqdm
import datetime
from sklearn.preprocessing import LabelBinarizer 

# base path of video dataset
BASE_PATH = 'C:\\Users\\thoma\\Documents\\CSU East Bay\\2nd Year\\Fall 2019\\CS 663\\Exercises\\LSTM Exercise\\UCF101\\UCF-101'
VIDEOS_PATH = os.path.join(BASE_PATH, '**', '*.avi')

# sequence length LSTM will process
SEQUENCE_LENGTH = 40

def frame_generator():
    video_paths = tf.io.gfile.glob(VIDEOS_PATH)
    np.random.shuffle(video_paths)
    for video_path in video_paths:
        frames = []
        cap = cv2.VideoCapture(video_path)
        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)
        current_frame = 0
        
        label = os.path.basename(os.path.dirname(video_path))
        
        max_images = SEQUENCE_LENGTH
        while True:
            success, frame = cap.read()
            if not success:
                break
                
            if current_frame % sample_every_frame == 0:
                frame = frame[:, :, ::-1]
                img = tf.image.resize(frame, (224, 224))
                img = tf.keras.applications.mobilenet_v2.preprocess_input(img)
                max_images -= 1
                yield img, video_path
                
            if max_images == 0:
                break
            current_frame += 1

dataset = tf.data.Dataset.from_generator(frame_generator,
                                         output_types=(tf.float32, tf.string),
                                         output_shapes=((224, 224, 3), ()))

dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)

mobilenet_v2 = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')
x = mobilenet_v2.output

pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)
feature_extraction_model = tf.keras.Model(mobilenet_v2.input,pooling_output)

current_path = None
all_features = []

# go through the dataset and use the mobilenet_v2 model to 
# extract the features for each image
for img, batch_paths in tqdm.tqdm(dataset):
    batch_features = feature_extraction_model(img)
    # reshape the tensor
    batch_features = tf.reshape(batch_features,
                                (batch_features.shape[0], -1))
    
    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):
        if path != current_path and current_path is not None:
            output_path = current_path.decode().replace('.avi','.npy')
            np.save(output_path, all_features)
            all_features = []
            
        current_path = path
        all_features.append(features)
        
LABELS = ['UnevenBars','ApplyLipstick','TableTennisShot','Fencing','Mixing','SumoWrestling','HulaHoop','PommelHorse','HorseRiding','SkyDiving','BenchPress','GolfSwing','HeadMassage','FrontCrawl','Haircut','HandstandWalking','Skiing','PlayingDaf','PlayingSitar','FrisbeeCatch','CliffDiving','BoxingSpeedBag','Kayaking','Rafting','WritingOnBoard','VolleyballSpiking','Archery','MoppingFloor','JumpRope','Lunges','BasketballDunk','Surfing','SkateBoarding','FloorGymnastics','Billiards','CuttingInKitchen','BlowingCandles','PlayingCello','JugglingBalls','Drumming','ThrowDiscus','BaseballPitch','SoccerPenalty','Hammering','BodyWeightSquats','SoccerJuggling','CricketShot','BandMarching','PlayingPiano','BreastStroke','ApplyEyeMakeup','HighJump','IceDancing','HandstandPushups','RockClimbingIndoor','HammerThrow','WallPushups','RopeClimbing','Basketball','Shotput','Nunchucks','WalkingWithDog','PlayingFlute','PlayingDhol','PullUps','CricketBowling','BabyCrawling','Diving','TaiChi','YoYo','BlowDryHair','PushUps','ShavingBeard','Knitting','HorseRace','TrampolineJumping','Typing','Bowling','CleanAndJerk','MilitaryParade','FieldHockeyPenalty','PlayingViolin','Skijet','PizzaTossing','LongJump','PlayingTabla','PlayingGuitar','BrushingTeeth','PoleVault','Punch','ParallelBars','Biking','BalanceBeam','Swing','JavelinThrow','Rowing','StillRings','SalsaSpin','TennisSwing','JumpingJack','BoxingPunchingBag']
encoder = LabelBinarizer()
encoder.fit(LABELS)

#setup a keras Sequential model with 1) Masking layer  2) LSTM layer with 512 cells, dropout 0.5, recurrent_dropout of 0.5  
# 3) a fully connected relu activation layer with 256 outputs,  4) a droupout layer 5) a final decision fully connected layer of length of labels
# (which is the number of classes) with softmax activation
model = tf.keras.Sequential([
    tf.keras.layers.Masking(mask_value=0.),
    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(LABELS), activation='softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy', 'top_k_categorical_accuracy'])

test_file = 'C:/Users/thoma/Documents/CSU East Bay/2nd Year/Fall 2019/CS 663/Exercises/LSTM Exercise/testlist01.txt'
train_file = 'C:/Users/thoma/Documents/CSU East Bay/2nd Year/Fall 2019/CS 663/Exercises/LSTM Exercise/trainlist01.txt'

with open(test_file) as f:
    test_list = [row.strip() for row in list(f)]

with open(train_file) as f:
    train_list = [row.strip() for row in list(f)]
    train_list = [row.split(' ')[0] for row in train_list]
[trainlist01.txt](https://github.com/tensorflow/tensorflow/files/3813089/trainlist01.txt)
[testlist01.txt](https://github.com/tensorflow/tensorflow/files/3813090/testlist01.txt)

def make_generator(file_list):
    def generator():
        np.random.shuffle(file_list)
        for path in file_list:
            full_path = os.path.join(BASE_PATH, path).replace('.avi', '.npy')

            label = os.path.basename(os.path.dirname(path))
            features = np.load(full_path)

            padded_sequence = np.zeros((SEQUENCE_LENGTH, 1280))
            padded_sequence[0:len(features)] = np.array(features)

            transformed_label = encoder.transform([label])
            yield padded_sequence, transformed_label[0]
    return generator

# Setup the train_dataset and valid_dataset (validation/testing).  
# Here we setting up training batch sets of 16.  

train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),
                 output_types=(tf.float32, tf.int16),
                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)


valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),
                 output_types=(tf.float32, tf.int16),
                 output_shapes=((SEQUENCE_LENGTH, 1280), (len(LABELS))))
valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = 'logs', update_freq=1000)
model.fit(train_dataset, epochs=17, callbacks=[tensorboard_callback], validation_data=valid_dataset)

BASE_DIRECTORY = 'C:\\Users\\thoma\\Documents\\CSU East Bay\\2nd Year\\Fall 2019\\CS 663\\Exercises\\LSTM Exercise\\saved_model\\LSTM\\1\\';
tf.saved_model.save(model, BASE_DIRECTORY)

&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='tmartin293' date='2019-11-11T21:29:39Z'>
		&lt;denchmark-link:https://github.com/tmartin293&gt;@tmartin293&lt;/denchmark-link&gt;
 Please post this question in stack overflow as this question is not related to bug/performance, build/install, docs or feature request. Thanks!
		</comment>
		<comment id='4' author='tmartin293' date='2019-12-27T01:00:22Z'>
		This does seem like a bug
		</comment>
		<comment id='5' author='tmartin293' date='2020-02-03T23:37:39Z'>
		I tried a different model that has  using method without a generator and  I didn't run into any error. Heres my &lt;denchmark-link:https://colab.sandbox.google.com/gist/gowthamkpr/b1082d7f664edeca3929108d56792f79/untitled4.ipynb&gt;gist&lt;/denchmark-link&gt;

&lt;denchmark-link:https://github.com/tmartin293&gt;@tmartin293&lt;/denchmark-link&gt;
 Can you please check if the error still exists with tf-nightly? Thanks!
		</comment>
		<comment id='6' author='tmartin293' date='2020-03-04T23:09:05Z'>
		&lt;denchmark-link:https://github.com/tmartin293&gt;@tmartin293&lt;/denchmark-link&gt;
 Can you please try with recent  and let us know whether it was resolved for you? Thanks!
		</comment>
		<comment id='7' author='tmartin293' date='2020-03-21T01:09:32Z'>
		It has been 15 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='8' author='tmartin293' date='2020-03-21T16:51:58Z'>
		Closing due to lack of recent activity. Similar issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34644&gt;#34644&lt;/denchmark-link&gt;
 was resolved by recent . Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='9' author='tmartin293' date='2020-03-21T16:52:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34021&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34021&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='tmartin293' date='2020-04-22T20:33:13Z'>
		It occurs when dropout parameter is used on the LSTM. Still occuring in TF 2.1
		</comment>
		<comment id='11' author='tmartin293' date='2020-04-22T21:30:20Z'>
		&lt;denchmark-link:https://github.com/wtesler&gt;@wtesler&lt;/denchmark-link&gt;
 Can you please open a new issue with a standalone code to reproduce the error. Thanks!
		</comment>
	</comments>
</bug>