<bug id='34213' author='RogueLogix' open_date='2019-11-13T02:41:19Z' closed_time='2020-11-05T08:00:45Z'>
	<summary>MultiWorkerMirroredStrategy distribution error BaseCollectiveExecutor::StartAbort Invalid argument: Lower bound check fail for input 1 from node Mkl2Tf/_30 to node scoped_allocator_concat_1_1</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no-ish, keras multi-worker mirrored example
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora Server 31
TensorFlow installed from (source or binary): source (master branch, commit 73a3413), identical on both machines
TensorFlow version (use command below): v1.12.1-17924-g73a34133f6 2.0.0
Python version: 3.7.5
Bazel version (if compiling from source): 1.1.0
GCC/Compiler version (if compiling from source): GCC 9.2.1
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Crashes at model.fit
Describe the expected behavior
Not, crash?

Exact code used
&lt;denchmark-link:https://pastebin.com/CtTjs146&gt;Node0&lt;/denchmark-link&gt;

&lt;denchmark-link:https://pastebin.com/5LtGA6Hd&gt;Node1&lt;/denchmark-link&gt;


Logs from run
&lt;denchmark-link:https://pastebin.com/HQAQwtBg&gt;Node0&lt;/denchmark-link&gt;

&lt;denchmark-link:https://pastebin.com/ZFUjWkzf&gt;Node1&lt;/denchmark-link&gt;

To compile on Fedora 31 I did need to use a grpc version patch, this patch can be found &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33758#issuecomment-547867642&gt;here&lt;/denchmark-link&gt;
 in issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33758&gt;#33758&lt;/denchmark-link&gt;
. It consists of running this command before compiling tensorflow.
&lt;denchmark-code&gt;curl -L https://github.com/tensorflow/tensorflow/compare/master...hi-ogawa:grpc-backport-pr-18950.patch | git apply
&lt;/denchmark-code&gt;

bazel configured with Python 3 directory, and default otherwise.
bazel build command used is as follows
&lt;denchmark-code&gt;bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='RogueLogix' date='2019-11-17T00:20:17Z'>
		This seems to be a MKL related issue, as I got it working by recompiling without --config=mkl in the build, though with some seeming unrelated dataset overrun issues there
		</comment>
		<comment id='2' author='RogueLogix' date='2019-11-21T18:13:20Z'>
		&lt;denchmark-link:https://github.com/TensorFlow-MKL&gt;@TensorFlow-MKL&lt;/denchmark-link&gt;
 Could you please help take a look? Thank you very much!
		</comment>
		<comment id='3' author='RogueLogix' date='2019-11-21T23:53:59Z'>
		we are looking into this issue. will keep you posted on our findings shortly
		</comment>
		<comment id='4' author='RogueLogix' date='2020-01-29T23:46:25Z'>
		&lt;denchmark-link:https://github.com/preethivenkatesh&gt;@preethivenkatesh&lt;/denchmark-link&gt;
 Any updates?
		</comment>
		<comment id='5' author='RogueLogix' date='2020-02-12T00:32:08Z'>
		We have an engineer looking into this issue now. I'll keep you posted
		</comment>
		<comment id='6' author='RogueLogix' date='2020-02-12T00:33:51Z'>
		&lt;denchmark-link:https://github.com/preethivenkatesh&gt;@preethivenkatesh&lt;/denchmark-link&gt;
 Thank you very much!
		</comment>
		<comment id='7' author='RogueLogix' date='2020-04-27T02:14:46Z'>
		any updates?
		</comment>
		<comment id='8' author='RogueLogix' date='2020-05-22T00:00:10Z'>
		We looked at the issue. The issue is coming form the fact that Intel optimization does not support Scope allocator optimization. Scope allocator optimization is applied by default to Tensorflow's own distributed strategy. We can temporarily disable this optimization (scope allocator optimization) from multi-worker distribution strategy when used Intel optimization. The example should still run correctly. Will this be ok? Moreover, we are planning to support Scope allocator optimization for Intel Optimized Tensorflow in few months, and then we will again enable Scope allocator optimization.
		</comment>
		<comment id='9' author='RogueLogix' date='2020-05-22T02:38:54Z'>
		I'm not in need of the fix right now, I just ran into this issue, so do whatever you believe is best.
		</comment>
		<comment id='10' author='RogueLogix' date='2020-06-23T08:24:15Z'>
		&lt;denchmark-link:https://github.com/RogueLogix&gt;@RogueLogix&lt;/denchmark-link&gt;
 Is it possible that you close this issue?
		</comment>
		<comment id='11' author='RogueLogix' date='2020-11-05T07:53:13Z'>
		&lt;denchmark-link:https://github.com/RogueLogix&gt;@RogueLogix&lt;/denchmark-link&gt;
 Could you close this issue?
		</comment>
		<comment id='12' author='RogueLogix' date='2020-11-05T08:00:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34213&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34213&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='RogueLogix' date='2020-11-05T08:45:10Z'>
		&lt;denchmark-link:https://github.com/RogueLogix&gt;@RogueLogix&lt;/denchmark-link&gt;
  Thank you very much!
		</comment>
	</comments>
</bug>