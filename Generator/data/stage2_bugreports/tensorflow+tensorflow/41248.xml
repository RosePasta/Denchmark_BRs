<bug id='41248' author='scarlehoff' open_date='2020-07-09T19:37:46Z' closed_time='2020-08-25T21:42:05Z'>
	<summary>target_tensor argument from tf.keras.Model compile() method has dissapeared</summary>
	<description>
I am not entirely sure whether this is a bug or not.
I have a piece of code which was relying in the  argument of the  method. This code works fine in TF 2.1, however when updating to TF 2.2 it stopped working.
Looking in the documentation I've noticed that indeed, the argument  has dissapeared &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile&gt;link&lt;/denchmark-link&gt;
 however I haven't seen any mentions to this in the changelog.
Is this a bug or is it intentional? The error message just says
ValueError: target_tensors argument is not supported when executing eagerly
But looking at the source code 


tensorflow/tensorflow/python/keras/engine/training.py


         Line 2496
      in
      ae975ee






 if kwargs.pop('target_tensors', None) is not None: 




 this argument is clearly not accepted anymore.
If it is intentional, is there a recommended workaround? I can think of several not-very-intrusive ways around it, but all them feel a bit hacky.
	</description>
	<comments>
		<comment id='1' author='scarlehoff' date='2020-07-10T13:30:27Z'>
		&lt;denchmark-link:https://github.com/scarlehoff&gt;@scarlehoff&lt;/denchmark-link&gt;
,
In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='scarlehoff' date='2020-07-10T14:35:45Z'>
		Hi &lt;denchmark-link:https://github.com/amahendrakar&gt;@amahendrakar&lt;/denchmark-link&gt;
 sadly I cannot provide the code, but I've written a MWE that works fine in TF 2.1 but not in TF 2.2 or 2.3.
&lt;denchmark-code&gt;
import tensorflow as tf
import numpy as np

x = np.random.rand(1, 10)
y = np.random.rand(4)

my_model = tf.keras.Sequential(layers=tf.keras.layers.Dense(4, input_shape=(10,) ))
my_model.compile(loss='mse', target_tensors=[y], run_eagerly=False)

my_model.fit(x)
&lt;/denchmark-code&gt;

In TF 2.1 works while in 2.2 I get the following error:
ValueError: target_tensors argument is not supported when executing eagerly.
Note that I am explicitly setting run_eagerly=False (even thought I believe that's the default).
I know I can use disable_eager_execution to change the behaviour of my whole codebase but that's not what I would like to do.
In short, I would like to know whether this is an intentional change (i.e., target_tensors is basically not supported any more, since it is not included in the documentation).
		</comment>
		<comment id='3' author='scarlehoff' date='2020-07-15T08:23:43Z'>
		Was able to reproduce the issue with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/20fbce37e51bd27e2a57ea0e1a949316/41248.ipynb#scrollTo=wW5LjcAYgtyh&gt;TF v2.2&lt;/denchmark-link&gt;
, &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/a10f3be1d3b184b0359ae7ff01ca0665/41248-2-3.ipynb#scrollTo=vH4tBjkZhAOO&gt;TF v2.3.0-rc1&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/74ee054b72deb740aa8cb8755deb4235/41248-tf-nightly.ipynb&gt;TF-nightly&lt;/denchmark-link&gt;
. Facing an error stating  on running the code.
However, not facing any issues while running with &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/44cefdb88221ca255e4f02d0006bde7b/41248-2-1.ipynb&gt;TF v2.1&lt;/denchmark-link&gt;
. Please find the attached gist. Thanks!
		</comment>
		<comment id='4' author='scarlehoff' date='2020-07-20T17:31:51Z'>
		&lt;denchmark-link:https://github.com/scarlehoff&gt;@scarlehoff&lt;/denchmark-link&gt;
 Thanks for the issue!
Yes, target_tensors is no longer supported, as internally we shifted Keras away from using a global graph and towards using tf.function, and so the target-tensors concept was no longer feasible to support. Could you advise on a minimal example of what you'd like to use target tensors for, and I can advise on a workaround?
		</comment>
		<comment id='5' author='scarlehoff' date='2020-07-21T07:01:34Z'>
		Hi &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
, one example is the one I wrote above. I've already written a workaround for my particular problem (that is as fast as it was with 2.1, the main reason I was using  is speed).
It would be really helpful to change the error message when using target_tensors as it is a red herring (my first thought was, oh, no, somehow everything is running in eager mode now!)
In any case, even if I've already solved my problem let me include a minimal version of it and its workaround because surely there is a better way. It could also be helpful for some people looking for a solution, even if happens to be suboptimal.
To first approximation would like to be able to do this:
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

x = np.random.rand(1, 10)
y = np.random.rand(4)

my_model = tf.keras.Sequential(layers=tf.keras.layers.Dense(4, input_shape=(10,) ))
my_model.compile(loss='mse', target_tensors=[y], run_eagerly=False)

for _ in range(epochs):
    my_model.evaluate(x, y = None)
&lt;/denchmark-code&gt;

Since passing the y values for every step makes it become really slow.
&lt;denchmark-code&gt;for _ in range(epochs):
    my_model.evaluate(x, y = y) # very slow
&lt;/denchmark-code&gt;

My solution has been to use make_test_function to create a custom evaluate function which has already the y value compiled like
&lt;denchmark-code&gt;    def make_test_function(self):
        @tf.function
        def evaluate():
            ret = calculate_loss_of_model()
            return ret
        return evaluate
&lt;/denchmark-code&gt;

so I can indeed do my_model.evaluate(x, y = None) and recover the same performance I had when using TF 2.1.
Please let me know if you think there's a better way.
		</comment>
		<comment id='6' author='scarlehoff' date='2020-08-25T21:42:05Z'>
		Looks good to me, the other thing is that usually model.evaluate should be called on all the data at once, it's a batch-processing API. Calling it for each batch will be slow bc the tf.function might retrace if it can't determine that the input data is of the same type, shape, dtype, etc
		</comment>
		<comment id='7' author='scarlehoff' date='2020-08-25T21:42:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41248&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41248&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>