<bug id='41572' author='vietnamican' open_date='2020-07-21T01:33:53Z' closed_time='2020-08-18T16:27:37Z'>
	<summary>[TF 2.2.0] tf.io.decode_image caught CUDA_ERROR_NOT_INITIALIZED: initialization error when use_multiprocessing=True</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):
Python version: 3.6.9
GCC/Compiler version (if compiling from source): 8.4.0
CUDA/cuDNN version: 10.1/7.6.5
GPU model and memory: 6GB

I try to decode a dataset in *.tfrecord type using tf.io.decode_image
&lt;denchmark-code&gt;def get_item(type, index):
    if type == 'trainval':
        item = images_trainval[index]
    else:
        item = images_val[index]

    image = item['image/encoded']
    image = tf.io.decode_image(image, 3)
    image = image.numpy()

    mask = item['image/segmentation/class/encoded']
    mask = tf.io.decode_image(mask, 1)
    mask = mask.numpy()
    mask = mask.reshape(mask.shape[:2])

    return image, mask

class DLDataset(Dataset):
    def __init__(self, split, dataset_dir):
        self.split = split
        
        self.transformer = data_transforms[split]

    def __getitem__(self, i):
        image, mask = get_item(self.split, i)

        image, mask = safe_crop(image, mask, size=512)
        image = transforms.ToPILImage()(image.copy().astype(np.uint8))
        image = self.transformer(image)

        mask = torch.from_numpy(mask)

        return image, mask

    def __len__(self):
        return get_len(self.split)
&lt;/denchmark-code&gt;

And it caught error:
&lt;denchmark-code&gt;...
2020-07-21 08:04:06.203528: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203533: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203532: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203538: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203537: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203547: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203559: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203561: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203556: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203564: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203568: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203572: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203571: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203568: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203578: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203577: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203585: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
2020-07-21 08:04:06.203585: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 2.2K (2304 bytes) from device: CUDA_ERROR_NOT_INITIALIZED: initialization error
...
&lt;/denchmark-code&gt;

The error seems to be infinities. I had to press Ctrl + C to stop it.
But, when I try a clearly function (tf.io.decode_jpeg and tf.io.decode_png instead of tf.io.decode_image)
&lt;denchmark-code&gt;def get_item(type, index):
    if type == 'trainval':
        item = images_trainval[index]
    else:
        item = images_val[index]

    image = item['image/encoded']
    image = tf.io.decode_jpeg(image, 3)
    image = image.numpy()

    mask = item['image/segmentation/class/encoded']
    mask = tf.io.decode_png(mask, 1)
    mask = mask.numpy()
    mask = mask.reshape(mask.shape[:2])

    return image, mask
&lt;/denchmark-code&gt;

It work perfectly.
I noticed this error occurs when use workers &gt; 1 and use_multiprocessing = True in model fit. If i don't use multi workers, It will work.
	</description>
	<comments>
		<comment id='1' author='vietnamican' date='2020-07-21T07:35:03Z'>
		&lt;denchmark-link:https://github.com/vietnamican&gt;@vietnamican&lt;/denchmark-link&gt;

Looks like code is incomplete.Request you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='vietnamican' date='2020-07-25T06:01:26Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
. This is the simply version in colab:
&lt;denchmark-link:https://colab.research.google.com/drive/1tt3DmJ7CPQXklKFhtPOl7bF8mBVff1ov?usp=sharing&gt;https://colab.research.google.com/drive/1tt3DmJ7CPQXklKFhtPOl7bF8mBVff1ov?usp=sharing&lt;/denchmark-link&gt;

In notebook, It seems that the error is thread be locked rather than CUDA error
		</comment>
		<comment id='3' author='vietnamican' date='2020-07-27T06:33:10Z'>
		I have tried in colab with TF version 2.2,nightly version().Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/931d530a2a92272556b394654d7572cd/untitled184.ipynb&gt;here&lt;/denchmark-link&gt;
.You are also seeing the same behavior?.Thanks!
		</comment>
		<comment id='4' author='vietnamican' date='2020-07-27T15:16:51Z'>
		Look like tf.io.decode_image and torch.utils.data.Dataset is not compatible. I do not know where the error occurred, it maybe in tensorflow or it may be in pytorch. But now we can still handle it by using altenative function to decode image from TFRecord.
Are you going to investigate it?
		</comment>
		<comment id='5' author='vietnamican' date='2020-08-04T15:36:43Z'>
		&lt;denchmark-link:https://github.com/vietnamican&gt;@vietnamican&lt;/denchmark-link&gt;
 Were you able to find the cause of the error? Tried to reproduce this issue but was not able to
		</comment>
		<comment id='6' author='vietnamican' date='2020-08-11T16:21:06Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='7' author='vietnamican' date='2020-08-18T16:27:36Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='8' author='vietnamican' date='2020-08-18T16:27:38Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41572&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41572&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>