<bug id='34866' author='jtdutta1' open_date='2019-12-05T12:44:02Z' closed_time='2020-04-14T23:47:17Z'>
	<summary>Keras Custom Loss/Model Compilation</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10 1909
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
TensorFlow installed from (source or binary):
Binary, Pip
TensorFlow version (use command below):
1.14
Python version:
3.7.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
10/7.6.4
GPU model and memory:
RTX 2080 with 8GB VRAM, 16GB DRAM DDR4

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
for 1: unknown 1.14.0
Describe the current behavior
Model compilation fails with the following error.
&lt;denchmark-code&gt;Traceback (most recent call last):
  File ".\vgg_loss.py", line 103, in &lt;module&gt;
    main()
  File ".\vgg_loss.py", line 97, in main
    model.compile(optimizer='adam', loss=some_loss, metrics=['accuracy'])
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\base.py", 
line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py", 
line 337, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\training\tracking\base.py", 
line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py", 
line 1710, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
otal_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\keras\losses.py", line 215, 
in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File ".\vgg_loss.py", line 86, in some_loss
    return mse(vgg_model.predict(y_pred, steps=1), vgg_model.predict(y_true, steps=1))
  File "C:\Users\Intel\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py", 
line 1078, in predict       callbacks=callbacks)
    batch_outs = f(actual_inputs)
    run_metadata=self.run_metadata)
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
   (0) Invalid argument: You must feed a value for placeholder tensor 'input_node' with dtype 
     float 
and shape [1,512,512,3]
          [[{{node input_node}}]]
          [[block4_conv3/Relu/_217]]
   (1) Invalid argument: You must feed a value for placeholder tensor 'input_node' with dtype float 
 and shape [1,512,512,3]
          [[{{node input_node}}]]
 0 successful operations.
 0 derived errors ignored.
&lt;/denchmark-code&gt;

Describe the expected behavior
The code should compile properly.

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
I am attaching the &lt;denchmark-link:https://github.com/jtdutta1/Fastest/blob/master/vgg_loss.py&gt;link&lt;/denchmark-link&gt;
 to the code.
Also download the vgg model whose link is provided in the code. I am also referencing &lt;denchmark-link:https://drive.google.com/open?id=1OsKx6CPacs7V7d-1cNCI2bFIty2BVQEz&gt;here&lt;/denchmark-link&gt;
 again.
Be sure to run it as
&lt;denchmark-code&gt;python vgg_loss.py -p &lt;path_to_vgg_model&gt;
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='jtdutta1' date='2019-12-10T09:32:03Z'>
		I was able to replicate issue with given code in local for TF-1.14. Thank you!
		</comment>
		<comment id='2' author='jtdutta1' date='2019-12-11T06:45:47Z'>
		I didn't check myself, but does this issue occur in TF2.0? I'm using TF1.14 only because model compilation makes a dummy call to the loss function which involves empty tensors and there are core tf elements, which in 2.0 are eagerly executed by default, so ends up throwing empty tensor errors.
		</comment>
		<comment id='3' author='jtdutta1' date='2019-12-11T14:44:00Z'>
		I tried it using Tensorflow 2.0 and this was the error:-
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "vgg_loss.py", line 103, in &lt;module&gt;
    main()
  File "vgg_loss.py", line 97, in main
    model.compile(optimizer='adam', loss=some_loss, metrics=['accuracy'])
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\training\tracking\base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 373, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\training\tracking\base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 1653, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 1713, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\losses.py", line 221, in call
    return self.fn(y_true, y_pred, **self._fn_kwargs)
  File "vgg_loss.py", line 86, in some_loss
    return mse(vgg_model.predict(y_pred, steps=1), vgg_model.predict(y_true, steps=1))
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py", line 909, in predict
    use_multiprocessing=use_multiprocessing)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py", line 722, in predict
    callbacks=callbacks)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\engine\training_arrays.py", line 299, in model_iteration
    batch_outs = f(actual_inputs)
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\backend.py", line 3748, in __call__
    [x._numpy() for x in outputs],  # pylint: disable=protected-access
  File "C:\Users\Intel\Anaconda3\envs\tensorflowgpu\lib\site-packages\tensorflow_core\python\keras\backend.py", line 3748, in &lt;listcomp&gt;
    [x._numpy() for x in outputs],  # pylint: disable=protected-access
AttributeError: 'Tensor' object has no attribute '_numpy'
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='jtdutta1' date='2019-12-13T13:39:55Z'>
		I met similar issues in tf=1.14.0 of above. But I can give a workaround solution.
First, for tf=1.14.0 of above you have to explicit assign y_true by label_ref=tf.keras.layers.Input. Otherwise, tf is not able compute shape.
            # workaround solution
            if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
                label_mask  = y_true
                pre_softmax = clf_out
            else:
                label_mask  = label_ref
                pre_softmax = clf_out   
Second, label_ref should be the input and feed to model.
        # workaround solution
        if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
            input_list = [clf_input]
        else:
            input_list = [clf_input, label_ref]
Third, you have to adjust the output of the data pipeline and the input for evaluation
        # workaround solution
        if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
            outputX = dataX
        else:
            outputX = (dataX, dataY)
    # workaround solution
    if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
        model.evaluate(testX, testY, verbose=2, batch_size=batch_size)
    else:
        model.evaluate( (testX, testY), testY, verbose=2, batch_size=batch_size)
Finallu, for tf=2.x you have to disable eager_mode at the begin of the program.
import tensorflow as tf

# disable eager model for tf=2.x
if LooseVersion(tf.__version__) &gt;= LooseVersion('2.0.0'):
    tf.compat.v1.disable_eager_execution()
The following is the minimal testcase which works well in tf=1.13.1 or above:
#%%
from distutils.version import LooseVersion
import numpy as np
import tensorflow as tf

# disable eager model for tf=2.x
if LooseVersion(tf.__version__) &gt;= LooseVersion('2.0.0'):
    tf.compat.v1.disable_eager_execution()

batch_size = 100
#%%
def download_data():

    # get raw data
    (trainX, trainY), (testX, testY) = tf.keras.datasets.cifar10.load_data()
    trainX = trainX.astype(np.float32)
    testX  = testX.astype(np.float32)

    # ont-hot
    trainY = tf.keras.utils.to_categorical(trainY, 10)
    testY  = tf.keras.utils.to_categorical(testY , 10)

    # get validation sets
    training_size = 45000
    validX = trainX[training_size:,:]
    validY = trainY[training_size:,:]

    trainX = trainX[:training_size,:]
    trainY = trainY[:training_size,:]

    return trainX, trainY, validX, validY, testX, testY

#%%
def data_pipeline(dataX, dataY):

    # create dataset API
    def preprocess_fn(dataX, dataY):
        
        dataX = tf.image.random_flip_left_right(dataX)

        # workaround solution
        if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
            outputX = dataX
        else:
            outputX = (dataX, dataY)
        return outputX, dataY

    dataset = tf.data.Dataset.from_tensor_slices( (dataX, dataY) )
    dataset = dataset.shuffle(batch_size * 8)
    dataset = dataset.repeat()
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(preprocess_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
    return dataset

#%%
class custom_model():
    def __init__(self):

        # custom loss
        def cw_loss(y_true, y_pred):

            # workaround solution
            if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
                label_mask  = y_true
                pre_softmax = clf_out
            else:
                label_mask  = label_ref
                pre_softmax = clf_out                

            # API changed
            if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
                correct_logit = tf.reduce_sum(label_mask * pre_softmax, axis=1, keep_dims=True)
            else:
                correct_logit = tf.reduce_sum(label_mask * pre_softmax, axis=1, keepdims=True)

            distance = tf.nn.relu( pre_softmax - correct_logit + (1-label_mask) * 10) 
            inactivate = tf.cast( tf.less_equal(distance, 1e-9), dtype=tf.float32)
            weight = tf.keras.layers.Activation('softmax')(-1e9*inactivate + distance)
            loss = tf.reduce_sum((1-label_mask) * distance * weight, axis=1)
            loss = tf.math.reduce_mean(loss)
            return loss

        # API changed
        if LooseVersion(tf.__version__) &lt; LooseVersion('2.0.0'):
            model = tf.keras.applications.ResNet50(include_top=True, weights=None, input_shape=(32,32,3), pooling='max', classes=10)
        else:
            model = tf.keras.applications.resnet.ResNet50(include_top=True, weights=None, input_shape=(32,32,3), pooling='max', classes=10)

        clf_input = tf.keras.layers.Input(shape=(32,32,3), name="model/input")
        label_ref = tf.keras.layers.Input(shape=(10,) , name='label_ref')
        clf_out   = model(clf_input)

        # workaround solution
        if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
            input_list = [clf_input]
        else:
            input_list = [clf_input, label_ref]
    
        clf_model = tf.keras.models.Model(inputs=input_list, outputs=clf_out, name='clf_model')
        clf_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy', cw_loss])

        self.clf_model = clf_model

#%%
if __name__ == '__main__':

    # set GPU
    import os
    if os.environ.get("CUDA_VISIBLE_DEVICES") is None:
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"

    # reset tf session
    tf.compat.v1.keras.backend.clear_session()
    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)
    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))
    tf.compat.v1.keras.backend.set_session(sess) 

    # prepare data
    trainX, trainY, validX, validY, testX, testY = download_data()
    train_gen = data_pipeline(trainX, trainY)
    valid_gen = data_pipeline(validX, validY)
    test_gen = data_pipeline(testX, testY)

    # build targeted model
    targeted_model = custom_model()
    model = targeted_model.clf_model
    
    # fit and evalutate
    model.fit(train_gen,
            steps_per_epoch = trainY.shape[0] // batch_size,
            validation_data = valid_gen,
            validation_steps= validY.shape[0] // batch_size,
            epochs=5,
            verbose=2)

    # workaround solution
    if LooseVersion(tf.__version__) &lt; LooseVersion('1.14.0'):
        model.evaluate(testX, testY, verbose=2, batch_size=batch_size)
    else:
        model.evaluate( (testX, testY), testY, verbose=2, batch_size=batch_size)
The output in tf=1.13.1:
&lt;denchmark-code&gt;Epoch 1/5
 - 33s - loss: 2.4371 - acc: 0.2622 - cw_loss: 9.9063 - val_loss: 1.9639 - val_acc: 0.3262 - val_cw_loss: 9.8715
Epoch 2/5
 - 26s - loss: 1.8737 - acc: 0.3829 - cw_loss: 9.8150 - val_loss: 1.8466 - val_acc: 0.4072 - val_cw_loss: 9.8049
Epoch 3/5
 - 26s - loss: 1.6805 - acc: 0.4436 - cw_loss: 9.7643 - val_loss: 1.5574 - val_acc: 0.4428 - val_cw_loss: 9.7727
Epoch 4/5
 - 26s - loss: 1.5725 - acc: 0.4780 - cw_loss: 9.7303 - val_loss: 1.5726 - val_acc: 0.4788 - val_cw_loss: 9.7395
Epoch 5/5
 - 26s - loss: 1.5086 - acc: 0.5021 - cw_loss: 9.7073 - val_loss: 2.6803 - val_acc: 0.3964 - val_cw_loss: 9.8093
 - 4s - loss: 2.8093 - acc: 0.3939 - cw_loss: 9.8100
&lt;/denchmark-code&gt;

The output in tf=1.14.0:
&lt;denchmark-code&gt;Epoch 1/5
450/450 - 20s - loss: 2.5021 - acc: 0.2659 - cw_loss: 9.9067 - val_loss: 2.7677 - val_acc: 0.3236 - val_cw_loss: 9.8703
Epoch 2/5
450/450 - 13s - loss: 1.9023 - acc: 0.3856 - cw_loss: 9.8141 - val_loss: 2.2765 - val_acc: 0.4022 - val_cw_loss: 9.8072
Epoch 3/5
450/450 - 13s - loss: 1.6946 - acc: 0.4444 - cw_loss: 9.7639 - val_loss: 1.9999 - val_acc: 0.4464 - val_cw_loss: 9.7686
Epoch 4/5
450/450 - 13s - loss: 1.5590 - acc: 0.4810 - cw_loss: 9.7266 - val_loss: 1.5991 - val_acc: 0.4850 - val_cw_loss: 9.7293
Epoch 5/5
450/450 - 13s - loss: 1.4503 - acc: 0.5138 - cw_loss: 9.6943 - val_loss: 1.4578 - val_acc: 0.4950 - val_cw_loss: 9.6983
10000/10000 - 3s - loss: 1.4257 - acc: 0.5055 - cw_loss: 9.6953
&lt;/denchmark-code&gt;

The output in tf=2.0.0:
&lt;denchmark-code&gt;450/450 - 41s - loss: 2.3526 - accuracy: 0.3121 - cw_loss: 9.8773 - val_loss: 1.6616 - val_accuracy: 0.3846 - val_cw_loss: 9.8367
Epoch 2/5
450/450 - 30s - loss: 1.8045 - accuracy: 0.4361 - cw_loss: 9.7745 - val_loss: 2.3301 - val_accuracy: 0.4514 - val_cw_loss: 9.7658
Epoch 3/5
450/450 - 31s - loss: 1.6255 - accuracy: 0.4912 - cw_loss: 9.7207 - val_loss: 2.2725 - val_accuracy: 0.4530 - val_cw_loss: 9.7586
Epoch 4/5
450/450 - 30s - loss: 1.5215 - accuracy: 0.5255 - cw_loss: 9.6794 - val_loss: 5.8537 - val_accuracy: 0.4990 - val_cw_loss: 9.7133
Epoch 5/5
450/450 - 30s - loss: 1.4084 - accuracy: 0.5554 - cw_loss: 9.6447 - val_loss: 1.4579 - val_accuracy: 0.5442 - val_cw_loss: 9.6705
10000/10000 - 3s - loss: 1.5397 - accuracy: 0.5363 - cw_loss: 9.6739
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='jtdutta1' date='2019-12-16T04:09:20Z'>
		Ok I'll try to give this a try and get back to you in a week.
		</comment>
		<comment id='6' author='jtdutta1' date='2020-04-14T23:47:16Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='7' author='jtdutta1' date='2020-04-14T23:47:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34866&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34866&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>