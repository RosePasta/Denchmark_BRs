<bug id='35568' author='hoangcuong2011' open_date='2020-01-03T18:19:39Z' closed_time='2020-01-07T01:37:32Z'>
	<summary>A bug with inaccurate metric accuracy when using closure loss</summary>
	<description>
I just wanted to report a bug with closure loss in TF that gives us inaccurate accuracy result. Let me first by providing a simple code that build image classification on MNIST dataset successfully in [1]. I trained the model with 1 epoch and I got a very decent result:
Result:
60000/60000 [==============================] - 10s 168us/sample - loss: 0.2097 - acc: 0.9362 - val_loss: 0.0459 - val_acc: 0.9850
However, when I change the loss to using a "closure" loss as in [2], I got a different result regarding to the accuracy.
60000/60000 [==============================] - 10s 165us/sample - loss: 0.1980 - acc: 0.0989 - val_loss: 0.0433 - val_acc: 0.0995
Indeed, I found the reported accuracy (acc and val_acc) is very inaccurate, which I believe is a bug.  You can check the prediction output for some examples, which is highly accurate.
Meanwhile the loss is computed correctly I think.
Code for [1]:
&lt;denchmark-code&gt;from __future__ import print_function
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K
import numpy as np


num_classes = 10
epochs = 1

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

def create_model():
  input_sequence = tf.keras.layers.Input(dtype='float32', shape=input_shape, name='input_sequence') 
  conv1 = Conv2D(32, kernel_size=(3, 3),
                   activation='relu')(input_sequence)
  conv2d = Conv2D(64, (3, 3), activation='relu')(conv1)
  conv2d = Dropout(0.25)(MaxPooling2D(pool_size=(2, 2))(conv2d))
  conv2d = Flatten()(conv2d)
  conv2d = Dropout(0.5)(Dense(128, activation='relu')(conv2d))
  output = Dense(num_classes, activation='softmax')(conv2d)
  model = tf.keras.models.Model(inputs=[input_sequence], outputs=output)
  model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                optimizer=keras.optimizers.Adam(),
                metrics=['accuracy'])
  return model
  
model = create_model()
batch_size = 64
model.fit([np.array(x_train)], np.array(y_train),
  verbose=1,
  batch_size = batch_size,
  epochs=epochs,
  validation_data=([x_test], np.array(y_test)))
a = model.predict([x_test])
for x, y in zip(a[:20], y_test[:20]):
  print(x, np.argmax(x), y)
&lt;/denchmark-code&gt;

Code for [2]:
&lt;denchmark-code&gt;
from __future__ import print_function
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K
import numpy as np

num_classes = 10
epochs = 1

# input image dimensions
img_rows, img_cols = 28, 28

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

def create_model():
  input_sequence = tf.keras.layers.Input(dtype='float32', shape=input_shape, name='input_sequence') 
  conv1 = Conv2D(32, kernel_size=(3, 3),
                   activation='relu')(input_sequence)
  conv2d = Conv2D(64, (3, 3), activation='relu')(conv1)
  conv2d = Dropout(0.25)(MaxPooling2D(pool_size=(2, 2))(conv2d))
  conv2d = Flatten()(conv2d)
  conv2d = Dropout(0.5)(Dense(128, activation='relu')(conv2d))
  output = Dense(num_classes, activation='softmax')(conv2d)
  model = tf.keras.models.Model(inputs=[input_sequence], outputs=output)
  def custom_loss():
    def loss(y_true, y_predict):
      return tf.keras.losses.sparse_categorical_crossentropy(y_true, y_predict)
    return loss
  model.compile(loss=custom_loss(),
                optimizer=keras.optimizers.Adam(),
                metrics=['accuracy'])
  return model
  
model = create_model()
batch_size = 64
model.fit([np.array(x_train)], np.array(y_train),
  verbose=1,
  batch_size = batch_size,
  epochs=epochs,
  validation_data=([x_test], np.array(y_test)))
a = model.predict([x_test])
for x, y in zip(a[:20], y_test[:20]):
  print(x, np.argmax(x), y)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hoangcuong2011' date='2020-01-06T10:52:09Z'>
		Was able to reproduce the issue. Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/amahendrakar/481b5f3467fb7d7cba54cacc35bfdf76/35568.ipynb&gt;Gist&lt;/denchmark-link&gt;
 here. Thanks!
		</comment>
		<comment id='2' author='hoangcuong2011' date='2020-01-07T01:37:32Z'>
		&lt;denchmark-link:https://github.com/hoangcuong2011&gt;@hoangcuong2011&lt;/denchmark-link&gt;
 When you use ,  is internally inferred as . Just a small modification is required to your code. Please change  to . With that change, code works as expected. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/28e63296847d8838dfdab64220700721/untitled731.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
I am closing this issue as it was resolved. Please feel free to reopen the issue if the issue persists again. thanks!
		</comment>
		<comment id='3' author='hoangcuong2011' date='2020-01-07T01:37:34Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35568&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35568&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>