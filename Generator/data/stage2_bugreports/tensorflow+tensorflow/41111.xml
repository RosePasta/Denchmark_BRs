<bug id='41111' author='hoangcuong2011' open_date='2020-07-05T20:01:15Z' closed_time='2020-08-24T21:25:46Z'>
	<summary>Bug: tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor X with dtype Y and shape X</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): &gt;= 2.0
Python version: 3.6
Running on: CPUs (But I guess it happens on GPUs as well)

From my experience, this type of bug appears very often (I have posted a similar bug before &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40977&gt;#40977&lt;/denchmark-link&gt;
). Here is a (dumb) example where I write a custom layer and pass a parameter via () when I call that layer (Note that I turn off eager_execution). Running the following code results in the below error:
&lt;denchmark-code&gt;import tensorflow as tf
tf.compat.v1.disable_eager_execution()
from tensorflow.keras import backend as K
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

class MyWordEmbedding(tf.keras.layers.Layer):
    def build(self, input_shape):
        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')
        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end
    
    def call(self, inputs):
        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])

class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self, mask_para, **kwargs):
        self.mask_para = mask_para
        super(EncoderLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))
        super(EncoderLayer, self).build(input_shape)

    def call(self, x):
        Qoutput = tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        Koutput =  tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        Voutput =  tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        a = tf.einsum('ajk,afk-&gt;ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(self.mask_para, axis=1), [1, 64, 1])
        a = tf.matmul(a, Voutput)
        return a

    def compute_mask(self, inputs, mask):
        return mask

    def compute_output_shape(self, input_shape):
        return input_shape[0]

def create_encoder_model():
    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))
    a = MyWordEmbedding()([word_ids_fr])
    a = EncoderLayer(K.cast(K.not_equal(0, word_ids_fr), dtype='float32'))([a])
    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)
    return model

def create_model():
    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))
    a = tf.keras.Input(shape=(None, 512,))
    b = MyWordEmbedding()([word_ids_en])
    b = b + a
    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)
    return model
    
def evaluate():
    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')
    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)

decoder_model = create_model()
encoder_model = create_encoder_model()
evaluate()
&lt;/denchmark-code&gt;

Error:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype int32 and shape [?,?]
	 [[{{node input_3}}]]
&lt;/denchmark-code&gt;

Fixing this error is easy for this case because I know exactly where (see the solution below). In detail I pass the para though call function and not the init function. Nonetheless finding this error in a big project is very difficult because I need to throw many lines of code to know exactly where it causes the error.
&lt;denchmark-code&gt;import tensorflow as tf
tf.compat.v1.disable_eager_execution()
from tensorflow.keras import backend as K
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

class MyWordEmbedding(tf.keras.layers.Layer):
    def build(self, input_shape):
        self.kernel = self.add_weight(shape=(300, 512), dtype='float32')
        super(MyWordEmbedding, self).build(input_shape)  # Be sure to call this at the end
    
    def call(self, inputs):
        return tf.nn.embedding_lookup(params=self.kernel, ids=inputs[0])

class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(EncoderLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        self.Qdense = self.add_weight(name='Qdense', shape=(512, 512))
        super(EncoderLayer, self).build(input_shape)

    def call(self, x):
        Qoutput = tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        Koutput =  tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        Voutput =  tf.einsum('aij,jk-&gt;aik', x[0], self.Qdense)
        mask_para = x[1]
        a = tf.einsum('ajk,afk-&gt;ajf', Qoutput, Koutput) * tf.tile(K.expand_dims(mask_para, axis=1), [1, 64, 1])
        a = tf.matmul(a, Voutput)
        return a

    def compute_mask(self, inputs, mask):
        return mask

    def compute_output_shape(self, input_shape):
        return input_shape[0]

def create_encoder_model():
    word_ids_fr = tf.keras.layers.Input(dtype='int32', shape=(None,))
    a = MyWordEmbedding()([word_ids_fr])
    a = EncoderLayer()([a, K.cast(K.not_equal(0, word_ids_fr), dtype='float32')])
    model = tf.keras.models.Model(inputs=[word_ids_fr], outputs=a)
    return model

def create_model():
    word_ids_en = tf.keras.layers.Input(dtype='int32', shape=(None,))
    a = tf.keras.Input(shape=(None, 512,))
    b = MyWordEmbedding()([word_ids_en])
    b = b + a
    model = tf.keras.models.Model(inputs=[word_ids_en, a], outputs=b)
    return model
    
def evaluate():
    source_sequence_ids = pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='pre')
    output = decoder_model.predict([pad_sequences(np.random.randint(5, size=(3, 64)), maxlen=64, padding='post'), encoder_model(source_sequence_ids, training=False)], steps=1, verbose=1, batch_size=256)

decoder_model = create_model()
encoder_model = create_encoder_model()
evaluate()
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='hoangcuong2011' date='2020-07-06T10:18:44Z'>
		I am able to replicate this issue, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/c727e3fb2ca4ec5321fdd842a29c7b13/untitled260.ipynb&gt;gist here.&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='hoangcuong2011' date='2020-07-07T00:57:42Z'>
		&lt;denchmark-link:https://github.com/hoangcuong2011&gt;@hoangcuong2011&lt;/denchmark-link&gt;
 As this is a duplicate of the issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40977&gt;#40977&lt;/denchmark-link&gt;
 lets close the issue here and track it in one single place. thanks!
		</comment>
		<comment id='3' author='hoangcuong2011' date='2020-07-07T01:07:21Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 if you look at the code carefully you will notice the source of the error is  different.
I am fine if you want me close this one. I am just not sure once &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40977&gt;#40977&lt;/denchmark-link&gt;
 is fixed this one is fixed as well (because they are different).
		</comment>
		<comment id='4' author='hoangcuong2011' date='2020-07-31T15:32:57Z'>
		&lt;denchmark-link:https://github.com/hoangcuong2011&gt;@hoangcuong2011&lt;/denchmark-link&gt;
 As you figured out how this error is being caused, are you saying that we need to improve the error message so we can easily debug this issue?
		</comment>
		<comment id='5' author='hoangcuong2011' date='2020-07-31T15:44:31Z'>
		No. I suggested it is a bug.
		</comment>
		<comment id='6' author='hoangcuong2011' date='2020-08-10T19:49:37Z'>
		&lt;denchmark-link:https://github.com/hoangcuong2011&gt;@hoangcuong2011&lt;/denchmark-link&gt;
 I am gonna go ahead and close this issue as it a duplicate and lets track it here &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40977&gt;#40977&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='7' author='hoangcuong2011' date='2020-08-17T20:27:32Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='hoangcuong2011' date='2020-08-24T21:25:42Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='9' author='hoangcuong2011' date='2020-08-24T21:25:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41111&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41111&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>