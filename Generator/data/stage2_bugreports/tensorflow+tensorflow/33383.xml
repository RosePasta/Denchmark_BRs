<bug id='33383' author='scharron' open_date='2019-10-15T15:13:12Z' closed_time='2019-11-01T23:01:07Z'>
	<summary>Desynchronized zipped datasets when using tf.data.experimental.ignore_errors</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
na
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
v2.0.0-rc2-26-g64c3d38 2.0.0
Python version:
Python 3.7.4
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
cuda 10.0
GPU model and memory:
P100 / 16GB

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
When an error is caught using the tf.data.experimental.ignore_errors on a zipped dataset, only the faulty dataset drops an element. The datasets are therefore desynchronized.
Describe the expected behavior
Datasets should stay synchronized by dropping an element from both datasets.
Code to reproduce the issue
&lt;denchmark-code&gt;good_dataset = tf.data.Dataset.from_tensor_slices([1., 2., 0., 4.])
bad_dataset = good_dataset.map(lambda x: tf.debugging.check_numerics(1. / x, "error"))

dataset = tf.data.Dataset.zip((bad_dataset, good_dataset))
dataset = dataset.apply(tf.data.experimental.ignore_errors())

for bad, good in dataset:
    print(float(good), float(bad))

1.0 1.0
2.0 0.5
0.0 0.25
&lt;/denchmark-code&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='scharron' date='2019-10-16T06:52:50Z'>
		I could reproduce the issue with Tf 2.0.0. Please see the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/48e54114ef599b79cd9d09e4a7fb9736/untitled201.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='scharron' date='2019-10-30T00:31:24Z'>
		This is working as intended. The good dataset dropped 0.0 while the bad dataset dropped 1 / 0.0.
&lt;denchmark-link:https://github.com/scharron&gt;@scharron&lt;/denchmark-link&gt;
 What output would you expect for your example?
		</comment>
		<comment id='3' author='scharron' date='2019-10-31T10:25:17Z'>
		&lt;denchmark-link:https://github.com/jsimsa&gt;@jsimsa&lt;/denchmark-link&gt;
 Oops sorry I went too fast, I fixed the code to reproduce
(if zipping good then bad it works, but the reverse does not)
		</comment>
		<comment id='4' author='scharron' date='2019-10-31T15:12:27Z'>
		I think the issue is that, in case of zip, when error or end-of-sequence encountered the remaining components are not "flushed out".  So out-of-sync happens when ignore_errors is in play.
Created a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/33887&gt;#33887&lt;/denchmark-link&gt;
, think this could fix the issue.
		</comment>
		<comment id='5' author='scharron' date='2019-11-01T23:01:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33383&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33383&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='scharron' date='2019-11-04T14:35:26Z'>
		Thanks !
Wouldn't it be possible and useful to also issue a warning if the tf.data.experimental.ignore_errors is applied to any Dataset used as input to tf.data.Dataset.zip.
This could also result in datasets desynchronization if any of the zipped datasets drops any item, and in my opinion shouldn't be the behaviour of a zip function.
		</comment>
	</comments>
</bug>