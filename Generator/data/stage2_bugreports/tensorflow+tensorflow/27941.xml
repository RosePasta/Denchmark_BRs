<bug id='27941' author='kotritrona' open_date='2019-04-18T04:05:47Z' closed_time='2020-09-19T13:22:07Z'>
	<summary>RNN compatibility issue on unknown batch_size</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colaboratory
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0-alpha0 or 1.13.1
Python version: 3.6.7
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: not using GPU
GPU model and memory: not using GPU

Describe the current behavior
I sent some data from one model's loss function to another model. The other model starts with a RNN layer.
in tensorflow 1.12.0 and before, the variable y_pred is shape (32, 10, 10) or (20, 10, 10) as first dimension is batch_size, and the model trained normally
in tensorflow 1.13.1 and 2.0.0-alpha0, it shows that the shape is (None, 10, 10) then throws this exception
&lt;denchmark-code&gt;/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in &lt;listcomp&gt;(.0)
   3217     outputs = self._graph_fn(*converted_inputs)
   3218     return nest.pack_sequence_as(self._outputs_structure,
-&gt; 3219                                  [x.numpy() for x in outputs])
   3220 
   3221 

AttributeError: 'Tensor' object has no attribute 'numpy'
&lt;/denchmark-code&gt;

probably because it changed the behavior to use a dynamic batch size tensor, then tensors of unknown batch size don't have the numpy method?
If the RNN layer is not present, and the data is 2d (like (None, 10) ), the model can train normally.
CNN and Flatten seem to also have the problem.
Describe the expected behavior
I think it should not use $.numpy() there in the backend, probably(?)
Code to reproduce the issue
import tensorflow as tf
import numpy as np
from tensorflow import keras

# try-except eager trigger to prevent trouble from ipynb
try:
    tf.enable_eager_execution();
except:
    pass

def build_classifier_model():
    model = keras.Sequential([
        keras.layers.SimpleRNN(64, input_shape=(10, 10)),
        keras.layers.Dense(64, activation=tf.nn.relu),
        keras.layers.Dense(1, activation=tf.nn.tanh)
    ])

    optimizer = tf.optimizers.Adam(0.001) #tf.train.AdamOptimizer(0.001)

    model.compile(loss='mse',
                optimizer=optimizer,
                metrics=[keras.metrics.mae])
    return model

some_model = build_classifier_model();
  
def build_model():
    def custom_loss(y_true, y_pred):
      # simply tile y_pred as an example
      y_cred = tf.tile(tf.expand_dims(y_pred, axis=2), (1, 1, 10))
      print(y_cred.shape)
      return tf.reduce_sum(some_model(y_cred) ** 2)
    
    model = keras.Sequential([
        keras.layers.Dense(64, input_shape=(12,)),
        keras.layers.Dense(10, activation=tf.nn.tanh)
    ])

    optimizer = tf.optimizers.Adam(0.001) #tf.train.AdamOptimizer(0.001)

    model.compile(loss=custom_loss,
                optimizer=optimizer,
                metrics=[keras.metrics.mae])
    return model
        
m = build_model();
# fitting randomness as example
x = np.random.random((500, 12));
y = tf.cast(np.random.randint(0, 2, size=(500,)), tf.float32);
m.fit(x, y, epochs=10);
Other info / logs
full exception log
(None, 10, 10)

---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

&lt;ipython-input-3-de77aceb3f93&gt; in &lt;module&gt;()
     38     return model
     39 
---&gt; 40 m = build_model();
     41 # fitting randomness as example
     42 x = np.random.random((500, 12));

&lt;ipython-input-3-de77aceb3f93&gt; in build_model()
     35     model.compile(loss=custom_loss,
     36                 optimizer=optimizer,
---&gt; 37                 metrics=[keras.metrics.mae])
     38     return model
     39 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    454     self._setattr_tracking = False  # pylint: disable=protected-access
    455     try:
--&gt; 456       result = method(self, *args, **kwargs)
    457     finally:
    458       self._setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    428       #                   loss_weight_2 * output_2_loss_fn(...) +
    429       #                   layer losses.
--&gt; 430       self.total_loss = self._prepare_total_loss(skip_target_indices, masks)
    431 
    432       # Functions for train, test and predict will

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _prepare_total_loss(self, skip_target_indices, masks)
   1684             loss_fn.reduction = losses_utils.ReductionV2.NONE
   1685             weighted_losses = loss_fn(
-&gt; 1686                 y_true, y_pred, sample_weight=sample_weight)
   1687             loss_fn.reduction = current_loss_reduction
   1688 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py in __call__(self, y_true, y_pred, sample_weight)
     94     with ops.name_scope(scope_name, format(self.__class__.__name__),
     95                         (y_pred, y_true, sample_weight)):
---&gt; 96       losses = self.call(y_true, y_pred)
     97       return losses_utils.compute_weighted_loss(
     98           losses, sample_weight, reduction=self.reduction)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py in call(self, y_true, y_pred)
    156       Loss values per sample.
    157     """
--&gt; 158     return self.fn(y_true, y_pred, **self._fn_kwargs)
    159 
    160   def get_config(self):

&lt;ipython-input-3-de77aceb3f93&gt; in custom_loss(y_true, y_pred)
     24       y_cred = tf.tile(tf.expand_dims(y_pred, axis=2), (1, 1, 10))
     25       print(y_cred.shape)
---&gt; 26       return tf.reduce_sum(some_model(y_cred) ** 2)
     27 
     28     model = keras.Sequential([

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    559       # framework.
    560       if base_layer_utils.needs_keras_history(inputs):
--&gt; 561         base_layer_utils.create_keras_history(inputs)
    562 
    563     # Handle Keras mask propagation from previous layer to current layer.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)
    249       operations and need to have Keras metadata assigned to them.
    250   """
--&gt; 251   _create_keras_history_helper(tensors, set())
    252 
    253 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops)
    286           # when originating from an eager context
    287           # so can't be supported.
--&gt; 288           constants[i] = backend.function([], op_input)([])
    289       processed_ops = _create_keras_history_helper(layer_inputs, processed_ops)
    290       name = op.name

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in __call__(self, inputs)
   3217     outputs = self._graph_fn(*converted_inputs)
   3218     return nest.pack_sequence_as(self._outputs_structure,
-&gt; 3219                                  [x.numpy() for x in outputs])
   3220 
   3221 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py in &lt;listcomp&gt;(.0)
   3217     outputs = self._graph_fn(*converted_inputs)
   3218     return nest.pack_sequence_as(self._outputs_structure,
-&gt; 3219                                  [x.numpy() for x in outputs])
   3220 
   3221 

AttributeError: 'Tensor' object has no attribute 'numpy'
	</description>
	<comments>
		<comment id='1' author='kotritrona' date='2019-04-29T19:05:24Z'>
		&lt;denchmark-link:https://github.com/kotritrona&gt;@kotritrona&lt;/denchmark-link&gt;
 I could reproduce the issue with TF2.0. However, with little modifications to the above code, I could run in TF-nightly (gist is &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/b24b8695bdf3deb42f5052025bde623f/untitled117.ipynb&gt;here&lt;/denchmark-link&gt;
) without AtrributeError. Thanks!
		</comment>
		<comment id='2' author='kotritrona' date='2019-04-30T17:48:07Z'>
		Adding Tom here since it seems to be related to TensorFlowOpLayer that was added recently.
		</comment>
		<comment id='3' author='kotritrona' date='2020-09-12T21:03:42Z'>
		&lt;denchmark-link:https://github.com/kotritrona&gt;@kotritrona&lt;/denchmark-link&gt;
 Looks like this was resolved in recent . &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/e945ef2b297613a3181d150d4479285b/untitled117.ipynb&gt;Here&lt;/denchmark-link&gt;
 is the gist for your reference.
Can you please verify once and close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='4' author='kotritrona' date='2020-09-19T13:22:07Z'>
		I am closing this issue as this was resolved in recent tf-nightly. Please feel free to reopen if this was not resolved for you. Thanks!
		</comment>
		<comment id='5' author='kotritrona' date='2020-09-19T13:22:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27941&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27941&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>