<bug id='38620' author='peakji' open_date='2020-04-17T05:07:44Z' closed_time='2020-06-24T10:49:21Z'>
	<summary>Mask missing in restored Keras SavedModel</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4 and Linux Ubuntu 18.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0 and v2.2.0-rc3
Python version: 3.6.0
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the current behavior
Calling the model directly returns correct results:
&lt;denchmark-code&gt;array([[1, 2], [3, 0]], dtype=int32)
&lt;/denchmark-code&gt;

But if we save the model to a SavedModel and restore it, the new model fails to pass the mask from the first layer to the second layer, resulting in:
&lt;denchmark-code&gt;ValueError: Could not find matching function to call loaded from the SavedModel.
  Positional arguments (2 total):
    * Tensor("inputs:0", shape=(None, 2), dtype=int32)
    * None
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (2 total):
    * TensorSpec(shape=(None, 2), dtype=tf.int32, name='inputs')
    * TensorSpec(shape=(None, 2), dtype=tf.bool, name='mask')
  Keyword arguments: {}
&lt;/denchmark-code&gt;

I've updated TensorFlow to v2.2.0-rc3 and nightly, the issue is still reproducible.
Describe the expected behavior
The model restored from the SavedModel should behave exactly the same as the original model: the first layer passing mask to the second layer.
Standalone code to reproduce the issue
Colab notebook:
&lt;denchmark-link:https://colab.research.google.com/drive/1VlL9on7myJIX9xP2efIwvgESmWGafdfx&gt;https://colab.research.google.com/drive/1VlL9on7myJIX9xP2efIwvgESmWGafdfx&lt;/denchmark-link&gt;

Plain text:
import tensorflow as tf


class MyMasking(tf.keras.layers.Layer):

    def call(self, inputs):
        return inputs

    def compute_mask(self, inputs, mask=None):
        mask = tf.not_equal(inputs, 0)
        return mask


class MyLayer(tf.keras.layers.Layer):

    def call(self, inputs, mask=None):
        return inputs


samples = tf.constant([[1, 2], [3, 0]], dtype=tf.int32)
model = tf.keras.Sequential([MyMasking(), MyLayer()])
tf.print(model.predict(samples))

model.save('./temp_model', save_format='tf')

new_model = tf.keras.models.load_model('./temp_model')
tf.print(new_model.predict(samples))
	</description>
	<comments>
		<comment id='1' author='peakji' date='2020-04-17T06:03:40Z'>
		I have tried on colab with TF version 2.1.0 , 2.2.0-rc3 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/2bfd3ff096ee1f5a05413a4544152ca2/untitled781.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='peakji' date='2020-04-17T15:18:20Z'>
		&lt;denchmark-link:https://github.com/peakji&gt;@peakji&lt;/denchmark-link&gt;
 Agree with you. I think this is more related to saving and loading of mask in subclass model. I tried your approach (predict, *.save, *.load_model, predict) on a subclassed model without a mask, everything works as expected. &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/e8e2105ec638271848e4bdf6e76fd3d3/38620.ipynb&gt;Here&lt;/denchmark-link&gt;
 is a gist for our reference. Thanks!
		</comment>
		<comment id='3' author='peakji' date='2020-04-22T02:57:21Z'>
		Any update on this one? Just ran into the same issue when adapting to tf 2.x
		</comment>
		<comment id='4' author='peakji' date='2020-06-24T10:49:22Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38620&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38620&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='peakji' date='2020-06-29T20:19:28Z'>
		This is not an error. As we are using custom layers in the model, we need to use  while loading the model. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/b4355c380f72d14c4f78d026acee3223/untitled201.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
&lt;denchmark-code&gt;new_model = tf.keras.models.load_model('./temp_model',custom_objects={'MyMasking':MyMasking(),'MyLayer':MyLayer()})
tf.print(new_model.predict(samples))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='peakji' date='2020-06-30T04:15:46Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks for circling back!
This is weird since we are saving the model in the SavedModel format. According to the &lt;denchmark-link:https://www.tensorflow.org/guide/keras/save_and_serialize#savedmodel_format&gt;docs&lt;/denchmark-link&gt;
 and our experience,  are only required while using the old H5 format, which has a known limitation of not including computation graph of custom objects.
I'm not sure why this could work for SavedModels, but still it is really inconvenient, if not impossible, to pass in custom_objects while using TensorFlow Serving.
Actually we've worked around this issue by replacing all functional calls into subclassed models and manually passing the masks all the way down. The new SavedModel works correctly in both Python and TF Serving, without using custom_objects.
		</comment>
	</comments>
</bug>