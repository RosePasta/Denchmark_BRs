<bug id='44736' author='creidieki' open_date='2020-11-10T17:00:30Z' closed_time='2020-11-10T18:14:42Z'>
	<summary>Validation step overwrites callback's internal predict call</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
Python version: 3.8.5
CUDA/cuDNN version: 10.1
GPU model and memory: GeForce RTX 2080 Ti 11GB x8

I'm training a network, and I'm trying to collect metrics on two separate validation sets. I've been using the built-in validation for one of them, and I wrote a callback for the other. However, in epochs when both run, the callback seems to always get the same answer as the built-in validation set.
I have a minimal test case below. This is a completely trivial network where the output and input are equal. I've built the situation as follows:

Let x = np.ones(5,).
It trains on input = output = x, so the training error is always 0.
It validates on input = x, output = 2*x, so the validation error is always 1.
The callback validates on input = x, output = 3*x, so the callback's validation error should always be 2.

&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model

input_data = Input(shape=(5,))
model = Model(inputs=input_data, outputs=input_data)
model.compile(loss='mae')

class valCallback(tf.keras.callbacks.Callback):
    def __init__(self, model, inputs, outputs):
        self.model = model
        self.inputs = inputs
        self.outputs = outputs
        
    def on_epoch_end(self, epoch, logs={}):
        val = self.model.evaluate(self.inputs, self.outputs, verbose=0)
        print("\nVAL: ", val)

traindata = np.ones((5))
vc = valCallback(model, traindata, 3*traindata)  
model.fit(traindata, traindata, 
          validation_data=(traindata, 2*traindata),
          epochs=4, callbacks=[vc], validation_freq=2, verbose=0)
&lt;/denchmark-code&gt;

In epoch 1, the callback correctly prints 2. In epoch 2, when the validation runs, the callback prints 1 instead (!).
Somehow the validation_data is overwriting the data in the callback, and I don't know how or why. The self.model.evaluate calls in the callback aren't getting the right answer any more, after validation has happened.
Desired output:
VAL: 2
VAL: 2
VAL: 2
VAL: 2
Actual output:
VAL: 2
VAL: 1
VAL: 1
VAL: 1
	</description>
	<comments>
		<comment id='1' author='creidieki' date='2020-11-10T17:12:15Z'>
		&lt;denchmark-link:https://github.com/creidieki&gt;@creidieki&lt;/denchmark-link&gt;

I have tried in colab with TF version and was able to reproduce the issue. However issue got resolved in nightly version).Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/a3dedb7ebfe9d30e668853a18a078726/untitled506.ipynb&gt;here&lt;/denchmark-link&gt;
.Please,verify once and close the issue.Thanks!
		</comment>
		<comment id='2' author='creidieki' date='2020-11-10T18:14:41Z'>
		This works! Thank you.
		</comment>
		<comment id='3' author='creidieki' date='2020-11-10T18:14:43Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44736&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44736&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>