<bug id='44885' author='BestSithInEU' open_date='2020-11-15T14:04:12Z' closed_time='2020-11-16T11:17:07Z'>
	<summary>Could not create cudnn handle TF2 GPU</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below): 2.1.0
Python version: 3.7.9
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: cudart64_101.dll / 7.6.0.64
GPU model and memory: RTX 2080

Describe the current behavior
2020-11-15 16:46:03.303728: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-11-15 16:46:03.307912: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-11-15 16:46:03.308022: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
I checked some "Could not create cudnn handle" errors but I couldn't find any solutions yet. And I installed also exactly same edition as tf mentioned in their sites.
-NVIDIA® GPU drivers —CUDA® 10.1 requires 418.x or higher.
-CUDA® Toolkit —TensorFlow supports CUDA® 10.1 (TensorFlow &gt;= 2.1.0)
-CUPTI ships with the CUDA® Toolkit.
-cuDNN SDK 7.6 (see cuDNN versions).
-(Optional) TensorRT 6.0 to improve latency and throughput for inference on some models.
I'm trying to use my simple CNN code;
&lt;denchmark-code&gt;# Convolutional Neural Network

# Importing Libraries

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Part 1 - Data Preprocessing

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

training_set = train_datagen.flow_from_directory('C:/Users/batuh/OneDrive/Masaüstü/Udemy Courses/Deep Learning A-Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

## Preprocessing the Test set

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory('C:/Users/batuh/OneDrive/Masaüstü/Udemy Courses/Deep Learning A-Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

# Part 2 - Building the CNN
## Initializing the CNN

cnn = tf.keras.models.Sequential()

## Step 1 - Convolution

cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', 
                               input_shape = [64, 64, 3]))

## Step 2 - Pooling

cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2))

### Adding Second Conv. Layer

cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))
cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2))

## Step 3 - Flattening

cnn.add(tf.keras.layers.Flatten())

## Step 4 - Full Connection

cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))

## Step 5 - Output Layer

cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

# Part 3 - Training the CNN
## Compiling the CNN
#with tf.device('/GPU:0'):
cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

## Training the CNN
cnn.fit(x = training_set, validation_data = test_set, epochs = 50)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='BestSithInEU' date='2020-11-15T15:23:41Z'>
		I am having the same problem. Setting the kernel size to 2 instead of of 3 makes it work.
		</comment>
		<comment id='2' author='BestSithInEU' date='2020-11-15T16:13:47Z'>
		
I am having the same problem. Setting the kernel size to 2 instead of of 3 makes it work.
This time I've got that one;

&lt;denchmark-code&gt;E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-11-15 18:53:39.858320: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node sequential/conv2d/Conv2D}}]]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='BestSithInEU' date='2020-11-16T02:30:43Z'>
		I think you should upgrade your tensorflow version to 2.3.0 or 2.4.0rc1
		</comment>
		<comment id='4' author='BestSithInEU' date='2020-11-16T05:02:07Z'>
		That reminds me of a common error with RTX cards.
Did you try to set the env variable TF_FORCE_GPU_ALLOW_GROWTH to "true" ?
Check this:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/37559&gt;#37559&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='BestSithInEU' date='2020-11-16T07:51:29Z'>
		Also try adding this to the start of this projects just after upgrading your tensorflow  version and importing it
physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)
		</comment>
		<comment id='6' author='BestSithInEU' date='2020-11-16T11:17:07Z'>
		Thanks for your help. I would like to summarize the solution briefly in case others have problems and investigate that problem.

This section must be added right after the import section. However, for usage of this code, people who face that issue, should use tensorflow 2.3 at least. I've double checked from &lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/config&gt;here&lt;/denchmark-link&gt;
, config added on Tensorflow 2.3.0. Again I really appreciated you both &lt;denchmark-link:https://github.com/king398&gt;@king398&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://github.com/jnd77&gt;@jnd77&lt;/denchmark-link&gt;
 . Have a nice day you all, &lt;3 Cheers!
		</comment>
		<comment id='7' author='BestSithInEU' date='2020-11-16T11:17:09Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44885&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44885&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='BestSithInEU' date='2020-11-16T15:39:28Z'>
		&lt;denchmark-link:https://github.com/BestSithInEU&gt;@BestSithInEU&lt;/denchmark-link&gt;
 Glad that you found it useful
		</comment>
		<comment id='9' author='BestSithInEU' date='2020-11-19T01:41:10Z'>
		Hey I'm using TF 2.2.0 with CUDA 10.1 I think it is compatible
I'm getting the same error even after performing the function to limit memory growth

Also try adding this to the start of this projects just after upgrading your tensorflow version and importing it
physical_devices = tf.config.list_physical_devices('GPU') tf.config.experimental.set_memory_growth(physical_devices[0], True)

E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
		</comment>
		<comment id='10' author='BestSithInEU' date='2020-11-19T02:02:13Z'>
		&lt;denchmark-link:https://github.com/RohanRatwani&gt;@RohanRatwani&lt;/denchmark-link&gt;
 which gpu you are using and please show your code in the issue and the full log file. Also try upgrading your tensorflow version to 2.3.0
. If you read the above answer you should tensorflow version 2.3.0 is minimum required for this
		</comment>
	</comments>
</bug>