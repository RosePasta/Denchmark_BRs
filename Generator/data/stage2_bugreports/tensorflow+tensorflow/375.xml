<bug id='375' author='hannes-brt' open_date='2015-11-28T23:39:33Z' closed_time='2016-02-19T07:45:29Z'>
	<summary>CUDA headers not found when implementing GPU kernel for user-op</summary>
	<description>
I am following the tutorial to implement a user-op. I have three files dna_encode_op.cc, dna_encode_op_gpu.cu.cc, and dna_encode_op.h.
I have configured TensorFlow with GPU support using ./configure. However, during compilation of dna_encode_op_gpu.cu.cc, Bazel doesn't find the CUDA headers:
&lt;denchmark-code&gt;INFO: From Compiling tensorflow/core/user_ops/dna_encode_op_gpu.cu.cc [for host]:
In file included from ./tensorflow/core/framework/tensor_types.h:4:0,
                 from tensorflow/core/user_ops/dna_encode_op_gpu.cu.cc:8:
./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:55:18: fatal error: cuda.h: No such file or directory
 #include &lt;cuda.h&gt;
                  ^
compilation terminated.
ERROR: /home/hannes/git/DNAflow_internal/tensorflow/core/BUILD:339:1: C++ compilation of rule '//tensorflow/core:user_ops_op_lib' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 50 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
&lt;/denchmark-code&gt;

Building the included ops works well, so I'm wondering whether I have to modify BUILD - however, there is no mention of this in the tutorials.
	</description>
	<comments>
		<comment id='1' author='hannes-brt' date='2015-12-01T00:14:40Z'>
		Btw, I discovered that when I move my files from user_ops/ to kernels/ they compile fine. So it seems BUILD is using different rules for user_ops/ and kernels/, with the CUDA headers not being included for user ops.
		</comment>
		<comment id='2' author='hannes-brt' date='2015-12-01T05:56:26Z'>
		Thanks for the report -- we're trying to figure out a better solution to custom ops than the user_ops directory, and in doing so should hopefully address these cuda header issues.
		</comment>
		<comment id='3' author='hannes-brt' date='2016-02-09T21:52:37Z'>
		I added &lt;denchmark-link:https://www.tensorflow.org/versions/master/how_tos/adding_an_op/index.html#adding-a-new-op&gt;instructions&lt;/denchmark-link&gt;
 for building ops and kernels outside of TensorFlow source tree. Please have a look to see if it fits your need.
		</comment>
		<comment id='4' author='hannes-brt' date='2016-02-19T07:45:29Z'>
		(Reopen if this new feature isn't working as expected)
		</comment>
		<comment id='5' author='hannes-brt' date='2016-03-09T16:57:39Z'>
		The instructions work fine for CPU-only ops, but seem to be insufficient for building an op with a GPU kernel. A slightly modified BUILD works fine though (for GPU-only kernels):
cc_binary(
    name = "softmax4d_op.so",
    srcs = [
        "softmax4d_op.cc",
        "softmax4d_op.h"
    ],
    copts = [
        "-x", "cuda",
        "-DGOOGLE_CUDA=1"
    ],
    linkopts = [
        "-Wl,-Bsymbolic",
        "-lm",
    ],
    linkshared = 1,
    linkstatic = 1,
    deps = [
        "//tensorflow/core:framework",
        "//tensorflow/core:cuda",
        "//third_party/eigen3"
    ],
)
I think it would be great to have a bit more details in the docs, and maybe even have a bazel rule for building custom ops, similar to tf_kernel_library().
		</comment>
		<comment id='6' author='hannes-brt' date='2019-05-29T10:46:29Z'>
		&lt;denchmark-link:https://github.com/hannes-brt&gt;@hannes-brt&lt;/denchmark-link&gt;
  hi, I encountered similar issues when I want to add a custom op which is implemented on GPU. You said it works when you copies these files from  to . Did you just copy the ,, to  or did you also add build target in ?
		</comment>
	</comments>
</bug>