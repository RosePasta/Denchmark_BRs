<bug id='33245' author='npuichigo' open_date='2019-10-11T12:47:23Z' closed_time='2020-02-28T19:27:30Z'>
	<summary>Cannot use dict base datasets with keras.Model.fit.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0
Python version: 3.6.4
CUDA/cuDNN version: 10.1
GPU model and memory: 7.6.2

In order to make both dataset and keras model have good structures, I create a dataset and a vanilla model like this.
# dataset is something like &lt;BatchDataset shapes: ({input: (None, 100)}, {output: (None, 10)}), types: ({input: tf.float32}, {output: tf.float32})&gt;

# subscale model is something like
class VanillaModel(Model):

  def __init__(self, num_units, **kwargs):
    super(VanillaModel, self).__init__(**kwargs)
    self.num_units = num_units

    # One linear projection layer.
    self.dense_proj = tf.keras.layers.Dense(num_units, activation='relu')

  def call(self, features):
    """Forward pass."""
    output = self.dense_proj(features['input'])
    return {
        'output': output
    }
When I use the dict based dataset (from tfds) with keras.Model.fit, the first call will cause expection as
# Compile model using dict with same keys.
model.compile('adam', {'output': 'mse'})

# The errors
 File "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py", line 1248, in cast_if_floating_dtype_and_mismatch
    if target.dtype != out.dtype:
AttributeError: 'str' object has no attribute 'dtype'
I checked the code and found that, when dict is passed, iterating through  will just get the keys of the dict, so the string keys have no dtyle.
(&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_utils.py#L1246&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_utils.py#L1246&lt;/denchmark-link&gt;
)
&lt;denchmark-link:https://user-images.githubusercontent.com/11533479/66652073-59916c00-ec67-11e9-8974-eda50bf98e18.png&gt;&lt;/denchmark-link&gt;

So how can I use dict based dataset and model with keras.Model.fit?
	</description>
	<comments>
		<comment id='1' author='npuichigo' date='2019-10-15T07:42:33Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
, Will it be possible to provide the standalone code to replicate the reported issue. Thanks!
		</comment>
		<comment id='2' author='npuichigo' date='2019-10-24T09:24:02Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
, Any update on code. Thanks!
		</comment>
		<comment id='3' author='npuichigo' date='2019-10-24T11:22:18Z'>
		The problem is that, if our model and dataset return dictionaries, how can we compile and fit the model.
import tensorflow as tf
import numpy as np

class VanillaModel(tf.keras.Model):

  def __init__(self, num_units, **kwargs):
    super(VanillaModel, self).__init__(**kwargs)
    self.num_units = num_units

    # One linear projection layer.
    self.dense_proj1 = tf.keras.layers.Dense(num_units, activation='relu')
    self.dense_proj2 = tf.keras.layers.Dense(num_units, activation='relu')

  def call(self, features):
    """Forward pass."""
    proj1_output = self.dense_proj1(features['input'])
    proj2_output = self.dense_proj2(features['input'])
    return {
        'proj1_output': proj1_output,
        'proj2_output': proj2_output
    }

input_tensor = np.random.normal(size=(50, 32)).astype(np.float32)
output_tensor1 = np.random.normal(size=(50, 16)).astype(np.float32)
output_tensor2 = np.random.normal(size=(50, 16)).astype(np.float32)

dataset = tf.data.Dataset.from_tensor_slices(({'input': input_tensor}, {'proj1_output': output_tensor1, 'proj2_output': output_tensor2}))
model = VanillaModel(16)

model.compile('adam', {'proj1_output': 'mse', 'proj2_output': 'mae'})
model.fit(dataset)
		</comment>
		<comment id='4' author='npuichigo' date='2019-11-11T05:59:41Z'>
		any updates?
		</comment>
		<comment id='5' author='npuichigo' date='2019-12-13T14:46:04Z'>
		I am facing the same issue when I am retrieving data from TFRecords.
		</comment>
		<comment id='6' author='npuichigo' date='2019-12-16T19:48:14Z'>
		Assigning to Tom who will be working on this as part of ideal fit/compile change.
		</comment>
		<comment id='7' author='npuichigo' date='2019-12-16T19:53:48Z'>
		For a quick workaround, note the Keras expects Datasets passed to fit to be of the form (features, labels or (features, labels, sample_weights)
Here's an example of grabbing MNIST from tensorflow_datasets and formatting it in the way Keras expects:
import tensorflow as tf
import tensorflow_datasets as tfds

def convert_dataset(item):
    """Puts the mnist dataset in the format Keras expects, (features, labels)."""
    image = item['image']
    label = item['label']
    image = tf.dtypes.cast(image, 'float32') / 255.
    return image, label

mnist_data = tfds.load('mnist')
mnist_train, mnist_test = mnist_data['train'], mnist_data['test']
mnist_train = mnist_train.map(convert_dataset).shuffle(1000).batch(100).repeat()
mnist_test = mnist_test.map(convert_dataset).batch(100)

model.fit(mnist_train, epochs=10, validation_data=mnist_test)
		</comment>
		<comment id='8' author='npuichigo' date='2019-12-17T11:13:15Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 That's true. But sometimes we have complicated models with multiple inputs and outputs, so it's more elegant if we can use dict based model and dataset.
		</comment>
		<comment id='9' author='npuichigo' date='2019-12-17T21:21:55Z'>
		&lt;denchmark-link:https://github.com/npuichigo&gt;@npuichigo&lt;/denchmark-link&gt;
 For those Models, each of  and  can be a dictionary:
ds = tf.data.Dataset.from_tensor_slices(
  ({'my_feature_1': ..., 'my_feature_2': ...}, {'my_label_1': ..., 'my_label_2': ...}))
		</comment>
		<comment id='10' author='npuichigo' date='2019-12-18T05:12:37Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 So it looks like my example.
&lt;denchmark-code&gt;dataset = tf.data.Dataset.from_tensor_slices(({'input': input_tensor}, {'proj1_output': output_tensor1, 'proj2_output': output_tensor2}))
&lt;/denchmark-code&gt;

But it seems that keras restrict the input and output names to something like input_1, input_2, output_1 and so on. Can you give a correct example?
		</comment>
		<comment id='11' author='npuichigo' date='2019-12-18T13:54:51Z'>
		If I use  tf.feature_column.categorical_column_with_vocabulary_list I was able to specify the column name in keras. But I faced the issue when I called model_to_estimator API to convert back to tensorflow model as the converted model was expecting inputs like input1,input2,... as you mentioned
		</comment>
		<comment id='12' author='npuichigo' date='2019-12-23T11:47:25Z'>
		same problem
		</comment>
		<comment id='13' author='npuichigo' date='2020-01-09T09:39:19Z'>
		I faced same issue. My workaround is not using the subclass way.  When I change to tf.keras.Model(inputs=...,outputs=...), the problem solved.
Or before model.complie, add two lines:
inputs = tf.keras.layer.Input(shape=(...))
model(inputs)      # you need to run the model once. model.build() doen't help.
In fact I found there's quite some limitation on subclass model, and there's no good guidline about how to avoid these limitations.Hope tensorflow can improve the usability of subclass model. I really prefer subclass model than sequence model becuase that's the way how we can easily debug the model with eager.
		</comment>
		<comment id='14' author='npuichigo' date='2020-02-28T19:27:30Z'>
		Thanks for the issue all! This is now fixed in the latest tf-nightlym you can use any arbitrary nested structure of data with subclassed Models.
Code below works (note I had to add a call to dataset.batch, this is needed to create batches of data when using from_tensor_slices):
class VanillaModel(tf.keras.Model):

  def __init__(self, num_units, **kwargs):
    super(VanillaModel, self).__init__(**kwargs)
    self.num_units = num_units

    # One linear projection layer.
    self.dense_proj1 = tf.keras.layers.Dense(num_units, activation='relu')
    self.dense_proj2 = tf.keras.layers.Dense(num_units, activation='relu')

  def call(self, features):
    """Forward pass."""
    proj1_output = self.dense_proj1(features['input'])
    proj2_output = self.dense_proj2(features['input'])
    return {
        'proj1_output': proj1_output,
        'proj2_output': proj2_output
    }

input_tensor = np.random.normal(size=(50, 32)).astype(np.float32)
output_tensor1 = np.random.normal(size=(50, 16)).astype(np.float32)
output_tensor2 = np.random.normal(size=(50, 16)).astype(np.float32)

dataset = tf.data.Dataset.from_tensor_slices(({'input': input_tensor}, {'proj1_output': output_tensor1, 'proj2_output': output_tensor2}))
dataset = dataset.batch(10)  # This needs to be called to create batches of data.
model = VanillaModel(16)

model.compile('adam', {'proj1_output': 'mse', 'proj2_output': 'mae'})
model.fit(dataset)
		</comment>
		<comment id='15' author='npuichigo' date='2020-02-28T19:27:32Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33245&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33245&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='npuichigo' date='2020-05-01T21:48:46Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;

When eager execution is disabled, the code snippet you posted above still fails under version  with the same error ().
		</comment>
		<comment id='17' author='npuichigo' date='2020-05-01T21:51:48Z'>
		&lt;denchmark-link:https://github.com/jgmakin&gt;@jgmakin&lt;/denchmark-link&gt;
 Disabling eager execution is a v1 compatibility feature, in general we're only making critical security or regression fixes in the v1 compatibility code for tf.keras. I'd recommend migrating to the TF2 style
		</comment>
		<comment id='18' author='npuichigo' date='2020-05-01T22:02:11Z'>
		Ah, ok, thanks.  I tend to disable eager execution under the assumption that this improves performance, but perhaps that isn't the case anymore?
		</comment>
		<comment id='19' author='npuichigo' date='2020-05-01T22:05:35Z'>
		&lt;denchmark-link:https://github.com/jgmakin&gt;@jgmakin&lt;/denchmark-link&gt;
 When using , everything runs inside a graph anyway (a  graph) so performance should be good
For more, check out &lt;denchmark-link:https://www.tensorflow.org/guide/function&gt;this guide&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>