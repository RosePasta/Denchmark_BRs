<bug id='35485' author='marxwolf' open_date='2019-12-29T23:19:53Z' closed_time='2020-02-11T23:00:16Z'>
	<summary>apply_gradients Error after do weight modification</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): conda
TensorFlow version (use command below): 1.15.0
Python version: 3.7.5
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
I want to do some modification of gradient, weight separately. When I do modification of gradient, it works, but when I use similar code to do modification of weight, it does not work.
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))

train_op = tf.train.GradientDescentOptimizer(0.01)
w = tf.trainable_variables()[0]
grads_vars = train_op.compute_gradients(cross_entropy, var_list=[w])
residual = tf.zeros([784, 10])

for i, (g, v) in enumerate(grads_vars):
    import pdb; pdb.set_trace()
    # if len(g.shape) == 2:
    #     g_size = 1
    #     g_shape = g.get_shape().as_list()
    #     for j in g_shape:
    #         g_size *= j
    #     top_k_size = int(g_size * 0.1)
    #     g = tf.add(g, residual)
    #     g_top_k = get_top_k(g, top_k_size)
    #     residual = tf.subtract(g, g_top_k)
    #     grads_vars[i] = (g_top_k, v)
    if len(v.shape) == 2:
        v_size = 1
        v_shape = v.get_shape().as_list()
        for j in v_shape:
            v_size *= j
        top_k_size = int(v_size * 0.1)
        grads_vars[i] = (g, get_top_k(v, top_k_size))

opt = train_op.apply_gradients(grads_vars)
Traceback (most recent call last):
  File "/home/usu_hu_lab/Documents/tfv1/mnist_train.py", line 52, in &lt;module&gt;
    if len(v.shape) == 2:
  File "/usr/local/anaconda3/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py", line 614, in apply_gradients
    update_ops.append(processor.update_op(self, grad))
  File "/usr/local/anaconda3/envs/tfv1/lib/python3.7/site-packages/tensorflow_core/python/training/optimizer.py", line 194, in update_op
    raise NotImplementedError("Trying to update a Tensor ", self._v)
NotImplementedError: ('Trying to update a Tensor ', &lt;tf.Tensor 'Select:0' shape=(784, 10) dtype=float32&gt;)
Describe the expected behavior
Actually, when I use pdb to debug the v, it is a variable, it should be updated.
(Pdb) p v
&lt;tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref&gt;
(Pdb) p type(v)
&lt;class 'tensorflow.python.ops.variables.RefVariable'&gt;
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='marxwolf' date='2019-12-30T09:39:52Z'>
		&lt;denchmark-link:https://github.com/marxwolf&gt;@marxwolf&lt;/denchmark-link&gt;

Looks like code is incomplete. Request you to provide colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='2' author='marxwolf' date='2019-12-30T16:25:52Z'>
		This is the full code.
import numpy as np
import tensorflow as tf
from tensorflow_core.examples.tutorials.mnist import input_data

def get_top_k(t, k):
	if len(t.shape) == 1:
		values, _ = tf.nn.top_k(t, k)
	elif len(t.shape) == 2:
		flatten_t = tf.reshape(t, [-1])
		values, _ = tf.nn.top_k(flatten_t, k)
	
	threshold = values[-1]

	mask = tf.greater_equal(t, threshold)
	zeros = tf.zeros_like(t)
	top_k = tf.where(mask, t, zeros)

	return top_k


mnist = input_data.read_data_sets("MNIST_data", one_hot=True)

x = tf.placeholder(tf.float32, [None, 784])

W1 = tf.Variable(tf.zeros([784, 10]))

b1 = tf.Variable(tf.zeros([10]))

y = tf.nn.softmax(tf.matmul(x, W1) + b1)

y_ = tf.placeholder(tf.float32, [None, 10])

cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))

train_op = tf.train.GradientDescentOptimizer(0.01)
w = tf.trainable_variables()[0]
grads_vars = train_op.compute_gradients(cross_entropy, var_list=[w])
# residual = tf.zeros([784, 10])

for i, (g, v) in enumerate(grads_vars):
    # import pdb; pdb.set_trace()
    # if len(g.shape) == 2:
    #     g_size = 1
    #     g_shape = g.get_shape().as_list()
    #     for j in g_shape:
    #         g_size *= j
    #     top_k_size = int(g_size * 0.1)
    #     grads_vars[i] = (get_top_k(g, top_k_size), v)
        # g = tf.add(g, residual)
        # g_top_k = get_top_k(g, top_k_size)
        # residual = tf.subtract(g, g_top_k)
        # grads_vars[i] = (g_top_k, v)
    if len(v.shape) == 2:
        v_size = 1
        v_shape = v.get_shape().as_list()
        for j in v_shape:
            v_size *= j
        top_k_size = int(v_size * 0.1)
        grads_vars[i] = (g, get_top_k(v, top_k_size))

opt = train_op.apply_gradients(grads_vars)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    for i in range(1000):
        x_batch, y_batch = mnist.train.next_batch(100)
        _, gradvar, loss = sess.run([opt, grads_vars, cross_entropy], {x: x_batch, y_: y_batch})
        # import pdb; pdb.set_trace()
        
        if i % 100 == 0:
            print("The %s-th steps, loss = %f" % (i, loss))

    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))

    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))
		</comment>
		<comment id='3' author='marxwolf' date='2020-01-02T06:34:12Z'>
		I have tried on colab with TF version 1.15 and was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/517c5e9702ebff15b9c6359920da90c8/untitled526.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='4' author='marxwolf' date='2020-01-06T21:38:55Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 When will you help to fix this problem?
		</comment>
		<comment id='5' author='marxwolf' date='2020-01-28T22:11:19Z'>
		Similar ti the issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/21134&gt;#21134&lt;/denchmark-link&gt;
. As &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
 mentioned We can only compute gradients wrt Variables not tensors.
		</comment>
		<comment id='6' author='marxwolf' date='2020-02-06T20:59:44Z'>
		&lt;denchmark-link:https://github.com/marxwolf&gt;@marxwolf&lt;/denchmark-link&gt;
 Are you still facing the same issue?
		</comment>
		<comment id='7' author='marxwolf' date='2020-02-11T23:00:15Z'>
		Closing this issue as it has been inactive for more thank 2 weeks. Please add additions comments and we can open the issue again. Thanks!
		</comment>
		<comment id='8' author='marxwolf' date='2020-02-11T23:00:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35485&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35485&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>