<bug id='44694' author='slimwangyue' open_date='2020-11-09T07:41:54Z' closed_time='2020-11-30T19:41:45Z'>
	<summary>How to avoid unsupported ops during the tf lite conversion</summary>
	<description>
System information

OS Platform and Distribution: Windows 10
TensorFlow installed from (source or binary): pip installed tf
TensorFlow version (or github SHA if from source): See below for detailed info

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;import torch
import torch.onnx
import tensorflow as tf
import onnx
import os

from onnx_tf.backend import prepare
from models.pytorch import models
from models import vgg
from models import googlenet
from models import lenet


output_dir = "./results/vgg/"

network = vgg.VGG('VGG13')
# network = lenet.LeNet()


if not os.path.exists(output_dir):
    os.makedirs(output_dir)

network.eval()
input_image = torch.randn(1, 3, 32, 32, requires_grad=True)
torch_out = network(input_image)

# Export the model to ONNX
torch.onnx.export(network,               # model being run
                  input_image,                         # model input (or a tuple for multiple inputs)
                  output_dir + "model.onnx",   # where to save the model (can be a file or file-like object)
                  export_params=True,        # store the trained parameter weights inside the model file
                  opset_version=10,          # the ONNX version to export the model to
                  do_constant_folding=True,  # whether to execute constant folding for optimization
                  input_names = ['input'],   # the model's input names
                  output_names = ['output'], # the model's output names
                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes
                                'output' : {0 : 'batch_size'}})
# Export the model to TF
onnx_model = onnx.load(output_dir + 'model.onnx')  # load onnx model
tf_rep = prepare(onnx_model)  # prepare tf representation
tf_rep.export_graph(output_dir + 'tf_model')  # export the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=output_dir+'tf_model', signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True

# Uncomment this line to use tfops in tflite conversion, will not run on mobile devices
# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()


with open(output_dir + 'model.tflite', 'wb') as f:
    f.write(tflite_model)
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;--Under 2.2.0 (onnxtf only support &gt;=2.2.0)
loc("onnx_tf_prefix_Pad_25@__inference_cond_true_306_570_frozen"): error: 'tfl.pad' op failed to verify that operand 0's rank e
quals operand 1's size
Traceback (most recent call last):
  File "c:\users\macin\.conda\envs\normaltf\lib\runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "c:\users\macin\.conda\envs\normaltf\lib\runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "C:\Users\macin\.conda\envs\normalTF\Scripts\toco_from_protos.exe\__main__.py", line 7, in &lt;module&gt;
  File "c:\users\macin\.conda\envs\normaltf\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py", line 93, in mai
n
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "c:\users\macin\.conda\envs\normaltf\lib\site-packages\tensorflow\python\platform\app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "c:\users\macin\.conda\envs\normaltf\lib\site-packages\absl\app.py", line 300, in run
    _run_main(main, args)
  File "c:\users\macin\.conda\envs\normaltf\lib\site-packages\absl\app.py", line 251, in _run_main
    sys.exit(main(argv))
  File "c:\users\macin\.conda\envs\normaltf\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py", line 56, in exe
cute
    enable_mlir_converter)
Exception: &lt;unknown&gt;:0: error: loc("onnx_tf_prefix_Pad_25@__inference_cond_true_306_570_frozen"): 'tfl.pad' op failed to verify
 that operand 0's rank equals operand 1's size

--Under 2.3.0
....a lot of characters
E6C3C3C21133B87CD213B7AEACD3B8219B83B43EBE8BBA4F8FFBB8F16FFBBC74C313CAD77963B48FC453CA0AF66BC2CCB35BB6DC30CBCC21323BC59E28DBA11
17A83A7931A8BB15E826BCADD90EBC481C223CF6CA513C17E92B3CBA57D5B82DB97BBB4B465B3C795EC53B786FED3B69FCA2BB6E81DA3BDFFE3ABC93CA08BBB
E8068BC1152553C225124BB5DF0DD3B0EEE3DBCEF8E02BC1F3A14BC4F0A28BC3415423B7CA785BA008236BBF1A75C3CF94F503CD367A13A0DC744BC30E47239
072F77BB1B72F03B8EC518BA3A1E5D3CF5953C3CC33A4F3C0B562DBCE2334D3C2E33653C9050F2B9A71E073C9A3C26BCF63130BBA0D86A3CDD41D1BB43D045B
BDD6A883B5594113CCCA3A43B6D08B3BB9B385F3BE4D90F3C99C5B8BB6E7F583CD103493CD9EC89BBD0C511B82838D63B8A49B1BBE3D92C3B60644F3BC68B02
3C030400BCBC6F99BB2D9ECDBA25435B3C4A74BD3AEF522CBB3A67AB3B0E66183A6DEDF73B2B3A5EBB925F92BBD008DB3A0D2652BCE11C123C0FB468BC14E02
93BB8E1F43AB857093C0AC9173BF0932DBCC06BA33BC9DF31BCB37F5A3C29B24D3B006908BC3C768B3B5526103B5AB2A3BBF87A7E3B8519BA3B530B323CD898
6BBCFF61B33B413A893B9CD2B13B5AD147BB56B62FBB748E383CAECA4B3C88E0B03B069137BC8E02FAB96B5A64BC980850BCD434753B6F88D8BBFCBC093C07E
EA73BEAA240BC28B18A3BC6A851BC1351DFBB50762C3C0D6ECDBA45150ABC94635CBC486A6ABCBE735F3C5A626DBC308543BB86C86BBCE670B73B74FA1DBC16
9730BB21E4293C12C570BCFD1990BBCA8AB73B22D66C3A122870BCBF0E0FBCAEC26CBC3D9E4E3C42049D3BD41CF2BB2FD72CBCADCA2DBCD966563CCA946B3C7
DE203BCC4FA0D3CD289E83BF7439ABBB2B920BC18C1033CC3E22CBCC6883C3BB877513CDB515A3C"&gt; : tensor&lt;512xf32&gt;} : () -&gt; tensor&lt;512xf32&gt;
  %cst_26 = "std.constant"() {value = dense&lt;"0x7460CA3B75992EBC01CB64BC4859043C8B26BABBE5BE90BB89EC193BF8C9C23A98BC093C3C04E93A
2C2424BC681B0BBCE8AC8C3B2FC84DBCDD113CBC116F90BB1306B3BB5EB078BA6A0F7B3B23B6003C41648FBAC2D860BC38FD92BB581C16BCEC00CEBB44F84FB
CF35314BCB63B02BC4B7239BC9EE30BBC9B851F3CF6D260396245A3BB86D442BCCEBC62BC63F969BBEB6E563CEA56B53B28FD573C98974B3C361671BCFB9C60
3C0978603C733C4A3CDD7353BCC4782ABB0F0E6B3BF534F83BF93C8E3AB8E25D3C2493CF3AD439CE3A2428153CCAF95FBCAC4E703CF23823BC496BA83812CC1
2BCCF4A833B7FFABF3BA87BB0BB84F96B3C4EF1F33B2D9FDD3B48D304BC6AAE693C2FFEF03BB110333BE69C4C3C480143BBB902263CF7B752BB817AC1BB180A
C33A2E3819BCAD2CE93BF2313A3C34D9C73B6D5457BCBC5B403C054C09BC88276DBC42F891BBAE5F5F3C99A39ABBB9B958B9995396BBD270513C557D10BCA61
C203CF12C543C2409223C8D7ECDBB07772D3AAAD71B3C41663DBC82F2D9BB622D703C54E5FF3A0CF9293B68A80CBC6D6FA0BBE56F8ABB2F444F3C18FE54BCBA
C5473BE46AB7BA50B2B13B067E19BCDBE244BB5D7A63BB43752A3C689DC33A44986A3CB018133AFD5120BC5954F1BB0272D5BA07071ABC94BB34BC89D258BC3
D14B53A700411BA52346DBBA0EEFFBB37544CBC1E663EBC8CC3E13B81656F3A5B98773BE8DF16BC805AA53B290DA7B94CDF4DBCB7DDE53B6A4E1FBCA59934BC
B85CBDBBBA92213C3CB41A3CB58BCD3A61B782BBB80FE5BB692E65BC7D4603BC4B9A52BB7103DDBBFBF4003C07DF2CBC939D4CBC0645CF3B56F5853B0827FA3
B8FD0493C92FD303BBCFE8C3B1E175F3C9890393C961A573C03212A3CFC022A3B8687DBBB0B46EA3A4D4A33BB85C93D3CFF7233BC9BA233BC512D5B3CB784A6
3B583C12BB01121ABC2AE4C23B1ACF61BB21E2D2BBFCD36FBCC2DBB53B9380153B6A78D0BB315B683CFEB547392C4F42BCE726903B9376D8BBD37232BCD564D
23BF2264FBCEE2B633C040CCFBB2AD0303B2FA456BC774E5FBB67F7423CFB2B893AAF1A7838B08D11BCA0C63EBC0FEAF6B90299913B5E112CBCCF67353C8F14
A7BBB6DE48BC62E617BCE915C1BB920919BC7D50D23B3D0217BCCA0101BBF062B13B5A11663CD42CBD3B5D2CA03B3682983A03650D3C1C5E333CFDA46FBB59F
4373CC2B8643C4F2D4EBC033DFC3BAFCDC4BAB2A73BBCD3FBEAB97B25B9BB1F655DBCDD60CBBB9E0E9D3B59FE303C672F013C0FB009BCFFAB17BC8EB76C3B32
9327BC5477C3BB896DB9BB441FFDBB41D0A8BB8935C0BA2047B13B744CFA3B85CDDE3B22196F3A11E993BB37D0E8BB2E0B0D3B18C3A9BA40224F3B5B0C00BCD
2B646BC76463CBB131FD83B9D10723B41C2B83B41F04ABBE57533BA210E8EBAA9B8883B80FF683BE4848D3BBC11D5BB989E2C3C6BF04EBC7691523CEB74603C
037A5B3C39AB953BFEC80B3BD1448FB809BE043C41890D3C19D702BB2877513C6495E5BBEADA62BC2E65EDBBAB059ABB045A533C3629693CE91DE9BB1542A0B
B0169033BBB5B5A3C7A053A3CF69F553BBAE716BBB032463C6E35CF3BCA0430BCF54910BCEAC5783BE6B36D3B75C355BC0D75D33B407CC4B9373841BCADBD37
3C63222E3B2D337DB9FFDF51BB526EF23B519AF1B99E3F6F3CACEE2A3B14E48ABBB7CF5FB67EAB2E3CFEC447B943D65EBB2D5A563C551434BBC162ADBB5361D
93BDE17233BD58A48BC2649933B139747BC53A25DBBA94B8EBBEE5DC43BC7D16D3CD1D288BB2C30393C41552EBCF2A06D398667C9BBDA5DBD3AB6BE3DBCE79A
4F3C6538643A0B4D54BC30CA973B1D30AF3BCC062C3B6D9DE93B7B2C88BB5B8915BB37AE20BC82A1F33B498AD23BFEA8203C750B48BCF987D8B936ADAB3BE30
A54BC90AA503B13DD6ABB247F5C3BB334693909FE1E3C5AF330BC33410C3CFE509D3BB516FDBB2466C83B740C523C71812CBC20EF16BC5DB4623CE030CABB83
4F8F3B8443B0BB6263573CFBB5133C732946BCFC51E8BADC1940BC38095FBC4A400CBB6C1AE8BA34C2C73B8DC010BC5E26A5BB66724ABCBE65EBBB40003F3CA
4FB193CE73327BC14622DBC1C64503AFD4814BCBD1424BC41174139C42352BC7F5D21BC11B294BBC3CAA83B6B565E3B1707513BA92DD8BA657383BABD259CBA
716E293C681C973BC2412FBC87BF39BC25E24F3C51D7533C9319D3BB5C0C343CCEC8C3BB0759B4BB6D80503C6A804C3C1BAC2D3BADB02F3C8866AB39BCFCB0B
BDFD8B43BD171C1BB64D8393C7F8E45BB1ECF533B4E88923BA8D44FBC69F88E3AE00B473C5E81803A2739A7BBF1656EBC50F7F83B892F5BBCACAA08BC093509
BC527A93BB3D4CFEBA0F1B62BC8CC6C83BCA0CBC3A62008DBAA4AA70BC118216BCC7236FBC83173BBA636FA0BBE7F5233CE3862A3C93DF0C3C5F93503CA0F80
93C9BA4F13B70AD023C871E0C3CE113ECBBE1F2F53BCF3EA63B88F600BCA2515D3CC2493DBB04DB433BEDF719BA6807283C1B74F2BBAE4131BC123DB7BB2169
27BC2DE1B4BAD2D748BCF3C7433C70F50F3CCF6E6DBC6FA7473CE6A191BB8D59623C3C5787BB516302BCDCA7D43BFE2E19BC9F28663C2D4C663C6A944C3CAFA
4063C0074A3BB4BCEA1B920250FBCC0D3E03B799935BC0271B7BBC69F41BC6495D4BB16CC0F3CBCF1CE371D4CE53A6994303C66C149BCCFA3A83B39A669BCB9
53363C7668FF3BF57D1ABB74B4EC3B2FAB613CE05DAA3A42A4B7BB011114BC4A517A3BAFEBC0BB9079143C6D8968BC88B60CBC2A5A143C13E662BCEF34013C4
7BB52BCA99D433C5F9B02BC6738503CF605663C4238DB3B62F2093C75A43DBCBF61313CEC6CD53B"&gt; : tensor&lt;512xf32&gt;} : () -&gt; tensor&lt;512xf32&gt;
  %cst_27 = "std.constant"() {value = dense&lt;"0x87236A3B5915D9B9F4955CBC1A453A3CEE1A4ABCC4746FBC09A51ABC09960D3C9E9F3CBC8C185CBB
24CD5CBCBBF7A8BB1138603CE161053C0493A33B1D9C433C1E02193A0D4E44BC665BD5BBF2D2A33A6B231CBC11FB8EBB143A55BCBE28713C68BC3E3CA0B6C7B
BC4D3263CCBC653BAEE36F33B85284E3C170C5C3CC3A8233C01D9873B5489B5BBCF3F6DBC574269BB23565F3B6511EC3B1DEA5FBC96D535BC1030B13B3218C2
3BC006E33BB80760BC1BCC563C95572DBC414265BC99E339BCB2229F3BDB07BB3AB7E0C6BBEA4B6ABCF12E54BC92195ABC0D70483C26D69DBBC19281BBC470C
EBA7912AF3B24E31EBBD796183CC2F73BBADA9A273C8D2D263B7EEE1DBC59EB023BBF6D193C6AB762BBAFF7ACBA1EABE0BB938AB2BBBF47673CD296473C0B45
C03B31ADA6BA96A0203C83D49B3B6855CEBBDFA541BC08931BBC637A1BBCC4892FBC01A1233CCBE040BC1E93B53BE4A6593CB038DCBAB20E7B3B3A1813BCB54
30ABC2BD014BC0CE340BCEB2153BC700B5F3C120630BCC5C933B82947883B859802BAB5151ABC3DC14B3AE04DE13B6FACEF3B113EAC3B3A25353CC02BC83BE6
8CBCBB3EC7AA3BBB4A39BB89530B3CF08312BBD5013D3C8F721EBC0723203B05E94DBC8107353BCFB91439EBA6443BFB3D0EBC442AD6BB5ECA21BC672FC5BAE
85CF4BAB39207BC5378133CB1093EBC0AF0403CC746673CF9C234BCC1414D3BF08FF5BBC2013DBA32316A3C3D947CBB66D02F3A4D844DBC4983E93B2703823B
56DD3BBB206DC9BB54509FBB29931C3BCCC70F3C5C194FBBD7A109BBAA91EE3A99B168BC5FBA5DBCC8B768BB5FB787BBAA3A5FBC9FD75C3C1011E23B6E8ADB3
BD0DF7FBBC2FCF43B46DCDA3B4046C439BB1645BC946CFEBBC80BBDBB6CA66F3C530DBF3B5CA867BC205833BC8C7037BC0CFA073CE7E2823BDC887EBA2EA136
BCCCB7163CCBE0243C38CA4C3C1FDA20BBCC2CB83ACB175CBC2E6BAF3A557984B969EBC4BBD025433A557FCC3A1BC638BBA57517BC4D74D23BC968373C6D4B8
ABBEBD0683C87C1C03B1D16483C55A1D13B1352253CB530AF3BE79D1F3C7FCBC43923C52DBB2B6D5DBB00BB13BB92A608BC14D0583CAC5070BCB991E6BB218E
7B3B48AE3BBCD9645C3CF0F41A3C4995493C46A75BBC92826A3CC25DD6BA61CC38BC2D625DBC83175F3BD64227BC15281BBBE8F5F93BC1892F3C9AC7D6B97B3
9363C67269ABBC2DC483B93386D3CB984243C63F4293CC799F5BA3752B3BB8F53C1BBE0C7803B7898A33B953DBB3BA84B1F3BE19FBA3B741364BC205B1A3C7D
A0283BBB8AC03B4EFB333C4417B6BA4C81023CB98113BC60D343BBE8C5363B1DEC173C02A13ABCB173243C66E6443CAA3C6EBCBF0D20BCB57E44BC9915053C0
0DE6CBC3B0145BBC2F352BCD5E9163C611841BCF7DA543CC5F08EBB28EDA53BF0BE973BAF4D6ABBF3E25B3C4F5DB23B378159BCD273ECBAC888343C7752DFB9
5C3B1DBA5B5F2C3B24A7273CD40667BB6FCD63BCD2CB323CC252043CF58A96BB226BA4BA7DB0BEBB58D635BB5F3913BC148E0E3C5149A13BB40A68B862C5653
C9252003BCFF6293C09B8AEBB4EBB493A7799AEBA526F51BCD59A4E3C946A67BBD3CC9BBBD5D2303C23303CBC984C4E3BD582C1BBAD8FEB3B18F3803B049CB6
B9A6E3DC3B7923333B034269BC8A60E63B916BE93B6C7F5CBC24DD9E3A1A2ECEBB4C55643C0D8339BC16E9FE3B924E33BC4BD7A0B847CD6A3B997E47BCF9BFB
ABB191844BC8BC759BCFB985CBC605DA33B642ED4BB684DA9B95686C13BA53FB3BB91F16FBABED41FBC4DE26E3C437C373C6E165F3C0F4EF4BB8987543CFFBC
D73B23A39CBB85B955BCA2FBD33A39FFC53B8DC7B33AAB1A1ABC2DC206BCC8D8B03BB18B403A7AA520BC7132A13BD0FFD9BB4D5FC7BB84C62B3B07E0C4BAD72
F88BB2DC8D9BBA923493CC6DD3DBB5319143BFAD563BC1F8812BCFFDE1EBC322E453C2C9302BC8BE6C4BB573109BBFCC17EBB90351E3B1ABC3DBC95BEFDBA5D
06E3BB76B5C93A153226BBF99EF13A7ECAAF3A3EA419BC06604C3CE4EAD4BBB208FCBB636B5E3B51DB473CFCD7FDBBE457A53B848E48BC3215003B4D1F16BC8
3D334BC1278BBBB5AE6543A23CB193C74251DBCCEB7583C800530BC61D702BC6BD8EBBA56D3503CB485693CD91641BCDD5AE6BBB97A5FBC81B200BC1A1C53BC
7D6E4DB9862E0BBBEA245E3C27E1F63A6818C3BAF26B913B04EF1A3C174A13BCDF4213BCB954F9BBC21D293CF62D66BCD0102F3C742F01BC83D2773B27B55A3
C59C5EBBBC72BDFBB206E5F3CAD993F3B85B65C3C1356553CCD9F9CB919C0243C53922FBC9E761C3C3C5DD53B8F7696BA1ADAE8BB27A7073B9D0CB93B277C13
3CE21AA53A9B896D3C061AC43B2898F33A9D3B123CFC17B03BE04561BC9315A0BA492C0D3C0B4958BC01AD603C3066103CEC13E13BC90D72BB543085B9D972E
ABB18D6073C4754FC3B59115B3C823D463CA49EAF3BC38F843B8B06903B19305CBCC44B91BBFB020ABCE6A44FBCCE67F8BA2732ACBBBF0EA93BA507F73B6110
023B782E38BCF87C8DBB740524BC37DC39BB689D283C9B58903B66CC55BC5EF09D3B890990BA9FE483BBDCAA633C2D437C391379FB3BFD96263BB4CFDCBB6E3
C473C59043FBB94FF443C905851BC5DC21B3A0457323C3189183C0DE2BFBB2FA0B33BAAF64FBC5306633CC7D4E43B65EB8FBBF3FE08BCB2F94A3C5FCD47BCEF
CF70BC30E5333C26FF9FBB016970BBC105DF3B8672F43BECF9D5BB5C40143C114CA03B0D7A21BCA45C56BC5A9EB1BB9E782D3C45BB0F3B9A9623BB8BA7483C9
57CDFBB11789ABBDB3607BC37C3503BCFE8493CACD1853AA8FF153C27BB2A3C3B03823BDACFF33B"&gt; : tensor&lt;512xf32&gt;} : () -&gt; tensor&lt;512xf32&gt;
  %cst_28 = "std.constant"() {value = dense&lt;0&gt; : tensor&lt;1xi32&gt;} : () -&gt; tensor&lt;1xi32&gt;
  %cst_29 = "std.constant"() {value = dense&lt;1&gt; : tensor&lt;1xi32&gt;} : () -&gt; tensor&lt;1xi32&gt;
  %cst_30 = "std.constant"() {value = dense&lt;0&gt; : tensor&lt;4x2xi32&gt;} : () -&gt; tensor&lt;4x2xi32&gt;
  %0 = "tfl.pad"(%arg0, %cst) : (tensor&lt;?x3x32x32xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x3x34x34xf32&gt;
  %1 = "tfl.transpose"(%0, %cst_3) : (tensor&lt;?x3x34x34xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x34x34x3xf32&gt;
  %2 = "tfl.split"(%cst_1, %1) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x34x34x3xf32&gt;) -&gt; tensor&lt;?x34x34x3xf32&gt;
  %3 = "tfl.conv_2d"(%2, %cst_8, %cst_18) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function
= "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x34x34x3xf32&gt;, tensor&lt;64x3x3x3xf32&gt;, tensor&lt;64x
f32&gt;) -&gt; tensor&lt;?x32x32x64xf32&gt;
  %4 = "tfl.transpose"(%3, %cst_2) : (tensor&lt;?x32x32x64xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x64x32x32xf32&gt;
  %5 = "tfl.pad"(%4, %cst) : (tensor&lt;?x64x32x32xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x64x34x34xf32&gt;
  %6 = "tfl.transpose"(%5, %cst_3) : (tensor&lt;?x64x34x34xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x34x34x64xf32&gt;
  %7 = "tfl.split"(%cst_1, %6) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x34x34x64xf32&gt;) -&gt; tensor&lt;?x34x34x64xf32&gt;
  %8 = "tfl.conv_2d"(%7, %cst_9, %cst_19) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function
= "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x34x34x64xf32&gt;, tensor&lt;64x3x3x64xf32&gt;, tensor&lt;6
4xf32&gt;) -&gt; tensor&lt;?x32x32x64xf32&gt;
  %9 = "tfl.transpose"(%8, %cst_2) : (tensor&lt;?x32x32x64xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x64x32x32xf32&gt;
  %10 = "tfl.transpose"(%9, %cst_3) : (tensor&lt;?x64x32x32xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x32x32x64xf32&gt;
  %11 = "tfl.max_pool_2d"(%10) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = "NONE", padding =
"VALID", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor&lt;?x32x32x64xf32&gt;) -&gt; tensor&lt;?x16x16x64xf32&gt;
  %12 = "tfl.transpose"(%11, %cst_2) : (tensor&lt;?x16x16x64xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x64x16x16xf32&gt;
  %13 = "tfl.pad"(%12, %cst) : (tensor&lt;?x64x16x16xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x64x18x18xf32&gt;
  %14 = "tfl.transpose"(%13, %cst_3) : (tensor&lt;?x64x18x18xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x18x18x64xf32&gt;
  %15 = "tfl.split"(%cst_1, %14) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x18x18x64xf32&gt;) -&gt; tensor&lt;?x18x18x64xf32&gt;
  %16 = "tfl.conv_2d"(%15, %cst_10, %cst_20) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x18x18x64xf32&gt;, tensor&lt;128x3x3x64xf32&gt;, tens
or&lt;128xf32&gt;) -&gt; tensor&lt;?x16x16x128xf32&gt;
  %17 = "tfl.transpose"(%16, %cst_2) : (tensor&lt;?x16x16x128xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x128x16x16xf32&gt;
  %18 = "tfl.pad"(%17, %cst) : (tensor&lt;?x128x16x16xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x128x18x18xf32&gt;
  %19 = "tfl.transpose"(%18, %cst_3) : (tensor&lt;?x128x18x18xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x18x18x128xf32&gt;
  %20 = "tfl.split"(%cst_1, %19) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x18x18x128xf32&gt;) -&gt; tensor&lt;?x18x18x128xf32&gt;
  %21 = "tfl.conv_2d"(%20, %cst_11, %cst_21) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x18x18x128xf32&gt;, tensor&lt;128x3x3x128xf32&gt;, te
nsor&lt;128xf32&gt;) -&gt; tensor&lt;?x16x16x128xf32&gt;
  %22 = "tfl.transpose"(%21, %cst_2) : (tensor&lt;?x16x16x128xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x128x16x16xf32&gt;
  %23 = "tfl.transpose"(%22, %cst_3) : (tensor&lt;?x128x16x16xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x16x16x128xf32&gt;
  %24 = "tfl.max_pool_2d"(%23) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = "NONE", padding =
"VALID", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor&lt;?x16x16x128xf32&gt;) -&gt; tensor&lt;?x8x8x128xf32&gt;
  %25 = "tfl.transpose"(%24, %cst_2) : (tensor&lt;?x8x8x128xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x128x8x8xf32&gt;
  %26 = "tfl.pad"(%25, %cst) : (tensor&lt;?x128x8x8xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x128x10x10xf32&gt;
  %27 = "tfl.transpose"(%26, %cst_3) : (tensor&lt;?x128x10x10xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x10x10x128xf32&gt;
  %28 = "tfl.split"(%cst_1, %27) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x10x10x128xf32&gt;) -&gt; tensor&lt;?x10x10x128xf32&gt;
  %29 = "tfl.conv_2d"(%28, %cst_12, %cst_22) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x10x10x128xf32&gt;, tensor&lt;256x3x3x128xf32&gt;, te
nsor&lt;256xf32&gt;) -&gt; tensor&lt;?x8x8x256xf32&gt;
  %30 = "tfl.transpose"(%29, %cst_2) : (tensor&lt;?x8x8x256xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x256x8x8xf32&gt;
  %31 = "tfl.pad"(%30, %cst) : (tensor&lt;?x256x8x8xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x256x10x10xf32&gt;
  %32 = "tfl.transpose"(%31, %cst_3) : (tensor&lt;?x256x10x10xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x10x10x256xf32&gt;
  %33 = "tfl.split"(%cst_1, %32) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x10x10x256xf32&gt;) -&gt; tensor&lt;?x10x10x256xf32&gt;
  %34 = "tfl.conv_2d"(%33, %cst_13, %cst_23) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x10x10x256xf32&gt;, tensor&lt;256x3x3x256xf32&gt;, te
nsor&lt;256xf32&gt;) -&gt; tensor&lt;?x8x8x256xf32&gt;
  %35 = "tfl.transpose"(%34, %cst_2) : (tensor&lt;?x8x8x256xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x256x8x8xf32&gt;
  %36 = "tfl.transpose"(%35, %cst_3) : (tensor&lt;?x256x8x8xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x8x8x256xf32&gt;
  %37 = "tfl.max_pool_2d"(%36) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = "NONE", padding =
"VALID", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor&lt;?x8x8x256xf32&gt;) -&gt; tensor&lt;?x4x4x256xf32&gt;
  %38 = "tfl.transpose"(%37, %cst_2) : (tensor&lt;?x4x4x256xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x256x4x4xf32&gt;
  %39 = "tfl.pad"(%38, %cst) : (tensor&lt;?x256x4x4xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x256x6x6xf32&gt;
  %40 = "tfl.transpose"(%39, %cst_3) : (tensor&lt;?x256x6x6xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x6x6x256xf32&gt;
  %41 = "tfl.split"(%cst_1, %40) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x6x6x256xf32&gt;) -&gt; tensor&lt;?x6x6x256xf32&gt;
  %42 = "tfl.conv_2d"(%41, %cst_14, %cst_24) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x6x6x256xf32&gt;, tensor&lt;512x3x3x256xf32&gt;, tens
or&lt;512xf32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %43 = "tfl.transpose"(%42, %cst_2) : (tensor&lt;?x4x4x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x4x4xf32&gt;
  %44 = "tfl.pad"(%43, %cst) : (tensor&lt;?x512x4x4xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x512x6x6xf32&gt;
  %45 = "tfl.transpose"(%44, %cst_3) : (tensor&lt;?x512x6x6xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x6x6x512xf32&gt;
  %46 = "tfl.split"(%cst_1, %45) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x6x6x512xf32&gt;) -&gt; tensor&lt;?x6x6x512xf32&gt;
  %47 = "tfl.conv_2d"(%46, %cst_15, %cst_25) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x6x6x512xf32&gt;, tensor&lt;512x3x3x512xf32&gt;, tens
or&lt;512xf32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %48 = "tfl.transpose"(%47, %cst_2) : (tensor&lt;?x4x4x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x4x4xf32&gt;
  %49 = "tfl.transpose"(%48, %cst_3) : (tensor&lt;?x512x4x4xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %50 = "tfl.max_pool_2d"(%49) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = "NONE", padding =
"VALID", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor&lt;?x4x4x512xf32&gt;) -&gt; tensor&lt;?x2x2x512xf32&gt;
  %51 = "tfl.transpose"(%50, %cst_2) : (tensor&lt;?x2x2x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x2x2xf32&gt;
  %52 = "tfl.pad"(%51, %cst) : (tensor&lt;?x512x2x2xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x512x4x4xf32&gt;
  %53 = "tfl.transpose"(%52, %cst_3) : (tensor&lt;?x512x4x4xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %54 = "tfl.split"(%cst_1, %53) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x4x4x512xf32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %55 = "tfl.conv_2d"(%54, %cst_16, %cst_26) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x4x4x512xf32&gt;, tensor&lt;512x3x3x512xf32&gt;, tens
or&lt;512xf32&gt;) -&gt; tensor&lt;?x2x2x512xf32&gt;
  %56 = "tfl.transpose"(%55, %cst_2) : (tensor&lt;?x2x2x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x2x2xf32&gt;
  %57 = "tfl.pad"(%56, %cst) : (tensor&lt;?x512x2x2xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x512x4x4xf32&gt;
  %58 = "tfl.transpose"(%57, %cst_3) : (tensor&lt;?x512x4x4xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %59 = "tfl.split"(%cst_1, %58) {num_splits = 1 : i32} : (tensor&lt;i32&gt;, tensor&lt;?x4x4x512xf32&gt;) -&gt; tensor&lt;?x4x4x512xf32&gt;
  %60 = "tfl.conv_2d"(%59, %cst_17, %cst_27) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_functi
on = "RELU", padding = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x4x4x512xf32&gt;, tensor&lt;512x3x3x512xf32&gt;, tens
or&lt;512xf32&gt;) -&gt; tensor&lt;?x2x2x512xf32&gt;
  %61 = "tfl.transpose"(%60, %cst_2) : (tensor&lt;?x2x2x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x2x2xf32&gt;
  %62 = "tfl.transpose"(%61, %cst_3) : (tensor&lt;?x512x2x2xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x2x2x512xf32&gt;
  %63 = "tfl.max_pool_2d"(%62) {filter_height = 2 : i32, filter_width = 2 : i32, fused_activation_function = "NONE", padding =
"VALID", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor&lt;?x2x2x512xf32&gt;) -&gt; tensor&lt;?x1x1x512xf32&gt;
  %64 = "tfl.transpose"(%63, %cst_2) : (tensor&lt;?x1x1x512xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x512x1x1xf32&gt;
  %65 = "tfl.pad"(%64, %cst_30) : (tensor&lt;?x512x1x1xf32&gt;, tensor&lt;4x2xi32&gt;) -&gt; tensor&lt;?x512x1x1xf32&gt;
  %66 = "tfl.transpose"(%65, %cst_3) : (tensor&lt;?x512x1x1xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x?x?x?xf32&gt;
  %67 = "tfl.average_pool_2d"(%66) {filter_height = 1 : i32, filter_width = 1 : i32, fused_activation_function = "NONE", paddin
g = "VALID", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor&lt;?x?x?x?xf32&gt;) -&gt; tensor&lt;?x?x?x?xf32&gt;
  %68 = "tfl.transpose"(%67, %cst_2) : (tensor&lt;?x?x?x?xf32&gt;, tensor&lt;4xi32&gt;) -&gt; tensor&lt;?x?x?x?xf32&gt;
  %69 = "tfl.shape"(%68) : (tensor&lt;?x?x?x?xf32&gt;) -&gt; tensor&lt;4xi64&gt;
  %70 = "tfl.gather"(%69, %cst_4) {axis = 0 : i32} : (tensor&lt;4xi64&gt;, tensor&lt;i64&gt;) -&gt; tensor&lt;i64&gt;
  %71 = "tfl.reshape"(%70, %cst_29) : (tensor&lt;i64&gt;, tensor&lt;1xi32&gt;) -&gt; tensor&lt;1xi64&gt;
  %72 = "tfl.concatenation"(%71, %cst_5) {axis = 0 : i32, fused_activation_function = "NONE"} : (tensor&lt;1xi64&gt;, tensor&lt;1xi64&gt;)
-&gt; tensor&lt;2xi64&gt;
  %73 = "tfl.equal"(%72, %cst_4) : (tensor&lt;2xi64&gt;, tensor&lt;i64&gt;) -&gt; tensor&lt;2xi1&gt;
  %74 = "tfl.where"(%73) : (tensor&lt;2xi1&gt;) -&gt; tensor&lt;?x1xi64&gt;
  %75 = "tfl.squeeze"(%74) {squeeze_dims = [-1]} : (tensor&lt;?x1xi64&gt;) -&gt; tensor&lt;?xi64&gt;
  %76 = "tfl.gather"(%69, %75) {axis = 0 : i32} : (tensor&lt;4xi64&gt;, tensor&lt;?xi64&gt;) -&gt; tensor&lt;?xi64&gt;
  %77 = "tfl.sparse_to_dense"(%74, %cst_0, %76, %cst_4) : (tensor&lt;?x1xi64&gt;, tensor&lt;1xi64&gt;, tensor&lt;?xi64&gt;, tensor&lt;i64&gt;) -&gt; tenso
r&lt;2xi64&gt;
  %78 = "tf.AddV2"(%72, %77) {device = ""} : (tensor&lt;2xi64&gt;, tensor&lt;2xi64&gt;) -&gt; tensor&lt;2xi64&gt;
  %79 = "tfl.cast"(%78) : (tensor&lt;2xi64&gt;) -&gt; tensor&lt;2xi32&gt;
  %80 = "tfl.reshape"(%68, %79) : (tensor&lt;?x?x?x?xf32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;?x?xf32&gt;
  %81 = "tfl.shape"(%80) : (tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;2xi32&gt;
  %82 = "tfl.strided_slice"(%81, %cst_28, %cst_29, %cst_29) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32,
 new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor&lt;2xi32&gt;, tensor&lt;1xi32&gt;, tensor&lt;1xi32&gt;, tensor&lt;1xi32&gt;) -&gt; tensor&lt;
i32&gt;
  %83 = "tfl.pack"(%82, %cst_1) {axis = 0 : i32, values_count = 2 : i32} : (tensor&lt;i32&gt;, tensor&lt;i32&gt;) -&gt; tensor&lt;2xi32&gt;
  %84 = "tfl.reshape"(%68, %83) : (tensor&lt;?x?x?x?xf32&gt;, tensor&lt;2xi32&gt;) -&gt; tensor&lt;?x?xf32&gt;
  %85 = "tfl.fully_connected"(%84, %cst_6, %cst_7) {fused_activation_function = "NONE", keep_num_dims = false, weights_format =
 "DEFAULT"} : (tensor&lt;?x?xf32&gt;, tensor&lt;10x512xf32&gt;, tensor&lt;10xf32&gt;) -&gt; tensor&lt;?x10xf32&gt;
  "std.return"(%85) : (tensor&lt;?x10xf32&gt;) -&gt; ()
}) {sym_name = "main", tf.entry_function = {control_outputs = "", inputs = "input", outputs = "Identity"}, type = (tensor&lt;?x3x3
2x32xf32&gt;) -&gt; tensor&lt;?x10xf32&gt;} : () -&gt; ()

But the issue is with AddV2


--Under nightly
error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.AddV2 {device = ""}
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py", line 213, in toco_convert_protos
    enable_mlir_converter)
  File "C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\wrap_toco.py", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: &lt;unknown&gt;:0: error: loc(callsite(callsite("add_10@__inference___call___388" at "PartitionedCall@__inference_signature_wrapper_441") at "PartitionedCall")): 'tf.AddV2' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: note: loc("PartitionedCall"): called from
&lt;unknown&gt;:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.AddV2 {device = ""}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:/Users/macin/Documents/GitHub/torchToTFLite/converter.py", line 49, in &lt;module&gt;
    tflite_model = converter.convert()
  File "C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\lite.py", line 739, in convert
    result = _convert_saved_model(**converter_kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py", line 637, in convert_saved_model
    enable_mlir_converter=True)
  File "C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\lite\python\convert.py", line 216, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: &lt;unknown&gt;:0: error: loc(callsite(callsite("add_10@__inference___call___388" at "PartitionedCall@__inference_signature_wrapper_441") at "PartitionedCall")): 'tf.AddV2' op is neither a custom op nor a flex op
&lt;unknown&gt;:0: note: loc("PartitionedCall"): called from
&lt;unknown&gt;:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.AddV2 {device = ""}
&lt;/denchmark-code&gt;

Also, please include a link to the saved model or GraphDef
&lt;denchmark-code&gt;https://drive.google.com/file/d/1UPXTbUaXzWDzHJUz8W7plO_L6lgNCNVD/view?usp=sharing
&lt;/denchmark-code&gt;

Failure details
The saved model converted from PyTorch contains ops AddV2 and pad. Pad caused problems in 2.2.0 while AddV2 causes problems in 2.3.0 and nightly.
	</description>
	<comments>
		<comment id='1' author='slimwangyue' date='2020-11-17T18:20:15Z'>
		Can anyone help with this issue? I have been stuck on it for several weeks.
		</comment>
		<comment id='2' author='slimwangyue' date='2020-11-21T00:43:36Z'>
		It looks like your model uses add with Int64 types, TFLite doesn't support Add with Int64 types, and that's why it can't convert the TF op to the corresponding TFLite Op.
You can either,

Change the Add to use I32 instead of I64.
Add Cast before the Add op to cast from I64 to I32
Use TFLite with Select options, which in this case the Add Op with Int64 will be run using TF not TFLite - there is some penalty for doing this. See more details here

		</comment>
		<comment id='3' author='slimwangyue' date='2020-11-27T08:27:31Z'>
		Thank you for the advice!
For deployment reasons, it is hard for us to go with option 3 using TF ops.
As we are working with a long pipeline from PyTorch -&gt; ONNX -&gt; savedmodel -&gt; TFLite, it appears hard to control dtype in the savedmodel stage, where the Int64 Add appears.
I was hoping, is there any way to directly modify data type in the savedmodel encoding? So that we can keep the pipeline the same, modify datatype in savedmodel, then get to TFLite.
		</comment>
		<comment id='4' author='slimwangyue' date='2020-11-30T19:41:13Z'>
		&lt;denchmark-link:https://github.com/Makkiy&gt;@Makkiy&lt;/denchmark-link&gt;
 You can load the model and update as you wish and save it again.
See guide
&lt;denchmark-link:https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format&gt;https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='slimwangyue' date='2020-11-30T19:41:45Z'>
		I am going to close the issue, feel free to reopen or create a new one. If there is an issue you wish to report.
Thanks
		</comment>
		<comment id='6' author='slimwangyue' date='2020-11-30T19:41:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44694&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44694&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='slimwangyue' date='2020-12-02T00:52:47Z'>
		Sorry, we cannot fix the problem with your solution. The loaded model is empty.
		</comment>
		<comment id='8' author='slimwangyue' date='2020-12-04T18:23:38Z'>
		&lt;denchmark-link:https://github.com/slimwangyue&gt;@slimwangyue&lt;/denchmark-link&gt;
 I think you might have done something wrong. You're trying to convert this same model to TFLite, so it shouldn't be empty.
		</comment>
	</comments>
</bug>