<bug id='9590' author='JamesKostas' open_date='2017-05-02T08:50:57Z' closed_time='2017-05-13T00:07:40Z'>
	<summary>Memory Leak from Deep Learning Training Step? (Finalized Graph)</summary>
	<description>
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes, although my code is somewhat based on the MNIST deep learning tutorial.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 14.04 VERSION="14.04.5 LTS, Trusty Tahr"
TensorFlow installed from (source or binary):
binary (I think, not 100% sure since it's been a few months since install. How can I check?)
TensorFlow version (use command below):
('v0.11.0-2614-g14aeb08-dirty', '0.12.0-rc0')
Bazel version (if compiling from source):
CUDA/cuDNN version:
CUDA Version 8.0.44
GPU model and memory:
GeForce GTX 780M 4GB
Exact command to reproduce:
self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I apologize if this is not an actual bug; I am relatively new to TensorFlow. I have posted on StackOverflow &lt;denchmark-link:http://stackoverflow.com/questions/43695085/tensorflow-deep-learning-memory-leak&gt;here&lt;/denchmark-link&gt;
 and the only response I have gotten suggests filing a bug report here.
If I comment the sess.run line above, and only that line, out (but still do all my pre-processing and validation/testing and such for a few thousand training batches), the memory leak does not happen.
The leak is on the order of a few GB per hour (I am running Ubuntu, and have 16GB RAM + 16GB swap; the system becomes very laggy and unresponsive after 1-3 hours of running, when about 1/3-1/2 the RAM is used, which is a bit weird to me since I still have lots of RAM and the CPU is mostly free when this happens...)
Here is some of the initializer code (only run once, at the beginning) if it is relevant:
&lt;denchmark-code&gt;
    with tf.name_scope('after_final_layer') as scope:
        self.layer1 = weights["wc1"]
        self.y_conv = network(self.x, weights, biases, self.keepratio)['out']
        variable_summaries(self.y_conv)
        # Note: Don't add a softmax reducer in the network if you are going to use this
        # cross-entropy function
        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.y_conv, self.y_true, name = "softmax/cross_ent"), name = "reduce_mean")
        self.train_step = tf.train.AdamOptimizer(learning_rate, name = "Adam_Optimizer").minimize(self.cross_entropy)

        self.prediction = tf.argmax(self.y_conv, 1)
        self.correct_prediction = tf.equal(self.prediction, tf.argmax(self.y_true, 1))

        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))

        if tensorboard:
            # Merge all the summaries and write them out to the directory below
            self.merged = tf.summary.merge_all()
            self.my_writer = tf.summary.FileWriter('/home/james/PycharmProjects/AI_Final/my_tensorboard', graph=self.sess.graph)

        # self.sess.run(tf.initialize_all_variables()) #old outdated way to do below
        tf.global_variables_initializer().run(session=self.sess)
        self.sess.graph.finalize() #make sure nothing new is added to graph

&lt;/denchmark-code&gt;

Notice that I have finalized the graph, so nothing new should be added to it.
Am I doing something wrong/is this expected behavior, or is this a real bug?
I have attached the source code as well (two .py files in directory).  Note: I am happy put in the work to reduce the source to a minimal recreation of the bug, but first I'd like verification that 1) this would be helpful (i.e. that the above info is not enough) and that 2) this is probably a bug, and not just an obvious beginner mistake on my part.
Thank you in advance.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/969906/source.zip&gt;source.zip&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='JamesKostas' date='2017-05-06T18:08:15Z'>
		&lt;denchmark-link:https://github.com/jart&gt;@jart&lt;/denchmark-link&gt;
 could you take a look at the summary portion to see if you find anything obvious there?
I don't see obvious leak.
Could you run with the env variable TF_CPP_MIN_VLOG_LEVEL=1 *look at anything with __LOG_MEMORY__ and tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)?
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1824&gt;#1824&lt;/denchmark-link&gt;
 is a good example of debugging.
		</comment>
		<comment id='2' author='JamesKostas' date='2017-05-08T01:47:39Z'>
		&lt;denchmark-link:https://github.com/drpngx&gt;@drpngx&lt;/denchmark-link&gt;
 Every thousand steps, instead of doing a normal training step, I did
&lt;denchmark-code&gt;                run_metadata = tf.RunMetadata()
                self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels,
                                                      self.keepratio: self.training_keep_rate, },
                          options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)
                text_file = open("Output.txt", "a")
                text_file.write("\n\n\nstep %s\n:" % self.training_step_counter)
                text_file.write(str(run_metadata))

                text_file.close()

&lt;/denchmark-code&gt;

Did I do it correctly?  The output is attached for steps 0, 1000, 2000, 3000, 4000 (by which time a few GB have leaked).  Search for "step [number]" to go quickly between them.  I don't see anything about __LOG_MEMORY__ in there.  If I did it wrong, please let me know and I'll run it again.  Thanks!
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/982152/Output.txt&gt;Output.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='JamesKostas' date='2017-05-08T02:02:17Z'>
		It looks like it didn't work. You need to set the env variable, something like this
&lt;denchmark-code&gt;env TF_CPP_MIN_LOG_LEVEL=1 python my_tensorflow_program.py
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='JamesKostas' date='2017-05-09T16:45:24Z'>
		I tried again, running it like you directed.  I still do not see anything about __LOG_MEMORY__ in there.  If it's still not correct, the code is the same as above (every 1000 training steps I run the following)
&lt;denchmark-code&gt;                run_metadata = tf.RunMetadata()
                self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels,
                                                      self.keepratio: self.training_keep_rate, },
                          options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)
                text_file = open("Output.txt", "a")
                text_file.write("\n\n\nstep %s\n:" % self.training_step_counter)
                text_file.write(str(run_metadata))

                text_file.close()

&lt;/denchmark-code&gt;

and the command I ran was
&lt;denchmark-code&gt;env TF_CPP_MIN_LOG_LEVEL=1 python deep_1_02.py
&lt;/denchmark-code&gt;

Sorry if I'm not doing it correctly; I appreciate your help!
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/987324/Output.txt&gt;Output.txt&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='JamesKostas' date='2017-05-09T16:49:17Z'>
		Sorry, try setting the min VLOG level (TF_CPP_MIN_VLOG_LEVEL). There should be a lot of spew.
		</comment>
		<comment id='6' author='JamesKostas' date='2017-05-09T16:52:36Z'>
		Note that setting TF_CPP_MIN_VLOG_LEVEL if TF_CPP_MIN_LOG_LEVEL is set will have no effect. So you have to unset TF_CPP_MIN_LOG_LEVEL first.
I wrote &lt;denchmark-link:https://github.com/yaroslavvb/memory_util&gt;memory_util&lt;/denchmark-link&gt;
 to parse this log output. Save log to , and then do something like this to get a human readable timeline
memory_util.print_memory_timeline(open('stderr.txt').read(), ignore_less_than_bytes=10**6) 
		</comment>
		<comment id='7' author='JamesKostas' date='2017-05-09T19:15:53Z'>
		No luck getting any other kinds of output.  What am I looking for?  Will it print out in the console or is it going to be stored in my run_metadata = tf.RunMetadata() variable?
I've tried:

unsetting the env variables
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = "1"
os.environ['TF_CPP_MIN_LOG_LEVEL'] = "1"
restarting the computer
Exporting both versions of the above. (Doing it in the terminal instead of in the Python code)
Looking for results in both my output file and in my terminal

What exactly am I looking for?  Any ideas on why I'm not getting all the output?  Thank you again for the help.
		</comment>
		<comment id='8' author='JamesKostas' date='2017-05-09T19:25:22Z'>
		I just did this on my mac, using Mac CPU nightly from last week:
&lt;denchmark-code&gt;unset TF_CPP_MIN_LOG_LEVEL
export TF_CPP_MIN_VLOG_LEVEL=1
python -c "import tensorflow as tf; s = tf.Session(); s.run(tf.ones(()))"

&lt;/denchmark-code&gt;

and I saw a bunch of messages like this
&lt;denchmark-code&gt;2017-05-09 12:24:27.745962: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: "cpu" ptr: 140654466064000 } } }
2017-05-09 12:24:27.746192: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: "cpu" }
2017-05-09 12:24:27.746206: I tensorflow/core/framework/op_kernel.cc:1034] Instantiating kernel for node: ones = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [] values: 1&gt;, _device="/job:localhost/replica:0/task:0/cpu:0"]()
2017-05-09 12:24:27.746243: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: "cpu" ptr: 140654466061120 } } }
2017-05-09 12:24:27.776009: I tensorflow/core/framework/op_kernel.cc:1034] Instantiating kernel for node: _retval_ones_0_0 = _Retval[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"](ones)
2017-05-09 12:24:27.776123: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogStep { step_id: 1 handle: "-&gt;ones:0//0/;0" }
2017-05-09 12:24:27.776198: I tensorflow/core/common_runtime/executor.cc:1556] Process node: 0 step 1 _SOURCE = NoOp[]() is dead: 0
2017-05-09 12:24:27.776254: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6 kernel_name: "Unknown (from Proto)" tensor { dtype: DT_FLOAT shape { } allocation_description { requested_bytes: 4 allocator_name: "cpu" ptr: 140654466065440 } } }

&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='JamesKostas' date='2017-05-09T19:46:40Z'>
		&lt;denchmark-code&gt;unset TF_CPP_MIN_LOG_LEVEL
export TF_CPP_MIN_VLOG_LEVEL=1
python -c "import tensorflow as tf; s = tf.Session(); s.run(tf.ones(()))"
&lt;/denchmark-code&gt;

results only in
&lt;denchmark-code&gt;I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 780M
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:01:00.0
Total memory: 3.97GiB
Free memory: 3.64GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2f6e280
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: GeForce GTX 780M
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:07:00.0
Total memory: 3.97GiB
Free memory: 3.92GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 780M, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -&gt; (device: 1, name: GeForce GTX 780M, pci bus id: 0000:07:00.0)
&lt;/denchmark-code&gt;

Do I need to update my version or am I doing something else wrong? I'm using tf version 0.12.0-rc0, np version 1.12.0b1, Python version 2.7.6.  Thanks!
		</comment>
		<comment id='10' author='JamesKostas' date='2017-05-09T19:52:06Z'>
		Correct, your TF version is too old, you need at least 1.0, but perhaps a later version
		</comment>
		<comment id='11' author='JamesKostas' date='2017-05-13T00:07:32Z'>
		The issue is corrected in 1.1.  Thank you both for the help!  The reason I was using the old version is because &lt;denchmark-link:https://www.tensorflow.org/versions/&gt;it says here that 0.12 is the latest stable version.&lt;/denchmark-link&gt;
  If that is not the case I would suggest updating that page if possible to avoid other people making the same mistake.  Thanks again for your time and help!
		</comment>
	</comments>
</bug>