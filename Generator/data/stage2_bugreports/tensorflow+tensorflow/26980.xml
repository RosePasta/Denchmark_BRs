<bug id='26980' author='meyerjo' open_date='2019-03-21T09:11:37Z' closed_time='2019-03-27T21:12:56Z'>
	<summary>[TF2.0a0] Distribute Strategies and Summary Writer don't work together</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: python 3.6
CUDA/cuDNN version: 10.1
GPU model and memory: TITAN X

Describe the current behavior
I am trying to use tf.summary at the same time as using distribute strategies. However, the call to strategy.experimental_run seems to end the scope of the summary_writer. I have initialized it properly, but it is not available to me. I have tried passing the SummaryWriter object directly as another parameter of the train_step but it does not work and fails with the error message. Somehow, the scope seems to be lost through the experimental_run call.
[ops/summary_ops_v2.py:608] ValueError: No step set via 'step' argument or tf.summary.experimental.set_step()
For the most part, I followed this guide on how to work with DuplicateStrategies:
&lt;denchmark-link:https://www.tensorflow.org/alpha/tutorials/distribute/training_loops&gt;https://www.tensorflow.org/alpha/tutorials/distribute/training_loops&lt;/denchmark-link&gt;

Describe the expected behavior
Being able to write to write to the summary from within the training loop.
Code to reproduce the issue
import tensorflow as tf

def train_step(input, s_writer):
  with s_writer.as_default():
    tf.summary.scalar('test', 0)

def distributed_train(s_writer):
  return strategy.experimental_run(
    lambda x: train_step(x, s_writer), train_iterator)

if __name__ == '__main__':
  dataset = tf.data.Dataset.from_tensor_slices(
    (tf.random.uniform([5, 100])))

  strategy = tf.distribute.MirroredStrategy()
  summary_writer = tf.summary.create_file_writer('/tmp/test')

  with summary_writer.as_default() as summary_scope:
    with strategy.scope():

      train_iterator = strategy.make_dataset_iterator(dataset)
      train_iterator.initialize()

      tf.summary.experimental.set_step(0)
      # This works
      train_step(None, summary_writer)

      # This fails
      distributed_train(summary_writer)
	</description>
	<comments>
		<comment id='1' author='meyerjo' date='2019-03-26T07:48:09Z'>
		Thanks for reporting, we will take a look at it.
		</comment>
		<comment id='2' author='meyerjo' date='2019-03-26T17:31:22Z'>
		Issue identified, fix is on the way (should be submitted today)
		</comment>
		<comment id='3' author='meyerjo' date='2019-03-26T18:24:55Z'>
		Hi Johannes,
Could you please test if &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/7bdb838313d322773908cf8368c03ec98117ad55&gt;7bdb838&lt;/denchmark-link&gt;
 solves your issue?
Thanks!
		</comment>
		<comment id='4' author='meyerjo' date='2019-03-27T12:02:11Z'>
		I guess it is already included in the most recent nightly, isn't it? It seems to be working now.
		</comment>
		<comment id='5' author='meyerjo' date='2019-03-27T21:12:56Z'>
		Yeah nightly is less than one day old.
Good to know it works for you :-)
Closing this issue.
		</comment>
		<comment id='6' author='meyerjo' date='2019-03-27T21:12:57Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26980&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26980&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>