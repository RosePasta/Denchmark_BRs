<bug id='33613' author='Vooblin' open_date='2019-10-22T15:06:52Z' closed_time='2020-12-09T20:23:12Z'>
	<summary>[TFLite, Bug] Unexpected weights changes after conversion</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): VERSION=2.0.0, GIT_VERSION=v1.12.1-15611-g025365a736
Python version: 3.6.8
Bazel version (if compiling from source): 0.26.1
GCC/Compiler version (if compiling from source): GCC 8.3.0
CUDA/cuDNN version: CUDA Version: 10.1
GPU model and memory: GeForce GTX 1080 Titan 11GB

Describe the current behavior
In this issue code from tensorflow/models is used (tensorflow/models/official/nlp/bert_modeling.py). After conversion weights of model seriously changes. After some minimal fixes in source code of tensorflow/models it is solved but program mustn't changes. Below I show some cases. Code of keras layer EmbeddingPostprocessor:
&lt;denchmark-code&gt;def call(self, inputs):
    """Implements call() for the layer."""
    unpacked_inputs = tf_utils.unpack_inputs(inputs)
    word_embeddings = unpacked_inputs[0]
    token_type_ids = unpacked_inputs[1]
    input_shape = tf_utils.get_shape_list(word_embeddings, expected_rank=3)
    batch_size = input_shape[0]
    seq_length = input_shape[1]
    width = input_shape[2]

    output = word_embeddings
    if self.use_type_embeddings:
      flat_token_type_ids = tf.reshape(token_type_ids, [-1])
      one_hot_ids = tf.one_hot(
          flat_token_type_ids,
          depth=self.token_type_vocab_size,
          dtype=self.dtype)
      token_type_embeddings = tf.matmul(one_hot_ids, self.type_embeddings)
      token_type_embeddings = tf.reshape(token_type_embeddings,
                                         [batch_size, seq_length, width])
      output += token_type_embeddings

    if self.use_position_embeddings:
      position_embeddings = tf.expand_dims(
          tf.slice(self.position_embeddings, [0, 0], [seq_length, width]),
          axis=0)

      output += position_embeddings

    output = self.output_layer_norm(output)
    output = self.output_dropout(output)

    return output
&lt;/denchmark-code&gt;


Without changes in source code. Weights are incorrect.
Fixes are shown under this point. In this case weights are correct.

&lt;denchmark-code&gt;if self.use_type_embeddings:
      flat_token_type_ids = tf.reshape(token_type_ids, [-1])
      token_type_embeddings = tf.gather(self.type_embeddings, flat_token_type_embeddings)
      token_type_embeddings = tf.reshape(token_type_embeddings,
                                         [batch_size, seq_length, width])
      output += token_type_embeddings
&lt;/denchmark-code&gt;


Use EmbeddingPostprocessor without position_embeddings. In this case weights are correct. Example with full code is in the part "Code to reproduce the issue"

&lt;denchmark-code&gt;outputs = EmbeddingPostprocessor(
    use_type_embeddings=True,
    token_type_vocab_size=2,
    use_position_embeddings=False,
    dtype=tf.float32)(input1, input2)
&lt;/denchmark-code&gt;

Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

from official.nlp.bert_modeling import EmbeddingPostprocessor

size = 100

input1 = tf.keras.layers.Input(shape=(size, size), dtype=tf.float32, name='1')
input2 = tf.keras.layers.Input(shape=(size,), dtype=tf.int32, name='2')
outputs = EmbeddingPostprocessor(
    use_type_embeddings=True,
    token_type_vocab_size=2,
    dtype=tf.float32)(input1, input2)
model = tf.keras.Model(inputs=[input1, input2], outputs=outputs)

example1 = tf.constant(np.random.random_sample(size=(1, size, size)), dtype=tf.float32)
example2 = tf.constant(np.random.randint(2, size=(1, size), dtype=np.int32))
example = {'1': example1, '2': example2}

output1 = model.predict(example)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.reset_all_variables()
interpreter.set_tensor(input_details[0]['index'], example[input_details[0]['name']])
interpreter.set_tensor(input_details[1]['index'], example[input_details[1]['name']])
interpreter.invoke()

output2 = interpreter.get_tensor(output_details[0]['index'])

print(np.sum(np.abs(output1 - output2)))
&lt;/denchmark-code&gt;

Other info / logs

With error:

&lt;denchmark-code&gt;*** INFO MESSAGES ***
691.0672
&lt;/denchmark-code&gt;


Without error:

&lt;denchmark-code&gt;*** INFO MESSAGES ***
0.0021286607
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Vooblin' date='2019-10-23T08:10:56Z'>
		&lt;denchmark-link:https://github.com/Vooblin&gt;@Vooblin&lt;/denchmark-link&gt;
, Since the associated PR has been merged. Can we close this issue.
		</comment>
		<comment id='2' author='Vooblin' date='2019-11-06T11:14:45Z'>
		&lt;denchmark-link:https://github.com/Vooblin&gt;@Vooblin&lt;/denchmark-link&gt;
, Can you please let us know if you are happy to close if no issue persists. Thanks!
		</comment>
		<comment id='3' author='Vooblin' date='2019-11-07T09:59:26Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 Sorry, I missed your last comment and forgot about this issue. Associated PR fixed only code in tensorflow/models. I think that this issue related to problem with tflite converter and PR didn't fix it. So I think that problem wasn't solved but if you think that it's not so important and it doesn't need to be fixed now then I won't mind closing this issue.
		</comment>
		<comment id='4' author='Vooblin' date='2020-12-09T17:23:40Z'>
		&lt;denchmark-link:https://github.com/Vooblin&gt;@Vooblin&lt;/denchmark-link&gt;
,
Is this still an issue? Could you please update TensorFlow to v2.3 and check if you are facing the same issue. Thanks!
		</comment>
		<comment id='5' author='Vooblin' date='2020-12-09T20:23:13Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33613&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33613&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>