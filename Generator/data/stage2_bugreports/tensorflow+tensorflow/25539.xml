<bug id='25539' author='Kwander' open_date='2019-02-06T09:02:18Z' closed_time='2019-03-07T00:44:07Z'>
	<summary>Tensorflow AOT compiled graph does not use GPU</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.12.0 (tensorflow-gpu, tensorflow-base)
Python version: 3.6.8
Bazel version (if compiling from source): 0.21.0
GCC/Compiler version (if compiling from source): 5.4.0 20160609
CUDA/cuDNN version: 7.1.2
GPU model and memory: GeForce GTX 1080, 8GB


Following the &lt;denchmark-link:https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd&gt;https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd&lt;/denchmark-link&gt;
 tutorial, which is based on &lt;denchmark-link:https://www.tensorflow.org/xla/tfcompile&gt;https://www.tensorflow.org/xla/tfcompile&lt;/denchmark-link&gt;
, all the compilation steps succeed. I am also able to invoke the compiled graph, producing correct prediction results. A non-compiled predict of a single image using RestNet50 takes 5ms, a compiled version takes ~140ms.
Note: I have ran ./configure via a terminal to use force CUDA support (such option is not accepted in the example).
Describe the expected behavior
The compiled version prediction of a single image should be as fast as a non-compiled prediction. I suspect the compiled graph uses CPU for the inference.

Follow the &lt;denchmark-link:https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd&gt;https://gist.github.com/carlthome/6ae8a570e21069c60708017e3f96c9fd&lt;/denchmark-link&gt;
 tutorial. To evaluate the compiled and the non-compiled graph prediction of a single image duration, add these two lines to the end of the notebook:
%timeit -n 20 predict(x)
%timeit -n 20 model.predict(x)
	</description>
	<comments>
		<comment id='1' author='Kwander' date='2019-03-01T00:48:19Z'>
		&lt;denchmark-link:https://github.com/Kwander&gt;@Kwander&lt;/denchmark-link&gt;
 Is this related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25548&gt;this&lt;/denchmark-link&gt;
. If it is duplicate, please close this. If it is not duplicate, did you enable/disable XLA here. Thanks!
		</comment>
		<comment id='2' author='Kwander' date='2019-03-01T18:15:30Z'>
		
Tensorflow AOT compiled graph does not use GPU

This behavior is WAI.  AOT compilation only uses the CPU.  If you want to use the GPU, you can't use AOT compilation.
		</comment>
		<comment id='3' author='Kwander' date='2019-03-07T00:44:07Z'>
		I think it was resolved. I am closing this issue. Thanks!
		</comment>
		<comment id='4' author='Kwander' date='2019-04-28T03:46:55Z'>
		

Tensorflow AOT compiled graph does not use GPU

This behavior is WAI. AOT compilation only uses the CPU. If you want to use the GPU, you can't use AOT compilation.

Sorry to bother. I just did something similar to this issue. Since I can't find what WAI is, could you please tell me what it is?
Besides, do you know is there another way to use pure GPU acceleration for compiled DL model since AOT won't use GPU and JIT requires compiling every time the model runs. Just Thank you!
		</comment>
		<comment id='5' author='Kwander' date='2019-04-28T04:33:46Z'>
		WAI = working as intended.

There is no way today to use XLA:GPU without recompiling every time.  It's
not something on our roadmap.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sat, Apr 27, 2019 at 8:52 PM mati1994 ***@***.***&gt; wrote:
 Tensorflow AOT compiled graph does not use GPU

 This behavior is WAI. AOT compilation only uses the CPU. If you want to
 use the GPU, you can't use AOT compilation.

 Sorry to bother. I just did something similar to this issue. Since I can't
 find what WAI is, could you please tell me what it is?
 Besides, do you know is there another way to use pure GPU acceleration for
 compiled DL model since AOT won't use GPU and JIT requires compiling every
 time the model runs. Just Thank you!

 —
 You are receiving this because you commented.
 Reply to this email directly, view it on GitHub
 &lt;#25539 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AABEZBYJT3PGMSW5XAR6AWDPSUNRNANCNFSM4GUTF6UQ&gt;
 .



		</comment>
		<comment id='6' author='Kwander' date='2019-12-26T06:57:34Z'>
		&lt;denchmark-link:https://github.com/jlebar&gt;@jlebar&lt;/denchmark-link&gt;
 Just wonder is there any progress to improve the every recompiling?
		</comment>
		<comment id='7' author='Kwander' date='2019-12-26T14:41:40Z'>
		Hi, happy holidays.

I left the project a few months ago, you'll want to check with sanjoy@.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Dec 26, 2019, 1:57 AM Colin ***@***.***&gt; wrote:
 @jlebar &lt;https://github.com/jlebar&gt; Just wonder is there any progress to
 improve the every recompiling?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#25539?email_source=notifications&amp;email_token=AABEZB6O2JMUBY7AOZOWLR3Q2RIWJA5CNFSM4GUTF6U2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEHVB55Q#issuecomment-568991478&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AABEZB5OI25TJICZTMCTENLQ2RIWJANCNFSM4GUTF6UQ&gt;
 .



		</comment>
	</comments>
</bug>