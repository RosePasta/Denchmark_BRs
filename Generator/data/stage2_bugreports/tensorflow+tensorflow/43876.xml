<bug id='43876' author='gupta35' open_date='2020-10-08T12:14:20Z' closed_time='2020-10-09T17:58:38Z'>
	<summary>OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.</summary>
	<description>
import numpy as np
import os
import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.models as models
import tensorflow.keras.layers as layers
import tensorflow.keras.optimizers as optimizers
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler
from tensorflow.keras import backend
def unet(pretrained_weights = None,input_size = (256,256,1)):
inputs = keras.Input(shape = input_size)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
drop4 = Dropout(0.5)(conv4)
pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
&lt;denchmark-code&gt;conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
drop5 = Dropout(0.5)(conv5)

up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
merge6 = concatenate([drop4,up6], axis = 3)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
merge7 = concatenate([conv3,up7], axis = 3)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
merge8 = concatenate([conv2,up8], axis = 3)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
merge9 = concatenate([conv1,up9], axis = 3)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

model = Model(inputs = inputs, outputs = conv10)

def iou(y_pred, y_true):
    y_pred = tf.cast((y_pred &gt; 0), dtype=tf.float32)
    i = tf.reduce_sum(y_true * y_pred)
    u = tf.reduce_sum(y_true + y_pred)
    return (i / u).item()if u != 0 else u.item()

ssim1 = tf.image.ssim(inputs, conv10, max_val=255, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03)

model.compile(optimizer = Adam(lr = 1e-4), loss = 'ssim1', metrics = ['accuracy',iou])

model.summary()


if(pretrained_weights):
	model.load_weights(pretrained_weights)

return model
&lt;/denchmark-code&gt;

model = unet()
	</description>
	<comments>
		<comment id='1' author='gupta35' date='2020-10-08T12:54:23Z'>
		Can you reformat correctly the code block and very that we can copy, past and directly run your example?
		</comment>
		<comment id='2' author='gupta35' date='2020-10-08T17:08:08Z'>
		import numpy as np
import os
import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.models as models
import tensorflow.keras.layers as layers
import tensorflow.keras.optimizers as optimizers
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler
from tensorflow.keras import backend
		</comment>
		<comment id='3' author='gupta35' date='2020-10-08T17:08:52Z'>
		def unet(pretrained_weights = None,input_size = (256,256,1)):
inputs = keras.Input(shape = input_size)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)
pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)
conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)
pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)
conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)
pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)
conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)
drop4 = Dropout(0.5)(conv4)
pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
&lt;denchmark-code&gt;conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)
conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)
drop5 = Dropout(0.5)(conv5)

up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))
merge6 = concatenate([drop4,up6], axis = 3)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)
conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)

up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))
merge7 = concatenate([conv3,up7], axis = 3)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)
conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)

up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))
merge8 = concatenate([conv2,up8], axis = 3)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)
conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)

up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))
merge9 = concatenate([conv1,up9], axis = 3)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)
conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)
conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)

model = Model(inputs = inputs, outputs = conv10)

def iou(y_pred, y_true):
    y_pred = tf.cast((y_pred &gt; 0), dtype=tf.float32)
    i = tf.reduce_sum(y_true * y_pred)
    u = tf.reduce_sum(y_true + y_pred)
ssim1 = tf.image.ssim(inputs, conv10, max_val=1.0, filter_size=11,filter_sigma=1.5, k1=0.01, k2=0.03)

model.compile(optimizer = Adam(lr = 1e-4), loss = 'ssim1', metrics = ['accuracy',iou])

model.summary()


if(pretrained_weights):
	model.load_weights(pretrained_weights)

return model
&lt;/denchmark-code&gt;

model = unet()
&lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='gupta35' date='2020-10-09T04:13:07Z'>
		&lt;denchmark-link:https://github.com/gupta35&gt;@gupta35&lt;/denchmark-link&gt;

Please, fill &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/new/choose&gt;issue template&lt;/denchmark-link&gt;
.Please, let us know which TF version you are using?
Request you to share colab link or simple standalone code with proper indentation and supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='5' author='gupta35' date='2020-10-09T07:59:16Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

I am running this code in google colab.
		</comment>
		<comment id='6' author='gupta35' date='2020-10-09T08:10:43Z'>
		Can you format correctly your code block or share your colab?
		</comment>
		<comment id='7' author='gupta35' date='2020-10-09T08:13:41Z'>
		&lt;denchmark-link:https://colab.research.google.com/drive/1mhKTeMz0-NqTAXzP3_qyO4pdE-k5E7K4?usp=sharing&gt;https://colab.research.google.com/drive/1mhKTeMz0-NqTAXzP3_qyO4pdE-k5E7K4?usp=sharing&lt;/denchmark-link&gt;

you can excess this code from the above link.
		</comment>
		<comment id='8' author='gupta35' date='2020-10-09T10:46:25Z'>
		&lt;denchmark-link:https://github.com/gupta35&gt;@gupta35&lt;/denchmark-link&gt;

I have tried in colab with TF nightly version() and i am not seeing any issue.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/f9aa6e340ac337f78125f6df8aa670df/untitled438.ipynb&gt;here&lt;/denchmark-link&gt;
.Please, verify once and close the issue.Thanks!
		</comment>
		<comment id='9' author='gupta35' date='2020-10-09T17:58:51Z'>
		not done
		</comment>
	</comments>
</bug>