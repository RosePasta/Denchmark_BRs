<bug id='38116' author='eaaarmah' open_date='2020-04-01T12:32:59Z' closed_time='2020-05-14T02:00:52Z'>
	<summary>Error converting MobileNet and MobileNetV2 to tflite (FusedBatchedNormV3)</summary>
	<description>
System information
Linux Ubuntu 18.04:
Used pip install, conda install
Used 2.0.0 , 2.1.0, tf-nightly 2.2.0-dev20200401
Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
import tensorflow as tf
#import tensorflow_addons as tfa
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import pathlib
from sklearn.utils import class_weight
print(tf.__version__)
print("Eagerly enabled: ", tf.executing_eagerly())

model.load_weights("MobileNet_Model3_with_Reg_6_c.h5") 
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
&lt;/denchmark-code&gt;

The output from the converter invocation
&lt;denchmark-code&gt;ConverterError: See console for info.
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/vectorweb4/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-04-01 07:24:52.175680: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183563: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183617: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183639: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183661: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183680: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183700: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183720: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183739: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183756: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183775: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183795: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183817: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183834: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183853: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183870: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183890: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183907: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183927: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183945: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183965: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.183982: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.184002: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.184021: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.184039: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.184058: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.184077: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: FusedBatchNormV3
2020-04-01 07:24:52.185918: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 118 operators, 397 arrays (0 quantized)
2020-04-01 07:24:52.188931: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 118 operators, 397 arrays (0 quantized)
2020-04-01 07:24:52.201162: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 90 operators, 396 arrays (0 quantized)
2020-04-01 07:24:52.205488: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 89 operators, 395 arrays (0 quantized)
2020-04-01 07:24:52.208850: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 88 operators, 393 arrays (0 quantized)
2020-04-01 07:24:52.212215: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 88 operators, 393 arrays (0 quantized)
2020-04-01 07:24:52.215005: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 88 operators, 393 arrays (0 quantized)
2020-04-01 07:24:52.220046: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 4513344 bytes, theoretical optimal value: 4513344 bytes.
2020-04-01 07:24:52.220849: E tensorflow/lite/toco/toco_tooling.cc:462] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, PAD, RELU6, SOFTMAX. Here is a list of operators for which you will need custom implementations: FusedBatchNormV3.
Traceback (most recent call last):
  File "/home/vectorweb4/.local/bin/toco_from_protos", line 11, in &lt;module&gt;
    sys.exit(main())
  File "/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File "/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File "/home/vectorweb4/.local/lib/python3.6/site-packages/absl/app.py", line 299, in run
    _run_main(main, args)
  File "/home/vectorweb4/.local/lib/python3.6/site-packages/absl/app.py", line 250, in _run_main
    sys.exit(main(argv))
  File "/home/vectorweb4/.local/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, PAD, RELU6, SOFTMAX. Here is a list of operators for which you will need custom implementations: FusedBatchNormV3.

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='eaaarmah' date='2020-04-02T08:57:50Z'>
		&lt;denchmark-link:https://github.com/eaaarmah&gt;@eaaarmah&lt;/denchmark-link&gt;
, Try with these lines of code to convert
&lt;denchmark-code&gt;converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.allow_custom_ops=True
converter.experimental_new_converter =True
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

Let us know how it progresses. Thanks
		</comment>
		<comment id='2' author='eaaarmah' date='2020-04-07T14:55:30Z'>
		The coverter worked.
However when I tried to save it with the code below, I got this error message
&lt;denchmark-code&gt;open("converted_model.tflite", "wb").write(tflite_model)
interpreter = tf.lite.Interpreter(model_path="converted_model.tflite")
interpreter.allocate_tensors()
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;Error message&lt;/denchmark-h&gt;

RuntimeError                              Traceback (most recent call last)
 in 
1 open("converted_model.tflite", "wb").write(tflite_model)
2 interpreter = tf.lite.Interpreter(model_path="converted_model.tflite")
----&gt; 3 interpreter.allocate_tensors()
~/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)
242   def allocate_tensors(self):
243     self._ensure_safe()
--&gt; 244     return self._interpreter.AllocateTensors()
245
246   def _safe_to_run(self):
~/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)
104
105     def AllocateTensors(self):
--&gt; 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
107
108     def Invoke(self):
RuntimeError: Encountered unresolved custom op: FusedBatchNormV3.Node number 2 (FusedBatchNormV3) failed to prepare.
		</comment>
		<comment id='3' author='eaaarmah' date='2020-04-08T17:57:02Z'>
		&lt;denchmark-link:https://github.com/eaaarmah&gt;@eaaarmah&lt;/denchmark-link&gt;
 Can you please share a standalone code to reproduce the issue? Standalone code leads to faster resolution of your issue. Thanks!
		</comment>
		<comment id='4' author='eaaarmah' date='2020-04-09T09:15:48Z'>
		&lt;denchmark-link:https://colab.research.google.com/drive/1Sz2B7Tt4x5qhNFXFJc4nJBnQRcHaWus8&gt;https://colab.research.google.com/drive/1Sz2B7Tt4x5qhNFXFJc4nJBnQRcHaWus8&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.allow_custom_ops=True
converter.experimental_new_converter =True
tflite_model = converter.convert()

open("converted_model.tflite", "wb").write(tflite_model)
interpreter = tf.lite.Interpreter(model_path="converted_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='eaaarmah' date='2020-04-21T04:34:05Z'>
		Hi Team, how's it going with this bug?
		</comment>
		<comment id='6' author='eaaarmah' date='2020-04-25T19:03:36Z'>
		&lt;denchmark-link:https://github.com/eaaarmah&gt;@eaaarmah&lt;/denchmark-link&gt;
 Did you forgot to add  building code? I get this error.

Always try to please share a standalone code that runs and produces the error you are facing. Thanks!
		</comment>
		<comment id='7' author='eaaarmah' date='2020-05-14T02:00:52Z'>
		I am closing this issue as it is a duplicate of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/38113&gt;#38113&lt;/denchmark-link&gt;
. We will follow the issue there. Please feel free to reopen if I am mistaken. Thanks!
		</comment>
		<comment id='8' author='eaaarmah' date='2020-05-14T02:00:53Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38116&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38116&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>