<bug id='30094' author='mahzoon' open_date='2019-06-24T17:22:59Z' closed_time='2020-04-10T04:11:12Z'>
	<summary>Tensorboard callback with histogram_freq=1 crashes after one epoch in non-eager mode</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below):
tf version = 2.0.0-dev20190622
tf git version = v1.12.1-4759-g9856697d8b
Python version: 3.6.4
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior
Calling the Keras fit function in non-eager mode fails after one epoch, if specifying a tensorboard callback which has histogram_freq=1.
Describe the expected behavior
I think the fit function should continue training without crashing.
Code to reproduce the issue
import tensorflow as tf

tf.compat.v1.disable_eager_execution()

# model architecture
inputs = tf.keras.Input(shape=(784,), name='flattened_image')
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(64, activation='relu')(x)
outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)
# creating the model
model = tf.keras.Model(inputs=inputs, outputs=outputs, name='test1')

# loading data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(60000, 784).astype('float32') / 255
x_test = x_test.reshape(10000, 784).astype('float32') / 255

# create the training dataset
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
# shuffle, batch and prefetch for optimizing io reads
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64).prefetch(1024)
# create the validation dataset.
val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
# batch and prefetch for optimizing io reads
val_dataset = val_dataset.batch(64).prefetch(1024)

# compile the model
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='rmsprop',
    metrics=['accuracy'],
)

tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir='./tensorboard_logs/',
    # enabling histogram will crash the learninig in non-eager mode
    histogram_freq=1, # every epoch
    write_images=True, # visualize model weights in image form
    update_freq='batch', # this can be 'epoch' to make training faster (less logs)
)

# fit the model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    callbacks=[tensorboard_callback],
    epochs=2,
    steps_per_epoch=50
)

# the returned "history" object holds a record of the loss values and metric values during training
print('\nhistory dict:', history.history)
Other info / logs
Here is the stack trace...
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0624 13:13:30.813938 140736272085888 deprecation.py:506] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1624: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2019-06-24 13:13:34.039928: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-24 13:13:34.055276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda14c310d0 executing computations on platform Host. Devices:
2019-06-24 13:13:34.055294: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
2019-06-24 13:13:35.799524: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1541] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0624 13:13:43.409096 140736272085888 deprecation.py:323] From /temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Apply a constraint manually following the optimizer update step.
Train on 50 steps, validate on 157 steps
Epoch 1/2
30/50 [=================&gt;............] - ETA: 0s - loss: 1.3660 - accuracy: 0.6500  Traceback (most recent call last):
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py", line 570, in read_variable_op
    "dtype", dtype)
tensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "error_showcase_tb.py", line 50, in &lt;module&gt;
    steps_per_epoch=50
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 669, in fit
    use_multiprocessing=use_multiprocessing)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py", line 669, in fit
    steps_name='steps_per_epoch')
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py", line 444, in model_iteration
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py", line 296, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py", line 1612, in on_epoch_end
    self._log_weights(epoch)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py", line 1691, in _log_weights
    weight = K.get_value(weight)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3016, in get_value
    return x.numpy()
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 580, in numpy
    return self.read_value().numpy()
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 633, in read_value
    value = self._read_variable_op()
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 611, in _read_variable_op
    self._dtype)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py", line 575, in read_variable_op
    resource, dtype=dtype, name=name, ctx=_ctx)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py", line 613, in read_variable_op_eager_fallback
    attrs=_attrs, ctx=_ctx, name=name)
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 71, in quick_execute
    raise e
  File "/temp/v36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py", line 61, in quick_execute
    num_outputs)
TypeError: An op outside of the function building code is being passed
a "Graph" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: dense/kernel:0
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mahzoon' date='2019-07-21T12:21:18Z'>
		Same problem in tf 1.14.0
		</comment>
		<comment id='2' author='mahzoon' date='2019-08-13T19:59:16Z'>
		I'm also having this problem! TensorFlow version 1.14, running on CPU
		</comment>
		<comment id='3' author='mahzoon' date='2019-08-13T22:22:24Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 could you take a look?  I'm not sure how Keras is supposed to behave here in TF 2.0 + non-eager mode.
		</comment>
		<comment id='4' author='mahzoon' date='2019-11-21T23:46:05Z'>
		This issue still exists. Any updates?
		</comment>
		<comment id='5' author='mahzoon' date='2020-01-09T09:20:52Z'>
		Same problem in tf 1.14.0
		</comment>
		<comment id='6' author='mahzoon' date='2020-03-07T08:43:21Z'>
		the same problem in tf2.0.0
		</comment>
		<comment id='7' author='mahzoon' date='2020-03-13T06:56:28Z'>
		Issue is replicating with Tf 2.2.rc0.
Please find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/2b70167d52f21e4247bbbd965997dafe/untitled451.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='8' author='mahzoon' date='2020-03-31T21:33:29Z'>
		&lt;denchmark-link:https://github.com/mahzoon&gt;@mahzoon&lt;/denchmark-link&gt;
 Generally it is not recommended to combine 1.x and 2.x functionality.
In general, if you want to maintain v1 behavior, it's best to use the v1 apis as well: I updated first two lines of your code as follows.
&lt;denchmark-code&gt;#import tensorflow as tf
import tensorflow.compat.v1 as tf

#tf.compat.v1.disable_eager_execution()
&lt;/denchmark-code&gt;

With this change, everything works as expected. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/8c2f3b08d3ff0ff011676e4d0505f283/untitled50.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
Please close the issue if this was resolved for you. Thanks!
		</comment>
		<comment id='9' author='mahzoon' date='2020-04-08T00:30:06Z'>
		&lt;denchmark-link:https://github.com/mahzoon&gt;@mahzoon&lt;/denchmark-link&gt;
 Can you please check my last comment? Thanks!
If this was resolved for you, then please close the issue. Thanks!
		</comment>
		<comment id='10' author='mahzoon' date='2020-04-10T04:11:12Z'>
		&lt;denchmark-link:https://github.com/mahzoon&gt;@mahzoon&lt;/denchmark-link&gt;
 I am closing this as this was resolved in recent . Please feel free to reopen if this was not resolved for you. Thanks!
		</comment>
		<comment id='11' author='mahzoon' date='2020-04-10T04:11:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30094&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30094&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>