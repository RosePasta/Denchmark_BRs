<bug id='24980' author='mawright' open_date='2019-01-17T02:02:36Z' closed_time='2019-08-30T17:48:59Z'>
	<summary>MKL-backed tensorflow throws errors on softmax on empty tensors; GPU and Eigen versions do not</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary from anaconda
TensorFlow version (use command below): 1.12.0
Python version: 3.6.8
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
Calling tf.nn.softmax on a tensor that has a dimension 0 throws an exception at runtime, when Tensorflow is backed by MKL. The same op returns an empty array of suitable size (i.e., the same size as the input tensor) under GPU and Eigen.
Note that this happens no matter which axis the softmax is taken across (the 0-length dim or a nonzero-length one).
Stacktrace:
&lt;denchmark-code&gt;python test.py 
2019-01-16 17:55:50.289518: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-16 17:55:50.294890: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-01-16 17:55:50.303432: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at mkl_softmax_op.cc:167 : Aborted: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:164
Traceback (most recent call last):
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1334, in _do_call
    return fn(*args)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:164
	 [[{{node Softmax}} = _MklSoftmax[T=DT_FLOAT, _kernel="MklOp", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_Placeholder_0_0, DMT/_0)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test.py", line 9, in &lt;module&gt;
    print(sess.run(softmax, {tensor: x}))
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 929, in run
    run_metadata_ptr)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1328, in _do_run
    run_metadata)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.AbortedError: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:164
	 [[node Softmax (defined at test.py:5)  = _MklSoftmax[T=DT_FLOAT, _kernel="MklOp", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_Placeholder_0_0, DMT/_0)]]

Caused by op 'Softmax', defined at:
  File "test.py", line 5, in &lt;module&gt;
    softmax = tf.nn.softmax(tensor)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py", line 1722, in softmax
    return _softmax(logits, gen_nn_ops.softmax, axis, name)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py", line 1673, in _softmax
    return compute_op(logits, name=name)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py", line 7138, in softmax
    "Softmax", logits=logits, name=name)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 488, in new_func
    return func(*args, **kwargs)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 3274, in create_op
    op_def=op_def)
  File "/home/matt/anaconda3/envs/learn/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1770, in __init__
    self._traceback = tf_stack.extract_stack()

AbortedError (see above for traceback): Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:164
	 [[node Softmax (defined at test.py:5)  = _MklSoftmax[T=DT_FLOAT, _kernel="MklOp", _device="/job:localhost/replica:0/task:0/device:CPU:0"](_arg_Placeholder_0_0, DMT/_0)]]
&lt;/denchmark-code&gt;

Describe the expected behavior
tf.nn.softmax on an empty tensor returns an empty tensor on all configurations.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
import tensorflow as tf
import numpy as np

tensor = tf.placeholder(tf.float32, [10, None])
softmax = tf.nn.softmax(tensor)
x = np.random.randn(10, 0)

with tf.Session() as sess:
    print(sess.run(softmax, {tensor: x}))

This may be related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/23145&gt;#23145&lt;/denchmark-link&gt;
 which has a similar error message but seems to be caused by a different situation.
	</description>
	<comments>
		<comment id='1' author='mawright' date='2019-01-18T19:09:29Z'>
		&lt;denchmark-link:https://github.com/azaks2&gt;@azaks2&lt;/denchmark-link&gt;
 who should look at this?
		</comment>
		<comment id='2' author='mawright' date='2019-03-17T19:13:33Z'>
		I have the same issue with Tensorflow softmax.
I use macOS 10.14, python 3.6 with Conda installed Tensorflow.
"
File "/Users/lvhw/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1348, in _do_call
raise type(e)(node_def, op, message)
AbortedError: Operation received an exception:Status: 3, message: could not initialize a memory descriptor, in file tensorflow/core/kernels/mkl_softmax_op.cc:164
[[node Softmax (defined at /Users/lvhw/Desktop/CRF-image-segmentation-master/CRFCNNImageSegmentation.py:171)  = _MklSoftmax[T=DT_FLOAT, _kernel="MklOp", _device="/job:localhost/replica:0/task:0/device:CPU:0"](conv2d_transpose, conv2d_transpose:1)]]
Caused by op 'Softmax', defined at:
File "/Users/lvhw/anaconda3/lib/python3.6/runpy.py", line 193, in _run_module_as_main
"main", mod_spec)
File "/Users/lvhw/anaconda3/lib/python3.6/runpy.py", line 85, in _run_code
exec(code, run_globals)
File "/Users/lvhw/anaconda3/lib/python3.6/site-packages/spyder_kernels/console/main.py", line 11, in 
start.main()
"
		</comment>
		<comment id='3' author='mawright' date='2019-03-18T05:36:38Z'>
		&lt;denchmark-link:https://github.com/agramesh1&gt;@agramesh1&lt;/denchmark-link&gt;
  - Can you take a look at this?
		</comment>
		<comment id='4' author='mawright' date='2019-03-18T17:27:03Z'>
		&lt;denchmark-link:https://github.com/tatianashp&gt;@tatianashp&lt;/denchmark-link&gt;
  thanks.  Pinging &lt;denchmark-link:https://github.com/TensorFlow-MKL&gt;@TensorFlow-MKL&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='mawright' date='2019-03-19T07:17:41Z'>
		Would you please upgrade your tensorflow to the latest version (ver 1.13.1)? It seems to be fixed in this release.
$ pip install --upgrade intel-tensorflow
$ python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
b'v1.13.1-0-g6612da8' 1.13.1
$ python test.py
2019-03-19 16:15:55.541077: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-03-19 16:15:55.574388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2500000000 Hz
2019-03-19 16:15:55.585260: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2f945c0 executing computations on platform Host. Devices:
2019-03-19 16:15:55.585295: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): , 
2019-03-19 16:15:55.595114: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-03-19 16:15:55.630654: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr
2019-03-19 16:15:55.630703: E tensorflow/core/common_runtime/bfc_allocator.cc:373] tried to deallocate nullptr
[]
test.py is the reproducible test case.
Please let me know if this does not work on your side.
		</comment>
		<comment id='6' author='mawright' date='2019-08-23T22:24:05Z'>
		please close this issue if you have this solution working
		</comment>
		<comment id='7' author='mawright' date='2019-08-30T17:48:59Z'>
		workaround suggested. Closing this issue. Please reopen this issue if the solution provided doesn't solve the issue
		</comment>
		<comment id='8' author='mawright' date='2019-08-30T17:49:00Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=24980&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=24980&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>