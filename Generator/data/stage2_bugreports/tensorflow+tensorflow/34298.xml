<bug id='34298' author='Stick-To' open_date='2019-11-15T02:35:57Z' closed_time='2019-12-03T07:27:38Z'>
	<summary>could not restore weights to model with same structure  when enable_eager</summary>
	<description>
Sytem: ubuntu18.04
TF version: 2.0
Hardware: gtx1080ti and gt 840m
CUDA: 10.0
CUDNN: 7.6
&lt;denchmark-code&gt;class RetinaNet(tf.keras.Model):
    def __init__(self, config):
        super(RetinaNet, self).__init__()
        self.config = config
        self.num_classes = config['num_classes']
        self.weight_decay = config['weight_decay']
        self.mode = config['mode']
        self.batch_size = config['batch_size'] if config['mode'] == 'train' else 1
        self.lr = config['lr']

        image = tf.keras.Input(shape=[None, None, 3], batch_size=self.batch_size, dtype=tf.float32)
        self.backone = backone.model[config['backone']](
            image, config['backone_conv_trainable'], config['backone_bn_trainable'],
            weight=backone.weight[config['backone']]
        )
        self.opt = tf.keras.optimizers.SGD(self.lr, momentum=0.9)

        if config['mode'] == 'train':
            gt = tf.keras.Input(shape=[None, 5], batch_size=self.batch_size, dtype=tf.float32)
            self.model = self._build_graph(image, gt)
        else:
            self.model = self._build_graph(image)

    def _build_graph(self, image, gt=None):
        num_fpn_layers = 5
        fpn_channels = 256
        endpoints = self.backone(image)
        fpn = fpn_generator(endpoints[1:], fpn_channels, num_fpn_layers, mode='dconv')
        p3, p4, p5, p6, p7 = fpn
        dw_rate = [8., 16., 32., 64., 128.]
        anchors = [
            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],

            [[4, 4], [4. * 2., 4. / 2.], [4. / 2., 4. * 2.], [4. * 3, 4. / 3.], [4. / 3., 4. * 3.]],
        ]
        anchors_all = anchor_generator(
            fpn, anchors, dw_rate, flatten=True
        )
        anchors_all = tf.concat(anchors_all, axis=0)
        self.cla_head = self._cla_head(fpn_channels, 5)
        self.reg_head = self._reg_head(fpn_channels, 5)
        p3c = self.cla_head(p3)
        p3r = self.reg_head(p3)
        p4c = self.cla_head(p4)
        p4r = self.reg_head(p4)
        p5c = self.cla_head(p5)
        p5r = self.reg_head(p5)
        p6c = self.cla_head(p6)
        p6r = self.reg_head(p6)
        p7c = self.cla_head(p7)
        p7r = self.reg_head(p7)
        pc = tf.concat([p3c, p4c, p5c, p6c, p7c], axis=1)
        pr = tf.concat([p3r, p4r, p5r, p6r, p7r], axis=1)
        pc = tf.nn.sigmoid(pc)
        if self.mode == 'train':
            i = 0
            loss = tf.constant([0., 0.], dtype=tf.float32, shape=[1, 2])
            cond = lambda loss, i: tf.less(i, self.batch_size)
            body = lambda loss, i: (
                tf.add(loss, self._compute_one_image_loss(
                    tf.gather(gt, i),
                    anchors_all,
                    tf.gather(pc, i),
                    tf.gather(pr, i))
                       ),
                tf.add(i, 1)
            )
            loss, _ = tf.while_loop(cond, body, (loss, i))
            loss /= self.batch_size
            return tf.keras.Model(inputs=[image, gt], outputs=loss, name='retinanet')
        else:
            nms_score_threshold = 0.5
            nms_max_boxes = 100
            nms_iou_threshold = 0.45
            pr = pr[0, ...]
            confidence = pc[0, ...]
            y1x1y2x2 = bbox_decode(anchors_all, pr, normlization=[10., 10., 5., 5.])
            filter_mask = tf.greater_equal(confidence, nms_score_threshold)
            scores = []
            class_id = []
            bbox = []
            for i in range(self.num_classes):
                scoresi = tf.boolean_mask(confidence[:, i], filter_mask[:, i])
                bboxi = tf.boolean_mask(y1x1y2x2, filter_mask[:, i])
                selected_indices = tf.image.non_max_suppression(
                    bboxi, scoresi, nms_max_boxes, nms_iou_threshold,
                )
                scores.append(tf.gather(scoresi, selected_indices))
                bbox.append(tf.gather(bboxi, selected_indices))
                class_id.append(tf.ones_like(tf.gather(scoresi, selected_indices), tf.int32) * i)
            bbox = tf.concat(bbox, axis=0)
            scores = tf.concat(scores, axis=0)
            class_id = tf.concat(class_id, axis=0) + 1
            detection_pred = [scores, bbox, class_id]
            return tf.keras.Model(inputs=image, outputs=detection_pred, name='retinanet')

    def _compute_one_image_loss(self, gt, anchors, pc, pr):
        slice_index = tf.argmin(gt, axis=0)[0]
        gt = tf.gather(gt, tf.range(0, slice_index, dtype=tf.int64))
        gt_bbox = gt[:, 0:4]
        label = tf.cast(gt[..., 4:5], dtype=tf.int32) - 1
        pos_threshold = 0.5
        neg_threshold = 0.4
        gaiou = bbox_iou(gt_bbox, anchors)
        pos_pc, pos_label, pos_pr, pos_gt_bbox, pos_a, neg_pc = partition_pos_neg_samples(
            gt_bbox, label, gaiou, pc, pr, anchors, pos_threshold, neg_threshold
        )
        pos_gr = bbox_encode(pos_gt_bbox, pos_a, normlization=[10., 10, 5., 5.])
        reg_loss = tf.reduce_sum(smooth_l1_loss(pos_pr-pos_gr))
        pos_label = tf.one_hot(pos_label, self.num_classes, dtype=tf.float32)
        cla_loss = focal_loss(pos_pc, pos_label, neg_pc, alpha=0.25, gamma=2.)
        reg_loss = tf.reshape(reg_loss, [1, 1])
        cla_loss = tf.reshape(cla_loss, [1, 1])
        loss = tf.concat([cla_loss, reg_loss], axis=-1)
        return loss

    def _cla_head(self, input_channels, anchors):
        x = tf.keras.Input(shape=[None, None, input_channels], dtype=tf.float32)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(x)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        pred = layers.Conv2D(self.num_classes * anchors, 3, 1, 'same', kernel_initializer='he_normal',
                             bias_initializer=tf.constant_initializer(-4.595))(relu)
        pred = tf.reshape(pred, [self.batch_size, -1, self.num_classes])
        return tf.keras.Model(inputs=x, outputs=pred, name='cla_head')

    def _reg_head(self, input_channels, anchors):
        x = tf.keras.Input(shape=[None, None, input_channels], dtype=tf.float32)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(x)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        conv = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        bn = layers.BatchNormalization(3, epsilon=1.001e-5)(conv)
        relu = layers.Activation('relu')(bn)
        pred = layers.Conv2D(4 * anchors, 3, 1, 'same', kernel_initializer='he_normal')(relu)
        pred = tf.reshape(pred, [self.batch_size, -1, 4])
        return tf.keras.Model(inputs=x, outputs=pred, name='reg_head')

    def save_weights(self, filepath, overwrite=True, save_format=None):
        self.model.save_weights(filepath, overwrite, save_format)

    def load_weights(self, filepath, by_name=False):
        self.model.load_weights(filepath, by_name)
&lt;/denchmark-code&gt;

the save weights code is
&lt;denchmark-code&gt;config = {
    'num_classes': 20,
    'batch_size':batch_size,
    'mode': 'train',
    'lr': lr,
    'weight_decay':1e-4,
    'backone': 'resnetv1_18',
    'backone_conv_trainable': True,
    'backone_bn_trainable': True,
}
ssd = RetinaNet(config)
ssd.save_weights('saved_weights/1.tf')
&lt;/denchmark-code&gt;

the load weights code is
&lt;denchmark-code&gt;config = {
    'num_classes': 20,
    'batch_size':batch_size,
    'mode': 'test',
    'lr': lr,
    'weight_decay':1e-4,
    'backone': 'resnetv1_18',
    'backone_conv_trainable': True,
    'backone_bn_trainable': True,
}
ssd = RetinaNet(config)
ssd.load_weights('saved_weights/1.tf')
&lt;/denchmark-code&gt;

&lt;denchmark-h:h2&gt;When enable_eager&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;the weights saved under mode=='train' could not  be restored into model when mode=='test'&lt;/denchmark-h&gt;

The error message is as follows:
&lt;denchmark-code&gt;WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.engine.training.Model object at 0x7fa25076a3d0&gt; and &lt;tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fa240170810&gt;).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.engine.training.Model object at 0x7fa270103250&gt; and &lt;tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7fa1f35aced0&gt;).
Traceback (most recent call last):
  File "/home/master/workspace/objdect/test1.py", line 23, in &lt;module&gt;
    ssd.load_weights('saved_weights/1.tf')
  File "/home/master/workspace/objdect/RetinaNet.py", line 170, in load_weights
    self.model.load_weights(filepath, by_name)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py", line 181, in load_weights
    return super(Model, self).load_weights(filepath, by_name)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py", line 1149, in load_weights
    status = self._trackable_saver.restore(filepath)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", line 1270, in restore
    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py", line 209, in restore
    restore_ops = trackable._restore_from_checkpoint_position(self)  # pylint: disable=protected-access
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py", line 908, in _restore_from_checkpoint_position
    tensor_saveables, python_saveables))
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py", line 289, in restore_saveables
    validated_saveables).restore(self.save_path_tensor)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py", line 255, in restore
    restore_ops.update(saver.restore(file_prefix))
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py", line 102, in restore
    restored_tensors, restored_shapes=None)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py", line 115, in restore
    self.handle_op, self._var_shape, restored_tensor)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py", line 291, in shape_safe_assign_variable_handle
    shape.assert_is_compatible_with(value_tensor.shape)
  File "/home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py", line 1115, in assert_is_compatible_with
    raise ValueError("Shapes %s and %s are incompatible" % (self, other))
ValueError: Shapes (20,) and (100,) are incompatible
&lt;/denchmark-code&gt;

the Shapes(20,) is the shape of reg_head, the Shapes(100,) is the shape of cla_head
Maybe the loading order is out of order
&lt;denchmark-h:h2&gt;When disable_eager&lt;/denchmark-h&gt;

&lt;denchmark-h:h2&gt;the weights saved under mode=='train' could  be restored into model when mode=='test' with some Warnings:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;WARNING:tensorflow:From /home/master/app/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.engine.training.Model object at 0x7f26680ae5d0&gt; and &lt;tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f26408af190&gt;).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.

Two checkpoint references resolved to different objects (&lt;tensorflow.python.keras.engine.training.Model object at 0x7f266830fdd0&gt; and &lt;tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer object at 0x7f26402047d0&gt;).

&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Stick-To' date='2019-11-18T11:03:28Z'>
		&lt;denchmark-link:https://github.com/Stick-To&gt;@Stick-To&lt;/denchmark-link&gt;
,
Tried reproducing your issue but encountered the error, , after giving some dummy values to  and . Please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/47956cd5c8b7742f2e313efc116a7fdc/34298.ipynb&gt;Gist&lt;/denchmark-link&gt;
. Can you please help me to reproduce the error. Thanks!
		</comment>
		<comment id='2' author='Stick-To' date='2019-11-18T11:58:53Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
    It's done
		</comment>
		<comment id='3' author='Stick-To' date='2019-11-18T11:59:50Z'>
		when I combine _cla_head and _reg_head as this, the code could run well
&lt;denchmark-code&gt;def _head(self, input_channels, anchors):
    x = tf.keras.Input(shape=[None, None, input_channels], dtype=tf.float32)
    conv1 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='cla_conv1')(x)
    bn1 = layers.BatchNormalization(3, epsilon=1.001e-5, name='cla_bn1')(conv1)
    relu1 = layers.Activation('relu', name='cla_relu1')(bn1)
    conv1 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='cla_conv2')(relu1)
    bn1 = layers.BatchNormalization(3, epsilon=1.001e-5, name='cla_bn2')(conv1)
    relu1 = layers.Activation('relu', name='cla_relu2')(bn1)
    conv1 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='cla_conv3')(relu1)
    bn1 = layers.BatchNormalization(3, epsilon=1.001e-5, name='cla_bn3')(conv1)
    relu1 = layers.Activation('relu', name='cla_relu3')(bn1)
    cla_pred = layers.Conv2D(self.num_classes * anchors, 3, 1, 'same', kernel_initializer='he_normal',
                          name='cla_conv4', bias_initializer=tf.constant_initializer(-4.595))(relu1)
    cla_pred = tf.reshape(cla_pred, [self.batch_size, -1, self.num_classes])

    conv2 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='reg_conv1')(x)
    bn2 = layers.BatchNormalization(3, epsilon=1.001e-5, name='reg_bn1')(conv2)
    relu2 = layers.Activation('relu', name='reg_relu1')(bn2)
    conv2 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='reg_conv2')(relu2)
    bn2 = layers.BatchNormalization(3, epsilon=1.001e-5, name='reg_bn2')(conv2)
    relu2 = layers.Activation('relu', name='reg_relu2')(bn2)
    conv2 = layers.Conv2D(256, 3, 1, 'same', kernel_initializer='he_normal', name='reg_conv3')(relu2)
    bn2 = layers.BatchNormalization(3, epsilon=1.001e-5, name='reg_bn3')(conv2)
    relu2 = layers.Activation('relu', name='reg_relu3')(bn2)
    reg_pred = layers.Conv2D(4 * anchors, 3, 1, 'same', kernel_initializer='he_normal', name='reg_conv4')(relu2)
    reg_pred = tf.reshape(reg_pred, [self.batch_size, -1, 4])
    return tf.keras.Model(inputs=x, outputs=[cla_pred, reg_pred])
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='Stick-To' date='2019-11-18T12:04:35Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://colab.research.google.com/gist/Stick-To/e745c258bfa65bdda2d95844e1ce3f76/34298.ipynb&gt;https://colab.research.google.com/gist/Stick-To/e745c258bfa65bdda2d95844e1ce3f76/34298.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='Stick-To' date='2019-11-19T05:13:03Z'>
		Could reproduce the error with TF Version 2.0. Here is the &lt;denchmark-link:https://colab.research.google.com/gist/Stick-To/e745c258bfa65bdda2d95844e1ce3f76/34298.ipynb&gt;Gist&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='Stick-To' date='2019-11-19T07:20:41Z'>
		&lt;denchmark-link:https://github.com/rmothukuru&gt;@rmothukuru&lt;/denchmark-link&gt;
  the reconstruction of it is done, isn't it?
&lt;denchmark-link:https://colab.research.google.com/gist/Stick-To/e745c258bfa65bdda2d95844e1ce3f76/34298.ipynb&gt;https://colab.research.google.com/gist/Stick-To/e745c258bfa65bdda2d95844e1ce3f76/34298.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Stick-To' date='2019-11-19T08:35:30Z'>
		&lt;denchmark-link:https://github.com/Stick-To&gt;@Stick-To&lt;/denchmark-link&gt;
,
Yes, it is done and I have forwarded it to another Engineer. Thanks!
		</comment>
		<comment id='8' author='Stick-To' date='2019-12-03T07:27:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34298&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34298&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='9' author='Stick-To' date='2020-03-31T11:31:09Z'>
		I know this issue has been closed, but I've also been struggling with this. Has this been resolved, or if not, any where I can follow progress?
		</comment>
		<comment id='10' author='Stick-To' date='2020-03-31T14:28:57Z'>
		&lt;denchmark-link:https://github.com/stefanobranco&gt;@stefanobranco&lt;/denchmark-link&gt;
 Please create a new issue with details and a simple standalone code to reproduce the issue. Thanks!
		</comment>
	</comments>
</bug>