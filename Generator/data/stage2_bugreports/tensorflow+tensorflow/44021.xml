<bug id='44021' author='hugoych' open_date='2020-10-14T16:34:34Z' closed_time='2020-12-18T01:50:07Z'>
	<summary>Different output for custom tf.keras.Model within tf.function</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
TensorFlow installed from (source or binary): Colab Pre-Installed
TensorFlow version (use command below): 2.3.0
Python version: 3.6.9
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
I'm trying to obtain reproducible results between graph and eager execution. While doing that I observed that calling my tf.keras.Model within a tf.function wouldn't exactly give me the same results as in eager execution. I was wondering if that's expected ? If yes, what's the reason for it ?
Describe the expected behavior
I would expect to get exactly the same value.

Here is a Colab : &lt;denchmark-link:https://colab.research.google.com/drive/1n4p-Iq_g7dT-Vv5cb-s6nyeqjuYjyyGL?usp=sharing&gt;https://colab.research.google.com/drive/1n4p-Iq_g7dT-Vv5cb-s6nyeqjuYjyyGL?usp=sharing&lt;/denchmark-link&gt;

Other info / logs
	</description>
	<comments>
		<comment id='1' author='hugoych' date='2020-10-15T19:22:50Z'>
		I ran the code shared, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/77a8239694426f5c721cf17da53f4727/untitled435.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='hugoych' date='2020-10-26T16:29:14Z'>
		Hey,
Do you have any update on the matter &lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 ?
Thanks in advance!
		</comment>
		<comment id='3' author='hugoych' date='2020-11-02T16:54:32Z'>
		When I set training=True the issue goes away. When training=Falseabout 90% of the values are the same between graph mode and eager mode.
&lt;denchmark-code&gt;np.isclose(encoder(inputs, False).numpy(), graph_call(inputs, False).numpy()).astype(np.int).mean()
=&gt; 0.903798828125
&lt;/denchmark-code&gt;

I wouldn't be surprised if this is the expected behavior.
		</comment>
		<comment id='4' author='hugoych' date='2020-11-05T18:39:25Z'>
		Hi there,
The output in eager and graph appears to be the same -- the issue is with the code you use to check the difference. Run the following to demonstrate that the outputs are identical:
&lt;denchmark-code&gt;a = encoder(inputs, False)
b = graph_call(inputs, False)
print(a)
print(b)
print(tf.reduce_max(a - b))  # prints 0
&lt;/denchmark-code&gt;


When I set training=True the issue goes away

You are using SyncBatchNormalization in your model, which would introduce potential differences in training mode (hence triggering your check).
		</comment>
		<comment id='5' author='hugoych' date='2020-11-06T13:42:27Z'>
		
Hi there,
The output in eager and graph appears to be the same -- the issue is with the code you use to check the difference. Run the following to demonstrate that the outputs are identical:
a = encoder(inputs, False)
b = graph_call(inputs, False)
print(a)
print(b)
print(tf.reduce_max(a - b))  # prints 0


When I set training=True the issue goes away

You are using SyncBatchNormalization in your model, which would introduce potential differences in training mode (hence triggering your check).

Hi,
Thanks for the answer! I'm sorry I had changed the colab without noticing while doing more tests. My issue was when training=True.
You are right, this difference only occurs when using tf.keras.layers.experimental.SyncBatchNormalization.
Do you have a idea why it is the case ? Especially here, we aren't using any distribution strategy so the layer should behave as a tf.keras.layers.BatchNormalization no ? The tensorflow documentation says "Without tf.distribute strategy, this layer behaves as a regular tf.keras.layers.BatchNormalization layer."
I modified the colab to highlight what I'm stating here.
		</comment>
		<comment id='6' author='hugoych' date='2020-12-04T01:29:47Z'>
		&lt;denchmark-link:https://github.com/hugoych&gt;@hugoych&lt;/denchmark-link&gt;
 Difference in the results from eager and graph mode is very very low. I tried with the following tolerance levels and are close upto 6th decimal. Please check the &lt;denchmark-link:https://colab.research.google.com/gist/jvishnuvardhan/64f870eb338876c070b621fcaed8c978/issue_tf_function.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
&lt;denchmark-code&gt;tf.experimental.numpy.allclose(
    eager_true_s, graph_true_s, rtol=1e-06, atol=1e-06)

# ndarray&lt;&lt;tf.Tensor: shape=(), dtype=bool, numpy=True&gt;&gt;
&lt;/denchmark-code&gt;

Please close the issue if this was resolved for you. thanks!
		</comment>
		<comment id='7' author='hugoych' date='2020-12-11T02:27:52Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='8' author='hugoych' date='2020-12-18T01:50:08Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44021&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44021&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>