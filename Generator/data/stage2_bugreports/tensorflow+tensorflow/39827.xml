<bug id='39827' author='dimitreOliveira' open_date='2020-05-23T23:18:06Z' closed_time='2020-07-10T19:12:20Z'>
	<summary>InvalidArgumentError while using GRU layer in custom training loop</summary>
	<description>
System information

TensorFlow version 2.1.0
Python version: 3
GPU model and memory: NVIDIA Tesla P100
CUDA Version: 10.1
Environment: This happens both on Kaggle and Colab

Describe the current behavior
I'm trying to train a Hugging face transformer model (roBERTa base) with a custom training loop, and got the error below:
&lt;denchmark-code&gt;InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24
	 [[{{node while/body/_1/StatefulPartitionedCall}}]]
  (1) Invalid argument:  InstantiateOptions.input_devices must have the same length as the number of arguments: input_devices length = 23 number of arguments = 24
	 [[{{node while/body/_1/StatefulPartitionedCall}}]]
	 [[while/body/_1/Adam/Cast_6/ReadVariableOp/_30]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_step_35635]

Function call stack:
train_step -&gt; train_step
&lt;/denchmark-code&gt;

The thing is I can run the same model using model.fit() API, and this error only happens when I use a LSTM or GRU layer on top of the transformer
Describe the expected behavior
Training should go normal
	</description>
	<comments>
		<comment id='1' author='dimitreOliveira' date='2020-05-25T17:57:09Z'>
		&lt;denchmark-link:https://github.com/dimitreOliveira&gt;@dimitreOliveira&lt;/denchmark-link&gt;

Can you please share a simple stand alone code for us to replicate the issue faced or if possible please share colab gist with the error
		</comment>
		<comment id='2' author='dimitreOliveira' date='2020-06-01T18:10:51Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='dimitreOliveira' date='2020-06-03T01:09:47Z'>
		Hi &lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
  , this is the model architecture, I don't have a colab gist or a stand-alone coded, but I can provid some of the code I have used.
&lt;denchmark-code&gt;module_config = RobertaConfig.from_pretrained(config['config_path'], output_hidden_states=False)

def model_fn(MAX_LEN):
    input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')
    attention_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')
    
    base_model = TFRobertaModel.from_pretrained(config['base_model_path'], config=module_config, name="base_model")
    last_hidden_state, _ = base_model({'input_ids': input_ids, 'attention_mask': attention_mask})
    
    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(last_hidden_state)
    x = layers.Dropout(.1)(x)
    
    x_start = layers.TimeDistributed(layers.Dense(1))(x)
    x_start = layers.Flatten()(x_start)
    y_start = layers.Activation('softmax', name='y_start')(x_start)
    
    x_end = layers.TimeDistributed(layers.Dense(1))(x)
    x_end = layers.Flatten()(x_end)
    y_end = layers.Activation('softmax', name='y_end')(x_end)

    model = Model(inputs=[input_ids, attention_mask], outputs=[y_start, y_end])
    
    return model
&lt;/denchmark-code&gt;

And I was using it for a QA problem, so I also did:
&lt;denchmark-code&gt;model.compile(optimizer, loss={'y_start': losses.CategoricalCrossentropy(),
                                   'y_end': losses.CategoricalCrossentropy()})
&lt;/denchmark-code&gt;

The tricky part is that is jsut happens inside a custom training loop. Here are some of the code I have used.
&lt;denchmark-code&gt;# Step functions
    @tf.function
    def train_step(data_iter):
        def train_step_fn(x, y):
            with tf.GradientTape() as tape:
                probabilities = model(x, training=True)
                loss_start = loss_fn_start(y['y_start'], probabilities[0])
                loss_end = loss_fn_end(y['y_end'], probabilities[1])
                loss = tf.math.add(loss_start, loss_end)
            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))
            # update metrics
            train_acc_start.update_state(y['y_start'], probabilities)
            train_acc_end.update_state(y['y_end'], probabilities)
            train_loss.update_state(loss)
            train_loss_start.update_state(loss_start)
            train_loss_end.update_state(loss_end)
        for _ in tf.range(step_size):
            strategy.experimental_run_v2(train_step_fn, next(data_iter))

loss_fn_start = losses.categorical_crossentropy
loss_fn_end = losses.categorical_crossentropy

train_acc_start = metrics.CategoricalAccuracy()
train_acc_end = metrics.CategoricalAccuracy()
train_loss = metrics.Sum()
train_loss_start = metrics.Sum()
train_loss_end = metrics.Sum()
&lt;/denchmark-code&gt;

Let me know if you need any more information.
		</comment>
		<comment id='4' author='dimitreOliveira' date='2020-06-03T11:06:32Z'>
		&lt;denchmark-link:https://github.com/dimitreOliveira&gt;@dimitreOliveira&lt;/denchmark-link&gt;

Please share code such that i can replicate the issue faced, i ran the code shared and face a different error.
please find the &lt;denchmark-link:https://colab.sandbox.google.com/gist/Saduf2019/1496558d57374d9b904a394bc1eb9309/untitled217.ipynb&gt;gist here&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='dimitreOliveira' date='2020-07-01T14:38:41Z'>
		&lt;denchmark-link:https://github.com/dimitreOliveira&gt;@dimitreOliveira&lt;/denchmark-link&gt;

Please update on the above comment.
		</comment>
		<comment id='6' author='dimitreOliveira' date='2020-07-08T15:19:39Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='7' author='dimitreOliveira' date='2020-07-10T19:11:35Z'>
		Closing this issue as it cant be reproduced as the code cannot be provided by the user and has been inactive for more than 4 weeks. Please add additional comments for us to open this issue again.
		</comment>
		<comment id='8' author='dimitreOliveira' date='2020-07-10T19:12:22Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39827&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39827&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>