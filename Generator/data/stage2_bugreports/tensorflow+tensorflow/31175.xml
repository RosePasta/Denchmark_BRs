<bug id='31175' author='MartinNowak' open_date='2019-07-30T23:37:58Z' closed_time='2019-08-15T09:31:00Z'>
	<summary>TF2.0 - memory leak caused by autograph retracing due to bound method argument</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 30
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v2.0.0-beta0-16-g1d91213fe7 2.0.0-beta1
Python version: 3.5.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
Factoring out a train step function into our custom model lead to a memory leak due to continuously retracing the full autograph epoch dataset loop.
The root cause was that bound instance methods are not identical model.step is not model.step.
Describe the expected behavior
According to Issue 36175: Identity of bound methods - Python tracker this is supposed to be expected behavior in Python.
I merely want to clarify the autograph behaviour and document this for other tensorflow users.
I guess there might be reasons to use identity (is) comparison on arguments when deciding whether an autograph needs retracing, but if it were possible to use equality comparison (== ) for arguments that are methods this surprising behaviour could be avoided.
Code to reproduce the issue
import tensorflow as tf

@tf.function
def run_epoch(dataset, step):
    print('retrace')
    for X in dataset:
        step(X)

class Model:
    def step(self, X):
        return X * 2

dataset = tf.data.Dataset.from_tensor_slices(list(range(128)))
model = Model()

for i in range(20):
    # leads to retrace of run_epoch due to non-identity model.step
    # (i.e. `model.step is not model.step`)
    run_epoch(dataset, model.step)
Other info / logs
Possible workarounds:

store the bound method in a variable and thus keep using the same instance
step_fn = model.step
declare the method as @staticmethod and pass the model instance explicitly as first parameter

	</description>
	<comments>
		<comment id='1' author='MartinNowak' date='2019-07-31T08:17:35Z'>
		I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Please, find the &lt;denchmark-link:https://colab.research.google.com/drive/1KpbCu6lgchU1A_zWcYc62m6Mxkpopz4l&gt;gist&lt;/denchmark-link&gt;
 here.Thanks!
		</comment>
		<comment id='2' author='MartinNowak' date='2019-07-31T13:49:35Z'>
		&lt;denchmark-link:https://github.com/kkimdev&gt;@kkimdev&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 FYI
This is a surprising and subtle behavior. I believe the proper fix would be to be resilient to this case, by comparing functions using the equality operator == instead of is:
&lt;denchmark-code&gt;&gt;&gt;&gt; model.step is model.step
False
&gt;&gt;&gt; model.step == model.step
True
&lt;/denchmark-code&gt;

In the mean time, another workaround I would recommend is to use the model object as argument, instead of methods:
&lt;denchmark-code&gt;for i in range(20):
    # passing the entire `model` avoids the retrace.
    run_epoch(dataset, model)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='MartinNowak' date='2019-07-31T15:51:24Z'>
		I concur that the best workaround is to just pass the model. I don't think relying on equality comparison instead of identity comparison for functions is ideal since equality comparison is more expensive and this would create a harder-to-understand mental model.
		</comment>
		<comment id='4' author='MartinNowak' date='2019-08-02T09:05:22Z'>
		
I concur that the best workaround is to just pass the model.

Well, our actual model has a train and eval step functions, and this refactoring was the result of reusing the same code for metrics computation. Passing both the model and a @staticmethod function is indeed the chosen workaround.
The performance argument seems mood, how would argument comparison play a measurable role w.r.t. executing an autograph function.
import timeit, types, tensorflow as tf

class Model:
  def step(self):
    pass

m = Model()
timeit.timeit('m.step is m.step', number=1_000_000, globals={'m': m})
timeit.timeit('m.step == m.step', number=1_000_000, globals={'m': m})
# still fairly fast
timeit.timeit('var == var if type(var) == types.MethodType else var is var', number=1_000_000, globals={'var': m.step, 'types': types})

@tf.function
def graph(model):
  pass

timeit.timeit('graph(m)', number=1_000, globals={'graph': graph, 'm': m})
But as mentioned I'm not positive that working around this specific Python detail in TF would be worthwhile, merely wanted to document it.
		</comment>
		<comment id='5' author='MartinNowak' date='2019-08-15T09:31:01Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=31175&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=31175&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>