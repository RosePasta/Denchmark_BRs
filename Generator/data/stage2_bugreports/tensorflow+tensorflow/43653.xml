<bug id='43653' author='Doekeb' open_date='2020-09-29T19:11:26Z' closed_time='2020-10-03T01:42:31Z'>
	<summary>tensorflow.keras.backend.dot does not work as expected when second argument is 3-dimensional or higher</summary>
	<description>
&lt;denchmark-h:h1&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes (but reproducing this bug requires very minimal code)


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Manjaro Linux (rolling release)


TensorFlow installed from (source or binary):

binary


TensorFlow version (use command below):

git version: v2.3.0-rc2-23-gb36436b087 (2.3.0)


Python version:

python 3.8



&lt;denchmark-h:h1&gt;Describe the current behavior&lt;/denchmark-h&gt;

tensorflow.keras.backend.dot does not compute dot product along expected axes. It computes dot product along the last axis of the first argument and along the next-to-last axis of the second argument.
&lt;denchmark-h:h1&gt;Describe the expected behavior&lt;/denchmark-h&gt;

I expect dot product to be computed along the last axis of the first argument and the first axes of the second argument. (Note that this only differs from the current behavior if the second argument is 3-dimensional or higher.)
&lt;denchmark-h:h1&gt;Note&lt;/denchmark-h&gt;

This behavior is not incorrect per se, rather it is unconventional and unexpected and therefore it can cause extremely mysterious errors. At the very least, this behavior should be included in the documentation (it is not currently documented) with a few more examples to illustrate. Perhaps this is the best solution to avoid breaking the code of people who have figured out this subtlety and used it extensively.
&lt;denchmark-h:h1&gt;Standalone code to reproduce the issue&lt;/denchmark-h&gt;

&lt;denchmark-h:h3&gt;Example 1:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;import tensorflow.keras.backend as K

x = K.placeholder(shape=(1, 2))
y = K.placeholder(shape=(2, 3, 4))

print(K.dot(x, y))
&lt;/denchmark-code&gt;

I expect this to print a placeholder tensor of shape (1, 3, 4), but instead, I get a long traceback, the last line of which is:
&lt;denchmark-code&gt;ValueError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_3}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_7, Reshape_8)' with input shapes: [1,2], [3,8].
&lt;/denchmark-code&gt;

(see below for full traceback)
&lt;denchmark-h:h3&gt;Example 2:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;x = K.placeholder(shape=(1, 2))
y = K.placeholder(shape=(3, 2, 4))

print(K.dot(x, y))
&lt;/denchmark-code&gt;

I would expect this to raise an error because the last dimension of x does not match the first dimension of y. Instead, this prints a placeholder tensor of shape (1,3,4) indicating that the dot product was computed along the last axis of x and the next-to-last axis of y.
&lt;denchmark-h:h3&gt;Example 3:&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;x = K.placeholder(shape=(1, 2))
y = K.placeholder(shape=(3, 4, 5, 6, 7, 2, 8))

print(K.dot(x, y))
&lt;/denchmark-code&gt;

Again, I expect this to raise an error, but the dot product is computed without complaint.
&lt;denchmark-h:h1&gt;Other info / logs&lt;/denchmark-h&gt;

Traceback from Example 1 above:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)
   1811   try:
-&gt; 1812     c_op = pywrap_tf_session.TF_FinishOperation(op_desc)
   1813   except errors.InvalidArgumentError as e:

InvalidArgumentError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_5}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_12, Reshape_13)' with input shapes: [1,2], [3,8].

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
&lt;ipython-input-34-711261b03ba4&gt; in &lt;module&gt;
----&gt; 1 K.dot(x, y)

~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """Call target, and fall back on dispatchers if there is a TypeError."""
    200     try:
--&gt; 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py in dot(x, y)
   1825         array_ops.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])
   1826     return array_ops.reshape(
-&gt; 1827         math_ops.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:])
   1828   if is_sparse(x):
   1829     out = sparse_ops.sparse_tensor_dense_matmul(x, y)

~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """Call target, and fall back on dispatchers if there is a TypeError."""
    200     try:
--&gt; 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)
   3252       return ret
   3253     else:
-&gt; 3254       return gen_math_ops.mat_mul(
   3255           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
   3256 

~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)
   5638     transpose_b = False
   5639   transpose_b = _execute.make_bool(transpose_b, "transpose_b")
-&gt; 5640   _, _, _op, _outputs = _op_def_library._apply_op_helper(
   5641         "MatMul", a=a, b=b, transpose_a=transpose_a, transpose_b=transpose_b,
   5642                   name=name)

~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    740       # Add Op to graph
    741       # pylint: disable=protected-access
--&gt; 742       op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    743                                  name=scope, input_types=input_types,
    744                                  attrs=attr_protos, op_def=op_def)

~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
    589       inp = self.capture(inp)
    590       inputs[i] = inp
--&gt; 591     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    592         op_type, inputs, dtypes, input_types, name, attrs, op_def,
    593         compute_device)

~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
   3475     # Session.run call cannot occur between creating and mutating the op.
   3476     with self._mutation_lock():
-&gt; 3477       ret = Operation(
   3478           node_def,
   3479           self,

~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1972       if op_def is None:
   1973         op_def = self._graph._get_op_def(node_def.op)
-&gt; 1974       self._c_op = _create_c_op(self._graph, node_def, inputs,
   1975                                 control_input_ops, op_def)
   1976       name = compat.as_str(node_def.name)

~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)
   1813   except errors.InvalidArgumentError as e:
   1814     # Convert to ValueError for backwards compatibility.
-&gt; 1815     raise ValueError(str(e))
   1816 
   1817   return c_op

ValueError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_5}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_12, Reshape_13)' with input shapes: [1,2], [3,8].
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='Doekeb' date='2020-09-29T19:13:41Z'>
		There are of course plenty of workarounds: You can simply reshape your data, or you can use tensorflow.tensordot(x, y, axes=(-1, 0)).
		</comment>
		<comment id='2' author='Doekeb' date='2020-09-30T11:59:07Z'>
		Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it &lt;denchmark-link:https://colab.research.google.com/gist/amahendrakar/81fe29b0ab56a1678f0dff40f2c6b61c/43653-tf-nightly.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='3' author='Doekeb' date='2020-09-30T21:09:12Z'>
		&lt;denchmark-link:https://github.com/Doekeb&gt;@Doekeb&lt;/denchmark-link&gt;
 Looks like this is intended. I checked  as follows and numpy also throws similar error.
&lt;denchmark-code&gt;import numpy as np
np.dot(np.ones((1,2),dtype=np.int32),np.ones((2,3,4),dtype=np.int32))

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-14-589d6aaa8220&gt; in &lt;module&gt;()
----&gt; 1 np.dot(np.ones((1,2),dtype=np.int32),np.ones((2,3,4),dtype=np.int32))

&lt;__array_function__ internals&gt; in dot(*args, **kwargs)

ValueError: shapes (1,2) and (2,3,4) not aligned: 2 (dim 1) != 3 (dim 1)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='Doekeb' date='2020-09-30T21:25:02Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks for checking it out so quickly and for the numpy reference! I am willing to accept that this is intended behavior, however I do insist that it should be explained in tensorflow documentation (see my note in the original report).
Indeed, the numpy docstring includes the following:
&lt;denchmark-code&gt;- If `a` is an N-D array and `b` is an M-D array (where ``M&gt;=2``), it is a
  sum product over the last axis of `a` and the second-to-last axis of `b`::

    dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])
&lt;/denchmark-code&gt;

But no such explanation (nor illustrative example) is found in the current tensorflow documentation which reads in its entirety as follows:
&lt;denchmark-code&gt;Signature: tf.keras.backend.dot(x, y)
Docstring:
Multiplies 2 tensors (and/or variables) and returns a tensor.

Arguments:
    x: Tensor or variable.
    y: Tensor or variable.

Returns:
    A tensor, dot product of `x` and `y`.

Examples:

&gt;&gt;&gt; x = tf.keras.backend.placeholder(shape=(2, 3))
&gt;&gt;&gt; y = tf.keras.backend.placeholder(shape=(3, 4))
&gt;&gt;&gt; xy = tf.keras.backend.dot(x, y)
&gt;&gt;&gt; xy
&lt;tf.Tensor ... shape=(2, 4) dtype=float32&gt;

&gt;&gt;&gt; x = tf.keras.backend.placeholder(shape=(32, 28, 3))
&gt;&gt;&gt; y = tf.keras.backend.placeholder(shape=(3, 4))
&gt;&gt;&gt; xy = tf.keras.backend.dot(x, y)
&gt;&gt;&gt; xy
&lt;tf.Tensor ... shape=(32, 28, 4) dtype=float32&gt;

&gt;&gt;&gt; x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=0, high=1)
&gt;&gt;&gt; y = tf.keras.backend.ones((4, 3, 5))
&gt;&gt;&gt; xy = tf.keras.backend.dot(x, y)
&gt;&gt;&gt; tf.keras.backend.int_shape(xy)
(2, 4, 5)
File:      ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py
Type:      function
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='Doekeb' date='2020-09-30T22:57:40Z'>
		&lt;denchmark-link:https://github.com/Doekeb&gt;@Doekeb&lt;/denchmark-link&gt;
 Thanks for the detailed information. Sure. we will update it soon. Thanks!
		</comment>
		<comment id='6' author='Doekeb' date='2020-10-03T01:42:31Z'>
		&lt;denchmark-link:https://github.com/Doekeb&gt;@Doekeb&lt;/denchmark-link&gt;
 we have updated it and it will take some time to reflect on TF website. Thanks for raising this issue.
I am closing this issue as this was resolved. Thanks!
		</comment>
		<comment id='7' author='Doekeb' date='2020-10-03T01:42:33Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43653&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43653&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>