<bug id='32286' author='Peque' open_date='2019-09-06T12:45:03Z' closed_time='2019-11-08T16:44:49Z'>
	<summary>Simple `model.evaluate()` example floods output with `=` characters</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Fedora 30


Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):

(binary): pip install tensorflow==2.0.0-rc0


TensorFlow version (use command below):

v2.0.0-beta1-5101-gc75bb66 2.0.0-rc0


Python version:

Python 3.7.4


Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with: 1. TF 1.0:  2. TF 2.0: 
Describe the current behavior
Running the code, I get an output flooded with hundreds of thousands of = characters when calling model.evaluate().
&lt;denchmark-code&gt;Train on 60000 samples
Epoch 1/5
60000/60000 [==============================] - 3s 43us/sample - loss: 0.5010 - accuracy: 0.8228
Epoch 2/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.3766 - accuracy: 0.8639
Epoch 3/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.3408 - accuracy: 0.8753
Epoch 4/5
60000/60000 [==============================] - 2s 37us/sample - loss: 0.3155 - accuracy: 0.8839
Epoch 5/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.2980 - accuracy: 0.8903
10000/1 [==================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
...
... Literally hundreds of thousands of `=` ...
...
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================================================
===========================================] - 0s 26us/sample - loss: 0.2803 - accuracy: 0.8673

&lt;/denchmark-code&gt;

Describe the expected behavior
&lt;denchmark-code&gt;Train on 60000 samples
Epoch 1/5
60000/60000 [==============================] - 3s 43us/sample - loss: 0.5010 - accuracy: 0.8228
Epoch 2/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.3766 - accuracy: 0.8639
Epoch 3/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.3408 - accuracy: 0.8753
Epoch 4/5
60000/60000 [==============================] - 2s 37us/sample - loss: 0.3155 - accuracy: 0.8839
Epoch 5/5
60000/60000 [==============================] - 2s 38us/sample - loss: 0.2980 - accuracy: 0.8903
10000/10000 [==============================] - 0s 26us/sample - loss: 0.2803 - accuracy: 0.8673
&lt;/denchmark-code&gt;

Code to reproduce the issue
import tensorflow as tf

mnist = tf.keras.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()
training_images = training_images / 255.0
test_images = test_images / 255.0
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation=tf.nn.relu),
    tf.keras.layers.Dense(10, activation=tf.nn.softmax)
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(training_images, training_labels, epochs=5)

test_loss = model.evaluate(test_images, test_labels)
Other info / logs
Running this code in a Jupyter Notebook results in a performance penalty for the huge, unnecessary output.
	</description>
	<comments>
		<comment id='1' author='Peque' date='2019-09-06T17:02:16Z'>
		Perhaps you can use semi-verbose by setting  to avoid repeated logging of  character.
&lt;denchmark-link:https://colab.sandbox.google.com/gist/ymodak/da242ce544a5102fce8eddf002b9ef10/github_issue_32286.ipynb&gt;GitHub_Gist&lt;/denchmark-link&gt;

test_loss = model.evaluate(test_images, test_labels, verbose=2)
		</comment>
		<comment id='2' author='Peque' date='2019-09-06T17:49:37Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 Yeah, that is not a problem, I can set verbose to 0 as well, but I think it is a bug anyway. Note the  in the progress bar, instead of . I think that is unexpected. 
		</comment>
		<comment id='3' author='Peque' date='2019-11-01T17:45:37Z'>
		same problem here
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/32320#issuecomment-548883188&gt;#32320 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='Peque' date='2019-11-08T16:44:49Z'>
		&lt;denchmark-link:https://github.com/Peque&gt;@Peque&lt;/denchmark-link&gt;
 This has been resolved recently in  which is  that will be released in the future. I am closing this issue. Please check the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/5ead8e4a4613f9bf58996093154d1290/untitled634.ipynb&gt;here&lt;/denchmark-link&gt;
.
Please feel free to open the issue if it persists again. Thanks!
		</comment>
		<comment id='5' author='Peque' date='2019-11-08T16:44:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32286&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32286&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='Peque' date='2020-07-10T20:07:28Z'>
		this issue still seems to still persist with the current tf-nightly - has anyone found a solution?
		</comment>
		<comment id='7' author='Peque' date='2020-07-10T20:21:36Z'>
		&lt;denchmark-link:https://github.com/warriorgiggles&gt;@warriorgiggles&lt;/denchmark-link&gt;
 Can you please create a new issue with a simple standalone code to reproduce the issue? Thanks!
		</comment>
	</comments>
</bug>