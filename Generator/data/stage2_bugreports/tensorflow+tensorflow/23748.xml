<bug id='23748' author='JamesGlooTeam' open_date='2018-11-14T16:19:40Z' closed_time='2020-02-06T19:47:02Z'>
	<summary>tensorflow.keras Dense layers complain if the input is a sparse Input layer.</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
OSX Mojave 10.14.1
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
na
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
1.10.0 (v1.10.0-rc1-19-g656e7a2b34)
Python version:
3.5
Bazel version (if compiling from source):
NA
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
See below, which I ran on a OSX Mojave Macbook Pro (Early 2015), ipython running python 3.5, tensorflow 1.10.0:
&lt;denchmark-code&gt;In [1]: from tensorflow.keras.models import Model
//anaconda/envs/dssm/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5
  return f(*args, **kwds)

In [2]: from tensorflow.keras.layers import Input, Dense

In [3]: i = Input((4,), sparse=True)

In [4]: d = Dense(4)(i)
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-4-0fb73bda26dc&gt; in &lt;module&gt;
----&gt; 1 d = Dense(4)(i)

//anaconda/envs/dssm/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    718
    719         # Check input assumptions set before layer building, e.g. input rank.
--&gt; 720         self._assert_input_compatibility(inputs)
    721         if input_list and self._dtype is None:
    722           try:

//anaconda/envs/dssm/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py in _assert_input_compatibility(self, inputs)
   1408           spec.min_ndim is not None or
   1409           spec.max_ndim is not None):
-&gt; 1410         if x.shape.ndims is None:
   1411           raise ValueError('Input ' + str(input_index) + ' of layer ' +
   1412                            self.name + ' is incompatible with the layer: '

AttributeError: 'SparseTensor' object has no attribute 'shape'
&lt;/denchmark-code&gt;

Describe the expected behavior
If I were using normal Keras, I'd expect no errors trying to do the above and for the model to compile subsequently without issue.
Code to reproduce the issue
See the code in my snippet above.
Other info / logs
	</description>
	<comments>
		<comment id='1' author='JamesGlooTeam' date='2018-12-03T21:33:55Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 -- I recall you worked on something similar recently; can you comment on what is expected here?
Note that in 1.12 the above gives a different error:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-4-0347ad7938f4&gt; in &lt;module&gt;()
      2 from tensorflow.keras.layers import Input, Dense
      3 i = Input(shape=(4,), sparse=True)
----&gt; 4 d = Dense(4)(i)

google3/third_party/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    532       if not self.built:
    533         # Build layer if applicable (if the `build` method has been overridden).
--&gt; 534         self._maybe_build(inputs)
    535         # We must set self.built since user defined build functions are not
    536         # constrained to set self.built.

google3/third_party/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   1592     # Only call `build` if the user has manually overridden the build method.
   1593     if not hasattr(self.build, '_is_default'):
-&gt; 1594       self.build(input_shapes)
   1595 
   1596 

google3/third_party/tensorflow/python/keras/layers/core.py in build(self, input_shape)
    928     input_shape = tensor_shape.TensorShape(input_shape)
    929     if tensor_shape.dimension_value(input_shape[-1]) is None:
--&gt; 930       raise ValueError('The last dimension of the inputs to `Dense` '
    931                        'should be defined. Found `None`.')
    932     last_dim = tensor_shape.dimension_value(input_shape[-1])

ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='JamesGlooTeam' date='2018-12-03T21:59:17Z'>
		&lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 I looked into this issue last week. There are several things that need to be fixed.
One is that sparse.placeholder could not recognize . It will always converts to  so that the error of:
&lt;denchmark-code&gt;ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.
&lt;/denchmark-code&gt;

I created a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/24048&gt;#24048&lt;/denchmark-link&gt;
 to fix the above shape inforamtion issue first.
There might be some other places that need to be fixed to make &lt;denchmark-link:https://github.com/JamesGlooTeam&gt;@JamesGlooTeam&lt;/denchmark-link&gt;
 example work though.
(Note: as pointed out by &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
, the error is based in 1.12 and is different from the original error posted by &lt;denchmark-link:https://github.com/JamesGlooTeam&gt;@JamesGlooTeam&lt;/denchmark-link&gt;
 )
		</comment>
		<comment id='3' author='JamesGlooTeam' date='2018-12-03T22:12:55Z'>
		This is because for SparseTensors, the shape is actually a Tensor. Tensors can't have None values.
You can get around this on the Input layer by defining your batch_size:
x = keras.Input(batch_size=10, shape=(4,), sparse=True)
However, Dense layers (and most layers in general it seems) don't support sparse inputs, so you would need to subclass Layer in order to call tf.sparse.sparse_dense_matmul on your inputs, or create a Lambda layer to convert your sparse inputs to dense.
		</comment>
		<comment id='4' author='JamesGlooTeam' date='2018-12-03T22:14:37Z'>
		Ideally, the shape of a SparseTensor would probably be a TensorShape, but I think that would be a pretty substantial rewrite of a lot of the sparse ops in order to allow None values to flow through
		</comment>
		<comment id='5' author='JamesGlooTeam' date='2018-12-03T22:55:41Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 The PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/24048&gt;#24048&lt;/denchmark-link&gt;
 propose to convert  to  for the shape tensor then the information could be preserved without making drastic changes.
		</comment>
		<comment id='6' author='JamesGlooTeam' date='2019-03-04T17:52:54Z'>
		Hi,
I got the same issue, if the input is sparse then even when I apply the Dense layer I got an error.
That's too bad because to train a neural network, specifying sparse=True in the input layer makes the learning phase 5 times faster ...
Anyone has a solution for that ?
Thanks a lot.
		</comment>
		<comment id='7' author='JamesGlooTeam' date='2019-03-21T02:43:22Z'>
		
@omalleyt12 -- I recall you worked on something similar recently; can you comment on what is expected here?
Note that in 1.12 the above gives a different error:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-4-0347ad7938f4&gt; in &lt;module&gt;()
      2 from tensorflow.keras.layers import Input, Dense
      3 i = Input(shape=(4,), sparse=True)
----&gt; 4 d = Dense(4)(i)

google3/third_party/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    532       if not self.built:
    533         # Build layer if applicable (if the `build` method has been overridden).
--&gt; 534         self._maybe_build(inputs)
    535         # We must set self.built since user defined build functions are not
    536         # constrained to set self.built.

google3/third_party/tensorflow/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   1592     # Only call `build` if the user has manually overridden the build method.
   1593     if not hasattr(self.build, '_is_default'):
-&gt; 1594       self.build(input_shapes)
   1595 
   1596 

google3/third_party/tensorflow/python/keras/layers/core.py in build(self, input_shape)
    928     input_shape = tensor_shape.TensorShape(input_shape)
    929     if tensor_shape.dimension_value(input_shape[-1]) is None:
--&gt; 930       raise ValueError('The last dimension of the inputs to `Dense` '
    931                        'should be defined. Found `None`.')
    932     last_dim = tensor_shape.dimension_value(input_shape[-1])

ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.


i got the same error in tf1.13. Anyones has a quick local fix solution?
Thanks a lot!
		</comment>
		<comment id='8' author='JamesGlooTeam' date='2019-03-21T17:27:40Z'>
		SparseTensors aren't supported in Dense layer currently, although this is something we are considering. You can implement a custom layer that calls tf.sparse.sparse_dense_matmul on your SparseTensor
		</comment>
		<comment id='9' author='JamesGlooTeam' date='2019-04-25T14:09:47Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 Is there some progress on this issue?
I'd like to build a large sparse logistic regression model with Keras and having a dense layer supporting sparse input in Keras would be quite cool.

Should I wait for such a feature landing in Keras or should I implement my own layer?
Is there already an existing snippet with such a layer somewhere?

		</comment>
		<comment id='10' author='JamesGlooTeam' date='2019-07-22T13:28:24Z'>
		Maybe, the medium article I wrote on ingesting sparse inputs in Tensorflow Keras can help you out : &lt;denchmark-link:https://medium.com/dailymotion/how-to-design-deep-learning-models-with-sparse-inputs-in-tensorflow-keras-fd5e754abec1&gt;https://medium.com/dailymotion/how-to-design-deep-learning-models-with-sparse-inputs-in-tensorflow-keras-fd5e754abec1&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='JamesGlooTeam' date='2019-08-26T02:35:10Z'>
		&lt;denchmark-link:https://github.com/SharoneDayan&gt;@SharoneDayan&lt;/denchmark-link&gt;


Maybe, the medium article I wrote on ingesting sparse inputs in Tensorflow Keras can help you out : https://medium.com/dailymotion/how-to-design-deep-learning-models-with-sparse-inputs-in-tensorflow-keras-fd5e754abec1

On TensorFlow 2.0.0-rc0 I get "ValueError: The two structures don't have the same nested structure." trying your DenseLayerForSparse layer. Using sparse inputs as to regular Dense gives the "ValueError: The last dimension of the inputs to Dense should be defined. Found None." There doesn't seem to be any simple fix to this that doesn't involve in-depth understanding of TF2 internals..
Fixing the batch_size to all inputs as &lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 suggests gives the same "two structures don't have the same nested structure" error, and it seems that SparseTensorSpec gets the training dataset size as its first axis, whereas the SparseTensor -structure gets the batch_size as its first axis. Same when trying the DenseLayerSparse workaround.
Sparse inputs have worked out of the box for Keras so far, as in every other DL backend. These are a common use case with document and graph data, so it's strange that this feature is not working so close to TF2 full release, especially since SparseTensors are one of the advertised new features.
		</comment>
		<comment id='12' author='JamesGlooTeam' date='2019-08-27T08:49:20Z'>
		&lt;denchmark-link:https://github.com/anttttti&gt;@anttttti&lt;/denchmark-link&gt;

Possibly related:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31999&gt;#31999&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='JamesGlooTeam' date='2019-09-24T22:11:35Z'>
		Can confirm that updating to &gt;=1.14 breaks most code dealing with sparse data, which is especially relevant for graphs and text as &lt;denchmark-link:https://github.com/anttttti&gt;@anttttti&lt;/denchmark-link&gt;
 mentioned.
This does not seem to be an issue that can be easily worked around, and the only stable solution is to use Keras 2.2.5 (not 2.3, because that's broken too since it was made to be similar to tf.keras).
This seems like a huge step back and effectively makes it impossible to use sparse tensors in a Keras model.
		</comment>
		<comment id='14' author='JamesGlooTeam' date='2019-10-12T04:09:17Z'>
		For tensorflow 2.0 (not rc):
x = Input(shape=(32,), sparse=True)
y = Dense(1, activation='sigmoid')(x)
model = Model(x, y)
I am still getting:
ValueError: The last dimension of the inputs to Dense should be defined. Found None.
Anyone know how to resolve?
		</comment>
		<comment id='15' author='JamesGlooTeam' date='2019-11-22T18:43:29Z'>
		Hi &lt;denchmark-link:https://github.com/kechan&gt;@kechan&lt;/denchmark-link&gt;
, did you figure out the solution? I'm running into the same issue too.
		</comment>
		<comment id='16' author='JamesGlooTeam' date='2019-11-22T20:16:25Z'>
		&lt;denchmark-link:https://github.com/quangkevin&gt;@quangkevin&lt;/denchmark-link&gt;

No. I haven't looked into it again. I thought i just use Masking for my particular model and move on. But try install tf.nightly and see if the issue is still there. it appears this "bug" has been opened for a long while.
		</comment>
		<comment id='17' author='JamesGlooTeam' date='2019-11-26T22:31:45Z'>
		
This is because for SparseTensors, the shape is actually a Tensor. Tensors can't have None values.
You can get around this on the Input layer by defining your batch_size:
x = keras.Input(batch_size=10, shape=(4,), sparse=True)
However, Dense layers (and most layers in general it seems) don't support sparse inputs, so you would need to subclass Layer in order to call tf.sparse.sparse_dense_matmul on your inputs, or create a Lambda layer to convert your sparse inputs to dense.

Hi omalleyt12,
I have tried using the tf.sparse.sparse_dense_matmul() function to convert my sparse tensor into a dense one. But it still cannot fit into a dense layer:
for p, dim in zip(adjacency_powers, dim_per_power):
net_p = adj_times_x(sparse_adjacency, x, p)
&lt;denchmark-code&gt;with tf.variable_scope('r%i_l%i_p%s' % (replica, layer_id, str(p))):
  layer = tf.layers.Dense(
      dim,
      kernel_regularizer=kernel_regularizer,
      activation=None, use_bias=False)
  net_p = layer.apply(net_p)
&lt;/denchmark-code&gt;

def adj_times_x(adj, x, adj_pow=1):
"""Multiplies (adj^adj_pow)*x."""
for i in range(adj_pow):
x = tf.sparse_tensor_dense_matmul(adj, x)
return x
and the error is still "ValueError: The last dimension of the inputs to Dense should be defined. Found None."
Any suggestions regarding this?
Thanks
		</comment>
		<comment id='18' author='JamesGlooTeam' date='2020-01-12T22:34:13Z'>
		This is not fixed in 2.1.0 :(
This is a major blocker for the &lt;denchmark-link:https://danielegrattarola.github.io/spektral/&gt;Spektral&lt;/denchmark-link&gt;
 library. Can we get some attention on this issue?
		</comment>
		<comment id='19' author='JamesGlooTeam' date='2020-02-06T18:54:49Z'>
		&lt;denchmark-link:https://github.com/cgarciae&gt;@cgarciae&lt;/denchmark-link&gt;
 -- can you file a new bug with a minimal repro in 2.x? This bug is very old, and it's hard to tell exactly what condition set doesn't work here.
		</comment>
		<comment id='20' author='JamesGlooTeam' date='2020-02-06T18:54:51Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23748&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23748&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='21' author='JamesGlooTeam' date='2020-02-06T19:41:42Z'>
		Hi &lt;denchmark-link:https://github.com/karmel&gt;@karmel&lt;/denchmark-link&gt;
,
I just submitted the fix for this. It should be synced out shortly.
		</comment>
		<comment id='22' author='JamesGlooTeam' date='2020-02-06T19:47:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23748&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23748&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>