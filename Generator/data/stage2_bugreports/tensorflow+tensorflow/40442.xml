<bug id='40442' author='Jamesweng' open_date='2020-06-14T06:35:09Z' closed_time='2020-07-13T14:32:45Z'>
	<summary>image normalization preprocess in Tensorflow Lite iOS object detection examples</summary>
	<description>
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iphoneX
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1.0
Python version:3.5
Bazel version (if compiling from source):no
GCC/Compiler version (if compiling from source):no
CUDA/cuDNN version: not related, run on cpu
GPU model and memory:  not related, run on cpu

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
Hi, can anyone help to confirm which one is correct for the object detection model used in example(coco_mobilenet_ssd_v1)?
from the Tensorflow Lite IOS object_detection example, it use "x / 255.0" to normalize image for preprocess.
&lt;denchmark-link:https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L319&gt;https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L319&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;// Not quantized, convert to floats
let bytes = Array&lt;UInt8&gt;(unsafeData: byteData)!
var floats = [Float]()
for i in 0..&lt;bytes.count {
  floats.append(Float(bytes[i]) / 255.0)
}
return Data(copyingBufferOf: floats)
&lt;/denchmark-code&gt;

while in the Tensorflow Lite Android object_detection example, it use "(x -128.0) / 128.0"
&lt;denchmark-link:https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L171&gt;https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/TFLiteObjectDetectionAPIModel.java#L171&lt;/denchmark-link&gt;

// Float model
private static final float IMAGE_MEAN = 128.0f;
private static final float IMAGE_STD = 128.0f;
...
imgData.putFloat((((pixelValue &gt;&gt; 16) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);
imgData.putFloat((((pixelValue &gt;&gt; 8) &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);
imgData.putFloat(((pixelValue &amp; 0xFF) - IMAGE_MEAN) / IMAGE_STD);
while from the ssd mobilenet v1 feature extractor , it use "(2.0 / 255.0) * resized_inputs - 1.0" which is different from the above two
&lt;denchmark-link:https://github.com/tensorflow/models/blob/master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L78&gt;https://github.com/tensorflow/models/blob/master/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py#L78&lt;/denchmark-link&gt;

350   def preprocess(self, resized_inputs):
351     """SSD preprocessing.
352
353     Maps pixel values to the range [-1, 1]. The preprocessing assumes an input
354     value range of [0, 255].
355
356     Args:
357       resized_inputs: a [batch, height, width, channels] float tensor
358         representing a batch of images.
359
360     Returns:
361       preprocessed_inputs: a [batch, height, width, channels] float tensor
362         representing a batch of images.
363     """
364     return (2.0 / 255.0) * resized_inputs - 1.0
Describe the expected behavior
we got different accuracy when using a same model(ssd_mobilenet_v1) on PC vs. iOS when using tensorflow lite example code and pre trained model, for ssd_mobilenet_v1 how much accuracy loss on iOS is expected?
Appreciate for any help, Thanks!
	</description>
	<comments>
		<comment id='1' author='Jamesweng' date='2020-06-15T05:16:44Z'>
		&lt;denchmark-link:https://github.com/Jamesweng&gt;@Jamesweng&lt;/denchmark-link&gt;

Please share simple stand alone code so we can replicate the accuracy for both and analyse the issue. or if possible share a colab gist with the issue faced.
		</comment>
		<comment id='2' author='Jamesweng' date='2020-06-15T07:32:42Z'>
		
@Jamesweng
Please share simple stand alone code so we can replicate the accuracy for both and analyse the issue. or if possible share a colab gist with the issue faced.

Thanks for your reply Saduf, we finally verified that it's the wrong preprocess parameter in iOS causes the accuracy loss, when we change the iOS object detection example code
From
&lt;denchmark-link:https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L319&gt;https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L319&lt;/denchmark-link&gt;

for i in 0..&lt;bytes.count {
floats.append(Float(bytes[i]) / 255.0)
}
To
for i in 0..&lt;bytes.count {
floats.append(Float(bytes[i]) / 127.5 - 1.0)
}
the accuracy in iOS is the same as PC now.
		</comment>
		<comment id='3' author='Jamesweng' date='2020-06-22T10:12:09Z'>
		&lt;denchmark-link:https://github.com/Jamesweng&gt;@Jamesweng&lt;/denchmark-link&gt;
 Thanks for the detailed investigation! I think you're right that the iOS side preprocessing logic is incorrect for the floating-point model.
Would you be willing to send a PR with a fix?
		</comment>
		<comment id='4' author='Jamesweng' date='2020-06-24T17:38:05Z'>
		Hi &lt;denchmark-link:https://github.com/yyoon&gt;@yyoon&lt;/denchmark-link&gt;
 I created a PR here - &lt;denchmark-link:https://github.com/tensorflow/examples/pull/226&gt;tensorflow/examples#226&lt;/denchmark-link&gt;

Thanks
		</comment>
		<comment id='5' author='Jamesweng' date='2020-06-25T14:11:35Z'>
		Hi &lt;denchmark-link:https://github.com/Jamesweng&gt;@Jamesweng&lt;/denchmark-link&gt;
. I'm also facing this loss accuracy problem but with quantized models. I opened the issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40518&gt;#40518&lt;/denchmark-link&gt;
 to try solving this, we have some possibilities but not very clear right now. Can you please share how do you run the inference in iOS? I get a  from camera or gallery, covert it to  and then call the  from the . Are you also doing this procedure?
Thanks!
		</comment>
		<comment id='6' author='Jamesweng' date='2020-06-26T03:24:40Z'>
		
Hi @Jamesweng. I'm also facing this loss accuracy problem but with quantized models. I opened the issue #40518 to try solving this, we have some possibilities but not very clear right now. Can you please share how do you run the inference in iOS? I get a UIImage from camera or gallery, covert it to CVPixelBuffer and then call the runModel(onFrame: myCvPixelBuffer) from the modelDataHandler.swift. Are you also doing this procedure?
Thanks!

Hi &lt;denchmark-link:https://github.com/zampnrs&gt;@zampnrs&lt;/denchmark-link&gt;
 , here's something I can share when loading image from gallery -
MAKE SURE YOUR INPUT IMAGE's pixel format(ARGB channel order) is consistent with the one needed in model preprocess, there's 'rgbDataFromBuffer()' process inside runModel() which is expected to remove the alpha channel from the input pixelBuffer. If you're passing in ARGB and take it as BGRA mistakenly, you may result a bad accuracy.
Thanks,
		</comment>
		<comment id='7' author='Jamesweng' date='2020-07-13T14:32:46Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40442&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40442&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>