<bug id='29700' author='mukeshmithrakumar' open_date='2019-06-12T18:23:06Z' closed_time='2019-11-19T19:16:25Z'>
	<summary>[TF 2.0] tf.linalg.inv</summary>
	<description>
System information

TensorFlow version: '2.0.0-dev20190612'
Python version: 3.6.7

Describe the current behavior
I am taking the inverse of a matrix with a large condition number, see the code for the matrix example, when I try tf.linalg.inv(A) I get the error: InvalidArgumentError: Input is not invertible. [Op:MatrixInverse]
Describe the expected behavior
I don't think that is the correct error, because the Matrix can be inverted because the determinant is not exactly zero and TF gets it as zero due to the way tf.linalg.det is implemented. But if you try the same in numpy or Matlab, we can get the inv, in numpy you get the inv and in Matlab, you get the inv with a warning. Again, the determinant is very small (2.1934511e-08), for all purposes it can be assumed to be zero, so in the least, the error can be more of a warning rather than a not invertible error.
Also, I am curious to know how precise TF calculations are or after how many significant figure something is rounded to be zero. If you have any resources or links so I can check it out, would really appreciate it.
Code to reproduce the issue
&lt;denchmark-code&gt;A = tf.constant([[4.1, 2.8], [9.676, 6.608]], dtype=tf.float32)
Ainvnp = np.linalg.inv(A)
print(A2inv)

Ainvtf = tf.linalg.inv(A)
print(Ainvtf)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='mukeshmithrakumar' date='2019-06-14T09:18:00Z'>
		I have tried on Colab with TensorFlow version 2.0.0-dev20190612 and was able to get inverse of matrix when trying with numpy but got the mentioned error when trying with "tf.linalg.inv"
		</comment>
		<comment id='2' author='mukeshmithrakumar' date='2019-11-19T13:11:28Z'>
		any update?
		</comment>
		<comment id='3' author='mukeshmithrakumar' date='2019-11-19T19:16:25Z'>
		If the condition number of your matrix approaches 1/std::numeric_limits&lt;T&gt;::epsilon() then it is "numerically singular", or "numerically indistinguishable" from a singular matrix.
As you mention, Matlab warns you if it determines that you are in this regime, since this means that the results returned by numpy.linalg.inv or inv in Matlab are essentially garbage (well, it turns out they are not entirely random, and you can solve ill-conditioned systems to your advantage, if you know what you are doing, e.g. when computing eigenvectors of a matrix using inverse iteration. But that's beyond the scope of this issue, I think.)
In TensorFlow we chose to fail with an error in this case, instead of returning garbage. The TF error only occurs when zeros appear in the diagonal of the underlying LU decomposition, which is not nearly as reliable as the condition number estimation approach used by Matlab. I contributed a condition estimator to the Eigen library used by TF on CPU, and we should probably consider using it.
My advice would be:

Don't compute the inverse of a matrix unless you absolutely have to. If you are really solving a linear system of equations, consider using tf.linalg.solve. Use tf.linalg.solve_ls, if you are solving a least-squares problem or an under-determined linear system.
If you think you need the inverse for an ill-conditioned matrix, you most likely want the pseudo-inverse provided by tf.linalg.pinv.
If you really want to work with an ill-conditioned matrix, use tf.linalg.svd.

I would recommend picking up a textbook on numerical linear algebra and read about (backwards) error analysis to better understand what the limitations of these algorithms are. Personally I really like Jim Demmel's book: &lt;denchmark-link:https://epubs.siam.org/doi/book/10.1137/1.9781611971446?mobileUi=0&gt;https://epubs.siam.org/doi/book/10.1137/1.9781611971446?mobileUi=0&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='mukeshmithrakumar' date='2019-11-19T19:16:27Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29700&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29700&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='mukeshmithrakumar' date='2020-10-12T15:19:34Z'>
		Hello guys,
My simple question is that why the Matlab running on my laptop (Intel, core i5, 8G ram) computes the inverse faster as compared to the Google TPU. Code attached...
Matlab code:
A = rand(3000,3000);
tic
inv(A);
t = toc;
disp(t)
Output:
1.1297
Python code:
import numpy as np
import scipy as sp
import timeit
import tensorflow as tf
dim = 3000
mat = tf.random.uniform(shape=(dim,dim))
st = timeit.default_timer()
tf.linalg.inv(mat)
print("time elapsed tensorflow:", timeit.default_timer() - st)
x = np.random.rand(dim,dim)
st = timeit.default_timer()
np.linalg.inv(x)
print("time elapsed scipy: ", timeit.default_timer() - st)
Output:
time elapsed tensorflow: 1.3009283419999065
time elapsed scipy: 2.618305011000075
		</comment>
		<comment id='6' author='mukeshmithrakumar' date='2020-10-12T18:25:13Z'>
		&lt;denchmark-link:https://github.com/umairbinmansoor&gt;@umairbinmansoor&lt;/denchmark-link&gt;
 Please open a new issue with a simple standalone code to reproduce the issue. Your code uses only cpu as you didn't enable any TPU. Thanks!
		</comment>
		<comment id='7' author='mukeshmithrakumar' date='2020-10-13T05:55:52Z'>
		
@umairbinmansoor Please open a new issue with a simple standalone code to reproduce the issue. Your code uses only cpu as you didn't enable any TPU. Thanks!

&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
, I have the earlier output with the TPU selected but the funny thing is, with GPU, I am getting 0.1153 s
		</comment>
	</comments>
</bug>