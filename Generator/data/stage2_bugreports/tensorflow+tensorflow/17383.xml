<bug id='17383' author='zhiz21' open_date='2018-03-02T19:38:52Z' closed_time='2018-03-15T00:00:49Z'>
	<summary>Performance dropped in cifar10 in TF 1.6.0 compiled with MKL</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.6.0
Python version: 2.7/3.6
Bazel version (if compiling from source): Build label: 0.7.0
GCC/Compiler version (if compiling from source): 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
CUDA/cuDNN version: V9.0.176
GPU model and memory: N/A
Exact command to reproduce:

&lt;denchmark-code&gt;git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
./configure
&lt;/denchmark-code&gt;

I enabled Jemalloc, XLA JIT, Amazon S3 support during configuration.
&lt;denchmark-code&gt;bazel build --config=opt --config=mkl --config=monolithic --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" --copt="-DEIGEN_USE_VML" //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
sudo pip install /tmp/tensorflow_pkg/tensorflow-1.6.0-cp27-cp27mu-linux_x86_64.whl
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;export OMP_NUM_THREADS=72
export KMP_AFFINITY=granularity=fine,verbose,compact,1,0
export KMP_BLOCKTIME=1
export KMP_SETTINGS=1
export OMP_PROC_BIND=true

git clone https://github.com/tensorflow/models.git
cd models/tutorials/image/cifar10
python cifar10_train.py
&lt;/denchmark-code&gt;

&lt;denchmark-h:h3&gt;Hardware information&lt;/denchmark-h&gt;

-Model Name: Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz
-CPU(s): 72
-Architecture:x86_64
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

I work with an AWS C5.18xlarge instance.
With TensorFlow 1.5.0 compiled with MKL and setting MKL parameters shown above, I can get a ~2000 examples/sec speed when running cifar10_train.py. But for TensorFlow 1.6.0 with exactly same building steps, I can only get speed of ~300 examples/sec.
	</description>
	<comments>
		<comment id='1' author='zhiz21' date='2018-03-07T02:07:21Z'>
		I see this regression also. Training is 5 times slower with 1.6 vs. 1.5 on my slightly modified copy of the CIFAR10 example from &lt;denchmark-link:https://github.com/tensorflow/models&gt;https://github.com/tensorflow/models&lt;/denchmark-link&gt;
. CPU usage is 20X higher for that 5X slower training run. This translates to a 100X increase in CPU usage per batch. Something is very wrong.
		</comment>
		<comment id='2' author='zhiz21' date='2018-03-07T21:58:35Z'>
		We have reproduced this problem within Intel and are working on a fix.
		</comment>
		<comment id='3' author='zhiz21' date='2018-03-07T22:46:38Z'>
		Great! Thank you for such a quick turnaround!
		</comment>
		<comment id='4' author='zhiz21' date='2018-03-17T01:21:49Z'>
		The regression has been fixed in master. The fix will be included in TF1.7.
		</comment>
		<comment id='5' author='zhiz21' date='2018-05-04T14:58:23Z'>
		Did this fix make it to 1.7? I am still seeing a slowdown there (see the ref issue above for a script reproducing the problem)
		</comment>
		<comment id='6' author='zhiz21' date='2018-05-05T01:35:12Z'>
		Yes, the fix is in 1.7. After some changes inTF 1.6, cifar10 was about 8x slower than TF 1.5. After the fix, TF 1.7 is now about 12% slower. The fix in TF 1.7 was temporary, it will be improved in the future versions.
		</comment>
		<comment id='7' author='zhiz21' date='2018-05-08T19:59:05Z'>
		Then it seems that the slowdown I encountered is due to a different reason, since my code is still slow on 1.7 (about 100 times slower than in 1.4).
		</comment>
	</comments>
</bug>