<bug id='28429' author='srihari-humbarwadi' open_date='2019-05-06T08:10:11Z' closed_time='2019-06-04T16:18:29Z'>
	<summary>Profile tab in tensorboard keeps saying "Processing datasets"</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.0.0-alpha0
Python version: 3.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 10.1, 7.5
GPU model and memory: 3x GTX 1080Ti, 11Gb

Describe the current behavior
I was training a tf.keras and had a tensorboard callback, but i don't seem to get the new profiling feature to work.
Code to reproduce the issue
&lt;denchmark-code&gt;train_dataset = tf.data.Dataset.from_tensor_slices(
    (train_images, train_labels))
train_dataset = train_dataset.shuffle(buffer_size=256)
train_dataset = train_dataset.apply(tf.data.experimental.map_and_batch(map_func=load_data,
                                                                       batch_size=batch_size,
                                                                       num_parallel_calls=tf.data.experimental.AUTOTUNE,
                                                                       drop_remainder=True))
train_dataset = train_dataset.repeat()
train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)

val_dataset = tf.data.Dataset.from_tensor_slices(
    (val_images, val_labels))
val_dataset = val_dataset.shuffle(buffer_size=256)
val_dataset = val_dataset.apply(tf.data.experimental.map_and_batch(map_func=load_data,
                                                                   batch_size=batch_size,
                                                                   num_parallel_calls=tf.data.experimental.AUTOTUNE,
                                                                   drop_remainder=True))
val_dataset = train_dataset.repeat()
val_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)

callbacks = [tf.keras.callbacks.TensorBoard(update_freq='batch'),
             tf.keras.callbacks.ModelCheckpoint('model/weights.h5', 
                                                save_best_only=True, 
                                                save_weights_only=True)]
model.fit(train_dataset,
          steps_per_epoch=len(train_images) // batch_size,
          epochs=300,
          validation_data=val_dataset,
          validation_steps=len(val_images) // batch_size,
          callbacks=callbacks)
&lt;/denchmark-code&gt;

Other info / logs
There are the logs from tensorboard
&lt;denchmark-code&gt;I0506 13:36:28.764028 139696445298432 _internal.py:122] ::ffff:10.10.10.14 - - [06/May/2019 13:36:28] "GET /data/plugin/profile/tools HTTP/1.1" 200 -
I0506 13:36:28.786284 139696445298432 _internal.py:122] ::ffff:10.10.10.14 - - [06/May/2019 13:36:28] "GET /data/plugin/profile/hosts?run=2019-05-05_18-45-33&amp;tag=trace_viewer HTTP/1.1" 200 -
I0506 13:36:28.829900 139696445298432 _internal.py:122] ::ffff:10.10.10.14 - - [06/May/2019 13:36:28] "GET /data/plugin/profile/hosts?run=2019-05-05_18-45-33&amp;tag=trace_viewer HTTP/1.1" 200 -
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='srihari-humbarwadi' date='2019-05-06T08:11:17Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='srihari-humbarwadi' date='2019-05-20T19:32:55Z'>
		&lt;denchmark-link:https://github.com/srihari-humbarwadi&gt;@srihari-humbarwadi&lt;/denchmark-link&gt;
 Could you provide a standalone code to reproduce? Thanks!
		</comment>
		<comment id='3' author='srihari-humbarwadi' date='2019-06-04T13:22:23Z'>
		It has been 14 days with no activity and the awaiting response label was assigned. Is this still an issue?
		</comment>
		<comment id='4' author='srihari-humbarwadi' date='2019-06-04T16:18:29Z'>
		Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!
		</comment>
		<comment id='5' author='srihari-humbarwadi' date='2019-06-04T16:18:31Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28429&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28429&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='srihari-humbarwadi' date='2020-01-09T04:32:07Z'>
		Hi. I am seeing this same issue. I built a tf.keras model with model subclassing on tf 2.0, and then executed the following code to log the graph and run the tensorboard profiler:
tf.summary.trace_on(graph=True, profiler=True)
network(np.random.randn(1, 84, 84, 4))
with summary_writer.as_default():
tf.summary.trace_export(name="model_trace", step=0, profiler_outdir=log_dir)
The graph gets logged to tensorboard correctly but when I open the "profile" tab, it says "Processing Datasets" and it does not make any progress, it has been stuck like that for hours.
Maybe I should add that the context is Deep Reinforcement Learning, so the data comes from a replay buffer (implemented as a list), so the dataset is dynamic and data is added and removed continuously.
		</comment>
		<comment id='7' author='srihari-humbarwadi' date='2020-01-09T05:54:08Z'>
		&lt;denchmark-link:https://github.com/markelsanz14&gt;@markelsanz14&lt;/denchmark-link&gt;
 Please open a new issue with your issue details and a standalone code to reproduce the issue. Please open the issue in  repo. Thanks!
		</comment>
	</comments>
</bug>