<bug id='29911' author='mcoolsce' open_date='2019-06-18T11:02:40Z' closed_time='2019-12-27T18:49:22Z'>
	<summary>Input_signature of a tf.function decorator crashes when using multiple GPUs with MirroredStrategy</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7.6.1810
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: /
TensorFlow installed from (source or binary): pip binary
TensorFlow version (use command below): tensorflow-gpu 2.0.0-beta0
Python version: 3.6.8
Bazel version (if compiling from source): /
GCC/Compiler version (if compiling from source): /
CUDA/cuDNN version: 10.0.130 / 7.6.0
GPU model and memory: Tesla P100-SXM2-16GB

Describe the current behavior
Tensorflow crashes when checking the input_signature of a tf.function decorator when using multiple GPUs in a MirroredStrategy. A ValueError is generated cause a PerReplica object cannot be converted to a Tensor (see the log below). Below you can find the minimum code needed to reproduce the error. The code runs just fine when I only utilize one GPU strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0"]). Furthermore, if the optional argument input_signature is discarded (only using @tf.function()) the error disappears too (again using multiple GPUs). Hence, the specific combination of input_signature and multiple GPUs causes the problem (which I need for performance reasons in my work).
Describe the expected behavior
The code below won't generate any errors.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np
        
strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0", "/gpu:1"])
    
with strategy.scope():
    dataset = tf.data.Dataset.from_tensor_slices(np.ones([100, 12]).astype(np.float32))
    dataset = dataset.batch(4)
    dataset = strategy.experimental_distribute_dataset(dataset)
    
    def compute(input_data):
        return tf.reduce_sum(input_data, [1])
    
    @tf.function(input_signature = (tf.TensorSpec([None, 12], tf.float32),))
    def distributed_run(input_data):
        return strategy.experimental_run_v2(compute, args = (input_data,))

    for x in dataset:
        output = distributed_run(x)
        print(output)
&lt;/denchmark-code&gt;

Other info / logs

Traceback (most recent call last):
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1216, in _convert_inputs_to_signature
value, dtype_hint=spec.dtype)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1100, in convert_to_tensor
return convert_to_tensor_v2(value, dtype, preferred_dtype, name)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1158, in convert_to_tensor_v2
as_ref=False)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1237, in internal_convert_to_tensor
ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 305, in _constant_tensor_conversion_function
return constant(v, dtype=dtype, name=name)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 246, in constant
allow_broadcast=True)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 254, in _constant_impl
t = convert_to_eager_tensor(value, ctx, dtype)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 115, in convert_to_eager_tensor
return ops.EagerTensor(value, handle, device, dtype)
ValueError: Attempt to convert a value (PerReplica:{
0 /job:localhost/replica:0/task:0/device:GPU:0: &lt;tf.Tensor: id=107, shape=(2, 12), dtype=float32, numpy=
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;,
1 /job:localhost/replica:0/task:0/device:GPU:1: &lt;tf.Tensor: id=108, shape=(2, 12), dtype=float32, numpy=
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;
}) with an unsupported type (&lt;class 'tensorflow.python.distribute.values.PerReplica'&gt;) to a Tensor.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "issue2.py", line 19, in 
output = distributed_run(x)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 432, in call
*args, **kwds)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1169, in canonicalize_function_inputs
self._flat_input_signature)
File "/data/gent/gvo000/gvo00003/vsc41939/GENIUS/miniconda3/envs/tensorflow2/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1222, in _convert_inputs_to_signature
(str(inputs), str(input_signature)))
ValueError: When input_signature is provided, all inputs to the Python function must be convertible to tensors.Inputs ((PerReplica:{
0 /job:localhost/replica:0/task:0/device:GPU:0: &lt;tf.Tensor: id=107, shape=(2, 12), dtype=float32, numpy=
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;,
1 /job:localhost/replica:0/task:0/device:GPU:1: &lt;tf.Tensor: id=108, shape=(2, 12), dtype=float32, numpy=
array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)&gt;
},)), input_signature((TensorSpec(shape=(None, 12), dtype=tf.float32, name=None),)).

	</description>
	<comments>
		<comment id='1' author='mcoolsce' date='2019-06-26T02:07:46Z'>
		Thank you for reporting, we are going to look into fixing this issue.
In the meantime, I am wondering how you can get around this issue to get the performance you're seeking. I am assuming that your input data has varying dimensions in various steps, and you don't want to tf.function to retrace everytime that happens. And you're trying to avoid that re-tracing by providing an appropriate input signature.
The 3 possible workarounds could be:

Try the experimental_relax_shapes argument to tf.function https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/function. This may not give you the most optimal but it could work.
Instead of passing the actual inputs as argument to the tf.function, pass something that can be used to get the inputs. For instance, pass a callable that when called will return the data. This callable will never change so the function will not retrace. This is kind of hacky but something we have used sometimes to get good performance. You can also create the iterator on the dataset by iter(dataset) and pass that as argument to the function, and do next() inside the function to get the inputs. That will also get around this issue, I believe.
You could also consider passing the entire dataset into the tf.function and iterate inside it. This will arguably give you the best performance as it will convert the entire thing into a tf.while_loop.

		</comment>
		<comment id='2' author='mcoolsce' date='2019-06-26T10:57:11Z'>
		Thanks for the reply and the suggestions. I will experiment with them in the following days.
		</comment>
		<comment id='3' author='mcoolsce' date='2019-07-30T18:25:54Z'>
		I had the same problem and am curious if the suggestions (and which one, specifically) worked for you &lt;denchmark-link:https://github.com/mcoolsce&gt;@mcoolsce&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='mcoolsce' date='2019-07-31T06:24:06Z'>
		&lt;denchmark-link:https://github.com/dsgupta&gt;@dsgupta&lt;/denchmark-link&gt;
, I tried all the options and the second one seems to work fine:


The argument experimental_relax_shapes had no effect at all.


This is the option I am using now. I create my dataset and make an iterable out of it, which is the only argument going into the tf.function. Inside the function, I call next(dataset) to get access to my data. Performance-wise (tested on 1 GPU), it seems that is option is a little bit slower compared to my original code.


I think the third option is theoretically the fastest but it throws some Out of Memory errors a few iterations in the converted tf.while_loop. I just pass my entire dataset into the tf.function wrapper and used a python for loop to iterate over the data. This is very strange as I had no memory issues at all before (where I iterate over the data using a python for loop outside the tf.function).


		</comment>
		<comment id='5' author='mcoolsce' date='2019-07-31T15:58:39Z'>
		&lt;denchmark-link:https://github.com/mcoolsce&gt;@mcoolsce&lt;/denchmark-link&gt;
 Thanks for the response! I faced the same sort of problem with the third approach, but instead of Out of Memory, I was getting Recursion Depth Exceeded if I tried using  I'll try the second one and see how it goes.
		</comment>
		<comment id='6' author='mcoolsce' date='2019-10-30T13:34:37Z'>
		The first one doesn't work.
I tried the second option, but it turns out to be another problem "BaseCollectiveExecutor::StartAbort Out of range: End of sequence".
The third option is not suitable for me since I want to dynamically adjust the training strategy with the loss from the train step.
Any other suggestions ?
		</comment>
		<comment id='7' author='mcoolsce' date='2019-11-11T03:47:44Z'>
		&lt;denchmark-link:https://github.com/Slyne&gt;@Slyne&lt;/denchmark-link&gt;
 is the issue you encountered with second approach a bug? perhaps you can file a separate issue for that and we can figure out how you can make progress with that?
the only other workaround I can think of is if you want to actually make up the distributed input signature yourself. I can provide the code for that but it requires using private TF APIs.
		</comment>
		<comment id='8' author='mcoolsce' date='2019-11-11T08:15:13Z'>
		
@Slyne is the issue you encountered with second approach a bug? perhaps you can file a separate issue for that and we can figure out how you can make progress with that?
the only other workaround I can think of is if you want to actually make up the distributed input signature yourself. I can provide the code for that but it requires using private TF APIs.

The second workaround gives an error like this issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/22484&gt;#22484&lt;/denchmark-link&gt;
, unless I stop iterating the dataset before the last step.
		</comment>
		<comment id='9' author='mcoolsce' date='2019-11-17T19:00:05Z'>
		&lt;denchmark-link:https://github.com/Slyne&gt;@Slyne&lt;/denchmark-link&gt;
 can you share the code for what you're doing when using the second workaround? likely you need to change your code to catch the out of range error (or i maybe able to suggest a slightly different API to get the next element)
		</comment>
		<comment id='10' author='mcoolsce' date='2019-11-20T03:23:17Z'>
		Any info about when will this bug be fixed?
		</comment>
		<comment id='11' author='mcoolsce' date='2019-11-21T10:00:54Z'>
		Any info about when this bug will be fixed. For dynamic batch size inputs, this input_signature is essential, otherwise it will lead to tracing, which is very expensive.
		</comment>
		<comment id='12' author='mcoolsce' date='2019-12-27T18:49:22Z'>
		This issue has now been &lt;denchmark-link:e1136256a791b02f793ff3f3e1f9ee7da4606807&gt;fixed&lt;/denchmark-link&gt;
. You can use the  property on the dataset or iterator to specify the . For example,
&lt;denchmark-code&gt;# For the `experimental_distribute_dataset API`
dataset = tf.data.Dataset(...)
dist_dataset = strategy.experimental_distributed_dataset(dataset)
# Use the `element_spec` of the distributed dataset
@tf.function(input_signature=[dist_dataset.element_spec])
def train_step(...):
  ....

# Use the `element_spec` of the distributed iterator
iterator = iter(dist_dataset)
@tf.function(input_signature=[iterator.element_spec])
def train_step(..)
  ...

# For the `experimental_distribute_datasets_from_function` API
# Use the `element_spec` of the distributed iterator
dataset = tf.data.Dataset(...)
dist_dataset = strategy.experiemental_distribute_datasets_from_function(dataset)
iterator = iter(dist_dataset)
@tf.function(input_signature=[iterator.element_spec])
def train_step(..)
  ...
&lt;/denchmark-code&gt;

Please reopen if you run into issues.
		</comment>
		<comment id='13' author='mcoolsce' date='2019-12-27T18:49:24Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29911&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29911&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='14' author='mcoolsce' date='2020-01-21T23:40:39Z'>
		
This issue has now been fixed. You can use the element_spec property on the dataset or iterator to specify the tf.TypeSpec. For example,
# For the `experimental_distribute_dataset API`
dataset = tf.data.Dataset(...)
dist_dataset = strategy.experimental_distributed_dataset(dataset)
# Use the `element_spec` of the distributed dataset
@tf.function(input_signature=[dist_dataset.element_spec])
def train_step(...):
  ....

# Use the `element_spec` of the distributed iterator
iterator = iter(dist_dataset)
@tf.function(input_signature=[iterator.element_spec])
def train_step(..)
  ...

# For the `experimental_distribute_datasets_from_function` API
# Use the `element_spec` of the distributed iterator
dataset = tf.data.Dataset(...)
dist_dataset = strategy.experiemental_distribute_datasets_from_function(dataset)
iterator = iter(dist_dataset)
@tf.function(input_signature=[iterator.element_spec])
def train_step(..)
  ...

Please reopen if you run into issues.

This method only works for tf-nightly-gpu (Tensorflow version: 2.2.0) and not for TF 2.0
		</comment>
		<comment id='15' author='mcoolsce' date='2020-02-07T17:36:06Z'>
		&lt;denchmark-link:https://github.com/anj-s&gt;@anj-s&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/alisaaalehi&gt;@alisaaalehi&lt;/denchmark-link&gt;

the provided solution doesn't work for me (on 2.2.0.dev20200207).

can you clarify which function would need to be decorated: the inner train_step or the distributed_train_step?
my guess is that in my case the input_signature doesn't match as I modified the input in the training step (x = encoder(x)). Is that correct? What would be a suggested better way to handle thins?

        def train_step(x, y):
            with tf.GradientTape() as tape:
                logits = model(x, training=True)
                # Loss value for this batch.
                loss, metrics = loss_fn(logits, targets, encoder)
                loss = loss * (1.0 / global_batch_size)
                # Get gradients of weights wrt the loss.
                gradients = tape.gradient(loss, mapper.trainable_weights)
                # Update the weights of our model
                optimizer.apply_gradients(zip(gradients, mapper.trainable_weights))
                return loss, metrics

        @tf.function(input_signature=[train_iter.element_spec])
        def distributed_train_step(x, y):
            per_example_losses, _ = mirrored_strategy.experimental_run_v2(
                train_step, args=(x, y)
            )
            return mirrored_strategy.reduce(
                tf.distribute.ReduceOp.SUM,
                per_example_losses,
                axis=None
            )

        def distributed_training(steps):
            total_loss = 0.0
            num_train_batches = 0.0
            for _ in range(steps):
                x, y = next(train_iter)
                x = encoder(x)  #  would this be a problem?
                total_loss += distributed_train_step(mix, targets)
                ckpt.step.assign_add(1)
                num_train_batches += 1

            return total_loss, num_train_batches
Update: removing the encoder, thus making it part of the model does not yield into a crash and even works for 2.1.0 stable. That being said, I would add the following question:

Is it possible (and are there any caveats) to have/overwrite an input signature that does not match with dataset.element_spec so that it works in the case mentioned above? (Of course, using variable shape tensors as in the example by @mcoolsce)

		</comment>
		<comment id='16' author='mcoolsce' date='2020-06-06T16:31:49Z'>
		This is still not working even in TF-2.2.0 and 2.3 nightlly gpu versions. Any thoughts on this?
&lt;denchmark-link:https://github.com/goldiegadde&gt;@goldiegadde&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/anj-s&gt;@anj-s&lt;/denchmark-link&gt;

		</comment>
		<comment id='17' author='mcoolsce' date='2020-06-06T17:46:37Z'>
		&lt;denchmark-link:https://github.com/s4sarath&gt;@s4sarath&lt;/denchmark-link&gt;
 please provide code to repro your issue (either here or in a new bug).
		</comment>
		<comment id='18' author='mcoolsce' date='2020-06-07T03:37:38Z'>
		Hi &lt;denchmark-link:https://github.com/guptapriya&gt;@guptapriya&lt;/denchmark-link&gt;
 . Thanks for the quick response.  I have tested this both on TF 2.2.0 GPU and TF 2.3 nightly build also . On colab.
a.) Using MirroredStrategy experimental distribute ( TF 2.2.0 )
&lt;denchmark-code&gt;ds = strategy.experimental_distribute_dataset(train_dataset)
def train_no_tracing(ds):
  @tf.function(input_signature=[ds.element_spec])
  def step_fn(inputs):
    # train the model with inputs
    return inputs
  for index,batch in enumerate(ds):
    replica_results = strategy.run(step_fn, args=(batch,))
    print(index)
    if index == 11:
      break

train_no_tracing(ds)
&lt;/denchmark-code&gt;

TypeError                                 Traceback (most recent call last)
 in ()
----&gt; 1 train_no_tracing(ds)
12 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
966           except Exception as e:  # pylint:disable=broad-except
967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
969             else:
970               raise
TypeError: in user code:
&lt;denchmark-code&gt;TypeError: tf___call_for_each_replica() missing 1 required positional argument: 'kwargs'
&lt;/denchmark-code&gt;

b.) Same code in  TF nightly build '2.3.0-dev20200605'
Now error is somewhat similar not exact
&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

TypeError                                 Traceback (most recent call last)
 in ()
12       break
13
---&gt; 14 train_no_tracing(ds)
13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
966           except Exception as e:  # pylint:disable=broad-except
967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
969             else:
970               raise
TypeError: in user code:
&lt;denchmark-code&gt;/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/mirrored_run.py:96 call_for_each_replica  *
    return _call_for_each_replica(strategy, fn, args, kwargs)

TypeError: tf__step_fn() takes 1 positional argument but 2 were given
&lt;/denchmark-code&gt;

c.) Using experimental_distribute_from_dataset_function
&lt;denchmark-code&gt;def get_dataset_fn():
  """Gets a closure to create a dataset.."""

  def _dataset_fn(input_context=None):
    """Returns tf.data.Dataset for distributed BERT pretraining."""
    batch_size = input_context.get_per_replica_batch_size(
                    BATCH_SIZE)
    print("batch_size", batch_size, input_context)
    print('---------------------------------------')
    d = train_dataset
    return d

  return _dataset_fn

input_fn = get_dataset_fn()
ds = iter(strategy.experimental_distribute_datasets_from_function(input_fn))


# Lets run a simple iteration

def train_with_tracing(ds):
  @tf.function(input_signature=None)
  def step_fn(inputs):
    # train the model with inputs
    return inputs
  # epochs
  for index in range(1000):
    replica_results = strategy.run(step_fn, args=(next(ds),))
    print(index)
    if index == 11:
      break

train_no_tracing(ds)

&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;TypeError: tf___call_for_each_replica() missing 1 required positional argument: 'kwargs'
&lt;/denchmark-code&gt;

Here is the gist for TF 2.2.0
&lt;denchmark-link:https://colab.research.google.com/gist/s4sarath/899d93bd5381efd34dffe9f89c2688a6/dataset_gpu.ipynb&gt;https://colab.research.google.com/gist/s4sarath/899d93bd5381efd34dffe9f89c2688a6/dataset_gpu.ipynb&lt;/denchmark-link&gt;

Here is the gist for TF 2.3 nightly
&lt;denchmark-link:https://colab.research.google.com/gist/s4sarath/f42fece3e4f217ee3c0b9a5873223160/dataset_gpu_nightly.ipynb&gt;https://colab.research.google.com/gist/s4sarath/f42fece3e4f217ee3c0b9a5873223160/dataset_gpu_nightly.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='19' author='mcoolsce' date='2020-06-07T03:39:09Z'>
		To give some idea about dataset, it is having same batch_size, but different inupt length in each batch. ( dynamic input , to avoid unnecessary padding ) . Thats what tracing is precisely using for I guess .
		</comment>
		<comment id='20' author='mcoolsce' date='2020-06-08T19:08:02Z'>
		thanks &lt;denchmark-link:https://github.com/s4sarath&gt;@s4sarath&lt;/denchmark-link&gt;
. &lt;denchmark-link:https://github.com/anj-s&gt;@anj-s&lt;/denchmark-link&gt;
 could you take a look at the attached colabs? This looks like a bug to me - it could likely be due to how we handle  passed to  that are annotated with tf.functions.
&lt;denchmark-link:https://github.com/s4sarath&gt;@s4sarath&lt;/denchmark-link&gt;
 one thing you could try right now is to put the call to  inside a tf.function and add the input signature to that. See this unit test here:


		</comment>
	</comments>
</bug>