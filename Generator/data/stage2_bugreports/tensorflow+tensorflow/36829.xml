<bug id='36829' author='hgaiser' open_date='2020-02-17T16:01:02Z' closed_time='2020-02-28T17:58:02Z'>
	<summary>[Keras] Fatal exception training a model with more outputs than targets from the generator</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 2.1.0
Python version: 3.8
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: NA
GPU model and memory: NA

Describe the current behavior
With eager execution enabled, the number of targets generated by the generator and the number of outputs produced by the model have to be the same. If there is a difference between the two, training fails with the following error:
ValueError: Unable to match target structure and sample_weight_modes structure:
  ...
    to  
  ['...', '...']
Describe the expected behavior
The example below should work whether using eager or non-eager execution.
Code to reproduce the issue Provide a reproducible test case that is the
bare minimum necessary to generate the problem.
import tensorflow as tf
import numpy as np

# This script works if v2 is disabled, but fails if v2 is enabled.
tf.compat.v1.disable_v2_behavior()

# Create a very simple generator.
class Generator(tf.keras.utils.Sequence):
	def __len__(self):
		return 1

	def __getitem__(self, index):
		return np.zeros((1, 100, 100)), np.zeros((1, 2))
generator = Generator()

# Create a simple model with two outputs, one has a loss attached to it the other does not.
inputs = tf.keras.Input((100, 100))
flattened = tf.keras.layers.Flatten()(inputs)
output_1 = tf.keras.layers.Dense(2, name='output_for_loss')(flattened)
output_2 = tf.keras.layers.Reshape((2, -1), name='some_other_output')(flattened)
model = tf.keras.Model(inputs=inputs, outputs=[output_1, output_2])
model.compile(loss={'output_for_loss': tf.keras.losses.binary_crossentropy})

# Train using the generator.
model.fit(generator)
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Complete traceback:
Traceback (most recent call last):
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py", line 329, in assert_same_structure
    _pywrap_utils.AssertSameStructure(nest1, nest2, check_types,
ValueError: The two structures don't have the same nested structure.

First structure: type=ndarray str=[[0. 0.]]

Second structure: type=tuple str=(None, None)

More specifically: Substructure "type=tuple str=(None, None)" is a sequence, while substructure "type=ndarray str=[[0. 0.]]" is not

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 1076, in broadcast_sample_weight_modes
    nest.assert_same_structure(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py", line 334, in assert_same_structure
    raise type(e)("%s\n"
ValueError: The two structures don't have the same nested structure.

First structure: type=ndarray str=[[0. 0.]]

Second structure: type=tuple str=(None, None)

More specifically: Substructure "type=tuple str=(None, None)" is a sequence, while substructure "type=ndarray str=[[0. 0.]]" is not
Entire first structure:
.
Entire second structure:
(., .)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 1087, in broadcast_sample_weight_modes
    sample_weight_modes = nest.pack_sequence_as(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py", line 504, in pack_sequence_as
    return _pack_sequence_as(structure, flat_sequence, expand_composites)
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py", line 448, in _pack_sequence_as
    raise ValueError(
ValueError: The target structure is of type `&lt;class 'numpy.ndarray'&gt;`
  [[0. 0.]]
However the input structure is a sequence (&lt;class 'list'&gt;) of length 2.
  [None, None]
nest cannot guarantee that it is safe to map one to the other.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test.py", line 25, in &lt;module&gt;
    model.fit(generator)
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py", line 800, in fit
    return func.fit(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 219, in fit
    training_data_adapter, validation_adapter = _process_training_inputs(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 579, in _process_training_inputs
    train_adapter = _process_inputs(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py", line 693, in _process_inputs
    adapter = adapter_cls(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 945, in __init__
    super(KerasSequenceAdapter, self).__init__(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 752, in __init__
    ) = self._canonicalize_peek(peek, kwargs.get("sample_weight_modes"))
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 806, in _canonicalize_peek
    sample_weight_modes = broadcast_sample_weight_modes(
  File "/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py", line 1093, in broadcast_sample_weight_modes
    raise ValueError(
ValueError: Unable to match target structure and sample_weight_modes structure:
  ...
    to  
  ['...', '...']
This issue seems to be introduced in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/ac20030c96d37e980333b604402ef6dba48ef5e2&gt;ac20030&lt;/denchmark-link&gt;
 .
	</description>
	<comments>
		<comment id='1' author='hgaiser' date='2020-02-18T09:54:57Z'>
		&lt;denchmark-link:https://github.com/hgaiser&gt;@hgaiser&lt;/denchmark-link&gt;

I tried to reproduce the issue in colab with TF 2.1 by enabling and disabling v2_behavior. I am not seeing any error message.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/d80d5b3723420971b154409e66cc6e86/untitled645.ipynb&gt;here&lt;/denchmark-link&gt;
. Is this the expected behavior? Thanks!
		</comment>
		<comment id='2' author='hgaiser' date='2020-02-18T10:20:24Z'>
		Hey, it looks like you didn't enable V2 in one of the two blocks. Could you
try that?

EDIT: Upon further inspection, seems that in the second block you didn't call `tf.compat.v1.enable_v2_behavior` because it was missing parenthesis at the end.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, 18 Feb 2020, 10:55 ravikyram, ***@***.***&gt; wrote:
 @hgaiser &lt;https://github.com/hgaiser&gt;

 I tried to reproduce the issue in colab with TF 2.1 by enabling and
 disabling v2_behavior. I am not seeing any error message.Please, find the
 gist here
 &lt;https://colab.sandbox.google.com/gist/ravikyram/d80d5b3723420971b154409e66cc6e86/untitled645.ipynb&gt;.
 Is this the expected behavior? Thanks!

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#36829?email_source=notifications&amp;email_token=AAFO22XPTY2IYEEORBVXLFTRDOV7VA5CNFSM4KWULM42YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMBKFLY#issuecomment-587375279&gt;,
 or unsubscribe
 &lt;https://github.com/notifications/unsubscribe-auth/AAFO22RGEGCJSIYLIW47P3LRDOV7VANCNFSM4KWULM4Q&gt;
 .



		</comment>
		<comment id='3' author='hgaiser' date='2020-02-18T10:59:04Z'>
		I slightly changed your example:
&lt;denchmark-link:https://colab.research.google.com/gist/hgaiser/222f71b25e2cd3c7479931f59af5e757/untitled0.ipynb&gt;https://colab.research.google.com/gist/hgaiser/222f71b25e2cd3c7479931f59af5e757/untitled0.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='hgaiser' date='2020-02-19T07:06:31Z'>
		I tried to reproduce the issue in colab with &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/4cf7cbc1f16674a7c0c96f58601a9017/untitled0.ipynb&gt;TF 2.1 gist&lt;/denchmark-link&gt;
 ,&lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/bb51b125d818125a6d2b147ec69671f3/untitled649.ipynb&gt;TF 2.2.0-dev20200218 gist&lt;/denchmark-link&gt;
 and was able to reproduce the issue.Thanks!
		</comment>
		<comment id='5' author='hgaiser' date='2020-02-25T03:17:41Z'>
		Any progress with this? I need to train with multiple outputs and losses@@
		</comment>
		<comment id='6' author='hgaiser' date='2020-02-28T17:58:01Z'>
		&lt;denchmark-link:https://github.com/hgaiser&gt;@hgaiser&lt;/denchmark-link&gt;
 Thanks for the issue!
This is fixed in the latest tf-nightly: pip install -U tf-nightly
		</comment>
		<comment id='7' author='hgaiser' date='2020-02-28T17:58:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36829&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36829&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>