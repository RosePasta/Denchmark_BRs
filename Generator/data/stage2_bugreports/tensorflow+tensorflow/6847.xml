<bug id='6847' author='bodokaiser' open_date='2017-01-14T08:29:25Z' closed_time='2019-11-12T06:32:30Z'>
	<summary>Better documentation for tf.extract_image_patches</summary>
	<description>
In this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6743#issuecomment-272525783&gt;issue&lt;/denchmark-link&gt;
 someone requested a reverse operation to . The comments suggest that there exists a &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_grad.py#L575&gt;gradient operation&lt;/denchmark-link&gt;
 for this purpose which was added with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/3672&gt;this PR&lt;/denchmark-link&gt;
.
Unfortunately it is not obvious how to apply this gradient operation and there are no information on this in the &lt;denchmark-link:https://www.tensorflow.org/versions/master/api_docs/python/array_ops/slicing_and_joining#extract_image_patches&gt;api docs&lt;/denchmark-link&gt;
 therefor I request to add an example to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a4c8df209d7413068f4ed3e71c43eb798fbd5580/tensorflow/g3doc/api_docs/python/functions_and_classes/shard4/tf.extract_image_patches.md&gt;tf.extract_image_patches&lt;/denchmark-link&gt;
 where one transforms an  tensor of shape  to  and vice versa.
Thank you in advance!
	</description>
	<comments>
		<comment id='1' author='bodokaiser' date='2017-01-15T22:28:10Z'>
		&lt;denchmark-link:https://github.com/dr4b&gt;@dr4b&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
 Want to bring to your attention that two users have requested better documentation for ExtractImagePatches, which currently has a one-liner doc. I think more accessible documentation is always a good thing. I've marked it "contributions welcome" but feel free to self-assign if it's something you're interested in doing.
		</comment>
		<comment id='2' author='bodokaiser' date='2017-06-16T18:06:35Z'>
		&lt;denchmark-link:https://github.com/wolffg&gt;@wolffg&lt;/denchmark-link&gt;
 This still seems to be an issue. Could you take a look?
		</comment>
		<comment id='3' author='bodokaiser' date='2017-06-26T16:28:12Z'>
		&lt;denchmark-link:https://github.com/wolffg&gt;@wolffg&lt;/denchmark-link&gt;
 Is it possible to use tf.extract_image_patches as a not-trainable 2d convolution layer? how will the loss be computed with mixed tf.extract_image_patches and 2d convolutions?
		</comment>
		<comment id='4' author='bodokaiser' date='2017-06-27T19:02:32Z'>
		I think &lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
 is more likely to be able to clear this up than I.
		</comment>
		<comment id='5' author='bodokaiser' date='2017-06-27T20:33:48Z'>
		&lt;denchmark-link:https://github.com/agniszczotka&gt;@agniszczotka&lt;/denchmark-link&gt;
: if you don't want to have backprop through extract_image_patches, wrap the output of tf.extract_image_patches() in tf.stop_gradient().
I think there's two issues being conflated here:


extract_image_patches doesn't have good documentation, and should be improved.  I would love one of the authors or maintainers of this code to add some.  @gpapan and @benoitsteiner ?


It sounds like people want access to the gradient function of tf.extract_image_patches() without having to use it as a gradient (essentially a reduction) as part of the API with corresponding documentation.  This is similar to people who want 'deconvolution' (the backward pass of convolution) as its own API.  Such a feature is possible just like with deconvolution, it just requires writing the code and exposing it in the API after getting API approval.


		</comment>
		<comment id='6' author='bodokaiser' date='2017-11-03T16:23:22Z'>
		&lt;denchmark-link:https://github.com/vrv&gt;@vrv&lt;/denchmark-link&gt;
  "2. It sounds like people want access to the gradient function of tf.extract_image_patches() without having to use it as a gradient (essentially a reduction). This is similar to people who want 'deconvolution' (the backward pass of convolution) as its own API. "
This is a quite common use-case for many ops even  beyond 'deconvolution'  and 'extract_image_patches()'. Do you think it would be possible to great a general API, which lets you (easily) evaluate any op  (or even subgraph) backwards?
The api could work similar to pytorchs .backward() call which can be applied to subgraphs.
		</comment>
		<comment id='7' author='bodokaiser' date='2017-11-03T16:45:35Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 What do you think?
The equivalent of .backward() might be exposing ops.get_gradient_function(), and would provide a mechanism to get the gradient of an op, but not as part of a documented API.  Perhaps that is good enough though?
		</comment>
		<comment id='8' author='bodokaiser' date='2017-11-03T16:53:50Z'>
		You can get the equivalent of .backward() now for any tf op by doing something like tfe.gradients_function(tf.extract_image_patches)(arguments_to_image_patches ,..., dy=arguments_to_the_gradient_function) if tf.extract_image_patches has a gradient defined. When executing graphs this will only compute the forward pass if the backward function needs it (like how the gradient of exp or the gradient of relu uses the output of relu).
		</comment>
		<comment id='9' author='bodokaiser' date='2017-12-20T19:26:41Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='10' author='bodokaiser' date='2018-01-04T19:18:19Z'>
		It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.
		</comment>
		<comment id='11' author='bodokaiser' date='2018-01-24T13:19:08Z'>
		Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the contributions welcome label. Thank you.
		</comment>
		<comment id='12' author='bodokaiser' date='2019-11-12T06:32:30Z'>
		Closing this issue, as tf.extract_image_patches is no longer supported in TensorFlow 2.0.
		</comment>
		<comment id='13' author='bodokaiser' date='2019-12-06T05:04:11Z'>
		&lt;denchmark-link:https://github.com/dynamicwebpaige&gt;@dynamicwebpaige&lt;/denchmark-link&gt;
 The reason for closing it is not valid because  is not removed but just renamed to . I suggest edit the tile to "reverse op for " rather than closing it. This is not solved yet.
		</comment>
	</comments>
</bug>