<bug id='43043' author='SimonWeitzhofer' open_date='2020-09-08T11:57:20Z' closed_time='2020-12-14T16:53:42Z'>
	<summary>GradientTape.batch_jacobian returns the wrong type in case of constant functions</summary>
	<description>
System information
Google Colaboratory with TF 2.3.0, git version v2.3.0-0-gb36436b087
Describe the current behavior
tf.GradientTape.batch_jacobian of a constant function with return type float64 returns a zero matrix of type float32
Describe the expected behavior
return a zero matrix of type float64
Standalone code to reproduce the issue
&lt;denchmark-code&gt;@tf.function
def foo(val):
  return tf.constant([[3.0],[4.0]],dtype=tf.dtypes.float64)

c = tf.constant([[1.],[2.]],dtype=tf.dtypes.float64)
with tf.GradientTape() as g:
			g.watch(c)
			f = foo(c)

print(g.batch_jacobian(f,c)) 
&lt;/denchmark-code&gt;

Other info / logs
Workaround: setting the option unconnected_gradients to 'zero'
&lt;denchmark-code&gt;@tf.function
def foo(val):
  return tf.constant([[3.0],[4.0]],dtype=tf.dtypes.float64)

c = tf.constant([[1.],[2.]],dtype=tf.dtypes.float64)
with tf.GradientTape() as g:
			g.watch(c)
			f = foo(c)

print(g.batch_jacobian(f,c,unconnected_gradients='zero'))
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='SimonWeitzhofer' date='2020-09-08T12:16:24Z'>
		I have tried in colab with TF versions 2.3, nightly versions() and was able to reproduce the issue. Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/35d2bc5bc15e34e22c1ce942dbb92918/untitled324.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='SimonWeitzhofer' date='2020-09-08T12:34:41Z'>
		If you let interact the watched c with f it will return the correct dtype:
&lt;denchmark-code&gt;with tf.GradientTape() as g:
      c = tf.constant([[3.],[2.]],dtype=tf.dtypes.float64)
      g.watch(c)
      f = foo()*c
      print(f)
print(c)
print(g.batch_jacobian(f,c))
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='SimonWeitzhofer' date='2020-11-25T18:46:44Z'>
		&lt;denchmark-link:https://github.com/SimonWeitzhofer&gt;@SimonWeitzhofer&lt;/denchmark-link&gt;
 Can you please check &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 suggestion and let us know whether the issue resolved for you. Thanks!
		</comment>
		<comment id='4' author='SimonWeitzhofer' date='2020-11-26T07:39:09Z'>
		The function f in &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 suggestion is not constant anymore. So, no, if the suggestion is not to use constant functions, then I don't think this is a proper solution.
Actually there is a workaround, namely setting unconnected_gradients='zero' as described in the bug-report.
I would be ok with tensorflow returning None or throwing an exception. Returning a float32 tensor, however, seems wrong to me.
		</comment>
		<comment id='5' author='SimonWeitzhofer' date='2020-11-26T13:07:02Z'>
		Mine was not a solution it was just to check that when it is not constant anymore the dtype is working correctly.
You problem is related that in the default case unconnect_gradients='null' we are not handling any specific dtype on the source.



tensorflow/tensorflow/python/eager/pywrap_tfe_src.cc


        Lines 2804 to 2814
      in
      31f0b21






 if (unconnected_gradients_zero) { 



 // generate a zeros tensor in the shape of sources[i] 



   tensorflow::DataType dtype = 



 tensorflow::PyTensor_DataType(sources_obj[i]); 



   PyTapeTensor tensor = 



 PyTapeTensor(sources_vec[i], dtype, sources_obj[i]); 



   result[i] = tensor.ZerosLike(); 



 } else { 



 Py_INCREF(Py_None); 



   result[i] = Py_None; 



 } 





/cc &lt;denchmark-link:https://github.com/edloper&gt;@edloper&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='SimonWeitzhofer' date='2020-12-14T16:53:43Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43043&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43043&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>