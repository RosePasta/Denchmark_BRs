<bug id='32544' author='isaacgerg' open_date='2019-09-15T17:46:18Z' closed_time='2019-12-17T03:33:54Z'>
	<summary>tf.keras batch normalization is batch dependent at test time</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.13
Python version: 3.7
CUDA/cuDNN version: 10
GPU model and memory: RTX

Describe the current behavior
When doing inference using tf.keras batchnormalization,  for a given input sample x, the output is dependent on the other samples in the batch.  I can modify the other samples in the batch to influence the output of x.  This should not be the case as all samples should be processed independently.  Whether I run a sample x as a batch size of 1 or with other samples, its output should be exactly the same.  I am seeing differences of 0.3 at times (see my output below).
It appears keras is also having this issue: &lt;denchmark-link:https://github.com/keras-team/keras/issues/12400&gt;keras-team/keras#12400&lt;/denchmark-link&gt;

Describe the expected behavior
Upon using tf.keras batch normalization at test time, a given input sample x should have the same output regardless of the other samples in the batch
Code to reproduce the issue
Note: I put the code into colab and was able to verify the bug.
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

input1 = tf.keras.layers.Input(shape=(128,128,1))
x = tf.keras.layers.BatchNormalization()(input1)
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(5, activation = 'softmax')(x)

model = tf.keras.models.Model(input1, x)

batchSize = 64
x = np.random.rand(1, 128,128,1)
x = np.repeat(x, batchSize, axis=0)

print('The following rows should all be equal...')
for k in range(1, batchSize):  
    y = model.predict(x[0:k,:,:,:], batch_size=8)
    print(y[0,:])
&lt;/denchmark-code&gt;

I get the following output:
&lt;denchmark-code&gt;The following rows should all be equal...
2019-09-15 16:46:29.463998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-09-15 16:46:29.463998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-15 16:46:29.463998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-09-15 16:46:29.463998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-09-15 16:46:29.464999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11334 MB memory) -&gt; physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1)
2019-09-15 16:46:30.597112: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library cublas64_100.dll locally
[0.38215435 0.66578805 0.45068434 0.85698235 0.7698223 ]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215438 0.66578805 0.45068428 0.85698223 0.76982236]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
[0.38215443 0.66578794 0.4506843  0.85698223 0.76982224]
&lt;/denchmark-code&gt;

When i run on the CPU, the problem goes away.
When I run on my own data, I get the following code / output which shows the problem more severely:
&lt;denchmark-code&gt;    x,y = testGenerator.next(0)
    score = []
    for kk in range(1, 16):
        s = model.predict(x[0:kk,:,:,:])
        print(s[0][0,:])
&lt;/denchmark-code&gt;

Gives output...
&lt;denchmark-code&gt;[9.3195647e-01 4.5844557e-04 6.6464258e-05 6.7509413e-02 2.0588086e-06
 1.3121526e-06 1.7270798e-06 2.0374323e-06 2.1472629e-06]
[9.3195647e-01 4.5844595e-04 6.6464192e-05 6.7509346e-02 2.0587986e-06
 1.3121462e-06 1.7270781e-06 2.0374266e-06 2.1472567e-06]
[9.3195623e-01 4.5845023e-04 6.6464687e-05 6.7509525e-02 2.0588097e-06
 1.3121534e-06 1.7270876e-06 2.0374339e-06 2.1472645e-06]
[9.1518945e-01 5.7900354e-04 8.6429020e-05 8.4134214e-02 2.4391386e-06
 1.5495950e-06 2.0541604e-06 2.3649241e-06 2.5034813e-06]
[9.1518945e-01 5.7900301e-04 8.6429180e-05 8.4134296e-02 2.4391431e-06
 1.5496009e-06 2.0541527e-06 2.3649197e-06 2.5034813e-06]
[9.1442782e-01 5.8447709e-04 8.7354209e-05 8.4889315e-02 2.4558769e-06
 1.5600473e-06 2.0685882e-06 2.3791872e-06 2.5190409e-06]
[9.1442782e-01 5.8447709e-04 8.7354209e-05 8.4889315e-02 2.4558769e-06
 1.5600473e-06 2.0685882e-06 2.3791872e-06 2.5190409e-06]
[9.1442782e-01 5.8447709e-04 8.7354209e-05 8.4889315e-02 2.4558769e-06
 1.5600473e-06 2.0685882e-06 2.3791872e-06 2.5190409e-06]
[9.1442782e-01 5.8447709e-04 8.7354209e-05 8.4889315e-02 2.4558769e-06
 1.5600473e-06 2.0685882e-06 2.3791872e-06 2.5190409e-06]
[2.7099210e-01 5.2615767e-03 1.4831917e-03 7.2222257e-01 9.9957060e-06
 6.1737474e-06 8.7498120e-06 7.3227852e-06 8.3933583e-06]
[2.7099210e-01 5.2615767e-03 1.4831917e-03 7.2222257e-01 9.9957060e-06
 6.1737474e-06 8.7498120e-06 7.3227852e-06 8.3933583e-06]
[2.7099210e-01 5.2615767e-03 1.4831917e-03 7.2222257e-01 9.9957060e-06
 6.1737474e-06 8.7498120e-06 7.3227852e-06 8.3933583e-06]
[2.7099210e-01 5.2615767e-03 1.4831917e-03 7.2222257e-01 9.9957060e-06
 6.1737474e-06 8.7498120e-06 7.3227852e-06 8.3933583e-06]
[2.7099210e-01 5.2615767e-03 1.4831917e-03 7.2222257e-01 9.9957060e-06
 6.1737474e-06 8.7498120e-06 7.3227852e-06 8.3933583e-06]
[1.9735371e-01 5.5795610e-03 1.7620743e-03 7.9526496e-01 9.8536966e-06
 6.0714729e-06 8.6973323e-06 7.0008568e-06 8.0944292e-06]
&lt;/denchmark-code&gt;

EDIT 1: Added code to replicate issue.  Also, If you remove the batch norm, the problem still persists.
EDIT 2: Displayed results from running on my own data.
	</description>
	<comments>
		<comment id='1' author='isaacgerg' date='2019-09-16T08:43:34Z'>
		&lt;denchmark-link:https://github.com/isaacgerg&gt;@isaacgerg&lt;/denchmark-link&gt;
, I could execute the code in colab. Please take a look at colab &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/ccbd9e29de1c4dd5cf591c08b18bbe41/untitled151.ipynb&gt;gist&lt;/denchmark-link&gt;
 and confirm the expected behavior. Thanks!
		</comment>
		<comment id='2' author='isaacgerg' date='2019-09-16T13:41:58Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 Yes, that gist looks correct.  For the run I did, the first 2 rows were not identical.
		</comment>
		<comment id='3' author='isaacgerg' date='2019-09-16T15:12:24Z'>
		Coming from &lt;denchmark-link:https://github.com/keras-team/keras/issues/12400&gt;keras-team/keras#12400&lt;/denchmark-link&gt;

I can verify that the rows are not equal for me. I tried multiple times, it is not equal.
		</comment>
		<comment id='4' author='isaacgerg' date='2019-09-16T19:06:48Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 I am able to replicate the error exactly when fixing the RNG seeds.
&lt;denchmark-code&gt;import random
import tensorflow as tf
import numpy as np

tf.keras.backend.clear_session()
random.seed(1)
np.random.seed(1)
tf.random.set_random_seed(1) 
input1 = tf.keras.layers.Input(shape=(128,128,1))
#x = tf.keras.layers.BatchNormalization()(input1)
x = tf.keras.layers.Flatten()(input1)
x = tf.keras.layers.Dense(5, activation = 'softmax')(x)

model = tf.keras.models.Model(input1, x)

batchSize = 32
x = np.random.rand(1, 128,128,1)
x = np.repeat(x, batchSize, axis=0)

print('The following rows should all be equal...')
for k in range(1, batchSize):  
    y = model.predict(x[0:k,:,:,:], batch_size=8)
    print(y[0,:])
&lt;/denchmark-code&gt;

In colab, i get the following snippet...
&lt;denchmark-code&gt;The following rows should all be equal...
[0.06958179 0.13309403 0.07133754 0.45234346 0.27364326]
[0.06958182 0.13309415 0.07133748 0.45234346 0.27364317]
[0.06958182 0.13309413 0.07133747 0.4523434  0.27364317]
[0.06958182 0.13309413 0.07133747 0.4523434  0.27364317]
[0.06958182 0.13309413 0.07133747 0.4523434  0.27364317]
[0.06958182 0.13309413 0.07133747 0.4523434  0.27364317]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
[0.06958179 0.13309415 0.07133748 0.45234346 0.2736431 ]
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='isaacgerg' date='2019-09-17T06:33:56Z'>
		&lt;denchmark-link:https://github.com/isaacgerg&gt;@isaacgerg&lt;/denchmark-link&gt;
, Can you please share the colab gist here. Thanks!
		</comment>
		<comment id='6' author='isaacgerg' date='2019-09-17T13:19:37Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;

&lt;denchmark-link:https://colab.research.google.com/gist/isaacgerg/b6c6727a768744383359a2faf8c946d7/tfkeras_bug1.ipynb&gt;https://colab.research.google.com/gist/isaacgerg/b6c6727a768744383359a2faf8c946d7/tfkeras_bug1.ipynb&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='isaacgerg' date='2019-09-17T17:35:28Z'>
		&lt;denchmark-link:https://github.com/twinanda&gt;@twinanda&lt;/denchmark-link&gt;
 have you come up with a fix?
		</comment>
		<comment id='8' author='isaacgerg' date='2019-09-30T08:14:19Z'>
		&lt;denchmark-link:https://github.com/isaacgerg&gt;@isaacgerg&lt;/denchmark-link&gt;
 no, unfortunately not. I am looking into other normalization methods for this. Maybe instancenorm might yield similar convergence, without the inconsistency of batchnorm. Let me know if you find something on your side. :)
		</comment>
		<comment id='9' author='isaacgerg' date='2019-11-11T17:15:42Z'>
		I believe I've figured it out, but no one will like the verdict, myself included: the problem is , and  has nothing to do with it. It's a work in progress, but I've narrowed down the exact operation responsible:  - you can follow the work &lt;denchmark-link:https://stackoverflow.com/questions/58740925/why-is-np-dot-imprecise-n-dim-arrays&gt;here&lt;/denchmark-link&gt;
. Will update later with all relevant testing code, and a solution. I've also made &lt;denchmark-link:https://github.com/keras-team/keras/issues/12400&gt;OP's&lt;/denchmark-link&gt;
 images into a gif for direct comparison:
&lt;denchmark-link:https://camo.githubusercontent.com/15ede1976618ad60f111cf70706faf58a8a69445ea03cba87953917846fe0251/68747470733a2f2f692e737461636b2e696d6775722e636f6d2f6e4f7149472e676966&gt;&lt;/denchmark-link&gt;

(P.S. removing BatchNormalization in your tests may "solve" the problem, but it's not BN that's problematic, but how it transforms input tensor dimensionalities - will clarify later)
		</comment>
		<comment id='10' author='isaacgerg' date='2019-11-11T17:50:51Z'>
		&lt;denchmark-link:https://github.com/OverLordGoldDragon&gt;@OverLordGoldDragon&lt;/denchmark-link&gt;
 Thanks for following up.  I wonder if this is the same issue found with softmax here: &lt;denchmark-link:https://github.com/keras-team/keras/issues/13328&gt;keras-team/keras#13328&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='isaacgerg' date='2019-12-17T03:33:54Z'>
		I'm inclined to agree that this looks like normal floating point variability. Thanks for the analysis everyone.
		</comment>
		<comment id='12' author='isaacgerg' date='2019-12-17T03:33:56Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32544&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32544&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>