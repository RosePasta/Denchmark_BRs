<bug id='38708' author='pascalisnala' open_date='2020-04-20T13:45:39Z' closed_time='2020-05-11T01:54:28Z'>
	<summary>LSTM Keras conversion to tflite model work fine. But the MLkit firebase ml model interpreter error on loading model</summary>
	<description>
System information

OS Platform: Google Colab, Android 9 (Poco F1)
TensorFlow installed from (source or binary): binary
TensorFlow version (or github SHA if from source): 2.2.0-rc3
firebase ml model interpreter version: firebase-ml-model-interpreter:22.0.2

I used this following code to produce my LSTM model
&lt;denchmark-code&gt;model = Sequential()
model.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=X.shape[1:]))
model.add(Dropout(0.1))
model.add(BatchNormalization())

model.add(Dense(64, activation="relu"))
model.add(Dropout(0.2))

model.add(Dense(1, activation="sigmoid"))

opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)
model.compile(loss="binary_crossentropy",
             optimizer=opt,
             metrics=["accuracy"])
&lt;/denchmark-code&gt;

Command used to run the converter or code if you’re using the Python API
&lt;denchmark-code&gt;converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
&lt;/denchmark-code&gt;

Failure details
the conversion run just fine, no error and I can download the TFlite model. However, when I tried to put this model into my android app, it shows error caused by Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model.
I think if the conversion to tflite model is successful, we should be able to run it on the interpreter
Any other info / logs
here is the full logs of the error
&lt;denchmark-code&gt;E/ModelResourceManager: Error preloading model resource
    com.google.firebase.ml.common.FirebaseMLException: Local model load failed with the model options: Local model path: drowsy-detector-v21.tflite. Remote model name: unspecified. 
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:36)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111)
        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107)
        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53)
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7)
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24)
        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32)
        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6)
        at android.os.Looper.loop(Looper.java:201)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model
        at org.tensorflow.lite.NativeInterpreterWrapper.createModelWithBuffer(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.&lt;init&gt;(NativeInterpreterWrapper.java:59)
        at org.tensorflow.lite.Interpreter.&lt;init&gt;(Interpreter.java:207)
        at com.google.android.gms.internal.firebase_ml.zzrj.zzb(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:174)
        at com.google.android.gms.internal.firebase_ml.zzrl.zzc(Unknown Source:0)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:170)
        at com.google.android.gms.internal.firebase_ml.zzrk.zza(Unknown Source:6)
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zzb(com.google.firebase:firebase-ml-common@@22.1.0:61)
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:21)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111) 
        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107) 
        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53) 
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7) 
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24) 
        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32) 
        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4) 
        at android.os.Handler.handleCallback(Handler.java:873) 
        at android.os.Handler.dispatchMessage(Handler.java:99) 
        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='pascalisnala' date='2020-04-26T03:17:51Z'>
		any update on this?
		</comment>
		<comment id='2' author='pascalisnala' date='2020-05-07T05:57:39Z'>
		&lt;denchmark-link:https://github.com/pascalisnala&gt;@pascalisnala&lt;/denchmark-link&gt;
 We also announced support for TF 2.0 Keras LSTM To fused TFLite LSTM. Please see
&lt;denchmark-link:https://groups.google.com/a/tensorflow.org/g/tflite/c/Ub4apUvblN8&gt;https://groups.google.com/a/tensorflow.org/g/tflite/c/Ub4apUvblN8&lt;/denchmark-link&gt;

Do you want to try this out?
		</comment>
		<comment id='3' author='pascalisnala' date='2020-05-11T01:54:29Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38708&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38708&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>