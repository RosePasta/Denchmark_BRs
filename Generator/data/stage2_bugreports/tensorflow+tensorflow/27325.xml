<bug id='27325' author='willbattel' open_date='2019-03-30T22:06:25Z' closed_time='2020-01-06T04:34:53Z'>
	<summary>TFLite delegates/gpu/libmetal_delegate.a is missing</summary>
	<description>
Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave (10.14.1)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): Not installed.
TensorFlow version: master branch (latest commit 6353d94)
Python version: 3.7.2
Installed using virtualenv? pip? conda?: Not installed, just calling shell scripts from repo
Bazel version (if compiling from source): 0.18.0
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the problem
Attempting to build iOS Metal TFLite Delegate with create_ios_frameworks.sh yields the following error:
&lt;denchmark-code&gt;$ tensorflow/lite/lib_package/create_ios_frameworks.sh -g
Starting
File /path/to/tensorflow/tensorflow/lite/lib_package/../delegates/gpu/libmetal_delegate.a doesn't exist.
It's requried for building TFLite Framework with GPU. Aborting.
&lt;/denchmark-code&gt;

Provide the exact sequence of commands / steps that you executed before running into the problem
This is how I am attempting to create the iOS framework:
&lt;denchmark-code&gt;$ tensorflow/lite/tools/make/download_dependencies.sh
$ tensorflow/lite/tools/make/build_ios_universal_lib.sh
$ tensorflow/lite/lib_package/create_ios_frameworks.sh -g
&lt;/denchmark-code&gt;

I saw that the  flag got added to  in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/59d535a0df17eaf3033bbff73ef4e1e1988c454e&gt;59d535a&lt;/denchmark-link&gt;
. Without the flag, I am able to successfully build the framework but, as expected, the GPU is not utilized.
I know the GPU delegates only got open-sourced a couple of days ago, and before that I had unsurprisingly been getting the same error but with , which was added in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/fb772b781b011471dec443e1f3cd6b664958b767&gt;fb772b7&lt;/denchmark-link&gt;
. Is  supposed to be present or is it still pending open-sourcing?
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
N/A
	</description>
	<comments>
		<comment id='1' author='willbattel' date='2019-04-02T12:58:49Z'>
		With one line modification to
diff --git a/tensorflow/lite/delegates/gpu/metal_delegate.mm b/tensorflow/lite/delegates/gpu/metal_delegate.mm
index 66bfb043e5..b71881b73f 100644
--- a/tensorflow/lite/delegates/gpu/metal_delegate.mm
+++ b/tensorflow/lite/delegates/gpu/metal_delegate.mm
@@ -23,7 +23,7 @@
 #include &lt;string&gt;
 #include &lt;vector&gt;
 
-#include "third_party/absl/types/span.h"
+#include "absl/types/span.h"
 #include "tensorflow/lite/builtin_ops.h"
 #include "tensorflow/lite/c/c_api_internal.h"
 #include "tensorflow/lite/delegates/gpu/common/convert.h"
With something like
bazel build --apple_platform_type ios --ios_multi_cpus=arm64 \
tensorflow/lite/delegates/gpu:metal_delegate
you can get arm64 bazel-tensorflow/bazel-out/apl-ios_arm64-opt/bin/tensorflow/lite/delegates/gpu/libmetal_delegate.a.
		</comment>
		<comment id='2' author='willbattel' date='2019-04-03T04:38:24Z'>
		&lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;
 thank you, your solution did work. After modifying  I was able to build  which allowed  to run with the  flag.
This issue should probably remain open until this workaround is no longer necessary.
		</comment>
		<comment id='3' author='willbattel' date='2019-04-03T13:31:55Z'>
		I sent a PR just now :-)
		</comment>
		<comment id='4' author='willbattel' date='2019-06-21T09:19:02Z'>
		&lt;denchmark-link:https://github.com/fredbertsch&gt;@fredbertsch&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/59912414-8e737c00-9448-11e9-8e6a-04ecb53303f2.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/59912439-97fce400-9448-11e9-9acf-c8d408694f3b.png&gt;&lt;/denchmark-link&gt;

what was wrong ?
		</comment>
		<comment id='5' author='willbattel' date='2019-06-22T10:14:11Z'>
		&lt;denchmark-link:https://github.com/weinixuehao&gt;@weinixuehao&lt;/denchmark-link&gt;
 How did you build your ? iPhone emulator is x86_64 based, make sure you have x86_64 stuff in it.
		</comment>
		<comment id='6' author='willbattel' date='2019-06-24T08:06:49Z'>
		&lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;

I built with below commands
&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/60001804-ddfcb680-9699-11e9-97e9-2285c27e62de.png&gt;&lt;/denchmark-link&gt;

arm64 and x86_64 is ok but i need armv7 armv7s as my xcode project valid architecture is
&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/60001879-0edceb80-969a-11e9-9f8b-233b304b18c0.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='willbattel' date='2019-06-24T08:39:19Z'>
		interesting, why do you need 32-bit binaries? iPhone 6s has 64-bit CPUs. I think you can simply remove armv7 and armv7s. Anyway, something like
&lt;denchmark-code&gt;build --apple_platform_type ios --ios_multi_cpus=armv7 
//tensorflow/lite/delegates/gpu:metal_delegate 
&lt;/denchmark-code&gt;

should work. And as far as I can remember bazel doesn't support armv7s.
		</comment>
		<comment id='8' author='willbattel' date='2019-06-24T14:20:57Z'>
		&lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;

I am newbie to ios and tensorflowlite binary like
&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/60025814-ffc36100-96cc-11e9-8b59-b23825a1f983.png&gt;&lt;/denchmark-link&gt;

So i am worried the following two problems.
1、if metal_delegate binary only arm64 will cause compilation problems?
2、iphone5 has 32-bit CPUS will cause crash problems?
Why tensorflowlite has armv7, armv7s, arm64 ... but metal_delegate only has arm64 is OK?
I`m very puzzled!
		</comment>
		<comment id='9' author='willbattel' date='2019-06-24T14:38:01Z'>
		I don't think Metal (the API) supports iOS devices older than A7 (iPhone 5s). That is, there is no reason to worry about iPhone 5 (A6).
		</comment>
		<comment id='10' author='willbattel' date='2019-06-24T14:49:01Z'>
		&lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;

Thanks!
Please help me debug this issue If you have enough time.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/29864&gt;#29864&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='willbattel' date='2019-06-25T03:42:43Z'>
		&lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;

It need too many dependency libs after reference metal lib otherwise throw undefined symbol ...
Why bazel do not merge to one lib after built successfully? Maybe bazel has this option but i do not know
&lt;denchmark-link:https://user-images.githubusercontent.com/17869361/60067704-4dc47d00-973e-11e9-9b5b-910ca61a1492.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='willbattel' date='2019-07-31T03:08:30Z'>
		&lt;denchmark-link:https://github.com/weinixuehao&gt;@weinixuehao&lt;/denchmark-link&gt;
 instead of building the bazel target , build  — this gives you a single archive file with all dependencies included. &lt;denchmark-link:https://docs.bazel.build/versions/master/be/objective-c.html#objc_library_implicit_outputs&gt;https://docs.bazel.build/versions/master/be/objective-c.html#objc_library_implicit_outputs&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='willbattel' date='2019-10-30T13:38:35Z'>
		
With one line modification to
diff --git a/tensorflow/lite/delegates/gpu/metal_delegate.mm b/tensorflow/lite/delegates/gpu/metal_delegate.mm
index 66bfb043e5..b71881b73f 100644
--- a/tensorflow/lite/delegates/gpu/metal_delegate.mm
+++ b/tensorflow/lite/delegates/gpu/metal_delegate.mm
@@ -23,7 +23,7 @@
 #include &lt;string&gt;
 #include &lt;vector&gt;
 
-#include "third_party/absl/types/span.h"
+#include "absl/types/span.h"
 #include "tensorflow/lite/builtin_ops.h"
 #include "tensorflow/lite/c/c_api_internal.h"
 #include "tensorflow/lite/delegates/gpu/common/convert.h"
With something like
bazel build --apple_platform_type ios --ios_multi_cpus=arm64 \
tensorflow/lite/delegates/gpu:metal_delegate
you can get arm64 bazel-tensorflow/bazel-out/apl-ios_arm64-opt/bin/tensorflow/lite/delegates/gpu/libmetal_delegate.a.

I run the command below :
&lt;denchmark-code&gt;bazel build --apple_platform_type ios --ios_multi_cpus=arm64 \
tensorflow/lite/delegates/gpu:metal_delegate
&lt;/denchmark-code&gt;

but there is an error like this :
'@local_config_cc//:toolchain' does not contain a toolchain for cpu 'ios_arm64'
Could you tell me how to fix it ? thx a lot
		</comment>
		<comment id='14' author='willbattel' date='2020-01-06T04:34:53Z'>
		
Could you tell me how to fix it ? thx a lot

Looks like this is a question for &lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;
 ?

@freedomtan thank you, your solution did work. After modifying metal_delegate.mm I was able to build libmetal_delegate.a which allowed create_ios_frameworks.sh to run with the -g flag.
This issue should probably remain open until this workaround is no longer necessary.

The workaround is &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/a592eff24bdae523970ec636d38d8c6b221de40a/tensorflow/lite/delegates/gpu/metal_delegate.mm#L29&gt;no longer necessary&lt;/denchmark-link&gt;
 so I'm closing the issue.
		</comment>
		<comment id='15' author='willbattel' date='2020-01-06T04:34:55Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27325&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/27325&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='16' author='willbattel' date='2020-01-06T08:12:41Z'>
		&lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
 oops, didn't notice that.
&lt;denchmark-link:https://github.com/thameslu&gt;@thameslu&lt;/denchmark-link&gt;
 in case didn't find the solution yet, I think you probably need to "run the  script in the root TensorFlow checkout directory, and answer "Yes" when the script asks if you wish to build TensorFlow with iOS support", as described in the &lt;denchmark-link:https://www.tensorflow.org/lite/guide/build_ios#configure_workspace_and_bazelrc&gt;build TF Lite for iOS&lt;/denchmark-link&gt;
 guide
		</comment>
		<comment id='17' author='willbattel' date='2020-03-11T14:59:49Z'>
		
ensorFlow with iOS support", as described in the build TF Lite for iOS guide

thank you, i will have a try &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/freedomtan&gt;@freedomtan&lt;/denchmark-link&gt;

		</comment>
		<comment id='18' author='willbattel' date='2020-11-09T11:22:58Z'>
		&lt;denchmark-link:https://github.com/thameslu&gt;@thameslu&lt;/denchmark-link&gt;
 ，hi，How did you solve the problem? when i use metal delegate on ios i have the similar problem as follow,
_OBJC_CLASS_$_TFLInferenceContext", referenced from: objc-class-ref in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::BuildModel(TfLiteContext*, TfLiteDelegateParams const*, tflite::gpu::Model&lt;tflite::gpu::TensorRef&lt;tflite::gpu::StrongShape&lt;(tflite::gpu::Layout)10&gt; &gt; &gt;*)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)::$_1::__invoke(TfLiteContext*, char const*, unsigned long) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "_OBJC_CLASS_$_TFLBufferConvert", referenced from: objc-class-ref in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::GetOpsToReplace(TfLiteContext*)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::GetElementsSizeForPHWC4(tflite::gpu::StrongShape&lt;(tflite::gpu::Layout)10&gt; const&amp;)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)::$_1::__invoke(TfLiteContext*, char const*, unsigned long) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::metal::ValidateOptimizeModel(std::__1::vector&lt;unsigned int, std::__1::allocator&lt;unsigned int&gt; &gt; const&amp;, std::__1::vector&lt;unsigned int, std::__1::allocator&lt;unsigned int&gt; &gt; const&amp;, std::__1::vector&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt;, std::__1::allocator&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt; &gt; &gt; const&amp;, std::__1::vector&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt;, std::__1::allocator&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt; &gt; &gt;*)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)::$_1::__invoke(TfLiteContext*, char const*, unsigned long) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::ApplyGeneralTransformations(tflite::gpu::ModelTransformer*)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)::$_1::__invoke(TfLiteContext*, char const*, unsigned long) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::metal::Compile(tflite::gpu::Model&lt;tflite::gpu::TensorRef&lt;tflite::gpu::StrongShape&lt;(tflite::gpu::Layout)10&gt; &gt; &gt; const&amp;, tflite::gpu::metal::RuntimeOptions const&amp;, std::__1::vector&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt;, std::__1::allocator&lt;std::__1::shared_ptr&lt;tflite::gpu::metal::ComputeTaskDescriptor&gt; &gt; &gt;*)", referenced from: tflite::gpu::metal::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)::$_1::__invoke(TfLiteContext*, char const*, unsigned long) in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) "tflite::gpu::metal::CreateComputeProgram(id&lt;MTLDevice&gt;, NSString*, NSString, NSDictionary&lt;NSString, NSString&gt;*, id&lt;MTLComputePipelineState&gt; __autoreleasing*)", referenced from: _TFLGpuDelegateCreate in libmetal_delegate.a(metal_delegate_bf7d4aad90502bdf5c67c8a69622de9d.o) ld: symbol(s) not found for architecture arm64 clang: error: linker command failed with exit code 1 (use -v to see invocation)
and i have tried this,
tensorflow-1.15.4 % lipo -info tensorflow/lite/gen/ios_frameworks/tensorflow_lite_gpu.framework/libmetal_delegate.a
Non-fat file: tensorflow/lite/gen/ios_frameworks/tensorflow_lite_gpu.framework/libmetal_delegate.a is architecture: arm64
could you help me build the metal delegate framework correctly and run the tflite model with gpu on iphone?
		</comment>
	</comments>
</bug>