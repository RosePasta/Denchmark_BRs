<bug id='40760' author='mynameisteodora' open_date='2020-06-24T12:56:18Z' closed_time='2020-06-25T18:13:47Z'>
	<summary>CUDA_ERROR_OUT_OF_MEMORY when converting model to tflite with the new experimental converter</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Scientific Linux 7.6, Nitrogen
TensorFlow installed from (source or binary): anaconda
TensorFlow version (or github SHA if from source): 2.2.0

Command used to run the converter or code if youâ€™re using the Python API
If possible, please share a link to Colab/Jupyter/any notebook.
&lt;denchmark-code&gt;# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()```

**The output from the converter invocation**

&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

ConverterError                            Traceback (most recent call last)
 in 
2 converter = tf.lite.TFLiteConverter.from_keras_model(model)
3 # converter.experimental_new_converter = False
----&gt; 4 tflite_model = converter.convert()
5
6 # # Save the TF Lite model.
~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
516         input_tensors=input_tensors,
517         output_tensors=output_tensors,
--&gt; 518         **converter_kwargs)
519
520     if self._is_calibration_quantize():
~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
494       input_data.SerializeToString(),
495       debug_info_str=debug_info_str,
--&gt; 496       enable_mlir_converter=enable_mlir_converter)
497   return data
498
~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
225       stdout = _try_convert_to_unicode(stdout)
226       stderr = _try_convert_to_unicode(stderr)
--&gt; 227       raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
228   finally:
229     # Must manually cleanup files.
ConverterError: See console for info.
2020-06-24 13:49:09.713424: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-24 13:49:09.713504: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-06-24 13:49:09.727632: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-24 13:49:09.733205: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz
2020-06-24 13:49:09.734188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe1a42f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 13:49:09.734222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-24 13:49:09.735171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-24 13:49:09.741175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.742017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-24 13:49:09.742210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 13:49:09.744013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-24 13:49:09.745773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-24 13:49:09.746089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-24 13:49:09.748160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-24 13:49:09.749163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-24 13:49:09.753168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-24 13:49:09.753338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.753698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.754068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-24 13:49:09.754113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 13:49:09.801823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-24 13:49:09.801860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0
2020-06-24 13:49:09.801898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N
2020-06-24 13:49:09.802119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.802588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.802907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 13:49:09.803250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-24 13:49:09.805103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558fe25c8fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-24 13:49:09.805141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-06-24 13:49:09.807773: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 11.81M (12386304 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.808353: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 10.63M (11147776 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.808846: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 9.57M (10033152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.809396: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 8.61M (9029888 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.809879: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 7.75M (8126976 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.810419: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.98M (7314432 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.810917: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 6.28M (6583040 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 13:49:09.813411: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles&lt;T, NumThreads, TileLongSide, TileShortSide&gt;, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory
Fatal Python error: Aborted
Current thread 0x00007fe187194740 (most recent call first):
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 56 in execute
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py", line 250 in _run_main
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py", line 299 in run
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 40 in run
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 93 in main
File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/bin/toco_from_protos", line 11 in ```
Also, please include a link to the saved model or GraphDef
&lt;denchmark-code&gt;# Put link here or attach to the issue.
&lt;/denchmark-code&gt;

Failure details
The conversion is not successful and returns CUDA_ERROR_OUT_OF_MEMORY. However, if I set the experimental_new_converter flag to False, it works.
RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.
Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='mynameisteodora' date='2020-06-24T18:30:40Z'>
		I suspect that your session is running out of memory before conversion. This is plausible since gpu memory is not released till you kill the session.
For sanity check can you please try other method for tf lite conversion.
# Converting a SavedModel to a TensorFlow Lite model.
converter = lite.TFLiteConverter.from_saved_model(saved_model_dir)
Create a new notebook (instance) and convert your model from saved_model_dir to TF Lite.
		</comment>
		<comment id='2' author='mynameisteodora' date='2020-06-24T19:52:16Z'>
		I tried it and it gives this error instead, though i see it still has something to do with internal memory:
&lt;denchmark-code&gt;---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
&lt;ipython-input-2-5e5eca5ce13e&gt; in &lt;module&gt;
      1 # Converting a SavedModel to a TensorFlow Lite model.
      2 converter = tf.lite.TFLiteConverter.from_saved_model("./model_try")
----&gt; 3 tflite_model = converter.convert()

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)
    516         input_tensors=input_tensors,
    517         output_tensors=output_tensors,
--&gt; 518         **converter_kwargs)
    519 
    520     if self._is_calibration_quantize():

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    494       input_data.SerializeToString(),
    495       debug_info_str=debug_info_str,
--&gt; 496       enable_mlir_converter=enable_mlir_converter)
    497   return data
    498 

~/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--&gt; 227       raise ConverterError("See console for info.\n%s\n%s\n" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-06-24 20:51:33.900488: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.
2020-06-24 20:51:33.900532: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.
2020-06-24 20:51:33.920571: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-06-24 20:51:33.925758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3000000000 Hz
2020-06-24 20:51:33.926418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5626744c8d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 20:51:33.926452: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-06-24 20:51:33.927649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-06-24 20:51:33.930945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.931368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-06-24 20:51:33.931574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 20:51:33.933261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-06-24 20:51:33.935057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-06-24 20:51:33.935373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-06-24 20:51:33.937151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-06-24 20:51:33.938008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-06-24 20:51:33.942043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-06-24 20:51:33.942194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.942522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.942754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-06-24 20:51:33.942805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-06-24 20:51:33.991123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-06-24 20:51:33.991168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-06-24 20:51:33.991199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-06-24 20:51:33.991370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.991689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.992023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-06-24 20:51:33.992277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 193 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-06-24 20:51:34.000583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56267504edc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-06-24 20:51:34.000613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-06-24 20:51:34.002881: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 193.81M (203227136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-06-24 20:51:34.085757: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles&lt;T, NumThreads, TileLongSide, TileShortSide&gt;, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: out of memory
Fatal Python error: Aborted

Current thread 0x00007f4a10303740 (most recent call first):
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 56 in execute
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py", line 250 in _run_main
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/absl/app.py", line 299 in run
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/python/platform/app.py", line 40 in run
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py", line 93 in main
  File "/afs/inf.ed.ac.uk/user/t/tgeorges/anaconda3/envs/specknet/bin/toco_from_protos", line 11 in &lt;module&gt;
&lt;/denchmark-code&gt;

		</comment>
		<comment id='3' author='mynameisteodora' date='2020-06-24T22:06:38Z'>
		Can you please try &lt;denchmark-link:https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth&gt;limiting gpu memory growth&lt;/denchmark-link&gt;
?
Kill the current session, exit the python interpreter.
Then put following lines on top of your code.
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpus[0], True)
# your rest of the code
		</comment>
		<comment id='4' author='mynameisteodora' date='2020-06-25T08:52:34Z'>
		Yep that did the trick. Thank you very much!
		</comment>
		<comment id='5' author='mynameisteodora' date='2020-06-25T18:13:47Z'>
		You are welcome. Thanks for confirmation.
		</comment>
		<comment id='6' author='mynameisteodora' date='2020-06-25T18:13:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40760&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/40760&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>