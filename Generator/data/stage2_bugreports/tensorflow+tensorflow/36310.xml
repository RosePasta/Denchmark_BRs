<bug id='36310' author='lennyerik' open_date='2020-01-29T13:20:20Z' closed_time='2020-10-25T12:34:17Z'>
	<summary>Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles&amp;lt;T, NumThreads, TileLongSide, TileShortSide&amp;gt;, ...) Internal: invalid configuration argument when using the tf.keras MaxPooling3D layer</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I have written my own model training script.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 19.10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
TensorFlow installed from (source or binary): From binary (pip)
TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de (2.1.0)
Python version: 3.7.5 (pip version 20.0.2)
Bazel version (if compiling from source): None
GCC/Compiler version (if compiling from source): None
CUDA/cuDNN version: CUDA V10.1.243 (10.1), cuDNN 7.6.5.32-1+cuda10.1
GPU model and memory: 2x Nvidia GeForce GTX 1070 Ti (8GB VRAM each)


When using tensorflow's  to scale a -based model with the  layer, tensorflow outputs the error:
, followed by  when trying to train the model.
I was able to verify that the MaxPooling3D layer appears to be the issue, because when taking it out of the test script (see "Code to reproduce the issue"), the issue does not persist.
The same issue also occurs when using the, now deprecated, .
I am yet unsure whether this is a problem in tensorflow itself or any of the used frameworks.
Please note, that this issue is most likely not related to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/30665&gt;#30665&lt;/denchmark-link&gt;
 or &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33696&gt;#33696&lt;/denchmark-link&gt;
 since they describe an issue related to the internal CUDA kernel  rather than the  described here.
I am happy to provide further, more specific information on the used training script or the issue itself, if requested.
Describe the expected behavior
The model should train normally and not output any errors, as it does when executed without the distributed scope or when reducing the MirroredStrategy to only use one GPU.
Code to reproduce the issue
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras import *
import tensorflow as tf
import numpy as np

strat = tf.distribute.MirroredStrategy(devices=['/gpu:0', '/gpu:1'])

with strat.scope():
    model = Sequential()
    model.add(MaxPooling3D((1, 2, 2), input_shape=(None, 640, 480, 1)))
    model.add(ConvLSTM2D(16, kernel_size=(3,3)))
    model.add(Flatten())
    model.add(Dense(1))
    model.summary()
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])

    x = np.random.rand(1, 10, 640, 480, 1)
    y = np.random.rand(1, 1)
    model.fit(x=x, y=y, epochs=10)
Other info / logs
Full console output:
&lt;denchmark-code&gt;(venv) [REDACTED]@[REDACTED]:[REDACTED]$ python test.py
2020-01-29 13:32:31.798280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-01-29 13:32:31.799195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-01-29 13:32:32.130276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-29 13:32:32.168392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.168824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.168866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.169410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.169467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.169549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:32.170673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-29 13:32:32.170902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-29 13:32:32.171948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-29 13:32:32.172544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-29 13:32:32.172565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:32.172641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.172988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.173522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.173857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.174368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-01-29 13:32:32.174654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-29 13:32:32.198716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz
2020-01-29 13:32:32.199091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47afc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-29 13:32:32.199105: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-29 13:32:32.293103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.303707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.304142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4845b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-01-29 13:32:32.304154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1
2020-01-29 13:32:32.304159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
2020-01-29 13:32:32.304924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.305233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.305520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.305527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:32.305535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-29 13:32:32.305543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-29 13:32:32.305551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-29 13:32:32.305558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-29 13:32:32.305565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:32.305593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-01-29 13:32:32.306766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.546439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-29 13:32:32.546463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 
2020-01-29 13:32:32.546468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y 
2020-01-29 13:32:32.546471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N 
2020-01-29 13:32:32.546636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.546935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.547217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.547478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6807 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-01-29 13:32:32.547823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.548093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7562 MB memory) -&gt; physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
max_pooling3d (MaxPooling3D) (None, None, 320, 240, 1) 0         
_________________________________________________________________
conv_lst_m2d (ConvLSTM2D)    (None, 318, 238, 16)      9856      
_________________________________________________________________
flatten (Flatten)            (None, 1210944)           0         
_________________________________________________________________
dense (Dense)                (None, 1)                 1210945   
=================================================================
Total params: 1,220,801
Trainable params: 1,220,801
Non-trainable params: 0
_________________________________________________________________
Train on 1 samples
Epoch 1/10
2020-01-29 13:32:35.394061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:35.638536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:35.639247: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles&lt;T, NumThreads, TileLongSide, TileShortSide&gt;, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument
Aborted (core dumped)
&lt;/denchmark-code&gt;

Last few lines of output with the TF_CPP_MIN_VLOG_LEVEL=2 environment variable set:
&lt;denchmark-code&gt;2020-01-29 13:42:39.018679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/Cast op Cast on GPU 1 stream[0]
2020-01-29 13:42:39.018689: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: "replica_1/Cast" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 640 } dim { size: 480 } dim { size: 1 } } } }
2020-01-29 13:42:39.018696: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 167 step -6348371833153678773 {{node replica_1/Cast}} = Cast[DstT=DT_FLOAT, SrcT=DT_DOUBLE, Truncate=false, _XlaHasReferenceVars=false, _device="/job:localhost/replica:0/task:0/device:GPU:1"](cond_3/output/_37) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018703: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device="/job:localhost/replica:0/task:0/device:GPU:1"](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]
2020-01-29 13:42:39.018720: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: "replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze" tensor { dtype: DT_FLOAT shape { dim { } } } }
2020-01-29 13:42:39.018726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]
2020-01-29 13:42:39.018734: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: "replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } } } }
2020-01-29 13:42:39.018740: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device="/job:localhost/replica:0/task:0/device:GPU:1"](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018750: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device="/job:localhost/replica:0/task:0/device:GPU:1"](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/strided_slice op StridedSlice on GPU 1 stream[0]
2020-01-29 13:42:39.018763: I tensorflow/core/common_runtime/bfc_allocator.cc:227] AllocateRaw gpu_host_bfc  4
2020-01-29 13:42:39.018775: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: "replica_1/strided_slice" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }
2020-01-29 13:42:39.018785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/strided_slice op StridedSlice on GPU 1 stream[0]
2020-01-29 13:42:39.018793: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: "replica_1/strided_slice" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: "gpu_host_bfc" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }
2020-01-29 13:42:39.018801: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device="/job:localhost/replica:0/task:0/device:GPU:1"](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018808: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 16619 allocator_name: "cpu" }
2020-01-29 13:42:39.018819: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 170 step -6348371833153678773 {{node replica_1/sequential/max_pooling3d/MaxPool3D}} = MaxPool3D[T=DT_FLOAT, _XlaHasReferenceVars=false, data_format="NDHWC", ksize=[1, 1, 2, 2, 1], padding="VALID", strides=[1, 1, 2, 2, 1], _device="/job:localhost/replica:0/task:0/device:GPU:1"](replica_1/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/sequential/max_pooling3d/MaxPool3D op MaxPool3D on GPU 1 stream[0]
2020-01-29 13:42:39.018838: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: "replica_1/sequential/max_pooling3d/MaxPool3D" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 320 } dim { size: 240 } dim { size: 1 } } } }
2020-01-29 13:42:39.018849: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: "replica_1/sequential/max_pooling3d/MaxPool3D" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 1 } dim { size: 10 } dim { size: 640 } dim { size: 480 } } } }
2020-01-29 13:42:39.018862: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles&lt;T, NumThreads, TileLongSide, TileShortSide&gt;, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument
Aborted (core dumped)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='lennyerik' date='2020-01-29T19:53:57Z'>
		After a bit more testing, I came to the conclusion that the issue only occurs when using the  layer as the input layer of the model. Is this expected behaviour? If so, why does the model work as a single-GPU model?
After placing the layer behind the  layers of my model, the issue has disappeared, however now it seems like tensorflow is only using the compute capabilities of one of my graphics cards, even with the distributed strategy, since nvidia-smi shows full memory usage on both cards, increased wattage on both cards, but only increased activity on one card, much like in &lt;denchmark-link:https://datascience.stackexchange.com/questions/63609/tensorflow-mirroredstrategy-looks-like-it-may-only-be-working-on-one-gpu&gt;this Stackexchange post&lt;/denchmark-link&gt;
. I cannot confirm that the issues are related, though.
		</comment>
		<comment id='2' author='lennyerik' date='2020-02-05T20:48:55Z'>
		&lt;denchmark-link:https://github.com/lennyerik&gt;@lennyerik&lt;/denchmark-link&gt;
 it looks like your data contains 1 sample and you don't specify a batch size which causes this error. We should be handling this use case and I still need to identify the root case. In the meantime you can increase the number of input samples which should work (i tried number of samples= 2, 3).
		</comment>
		<comment id='3' author='lennyerik' date='2020-02-07T23:53:11Z'>
		Thank you for attending to this issue and providing me with a working solution!
I am looking forward to seeing a fix for this specific issue in the future.
		</comment>
		<comment id='4' author='lennyerik' date='2020-06-08T11:28:53Z'>
		In case anyone else is going crazy because of the GpuLaunchKernel(...) status: Internal: invalid configuration argumnent error, please note that this may also occur if the batch size you use is such that there will be an odd batch with a single record, in my case, the error occurred with the following numbers, when distributed across 4 GPUs:
# Assuming `ds` has 89 records in total
num_records = 89
batch_size = 8
ds = ds.batch(batch_size).repeat().cache().prefetch(tf.data.experimental.AUTOTUNE) # i.e., 11 batches of 8 records, and 1 batch of 1 record
step_size = math.ceil(num_records / batch_size) # i.e., 12
...
model.fit(
  ds,
  steps_per_epoch=step_size,
  # other arguments
  )
To fix the issue, change your batch size such that there won't be an odd batch with a single record.
		</comment>
		<comment id='5' author='lennyerik' date='2020-06-28T06:24:31Z'>
		Thank you &lt;denchmark-link:https://github.com/YongJieYongJie&gt;@YongJieYongJie&lt;/denchmark-link&gt;
 , also see this solution: &lt;denchmark-link:https://stackoverflow.com/a/59971264/2468587&gt;https://stackoverflow.com/a/59971264/2468587&lt;/denchmark-link&gt;
, make sure the total number of data can be divided by the batch_size.
		</comment>
		<comment id='6' author='lennyerik' date='2020-07-06T09:10:06Z'>
		Thanks &lt;denchmark-link:https://github.com/YongJieYongJie&gt;@YongJieYongJie&lt;/denchmark-link&gt;
, that worked for me ! As suggestion, you can set the option   and you don't have to take care about whether your last batch is an odd batch or not.
		</comment>
		<comment id='7' author='lennyerik' date='2020-08-07T05:27:59Z'>
		This problem seems only happens when using multiple GPUs training. For single GPU training, even the number of samples is NOT divisible by batch_size, NO such error will be raised. Hence this may be a bug.
The solution proposed by &lt;denchmark-link:https://github.com/JTorres258&gt;@JTorres258&lt;/denchmark-link&gt;
 is simple but not suitable for model.predict() since in prediction we are not allowed to drop any samples.
The solution proposed by &lt;denchmark-link:https://github.com/YongJieYongJie&gt;@YongJieYongJie&lt;/denchmark-link&gt;
 is not the best solution since batch_size is a important hyper-parameter that need to be fine-tuned.
For training phase, I suggest to use the solution by &lt;denchmark-link:https://github.com/JTorres258&gt;@JTorres258&lt;/denchmark-link&gt;
 , drop few examples will be affect training.
For predict phase, I suggest to use single GPU only, or use the solution by &lt;denchmark-link:https://github.com/YongJieYongJie&gt;@YongJieYongJie&lt;/denchmark-link&gt;
 to set dynamic batch_size since batch_size won't affect prediction.
By the way, if you tend to use model.predict() with single GPU right after model.fit() with multiple GPUs in same .py file. You can save the trained model first and then load it back to do prediction.
		</comment>
		<comment id='8' author='lennyerik' date='2020-08-12T10:26:03Z'>
		I can confirm this problem with two GPUs in mirrored strategy, 6105 records and a batch size of 4, i.e. 1 remaining record for the last step.
		</comment>
		<comment id='9' author='lennyerik' date='2020-10-09T19:11:52Z'>
		I faced the same issue this week when I migrated from tensorflow 2.1 to 2.3.
It does not matter the version of my python env. I tried 3.6, 3.7 and 3.8 the result was the same
I don't think the issue is connected to python as other folks suggested. I ran the binary in C the result was the same.
My assumption is that the new build has some incompatibility with my GPU card and Nvidia tool kit.
Here you are a couple of outputs from my tests
===================================================================================
Error: Non-OK-status: GpuLaunchKernel(BlockReduceKernel
C# binding and tensorflow-gpu 2.3.1
Test: tf.reduce_sum
D:\Development\blazor-ml\GPUTest\bin\Debug\netcoreapp3.1&gt;GPUTest.exe
2020-10-09 20:41:29.568433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:41:29.634163: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-09 20:41:29.662615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26ce71f4010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-09 20:41:29.662701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-09 20:41:29.664614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-10-09 20:41:30.212957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 20:41:30.213137: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:41:30.218036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:41:30.222788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-09 20:41:30.224161: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-09 20:41:30.234935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 20:41:30.237664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 20:41:30.250487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:41:30.250741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-09 20:41:30.331397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-09 20:41:30.331557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-09 20:41:30.332424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-09 20:41:30.333246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-10-09 20:41:30.344382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26cf2de55c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-09 20:41:30.344498: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0
2020-10-09 20:41:30.813185: F .\tensorflow/core/kernels/reduction_gpu_kernels.cu.h:670] Non-OK-status: GpuLaunchKernel(BlockReduceKernel&lt;IN_T, T*, num_threads, Op&gt;, num_blocks, num_threads, 0, cu_stream, in, (T*)temp_storage.flat&lt;int8_t&gt;().data(), in_size, op, init) status: Internal: no kernel image is available for execution on the device
===================================================================================
ERROR: Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch
Python 3.8 Tensorflow-gpu 2.3.1
x = Input(shape=(32,))
y = Dense(16, activation='softmax')(x)
model1 = Model(x, y)
&lt;denchmark-code&gt;To access the notebook, open this file in a browser:
    file:///D:/Development/Tensorflow/Model/WPy64-3850/settings/runtime/nbserver-5672-open.html
Or copy and paste one of these URLs:
    http://localhost:8888/?token=16d7994d801fd8e90e8340fa1fbc47712a74654b1df77f1f
 or http://127.0.0.1:8888/?token=16d7994d801fd8e90e8340fa1fbc47712a74654b1df77f1f
&lt;/denchmark-code&gt;

[W 20:51:38.774 NotebookApp] 404 GET /nbextensions/jupyter_tensorboard/tree.js?v=20201009205136 (::1) 11.97ms referer=&lt;denchmark-link:http://localhost:8888/tree&gt;http://localhost:8888/tree&lt;/denchmark-link&gt;

[W 20:51:38.778 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009205136 (::1) 3.02ms referer=&lt;denchmark-link:http://localhost:8888/tree&gt;http://localhost:8888/tree&lt;/denchmark-link&gt;

[W 20:51:41.012 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted
[W 20:51:41.060 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009205136 (::1) 3.98ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

[W 20:51:41.105 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009205136 (::1) 2.04ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

[I 20:51:42.312 NotebookApp] Kernel started: 8cbadda4-3af2-4e8f-bcd4-4d3ba04a3d11, name: python3
2020-10-09 20:51:51.863055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:51:56.427210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-10-09 20:51:56.983650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 20:51:56.983827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:51:56.991328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:51:57.011813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-09 20:51:57.016791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-09 20:51:57.038352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 20:51:57.042855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 20:51:57.101006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:51:57.101325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-09 20:51:59.525460: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-09 20:51:59.536727: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b5355a73f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-09 20:51:59.536898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-09 20:51:59.873720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 20:51:59.873956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:51:59.883568: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:51:59.884599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-09 20:51:59.885629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-09 20:51:59.886257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 20:51:59.886318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 20:51:59.886376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:51:59.886493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-09 20:51:59.979884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-09 20:51:59.980110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-09 20:51:59.982977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-09 20:51:59.983718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-10-09 20:51:59.990807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2b538186e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-09 20:51:59.991051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0
2020-10-09 20:52:00.278898: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device
[I 20:52:12.311 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports
WARNING:root:kernel 8cbadda4-3af2-4e8f-bcd4-4d3ba04a3d11 restarted
===================================================================================
Failed with an error Non-OK-status: GpuLaunchKernel
python 3.7 Tensorflow-gpu 2.3.1
Test:
x = Input(shape=(32,))
y = Dense(16, activation='softmax')(x)
model1 = Model(x, y)
&lt;denchmark-code&gt;Or copy and paste one of these URLs:
    http://localhost:8888/?token=66fb5843df207dd0b557b47408b83906d62d9592f2916484
 or http://127.0.0.1:8888/?token=66fb5843df207dd0b557b47408b83906d62d9592f2916484
&lt;/denchmark-code&gt;

[W 21:04:14.850 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009210412 (::1) 10.96ms referer=&lt;denchmark-link:http://localhost:8888/tree&gt;http://localhost:8888/tree&lt;/denchmark-link&gt;

[W 21:04:19.657 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted
[W 21:04:19.712 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009210412 (::1) 5.97ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

[I 21:04:20.873 NotebookApp] Kernel started: 12a69ce5-7a94-40fe-88ae-a8fbe6271ed6, name: python3
[W 21:04:21.279 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009210412 (::1) 2.00ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

2020-10-09 21:04:23.113979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 21:04:27.120750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-10-09 21:04:27.662137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 21:04:27.662346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 21:04:27.670493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-09 21:04:27.689090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-09 21:04:27.694532: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-09 21:04:27.717405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 21:04:27.720870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 21:04:27.775674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 21:04:27.776096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-09 21:04:28.705622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-10-09 21:04:28.719573: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x245c22e0920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-09 21:04:28.719775: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-09 21:04:29.052348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 21:04:29.052810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-10-09 21:04:29.055798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-10-09 21:04:29.061761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-10-09 21:04:29.062368: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-10-09 21:04:29.063025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 21:04:29.063610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 21:04:29.064345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 21:04:29.065137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-10-09 21:04:29.165120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-09 21:04:29.165332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0
2020-10-09 21:04:29.166904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N
2020-10-09 21:04:29.172752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3121 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-10-09 21:04:29.178803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x245c2837720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-09 21:04:29.179925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 950M, Compute Capability 5.0
2020-10-09 21:04:29.465815: F .\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: no kernel image is available for execution on the device
[I 21:04:38.860 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports
===================================================================================
Test SUCCEEDED
python 3.7 Tensorflow-gpu 2.1
Test:
x = Input(shape=(32,))
y = Dense(16, activation='softmax')(x)
model1 = Model(x, y)
&lt;denchmark-code&gt;To access the notebook, open this file in a browser:
    file:///D:/Development/Tensorflow/Model/WPy64-3771/settings/runtime/nbserver-18700-open.html
Or copy and paste one of these URLs:
    http://localhost:8888/?token=1dce3844acff60aa0479a92618c3b9935dd49fdde742d900
 or http://127.0.0.1:8888/?token=1dce3844acff60aa0479a92618c3b9935dd49fdde742d900
&lt;/denchmark-code&gt;

[W 20:54:22.526 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/tree_tab/main.js?v=20201009205419 (::1) 9.83ms referer=&lt;denchmark-link:http://localhost:8888/tree&gt;http://localhost:8888/tree&lt;/denchmark-link&gt;

[W 20:54:24.928 NotebookApp] Notebook keras_freeze_tf_pb.ipynb is not trusted
[W 20:54:24.983 NotebookApp] 404 GET /nbextensions/nbextensions_configurator/config_menu/main.js?v=20201009205419 (::1) 7.98ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

[I 20:54:26.204 NotebookApp] Kernel started: 4f4a70a5-ed88-4dff-8a60-958fbd5d277c, name: python3
[W 20:54:26.412 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20201009205419 (::1) 2.00ms referer=&lt;denchmark-link:http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&gt;http://localhost:8888/notebooks/keras_freeze_tf_pb.ipynb&lt;/denchmark-link&gt;

2020-10-09 20:54:28.598195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:54:31.123064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-10-09 20:54:31.670977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 20:54:31.671158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:54:31.679963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:54:31.700293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-10-09 20:54:31.705279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-10-09 20:54:31.731012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 20:54:31.734385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 20:54:31.794893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:54:31.795184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-10-09 20:54:32.848984: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-10-09 20:54:33.172382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 950M computeCapability: 5.0
coreClock: 1.124GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 29.83GiB/s
2020-10-09 20:54:33.172844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-10-09 20:54:33.175709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:54:33.180437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-10-09 20:54:33.180989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-10-09 20:54:33.181848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-10-09 20:54:33.182635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-10-09 20:54:33.183265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:54:33.184016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-10-09 20:54:36.193571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-09 20:54:36.193648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-10-09 20:54:36.194359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-10-09 20:54:36.195110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3033 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 950M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-10-09 20:56:00.634227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-10-09 20:56:00.917849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-10-09 20:56:01.860562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
		</comment>
		<comment id='10' author='lennyerik' date='2020-10-25T12:34:17Z'>
		&lt;denchmark-link:https://github.com/lennyerik&gt;@lennyerik&lt;/denchmark-link&gt;
 Closing this issue as of now  since the necessary changes are done. Please feel free to re-open the issue if needed. Thanks!
		</comment>
		<comment id='11' author='lennyerik' date='2020-10-25T12:34:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36310&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36310&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='12' author='lennyerik' date='2020-10-25T15:04:36Z'>
		
Closing this issue as of now since the necessary changes are done. Please feel free to re-open the issue if needed. Thanks!

&lt;denchmark-link:https://github.com/saikumarchalla&gt;@saikumarchalla&lt;/denchmark-link&gt;
 In which commit / release?
		</comment>
	</comments>
</bug>