<bug id='32006' author='jackd' open_date='2019-08-27T11:06:41Z' closed_time='2020-01-28T20:50:38Z'>
	<summary>Very unhelpful error msg building keras models with while loops</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution: Linux Ubuntu 16.04:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): v1.12.1-9365-gff401a6 1.15.0-dev20190821
Python version: 3.6.8
CUDA/cuDNN version: 10.0 / ??
GPU model and memory: Quadro 2gb

Describe the current behavior
_create_keras_history_helper is making building networks much more pleasant in general by forgoing the need to wrap everything in Lambda layers. It's failing for while loops without Lambda wrapping, giving a very unhelpful error message. tensorflow.python.framework.errors_impl.InvalidArgumentError: A cross-device loop must have a pivot predicate: while/while_context
Describe the expected behavior
Indicate the source of the problem/possible resolution.
Code to reproduce the issue
import tensorflow as tf

def cond(i, x):
    return tf.reduce_all(x &lt; 10)

def body(i, x):
    return i + 1, x + i

x = tf.keras.layers.Input(shape=(), dtype=tf.float32)
inc = tf.while_loop(cond, body, [tf.constant(0, dtype=tf.float32), x])
# the following fixes things
# inc = tf.keras.layers.Lambda(lambda x: tf.while_loop(
#     cond, body, [tf.constant(0, dtype=tf.float32), x]))(x)

model = tf.keras.Model(inputs=x, outputs=inc)  # &lt;- error occurs here
Other info / logs
Traceback:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "loop.py", line 23, in &lt;module&gt;
    model = tf.keras.Model(inputs=x, outputs=inc)  # &lt;- error occurs here
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py", line 147, in __init__
    super(Model, self).__init__(*args, **kwargs)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 164, in __init__
    self._init_graph_network(*args, **kwargs)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 267, in _init_graph_network
    base_layer_utils.create_keras_history(self._nested_outputs)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py", line 184, in create_keras_history
    _, created_layers = _create_keras_history_helper(tensors, set(), [])
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py", line 231, in _create_keras_history_helper
    layer_inputs, processed_ops, created_layers)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py", line 231, in _create_keras_history_helper
    layer_inputs, processed_ops, created_layers)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py", line 229, in _create_keras_history_helper
    constants[i] = backend.function([], op_input)([])
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3473, in __call__
    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py", line 3410, in _make_callable
    callable_fn = session._make_callable_from_options(callable_opts)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1505, in _make_callable_from_options
    return BaseSession._Callable(self, callable_options)
  File ".../.anaconda2/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow_core/python/client/session.py", line 1460, in __init__
    session._session, options_ptr)
tensorflow.python.framework.errors_impl.InvalidArgumentError: A cross-device loop must have a pivot predicate: while/while_context
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='jackd' date='2019-08-28T08:43:12Z'>
		&lt;denchmark-link:https://github.com/jackd&gt;@jackd&lt;/denchmark-link&gt;
 ,
When tried executing the given code I got error  Thanks!
		</comment>
		<comment id='2' author='jackd' date='2019-08-28T23:38:18Z'>
		&lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;
 I've just re-run and my output hasn't changed, though if you are getting that output then I'm even more bermused. That sounds like an error associated with running a session, but there's nothing in the code trying to do that.
		</comment>
		<comment id='3' author='jackd' date='2019-08-29T09:04:00Z'>
		&lt;denchmark-link:https://github.com/jackd&gt;@jackd&lt;/denchmark-link&gt;
,
Thank you, I was able to replicate the issue with TF-nightly-gpu. Kindly find the &lt;denchmark-link:https://colab.research.google.com/drive/1sNlOEfOWiUZEE9KH044VfmMcPbMIWIuO&gt;Gist&lt;/denchmark-link&gt;
 of colab.
		</comment>
		<comment id='4' author='jackd' date='2020-01-28T20:50:38Z'>
		Can you wrap the while loop in a lambda layer?
&lt;denchmark-code&gt;inc = tf.keras.layers.Lambda(lambda i: tf.while_loop(cond, body, [tf.constant(0, dtype=tf.float32), i]))(x)
&lt;/denchmark-code&gt;

By default if TF ops are used in a tf.keras model, without having been wrapped in a tf.keras layer, we try to wrap them ourselves. This will work only for use cases where we can backtrack to the inputs of the model. If your custom op has a control dependency for example, this automatic wrapping will not work.
		</comment>
		<comment id='5' author='jackd' date='2020-01-28T20:50:40Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32006&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32006&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='jackd' date='2020-01-28T22:28:18Z'>
		&lt;denchmark-link:https://github.com/pavithrasv&gt;@pavithrasv&lt;/denchmark-link&gt;
 yes, wrapping it in a keras layer resolves things. I'm starting to accept that  isn't the panacea I thought it once was - and trying to write code that feels more like non-keras tf without wrapping things in s is generally just a bad idea.
My main issue is the lack of informative error message. A cross-device loop must have a pivot predicate: while/while_context doesn't exactly shout "you're missing a Lambda layer."
		</comment>
	</comments>
</bug>