<bug id='22063' author='kenryd' open_date='2018-09-04T19:41:36Z' closed_time='2018-10-09T21:09:10Z'>
	<summary>Tensorflow segfaults in eager mode with DEVICE_PLACEMENT_EXPLICIT</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.4
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.10.1-0-g4dcfddc5d1
Python version: 1.10.1
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: 7.1.3
GPU model and memory: GeForce GTX 1080, 8Gb
Exact command to reproduce:
[1]: import tensorflow as tf
[2]: tf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_EXPLICIT)
[3]: a = tf.zeros((2,2))

Full output:
&lt;denchmark-code&gt;In [1]: import tensorflow as tf

In [2]: tf.enable_eager_execution(device_policy=tf.contrib.eager.DEVICE_PLACEMENT_EXPLICIT)

In [3]: tf.__version__
Out[3]: '1.10.1'

In [4]: a = tf.zeros((2,2))
2018-09-04 12:39:47.441463: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-09-04 12:39:47.524855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-09-04 12:39:47.525190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335
pciBusID: 0000:01:00.0
totalMemory: 7.92GiB freeMemory: 3.93GiB
2018-09-04 12:39:47.525203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-09-04 12:39:47.706125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-09-04 12:39:47.706148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-09-04 12:39:47.706153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-09-04 12:39:47.706287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3660 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
Segmentation fault (core dumped)
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='kenryd' date='2018-09-04T20:26:06Z'>
		I can also reproduce this in a similar environment (v1.10.1 on Ubuntu 16.04). Also, this does not occur in v1.9.0.
		</comment>
		<comment id='2' author='kenryd' date='2018-10-04T19:07:12Z'>
		Nagging Assignee &lt;denchmark-link:https://github.com/rohan100jain&gt;@rohan100jain&lt;/denchmark-link&gt;
: It has been 29 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.
		</comment>
		<comment id='3' author='kenryd' date='2018-10-09T21:09:10Z'>
		On 1.11 I get a stack trace instead of a segfault. The way to fix this is to explicitly specify whether you want the CPU or GPU device, so while tf.zeros((2, 2)) fails, the following works
&lt;denchmark-code&gt;with tf.device('gpu:0'):
  tf.zeros((2,2))
&lt;/denchmark-code&gt;

		</comment>
	</comments>
</bug>