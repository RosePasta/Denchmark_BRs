<bug id='14985' author='balconychy' open_date='2017-11-30T04:20:21Z' closed_time='2018-01-05T14:05:19Z'>
	<summary>tf.nn.fractional_max_pool output have same batch size when feed with different input batch size</summary>
	<description>
&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

tf.nn.fractional_max_pool output have same batch size when feed with different input batch size.
Attached is test code I write. 2 different input is feed in with different batch size , outputs get same batch size.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1516498/pool_test.py.txt&gt;pool_test.py.txt&lt;/denchmark-link&gt;

###code result
shape of input_a (3, 32, 32, 3)
shape of output_a (3, 21, 21, 3)
shape of input_b (4, 32, 32, 3)
shape of output_b (3, 21, 21, 3)
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;

== cat /etc/issue ===============================================
Linux c-1080u 4.10.0-40-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44&gt;#44&lt;/denchmark-link&gt;
~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION="16.04.3 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux c-1080u 4.10.0-40-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44&gt;#44&lt;/denchmark-link&gt;
~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.13.3)
numpydoc (0.7.0)
== check for virtualenv =========================================
False
== tensorflow import ============================================
Traceback (most recent call last):
File "", line 1, in 
ModuleNotFoundError: No module named 'tensorflow'
== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
Thu Nov 30 11:55:40 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
|  0%   51C    P8    21W / 280W |    860MiB / 11169MiB |      9%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |
|    0      1540      G   compiz                                       315MiB |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
== cat /etc/issue ===============================================
Linux c-1080u 4.10.0-40-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44&gt;#44&lt;/denchmark-link&gt;
~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION="16.04.3 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux c-1080u 4.10.0-40-generic &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44&gt;#44&lt;/denchmark-link&gt;
~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.0.post1)
tensorflow-gpu (1.4.0)
tensorflow-tensorboard (0.4.0rc3)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)
== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
Thu Nov 30 11:56:18 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
|  0%   51C    P0    80W / 280W |    860MiB / 11169MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |
|    0      1540      G   compiz                                       315MiB |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
	</description>
	<comments>
		<comment id='1' author='balconychy' date='2017-11-30T19:51:44Z'>
		&lt;denchmark-link:https://github.com/balconychy&gt;@balconychy&lt;/denchmark-link&gt;
 Thanks for the clear bug description!
Looks like &lt;denchmark-link:https://github.com/weiranzhao&gt;@weiranzhao&lt;/denchmark-link&gt;
 wrote the code, and &lt;denchmark-link:https://github.com/josh11b&gt;@josh11b&lt;/denchmark-link&gt;
 might have reviewed it.  Can one of you take a look at this?
For convenience, here's the repro program that &lt;denchmark-link:https://github.com/balconychy&gt;@balconychy&lt;/denchmark-link&gt;
 created:
&lt;denchmark-code&gt;import  cifar10
import tensorflow as tf
import tensorflow.contrib.slim as slim
import numpy as np

def check_unequal_size():
    input_holder = tf.placeholder(tf.float32, [None,32,32,3])
    out=tf.nn.fractional_max_pool(input_holder,[1,1.5,1.5,1],name="low_fea_pool")
    sess=tf.Session()
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
    x_train = x_train.astype('float32')
    input_a=x_train[1:4]
    input_b=x_train[1:5]
    output_a,_,_=sess.run(out,
               {input_holder:input_a
                })
    output_b,_,_= sess.run(out,
                 {input_holder: input_b
                 })
    print("shape of input_a",input_a.shape)
    print("shape of output_a", output_a.shape)
    print("shape of input_b", input_b.shape)
    print("shape of output_b", output_b.shape)
    pass

check_unequal_size()
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='balconychy' date='2017-12-20T01:27:24Z'>
		It has been 14 days with no activity and the awaiting tensorflower label was assigned. Please update the label and/or status accordingly.
		</comment>
		<comment id='3' author='balconychy' date='2017-12-21T20:54:15Z'>
		Thanks for the detailed example. I am working on a fix. Will update the thread when it is checked in to master branch.
		</comment>
		<comment id='4' author='balconychy' date='2018-01-09T21:37:07Z'>
		&lt;denchmark-link:https://github.com/balconychy&gt;@balconychy&lt;/denchmark-link&gt;

This should have been fixed. I checked this with nightly build at tf-nightly 1.6.0.dev20180109.
		</comment>
	</comments>
</bug>