<bug id='34250' author='pw2393' open_date='2019-11-13T23:08:57Z' closed_time='2019-11-19T00:41:06Z'>
	<summary>Collective AllGather Fails on Polymorphic Shapes</summary>
	<description>
System information

OS Platform and Distribution: Ubuntu 18.04
TensorFlow installed from (source or binary): binary whl
TensorFlow version (use command below): tensorflow-gpu==2.0.0
Python version: 3.6.8
CUDA/cuDNN version: 10.0 / 7.6.4
GPU model and memory: GeForce GTX 1080 Ti

Describe the current behavior
import numpy as np
import tensorflow as tf

from tensorflow.core.protobuf import config_pb2
from tensorflow.python.ops import collective_ops

t0 = [0, 1, 2, 3, 4, 5, 6, 7]
t1 = [10, 11, 12, 13, 14, 15, 16, 17]
expected = [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17]

group_size = 2
group_key = 1
instance_key = 123

with tf.compat.v1.Session(
        config=config_pb2.ConfigProto(device_count={'CPU': group_size})) as sess:

    with tf.device('/CPU:0'):
        in0 = tf.compat.v1.placeholder(dtype=tf.int32, shape=[None])
        c0 = collective_ops.all_gather(in0, group_size=group_size, group_key=group_key, instance_key=instance_key)
    with tf.device('/CPU:1'):
        in1 = tf.compat.v1.placeholder(dtype=tf.int32, shape=[None])
        c1 = collective_ops.all_gather(in1, group_size=group_size, group_key=group_key, instance_key=instance_key)

    # SUCCESS:
    results = sess.run([c0, c1], feed_dict={in0: t0, in1: t1})
    assert np.allclose(results[0], expected)
    assert np.allclose(results[1], expected)

    # FAIL:
    results_ = sess.run([c0, c1], feed_dict={in0: t0[1:], in1: t1[1:]})
    # &gt; 2019-11-13 17:45:50.521948: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: Inconsistent output shapes, got [14], but expected is [16].
In one session, if one runs the above graph second time with the feed in a size different from the first time, it will raise an error: Inconsistent output shapes, got [14], but expected is [16].
Describe the expected behavior

The graph construction above sets the expected shapes of the placeholders as polymorphic [None]. However, after the first session.run, the collective op caches its output shape (which is 16 in our case) in "tensorflow/tensorflow/core/kernels/collective_ops.cc". But should it be expected that the collective op keeps its graph-defined polymorphic behavior? Specifically, in our case, should it allow a user to all gather two size 7 tensors into a size 14?

Code to reproduce the issue
See above
	</description>
	<comments>
		<comment id='1' author='pw2393' date='2019-11-14T00:07:13Z'>
		Hi &lt;denchmark-link:https://github.com/tensorflower&gt;@tensorflower&lt;/denchmark-link&gt;
, I opened a pull request there &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/34295&gt;#34295&lt;/denchmark-link&gt;
  for this issue. If someone would like to review it, I'd very appreciate it  
		</comment>
		<comment id='2' author='pw2393' date='2019-11-19T00:41:07Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34250&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34250&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>