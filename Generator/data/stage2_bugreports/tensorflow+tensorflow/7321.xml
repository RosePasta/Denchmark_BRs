<bug id='7321' author='Bruczzz' open_date='2017-02-07T05:38:44Z' closed_time='2017-06-16T18:17:37Z'>
	<summary>Tensorflow retrained model compression fails with error: terminate called after throwing an instance of 'std::bad_alloc'   what():  std::bad_alloc Aborted (core dumped)</summary>
	<description>
I am doing a college project on tensorflow. I have successfully retrained using rerain.py file, to use that model in android program. I was trying to compress the model using commands in the following
link: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&lt;/denchmark-link&gt;

But it is getting terminated throwing the below error:
ERROR:   terminate called after throwing an instance of 'std::bad_alloc'   what():  std::bad_alloc Aborted (core dumped)
I am working on  an Ubuntu 14.04 machine with 4GB RAM.
Please help.
Thanks,
Bruczzz
	</description>
	<comments>
		<comment id='1' author='Bruczzz' date='2017-02-07T15:31:16Z'>
		It sounds like you ran out of memory.  However, it's impossible for us to help with the level of detail you given.  For example, what command did you run that ran out of memory?
		</comment>
		<comment id='2' author='Bruczzz' date='2017-02-10T11:06:35Z'>
		I am referring the "Shrinking File Size" section given at &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size&lt;/denchmark-link&gt;

The command that failed was:

bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=tensorflow_inception_graph.pb \
--out_graph=optimized_inception_graph.pb \
--inputs='Mul:0' \
--outputs='final_result:0' \
--transforms='\
round_weights(num_steps=256) \
'

		</comment>
		<comment id='3' author='Bruczzz' date='2017-02-10T15:18:20Z'>
		&lt;denchmark-link:https://github.com/Bruczzz&gt;@Bruczzz&lt;/denchmark-link&gt;
 What version of TensorFlow are you using?  A request for this was in the instructions that you deleted when creating the issue.
&lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 What would  be doing that consumes a bunch of memory?  Are there huge constants in these graphs?
		</comment>
		<comment id='4' author='Bruczzz' date='2017-02-10T16:35:20Z'>
		Apologies, this is a known bug with the command line parser. If you remove the '' and newlines in the transform script it should work. I have a fix pending, I'm hoping to get it in soon.
		</comment>
		<comment id='5' author='Bruczzz' date='2017-02-13T05:54:34Z'>
		Thanks a lot &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
  and &lt;denchmark-link:https://github.com/girving&gt;@girving&lt;/denchmark-link&gt;
. Now I am able to compress my retrained model successfully.
		</comment>
		<comment id='6' author='Bruczzz' date='2017-02-13T16:39:00Z'>
		If you look at the Slim library, there's a pretrained Inception v1 model that only has seven million parameters and so shrinks down to 7MB. You might want to try fine-tuning that.
&lt;denchmark-link:https://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained&gt;https://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained&lt;/denchmark-link&gt;

		</comment>
		<comment id='7' author='Bruczzz' date='2017-02-15T10:35:26Z'>
		Thanks you so much &lt;denchmark-link:https://github.com/petewarden&gt;@petewarden&lt;/denchmark-link&gt;
 for your information and time.
I tried fine tuning on V3 model using flower data as provided on tensorflow page, it is generating again a check point. Got stuck there with no clue of converting check point to .pb file. So that it can be compressed and used in android application.
I have tried  compression of  inception v3 model using quantization in two ways, but i feel quantizied model is getting corrupted or on classification something going wrong and producing incorrect results. Raised issue on that : &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7523&gt;#7523&lt;/denchmark-link&gt;

Please assist me.
Thanks
		</comment>
		<comment id='8' author='Bruczzz' date='2017-06-16T18:17:37Z'>
		Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
		</comment>
		<comment id='9' author='Bruczzz' date='2017-08-04T10:07:07Z'>
		I am runnning into the same error with the following code. As I am quite new to tensor flow I am trying to understand what is actually causing the abort
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1199967/paint2.txt&gt;paint2.txt&lt;/denchmark-link&gt;

I am sorry if it is a known bug. I am using python 3 tensorflow with pip install, GPU still not working.
		</comment>
		<comment id='10' author='Bruczzz' date='2017-10-07T13:52:27Z'>
		Hi, I encountered the same problem when working on Ubuntu 16.04 virtual machine with 1GB memory. I trained a neural network with weights of 84MB in total. Is it possible that the model ended up so huge to take up all memory?
		</comment>
		<comment id='11' author='Bruczzz' date='2017-11-25T08:52:04Z'>
		Hi,i have the same issue after running 4 epoch,and i have tested in other machin,but problem exists.
I use tensorflow 1.3,ubuntu 16.04,gtx 1080 gpu ,system ram=128
and i am working on shared server with 3 gpus
this is my trainig code:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/1502929/github.txt&gt;github.txt&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>