<bug id='44543' author='cookingbear' open_date='2020-11-03T09:41:14Z' closed_time='2020-11-19T15:33:09Z'>
	<summary>ERROR: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. ERROR: Node number 484 (FlexFusedBatchNormV3) failed to prepare.</summary>
	<description>
I use the version tf-nightly==2.5.0-dev20201029 and tested the tflite model
I converted the model into tflite and the python code below can run successfully.
&lt;denchmark-code&gt;interpreter = tf.lite.Interpreter(model_path="model.tflite")
for samples in data_queue:
            input_details = interpreter.get_input_details()
            output_details = interpreter.get_output_details()
            interpreter.resize_tensor_input(input_details[0]['index'], samples["input"].shape)
            interpreter.allocate_tensors()
            interpreter.set_tensor(input_details[0]['index'], samples["input"])
            interpreter.invoke()
            features = interpreter.get_tensor(output_details[0]['index'])
            self.vocoder(features.numpy()) 
&lt;/denchmark-code&gt;

However, when I use C++ code to test the tflite model, the erros below showed:
ERROR: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
ERROR: Node number 484 (FlexFusedBatchNormV3) failed to prepare.
	</description>
	<comments>
		<comment id='1' author='cookingbear' date='2020-11-03T17:14:20Z'>
		&lt;denchmark-link:https://github.com/cookingbear&gt;@cookingbear&lt;/denchmark-link&gt;

Please refer ot this issie with same error and let us know: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40157&gt;#40157&lt;/denchmark-link&gt;
 , &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/40677#issuecomment-653680600&gt;link&lt;/denchmark-link&gt;
.
Else please share a simple standalone to reproduce the error? Thanks!
		</comment>
		<comment id='2' author='cookingbear' date='2020-11-03T23:08:24Z'>
		
@cookingbear
Please refer ot this issie with same error and let us know: #40157 , link.
Else please share a simple standalone to reproduce the error? Thanks!

the code can be seen in &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/44520&gt;#44520&lt;/denchmark-link&gt;

and I do not think the problem is same as that from the link you shared.
can you please look into this?
		</comment>
		<comment id='3' author='cookingbear' date='2020-11-04T08:16:22Z'>
		&lt;denchmark-link:https://github.com/cookingbear&gt;@cookingbear&lt;/denchmark-link&gt;

The code shared in #$4520 does not have the error reported, i ran the code and see aonly a warning, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/88d4f6ce278ff55dc0bb404a4eb7f331/untitled458.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Can you please share a colab gist of the error reported,
		</comment>
		<comment id='4' author='cookingbear' date='2020-11-04T10:35:27Z'>
		
@cookingbear
The code shared in #$4520 does not have the error reported, i ran the code and see aonly a warning, please find the gist here.
Can you please share a colab gist of the error reported,

I just found that if I delete the line below, the similar errors metioned above would show during the tflite model converting process. the other codes remained the same.
&lt;denchmark-code&gt;converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                                                     tf.lite.OpsSet.SELECT_TF_OPS]
&lt;/denchmark-code&gt;

errors:
error: 'tf.FusedBatchNormV3' op is neither a custom op nor a flex op
:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
tf.FusedBatchNormV3 {data_format = "NHWC", device = "", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e+00 : f32, is_training = true}
The errors above are also related with FusedBatchNormV3 which is the same as that showed by inference using c++
		</comment>
		<comment id='5' author='cookingbear' date='2020-11-04T10:37:19Z'>
		

@cookingbear
The code shared in #$4520 does not have the error reported, i ran the code and see aonly a warning, please find the gist here.
Can you please share a colab gist of the error reported,

I just found that if I delete the line below, the similar errors metioned above would show during the tflite model converting process. the other codes remained the same.
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                                                     tf.lite.OpsSet.SELECT_TF_OPS]

errors:
error: 'tf.FusedBatchNormV3' op is neither a custom op nor a flex op
:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
tf.FusedBatchNormV3 {data_format = "NHWC", device = "", epsilon = 1.000000e-03 : f32, exponential_avg_factor = 1.000000e+00 : f32, is_training = true}
The errors above are also related with FusedBatchNormV3 which is the same as that showed by inference using c++

I mean that if you delete that line mentioned above in the colab, the errors would show. If this problem can be solved, maybe the original problem can be solved too.
		</comment>
		<comment id='6' author='cookingbear' date='2020-11-05T17:27:44Z'>
		I just found that the error is related with LayerNormalization. If I replace it with BatchNormalization, it can run successfully. But in my code, LayerNormalization is necessary. Although I can convert the code to the tflite model, it still show the error during inference using c++
		</comment>
		<comment id='7' author='cookingbear' date='2020-11-07T02:00:48Z'>
		&lt;denchmark-link:https://github.com/cookingbear&gt;@cookingbear&lt;/denchmark-link&gt;
 Please check this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/43934#issuecomment-714832778&gt;comment&lt;/denchmark-link&gt;
 which is similar to your issue. Also, check &lt;denchmark-link:https://www.tensorflow.org/lite/guide/ops_select&gt;this resource&lt;/denchmark-link&gt;
 on how to enable . Thanks!
		</comment>
		<comment id='8' author='cookingbear' date='2020-11-14T02:19:48Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='9' author='cookingbear' date='2020-11-19T15:33:10Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44543&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44543&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>