<bug id='33090' author='tlkh' open_date='2019-10-06T18:58:51Z' closed_time='2019-10-16T00:16:40Z'>
	<summary>model.evaluate gives unexpected results</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, but very close to example code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab and Ubuntu 18.04
TensorFlow installed from (source or binary): Source and binary
TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0 and v2.0.0-rc2-26-g64c3d38 2.0.0
Python version: 3.6.8 and 3.6.7
Bazel version (if compiling from source): 0.24.1
GCC/Compiler version (if compiling from source): 7.4.0
CUDA/cuDNN version: 10.0, 7.6
GPU model and memory: K80, V100 16GB

Describe the current behavior

model.fit() works and training converges
validation during training gives effectively random performance
model.evaluate() on both training and validation set gives random performance

Training and evaluating on the same training set gives random evaluation performance but expected training performance. Hence, there seems to be an issue with the evaluation in TF.
Describe the expected behavior
At very least, if I evaluate on the training set, I should see loss and accuracy similar to that is output during training.
Code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Check Colab notebook to reproduce the issue: &lt;denchmark-link:https://colab.research.google.com/drive/1HBdfWjx3jj65wrP_a0r_Tu80genKBsw2&gt;https://colab.research.google.com/drive/1HBdfWjx3jj65wrP_a0r_Tu80genKBsw2&lt;/denchmark-link&gt;

Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
Colab notebook should demonstrate everything and aid investigation.
Thanks in advance to anyone who can help!
	</description>
	<comments>
		<comment id='1' author='tlkh' date='2019-10-07T12:01:25Z'>
		Could reproduce the issue with Tensorflow Version 2.0. Training Loss is 0.6364 for model.fit but Training Loss is 4.4208 for model.evaluate.
Here is the &lt;denchmark-link:https://colab.sandbox.google.com/gist/rmothukuru/f04842c98ea2332523f10b37537f0596/33090.ipynb#scrollTo=-C5i8c_Vmgwy&gt;Gist&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='2' author='tlkh' date='2019-10-16T00:16:40Z'>
		&lt;denchmark-link:https://github.com/tlkh&gt;@tlkh&lt;/denchmark-link&gt;
 I think this is expected as your model is using BatchNorm. There are some layers (BatchNorm, Dropout) that are enabled during training and disabled while evaluation. If you disable BatchNorm and run the training (model.fit) and Evaluation (model.evaluate), the results should be very close (not exactly same). Please check this &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/735dcb2ba93dbbfd0574214765eabffd/tf33031.ipynb&gt;gist&lt;/denchmark-link&gt;
. This is similar to &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33031&gt;this issue&lt;/denchmark-link&gt;
. Thanks!
I am closing the issue as it was resolved. Please feel free to open it if the issue persists again. Thanks!
		</comment>
		<comment id='3' author='tlkh' date='2019-10-16T00:16:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33090&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33090&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='tlkh' date='2019-10-27T14:25:37Z'>
		&lt;denchmark-link:https://github.com/jvishnuvardhan&gt;@jvishnuvardhan&lt;/denchmark-link&gt;
 Thanks. Sorry for the late response, I was tied up with other matters. I have figured out that the actual issue is with the Keras Applications ResNet model, which has the BatchNorm layers, which . This results in the essentially random evaluation behavior. I will open a separate issue.
		</comment>
		<comment id='5' author='tlkh' date='2019-10-28T18:14:21Z'>
		&lt;denchmark-link:https://github.com/tlkh&gt;@tlkh&lt;/denchmark-link&gt;
 BatchNorm will always have different behavior b/t train and evaluate. During training, batches are normed. During inference, the trained weights are used for normalization. If you set trainable=False, these statistics will not update and so therefore will result in poor evaluation performance
		</comment>
		<comment id='6' author='tlkh' date='2019-12-01T04:37:50Z'>
		I have discovered the behavior of BatchNorm was changed specifically in TensorFlow 2.0 according to the docs in the code (which don't render correctly on the website). This answers my confusion why training that worked in TF 1.x does not work in TF 2.0
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization_v2.py#L26-L65&gt;https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization_v2.py#L26-L65&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>