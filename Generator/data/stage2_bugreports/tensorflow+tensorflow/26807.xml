<bug id='26807' author='jeffpollock9' open_date='2019-03-17T17:28:50Z' closed_time='2019-03-21T20:28:17Z'>
	<summary>[TF 2.0] tf 2 doesn't allow static unrolling of loops which can be slower</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.13.1
Python version: Python 3.6.7
CUDA/cuDNN version: 10.0/7.4
GPU model and memory: GeForce GTX 1060, Compute Capability 6.1, 6GB RAM

Describe the current behavior
There doesn't appear to be any way to unroll a loop statically when using tf.function. In tensorflow 1 I was able to create lots of nodes in a graph using a for loop, when using tf.function autograph replaces this with a tf.while_loop which seems to be slower in some cases.
Describe the expected behavior
There should be a way to statically unroll a loop when using tf.function for performance reasons.
Code to reproduce the issue
This code calculates a matrix exponential using a taylor series. I also noticed that has gotten a lot slower but that was not my main interest in this issue (I believe the implementation for that has changed to support autodiff, see &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/15465&gt;#15465&lt;/denchmark-link&gt;
)
output (using the latest tensorflow-gpu and tensorflow-gpu==2.0.0-alpha respectively from pip):
(tf1) $ python expm.py 
BENCHMARKS:
tf took 0.1753 seconds for 25 iterations
taylor took 0.0146 seconds for 25 iterations

(tf2) $ python expm.py 
BENCHMARKS:
tf took 0.7331 seconds for 25 iterations
taylor took 1.0135 seconds for 25 iterations
taylor_v2 took 0.5931 seconds for 25 iterations
input:
import tensorflow as tf
import numpy as np
import time as tm

MATRIX_DIM = 1000
TAYLOR_SUM = 30
EPS = 1e-2
WARMUP = 10
ITERATIONS = 25


def benchmark(name, fn):
    for _ in range(WARMUP):
        value = fn()
    start = tm.time()
    for _ in range(ITERATIONS):
        value = fn()
    end = tm.time()
    runtime = end - start
    print(f"{name} took {runtime:.4f} seconds for {ITERATIONS} iterations")
    return value


def taylor_expm(x, n):
    x_0 = tf.eye(tf.shape(x)[0], dtype=x.dtype)
    x_i = x
    y = x_0 + x_i
    for i in range(2, n + 1):
        x_i = (x_i @ x) / tf.cast(i, x.dtype)
        y = y + x_i
    return y


np.random.seed(42)

x = tf.constant(np.random.uniform(-0.5, 0.5, [MATRIX_DIM, MATRIX_DIM]), tf.float32)

if tf.__version__.startswith("2"):

    @tf.function
    def taylor_expm_v2(x, n):
        return taylor_expm(x, n)

    print("\nBENCHMARKS:")
    tf_expm = benchmark("tf", lambda: tf.linalg.expm(x))
    my_expm = benchmark("taylor", lambda: taylor_expm(x, TAYLOR_SUM))
    my_expm_v2 = benchmark("taylor_v2", lambda: taylor_expm_v2(x, TAYLOR_SUM))

    np.testing.assert_allclose(tf_expm.numpy(), my_expm.numpy(), atol=EPS)
    np.testing.assert_allclose(tf_expm.numpy(), my_expm_v2.numpy(), atol=EPS)
else:
    tf_expm_ = tf.linalg.expm(x)
    my_expm_ = taylor_expm(x, TAYLOR_SUM)

    with tf.Session() as sess:
        print("\nBENCHMARKS:")
        tf_expm = benchmark("tf", lambda: sess.run(tf_expm_))
        my_expm = benchmark("taylor", lambda: sess.run(my_expm_))

    np.testing.assert_allclose(tf_expm, my_expm, atol=EPS)
	</description>
	<comments>
		<comment id='1' author='jeffpollock9' date='2019-03-21T20:16:22Z'>
		The loop is actually being unrolled in this example. You can verify this by inserting a few print statements:
&lt;denchmark-code&gt;    print('trace 1')
    for i in range(2, n + 1):
        print('trace 2')
        ...
&lt;/denchmark-code&gt;

Out of curiosity, I tried a version that uses tf.while_loop, like so:
&lt;denchmark-code&gt;    for i in tf.range(2, n + 1):
        ...
&lt;/denchmark-code&gt;

and that didn't seem to change the results significantly in my tests.
		</comment>
		<comment id='2' author='jeffpollock9' date='2019-03-21T20:19:15Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

Out of curiosity, I tried a mostly-empty function:
&lt;denchmark-code&gt;def taylor_expm_empty(x, n):
    x_0 = tf.eye(tf.shape(x)[0], dtype=x.dtype)
    x_i = x
    y = x_0 + x_i
    return y
&lt;/denchmark-code&gt;

The results were comparable with taylor_v2. So I wonder whether we're looking at invocation overhead here?
		</comment>
		<comment id='3' author='jeffpollock9' date='2019-03-21T20:28:17Z'>
		&lt;denchmark-link:https://github.com/mdanatg&gt;@mdanatg&lt;/denchmark-link&gt;
 you're most likely looking at function building / pruning / first execution overhead, yes.
		</comment>
		<comment id='4' author='jeffpollock9' date='2019-03-21T20:28:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26807&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26807&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='jeffpollock9' date='2019-03-21T21:26:16Z'>
		Many thanks for your time looking at this. I can see now that some static unrolling of the loop is happening, however I'm still not sure how to make the v2 version as fast as the v1 version, which might make tf2 unusable for some work I am doing.
Is there any way to make the tf2 version competitive?
		</comment>
		<comment id='6' author='jeffpollock9' date='2019-03-21T21:42:03Z'>
		&lt;denchmark-link:https://github.com/jeffpollock9&gt;@jeffpollock9&lt;/denchmark-link&gt;
 can you run your code through a profiler (like cProfiler in python) to find out what the bottlenecks are?
Happy to work on improving the performance of TF v2.
		</comment>
		<comment id='7' author='jeffpollock9' date='2019-03-22T09:27:25Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 I've tried to run the code through &lt;denchmark-link:https://docs.python.org/3.6/library/profile.html#profile.Profile&gt;cProfile&lt;/denchmark-link&gt;
 (mostly just copied their example) and profile the same code which was being timed, but I don't think it gives anything particularly useful (likely just my misunderstanding, though). Looks like it is spending all of the time in ?
output:
&lt;denchmark-code&gt;BENCHMARKS:
tf took 0.7202 seconds for 25 iterations
taylor took 1.1474 seconds for 25 iterations
taylor_v2 took 0.5886 seconds for 25 iterations

PROFILES:
profile for taylor_v2
         2251 function calls in 0.592 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       25    0.000    0.000    0.592    0.024 expm.py:73(&lt;lambda&gt;)
       25    0.000    0.000    0.592    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py:400(__call__)
       25    0.000    0.000    0.591    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:1267(__call__)
       25    0.000    0.000    0.590    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:542(_filtered_call)
       25    0.000    0.000    0.590    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:560(_call_flat)
       25    0.000    0.000    0.589    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:379(call)
       25    0.000    0.000    0.588    0.024 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py:33(quick_execute)
       25    0.588    0.024    0.588    0.024 {built-in method _pywrap_tensorflow_internal.TFE_Py_Execute}
       25    0.000    0.000    0.001    0.000 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:1505(_maybe_define_function)
       25    0.000    0.000    0.001    0.000 /home/jeff/.virtualenvs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py:1414(_cache_key)
   ...
&lt;/denchmark-code&gt;

input:
import tensorflow as tf
import numpy as np
import time as tm
import cProfile as pr
import io
import pstats as ps

MATRIX_DIM = 1000
TAYLOR_SUM = 30
EPS = 1e-2
WARMUP = 10
ITERATIONS = 25


def benchmark(name, fn):
    for _ in range(WARMUP):
        value = fn()
    start = tm.time()
    for _ in range(ITERATIONS):
        value = fn()
    end = tm.time()
    runtime = end - start
    print(f"{name} took {runtime:.4f} seconds for {ITERATIONS} iterations")
    return value


def profile(name, fn):
    for _ in range(WARMUP):
        value = fn()

    profile = pr.Profile()
    profile.enable()

    for _ in range(ITERATIONS):
        value = fn()

    profile.disable()
    s = io.StringIO()
    sortby = "cumulative"
    stats = ps.Stats(profile, stream=s).sort_stats(sortby)
    stats.print_stats()
    print(f"profile for {name}")
    print(s.getvalue())

    return value


def taylor_expm(x, n):
    x_0 = tf.eye(tf.shape(x)[0], dtype=x.dtype)
    x_i = x
    y = x_0 + x_i
    for i in range(2, n + 1):
        x_i = (x_i @ x) / tf.cast(i, x.dtype)
        y = y + x_i
    return y


@tf.function
def taylor_expm_v2(x, n):
    return taylor_expm(x, n)


np.random.seed(42)

x = tf.constant(np.random.uniform(-0.5, 0.5, [MATRIX_DIM, MATRIX_DIM]), tf.float32)

print("\nBENCHMARKS:")
tf_expm = benchmark("tf", lambda: tf.linalg.expm(x))
my_expm = benchmark("taylor", lambda: taylor_expm(x, TAYLOR_SUM))
my_expm_v2_b = benchmark("taylor_v2", lambda: taylor_expm_v2(x, TAYLOR_SUM))

print("\nPROFILES:")
my_expm_v2_p = profile("taylor_v2", lambda: taylor_expm_v2(x, TAYLOR_SUM))

np.testing.assert_allclose(tf_expm.numpy(), my_expm.numpy(), atol=EPS)
np.testing.assert_allclose(tf_expm.numpy(), my_expm_v2_b.numpy(), atol=EPS)
np.testing.assert_allclose(tf_expm.numpy(), my_expm_v2_p.numpy(), atol=EPS)
		</comment>
		<comment id='8' author='jeffpollock9' date='2019-03-25T17:11:38Z'>
		This shows that most of the execution time of your program is indeed inside tensorflow's runtime, and not python overhead, so slow graph building is not the cause for your poor performance.
		</comment>
		<comment id='9' author='jeffpollock9' date='2019-03-25T21:58:03Z'>
		Any idea what is the cause then? A sequence of matrix multiplications with some element wise addition and division being approximately 40 times slower with the tensorflow 2 runtime feels very worrying to me. I hope I have made a mistake somewhere but I am really struggling to see where.
Also please let me know if it is worth opening another issue for this.
		</comment>
		<comment id='10' author='jeffpollock9' date='2019-03-25T23:03:19Z'>
		I think it's worth opening another issue, yes.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Mon, Mar 25, 2019 at 3:01 PM Jeff ***@***.***&gt; wrote:
 Any idea what is the cause then? A sequence of matrix multiplications with
 some element wise addition and division being approximately 40 times slower
 with the tensorflow 2 runtime feels very worrying to me. I hope I have made
 a mistake somewhere but I am really struggling to see where.

 Also please let me know if it is worth opening another issue for this.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#26807 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxYinQnaXqsCAZ3f1fT4F86KDs58Dks5vaUc3gaJpZM4b4huJ&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='11' author='jeffpollock9' date='2019-03-26T09:51:42Z'>
		Many thanks to everyone with your help on this, I have opened a new issue as per &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
's suggestion (&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27143&gt;#27143&lt;/denchmark-link&gt;
) so can continue this discussion there.
		</comment>
	</comments>
</bug>