<bug id='11888' author='rubenvereecken' open_date='2017-07-30T20:23:11Z' closed_time='2019-08-06T22:05:11Z'>
	<summary>Can't import graph containing MutableHashTable</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 18
TensorFlow installed from (source or binary): Binary (pip)
TensorFlow version (use command below): v1.3.0.0rc0
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

Import a meta graph containing MutableHashTable operations fails. The MutableHashTable in my use case is named and inside a scope. After some digging around I found that the error is a result of a collection saveable_objects containing names of MutableHashTables but without the proper scoping.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

&lt;denchmark-code&gt;graph = create_eval_graph()
tf.train.export_meta_graph('eval_model.meta', graph=graph, as_text=True)

# ...
s = tf.train.import_meta_graph('eval_model.meta') # Fails 
&lt;/denchmark-code&gt;

This throws the following
&lt;denchmark-code&gt;---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-238-7de9a7b0d1f2&gt; in &lt;module&gt;()
----&gt; 1 s = tf.train.import_meta_graph('eval_model.meta')

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1696                                       clear_devices=clear_devices,
   1697                                       import_scope=import_scope,
-&gt; 1698                                       **kwargs)
   1699   if meta_graph_def.HasField("saver_def"):
   1700     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    690           for value in field.value:
    691             col_op = graph.as_graph_element(
--&gt; 692                 ops.prepend_name_scope(value, scope_to_prepend_to_names))
    693             graph.add_to_collection(key, col_op)
    694         elif kind == "int64_list":

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)
   2704 
   2705     with self._lock:
-&gt; 2706       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
   2707 
   2708   def _as_graph_element_locked(self, obj, allow_tensor, allow_operation):

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)
   2764         if name not in self._nodes_by_name:
   2765           raise KeyError("The name %s refers to an Operation not in the "
-&gt; 2766                          "graph." % repr(name))
   2767         return self._nodes_by_name[name]
   2768 

KeyError: "The name 'lstm_c_table' refers to an Operation not in the graph."
&lt;/denchmark-code&gt;

Where lstm_c_table is created as follows
&lt;denchmark-code&gt;tf.contrib.lookup.MutableHashTable(key_dtype=tf.string, value_dtype=tf.float32, default_value=value, name='lstm_c_table')
&lt;/denchmark-code&gt;

I looked at the generated proto and it contains the following node:
&lt;denchmark-code&gt;  node {
    name: "input/lstm_c_table"
    op: "MutableHashTableOfTensorsV2"
    attr {
      key: "_output_shapes"
      value {
        list {
          shape {
          }
        }
      }
    }
    attr {
      key: "container"
      value {
        s: ""
      }
    }
    attr {
      key: "key_dtype"
      value {
        type: DT_STRING
      }
    }
    attr {
      key: "shared_name"
      value {
        s: ""
      }
    }
    attr {
      key: "use_node_name_sharing"
      value {
        b: true
      }
    }
    attr {
      key: "value_dtype"
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: "value_shape"
      value {
        shape {
          dim {
            size: 512
          }
        }
      }
    }
  }
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;collection_def {
  key: "saveable_objects"
  value {
    node_list {
      value: "lstm_c_table"
      value: "lstm_h_table"
      value: "history_table"
      value: "first_table"
      value: "encode_lstm_c_table"
      value: "encode_lstm_h_table"
    }
  }
}
&lt;/denchmark-code&gt;

Either removing the above collection or prefixing all the values with input/ results in the following error:
&lt;denchmark-code&gt;TypeError: Can't convert Operation 'input/lstm_c_table' to Tensor (target dtype=None, name=None, as_ref=True)
&lt;/denchmark-code&gt;

This solution is part of an imitation of batch_sequences_with_states so a graph can be exported that does not rely on queues but instead uses placeholders and the feed_dict mechanism, for use in interactive model evaluation.
	</description>
	<comments>
		<comment id='1' author='rubenvereecken' date='2018-06-16T01:45:58Z'>
		Hello, i got the same problem. tf.train.import_meta_graph when graph contain MutableHashTables. Did you have a solution?
		</comment>
		<comment id='2' author='rubenvereecken' date='2018-06-16T08:31:27Z'>
		A terrible, terrible solution, yes. Save all the information you can and
rebuild the graph. But that requires the code to be the same, it gets
messy.

Best of luck.
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Sat, 16 Jun 2018, 02:48 Zhouwei, ***@***.***&gt; wrote:
 Hello, i got the same problem. tf.train.import_meta_graph when graph
 contain MutableHashTables. Did you have a solution?

 —
 You are receiving this because you authored the thread.
 Reply to this email directly, view it on GitHub
 &lt;#11888 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AE-ZKa0RyGplajVc4LbiERntI7CrrqYRks5t9GPygaJpZM4OnvHn&gt;
 .



		</comment>
		<comment id='3' author='rubenvereecken' date='2018-06-16T14:31:43Z'>
		Right, that works. But not flexible, i will keep working on it... Thank you.
		</comment>
		<comment id='4' author='rubenvereecken' date='2018-08-23T16:48:34Z'>
		The scope-propagation issue is still present in v1.10.0
		</comment>
		<comment id='5' author='rubenvereecken' date='2019-08-06T22:05:11Z'>
		This is a stale issue. Please check the issue with latest TensorFlow. If the issue still persists in the newer version of TF, please feel free to reopen it by providing details about the issue and a standalone code to reproduce the issue. Thanks!
		</comment>
		<comment id='6' author='rubenvereecken' date='2019-08-06T22:05:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=11888&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=11888&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>