<bug id='25478' author='dvisztempacct' open_date='2019-02-04T05:04:02Z' closed_time='2019-02-05T00:24:02Z'>
	<summary>TF 1.11.0 Updating non-Variables?</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes https://gist.github.com/dvisztempacct/43e738e1651ecf61323ae92cae41c94c
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu Bionic Derivative (System76 PopOS)
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
n/a
TensorFlow installed from (source or binary):

&lt;denchmark-code&gt;pip3 install tensorflow==1.11.0
&lt;/denchmark-code&gt;


TensorFlow version (use command below):

&lt;denchmark-code&gt;$ python3 -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!
  RequestsDependencyWarning)
v1.11.0-0-gc19e29306c 1.11.0
&lt;/denchmark-code&gt;


Python version:

&lt;denchmark-code&gt;$ python3 --version
Python 3.6.7
&lt;/denchmark-code&gt;


Bazel version (if compiling from source):
n/a
GCC/Compiler version (if compiling from source):
n/a
CUDA/cuDNN version:

&lt;denchmark-code&gt;$ dpkg -l | grep -iE 'cuda|cudnn'
ii  cuda-repo-ubuntu1604                             9.0.176-1                           amd64        cuda repository configuration files
ii  system76-cuda                                    0pop2                               amd64        NVIDIA CUDA Compiler / Libraries / Toolkit Metapackage
ii  system76-cuda-9.0                                0pop3                               amd64        NVIDIA CUDA 9.0 Compiler / Libraries / Toolkit
ii  system76-cuda-9.2                                0pop3                               amd64        NVIDIA CUDA 9.2 Compiler / Libraries / Toolkit
ii  system76-cudnn-9.0                               7.1.4~0pop1                         amd64        NVIDIA CUDA Deep Neural Network library (cuDNN) for CUDA 9.0
&lt;/denchmark-code&gt;


GPU model and memory:

&lt;denchmark-code&gt;$ lspci | grep VGA
00:02.0 VGA compatible controller: Intel Corporation Device 3e9b
01:00.0 VGA compatible controller: NVIDIA Corporation GP104M [GeForce GTX 1070 Mobile] (rev a1)
$ nvidia-smi
Sun Feb  3 20:54:44 2019
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.78       Driver Version: 410.78       CUDA Version: 10.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:01:00.0  On |                  N/A |
| N/A   52C    P5    16W /  N/A |    682MiB /  8119MiB |     29%      Default |
+-------------------------------+----------------------+----------------------+
&lt;/denchmark-code&gt;

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
Non-variables seem to be being updated.
Describe the expected behavior
Non-variables should be initialized when running tf.global_variables_initializer and otherwise not updated.

&lt;denchmark-link:https://gist.github.com/dvisztempacct/43e738e1651ecf61323ae92cae41c94c&gt;https://gist.github.com/dvisztempacct/43e738e1651ecf61323ae92cae41c94c&lt;/denchmark-link&gt;


&lt;denchmark-link:https://user-images.githubusercontent.com/37460069/52190947-d2961500-27f6-11e9-9585-27ad0a23432c.png&gt;&lt;/denchmark-link&gt;

I may simply be misunderstanding how tf.random_normal is supposed to work, but I had thought if I didn't initialize a tf.Variable using the tensor returned by tf.random_normal (as I do on line 12) that it would only be initialized by tf.global_variables_initializer or similar, and wouldn't be updated or reinitialized upon subsequent runs unless I included such an initializer.
Thanks!
	</description>
	<comments>
		<comment id='1' author='dvisztempacct' date='2019-02-05T00:24:01Z'>
		tf.random_normal is a stateful operation. This means every time it's executed its output tensor might have a different value (or that it might have side effects). So I think the behavior you're observing is by design.
If you want a constant random normal vector use tf.constant(np.random.normal(...)), say.
		</comment>
		<comment id='2' author='dvisztempacct' date='2019-02-05T18:19:42Z'>
		Hi &lt;denchmark-link:https://github.com/alex-petrenko&gt;@alex-petrenko&lt;/denchmark-link&gt;
 I did try :
&lt;denchmark-code&gt;import tensorflow as tf
foo = tf.random_normal(
    shape=[],
    mean=0.0,
    stddev=1.0,
    name='train_x'
)
train_x = tf.constant(foo, shape=foo.shape)
&lt;/denchmark-code&gt;

The output:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "bug.py", line 8, in &lt;module&gt;
    train_x = tf.constant(foo, shape=foo.shape)
  File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 207, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 442, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 350, in _AssertCompatible
    raise TypeError("List of Tensors when single Tensor expected")
TypeError: List of Tensors when single Tensor expected
&lt;/denchmark-code&gt;

The only thing that did work for me was a tf.Variable with trainable=False. Which leads me to wonder: what is the difference between a tf.constant and tf.Variable with trainable=False?
Thanks!
Edit: Thanks also for the note about random_normal being stateful. I had assumed that once initialized, its value would not change when the graph is reevaluated.
		</comment>
		<comment id='3' author='dvisztempacct' date='2019-02-05T18:42:49Z'>
		tf.constant takes a numpy array as an argument, not a tensor
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Feb 5, 2019 at 10:25 AM Don Viszneki ***@***.***&gt; wrote:
 Hi @alex-petrenko &lt;https://github.com/alex-petrenko&gt; I did try tf.constant
 :

 import tensorflow as tf
 foo = tf.random_normal(
     shape=[],
     mean=0.0,
     stddev=1.0,
     name='train_x'
 )
 train_x = tf.constant(foo, shape=foo.shape)

 The output:

 Traceback (most recent call last):
   File "bug.py", line 8, in &lt;module&gt;
     train_x = tf.constant(foo, shape=foo.shape)
   File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py", line 207, in constant
     value, dtype=dtype, shape=shape, verify_shape=verify_shape))
   File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 442, in make_tensor_proto
     _AssertCompatible(values, dtype)
   File "/home/hdon/.local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py", line 350, in _AssertCompatible
     raise TypeError("List of Tensors when single Tensor expected")
 TypeError: List of Tensors when single Tensor expected

 The only thing that did work for me was a tf.Variable with trainable=False.
 Which leads me to wonder: what is the difference between a tf.constant
 and tf.Variable with trainable=False?

 Thanks!

 —
 You are receiving this because you modified the open/close state.
 Reply to this email directly, view it on GitHub
 &lt;#25478 (comment)&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAATxfJn3T_RL7PGXi51IFyEyaTXWkwhks5vKcx7gaJpZM4agjd4&gt;
 .


-- 
 - Alex

		</comment>
	</comments>
</bug>