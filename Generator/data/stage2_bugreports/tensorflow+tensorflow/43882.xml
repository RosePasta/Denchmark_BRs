<bug id='43882' author='reuvenperetz' open_date='2020-10-08T14:56:33Z' closed_time='2020-11-21T21:06:10Z'>
	<summary>folding batchnorm into conv in per-tensor weights quantization</summary>
	<description>
System information

OS Platform and Distribution: Linux Ubuntu 18.04
TensorFlow installed from: binary
TensorFlow version (or github SHA if from source): 2.3.1

Command used to run the converter or code if youâ€™re using the Python API
I took the keras qat tutorial and added a BatchNormalization layer in between the Conv2D and ReLU:
&lt;denchmark-code&gt;import tempfile
import os
import tensorflow as tf
from tensorflow import keras

mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.InputLayer(input_shape=(28, 28)),
    keras.layers.Reshape(target_shape=(28, 28, 1)),
    keras.layers.Conv2D(filters=12, kernel_size=(3, 3)),
    keras.layers.BatchNormalization(),
    keras.layers.ReLU(),
    keras.layers.MaxPooling2D(pool_size=(2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(10)
])
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
    train_images,
    train_labels,
    epochs=1,
    validation_split=0.1,
)
import tensorflow_model_optimization as tfmot
quantize_model = tfmot.quantization.keras.quantize_model
q_aware_model = quantize_model(model)
q_aware_model.compile(optimizer='adam',
                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                      metrics=['accuracy'])
train_images_subset = train_images[0:1000]  # out of 60000
train_labels_subset = train_labels[0:1000]
q_aware_model.fit(train_images_subset, train_labels_subset,
                  batch_size=500, epochs=1, validation_split=0.1)
converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

quantized_tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
    f.write(quantized_tflite_model)
&lt;/denchmark-code&gt;

When I quantize the weights per-channel, I can see (using Netron) that the BatchNorm was folded into Conv2D (as I expect it to be). When I changed &lt;denchmark-link:https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantizers.py&gt;Default8BitConvWeightsQuantizer&lt;/denchmark-link&gt;
 to use per-tensor quantization (flipping per-axis flag and removing shape arguments in build), I saw that the BatchNorm was not folded.
Is this the way it should be? Or is it an issue?
The output from the converter invocation
&lt;denchmark-code&gt;WARNING:tensorflow:From ***/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-10-08 17:35:12.606042: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From ***/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-10-08 17:35:13.543657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-08 17:35:13.544090: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 1
2020-10-08 17:35:13.544145: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-10-08 17:35:13.601942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-08 17:35:13.602363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7313c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-08 17:35:13.602374: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-10-08 17:35:13.602525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-08 17:35:13.602870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-10-08 17:35:13.603313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-08 17:35:13.603317: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-10-08 17:35:13.603326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-08 17:35:13.603330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-10-08 17:35:13.603333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-10-08 17:35:13.604761: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-10-08 17:35:13.604769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-10-08 17:35:13.604772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-10-08 17:35:13.650284: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-10-08 17:35:13.650302: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
2020-10-08 17:35:13.653368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-08 17:35:13.653747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-10-08 17:35:13.654132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-10-08 17:35:13.654135: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-10-08 17:35:13.654145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-08 17:35:13.654148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-10-08 17:35:13.654151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 

Process finished with exit code 0

&lt;/denchmark-code&gt;

Thanks!
	</description>
	<comments>
		<comment id='1' author='reuvenperetz' date='2020-10-09T06:40:18Z'>
		&lt;denchmark-link:https://github.com/reuvenperetz&gt;@reuvenperetz&lt;/denchmark-link&gt;

I ran the code shared on tf 2.3 and do not face any error, please find the &lt;denchmark-link:https://colab.research.google.com/gist/Saduf2019/b9ea6d386228f2a83eb1bd136e3e8476/untitled427.ipynb&gt;gist here&lt;/denchmark-link&gt;
.
Please provide with colab gist the error reported.
		</comment>
		<comment id='2' author='reuvenperetz' date='2020-10-09T07:14:36Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 How did you test this folding in colab?
He asked:

When I quantize the weights per-channel, I can see (using Netron) that the BatchNorm was folded into Conv2D (as I expect it to be). When I changed Default8BitConvWeightsQuantizer to use per-tensor quantization (flipping per-axis flag and removing shape arguments in build), I saw that the BatchNorm was not folded.
Is this the way it should be? Or is it an issue?

		</comment>
		<comment id='3' author='reuvenperetz' date='2020-10-10T12:33:33Z'>
		I used Netron to check it.
Graph when I quantize it per-tensor:
&lt;denchmark-link:https://user-images.githubusercontent.com/44209964/95655008-00c01200-0b0d-11eb-9d84-13e3d99be95d.jpg&gt;&lt;/denchmark-link&gt;

Graph when I quantize it per-channel:
&lt;denchmark-link:https://user-images.githubusercontent.com/44209964/95655044-47ae0780-0b0d-11eb-92fb-dd8612792b2a.jpg&gt;&lt;/denchmark-link&gt;

By the way, the batchnorm is folded in both cases when I don't use the MLIR converter (converter.experimental  converter=False)
		</comment>
		<comment id='4' author='reuvenperetz' date='2020-10-20T19:45:55Z'>
		&lt;denchmark-link:https://github.com/karimnosseir&gt;@karimnosseir&lt;/denchmark-link&gt;

With the focus on these layers in the model... Conv2d --&gt; BatchNorm --&gt; ReLu
For per-channel quantization:
For per-channel quantization + TOCO converter:
For per-tensor quantization (TF code modified by the user) + TOCO converter:

All 3 layers are combined into one layer.

For per-tensor quantization (TF code modified by the user):

All 3 layers are NOT combined into one layer.

We can ignore the usage of TOCO converter as that will be soon deprecated, however:

Do we support per tensor quantized models? (instead of users modifying the TF code)
If we do/don't, is the above behavior expected? (The 3 layers are NOT combined/folded into one unit)

		</comment>
		<comment id='5' author='reuvenperetz' date='2020-11-21T21:06:10Z'>
		Actually the one with the old (deprecated) converter is wrong, and the one with the new converter (default) is correct.
Let me try to explain,
Keras by default sets dynamic batch size to true.
That means that the model input shape is [*,28,28] not [1,28,28].
The old(deprecated) converter used to ignore the dynamic batch and override this to 1 - which is wrong since this is not what the original model has - you can imagine how bad it will be when you try to resize the inputs at runtime.
The current converter instead handles the dynamic batch size correct, and the model generated can be resized at runtime correct.
That's why the sequence of "Shape, StridedSlice, Pack" wasn't constant folded, since the shape is dependent on the shape defined at runtime.
If you don't want dynamic batch in the final model, then set the model before converting to have a static shape.
For example,
input_name = model.input_names[0]
index = model.input_names.index(input_name)
q_aware_model.inputs[index].set_shape([1, 28, 28])
converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
quantized_tflite_model = converter.convert()
Hope that helps
Thanks
		</comment>
		<comment id='6' author='reuvenperetz' date='2020-11-21T21:06:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43882&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43882&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>