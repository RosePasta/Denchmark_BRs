<bug id='38233' author='phuongchi911' open_date='2020-04-05T07:09:20Z' closed_time='2020-05-04T03:32:02Z'>
	<summary>ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0',</summary>
	<description>
System information
Colab tensorflow 2.2.0
Describe the current behavior:
I faced this error when i tried   to solve my own data issues, which is multiple label semantic segmentations. When I ran on Jupiter notebook on my local Mac Book with Keras installation (not tf.keras but keras only), model could train normally as expected as below.
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/78468464-fdf1f800-774a-11ea-9dc3-315a49fc430e.png&gt;&lt;/denchmark-link&gt;

However, I stopped training the whole model on local Mac Book due to its limited memory and capability and I switched to Colab, Tensorflow version:  2.2.0-rc2 and faced this error:
    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0'].
Full error:
&lt;denchmark-h:h2&gt;Epoch 1/40&lt;/denchmark-h&gt;

ValueError                                Traceback (most recent call last)
 in ()
5     callbacks=callbacks,
6     validation_data=valid_dataloader,
----&gt; 7     validation_steps=(no_of_validation_images//1),verbose=1
8 )
10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
64   def _method_wrapper(self, *args, **kwargs):
65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---&gt; 66       return method(self, *args, **kwargs)
67
68     # Running inside run_distribute_coordinator already.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
783                 batch_size=batch_size):
784               callbacks.on_train_batch_begin(step)
--&gt; 785               tmp_logs = train_function(iterator)
786               # Catch OutOfRangeError for Datasets of unknown size.
787               # This blocks until the batch has finished executing.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in call(self, *args, **kwds)
578         xla_context.Exit()
579     else:
--&gt; 580       result = self._call(*args, **kwds)
581
582     if tracing_count == self._get_tracing_count():
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
625       # This is the first call of call, so we have to initialize.
626       initializers = []
--&gt; 627       self._initialize(args, kwds, add_initializers_to=initializers)
628     finally:
629       # At this point we know that the initialization is complete (or less
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
504     self._concrete_stateful_fn = (
505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--&gt; 506             *args, **kwds))
507
508     def invalid_creator_scope(*unused_args, **unused_kwds):
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
2444       args, kwargs = None, None
2445     with self._lock:
-&gt; 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
2447     return graph_function
2448
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
2775
2776       self._function_cache.missed.add(call_context_key)
-&gt; 2777       graph_function = self._create_graph_function(args, kwargs)
2778       self._function_cache.primary[cache_key] = graph_function
2779       return graph_function, args, kwargs
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
2665             arg_names=arg_names,
2666             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2667             capture_by_value=self._capture_by_value),
2668         self._function_attributes,
2669         # Tell the ConcreteFunction to clean up its graph once it goes out of
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
979         _, original_func = tf_decorator.unwrap(python_func)
980
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
982
983       # invariant: func_outputs contains only Tensors, CompositeTensors,
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
439         # wrapped allows AutoGraph to swap in a converted function. We give
440         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 441         return weak_wrapped_fn().wrapped(*args, **kwds)
442     weak_wrapped_fn = weakref.ref(wrapped_fn)
443
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
966           except Exception as e:  # pylint:disable=broad-except
967             if hasattr(e, "ag_error_metadata"):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
969             else:
970               raise
ValueError: in user code:
&lt;denchmark-code&gt;/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *
    outputs = self.distribute_strategy.run(
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
    return fn(*args, **kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:475 train_step  **
    self.trainable_variables)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1741 _minimize
    trainable_variables))
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:525 _aggregate_gradients
    filtered_grads_and_vars = _filter_grads(grads_and_vars)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1203 _filter_grads
    ([v.name for _, v in grads_and_vars],))

ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0', 'conv2d_11/kernel:0', 'conv2d_11/bias:0', 'conv2d_transpose_1/kernel:0', 'conv2d_transpose_1/bias:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0', 'conv2d_13/kernel:0', 'conv2d_13/bias:0', 'conv2d_transpose_2/kernel:0', 'conv2d_transpose_2/bias:0', 'conv2d_14/kernel:0', 'conv2d_14/bias:0', 'conv2d_15/kernel:0', 'conv2d_15/bias:0', 'conv2d_transpose_3/kernel:0', 'conv2d_transpose_3/bias:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'conv2d_18/kernel:0', 'conv2d_18/bias:0'].
&lt;/denchmark-code&gt;

Describe the expected behavior:
Could train model
Standalone code to reproduce the issue
Thank you for looking into this
	</description>
	<comments>
		<comment id='1' author='phuongchi911' date='2020-04-06T08:06:33Z'>
		&lt;denchmark-link:https://github.com/phuongchi911&gt;@phuongchi911&lt;/denchmark-link&gt;
, Thanks for reporting this issue.
Can you provide the access to the dataset. Thanks
		</comment>
		<comment id='2' author='phuongchi911' date='2020-04-06T08:28:40Z'>
		
@phuongchi911, Thanks for reporting this issue.
Can you provide the access to the dataset. Thanks

&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 thanks so much for fast response. Please kindly refer to this link for the dataset
I am looking forward to your advice.
		</comment>
		<comment id='3' author='phuongchi911' date='2020-04-09T06:38:14Z'>
		&lt;denchmark-link:https://github.com/phuongchi911&gt;@phuongchi911&lt;/denchmark-link&gt;
, I tried to replicate the issue but getting different error.
PLease take a look at the &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb&gt;gist&lt;/denchmark-link&gt;
 and confirm the issue. Thanks
		</comment>
		<comment id='4' author='phuongchi911' date='2020-04-09T06:59:45Z'>
		
@phuongchi911, I tried to replicate the issue but getting different error.
PLease take a look at the gist and confirm the issue. Thanks

&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 may you confirm if this is the error u see? If yes, please help to restart the runtime and run all over again after u installed the segmentation model above. Error will dissappear.
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/78866603-4a527600-7a72-11ea-92b5-7e883945c6fb.png&gt;&lt;/denchmark-link&gt;

The error I am facing is when I was trying to run this block of code below to train my model which I mentioned in my first post.
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/78866702-7c63d800-7a72-11ea-9424-c1b3316b9eb2.png&gt;&lt;/denchmark-link&gt;

I did not face this error if I use keras only on jupyter notebook on my local Macbook. But since my Mac is not strong enough to train the whole model, so  i stopped and swtiched to Colab and face the error. Thank you very much for looking into this
		</comment>
		<comment id='5' author='phuongchi911' date='2020-04-14T12:11:55Z'>
		&lt;denchmark-link:https://github.com/phuongchi911&gt;@phuongchi911&lt;/denchmark-link&gt;
, After installing segmentation-models still it is giving . Please take a look at &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/3e94edfb9e87d78e7165272011bab509/untitled498.ipynb&gt;gist&lt;/denchmark-link&gt;
. Thanks
		</comment>
		<comment id='6' author='phuongchi911' date='2020-04-14T12:45:48Z'>
		
@phuongchi911, After installing segmentation-models still it is giving no module named 'segmentation_models'. Please take a look at gist. Thanks

&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
  yes what i did to avoid that error was
1/after first installation when u ran this line of code import segmentation_models as sm there would prompt error below
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/79226050-508c8c00-7e90-11ea-931e-cd4f9f809db4.png&gt;&lt;/denchmark-link&gt;

2/ So I restarted the run time, run again without doing the installation the model. Then there was no error
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/79226157-7c0f7680-7e90-11ea-8485-cba2521b4a07.png&gt;&lt;/denchmark-link&gt;

And the only error i encountered was when i tried to run the training code block as below
&lt;denchmark-link:https://user-images.githubusercontent.com/43133053/79226225-99444500-7e90-11ea-92a6-6902ecf8a543.png&gt;&lt;/denchmark-link&gt;

May you kindly see the &lt;denchmark-link:https://colab.research.google.com/gist/phuongchi911/e1728367ab59ae941b0dc343bbc74306/untitled498.ipynb&gt;gist&lt;/denchmark-link&gt;

. I ran it directly on the gist u shared.
Thank you very much
		</comment>
		<comment id='7' author='phuongchi911' date='2020-05-01T09:13:34Z'>
		Hi, I am also experiencing this issue. I could not find any reason why this is happening.
		</comment>
		<comment id='8' author='phuongchi911' date='2020-05-02T01:00:02Z'>
		Also here with Transformer model using fit().
I saw this &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28836&gt;code&lt;/denchmark-link&gt;
:

to apply apply_gradients.. inside a train_step function.
But using fit(), I don't know how
		</comment>
		<comment id='9' author='phuongchi911' date='2020-05-02T20:14:01Z'>
		I have not tried it yet, but TF 2.2 has a new api to overwrite the training step which contains the tf.GradientTape(). Accessing the gradients there would be possible.
from &lt;denchmark-link:https://github.com/tensorflow/tensorflow/releases&gt;https://github.com/tensorflow/tensorflow/releases&lt;/denchmark-link&gt;
:
&lt;denchmark-code&gt;You can now use custom training logic with Model.fit by overriding Model.train_step.
&lt;/denchmark-code&gt;

		</comment>
		<comment id='10' author='phuongchi911' date='2020-05-03T04:31:45Z'>
		Yes i have been trying to figure out how to

Also here with Transformer model using fit().
I saw this code:
with tf.GradientTape() as tape
to apply apply_gradients.. inside a train_step function.
But using fit(), I don't know how

Yes I also came across with that code but still not clear how to apply it to my problem. From my understanding it is maybe due to the dead gradients.
Not sure if the tensorflow support person will have any advise on this problem as I am stuck for a month
		</comment>
		<comment id='11' author='phuongchi911' date='2020-05-04T03:32:00Z'>
		Hi All I fixed my problem. It is not because of tensorflow itself, the issue is in the dataloader block code.
		</comment>
		<comment id='12' author='phuongchi911' date='2020-05-04T03:32:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38233&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38233&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='13' author='phuongchi911' date='2020-05-04T08:37:56Z'>
		&lt;denchmark-link:https://github.com/phuongchi911&gt;@phuongchi911&lt;/denchmark-link&gt;
, Can you describe in more details the solution ?
		</comment>
		<comment id='14' author='phuongchi911' date='2020-05-05T17:33:54Z'>
		
@phuongchi911, Can you describe in more details the solution ?

Hi as I mentioned it is about my own data generator coding issue. Not in Tensorflow. It should return a tuple in the dataloader. But i am not sure if this will apply to your dataset.
		</comment>
		<comment id='15' author='phuongchi911' date='2020-05-05T17:43:52Z'>
		

@phuongchi911, Can you describe in more details the solution ?

Hi as I mentioned it is about my own data generator coding issue. Not in Tensorflow. It should return a tuple in the dataloader. But i am not sure if this will apply to your dataset.

God! This worked here too, it was not returning a tuple. Thank you very much!
Interesting that in previous versions it worked (even with this error)
		</comment>
		<comment id='16' author='phuongchi911' date='2020-05-09T11:40:47Z'>
		&lt;denchmark-code&gt;ValueError: No gradients provided for any variable: ['conv2d_1/kernel:0', 'conv2d_1/bias:0'].
&lt;/denchmark-code&gt;

		</comment>
		<comment id='17' author='phuongchi911' date='2020-05-09T11:51:49Z'>
		&lt;denchmark-link:https://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing&gt;https://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing&lt;/denchmark-link&gt;

i am getting same issue while running the fit the model
		</comment>
		<comment id='18' author='phuongchi911' date='2020-11-15T16:14:26Z'>
		
https://colab.research.google.com/drive/1Okqfq5UXFttj_atsmVqwooDwVibLtriq?usp=sharing
i am getting same issue while running the fit the model

change input type to tuple instead of list for model input.
		</comment>
	</comments>
</bug>