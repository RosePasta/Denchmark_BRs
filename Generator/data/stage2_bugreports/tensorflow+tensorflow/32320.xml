<bug id='32320' author='FlorinAndrei' open_date='2019-09-07T21:33:14Z' closed_time='2019-11-01T21:39:49Z'>
	<summary>keras model.evaluate() progress bar WAY too long by default</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): just testing this https://www.tensorflow.org/tutorials/keras/basic_classification
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 fully updated
TensorFlow installed from (source or binary): pip3 install --user tensorflow-gpu==2.0.0-rc0
TensorFlow version (use command below): v2.0.0-beta1-5101-gc75bb66a99 2.0.0-rc0
Python version: 3.7.4
CUDA/cuDNN version: 10.0
GPU model and memory: GeForce GTX 1660 Ti, 6 GB

Describe the current behavior
Just running a basic image classifier with Keras. Import data, create model, train, evaluate.
I run python script-name.py in the Command Prompt.
model.evaluate() prints out an insanely long progress bar at the end. It's many, MANY pages long, with Command Prompt already maximized (so one page is already a lot of characters). I have to scroll WAAAY UP to see the previous output.
Describe the expected behavior
I know I could turn off verbosity, but I would expect sane defaults for the progress bars printed by TF/Keras. And with verbose=1 that thing is so huge, it's useless.
Code to reproduce the issue
from __future__ import absolute_import, division, print_function, unicode_literals

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
from pprint import pprint

# CUDA vs CPU
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

print(tf.__version__)

# load train/test data
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# print shape/size for train/test data
print(train_images.shape, len(train_labels), test_images.shape, len(test_labels))

# show first image
plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
#plt.show()

# normalize pixel values (0...1)
train_images = train_images / 255.0
test_images = test_images / 255.0

# show first 25 images, sanity check
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
#plt.show()

# build the model
# flat 1D layer
# dense 128-node layer
# dense softmax output layer
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

# compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# train the model
model.fit(train_images, train_labels, epochs=5)

# evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)
	</description>
	<comments>
		<comment id='1' author='FlorinAndrei' date='2019-09-09T05:53:36Z'>
		I tried on Google colab but it is working as expected.Please see the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/gadagashwini/4e8b0ca20a27ab518f6329aaf5479dd6/untitled127.ipynb&gt;here&lt;/denchmark-link&gt;
.
And, I could replicate the issue on my system by running it on terminal. Please see the screenshot below.
&lt;denchmark-link:https://user-images.githubusercontent.com/48476109/64506178-3421e300-d2f4-11e9-852a-9d1a6d1e64ac.png&gt;&lt;/denchmark-link&gt;

Thnaks!
		</comment>
		<comment id='2' author='FlorinAndrei' date='2019-09-09T08:38:13Z'>
		Same problem here.
Code:
import tensorflow as tf
from tensorflow import keras
print('Version of TensorFlow:', tf.__version__)
print('Version of tf.keras:', tf.keras.__version__)

# Import dataset
fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

# Build and Compile the model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy']
             )

# Train the model
print('Training')
model.fit(train_images, train_labels, epochs=5)

# Evaluate the model
print('Evaluating')
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)
print('\nTest accuracy:', test_acc)
Output:
&lt;denchmark-link:https://user-images.githubusercontent.com/14865017/64515840-a7742680-d2ed-11e9-973f-488e72f1c440.png&gt;&lt;/denchmark-link&gt;

Notice how short the slider is. It is all filled with "=" signs.
		</comment>
		<comment id='3' author='FlorinAndrei' date='2019-09-09T21:24:35Z'>
		I confirm I am seeing the issue too. The eval progress bar seems to be broken. Adding a batch size and a number of steps does not change the erroneous behavior:
model.evaluate(test_images, test_labels, verbose=1, batch_size=1000, steps=10)
Expecting exactly 10 progress steps with an eval dataset of 10,000 elements
Getting many many steps....
		</comment>
		<comment id='4' author='FlorinAndrei' date='2019-10-01T03:59:30Z'>
		Same issue here. Even on the official tutorial page, the progress bar is extremely long.
&lt;denchmark-link:url&gt;https://www.tensorflow.org/tutorials/keras/classification&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='FlorinAndrei' date='2019-10-01T18:44:02Z'>
		&lt;denchmark-link:https://github.com/qlzh727&gt;@qlzh727&lt;/denchmark-link&gt;
 Could this be related to the training_v2 loop?
		</comment>
		<comment id='6' author='FlorinAndrei' date='2019-10-01T18:59:24Z'>
		Very likely.
		</comment>
		<comment id='7' author='FlorinAndrei' date='2019-11-01T17:42:12Z'>
		


tensorflow/tensorflow/python/keras/engine/training_v2.py


         Line 448
      in
      f9ad945






 samples=use_sample, 





samples=use_sample should be samples=total_samples
		</comment>
		<comment id='8' author='FlorinAndrei' date='2019-11-01T18:26:53Z'>
		&lt;denchmark-link:https://github.com/djshen&gt;@djshen&lt;/denchmark-link&gt;
 Thanks for the find! Agreed, would you please submit a PR to fix this? You can add me as a reviewer, I will approve
		</comment>
		<comment id='9' author='FlorinAndrei' date='2019-11-01T19:38:46Z'>
		&lt;denchmark-link:https://github.com/omalleyt12&gt;@omalleyt12&lt;/denchmark-link&gt;
 I created a PR &lt;denchmark-link:https://github.com/tensorflow/tensorflow/pull/33921&gt;#33921&lt;/denchmark-link&gt;

		</comment>
		<comment id='10' author='FlorinAndrei' date='2019-11-01T21:39:50Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='11' author='FlorinAndrei' date='2019-12-28T18:14:22Z'>
		same here, is going to be merged in 2.1?
		</comment>
		<comment id='12' author='FlorinAndrei' date='2020-01-02T18:41:43Z'>
		Yes this should be fixed in 2.1
		</comment>
	</comments>
</bug>