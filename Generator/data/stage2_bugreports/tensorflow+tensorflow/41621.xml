<bug id='41621' author='mukurgupta' open_date='2020-07-22T07:42:30Z' closed_time='2020-07-28T04:33:52Z'>
	<summary>Not found: Key dense/kernel not found in checkpoint</summary>
	<description>
I am trying to write an encoder/decoder model for a sequence using the TensorFlow estimator and tfa.seq2seq. It is running fine for training and loading the checkpoints when I am training it again but it is not working with the inference. Seems like the encoder is alright but there is some issue with the decoder.
Here is the training decoder code which estimator.train calls and it is working fine:
&lt;denchmark-code&gt;decoder_emb_inp = tf.compat.v1.nn.embedding_lookup(self.embedding_decoder, target_input)
sampler =  tfa.seq2seq.TrainingSampler(time_major=False)
my_decoder = tfa.seq2seq.BasicDecoder(cell, sampler, output_layer=None)

outputs, final_context_state, _ = tfa.seq2seq.dynamic_decode(decoder = my_decoder,swap_memory = False,scope ='decoder_scope',
	output_time_major=False,decoder_init_input= decoder_emb_inp,
	decoder_init_kwargs= {'initial_state' : decoder_initial_state,'sequence_length': tf.tile([self.length], [self.batch_size])})

sample_id = outputs.sample_id
logits = self.output_layer(outputs.rnn_output) #self.output_layer=tf.keras.layers.Dense(self.vocab_size)
&lt;/denchmark-code&gt;

This is the code I am using for inference:
&lt;denchmark-code&gt;start_tokens = tf.fill([self.batch_size], tf.constant(0))
end_token = tf.constant(0)

sampler =  tfa.seq2seq.GreedyEmbeddingSampler()
my_decoder = MyDecoder(cell, sampler, output_layer=self.output_layer)        
outputs, final_context_state, _ = tfa.seq2seq.dynamic_decode(decoder=my_decoder,maximum_iterations=self.length, 
	swap_memory=True, scope='decoder_scope',decoder_init_input=self.embedding_decoder,
	decoder_init_kwargs= {'initial_state' : decoder_initial_state,'start_tokens': start_tokens, 'end_token': end_token})
        
logits = outputs.rnn_output
sample_id = outputs.sample_id
&lt;/denchmark-code&gt;

In inference I'm getting this error:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.NotFoundError: Key BasicDecoderStep/my_dense/kernel not found in checkpoint
         [[{{node save/RestoreV2}}]]
&lt;/denchmark-code&gt;

I have tried modifying the output layer, but it is not working. Moreover, if I delete all the checkpoints in the model_dir (passed to estimator), the inference code initializes everything and works fine but doesn't make right predictions.
So how do I make inference part read the checkpoints which were created during training and not throw the above error?
I would appreciate any help to fix this error.
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
TensorFlow installed from (source or binary):
TensorFlow version (use command below): 2.2
Python version: 3.6
Bazel version (if compiling from source): NA
GCC/Compiler version (if compiling from source): NA
CUDA/cuDNN version:
GPU model and memory: NA

	</description>
	<comments>
		<comment id='1' author='mukurgupta' date='2020-07-22T07:48:15Z'>
		&lt;denchmark-link:https://github.com/mukurgupta&gt;@mukurgupta&lt;/denchmark-link&gt;

Request you to share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!
		</comment>
		<comment id='2' author='mukurgupta' date='2020-07-22T11:07:24Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

I have made the miniature version of the model.
Following is the main file for the model:
&lt;denchmark-code&gt;import os
import numpy as np 
import tensorflow as tf 
import collections

import decoder

model_dir='./models'

params={}

#Change this to 'predict' during inference
params['mode'] = 'predict'


params['source_length']=10
params['train_epochs']= 5
params['lr']=0.001

params['encoder_length']=5
params['max_gradient_norm']=5

params['decoder_hidden_size']=6
params['decoder_length']=10
params['decoder_vocab_size']=10

def predict_from_file(estimator):
	def infer_input_fn():
		t=np.array([[0,1,2,3,4,5,6,7,8,9]], dtype='int')
		dataset = tf.data.Dataset.from_tensor_slices(t)

		def decode_record(record):
			return record, tf.constant([0], dtype=tf.int32)
		
		dataset = dataset.map(decode_record)
		dataset = dataset.batch(1)
		iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
		inputs, targets_inputs = iterator.get_next()

		return {
		'decoder_input' : targets_inputs,
		}, None
	results = []
	new_ids = []
	perfs = []
	result_iter = estimator.predict(infer_input_fn)
	for result in result_iter:
		output = result['sample_id'].flatten()
		output = ' '.join(map(str, output))
		results.append(output)


def input_fn(params, mode):
	t=np.array([[0,1,2,3,4,5,6,7,8,9]])
	decoder_target_dataset = tf.data.Dataset.from_tensor_slices(t)

	def decode(decoder_tgt):
		decoder_src = tf.compat.v1.concat([tf.constant([0]) ,decoder_tgt[:-1]], axis=0)
		return (decoder_src, decoder_tgt)

	dataset = decoder_target_dataset.map(decode)
	
	dataset = dataset.repeat(None)
	dataset = dataset.batch(1)
	iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)
	batched = iterator.get_next()

	decoder_input, decoder_target = batched	

	return{
		'decoder_input': decoder_input,
		'decoder_target': decoder_target
	}, None


def model_fn(features, labels, mode, params):
	if mode == tf.estimator.ModeKeys.TRAIN:
		decoder_input = features['decoder_input']
		decoder_target = features['decoder_target']

		my_decoder = decoder.Model(decoder_input, decoder_target, params, mode, 'Decoder')
		total_loss = my_decoder.loss

		global_step = tf.compat.v1.train.get_or_create_global_step()
		learning_rate = tf.constant(params['lr'])
		opt = tf.compat.v1.train.AdamOptimizer(learning_rate=tf.constant(params['lr']))

		with tf.control_dependencies(tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)):
			gradients, variables = zip(*opt.compute_gradients(total_loss))
			clipped_gradients, _ = tf.clip_by_global_norm(gradients, params['max_gradient_norm'])
			train_op = opt.apply_gradients(zip(clipped_gradients, variables), global_step=global_step)

		tf.identity(learning_rate, 'learning_rate')

		return tf.estimator.EstimatorSpec(mode=mode,loss=total_loss,train_op=train_op)

	elif mode == tf.estimator.ModeKeys.PREDICT:
		decoder_input = features.get('decoder_input', None)
		decoder_target = features.get('decoder_target', None)
		
		my_decoder = decoder.Model(decoder_input, decoder_target, params, mode, 'Decoder')
		res = my_decoder.decode()
		sample_id = res['sample_id']

		predictions = {
		  'sample_id' : sample_id,
		}
		return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

def main():
	if params['mode']=='train':
		estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, params=params)
		estimator.train(input_fn=lambda: input_fn(params, 'train'),max_steps=params['train_epochs'])
		print("\nTraining Done\n")

	elif params['mode']=='predict':
		estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, params=params)
		predict_from_file(estimator)

if __name__ == '__main__':
	tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
	main()

&lt;/denchmark-code&gt;

The above code runs fine if params['mode']='train' and also creates the checkpoints in the models directory. But on 'predict' mode, it throws error.
Here is the code for the decoder.py:
&lt;denchmark-code&gt;import collections
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.python.framework import ops
from tensorflow_addons.seq2seq.basic_decoder import BasicDecoderOutput

class MyDecoder(tfa.seq2seq.BasicDecoder):
  def __init__(self, cell, sampler, output_layer=None):
    super(MyDecoder, self).__init__(cell, sampler, output_layer)

  def step(self, time, inputs, state, name=None):
    cell_outputs, cell_state = self.cell(inputs, state)
    if self.output_layer is not None:
      cell_outputs = self.output_layer(cell_outputs)
    sample_ids = self.sampler.sample(
      time=time, outputs=cell_outputs, state=cell_state)
    (finished, next_inputs, next_state) = self.sampler.next_inputs(
      time=time,
      outputs=cell_outputs,
      state=cell_state,
      sample_ids=sample_ids)
    outputs = BasicDecoderOutput(cell_outputs, sample_ids)
    return (outputs, next_state, next_inputs, finished)

class Decoder():
  def __init__(self, params, mode, embedding_decoder, output_layer):
    self.hidden_size = params['decoder_hidden_size']
    self.length = params['decoder_length']
    self.source_length = params['encoder_length']
    self.vocab_size = params['decoder_vocab_size']
    self.embedding_decoder = embedding_decoder
    self.output_layer = output_layer
    self.mode = mode
	
  def build_decoder(self, target_input, batch_size):	    
    tgt_sos_id = tf.constant(0)
    tgt_eos_id = tf.constant(0)

    self.batch_size=batch_size

    with tf.compat.v1.variable_scope('decoder'):
      cell, decoder_initial_state = self.build_decoder_cell()
      
      if self.mode != tf.estimator.ModeKeys.PREDICT:
        decoder_emb_inp = tf.compat.v1.nn.embedding_lookup(self.embedding_decoder, target_input)
        sampler =  tfa.seq2seq.TrainingSampler(time_major=False)
        my_decoder = MyDecoder(cell, sampler, output_layer=None)

        outputs, final_context_state, _ = tfa.seq2seq.dynamic_decode(decoder = my_decoder,swap_memory = False,scope ='decoder_scope',output_time_major=False,decoder_init_input= decoder_emb_inp,decoder_init_kwargs= {'initial_state' : decoder_initial_state,'sequence_length': tf.tile([self.length], [self.batch_size])})
        
        sample_id = outputs.sample_id
        logits = self.output_layer(outputs.rnn_output)

      else:
        start_tokens = tf.fill([self.batch_size], tgt_sos_id)
        end_token = tgt_eos_id

        sampler =  tfa.seq2seq.GreedyEmbeddingSampler()
        my_decoder = MyDecoder(cell, sampler, output_layer=self.output_layer)        
        outputs, final_context_state, _ = tfa.seq2seq.dynamic_decode(decoder=my_decoder,maximum_iterations=self.length, swap_memory=True, scope='decoder_scope',decoder_init_input=self.embedding_decoder,decoder_init_kwargs= {'initial_state' : decoder_initial_state,'start_tokens': start_tokens, 'end_token': end_token})
        
        logits = outputs.rnn_output
        sample_id = outputs.sample_id    
		
    return logits, sample_id, final_context_state

  def build_decoder_cell(self):
    batch_size= self.batch_size
    cell = tf.compat.v1.nn.rnn_cell.LSTMCell(self.hidden_size,initializer='orthogonal')
    cell = tf.compat.v1.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=1)

    decoder_initial_state = cell.zero_state(batch_size, tf.float32)

    return cell, decoder_initial_state


class Model:
  def __init__(self, target_input, target, params, mode, scope=None):
    self.params = params
    self.target_input = target_input
    self.target = target
    self.batch_size = tf.shape(self.target_input)[0]
    self.mode = mode
    self.vocab_size = params['decoder_vocab_size']
    self.decoder_length = params['decoder_length']
    self.hidden_size = params['decoder_hidden_size']

    initializer = tf.random_uniform_initializer(-0.1,0.1)
    tf.compat.v1.get_variable_scope().set_initializer(initializer)
    self.build_graph(scope=scope)

  def build_graph(self, scope=None):
    with tf.compat.v1.variable_scope(scope):
      self.W_emb = tf.compat.v1.get_variable('W_emb', [self.vocab_size, self.hidden_size])
      with tf.compat.v1.variable_scope("decoder/output_projection"):
        self.output_layer = tf.keras.layers.Dense(self.vocab_size, use_bias=False)
      
      self.logits, self.sample_id, self.final_context_state = self.build_decoder()
      
      if self.mode != tf.estimator.ModeKeys.PREDICT:
        self.compute_loss()
      else:
        self.loss=None
        self.total_loss=None

  def build_decoder(self):
    decoder = Decoder(self.params, self.mode, self.W_emb, self.output_layer)
    logits, sample_id, final_context_state = decoder.build_decoder(self.target_input, self.batch_size)
    	
    return logits, sample_id, final_context_state

  def compute_loss(self):
    target_output = self.target
    crossent = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=target_output, logits=self.logits)
    tf.identity(crossent, 'cross_entropy')
    self.loss = crossent

  def decode(self):
    return {'sample_id' : self.sample_id}

&lt;/denchmark-code&gt;

Error is:
&lt;denchmark-code&gt;tensorflow.python.framework.errors_impl.NotFoundError: Key dense/kernel not found in checkpoint
         [[{{node save/RestoreV2}}]]
&lt;/denchmark-code&gt;

I'd appreciate your help on this.
		</comment>
		<comment id='3' author='mukurgupta' date='2020-07-22T11:55:38Z'>
		&lt;denchmark-link:https://github.com/mukurgupta&gt;@mukurgupta&lt;/denchmark-link&gt;

I have tried in colab with TF version 2.2.Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/69ebcdb7e6ee4a2eaaa2ce31b3448861/untitled172.ipynb&gt;here&lt;/denchmark-link&gt;
.You are also seeing same behavior?
Thanks!
		</comment>
		<comment id='4' author='mukurgupta' date='2020-07-22T13:22:34Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;

Yes you are correct. But you ran it in prediction mode without any checkpoints so it is initializing and won't have any errors but this prediction is wrong as everything is being initialized here and there's no use of training then.

INFO:tensorflow:Could not find trained model in model_dir: ./models, running initialization to predict.

For right prediction you need to change the mode to train first, create checkpoints in './models' and then run it on predict mode.

params['mode'] = 'train'

Or you can use the checkpoints I'm attaching below and put them in the './models' directory.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/4960194/models.zip&gt;models.zip&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='mukurgupta' date='2020-07-24T18:10:10Z'>
		I've also encountered this error, it seems like it is caused by the saver not correctly naming Keras model variables when they are restored in eager mode.
Unfortunately, you can't seem to load the variables without eager either when the model structure differs, but the variables do not. This becomes particularly apparent in models like the LSTM, which have different encoding and decoding model structures (and thus, the model parameters are not restored properly).
		</comment>
		<comment id='6' author='mukurgupta' date='2020-07-24T19:38:25Z'>
		Thanks to &lt;denchmark-link:https://github.com/k-w-w&gt;@k-w-w&lt;/denchmark-link&gt;
, I was able to get this working by using the following scaffold in the return from the model_fn:
def model_fn(..., mode):
    ...
    if mode == tf.estimator.ModeKeys.TRAIN:
        ...
        return tf.estimator.EstimatorSpec(
            mode=mode,
            loss=loss,
            train_op=train_op,
            scaffold=tf.compat.v1.train.Scaffold(
                saver=tf.train.Checkpoint(
                    optimizer=optimizer,
                    model=model,
                    global_step=tf.compat.v1.train.get_or_create_global_step())))
     if mode == tf.estimator.ModeKeys.EVAL:
        ...
        return tf.estimator.EstimatorSpec(
            mode=mode,
            loss=loss,
            scaffold=tf.compat.v1.train.Scaffold(
                  saver=tf.train.Checkpoint(
                      model=model,
                      global_step=tf.compat.v1.train.get_or_create_global_step())))
If you want to load the weights later, you could use:
&lt;denchmark-code&gt;model = tf.keras.Model(...)
ckpt = tf.train.Checkpoint(model=model)
ckpt.restore(model_dir)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='7' author='mukurgupta' date='2020-07-28T04:33:52Z'>
		&lt;denchmark-link:https://github.com/DavidMChan&gt;@DavidMChan&lt;/denchmark-link&gt;

Yes, this works for me. Thank you so much for your help.
		</comment>
		<comment id='8' author='mukurgupta' date='2020-07-28T04:33:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41621&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41621&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>