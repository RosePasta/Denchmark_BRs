<bug id='24741' author='aisolab' open_date='2019-01-07T12:44:40Z' closed_time='2019-01-08T05:30:03Z'>
	<summary>When passing tf.data.Dataset instance to model.fit method which is instantiated by tf.keras.Sequential, tf.keras.Model, subclassing tf.keras.Model, passing metrics argument to 'accuracy' in model.compile method provokes TypeError</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.2
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.12.0
Python version: 3.6.6

You can collect some of this information using our environment capture &lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the current behavior
When passing tf.data.Dataset instance to model.fit method which is instantiated by tf.keras.Sequential, tf.keras.Model, subclassing tf.keras.Model, passing metrics argument to 'accuracy' in model.compile method provokes TypeError. But passing np.array to model.fit method doesn't provoke TypeError.
Code to reproduce the issue
tf.data.Dataset provkes TypeError. (because I think tf.keras.metrics.sparse_categorical_accuracy
import numpy as np
import tensorflow as tf
keras = tf.keras

# tf.data.Dataset instance
tr_data = np.random.random((1000, 32)).astype(np.float32)
tr_label = np.random.randint(low=0, high=10, size = 1000).astype(np.int32)
tr_dataset = tf.data.Dataset.from_tensor_slices((tr_data, tr_label))
tr_dataset = tr_dataset.batch(batch_size=32)
tr_dataset = tr_dataset.repeat()

val_data = np.random.random((100, 32)).astype(np.float32)
val_label = np.random.randint(low=0, high=10, size = 100).astype(np.int32)
val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))
val_dataset = val_dataset.batch(batch_size=100).repeat()

# Training
model = keras.Sequential()
model.add(keras.layers.Dense(units=64, activation='relu'))
model.add(keras.layers.Dense(units=64, activation='relu'))
model.add(keras.layers.Dense(units=10, activation='softmax'))
model.compile(optimizer=tf.train.GradientDescentOptimizer(.01), 
              loss=keras.losses.sparse_categorical_crossentropy,
              metrics=['accuracy'])

model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,
          validation_data = val_dataset, validation_steps = 1)
output
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    509                 as_ref=input_arg.is_ref,
--&gt; 510                 preferred_dtype=default_dtype)
    511           except TypeError as err:

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
   1145     if ret is None:
-&gt; 1146       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1147 

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    982         "Tensor conversion requested dtype %s for Tensor with dtype %s: %r" %
--&gt; 983         (dtype.name, t.dtype.name, str(t)))
    984   return t

ValueError: Tensor conversion requested dtype int32 for Tensor with dtype int64: 'Tensor("metrics/acc/ArgMax:0", shape=(?,), dtype=int64)'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-3-ef35f2c07d04&gt; in &lt;module&gt;
      9 
     10 model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,
---&gt; 11           validation_data = val_dataset, validation_steps = 1)

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)
   1534         steps_name='steps_per_epoch',
   1535         steps=steps_per_epoch,
-&gt; 1536         validation_split=validation_split)
   1537 
   1538     # Prepare validation data.

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)
    990         x, y, sample_weight = next_element
    991     x, y, sample_weights = self._standardize_weights(x, y, sample_weight,
--&gt; 992                                                      class_weight, batch_size)
    993     return x, y, sample_weights
    994 

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _standardize_weights(self, x, y, sample_weight, class_weight, batch_size)
   1078                      metrics=self.metrics,
   1079                      loss_weights=self.loss_weights,
-&gt; 1080                      target_tensors=target_tensors)
   1081 
   1082     # In graph mode, if we had just set inputs and targets as symbolic tensors

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py in _method_wrapper(self, *args, **kwargs)
    472     self._setattr_tracking = False  # pylint: disable=protected-access
    473     try:
--&gt; 474       method(self, *args, **kwargs)
    475     finally:
    476       self._setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    646         targets=self.targets,
    647         skip_target_indices=skip_target_indices,
--&gt; 648         sample_weights=self.sample_weights)
    649 
    650     # Prepare gradient updates and state updates.

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _handle_metrics(self, outputs, skip_target_indices, targets, sample_weights, masks)
    311         metric_results.extend(
    312             self._handle_per_output_metrics(self._per_output_metrics[i], target,
--&gt; 313                                             output, output_mask))
    314         metric_results.extend(
    315             self._handle_per_output_metrics(

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)
    268               metric_fn)
    269           metric_result = weighted_metric_fn(
--&gt; 270               y_true, y_pred, weights=weights, mask=mask)
    271 
    272         if not context.executing_eagerly():

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py in weighted(y_true, y_pred, weights, mask)
    596     """
    597     # score_array has ndim &gt;= 2
--&gt; 598     score_array = fn(y_true, y_pred)
    599     if mask is not None:
    600       mask = math_ops.cast(mask, y_pred.dtype)

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py in sparse_categorical_accuracy(y_true, y_pred)
    660     y_pred = math_ops.cast(y_pred, K.floatx())
    661 
--&gt; 662   return math_ops.cast(math_ops.equal(y_true, y_pred), K.floatx())
    663 
    664 

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py in equal(x, y, name)
   2732   if _ctx is None or not _ctx._eager_context.is_eager:
   2733     _, _, _op = _op_def_lib._apply_op_helper(
-&gt; 2734         "Equal", x=x, y=y, name=name)
   2735     _result = _op.outputs[:]
   2736     _inputs_flat = _op.inputs

/usr/local/var/pyenv/versions/3.6.6/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)
    544                   "%s type %s of argument '%s'." %
    545                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--&gt; 546                    inferred_from[input_arg.type_attr]))
    547 
    548           types = [values.dtype]

TypeError: Input 'y' of 'Equal' Op has type int64 that does not match type int32 of argument 'x'.
np.array doesn't provoke TypeError
import numpy as np
import tensorflow as tf
keras = tf.keras

# np.array 
tr_data = np.random.random((1000, 32)).astype(np.float32)
tr_label = np.random.randint(low=0, high=10, size = 1000).astype(np.int32)
# tr_dataset = tf.data.Dataset.from_tensor_slices((tr_data, tr_label))
# tr_dataset = tr_dataset.batch(batch_size=32)
# tr_dataset = tr_dataset.repeat()

val_data = np.random.random((100, 32)).astype(np.float32)
val_label = np.random.randint(low=0, high=10, size = 100).astype(np.int32)
# val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))
# val_dataset = val_dataset.batch(batch_size=100).repeat()

# Training
model = keras.Sequential()
model.add(keras.layers.Dense(units=64, activation='relu'))
model.add(keras.layers.Dense(units=64, activation='relu'))
model.add(keras.layers.Dense(units=10, activation='softmax'))
model.compile(optimizer=tf.train.GradientDescentOptimizer(.01), 
              loss=keras.losses.sparse_categorical_crossentropy,
              metrics=['accuracy'])

model.fit(x=tr_data, y=tr_label, epochs=5, batch_size=32, validation_data=(val_data, val_label))
# model.fit(tr_dataset, epochs = 5, steps_per_epoch = 1000 // 32,
#           validation_data = val_dataset, validation_steps = 1)
output
Train on 1000 samples, validate on 100 samples
Epoch 1/5
1000/1000 [==============================] - 0s 171us/step - loss: 2.3126 - acc: 0.1160 - val_loss: 2.3027 - val_acc: 0.1000
Epoch 2/5
1000/1000 [==============================] - 0s 43us/step - loss: 2.3078 - acc: 0.1200 - val_loss: 2.2976 - val_acc: 0.0900
Epoch 3/5
1000/1000 [==============================] - 0s 45us/step - loss: 2.3049 - acc: 0.1240 - val_loss: 2.2953 - val_acc: 0.0800
Epoch 4/5
1000/1000 [==============================] - 0s 42us/step - loss: 2.3030 - acc: 0.1190 - val_loss: 2.2926 - val_acc: 0.0900
Epoch 5/5
1000/1000 [==============================] - 0s 46us/step - loss: 2.3009 - acc: 0.1200 - val_loss: 2.2925 - val_acc: 0.1000
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='aisolab' date='2019-01-07T21:19:59Z'>
		&lt;denchmark-link:https://github.com/aisolab&gt;@aisolab&lt;/denchmark-link&gt;
 I tried with tf-nightly and it works fine. I think the issue may have been fixed. Can you try with tf-nightly and see if the issue persist?
&lt;denchmark-code&gt;root@ubuntu:/v# python3 -c 'import tensorflow as tf; print(tf.VERSION)'
1.13.0-dev20190104
root@ubuntu:/v# python3 24741.py
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:439: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1761: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.
2019-01-07 21:19:22.135609: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-01-07 21:19:22.158710: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz
2019-01-07 21:19:22.159015: I tensorflow/compiler/xla/service/service.cc:161] XLA service 0x3efce10 executing computations on platform Host. Devices:
2019-01-07 21:19:22.159035: I tensorflow/compiler/xla/service/service.cc:168]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:125: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Epoch 1/5
31/31 [==============================] - 0s 6ms/step - loss: 2.3249 - acc: 0.0958 - val_loss: 2.3252 - val_acc: 0.0600
Epoch 2/5
31/31 [==============================] - 0s 866us/step - loss: 2.3218 - acc: 0.1002 - val_loss: 2.3213 - val_acc: 0.0600
Epoch 3/5
31/31 [==============================] - 0s 867us/step - loss: 2.3174 - acc: 0.0971 - val_loss: 2.3191 - val_acc: 0.0600
Epoch 4/5
31/31 [==============================] - 0s 864us/step - loss: 2.3134 - acc: 0.0950 - val_loss: 2.3173 - val_acc: 0.0400
Epoch 5/5
31/31 [==============================] - 0s 834us/step - loss: 2.3105 - acc: 0.0961 - val_loss: 2.3166 - val_acc: 0.0500
root@ubuntu:/v# 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='aisolab' date='2019-01-08T04:08:58Z'>
		&lt;denchmark-link:https://github.com/yongtang&gt;@yongtang&lt;/denchmark-link&gt;
 Thanks. I confirmed that it works fine at tf-nightly version
		</comment>
		<comment id='3' author='aisolab' date='2019-01-08T05:30:03Z'>
		Closing this issue since its resolved. Thanks everybody :)
		</comment>
		<comment id='4' author='aisolab' date='2019-08-04T13:13:50Z'>
		Thankyou,,,It is working for me.
		</comment>
	</comments>
</bug>