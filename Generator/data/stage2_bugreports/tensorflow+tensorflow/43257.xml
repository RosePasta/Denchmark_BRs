<bug id='43257' author='drajsel' open_date='2020-09-16T06:34:51Z' closed_time='2020-09-16T15:16:12Z'>
	<summary>MobileNetV3 Small/Large not fully quantized after full integer post-training quantization runs with no errors</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A (used Google Colaboratory)
TensorFlow version (using the command in the template): v1.12.1-39569-gcb34190201 2.4.0-dev20200818

Describe the current behavior
The model is not fully quantized after full integer quantization even though no error occurs during the quantization.
Describe the expected behavior
I tried using the quantized version in the example Android app but it crashed every time so I wanted to see if the quantized version worked on Coral devices, but then it failed to compile with the error "Model is not fully quantized.".

&lt;denchmark-link:https://colab.research.google.com/drive/1B-VbTOCpmGhgv5adOpnGn68VARo30bF9?usp=sharing&gt;https://colab.research.google.com/drive/1B-VbTOCpmGhgv5adOpnGn68VARo30bF9?usp=sharing&lt;/denchmark-link&gt;

	</description>
	<comments>
		<comment id='1' author='drajsel' date='2020-09-16T07:24:47Z'>
		I could reproduce the issue in colab with TF nightly version() .Please, find the gist &lt;denchmark-link:https://colab.research.google.com/gist/ravikyram/d303b7aebb1a4c8fef8743902cb0153e/untitled361.ipynb&gt;here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='2' author='drajsel' date='2020-09-16T10:51:42Z'>
		Hi..Im trying to convert Mobilenetv3 onnx model to tensorflow.
I need tensorflow==1.12.0 for my inferencing.
I searched all over to find the onnx and onnx-tf versions corresponding to tensorflow==1.12.0
Could anyone suggest me the compatible versions of onnx,onnx-tf and torch for my required tensorflow version?
&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/drajsel&gt;@drajsel&lt;/denchmark-link&gt;

Thanks in advance!
		</comment>
		<comment id='3' author='drajsel' date='2020-09-16T14:03:16Z'>
		&lt;denchmark-link:https://github.com/drajsel&gt;@drajsel&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 You need to use the old TOCO with  for a working coral compilation.
This is cause:
&lt;denchmark-link:https://github.com/google-coral/edgetpu/issues/168#issuecomment-679233152&gt;google-coral/edgetpu#168 (comment)&lt;/denchmark-link&gt;

/cc &lt;denchmark-link:https://github.com/Namburger&gt;@Namburger&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='drajsel' date='2020-09-16T15:16:12Z'>
		&lt;denchmark-link:https://github.com/ravikyram&gt;@ravikyram&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/bhack&gt;@bhack&lt;/denchmark-link&gt;
 The compilation is successful now, but it doesn't seem to matter now because of this:
&lt;denchmark-code&gt;Number of operations that will run on Edge TPU: 1
Number of operations that will run on CPU: 122
&lt;/denchmark-code&gt;

Thank you all anyway!
It worked for the downloaded model, but in the case where I have two outputs it doesn't work (Unsupported explicit zero output index: serving_default_input_2:0). Do you have any suggestions, what I should look into? I know it's outside the scope of this bug, but I've tried many approaches in TF 2, TF 1.15, using the toco command line converter like seen in quantization for object detection models in TF 1.x etc.
		</comment>
		<comment id='5' author='drajsel' date='2020-09-16T15:16:14Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43257&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43257&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='6' author='drajsel' date='2020-09-16T15:45:02Z'>
		&lt;denchmark-link:https://github.com/drajsel&gt;@drajsel&lt;/denchmark-link&gt;
 I don't know If there Is something fresh from the unstable apt channel instead of the stable in echo 
So that you don't need to use TOCO (converter.experimental_new_converter = False)
		</comment>
	</comments>
</bug>