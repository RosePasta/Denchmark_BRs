<bug id='41976' author='RayLucchesi' open_date='2020-08-01T21:59:35Z' closed_time='2020-08-26T00:47:19Z'>
	<summary>TF 2.4.0 build from source gets InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid.</summary>
	<description>
Nvidia-SMI command issued from inside the container
NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: ERR!     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   33C    P8     6W / 180W |    193MiB /  8117MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|============================================================================
I am running Ubuntu 20.04. I followed the instructions to Build from source:
After I compiled TF inside the container, I committed and saved it.
I run the following commands to load the image and execute jupyter notebook:
docker run --gpus all --ipc="host" -it -w /tensorflow -v $PWD:/mnt -p 8888:8888 -e HOST_PERMS="$(id -u):$(id -g)" tensorflow/tensorflow:from-src2 bash
export LD_LIBRARY_PATH=“/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64”
pip install jupyter
pip install jupyter_http_over_ws
jupyter serverextension enable --py jupyter_http_over_ws
jupyter notebook --no-browser --notebook-dir=/mnt/notebooks --ip=0.0.0.0  --debug --NotebookApp.allow_origin='&lt;denchmark-link:https://www.example.com&gt;https://www.example.com&lt;/denchmark-link&gt;
' --NotebookApp.allow_remote_access=True --allow-root
This gets me a running notebook server.
I try to run the tensorflow-tutorials/text_classification.ipynb file
When I ran the:
raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(
'aclImdb/train',
batch_size=batch_size,
validation_split=0.2,
subset='training',
seed=seed)
In the jupyter notebook, I get:
TypeError: Could not build a TypeSpec for ['aclImdb/train/neg/4932_4.txt',
[there follows many pages of text similar to the above]...
Then I get the following
**with type list
During handling of the above exception, another exception occurred:**
InternalError                             Traceback (most recent call last)
 in 
7     validation_split=0.2,
8     subset='training',
----&gt; 9     seed=seed)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/text_dataset.py in text_dataset_from_directory(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)
159       label_mode=label_mode,
160       num_classes=len(class_names),
--&gt; 161       max_length=max_length)
162   if shuffle:
163     # Shuffle locally at each iteration
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/text_dataset.py in paths_and_labels_to_dataset(file_paths, labels, label_mode, num_classes, max_length)
175                                 max_length):
176   """Constructs a dataset of text strings and labels."""
--&gt; 177   path_ds = dataset_ops.Dataset.from_tensor_slices(file_paths)
178   string_ds = path_ds.map(
179       lambda x: path_to_string_content(x, max_length))
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py in from_tensor_slices(tensors)
680       Dataset: A Dataset.
681     """
--&gt; 682     return TensorSliceDataset(tensors)
683
684   class _GeneratorState(object):
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py in init(self, element)
2999   def init(self, element):
3000     """See Dataset.from_tensor_slices() for details."""
-&gt; 3001     element = structure.normalize_element(element)
3002     batched_spec = structure.type_spec_from_value(element)
3003     self._tensors = structure.to_batched_tensor_list(batched_spec, element)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in normalize_element(element)
96         # the value. As a fallback try converting the value to a tensor.
97         normalized_components.append(
---&gt; 98             ops.convert_to_tensor(t, name="component_%d" % i))
99       else:
100         if isinstance(spec, sparse_tensor.SparseTensorSpec):
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
1524
1525     if ret is None:
-&gt; 1526       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
1527
1528     if ret is NotImplemented:
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
337                                          as_ref=False):
338   _ = as_ref
--&gt; 339   return constant(v, dtype=dtype, name=name)
340
341
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
263   """
264   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--&gt; 265                         allow_broadcast=True)
266
267
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
274       with trace.Trace("tf.constant"):
275         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--&gt; 276     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
277
278   g = ops.get_default_graph()
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
299 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
300   """Implementation of eager constant."""
--&gt; 301   t = convert_to_eager_tensor(value, ctx, dtype)
302   if shape is None:
303     return t
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
95     except AttributeError:
96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
---&gt; 97   ctx.ensure_initialized()
98   return ops.EagerTensor(value, ctx.device_name, dtype)
99
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in ensure_initialized(self)
547         if self._use_tfrt is not None:
548           pywrap_tfe.TFE_ContextOptionsSetTfrt(opts, self._use_tfrt)
--&gt; 549         context_handle = pywrap_tfe.TFE_NewContext(opts)
550       finally:
551         pywrap_tfe.TFE_DeleteContextOptions(opts)
InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid.
This from /tensorflow_src/.bazelrc : release_gpu_common --action_env=TF_CUDA_COMPUTE_CAPABILITIES="sm_35,sm_37,sm_52,sm_60,sm_61,compute_70
I believe the GeForce 1070 is sm_61 compute level.
Some software versions
gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Python 3.6.9
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

You can collect some of this information using our environment capture
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh&gt;script&lt;/denchmark-link&gt;

You can also obtain the TensorFlow version with:

TF 1.0: python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
TF 2.0: python -c "import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)"

Describe the current behavior
Describe the expected behavior
Standalone code to reproduce the issue
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
I will attach the full .bazelrc file and a piped output of the build from source when I can figure out how to do that. I’m on an iPad now and can copy and paste but can’t seem to figure out how to copy a file to the ipad and then upload to github issue...
	</description>
	<comments>
		<comment id='1' author='RayLucchesi' date='2020-08-01T22:11:15Z'>
		&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5011355/BazelRC.txt&gt;BazelRC.txt&lt;/denchmark-link&gt;

I thought I had kept the build pipe around but apparently didn't so don't have that file. If you need any more information please let me know.
		</comment>
		<comment id='2' author='RayLucchesi' date='2020-08-01T22:11:18Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41976&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41976&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='3' author='RayLucchesi' date='2020-08-01T22:11:54Z'>
		Sorry closed the issue when I just wanted to add my comment. I re-opened
		</comment>
		<comment id='4' author='RayLucchesi' date='2020-08-01T22:27:01Z'>
		I’m using Nvidia-MPS so this is the nvidia-smi from outside the container.
NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:01:00.0 Off |                  N/A |
|  0%   32C    P8     6W / 180W |    193MiB /  8117MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1070    Off  | 00000000:05:00.0 Off |                  N/A |
|  0%   29C    P8     5W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1070    Off  | 00000000:06:00.0 Off |                  N/A |
|  0%   29C    P8     4W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1056      G   /usr/lib/xorg/Xorg                 36MiB |
|    0   N/A  N/A      1501      G   /usr/bin/gnome-shell               15MiB |
|    0   N/A  N/A      2205      C   /usr/bin/python3                  137MiB |
|    1   N/A  N/A      1056      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A      1056      G   /usr/lib/xorg/Xorg                  4MiB
I only let 1 GPU into the container.
		</comment>
		<comment id='5' author='RayLucchesi' date='2020-08-01T23:12:33Z'>
		Here’s the trace back from the 1st error (type error)
TypeError                                 Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in normalize_element(element)
92       try:
---&gt; 93         spec = type_spec_from_value(t, use_fallback=False)
94       except TypeError:
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in type_spec_from_value(element, use_fallback)
465   raise TypeError("Could not build a TypeSpec for %r with type %s" %
--&gt; 466                   (element, type(element).name))
467
		</comment>
		<comment id='6' author='RayLucchesi' date='2020-08-01T23:32:12Z'>
		This from inside container:
Bazel label: 3.1.0
Ubuntu version: 18.04
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
numpy                  1.18.5
protobuf               3.12.2
tensorflow             2.4.0
tensorflow-estimator   2.2.0
tf.version.VERSION = 2.4.0
tf.version.GIT_VERSION = v1.12.1-37438-g6711d96f6c
tf.version.COMPILER_VERSION = 7.5.0
python version: 3.6.9
python compiler version: GCC 8.4.0
In Docker: Yes
Check for Virtual Environment: False
== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a
If you need anything else out of tf_env.txt let me know.
		</comment>
		<comment id='7' author='RayLucchesi' date='2020-08-02T18:00:52Z'>
		could this be some sort of timeout. I'm running
Jupyter Notebook 6.1.0
When I tried persistence mode on the GPU it seemed to transfer more data before it generated the error. it went from 135MiB of data assigned to python3 at time of error (with persistence mode OFF) to 189MiB of data assigned to Python3 at time of error (with persistence mode ON).
		</comment>
		<comment id='8' author='RayLucchesi' date='2020-08-02T21:11:59Z'>
		Very strange, when I reran the jupyter server and tried to run the same notebook (a 2nd time) within the same container (but adding a --MappingKernelManager.cull_interval=1200 to the server command. The notebook ran just fine and much faster. I do have persistence mode on... I don’t think the cull-interval had anything to do with it.
Is it possible that the first load of the Nvidia GPU takes a long time because we are loading in some standard NVidia and Tensorflow routines and modules but once they are present in the GPU they no longer have to be loaded (as long as persistence mode is on). That could explain why the first time I ran the text classification notebook it took so long (and ultimately errored off) but the 2nd time it flew right threw that statement.
		</comment>
		<comment id='9' author='RayLucchesi' date='2020-08-04T04:57:24Z'>
		Here is some other information from the debug run of the jupyter notebook:
2020-08-04 04:45:30.731142: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-04 04:45:30.731178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-08-04 04:45:30.731193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-08-04 04:45:30.731244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-08-04 04:45:30.731263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-08-04 04:45:30.731281: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-08-04 04:45:30.731295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
Seems to be loading some files for cuda 10.1 (libcudart) and others from cuda 10.0 (libcublas, libcufft, libcurand, libcusolver, &amp; libcusparse)
I tried to recreate the sequence that worked last night but can’t seem to get it to work tonight.  Any time I Ctrl-c the jupyter notebook server it seems to clear GPU memory so I get a fresh start. It seems last night it left it alone and I was able to start another jupyter notebook server session and it worked ok the second time I ran it. Sigh, that’s not working at all today.
		</comment>
		<comment id='10' author='RayLucchesi' date='2020-08-04T21:52:47Z'>
		sorry i updated the wrong incident. Here's the "lshw" command output:
ubuntu-ai
description: Desktop Computer
product: MS-7A62 (Default string)
vendor: MSI
version: 1.0
serial: Default string
width: 64 bits
capabilities: smbios-3.0.0 dmi-3.0.0 smp vsyscall32
configuration: boot=normal chassis=desktop family=Default string sku=Default string uuid=00000000-0000-0000-0000-4CCC6AF7447F
*-core
description: Motherboard
product: Z270 GAMING M3 (MS-7A62)
vendor: MSI
physical id: 0
version: 1.0
serial: H316061861
slot: Default string
*-firmware
description: BIOS
vendor: American Megatrends Inc.
physical id: 0
version: 1.10
date: 02/07/2017
size: 64KiB
capacity: 16MiB
capabilities: pci upgrade shadowing cdboot bootselect socketedrom edd int13floppy1200 int13floppy720 int13floppy2880 int5printscreen int9keyboard int14serial int17printer acpi usb biosbootspecification uefi
*-memory
description: System Memory
physical id: 3c
slot: System board or motherboard
size: 8GiB
*-bank:0
description: [empty]
physical id: 0
slot: ChannelA-DIMM0
*-bank:1
description: DIMM DDR4 Synchronous 2400 MHz (0.4 ns)
product: BLS4G4D240FSB.8FBD2
vendor: 859B
physical id: 1
serial: A624BDFD
slot: ChannelA-DIMM1
size: 4GiB
width: 64 bits
clock: 2400MHz (0.4ns)
*-bank:2
description: [empty]
physical id: 2
slot: ChannelB-DIMM0
*-bank:3
description: DIMM DDR4 Synchronous 2400 MHz (0.4 ns)
product: BLS4G4D240FSB.8FBD2
vendor: 859B
physical id: 3
serial: A624BDFC
slot: ChannelB-DIMM1
size: 4GiB
width: 64 bits
clock: 2400MHz (0.4ns)
*-cache:0
description: L1 cache
physical id: 42
slot: L1 Cache
size: 128KiB
capacity: 128KiB
capabilities: synchronous internal write-back unified
configuration: level=1
*-cache:1
description: L2 cache
physical id: 43
slot: L2 Cache
size: 512KiB
capacity: 512KiB
capabilities: synchronous internal write-back unified
configuration: level=2
*-cache:2
description: L3 cache
physical id: 44
slot: L3 Cache
size: 3MiB
capacity: 3MiB
capabilities: synchronous internal write-back unified
configuration: level=3
*-cpu
description: CPU
product: Intel(R) Pentium(R) CPU G4400 @ 3.30GHz
vendor: Intel Corp.
physical id: 45
bus info: cpu@0
version: Intel(R) Pentium(R) CPU G4400 @ 3.30GHz
serial: To Be Filled By O.E.M.
slot: U3E1
size: 3206MHz
capacity: 4005MHz
width: 64 bits
clock: 100MHz
capabilities: lm fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp x86-64 constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust erms invpcid rdseed smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d cpufreq
configuration: cores=2 enabledcores=2 threads=2
*-pci
description: Host bridge
product: Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor Host Bridge/DRAM Registers
vendor: Intel Corporation
physical id: 100
bus info: pci@0000:00:00.0
version: 07
width: 32 bits
clock: 33MHz
configuration: driver=skl_uncore
resources: irq:0
*-pci:0
description: PCI bridge
product: Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16)
vendor: Intel Corporation
physical id: 1
bus info: pci@0000:00:01.0
version: 07
width: 32 bits
clock: 33MHz
capabilities: pci pm msi pciexpress normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:120 ioport:e000(size=4096) memory:de000000-df0fffff ioport:c0000000(size=301989888)
*-display
description: VGA compatible controller
product: GP104 [GeForce GTX 1070 Ti]
vendor: NVIDIA Corporation
physical id: 0
bus info: pci@0000:01:00.0
version: a1
width: 64 bits
clock: 33MHz
capabilities: pm msi pciexpress vga_controller bus_master cap_list rom
configuration: driver=nvidia latency=0
resources: irq:137 memory:de000000-deffffff memory:c0000000-cfffffff memory:d0000000-d1ffffff ioport:e000(size=128) memory:c0000-dffff
*-multimedia
description: Audio device
product: GP104 High Definition Audio Controller
vendor: NVIDIA Corporation
physical id: 0.1
bus info: pci@0000:01:00.1
version: a1
width: 32 bits
clock: 33MHz
capabilities: pm msi pciexpress bus_master cap_list
configuration: driver=snd_hda_intel latency=0
resources: irq:17 memory:df080000-df083fff
*-generic:0 UNCLAIMED
description: System peripheral
product: Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th/8th Gen Core Processor Gaussian Mixture Model
vendor: Intel Corporation
physical id: 8
bus info: pci@0000:00:08.0
version: 00
width: 64 bits
clock: 33MHz
capabilities: msi pm cap_list
configuration: latency=0
resources: memory:dd12f000-dd12ffff
*-usb
description: USB controller
product: 200 Series/Z370 Chipset Family USB 3.0 xHCI Controller
vendor: Intel Corporation
physical id: 14
bus info: pci@0000:00:14.0
version: 00
width: 64 bits
clock: 33MHz
capabilities: pm msi xhci bus_master cap_list
configuration: driver=xhci_hcd latency=0
resources: irq:127 memory:dd110000-dd11ffff
*-usbhost:0
product: xHCI Host Controller
vendor: Linux 5.4.0-42-generic xhci-hcd
physical id: 0
bus info: usb@1
logical name: usb1
version: 5.04
capabilities: usb-2.00
configuration: driver=hub slots=16 speed=480Mbit/s
*-usb:0
description: Mouse
product: USB Optical Mouse
vendor: Logitech
physical id: 7
bus info: usb@1:7
version: 72.00
capabilities: usb-2.00
configuration: driver=usbhid maxpower=100mA speed=2Mbit/s
*-usb:1
description: Keyboard
product: USB Keyboard
vendor: Logitech
physical id: 8
bus info: usb@1:8
version: 64.00
capabilities: usb-1.10
configuration: driver=usbhid maxpower=90mA speed=2Mbit/s
*-usbhost:1
product: xHCI Host Controller
vendor: Linux 5.4.0-42-generic xhci-hcd
physical id: 1
bus info: usb@2
logical name: usb2
version: 5.04
capabilities: usb-3.00
configuration: driver=hub slots=10 speed=5000Mbit/s
*-generic:1 UNCLAIMED
description: Signal processing controller
product: 200 Series PCH Thermal Subsystem
vendor: Intel Corporation
physical id: 14.2
bus info: pci@0000:00:14.2
version: 00
width: 64 bits
clock: 33MHz
capabilities: pm msi cap_list
configuration: latency=0
resources: memory:dd12e000-dd12efff
*-communication
description: Communication controller
product: 200 Series PCH CSME HECI &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1&gt;#1&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 16
bus info: pci@0000:00:16.0
version: 00
width: 64 bits
clock: 33MHz
capabilities: pm msi bus_master cap_list
configuration: driver=mei_me latency=0
resources: irq:132 memory:dd12d000-dd12dfff
*-sata
description: SATA controller
product: 200 Series PCH SATA controller [AHCI mode]
vendor: Intel Corporation
physical id: 17
bus info: pci@0000:00:17.0
logical name: scsi0
version: 00
width: 32 bits
clock: 66MHz
capabilities: sata msi pm ahci_1.0 bus_master cap_list emulated
configuration: driver=ahci latency=0
resources: irq:131 memory:dd128000-dd129fff memory:dd12c000-dd12c0ff ioport:f050(size=8) ioport:f040(size=4) ioport:f020(size=32) memory:dd12b000-dd12b7ff
*-disk
description: ATA Disk
product: SanDisk SDSSDA12
physical id: 0.0.0
bus info: scsi@0:0.0.0
logical name: /dev/sda
version: 80RL
serial: 171833459715
size: 111GiB (120GB)
capabilities: gpt-1.00 partitioned partitioned:gpt
configuration: ansiversion=5 guid=725cc7ba-faa9-4fe5-9e62-6b7b8a0b7aa7 logicalsectorsize=512 sectorsize=512
*-volume:0
description: Windows FAT volume
vendor: mkfs.fat
physical id: 1
bus info: scsi@0:0.0.0,1
logical name: /dev/sda1
logical name: /boot/efi
version: FAT32
serial: 1773-3e94
size: 510MiB
capacity: 511MiB
capabilities: boot fat initialized
configuration: FATs=2 filesystem=fat mount.fstype=vfat mount.options=rw,relatime,fmask=0022,dmask=0022,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro state=mounted
*-volume:1
description: EXT4 volume
vendor: Linux
physical id: 2
bus info: scsi@0:0.0.0,2
logical name: /dev/sda2
logical name: /boot
version: 1.0
serial: af28e231-0e6d-41f6-a632-b96cc017ffba
size: 1GiB
capabilities: journaled extended_attributes large_files huge_files dir_nlink recover 64bit extents ext4 ext2 initialized
configuration: created=2020-07-22 19:01:51 filesystem=ext4 lastmountpoint=/boot modified=2020-08-03 17:23:18 mount.fstype=ext4 mount.options=rw,relatime mounted=2020-08-03 17:23:18 state=mounted
*-volume:2
description: EFI partition
physical id: 3
bus info: scsi@0:0.0.0,3
logical name: /dev/sda3
serial: PYSAzy-ypr8-pyaN-oJcD-y4NN-YdMJ-hPwFpv
size: 110GiB
capabilities: lvm2
*-pci:1
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17&gt;#17&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1b
bus info: pci@0000:00:1b.0
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:121
*-pci:2
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/19&gt;#19&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1b.2
bus info: pci@0000:00:1b.2
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:122 memory:df300000-df3fffff
*-usb
description: USB controller
product: ASM2142 USB 3.1 Host Controller
vendor: ASMedia Technology Inc.
physical id: 0
bus info: pci@0000:03:00.0
version: 00
width: 64 bits
clock: 33MHz
capabilities: msi msix pm pciexpress xhci bus_master cap_list
configuration: driver=xhci_hcd latency=0
resources: irq:18 memory:df300000-df307fff
*-usbhost:0
product: xHCI Host Controller
vendor: Linux 5.4.0-42-generic xhci-hcd
physical id: 0
bus info: usb@3
logical name: usb3
version: 5.04
capabilities: usb-2.00
configuration: driver=hub slots=2 speed=480Mbit/s
*-usbhost:1
product: xHCI Host Controller
vendor: Linux 5.4.0-42-generic xhci-hcd
physical id: 1
bus info: usb@4
logical name: usb4
version: 5.04
capabilities: usb-3.10
configuration: driver=hub slots=2 speed=10000Mbit/s
*-pci:3
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1&gt;#1&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1c
bus info: pci@0000:00:1c.0
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:123
*-pci:4
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6&gt;#6&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1c.5
bus info: pci@0000:00:1c.5
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:124 ioport:d000(size=4096) memory:dc000000-dd0fffff ioport:a0000000(size=301989888)
*-display
description: VGA compatible controller
product: GP104 [GeForce GTX 1070]
vendor: NVIDIA Corporation
physical id: 0
bus info: pci@0000:05:00.0
version: a1
width: 64 bits
clock: 33MHz
capabilities: pm msi pciexpress vga_controller bus_master cap_list rom
configuration: driver=nvidia latency=0
resources: irq:138 memory:dc000000-dcffffff memory:a0000000-afffffff memory:b0000000-b1ffffff ioport:d000(size=128) memory:dd000000-dd07ffff
*-multimedia
description: Audio device
product: GP104 High Definition Audio Controller
vendor: NVIDIA Corporation
physical id: 0.1
bus info: pci@0000:05:00.1
version: a1
width: 32 bits
clock: 33MHz
capabilities: pm msi pciexpress bus_master cap_list
configuration: driver=snd_hda_intel latency=0
resources: irq:18 memory:dd080000-dd083fff
*-pci:5
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7&gt;#7&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1c.6
bus info: pci@0000:00:1c.6
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:125 ioport:c000(size=4096) memory:da000000-db0fffff ioport:80000000(size=301989888)
*-display
description: VGA compatible controller
product: GP104 [GeForce GTX 1070]
vendor: NVIDIA Corporation
physical id: 0
bus info: pci@0000:06:00.0
version: a1
width: 64 bits
clock: 33MHz
capabilities: pm msi pciexpress vga_controller bus_master cap_list rom
configuration: driver=nvidia latency=0
resources: irq:139 memory:da000000-daffffff memory:80000000-8fffffff memory:90000000-91ffffff ioport:c000(size=128) memory:db000000-db07ffff
*-multimedia
description: Audio device
product: GP104 High Definition Audio Controller
vendor: NVIDIA Corporation
physical id: 0.1
bus info: pci@0000:06:00.1
version: a1
width: 32 bits
clock: 33MHz
capabilities: pm msi pciexpress bus_master cap_list
configuration: driver=snd_hda_intel latency=0
resources: irq:19 memory:db080000-db083fff
*-pci:6
description: PCI bridge
product: 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8&gt;#8&lt;/denchmark-link&gt;

vendor: Intel Corporation
physical id: 1c.7
bus info: pci@0000:00:1c.7
version: f0
width: 32 bits
clock: 33MHz
capabilities: pci pciexpress msi pm normal_decode bus_master cap_list
configuration: driver=pcieport
resources: irq:126 ioport:b000(size=4096) memory:df200000-df2fffff
*-network
description: Ethernet interface
product: Killer E2500 Gigabit Ethernet Controller
vendor: Qualcomm Atheros
physical id: 0
bus info: pci@0000:07:00.0
logical name: enp7s0
version: 10
serial: 4c:cc:6a:f7:44:7f
size: 1Gbit/s
capacity: 1Gbit/s
width: 64 bits
clock: 33MHz
capabilities: pm pciexpress msi msix bus_master cap_list ethernet physical tp 10bt 10bt-fd 100bt 100bt-fd 1000bt-fd autonegotiation
configuration: autonegotiation=on broadcast=yes driver=alx duplex=full ip=10.0.0.184 latency=0 link=yes multicast=yes port=twisted pair speed=1Gbit/s
resources: irq:19 memory:df200000-df23ffff ioport:b000(size=128)
*-isa
description: ISA bridge
product: 200 Series PCH LPC Controller (Z270)
vendor: Intel Corporation
physical id: 1f
bus info: pci@0000:00:1f.0
version: 00
width: 32 bits
clock: 33MHz
capabilities: isa bus_master
configuration: latency=0
*-memory UNCLAIMED
description: Memory controller
product: 200 Series/Z370 Chipset Family Power Management Controller
vendor: Intel Corporation
physical id: 1f.2
bus info: pci@0000:00:1f.2
version: 00
width: 32 bits
clock: 33MHz (30.3ns)
configuration: latency=0
resources: memory:dd124000-dd127fff
*-multimedia
description: Audio device
product: 200 Series PCH HD Audio
vendor: Intel Corporation
physical id: 1f.3
bus info: pci@0000:00:1f.3
version: 00
width: 64 bits
clock: 33MHz
capabilities: pm msi bus_master cap_list
configuration: driver=snd_hda_intel latency=32
resources: irq:133 memory:dd120000-dd123fff memory:dd100000-dd10ffff
*-serial
description: SMBus
product: 200 Series/Z370 Chipset Family SMBus Controller
vendor: Intel Corporation
physical id: 1f.4
bus info: pci@0000:00:1f.4
version: 00
width: 64 bits
clock: 33MHz
configuration: driver=i801_smbus latency=0
resources: irq:16 memory:dd12a000-dd12a0ff ioport:f000(size=32)
*-pnp00:00
product: PnP device PNP0c02
physical id: 1
capabilities: pnp
configuration: driver=system
*-pnp00:01
product: PnP device PNP0303
physical id: 2
capabilities: pnp
configuration: driver=i8042 kbd
*-pnp00:02
product: PnP device PNP0f03
physical id: 3
capabilities: pnp
configuration: driver=i8042 aux
*-pnp00:03
product: PnP device PNP0501
physical id: 4
capabilities: pnp
configuration: driver=serial
*-pnp00:04
product: PnP device PNP0c02
physical id: 5
capabilities: pnp
configuration: driver=system
*-pnp00:05
product: PnP device PNP0c02
physical id: 6
capabilities: pnp
configuration: driver=system
*-pnp00:06
product: PnP device PNP0b00
physical id: 7
capabilities: pnp
configuration: driver=rtc_cmos
*-pnp00:07
product: PnP device INT3f0d
physical id: 8
capabilities: pnp
configuration: driver=system
*-pnp00:08
product: PnP device PNP0c02
physical id: 9
capabilities: pnp
configuration: driver=system
*-pnp00:09
product: PnP device PNP0c02
physical id: a
capabilities: pnp
configuration: driver=system
*-pnp00:0a
product: PnP device PNP0c02
physical id: b
capabilities: pnp
configuration: driver=system
*-pnp00:0b
product: PnP device PNP0c02
physical id: c
capabilities: pnp
configuration: driver=system
*-power UNCLAIMED
description: To Be Filled By O.E.M.
product: To Be Filled By O.E.M.
vendor: To Be Filled By O.E.M.
physical id: 1
version: To Be Filled By O.E.M.
serial: To Be Filled By O.E.M.
capacity: 32768mWh
*-network:0
description: Ethernet interface
physical id: 2
logical name: vetha11e727
serial: 7e:40:7f:0a:04:8c
size: 10Gbit/s
capabilities: ethernet physical
configuration: autonegotiation=off broadcast=yes driver=veth driverversion=1.0 duplex=full link=yes multicast=yes port=twisted pair speed=10Gbit/s
*-network:1
description: Ethernet interface
physical id: 3
logical name: docker0
serial: 02:42:69:a5:23:2a
capabilities: ethernet physical
configuration: broadcast=yes driver=bridge driverversion=2.3 firmware=N/A ip=172.17.0.1 link=yes multicast=yes
		</comment>
		<comment id='11' author='RayLucchesi' date='2020-08-04T21:53:47Z'>
		here's the "lspci" command output:
lspci
00:00.0 Host bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor Host Bridge/DRAM Registers (rev 07)
00:01.0 PCI bridge: Intel Corporation Xeon E3-1200 v5/E3-1500 v5/6th Gen Core Processor PCIe Controller (x16) (rev 07)
00:08.0 System peripheral: Intel Corporation Xeon E3-1200 v5/v6 / E3-1500 v5 / 6th/7th/8th Gen Core Processor Gaussian Mixture Model
00:14.0 USB controller: Intel Corporation 200 Series/Z370 Chipset Family USB 3.0 xHCI Controller
00:14.2 Signal processing controller: Intel Corporation 200 Series PCH Thermal Subsystem
00:16.0 Communication controller: Intel Corporation 200 Series PCH CSME HECI &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1&gt;#1&lt;/denchmark-link&gt;

00:17.0 SATA controller: Intel Corporation 200 Series PCH SATA controller [AHCI mode]
00:1b.0 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/17&gt;#17&lt;/denchmark-link&gt;
 (rev f0)
00:1b.2 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/19&gt;#19&lt;/denchmark-link&gt;
 (rev f0)
00:1c.0 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/1&gt;#1&lt;/denchmark-link&gt;
 (rev f0)
00:1c.5 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/6&gt;#6&lt;/denchmark-link&gt;
 (rev f0)
00:1c.6 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/7&gt;#7&lt;/denchmark-link&gt;
 (rev f0)
00:1c.7 PCI bridge: Intel Corporation 200 Series PCH PCI Express Root Port &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/8&gt;#8&lt;/denchmark-link&gt;
 (rev f0)
00:1f.0 ISA bridge: Intel Corporation 200 Series PCH LPC Controller (Z270)
00:1f.2 Memory controller: Intel Corporation 200 Series/Z370 Chipset Family Power Management Controller
00:1f.3 Audio device: Intel Corporation 200 Series PCH HD Audio
00:1f.4 SMBus: Intel Corporation 200 Series/Z370 Chipset Family SMBus Controller
01:00.0 VGA compatible controller: NVIDIA Corporation GP104 [GeForce GTX 1070 Ti] (rev a1)
01:00.1 Audio device: NVIDIA Corporation GP104 High Definition Audio Controller (rev a1)
03:00.0 USB controller: ASMedia Technology Inc. ASM2142 USB 3.1 Host Controller
05:00.0 VGA compatible controller: NVIDIA Corporation GP104 [GeForce GTX 1070] (rev a1)
05:00.1 Audio device: NVIDIA Corporation GP104 High Definition Audio Controller (rev a1)
06:00.0 VGA compatible controller: NVIDIA Corporation GP104 [GeForce GTX 1070] (rev a1)
06:00.1 Audio device: NVIDIA Corporation GP104 High Definition Audio Controller (rev a1)
07:00.0 Ethernet controller: Qualcomm Atheros Killer E2500 Gigabit Ethernet Controller (rev 10)
		</comment>
		<comment id='12' author='RayLucchesi' date='2020-08-05T03:49:22Z'>
		If you need anything else let me know. I’m only passing one gpu into Tensorflow and thats the 1070Ti
		</comment>
		<comment id='13' author='RayLucchesi' date='2020-08-05T15:44:15Z'>
		The exact steps I took to generate the problem:
First I built from source for GPU following the instructions at the bottom of &lt;denchmark-link:https://www.tensorflow.org/install/source&gt;https://www.tensorflow.org/install/source&lt;/denchmark-link&gt;

sudo nvidia-smi -pm 1
docker run --gpus 1 --ipc="host" -it -w /tensorflow -v $PWD:/mnt -p 8888:8888 -e HOST_PERMS="$(id -u):$(id -g)" tensorflow/tensorflow:from-src2 bash
export LD_LIBRARY_PATH=“/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64”
pip install jupyter
pip install jupyter_http_over_ws
jupyter serverextension enable --py jupyter_http_over_ws
jupyter notebook --no-browser --notebook-dir=/mnt/notebooks --ip=0.0.0.0 --MappingKernelManager.cull_interval=1200 --debug --NotebookApp.allow_origin='&lt;denchmark-link:https://www.example.com&gt;https://www.example.com&lt;/denchmark-link&gt;
' --NotebookApp.allow_remote_access=True --allow-root
		</comment>
		<comment id='14' author='RayLucchesi' date='2020-08-05T20:21:46Z'>
		&lt;denchmark-link:https://github.com/RayLucchesi&gt;@RayLucchesi&lt;/denchmark-link&gt;
 TF 2.4 version is a nightly version which is unstable. Perhaps you may want to try with latest stable TF 2.3 version for building with source?
		</comment>
		<comment id='15' author='RayLucchesi' date='2020-08-05T22:36:46Z'>
		&lt;denchmark-link:https://github.com/ymodak&gt;@ymodak&lt;/denchmark-link&gt;
 I was just following instructions on the website I indicated above. I'd like to try to rebuild from source from TF2.2 as TF 2.3 seems to have a similar problem.
How would one build with a different level than what's current?   I guess use "git fetch" with either "git merge v2.2" or "git merge v2.3" instead of "git pull" as per the instructions in &lt;denchmark-link:https://www.tensorflow.org/install/source&gt;https://www.tensorflow.org/install/source&lt;/denchmark-link&gt;
?
		</comment>
		<comment id='16' author='RayLucchesi' date='2020-08-05T23:09:29Z'>
		maybe use "git fetch" with "git merge v2.2.0-rc4"?
or can I just do "git pull refs/tag-/v2.2.0-rc4"?
		</comment>
		<comment id='17' author='RayLucchesi' date='2020-08-06T14:43:16Z'>
		&lt;denchmark-link:https://github.com/RayLucchesi&gt;@RayLucchesi&lt;/denchmark-link&gt;
 "git checkout v2.3.0", for example - see &lt;denchmark-link:https://www.tensorflow.org/install/source#download_the_tensorflow_source_code&gt;https://www.tensorflow.org/install/source#download_the_tensorflow_source_code&lt;/denchmark-link&gt;
.
		</comment>
		<comment id='18' author='RayLucchesi' date='2020-08-07T01:30:06Z'>
		Did the git checkout “git checkout v2.3.0” in the tensorflow_src directory and it came back with “ error: pathspec 'v2.3.0' did not match any file(s) known to git.”
It seems I had to do a git fetch first
		</comment>
		<comment id='19' author='RayLucchesi' date='2020-08-07T03:53:54Z'>
		Can you try building for 2.2?
$ git checkout v2.2.0
		</comment>
		<comment id='20' author='RayLucchesi' date='2020-08-08T06:04:54Z'>
		i tried to build from source using  v2.3.0 and the build failed but I think it ran out of space.
I cleaned up some files and tried to build from source using git checkout v2.2.0 and the ./configure command failed with
./configure
Traceback (most recent call last):
File "./configure.py", line 1551, in 
main()
File "./configure.py", line 1368, in main
_TF_MAX_BAZEL_VERSION)
File "./configure.py", line 483, in check_bazel_version
['bazel', '--batch', '--bazelrc=/dev/null', 'version'])
File "./configure.py", line 159, in run_shell
output = subprocess.check_output(cmd, stderr=stderr)
File "/usr/lib/python3.6/subprocess.py", line 356, in check_output
**kwargs).stdout
File "/usr/lib/python3.6/subprocess.py", line 438, in run
output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command '['bazel', '--batch', '--bazelrc=/dev/null', 'version']' returned non-zero exit status 1.
So I'm going to retry build from source using v2.3.0 again...
Realize that every time I build from source it's a 11+ hour operation.
Also not sure what to make of "stu1130 added a commit to awslabs/djl that referenced this issue 5 hours ago" comment above is this a fix to the problem in v2.3?
		</comment>
		<comment id='21' author='RayLucchesi' date='2020-08-08T20:13:57Z'>
		So after another evening of building from source this time with V2.3.0. I get through that ok (after clearing out some used and unused container images) and then I do the build whl and that works and then I pip uninstall tensorflow and then pip install tensorflow-2.3.0-cp36-cp36m-linux_x86_64.whl and that seems to work.
Following the instructions in the build from source website I try a simple python program to print out the #GPUs.
python -c "import tensorflow as tf; print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))"
which fails as follows:
python -c "import tensorflow as tf; print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))"
Traceback (most recent call last):
File "", line 1, in 
File "/tensorflow_src/tensorflow/init.py", line 24, in 
from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
File "/tensorflow_src/tensorflow/python/init.py", line 40, in 
from tensorflow.python.eager import context
File "/tensorflow_src/tensorflow/python/eager/context.py", line 32, in 
from tensorflow.core.framework import function_pb2
ImportError: cannot import name 'function_pb2'
I have copies of the terminal output from the bazel build, the build wheel, the pip uninstall and pip install if you want them.
		</comment>
		<comment id='22' author='RayLucchesi' date='2020-08-08T20:22:05Z'>
		when I cd $HOME and try the same program
cd $HOME
root@17638e5f9f58:~# python -c "import tensorflow as tf; print(' Num GPUs Available: ', len(tf.config.experimental.list_physical_devices('GPU')))"
2020-08-08 20:19:24.128138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-08-08 20:19:25.347871: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-08-08 20:19:25.347901: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: UNKNOWN ERROR (-1)
2020-08-08 20:19:25.347918: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 17638e5f9f58
2020-08-08 20:19:25.348048: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 17638e5f9f58
2020-08-08 20:19:25.348182: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
2020-08-08 20:19:25.348559: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 450.57.0
Num GPUs Available:  0
I get my favorite CUINIT unknown error (-1)
		</comment>
		<comment id='23' author='RayLucchesi' date='2020-08-09T03:46:01Z'>
		Of course that’s because the stubs folder is in $LD_LIBRARY_PATH. When I delete that with
export LD_LIBRARY_PATH=“/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x64_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64”
It now comes up ok
But now after i commit the container and startup a jupyter notebook server in the container it seems to work. thanks for your help.
Mind if I ask what the revert update to tf2_3 did?
		</comment>
		<comment id='24' author='RayLucchesi' date='2020-08-24T06:46:41Z'>
		It’s taken me a bit but it appears as if tf is built for GPUs, the docker container has GPUS ALL and I can see the GPUS in the container using NVIDIA-SMI but for some reason TF is not using any gpus.
print(device_lib.list_local_devices())
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 7047076578536459057
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
tf.test.is_built_with_gpu_support()
​
Out[5]:
True
tf.test.is_gpu_available(
cuda_only=False, min_cuda_compute_capability=None
)
WARNING:tensorflow:From :2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.config.list_physical_devices('GPU') instead.
Out[3]:
False
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
​
Num GPUs Available:  0
docker container exec b48df43026b0 nvidia-smi
Mon Aug 24 06:08:41 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: ERR!     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  On   | 00000000:01:00.0 Off |                  N/A |
|  0%   32C    P8     6W / 180W |     54MiB /  8116MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1070    On   | 00000000:05:00.0 Off |                  N/A |
|  0%   28C    P8     4W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1070    On   | 00000000:06:00.0 Off |                  N/A |
|  0%   27C    P8     4W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
So the docker container has GPUs (3 of them). TF was built with GPU support but for some reason TF is not discovering the GPUs nor using them.
I’ve tried this by just using one GPU “GPUS 1” on docker command and it doesn’t seem to make a difference except in the Nvidia-SMi command.
I used to have debug on for the jupyter notebook server and I saw that it accessed CUDA libraries...
		</comment>
		<comment id='25' author='RayLucchesi' date='2020-08-24T06:47:57Z'>
		Oh and I tried this:
tf.config.list_physical_devices('GPU')
​
Out[4]:
[]
Which also shows no GPUs...
		</comment>
		<comment id='26' author='RayLucchesi' date='2020-08-24T22:30:12Z'>
		Sorry my mistake forgot to extract "/usr/local/cuda/lib64/stubs" from $LD_LIBRARY_PATH. When I did that GPUs were available again.
		</comment>
		<comment id='27' author='RayLucchesi' date='2020-08-24T22:50:12Z'>
		After all that I'm back to my favorite CUDA intialization failed error:
CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid.
After the failure here is what NVIDIA-SMI command shows in the container:
Mon Aug 24 22:41:54 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: ERR!     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  On   | 00000000:01:00.0 Off |                  N/A |
|  0%   40C    P8     7W / 180W |    165MiB /  8116MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
and this is what the NVIDIA-SMI command shows at the ubuntu system (outside the container)
nvidia-smi
Mon Aug 24 16:42:45 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  On   | 00000000:01:00.0 Off |                  N/A |
|  0%   39C    P8     7W / 180W |    165MiB /  8116MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1070    On   | 00000000:05:00.0 Off |                  N/A |
|  0%   30C    P8     5W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 1070    On   | 00000000:06:00.0 Off |                  N/A |
|  0%   28C    P8     4W / 166W |      7MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1010      G   /usr/lib/xorg/Xorg                 36MiB |
|    0   N/A  N/A      1684      G   /usr/bin/gnome-shell               15MiB |
|    0   N/A  N/A      5623      C   /usr/bin/python3                  109MiB |
|    1   N/A  N/A      1010      G   /usr/lib/xorg/Xorg                  4MiB |
|    2   N/A  N/A      1010      G   /usr/lib/xorg/Xorg                  4MiB |
+-----------------------------------------------------------------------------+
It seems I can use TF services to see the GPU but I can't seem to get tf.keras to build a model that uses them. Here's the model I was attempting to define at the time of the error:
model = tf.keras.Sequential()
model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(128,(3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(128,(3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.summary()
The error seems to have been generated on the 1st statement above.  I uploaded the traceback for the error.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/5120556/cuda_init_error_traceback.log&gt;cuda_init_error_traceback.log&lt;/denchmark-link&gt;

anything else you need please let me know. At this point we are back to ground 0, getting the cuda initialization error.
It seems every time I thought it was working we were not working with GPUs.
		</comment>
		<comment id='28' author='RayLucchesi' date='2020-08-24T23:12:45Z'>
		Turns out I need to rebuild from source with compute capability 6.1 to support the GeForce 1070/1070 Titan GPUs... doing that now. I'll let you know tomorrow after the build finishes whether it works or not.
		</comment>
		<comment id='29' author='RayLucchesi' date='2020-08-26T00:46:25Z'>
		After rebuild from source  (TF 2.4) and using the correct CUDA GPU compute capability, 6.1, it now seems to work once I delete stubs from LD_LIBRARY_PATH. So as far as I’m concerned you can close this issue.
However, the CUINIT error message is somewhat cryptic, I would suggest rewording it to say something about TF build doesn’t support the GPU that’s available and that it needs to be rebuilt from source with the correct CUDA GPU compute capability.
Thanks for all your help in this.
		</comment>
		<comment id='30' author='RayLucchesi' date='2020-08-26T00:47:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41976&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/41976&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>