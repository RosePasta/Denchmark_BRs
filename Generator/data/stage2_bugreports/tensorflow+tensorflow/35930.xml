<bug id='35930' author='bj1123' open_date='2020-01-16T09:58:58Z' closed_time='2020-06-25T21:43:53Z'>
	<summary>load_weights does not work when weights are saved in h5 format</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 2.1
Python version: 3.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:

Describe the current behavior
model can't restore weights from h5 file
Describe the expected behavior
Code to reproduce the issue
&lt;denchmark-code&gt;class Model(keras.Model):
    def __init__(self, inp1, inp2):
        super(Model, self).__init__()
        self.x1 = self.add_weight('w1',[inp1])
        self.x2 = self.add_weight('w2',[inp2])
    def call(self,x):
        return x
# load_weights method works when save format is 'tf
x = Model(100,200)
x.save_weights('temp.tmp',save_format='tf')
old = x.weights[0][0].numpy()
print(old)
x = Model(100,200)
x.load_weights('temp.tmp')
new = x.weights[0][0].numpy()
print(new)
print(old==new)

# load_weights method does not work when save format is 'h5'
x = Model(100,200)
x.save_weights('temp.h5',save_format='h5')
old = x.weights[0][0].numpy()
print(old)
x = Model(100,200)
x.load_weights('temp.h5')
new = x.weights[0][0].numpy()
print(new)
print(old==new)
&lt;/denchmark-code&gt;

Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
	</description>
	<comments>
		<comment id='1' author='bj1123' date='2020-01-17T03:23:42Z'>
		&lt;denchmark-link:https://github.com/bj1123&gt;@bj1123&lt;/denchmark-link&gt;
 ,
When tried running the given code in both &lt;denchmark-link:https://colab.sandbox.google.com/drive/1rqcqkeDpD0TG3brFJtyq1x8WEfET0vcU#scrollTo=RbZaVocMg-u_&gt;2.1&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://colab.sandbox.google.com/drive/19sCVnZyjsRYzxeCs5M5IjMGli_nP-PnK#scrollTo=0FawR_S5fFm8&gt;tf-nightly&lt;/denchmark-link&gt;
, I didn't face any error.Thanks!
		</comment>
		<comment id='2' author='bj1123' date='2020-01-17T06:00:08Z'>
		
@bj1123 ,
When tried running the given code in both 2.1 and tf-nightly, I didn't face any error.Thanks!

&lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;
 It doesn't raise error. The problem is that the saved weights are not restored. The weights of the model remain the same even after load_weights are called.
		</comment>
		<comment id='3' author='bj1123' date='2020-01-22T06:41:11Z'>
		&lt;denchmark-link:https://github.com/bj1123&gt;@bj1123&lt;/denchmark-link&gt;
 ,
I just modified few lines of code and I am able to load the model weights successfully,kindly refer the &lt;denchmark-link:https://colab.sandbox.google.com/gist/oanush/8b8802b2743fbaf47149c5941da8e213/35930_tf-nightly.ipynb&gt;gist of colab&lt;/denchmark-link&gt;
. Please refer these links of &lt;denchmark-link:https://github.com/keras-team/keras/issues/12094#issuecomment-481397688&gt;github&lt;/denchmark-link&gt;
 and &lt;denchmark-link:https://stackoverflow.com/questions/41859997/keras-model-load-weights-for-neural-net&gt;stackoverflow&lt;/denchmark-link&gt;
 for more information.
		</comment>
		<comment id='4' author='bj1123' date='2020-01-22T08:55:25Z'>
		&lt;denchmark-link:https://github.com/oanush&gt;@oanush&lt;/denchmark-link&gt;

I think your modification can not assure the weights are successfully loaded. If you comment out the code for initializing the model, the model weights remain the same and printing variables "old" and "new" happen to be the same whether or not the weights are successfully loaded. I slightly changed the codes for better understanding, and it still shows the same problem.
&lt;denchmark-code&gt;class Model(keras.Model):
    def __init__(self, inp1, inp2):
        super(Model, self).__init__()
        self.x1 = self.add_weight('w1',[inp1])
        self.x2 = self.add_weight('w2',[inp2])
    def call(self,x):
        return x
# load_weights method works when save format is 'tf
x = Model(100,200)
x.save_weights('temp.tmp',save_format='tf')
old = x.weights[0][0].numpy()
x.weights[0].assign(tf.zeros_like(x.weights[0]))
print(old)
x.load_weights('temp.tmp')
new = x.weights[0][0].numpy()
print(new)
print(old==new)

# load_weights method does not work when save format is 'h5'
x = Model(100,200)
x.save_weights('temp.h5',save_format='h5')
old = x.weights[0][0].numpy()
x.weights[0].assign(tf.zeros_like(x.weights[0]))
print(old)
x.load_weights('temp.h5')
new = x.weights[0][0].numpy()
print(new)
print(old==new)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='5' author='bj1123' date='2020-02-24T15:06:18Z'>
		Any update regarding this issue ?
I am having the same problem trying to load inceptionV3 weights trained with TF1.13  using TF2.1.
		</comment>
		<comment id='6' author='bj1123' date='2020-03-13T23:07:08Z'>
		This issue is so annoying. I am using both Anaconda's TF 2.1 GPU and MKL on both Linux and Windows. After training loss is for example 0.2 loading the weights error increases significantly as if the model is not trained.
		</comment>
		<comment id='7' author='bj1123' date='2020-04-17T13:38:44Z'>
		I also have this issue, anyone know a solution yet?
		</comment>
		<comment id='8' author='bj1123' date='2020-04-17T14:05:33Z'>
		&lt;denchmark-link:https://github.com/cs-mac&gt;@cs-mac&lt;/denchmark-link&gt;

I hope this might help
&lt;denchmark-code&gt;def load_weights(model,save_path):
    hf = h5py.File(save_path, 'r')
    for i in model.trainable_weights:
        res = hf.get(i.name)
        res = tf.convert_to_tensor(np.array(res))
        if res.shape == i.shape:
            i.assign(res)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='9' author='bj1123' date='2020-04-17T15:11:05Z'>
		&lt;denchmark-link:https://github.com/bj1123&gt;@bj1123&lt;/denchmark-link&gt;

Thank you for your reply!
I managed to fix the mistake, embarrassingly enough it was a user error on my part.
I remade the whole trained model to access some layer I needed. Then I used this newly created model, which of course was not trained yet, instead of the trained model. Therefore, all attention weights seemed random.
		</comment>
		<comment id='10' author='bj1123' date='2020-06-25T21:43:54Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35930&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35930&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>