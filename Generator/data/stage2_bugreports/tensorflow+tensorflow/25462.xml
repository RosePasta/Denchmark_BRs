<bug id='25462' author='zhang-jian' open_date='2019-02-02T23:33:56Z' closed_time='2019-03-20T00:54:53Z'>
	<summary>tflite outputs don't match with tensorflow outputs for conv2d_transpose</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): v1.12.0-0-ga6d8ffae09 1.12.0 (using python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)")
Python version: Python 3.5.4 |Anaconda custom (64-bit)| (default, Nov 20 2017, 18:44:38)
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): [GCC 7.2.0] on linux
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Describe the current behavior
tflite outputs don't match with tensorflow outputs
Describe the expected behavior
tflite outputs is expected to match tensorflow outputs
Code to reproduce the issue
import tensorflow as tf
import numpy as np

np.random.seed(1234)
tf.random.set_random_seed(1234)

def trans_conv1d(x,
                 num_filters,
                 filter_length,
                 stride):
    batch_size, length, num_input_channels = x.get_shape().as_list()
    x = tf.reshape(x, [batch_size, 1, length, num_input_channels])

    weights = tf.get_variable('W', shape=(1, filter_length, num_filters, num_input_channels))
    biases = tf.get_variable('b', shape=(num_filters,))

    y = tf.nn.conv2d_transpose(
        x,
        filter=weights,
        output_shape=(batch_size, 1, stride * length, num_filters),
        strides=(1, 1, stride, 1),
        padding='SAME',
        data_format='NHWC',
        name="cnn2d")
    y = tf.nn.bias_add(y, biases)
    return y

num_filters = 4
filter_length = 40
stride = 8
x = tf.placeholder(dtype = tf.float32, shape = [1, 96, 2], name = "input")
y = trans_conv1d(x, num_filters, filter_length, stride)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
input_data = np.array(np.random.rand(1, 96, 2), dtype=np.float32)
output_data_tf = sess.run(y, feed_dict={x:input_data})
converter = tf.contrib.lite.TFLiteConverter.from_session(sess, [x], [y])
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)
sess.close()

# tflite test
interpreter = tf.contrib.lite.Interpreter(model_path="converted_model.tflite")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on the same input data.
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()
output_data_tflite = interpreter.get_tensor(output_details[0]['index'])
print(np.array_equal(output_data_tf, output_data_tflite))

Other info / logs
False
	</description>
	<comments>
		<comment id='1' author='zhang-jian' date='2019-02-07T09:18:04Z'>
		Just wondering if there is any update on this? Thanks
		</comment>
		<comment id='2' author='zhang-jian' date='2019-03-19T03:30:06Z'>
		&lt;denchmark-link:https://github.com/haozha111&gt;@haozha111&lt;/denchmark-link&gt;
 Could you take a look since you're recently looking into TransposeConv?
		</comment>
		<comment id='3' author='zhang-jian' date='2019-03-19T23:41:05Z'>
		Sure.
		</comment>
		<comment id='4' author='zhang-jian' date='2019-03-20T00:10:35Z'>
		Patched your code and run with tf-nightly. Here is the result:
INFO: Initialized TensorFlow Lite runtime.
output tf: [[[[ 0.18149409  0.12595409  0.25195837 -0.7155486 ]
[ 0.15551439  0.15711296  0.42898354 -0.4680799 ]
[-0.09389246 -0.14556983  0.5282279  -0.2589781 ]
...
[ 0.16891086 -0.02126111  0.17114447 -0.08986548]
[ 0.02455523  0.10942102  0.41191384 -0.33445707]
[ 0.07544918  0.02863858  0.36540815 -0.33818465]]]]
output tflite: [[[[ 0.18149409  0.12595409  0.25195837 -0.7155486 ]
[ 0.15551439  0.15711296  0.42898354 -0.46807992]
[-0.09389246 -0.14556983  0.5282279  -0.2589781 ]
...
[ 0.16891086 -0.02126111  0.17114449 -0.08986548]
[ 0.02455523  0.10942102  0.41191384 -0.33445707]
[ 0.07544918  0.02863858  0.36540815 -0.33818465]]]]
False
diff: [[[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]
[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  2.9802322e-08]
[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]
...
[ 0.0000000e+00  0.0000000e+00 -1.4901161e-08  0.0000000e+00]
[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]
[ 0.0000000e+00 -3.7252903e-09  0.0000000e+00  0.0000000e+00]]]]
As you can see, most of the output values agree, with only a few differences. However the difference is pretty small(1e-8).
If you try diff by: print(np.allclose(output_data_tf, output_data_tflite, atol=1e-8))
The result will agree. I will investigate more on this.
		</comment>
		<comment id='5' author='zhang-jian' date='2019-03-20T00:47:51Z'>
		Numerical errors are almost unavoidable in floating point calculation.
In many of our test cases, we test with 1e-6 threshold.
1e-8 is pretty acceptable, so I'd say this is intended behavior.
I'd suggest to always test float results with a threshold, not exact matching.
		</comment>
		<comment id='6' author='zhang-jian' date='2019-03-20T00:54:53Z'>
		Agreed. I will close for now.
		</comment>
	</comments>
</bug>