<bug id='28646' author='KichangKim' open_date='2019-05-12T23:38:36Z' closed_time='2019-11-12T22:29:01Z'>
	<summary>[TF 2.0] keras model.train_on_batch allocates extremely large CPU memory</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1809
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.0.0-dev20190504
Python version: 3.6.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 10
GPU model and memory: Geforce GTX 1070 8GB

Describe the current behavior
When I try to train_on_batch, TF 2.0 allcaotes memory endless and finally crashes. Using tf.keras.backend.set_learning_phase(1) can be temporary solution, but this trick doesn work with lateset build (dev20190511).
Describe the expected behavior
The model can be trained regardless of tf.keras.backend.set_learning_phase(1) because I used model.train_on_batch(). It should handle learning phase internally.
Code to reproduce the issue
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np


def conv(x, filters, kernel_size, strides=(1, 1), padding='same', initializer='he_normal'):
    c = tf.keras.layers.Conv2D(
        filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, kernel_initializer=initializer, use_bias=False)(x)

    return c


def conv_bn(x, filters, kernel_size, strides=(1, 1), padding='same', initializer='he_normal', bn_gamma_initializer='ones'):
    c = conv(x, filters=filters, kernel_size=kernel_size,
             strides=strides, padding=padding, initializer=initializer)

    c_bn = tf.keras.layers.BatchNormalization(
        gamma_initializer=bn_gamma_initializer)(c)

    return c_bn


def conv_bn_relu(x, filters, kernel_size, strides=(1, 1), padding='same', initializer='he_normal', bn_gamma_initializer='ones'):
    c_bn = conv_bn(x, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,
                   initializer=initializer, bn_gamma_initializer=bn_gamma_initializer)

    return tf.keras.layers.Activation('relu')(c_bn)


def conv_gap(x, output_filters, kernel_size=(1, 1)):
    x = conv(x, filters=output_filters, kernel_size=kernel_size)
    x = tf.keras.layers.GlobalAveragePooling2D()(x)

    return x


def my_block(x, output_filters, inter_filters):
    c1 = conv_bn_relu(x, inter_filters, (1, 1))
    c2 = conv_bn_relu(c1, inter_filters, (3, 3))
    c3 = conv_bn(
        c2, output_filters, (1, 1), bn_gamma_initializer='zeros')

    p = tf.keras.layers.add([c3, x])

    return tf.keras.layers.Activation('relu')(p)


def my_block_inc(x, output_filters, inter_filters, strides1x1=(1, 1), strides2x2=(2, 2)):
    c1 = conv_bn_relu(
        x, inter_filters, (1, 1), strides=strides1x1)
    c2 = conv_bn_relu(
        c1, inter_filters, (3, 3), strides=strides2x2)
    c3 = conv_bn(
        c2, output_filters, (1, 1), bn_gamma_initializer='zeros')

    strides = np.multiply(strides1x1, strides2x2)
    s = conv_bn(
        x, output_filters, (1, 1), strides=strides)  # shortcut

    p = tf.keras.layers.add([c3, s])

    return tf.keras.layers.Activation('relu')(p)


def repeat_blocks(x, block_delegate, count, **kwargs):
    assert count &gt;= 0

    for _ in range(count):
        x = block_delegate(x, **kwargs)
    return x


# This line makes trick!
# tf.keras.backend.set_learning_phase(1)
shape = (299, 299, 3)

inputs = tf.keras.Input(shape, dtype='float32')
outputs = conv_bn_relu(inputs, 256 // 4, (7, 7), strides=(2, 2))
outputs = tf.keras.layers.MaxPool2D(
    (3, 3), strides=(2, 2), padding='same')(outputs)
outputs = my_block_inc(outputs, 256, 256 // 4, strides2x2=(1, 1))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=2,
                        output_filters=256,
                        inter_filters=256 // 4)

outputs = my_block_inc(outputs, 512, 512 // 4, strides2x2=(2, 2))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=7,
                        output_filters=512,
                        inter_filters=512 // 4)

outputs = my_block_inc(outputs, 1024, 1024 // 4, strides2x2=(2, 2))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=40,
                        output_filters=1024,
                        inter_filters=1024 // 4)

outputs = my_block_inc(outputs, 1024, 1024 // 4, strides2x2=(2, 2))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=16,
                        output_filters=1024,
                        inter_filters=1024 // 4)

outputs = my_block_inc(outputs, 1024, 1024 // 4, strides2x2=(2, 2))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=16,
                        output_filters=1024,
                        inter_filters=1024 // 4)

outputs = my_block_inc(outputs, 2048, 2048 // 4, strides2x2=(2, 2))
outputs = repeat_blocks(outputs, block_delegate=my_block,
                        count=6,
                        output_filters=2048,
                        inter_filters=2048 // 4)

outputs = conv_gap(outputs, 1024)
outputs = tf.keras.layers.Activation('sigmoid')(outputs)
model = tf.keras.models.Model(
    inputs=inputs, outputs=outputs, name='resnet_custom_v2')

optimizer = tf.optimizers.Adam(0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy',
              metrics=['mean_absolute_error'])


def make_batch(_):
    x = np.ones((shape[0], shape[1], shape[2]), dtype='float32')
    y = np.ones((1024), dtype='float32')

    return (x, y)


dataset = tf.data.Dataset.from_tensor_slices(
    ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])
dataset = dataset.map(lambda x: tf.py_function(
    make_batch, (x,), (tf.float32, tf.float32)))
dataset = dataset.batch(10)

for x, y in dataset:
    step_results = model.train_on_batch(x=x, y=y)
    print(f'loss={step_results[0]}')

&lt;/denchmark-code&gt;

If you uncomment tf.keras.backend.set_learning_phase(1), the model may be successully trained. But with TF 2.0 dev20190511, the traininig is always failed regardless of tf.keras.backend.set_learning_phase(1).
	</description>
	<comments>
		<comment id='1' author='KichangKim' date='2019-05-13T01:10:23Z'>
		Related comment:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28110#issuecomment-490082449&gt;#28110 (comment)&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='KichangKim' date='2019-05-13T11:44:20Z'>
		&lt;denchmark-link:https://github.com/KichangKim&gt;@KichangKim&lt;/denchmark-link&gt;
 Able to reproduce the issue using build (dev20190511) allocates endless memory and finally crashes.
		</comment>
		<comment id='3' author='KichangKim' date='2019-06-21T01:20:13Z'>
		I found that TensorFlow 2.0.0-beta1 still have this issue.
		</comment>
		<comment id='4' author='KichangKim' date='2019-10-08T11:13:11Z'>
		Same problem here. Exact same code was running fine on tf.keras 1.14 causes OOM with tf.keras 2.0. Code snippet:
&lt;denchmark-code&gt;import numpy as np
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam


imagenet_test = [e.g. your image directory]

model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))
model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['acc'])

datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_generator = datagen.flow_from_directory(directory=imagenet_test,
                                            batch_size=256,
                                            class_mode='sparse',
                                            target_size=(224, 224))
steps = np.ceil(len(test_generator.classes) / 256)

model.evaluate_generator(test_generator, steps, verbose=1)
&lt;/denchmark-code&gt;

The above code won't throw OOM error when use a very small batch size (e.g. 8) or with eager execution turned off.
		</comment>
		<comment id='5' author='KichangKim' date='2019-10-08T21:14:42Z'>
		
Same problem here. Exact same code was running fine on tf.keras 1.14 causes OOM with tf.keras 2.0. Will update code snippet.

I think OOM issue is related with &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/31871&gt;#31871&lt;/denchmark-link&gt;
 too. Also it is not fixed yet.
		</comment>
		<comment id='6' author='KichangKim' date='2019-11-12T22:29:00Z'>
		I found that tf-nightly-gpu==2.1.0.dev20191112 does not have this issue anymore. Thanks.
		</comment>
		<comment id='7' author='KichangKim' date='2019-11-12T22:29:02Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28646&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28646&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>