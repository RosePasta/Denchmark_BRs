<bug id='30580' author='elyasmehtabuddin' open_date='2019-07-10T22:38:18Z' closed_time='2019-09-04T19:20:45Z'>
	<summary>TPU has XLA compilation issue on TF 1.14</summary>
	<description>
I am getting an issue with using XLA on the cloud TPU on tensorflow version 1.14
System information

Using Google's cloud TPU with Tensorflow 1.14
v1.14.0-rc1-22-gaf24dc91b5 1.14.0

&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3379601/tf_env.txt&gt;tf_env.txt&lt;/denchmark-link&gt;

System info (sanity check log message removed, full  attached above):
&lt;denchmark-code&gt;
== check python ===================================================
python version: 3.5.3
python branch: 
python build version: ('default', 'Sep 27 2018 17:25:39')
python compiler version: GCC 6.3.0 20170516
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Sat Jun 22 23:33:41 PDT 2019
os release version: 4.14.111+
os platform: Linux-4.14.111+-x86_64-with-debian-9.9
linux distribution: ('debian', '9.9', '')
linux os distribution: ('debian', '9.9', '')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='cs-6000-devshell-vm-cb1acb17-794a-49c5-8346-cd612beb1d0d', release='4.14.111+', version='#1 SMP Sat Jun 22 23:33:41 PDT 2019', machine='x86_64', processor='')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Debian 6.3.0-18+deb9u1) 6.3.0 20170516
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy (1.16.4)
protobuf (3.8.0)
tensorflow (1.14.0)
tensorflow-estimator (1.14.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 1.14.0
tf.version.GIT_VERSION = v1.14.0-rc1-22-gaf24dc91b5
tf.version.COMPILER_VERSION = 4.8.5
Sanity check: -- EDITED OUT ---

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 147: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 1.14.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /usr/local/lib/python3.5/dist-packages

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 5, 3, 'final', 0)

== bazel version  ===============================================
Build label: 0.27.1
Build time: Tue Jul 2 17:49:35 2019 (1562089775)
Build timestamp: 1562089775
Build timestamp as int: 1562089775

&lt;/denchmark-code&gt;

Describe the current behavior
When I run my model (which is a partial implementation of Transformer) using XLA, I get an error message.
The error message is the following:
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0710 13:59:32.655435 139705705027328 deprecation_wrapper.py:119] From issue.py:24: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

W0710 13:59:32.655846 139705705027328 deprecation.py:323] From issue.py:25: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
W0710 13:59:32.655990 139705705027328 deprecation.py:323] From issue.py:26: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
W0710 13:59:32.663649 139705705027328 deprecation_wrapper.py:119] From issue.py:68: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0710 13:59:32.707169 139705705027328 deprecation_wrapper.py:119] From issue.py:85: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.

W0710 13:59:32.714751 139705705027328 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0710 13:59:33.743603 139705705027328 deprecation_wrapper.py:119] From issue.py:205: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

W0710 13:59:35.527529 139705705027328 deprecation_wrapper.py:119] From issue.py:206: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0710 13:59:35.536509 139705705027328 deprecation_wrapper.py:119] From issue.py:208: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W0710 13:59:35.547362 139705705027328 deprecation_wrapper.py:119] From issue.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-10 13:59:35.547951: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-10 13:59:35.799823: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-07-10 13:59:35.800045: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5608f773ae90 executing computations on platform Host. Devices:
2019-07-10 13:59:35.800062: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
W0710 13:59:35.811006 139705705027328 deprecation_wrapper.py:119] From issue.py:31: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2019-07-10 13:59:36.203915: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-07-10 13:59:36.572778: W tensorflow/core/framework/allocator.cc:107] Allocation of 67141632 exceeds 10% of system memory.
2019-07-10 13:59:36.861743: W tensorflow/core/framework/allocator.cc:107] Allocation of 67141632 exceeds 10% of system memory.
2019-07-10 13:59:37.125698: W tensorflow/core/framework/allocator.cc:107] Allocation of 67141632 exceeds 10% of system memory.
2019-07-10 13:59:37.551537: W tensorflow/core/framework/allocator.cc:107] Allocation of 67141632 exceeds 10% of system memory.
W0710 13:59:39.391257 139705705027328 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
W0710 13:59:39.444635 139705705027328 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
W0710 13:59:39.445140 139705705027328 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
2019-07-10 13:59:44.506360: W tensorflow/core/framework/op_kernel.cc:1502] OP_REQUIRES failed at xla_ops.cc:343 : Invalid argument: Detected unsupported operations when trying to compile graph cluster_13546192731870215987[] on XLA_CPU_JIT: TemporaryVariable (No registered 'TemporaryVariable' OpKernel for XLA_CPU_JIT devices compatible with node {{node gradients/AddN_13/tmp_var}}
  .  Registered:  device='CPU'
){{node gradients/AddN_13/tmp_var}}
  This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS="tf_xla_auto_jit=2" which will attempt to use xla to compile as much of the graph as the compiler is able to.
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1356, in _do_call
    return fn(*args)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph cluster_13546192731870215987[] on XLA_CPU_JIT: TemporaryVariable (No registered 'TemporaryVariable' OpKernel for XLA_CPU_JIT devices compatible with node {{node gradients/AddN_13/tmp_var}}
  .  Registered:  device='CPU'
){{node gradients/AddN_13/tmp_var}}
  This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS="tf_xla_auto_jit=2" which will attempt to use xla to compile as much of the graph as the compiler is able to.
   [[cluster]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "issue.py", line 221, in &lt;module&gt;
    sys.exit(main(sys.argv))
  File "issue.py", line 217, in main
    hlo = get_hlo(transformer_model_fn, transformer_input_fn)
  File "issue.py", line 33, in get_hlo
    sess.run(loss)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 950, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1350, in _do_run
    run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph cluster_13546192731870215987[] on XLA_CPU_JIT: TemporaryVariable (No registered 'TemporaryVariable' OpKernel for XLA_CPU_JIT devices compatible with node {{node gradients/AddN_13/tmp_var}}
  .  Registered:  device='CPU'
){{node gradients/AddN_13/tmp_var}}
  This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 or the environment variable TF_XLA_FLAGS="tf_xla_auto_jit=2" which will attempt to use xla to compile as much of the graph as the compiler is able to.
   [[cluster]]
&lt;/denchmark-code&gt;

Describe the expected behavior
I expect there to be no error message!
Code to reproduce the issue
Reproduce with python3 issue.py
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/files/3379603/issue.py.zip&gt;issue.py.zip&lt;/denchmark-link&gt;

issue.py is the following (also zipped above):
&lt;denchmark-code&gt;import sys
import tensorflow as tf
import numpy as np

from tensorflow.contrib.compiler.xla import compile

HIDDEN_SIZE = 2048
FILTER_SIZE = 8196
NUM_HEADS = 32
D_K = HIDDEN_SIZE // NUM_HEADS
D_K_ROOT = D_K ** (-0.5)
WORD_LEN = 512 


def get_hlo(model_fn, input_fn):

    def xla_model_fn(features, labels):
        spec = model_fn(features, labels, mode="train", params=None)
        with tf.control_dependencies([spec.train_op]):
            return tf.identity(spec.loss, name=spec.loss.op.name)

    train_ds = input_fn().repeat()

    iterator = tf.data.Iterator.from_structure(
        train_ds.output_types,
        train_ds.output_shapes,
    )
    loss, = compile(xla_model_fn, inputs=iterator.get_next())

    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(iterator.make_initializer(train_ds))
        sess.run(loss)


def transformer_input_fn():
    feat_shape = [1, WORD_LEN, HIDDEN_SIZE]
    labels_shape = [1, 1, 1, WORD_LEN]

    model_inputs = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(
                    np.random.uniform(size=feat_shape)
                ),
                feat_shape,
            ),
            tf.float32,
        ),
    ]

    model_expected = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(np.random.uniform(size=labels_shape)),
                labels_shape,
            ),
            tf.float32,
        ),
    ]

    dataset = (model_inputs, model_expected)
    dataset = tf.data.Dataset.from_tensor_slices(dataset)
    return dataset


def transformer_model_fn(features, labels, mode, params):
    layer_norm_scale = tf.get_variable(
        "layer_norm_scale",
        [HIDDEN_SIZE],
        initializer=tf.ones_initializer(),
    )
    layer_norm_bias = tf.get_variable(
        "layer_norm_bias",
        [HIDDEN_SIZE],
        initializer=tf.zeros_initializer(),
    )

    def layer_normalization(net):
        mean = tf.reduce_mean(net, axis=[-1], keepdims=True)
        mean = tf.multiply(mean, -1)
        diff = tf.add(net, mean)
        var = tf.reduce_mean(tf.square(diff), axis=[-1], keepdims=True)
        var = tf.add(var, 1e-6)
        net = tf.multiply(diff, tf.rsqrt(var))
        return tf.add(tf.multiply(net, layer_norm_scale), layer_norm_bias)

    def transformer_fc(net, size, use_bias=True):
        return tf.keras.layers.Dense(
            size,
            activation=None,
            use_bias=use_bias,
        )(net)

    def feed_forward(net):
        net = transformer_fc(net, FILTER_SIZE)
        net = tf.nn.relu(net)
        net = tf.nn.dropout(net, rate=0.1)
        net = transformer_fc(net, HIDDEN_SIZE)
        return net

    def multi_headed_attention(q, k, v, bias):
        def split_heads(net):
            net = tf.reshape(
                net,
                [1, WORD_LEN, NUM_HEADS, D_K],
            )
            net = tf.transpose(net, [0, 2, 1, 3])
            return net

        def combine_heads(net):
            net = tf.transpose(net, [0, 2, 1, 3])
            net = tf.reshape(
                net, [1, WORD_LEN, HIDDEN_SIZE]
            )
            return net

        q = transformer_fc(q, HIDDEN_SIZE, use_bias=False)
        k = transformer_fc(k, HIDDEN_SIZE, use_bias=False)
        v = transformer_fc(v, HIDDEN_SIZE, use_bias=False)

        q = split_heads(q)
        k = split_heads(k)
        v = split_heads(v)

        q = tf.multiply(q, D_K_ROOT)
        x = tf.matmul(q, k, transpose_b=True)
        x = tf.add(x, bias)

        x = tf.nn.softmax(x)
        x = tf.nn.dropout(x, rate=0.1)
        x = tf.matmul(x, v)

        x = combine_heads(x)
        x = transformer_fc(x, HIDDEN_SIZE, use_bias=False)
        return x

    def encoder_block(net, enc_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, enc_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def encode(enc_input, enc_bias):
        net = tf.nn.dropout(enc_input, rate=0.1)
        net = encoder_block(net, enc_bias) 
        return net

    def decoder_block(net, enc_output, dec_bias, enc_dec_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, enc_output, enc_output, enc_dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def decode(dec_input, enc_output, dec_bias, enc_dec_bias):
        net = tf.nn.dropout(dec_input, rate=0.1)
        net = decoder_block(net, enc_output, dec_bias, enc_dec_bias)
        return net

    labels = tf.stop_gradient(labels)

    enc_input = features
    dec_input = features
    enc_bias = labels
    enc_dec_bias = labels
    dec_bias = labels
    target = features

    enc_output = encode(enc_input, enc_bias)
    dec_output = decode(dec_input, enc_output, dec_bias, enc_dec_bias)

    net = dec_output

    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(
            labels=target,
            logits=net,
        )
    )
    train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
    global_step = tf.train.get_or_create_global_step()

    update_global_step = tf.assign(
        global_step, global_step + 1, name="update_global_step"
    )
    return tf.estimator.EstimatorSpec(
        mode, loss=loss, train_op=tf.group(train_step, update_global_step)
    )


def main(args):
    hlo = get_hlo(transformer_model_fn, transformer_input_fn)


if __name__ == "__main__":
    sys.exit(main(sys.argv))

&lt;/denchmark-code&gt;

Other info / logs
The issue can actually be avoided if the issue.py file is modified slightly:
change
&lt;denchmark-code&gt;HIDDEN_SIZE = 2048
FILTER_SIZE = 8196 
NUM_HEADS = 32
&lt;/denchmark-code&gt;

to
&lt;denchmark-code&gt;HIDDEN_SIZE = 2048 // 4
FILTER_SIZE = 8196 // 4
NUM_HEADS = 32 // 4
&lt;/denchmark-code&gt;

on lines 7-9
Note that this fix works on the Google cloud TPU, may not work on other machines?
The issue was also reproduced on multiple tf versions:
 tensorflow/tensorflow:1.13.0rc0-py3: Was able to reproduce the issue
 tensorflow/tensorflow:1.13.0rc1-py3: Was able to reproduce the issue
 tensorflow/tensorflow:1.13.0rc2-py3: Was able to reproduce the issue
 tensorflow/tensorflow:1.13.1-py3: Was able to reproduce the issue
 tensorflow/tensorflow:1.14.0-py3: Was able to reproduce the issue
 tensorflow/tensorflow:2.0.0a0-py3: No module named 'tensorflow.contrib' import error
All of these tf versions were run on vanilla tf docker images. The fix above where I divide the numbers by 4 also fixes the issue on all those versions as well.
tf version 2 and higher was not tested because of significant API changes, for this I need to spend some time creating a new python file with new API calls to get the issue reproduced
Images:
Issue reproduced using issue.py:
&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/61009735-92e4d380-a328-11e9-9701-aed9d921ecde.png&gt;&lt;/denchmark-link&gt;

Issue avoided by dividing variables by 4  (expected behavior):
&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/61009751-9f692c00-a328-11e9-9e2c-9c2417211360.png&gt;&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0710 15:25:47.346601 140584685344512 deprecation_wrapper.py:119] From issue.py:24: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.

W0710 15:25:47.347033 140584685344512 deprecation.py:323] From issue.py:25: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(dataset)`.
W0710 15:25:47.347194 140584685344512 deprecation.py:323] From issue.py:26: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(dataset)`.
W0710 15:25:47.356488 140584685344512 deprecation_wrapper.py:119] From issue.py:68: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0710 15:25:47.417571 140584685344512 deprecation_wrapper.py:119] From issue.py:85: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.

W0710 15:25:47.425961 140584685344512 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
W0710 15:25:48.473849 140584685344512 deprecation_wrapper.py:119] From issue.py:205: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.

W0710 15:25:49.911786 140584685344512 deprecation_wrapper.py:119] From issue.py:206: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0710 15:25:49.917340 140584685344512 deprecation_wrapper.py:119] From issue.py:208: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

W0710 15:25:49.928683 140584685344512 deprecation_wrapper.py:119] From issue.py:30: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2019-07-10 15:25:49.929245: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-10 15:25:49.939914: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2019-07-10 15:25:49.940074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563e2d4be50 executing computations on platform Host. Devices:
2019-07-10 15:25:49.940087: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;
W0710 15:25:49.940532 140584685344512 deprecation_wrapper.py:119] From issue.py:31: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

2019-07-10 15:25:50.432006: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
W0710 15:25:50.529966 140584685344512 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
W0710 15:25:50.530351 140584685344512 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
W0710 15:25:50.530480 140584685344512 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
2019-07-10 15:26:03.872235: W tensorflow/core/framework/allocator.cc:107] Allocation of 123777024 exceeds 10% of system memory.
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='elyasmehtabuddin' date='2019-07-11T11:28:27Z'>
		I tried on Colab with TPU and without TPU using tensorflow version 1.14. I am able to reproduce the issue. Thanks!
		</comment>
		<comment id='2' author='elyasmehtabuddin' date='2019-07-11T20:47:43Z'>
		This fails because the XLA cluster has a TemporaryVariable op which XLA does not support.  I'm not familiar enough with the TF APIs here to immediately point out where it is coming from, but I'd suggest changing your model to use resource variables to see if that fixes the issue.
		</comment>
		<comment id='3' author='elyasmehtabuddin' date='2019-07-12T14:26:35Z'>
		&lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;

I enabled resource variables by:

placing tf.enable_resource_variables() in the beginning of my transformer_model_fn
placing tf.enable_resource_variables() right before I compile the XLA
passing in use_resource=True for tf.get_variable

I still get the same issue. The TemporaryVariable I believe is a part of the gradient calculation for reduce_sum, I need reduce_sum for this model. What I find an issue here is that TemporaryVariable doesn't appear (the issue is avoided) if I reduce the HIDDEN_SIZE, FILTER_SIZE and NUM_HEADS by a factor of 4.
Code:
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

from tensorflow.contrib.compiler.xla import compile

HIDDEN_SIZE = 2048
FILTER_SIZE = 8196
NUM_HEADS = 32
D_K = HIDDEN_SIZE // NUM_HEADS
D_K_ROOT = D_K ** (-0.5)
WORD_LEN = 512 


def get_hlo(model_fn, input_fn):

    def xla_model_fn(features, labels):
        spec = model_fn(features, labels, mode="train", params=None)
        with tf.control_dependencies([spec.train_op]):
            return tf.identity(spec.loss, name=spec.loss.op.name)

    train_ds = input_fn().repeat()

    iterator = tf.data.Iterator.from_structure(
        train_ds.output_types,
        train_ds.output_shapes,
    )
    tf.enable_resource_variables()
    loss, = compile(xla_model_fn, inputs=iterator.get_next())
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(iterator.make_initializer(train_ds))
        sess.run(loss)


def transformer_input_fn():
    feat_shape = [1, WORD_LEN, HIDDEN_SIZE]
    labels_shape = [1, 1, 1, WORD_LEN]

    model_inputs = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(
                    np.random.uniform(size=feat_shape)
                ),
                feat_shape,
            ),
            tf.float32,
        ),
    ]

    model_expected = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(np.random.uniform(size=labels_shape)),
                labels_shape,
            ),
            tf.float32,
        ),
    ]

    dataset = (model_inputs, model_expected)
    dataset = tf.data.Dataset.from_tensor_slices(dataset)
    return dataset


def transformer_model_fn(features, labels, mode, params):
    tf.enable_resource_variables()
    layer_norm_scale = tf.get_variable(
        "layer_norm_scale",
        [HIDDEN_SIZE],
        initializer=tf.ones_initializer(),
        use_resource=True,
    )
    layer_norm_bias = tf.get_variable(
        "layer_norm_bias",
        [HIDDEN_SIZE],
        initializer=tf.zeros_initializer(),
        use_resource=True,
    )

    def layer_normalization(net):
        mean = tf.reduce_mean(net, axis=[-1], keepdims=True)
        mean = tf.multiply(mean, -1)
        diff = tf.add(net, mean)
        var = tf.reduce_mean(tf.square(diff), axis=[-1], keepdims=True)
        var = tf.add(var, 1e-6)
        net = tf.multiply(diff, tf.rsqrt(var))
        return tf.add(tf.multiply(net, layer_norm_scale), layer_norm_bias)

    def transformer_fc(net, size, use_bias=True):
        return tf.keras.layers.Dense(
            size,
            activation=None,
            use_bias=use_bias,
        )(net)

    def feed_forward(net):
        net = transformer_fc(net, FILTER_SIZE)
        net = tf.nn.relu(net)
        net = tf.nn.dropout(net, rate=0.1)
        net = transformer_fc(net, HIDDEN_SIZE)
        return net

    def multi_headed_attention(q, k, v, bias):
        def split_heads(net):
            net = tf.reshape(
                net,
                [1, WORD_LEN, NUM_HEADS, D_K],
            )
            net = tf.transpose(net, [0, 2, 1, 3])
            return net

        def combine_heads(net):
            net = tf.transpose(net, [0, 2, 1, 3])
            net = tf.reshape(
                net, [1, WORD_LEN, HIDDEN_SIZE]
            )
            return net

        q = transformer_fc(q, HIDDEN_SIZE, use_bias=False)
        k = transformer_fc(k, HIDDEN_SIZE, use_bias=False)
        v = transformer_fc(v, HIDDEN_SIZE, use_bias=False)

        q = split_heads(q)
        k = split_heads(k)
        v = split_heads(v)

        q = tf.multiply(q, D_K_ROOT)
        x = tf.matmul(q, k, transpose_b=True)
        x = tf.add(x, bias)

        x = tf.nn.softmax(x)
        x = tf.nn.dropout(x, rate=0.1)
        x = tf.matmul(x, v)

        x = combine_heads(x)
        x = transformer_fc(x, HIDDEN_SIZE, use_bias=False)
        return x

    def encoder_block(net, enc_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, enc_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def encode(enc_input, enc_bias):
        net = tf.nn.dropout(enc_input, rate=0.1)
        net = encoder_block(net, enc_bias) 
        return net

    def decoder_block(net, enc_output, dec_bias, enc_dec_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, enc_output, enc_output, enc_dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def decode(dec_input, enc_output, dec_bias, enc_dec_bias):
        net = tf.nn.dropout(dec_input, rate=0.1)
        net = decoder_block(net, enc_output, dec_bias, enc_dec_bias)
        return net

    labels = tf.stop_gradient(labels)

    enc_input = features
    dec_input = features
    enc_bias = labels
    enc_dec_bias = labels
    dec_bias = labels
    target = features

    enc_output = encode(enc_input, enc_bias)
    dec_output = decode(dec_input, enc_output, dec_bias, enc_dec_bias)

    net = dec_output

    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(
            labels=target,
            logits=net,
        )
    )
    train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
    global_step = tf.train.get_or_create_global_step()

    update_global_step = tf.assign(
        global_step, global_step + 1, name="update_global_step"
    )
    return tf.estimator.EstimatorSpec(
        mode, loss=loss, train_op=tf.group(train_step, update_global_step)
    )


def main(args):
    hlo = get_hlo(transformer_model_fn, transformer_input_fn)


if __name__ == "__main__":
    sys.exit(main(sys.argv))

&lt;/denchmark-code&gt;

		</comment>
		<comment id='4' author='elyasmehtabuddin' date='2019-07-19T06:35:27Z'>
		I have the same warnings so i want to know if you have solved the warnings in your outputs: (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
		</comment>
		<comment id='5' author='elyasmehtabuddin' date='2019-07-19T21:44:53Z'>
		&lt;denchmark-link:https://github.com/tangjie77wd&gt;@tangjie77wd&lt;/denchmark-link&gt;
 Not sure, I don't know how to solve that warning
		</comment>
		<comment id='6' author='elyasmehtabuddin' date='2019-07-19T22:51:56Z'>
		
@sanjoy
I enabled resource variables by:

placing tf.enable_resource_variables() in the beginning of my transformer_model_fn
placing tf.enable_resource_variables() right before I compile the XLA
passing in use_resource=True for tf.get_variable

I still get the same issue. The TemporaryVariable I believe is a part of the gradient calculation for reduce_sum, I need reduce_sum for this model. What I find an issue here is that TemporaryVariable doesn't appear (the issue is avoided) if I reduce the HIDDEN_SIZE, FILTER_SIZE and NUM_HEADS by a factor of 4.

I see.
Unfortunately I'm not familiar enough with the Python API side of things to help you here.  Maybe &lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 can help, or find someone else who can help?
		</comment>
		<comment id='7' author='elyasmehtabuddin' date='2019-07-22T08:41:10Z'>
		
@tangjie77wd Not sure, I don't know how to solve that warning

Thanks anyway.I am trying other solutions.
		</comment>
		<comment id='8' author='elyasmehtabuddin' date='2019-07-22T14:46:44Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

The fundamental issue here is that by changing the hidden size of the model we introduce a  into the model which in turn causes XLA to fail because XLA doesn't support this op. Having the same fundamental network and just changing the hidden size of a model shouldn't introduce different types of operations into the network, I would expect this  to be avoided at all costs to get the most XLA functionality.
This model is an incomplete Transformer model from the paper Attention Is All You Need, which is by no means a niche model.
		</comment>
		<comment id='9' author='elyasmehtabuddin' date='2019-07-22T15:47:06Z'>
		Maybe we should then extend the tf-xla bridge to support temporary variables with known shapes?
		</comment>
		<comment id='10' author='elyasmehtabuddin' date='2019-07-22T16:49:20Z'>
		That would also be a good solution
		</comment>
		<comment id='11' author='elyasmehtabuddin' date='2019-07-23T01:45:52Z'>
		No,i do not change the input size of the model since the size of my input image is the same with the requirement size of the model.
		</comment>
		<comment id='12' author='elyasmehtabuddin' date='2019-07-23T15:45:12Z'>
		
Maybe we should then extend the tf-xla bridge to support temporary variables with known shapes?

I'm reverse engineering from the kernel implementation but isn't TemporaryVariable a ref variable?  If yes, I don't think we can support it in the tf-xla bridge (without a lot of work!).
I think it is a ref variable because the kernel creates an instance of TmpVar and calls context-&gt;set_output_ref(0, &amp;tmp_var-&gt;mu, &amp;tmp_var-&gt;val);.
		</comment>
		<comment id='13' author='elyasmehtabuddin' date='2019-07-23T16:47:19Z'>
		It currently is a ref variable, but one could in principle make the same
API work with resource variables.

But now I'm confused: TemporaryVariable is not a public symbol in the TF
API; how did you come to have a graph with it? (and if you have a graph
which depends on non-public APIs I think you're on your own)
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Tue, Jul 23, 2019 at 8:53 AM Sanjoy Das ***@***.***&gt; wrote:
 Maybe we should then extend the tf-xla bridge to support temporary
 variables with known shapes?

 I'm reverse engineering from the kernel implementation but isn't
 TemporaryVariable a ref variable? If yes, I don't think we can support it
 in the tf-xla bridge (without a lot of work!).

 I think it is a ref variable because the kernel creates an instance of
 TmpVar and calls context-&gt;set_output_ref(0, &amp;tmp_var-&gt;mu, &amp;tmp_var-&gt;val);.

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#30580?email_source=notifications&amp;email_token=AAABHROH4RHGLTYD4X6WY7LQA4SPTA5CNFSM4H77IJK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2TRXGQ#issuecomment-514268058&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAABHROO5IECHNCURC3RDG3QA4SPTANCNFSM4H77IJKQ&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='14' author='elyasmehtabuddin' date='2019-07-25T20:55:30Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;

So it seems we can try supporting TemporaryVariableOp with known sizes on XLA, but if that is not possible for any reason, is it still possible to try and avoid using TemporaryVariableOp when possible (i.e. for this model I am using changing the hidden size introduces the op)?
		</comment>
		<comment id='15' author='elyasmehtabuddin' date='2019-07-25T21:28:51Z'>
		Can you provide a minimal example of a model which has temporary variable?
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Thu, Jul 25, 2019 at 2:03 PM Elyas Mehtabuddin ***@***.***&gt; wrote:
 @alextp &lt;https://github.com/alextp&gt; @sanjoy &lt;https://github.com/sanjoy&gt;

 So it seems we can try supporting TemporaryVariableOp with known sizes on
 XLA, but if that is not possible for any reason, is it still possible to
 try and avoid using TemporaryVariableOp when possible (i.e. for this model
 I am using changing the hidden size introduces the op)?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#30580?email_source=notifications&amp;email_token=AAABHRJ25NFADVTPL47JZOTQBIIKZA5CNFSM4H77IJK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD22X6WA#issuecomment-515211096&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAABHRKVF3VRABM6T2EPM2LQBIIKZANCNFSM4H77IJKQ&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='16' author='elyasmehtabuddin' date='2019-07-26T06:45:28Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

When I posted this issue I wanted it to be resolved as quickly as possible, I spent as much time on my end actually trying to make the smallest example to reproduce the issue. The original model I had was the full Transformer model, I was able to strip it down to what it is right now and still reproduce the issue. However, if I remove any part of the model now the issue completely goes away (which is really annoying). Like if I remove the layer normalization layer or if I completely remove the encoder or decoder the issue is gone. I actually had a lot of trouble even getting it to reproduce to the script I have above, the original model was many many more lines and files.
TLDR: The example above is actually the best minimal example I could come up with at the moment.
		</comment>
		<comment id='17' author='elyasmehtabuddin' date='2019-07-31T16:28:40Z'>
		Ok, looking at this more carefully it seems that the error is coming from the aggregation method accumulate_n in the optimizer.
So if you replace
&lt;denchmark-code&gt;    train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
&lt;/denchmark-code&gt;

with
&lt;denchmark-code&gt;    train_step = tf.train.GradientDescentOptimizer(0.0001, aggregation_method=tf.AggregationMethod.ADD_N).minimize(loss)
&lt;/denchmark-code&gt;

things should work.
What I don't understand is why TF seems to be defaulting to accumulate_n in your case.
		</comment>
		<comment id='18' author='elyasmehtabuddin' date='2019-07-31T20:46:17Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

Sounds like good news! However I wasn't able to fix it on the TPU machine I am working on. Its on tf 1.14.0.
&lt;denchmark-code&gt;
train_step = tf.train.GradientDescentOptimizer(0.0001, aggregation_method=tf.AggregationMethod.ADD_N).minimize(loss)

&lt;/denchmark-code&gt;

gives me an error:
&lt;denchmark-code&gt;Traceback (most recent call last):
  File "issue.py", line 220, in &lt;module&gt;
    hlo = get_hlo(transformer_model_fn, transformer_input_fn)
  File "issue.py", line 30, in get_hlo
    loss, = compile(xla_model_fn, inputs=iterator.get_next())
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/compiler/xla/xla.py", line 110, in compile
    return _compile_internal(computation, inputs)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/compiler/xla/xla.py", line 352, in _compile_internal
    outputs = computation(*computation_inputs)
  File "issue.py", line 18, in xla_model_fn
    spec = model_fn(features, labels, mode="train", params=None)
  File "issue.py", line 210, in transformer_model_fn
    train_step = tf.train.GradientDescentOptimizer(0.0001, aggregation_method=tf.AggregationMethod.ADD_N).minimize(loss)
TypeError: __init__() got an unexpected keyword argument 'aggregation_method'
&lt;/denchmark-code&gt;

It looks like aggregation_method is a parameter for minimize not the gradient descent constructor?
I changed it to:
&lt;denchmark-code&gt;
train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss, aggregation_method=tf.AggregationMethod.ADD_N)

&lt;/denchmark-code&gt;

Doing that gave me back my original issue I had.
Is aggregation_method a new parameter for the gradient descent optimizer constructor in a later tf 1.14 / 2 version? Maybe I am doing something obviously wrong here?
		</comment>
		<comment id='19' author='elyasmehtabuddin' date='2019-08-01T06:56:33Z'>
		
I have the same warnings so i want to know if you have solved the warnings in your outputs: (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set. If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU. To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.

Has already been solved!
		</comment>
		<comment id='20' author='elyasmehtabuddin' date='2019-08-01T15:13:08Z'>
		aggregation_method has been an argument to minimize since ~forever


I'm sorry, I don't understand what's your original issue here
&lt;denchmark-link:#&gt;…&lt;/denchmark-link&gt;


On Wed, Jul 31, 2019 at 1:53 PM Elyas Mehtabuddin ***@***.***&gt; wrote:
 @alextp &lt;https://github.com/alextp&gt;
 Sounds like good news! However I wasn't able to fix it on the TPU machine
 I am working on. Its on tf 1.14.0.

 train_step = tf.train.GradientDescentOptimizer(0.0001,
 aggregation_method=tf.AggregationMethod.ADD_N).minimize(loss)

 gives me an error:

 Traceback (most recent call last):
   File "issue.py", line 220, in &lt;module&gt;
     hlo = get_hlo(transformer_model_fn, transformer_input_fn)
   File "issue.py", line 30, in get_hlo
     loss, = compile(xla_model_fn, inputs=iterator.get_next())
   File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/compiler/xla/xla.py", line 110, in compile
     return _compile_internal(computation, inputs)
   File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/compiler/xla/xla.py", line 352, in _compile_internal
     outputs = computation(*computation_inputs)
   File "issue.py", line 18, in xla_model_fn
     spec = model_fn(features, labels, mode="train", params=None)
   File "issue.py", line 210, in transformer_model_fn
     train_step = tf.train.GradientDescentOptimizer(0.0001, aggregation_method=tf.AggregationMethod.ADD_N).minimize(loss)
 TypeError: __init__() got an unexpected keyword argument 'aggregation_method'

 It looks like aggregation_method is a parameter for minimize not the
 gradient descent constructor?

 I changed it to:
 train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss,
 aggregation_method=tf.AggregationMethod.ADD_N)

 Doing that gave me back my original issue I had.
 Is aggregation_method a new parameter for the gradient descent optimizer
 constructor in a later tf 1.14 / 2 version? Maybe I am doing something
 obviously wrong here?

 —
 You are receiving this because you were mentioned.
 Reply to this email directly, view it on GitHub
 &lt;#30580?email_source=notifications&amp;email_token=AAABHRPHN4F7IOTS2TEMCYTQCH3UVA5CNFSM4H77IJK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3IQG5A#issuecomment-517014388&gt;,
 or mute the thread
 &lt;https://github.com/notifications/unsubscribe-auth/AAABHRLZR7IG4CHJJ26PGN3QCH3UVANCNFSM4H77IJKQ&gt;
 .


-- 
 - Alex

		</comment>
		<comment id='21' author='elyasmehtabuddin' date='2019-08-01T18:18:57Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;

Sorry, what I meant to say was that adding  as a parameter to thee  function did NOT resolve my issue.
		</comment>
		<comment id='22' author='elyasmehtabuddin' date='2019-08-01T21:15:56Z'>
		&lt;denchmark-link:https://github.com/elyasmehtabuddin&gt;@elyasmehtabuddin&lt;/denchmark-link&gt;
 this is very weird because nothing in the TF public API should be using accumulate_n (and indeed when I ran your code I couldn't reproduce the error) but the error is coming from a call to accumulate_n.
Can you monkey-patch tf to suss out the problem? Something like
&lt;denchmark-code&gt;from tensorflow.python.ops import math_ops
math_ops.accumulate_n = lambda *a, **k: assert False
&lt;/denchmark-code&gt;

on the top of your file should give a stack trace of the code trying to use accumulate_n.
		</comment>
		<comment id='23' author='elyasmehtabuddin' date='2019-08-05T15:39:27Z'>
		
@elyasmehtabuddin this is very weird because nothing in the TF public API should be using accumulate_n (and indeed when I ran your code I couldn't reproduce the error) but the error is coming from a call to accumulate_n.
Can you monkey-patch tf to suss out the problem? Something like
from tensorflow.python.ops import math_ops
math_ops.accumulate_n = lambda *a, **k: assert False

on the top of your file should give a stack trace of the code trying to use accumulate_n.

I wasn't able to hit that assertion, my code to reproduce:
&lt;denchmark-code&gt;import tensorflow as tf
import numpy as np

from tensorflow.contrib.compiler.xla import compile
from tensorflow.python.compiler.xla import jit

from tensorflow.python.ops import math_ops
def fail_me(*a, **k):
    assert False
    return 0
math_ops.accumulate_n = fail_me


HIDDEN_SIZE = 2048
FILTER_SIZE = 8196
NUM_HEADS = 32
D_K = HIDDEN_SIZE // NUM_HEADS
D_K_ROOT = D_K ** (-0.5)
WORD_LEN = 512 


def get_hlo(model_fn, input_fn):

    def xla_model_fn(features, labels):
        spec = model_fn(features, labels, mode="train", params=None)
        with jit.experimental_jit_scope():
            with tf.control_dependencies([spec.train_op]):
                return tf.identity(spec.loss, name=spec.loss.op.name)

    train_ds = input_fn().repeat()

    iterator = tf.data.Iterator.from_structure(
        train_ds.output_types,
        train_ds.output_shapes,
    )
    tf.enable_resource_variables()
    loss, = compile(xla_model_fn, inputs=iterator.get_next())
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(iterator.make_initializer(train_ds))
        sess.run(loss)


def transformer_input_fn():
    feat_shape = [1, WORD_LEN, HIDDEN_SIZE]
    labels_shape = [1, 1, 1, WORD_LEN]

    model_inputs = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(
                    np.random.uniform(size=feat_shape)
                ),
                feat_shape,
            ),
            tf.float32,
        ),
    ]

    model_expected = [
        tf.image.convert_image_dtype(
            tf.reshape(
                tf.constant(np.random.uniform(size=labels_shape)),
                labels_shape,
            ),
            tf.float32,
        ),
    ]

    dataset = (model_inputs, model_expected)
    dataset = tf.data.Dataset.from_tensor_slices(dataset)
    return dataset


def transformer_model_fn(features, labels, mode, params):
    tf.enable_resource_variables()
    layer_norm_scale = tf.get_variable(
        "layer_norm_scale",
        [HIDDEN_SIZE],
        initializer=tf.ones_initializer(),
        use_resource=True,
    )
    layer_norm_bias = tf.get_variable(
        "layer_norm_bias",
        [HIDDEN_SIZE],
        initializer=tf.zeros_initializer(),
        use_resource=True,
    )

    def layer_normalization(net):
        mean = tf.reduce_mean(net, axis=[-1], keepdims=True)
        mean = tf.multiply(mean, -1)
        diff = tf.add(net, mean)
        var = tf.reduce_mean(tf.square(diff), axis=[-1], keepdims=True)
        var = tf.add(var, 1e-6)
        net = tf.multiply(diff, tf.rsqrt(var))
        return tf.add(tf.multiply(net, layer_norm_scale), layer_norm_bias)

    def transformer_fc(net, size, use_bias=True):
        return tf.keras.layers.Dense(
            size,
            activation=None,
            use_bias=use_bias,
        )(net)

    def feed_forward(net):
        net = transformer_fc(net, FILTER_SIZE)
        net = tf.nn.relu(net)
        net = tf.nn.dropout(net, rate=0.1)
        net = transformer_fc(net, HIDDEN_SIZE)
        return net

    def multi_headed_attention(q, k, v, bias):
        def split_heads(net):
            net = tf.reshape(
                net,
                [1, WORD_LEN, NUM_HEADS, D_K],
            )
            net = tf.transpose(net, [0, 2, 1, 3])
            return net

        def combine_heads(net):
            net = tf.transpose(net, [0, 2, 1, 3])
            net = tf.reshape(
                net, [1, WORD_LEN, HIDDEN_SIZE]
            )
            return net

        q = transformer_fc(q, HIDDEN_SIZE, use_bias=False)
        k = transformer_fc(k, HIDDEN_SIZE, use_bias=False)
        v = transformer_fc(v, HIDDEN_SIZE, use_bias=False)

        q = split_heads(q)
        k = split_heads(k)
        v = split_heads(v)

        q = tf.multiply(q, D_K_ROOT)
        x = tf.matmul(q, k, transpose_b=True)
        x = tf.add(x, bias)

        x = tf.nn.softmax(x)
        x = tf.nn.dropout(x, rate=0.1)
        x = tf.matmul(x, v)

        x = combine_heads(x)
        x = transformer_fc(x, HIDDEN_SIZE, use_bias=False)
        return x

    def encoder_block(net, enc_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, enc_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def encode(enc_input, enc_bias):
        net = tf.nn.dropout(enc_input, rate=0.1)
        net = encoder_block(net, enc_bias) 
        return net

    def decoder_block(net, enc_output, dec_bias, enc_dec_bias):
        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, residual, residual, dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = multi_headed_attention(
            residual, enc_output, enc_output, enc_dec_bias
        )
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        residual = layer_normalization(net)
        residual = feed_forward(residual)
        residual = tf.nn.dropout(residual, rate=0.1)
        net = tf.add(residual, net)

        return layer_normalization(net)

    def decode(dec_input, enc_output, dec_bias, enc_dec_bias):
        net = tf.nn.dropout(dec_input, rate=0.1)
        net = decoder_block(net, enc_output, dec_bias, enc_dec_bias)
        return net

    labels = tf.stop_gradient(labels)

    enc_input = features
    dec_input = features
    enc_bias = labels
    enc_dec_bias = labels
    dec_bias = labels
    target = features

    enc_output = encode(enc_input, enc_bias)
    dec_output = decode(dec_input, enc_output, dec_bias, enc_dec_bias)

    net = dec_output

    loss = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits_v2(
            labels=target,
            logits=net,
        )
    )
    # train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)
    train_step = tf.train.GradientDescentOptimizer(
        0.0001
    ).minimize(loss, aggregation_method=tf.AggregationMethod.ADD_N)
    global_step = tf.train.get_or_create_global_step()

    update_global_step = tf.assign(
        global_step, global_step + 1, name="update_global_step"
    )
    return tf.estimator.EstimatorSpec(
        mode, loss=loss, train_op=tf.group(train_step, update_global_step)
    )

hlo = get_hlo(transformer_model_fn, transformer_input_fn)
&lt;/denchmark-code&gt;

		</comment>
		<comment id='24' author='elyasmehtabuddin' date='2019-08-05T19:45:57Z'>
		&lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
 do you think a graph rewrite pass could be adding the temporary variable here before the tfxla bridge sees the code? I'm very confused.
&lt;denchmark-link:https://github.com/elyasmehtabuddin&gt;@elyasmehtabuddin&lt;/denchmark-link&gt;
 I'm specially confused because I run your code on colab and see no errors. Can you give me a colab to reproduce this on colab.research.google.com ?
		</comment>
		<comment id='25' author='elyasmehtabuddin' date='2019-08-05T20:42:26Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 Sure thing!
&lt;denchmark-link:https://colab.research.google.com/drive/1sy0E7UHTngQ-mivhiOMb0v9xFB7WvaFE&gt;https://colab.research.google.com/drive/1sy0E7UHTngQ-mivhiOMb0v9xFB7WvaFE&lt;/denchmark-link&gt;

&lt;denchmark-link:https://user-images.githubusercontent.com/44978436/62493786-d3e4d200-b786-11e9-94bf-85e642d62edf.png&gt;&lt;/denchmark-link&gt;

		</comment>
		<comment id='26' author='elyasmehtabuddin' date='2019-08-06T00:11:20Z'>
		
XLA encapsulates subgraph into a function
Grappler optimizes function library, and memory optimizer adds "tmp_var" node

Currently XLA-encapsulated functions are not marked with any attributes, and I guess there might be more potential problems in other optimizers. I think XLA should mark such functions with some attribute, so Grappler can skip them.
		</comment>
		<comment id='27' author='elyasmehtabuddin' date='2019-08-07T22:29:08Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 Hey it appears I screwed up the permissions with the link for the google collab, this one should work:
&lt;denchmark-link:https://colab.research.google.com/drive/1sy0E7UHTngQ-mivhiOMb0v9xFB7WvaFE&gt;https://colab.research.google.com/drive/1sy0E7UHTngQ-mivhiOMb0v9xFB7WvaFE&lt;/denchmark-link&gt;

		</comment>
		<comment id='28' author='elyasmehtabuddin' date='2019-08-08T16:03:35Z'>
		&lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
 I think this boils down to a problem in the interaction between the tf-xla bridge and grappler, then.
I think the workaround is to disable the grappler arithmetic optimizer here. &lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
 can you put instructions here?
		</comment>
		<comment id='29' author='elyasmehtabuddin' date='2019-08-19T18:14:12Z'>
		&lt;denchmark-link:https://github.com/alextp&gt;@alextp&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/sanjoy&gt;@sanjoy&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
 Any updates on this?
		</comment>
		<comment id='30' author='elyasmehtabuddin' date='2019-08-20T00:46:46Z'>
		I think this should be fixed, but I'm not sure if it will be available in any of the v1 releases.
		</comment>
		<comment id='31' author='elyasmehtabuddin' date='2019-08-20T16:57:26Z'>
		&lt;denchmark-link:https://github.com/ezhulenev&gt;@ezhulenev&lt;/denchmark-link&gt;
 Thank you for pushing the commit, will test and see how it goes!
		</comment>
		<comment id='32' author='elyasmehtabuddin' date='2019-09-04T19:20:45Z'>
		Sorry guys I was on vacation.
I compiled tf 1.13 from scratch and installed the whl, the issue was there.
I then cherry-picked commit 471b73c238709fb796929eb412f1dab763b3f8cc and added those changes manually to a new branch I created based off of 1.13.
Then I compiled this custom whl and installed it, the issue went away.
Issue is resolved! Thanks!!!
		</comment>
		<comment id='33' author='elyasmehtabuddin' date='2019-09-04T19:20:47Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=30580&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=30580&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>