<bug id='29571' author='sbsky' open_date='2019-06-09T12:50:44Z' closed_time='2019-08-02T07:38:40Z'>
	<summary>tflite: Slicing isn't compatible with quantisation</summary>
	<description>
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): v1.12.1-3185-g1a4a0aee1f 1.13.1
Python version: 3.6.7
CUDA/cuDNN version: -
GPU model and memory: -

I'm trying to implement shufflenet v2 in Tensorflow 2.0 with tflite, which requires slicing.  This works fine with float precision, however when I turn on quantization I get an error.
&lt;denchmark-code&gt;import numpy as np
import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION)

channels = 64
# Slicing &amp; quantization together results in an error
use_slice = True
quantize = True

input = tf.keras.layers.Input(shape=(channels))
x = input
x *= x
if use_slice:
    x = x[:, ::2]

model = tf.keras.Model(inputs=[input], outputs=[x])
model.summary()


def _gen_input(channels):
    return tf.constant(np.random.uniform(0, 1, size=(1, channels,)), dtype=tf.float32)

# Test normal tensorflow forward pass
model(_gen_input(channels))

converter = tf.lite.TFLiteConverter.from_keras_model(model)
if quantize:
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

def representative_data_gen():
    for _ in range(100):
        yield [_gen_input(channels)]

converter.representative_dataset = representative_data_gen
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.set_tensor(input_details[0]['index'], _gen_input(channels))
interpreter.invoke()
tflite_results = interpreter.get_tensor(output_details[0]['index'])
&lt;/denchmark-code&gt;

If I turn off either 'use_slice' or 'quantise', it works fine - however with both on I get the following error:
RuntimeError: tensorflow/lite/kernels/dequantize.cc:67 op_context.input-&gt;type == kTfLiteUInt8 || op_context.input-&gt;type == kTfLiteInt8 || op_context.input-&gt;type == kTfLiteFloat16 was not true.Node number 3 (DEQUANTIZE) failed to prepare.
	</description>
	<comments>
		<comment id='1' author='sbsky' date='2019-06-26T08:35:46Z'>
		Any updates on this?  Please let me know if there's any more debug info required.
		</comment>
		<comment id='2' author='sbsky' date='2019-08-02T07:38:40Z'>
		This looks to have been fixed - just gave this a retest with the latest tf 2.0 nightly
		</comment>
		<comment id='3' author='sbsky' date='2019-08-02T07:38:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=29571&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=29571&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>