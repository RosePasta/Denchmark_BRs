<bug id='42043' author='Shiro-LK' open_date='2020-08-04T20:23:57Z' closed_time='2020-08-25T08:25:40Z'>
	<summary>"logs" Callback bugs with TF 2.3 on colab with TPU</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
TensorFlow version (use command below): 2.3
Python version:
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:TPU
GPU model and memory:

I got some weird issue, it seems that when using a custom callback for computing a metric, and then save it in the logs,
the ModelCheckpoint function does not see the metrics saved in logs, so it does not save the model at the end of an epoch. I have seen this issue today. It worked well few days ago, so it seems to be related to TF 2.3. I also see some issue about the memory, I have to lower the batch size to make the training work.
WARNING:tensorflow:Can save best model only with roc_val available, skipping.
WARNING:tensorflow:Callbacks method on_train_batch_endis slow compared to the batch time (batch time: 0.0288s vson_train_batch_end time: 0.9656s). Check your callbacks.
&lt;denchmark-code&gt;class RocCallback(Callback):
    def __init__(self , dataset_val):
        self.x = dataset_val
        self.y =  np.concatenate([np.array(x[1]) for x in list(dataset_val)]).reshape(-1)
    def on_train_begin(self, logs={}):
        return

    def on_train_end(self, logs={}):
        return

    def on_epoch_begin(self, epoch, logs={}):
        return

    def on_epoch_end(self, epoch, logs={}):
        pred = model.predict(self.x)
        roc_val = roc_auc_score(self.y, pred)
        logs["roc_val"] = roc_val
        print('\n - %s average: %s' % ('roc_val', str(round(roc_val,4))),end=100*' '+'\n')
        return

    def on_batch_begin(self, batch, logs={}):
        return

    def on_batch_end(self, batch, logs={}):
        return
&lt;/denchmark-code&gt;

&lt;denchmark-code&gt;tf.keras.callbacks.ModelCheckpoint("model.h5", monitor='roc_val', verbose=0, save_best_only=True,
        save_weights_only=True, mode='max', save_freq='epoch')
&lt;/denchmark-code&gt;

Is there a way to choose the version of TF (2.2) on colab  ?
	</description>
	<comments>
		<comment id='1' author='Shiro-LK' date='2020-08-05T00:27:57Z'>
		&lt;denchmark-link:https://github.com/Shiro-LK&gt;@Shiro-LK&lt;/denchmark-link&gt;
 see &lt;denchmark-link:https://github.com/googlecolab/colabtools/issues/1470&gt;googlecolab/colabtools#1470&lt;/denchmark-link&gt;
 for switching the TF+TPU version in colab.
		</comment>
		<comment id='2' author='Shiro-LK' date='2020-08-12T15:21:08Z'>
		This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.
		</comment>
		<comment id='3' author='Shiro-LK' date='2020-08-13T11:50:03Z'>
		&lt;denchmark-link:https://github.com/craigcitro&gt;@craigcitro&lt;/denchmark-link&gt;
 the fix you mentioned is not working for me. If I downgrade tensorflow I get the following error:

Do you have any ideas how can I overcome this? Thanks
		</comment>
		<comment id='4' author='Shiro-LK' date='2020-08-13T16:15:50Z'>
		I don't have any real expertise on the TF side (so hoping someone else jumps in).
		</comment>
		<comment id='5' author='Shiro-LK' date='2020-08-13T16:46:52Z'>
		I had a similar error. It is important to follow this &lt;denchmark-link:https://colab.research.google.com/gist/graf10a/642c143fd80887ac8a69819250f5141b/tf_tpu_issue_submission_fixed.ipynb&gt;https://colab.research.google.com/gist/graf10a/642c143fd80887ac8a69819250f5141b/tf_tpu_issue_submission_fixed.ipynb&lt;/denchmark-link&gt;
 exactly (the first and the second cells). Not just downgrade. There should be two separate cells, import requests etc.
		</comment>
		<comment id='6' author='Shiro-LK' date='2020-08-13T16:56:43Z'>
		This might be because of a change in how model loading and saving is handled on TPU. Can you try to add the following option to your checkpoint call:
&lt;denchmark-code&gt;# TPUs need this extra setting to save to local disk, otherwise, they can only save models to GCS (Google Cloud Storage).
# The setting instructs Tensorflow to retrieve all parameters from the TPU then do the saving from the local VM, not the TPU.
save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')
tf.keras.callbacks.ModelCheckpoint("saved_model", monitor='roc_val', verbose=0, save_best_only=True,
        save_weights_only=True, mode='max', save_freq='epoch', options=save_locally)
&lt;/denchmark-code&gt;

Please notice in the code that I also recommend to change the type of the saved model from .h5 (the legacy Keras format) to "Tensorflow saved model", the standard tensorflow format. The format is determined based on the extension. Saving from TPU to local disk now works in TF saved model format, with the /job:localhost save option. This is new in TF 2.3. Previously, saving locally from TPU only worked in the .h5 format. This is not supposed to have changed but as your bug report points out, it looks like it has.
		</comment>
		<comment id='7' author='Shiro-LK' date='2020-08-13T17:49:46Z'>
		&lt;denchmark-link:https://github.com/Shiro-LK&gt;@Shiro-LK&lt;/denchmark-link&gt;
, the behavior change may be a result of a recent code change. Can you try setting  to True on the custom callback's attr before  and see if it then allows you to pass around information in ?
		</comment>
		<comment id='8' author='Shiro-LK' date='2020-08-25T08:25:39Z'>
		Closing as stale. Please reopen if you'd like to work on this further.
		</comment>
		<comment id='9' author='Shiro-LK' date='2020-08-25T08:25:41Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42043&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42043&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>