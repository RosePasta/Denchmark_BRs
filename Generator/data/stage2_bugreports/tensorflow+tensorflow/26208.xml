<bug id='26208' author='ghost(ghost)' open_date='2019-02-28T13:17:32Z' closed_time='2019-04-05T19:58:38Z'>
	<summary>TensorFlow device GPU:0 was not registered</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code: Yes
OS Platform and Distribution: Red Hat Enterprise Linux Server release 7.4
TensorFlow installed from (source or binary): source
TensorFlow version: 1.10.0
Python version: 3.6.6
CUDA/cuDNN version: V9.2.88
GPU model and memory: Intel(R) Xeon(R) CPU E5-2690 0 @ 2.90GHz

Describe the current behavior
Currently I am using distributed Tensorflow to connect two machines one with only a CPU(ps) and one with a CPU and GPU(worker), the worker machine runs only the cluster and server commands followed by a join command and then remains idle,
the training algorithm is run on the ps machine after defining the cluster and the server and then the training is run but I get "E tensorflow/core/grappler/clusters/utils.cc:128] Not found: TensorFlow device GPU:0 was not registered" between each epoch of training and it is not run on the gpu (the delay is very big)
Describe the expected behavior
the training should be able to run on the GPU of the worker machine
Code to reproduce the issue
Code run on the worker machine :
import tensorflow as tf
cluster = tf.train.ClusterSpec({
"worker": [
"172.24.145.121:2222",
],
"ps": [
"172.24.145.14:2222"
]})
server = tf.train.Server(cluster, job_name="worker", task_index=0)
server.join()
and on the ps machine:
import tensorflow as tf
import time
from tensorflow.examples.tutorials.mnist import input_data
cluster = tf.train.ClusterSpec({
"worker": [
"172.24.145.121:2222",
],
"ps": [
"172.24.145.14:2222"
]})
server = tf.train.Server(cluster, job_name="ps", task_index=0)
tf.logging.set_verbosity(tf.logging.ERROR)
mnist = input_data.read_data_sets("/tmp/data",one_hot=True)
n_nodes_hl1=500
n_nodes_hl2=500
n_nodes_hl3=500
n_classes = 10
batch_size = 100
x = tf.placeholder('float',[None, 784],name="x")
y = tf.placeholder('float',name="y_pred")
def neural_network_model(data):
with tf.device("/job:worker/task:0/gpu:0"):
hidden_1_layer= {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1]),name="layer1_w"),
'biases':tf.Variable(tf.random_normal([n_nodes_hl1]),name="layer1_b")}
&lt;denchmark-code&gt;	hidden_2_layer= {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2]),name="layer2_w"),
            	    'biases':tf.Variable(tf.random_normal([n_nodes_hl2]),name="layer2_b")}

	hidden_3_layer= {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3]),name="layer3_w"),
        	        'biases':tf.Variable(tf.random_normal([n_nodes_hl3]),name="layer3_b")}

	output_layer= {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes]),name="output_w"),
    	            'biases':tf.Variable(tf.random_normal([n_classes]),name="output_b")}

l1= tf.add(tf.matmul(data,hidden_1_layer['weights']),hidden_1_layer['biases'],name="l1")
l1= tf.nn.relu(l1)

l2= tf.add(tf.matmul(l1,hidden_2_layer['weights']),hidden_2_layer['biases'],name="l2")
l2= tf.nn.relu(l2)

l3= tf.add(tf.matmul(l2,hidden_3_layer['weights']),hidden_3_layer['biases'],name="l3")
l3= tf.nn.relu(l3)

output= tf.add(tf.matmul(l3,output_layer['weights']),output_layer['biases'],name="output")

return output
&lt;/denchmark-code&gt;

def train_neural_network(x):
prediction=neural_network_model(x)
cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y))
&lt;denchmark-code&gt;optimizer = tf.train.AdamOptimizer().minimize(cost)

hm_epoch = 10
&lt;/denchmark-code&gt;

with tf.Session(server.target) as sess:
sess.run(tf.global_variables_initializer())
for epoch in range(hm_epoch):
epoch_loss =0
start_time = time.time()
for _ in range(int(mnist.train.num_examples/batch_size)): #(X_train.size/(28*28))
epoch_x,epoch_y=mnist.train.next_batch(batch_size)
_,c = sess.run([optimizer, cost], feed_dict = {x:epoch_x, y:epoch_y})
epoch_loss += c
duration = time.time()-start_time
print('Epoch', epoch+1,'completed out of ',hm_epoch,'loss: ',epoch_loss)
correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct,'float'))
print('Accuracy:' ,accuracy.eval({x:mnist.test.images,y:mnist.test.labels}),' Duration: ' ,duration)
train_neural_network(x)
Other info / logs
E tensorflow/core/grappler/clusters/utils.cc:128] Not found: TensorFlow device GPU:0 was not registered
	</description>
	<comments>
		<comment id='1' author='ghost(ghost)' date='2019-02-28T20:24:52Z'>
		Can you run the following to check whether TensorFlow is actually seeing your GPUs? If not, you might want to try reinstalling CUDA/CuDNN and TensorFlow (make sure you are using the GPU binaries for TF).
Alternatively, you might also want to try our docker images with a bunch of those built-in: &lt;denchmark-link:https://www.tensorflow.org/install/docker&gt;https://www.tensorflow.org/install/docker&lt;/denchmark-link&gt;

&lt;denchmark-code&gt;import tensorflow as tf
s = tf.Session()
print(s.list_devices())
&lt;/denchmark-code&gt;

		</comment>
		<comment id='2' author='ghost(ghost)' date='2019-03-01T11:16:05Z'>
		TensorFlow sees the GPU if I run the master session from the node that has the GPU, but if I start the master session is from the node that only has cpu I get the TensorFlow device GPU:0 was not registered, even though I can run variables on the cpu of the other node that has both the GPU and CPU
		</comment>
		<comment id='3' author='ghost(ghost)' date='2019-03-01T18:00:24Z'>
		So if you do something like
&lt;denchmark-code&gt;import tensorflow as tf
s = tf.Session(master="grpc://remote.server.ip.address:port")
print(s.list_devices())
&lt;/denchmark-code&gt;

you won't see GPU, but if you run that snippet locally you will? I wonder if the local version you run with Python is different somehow than the remote server you start?
		</comment>
		<comment id='4' author='ghost(ghost)' date='2019-03-02T11:49:58Z'>
		Well, When I ran this snippet it import tensorflow as tf s = tf.Session(master="grpc://remote.server.ip.address:port") print(s.list_devices()) it shows all the devices correctly and after a bit of testing there is indeed improved performance which shows that the GPU of the remote server is being used, but

E tensorflow/core/grappler/clusters/utils.cc:128] Not found: TensorFlow device GPU:0 was not registered



Keeps showing up between each of the epoch's in training when the the master session is initiated on the node with only the cpu.  I don't get this error when I initiate the master session and run the training on the node that contains the gpu and cpu, and use the other cpu node remotely.
		</comment>
		<comment id='5' author='ghost(ghost)' date='2019-03-04T18:25:15Z'>
		Can you show what s.list_devices() returns?
Also, in your original script, you are assigning ops to , however the &lt;denchmark-link:https://www.tensorflow.org/guide/using_gpu#using_multiple_gpus&gt;canonical TensorFlow device names&lt;/denchmark-link&gt;
 for GPUs are in the format , so that might be an issue as well.
		</comment>
		<comment id='6' author='ghost(ghost)' date='2019-03-04T21:37:28Z'>
		ok after changing from /job:worker/task:0/gpu:0 to /job:worker/task:0/device:GPU:0 there was no difference i still get the

E tensorflow/core/grappler/clusters/utils.cc:128] Not found: TensorFlow device GPU:0 was not registered



and s.list_devices() returns W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created. [_DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 268435456), _DeviceAttributes(/job:worker/replica:0/task:0/device:GPU:0, GPU, 11281927373), _DeviceAttributes(/job:ps/replica:0/task:0/device:CPU:0, CPU, 268435456)]
The same devices are there if i run the session from locally or remotely the only difference is if I run it remotely i dont get the

E tensorflow/core/grappler/clusters/utils.cc:128] Not found: TensorFlow device GPU:0 was not registered

		</comment>
		<comment id='7' author='ghost(ghost)' date='2019-03-04T22:03:10Z'>
		
The same devices are there if i run the session from locally or remotely the only difference is if I run it remotely i dont get the

Do you mean if you run it locally on the machine with the GPU you don't get the error?
Can you also try passing in a cluster_def when you create the session?
&lt;denchmark-code&gt;cluster_spec = tf.train.ClusterSpec( ... )
cluster_def = cluster_spec.as_cluster_def()
with tf.Session(target=master, config=tf.ConfigProto(cluster_def=cluster_def, log_device_placement=True)):
  ...
&lt;/denchmark-code&gt;

		</comment>
		<comment id='8' author='ghost(ghost)' date='2019-03-04T22:23:26Z'>
		Yes, if I run it locally on the machine with the GPU I don't get the error, also if I run the session remotely on the machine with the GPU using the CPU machine I don't get the error (using the  tf.Session("grpc://remote.server.ip.address:port") ), but if I start the session on the machine with only the CPU I get the error.
		</comment>
		<comment id='9' author='ghost(ghost)' date='2019-03-05T02:07:40Z'>
		when i try to pass the cluster_def when I create the session I get this error
tensorflow.python.framework.errors_impl.InvalidArgumentError: The ClusterSpec names the job and task index to be the same names that were provided when the server booted. This is currently not allowed. Job: ps, task index: 0
		</comment>
		<comment id='10' author='ghost(ghost)' date='2019-03-09T02:19:13Z'>
		Can you create both tf.train.Servers without passing in the ClusterSpec? ClusterSpec propagation only works when there are no conflicting types.
		</comment>
		<comment id='11' author='ghost(ghost)' date='2019-03-15T12:09:09Z'>
		Yes
		</comment>
		<comment id='12' author='ghost(ghost)' date='2019-03-15T19:53:01Z'>
		So does it work without the ClusterSpec?
		</comment>
		<comment id='13' author='ghost(ghost)' date='2019-04-05T19:58:38Z'>
		Closing issue for now, feel free to re-open if this continues to be an issue.
		</comment>
		<comment id='14' author='ghost(ghost)' date='2019-04-05T19:58:39Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=26208&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=26208&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='15' author='ghost(ghost)' date='2019-07-23T13:58:37Z'>
		&lt;denchmark-link:https://github.com/frankchn&gt;@frankchn&lt;/denchmark-link&gt;
 Hi, do you mean the clusterspec for the server.start() and server.join() are different thats why it raises "Not found: TF GPU device with id 0 was not registered." ? because i got the same issue as well but i thought tf.train.Server must take clusterspec as argument.
since i am using estimator, i am not sure how to do the cluster_def tho
		</comment>
		<comment id='16' author='ghost(ghost)' date='2019-07-23T17:31:03Z'>
		&lt;denchmark-link:https://github.com/colmantse&gt;@colmantse&lt;/denchmark-link&gt;
 Can you open another issue with more complete details? That error happens when TensorFlow cannot detect GPUs in your system.
		</comment>
		<comment id='17' author='ghost(ghost)' date='2019-07-23T17:41:32Z'>
		hi, thanks for the prompt reply. I suspect it has to do with me passing the wrong configproto when starting the server. i will come back tmr if it is not the case. many thanks!
		</comment>
	</comments>
</bug>