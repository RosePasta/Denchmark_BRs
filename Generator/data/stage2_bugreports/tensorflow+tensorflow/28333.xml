<bug id='28333' author='KUASWoodyLIN' open_date='2019-05-02T07:40:34Z' closed_time='2019-05-15T23:11:11Z'>
	<summary>Distributed Training TF2.0 validation_data Bug</summary>
	<description>
System information

OS Platform and Distribution: Docker-nvidia(2.0.0a0-gpu-py3)
TensorFlow version: '2.0.0-alpha0'
Python version: 3.5.2
CUDA/cuDNN version: 10.0

Hello I'm trying the &lt;denchmark-link:https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/distribute/keras.ipynb&gt;Code&lt;/denchmark-link&gt;
 here,
and change the training code.
&lt;denchmark-code&gt;history = model_1.fit(train_data,
                      epochs=200, 
                      validation_data=valid_data,
                      callbacks=[model_cbk, model_esp])
&lt;/denchmark-code&gt;

And it come out the error, I think it should be validation_data bug:
&lt;denchmark-code&gt;WARNING: Logging before flag parsing goes to stderr.
W0502 06:49:43.398314 140660990936832 distributed_training_utils.py:182] Your input callback is not one of the predefined Callbacks that supports DistributionStrategy. You might encounter an error if you access one of the model's attributes as part of the callback since these attributes are not set. You can access each of the individual distributed models using the `_grouped_model` attribute of your original model.
W0502 06:49:43.399307 140660990936832 distributed_training_utils.py:182] Your input callback is not one of the predefined Callbacks that supports DistributionStrategy. You might encounter an error if you access one of the model's attributes as part of the callback since these attributes are not set. You can access each of the individual distributed models using the `_grouped_model` attribute of your original model.
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-16-74ec5f39e862&gt; in &lt;module&gt;
      2                       epochs=200,
      3                       validation_data=valid_data,
----&gt; 4                       callbacks=[model_cbk, model_esp])

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    744             steps_per_epoch=steps_per_epoch,
    745             validation_steps=validation_steps,
--&gt; 746             validation_freq=validation_freq)
    747 
    748     batch_size = self._validate_or_infer_batch_size(

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_distributed.py in fit_distributed(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)
    129         validation_steps=validation_steps,
    130         validation_freq=validation_freq,
--&gt; 131         steps_name='steps_per_epoch')
    132 
    133 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)
    139 
    140   if mode == ModeKeys.TRAIN:
--&gt; 141     _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)
    142 
    143   # Enter DistributionStrategy scope.

/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py in _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)
    437 def _print_train_info(inputs, val_inputs, steps_per_epoch, verbose):
    438   if (val_inputs and steps_per_epoch is None and verbose and inputs and
--&gt; 439       hasattr(inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):
    440     print('Train on %d samples, validate on %d samples' %
    441           (inputs[0].shape[0], val_inputs[0].shape[0]))

TypeError: 'BatchDataset' object does not support indexing
&lt;/denchmark-code&gt;

	</description>
	<comments>
		<comment id='1' author='KUASWoodyLIN' date='2019-05-03T10:32:58Z'>
		&lt;denchmark-link:https://github.com/KUASWoodyLIN&gt;@KUASWoodyLIN&lt;/denchmark-link&gt;
 In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!
		</comment>
		<comment id='2' author='KUASWoodyLIN' date='2019-05-04T16:10:56Z'>
		&lt;denchmark-link:https://github.com/gadagashwini&gt;@gadagashwini&lt;/denchmark-link&gt;
 Here is &lt;denchmark-link:https://colab.research.google.com/gist/KUASWoodyLIN/5567f55bc205f04998db8f9f7a425c34/-keras-ipynb.ipynb&gt;Code &lt;/denchmark-link&gt;
on google colab that I have modified.
		</comment>
		<comment id='3' author='KUASWoodyLIN' date='2019-05-14T21:53:45Z'>
		The   argument in  in your case is a  which is not among the accepted data structures.
You may want to convert it in one of the accepted types; tuple (x_val, y_val) of Numpy arrays, dataset iterator etc
&lt;denchmark-link:https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit&gt;https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit&lt;/denchmark-link&gt;

		</comment>
		<comment id='4' author='KUASWoodyLIN' date='2019-05-15T23:11:12Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=28333&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=28333&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>