<bug id='25614' author='ved27' open_date='2019-02-08T09:54:22Z' closed_time='2019-04-20T04:26:19Z'>
	<summary>Segmentation fault - Convolution in tflite</summary>
	<description>
Please make sure that this is a bug. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution : Linux Ubuntu 16.04
TensorFlow installed from github:
TensorFlow version tf 1.13:
Python version: 3.6
Bazel version (if compiling from source): 0.21.0
GCC/Compiler version (if compiling from source): 5.4.0 20160609
CUDA : 9.0
RAM : 32GB

Hi,
I encountered a segmentation fault in the Im2Col of Convolution while running a tflite model.
I observed that when the Im2Col buffer size &gt;  2GB, this crash occurs.
For example :
input : 1x828x1000x32 ; output: 1x828x1000x3  ;kernel: 9x9  does not crash
but for
input:1x832x100x32 ; output: 1x832x1000x3; kernel 9x9  convolution crashes.
I want to know if there is any memory limit for convolution in tflite to run ?
I kindly request you to let me know this. sooner the better
Awaiting you reply,
Vedavyas.
	</description>
	<comments>
		<comment id='1' author='ved27' date='2019-02-08T17:24:06Z'>
		&lt;denchmark-link:https://github.com/ved27&gt;@ved27&lt;/denchmark-link&gt;
 Could you share some reproducible code and also please mention what is your OS. Please provide as many details as possible to resolve this faster. Thanks!
		</comment>
		<comment id='2' author='ved27' date='2019-02-08T18:05:20Z'>
		Hi ,
I'm unable to share the exact code. However, I am able to reproduce the issue setting the above input shapes and kernel sizes in the testing code of quantized convolution in tflite.
Awaiting your reply,
		</comment>
		<comment id='3' author='ved27' date='2019-02-11T17:08:59Z'>
		Hi,
I kindly request you to look into this soon, as it would be helpful for me to rule out the models which seem to take high memory while executing tflite interpreter.
Awaiting your reply,
		</comment>
		<comment id='4' author='ved27' date='2019-02-18T05:50:20Z'>
		Hi,
I kindly request you to address this issue. It has almost been 9 days.
Thankful if someone can give me a confirmation on the memory limitation of tflite
Regards,
		</comment>
		<comment id='5' author='ved27' date='2019-04-19T08:12:41Z'>
		&lt;denchmark-link:https://github.com/ved27&gt;@ved27&lt;/denchmark-link&gt;
 : Did you encounter this issue while running some model? If yes, would you be able to share the model? (Just for my reference).
Any way i have found the root-cause for your issue.
&lt;denchmark-h:h3&gt;NOTE: As of now TFLite does not have any memory limit for convolution.&lt;/denchmark-h&gt;

I have verified with 3GB memory allocation, there is no issue.
But in your case, the root-cause is classic "Integer overflow".
Currently GEMM supports limited by (row * col &lt; 2^31).
As in your case it has exceeded the limit, it is leading to memory corruption.
Currently i am working on a solution for this, will keep you updated if anything come up.
Would suggest to use models which has lower memory requirement(lower than 2^31) for Convolution currently.
If my post helped you, would appreciate if you close this issue.
Please feel free to post if anything from your end, Thanks.
		</comment>
		<comment id='6' author='ved27' date='2019-04-20T04:24:16Z'>
		Yeah. I debugged and found the root cause earlier.
There has been inconsistency between the datatype usage in various parts of tflite . (int / size_t / unsigned int ).
And ultimately the GEMM's limitation , causing the crash to occur.
I wished a better implementation of convolution in tflite. Implementations other than Im2Col, such as Kn2row can be deployed .
Thank you much for the reply
		</comment>
		<comment id='7' author='ved27' date='2019-04-20T04:26:20Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=25614&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=25614&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>