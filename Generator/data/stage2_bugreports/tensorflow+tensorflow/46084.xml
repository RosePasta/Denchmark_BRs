<bug id='46084' author='ek9852' open_date='2020-12-31T04:04:00Z' closed_time='2020-12-31T19:31:47Z'>
	<summary>u-net always not able to run in a single delegate</summary>
	<description>
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No, just use  prebuilt  android_aarch64_benchmark_model
OS Platform and Distribution:
ested on Android
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Qualcomm dragon 855
TensorFlow installed from (source or binary):
google tensorflow prebuilt android_aarch64_benchmark_model

Describe the current behavior
I tried many u-net model for semantic segmentation, none of those can be run on nnapi delegate fully. and most likely the transpose conv will be fallback on CPU. Though the underlying nnapi accel supports transport conv.
Describe the expected behavior
It should run the model fully on one single delegate without fallback to CPU which extremely slow. Or have some kinds of indication  why t is not  running fully in nnapi delegate and fallback to CPU. The TRANSPOSE_CONV and CONV2D are clearly supported by the underly nnapi acceleration. But it just fallback to CPU for unknown reason.

Download android_aarch64_benchmark_model from &lt;denchmark-link:https://www.tensorflow.org/lite/performance/measurement&gt;https://www.tensorflow.org/lite/performance/measurement&lt;/denchmark-link&gt;

adb push that into /data/local/tmp/
created one using unet with post quant.
Run
/android_aarch64_benchmark_model  --graph=model.tflite  --use_nnapi=true  --nnapi_accelerator_name=qti-gpu --enable_op_profiling=true
Expected:
Explicitly applied NNAPI delegate, and the model graph will be completely executed by the delegate.
Current:
Explicitly applied NNAPI delegate, and the model graph will be partially executed by the delegate w/ 4 delegate kernels.
Other info / logs Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
STARTING!
Log parameter values verbosely: [0]
Graph: [model.tflite]
Enable op profiling: [1]
Use NNAPI: [1]
NNAPI accelerator name: [qti-gpu]
NNAPI accelerators available: [qti-default,qti-dsp,qti-gpu,qti-hta,nnapi-reference]
Loaded model model.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for NNAPI.
Explicitly applied NNAPI delegate, and the model graph will be partially executed by the delegate w/ 4 delegate kernels.
The input model file size (MB): 0.398212
Initialized session in 185.23ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=10 first=72646 curr=55109 min=43832 max=72646 avg=50987.8 std=7966
Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=50 first=57407 curr=57830 min=39546 max=63652 avg=54400.3 std=5091
Inference timings in us: Init: 185230, First inference: 72646, Warmup (avg): 50987.8, Inference (avg): 54400.3
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=3.77344 overall=14.918
Profiling Info for Benchmark Initialization:
============================== Run Order ==============================
[node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
ModifyGraphWithDelegate	            0.000	  184.511	  184.511	 50.938%	 50.938%	  3864.000	        1	ModifyGraphWithDelegate/0
AllocateTensors	           95.737	  177.694	   88.858	 49.062%	100.000%	     0.000	        2	AllocateTensors/0
============================== Top by Computation Time ==============================
[node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
ModifyGraphWithDelegate	            0.000	  184.511	  184.511	 50.938%	 50.938%	  3864.000	        1	ModifyGraphWithDelegate/0
AllocateTensors	           95.737	  177.694	   88.858	 49.062%	100.000%	     0.000	        2	AllocateTensors/0
Number of nodes executed: 2
============================== Summary by node type ==============================
[Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
ModifyGraphWithDelegate	        1	   184.511	    50.938%	    50.938%	  3864.000	        1
AllocateTensors	        1	   177.715	    49.062%	   100.000%	     0.000	        2
Timings (microseconds): count=1 curr=362226
Memory (bytes): count=0
2 nodes observed
Operator-wise Profiling Info for Regular Benchmark Runs:
============================== Run Order ==============================
[node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
TfLiteNnapiDelegate	            0.000	    7.375	    6.549	 12.047%	 12.047%	     0.000	        1	[unet/Relu_1;StatefulPartitionedCall/unet/Relu_1;unet/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_1/BiasAdd/ReadVariableOp;unet/conv2d_1/BiasAdd;StatefulPartitionedCall/unet/conv2d_1/BiasAdd;unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_15/BiasAdd/ReadVariableOp;unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/Conv2D/ReadVariableOp;unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_1/Conv2D/ReadVariableOp;unet/conv2d_1/Conv2D;StatefulPartitionedCall/unet/conv2d_1/Conv2D1, unet/Relu_3;StatefulPartitionedCall/unet/Relu_3;unet/batch_normalization_3/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_3/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_3/BiasAdd/ReadVariableOp;unet/conv2d_3/BiasAdd;StatefulPartitionedCall/unet/conv2d_3/BiasAdd;unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_13/BiasAdd/ReadVariableOp;unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/Conv2D/ReadVariableOp;unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_3/Conv2D/ReadVariableOp;unet/conv2d_3/Conv2D;StatefulPartitionedCall/unet/conv2d_3/Conv2D1, unet/batch_normalization_7/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_7/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_7/BiasAdd/ReadVariableOp;unet/conv2d_7/BiasAdd;StatefulPartitionedCall/unet/conv2d_7/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_7/Conv2D/ReadVariableOp;unet/conv2d_7/Conv2D;StatefulPartitionedCall/unet/conv2d_7/Conv2D1]:25
CONV_2D	            6.554	   11.632	    6.679	 12.286%	 24.333%	     0.000	        1	[unet/batch_normalization_8/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_8/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_8/BiasAdd/ReadVariableOp;unet/conv2d_8/BiasAdd;StatefulPartitionedCall/unet/conv2d_8/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_8/Conv2D/ReadVariableOp;unet/conv2d_8/Conv2D;StatefulPartitionedCall/unet/conv2d_8/Conv2D1]:10
CONV_2D	           13.236	    7.296	    6.370	 11.717%	 36.050%	     0.000	        1	[unet/Relu_7;StatefulPartitionedCall/unet/Relu_7;unet/batch_normalization_9/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_9/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_9/BiasAdd/ReadVariableOp;unet/conv2d_9/BiasAdd;StatefulPartitionedCall/unet/conv2d_9/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_9/Conv2D/ReadVariableOp;unet/conv2d_9/Conv2D;StatefulPartitionedCall/unet/conv2d_9/Conv2D1]:11
CONV_2D	           19.609	    4.624	    5.985	 11.009%	 47.059%	     0.000	        1	[unet/Relu_8;StatefulPartitionedCall/unet/Relu_8;unet/batch_normalization_10/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_10/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_10/BiasAdd/ReadVariableOp;unet/conv2d_10/BiasAdd;StatefulPartitionedCall/unet/conv2d_10/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_10/Conv2D/ReadVariableOp;unet/conv2d_10/Conv2D;StatefulPartitionedCall/unet/conv2d_10/Conv2D1]:12
TfLiteNnapiDelegate	           25.596	    3.368	    3.671	  6.753%	 53.812%	     0.000	        1	[unet/Relu_10;StatefulPartitionedCall/unet/Relu_10;unet/batch_normalization_12/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_12/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_12/BiasAdd/ReadVariableOp;unet/conv2d_12/BiasAdd;StatefulPartitionedCall/unet/conv2d_12/BiasAdd;unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_13/BiasAdd/ReadVariableOp;unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/Conv2D/ReadVariableOp;unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_12/Conv2D/ReadVariableOp;unet/conv2d_12/Conv2D;StatefulPartitionedCall/unet/conv2d_12/Conv2D1]:26
TRANSPOSE_CONV	           29.271	    3.924	    4.570	  8.407%	 62.218%	     0.000	        1	[unet/conv2d_transpose/conv2d_transpose;StatefulPartitionedCall/unet/conv2d_transpose/conv2d_transpose1]:15
ADD	           33.843	    0.238	    0.267	  0.490%	 62.709%	     0.000	        1	[unet/conv2d_transpose/BiasAdd;StatefulPartitionedCall/unet/conv2d_transpose/BiasAdd]:16
TfLiteNnapiDelegate	           34.111	    4.639	    4.690	  8.627%	 71.335%	     0.000	        1	[unet/Relu_12;StatefulPartitionedCall/unet/Relu_12;unet/batch_normalization_14/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_14/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_14/BiasAdd/ReadVariableOp;unet/conv2d_14/BiasAdd;StatefulPartitionedCall/unet/conv2d_14/BiasAdd;unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_15/BiasAdd/ReadVariableOp;unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/Conv2D/ReadVariableOp;unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_14/Conv2D/ReadVariableOp;unet/conv2d_14/Conv2D;StatefulPartitionedCall/unet/conv2d_14/Conv2D1]:27
TRANSPOSE_CONV	           38.804	    7.393	    8.092	 14.884%	 86.219%	     0.000	        1	[unet/conv2d_transpose_1/conv2d_transpose;StatefulPartitionedCall/unet/conv2d_transpose_1/conv2d_transpose1]:20
ADD	           46.899	    0.915	    1.073	  1.974%	 88.194%	     0.000	        1	[unet/conv2d_transpose_1/BiasAdd;StatefulPartitionedCall/unet/conv2d_transpose_1/BiasAdd]:21
TfLiteNnapiDelegate	           47.974	    5.968	    6.418	 11.806%	100.000%	     0.000	        1	[Identity]:28
============================== Top by Computation Time ==============================
[node type]	          [start]	  [first]	 [avg ms]	     [%]	  [cdf%]	  [mem KB]	[times called]	[Name]
TRANSPOSE_CONV	           38.804	    7.393	    8.092	 14.884%	 14.884%	     0.000	        1	[unet/conv2d_transpose_1/conv2d_transpose;StatefulPartitionedCall/unet/conv2d_transpose_1/conv2d_transpose1]:20
CONV_2D	            6.554	   11.632	    6.679	 12.286%	 27.170%	     0.000	        1	[unet/batch_normalization_8/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_8/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_8/BiasAdd/ReadVariableOp;unet/conv2d_8/BiasAdd;StatefulPartitionedCall/unet/conv2d_8/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_8/Conv2D/ReadVariableOp;unet/conv2d_8/Conv2D;StatefulPartitionedCall/unet/conv2d_8/Conv2D1]:10
TfLiteNnapiDelegate	            0.000	    7.375	    6.549	 12.047%	 39.217%	     0.000	        1	[unet/Relu_1;StatefulPartitionedCall/unet/Relu_1;unet/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_1/BiasAdd/ReadVariableOp;unet/conv2d_1/BiasAdd;StatefulPartitionedCall/unet/conv2d_1/BiasAdd;unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_15/BiasAdd/ReadVariableOp;unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/Conv2D/ReadVariableOp;unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_1/Conv2D/ReadVariableOp;unet/conv2d_1/Conv2D;StatefulPartitionedCall/unet/conv2d_1/Conv2D1, unet/Relu_3;StatefulPartitionedCall/unet/Relu_3;unet/batch_normalization_3/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_3/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_3/BiasAdd/ReadVariableOp;unet/conv2d_3/BiasAdd;StatefulPartitionedCall/unet/conv2d_3/BiasAdd;unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_13/BiasAdd/ReadVariableOp;unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/Conv2D/ReadVariableOp;unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_3/Conv2D/ReadVariableOp;unet/conv2d_3/Conv2D;StatefulPartitionedCall/unet/conv2d_3/Conv2D1, unet/batch_normalization_7/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_7/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_7/BiasAdd/ReadVariableOp;unet/conv2d_7/BiasAdd;StatefulPartitionedCall/unet/conv2d_7/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_7/Conv2D/ReadVariableOp;unet/conv2d_7/Conv2D;StatefulPartitionedCall/unet/conv2d_7/Conv2D1]:25
TfLiteNnapiDelegate	           47.974	    5.968	    6.418	 11.806%	 51.023%	     0.000	        1	[Identity]:28
CONV_2D	           13.236	    7.296	    6.370	 11.717%	 62.740%	     0.000	        1	[unet/Relu_7;StatefulPartitionedCall/unet/Relu_7;unet/batch_normalization_9/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_9/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_9/BiasAdd/ReadVariableOp;unet/conv2d_9/BiasAdd;StatefulPartitionedCall/unet/conv2d_9/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_9/Conv2D/ReadVariableOp;unet/conv2d_9/Conv2D;StatefulPartitionedCall/unet/conv2d_9/Conv2D1]:11
CONV_2D	           19.609	    4.624	    5.985	 11.009%	 73.749%	     0.000	        1	[unet/Relu_8;StatefulPartitionedCall/unet/Relu_8;unet/batch_normalization_10/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_10/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_10/BiasAdd/ReadVariableOp;unet/conv2d_10/BiasAdd;StatefulPartitionedCall/unet/conv2d_10/BiasAdd;unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_11/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_11/BiasAdd/ReadVariableOp;unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/BiasAdd;StatefulPartitionedCall/unet/conv2d_11/Conv2D/ReadVariableOp;unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_11/Conv2D;StatefulPartitionedCall/unet/conv2d_10/Conv2D/ReadVariableOp;unet/conv2d_10/Conv2D;StatefulPartitionedCall/unet/conv2d_10/Conv2D1]:12
TfLiteNnapiDelegate	           34.111	    4.639	    4.690	  8.627%	 82.376%	     0.000	        1	[unet/Relu_12;StatefulPartitionedCall/unet/Relu_12;unet/batch_normalization_14/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_14/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_14/BiasAdd/ReadVariableOp;unet/conv2d_14/BiasAdd;StatefulPartitionedCall/unet/conv2d_14/BiasAdd;unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_15/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_15/BiasAdd/ReadVariableOp;unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/BiasAdd;StatefulPartitionedCall/unet/conv2d_15/Conv2D/ReadVariableOp;unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_15/Conv2D;StatefulPartitionedCall/unet/conv2d_14/Conv2D/ReadVariableOp;unet/conv2d_14/Conv2D;StatefulPartitionedCall/unet/conv2d_14/Conv2D1]:27
TRANSPOSE_CONV	           29.271	    3.924	    4.570	  8.407%	 90.783%	     0.000	        1	[unet/conv2d_transpose/conv2d_transpose;StatefulPartitionedCall/unet/conv2d_transpose/conv2d_transpose1]:15
TfLiteNnapiDelegate	           25.596	    3.368	    3.671	  6.753%	 97.535%	     0.000	        1	[unet/Relu_10;StatefulPartitionedCall/unet/Relu_10;unet/batch_normalization_12/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_12/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_12/BiasAdd/ReadVariableOp;unet/conv2d_12/BiasAdd;StatefulPartitionedCall/unet/conv2d_12/BiasAdd;unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/batch_normalization_13/FusedBatchNormV3;StatefulPartitionedCall/unet/conv2d_13/BiasAdd/ReadVariableOp;unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/BiasAdd;StatefulPartitionedCall/unet/conv2d_13/Conv2D/ReadVariableOp;unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_13/Conv2D;StatefulPartitionedCall/unet/conv2d_12/Conv2D/ReadVariableOp;unet/conv2d_12/Conv2D;StatefulPartitionedCall/unet/conv2d_12/Conv2D1]:26
ADD	           46.899	    0.915	    1.073	  1.974%	 99.510%	     0.000	        1	[unet/conv2d_transpose_1/BiasAdd;StatefulPartitionedCall/unet/conv2d_transpose_1/BiasAdd]:21
Number of nodes executed: 11
============================== Summary by node type ==============================
[Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called]
TfLiteNnapiDelegate	        4	    21.327	    39.233%	    39.233%	     0.000	        4
CONV_2D	        3	    19.033	    35.013%	    74.246%	     0.000	        3
TRANSPOSE_CONV	        2	    12.661	    23.291%	    97.537%	     0.000	        2
ADD	        2	     1.339	     2.463%	   100.000%	     0.000	        2
Timings (microseconds): count=50 first=57372 curr=57796 min=39517 max=63611 avg=54364.5 std=5088
Memory (bytes): count=0
11 nodes observed
	</description>
	<comments>
		<comment id='1' author='ek9852' date='2020-12-31T05:03:58Z'>
		&lt;denchmark-link:https://github.com/ek9852&gt;@ek9852&lt;/denchmark-link&gt;

Please share minimum stand alone code to replicate the error faced, or if possible share a colab gist with issue reported.
		</comment>
		<comment id='2' author='ek9852' date='2020-12-31T05:16:08Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 As I already mentioned. Just use the prebuilt benchmark binary on android phone with a unet model There is no application or custom code need.
		</comment>
		<comment id='3' author='ek9852' date='2020-12-31T19:31:47Z'>
		This turns out to be quant transpose convolution  layer not supported in  &lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/nnapi/nnapi_delegate.cc#L2228&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/nnapi/nnapi_delegate.cc#L2228&lt;/denchmark-link&gt;

The layer version of INT8 transpose convolution layer had a version  of 2 which failed the above checking.
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/versioning/op_version.cc#L261&gt;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/versioning/op_version.cc#L261&lt;/denchmark-link&gt;

I am opening a new case for that.
		</comment>
		<comment id='4' author='ek9852' date='2020-12-31T19:31:49Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46084&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/46084&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='5' author='ek9852' date='2020-12-31T19:36:36Z'>
		Opened a new ticket &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/46098&gt;#46098&lt;/denchmark-link&gt;
 for that
		</comment>
	</comments>
</bug>