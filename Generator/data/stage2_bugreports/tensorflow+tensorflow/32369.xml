<bug id='32369' author='bparr' open_date='2019-09-09T22:26:59Z' closed_time='2019-09-12T21:21:29Z'>
	<summary>tf.keras.layers.LSTM does not pass its trainable values to its cell</summary>
	<description>
System information

TensorFlow version 1.12.0 (I believe the issue appears in 1.14.0 as well).
Python version: 3.5.2

&lt;denchmark-code&gt;import tensorflow as tf

lstm_input = tf.placeholder(dtype=tf.float64, shape=[3, 1, 4])
lstm = tf.keras.layers.LSTM(512, dtype=tf.float64)
print(lstm.cell.dtype)  # prints None!!!
result = lstm(lstm_input)
&lt;/denchmark-code&gt;

When running this, the last line raises the following error:
TypeError: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.
The LSTM constructor is not passing the dtype to the LSTMCell constructor, so lstm.cell.dtype is just None. So the weights created in LSTMCell.build have their dtype default to tf.float32, which seems to cause the error. Adding lstm.cell._dtype = 'float64' right before the last line seems to "fix" the issue. There may be other mismatches between LSTM and LSTMCell, but the dtype mismatch is the one I ran into.
	</description>
	<comments>
		<comment id='1' author='bparr' date='2019-09-09T22:45:27Z'>
		Also seems to be a very similar problem with using tf.keras.layers.LSTM(512, trainable=False), where the created weights end up being trainable.
Am I misunderstanding the API?
		</comment>
		<comment id='2' author='bparr' date='2019-09-10T05:47:50Z'>
		Can you try with tf-nightly (!pip install tf-nightly ) and let us know whether the issue still persists. Thanks!
		</comment>
		<comment id='3' author='bparr' date='2019-09-10T17:04:25Z'>
		tf-nightly seems to handle dtype correctly. I'm guessing it's because of &lt;denchmark-link:https://github.com/tensorflow/tensorflow/commit/d90e521d71b88f469e68eb1a467606ea6d44c733&gt;d90e521&lt;/denchmark-link&gt;
 or similar.
However, if I use tf.keras.layers.LSTM(512, trainable=False), the created weights still end up being trainable. There may be other mismatches still besides trainable.
		</comment>
		<comment id='4' author='bparr' date='2019-09-11T12:24:08Z'>
		I have tried on colab with TF version 1.12,1.14, nightly versions usingand was able to reproduce the issue.Please, find the gist &lt;denchmark-link:https://colab.sandbox.google.com/gist/ravikyram/5575b47ccc0fc4a67ec99dbe4d48a4ca/untitled172.ipynb&gt;here&lt;/denchmark-link&gt;
.Thanks!
		</comment>
		<comment id='5' author='bparr' date='2019-09-11T20:56:19Z'>
		&lt;denchmark-link:https://github.com/bparr&gt;@bparr&lt;/denchmark-link&gt;
 I could reproduce the issue with even . However, there is a workaround as follows
#tf.keras.backend.set_floatx('float64')  #workaround
If you enable the above line, then it will set default dtype as you wish and it doesn't throw any error. Please check the &lt;denchmark-link:https://colab.sandbox.google.com/gist/jvishnuvardhan/1f3b64224cb322e36323f7baf0263154/tf_32369_dtype_keras.ipynb&gt;gist here&lt;/denchmark-link&gt;
. Thanks!
		</comment>
		<comment id='6' author='bparr' date='2019-09-12T21:21:30Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=32369&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=32369&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>