<bug id='37195' author='anthonyatp' open_date='2020-02-29T17:54:46Z' closed_time='2020-03-11T10:14:03Z'>
	<summary>ValueError: Dimension 0 in both shapes must be equal</summary>
	<description>
System information

OS Platform and Distribution: Google AI Platform
TensorFlow version: v2.0
Python version: v3.*
Machine type: 16 vCPUs, 30 GB RAM
GPU: 1x NVIDIA Tesla K80

I am training a model to caption images and have mostly used this tutorial: &lt;denchmark-link:https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset&gt;https://www.tensorflow.org/tutorials/text/image_captioning#download_and_prepare_the_ms-coco_dataset&lt;/denchmark-link&gt;

The only thing that is different from this notebook is that I am using a different dataset.
When I try and train the model I get the error in the first epoch:
ValueError: Dimension 0 in both shapes must be equal, but are 10 and 48. Shapes are [10,1] and [48,1]
I have tried this with many different batch sizes and the error is always in the format:
ValueError: Dimension 0 in both shapes must be equal, but are 10 and {BATHCH_SIZE}. Shapes are [10,1] and [{BATHCH_SIZE},1]
I also found a similar issue on github: &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/27862&gt;#27862&lt;/denchmark-link&gt;

It is suggested to change the batch size to 48 but that didn't work for me.
Can anyone help out?
Thanks
	</description>
	<comments>
		<comment id='1' author='anthonyatp' date='2020-02-29T18:41:20Z'>
		Just from the looks of your error message, I’m wondering if setting the batch size to 10 would solve the issue. I know this isn’t a fundamental fix or an answer to your question, but can you give it a try?
		</comment>
		<comment id='2' author='anthonyatp' date='2020-02-29T19:13:15Z'>
		yes, I tried that too. But still got the error:
ValueError: Dimension 0 in both shapes must be equal, but are 4 and 10. Shapes are [4,1] and [10,1]
I haven't tried batch size 4 but I assume there is a deeper issue here
		</comment>
		<comment id='3' author='anthonyatp' date='2020-03-02T09:28:14Z'>
		&lt;denchmark-link:https://github.com/anthonyatp&gt;@anthonyatp&lt;/denchmark-link&gt;

Will it be possible to share colab link or simple standalone code with supporting files to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!
		</comment>
		<comment id='4' author='anthonyatp' date='2020-03-02T14:43:34Z'>
		So, I managed to solve the issue by limiting my dataset to a round number (it was 14,586 and I limited to 14,000).
Is this something that should always be done with datasets? Or is there another reason why I couldn't train the model initially?
Apologies if this is naivety on my behalf. I can put together a notebook to share if required
		</comment>
		<comment id='5' author='anthonyatp' date='2020-03-03T23:27:39Z'>
		&lt;denchmark-link:https://github.com/anthonyatp&gt;@anthonyatp&lt;/denchmark-link&gt;
 Please share the gist so that we can figure out where the issue was. Thanks!
		</comment>
		<comment id='6' author='anthonyatp' date='2020-03-11T10:14:04Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37195&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37195&gt;No&lt;/denchmark-link&gt;

		</comment>
	</comments>
</bug>