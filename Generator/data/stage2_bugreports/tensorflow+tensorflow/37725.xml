<bug id='37725' author='innjoshka' open_date='2020-03-19T20:28:45Z' closed_time='2020-04-22T00:57:46Z'>
	<summary>UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.</summary>
	<description>
System information

OS Platform and Distribution: Ubuntu 18.04.
LInux Kernel:


5.3.0-40-generic #32~18.04.1-Ubuntu SMP Mon Feb 3 14:05:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux


TensorFlow installed from source as written here (tried from binary also):
Build was with all flags OFF except cuda-Y
TensorFlow version: 2.1.0
Python version: 3.6.9
Bazel: 0.29.1
GCC/Compiler version: 7.5.0
CUDA/cuDNN version: - GPU model and memory:
CUDA: 10.1
CuDNN: 7.6.5 ( tried 7.6.1 also)
GPU model: Nvidia Geforce 1660 Ti (6 GB)

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Tried to execute simple MNIST CNN &lt;denchmark-link:https://keras.io/examples/mnist_cnn/&gt;example&lt;/denchmark-link&gt;
 but with  importing NOT keras!
Error

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
[[node sequential/conv2d/Conv2D (defined at :70) ]] [Op:__inference_distributed_function_1004]
Function call stack:
distributed_function

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Firstly, I got this error when installed tensorflow-gpu from binary via pip.
Then, I thought that against CUDA-10.1 I have to manually build tensorflow via bazel but after successful built - I got the same error. I have also tried change CuDNN version from 7.6.5 to 7.6.1 but again it did not help.
CUDA downloaded from nvidia website and works perfectly
CuDNN is rightly installed by downloading it from nvidia website and copying into /usr/loca/cuda-*
&lt;denchmark-code&gt;cp -P cuda/include/cudnn.h /usr/local/cuda-${CUDA_VERSION}/include
cp -P cuda/lib64/libcudnn* /usr/local/cuda-${CUDA_VERSION}/lib64/
chmod a+r /usr/local/cuda-${CUDA_VERSION}/lib64/libcudnn*
&lt;/denchmark-code&gt;

If I try to train model without Convolution layers all works great with GPU calculations:
for example
&lt;denchmark-code&gt;model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
&lt;/denchmark-code&gt;

If you need some additional information, I will add it.
Please, help me solve this issue, I truly don't know what else try using. BTW. As I am concerned, I need CUDA-10.1  because only this CUDA supports my Nvidia Geforce 1660 Ti.
	</description>
	<comments>
		<comment id='1' author='innjoshka' date='2020-03-20T06:01:10Z'>
		&lt;denchmark-link:https://github.com/innjoshka&gt;@innjoshka&lt;/denchmark-link&gt;

please share the tensorflow version on which this issue is faced.
could you please refer to existing similar issues as per error message shared:
&lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34355&gt;#34355&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34888&gt;#34888&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34518&gt;#34518&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/28326&gt;#28326&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/25160&gt;#25160&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/24828&gt;#24828&lt;/denchmark-link&gt;
 &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/33666&gt;#33666&lt;/denchmark-link&gt;

		</comment>
		<comment id='2' author='innjoshka' date='2020-03-20T09:01:31Z'>
		&lt;denchmark-link:https://github.com/Saduf2019&gt;@Saduf2019&lt;/denchmark-link&gt;
 added tensorflow version to the top.
from this issue &lt;denchmark-link:https://github.com/tensorflow/tensorflow/issues/34888&gt;#34888&lt;/denchmark-link&gt;
 I got it working
&lt;denchmark-code&gt; import tensorflow as tf
 gpus= tf.config.experimental.list_physical_devices('GPU')
 tf.config.experimental.set_memory_growth(gpus[0], True)
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

set_memory_growth, Conv2D, NN now trains - GPU 22s/epoch vs 30s/epoch CPU
Without  set_memory_growth, Conv2D, NN now trains - error
But after set_memory_growth, NN now trains, GPU 22s/epoch vs 30s/epoch CPU. ( Not the great improvement) And how is that possible that 6GB GPU errors on MNIST dataset with Conv2D layer?
Tested on this architecture
&lt;denchmark-code&gt;model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=tf.keras.losses.categorical_crossentropy,
              optimizer=tf.keras.optimizers.Adadelta(),
              metrics=['accuracy'])
&lt;/denchmark-code&gt;

&lt;denchmark-h:hr&gt;&lt;/denchmark-h&gt;

Without set_memory_growth  and without Conv2D layers on MNIST,  trains time on my machine takes GPU 3s.
With set_memory_growth  and without Conv2D layers on MNIST,  trains time on my machine takes GPU 5-6s.
Tested on this architecture
&lt;denchmark-code&gt;model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

model.compile(loss=tf.keras.losses.categorical_crossentropy,
              optimizer=tf.keras.optimizers.Adadelta(),
              metrics=['accuracy'])
&lt;/denchmark-code&gt;

Is that normal that difference 22s vs 5-6s? I understand that different architecture but Conv2D and 4 times time difference
		</comment>
		<comment id='3' author='innjoshka' date='2020-03-23T21:57:43Z'>
		&lt;denchmark-link:https://github.com/innjoshka&gt;@innjoshka&lt;/denchmark-link&gt;
 Can you please check this with  and let me know if the issue still persists. Thanks!
		</comment>
		<comment id='4' author='innjoshka' date='2020-03-24T10:21:25Z'>
		&lt;denchmark-link:https://github.com/gowthamkpr&gt;@gowthamkpr&lt;/denchmark-link&gt;
 I will try, Should I build from source or download via pip (as I know  cannot be downloaded via pip, only build from source, am I right?)
Can you give working versions of packages to successfully build :
CUDA version
CuDNN version
Bazel version
Nvidia driver version (435 is the latest for 10.1)
		</comment>
		<comment id='5' author='innjoshka' date='2020-04-05T07:57:25Z'>
		&lt;denchmark-code&gt;import tensorflow as tf
gpus= tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpus[0], True)
&lt;/denchmark-code&gt;

using this code inside my jupyter notebook worked.
&lt;denchmark-code&gt;tesorflow version = 2.1.0
Driver Version: 440.64       
CUDA Version: 10.2 
cudnn version: 7.6.5 
&lt;/denchmark-code&gt;

		</comment>
		<comment id='6' author='innjoshka' date='2020-04-22T00:57:46Z'>
		Closing this issue as it has been resolved. Please add additional comments for us to open this issue again. Thanks!
		</comment>
		<comment id='7' author='innjoshka' date='2020-04-22T00:57:48Z'>
		Are you satisfied with the resolution of your issue?
&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37725&gt;Yes&lt;/denchmark-link&gt;

&lt;denchmark-link:https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&amp;entry.2137816233=https://github.com/tensorflow/tensorflow/issues/37725&gt;No&lt;/denchmark-link&gt;

		</comment>
		<comment id='8' author='innjoshka' date='2020-05-08T23:32:18Z'>
		I had this same issue and any one of this solution helped me, but I got another solution. Apparently some TF.keras libraries were giving me problems instead I imported just keras libraries.
For example, here is my importing list for one project:
import sys
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from keras.models import Sequential  # Can not be moved
from tensorflow.keras.models import load_model
from keras.layers import Conv2D, MaxPooling2D  # Can not be moved
from keras.layers import Activation, Dropout, Flatten, Dense # Can not be moved
from tensorflow.keras import backend as K
from tensorflow.keras.preprocessing import image
import numpy as np
from os import listdir
from os.path import isfile, join
from keras import optimizers
import matplotlib.pyplot as plt
I am using:
Python : 3.6.8
Cuda: 10
Cunn: 7.6.0
tensorflow-gpu       2.0.0
Keras                2.3.1
I spent more than 8 hours trying all the solutions of this chat and just after doing this importing and configuration everything goes well. Actually, really well.
I believe that I can upgrade to tensorflow 2.1 and the corresponding Cuda and Cunn without any problem.
		</comment>
	</comments>
</bug>