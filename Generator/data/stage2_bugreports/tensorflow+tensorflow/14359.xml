<bug id='14359' author='humcasma' open_date='2017-11-08T12:23:58Z' closed_time='2017-11-10T00:48:59Z'>
	<summary>Keras model.trainable_weights does not return all trainable weights</summary>
	<description>
&lt;denchmark-h:h3&gt;System information&lt;/denchmark-h&gt;


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.12.6
TensorFlow installed from (source or binary): BINARY
TensorFlow version (use command below): v1.4.0-rc1-11-g130a514 1.4.0
Python version: 3.5.4
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

&lt;denchmark-h:h3&gt;Describe the problem&lt;/denchmark-h&gt;

When creating a Keras model where two "towers" are merged with help of a Lambda layer, not all trainable weights are added to trainable_weights.
&lt;denchmark-h:h3&gt;Source code / logs&lt;/denchmark-h&gt;

The code below creates a model with four trainable variables: 2 weights and 2 biases. However, model.trainable_weights returns only one weight and one bias.
&lt;denchmark-code&gt;def func(x,y):
    return tf.add(x,y)

a= tf.keras.layers.Input(shape= (64,))
b = tf.keras.layers.Dense(5)(a)
c = tf.keras.layers.Dense(5)(a)
d = tf.keras.layers.Lambda(func, arguments={'y':c})(b)
model = tf.keras.models.Model(a, d)
model.trainable_weights
&lt;/denchmark-code&gt;

Output:
[&lt;tf.Variable 'dense/kernel:0' shape=(64, 5) dtype=float32_ref&gt;, &lt;tf.Variable 'dense/bias:0' shape=(5,) dtype=float32_ref&gt;] 
	</description>
	<comments>
		<comment id='1' author='humcasma' date='2017-11-08T20:36:22Z'>
		&lt;denchmark-link:https://github.com/martinwicke&gt;@martinwicke&lt;/denchmark-link&gt;
, can you take a look at this?
		</comment>
		<comment id='2' author='humcasma' date='2017-11-10T00:48:59Z'>
		Your Lambda layer unfortunately breaks the model topology. So when you're defining your model, it's not taking into account the layers that came before c, because c is not being tracked as an input to your Lambda layer. Here's how to do it correctly in the general case:
def func(inputs):
    return tf.add(inputs[0], inputs[1])

a = tf.keras.Input(shape=(64,))
b = tf.keras.layers.Dense(5)(a)
c = tf.keras.layers.Dense(5)(a)
d = tf.keras.layers.Lambda(func)([b, c])
model = tf.keras.models.Model(a, d)
model.trainable_weights
But really in your case you could do:
a = tf.keras.Input(shape=(64,))
b = tf.keras.layers.Dense(5)(a)
c = tf.keras.layers.Dense(5)(a)
d = tf.keras.layers.add([b, c])
model = tf.keras.models.Model(a, d)
model.trainable_weights
		</comment>
	</comments>
</bug>